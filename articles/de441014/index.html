<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤲🏼 🈯️ 👸🏽 Low-Budget-Stereo-Rendering in wenigen Codezeilen (Stereogramm, Anaglyphe, Stereoskop) ⛩️ 🍼 👼🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ein weiteres Wochenende ist gekommen, was bedeutet, dass ich noch ein paar Dutzend Codezeilen schreibe und ein oder zwei Illustrationen mache. In früh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Low-Budget-Stereo-Rendering in wenigen Codezeilen (Stereogramm, Anaglyphe, Stereoskop)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441014/">  Ein weiteres Wochenende ist gekommen, was bedeutet, dass ich noch ein paar Dutzend Codezeilen schreibe und ein oder zwei Illustrationen mache.  In früheren Artikeln habe ich erklärt, wie man <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raytracing macht</a> und sogar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dinge in die Luft jagt</a> .  Das mag Sie überraschen, aber Computergrafiken sind recht einfach: Selbst ein paar hundert Zeilen bloßes C ++ können einige sehr aufregende Bilder erzeugen. <br><br>  Das heutige Thema ist das binokulare Sehen, und wir werden dabei nicht einmal die 100-Linien-Grenze durchbrechen.  Da wir 3D-Szenen zeichnen können, wäre es dumm, Stereopaare zu ignorieren. Deshalb machen wir heute so etwas: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br><br>  Der Wahnsinn der Schöpfer von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Magic Carpet macht</a> mich immer noch wahnsinnig.  Für diejenigen, die es nicht wissen, konnten Sie mit diesem Spiel ein 3D-Rendering sowohl im Anaglyphen- als auch im Stereogrammmodus <b>über das Haupteinstellungsmenü durchführen</b> !  Das war wild für mich. <br><br><h1>  Parallaxe </h1><br>  Also, lass uns beginnen.  Was bewirkt zunächst, dass unser Sehapparat die Tiefe von Objekten wahrnimmt?  Es gibt einen klugen Begriff "Parallaxe".  Konzentrieren wir uns auf den Bildschirm.  Alles, was sich in der Ebene des Bildschirms befindet, wird von unserem Gehirn als ein Objekt registriert.  Wenn jedoch eine Fliege zwischen unseren Augen und dem Bildschirm fliegt, nimmt das Gehirn sie als zwei Objekte wahr.  Die Spinne hinter dem Bildschirm wird ebenfalls verdoppelt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Unser Gehirn ist sehr effizient bei der Analyse leicht unterschiedlicher Bilder.  Es verwendet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">binokulare Disparität</a> , um mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereopsis</a> Informationen über die Tiefe von 2D-Bildern zu erhalten, die von der Netzhaut stammen.  Nun, scheiß auf die großen Worte und lass uns einfach Bilder zeichnen! <br><br>  Stellen wir uns vor, unser Monitor ist ein Fenster zur virtuellen Welt :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Unsere Aufgabe ist es, zwei Bilder von dem zu zeichnen, was wir durch dieses „Fenster“ sehen, eines für jedes Auge.  Auf dem Bild darüber das rot-blaue „Sandwich“.  Vergessen wir zunächst, wie wir diese Bilder an unser Gehirn liefern können. In diesem Stadium müssen wir nur zwei separate Dateien speichern.  Insbesondere möchte ich wissen, wie ich diese Bilder mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">meinem winzigen Raytracer erhalten kann</a> . <br><br>  Nehmen wir an, der Winkel ändert sich nicht und es ist der (0,0, -1) -Vektor.  Nehmen wir an, wir können die Kamera in den Bereich zwischen den Augen bewegen, aber was dann?  Ein kleines Detail: Der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kegelstumpf</a> durch unser „Fenster“ ist asymmetrisch.  Unser Raytracer kann jedoch nur einen symmetrischen Kegelstumpf erzeugen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  Und was machen wir jetzt?  Cheat :) <br><br>  Wir können etwas breitere Bilder als nötig rendern und dann einfach die zusätzlichen Teile ausschneiden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyphe </h1><br>  Ich denke, wir haben den grundlegenden Rendering-Mechanismus behandelt, und jetzt befassen wir uns mit dem Problem, das Bild an unser Gehirn zu liefern.  Der einfachste Weg ist diese Art von Brille: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Wir erstellen zwei Graustufen-Renderings und weisen den roten und blauen Kanälen jeweils linke und rechte Bilder zu.  Das bekommen wir: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  Das rote Glas schneidet einen Kanal aus, während das blaue Glas den anderen ausschneidet.  In Kombination erhalten die Augen ein anderes Bild und wir nehmen es in 3D wahr.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier sind die Änderungen</a> am Haupt-Commit des tinyraytracer.  Die Änderungen umfassen die Kamerapositionierung sowohl für die Augen- als auch für die Kanalmontage. <br><br>  Anaglyphen-Rendering ist eine der ältesten Methoden zum Betrachten von (computergenerierten) Stereobildern.  Es hat viele Nachteile, zum Beispiel eine schlechte Farbübertragung.  Andererseits sind diese zu Hause sehr einfach zu erstellen. <br><br>  Wenn Sie keinen Compiler auf Ihrem Computer haben, ist dies kein Problem.  Wenn Sie ein Guithub-Konto haben, können Sie den Code anzeigen, bearbeiten und ausführen (sic!) Mit einem Klick in Ihrem Browser. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://gitpod.io/&amp;usg=ALkJrhgQHGWqGIIFB1YgpUOUvMQT9dJC3w#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Im Gitpod öffnen"></a> <br><br>  Wenn Sie diesen Link öffnen, erstellt gitpod eine virtuelle Maschine für Sie, startet VS Code und öffnet ein Terminal auf der Remote-Maschine.  Im Befehlsverlauf (klicken Sie auf die Konsole und drücken Sie die Aufwärts-Taste) gibt es einen vollständigen Befehlssatz, mit dem Sie den Code kompilieren, starten und das resultierende Image öffnen können. <br><br><h1>  Stereoskop </h1><br>  Als Smartphones zum Mainstream wurden, erinnerten wir uns an die Erfindung des 19. Jahrhunderts, das Stereoskop.  Vor ein paar Jahren schlug Google vor, zwei Objektive (die zu Hause leider schwer herzustellen sind, man muss sie kaufen), ein Stück Pappe (überall erhältlich) und ein Smartphone (in der Tasche) zu verwenden, um glaubwürdig zu sein VR-Brille. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Sie sind reichlich auf AliExpress und kosten etwa 3 US-Dollar pro Paar.  Im Vergleich zum Anaglyphen-Rendering haben wir nicht einmal zu viel zu tun: Nehmen Sie einfach zwei Bilder auf und legen Sie sie nebeneinander.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist das Commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  Genau genommen müssen wir je nach Objektiv möglicherweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Verzerrung des Objektivs korrigieren</a> , aber das hat mich nicht gestört, da es trotzdem gut aussah.  Aber wenn wir wirklich die Fassvorverzerrung anwenden müssen, die die natürliche Verzerrung des Objektivs kompensiert, sieht es für mein Smartphone und meine Brille so aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br>  Hier ist der Gitpod-Link: <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://gitpod.io/&amp;usg=ALkJrhgQHGWqGIIFB1YgpUOUvMQT9dJC3w#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Im Gitpod öffnen"></a> <br><br><h1>  Autostereogramme </h1><br>  Und was machen wir, wenn wir keine zusätzliche Ausrüstung verwenden möchten?  Dann gibt es nur noch eine Option - Schielen.  Das vorige Bild ist ehrlich gesagt völlig ausreichend für die Stereoanzeige. Schielen Sie einfach die Augen (entweder kreuzen Sie die Augen oder ummauern Sie sie).  Hier ist ein Schema, das uns sagt, wie wir die vorherige Abbildung sehen können.  Zwei rote Linien zeigen die Bilder, wie sie von der linken Netzhaut wahrgenommen werden, zwei blaue - die rechte Netzhaut. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Wenn wir uns auf den Bildschirm konzentrieren, werden vier Bilder zu zwei kombiniert.  Wenn wir die Augen kreuzen oder uns auf ein entferntes Objekt konzentrieren, ist es möglich, dem Gehirn „drei“ Bilder zuzuführen.  Die zentralen Bilder überlappen sich, wodurch der Stereoeffekt entsteht. <br><br>  Unterschiedliche Menschen wenden unterschiedliche Methoden an: Zum Beispiel kann ich meine Augen nicht kreuzen, sondern sie leicht ummauern.  Es ist wichtig, dass das für eine bestimmte Methode erstellte Autostereogramm nur mit dieser Methode angezeigt wird. Andernfalls erhalten wir eine invertierte Tiefenkarte (erinnern Sie sich an positive und negative Parallaxe?).  Das Problem ist, dass es schwierig ist, die Augen zu kreuzen, so dass es nur bei kleinen Bildern funktioniert.  Aber was ist, wenn wir größere wollen?  Lassen Sie uns die Farben vollständig opfern und uns nur auf den Teil der Tiefenwahrnehmung konzentrieren.  Hier ist das Bild, das wir uns bis zum Ende des Artikels erhoffen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Dies ist ein Autostereogramm mit Wandaugen.  Für diejenigen, die die andere Methode bevorzugen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier ein Bild dafür</a> .  Wenn Sie nicht an Autostereogramme gewöhnt sind, probieren Sie verschiedene Bedingungen aus: Vollbild, kleineres Bild, Helligkeit, Dunkelheit.  Unser Ziel ist es, unsere Augen so zu wandeln, dass sich die beiden nahe gelegenen vertikalen Streifen überlappen.  Am einfachsten ist es, sich auf den oberen linken Teil des Bildes zu konzentrieren, da es einfach ist.  Persönlich öffne ich das Bild im Vollbildmodus.  Vergessen Sie nicht, auch den Mauszeiger zu entfernen! <br><br>  Hören Sie nicht bei einem unvollständigen 3D-Effekt auf.  Wenn Sie vage rundliche Formen sehen und der 3D-Effekt schwach ist, ist die Illusion unvollständig.  Die Kugeln sollen vom Bildschirm zum Betrachter „springen“, der Effekt muss stabil und nachhaltig sein.  Die Stereopsis hat eine Gisterese: Sobald Sie ein stabiles Bild erhalten, wird es umso detaillierter, je länger Sie es beobachten.  Je weiter die Augen vom Bildschirm entfernt sind, desto größer ist der Tiefenwahrnehmungseffekt. <br><br>  Dieses Stereogramm wurde mit einer Methode gezeichnet, die vor 25 Jahren in diesem Artikel vorgeschlagen wurde: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anzeigen von 3D-Bildern: Algorithmen für Einzelbild-Zufallspunktstereogramme</a> ." <br><br><h3>  Lass uns anfangen </h3><br>  Der Ausgangspunkt für das Rendern von Autostereogrammen ist die Tiefenkarte (da wir die Farben aufgeben).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dieses Commit</a> zeichnet das folgende Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Die näheren und weiteren Ebenen bestimmen unsere Tiefe: Der am weitesten entfernte Punkt in meiner Karte hat die Tiefe 0, während der nächstgelegene die Tiefe 1 hat. <br><br><h3>  Die Grundprinzipien </h3><br>  Nehmen wir an, unsere Augen befinden sich in einem Abstand vom Bildschirm.  Wir platzieren unsere (imaginäre) Fernebene (z = 0) im gleichen Abstand „hinter“ dem Bildschirm.  Wir wählen die μ-Variable, die den Ort der nahen Ebene (z = 1) bestimmt, die sich in μd Entfernung von der fernen Ebene befindet.  Für meinen Code habe ich μ = ⅓ gewählt.  Insgesamt lebt unsere gesamte „Welt“ in einer Entfernung von d-μd bis d hinter dem Bildschirm.  Angenommen, wir kennen den Abstand zwischen den Augen (in Pixel habe ich 400 Pixel gewählt): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Wenn wir den roten Punkt betrachten, sollten zwei grün markierte Pixel im Stereogramm dieselbe Farbe haben.  Wie berechnet man den Abstand zwischen ihnen?  Einfach  Wenn der aktuell projizierte Punkt die Tiefe von z hat, entspricht die Parallaxe geteilt durch den Abstand zwischen den Augen dem Bruchteil zwischen den entsprechenden Tiefen: p / e = (d-dμz) / (2d-dμz).  Beachten Sie übrigens, dass d vereinfacht ist und nirgendwo anders erscheint!  Dann ist p / e = (1 &amp; mgr; z) / (2 &amp; mgr; z), was bedeutet, dass die Parallaxe gleich p = e * (1 &amp; mgr; z) / (2 &amp; mgr; z) Pixel ist. <br><br>  Die Hauptidee hinter dem Autostereogramm ist: Wir gehen die gesamte Tiefenkarte durch, bestimmen für jeden Tiefenwert, welche Pixel dieselbe Farbe haben, und schreiben sie in unser System von Einschränkungen.  Dann gehen wir vom Zufallsbild aus und versuchen, alle zuvor festgelegten Einschränkungen zu erfüllen. <br><br><h3>  Quellbild vorbereiten </h3><br>  Hier bereiten wir das Bild vor, das später durch Parallaxenbeschränkungen eingeschränkt wird.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist das Commit</a> , und es zeichnet dies: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Beachten Sie, dass die Farben größtenteils zufällig sind, abgesehen von dem roten Kanal, in den ich rand () * sin eingefügt habe, um ein periodisches Muster zu erstellen.  Die Streifen sind 200 Pixel voneinander entfernt, was (bei μ = 1/3 und e = 400) der maximale Parallaxenwert in unserer Welt (der fernen Ebene) ist.  Das Muster ist technisch nicht notwendig, aber es hilft, die Augen zu fokussieren. <br><br><h3>  Autostereogramm-Rendering </h3><br>  Tatsächlich sieht der vollständige Code, der das Autostereogramm zeichnet, folgendermaßen aus: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist das Commit</a> . Die Funktion int parallax (const float z) gibt den Abstand zwischen Pixeln derselben Farbe für den aktuellen Tiefenwert an.  Wir rendern das Stereogramm zeilenweise, da die Linien unabhängig voneinander sind (wir haben keine vertikale Parallaxe).  Die Hauptschleife durchläuft einfach jede Zeile.  Jedes Mal, wenn mit einem unbegrenzten Satz von Pixeln begonnen wird, wird für jedes Pixel eine Gleichheitsbeschränkung hinzugefügt.  Am Ende erhalten wir eine bestimmte Anzahl von Clustern gleichfarbiger Pixel.  Beispielsweise sollten Pixel mit den Indizes links und rechts identisch sein. <br><br>  Wie speichere ich diese Einschränkungen?  Der einfachste Weg ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Union-Find-Datenstruktur</a> .  Ich werde nicht ins Detail gehen, gehe einfach zu Wikipedia, es sind buchstäblich drei Codezeilen.  Der Hauptpunkt ist, dass für jeden Cluster ein bestimmtes "Wurzel" -Pixel für den Cluster verantwortlich ist.  Das Stammpixel behält seine ursprüngliche Farbe bei, und alle anderen Pixel im Cluster müssen aktualisiert werden: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://gitpod.io/&amp;usg=ALkJrhgQHGWqGIIFB1YgpUOUvMQT9dJC3w#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Im Gitpod öffnen"></a> <br><br><h1>  Fazit </h1><br>  Das war's wirklich.  Zwanzig Codezeilen und unser Autostereogramm stehen bereit, damit Sie Ihre Augen darüber brechen können.  Übrigens, wenn wir uns genug anstrengen, ist es möglich, Farbinformationen zu übertragen. <br><br>  Ich habe andere stereoskopische Systeme wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">polarisierte 3D-Systeme</a> nicht behandelt, da ihre Herstellung viel teurer ist.  Wenn ich etwas verpasst habe, können Sie mich gerne korrigieren! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441014/">https://habr.com/ru/post/de441014/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441004/index.html">Splunk verlässt Russland (komplett)</a></li>
<li><a href="../de441006/index.html">Eine Übersicht über Bildsegmentierungsmethoden in der Scikit-Bildbibliothek</a></li>
<li><a href="../de441008/index.html">Kaninchen MQ im Verarbeitungssystem der Bewohner</a></li>
<li><a href="../de441010/index.html">Geh runter auf die sterbliche Erde ...</a></li>
<li><a href="../de441012/index.html">Interessante Fakten über die Geschichte des chinesischen Mondprogramms und der Weltraummission Chang'e-4</a></li>
<li><a href="../de441018/index.html">Tools zur Entwicklung und Spezifikation von NanoCAD Mechanics-Programmen</a></li>
<li><a href="../de441020/index.html">Wie VTB zu einem einzigen Wissen kam</a></li>
<li><a href="../de441022/index.html">Häufige Fehler von Fahrgästen von Eisenbahnen und Fluggesellschaften</a></li>
<li><a href="../de441024/index.html">Wir schreiben einen Crawler für ein oder zwei 1.0</a></li>
<li><a href="../de441026/index.html">VMware NSX für die Kleinsten. Teil 2. Firewall und NAT konfigurieren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
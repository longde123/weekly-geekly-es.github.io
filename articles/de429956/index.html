<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë® ü¶Ñ üë®üèº‚Äçüé® Kontinuierliche Integration in Yandex. Teil 2 üëì ‚è±Ô∏è üîù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im vorherigen Artikel haben wir √ºber die √úbertragung der Entwicklung auf ein einzelnes Repository mit einem stammbasierten Entwicklungsansatz mit einh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kontinuierliche Integration in Yandex. Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/429956/"><p>  Im vorherigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel haben</a> wir √ºber die √úbertragung der Entwicklung auf ein einzelnes Repository mit einem stammbasierten Entwicklungsansatz mit einheitlichen Systemen f√ºr Montage, Test, Bereitstellung und √úberwachung gesprochen und dar√ºber, welche Aufgaben ein kontinuierliches Integrationssystem l√∂sen muss, um unter solchen Bedingungen effektiv zu arbeiten. </p><br><p>  Heute werden wir Habr-Lesern √ºber das Ger√§t des kontinuierlichen Integrationssystems berichten. </p><br><p><img src="https://habrastorage.org/webt/wb/mt/xc/wbmtxcvurtd6cdv1aomjrtcyfw8.png" alt="Bild"></p><br><p>  Ein kontinuierliches Integrationssystem muss zuverl√§ssig und schnell funktionieren.  Das System sollte schnell auf eingehende Ereignisse reagieren und keine zus√§tzlichen Verz√∂gerungen bei der √úbermittlung der Testergebnisse an den Benutzer verursachen.  Die Ergebnisse der Montage und Pr√ºfung m√ºssen dem Benutzer in Echtzeit √ºbermittelt werden. </p><a name="habracut"></a><br><p>  Das kontinuierliche Integrationssystem ist ein Streaming-Datenverarbeitungssystem mit minimalen Verz√∂gerungen. </p><br><p>  Nachdem alle Ergebnisse zu einem bestimmten Zeitpunkt gesendet wurden (konfigurieren, erstellen, formatieren, kleine Tests, mittlere Tests usw.), signalisiert das Build-System dies dem kontinuierlichen Integrationssystem (‚Äûschlie√üt‚Äú die Phase), und der Benutzer sieht dies f√ºr diese Pr√ºfung und Zu diesem Zeitpunkt sind alle Ergebnisse bekannt.  Jede Stufe wird unabh√§ngig geschlossen.  Der Benutzer erh√§lt schneller ein n√ºtzliches Signal.  Nach Abschluss aller Phasen gilt die Pr√ºfung als abgeschlossen. </p><br><p>  Um das System zu implementieren, haben wir uns f√ºr die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kappa-</a> Architektur entschieden.  Das System besteht aus 2 Subsystemen: </p><br><ul><li>  Die Ereignis- und Datenverarbeitung findet in einer Echtzeitschaltung statt.  Alle Eingabedaten werden als Datenstr√∂me (Streams) behandelt.  Zuerst werden die Ereignisse im Stream aufgezeichnet und erst dann verarbeitet. </li><li>  Die Ergebnisse der Datenverarbeitung werden kontinuierlich in die Datenbank geschrieben, wo dann Aufrufe √ºber die API ausgef√ºhrt werden.  In der Kappa-Architektur wird dies als Serving Layer bezeichnet. </li></ul><br><p>  Alle Anforderungen zur Daten√§nderung m√ºssen die Echtzeitschaltung durchlaufen, da Sie dort immer den aktuellen Status des Systems haben m√ºssen.  Leseanforderungen werden nur an die Datenbank gesendet. </p><br><img src="https://habrastorage.org/webt/fb/bu/ps/fbbups7bcp0zgwvigxv5un9reek.png"><br><br><p>  Wo immer m√∂glich, befolgen wir die Nur-Anh√§ngen-Regel.  Keine √Ñnderungen oder L√∂schungen von Objekten, mit Ausnahme des L√∂schens alter, unn√∂tiger Daten. </p><br><p>  Pro Tag werden mehr als 2 TB Rohdaten durch den Dienst geleitet. </p><br><p>  Vorteile: </p><br><ul><li>  Streams enthalten alle Ereignisse und Nachrichten.  Wir k√∂nnen immer verstehen, was und wann passiert ist.  Stream kann als gro√ües Protokoll wahrgenommen werden. </li><li>  Hohe Effizienz und minimaler Overhead.  Es stellt sich heraus, dass es sich um ein vollst√§ndig ereignisorientiertes System handelt, bei dem keine Abfragen verloren gehen.  Es gibt keine Veranstaltung - wir machen nichts extra. </li><li>  Der Anwendungscode behandelt praktisch nicht die Grundelemente der Thread-Synchronisation und den von Threads gemeinsam genutzten Speicher.  Dies macht das System zuverl√§ssiger. </li><li>  Die Prozessoren sind gut voneinander isoliert, weil  Interagiere nicht direkt, nur √ºber Streams.  Eine gute Testabdeckung kann bereitgestellt werden. </li></ul><br><p>  Die Verarbeitung von Streaming-Daten ist jedoch nicht so einfach: </p><br><ul><li> Ein gutes Verst√§ndnis des Rechenmodells ist erforderlich.  Sie m√ºssen vorhandene Datenverarbeitungsalgorithmen √ºberdenken.  Nicht alle Algorithmen fallen sofort in das Stream-Modell und Sie m√ºssen Ihren Kopf ein wenig zerschlagen. </li><li>  Es muss sichergestellt werden, dass die Reihenfolge des Eingangs und der Verarbeitung von Ereignissen eingehalten wird. </li><li>  Sie m√ºssen in der Lage sein, miteinander verbundene Ereignisse zu verarbeiten, d. H.  Sie haben schnellen Zugriff auf alle erforderlichen Daten, w√§hrend Sie eine neue Nachricht verarbeiten. </li><li>  Sie m√ºssen auch in der Lage sein, doppelte Ereignisse zu verarbeiten. </li></ul><br><h3 id="potokovaya-obrabotka-dannyh-stream-processing">  Stream-Verarbeitung </h3><br><p>  W√§hrend der Arbeit an dem Projekt wurde die Stream Processor-Bibliothek geschrieben, mit deren Hilfe wir Streaming-Datenverarbeitungsalgorithmen in der Produktion schnell implementieren und starten konnten. </p><br><p>  Stream Processor ist eine Bibliothek zum Erstellen von Streaming-Datenverarbeitungssystemen.  Stream ist eine potenziell endlose Folge von Daten (Nachrichten), in die nur das Hinzuf√ºgen neuer Nachrichten m√∂glich ist. Bereits aufgezeichnete Nachrichten werden nicht ge√§ndert oder aus dem Stream gel√∂scht.  Konverter eines Streams in einen anderen (Stream-Prozessoren) bestehen funktional aus drei Teilen: einem Anbieter eingehender Nachrichten, der normalerweise Nachrichten aus einem oder mehreren Streams liest und in eine Verarbeitungswarteschlange stellt, einem Nachrichtenprozessor, der eingehende Nachrichten in ausgehende Nachrichten konvertiert und in eine Warteschlange stellt zum Datensatz und zum Schreiber, wo ausgehende Nachrichten, die innerhalb des Zeitfensters gruppiert sind, in den Ausgabestream fallen.  Von einem Stream-Prozessor generierte Datennachrichten k√∂nnen sp√§ter von anderen verwendet werden.  Somit bilden Streams und Prozessoren einen gerichteten Graphen, in dem Schleifen m√∂glich sind, insbesondere kann ein Stream-Prozessor sogar Nachrichten in demselben Stream erzeugen, von dem er Daten empf√§ngt. </p><br><p>  Es wird garantiert, dass jede Nachricht des Eingabestreams von jedem ihm zugeordneten Prozessor mindestens einmal verarbeitet wird (Semantik mindestens einmal).  Es wird auch garantiert, dass alle Nachrichten in der Reihenfolge verarbeitet werden, in der sie in diesem Stream angekommen sind.  Zu diesem Zweck werden Stream-Prozessoren auf alle Arbeitsdienstknoten verteilt, sodass zu einem Zeitpunkt nicht mehr als eine Instanz jedes registrierten Prozessors arbeitet. </p><br><p>  Die Verarbeitung miteinander verbundener Ereignisse ist eines der Hauptprobleme beim Erstellen von Systemen f√ºr die Streaming-Datenverarbeitung.  In der Regel erstellen Stream-Prozessoren beim Streaming von Nachrichten schrittweise einen bestimmten Status, der zum Zeitpunkt der Verarbeitung der aktuellen Nachricht g√ºltig war.  Solche Statusobjekte sind normalerweise nicht dem gesamten Stream als Ganzes zugeordnet, sondern einer bestimmten Teilmenge von Nachrichten, die durch den Schl√ºsselwert in diesem Stream bestimmt wird.  Effiziente Speicherung von Wohlstand ist der Schl√ºssel zum Erfolg.  Bei der Verarbeitung der n√§chsten Nachricht ist es wichtig, dass der Prozessor diesen Status schnell abrufen und basierend auf dieser und der aktuellen Nachricht ausgehende Nachrichten generieren kann.  Auf diese Statusobjekte k√∂nnen Prozessoren in L1 zugreifen (bitte nicht mit dem CPU-Cache verwechseln). Der LRU-Cache befindet sich im Speicher.  Falls im L1-Cache kein Status vorhanden war, wird er aus dem L2-Cache wiederhergestellt, der sich in demselben Speicher befindet, in dem die Streams gespeichert sind, und in dem er w√§hrend des Prozessorbetriebs regelm√§√üig gespeichert wird.  Wenn im L2-Cache kein Status vorhanden war, wird er aus den urspr√ºnglichen Stream-Nachrichten wiederhergestellt, als h√§tte der Prozessor alle urspr√ºnglichen Nachrichten verarbeitet, die dem aktuellen Nachrichtenschl√ºssel zugeordnet sind.  Mit der Caching-Technik k√∂nnen Sie auch das Problem der hohen Latenz des Speichers l√∂sen, da die sequentielle Verarbeitung h√§ufig nicht von der Leistung des Servers abh√§ngt, sondern von der Verz√∂gerung von Anforderungen und Antworten bei der Kommunikation mit dem Data Warehouse. </p><br><img width="400" src="https://habrastorage.org/webt/_o/pk/sj/_opksjvyut5cirxrnbjerswkt78.png"><br><br><p>  Um Daten in L1-Caches und Nachrichtendaten effektiv im Speicher zu speichern, verwenden wir zus√§tzlich zu speichereffizienten Strukturen Objektpools, mit denen Sie nur eine Kopie eines Objekts (oder sogar Teile davon) im Speicher haben k√∂nnen.  Diese Technik wird bereits im JDK zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">String-Internieren von Strings verwendet</a> und erstreckt sich in √§hnlicher Weise auf andere Objekttypen, die unver√§nderlich sein sollten. </p><br><p>  F√ºr eine kompakte Speicherung von Daten im Stream-Speicher werden einige Daten vor dem Schreiben in den Stream normalisiert, d. H.  in Zahlen verwandeln.  Effektive Komprimierungsalgorithmen k√∂nnen dann auf Zahlen (Objektkennungen) angewendet werden.  Zahlen werden sortiert, Deltas werden gez√§hlt, dann mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ZigZag-Codierung</a> codiert und dann vom Archivierer komprimiert.  Die Normalisierung ist keine Standardtechnik f√ºr das Streaming von Datenverarbeitungssystemen.  Diese Komprimierungstechnik ist jedoch sehr effektiv und die Datenmenge im am meisten geladenen Stream wird um das 1000-fache reduziert. </p><br><img width="600" src="https://habrastorage.org/getpro/habr/post_images/b1b/6f4/fa9/b1b6f4fa9d551a96fd4069b44435354f.png"><br><br><p>  F√ºr jeden Stream und Prozessor verfolgen wir den Lebenszyklus der Nachrichtenverarbeitung: das Auftreten neuer Nachrichten im Eingabestream, die Gr√∂√üe der Warteschlange f√ºr nicht verarbeitete Nachrichten, die Gr√∂√üe der Warteschlange zum Schreiben in den resultierenden Stream, die Nachrichtenverarbeitungszeit und die Verteilung der Zeit nach Nachrichtenverarbeitungsstufen: </p><br><img src="https://habrastorage.org/webt/jg/0q/rp/jg0qrpqbojreaugzrf66cikffwa.png"><br><br><h3 id="hranilische-dannyh">  Data Warehouse </h3><br><p>  Die Ergebnisse der Streaming-Datenverarbeitung sollten dem Benutzer so bald wie m√∂glich zur Verf√ºgung stehen.  Die verarbeiteten Daten aus den Streams sollten kontinuierlich in der Datenbank aufgezeichnet werden, wo Sie dann die Daten abrufen k√∂nnen (z. B. einen Bericht mit den Testergebnissen anzeigen, den Verlauf des Tests anzeigen). </p><br><p>  Eigenschaften gespeicherter Daten und Abfragen. <br>  Die meisten Daten sind Testl√§ufe.  √úber einen Monat werden mehr als 1,5 Milliarden Builds und Tests gestartet.  Bei jedem Start wird eine relativ gro√üe Menge an Informationen gespeichert: Ergebnis und Art des Fehlers, eine kurze Beschreibung des Fehlers (Snippet), mehrere Links zu Protokollen, Testdauer, eine Reihe von numerischen Werten, Metriken im Format name = value usw.  Einige dieser Daten - zum Beispiel Metriken und Dauer - sind sehr schwer zu komprimieren, da es sich tats√§chlich um Zufallswerte handelt.  Der andere Teil - zum Beispiel das Ergebnis, die Art des Fehlers, die Protokolle - kann effizienter gespeichert werden, da sie sich im selben Test von Lauf zu Lauf fast nicht √§ndern. </p><br><p>  Zuvor haben wir MySQL zum Speichern verarbeiteter Daten verwendet.  Wir begannen uns allm√§hlich gegen die F√§higkeiten der Datenbank auszuruhen: </p><br><ul><li>  Die verarbeitete Datenmenge verdoppelt sich alle sechs Monate. </li><li>  Wir konnten nur Daten f√ºr die letzten 2 Monate speichern, aber wir wollten Daten f√ºr mindestens ein Jahr speichern. </li><li>  Probleme mit der Ausf√ºhrungsgeschwindigkeit einiger schwerer (fast analytischer) Abfragen. </li><li>  Kompliziertes Datenbankschema.  Viele Tabellen (Normalisierung), was das Schreiben in die Datenbank erschwert.  Das Basisschema unterscheidet sich stark von dem Schema der Objekte, die in der Echtzeitschaltung verwendet werden. </li><li>  Server wird nicht heruntergefahren.  Der Ausfall eines separaten Servers oder das Herunterfahren des Rechenzentrums kann zu einem Systemausfall f√ºhren. </li><li>  Ziemlich komplizierte Bedienung. </li></ul><br><p>  Als Kandidaten f√ºr das neue Data Warehouse haben wir verschiedene Optionen in Betracht gezogen: PostgreSQL, MongoDB und verschiedene interne L√∂sungen, einschlie√ülich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ClickHouse</a> . </p><br><p>  Bei einigen L√∂sungen k√∂nnen wir unsere Daten nicht effizienter speichern als bei der alten MySQL-basierten L√∂sung.  Andere erlauben nicht die Implementierung schneller und komplexer (fast analytischer) Abfragen.  Zum Beispiel haben wir eine ziemlich schwere Anfrage, die Commits anzeigt, die sich auf ein bestimmtes Projekt auswirken (einige Tests).  In allen F√§llen, in denen wir keine schnellen SQL-Abfragen ausf√ºhren k√∂nnen, m√ºssten wir den Benutzer zwingen, lange zu warten oder einige Berechnungen im Voraus durchzuf√ºhren, was zu einem Verlust an Flexibilit√§t f√ºhrt.  Wenn Sie etwas im Voraus z√§hlen, m√ºssen Sie mehr Code schreiben und gleichzeitig die Flexibilit√§t verlieren - es gibt keine M√∂glichkeit, das Verhalten schnell zu √§ndern und etwas zu erz√§hlen.  Es ist viel bequemer und schneller, eine SQL-Abfrage zu schreiben, die die vom Benutzer ben√∂tigten Daten zur√ºckgibt und diese schnell √§ndern kann, wenn Sie das Verhalten des Systems √§ndern m√∂chten. </p><br><h3 id="clickhouse">  Clickhouse </h3><br><p>  Wir haben uns f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ClickHouse</a> entschieden.  ClickHouse ist ein s√§ulenf√∂rmiges Datenbankverwaltungssystem (DBMS) f√ºr die Online-Verarbeitung analytischer Abfragen (OLAP). </p><br><p>  Bei der Umstellung auf ClickHouse haben wir bewusst auf einige der M√∂glichkeiten verzichtet, die andere DBMS bieten, und daf√ºr eine mehr als angemessene Entsch√§digung in Form von sehr schnellen analytischen Abfragen und einem kompakten Data Warehouse erhalten. </p><br><p>  In relationalen DBMS werden Werte, die sich auf eine Zeile beziehen, physisch nebeneinander gespeichert.  In ClickHouse werden Werte aus verschiedenen Spalten separat gespeichert und Daten aus einer Spalte werden zusammen gespeichert.  Diese Reihenfolge der Datenspeicherung erm√∂glicht es Ihnen, ein hohes Ma√ü an Datenkomprimierung mit der richtigen Wahl des Prim√§rschl√ºssels bereitzustellen.  Dies wirkt sich auch darauf aus, in welchen Szenarien das DBMS gut funktioniert.  ClickHouse funktioniert besser bei Abfragen, bei denen eine kleine Anzahl von Spalten gelesen wird und die Abfrage eine gro√üe Tabelle verwendet und der Rest der Tabellen klein ist.  Aber auch bei nicht analytischen Abfragen kann ClickHouse gute Ergebnisse erzielen. </p><br><p>  Die Daten in den Tabellen sind nach Prim√§rschl√ºssel sortiert.  Die Sortierung erfolgt im Hintergrund.  Auf diese Weise k√∂nnen Sie einen sp√§rlichen Index f√ºr ein kleines Volume erstellen, mit dem Sie schnell Daten finden k√∂nnen.  ClickHouse hat keine Sekund√§rindizes.  Genau genommen gibt es einen sekund√§ren Index - den Partitionsschl√ºssel (ClickHouse schneidet Partitionsdaten ab, bei denen der Partitionsschl√ºssel in der Anforderung angegeben ist).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Weitere Details</a> . </p><br><p>  Das Datenschema mit Normalisierung ist nicht funktionsf√§hig, im Gegenteil, es ist vorzuziehen, die Daten abh√§ngig von den Anforderungen an sie zu denormalisieren.  Es ist vorzuziehen, "breite" Tabellen mit einer gro√üen Anzahl von Spalten zu erstellen.  Dieses Element ist auch mit dem vorherigen verwandt, da das Fehlen von Sekund√§rindizes manchmal Kopien von Tabellen mit einem anderen Prim√§rschl√ºssel erstellt. </p><br><p>  ClickHouse verf√ºgt nicht √ºber UPDATE und DELETE im klassischen Sinne, es besteht jedoch die M√∂glichkeit, diese zu emulieren. </p><br><p>  Daten m√ºssen in gro√üen Bl√∂cken und nicht zu oft (alle paar Sekunden) eingef√ºgt werden.  Das zeilenweise Laden von Daten ist bei realen Datenmengen praktisch nicht funktionsf√§hig. </p><br><p>  ClickHouse unterst√ºtzt keine Transaktionen, das System wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schlie√ülich konsistent</a> . </p><br><p>  Einige Funktionen von ClickHouse, √§hnlich wie bei anderen DBMS, erleichtern jedoch die √úbertragung vorhandener Systeme. </p><br><ul><li>  ClickHouse verwendet SQL, jedoch mit geringf√ºgigen Unterschieden, das f√ºr f√ºr OLAP-Systeme typische Abfragen n√ºtzlich ist.  Es gibt ein leistungsstarkes System von Aggregatfunktionen, ALL / ANY JOIN, Lambda-Ausdr√ºcken in Funktionen und anderen SQL-Erweiterungen, mit denen Sie fast jede analytische Abfrage schreiben k√∂nnen. </li><li>  ClickHouse unterst√ºtzt Replikation, Quorumaufzeichnung und Quorumlesung.  F√ºr eine zuverl√§ssige Datenspeicherung ist ein Quorum-Schreibvorgang erforderlich: INSERT ist nur erfolgreich, wenn ClickHouse fehlerfrei Daten auf eine bestimmte Anzahl von Replikaten schreiben konnte. </li></ul><br><p>  Weitere Informationen zu ClickHouse-Funktionen finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . </p><br><h4 id="osobennosti-raboty-s-clickhouse">  Funktionen f√ºr die Arbeit mit ClickHouse </h4><br><p>  Wahl des Prim√§rschl√ºssels und des Partitionsschl√ºssels. </p><br><p>  Wie w√§hle ich einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Prim√§rschl√ºssel</a> und einen Partitionsschl√ºssel aus?  Vielleicht ist dies die erste Frage, die sich beim Erstellen einer neuen Tabelle stellt.  Die Auswahl des Prim√§rschl√ºssels und des Partitionsschl√ºssels wird normalerweise von den Abfragen bestimmt, die f√ºr die Daten ausgef√ºhrt werden.  Gleichzeitig erweisen sich Abfragen, die beide Bedingungen verwenden, als am effektivsten: sowohl nach dem Prim√§rschl√ºssel als auch nach dem Partitionsschl√ºssel. </p><br><p>  In unserem Fall sind die Haupttabellen die Matrizen zum Ausf√ºhren der Tests.  Es ist logisch anzunehmen, dass bei dieser Datenstruktur die Schl√ºssel so ausgew√§hlt werden m√ºssen, dass die Umgehungsreihenfolge eines von ihnen in der Reihenfolge der Erh√∂hung der Zeilennummer und die Umgehungsreihenfolge des anderen - in der Reihenfolge der Erh√∂hung der Spaltennummer - erfolgt. </p><br><p>  Es ist auch wichtig zu beachten, dass die Auswahl des Prim√§rschl√ºssels die Kompaktheit der Datenspeicherung erheblich beeintr√§chtigen kann, da identische Werte bei der Umgehung des Prim√§rschl√ºssels in anderen Spalten fast keinen Platz in der Tabelle beanspruchen.  In unserem Fall √§ndern sich beispielsweise die Status der Tests von Commit zu Commit kaum.  Diese Tatsache bestimmte im Wesentlichen die Wahl des Prim√§rschl√ºssels - ein Paar aus Testkennung und Festschreibungsnummer.  Au√üerdem in dieser Reihenfolge. </p><br><img width="600" src="https://habrastorage.org/webt/0t/gj/jo/0tgjjoefxhjgbxexx4gevfwte7y.png"><br><br><p>  Der Partitionsschl√ºssel hat zwei Zwecke.  Zum einen k√∂nnen Partitionen so ‚Äûarchiviert‚Äú werden, dass sie dauerhaft aus dem Speicher gel√∂scht werden k√∂nnen, da die darin enthaltenen Daten bereits veraltet sind.  Andererseits ist der Partitionsschl√ºssel ein sekund√§rer Index, was bedeutet, dass Sie Abfragen beschleunigen k√∂nnen, wenn ein Ausdruck daf√ºr in ihnen vorhanden ist. </p><br><p>  F√ºr unsere Matrizen erscheint es ganz nat√ºrlich, die Festschreibungsnummer als Partitionsschl√ºssel zu w√§hlen.  Wenn Sie jedoch den Revisionswert im Ausdruck f√ºr den Partitionsschl√ºssel festlegen, enth√§lt eine solche Tabelle unangemessen viele Partitionen, wodurch die Leistung von Abfragen an diese Partition beeintr√§chtigt wird.  Daher kann im Ausdruck f√ºr den Partitionsschl√ºssel der Revisionswert in eine gro√üe Anzahl unterteilt werden, um die Anzahl der Partitionen zu verringern, z. B. PARTITION BY intDiv (Revision, 2000).  Diese Anzahl sollte gro√ü genug sein, damit die Anzahl der Partitionen die empfohlenen Werte nicht √ºberschreitet, w√§hrend sie klein genug sein sollte, damit nicht viele Daten in eine Partition fallen und die Datenbank nicht zu viele Daten lesen muss. </p><br><p>  Wie implementiere ich UPDATE und DELETE? </p><br><p>  Im √ºblichen Sinne werden UPDATE und DELETE in ClickHouse nicht unterst√ºtzt.  Anstelle von UPDATE und DELETE k√∂nnen Sie der Tabelle jedoch eine Spalte mit der Version hinzuf√ºgen und die spezielle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ReplacingMergeTree-</a> Engine verwenden (entfernt doppelte Datens√§tze mit demselben Prim√§rschl√ºsselwert).  In einigen F√§llen ist die Version nat√ºrlich von Anfang an in der Tabelle vorhanden. Wenn Sie beispielsweise eine Tabelle f√ºr den aktuellen Teststatus erstellen m√∂chten, ist die Version in dieser Tabelle die Festschreibungsnummer. </p><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> current_tests ( test_id UInt64, <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> Nullable(<span class="hljs-keyword"><span class="hljs-keyword">String</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">version</span></span> UInt64 ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree(<span class="hljs-keyword"><span class="hljs-keyword">version</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> test_id</code> </pre> <br><p>  Im Falle einer Datensatz√§nderung f√ºgen wir die Version mit einem neuen Wert hinzu, im Falle eines L√∂schens mit einem NULL-Wert (oder einem anderen speziellen Wert, der in den Daten nicht gefunden werden kann). </p><br><p>  Was haben Sie mit dem neuen Speicher erreicht? </p><br><p>  Eines der Hauptziele des Wechsels zu ClickHouse war die M√∂glichkeit, den Testverlauf √ºber einen langen Zeitraum (mehrere Jahre oder im schlimmsten Fall mindestens ein Jahr) zu speichern.  Bereits im Prototypenstadium wurde klar, dass wir die vorhandenen SSDs auf unseren Servern umgehen k√∂nnen, um eine mindestens dreij√§hrige Historie zu speichern.  Analytische Abfragen haben sich erheblich beschleunigt, jetzt k√∂nnen wir viel n√ºtzlichere Informationen aus unseren Daten extrahieren.  Die RPS-Marge hat zugenommen.  Dar√ºber hinaus wird dieser Wert durch Hinzuf√ºgen neuer Server zum ClickHouse-Cluster nahezu linear skaliert.  Das Erstellen eines neuen Data Warehouse f√ºr die ClickHouse-Datenbank ist f√ºr den Endbenutzer nur ein kaum wahrnehmbarer Schritt in Richtung eines wichtigeren Ziels: Hinzuf√ºgen neuer Funktionen, Beschleunigen und Vereinfachen der Entwicklung dank der M√∂glichkeit, gro√üe Datenmengen zu speichern und zu verarbeiten. </p><br><h4 id="prihodite-k-nam">  Komm zu uns </h4><br><p>  Unsere Abteilung wird st√§ndig erweitert.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Besuchen Sie uns,</a> wenn Sie an komplexen und interessanten Aufgaben und Algorithmen arbeiten m√∂chten.  Wenn Sie Fragen haben, k√∂nnen Sie mich direkt in PM fragen. </p><br><h3 id="poleznye-ssylki">  N√ºtzliche Links </h3><br><p>  Stream-Verarbeitung </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Protokoll: Was jeder Softwareentwickler √ºber die einheitliche Abstraktion von Echtzeitdaten wissen sollte</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Welt jenseits des Batches: Streaming 101</a> . </li><li>  Buchgestaltung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">datenintensiver Anwendungen</a> - O'Reilly Media. </li></ul><br><p>  Kappa Architektur </p><br><ul><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kappa-Architektur</a> . </li></ul><br><p>  ClickHouse: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yandex √∂ffnet ClickHouse</a> . </li><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://clickhouse.yandex</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429956/">https://habr.com/ru/post/de429956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429946/index.html">Wahnsinn und Erfolg von Oracle Database Code</a></li>
<li><a href="../de429948/index.html">Warum Produktmanager bei Fintech ben√∂tigt werden</a></li>
<li><a href="../de429950/index.html">So pflegen Sie gesunde Kommunikationsgewohnheiten von Remote-Teams</a></li>
<li><a href="../de429952/index.html">Die Vergangenheit, Gegenwart und Zukunft von Docker und anderen Containerlaufzeiten in Kubernetes</a></li>
<li><a href="../de429954/index.html">Der Programmierer f√ºr die irischen Buchmacher</a></li>
<li><a href="../de429958/index.html">F√ºnf einfache Debugging-Regeln f√ºr Anf√§nger</a></li>
<li><a href="../de429960/index.html">10 Gr√ºnde, warum Kunden ein Produkt abbestellen</a></li>
<li><a href="../de429964/index.html">U> X> I> P ... oder "Wie die Namen von Berufen √ºberspringen"</a></li>
<li><a href="../de429966/index.html">Ein √úberblick √ºber grundlegende Deep Domain-Anpassungstechniken (Teil 2)</a></li>
<li><a href="../de429968/index.html">Das gr√∂√üte Kurierunternehmen aus China setzt unbemannte "Mais-LKWs" f√ºr den Warentransport ein</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
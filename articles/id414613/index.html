<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßîüèª üíä üêì Kaggle Home Credit Default Risk Competition - Analisis Data dan Model Prediktif Sederhana ü§∑üèæ üå∞ üôèüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada festival data 2 di Minsk, Vladimir Iglovikov, insinyur visi mesin di Lyft, dengan sempurna mengatakan bahwa cara terbaik untuk mempelajari Ilmu D...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle Home Credit Default Risk Competition - Analisis Data dan Model Prediktif Sederhana</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414613/">  Pada festival data 2 di Minsk, Vladimir Iglovikov, insinyur visi mesin di Lyft, dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sempurna</a> mengatakan bahwa cara terbaik untuk mempelajari Ilmu Data adalah dengan berpartisipasi dalam kompetisi, menjalankan solusi orang lain, menggabungkannya, mencapai hasil dan menunjukkan pekerjaan Anda.  Sebenarnya, dalam kerangka paradigma ini, saya memutuskan untuk melihat lebih dekat pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kompetisi</a> penilaian risiko kredit Home Credit dan menjelaskan (kepada para pemula, Ilmuwan, dan pertama-tama kepada diri saya sendiri) bagaimana menganalisis dengan benar set data tersebut dan membuat model untuk mereka. <br><br><img src="https://habrastorage.org/webt/iv/ji/-t/ivji-tusvam8d05dqef8wjbmbye.png"><br><a name="habracut"></a><br>  (gambar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dari sini</a> ) <br><br><img src="https://habrastorage.org/webt/xc/er/pe/xcerpefrjvrblmubhxyeljevcie.png" width="250" align="right">  Home Credit Group adalah sekelompok bank dan organisasi kredit non-bank yang melakukan operasi di 11 negara (termasuk Rusia sebagai Home Credit dan Finance Bank LLC).  Tujuan dari kompetisi adalah untuk menciptakan metodologi untuk menilai kelayakan kredit dari peminjam yang tidak memiliki sejarah kredit.  Yang terlihat agak mulia - peminjam dari kategori ini sering tidak dapat memperoleh kredit dari bank dan dipaksa untuk beralih ke scammers dan pinjaman mikro.  Sangat menarik bahwa pelanggan tidak menetapkan persyaratan untuk transparansi dan interpretabilitas model (seperti yang biasanya terjadi pada bank), Anda dapat menggunakan apa pun, bahkan jaringan saraf. <br><br>  Sampel pelatihan terdiri dari 300+ ribu catatan, ada cukup banyak tanda - 122, di antaranya ada banyak yang kategorikal (non-numerik).  Tanda-tanda menggambarkan peminjam dengan cukup rinci, sampai ke bahan dari mana dinding rumahnya dibuat.  Bagian dari data terkandung dalam 6 tabel tambahan (data pada biro kredit, saldo kartu kredit dan pinjaman sebelumnya), data ini juga harus diproses entah bagaimana dan dimuat ke yang utama. <br><br>  Persaingan terlihat seperti tugas klasifikasi standar (1 di bidang TARGET berarti kesulitan dengan pembayaran, 0 berarti tidak ada kesulitan).  Namun, bukan 0/1 yang harus diprediksi, tetapi probabilitas masalah (yang, secara kebetulan, dapat dengan mudah dipecahkan dengan metode prediksi probabilitas predict_proba yang dimiliki semua model kompleks). <br><br>  Pada pandangan pertama, dataset ini cukup standar untuk tugas pembelajaran mesin, panitia menawarkan hadiah besar $ 70k, sebagai hasilnya, lebih dari 2.600 tim berpartisipasi dalam kompetisi hari ini, dan pertarungannya dalam seperseribu persen.  Namun, di sisi lain, popularitas seperti itu berarti bahwa dataset telah diperiksa atas dan ke bawah dan banyak kernel telah dibuat dengan EDA yang baik (Analisis Data Eksplorasi - penelitian dan analisis data dalam jaringan, termasuk grafis), rekayasa fitur (bekerja dengan atribut) dan dengan model yang menarik.  (Kernel adalah contoh bekerja dengan dataset yang dapat ditata siapa saja untuk menunjukkan hasil kerjanya kepada kuggler lain.) <br><br>  Kernel layak mendapat perhatian: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">EDA dengan deskripsi terperinci untuk pemula dan model sederhana</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deep EDA dengan Paket Plotly + Upload Data Biro</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Paket EDA yang bagus dengan Paket Seaborn</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Analisis komparatif masalah dan peminjam default</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">15-line LightGBM pada tiga tanda dengan kecepatan akhir 0,714</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Analisis tanda-tanda menurut biro kredit</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Memproses tambah.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tabel + LightGBM</a> </li></ul><br>  Untuk bekerja dengan data, rencana berikut ini biasanya disarankan, yang akan kami coba ikuti. <br><br><ol><li>  Memahami masalah dan berkenalan dengan data </li><li>  Pembersihan dan pemformatan data </li><li>  EDA </li><li>  Model dasar </li><li>  Perbaikan Model </li><li>  Model interpretasi </li></ol><br>  Dalam hal ini, Anda perlu mempertimbangkan fakta bahwa data tersebut cukup luas dan tidak dapat dikalahkan segera, masuk akal untuk bertindak secara bertahap. <br><br>  Mari kita mulai dengan mengimpor perpustakaan yang kita butuhkan dalam analisis untuk bekerja dengan data dalam bentuk tabel, membuat grafik, dan bekerja dengan matriks. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib inline</code> </pre> <br>  Unduh datanya.  Mari kita lihat apa yang kita semua miliki.  Lokasi ini di direktori "../input/", omong-omong, terhubung dengan persyaratan untuk meletakkan kernel Anda di Kaggle. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os PATH=<span class="hljs-string"><span class="hljs-string">"../input/"</span></span> print(os.listdir(PATH))</code> </pre> <br> <code>['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv']</code> <br> <br>  Ada 8 tabel dengan data (tidak termasuk tabel HomeCredit_columns_description.csv, yang berisi deskripsi bidang), yang saling berhubungan sebagai berikut: <br><br><img src="https://habrastorage.org/webt/vn/yr/84/vnyr84vhzozgnfinu2to2tyhlp8.png"><br><br>  application_train / application_test: Data master, peminjam diidentifikasi oleh bidang SK_ID_CURR <br>  biro: Data pinjaman sebelumnya dari lembaga kredit lain dari biro kredit <br>  bureau_balance: Data bulanan tentang pinjaman biro sebelumnya.  Setiap baris adalah bulan menggunakan pinjaman <br>  Aplikasi sebelumnya: Aplikasi sebelumnya untuk pinjaman Kredit Rumah, masing-masing memiliki bidang unik SK_ID_PREV <br>  POS_CASH_BALANCE: Data bulanan tentang pinjaman dalam Home Credit dengan penerbitan uang tunai dan pinjaman untuk pembelian barang <br>  credit_card_balance: Data saldo kartu kredit bulanan di Home Credit <br>  installments_payment: Riwayat pembayaran pinjaman sebelumnya di Home Credit. <br><br>  Pertama-tama, mari kita fokus pada sumber data utama dan melihat informasi apa yang dapat diekstrak darinya dan model mana yang akan dibangun.  Unduh data dasar. <br><br><ul><li>  app_train = pd.read_csv (PATH + 'application_train.csv',) </li><li>  app_test = pd.read_csv (PATH + 'application_test.csv',) </li><li>  print ("format set pelatihan:", app_train.shape) </li><li>  print ("format sampel uji:", app_test.shape) </li><li>  format sampel pelatihan: (307511, 122) </li><li>  format sampel uji: (48744, 121) </li></ul><br>  Secara total, kami memiliki 307 ribu catatan dan 122 tanda dalam sampel pelatihan dan 49 ribu catatan dan 121 tanda dalam tes.  Perbedaan ini jelas disebabkan oleh fakta bahwa tidak ada atribut target TARGET dalam sampel uji, dan kami akan memprediksinya. <br><br>  Mari kita lihat lebih dekat data <br><br><pre> <code class="python hljs">pd.set_option(<span class="hljs-string"><span class="hljs-string">'display.max_columns'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  pandas     app_train.head()</span></span></code> </pre> <br><br><img src="https://habrastorage.org/webt/xo/yc/rg/xoycrgiodfhonfrjbt50ncthrls.png"><br>  (8 kolom pertama ditampilkan) <br><br>  Sangat sulit untuk menonton data dalam format ini.  Mari kita lihat daftar kolom: <br><br> <code>app_train.info(max_cols=122) <br> &lt;class 'pandas.core.frame.DataFrame'&gt; <br> RangeIndex: 307511 entries, 0 to 307510 <br> Data columns (total 122 columns): <br> SK_ID_CURR 307511 non-null int64 <br> TARGET 307511 non-null int64 <br> NAME_CONTRACT_TYPE 307511 non-null object <br> CODE_GENDER 307511 non-null object <br> FLAG_OWN_CAR 307511 non-null object <br> FLAG_OWN_REALTY 307511 non-null object <br> CNT_CHILDREN 307511 non-null int64 <br> AMT_INCOME_TOTAL 307511 non-null float64 <br> AMT_CREDIT 307511 non-null float64 <br> AMT_ANNUITY 307499 non-null float64 <br> AMT_GOODS_PRICE 307233 non-null float64 <br> NAME_TYPE_SUITE 306219 non-null object <br> NAME_INCOME_TYPE 307511 non-null object <br> NAME_EDUCATION_TYPE 307511 non-null object <br> NAME_FAMILY_STATUS 307511 non-null object <br> NAME_HOUSING_TYPE 307511 non-null object <br> REGION_POPULATION_RELATIVE 307511 non-null float64 <br> DAYS_BIRTH 307511 non-null int64 <br> DAYS_EMPLOYED 307511 non-null int64 <br> DAYS_REGISTRATION 307511 non-null float64 <br> DAYS_ID_PUBLISH 307511 non-null int64 <br> OWN_CAR_AGE 104582 non-null float64 <br> FLAG_MOBIL 307511 non-null int64 <br> FLAG_EMP_PHONE 307511 non-null int64 <br> FLAG_WORK_PHONE 307511 non-null int64 <br> FLAG_CONT_MOBILE 307511 non-null int64 <br> FLAG_PHONE 307511 non-null int64 <br> FLAG_EMAIL 307511 non-null int64 <br> OCCUPATION_TYPE 211120 non-null object <br> CNT_FAM_MEMBERS 307509 non-null float64 <br> REGION_RATING_CLIENT 307511 non-null int64 <br> REGION_RATING_CLIENT_W_CITY 307511 non-null int64 <br> WEEKDAY_APPR_PROCESS_START 307511 non-null object <br> HOUR_APPR_PROCESS_START 307511 non-null int64 <br> REG_REGION_NOT_LIVE_REGION 307511 non-null int64 <br> REG_REGION_NOT_WORK_REGION 307511 non-null int64 <br> LIVE_REGION_NOT_WORK_REGION 307511 non-null int64 <br> REG_CITY_NOT_LIVE_CITY 307511 non-null int64 <br> REG_CITY_NOT_WORK_CITY 307511 non-null int64 <br> LIVE_CITY_NOT_WORK_CITY 307511 non-null int64 <br> ORGANIZATION_TYPE 307511 non-null object <br> EXT_SOURCE_1 134133 non-null float64 <br> EXT_SOURCE_2 306851 non-null float64 <br> EXT_SOURCE_3 246546 non-null float64 <br> APARTMENTS_AVG 151450 non-null float64 <br> BASEMENTAREA_AVG 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_AVG 157504 non-null float64 <br> YEARS_BUILD_AVG 103023 non-null float64 <br> COMMONAREA_AVG 92646 non-null float64 <br> ELEVATORS_AVG 143620 non-null float64 <br> ENTRANCES_AVG 152683 non-null float64 <br> FLOORSMAX_AVG 154491 non-null float64 <br> FLOORSMIN_AVG 98869 non-null float64 <br> LANDAREA_AVG 124921 non-null float64 <br> LIVINGAPARTMENTS_AVG 97312 non-null float64 <br> LIVINGAREA_AVG 153161 non-null float64 <br> NONLIVINGAPARTMENTS_AVG 93997 non-null float64 <br> NONLIVINGAREA_AVG 137829 non-null float64 <br> APARTMENTS_MODE 151450 non-null float64 <br> BASEMENTAREA_MODE 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MODE 157504 non-null float64 <br> YEARS_BUILD_MODE 103023 non-null float64 <br> COMMONAREA_MODE 92646 non-null float64 <br> ELEVATORS_MODE 143620 non-null float64 <br> ENTRANCES_MODE 152683 non-null float64 <br> FLOORSMAX_MODE 154491 non-null float64 <br> FLOORSMIN_MODE 98869 non-null float64 <br> LANDAREA_MODE 124921 non-null float64 <br> LIVINGAPARTMENTS_MODE 97312 non-null float64 <br> LIVINGAREA_MODE 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MODE 93997 non-null float64 <br> NONLIVINGAREA_MODE 137829 non-null float64 <br> APARTMENTS_MEDI 151450 non-null float64 <br> BASEMENTAREA_MEDI 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MEDI 157504 non-null float64 <br> YEARS_BUILD_MEDI 103023 non-null float64 <br> COMMONAREA_MEDI 92646 non-null float64 <br> ELEVATORS_MEDI 143620 non-null float64 <br> ENTRANCES_MEDI 152683 non-null float64 <br> FLOORSMAX_MEDI 154491 non-null float64 <br> FLOORSMIN_MEDI 98869 non-null float64 <br> LANDAREA_MEDI 124921 non-null float64 <br> LIVINGAPARTMENTS_MEDI 97312 non-null float64 <br> LIVINGAREA_MEDI 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MEDI 93997 non-null float64 <br> NONLIVINGAREA_MEDI 137829 non-null float64 <br> FONDKAPREMONT_MODE 97216 non-null object <br> HOUSETYPE_MODE 153214 non-null object <br> TOTALAREA_MODE 159080 non-null float64 <br> WALLSMATERIAL_MODE 151170 non-null object <br> EMERGENCYSTATE_MODE 161756 non-null object <br> OBS_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> OBS_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DAYS_LAST_PHONE_CHANGE 307510 non-null float64 <br> FLAG_DOCUMENT_2 307511 non-null int64 <br> FLAG_DOCUMENT_3 307511 non-null int64 <br> FLAG_DOCUMENT_4 307511 non-null int64 <br> FLAG_DOCUMENT_5 307511 non-null int64 <br> FLAG_DOCUMENT_6 307511 non-null int64 <br> FLAG_DOCUMENT_7 307511 non-null int64 <br> FLAG_DOCUMENT_8 307511 non-null int64 <br> FLAG_DOCUMENT_9 307511 non-null int64 <br> FLAG_DOCUMENT_10 307511 non-null int64 <br> FLAG_DOCUMENT_11 307511 non-null int64 <br> FLAG_DOCUMENT_12 307511 non-null int64 <br> FLAG_DOCUMENT_13 307511 non-null int64 <br> FLAG_DOCUMENT_14 307511 non-null int64 <br> FLAG_DOCUMENT_15 307511 non-null int64 <br> FLAG_DOCUMENT_16 307511 non-null int64 <br> FLAG_DOCUMENT_17 307511 non-null int64 <br> FLAG_DOCUMENT_18 307511 non-null int64 <br> FLAG_DOCUMENT_19 307511 non-null int64 <br> FLAG_DOCUMENT_20 307511 non-null int64 <br> FLAG_DOCUMENT_21 307511 non-null int64 <br> AMT_REQ_CREDIT_BUREAU_HOUR 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_DAY 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_WEEK 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_MON 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_QRT 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_YEAR 265992 non-null float64 <br> dtypes: float64(65), int64(41), object(16) <br> memory usage: 286.2+ MB</code> <br> <br>  Ingat anotasi terperinci menurut bidang di file HomeCredit_columns_description.  Seperti yang dapat Anda lihat dari info, bagian dari data tidak lengkap dan sebagian bersifat kategoris, mereka ditampilkan sebagai objek.  Sebagian besar model tidak bekerja dengan data seperti itu, kita harus melakukan sesuatu dengannya.  Pada ini, analisis awal dapat dianggap selesai, kami akan langsung pergi ke EDA <br><br><h2>  Analisis Data Eksplorasi atau penambangan data primer </h2><br>  Dalam proses EDA, kami menghitung statistik dasar dan menggambar grafik untuk menemukan tren, anomali, pola, dan hubungan dalam data.  Tujuan EDA adalah untuk mencari tahu data apa yang bisa diceritakan.  Biasanya, analisis berjalan dari atas ke bawah - dari tinjauan umum ke studi tentang masing-masing zona yang menarik perhatian dan mungkin menarik.  Selanjutnya, temuan ini dapat digunakan dalam konstruksi model, pemilihan fitur untuk itu dan dalam interpretasinya. <br><br><h3>  Distribusi Variabel Target </h3><br><pre> <code class="python hljs">app_train.TARGET.value_counts()</code> </pre> <br> <code>0 282686 <br> 1 24825 <br> Name: TARGET, dtype: int64</code> <br> <br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">"figure.figsize"</span></span>] = [<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>]‚Äã plt.hist(app_train.TARGET) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/xm/rd/ch/xmrdchcab8eqbwt2p1pie4jmaeu.png"><br><br>  Biarkan saya mengingatkan Anda bahwa 1 berarti masalah apa pun dengan pengembalian, 0 berarti tidak ada masalah.  Seperti yang Anda lihat, sebagian besar peminjam tidak memiliki masalah dengan pembayaran, bagian bermasalah adalah sekitar 8%.  Ini berarti bahwa kelas tidak seimbang dan ini mungkin perlu dipertimbangkan ketika membangun model. <br><br><h3>  Penelitian Data Hilang </h3><br>  Kami telah melihat bahwa kurangnya data cukup besar.  Mari kita lihat lebih detail di mana dan apa yang hilang. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def missing_values_table(df): #   mis_val = df.isnull().sum() #    mis_val_percent = 100 * df.isnull().sum() / len(df) #    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) #   mis_val_table_ren_columns = mis_val_table.rename( columns = {0 : 'Missing Values', 1 : '% of Total Values'}) #    mis_val_table_ren_columns = mis_val_table_ren_columns[ mis_val_table_ren_columns.iloc[:,1] != 0].sort_values( '% of Total Values', ascending=False).round(1) #  print ("   " + str(df.shape[1]) + " .\n" " " + str(mis_val_table_ren_columns.shape[0]) + "    .") #     return mis_val_table_ren_columns missing_values = missing_values_table(app_train) missing_values.head(10)</span></span></code> </pre> <br><br> <code>   122 . <br>  67    .</code> <br> <img src="https://habrastorage.org/webt/oa/jm/tp/oajmtpuvkymt4asczwqmhqziria.png"><br><br>  Dalam format grafis: <br><br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'seaborn-talk'</span></span>)‚Äã fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">18</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) miss_train = pd.DataFrame((app_train.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_test = pd.DataFrame((app_test.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_train[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> miss_test[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> missing = pd.concat([miss_train,miss_test],axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) ax = sns.pointplot(<span class="hljs-string"><span class="hljs-string">"index"</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,data=missing,hue=<span class="hljs-string"><span class="hljs-string">"type"</span></span>) plt.xticks(rotation =<span class="hljs-number"><span class="hljs-number">90</span></span>,fontsize =<span class="hljs-number"><span class="hljs-number">7</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"    "</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">"  %"</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">""</span></span>)</code> </pre> <br><br><img src="https://habrastorage.org/webt/iv/fc/ib/ivfcibv85aaktlxybl8bps2vurw.png"><br><br>  Ada banyak jawaban untuk pertanyaan "apa yang harus dilakukan dengan semua ini".  Anda dapat mengisinya dengan nol, Anda dapat menggunakan nilai median, Anda bisa menghapus baris tanpa informasi yang diperlukan.  Itu semua tergantung pada model yang kami rencanakan untuk digunakan, karena beberapa dari mereka secara sempurna mengatasi nilai yang hilang.  Sementara kita mengingat fakta ini dan meninggalkan semuanya apa adanya. <br><br><h3>  Jenis Kolom dan Pengodean Kategorikal </h3><br>  Seperti yang kita ingat.  bagian dari kolom adalah tipe objek, yaitu tidak memiliki nilai numerik, tetapi mencerminkan beberapa kategori.  Mari kita lihat kolom ini lebih dekat. <br><br><pre> <code class="python hljs">app_train.dtypes.value_counts()</code> </pre> <br> <code>float64 65 <br> int64 41 <br> object 16 <br> dtype: int64</code> <br> <br><pre> <code class="python hljs">app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br> <code>NAME_CONTRACT_TYPE 2 <br> CODE_GENDER 3 <br> FLAG_OWN_CAR 2 <br> FLAG_OWN_REALTY 2 <br> NAME_TYPE_SUITE 7 <br> NAME_INCOME_TYPE 8 <br> NAME_EDUCATION_TYPE 5 <br> NAME_FAMILY_STATUS 6 <br> NAME_HOUSING_TYPE 6 <br> OCCUPATION_TYPE 18 <br> WEEKDAY_APPR_PROCESS_START 7 <br> ORGANIZATION_TYPE 58 <br> FONDKAPREMONT_MODE 4 <br> HOUSETYPE_MODE 3 <br> WALLSMATERIAL_MODE 7 <br> EMERGENCYSTATE_MODE 2 <br> dtype: int64</code> <br> <br>  Kami memiliki 16 kolom, masing-masing dengan 2 hingga 58 opsi nilai yang berbeda.  Secara umum, model pembelajaran mesin tidak dapat melakukan apa pun dengan kolom seperti itu (kecuali untuk beberapa, seperti LightGBM atau CatBoost).  Karena kami berencana untuk mencoba model yang berbeda pada dataset, sesuatu perlu dilakukan dengan ini.  Pada dasarnya ada dua pendekatan: <br><br><ul><li>  Pengkodean Label - kategori diberikan digit 0, 1, 2 dan seterusnya dan ditulis dalam kolom yang sama </li><li>  One-Hot-encoding - satu kolom didekomposisi menjadi beberapa sesuai dengan jumlah opsi dan kolom ini menunjukkan opsi mana yang dimiliki catatan ini. </li></ul><br>  Di antara yang populer, perlu dicatat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">berarti pengkodean target</a> (terima kasih atas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kloryorangepants</a> klarifikasi). <br><br>  Ada masalah kecil dengan Pengkodean Label - ini memberikan nilai numerik yang tidak ada hubungannya dengan kenyataan.  Misalnya, jika kita berurusan dengan nilai numerik, maka penghasilan peminjam sebesar 100.000 pasti lebih besar dan lebih baik daripada pendapatan 20.000. Tetapi dapat dikatakan bahwa, misalnya, satu kota lebih baik dari yang lain karena satu diberi nilai 100 dan yang lainnya 200 ? <br><br>  One-Hot-encoding, di sisi lain, lebih aman, tetapi dapat menghasilkan kolom "ekstra".  Misalnya, jika kita menyandikan jenis kelamin yang sama menggunakan One-Hot, kita mendapatkan dua kolom, "jenis kelamin laki-laki" dan "jenis kelamin perempuan", meskipun satu akan cukup, "apakah itu laki-laki". <br><br>  Untuk dataset yang baik, perlu untuk memberi tanda kode dengan variabilitas rendah menggunakan Pengkodean Label, dan yang lainnya - One-Hot, tetapi untuk kesederhanaan kami menyandikan semuanya sesuai dengan One-Hot.  Praktis tidak akan mempengaruhi kecepatan perhitungan dan hasilnya.  Proses penyandian panda itu sendiri sangat sederhana. <br><br><pre> <code class="python hljs">app_train = pd.get_dummies(app_train) app_test = pd.get_dummies(app_test)‚Äã print(<span class="hljs-string"><span class="hljs-string">'Training Features shape: '</span></span>, app_train.shape) print(<span class="hljs-string"><span class="hljs-string">'Testing Features shape: '</span></span>, app_test.shape)</code> </pre> <br> <code>Training Features shape: (307511, 246) <br> Testing Features shape: (48744, 242)</code> <br> <br>  Karena jumlah opsi di kolom pilihan tidak sama, jumlah kolom sekarang tidak cocok.  Penyelarasan diperlukan - Anda harus menghapus kolom dari set pelatihan yang tidak ada dalam set tes.  Ini membuat metode penyelarasan, Anda perlu menentukan sumbu = 1 (untuk kolom). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,           . train_labels = app_train['TARGET']‚Äã #  -   .     app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)‚Äã print('  : ', app_train.shape) print('  : ', app_test.shape)‚Äã # Add target back in to the data app_train['TARGET'] = train_labels</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><h3>  Korelasi data </h3><br>  Cara yang baik untuk memahami data adalah dengan menghitung koefisien korelasi Pearson untuk data relatif terhadap atribut target.  Ini bukan metode terbaik untuk menunjukkan relevansi fitur, tetapi sederhana dan memungkinkan Anda mendapatkan gambaran tentang data.  Koefisien dapat diartikan sebagai berikut: <br><br><ul><li>  00-.19 ‚Äúsangat lemah‚Äù </li><li>  20-.39 "lemah" </li><li>  40-0,59 "rata-rata" </li><li>  60-, 79 kuat </li><li>  80-1.0 ‚Äúsangat kuat‚Äù </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    correlations = app_train.corr()['TARGET'].sort_values()‚Äã #  print('  : \n', correlations.tail(15)) print('\n  : \n', correlations.head(15))</span></span></code> </pre> <br> <code>  : <br> DAYS_REGISTRATION 0.041975 <br> OCCUPATION_TYPE_Laborers 0.043019 <br> FLAG_DOCUMENT_3 0.044346 <br> REG_CITY_NOT_LIVE_CITY 0.044395 <br> FLAG_EMP_PHONE 0.045982 <br> NAME_EDUCATION_TYPE_Secondary / secondary special 0.049824 <br> REG_CITY_NOT_WORK_CITY 0.050994 <br> DAYS_ID_PUBLISH 0.051457 <br> CODE_GENDER_M 0.054713 <br> DAYS_LAST_PHONE_CHANGE 0.055218 <br> NAME_INCOME_TYPE_Working 0.057481 <br> REGION_RATING_CLIENT 0.058899 <br> REGION_RATING_CLIENT_W_CITY 0.060893 <br> DAYS_BIRTH 0.078239 <br> TARGET 1.000000 <br> Name: TARGET, dtype: float64 <br> <br>   : <br> EXT_SOURCE_3 -0.178919 <br> EXT_SOURCE_2 -0.160472 <br> EXT_SOURCE_1 -0.155317 <br> NAME_EDUCATION_TYPE_Higher education -0.056593 <br> CODE_GENDER_F -0.054704 <br> NAME_INCOME_TYPE_Pensioner -0.046209 <br> ORGANIZATION_TYPE_XNA -0.045987 <br> DAYS_EMPLOYED -0.044932 <br> FLOORSMAX_AVG -0.044003 <br> FLOORSMAX_MEDI -0.043768 <br> FLOORSMAX_MODE -0.043226 <br> EMERGENCYSTATE_MODE_No -0.042201 <br> HOUSETYPE_MODE_block of flats -0.040594 <br> AMT_GOODS_PRICE -0.039645 <br> REGION_POPULATION_RELATIVE -0.037227 <br> Name: TARGET, dtype: float64</code> <br> <br>  Dengan demikian, semua data berkorelasi lemah dengan target (kecuali untuk target itu sendiri, yang, tentu saja, sama dengan dirinya sendiri).  Namun, usia dan beberapa "sumber data eksternal" dibedakan dari data.  Ini mungkin beberapa data tambahan dari organisasi kredit lain.  Sangat lucu bahwa meskipun tujuannya dinyatakan sebagai independensi dari data tersebut dalam membuat keputusan kredit, pada kenyataannya kita akan didasarkan terutama pada mereka. <br><br><h3>  Usia </h3><br>  Jelas bahwa semakin tua klien, semakin tinggi kemungkinan pengembalian (tentu saja hingga batas tertentu).  Tetapi untuk beberapa alasan, usia diindikasikan pada hari-hari negatif sebelum pinjaman dikeluarkan, oleh karena itu, usia tersebut berkorelasi positif dengan tidak adanya pembayaran kembali (yang terlihat agak aneh).  Kami membawanya ke nilai positif dan melihat korelasinya. <br><br><pre> <code class="python hljs">app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>] = abs(app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]) app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>].corr(app_train[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>])</code> </pre> <br> <code>-0.078239308309827088</code> <br> <br>  Mari kita lihat variabel lebih dekat.  Mari kita mulai dengan histogram. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  25  plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25) plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/v2/zq/1q/v2zq1qolo8rc5wx0tyao4ucygxc.png"><br><br>  Histogram distribusi itu sendiri mungkin mengatakan sedikit berguna, kecuali bahwa kita tidak melihat outlier khusus dan semuanya terlihat lebih atau kurang dapat dipercaya.  Untuk menunjukkan pengaruh pengaruh usia pada hasil, kita dapat membuat grafik estimasi kepadatan kernel (KDE) - distribusi kepadatan nuklir, dicat dengan warna atribut target.  Ini menunjukkan distribusi dari satu variabel dan dapat diartikan sebagai histogram yang dihaluskan (dihitung sebagai kernel Gaussian untuk setiap titik, yang kemudian dirata-rata untuk dihaluskan). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')‚Äã #  plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/st/xs/e1/stxse1wipiaqcf0a7trlm0lwz0g.png"><br><br>  Seperti yang dapat dilihat, bagian default adalah lebih tinggi untuk kaum muda dan menurun dengan bertambahnya usia.  Ini bukan alasan untuk selalu menolak kredit kepada kaum muda, "rekomendasi" semacam itu hanya akan menyebabkan hilangnya pendapatan dan pasar bagi bank.  Ini adalah kesempatan untuk memikirkan pemantauan yang lebih menyeluruh atas pinjaman, penilaian dan, mungkin, bahkan semacam pendidikan keuangan untuk peminjam muda. <br><br><h3>  Sumber eksternal </h3><br>  Mari kita lihat lebih dekat "sumber data eksternal" EXT_SOURCE dan korelasinya. <br><br><pre> <code class="python hljs">ext_data = app_train[[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]] ext_data_corrs = ext_data.corr() ext_data_corrs</code> </pre> <br><img src="https://habrastorage.org/webt/5k/ba/fe/5kbafej-y0vvcexlt6iebcjvjbs.png"><br><br>  Juga nyaman untuk menampilkan korelasi menggunakan heatmap <br><br><pre> <code class="python hljs">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = <span class="hljs-number"><span class="hljs-number">-0.25</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, vmax = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Correlation Heatmap'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/webt/e6/wj/vw/e6wjvwnetgs2y-i65_4okda-6t8.png"><br><br>  Seperti yang Anda lihat, semua sumber menunjukkan korelasi negatif dengan target.  Mari kita lihat distribusi KDE untuk setiap sumber. <br><br><pre> <code class="python hljs">plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment">#    for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']): #  plt.subplot(3, 1, i + 1) #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0') #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1') #  plt.title('Distribution of %s by Target Value' % source) plt.xlabel('%s' % source); plt.ylabel('Density'); plt.tight_layout(h_pad = 2.5)</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/lf/ig/xm/lfigxmxlck1s4w2uyygfudghajm.png"><br><br>  Gambarannya mirip dengan distribusi berdasarkan usia - dengan peningkatan indikator, kemungkinan pengembalian pinjaman meningkat.  Sumber ketiga adalah yang paling kuat dalam hal ini.  Meskipun secara absolut korelasinya dengan variabel target masih dalam kategori ‚Äúsangat rendah‚Äù, sumber dan usia data eksternal akan menjadi yang paling penting dalam membangun model. <br><br><h3>  Jadwal berpasangan </h3><br>  Untuk lebih memahami hubungan variabel-variabel ini, Anda bisa membuat bagan pasangan, di dalamnya kita bisa melihat hubungan masing-masing pasangan dan histogram distribusi sepanjang diagonal.  Di atas diagonal, Anda dapat menunjukkan scatterplot, dan di bawah - 2d KDE. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       age_data = app_train[['TARGET', 'DAYS_BIRTH']] age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365‚Äã #     plot_data = ext_data.drop(labels = ['DAYS_BIRTH'], axis=1).copy()‚Äã #   plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']‚Äã #         100 .  plot_data = plot_data.dropna().loc[:100000, :]‚Äã #     def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[0][1] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(.2, .8), xycoords=ax.transAxes, size = 20)‚Äã #   pairgrid object grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue = 'TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])‚Äã #  -  grid.map_upper(plt.scatter, alpha = 0.2)‚Äã #  -  grid.map_diag(sns.kdeplot)‚Äã #  -   grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);‚Äã plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/wu/bm/ut/wubmutz04p4kwsmmk34gbuoq71g.png"><br><br>  Pinjaman yang dibayar kembali ditunjukkan dengan warna biru, tidak dapat dikembalikan dalam warna merah.  Untuk menginterpretasikan semua ini agak sulit, tetapi cetakan yang baik pada T-shirt atau gambar di museum seni modern dapat keluar dari gambar ini. <br><br><h3>  Pemeriksaan tanda-tanda lain </h3><br>  Mari kita pertimbangkan lebih detail fitur-fitur lain dan ketergantungannya pada variabel target.  Karena ada banyak yang kategorikal (dan kami sudah berhasil menyandikannya), kami kembali memerlukan data awal.  Mari kita sebut mereka sedikit berbeda untuk menghindari kebingungan <br><br><pre> <code class="python hljs">application_train = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_train.csv"</span></span>) application_test = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_test.csv"</span></span>)</code> </pre> <br>  Kami juga akan membutuhkan beberapa fungsi untuk menampilkan distribusi dan pengaruhnya pada variabel target.  Banyak terima kasih <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kepada</a> mereka untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penulis</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kernel</a> ini <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_stats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feature,label_rotation=False,horizontal_layout=True)</span></span></span><span class="hljs-function">:</span></span> temp = application_train[feature].value_counts() df1 = pd.DataFrame({feature: temp.index,<span class="hljs-string"><span class="hljs-string">' '</span></span>: temp.values})‚Äã <span class="hljs-comment"><span class="hljs-comment">#   target=1   cat_perc = application_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean() cat_perc.sort_values(by='TARGET', ascending=False, inplace=True) if(horizontal_layout): fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6)) else: fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14)) sns.set_color_codes("pastel") s = sns.barplot(ax=ax1, x = feature, y=" ",data=df1) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) plt.ylabel(' ', fontsize=10) plt.tick_params(axis='both', which='major', labelsize=10)‚Äã plt.show();</span></span></code> </pre> <br>  Jadi, kami akan mempertimbangkan tanda-tanda utama klien <br><br><h3>  Jenis pinjaman </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_TYPE'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gf/xr/hd/gfxrhdfhqe7zyvlvwjmtgg-opam.png"><br><br>  Menariknya, pinjaman bergulir (mungkin cerukan atau sesuatu seperti itu) membentuk kurang dari 10% dari total jumlah pinjaman.  Pada saat yang sama, persentase tidak-kembali di antara mereka jauh lebih tinggi.  Alasan yang baik untuk merevisi metodologi bekerja dengan pinjaman ini, dan bahkan mungkin mengabaikannya. <br><br><h3>  Jenis kelamin pelanggan </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CODE_GENDER'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fj/vu/eu/fjvueuchpemqvpmijfzsslyiy5m.png"><br><br>  Ada hampir dua kali lebih banyak klien wanita daripada pria, dengan pria menunjukkan risiko yang jauh lebih tinggi. <br><br><h3>  Kepemilikan mobil dan properti </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_CAR'</span></span>) plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_REALTY'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/l4/iv/u4/l4ivu4-yhdkdma8yjrnhj07evdq.png"><br><img src="https://habrastorage.org/webt/fg/qn/2-/fgqn2-3qqhjvkbovec9zm_qkfgo.png"><br><br>  Klien dengan mobil setengah dari "tidak punya kuda".  Risikonya hampir sama, pelanggan dengan mesin membayar sedikit lebih baik. <br><br>  Untuk real estat, yang terjadi adalah sebaliknya - hanya ada sedikit pelanggan tanpa itu.  Risiko untuk pemilik properti juga sedikit lebih sedikit. <br><br><h3>  Status pernikahan </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_FAMILY_STATUS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/7u/qt/t1/7uqtt10kghqs01w-_y_1e6vx2jw.png"><br><br>  Sementara sebagian besar klien sudah menikah, yang paling berisiko adalah klien sipil dan lajang.  Duda menunjukkan risiko minimal. <br><br><h3>  Jumlah anak </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_CHILDREN'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/5s/ux/o8/5suxo8vh8yl68pnxqf4vm7c-ixa.png"><br><br>  Sebagian besar pelanggan tidak memiliki anak.  Pada saat yang sama, pelanggan dengan 9 dan 11 anak-anak menunjukkan pengembalian dana yang tidak lengkap <br><br><pre> <code class="python hljs">application_train.CNT_CHILDREN.value_counts()</code> </pre> <br> <code>0 215371 <br> 1 61119 <br> 2 26749 <br> 3 3717 <br> 4 429 <br> 5 84 <br> 6 21 <br> 7 7 <br> 14 3 <br> 19 2 <br> 12 2 <br> 10 2 <br> 9 2 <br> 8 2 <br> 11 1 <br> Name: CNT_CHILDREN, dtype: int64</code> <br> <br>  Seperti yang ditunjukkan oleh perhitungan nilai, data ini tidak signifikan secara statistik - hanya 1-2 klien dari kedua kategori.  Namun, ketiganya menjadi default, seperti halnya setengah dari pelanggan dengan 6 anak. <br><br><h3>  Jumlah anggota keluarga </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_FAM_MEMBERS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/bw/tg/sc/bwtgsctk9vk_y8tcx9bv9fraogu.png"><br><br>  Situasinya mirip - semakin sedikit mulut, semakin tinggi pengembaliannya. <br><br><h3>  Jenis penghasilan </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_INCOME_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/ow/la/kf/owlakfzs7cqh74msyjw9ngeq8h4.png"><br><br>  Ibu tunggal dan penganggur cenderung terputus pada tahap aplikasi - ada terlalu sedikit dari mereka dalam sampel.  Tetapi masalah secara stabil menunjukkan. <br><br><h3>  Jenis kegiatan </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'OCCUPATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/pw/m4/eu/pwm4eui3y46rrd0380w5jnkqiug.png"><br><br><pre> <code class="python hljs">application_train.OCCUPATION_TYPE.value_counts()</code> </pre> <br> <code>Laborers 55186 <br> Sales staff 32102 <br> Core staff 27570 <br> Managers 21371 <br> Drivers 18603 <br> High skill tech staff 11380 <br> Accountants 9813 <br> Medicine staff 8537 <br> Security staff 6721 <br> Cooking staff 5946 <br> Cleaning staff 4653 <br> Private service staff 2652 <br> Low-skill Laborers 2093 <br> Waiters/barmen staff 1348 <br> Secretaries 1305 <br> Realty agents 751 <br> HR staff 563 <br> IT staff 526 <br> Name: OCCUPATION_TYPE, dtype: int64</code> <br> <br>  Sangat menarik bagi pengemudi dan petugas keamanan yang cukup banyak dan menghadapi masalah lebih sering daripada kategori lainnya. <br><br><h3>  Pendidikan </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_EDUCATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dh/g9/-t/dhg9-t4wl5oaaultg0m4ujq4ky0.png"><br><br>  Semakin tinggi pendidikan, semakin baik perulangannya, jelas. <br><br><h3>  Jenis organisasi - majikan </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'ORGANIZATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/nm/eq/p-/nmeqp-rvrmowwpqhkjzvygeah20.png"><br><br>  Persentase tertinggi non-pengembalian diamati di Transportasi: tipe 3 (16%), Industri: tipe 13 (13,5%), Industri: tipe 8 (12,5%) dan Restoran (hingga 12%). <br><br><h3>  Alokasi pinjaman </h3><br>  Pertimbangkan distribusi jumlah pinjaman dan dampaknya terhadap pembayaran <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" AMT_CREDIT"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"AMT_CREDIT"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/x1/8k/qg/x18kqghr1tue4io96l_keuqcr94.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'AMT_CREDIT'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'AMT_CREDIT'], label = 'target == 1')‚Äã #  plt.xlabel(' '); plt.ylabel(''); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/_3/fu/cj/_3fucjn19lmxvjjaamrrlwumh5m.png"><br><br>  Seperti yang ditunjukkan grafik kepadatan, jumlah yang kuat akan dikembalikan lebih sering <br><br><h3>  Distribusi kepadatan </h3><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" REGION_POPULATION_RELATIVE"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"REGION_POPULATION_RELATIVE"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/26/3h/os/263hoss0mbvvq2p0ewagrw5v-sm.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'REGION_POPULATION_RELATIVE'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'REGION_POPULATION_RELATIVE'], label = 'target == 1')‚Äã #  plt.xlabel(''); plt.ylabel(' '); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fs/ez/82/fsez82q5fbqdkiqizkxjralpm-8.png"><br><br>  Pelanggan dari daerah yang lebih padat cenderung membayar pinjaman lebih baik. <br><br>  Jadi, kami mendapat ide tentang fitur utama dataset dan pengaruhnya terhadap hasilnya.  Kami tidak akan melakukan apa pun secara khusus dengan yang tercantum dalam artikel ini, tetapi mereka dapat menjadi sangat penting dalam pekerjaan di masa depan. <br><br><h2>  Rekayasa Fitur - Konversi Fitur </h2><br>  Kompetisi di Kaggle dimenangkan oleh transformasi tanda - orang yang bisa membuat tanda paling berguna dari data yang menang.  Setidaknya untuk data terstruktur, model yang menang pada dasarnya adalah opsi peningkatan gradien yang berbeda.  Lebih sering daripada tidak, itu lebih efisien untuk menghabiskan waktu mengonversi atribut daripada mengatur hyperparameters atau memilih model.  Model masih dapat belajar hanya dari data yang telah ditransfer ke sana.  Memastikan bahwa data itu relevan dengan tugas adalah tanggung jawab utama dari tanggal Scientist. <br><br>  Proses transformasi karakteristik dapat mencakup pembuatan data baru yang tersedia, pemilihan yang paling penting yang tersedia, dll.  Kami akan mencoba tanda polinomial kali ini. <br><br><h3>  Tanda-tanda jumlahnya banyak </h3><br>  Metode polinomial membangun fitur adalah bahwa kami hanya membuat fitur yang tingkat fitur yang tersedia dan produk mereka.  Dalam beberapa kasus, fitur yang dibangun tersebut mungkin memiliki korelasi yang lebih kuat dengan variabel target daripada "orang tua" mereka.  Meskipun metode seperti itu sering digunakan dalam model statistik, mereka jauh kurang umum dalam pembelajaran mesin.  Namun demikian.  tidak ada yang menghalangi kita untuk mencobanya, terutama karena Scikit-Learn memiliki kelas khusus untuk tujuan ini - PolynomialFeatures - yang menciptakan fitur polinomial dan produknya, Anda hanya perlu menentukan fitur asli sendiri dan tingkat maksimum yang perlu ditingkatkan.  Kami menggunakan efek paling kuat pada hasil 4 atribut dan derajat 3 agar tidak terlalu menyulitkan model dan menghindari overfitting (overtraining model - penyesuaian berlebihan pada sampel pelatihan). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']] poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]‚Äã #    from sklearn.preprocessing import Imputer imputer = Imputer(strategy = 'median')‚Äã poly_target = poly_features['TARGET']‚Äã poly_features = poly_features.drop('TARGET', axis=1)‚Äã poly_features = imputer.fit_transform(poly_features) poly_features_test = imputer.transform(poly_features_test) from sklearn.preprocessing import PolynomialFeatures #     3 poly_transformer = PolynomialFeatures(degree = 3) #    poly_transformer.fit(poly_features) #   poly_features = poly_transformer.transform(poly_features) poly_features_test = poly_transformer.transform(poly_features_test) print('  : ', poly_features.shape)</span></span></code> </pre> <br> <code>  : (307511, 35) <br>        get_feature_names</code> <br> <br><pre> <code class="python hljs">poly_transformer.get_feature_names(input_features = [<span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>])[:<span class="hljs-number"><span class="hljs-number">15</span></span>]</code> </pre> <br> <code>['1', <br> 'EXT_SOURCE_1', <br> 'EXT_SOURCE_2', <br> 'EXT_SOURCE_3', <br> 'DAYS_BIRTH', <br> 'EXT_SOURCE_1^2', <br> 'EXT_SOURCE_1 EXT_SOURCE_2', <br> 'EXT_SOURCE_1 EXT_SOURCE_3', <br> 'EXT_SOURCE_1 DAYS_BIRTH', <br> 'EXT_SOURCE_2^2', <br> 'EXT_SOURCE_2 EXT_SOURCE_3', <br> 'EXT_SOURCE_2 DAYS_BIRTH', <br> 'EXT_SOURCE_3^2', <br> 'EXT_SOURCE_3 DAYS_BIRTH', <br> 'DAYS_BIRTH^2']</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sebanyak 35 fitur polinomial dan turunannya. </font><font style="vertical-align: inherit;">Periksa korelasinya dengan target.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #   poly_features['TARGET'] = poly_target‚Äã #   poly_corrs = poly_features.corr()['TARGET'].sort_values()‚Äã #      print(poly_corrs.head(10)) print(poly_corrs.tail(5))</span></span></code> </pre> <br> <code>EXT_SOURCE_2 EXT_SOURCE_3 -0.193939 <br> EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 -0.189605 <br> EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH -0.181283 <br> EXT_SOURCE_2^2 EXT_SOURCE_3 -0.176428 <br> EXT_SOURCE_2 EXT_SOURCE_3^2 -0.172282 <br> EXT_SOURCE_1 EXT_SOURCE_2 -0.166625 <br> EXT_SOURCE_1 EXT_SOURCE_3 -0.164065 <br> EXT_SOURCE_2 -0.160295 <br> EXT_SOURCE_2 DAYS_BIRTH -0.156873 <br> EXT_SOURCE_1 EXT_SOURCE_2^2 -0.156867 <br> Name: TARGET, dtype: float64 <br> DAYS_BIRTH -0.078239 <br> DAYS_BIRTH^2 -0.076672 <br> DAYS_BIRTH^3 -0.074273 <br> TARGET 1.000000 <br> 1 NaN <br> Name: TARGET, dtype: float64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jadi, beberapa tanda menunjukkan korelasi yang lebih tinggi dari aslinya. </font><font style="vertical-align: inherit;">Masuk akal untuk mencoba belajar dengan mereka dan tanpa mereka (seperti banyak pembelajaran mesin, ini dapat ditentukan secara eksperimental). </font><font style="vertical-align: inherit;">Untuk melakukan ini, buat salinan kerangka data dan tambahkan fitur baru di sana.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      poly_features_test = pd.DataFrame(poly_features_test, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #    poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR'] app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')‚Äã #    poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR'] app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')‚Äã #   app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)‚Äã #   print('    : ', app_train_poly.shape) print('    : ', app_test_poly.shape)</span></span></code> </pre> <br> <code>    : (307511, 277) <br>     : (48744, 277)</code> <br> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pelatihan model </font></font></h2><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tingkat dasar </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam perhitungan, Anda harus mulai dari beberapa level dasar model, di bawah ini tidak mungkin lagi jatuh. </font><font style="vertical-align: inherit;">Dalam kasus kami, ini bisa menjadi 0,5 untuk semua klien uji - ini menunjukkan bahwa kami tidak tahu sama sekali apakah klien akan membayar pinjaman atau tidak. </font><font style="vertical-align: inherit;">Dalam kasus kami, pekerjaan pendahuluan telah dilakukan dan model yang lebih kompleks dapat digunakan.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Regresi Logistik </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk menghitung </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regresi logistik,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> kita perlu mengambil tabel dengan fitur kategorikal berkode, mengisi data yang hilang dan menormalkannya (membawanya ke nilai dari 0 hingga 1). </font><font style="vertical-align: inherit;">Semua ini menjalankan kode berikut:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MinMaxScaler, Imputer‚Äã <span class="hljs-comment"><span class="hljs-comment">#      if 'TARGET' in app_train: train = app_train.drop(labels = ['TARGET'], axis=1) else: train = app_train.copy() features = list(train.columns)‚Äã #    test = app_test.copy()‚Äã #     imputer = Imputer(strategy = 'median')‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã #    imputer.fit(train)‚Äã #      train = imputer.transform(train) test = imputer.transform(app_test)‚Äã #      scaler.fit(train) train = scaler.transform(train) test = scaler.transform(test)‚Äã print('  : ', train.shape) print('  : ', test.shape)</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami menggunakan regresi logistik dari Scikit-Learn sebagai model pertama. </font><font style="vertical-align: inherit;">Mari kita ambil model defolasi dengan satu koreksi - kita menurunkan parameter regularisasi C untuk menghindari overfitting. </font><font style="vertical-align: inherit;">Sintaksnya normal - kita membuat model, melatihnya dan memprediksi probabilitas menggunakan predict_proba (kita perlu probabilitas, bukan 0/1)</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression‚Äã <span class="hljs-comment"><span class="hljs-comment">#   log_reg = LogisticRegression(C = 0.0001)‚Äã #   log_reg.fit(train, train_labels) LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)      .  prdict_proba     mx 2,  m -  ,   -  0,  -  1.    ( ). log_reg_pred = log_reg.predict_proba(test)[:, 1]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekarang Anda dapat membuat file untuk diunggah ke Kaggle. </font><font style="vertical-align: inherit;">Buat bingkai data dari ID pelanggan dan kemungkinan tidak ada pengembalian dan unggah.</font></font><br><br><pre> <code class="python hljs">submit = app_test[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]] submit[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>] = log_reg_pred‚Äã submit.head()</code> </pre> <br> <code>SK_ID_CURR TARGET <br> 0 100001 0.087954 <br> 1 100005 0.163151 <br> 2 100013 0.109923 <br> 3 100028 0.077124 <br> 4 100038 0.151694</code> <br> <br><pre> <code class="python hljs">submit.to_csv(<span class="hljs-string"><span class="hljs-string">'log_reg_baseline.csv'</span></span>, index = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jadi, hasil karya raksasa kami: 0,673, dengan hasil terbaik untuk hari ini adalah 0,802.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Model yang Ditingkatkan - Hutan Acak </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logreg tidak menunjukkan dirinya dengan sangat baik, mari kita coba menggunakan model yang lebih baik - hutan acak. </font><font style="vertical-align: inherit;">Ini adalah model yang jauh lebih kuat yang dapat membangun ratusan pohon dan menghasilkan hasil yang jauh lebih akurat. </font><font style="vertical-align: inherit;">Kami menggunakan 100 pohon. </font><font style="vertical-align: inherit;">Skema bekerja dengan model adalah sama, sepenuhnya standar - memuat classifier, pelatihan. </font><font style="vertical-align: inherit;">prediksi.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier‚Äã <span class="hljs-comment"><span class="hljs-comment">#   random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)‚Äã #     random_forest.fit(train, train_labels)‚Äã #     predictions = random_forest.predict_proba(test)[:, 1]‚Äã #     submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #  submit.to_csv('random_forest_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hasil hutan acak sedikit lebih baik - 0,683</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Model pelatihan dengan fitur polinomial </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekarang kita punya model. </font><font style="vertical-align: inherit;">yang setidaknya melakukan sesuatu - saatnya untuk menguji tanda-tanda jumlahnya banyak. </font><font style="vertical-align: inherit;">Mari kita lakukan hal yang sama dengan mereka dan bandingkan hasilnya.</font></font><br><br><pre> <code class="python hljs">poly_features_names = list(app_train_poly.columns)‚Äã <span class="hljs-comment"><span class="hljs-comment">#         imputer = Imputer(strategy = 'median')‚Äã poly_features = imputer.fit_transform(app_train_poly) poly_features_test = imputer.transform(app_test_poly)‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã poly_features = scaler.fit_transform(poly_features) poly_features_test = scaler.transform(poly_features_test)‚Äã random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50) #     random_forest_poly.fit(poly_features, train_labels)‚Äã #  predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]‚Äã #    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('random_forest_baseline_engineered.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hasil hutan acak dengan fitur polinom menjadi lebih buruk - 0,633. </font><font style="vertical-align: inherit;">Yang sangat mempertanyakan perlunya penggunaan mereka.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Peningkatan Gradien </font></font></h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Meningkatkan gradien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> adalah "model serius" untuk pembelajaran mesin. </font><font style="vertical-align: inherit;">Hampir semua kompetisi terbaru "diseret" dengan tepat. </font><font style="vertical-align: inherit;">Mari kita membangun model sederhana dan menguji kinerjanya.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf = LGBMClassifier() clf.fit(train, train_labels)‚Äã predictions = clf.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('lightgbm_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasil dari LightGBM adalah 0.735, yang meninggalkan semua model lainnya.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Interpretasi Model - Pentingnya Atribut </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cara termudah untuk menafsirkan model adalah dengan melihat pentingnya fitur (yang tidak semua model bisa lakukan). </font><font style="vertical-align: inherit;">Karena classifier kami memproses array, dibutuhkan beberapa pekerjaan untuk mengatur ulang nama kolom sesuai dengan kolom array ini.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def show_feature_importances(model, features): plt.figure(figsize = (12, 8)) #          results = pd.DataFrame({'feature': features, 'importance': model.feature_importances_}) results = results.sort_values('importance', ascending = False) #  print(results.head(10)) print('\n     0.01 = ', np.sum(results['importance'] &gt; 0.01)) #  results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh', color = 'red', edgecolor = 'k', title = 'Feature Importances'); return results #         feature_importances = show_feature_importances(clf, features)</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seperti yang diharapkan, yang paling penting untuk model semua 4 fitur yang sama. </font><font style="vertical-align: inherit;">Pentingnya atribut bukan metode interpretasi model terbaik, tetapi memungkinkan Anda untuk memahami faktor utama yang digunakan model untuk prediksi</font></font><code>feature importance <br> 28 EXT_SOURCE_1 310 <br> 30 EXT_SOURCE_3 282 <br> 29 EXT_SOURCE_2 271 <br> 7 DAYS_BIRTH 192 <br> 3 AMT_CREDIT 161 <br> 4 AMT_ANNUITY 142 <br> 5 AMT_GOODS_PRICE 129 <br> 8 DAYS_EMPLOYED 127 <br> 10 DAYS_ID_PUBLISH 102 <br> 9 DAYS_REGISTRATION 69 <br> <br>     0.01 = 158</code> <br> <br><img src="https://habrastorage.org/webt/uc/pi/ox/ucpiox1dno_vps4lsuk0lmxk7si.png"><br><br><font style="vertical-align: inherit;"></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Menambahkan data dari tabel lain </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekarang kita akan dengan cermat mempertimbangkan tabel tambahan dan apa yang dapat dilakukan dengannya. </font><font style="vertical-align: inherit;">Segera mulai menyiapkan tabel untuk pelatihan lebih lanjut. </font><font style="vertical-align: inherit;">Tapi pertama-tama, hapus tabel voluminous masa lalu dari memori, hapus memori menggunakan pengumpul sampah, dan impor perpustakaan yang diperlukan untuk analisis lebih lanjut.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc‚Äã <span class="hljs-comment"><span class="hljs-comment">#del app_train, app_test, train_labels, application_train, application_test, poly_features, poly_features_test‚Äã gc.collect() import pandas as pd import numpy as np‚Äã from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.model_selection import train_test_split, KFold from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix from sklearn.feature_selection import VarianceThreshold‚Äã from lightgbm import LGBMClassifier</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Impor data, segera hapus kolom target di kolom terpisah </font></font><br><br><pre> <code class="python hljs">data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_train.csv'</span></span>) test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_test.csv'</span></span>) prev = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/previous_application.csv'</span></span>) buro = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau.csv'</span></span>) buro_balance = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau_balance.csv'</span></span>) credit_card = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/credit_card_balance.csv'</span></span>) POS_CASH = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/POS_CASH_balance.csv'</span></span>) payments = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/installments_payments.csv'</span></span>)‚Äã <span class="hljs-comment"><span class="hljs-comment">#Separate target variable y = data['TARGET'] del data['TARGET']</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Segera mengkodekan fitur-fitur kategorikal. </font><font style="vertical-align: inherit;">Kami sudah melakukan ini sebelumnya, dan kami membuat kode pelatihan dan menguji sampel secara terpisah, dan kemudian menyelaraskan data. </font><font style="vertical-align: inherit;">Mari kita coba pendekatan yang sedikit berbeda - kita akan menemukan semua tanda kategorikal ini, menggabungkan bingkai data, mengkodekan dari daftar yang ditemukan, dan kemudian lagi membagi sampel menjadi pelatihan dan pengujian.</font></font><br><br><pre> <code class="python hljs">categorical_features = [col <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[col].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>]‚Äã one_hot_df = pd.concat([data,test]) one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)‚Äã data = one_hot_df.iloc[:data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],:] test = one_hot_df.iloc[data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]:,]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape)</code> </pre> <br> <code>   (307511, 245) <br>    (48744, 245)</code> <br> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Data biro kredit pada saldo pinjaman bulanan. </font></font></h3><br><pre> <code class="python hljs">buro_balance.head()</code> </pre> <br><img src="https://habrastorage.org/webt/pa/im/0s/paim0sea2cdjnvm7lok--vi8oke.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MONTHS_BALANCE - jumlah bulan sebelum tanggal permohonan pinjaman. </font><font style="vertical-align: inherit;">Lihatlah lebih dekat pada "status"</font></font><br><br><pre> <code class="python hljs">buro_balance.STATUS.value_counts()</code> </pre> <br> <code>C 13646993 <br> 0 7499507 <br> X 5810482 <br> 1 242347 <br> 5 62406 <br> 2 23419 <br> 3 8924 <br> 4 5847 <br> Name: STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Status berarti yang berikut: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - ditutup, yaitu, pinjaman dibayar kembali. </font><font style="vertical-align: inherit;">X adalah status yang tidak dikenal. </font><font style="vertical-align: inherit;">0 - pinjaman saat ini, tidak ada kenakalan. </font><font style="vertical-align: inherit;">1 - penundaan 1-30 hari, 2 - penundaan 31-60 hari, dan seterusnya hingga status 5 - pinjaman dijual kepada pihak ketiga atau dihapusbukukan. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Di sini, misalnya, tanda-tanda berikut dapat dibedakan: buro_grouped_size - jumlah entri dalam database buro_grouped_max - saldo pinjaman maksimum buro_grouped_min - saldo pinjaman minimum. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dan semua status pinjaman ini dapat dikodekan (kami menggunakan metode unstack, sejak kami menggunakan metode unstack, karena SK_ID_BUREAU sama di sana-sini.</font></font><br><br><pre> <code class="python hljs">buro_grouped_size = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].size() buro_grouped_max = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].max() buro_grouped_min = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].min()‚Äã buro_counts = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>].value_counts(normalize = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) buro_counts_unstacked = buro_counts.unstack(<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>) buro_counts_unstacked.columns = [<span class="hljs-string"><span class="hljs-string">'STATUS_0'</span></span>, <span class="hljs-string"><span class="hljs-string">'STATUS_1'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_2'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_3'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_4'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_5'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_C'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_X'</span></span>,] buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_COUNT'</span></span>] = buro_grouped_size buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MIN'</span></span>] = buro_grouped_min buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MAX'</span></span>] = buro_grouped_max‚Äã buro = buro.join(buro_counts_unstacked, how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro_balance gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Informasi umum tentang biro kredit </font></font></h3><br><pre> <code class="python hljs">buro.head()</code> </pre> <br><img src="https://habrastorage.org/webt/00/7q/dz/007qdzakfbvd5qiizsxqwxvoari.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(7 kolom pertama diperlihatkan) Ada </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cukup banyak data yang, secara umum, Anda dapat mencoba menyandikan dengan One-Hot-Encoding, grup dengan SK_ID_CURR, rata-rata dan, dengan cara yang sama, bersiap untuk bergabung dengan tabel utama</font></font><br><br><pre> <code class="python hljs">buro_cat_features = [bcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> bcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> buro.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> buro[bcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] buro = pd.get_dummies(buro, columns=buro_cat_features) avg_buro = buro.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_buro[<span class="hljs-string"><span class="hljs-string">'buro_count'</span></span>] = buro[[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_buro[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Data pada aplikasi sebelumnya </font></font></h3><br><pre> <code class="python hljs">prev.head()</code> </pre> <br><img src="https://habrastorage.org/webt/nx/sv/z-/nxsvz-simhdingy0zqgnwg9xxpi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Demikian pula, kami menyandikan fitur-fitur kategorikal, rata-rata dan bergabung di atas ID saat ini. </font></font><br><br><pre> <code class="python hljs">prev_cat_features = [pcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prev.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> prev[pcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] prev = pd.get_dummies(prev, columns=prev_cat_features) avg_prev = prev.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() cnt_prev = prev[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count() avg_prev[<span class="hljs-string"><span class="hljs-string">'nb_app'</span></span>] = cnt_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> prev gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Saldo kartu kredit </font></font></h3><br><pre> <code class="python hljs">POS_CASH.head()</code> </pre> <br><img src="https://habrastorage.org/webt/aq/25/er/aq25erq2wzuknck85ina4twk2g8.png"><br><br><pre> <code class="python hljs">POS_CASH.NAME_CONTRACT_STATUS.value_counts()</code> </pre> <br> <code>Active 9151119 <br> Completed 744883 <br> Signed 87260 <br> Demand 7065 <br> Returned to the store 5461 <br> Approved 4917 <br> Amortized debt 636 <br> Canceled 15 <br> XNA 2 <br> Name: NAME_CONTRACT_STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kami menyandikan fitur kategorikal dan menyiapkan tabel untuk digabungkan </font></font><br><br><pre> <code class="python hljs">le = LabelEncoder() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Data Kartu </font></font></h3><br><pre> <code class="python hljs">credit_card.head()</code> </pre> <br><img src="https://habrastorage.org/webt/q5/wj/pj/q5wjpj8s-vak-svacdtlhqrwlus.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(7 kolom pertama) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pekerjaan serupa</font></font><br><br><pre> <code class="python hljs">credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Data Pembayaran </font></font></h3><br><pre> <code class="python hljs">payments.head()</code> </pre> <br><img src="https://habrastorage.org/webt/ay/fy/3y/ayfy3yp5tzdxsffurkrgjd4udwu.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(7 kolom pertama ditampilkan) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mari kita buat tiga tabel - dengan nilai rata-rata, minimum dan maksimum dari tabel ini.</font></font><br><br><pre> <code class="python hljs">avg_payments = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_payments2 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() avg_payments3 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).min() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_payments[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> payments gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Meja gabung </font></font></h3><br><pre> <code class="python hljs">data = data.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev, avg_buro, POS_CASH, credit_card, avg_payments, avg_payments2, avg_payments3 gc.collect() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, y.shape)</code> </pre> <br> <code>   (307511, 504) <br>    (48744, 504) <br>    (307511,)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dan, sebenarnya, kita akan mencapai tabel ganda ini dengan peningkatan gradien! </font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf2 = LGBMClassifier() clf2.fit(data, y)‚Äã predictions = clf2.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submission = test[['SK_ID_CURR']] submission['TARGET'] = predictions‚Äã #   submission.to_csv('lightgbm_full.csv', index = False)</span></span></code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hasilnya adalah 0,770. </font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oke, akhirnya, mari kita coba teknik yang lebih kompleks dengan melipat menjadi lipatan, validasi silang dan memilih iterasi terbaik.</font></font><br><br><pre> <code class="python hljs">folds = KFold(n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">546789</span></span>) oof_preds = np.zeros(data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) sub_preds = np.zeros(test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])‚Äã feature_importance_df = pd.DataFrame()‚Äã feats = [f <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n_fold, (trn_idx, val_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(folds.split(data)): trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx] val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx] clf = LGBMClassifier( n_estimators=<span class="hljs-number"><span class="hljs-number">10000</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, num_leaves=<span class="hljs-number"><span class="hljs-number">34</span></span>, colsample_bytree=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, subsample=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">8</span></span>, reg_alpha=<span class="hljs-number"><span class="hljs-number">.1</span></span>, reg_lambda=<span class="hljs-number"><span class="hljs-number">.1</span></span>, min_split_gain=<span class="hljs-number"><span class="hljs-number">.01</span></span>, min_child_weight=<span class="hljs-number"><span class="hljs-number">375</span></span>, silent=<span class="hljs-number"><span class="hljs-number">-1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">-1</span></span>, ) clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], eval_metric=<span class="hljs-string"><span class="hljs-string">'auc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">100</span></span>, early_stopping_rounds=<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#30 ) oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1] sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits fold_importance_df = pd.DataFrame() fold_importance_df["feature"] = feats fold_importance_df["importance"] = clf.feature_importances_ fold_importance_df["fold"] = n_fold + 1 feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0) print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]))) del clf, trn_x, trn_y, val_x, val_y gc.collect()‚Äã print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))‚Äã test['TARGET'] = sub_preds‚Äã test[['SK_ID_CURR', 'TARGET']].to_csv('submission_cross.csv', index=False)</span></span></code> </pre> <br> <code>Full AUC score 0.785845</code> <br> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Skor terakhir pada kaggle 0.783</font></font></b> <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ke mana harus pergi selanjutnya </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jelas terus bekerja dengan tanda-tanda. Jelajahi data, pilih beberapa tanda, gabungkan, lampirkan tabel tambahan dengan cara yang berbeda. Anda dapat bereksperimen dengan hyperparameters Mogheli - banyak arah. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Saya harap kompilasi kecil ini telah menunjukkan kepada Anda metode modern untuk meneliti data dan menyiapkan model prediksi. Pelajari datasaens, berpartisipasi dalam kompetisi, menjadi keren! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dan lagi tautan ke kernel yang membantu saya menyiapkan artikel ini. Artikel ini juga diposting dalam bentuk </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">laptop di Github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Anda dapat mengunduhnya, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dataset</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">dan jalankan serta percobaan. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Will Koehrsen. Mulai Di Sini: Pengantar Lembut </font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. HomeCreditRisk: EDA + Baseline Luas [0,772]</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Gabriel Preda. Home Credit Default Risk Extensive EDA</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pavan Raj. Loan repayers v/s Loan defaulters ‚Äî HOME CREDIT</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Lem Lordje Ko. 15 lines: Just EXT_SOURCE_x</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Shanth. HOME CREDIT ‚Äî BUREAU DATA ‚Äî FEATURE ENGINEERING</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dmitriy Kisil. Good_fun_with_LigthGBM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id414613/">https://habr.com/ru/post/id414613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id414597/index.html">Tanyakan pada Ethan: Seberapa dekat peradaban asing dapat bersatu?</a></li>
<li><a href="../id414601/index.html">Ketika gunung-gunung tinggi dan laptop-laptop besar: sedikit sejarah TI lagi</a></li>
<li><a href="../id414605/index.html">Kerajaan mini</a></li>
<li><a href="../id414609/index.html">Bisakah 2018 PWA (Progressive Web Apps) menjadi kompetisi yang layak untuk aplikasi asli?</a></li>
<li><a href="../id414611/index.html">Kisah saya tentang membuat aplikasi motivasi (iOS dan Android) untuk anak perempuan dengan anak perempuan di Unity dan C #</a></li>
<li><a href="../id414615/index.html">Lupakan GDPR: Reformasi hak cipta UE sepenuhnya dapat mengubah web</a></li>
<li><a href="../id414617/index.html">Efisiensi Sumber Daya Komputasi</a></li>
<li><a href="../id414619/index.html">Hogwarts Merah. Seri 8. Berlayar</a></li>
<li><a href="../id414621/index.html">Sistem robot mempercepat pengambilan sampel darah dan pengujian</a></li>
<li><a href="../id414625/index.html">Data Center World: apakah layak untuk diajak naik?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
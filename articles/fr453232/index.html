<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏹 👩‍🎨 ☪️ Écrire des milliards de chansons avec C # et Deep Learning 🆓 ⭐️ 👨‍🎓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je vais expliquer comment créer un site Web ASP.NET Core , qui utilise l'IA pour générer des paroles de chansons uniques en un seul ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Écrire des milliards de chansons avec C # et Deep Learning</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/453232/">  Dans cet article, je vais expliquer comment créer un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">site Web ASP.NET Core</a> , qui utilise l'IA pour générer des paroles de chansons uniques en un seul clic, et permet aux utilisateurs de voter pour les meilleures chansons. <br><a name="habracut"></a><br><h1>  Le réseau neuronal </h1><br>  Il y a environ 2,5 mois, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">OpenAI a</a> publié <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">un article de blog</a> , où ils ont démontré presque impossible: un modèle d'apprentissage en profondeur, qui peut écrire des articles, indiscernables de ceux écrits par des humains.  Le texte qu'il a généré était si impressionnant, que j'ai dû vérifier le calendrier pour m'assurer que ce n'était pas une blague de poisson d'avril (rappelez-vous que c'était en février et que Seattle était couverte de neige). <br><br><p><img src="https://habrastorage.org/webt/df/ok/nc/dfoknc5wbfxrkyvigyygtz9kctw.png" alt="Exemple de texte GPT-2"></p><br><p> Ils n'ont pas publié le plus grand réseau de neurones avec plus d'un milliard de paramètres qu'ils ont construits à ce jour (une décision très controversée), mais ils ont ouvert une version plus petite de 117 millions de paramètres <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">sur GitHub</a> sous licence MIT.  Le modèle porte un nom très inoubliable: <b>GPT-2</b> . </p><br><p>  Il y a environ un mois, alors que j'essayais de penser au projet cool que je pouvais faire avec TensorFlow, ce réseau est devenu le point de départ.  S'il pouvait déjà générer du texte anglais, il n'aurait pas dû être trop difficile de le <i>régler</i> avec précision pour générer les paroles des chansons, s'il existe un ensemble de données suffisamment volumineux. </p><br><h2>  Comment fonctionne GPT-2? </h2><br><p>  Il existe plusieurs réalisations importantes dans la recherche sur l'apprentissage en profondeur, qui ont rendu possible le GPT-2: </p><br><h3>  Apprentissage auto-supervisé </h3><br><p>  Cette technique a obtenu son nom finalisé par Yan LeCunn quelques jours seulement après avoir écrit la première version de cet article.  C'est une technique très puissante, qui peut être appliquée à pratiquement n'importe quel type de données du monde réel.  Pour former GPT-2, OpenAI a collecté des <i>dizaines de gigaoctets d'articles</i> provenant de diverses sources, qui ont été votés sur Reddit. </p><br><p>  Classiquement, il faudrait avoir un être humain pour parcourir tous ces articles et, par exemple, les marquer comme «positifs» ou «négatifs».  Ensuite, ils enseigneraient un réseau de neurones de manière supervisée pour classer ces articles de la même manière qu'un humain. </p><br><p><img src="https://habrastorage.org/webt/cn/sl/_2/cnsl_21o1f-vio39rn5auufl_lw.jpeg" alt="RECAPTCHA: trouver des signes stree"></p><br><p>  La nouvelle idée ici est que pour créer un modèle d'apprentissage en profondeur, qui a une compréhension de haut niveau de vos données, vous corrompez simplement les données et chargez le modèle de restaurer l'original.  Cela permet au modèle de comprendre les connexions entre les éléments de données et leurs contextes environnants. </p><br><p>  Prenons le texte comme exemple.  GPT-2 prend un échantillon du texte d'origine, sélectionne 15% des jetons à corrompre, puis en masque 80% (par exemple, remplace par un jeton de masque spécial, généralement ___), remplace 10% par un autre jeton aléatoire du dictionnaire, et conserve les 10% restants intacts.  Prenez <i>j'ai lancé une balle et elle est tombée dans l'herbe</i> .  Après la corruption, cela pourrait ressembler à ceci: <i>j'ai jeté une balle de voiture et ___ dans l'herbe</i> .  En termes simples, pour que le réseau rétablisse l'original, il doit apprendre que quelque chose sera probablement tombé et que la balle de voiture est quelque chose de très rare dans le contexte. </p><br><p>  Un modèle formé comme ça est bon pour générer / compléter des données partielles, mais les fonctionnalités de haut niveau qu'il a apprises (en tant que sorties de couches internes) peuvent être utilisées à d'autres fins en ajoutant une couche ou deux au-dessus et en affinant <b>seulement cette nouvelle dernière couche</b> sur un ensemble de données réel, <b>plus petit</b> et marqué par l'homme d'une manière conventionnelle. </p><br><h3>  Peu d'attention </h3><br><p>  GPT-2 utilise ce que l'on appelle l'auto-attention clairsemée.  En substance, c'est une technique qui permet au réseau de neurones traitant de grandes entrées de se concentrer sur certaines parties de celui-ci plus que sur d'autres.  Et le réseau apprend où il doit «regarder» pendant la formation.  Le mécanisme d'attention est mieux expliqué dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">ce billet de blog</a> . </p><br><p>  La partie <i>clairsemée</i> du titre de cette section fait référence à une restriction sur les segments d'entrée dans lesquels le mécanisme d'attention peut choisir.  L'attention initiale pourrait choisir parmi l'ensemble de l'entrée.  Cela a provoqué sa matrice de poids à O (input_size ^ 2), qui croît très rapidement avec la taille de l'entrée.  Une attention limitée restreint généralement cela d'une certaine manière.  Pour plus d'informations à ce sujet, consultez un autre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">article de blog OpenAI</a> . </p><br><p>  L'attention dans GPT-2 est <i>multi-tête</i> .  Imaginez que vous puissiez avoir un ou deux yeux supplémentaires que vous pourriez utiliser pour vérifier ce qui était dans le dernier paragraphe sans arrêter la lecture de l'actuel. </p><br><h3>  Beaucoup plus </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Connexions résiduelles</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">codage de paire d'octets</a> , prédiction de la phrase suivante et bien d'autres. </p><br><h2>  Portage de GPT-2 (et conversion de Python en général) </h2><br><p>  Le code du modèle d'origine est en Python, mais je suis un gars C #.  Heureusement, le code source est assez lisible, et le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">nœud de celui</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">ci</a> est en seulement 5 fichiers, peut-être 500 lignes au total.  J'ai donc créé un nouveau projet .NET Standard, installé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Gradient</a> (une liaison TensorFlow pour .NET) et converti ces fichiers ligne par ligne en C #.  Cela m'a pris environ 2 heures.  La seule chose pythonique restante dans le code était l'utilisation du module regex Python de pip (le gestionnaire de packages le plus couramment utilisé pour Python), car je ne voulais pas perdre de temps à apprendre les subtilités des expressions régulières Python ( <i>comme si cela ne suffisait pas). pour traiter déjà ceux .NET</i> ). </p><br><p>  La conversion consistait principalement à définir des classes similaires, à ajouter des types et à réécrire les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">compréhensions de liste</a> Python dans les constructions LINQ correspondantes.  En plus de LINQ de la bibliothèque standard, j'ai utilisé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">MoreLinq</a> , qui étend légèrement ce que LINQ peut faire. Par exemple: </p><br><p></p><pre><code class="python hljs">bs = list(range(ord(<span class="hljs-string"><span class="hljs-string">"!"</span></span>), ord(<span class="hljs-string"><span class="hljs-string">"~"</span></span>)+<span class="hljs-number"><span class="hljs-number">1</span></span>)) + list(range(ord(<span class="hljs-string"><span class="hljs-string">"¡"</span></span>), ord(<span class="hljs-string"><span class="hljs-string">"¬"</span></span>)+<span class="hljs-number"><span class="hljs-number">1</span></span>)) + list(range(ord(<span class="hljs-string"><span class="hljs-string">""</span></span>), ord(<span class="hljs-string"><span class="hljs-string">"ÿ"</span></span>)+<span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><p>  transformé en: </p><br><p></p><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bs = Range(<span class="hljs-string"><span class="hljs-string">'!'</span></span>, <span class="hljs-string"><span class="hljs-string">'~'</span></span> - <span class="hljs-string"><span class="hljs-string">'!'</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>) .Concat(Range(<span class="hljs-string"><span class="hljs-string">'¡'</span></span>, <span class="hljs-string"><span class="hljs-string">'¬'</span></span> -<span class="hljs-string"><span class="hljs-string">'¡'</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>)) .Concat(Range(<span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'ÿ'</span></span> - <span class="hljs-string"><span class="hljs-string">''</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>)) .ToList();</code> </pre> <br><p>  Une autre chose avec laquelle je devais me battre était une divergence entre la façon dont Python gère les plages et les nouvelles fonctionnalités des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">plages et des index</a> dans le prochain C # 8, que j'ai découvert lors du débogage de mes exécutions initiales: en C # 8, la fin de la plage est <b>inclusive</b> , tandis qu'en Python il est <b>exclusif</b> (pour inclure le tout dernier élément en Python, vous devez omettre le côté droit de <i>..</i> expression). </p><br><blockquote>  Il y a deux choses difficiles en informatique: l'invalidation du cache, le nommage des choses et les erreurs ponctuelles. </blockquote><br><p>  Malheureusement, le drop source d'origine ne contenait aucune formation ni même de code de réglage fin, mais <b>Neil Shepperd a</b> fourni un simple réglage fin sur son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">GitHub</a> , que je devais également porter.  Quoi qu'il en soit, le résultat de cet effort est un <b>code C #</b> , qui peut être utilisé <b>pour jouer avec GPT-2</b> , fait maintenant partie du référentiel des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">échantillons</a> de dégradé. </p><br><p>  Le but de l'exercice de portage est double: après le portage, on peut <b>jouer avec le code du modèle dans son IDE C # préféré</b> et montrer <b>qu'il est désormais possible d'obtenir des modèles d'apprentissage en profondeur de pointe fonctionnant en mode personnalisé. Les projets .NET</b> peu de temps après la sortie (entre la chute de code de GPT-2 et la première version de Billion Songs - un peu plus d'un mois). </p><br><h2>  Affiner les paroles des chansons </h2><br><p>  Il existe plusieurs façons d'obtenir un grand corpus de paroles de chansons.  Vous pouvez gratter l'un des sites Internet qui l'hébergent avec un analyseur HTML, le retirer de votre collection de karaoké ou des fichiers mp3.  Heureusement, quelqu'un l'a fait pour nous.  J'ai trouvé pas mal de jeux de données de paroles préparés sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Kaggle</a> .  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Chaque chanson que vous avez entendue</a> » semblait être la plus importante.  En essayant d'affiner GPT-2, j'ai rencontré deux problèmes. </p><br><h3>  Lecture CSV </h3><br><p>  Oui, vous l'avez lu correctement, l' <i>analyse CSV était un problème</i> .  Au départ, je voulais utiliser ML.NET, la nouvelle bibliothèque Microsoft pour l'apprentissage automatique, pour lire le fichier.  Cependant, après avoir parcouru la documentation et l'avoir configurée, je me suis rendu compte qu'elle ne pouvait pas traiter correctement les sauts de ligne dans les chansons.  Peu importe ce que j'ai fait, il a eu du mal après quelques centaines d'exemples et a commencé à mélanger des morceaux de paroles avec des titres et des artistes. </p><br><p>  J'ai donc dû recourir à une bibliothèque de niveau inférieur, avec laquelle j'avais auparavant une meilleure expérience: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">CsvHelper</a> .  Il fournit une interface de type <i>DataReader</i> .  Vous pouvez voir le code en l'utilisant <a href="" rel="nofollow">ici</a> .  Essentiellement, vous ouvrez un fichier, configurez un <i>CsvReader</i> , puis entrelacez l'appel à <i>.Read ()</i> avec les appels à <i>.GetField (fieldName)</i> . </p><br><h3>  Chansons courtes </h3><br><p>  La plupart des chansons sont courtes par rapport à un article moyen du jeu de données original utilisé par OpenAI.  La formation GPT-2 est plus efficace sur de gros morceaux de texte, j'ai donc dû regrouper plusieurs chansons en morceaux de texte continus pour les transmettre au formateur.  OpenAI semblait également utiliser cette technique, ils ont donc eu un jeton spécial <i>&lt;| endoftext |&gt;</i> , qui agit comme un séparateur entre les textes complets au sein d'un morceau, et sert également de jeton de début.  J'ai regroupé des chansons jusqu'à ce qu'un certain nombre de jetons soit atteint, puis j'ai renvoyé le morceau entier à inclure dans les données d'entraînement.  Le code correspondant est <a href="" rel="nofollow">ici</a> . </p><br><h3>  Configuration matérielle requise pour le réglage </h3><br><p>  Même la version plus petite de GPT-2 est grande.  Avec <b>12 Go de RAM GPU,</b> je ne pouvais <b>que définir la taille du lot à 2</b> (par exemple, former sur deux morceaux à la fois, des tailles de lot plus grandes améliorent les performances du GPU et les résultats de la formation).  3 jetterait <i>de mémoire</i> dans CUDA.  Et il a fallu une demi-journée pour régler les performances souhaitées sur mon V100.  Le bonus est que vous pouvez voir la progression, car de temps en temps le code de formation génère des échantillons générés, qui commencent sous forme de texte simple et ressemblent de plus en plus aux paroles des chansons au fur et à mesure que la formation progresse. </p><br><p>  Je ne l'ai pas essayé, mais la <b>formation sur le CPU sera probablement très lente</b> . </p><br><h3>  Modèle pré-réglé </h3><br><p>  Alors que je préparais ce billet de blog, j'ai réalisé qu'il valait mieux ne pas forcer tout le monde à passer des heures à affiner le <b>modèle des</b> <b>paroles</b> , j'ai donc <b>publié un</b> <b>pré-réglé</b> sur le <a href="" rel="nofollow">référentiel Billion Songs</a> .  Si vous essayez simplement d'exécuter Billion Songs, vous n'avez même pas besoin de le télécharger manuellement.  Le projet le fera par défaut pour vous. </p><br><div class="spoiler">  <b class="spoiler_title">mannequin semi-formé jouant HAL9000 sur moi</b> <div class="spoiler_text">  Je te jure, je suis censé t'écrire <br>  Et je te jure, je jure <br>  Tu l'as ruiné maintenant, j'espère que tu y arriveras <br>  Et j'espère que tu rêves, j'espère que tu rêves, j'espère que tu rêves J'espère que tu rêves J'espère que tu rêves <br>  À propos <br>  ce que je vais.  Je m'en vais.  Je m'en vais.  Je vais, je vais, je vais, je vais, je vais, je vais, je vais, <br>  Je vais, je vais, je vais ... </div></div><br><h1>  Créer un site Web </h1><br><p>  OK!  Cela ressemble à une chanson (en quelque sorte), faisons maintenant un site web! </p><br><p>  Comme je ne prévois pas de fournir d'API, je choisis le modèle Razor Pages par opposition à MVC.  J'ai également activé l'autorisation, car nous autoriserons les utilisateurs à voter pour les meilleures paroles et à avoir un top 10. </p><br><p>  En précipitant le MVP, je suis allé de l'avant et j'ai créé une page Web Song.cshtml, dont l'objectif pour l'instant sera d'appeler simplement GPT-2 et d'obtenir une chanson au hasard.  La mise en page de la page est triviale et se compose essentiellement de la chanson et de son titre: </p><br><pre> <code class="xml hljs">@page "/song/{id}" @model BillionSongs.Pages.SongModel<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">p</span></span></span><span class="hljs-tag">&gt;</span></span> @{ ViewData["Title"] = @Model.Song.Title ?? "Untitled"; } <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">article</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">style</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"text-align: center"</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">h3</span></span></span><span class="hljs-tag">&gt;</span></span>@(Model.Song.Title ?? "Untitled")<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">h3</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">pre</span></span></span><span class="hljs-tag">&gt;</span></span>@Model.Song.Lyrics<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">pre</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">article</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br><p>  Maintenant parce que j'aime mon code réutilisable, j'ai créé une interface, qui me permettra de brancher différents générateurs de paroles plus tard, qui seront injectés par ASP.NET dans SongModel. </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">interface</span></span> <span class="hljs-title"><span class="hljs-title">ILyricsGenerator</span></span> { <span class="hljs-function"><span class="hljs-function">Task&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">string</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GenerateLyrics</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">uint</span></span></span></span><span class="hljs-function"><span class="hljs-params"> song, CancellationToken cancellation</span></span></span><span class="hljs-function">)</span></span>; }</code> </pre><br><p>  En omettant le titre du morceau pour l'instant, tout ce que nous devons faire est d'enregistrer <i>Gpt2LyricsGenerator</i> dans le <i>démarrage, de configurer les services</i> et de l'appeler à partir du <i>SongModel</i> .  Commençons donc par le générateur.  Et la première chose que nous devons nous assurer, c'est que nous avons </p><br><h2>  Génération de paroles répétables </h2><br><p>  Parce que j'ai fait une déclaration audacieuse dans le titre, qu'il va y avoir plus d'un milliard de chansons, ne pensez même pas à les générer et à les stocker toutes.  Tout d'abord, sans métadonnées, cela prendrait à lui seul plus de 1 To d'espace disque.  Deuxièmement, il faut environ 3 minutes sur mon nettop pour générer une nouvelle chanson, il faudra donc une éternité pour les générer toutes.  Et je veux pouvoir transformer ce milliard en quintillion en passant à <i>Int64</i> si nécessaire!  Imaginez que nous pourrions faire 1 cent par chanson, sur 1 quintillion de chansons?  Ce serait plus que le PIB annuel mondial actuel! </p><br><p>  Au lieu de cela, ce que nous devons faire est de nous assurer que GPT-2 génère encore et encore le même morceau, étant donné son <i>identifiant</i> , que je spécifie dans l'itinéraire.  À cet effet, TensorFlow donne la possibilité de définir la graine de son générateur de nombres interne à tout moment via la fonction <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">tf.set_random_seed</a> comme ceci: <i>tf.set_random_seed (songNumber)</i> .  Ensuite, je voulais simplement appeler <i>Gpt2Sampler.SampleSequence</i> , pour obtenir le texte du morceau encodé, le décoder et retourner le résultat, complétant ainsi <i>Gpt2LyricsGenerator</i> . </p><br><p>  Malheureusement, au premier essai, cela n'a pas fonctionné comme prévu.  Chaque fois que je cliquais sur le bouton d'actualisation, un nouveau texte unique était renvoyé sur la page.  Après pas mal de débogage, j'ai finalement découvert que TensorFlow 1.X avait des problèmes de reproductibilité importants: de nombreuses opérations ont des états internes, qui ne sont pas affectés par <i>set_random_seed</i> et sont difficiles à atteindre pour réinitialiser. </p><br><p>  La réinitialisation des variables du modèle a permis de compenser ce problème, mais a également signifié que la session devait être recréée et que les poids du modèle devaient être rechargés à chaque appel.  Le rechargement d'une session de cette taille a provoqué une fuite de mémoire géante.  Pour éviter de rechercher sa cause dans le code source TensorFlow C ++, au lieu de générer un processus de génération de texte, j'ai décidé de générer un nouveau processus avec <i>Process.Start</i> , de générer du texte à cet <i>endroit</i> et de le lire à partir de la sortie standard.  Jusqu'à ce qu'un moyen de réinitialiser l'état du modèle dans TensorFlow soit stabilisé, ce serait la voie à suivre. </p><br><p>  Je me suis donc retrouvé avec deux classes: <a href="" rel="nofollow">Gpt2LyricsGenerator</a> , qui implémente <i>ILyricsGenerator</i> d'en haut en <i>générant</i> une nouvelle instance de BillionSongs.exe avec des paramètres de ligne de commande, qui incluent l'identifiant du morceau, et finalement instancie <a href="" rel="nofollow">Gpt2TextGenerator</a> , qui appelle en fait GPT-2 pour générer des paroles, et l'imprime simplement. </p><br><p>  Maintenant, rafraîchir la page m'a toujours donné le même texte. </p><br><h2>  Gérer 3 minutes pour générer une chanson </h2><br><p>  Quelle expérience utilisateur horrible ce serait!  Vous allez sur un site Web, cliquez sur «Créer une nouvelle chanson», et <b>absolument rien ne se passe pendant 3 (!) Minutes</b> pendant que mon nettop prend son temps pour générer les paroles des chansons que vous avez demandées. </p><br><p>  J'ai résolu ce problème à plusieurs niveaux: </p><br><h3>  Chansons prégénérantes </h3><br><p>  Comme mentionné ci-dessus, vous ne pouvez pas pré-générer toutes les chansons et les servir à partir d'une base de données.  Et vous ne pouvez pas simplement générer à la demande, car cela ralentit.  Alors, que pouvez-vous faire? </p><br><p>  C'est simple!  Étant donné que le principal moyen pour les utilisateurs de voir une nouvelle chanson est de cliquer sur le bouton «Créer au hasard», préparons à l'avance un grand nombre de chansons, les mettons dans une <i>file d'attente simultanée</i> et laissons «Make Random» faire apparaître des chansons.  Bien que le nombre de visiteurs soit faible, le serveur mettra du temps entre eux pour générer des chansons, qui seront ensuite facilement accessibles. </p><br><p>  Une autre astuce que j'ai utilisée consiste à boucler cette file d'attente plusieurs fois, afin que de nombreux utilisateurs puissent voir la même chanson prégénérée.  Il suffit de garder un équilibre entre l'utilisation de la RAM et le nombre de fois qu'un utilisateur doit cliquer sur «Créer au hasard» pour voir quelque chose qu'il a déjà vu.  J'ai simplement choisi 50 000 chansons comme un nombre raisonnable, ce qui prendrait seulement 50 Mo de RAM, tout en fournissant un assez grand nombre de clics. </p><br><p>  J'ai implémenté cette fonctionnalité dans la classe <a href="" rel="nofollow">PregeneratedSongProvider</a> : <i>IRandomSongProvider</i> (l'interface est injectée dans le code, responsable de la gestion du bouton «Make Random»). </p><br><h3>  Mise en cache </h3><br><p>  Les chansons pré-générées sont mises en cache dans la mémoire, mais j'ai également défini l'en-tête du <i>cache</i> HTTP sur <i>public</i> pour laisser le navigateur, et CDN (j'utilise CloudFlare) le mettre en cache pour éviter d'être touché par un afflux d'utilisateurs. </p><br><pre> <code class="cs hljs">[<span class="hljs-meta"><span class="hljs-meta">ResponseCache(VaryByHeader = </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"User-Agent"</span></span></span><span class="hljs-meta">, Duration = 3*60*60)</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">SongModel</span></span>: <span class="hljs-title"><span class="hljs-title">PageModel</span></span> { … }</code> </pre><br><h3>  Retourner des chansons populaires </h3><br><p>  La plupart des chansons générées par le GPT-2 affiné de cette manière sont assez ennuyeuses, sinon rudimentaires.  Pour rendre les clics sur «Make Random» plus attrayants, j'ai ajouté une probabilité de 25%, qu'au lieu d'une chanson complètement aléatoire, vous obtiendrez une chanson, qui a été précédemment votée par d'autres utilisateurs.  En plus d'augmenter l'engagement, cela augmente les chances que vous demandiez une chanson, mise en cache soit dans le CDN, soit en mémoire. </p><br><p>  Toutes les astuces ci-dessus sont câblées ensemble à l'aide de l'injection de dépendance ASP.NET dans la classe de <a href="" rel="nofollow">démarrage</a> . </p><br><h2>  Vote </h2><br><p>  La mise en œuvre du vote n'a rien de spécial.  Il y a <a href="" rel="nofollow">SongVoteCache</a> , qui maintient les comptes à jour.  Et un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">iframe hébergeant le bouton de vote</a> sur la page de la chanson, ce qui permet de mettre en cache la partie essentielle de la page - le titre et les paroles, tandis que le décompte des votes et le statut de connexion sont chargés plus tard. </p><br><h1>  Les résultats finaux </h1><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><img src="https://habrastorage.org/webt/aw/c7/wf/awc7wfzablt9gotcrrv8nsihrvu.png" alt="Échantillon de chanson généré"></a> <br></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Une version de démonstration</a> fonctionnant sur <s>mon nettop, dirigée par CloudFlare (donnez-lui du mou, son Core i3) est</s> maintenant figée et déplacée vers le niveau gratuit d'Azure App Service. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Le référentiel GitHub</a> , contenant le code source et les instructions pour exécuter le site Web et régler le modèle. </p><br><h1>  Plans pour l'avenir / exercices </h1><br><h2>  Générer des titres </h2><br><p>  GPT-2 est très facile à affiner.  On pourrait lui faire générer des titres de chansons en ajoutant ou en suffixant chaque échantillon de paroles de l'ensemble de données avec un jeton artificiel comme <i>&lt;| startoftitle |&gt;</i> , suivi du titre du même ensemble de données. </p><br><p>  Alternativement, les utilisateurs pourraient être autorisés à suggérer et / ou voter pour des titres. </p><br><h2>  Générer de la musique </h2><br><p>  À mi-chemin du développement de Billion Songs, j'ai pensé que ce serait cool de télécharger un tas de fichiers MIDI (c'est un format de musique old-school, qui est beaucoup plus proche du texte que des mp3), et de former GPT-2 sur eux pour en générer plus .  Certains de ces fichiers avaient même du texte intégré, <b>vous pouvez donc obtenir la génération de karaoké</b> . </p><br><p>  Je sais que la génération musicale de cette façon est très possible, car hier, <b>OpenAI a en fait publié une implémentation de cette idée</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">sur son blog</a> .  Mais hourra, <b>ils n'ont pas fait le karaoké!</b>  J'ai trouvé qu'il était possible de gratter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">http://www.midi-karaoke.info</a> à cet effet. </p><br><h2>  Gradient aka TensorFlow pour .NET </h2><br>  Veuillez consulter notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">blog</a> pour toute mise à jour. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr453232/">https://habr.com/ru/post/fr453232/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr453216/index.html">Systèmes de surveillance du trafic dans les réseaux VoIP. Deuxième partie - Principes d'organisation</a></li>
<li><a href="../fr453218/index.html">L'essentiel avec YaC 2019: une centaine de drones sur les routes, Yandex.Module, food, smart home</a></li>
<li><a href="../fr453220/index.html">13 erreurs de marketing par courriel à éviter pour un meilleur engagement</a></li>
<li><a href="../fr453222/index.html">SphinxSearch-meetup SuperJob</a></li>
<li><a href="../fr453228/index.html">Horloge Nixie sur indicateurs IN-18</a></li>
<li><a href="../fr453234/index.html">Rétro-ingénierie du protocole d'échange dans les équipements EOS</a></li>
<li><a href="../fr453236/index.html">Prototypage d'un jeu mobile, par où commencer et comment le faire. 2e partie</a></li>
<li><a href="../fr453238/index.html">Feux de circulation sur relais</a></li>
<li><a href="../fr453242/index.html">Aire de jeux pour les événements d'été</a></li>
<li><a href="../fr453246/index.html">ERP - Système de dégradation continue</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ä ü•å üë®üèΩ‚Äçüî¨ Das gro√üe Interview mit Martin Kleppmann: ‚ÄûDie Zukunft verteilter Datensysteme herausfinden‚Äú üê≤ ü§òüèΩ üå≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dr. Martin Kleppmann ist Forscher f√ºr verteilte Systeme an der Universit√§t von Cambridge und Autor des hochgelobten "Designing Data-Intensive Applicat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das gro√üe Interview mit Martin Kleppmann: ‚ÄûDie Zukunft verteilter Datensysteme herausfinden‚Äú</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jugru/blog/458056/"><img src="https://habrastorage.org/webt/ad/ax/dn/adaxdnyqcoiagri2sgsuibdstpy.jpeg"><br><br>  <b>Dr.</b>  <b>Martin Kleppmann</b> ist Forscher f√ºr verteilte Systeme an der Universit√§t von Cambridge und Autor des hochgelobten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Designing Data-Intensive Applications"</a> (O'Reilly Media, 2017). <br><br>  Kevin Scott, CTO bei Microsoft <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, sagte einmal</a> : ‚ÄûDieses Buch sollte f√ºr Softwareentwickler unbedingt gelesen werden m√ºssen.  "Das Entwerfen datenintensiver Anwendungen ist eine seltene Ressource, die Theorie und Praxis miteinander verbindet, um Entwicklern beim Entwerfen und Implementieren von Dateninfrastrukturen und -systemen zu helfen, kluge Entscheidungen zu treffen." <br><br>  Martins Forschungsschwerpunkte sind Collaboration-Software, CRDTs und die formale Verifizierung verteilter Algorithmen.  Zuvor war er Softwareentwickler und Unternehmer bei verschiedenen Internetunternehmen, darunter LinkedIn und Rapportive, wo er an einer gro√üen Dateninfrastruktur arbeitete. <br><br>  <b>Vadim Tsesko</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@incubos</a> ) ist ein f√ºhrender Softwareentwickler bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Odnoklassniki,</a> der im Core Platform-Team arbeitet.  Zu den wissenschaftlichen und technischen Interessen von Vadim geh√∂ren verteilte Systeme, Data Warehouses und die √úberpr√ºfung von Softwaresystemen. <br><br><h2>  Inhalt: </h2><br><ul><li>  √úbergang von der Wirtschaft zur akademischen Forschung; <br></li><li>  Diskussion √ºber "Entwerfen datenintensiver Anwendungen"; <br></li><li>  Gesunder Menschenverstand gegen k√ºnstlichen Hype und aggressives Marketing; <br></li><li>  Fallstricke des GAP-Theorems und anderer Branchenfehler; <br></li><li>  Vorteile der Dezentralisierung; <br></li><li>  Blockchains, Dat, IPFS, Filecoin, WebRTC; <br></li><li>  Neue CRDTs.  Formale √úberpr√ºfung mit Isabelle; <br></li><li>  Event-Sourcing.  Low-Level-Ansatz.  XA-Transaktionen <br></li><li>  Apache Kafka, PostgreSQL, Memcached, Redis, Elasticsearch; <br></li><li>  Wie man all diese Werkzeuge auf das wirkliche Leben anwendet; <br></li><li>  Erwartete Zielgruppe von Martins Vortr√§gen und der Hydra-Konferenz. <br></li></ul><br><a name="habracut"></a><br><hr><br><h2>  √úbergang von der Wirtschaft zur akademischen Forschung </h2><br>  <b>Vadim</b> : Die erste Frage, die ich Ihnen stellen m√∂chte, ist wirklich wichtig f√ºr mich.  Sie haben Go Test It und Rapportive gegr√ºndet und bei LinkedIn schon seit einiger Zeit Gro√üsysteme entworfen und entwickelt.  Dann haben Sie sich entschieden, vom Wirtschaftsingenieurwesen zum akademischen Bereich zu wechseln.  K√∂nnten Sie bitte die Motivation f√ºr diese Entscheidung erl√§utern?  Was hast du gewonnen und was musstest du opfern? <br><br>  <b>Martin</b> : Es war ein sehr interessanter Prozess.  Wie Sie anscheinend andeuten, wechseln nicht viele Menschen in diese Richtung.  Viele Menschen gehen von der Wissenschaft in die Industrie, aber nicht so viele zur√ºck.  Das ist verst√§ndlich, denn ich musste ziemlich viel bezahlen, um wieder in die Wissenschaft zu gehen.  Was ich an der Forschung wirklich liebe, ist die Freiheit, an Themen zu arbeiten, die ich interessant finde und die ich f√ºr wichtig halte, auch wenn diese Themen nicht innerhalb der n√§chsten 6 Monate zu einem wirtschaftlich tragf√§higen Produkt f√ºhren.  Nat√ºrlich muss sich das, was Sie bauen, in einem Unternehmen in ein Produkt verwandeln, das in der einen oder anderen Form verkauft werden kann.  Andererseits sind die Dinge, an denen ich gerade arbeite, Themen, die f√ºr die Zukunft der Entwicklung von Software und der Funktionsweise des Internets wirklich wichtig sind.  Aber wir verstehen diese Themen noch nicht gut genug, um kommerzielle Produkte zu entwickeln: Wir sind immer noch auf der Ebene, um herauszufinden, wie diese Technologien grunds√§tzlich aussehen m√ºssen.  Und da dies Grundlagenforschung ist, wurde mir klar, dass es besser ist, dies an einer Universit√§t zu tun, als es in einem Unternehmen zu versuchen, weil ich an einer Universit√§t frei bin, an Dingen zu arbeiten, die f√ºr weitere zehn Jahre m√∂glicherweise nicht wirtschaftlich werden, und das ist OK  Es ist in Ordnung, mit einem viel l√§ngeren Zeithorizont zu arbeiten, wenn Sie in der Forschung sind. <br><br><hr><br><h2>  ‚ÄûEntwerfen datenintensiver Anwendungen‚Äú </h2><br>  <b>Vadim</b> : Wir werden auf jeden Fall auf Ihre aktuellen Forschungsinteressen zur√ºckkommen.  Lassen Sie uns in der Zwischenzeit √ºber Ihr aktuelles Buch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Entwerfen datenintensiver Anwendungen</a> sprechen.  Ich bin ein gro√üer Fan Ihres Buches und ich glaube, es ist einer der besten Anleitungen zum Aufbau moderner verteilter Systeme.  Sie haben fast alle bemerkenswerten Erfolge auf dem neuesten Stand behandelt. <br><br>  <b>Martin</b> : Danke, ich bin froh, dass du es n√ºtzlich findest. <br><br>  <b>Vadim</b> : K√∂nnten Sie bitte nur f√ºr die ungl√ºcklichen Leser, die Ihr Buch noch nicht gelesen haben, einige wichtige Erfolge auf dem Gebiet der verteilten Systeme nennen? <br><br>  <b>Martin</b> : Nun, das Ziel des Buches ist nicht so sehr, eine bestimmte Technologie zu erkl√§ren.  Ziel ist es vielmehr, Ihnen einen Leitfaden f√ºr die gesamte Landschaft verschiedener Systeme zu geben, die zum Speichern und Verarbeiten von Daten verwendet werden.  Es gibt so viele verschiedene Datenbanken, Stream-Prozessoren, Stapelverarbeitungstools, alle Arten von Replikationstools usw., und es ist wirklich schwierig, sich einen √úberblick zu verschaffen.  Wenn Sie versuchen, eine bestimmte Anwendung zu erstellen, ist es sehr schwierig zu wissen, welche Datenbank Sie verwenden sollten und welche Tools f√ºr das zu l√∂sende Problem am besten geeignet sind.  Viele vorhandene Computerb√ºcher haben dieses Problem einfach nicht zufriedenstellend beantwortet.  Ich fand heraus, dass wenn Sie zum Beispiel ein Buch √ºber Cassandra lesen, es Ihnen sagen w√ºrde, warum Cassandra wunderbar ist, aber es w√ºrde Ihnen im Allgemeinen nichts √ºber Dinge erz√§hlen, f√ºr die es nicht gut passt.  Was ich in diesem Buch wirklich tun wollte, war, die Hauptfragen zu identifizieren, die Sie sich stellen m√ºssen, wenn Sie versuchen, eine Art Gro√üsystem aufzubauen.  Wenn Sie diese Fragen beantworten, k√∂nnen Sie herausfinden, welche Technologien f√ºr das jeweilige Problem, das Sie l√∂sen m√∂chten, geeignet und welche weniger geeignet sind - denn im Allgemeinen gibt es keine Technologie, die f√ºr alles perfekt ist.  Das Buch versucht Ihnen dabei zu helfen, die Vor- und Nachteile verschiedener Technologien in verschiedenen Umgebungen herauszufinden. <br><br><hr><br><h2>  Gesunder Menschenverstand gegen k√ºnstlichen Hype und aggressives Marketing </h2><br>  <b>Vadim</b> : In der Tat gibt es oft - wenn nicht immer - viele Technologien mit √ºberlappenden Funktionen, Merkmalen und Datenmodellen.  Und Sie k√∂nnen all diese Marketing-Schlagworte nicht glauben.  Sie m√ºssen die Whitepaper lesen, um die Interna zu lernen, und sogar versuchen, den Quellcode zu lesen, um zu verstehen, wie er genau funktioniert. <br><br>  <b>Martin</b> : Und ich habe festgestellt, dass Sie oft zwischen den Zeilen lesen m√ºssen, weil Ihnen die Dokumentation oft nicht wirklich sagt, wof√ºr eine bestimmte Datenbank schei√üe ist.  Die Wahrheit ist, dass jede Datenbank an irgendeiner Art von Arbeitsbelastung leidet. Die Frage ist nur, welche sie sind.  Ja, manchmal m√ºssen Sie die Bereitstellungsrichtlinien f√ºr Ops-Mitarbeiter lesen und versuchen, die tats√§chlichen Vorg√§nge auf dem System r√ºckzuentwickeln. <br><br>  <b>Vadim</b> : Glauben Sie nicht, dass der Branche das gemeinsame Vokabular oder eine Reihe von Kriterien fehlt, um verschiedene L√∂sungen f√ºr dasselbe Problem zu vergleichen?  √Ñhnliche Dinge werden mit unterschiedlichen Namen bezeichnet, einige Dinge werden weggelassen, die immer klar und explizit angegeben werden sollten, wie Transaktionsgarantien.  Was denkst du? <br><br>  <b>Martin</b> : Ja, ich denke, ein Problem unserer Branche ist, dass oft, wenn Leute √ºber ein bestimmtes Werkzeug sprechen, √ºber alles viel Hype herrscht.  Das ist verst√§ndlich, da die Tools von verschiedenen Unternehmen hergestellt werden und diese Unternehmen offensichtlich f√ºr ihre Produkte werben m√∂chten. Daher werden diese Unternehmen Menschen zu Konferenzen schicken, um dar√ºber zu sprechen, wie wunderbar ihr Produkt im Wesentlichen ist.  Es wird als Tech-Talk getarnt, aber im Grunde ist es immer noch eine Verkaufsaktivit√§t.  Als Branche k√∂nnten wir wirklich ehrlicher mit den Vor- und Nachteilen einiger Produkte umgehen.  Und ein Teil davon erfordert eine gemeinsame Terminologie, weil man sonst einfach nicht gleichberechtigt vergleichen kann.  √úber eine gemeinsame Terminologie hinaus brauchen wir jedoch Argumentationsm√∂glichkeiten f√ºr Dinge, in denen bestimmte Technologien gut oder schlecht sind. <br><br><hr><br><h2>  Fallstricke des CAP-Theorems und anderer Branchenfehler </h2><br>  <b>Vadim</b> : Meine n√§chste Frage ist ziemlich kontrovers.  K√∂nnten Sie bitte einige wichtige Fehler in der Branche nennen, auf die Sie w√§hrend Ihrer Karriere gesto√üen sind?  Vielleicht √ºberbewertete Technologien oder weit verbreitete L√∂sungen, die wir schon vor langer Zeit h√§tten loswerden sollen?  Es mag ein schlechtes Beispiel sein, aber vergleichen Sie JSON √ºber HTTP / 1.1 mit dem viel effizienteren gRPC √ºber HTTP / 2.  Oder gibt es eine alternative Sichtweise? <br><br>  <b>Martin</b> : Ich denke, in vielen F√§llen gibt es sehr gute Gr√ºnde, warum eine Technologie das eine und nicht das andere tut.  Daher z√∂gere ich sehr, Dinge als Fehler zu bezeichnen, da es sich in den meisten F√§llen um Kompromisse handelt.  In Ihrem Beispiel von JSON √ºber HTTP / 1.1 im Vergleich zu Protokollpuffern √ºber HTTP / 2 gibt es meiner Meinung nach durchaus vern√ºnftige Argumente f√ºr beide Seiten.  Wenn Sie beispielsweise Protokollpuffer verwenden m√∂chten, m√ºssen Sie Ihr Schema definieren, und ein Schema kann eine wunderbare Sache sein, da es dabei hilft, genau zu dokumentieren, welche Kommunikation stattfindet.  Einige Leute finden Schemata jedoch √§rgerlich, insbesondere wenn sie sich in einem fr√ºhen Entwicklungsstadium befinden und die Datenformate sehr h√§ufig √§ndern.  Da haben Sie es also, es geht um Kompromisse.  In einigen Situationen ist einer besser, in anderen ist der andere besser. <br><br>  In Bezug auf tats√§chliche Fehler, die ich f√ºr einfach schlecht halte, gibt es nur eine relativ kleine Anzahl von Dingen.  Eine Meinung, die ich habe, ist, dass der CAP-Satz grunds√§tzlich schlecht und einfach nicht n√ºtzlich ist.  Wenn Menschen den CAP-Satz verwenden, um Entwurfsentscheidungen zu rechtfertigen, denken sie oft, dass sie entweder falsch interpretieren, was CAP tats√§chlich sagt, oder das Offensichtliche auf eine Art und Weise angeben.  CAP als Theorem hat das Problem, dass es wirklich nur das Offensichtliche sagt.  Dar√ºber hinaus handelt es sich nur um ein sehr eng definiertes Konsistenzmodell, n√§mlich die Linearisierbarkeit, und ein sehr eng definiertes Verf√ºgbarkeitsmodell: Sie m√∂chten, dass jedes Replikat f√ºr Lese- und Schreibvorg√§nge vollst√§ndig verf√ºgbar ist, auch wenn es nicht mit anderen Replikaten kommunizieren kann.  Dies sind vern√ºnftige Definitionen, aber sie sind sehr eng gefasst, und viele Anwendungen fallen einfach nicht in den Fall, dass genau diese Definition der Konsistenz oder genau diese Definition der Verf√ºgbarkeit ben√∂tigt wird.  Und f√ºr alle Anwendungen, die eine andere Definition dieser W√∂rter verwenden, sagt Ihnen der CAP-Satz √ºberhaupt nichts.  Es ist einfach eine leere Aussage.  Ich denke, das ist ein Fehler. <br><br>  Und w√§hrend wir schimpfen, wenn Sie mich bitten, Fehler zu nennen, ist ein weiterer gro√üer Fehler, den ich in der Technologiebranche sehe, der Abbau von Kryptow√§hrungen, was ich f√ºr eine ungeheure Verschwendung von Elektrizit√§t halte.  Ich kann einfach nicht verstehen, warum die Leute das f√ºr eine gute Idee halten. <br><br>  <b>Vadim</b> : In Bezug auf das CAP-Theorem sind viele Speichertechnologien tats√§chlich abstimmbar, beispielsweise in Bezug auf AP oder CP.  Sie k√∂nnen den Modus ausw√§hlen, in dem sie arbeiten. <br><br>  <b>Martin</b> : Ja.  Dar√ºber hinaus gibt es viele Technologien, die nach der strengen Definition des GAP-Theorems weder konsistent noch verf√ºgbar sind.  Sie sind buchst√§blich nur P!  Nicht CP, nicht CA, nicht AP, nur P. Niemand sagt das, denn das w√ºrde schlecht aussehen, aber ehrlich gesagt k√∂nnte dies eine durchaus vern√ºnftige Designentscheidung sein.  Es gibt viele Systeme, f√ºr die das eigentlich v√∂llig in Ordnung ist.  Dies ist tats√§chlich einer der Gr√ºnde, warum ich denke, dass CAP eine so wenig hilfreiche Art ist, √ºber Dinge zu sprechen: weil es einen gro√üen Teil des Designraums gibt, den es einfach nicht erfasst, wo es absolut vern√ºnftige gute Designs f√ºr Software gibt, die es gibt erlaubt dir einfach nicht dar√ºber zu reden. <br><hr><br><h2>  Vorteile der Dezentralisierung </h2><br>  <b>Vadim</b> : Wenn Sie heute √ºber datenintensive Anwendungen sprechen, welche anderen gro√üen Herausforderungen, ungel√∂sten Probleme oder aktuellen Forschungsthemen k√∂nnen Sie nennen?  Soweit ich wei√ü, sind Sie ein wichtiger Bef√ºrworter der dezentralen Berechnung und Speicherung. <br><br>  <b>Martin</b> : Ja.  Eine der Thesen hinter meiner Forschung ist, dass wir uns im Moment zu sehr auf Server und Zentralisierung verlassen.  Wenn Sie dar√ºber nachdenken, wie das Internet urspr√ºnglich zu dem Zeitpunkt entwickelt wurde, als es sich aus ARPANET entwickelte, war es als sehr belastbares Netzwerk gedacht, in dem Pakete √ºber mehrere verschiedene Routen gesendet werden konnten und dennoch zum Ziel gelangen.  Und wenn eine Atombombe eine bestimmte amerikanische Stadt treffen w√ºrde, w√ºrde der Rest des Netzwerks immer noch funktionieren, da er nur die ausgefallenen Teile des Systems umrunden w√ºrde.  Dies war ein Entwurf des Kalten Krieges. <br><br>  Und dann haben wir beschlossen, alles in die Cloud zu stellen, und jetzt muss im Grunde alles √ºber eines der AWS-Rechenzentren wie us-east-1 irgendwo in Virginia gehen.  Wir haben dieses Ideal, dezentral verschiedene Teile des Netzwerks dezentral nutzen zu k√∂nnen, aufgehoben und diese Server eingebaut, auf die sich alles st√ºtzt, und jetzt ist es extrem zentralisiert.  Ich bin also an Dezentralisierung interessiert, in dem Sinne, dass ein Teil der Macht und Kontrolle √ºber Daten von diesen Servern weg und zur√ºck zu den Endbenutzern verlagert wird. <br><br>  Eine Sache, die ich in diesem Zusammenhang hinzuf√ºgen m√∂chte, ist, dass viele Leute, die √ºber Dezentralisierung sprechen, √ºber Dinge wie Kryptow√§hrungen sprechen, weil sie auch eine Form der Dezentralisierung versuchen, bei der die Kontrolle von einer zentralen Beh√∂rde wie einer Bank in ein Netzwerk verlagert wird von kooperierenden Knoten.  Aber das ist nicht wirklich die Art von Dezentralisierung, die mich interessiert: Ich finde, dass diese Kryptow√§hrungen tats√§chlich immer noch extrem zentralisiert sind, in dem Sinne, dass Sie eine Bitcoin-Transaktion im Bitcoin-Netzwerk durchf√ºhren m√ºssen - Sie m√ºssen das Netzwerk von Bitcoin verwenden, damit alles in diesem bestimmten Netzwerk zentralisiert ist.  Die Art und Weise, wie es aufgebaut ist, ist dezentralisiert in dem Sinne, dass es keinen einzigen Steuerknoten hat, aber das Netzwerk als Ganzes ist extrem zentralisiert, da jede Transaktion, die Sie durchf√ºhren m√ºssen, √ºber dieses Netzwerk erfolgen muss.  Sie k√∂nnen es nicht anders machen.  Ich denke, dass es immer noch eine Form der Zentralisierung ist. <br><br>  Im Fall einer Kryptow√§hrung kann diese Zentralisierung unvermeidlich sein, da Sie beispielsweise doppelte Ausgaben vermeiden m√ºssen. Dies ist ohne ein Netzwerk schwierig, das einen Konsens dar√ºber erzielt, welche Transaktionen genau stattgefunden haben und welche nicht.  Und genau das macht das Bitcoin-Netzwerk.  Es gibt jedoch viele Anwendungen, f√ºr die keine Blockchain erforderlich ist, die tats√§chlich mit einem viel flexibleren Datenmodell umgehen kann, das durch das System flie√üt.  Und das ist die Art von dezentralem System, die mich am meisten interessiert. <br><br>  <b>Vadim</b> : K√∂nnten Sie bitte vielversprechende oder unterbewertete Technologien im Bereich dezentraler Systeme au√üer Blockchain nennen?  Ich benutze IPFS seit einer Weile. <br><br>  <b>Martin</b> : F√ºr IPFS habe ich mich ein bisschen damit befasst, obwohl ich es selbst nicht benutzt habe.  Wir haben einige Arbeiten mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dat-</a> Projekt durchgef√ºhrt, das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IPFS</a> in dem Sinne √§hnlich ist, dass es auch eine dezentrale Speichertechnologie ist.  Der Unterschied besteht darin, dass an IPFS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Filecoin</a> , eine Kryptow√§hrung, angeh√§ngt ist, um die Speicherressourcen zu bezahlen, w√§hrend an Dat keine Blockchain angeh√§ngt ist. Es handelt sich lediglich um eine M√∂glichkeit, Daten auf mehreren Computern auf P2P-Weise zu replizieren. <br><br>  F√ºr das Projekt, an dem ich gearbeitet habe, war Dat eine gute L√∂sung, da wir eine Collaboration-Software erstellen wollten, in der mehrere verschiedene Benutzer jeweils ein Dokument oder eine Datenbank bearbeiten konnten und alle √Ñnderungen an diesen Daten an jeden gesendet wurden sonst wer braucht eine Kopie dieser Daten.  Wir k√∂nnen Dat verwenden, um diese Replikation auf P2P-Weise durchzuf√ºhren, und Dat k√ºmmert sich um alle Dinge auf Netzwerkebene, wie z. B. NAT-Traversal und Durchlaufen von Firewalls - es ist ein ziemlich schwieriges Problem, nur die Pakete von einem Ende zum anderen zu bringen .  Dar√ºber hinaus haben wir mithilfe von CRDTs eine Ebene erstellt, mit der mehrere Personen ein Dokument oder einen Datensatz bearbeiten und diese √Ñnderungen auf effiziente Weise austauschen k√∂nnen.  Ich denke, Sie k√∂nnen diese Art von Dingen wahrscheinlich auch auf IPFS aufbauen: Sie k√∂nnen wahrscheinlich den Filecoin-Aspekt ignorieren und nur den P2P-Replikationsaspekt verwenden, und es wird wahrscheinlich genauso gut funktionieren. <br><br>  <b>Vadim</b> : Sicher, obwohl die Verwendung von IPFS zu einer geringeren Reaktionsf√§higkeit f√ºhren kann, da das zugrunde liegende WebRTC-Dat P2P-Knoten direkt verbindet und IPFS wie eine verteilte Hash-Tabelle funktioniert. <br><br>  <b>Martin</b> : Nun, WebRTC befindet sich auf einer anderen Ebene des Stacks, da es haupts√§chlich dazu gedacht ist, zwei Personen miteinander zu verbinden, die m√∂glicherweise einen Videoanruf haben.  Tats√§chlich verwendet die Software, die wir derzeit f√ºr dieses Interview verwenden, m√∂glicherweise WebRTC.  Und WebRTC bietet Ihnen einen Datenkanal, √ºber den Sie beliebige Bin√§rdaten senden k√∂nnen. Dar√ºber hinaus ist der Aufbau eines vollst√§ndigen Replikationssystems jedoch noch ein ziemlicher Arbeitsaufwand.  Und das tun Dat oder IPFS bereits. <br><br>  Sie haben die Reaktionsf√§higkeit erw√§hnt - das ist sicherlich eine Sache, √ºber die Sie nachdenken sollten.  Angenommen, Sie m√∂chten die n√§chsten Google Text &amp; Tabellen dezentral erstellen.  Bei Google Text &amp; Tabellen ist die Einheit der √Ñnderungen, die Sie vornehmen, ein einziger Tastendruck.  Jeder einzelne Buchstabe, den Sie auf Ihrer Tastatur eingeben, wird m√∂glicherweise in Echtzeit an Ihre Mitarbeiter gesendet. Dies ist im Hinblick auf eine schnelle Zusammenarbeit in Echtzeit hervorragend.  Es bedeutet aber auch, dass sich beim Schreiben eines gro√üen Dokuments m√∂glicherweise Hunderttausende dieser Einzelzeichenbearbeitungen ansammeln, und viele dieser Technologien sind derzeit nicht sehr gut darin, diese Art von Bearbeitungsdaten zu komprimieren.  Sie k√∂nnen alle √Ñnderungen beibehalten, die Sie jemals an Ihrem Dokument vorgenommen haben, aber selbst wenn Sie nur hundert Bytes f√ºr jeden einzelnen Tastendruck senden und ein etwas gr√∂√üeres Dokument mit beispielsweise 100.000 Tastenanschl√§gen schreiben, sind Sie jetzt pl√∂tzlich Sie haben 10 MB Daten f√ºr ein Dokument, das normalerweise nur einige zehn Kilobyte gro√ü ist.  Wir haben also diesen enormen Aufwand f√ºr die Datenmenge, die gesendet werden muss, es sei denn, wir k√∂nnen √Ñnderungen kl√ºger komprimieren und verpacken. <br><br>  Anstatt jemandem die vollst√§ndige Liste aller Zeichen zu senden, die jemals eingegeben wurden, senden wir m√∂glicherweise nur den aktuellen Status des Dokuments und anschlie√üend alle Aktualisierungen, die seitdem aufgetreten sind.  Viele dieser Peer-to-Peer-Systeme haben jedoch noch keine M√∂glichkeit, diese Status-Snapshots so zu erstellen, dass sie effizient genug sind, um sie f√ºr Google Text &amp; Tabellen zu verwenden.  Dies ist eigentlich ein Bereich, an dem ich aktiv arbeite und versuche, bessere Algorithmen f√ºr die Synchronisierung verschiedener Benutzer f√ºr so etwas wie ein Textdokument zu finden, in dem wir nicht jeden einzelnen Tastendruck beibehalten m√∂chten, da dies zu teuer w√§re und wir m√∂chten um die Netzwerkbandbreite effizienter zu nutzen. <br><br><hr><br><h2>  Neue CRDTs.  Formale √úberpr√ºfung mit Isabelle </h2><br>  <b>Vadim</b> : Haben Sie es geschafft, diese Tastendruckdaten erheblich zu komprimieren?  Haben Sie neue CRDTs oder √§hnliches erfunden? <br><br>  <b>Martin</b> : Ja.  Bisher haben wir nur Prototypen daf√ºr, es ist noch nicht vollst√§ndig implementiert, und wir m√ºssen noch einige Experimente durchf√ºhren, um zu messen, wie effizient es tats√§chlich in der Praxis ist.  Wir haben jedoch einige Komprimierungsschemata entwickelt, die sehr vielversprechend aussehen.  In meinem Prototyp habe ich ihn von ungef√§hr 100 Bytes pro Bearbeitung auf ungef√§hr 1,7 Bytes Overhead pro Bearbeitung reduziert.  Und das ist nat√ºrlich viel vern√ºnftiger.  Aber wie gesagt, diese Experimente dauern noch an und die Anzahl k√∂nnte sich noch leicht √§ndern.  Aber ich denke, das Fazit ist, dass es dort noch viel Raum f√ºr Optimierungen gibt, so dass wir es noch viel besser machen k√∂nnen. <br><br>  <b>Vadim</b> : Also darum geht es in Ihrem Vortrag auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hydra-Konferenz</a> , habe ich recht? <br><br>  <b>Martin</b> : Ja genau.  Ich werde eine kurze Einf√ºhrung in den Bereich CRDTs, kollaborative Software und einige der Probleme geben, die in diesem Zusammenhang auftreten.  Dann werde ich einige der Forschungen beschreiben, die wir in diesem Bereich durchgef√ºhrt haben.  Es hat ziemlich viel Spa√ü gemacht, weil die Forschung, die wir durchgef√ºhrt haben, eine ganze Reihe verschiedener Anliegen betraf.  Auf der sehr angewandten Seite haben wir eine JavaScript-Implementierung dieser Algorithmen, und wir verwenden diese, um echte Softwareteile zu erstellen, und versuchen, diese Software selbst zu verwenden, um zu sehen, wie sie sich verh√§lt.  Am anderen Ende des Spektrums haben wir mit formalen Methoden gearbeitet, um die Richtigkeit dieser Algorithmen zu beweisen, da einige dieser Algorithmen sehr subtil sind und wir sehr sicher sein m√∂chten, dass die von uns hergestellten Systeme tats√§chlich korrekt sind, d. H. Sie erreichen immer einen konsistenten Zustand.  In der Vergangenheit gab es viele Algorithmen, die dies tats√§chlich nicht geschafft haben, was einfach falsch war, das hei√üt, in bestimmten Randf√§llen blieben sie dauerhaft inkonsistent.  Um diese Probleme zu vermeiden, die Algorithmen in der Vergangenheit hatten, haben wir formale Methoden verwendet, um die Richtigkeit unserer Algorithmen zu beweisen. <br><br>  <b>Vadim</b> : Wow.  Verwenden Sie wirklich Theorembeweiser wie Coq oder Isabelle oder irgendetwas anderes? <br><br>  <b>Martin</b> : Genau daf√ºr haben wir Isabelle benutzt. <br><br><blockquote>  Sie k√∂nnen an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Martins Vortrag</a> "Korrektheitsnachweise verteilter Systeme mit Isabelle" auf der The Strange Loop-Konferenz im September teilnehmen. </blockquote><br>  <b>Vadim</b> : H√∂rt sich toll an!  Werden diese Beweise ver√∂ffentlicht? <br><br>  <b>Martin</b> : Ja, unsere ersten Beweise sind bereits √∂ffentlich.  Wir haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das vor</a> anderthalb Jahren ver√∂ffentlicht: Es war ein Framework zur √úberpr√ºfung von CRDTs, und wir haben drei bestimmte CRDTs innerhalb dieses Frameworks √ºberpr√ºft, von denen das wichtigste RGA ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Replicated Growable Array</a> ) war, ein CRDT f√ºr die kollaborative Textbearbeitung.  Es ist zwar nicht sehr kompliziert, aber ein ziemlich subtiler Algorithmus, und daher ist es ein guter Fall, in dem Beweise ben√∂tigt werden, da es nicht offensichtlich ist, dass es wirklich richtig ist.  Und so gibt uns der Beweis die zus√§tzliche Gewissheit, dass es wirklich richtig ist.  Unsere fr√ºhere Arbeit dort bestand darin, einige vorhandene CRDTs zu verifizieren, und unsere j√ºngste Arbeit in diesem Bereich befasst sich mit unseren eigenen CRDTs f√ºr neue Datenmodelle, die wir entwickelt haben, und dem Nachweis, dass unsere eigenen CRDTs korrekt sind. <br><br>  <b>Vadim</b> : Wie viel gr√∂√üer ist der Beweis im Vergleich zur Beschreibung des Algorithmus?  Weil es manchmal ein Problem sein kann. <br><br>  <b>Martin</b> : Ja, das ist ein Problem - die Beweise sind oft viel Arbeit.  Ich denke in unserem neuesten Beispiel ... Lassen Sie mich einen kurzen Blick auf den Code werfen.  Die Beschreibung des Algorithmus und der Datenstrukturen umfasst etwa 60 Codezeilen.  Es ist also ein ziemlich kleiner Algorithmus.  Der Beweis ist √ºber 800 Zeilen.  Wir haben also ein Verh√§ltnis von ungef√§hr 12: 1 zwischen dem Proof und dem Code.  Und das ist leider ganz typisch.  Der Beweis ist eine gro√üe Menge zus√§tzlicher Arbeit.  Auf der anderen Seite haben wir, sobald wir den Beweis haben, sehr starke Gewissheit √ºber die Richtigkeit des Algorithmus gewonnen.  Dar√ºber hinaus haben wir als Menschen den Algorithmus viel besser verstanden.  Oft stelle ich fest, dass wir durch den Versuch, es zu formalisieren, das, was wir zu formalisieren versuchen, viel besser verstehen als zuvor.  Und das an sich ist tats√§chlich ein n√ºtzliches Ergebnis dieser Arbeit: Neben dem Beweis selbst gewinnen wir ein tieferes Verst√§ndnis, und das ist oft sehr hilfreich, um bessere Implementierungen zu schaffen. <br><br>  <b>Vadim</b> : K√∂nnten Sie bitte die Zielgruppe Ihres Vortrags beschreiben, wie hardcore wird es sein?  Was ist das vorl√§ufige Wissen, das Sie vom Publikum erwarten? <br><br>  <b>Martin</b> : Ich mag es, meine Vortr√§ge mit m√∂glichst wenig Vorkenntnissen zug√§nglich zu machen, und ich versuche, alle auf das gleiche Niveau zu bringen.  Ich decke viel Material ab, aber ich beginne bei einer niedrigen Basis.  Ich w√ºrde erwarten, dass die Leute √ºber allgemeine Erfahrungen mit verteilten Systemen verf√ºgen: Wie k√∂nnen Sie Daten √ºber ein Netzwerk mit TCP senden oder vielleicht eine ungef√§hre Vorstellung davon, wie Git funktioniert, was f√ºr diese Dinge ein recht gutes Modell ist.  Aber das ist wirklich alles, was Sie brauchen.  Dann ist es eigentlich nicht allzu schwierig, die Arbeit zu verstehen, die wir dar√ºber hinaus geleistet haben.  Ich erkl√§re alles anhand eines Beispiels und verwende Bilder, um alles zu veranschaulichen.  Hoffentlich kann jeder mitmachen. <br><br><hr><br><h2>  Event-Sourcing.  Low-Level-Ansatz.  XA-Transaktionen </h2><br>  <b>Vadim</b> : H√∂rt sich wirklich toll an.  Eigentlich haben wir etwas Zeit und ich m√∂chte einen Ihrer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">letzten Artikel</a> √ºber die Online-Ereignisverarbeitung diskutieren.  Sie sind ein gro√üartiger Bef√ºrworter der Idee des Event-Sourcing. Ist das richtig? <br><br>  <b>Martin</b> : Ja sicher. <br><br>  <b>Vadim</b> : Heutzutage gewinnt dieser Ansatz an Dynamik, und um alle Vorteile eines global geordneten Betriebsprotokolls zu nutzen, versuchen viele Ingenieure, ihn √ºberall einzusetzen.  K√∂nnten Sie bitte einige F√§lle beschreiben, in denen Event-Sourcing nicht die beste Option ist?  Nur um seinen Missbrauch und m√∂gliche Entt√§uschungen mit dem Ansatz selbst zu verhindern. <br><br>  <b>Martin</b> : Es gibt zwei verschiedene Schichten des Stapels, √ºber die wir zuerst sprechen m√ºssen.  Event Sourcing, wie von Greg Young und einigen anderen vorgeschlagen, ist als Mechanismus f√ºr die Datenmodellierung gedacht, dh wenn Sie ein Datenbankschema haben und die Kontrolle dar√ºber verlieren, weil es so viele verschiedene Tabellen gibt und diese Wenn alle Ereignisse durch unterschiedliche Transaktionen ge√§ndert werden, ist Event Sourcing eine M√∂glichkeit, dieses Datenmodell klarer zu gestalten, da die Ereignisse sehr direkt ausdr√ºcken k√∂nnen, was auf Unternehmensebene geschieht.  Welche Aktion hat der Benutzer ausgef√ºhrt?  Die Konsequenzen dieser Aktion k√∂nnen dann darin bestehen, dass verschiedene Tabellen usw. aktualisiert werden. Mit Event Sourcing trennen Sie die Aktion (das Ereignis) effektiv von ihren Auswirkungen, die irgendwo stromabw√§rts auftreten. <br><br>  Ich bin aus einem etwas anderen Blickwinkel in diesen Bereich gekommen, was eine untergeordnete Sichtweise der Verwendung von Systemen wie Kafka zum Erstellen hochskalierbarer Systeme darstellt.  Diese Ansicht ist in dem Sinne √§hnlich, dass Sie, wenn Sie etwas wie Kafka verwenden, Ereignisse verwenden, aber dies bedeutet nicht, dass Sie unbedingt Ereignisbeschaffung verwenden.  Umgekehrt m√ºssen Sie Kafka nicht verwenden, um Event-Sourcing durchzuf√ºhren.  Sie k√∂nnen Event-Sourcing in einer regul√§ren Datenbank durchf√ºhren oder eine spezielle Datenbank verwenden, die speziell f√ºr Event-Sourcing entwickelt wurde.  Diese beiden Ideen sind also √§hnlich, aber keine erfordert die andere, sie haben nur eine gewisse √úberlappung. <br><br>  Der Grund f√ºr die Verwendung eines Systems wie Kafka ist haupts√§chlich das Argument der Skalierbarkeit: In diesem Fall gehen einfach so viele Daten ein, dass Sie sie nicht realistisch in einer Datenbank mit einem einzelnen Knoten verarbeiten k√∂nnen, sodass Sie sie in einige partitionieren m√ºssen Wenn Sie ein Ereignisprotokoll wie Kafka verwenden, k√∂nnen Sie diese Arbeit auf mehrere Computer verteilen.  Es bietet eine gute, prinzipielle M√∂glichkeit zur Skalierung von Systemen.  Dies ist besonders n√ºtzlich, wenn Sie mehrere verschiedene Speichersysteme integrieren m√∂chten.  Wenn Sie beispielsweise nicht nur Ihre relationale Datenbank aktualisieren m√∂chten, sondern beispielsweise auch einen Volltextsuchindex wie Elasticsearch oder ein Caching-System wie Memcached oder Redis oder √§hnliches, und Sie m√∂chten, dass ein Ereignis eine hat Wenn Sie den Effekt auf all diese verschiedenen Systeme aktualisieren, ist so etwas wie Kafka sehr n√ºtzlich. <br><br>  In Bezug auf die von Ihnen gestellte Frage (in welchen Situationen w√ºrde ich diesen Event-Sourcing- oder Event-Log-Ansatz nicht verwenden) - Ich denke, es ist schwierig, genau zu sagen, aber als Faustregel w√ºrde ich sagen: Verwenden Sie das Einfachste .  Das hei√üt, was der Dom√§ne, die Sie implementieren m√∂chten, am n√§chsten kommt.  Wenn Sie also versuchen, eine relationale Datenbank, in die Sie nur einige Zeilen einf√ºgen und aktualisieren und l√∂schen, sehr gut zuzuordnen, verwenden Sie einfach eine relationale Datenbank und f√ºgen Sie einige Zeilen ein und aktualisieren und l√∂schen Sie sie.  Es ist nichts Falsches daran, relationale Datenbanken so zu verwenden, wie sie sind.  Sie haben lange Zeit gut f√ºr uns gearbeitet und tun dies auch weiterhin.  Wenn Sie sich jedoch in einer Situation befinden, in der Sie wirklich Schwierigkeiten haben, diese Art von Datenbank zu verwenden, beispielsweise weil die Komplexit√§t des Datenmodells au√üer Kontrolle ger√§t, ist es sinnvoll, auf so etwas wie eine Ereignisbeschaffung umzusteigen Ansatz. <br><br>  Wenn Sie auf der unteren Ebene (Skalierbarkeit) die Gr√∂√üe Ihrer Daten so festlegen, dass Sie sie einfach auf einem einzelnen Computer in PostgreSQL einf√ºgen k√∂nnen, ist dies wahrscheinlich in Ordnung. Verwenden Sie PostgreSQL einfach auf einem einzelnen Computer.  Wenn Sie jedoch an einem Punkt angelangt sind, an dem eine einzelne Maschine Ihre Last nicht mehr bew√§ltigen kann, m√ºssen Sie √ºber ein gro√ües System skalieren. Dann ist es sinnvoll, sich mit verteilten Systemen wie Kafka zu befassen.  Ich denke, das allgemeine Prinzip hier lautet: Verwenden Sie das, was f√ºr die jeweilige Aufgabe, die Sie l√∂sen m√∂chten, am einfachsten ist. <br><br>  <b>Vadim</b> : Es ist wirklich ein guter Rat.  W√§hrend sich Ihr System weiterentwickelt, k√∂nnen Sie die Entwicklungsrichtung, alle Abfragen, Muster und Datenfl√ºsse nicht genau vorhersagen. <br><br>  <b>Martin</b> : Genau und f√ºr solche Situationen sind relationale Datenbanken erstaunlich, weil sie sehr flexibel sind, insbesondere wenn Sie die JSON-Unterst√ºtzung einbeziehen, die sie jetzt haben.  PostgreSQL unterst√ºtzt JSON jetzt ziemlich gut.  Sie k√∂nnen einfach einen neuen Index hinzuf√ºgen, wenn Sie auf andere Weise abfragen m√∂chten.  Sie k√∂nnen einfach das Schema √§ndern und mit den Daten in einer anderen Struktur weiterarbeiten.  Wenn also die Gr√∂√üe des Datensatzes nicht zu gro√ü und die Komplexit√§t nicht zu gro√ü ist, funktionieren relationale Datenbanken gut und bieten ein hohes Ma√ü an Flexibilit√§t. <br><br>  <b>Vadim</b> : Lassen Sie uns ein bisschen mehr √ºber Event Sourcing sprechen.  Sie haben ein interessantes Beispiel erw√§hnt, bei dem mehrere Verbraucher Ereignisse aus einer Warteschlange basierend auf Kafka oder √§hnlichem konsumieren.  Stellen Sie sich vor, dass neue Dokumente ver√∂ffentlicht werden und mehrere Systeme Ereignisse verbrauchen: ein auf Elasticsearch basierendes Suchsystem, das die Dokumente durchsuchbar macht, ein Caching-System, das sie in einen auf Memcached basierenden Schl√ºsselwert-Cache legt, und ein relationales Datenbanksystem, das einige aktualisiert Tabellen entsprechend.  Ein Dokument kann ein Autoverkaufsangebot oder eine Immobilienanzeige sein.  Alle diese verbrauchenden Systeme arbeiten gleichzeitig und gleichzeitig. <br><br>  <b>Martin</b> : Ihre Frage ist also, wie Sie mit der Tatsache umgehen, dass bei mehreren Verbrauchern m√∂glicherweise einige aktualisiert wurden, die anderen jedoch noch kein Update gesehen haben und immer noch leicht zur√ºckbleiben. <br><br>  <b>Vadim</b> : Ja genau.  Ein Benutzer kommt auf Ihre Website, gibt eine Suchanfrage ein, erh√§lt einige Suchergebnisse und klickt auf einen Link.  Sie erh√§lt jedoch den 404-HTTP-Statuscode, da die Datenbank keine solche Entit√§t enth√§lt, die das Dokument noch nicht verwenden und beibehalten konnte. <br><br>  <b>Martin</b> : Ja, das ist eigentlich eine Herausforderung.  Im Idealfall m√∂chten Sie das, was wir als "kausale Konsistenz" zwischen diesen verschiedenen Speichersystemen bezeichnen w√ºrden.  Wenn ein System einige Daten enth√§lt, von denen Sie abh√§ngig sind, enthalten die anderen Systeme, die Sie betrachten, auch diese Abh√§ngigkeiten.  Leider ist es sehr schwierig, diese Art von kausaler Konsistenz √ºber verschiedene Speichertechnologien hinweg zusammenzustellen, und dies ist nicht wirklich die Schuld der Ereignisbeschaffung, da Sie unabh√§ngig davon, welchen Ansatz oder welches System Sie verwenden, um die Aktualisierungen an die verschiedenen Systeme zu senden kann immer zu Problemen mit der Parallelit√§t f√ºhren. <br><br> In your example of writing data to both Memcached and Elasticsearch, even if you try to do the writes to the two systems simultaneously you might have a little bit of network delay, which means that they arrive at slightly different times on those different systems, and get processed with slightly different timing. And so somebody who's reading across those two systems may see an inconsistent state. Now, there are some research projects that are at least working towards achieving that kind of causal consistency, but it's still difficult if you just want to use something like Elasticsearch or Memcached or so off the shelf. <br><br> A good solution here would be that you get presented, conceptually, with a consistent point-in-time snapshot across both the search index and the cache and the database. If you're working just within a relational database, you get something called snapshot isolation, and the point of snapshot isolation is that if you're reading from the database, it looks as though you've got your own private copy of the entire database. Anything you look at in the database, any data you query will be the state as of that point in time, according to the snapshot. So even if the data has afterwards been changed by another transaction, you will actually see the older data, because that older data forms part of a consistent snapshot. <br><br> And so now, in the case where you've got Elasticsearch and Memcached, really what you would ideally want is a consistent snapshot across these two systems. But unfortunately, neither Memcached nor Redis nor Elasticsearch have an efficient mechanism for making those kinds of snapshots that can be coordinated with different storage systems. Each storage system just thinks for itself and typically presents you the latest value of every key, and it doesn't have this facility for looking back and presenting a slightly older version of the data, because the most recent version of the data is not yet consistent. <br><br> I don't really have a good answer for what the solution would look like. I fear that the solution would require code changes to any of the storage systems that participate in this kind of thing. So it will require changes to Elasticsearch and to Redis and to Memcached and any other systems. And they would have to add some kind of mechanism for point-in-time snapshots that is cheap enough that you can be using it all the time, because you might be wanting the snapshot several times per second ‚Äî it's not just a once-a-day snapshot, it's very fine-grained. And at the moment the underlying systems are not there in terms of being able to do these kinds of snapshots across different storage systems. It's a really interesting research topic. I'm hoping that somebody will work on it, but I haven't seen any really convincing answers to that problem yet so far. <br><br> <b>Vadim</b> : Yeah, we need some kind of shared <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Multiversion Concurrency Control</a> . <br><br> <b>Martin</b> : Exactly, like the distributed transaction systems. XA distributed transactions will get you some of the way there, but unfortunately XA, as it stands, is not really very well suited because it only works if you're using locking-based concurrency control. This means that if you read some data, you have to take a lock on it so that nobody can modify that data while you have that lock. And that kind of locking-based concurrency control has terrible performance, so no system actually uses that in practice nowadays. But if you don't have that locking then you don't get the necessary isolation behavior in a system like XA distributed transactions. So maybe what we need is a new protocol for distributed transactions that allows snapshot isolation as the isolation mechanism across different systems. But I don't think I've seen anything that implements that yet. <br><br> <b>Vadim</b> : Yes, I hope somebody is working on it. <br><br> <b>Martin</b> : Yes, it would be really important. Also in the context of microservices, for example: the way that people promote that you should build microservices is that each microservice has its own storage, its own database, and you don't have one service directly accessing the database of another service, because that would break the encapsulation of the service. Therefore, each service just manages its own data. <br><br> For example, you have a service for managing users, and it has a database for the users, and everyone else who wants to find out something about users has to go through the user service. From the point of view of encapsulation that is nice: you're hiding details of the database schema from the other services for example. <br><br> But from the point of view of consistency across different services ‚Äî well, you've got a huge problem now, because of exactly the thing we were discussing: we might have data in two different services that depends upon each other in some way, and you could easily end up with one service being slightly ahead of or slightly behind the other in terms of timing, and then you could end up with someone who reads across different services, getting inconsistent results. And I don't think anybody building microservices currently has an answer to that problem. <br><br> <b>Vadim</b> : It is somewhat similar to workflows in our society and government, which are inherently asynchronous and there are no guarantees of delivery. You can get your passport number, then you can change it, and you need to prove that you changed it, and that you are the same person. <br><br> <b>Martin</b> : Yes, absolutely. As humans we have ways of dealing with this, for example, we might know that oh, sometimes that database is a bit outdated, I'll just check back tomorrow. And then tomorrow it's fine. But if it's software that we're building, we have to program all that kind of handling into the software. The software can't think for itself. <br><br> <b>Vadim</b> : Definitely, at least not yet. I have another question about the advantages of event sourcing. Event sourcing gives you the ability to stop processing events in case of a bug, and resume consuming events having deployed the fix, so that the system is always consistent. It's a really strong and useful property, but it might not be acceptable in some cases like banking where you can imagine a system that continues to accept financial transactions, but the balances are stale due to suspended consumers waiting for a bugfix from developers. What might be a workaround in such cases? <br><br> <b>Martin</b> : I think it's a bit unlikely to stop the consumer, deploying the fix and then restart it, because, as you say, the system has got to continue running, you can't just stop it. I think what is more likely to happen is: if you discover a bug, you let the system continue running, but while it continues running with the buggy code, you produce another version of the code that is fixed, you deploy that fixed version separately and run the two in parallel for a while. In the fixed version of the code you might go back in history and reprocess all of the input events that have happened since the buggy code was deployed, and maybe write the results to a different database. Once you've caught up again you've got two versions of the database, which are both based on the same event inputs, but one of the two processed events with the buggy code and the other processed the events with the correct code. At that point you can do the switchover, and now everyone who reads the data is going to read the correct version instead of the buggy version, and you can shut down the buggy version. That way you never need to stop the system from running, everything keeps working all the time. And you can take the time to fix the bug, and you can recover from the bug because you can reprocess those input events again. <br><br> <b>Vadim</b> : Indeed, it's a really good option if the storage systems are under your control, and we are not talking about side effects applied to external systems. <br><br> <b>Martin</b> : Yes, you're right, once we send the data to external systems it gets more difficult because you might not be able to easily correct it. But this is again something you find in financial accounting, for example. In a company, you might have quarterly accounts. At the end of the quarter, everything gets frozen, and all of the revenue and profit calculations are based on the numbers for that quarter. But then it can happen that actually, some delayed transaction came in, because somebody forgot to file a receipt in time. The transaction comes in after the calculations for the quarter have been finalized, but it still belongs in that earlier quarter. <br><br> What accountants do in this case is that in the next quarter, they produce corrections to the previous quarter's accounts. And typically those corrections will be a small number, and that's no problem because it doesn't change the big picture. But at the same time, everything is still accounted for correctly. At the human level of these accounting systems that has been the case ever since accounting systems were invented, centuries ago. It's always been the case that some late transactions would come in and change the result for some number that you thought was final, but actually, it wasn't because the correction could still come in. And so we just build the system with the mechanism to perform such corrections. I think we can learn from accounting systems and apply similar ideas to many other types of data storage systems, and just accept the fact that sometimes they are mostly correct but not 100% correct and the correction might come in later. <br><br> <b>Vadim</b> : It's a different point of view to building systems. <br><br> <b>Martin</b> : It is a bit of a new way of thinking, yes. It can be disorienting when you come across it at first. But I don't think there's really a way round it, because this impreciseness is inherent in the fact that we do not know the entire state of the world ‚Äî it is fundamental to the way distributed systems work. We can't just hide it, we can't pretend that it doesn't happen, because that imprecision is necessarily exposed in the way we process the data. <br><br><hr><br><h2> Professional growth and development </h2><br> <b>Vadim</b> : Do you think that conferences like <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hydra</a> are anticipated? Most distributed systems are quite different, and it is hard to imagine that many attendees will get to work and will start applying what they have learned in day-to-day activities. <br><br> <b>Martin</b> : It is broad, but I think that a lot of the interesting ideas in distributed systems are conceptual. So the insights are not necessarily like ¬´use this database¬ª or ¬´use this particular technology¬ª. They are more like ways of thinking about systems and about software. And those kinds of ideas can be applied quite widely. My hope is that when attendees go away from this conference, the lessons they take away are not so much what piece of software they should be using or which programming language they should be using ‚Äì really, I don't mind about that ‚Äì but more like how to <i>think</i> about the systems they are building. <br><br> <b>Vadim</b> : Why do you think it's important to give conference talks on such complex topics as your talk, compared to publishing papers, covering all their details and intricacies? Or should anyone do both? <br><br> <b>Martin</b> : I think they serve different purposes. When we write papers, the purpose is to have a very definitive, very precise analysis of a particular problem, and to go really deep in that. On the other hand, the purpose of a talk is more to get people interested in a topic and to start a conversation around it. I love going to conferences partly because of the discussions I then have around the talk, where people come to me and say: ¬´oh, we tried something like this, but we ran into this problem and that problem, what do you think about that?¬ª Then I get to think about other people's problems, and that's really interesting because I get to learn a lot from that. <br><br> So, from my point of view, the selfish reason for going to conferences is really to learn from other people, what their experiences have been, and to help share the experiences that we've made in the hope that other people will find them useful as well. But fundamentally, a conference talk is often an introduction to a subject, whereas a paper is a deep analysis of a very narrow question. I think those are different genres and I think we need both of them. <br><br> <b>Vadim</b> : And the last question. How do you personally grow as a professional engineer and a researcher? Could you please recommend any conferences, blogs, books, communities for those who wish to develop themselves in the field of distributed systems? <br><br> <b>Martin</b> : That's a good question. Certainly, there are things to listen to and to read. There's no shortage of conference talks that have been recorded and put online. There are books like my own book for example, which provides a bit of an introduction to the topic, but also lots of references to further reading. So if there are any particular detailed questions that you're interested in, you can follow those references and find the original papers where these ideas were discussed. They can be a very valuable way of learning about something in greater depth. <br><br> A really important part is also trying to implement things and seeing how they work out in practice, and talking to other people and sharing your experiences. Part of the value of a conference is that you get to talk to other people as well, live. But you can have that through other mechanisms as well; for example, there's a Slack channel that people have set up for people <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">interested in distributed systems</a> . If that's your thing you can join that. You can, of course, talk to your colleagues in your company and try to learn from them. I don't think there's one right way of doing this ‚Äî there are many different ways through which you can learn and get a deeper experience, and different paths will work for different people. <br><br> <b>Vadim</b> : Thank you very much for your advice and interesting discussion! It has been a pleasure talking to you. <br><br> <b>Martin</b> : No problem, yeah, it's been nice talking to you. <br><br> <b>Vadim</b> : Let's meet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">at the conference</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458056/">https://habr.com/ru/post/de458056/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458044/index.html">Informationssicherheit in der Provinz - Stagnation oder Entwicklung?</a></li>
<li><a href="../de458046/index.html">Gradle Spickzettel</a></li>
<li><a href="../de458048/index.html">Delegation als Manager-Tool</a></li>
<li><a href="../de458050/index.html">Wie war der Mobius 2019 Piter (und ein bisschen √ºber den n√§chsten Mobius)</a></li>
<li><a href="../de458052/index.html">AMA mit Habr. 10. Letzte * Ausgabe</a></li>
<li><a href="../de458060/index.html">Erstellen eines Grasshaders in der Unity-Engine</a></li>
<li><a href="../de458062/index.html">√úbersicht √ºber die UserGate-Plattform</a></li>
<li><a href="../de458064/index.html">PVS-Studio in den Clouds - Ausf√ºhren der Analyse auf Travis CI</a></li>
<li><a href="../de458068/index.html">PVS-Studio f√ºr Visual Studio</a></li>
<li><a href="../de458070/index.html">PVS-Studio f√ºr Visual Studio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö∂üèª üèº üë©üèΩ‚Äçüé® C√≥mo nosotros en TsIAN domesticamos terabytes de troncos üóø ‚úàÔ∏è üéç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos, mi nombre es Alexander, trabajo como ingeniero en CIAN y me dedico a la administraci√≥n de sistemas y la automatizaci√≥n de procesos de in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo nosotros en TsIAN domesticamos terabytes de troncos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/cian/blog/478564/"><img src="https://habrastorage.org/getpro/habr/post_images/f5a/f37/994/f5af37994ecad978b8cd3edd3dc7ae0a.png"><br><br>  Hola a todos, mi nombre es Alexander, trabajo como ingeniero en CIAN y me dedico a la administraci√≥n de sistemas y la automatizaci√≥n de procesos de infraestructura.  En los comentarios a uno de los art√≠culos anteriores, se nos pidi√≥ que dij√©ramos d√≥nde obtenemos 4 TB de registros por d√≠a y qu√© hacemos con ellos.  S√≠, tenemos muchos registros y se ha creado un cl√∫ster de infraestructura separado para procesarlos, lo que nos permite resolver problemas r√°pidamente.  En este art√≠culo, hablar√© sobre c√≥mo lo adaptamos durante el a√±o para trabajar con un flujo de datos cada vez mayor. <br><a name="habracut"></a><br><h3>  Por donde empezamos </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/6d2/1eb/3da/6d21eb3da4aa0189ae44b9ca951b15a8.jpg"><br><br>  En los √∫ltimos a√±os, la carga en cian.ru ha crecido muy r√°pidamente, y para el tercer trimestre de 2018, el tr√°fico de recursos alcanz√≥ los 11,2 millones de usuarios √∫nicos por mes.  En ese momento, en momentos cr√≠ticos, perdimos hasta el 40% de los registros, por lo que no pudimos lidiar r√°pidamente con los incidentes y dedicamos mucho tiempo y esfuerzo a resolverlos.  A menudo no pudimos encontrar la causa del problema, y ‚Äã‚Äãse repiti√≥ despu√©s de un tiempo.  Fue un infierno con el que ten√≠as que hacer algo. <br><br>  En ese momento, utilizamos un cl√∫ster de 10 nodos de datos con ElasticSearch versi√≥n 5.5.2 con configuraciones de √≠ndice t√≠picas para almacenar registros.  Se introdujo hace m√°s de un a√±o como una soluci√≥n popular y asequible: la secuencia de registro no era tan grande, no ten√≠a sentido crear configuraciones no est√°ndar. <br><br>  Logstash en diferentes puertos proporcion√≥ el procesamiento de registros entrantes en cinco coordinadores de ElasticSearch.  Un √≠ndice, independientemente del tama√±o, constaba de cinco fragmentos.  Se organiz√≥ la rotaci√≥n horaria y diaria, como resultado, aparecieron alrededor de 100 fragmentos nuevos en el grupo cada hora.  Si bien no hab√≠a muchos registros, el cl√∫ster se las arregl√≥ y nadie llam√≥ la atenci√≥n sobre su configuraci√≥n. <br><br><h3>  Problemas de crecimiento </h3><br>  El volumen de los registros generados creci√≥ muy r√°pidamente, ya que dos procesos se superpon√≠an entre s√≠.  Por un lado, hab√≠a cada vez m√°s usuarios del servicio.  Por otro lado, comenzamos a cambiar activamente a la arquitectura de microservicios, aserrando nuestros viejos monolitos en C # y Python.  Varias docenas de microservicios nuevos que reemplazaron partes del monolito generaron significativamente m√°s registros para el cluster de infraestructura. <br><br>  Fue la escala lo que nos llev√≥ al hecho de que el cl√∫ster se volvi√≥ pr√°cticamente incontrolable.  Cuando los registros comenzaron a llegar a una velocidad de 20 mil mensajes por segundo, la rotaci√≥n in√∫til frecuente aument√≥ el n√∫mero de fragmentos a 6 mil, y un nodo represent√≥ m√°s de 600 fragmentos. <br><br>  Esto condujo a problemas con la asignaci√≥n de RAM, y cuando un nodo cay√≥, comenz√≥ un movimiento simult√°neo de todos los fragmentos, multiplicando el tr√°fico y cargando los nodos restantes, lo que hizo casi imposible escribir datos en el cl√∫ster.  Y durante este per√≠odo nos quedamos sin registros.  Y con un problema de servidor, perdimos 1/10 del cl√∫ster en principio.  Una gran cantidad de peque√±os √≠ndices a√±adieron complejidad. <br><br>  Sin registros, no entend√≠amos las causas del incidente y tarde o temprano podr√≠amos volver a pisar el mismo rastrillo, pero en la ideolog√≠a de nuestro equipo esto era inaceptable, ya que todos los mecanismos de trabajo que ten√≠amos se agudizaron exactamente al contrario, nunca repitan los mismos problemas.  Para hacer esto, necesit√°bamos un volumen completo de registros y su entrega casi en tiempo real, ya que un equipo de ingenieros de servicio monitore√≥ las alertas no solo de las m√©tricas, sino tambi√©n de los registros.  Para comprender el alcance del problema, en ese momento el volumen total de registros era de aproximadamente 2 TB por d√≠a. <br><br>  Fijamos un objetivo: eliminar por completo la p√©rdida de registros y reducir el tiempo de entrega al cl√∫ster ELK a un m√°ximo de 15 minutos durante la fuerza mayor (confiamos en esta cifra en el futuro como un KPI interno). <br><br><h3>  Nuevo mecanismo de rotaci√≥n y nodos calientes-calientes </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/363/96f/05e/36396f05e01c97e805388ff27d134e2a.jpg"><br><br>  Comenzamos la transformaci√≥n del cl√∫ster actualizando la versi√≥n de ElasticSearch de 5.5.2 a 6.4.3.  Una vez m√°s, nos lleg√≥ un cl√∫ster de la versi√≥n 5, y decidimos pagarlo y actualizarlo por completo, todav√≠a no hay registros.  As√≠ que hicimos esta transici√≥n en solo un par de horas. <br><br>  La transformaci√≥n m√°s ambiciosa en esta etapa fue la introducci√≥n de tres nodos con el coordinador como un buffer intermedio Apache Kafka.  El intermediario de mensajes nos salv√≥ de perder registros durante problemas con ElasticSearch.  Al mismo tiempo, agregamos 2 nodos al cl√∫ster y cambiamos a una arquitectura caliente-caliente con tres nodos "calientes" dispuestos en diferentes bastidores en el centro de datos.  Redirigimos los registros a ellos que no deber√≠an perderse en ning√∫n caso, nginx, as√≠ como los registros de errores de la aplicaci√≥n.  Registros menores: depuraci√≥n, advertencia, etc., fueron a otros nodos y tambi√©n, despu√©s de 24 horas, los registros "importantes" se trasladaron desde los nodos "activos". <br><br>  Para no aumentar el n√∫mero de √≠ndices peque√±os, cambiamos de rotaci√≥n de tiempo al mecanismo de reinversi√≥n.  Hubo mucha informaci√≥n en los foros de que la rotaci√≥n por tama√±o de √≠ndice no es muy confiable, por lo que decidimos usar la rotaci√≥n por la cantidad de documentos en el √≠ndice.  Analizamos cada √≠ndice y registramos el n√∫mero de documentos despu√©s de los cuales la rotaci√≥n deber√≠a funcionar.  Por lo tanto, hemos alcanzado el tama√±o √≥ptimo del fragmento: no m√°s de 50 GB. <br><br><h3>  Optimizaci√≥n de cl√∫ster </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/cf3/c46/45e/cf3c4645e6b74cf5491f9878dacfa185.jpg"><br><br>  Sin embargo, no eliminamos por completo los problemas.  Desafortunadamente, los √≠ndices peque√±os aparecieron de todos modos: no alcanzaron el volumen establecido, no giraron y se eliminaron mediante la limpieza global de los √≠ndices anteriores a tres d√≠as, ya que eliminamos la rotaci√≥n por fecha.  Esto condujo a la p√©rdida de datos debido al hecho de que el √≠ndice del cl√∫ster desapareci√≥ por completo, y un intento de escribir en un √≠ndice inexistente rompi√≥ la l√≥gica del curador que utilizamos para el control.  El alias para la grabaci√≥n se transform√≥ en un √≠ndice y rompi√≥ la l√≥gica del rollover, causando un crecimiento incontrolado de algunos √≠ndices a 600 GB. <br><br>  Por ejemplo, para configurar la rotaci√≥n: <br><br><pre><code class="plaintext hljs">urator-elk-rollover.yaml --- actions:   1:     action: rollover     options:       name: "nginx_write"       conditions:         max_docs: 100000000   2:     action: rollover     options:       name: "python_error_write"       conditions:         max_docs: 10000000</code> </pre> <br><br>  En ausencia de alias de rollover, se produjo un error: <br><br><pre> <code class="plaintext hljs">ERROR   alias "nginx_write" not found. ERROR   Failed to complete action: rollover. &lt;type 'exceptions.ValueError'&gt;: Unable to perform index rollover with alias "nginx_write".</code> </pre><br><br>  Dejamos la soluci√≥n a este problema para la pr√≥xima iteraci√≥n y tomamos otra pregunta: cambiamos para extraer la l√≥gica de Logstash, que maneja los registros entrantes (eliminando informaci√≥n innecesaria y enriqueci√©ndola).  Lo colocamos en docker, que ejecutamos a trav√©s de docker-compose, y colocamos logstash-exporter en el mismo lugar, lo que proporciona las m√©tricas a Prometheus para el monitoreo operativo de la secuencia de registro.  Entonces nos dimos la oportunidad de cambiar sin problemas la cantidad de instancias de logstash responsables del procesamiento de cada tipo de registro. <br><br>  Mientras est√°bamos mejorando el cl√∫ster, el tr√°fico de cian.ru creci√≥ a 12.8 millones de usuarios √∫nicos por mes.  Como resultado, result√≥ que nuestras conversiones no se mantuvieron un poco al d√≠a con los cambios en la producci√≥n, y nos enfrentamos con el hecho de que los nodos "calientes" no pod√≠an hacer frente a la carga y ralentizaron la entrega completa de registros.  Recibimos los datos "en caliente" sin fallas, pero tuvimos que intervenir en la entrega del resto y hacer una renovaci√≥n manual para distribuir uniformemente los √≠ndices. <br><br>  Al mismo tiempo, escalar y cambiar la configuraci√≥n de las instancias de logstash en el cl√∫ster se complic√≥ por el hecho de que se trataba de un docker-compose local, y todas las acciones se realizaron a mano (para agregar nuevos extremos, ten√≠a que pasar por todos los servidores con las manos y hacer docker-compose up -d en todas partes). <br><br><h3>  Redistribuci√≥n de registros </h3><br>  En septiembre de este a√±o, seguimos viendo el monolito, la carga en el cl√∫ster aument√≥ y el flujo de registro se acercaba a 30 mil mensajes por segundo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/28c/ff7/c76/28cff7c7661c901102a69fe49beeccd0.png"><br><br>  Comenzamos la siguiente iteraci√≥n con la actualizaci√≥n de la plancha.  Cambiamos de cinco coordinadores a tres, reemplazamos nodos de datos y ganamos en t√©rminos de dinero y volumen de almacenamiento.  Para los nodos, utilizamos dos configuraciones: <br><br><ul><li>  Para nodos activos: E3-1270 v6 / 960 Gb SSD / 32 Gb x 3 x 2 (3 para Hot1 y 3 para Hot2). <br></li><li>  Para nodos calientes: E3-1230 v6 / 4Tb SSD / 32 Gb x 4. <br></li></ul><br>  En esta iteraci√≥n, sacamos el √≠ndice con registros de acceso de microservicios, que ocupan tanto espacio como los registros de nginx de front-end, en el segundo grupo de tres nodos activos.  Ahora almacenamos datos en nodos activos durante 20 horas y luego los transferimos para calentarlos a otros registros. <br><br>  Resolvimos el problema de la desaparici√≥n de peque√±os √≠ndices reconfigurando su rotaci√≥n.  Los √≠ndices ahora se rotan de todos modos cada 23 horas, incluso si hay pocos datos.  Esto aument√≥ ligeramente el n√∫mero de fragmentos (se convirtieron en unos 800), pero desde el punto de vista del rendimiento del cl√∫ster esto es tolerable. <br><br>  Como resultado, seis nodos "calientes" y solo cuatro "c√°lidos" resultaron en el cl√∫ster.  Esto provoca un ligero retraso en las solicitudes durante largos intervalos de tiempo, pero aumentar el n√∫mero de nodos en el futuro resolver√° este problema. <br><br>  En esta iteraci√≥n, tambi√©n se solucion√≥ el problema de la falta de escalado semiautom√°tico.  Para hacer esto, implementamos un cl√∫ster de infraestructura Nomad, similar a lo que ya hemos implementado para la producci√≥n.  Si bien el n√∫mero de Logstash no cambia autom√°ticamente seg√∫n la carga, llegaremos a esto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c5/331/493/5c533149373a09c73e329e3bb43e0d81.png"><br><br><h3>  Planes futuros </h3><br>  La configuraci√≥n implementada escala bien, y ahora almacenamos 13.3 TB de datos, todos registros en 4 d√≠as, lo cual es necesario para el an√°lisis de emergencia de alertas.  Convertimos parte de los registros a m√©tricas, que agregamos a Graphite.  Para facilitar el trabajo de los ingenieros, tenemos m√©tricas para el cl√∫ster de infraestructura y scripts para solucionar problemas t√≠picos semiautom√°ticos.  Despu√©s de aumentar el n√∫mero de nodos de datos, que est√° previsto para el pr√≥ximo a√±o, cambiaremos al almacenamiento de datos de 4 a 7 d√≠as.  Esto ser√° suficiente para el trabajo operativo, ya que siempre tratamos de investigar los incidentes lo antes posible, y los datos de telemetr√≠a est√°n disponibles para investigaciones a largo plazo. <br><br>  En octubre de 2019, el tr√°fico de cian.ru aument√≥ a 15,3 millones de usuarios √∫nicos por mes.  Esta fue una prueba seria de la soluci√≥n arquitect√≥nica para la entrega de registros. <br><br>  Ahora nos estamos preparando para actualizar ElasticSearch a la versi√≥n 7. Sin embargo, para esto tendremos que actualizar la asignaci√≥n de muchos √≠ndices en ElasticSearch, porque se trasladaron de la versi√≥n 5.5 y se declararon obsoletos en la versi√≥n 6 (simplemente no existen en la versi√≥n 7).  Y esto significa que, en el proceso de actualizaci√≥n, habr√° alguna fuerza mayor que nos dejar√° sin registros por el momento.  De las 7 versiones, estamos ansiosos por Kibana con una interfaz mejorada y nuevos filtros. <br><br>  Logramos el objetivo principal: dejamos de perder registros y redujimos el tiempo de inactividad del cl√∫ster de infraestructura de 2-3 ca√≠das por semana a un par de horas de trabajo de servicio por mes.  Todo este trabajo en producci√≥n es casi invisible.  Sin embargo, ahora podemos determinar con precisi√≥n lo que est√° sucediendo con nuestro servicio, podemos hacerlo r√°pidamente en un modo silencioso y no preocuparnos de que se pierdan los registros.  En general, estamos satisfechos, felices y nos estamos preparando para nuevos exploits, de los que hablaremos m√°s adelante. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/478564/">https://habr.com/ru/post/478564/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../478546/index.html">Websockets Alguna experiencia en desarrollo y operaci√≥n. Modificamos al cliente</a></li>
<li><a href="../478550/index.html">¬øC√≥mo gestionar un reloj? An√°lisis de la pista front-end del segundo campeonato de programaci√≥n.</a></li>
<li><a href="../478552/index.html">Segundo applet, cierre y botones transparentes en Processing 3</a></li>
<li><a href="../478554/index.html">Seminario web "SRE: ¬øexageraci√≥n o el futuro?" 12 de diciembre a las 11:00</a></li>
<li><a href="../478560/index.html">¬øSon an√≥nimos los mensajeros instant√°neos gratuitos?</a></li>
<li><a href="../478566/index.html">iOS Redes cuando la aplicaci√≥n no se est√° ejecutando</a></li>
<li><a href="../478572/index.html">Bot en redes neuronales: c√≥mo funciona y aprende un asistente virtual</a></li>
<li><a href="../478574/index.html">La verdad sobre los frenos de ferrocarril: Parte 4 - Frenos de pasajeros</a></li>
<li><a href="../478582/index.html">Informe VPN global sobre dispositivos m√≥viles en 2019</a></li>
<li><a href="../478584/index.html">Elementos internos de JVM, Parte 2 - Estructura de archivos de clase</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
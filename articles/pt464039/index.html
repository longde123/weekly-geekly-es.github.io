<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÉ üò¢ ‚úä Redes neurais e aprendizado profundo: um tutorial on-line, cap√≠tulo 6, parte 2: progresso recente no reconhecimento de imagens üöØ üîù üà∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Conte√∫do 

- Cap√≠tulo 1: usando redes neurais para reconhecer n√∫meros manuscritos 
- Cap√≠tulo 2: como o algoritmo de retropropaga√ß√£o funciona 
- Cap√≠t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neurais e aprendizado profundo: um tutorial on-line, cap√≠tulo 6, parte 2: progresso recente no reconhecimento de imagens</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464039/"><div class="spoiler">  <b class="spoiler_title">Conte√∫do</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 1: usando redes neurais para reconhecer n√∫meros manuscritos</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 2: como o algoritmo de retropropaga√ß√£o funciona</a> </li><li>  Cap√≠tulo 3: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1: aprimorando o m√©todo de treinamento de redes neurais</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2: Por que a regulariza√ß√£o ajuda a reduzir a reciclagem?</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 3: como escolher hiperpar√¢metros de redes neurais?</a> <br></li>
</ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 4: prova visual de que as redes neurais s√£o capazes de computar qualquer fun√ß√£o</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 5: por que as redes neurais profundas s√£o t√£o dif√≠ceis de treinar?</a> </li><li>  Cap√≠tulo 6: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1: Aprendizado Profundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2: progresso recente no reconhecimento de imagens</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Posf√°cio: existe um algoritmo simples para criar intelig√™ncia?</a> </li></ul></div></div><br>  Em 1998, quando o banco de dados MNIST apareceu, demorou semanas para treinar os computadores mais avan√ßados, que obtiveram resultados muito piores do que os computadores de hoje, que levam menos de uma hora para chegar √† GPU.  Portanto, o MNIST n√£o √© mais uma tarefa que ultrapassa os limites da tecnologia;  a velocidade do treinamento sugere que essa tarefa √© adequada para o estudo dessa tecnologia.  Enquanto isso, a pesquisa vai al√©m, e o trabalho moderno estuda problemas muito mais complexos.  Nesta se√ß√£o, descreverei brevemente alguns exemplos de trabalhos em andamento relacionados ao reconhecimento de imagens usando redes neurais. <br><br>  Esta se√ß√£o √© diferente do restante do livro.  No livro, concentrei-me em id√©ias presumivelmente duradouras - retropropaga√ß√£o, regulariza√ß√£o, redes convolucionais.  Tentei evitar os resultados considerados modernos na √©poca em que escrevi, cujo valor a longo prazo parecia d√∫bio.  Na ci√™ncia, esses resultados geralmente se mostram ef√™meros, desaparecem rapidamente e n√£o t√™m efeito a longo prazo.  Diante disso, o c√©tico diria: ‚Äú√â claro que o progresso recente no reconhecimento de imagens pode ser considerado um exemplo de uma viagem de um dia?  Em dois ou tr√™s anos, tudo vai mudar.  Ent√£o, √© prov√°vel que esses resultados sejam do interesse de um pequeno n√∫mero de profissionais competindo em primeiro plano?  Por que discuti-los? <br><a name="habracut"></a><br>  Tal c√©tico estar√° certo em que os pequenos detalhes de trabalhos recentes est√£o gradualmente perdendo a import√¢ncia percebida.  No entanto, nos √∫ltimos anos, houve melhorias incr√≠veis na solu√ß√£o de problemas particularmente complexos de reconhecimento de imagens usando redes neurais profundas (GNS).  Imagine um historiador da ci√™ncia escrevendo material sobre vis√£o computacional em 2100.  Eles definir√£o 2011-2015 (e provavelmente v√°rios anos depois disso) como um per√≠odo de avan√ßos significativos impulsionados por redes de convolu√ß√£o profunda (GSS).  Isso n√£o significa que o GOS ainda ser√° usado em 2100, sem mencionar detalhes como exce√ß√£o, ReLU e mais.  Mas isso significa que h√° uma transi√ß√£o importante na hist√≥ria das id√©ias no momento atual.  Isso √© semelhante a observar a descoberta do √°tomo, a inven√ß√£o de antibi√≥ticos: a inven√ß√£o e descoberta de propor√ß√µes hist√≥ricas.  Portanto, sem entrar em detalhes, vale a pena ter uma id√©ia das descobertas interessantes que est√£o sendo feitas hoje. <br><br><h3>  Trabalho 2012 LRMD </h3><br>  Deixe-me come√ßar com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho de 2012, de</a> autoria de um grupo de pesquisadores de Stanford e Google.  Vou cham√°-la de LRMD pelas primeiras letras dos nomes dos quatro primeiros autores.  O LRMD usou o NS para classificar imagens do banco de dados ImageNet, o que √© uma tarefa muito dif√≠cil de reconhecimento de padr√µes.  Os dados que eles usaram do ImageNet de 2011 inclu√≠ram 16 milh√µes de imagens coloridas, divididas em 20.000 categorias.  As imagens foram baixadas da Internet e classificadas pelo Mechanical Turk da Amazon.  Aqui est√£o alguns deles: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/323/b71/89a/323b7189a538cc4532b293b48f587cca.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/bed/423/c27/bed423c2789cb88297bf8946f1e92e82.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/855/3e5/38d/8553e538d4514742d4ebf554eae7c490.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/326/bc0/f49/326bc0f4920430fb06490cab8bb8eeeb.jpg"><br><br>  Eles pertencem √†s categorias, respectivamente: caxumba, fungo da raiz marrom, leite pasteurizado, lombrigas.  Se voc√™ deseja praticar, recomendo que voc√™ visite a lista de ferramentas manuais da ImagNet, onde s√£o feitas diferen√ßas entre montes, aplainadoras, aplainadoras para chanfro e dezenas de outros tipos de aplainadoras, para n√£o mencionar outras categorias.  N√£o conhe√ßo voc√™, mas n√£o consigo distinguir com certeza todas essas ferramentas.  Isto √© obviamente muito mais desafiador do que o MNIST!  A rede LRMD obteve um resultado decente com precis√£o de reconhecimento de imagem de 15,8% do ImageNet.  Isso pode n√£o parecer um resultado t√£o impressionante, mas houve uma grande melhoria em rela√ß√£o ao resultado anterior de 9,3%.  Esse salto sugere que os NSs podem oferecer uma abordagem eficaz para tarefas de reconhecimento de imagens muito complexas, como o ImageNet. <br><br><h3>  Trabalho 2012 KSH </h3><br>  O trabalho do LRMD em 2012 foi seguido pelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho de</a> Krizhevsky, Sutskever e Hinton (KSH).  A KSH treinou e testou o GSS usando um subconjunto limitado de dados do ImagNet.  Esse subconjunto √© definido pela popular competi√ß√£o de aprendizado de m√°quina - Desafio de reconhecimento visual em larga escala do ImageNet (ILSVRC).  O uso desse subconjunto deu a eles uma maneira conveniente de comparar sua abordagem com outras t√©cnicas principais.  O conjunto ILSVRC 2012 cont√©m cerca de 1,2 milh√µes de imagens de 1000 categorias.  Os conjuntos de verifica√ß√£o e confirma√ß√£o cont√™m 150.000 e 50.000 imagens, respectivamente, das mesmas 1000 categorias. <br><br>  Um dos desafios da competi√ß√£o ILSVRC √© que muitas imagens do ImageNet cont√™m v√°rios objetos.  Por exemplo, na imagem, o Labrador Retriever corre atr√°s de uma bola de futebol.  T.N.  A classifica√ß√£o ‚Äúcorreta‚Äù do ILSVRC pode corresponder ao r√≥tulo Labrador Retriever.  √â necess√°rio selecionar pontos do algoritmo se marcar a imagem como uma bola de futebol?  Devido a essa ambiguidade, o algoritmo foi considerado correto se a classifica√ß√£o ImageNet estivesse entre as 5 suposi√ß√µes mais prov√°veis ‚Äã‚Äãdo algoritmo em rela√ß√£o ao conte√∫do da imagem.  De acordo com este crit√©rio, dos 5 primeiros, o GSS da KSH alcan√ßou uma precis√£o de 84,7%, muito melhor que o advers√°rio anterior, que alcan√ßou uma precis√£o de 73,8%.  Usando uma m√©trica mais rigorosa, quando o r√≥tulo deve corresponder exatamente ao prescrito, a precis√£o do KSH atingiu 63,3%. <br><br>  Vale a pena descrever brevemente a rede KSH, pois inspirou muitos trabalhos que se seguiram.  Tamb√©m √©, como veremos, estreitamente conectado √†s redes que treinamos neste cap√≠tulo, embora seja mais complexo.  A KSH usou o GSS treinado em duas GPUs.  Eles usaram duas GPUs porque seu cart√£o espec√≠fico (NVIDIA GeForce GTX 580) n√£o tinha mem√≥ria suficiente para armazenar toda a rede.  Portanto, eles dividem a rede em duas partes. <br><br>  A rede KSH possui 7 camadas de neur√¥nios ocultos.  As cinco primeiras camadas ocultas s√£o convolucionais (algumas usam o pool m√°ximo) e as pr√≥ximas 2 est√£o totalmente conectadas.  A camada softmax de sa√≠da consiste em 1000 neur√¥nios correspondentes a 1000 classes de imagens.  Aqui est√° um esbo√ßo da rede, retirado do trabalho da KSH.  Os detalhes s√£o descritos abaixo.  Observe que muitas camadas s√£o divididas em 2 partes correspondentes a duas GPUs. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/986/143/0bb/9861430bb7c8c79540298a2db5122ec2.jpg"><br><br>  Na camada de entrada, h√° um neur√¥nio 3x224x224 indicando os valores RGB para uma imagem de tamanho 224x224.  Lembre-se de que o ImageNet cont√©m imagens de v√°rias resolu√ß√µes.  Isso apresenta um problema, j√° que a camada da rede de entrada geralmente possui um tamanho fixo.  A KSH lidou com isso escalando cada imagem para que seu lado curto tivesse um comprimento de 256 pixels.  Em seguida, eles cortam uma √°rea de 256x256 pixels no meio da imagem redimensionada.  Por fim, o KSH recupera peda√ßos de imagem aleat√≥rios de 224x224 (e seus reflexos horizontais) de imagens de 256x256.  Esse corte aleat√≥rio √© uma maneira de expandir os dados de treinamento para reduzir a reciclagem.  Isso ajuda especialmente a treinar uma rede t√£o grande como a KSH.  E, finalmente, essas imagens de 224x224 s√£o usadas como entrada na rede.  Na maioria dos casos, a imagem cortada cont√©m o objeto principal da imagem original. <br><br>  Passamos para as camadas ocultas da rede KSH.  A primeira camada oculta √© convolucional, com um passo de extra√ß√£o m√°xima.  Ele usa campos receptivos locais de tamanho 11x11 e uma etapa de 4 pixels.  No total, 96 cart√µes de recursos s√£o obtidos.  As cartas de personagem s√£o divididas em dois grupos de 48 pe√ßas, com as primeiras 48 em uma GPU e a segunda na outra.  O pool m√°ximo nessas camadas e nas subseq√ºentes √© realizado por se√ß√µes 3x3, mas as se√ß√µes de pool podem se sobrepor e est√£o localizadas a uma dist√¢ncia de apenas 2 pixels uma da outra. <br><br>  A segunda camada oculta tamb√©m √© convolucional, com pool m√°ximo.  Ele usa campos receptivos 5x5 locais e possui 256 cart√µes de recursos, divididos em 128 peda√ßos para cada GPU.  Os mapas de recursos usam apenas 48 canais de entrada e nem todas as 96 sa√≠das da camada anterior, como de costume.  Isso ocorre porque qualquer placa de recurso recebe entrada da GPU na qual est√° armazenada.  Nesse sentido, a rede est√° se afastando da arquitetura convolucional que descrevemos anteriormente neste cap√≠tulo, embora, obviamente, a id√©ia b√°sica permane√ßa a mesma. <br><br>  A terceira, quarta e quinta camadas s√£o convolucionais, mas sem agrupamento m√°ximo.  Seus par√¢metros: (3) 384 mapas de caracter√≠sticas, campos receptivos locais 3x3, 256 canais de entrada;  (4) 384 mapas de caracter√≠sticas, campos receptivos locais 3x3, 192 canais de entrada;  (5) 256 cart√µes de recursos, campos receptivos locais 3x3, 192 canais de entrada.  Na terceira camada, os dados s√£o trocados entre as GPUs (como mostrado na figura) para que os mapas de recursos possam usar todos os 256 canais de entrada. <br><br>  A sexta e a s√©tima camadas ocultas est√£o totalmente conectadas, 4096 neur√¥nios cada. <br><br>  A camada de sa√≠da √© softmax, consiste em 1000 unidades. <br><br>  A rede KSH tira proveito de muitas t√©cnicas.  Em vez de usar tangente sigm√≥ide ou hiperb√≥lica como uma fun√ß√£o de ativa√ß√£o, ele usa ReLUs, que aceleram bastante o aprendizado.  A rede KSH cont√©m cerca de 60 milh√µes de par√¢metros de treinamento e, portanto, mesmo com um grande conjunto de dados de treinamento, ela est√° sujeita a reciclagem.  Para lidar com isso, os autores expandiram o conjunto de treinamento cortando imagens aleatoriamente, conforme descrito acima.  Eles ent√£o usaram a variante de regulariza√ß√£o L2 e a exce√ß√£o.  A rede foi treinada usando descida de gradiente estoc√°stico com base no momento e com minipacotes. <br><br>  Esta √© uma breve vis√£o geral de muitos dos principais insights da KSH.  Omiti alguns detalhes; procure-os no artigo voc√™ mesmo.  Voc√™ tamb√©m pode ver o projeto de Alex Krizhevsky <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cuda-convnet</a> (e seus seguidores), contendo c√≥digo que implementa muitas das id√©ias descritas.  <a href="">Uma</a> vers√£o dessa rede <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">baseada no Theano</a> tamb√©m foi <a href="">desenvolvida</a> .  Voc√™ pode reconhecer id√©ias no c√≥digo semelhantes √†s que desenvolvemos neste cap√≠tulo, embora o uso de v√°rias GPUs complique as coisas.  O framework Caffe possui sua pr√≥pria vers√£o da rede KSH, consulte seus " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelos de zool√≥gico</a> " para obter detalhes. <br><br><h3>  Competi√ß√£o ILSVRC 2014 </h3><br>  Desde 2012, o progresso tem sido bastante r√°pido.  Participe da competi√ß√£o de 2014 do ILSVRC.  Como em 2012, os participantes tiveram que treinar redes para 1,2 milh√£o de imagens de 1000 categorias, e uma das 5 previs√µes prov√°veis ‚Äã‚Äãna categoria correta era um crit√©rio de qualidade.  <a href="">A equipe vencedora</a> , composta principalmente por funcion√°rios do Google, usou o GSS com 22 camadas de neur√¥nios.  Eles chamaram sua rede de GoogLeNet, em homenagem a LeNet-5.  A GoogLeNet alcan√ßou precis√£o de 93,33% pelos crit√©rios das cinco melhores op√ß√µes, o que melhorou seriamente os resultados do vencedor de 2013 (Clarifai, de 88,3%) e do vencedor de 2012 (KSH, de 84,7%). <br><br>  Qual √© a precis√£o da GoogLeNet 93,33%?  Em 2014, uma equipe de pesquisa escreveu uma <a href="">revis√£o da</a> competi√ß√£o ILSVRC.  Uma das quest√µes abordadas foi o qu√£o bem as pessoas seriam capazes de lidar com a tarefa.  Para o experimento, eles criaram um sistema que permite que as pessoas classifiquem imagens com o ILSVRC.  Como explica um dos autores do trabalho, Andrei Karpaty, em uma entrada informativa em seu blog, era muito dif√≠cil trazer a efic√°cia das pessoas aos indicadores do GoogLeNet: <br><blockquote>  A tarefa de marcar imagens com cinco categorias dentre 1.000 poss√≠veis rapidamente se tornou extremamente dif√≠cil, mesmo para os meus amigos no laborat√≥rio que trabalhavam com o ILSVRC e suas categorias h√° algum tempo.  Primeiro, quer√≠amos enviar a tarefa para o Amazon Mechanical Turk.  Ent√£o decidimos tentar contratar estudantes por dinheiro.  Por isso, organizei uma festa de marca√ß√£o entre especialistas em meu laborat√≥rio.  Depois disso, desenvolvi uma interface modificada que utilizava as previs√µes do GoogLeNet para reduzir o n√∫mero de categorias de 1000 para 100. No entanto, a tarefa era dif√≠cil - as pessoas pulavam categorias, com erros da ordem de 13 a 15%.  No final, percebi que, para me aproximar ainda mais do resultado do GoogLeNet, a abordagem mais eficaz seria me sentar e passar por um processo de aprendizado impossivelmente longo e pelo processo subsequente de marca√ß√£o completa.  No in√≠cio, a marca√ß√£o era de uma velocidade da ordem de 1 pe√ßa por minuto, mas acelerada com o tempo.  Algumas imagens eram f√°ceis de reconhecer, enquanto outras (por exemplo, certas ra√ßas de c√£es, esp√©cies de p√°ssaros ou macacos) exigiam v√°rios minutos de concentra√ß√£o.  Fiquei muito bom em distinguir entre ra√ßas de c√£es.  Com base na minha amostra de imagens, foram obtidos os seguintes resultados: O GoogLeNet se enganou em 6,8% dos casos;  minha taxa de erro foi de 5,1%, o que foi cerca de 1,7% melhor. </blockquote><br><br>  Em outras palavras, o especialista, que trabalhou com muito cuidado, apenas envidando esfor√ßos s√©rios, conseguiu se aproximar um pouco do STS.  Karpaty relata que o segundo especialista, treinado em menos imagens, conseguiu reduzir o erro em apenas 12% ao escolher at√© 5 etiquetas por imagem, o que √© muito menor que o GoogLeNet. <br><br>  Resultados impressionantes.  E desde o in√≠cio deste trabalho, v√°rias equipes relataram o desenvolvimento de sistemas cuja taxa de erro ao escolher as 5 melhores tags era ainda inferior a 5,1%.  √Äs vezes, essas conquistas foram abordadas na m√≠dia como o surgimento de sistemas capazes de reconhecer imagens melhor do que as pessoas.  Embora os resultados sejam geralmente impressionantes, h√° muitas nuances que n√£o podem ser consideradas: a vis√£o por computador funciona melhor nesses sistemas do que nos humanos.  De muitas maneiras, a competi√ß√£o ILSVRC √© uma tarefa muito limitada - os resultados de uma pesquisa de imagens em uma rede aberta n√£o corresponder√£o necessariamente ao que o programa atende em uma tarefa pr√°tica.  E, √© claro, o crit√©rio "uma das cinco melhores notas" √© bastante artificial.  Ainda temos um longo caminho a percorrer para resolver o problema do reconhecimento de imagem, sem mencionar a tarefa mais geral da vis√£o por computador.  Ainda assim, √© muito legal ver quanto progresso foi alcan√ßado na solu√ß√£o de uma tarefa t√£o dif√≠cil em apenas alguns anos. <br><br><h3>  Outras tarefas </h3><br>  Eu me concentrei no ImageNet, no entanto, existem alguns outros projetos usando o NS para reconhecimento de imagem.  Deixe-me descrever brevemente alguns resultados interessantes obtidos recentemente, apenas para ter uma id√©ia do trabalho moderno. <br><br>  Um <a href="">conjunto</a> pr√°tico e inspirador <a href="">de resultados</a> foi obtido por uma equipe do Google, que aplicou o GSS √† tarefa de reconhecimento de placas de endere√ßo no Google Street View.  Em seu trabalho, eles relatam como descobriram e reconheceram automaticamente quase 100 milh√µes de placas de endere√ßos com precis√£o compar√°vel ao trabalho humano.  E o sistema deles √© r√°pido: conseguiu descriptografar dados de todas as imagens do Google Street View na Fran√ßa em menos de uma hora!  Eles escrevem: "A obten√ß√£o desse novo conjunto de dados aumentou significativamente a qualidade da geocodifica√ß√£o do Google Maps em v√°rios pa√≠ses, especialmente onde n√£o havia outras fontes de geocodifica√ß√£o".  Em seguida, eles fazem uma declara√ß√£o mais geral: "Acreditamos que, gra√ßas a esse modelo, resolvemos o problema do reconhecimento √≥ptico de sequ√™ncias curtas de uma maneira que √© aplic√°vel em muitas aplica√ß√µes pr√°ticas". <br><br>  Talvez tenha criado a impress√£o de um desfile de resultados vitoriosos e inspiradores.  Obviamente, os relat√≥rios mais interessantes dizem respeito a coisas fundamentais que ainda n√£o est√£o claras para n√≥s.  Por exemplo, no <a href="">trabalho de 2013,</a> foi demonstrado que a Assembl√©ia Nacional tem, de fato, pontos cegos.  D√™ uma olhada nas imagens abaixo.  √Ä esquerda est√° a imagem do ImageNet, que a rede de pesquisadores classificou corretamente.  √Ä direita, h√° uma imagem ligeiramente modificada (no meio, as diferen√ßas s√£o mostradas), que a rede n√£o conseguiu mais reconhecer corretamente.  E os autores descobriram que essas mudan√ßas "contradit√≥rias" podem ser selecionadas para qualquer imagem do banco de dados, e n√£o apenas para a elite. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ddf/c77/f29/ddfc77f2996c1fb482fa448f1384d08a.jpg"><br><br>  Resultado desagrad√°vel.  Usamos uma rede baseada no mesmo c√≥digo da rede KSH - ou seja, √© uma rede que √© cada vez mais usada.  E embora esses NSs calculem, em princ√≠pio, fun√ß√µes cont√≠nuas, resultados semelhantes sugerem que provavelmente calculam fun√ß√µes quase discretas.  Pior, eles acabam sendo discretos de uma maneira que viola nossa no√ß√£o intuitiva de comportamento inteligente.  Isso √© um problema.  Al√©m disso, n√£o est√° muito claro o que exatamente leva √† discri√ß√£o, qual √© o problema: na fun√ß√£o de perda?  Quais fun√ß√µes de ativa√ß√£o usar?  Na arquitetura de rede?  Em outra coisa?  N√≥s n√£o sabemos. <br><br>  Mas esses resultados n√£o s√£o t√£o ruins quanto parecem.  Embora tais mudan√ßas contradit√≥rias sejam bastante comuns, √© improv√°vel que sejam encontradas na pr√°tica.  Conforme indicado no trabalho: <br><blockquote>  A exist√™ncia de negativos contradit√≥rios contradiz a capacidade da rede de alcan√ßar alta generaliza√ß√£o.  De fato, se a rede poderia generalizar bem, como poderia ser enganada por esses negativos contradit√≥rios indistingu√≠veis de exemplos comuns?  A explica√ß√£o √© que um conjunto de negativos competitivos tem uma probabilidade extremamente baixa e, portanto, n√£o √© observado (ou quase n√£o √© observado) no conjunto de dados de treinamento, no entanto, possui uma alta densidade (aproximadamente como n√∫meros racionais) e, portanto, pode ser encontrado em quase todos os casos . </blockquote><br><br>  No entanto, √© desagrad√°vel entendermos t√£o mal o trabalho da Assembl√©ia Nacional que esse resultado foi descoberto recentemente.  Obviamente, a principal vantagem de tais resultados ser√° que eles estimularam o surgimento de trabalhos subseq√ºentes sobre esse tema.  Um <a href="">trabalho recente de 2014</a> mostrou que √© poss√≠vel que uma rede treinada crie imagens que pare√ßam ru√≠do branco para uma pessoa, e a rede as classifique em categorias conhecidas com um alto grau de confian√ßa.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esta √© outra demonstra√ß√£o que ainda temos muito a entender no trabalho do NS e em seu uso no reconhecimento de imagens.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mas, apesar da presen√ßa de resultados semelhantes, o quadro geral √© inspirador. </font><font style="vertical-align: inherit;">Estamos vendo um r√°pido progresso na realiza√ß√£o de testes extremamente complexos, como o ImageNet. </font><font style="vertical-align: inherit;">Tamb√©m estamos vendo um r√°pido progresso na solu√ß√£o de problemas do mundo real, como o reconhecimento de placas de endere√ßo no StreetView. </font><font style="vertical-align: inherit;">Mas, apesar da inspira√ß√£o, n√£o basta observar melhorias no desempenho de testes de velocidade ou mesmo em tarefas do mundo real. </font><font style="vertical-align: inherit;">Existem fen√¥menos fundamentais, cuja ess√™ncia ainda mal compreendemos, por exemplo, a exist√™ncia de imagens competitivas. </font><font style="vertical-align: inherit;">E, embora esses problemas fundamentais ainda se abram (sem mencionar sua solu√ß√£o), seria prematuro falar sobre como abordar a solu√ß√£o do problema de reconhecimento de imagem. </font><font style="vertical-align: inherit;">Mas, ao mesmo tempo, esses problemas s√£o excelentes incentivos para trabalhos futuros.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Outras abordagens para redes neurais profundas </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neste livro, focamos em uma tarefa: a classifica√ß√£o dos n√∫meros MNIST. Uma excelente tarefa que nos fez entender muitas id√©ias eficazes: descida de gradiente estoc√°stico, retropropaga√ß√£o, redes convolucionais, regulariza√ß√£o etc. No entanto, essa tamb√©m √© uma tarefa bastante restrita. Depois de ler a literatura sobre redes neurais, voc√™ encontrar√° muitas id√©ias que n√£o discutimos: NSs recorrentes, m√°quinas Boltzmann, modelos generativos, transfer√™ncia de treinamento, aprendizado refor√ßado e assim por diante! As redes neurais s√£o uma vasta √°rea. No entanto, muitas id√©ias importantes s√£o varia√ß√µes daquelas que j√° discutimos e s√£o f√°ceis de entender. Nesta se√ß√£o, vou abrir levemente a cortina sobre essas vastas extens√µes. A discuss√£o deles n√£o seria detalhada e abrangente - isso inflaria bastante o livro. Ser√° impressionista,uma tentativa de mostrar a riqueza conceitual dessa √°rea e conectar alguns conceitos com os que j√° vimos. No texto, darei v√°rias refer√™ncias a outras fontes, quanto a materiais para treinamento adicional. √â claro que muitos deles logo estar√£o lotados por outros, e talvez voc√™ queira procurar literatura mais recente. No entanto, acredito que muitas id√©ias b√°sicas permanecer√£o interessantes por muito tempo.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Redes Neurais Recorrentes (RNS) </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nas redes de propaga√ß√£o direta que usamos, existe uma entrada que determina completamente a ativa√ß√£o de todos os neur√¥nios nas camadas subseq√ºentes. </font><font style="vertical-align: inherit;">Esta √© uma imagem muito est√°tica: tudo na rede √© fixo e tem um car√°ter cristalino e congelado. </font><font style="vertical-align: inherit;">Mas suponha que permitimos que os elementos da rede mudem dinamicamente. </font><font style="vertical-align: inherit;">Por exemplo, o comportamento dos neur√¥nios ocultos pode ser determinado n√£o apenas pelas ativa√ß√µes nas camadas anteriores, mas tamb√©m pelas ativa√ß√µes que ocorreram mais cedo. </font><font style="vertical-align: inherit;">A ativa√ß√£o de um neur√¥nio pode ser parcialmente determinada por sua ativa√ß√£o anterior. </font><font style="vertical-align: inherit;">Em redes com distribui√ß√£o direta, isso claramente n√£o acontece. </font><font style="vertical-align: inherit;">Ou, talvez, a ativa√ß√£o de neur√¥nios ocultos e de sa√≠da seja determinada n√£o apenas pela entrada atual na rede, mas tamb√©m pelas anteriores.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As redes neurais com esse tipo de comportamento vari√°vel no tempo s√£o conhecidas como redes neurais recorrentes, ou RNS. Existem v√°rias maneiras de formalizar matematicamente a descri√ß√£o informal do par√°grafo anterior. Voc√™ pode ter uma id√©ia deles lendo o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artigo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> da </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">Wikipedia</font></a><font style="vertical-align: inherit;"> . No momento da reda√ß√£o deste artigo, na vers√£o em ingl√™s do artigo, pelo menos 13 modelos diferentes s√£o descritos [no momento da tradu√ß√£o em 2019, j√° existem 18 / aprox.</font></font> transl.].<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mas, se deixarmos de lado os detalhes matem√°ticos, a ideia geral do RNS √© a presen√ßa de mudan√ßas din√¢micas na rede que ocorrem ao longo do tempo. E, sem surpresa, eles s√£o especialmente √∫teis para analisar dados ou processos que mudam ao longo do tempo. Esses dados e processos aparecem naturalmente em tarefas como an√°lise de fala ou linguagem natural. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uma das maneiras atuais de usar o RNS √© integrar melhor as redes neurais aos m√©todos tradicionais de representa√ß√£o de algoritmos, com conceitos como uma m√°quina de Turing e linguagens de programa√ß√£o comuns. No </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabalho de 2014</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O RNS foi desenvolvido, capaz de aceitar uma descri√ß√£o letra por letra de um programa python muito simples e prever o resultado de seu trabalho. Informalmente, a rede est√° aprendendo a "entender" certos programas python. </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O segundo trabalho de 2014</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> utilizou o RNS como ponto de partida para o desenvolvimento da neuromaquina de Turing (BDC). Este √© um computador universal, cuja estrutura inteira pode ser treinada usando descida gradiente. Eles treinaram seu BDC para criar algoritmos para v√°rias tarefas simples, como classifica√ß√£o ou c√≥pia.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Estes, √© claro, s√£o modelos de brinquedos muito simples. Aprender a executar um programa em python como o print (398345 + 42598) n√£o faz da rede neural um int√©rprete completo da linguagem! N√£o est√° claro o quanto essas id√©ias ser√£o mais fortes. No entanto, os resultados s√£o bastante interessantes. Historicamente, as redes neurais fizeram um bom trabalho ao reconhecer padr√µes que trope√ßavam nas abordagens algor√≠tmicas convencionais. E vice-versa, as abordagens algor√≠tmicas convencionais fazem um bom trabalho na resolu√ß√£o de problemas complexos para o NS. Hoje, ningu√©m est√° tentando implementar um servidor web ou um banco de dados baseado no NS! Seria √≥timo desenvolver modelos integrados que integram os pontos fortes da NS e das abordagens algor√≠tmicas tradicionais. O RNS e as id√©ias inspiradas por eles podem nos ajudar a fazer isso.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nos √∫ltimos anos, o RNS tem sido usado para resolver muitos outros problemas. Eles foram especialmente √∫teis no reconhecimento de fala. As abordagens baseadas em RNS </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">estabelecem registros</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para a qualidade do reconhecimento de fonemas. Eles tamb√©m foram </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">usados ‚Äã‚Äãpara desenvolver</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> modelos aprimorados da linguagem usada pelas pessoas. Modelos de linguagem aprimorados ajudam a reconhecer ambiguidades na fala que soam semelhantes. Um bom modelo de linguagem pode nos dizer que a frase "encaminhar para o infinito" √© muito mais prov√°vel do que a frase "encaminhar sem membros", embora pare√ßa semelhante. O RNS foi usado para obter conquistas recorde em determinados testes de idioma.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este trabalho √© parte do uso mais amplo de NS de todos os tipos, n√£o apenas do RNS, para resolver o problema do reconhecimento de fala. Por exemplo, uma abordagem baseada no GNS mostrou </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">excelentes resultados</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> no reconhecimento da fala cont√≠nua com um vocabul√°rio amplo. Outro </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sistema</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baseado em GNS </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">√© </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">implementado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> no sistema operacional Android do Google.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Falei um pouco sobre o que os RNCs s√£o capazes, mas n√£o expliquei como eles funcionam. </font><font style="vertical-align: inherit;">Voc√™ n√£o ficar√° surpreso ao saber que muitas das id√©ias do mundo das redes de distribui√ß√£o direta tamb√©m podem ser usadas no RNS. </font><font style="vertical-align: inherit;">Em particular, podemos treinar o RNS modificando a descida do gradiente e a propaga√ß√£o das costas na testa. </font><font style="vertical-align: inherit;">Muitas outras id√©ias usadas em redes de distribui√ß√£o direta, desde t√©cnicas de regulariza√ß√£o at√© fun√ß√µes de convolu√ß√£o e ativa√ß√£o e custo, tamb√©m ser√£o √∫teis. </font><font style="vertical-align: inherit;">Al√©m disso, muitas das id√©ias que desenvolvemos como parte do livro podem ser adaptadas para uso no RNS.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> M√≥dulos de mem√≥ria de longo prazo (DCT) </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dos problemas do RNS √© que os primeiros modelos eram muito dif√≠ceis de treinar, mais complicados do que o GNS. O motivo foram os problemas do gradiente inst√°vel, que discutimos no Cap√≠tulo 5. Lembre-se de que a manifesta√ß√£o usual desse problema era que o gradiente diminui o tempo todo ao se propagar pelas camadas na dire√ß√£o oposta. Isso diminui bastante o aprendizado das camadas iniciais. No RNS, esse problema se torna ainda pior, pois os gradientes se propagam n√£o apenas na dire√ß√£o oposta ao longo das camadas, mas tamb√©m na dire√ß√£o oposta no tempo. Se a rede funcionar por um longo per√≠odo, o gradiente pode se tornar extremamente inst√°vel e, com base nisso, ser√° muito dif√≠cil de aprender. Felizmente, uma ideia conhecida como m√≥dulos de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mem√≥ria de curto prazo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (DCT) de </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">longo prazo</font></a><font style="vertical-align: inherit;"> pode ser inclu√≠da no RNS </font><font style="vertical-align: inherit;">. Pela primeira vez, os m√≥dulos introduzidos</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hochreiter e Schmidguber em 1997</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , especificamente para ajudar a resolver o problema de um gradiente inst√°vel. </font><font style="vertical-align: inherit;">Os DCTs facilitam a obten√ß√£o de bons resultados na aprendizagem do RNS, e muitos trabalhos recentes (incluindo aqueles que eu j√° referenciei) usam o DCT ou id√©ias semelhantes.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Redes de confian√ßa profunda, modelos generativos e m√°quinas Boltzmann </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Atualmente, o interesse pela aprendizagem profunda ganhou um segundo f√¥lego em 2006, ap√≥s a publica√ß√£o de trabalhos ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) explicando como ensinar um tipo especial de NS chamado deep trust network (GDS). </font><font style="vertical-align: inherit;">A GDS por v√°rios anos influenciou o campo de pesquisa, mas sua popularidade come√ßou a declinar e as redes de distribui√ß√£o direta e os SNs recorrentes tornaram-se moda. </font><font style="vertical-align: inherit;">Apesar disso, algumas das propriedades do GDS os tornam muito interessantes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Primeiro, os GDSs s√£o um exemplo de modelo generativo. Em uma rede de distribui√ß√£o direta, especificamos ativa√ß√µes de entrada e elas determinam a ativa√ß√£o de neur√¥nios de caracter√≠sticas mais adiante na rede. O modelo generativo pode ser usado de maneira semelhante, mas voc√™ pode definir os valores dos neur√¥nios e executar a rede "na dire√ß√£o oposta", gerando os valores das ativa√ß√µes de entrada. Mais especificamente, um GDS treinado em imagens de d√≠gitos manuscritos pode gerar imagens semelhantes a d√≠gitos manuscritos (potencialmente e ap√≥s determinadas a√ß√µes). Em outras palavras, o GDM, em certo sentido, pode aprender a escrever. Nesse sentido, os modelos generativos s√£o semelhantes ao c√©rebro humano: eles n√£o podem apenas ler n√∫meros, mas tamb√©m escrev√™-los. </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">O</font></a><font style="vertical-align: inherit;"> famoso </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ditado de </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jeffrey Hinton</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">afirma que, para o reconhecimento de padr√µes, voc√™ primeiro precisa aprender a gerar imagens. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em segundo lugar, eles s√£o capazes de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aprender sem um professor</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e quase sem um professor. Por exemplo, ao treinar imagens, os GDSs podem aprender sinais √∫teis para entender outras imagens, mesmo se n√£o houver marcas nas imagens de treinamento. A capacidade de aprender sem um professor √© extremamente interessante, tanto do ponto de vista cient√≠fico fundamental quanto do pr√°tico - se for poss√≠vel que funcione bem o suficiente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dados todos esses pontos atraentes do GDS como modelos de aprendizado profundo, por que sua popularidade diminuiu? Em parte devido ao fato de outros modelos, como distribui√ß√£o direta e redes recorrentes, terem alcan√ßado resultados impressionantes, em particular, avan√ßos nas √°reas de reconhecimento de imagem e fala. N√£o √© de surpreender que esses modelos tenham recebido tanta aten√ß√£o e muito merecido. No entanto, uma conclus√£o desagrad√°vel segue disso. O mercado de id√©ias geralmente funciona de acordo com o esquema ‚Äúo vencedor ganha tudo‚Äù e quase toda a aten√ß√£o est√° voltada para o que h√° de mais moderno nesta √°rea agora. Pode ser extremamente dif√≠cil para as pessoas trabalharem em id√©ias atualmente impopulares, mesmo que seja √≥bvio que elas possam ser de interesse a longo prazo. Minha opini√£o pessoal √© que o GDS e outros modelos generativos merecem mais aten√ß√£o do que recebem.N√£o ficarei surpreso se o GDM ou modelo similar superar os modelos populares de hoje. Ler</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">este artigo √©</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para introdu√ß√£o ao campo do GDM. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este artigo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tamb√©m pode ser √∫til </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">N√£o se trata inteiramente do GDM, mas tem muitas coisas √∫teis sobre as m√°quinas limitadas da Boltzmann, um componente essencial do GDM.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Outras ideias </font></font></h3><br>  O que mais est√° acontecendo no campo da Assembl√©ia Nacional e da Defesa Civil?  Uma enorme quantidade de trabalho interessante.  Entre as √°reas ativas de pesquisa est√° o uso do NS para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">processar</a> <a href="">linguagem</a> natural, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tradu√ß√£o autom√°tica</a> e aplica√ß√µes mais inesperadas, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">inform√°tica musical</a> .  Existem muitas outras √°reas.  Em muitos casos, depois de ler este livro, voc√™ ser√° capaz de entender trabalhos recentes, embora, √© claro, seja necess√°rio preencher algumas lacunas de conhecimento. <br><br>  Terminarei esta se√ß√£o mencionando um trabalho particularmente interessante.  Ela combina redes convolucionais profundas com uma t√©cnica chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprendizado por</a> refor√ßo para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprender a jogar videogame</a> (e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">outro artigo</a> sobre isso).  A id√©ia √© usar uma rede convolucional para simplificar os dados de pixel da tela do jogo, transform√°-los em um conjunto mais simples de atributos que podem ser usados ‚Äã‚Äãpara tomar decis√µes sobre outras a√ß√µes: "v√° para a esquerda", "v√° para a direita", "atire" e etc.  Particularmente interessante √© que uma rede aprendeu muito bem a jogar sete videogames cl√°ssicos diferentes, √† frente dos especialistas em tr√™s deles.  Isso, √© claro, parece um truque, e o trabalho foi anunciado ativamente sob o t√≠tulo "Jogando jogos da Atari com aprendizado por refor√ßo".  No entanto, por tr√°s de um brilho superficial, vale a pena considerar o fato de que o sistema usa dados brutos de pixel - ele nem conhece as regras do jogo - e, com base nisso, √© treinado para tomar decis√µes de boa qualidade em v√°rias situa√ß√µes muito diferentes e muito competitivas, cada uma com seu pr√≥prio conjunto complexo de regras.  Muito bom. <br><br><h2>  O futuro das redes neurais </h2><br><h3>  Interfaces de inten√ß√£o do usu√°rio </h3><br>  Numa piada antiga, um professor impaciente diz a um aluno confuso: "N√£o ou√ßa minhas palavras, ou√ßa o que quero dizer".  Historicamente, os computadores geralmente n√£o entendiam, como um aluno confuso, o que um usu√°rio significa.  No entanto, a situa√ß√£o est√° mudando.  Ainda me lembro da primeira vez que fiquei surpreso ao escrever um pedido por engano ao Google, e o mecanismo de pesquisa me disse: "Voc√™ quis dizer [pedido correto]?"  O diretor do Google, Larry Page, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">certa vez descreveu o</a> mecanismo de pesquisa perfeito como um sistema que entende exatamente o que suas consultas significam e fornece exatamente o que voc√™ deseja. <br><br>  Essa √© a id√©ia de uma interface baseada na inten√ß√£o do usu√°rio.  Nele, em vez de responder a solicita√ß√µes literais do usu√°rio, o mecanismo de pesquisa usar√° o MO para atender a uma vaga solicita√ß√£o do usu√°rio, entender exatamente o que isso significa e agir com base nisso. <br><br>  A id√©ia de uma interface baseada na inten√ß√£o do usu√°rio pode ser aplicada mais amplamente do que apenas na pesquisa.  Nas pr√≥ximas d√©cadas, milhares de empresas criar√£o produtos nos quais o MO ser√° usado para interfaces do usu√°rio, referindo-se com calma a a√ß√µes imprecisas do usu√°rio e adivinhando suas verdadeiras inten√ß√µes.  J√° vimos exemplos iniciais dessas interfaces baseadas em inten√ß√£o: Apple Siri;  Wolfram Alpha;  IBM Watson  sistemas que marcam automaticamente fotos e v√≠deos e muito mais. <br><br>  A maioria deles ir√° falhar.  O desenvolvimento de interfaces √© uma coisa complicada e suspeito que, em vez de interfaces inspiradoras, muitas empresas criar√£o interfaces sem vida com base no MO.  O melhor MO do mundo n√£o o ajudar√° se sua interface for ruim.  No entanto, alguns produtos ter√£o sucesso.  Com o tempo, isso levar√° a uma mudan√ßa s√©ria no nosso relacionamento com os computadores.  H√° pouco tempo, por exemplo, em 2005, os usu√°rios tinham como certo que interagir com computadores requer alta precis√£o.  A natureza literal do computador serviu para espalhar a ideia de que os computadores s√£o muito literais;  o √∫nico ponto e v√≠rgula esquecido poderia mudar completamente a natureza da intera√ß√£o com o computador.  Mas acredito que nas pr√≥ximas d√©cadas desenvolveremos v√°rias interfaces de sucesso com base na inten√ß√£o do usu√°rio, e isso mudar√° radicalmente nossas expectativas ao trabalhar com computadores. <br><br><h3>  Aprendizado de m√°quina, ci√™ncia de dados e o c√≠rculo imaculado de inova√ß√£o </h3><br>  Obviamente, o MO n√£o √© usado apenas para criar interfaces com base na inten√ß√£o do usu√°rio.  Outra aplica√ß√£o interessante do MO √© a ci√™ncia de dados, onde √© usado para procurar "desconhecidos conhecidos" ocultos nos dados obtidos.  Esse j√° √© um t√≥pico da moda, sobre o qual muitos artigos foram escritos; portanto, n√£o estenderei isso por muito tempo.  Quero mencionar uma conseq√º√™ncia dessa moda, que nem sempre √© notada: a longo prazo, √© poss√≠vel que a maior inova√ß√£o na regi√£o de Moscou n√£o seja apenas uma inova√ß√£o conceitual.  O maior avan√ßo ser√° que a pesquisa no campo da MO se tornar√° lucrativa atrav√©s do uso de dados na ci√™ncia e em outras √°reas.  Se uma empresa puder investir um d√≥lar na pesquisa de MO e obter rapidamente um d√≥lar e dez centavos de receita, muito dinheiro ser√° despejado na regi√£o do MO.  Em outras palavras, MO √© o mecanismo que nos leva ao surgimento de v√°rios grandes mercados e √°reas de crescimento tecnol√≥gico.  Como resultado, aparecer√£o grandes equipes de pessoas especialistas neste campo que ter√£o acesso a recursos incr√≠veis.  Isso mover√° ainda mais o MO, criar√° ainda mais mercados e oportunidades, que ser√£o o c√≠rculo imaculado de inova√ß√£o. <br><br><h3>  O papel das redes neurais e da aprendizagem profunda </h3><br>  Descrevi o MO em termos gerais como uma maneira de criar novas oportunidades para o desenvolvimento de tecnologia.  Qual ser√° o papel espec√≠fico da Assembl√©ia Nacional e da Sociedade Civil em tudo isso? <br><br>  Para responder √† pergunta, √© √∫til recorrer √† hist√≥ria.  Na d√©cada de 1980, houve um alegre reavivamento ativo e otimismo associado √†s redes neurais, especialmente ap√≥s a populariza√ß√£o da propaga√ß√£o traseira.  Mas a recupera√ß√£o diminuiu e, nos anos 90, o bast√£o MO foi transferido para outras tecnologias, por exemplo, o m√©todo do vetor de suporte.  Hoje, a Assembl√©ia Nacional est√° novamente a cavalo, estabelecendo todos os tipos de recordes e superando muitos rivais em v√°rios problemas.  Mas quem garante que amanh√£ n√£o ser√° desenvolvida uma nova abordagem que ofusque novamente a NA?  Ou, talvez, o progresso no campo da Assembl√©ia Nacional comece a parar e nada os substitua? <br><br>  Portanto, √© muito mais f√°cil pensar no futuro do Minist√©rio da Defesa como um todo do que especificamente na Assembl√©ia Nacional.  Parte do problema √© que compreendemos muito mal a Assembl√©ia Nacional.  Por que o NS √© t√£o bom em compilar informa√ß√µes?  Como eles evitam a reciclagem t√£o bem, dado o grande n√∫mero de op√ß√µes?  Por que a descida do gradiente estoc√°stico funciona t√£o bem?  Qu√£o bem o NS funcionar√° ao dimensionar conjuntos de dados?  Por exemplo, se expandirmos a base do ImageNet 10 vezes, o desempenho do NS melhorar√° mais ou menos que a efic√°cia de outras tecnologias MO?  Todas essas s√£o quest√µes simples e fundamentais.  E at√© agora temos uma compreens√£o muito pobre das respostas a essas perguntas.  Nesse sentido, √© dif√≠cil dizer qual o papel da Assembl√©ia Nacional no futuro da regi√£o de Moscou. <br><br>  Farei uma previs√£o: acho que o GO n√£o vai a lugar nenhum.  A capacidade de estudar hierarquias de conceitos, de construir diferentes camadas de abstra√ß√µes, aparentemente, √© fundamental para o conhecimento do mundo.  Isso n√£o significa que as redes GO de amanh√£ n√£o ser√£o radicalmente diferentes das de hoje.  Podemos encontrar grandes mudan√ßas em suas partes constituintes, arquiteturas ou algoritmos de aprendizado.  Essas mudan√ßas podem ser dram√°ticas o suficiente para pararmos de considerar os sistemas resultantes como redes neurais.  No entanto, eles ainda se envolver√£o em defesa civil. <br><br><h3>  NS e GO logo levar√£o ao surgimento de intelig√™ncia artificial? </h3><br>  Neste livro, focamos no uso do NS na solu√ß√£o de problemas espec√≠ficos, por exemplo, classifica√ß√£o de imagens.  Vamos expandir nossas consultas: e os computadores pensantes de uso geral?  A Assembl√©ia Nacional e a Sociedade Civil podem nos ajudar a resolver o problema de criar uma IA de uso geral?  E se sim, dada a alta velocidade do progresso no campo da defesa civil, veremos o surgimento da IA ‚Äã‚Äãno futuro pr√≥ximo? <br><br>  Uma resposta detalhada a essa pergunta exigiria um livro separado.  Em vez disso, deixe-me oferecer uma observa√ß√£o com base na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lei de Conway</a> : <br><blockquote>  As organiza√ß√µes que projetam sistemas s√£o limitadas a um design que copia a estrutura de comunica√ß√£o desta organiza√ß√£o. </blockquote><br><br>  Ou seja, por exemplo, a lei de Conway afirma que o layout da aeronave Boeing 747 refletir√° a estrutura expandida da Boeing e de seus contratados no momento em que o modelo 747 estava sendo desenvolvido. Ou outro exemplo simples e concreto: considere uma empresa desenvolvendo software complexo.  Se o painel de controle do software deve ser conectado ao algoritmo MO, o designer do painel deve se comunicar com o especialista em MO da empresa.  A lei de Conway simplesmente formaliza essa observa√ß√£o. <br><br>  Pela primeira vez, quando ouviram a lei de Conway, muitas pessoas dizem: "Isso n√£o √© uma evid√™ncia comum?" Ou "√â mesmo?"  Come√ßarei com uma observa√ß√£o sobre sua infidelidade.  Vamos pensar: como a contabilidade da Boeing se reflete no modelo 747?  E o departamento de limpeza?  Uma equipe de alimenta√ß√£o?  A resposta √© que essas partes da organiza√ß√£o provavelmente n√£o aparecem em nenhum outro lugar do Esquema 747 explicitamente.  Portanto, voc√™ precisa entender que a lei de Conway se aplica apenas √†s partes da organiza√ß√£o que est√£o diretamente envolvidas em design e engenharia. <br><br>  E a observa√ß√£o sobre banalidade e evid√™ncia?  Talvez seja assim, mas acho que n√£o, porque as organiza√ß√µes geralmente trabalham para rejeitar a lei de Conway.  As equipes que desenvolvem novos produtos geralmente s√£o infladas devido ao n√∫mero excessivo de funcion√°rios ou, inversamente, √† falta de uma pessoa com conhecimento cr√≠tico.  Pense em todos os produtos com recursos in√∫teis e complicados.  Ou pense em produtos com falhas √≥bvias - por exemplo, com uma interface de usu√°rio terr√≠vel.  Nas duas classes de programas, os problemas geralmente surgem devido a uma incompatibilidade entre a equipe necess√°ria para lan√ßar um bom produto e a equipe que realmente se reuniu.  A lei de Conway pode ser √≥bvia, mas isso n√£o significa que as pessoas n√£o possam ignor√°-la regularmente. <br><br>  A lei de Conway √© aplic√°vel ao design e cria√ß√£o de sistemas nos casos em que, desde o in√≠cio, imaginamos em que partes constituintes o produto ser√° composto e como faz√™-lo.  Ela n√£o pode ser aplicada diretamente ao desenvolvimento da IA, uma vez que a IA ainda n√£o √© uma tarefa: n√£o sabemos em que partes ela consiste.  N√£o temos certeza do que perguntas b√°sicas voc√™ pode fazer.  Em outras palavras, no momento, a IA √© mais um problema da ci√™ncia do que engenheiros.  Imagine que voc√™ precisa come√ßar a desenvolver o 747¬∫ sem saber nada sobre motores a jato ou os princ√≠pios da aerodin√¢mica.  Voc√™ n√£o saberia quais especialistas contratar em sua organiza√ß√£o.  Como escreveu Werner von Braun, "pesquisa b√°sica √© o que estou fazendo quando n√£o sei o que estou fazendo".  Existe uma vers√£o da lei de Conway que se aplica a tarefas mais relacionadas √† ci√™ncia do que engenheiros? <br><br>  Para encontrar a resposta para essa pergunta, vamos relembrar a hist√≥ria da medicina.  Nos primeiros dias, a medicina era o dom√≠nio de praticantes, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Galeno</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hip√≥crates</a> , que estudavam todo o corpo humano.  Mas com o crescimento do volume de nosso conhecimento, tive que me especializar.  Descobrimos muitas id√©ias profundas - lembre-se da teoria microbiana das doen√ßas, ou compreenda o princ√≠pio da opera√ß√£o de anticorpos, ou o fato de que o cora√ß√£o, pulm√µes, veias e art√©rias formam o sistema cardiovascular.  Tais id√©ias profundas formaram a base para disciplinas mais restritas, como epidemiologia, imunologia e o ac√∫mulo de √°reas sobrepostas relacionadas ao sistema cardiovascular.  Foi assim que a estrutura do nosso conhecimento formou a estrutura social da medicina.  Isso √© especialmente not√°vel no caso da imunologia: a id√©ia da exist√™ncia de um sistema imunol√≥gico digno de um estudo separado era muito trivial.  Portanto, temos todo um campo da medicina - com especialistas, confer√™ncias, pr√™mios etc. - organizados em torno de algo que n√£o √© apenas invis√≠vel, mas talvez nem mesmo separado. <br><br>  Esse desenvolvimento de eventos foi repetido com frequ√™ncia em muitas disciplinas cient√≠ficas estabelecidas: n√£o apenas na medicina, mas tamb√©m na f√≠sica, matem√°tica, qu√≠mica e outras.  As regi√µes nascem monol√≠ticas, tendo apenas algumas id√©ias profundas em estoque.  Os primeiros especialistas s√£o capazes de cobrir todos eles.  Mas com o tempo, a solidez muda.  Descobrimos muitas novas id√©ias profundas, e h√° muitas delas para que algu√©m possa realmente dominar todas elas.  Como resultado, a estrutura social da regi√£o est√° sendo reorganizada e dividida, concentrando-se em torno dessas id√©ias.  Em vez de um mon√≥lito, temos campos divididos por campos divididos por campos - uma estrutura social complexa e recursiva que se refere a si mesma, cuja organiza√ß√£o reflete as conex√µes entre as id√©ias mais profundas.  √â assim que a estrutura do nosso conhecimento forma a organiza√ß√£o social da ci√™ncia.  No entanto, essa forma social, por sua vez, limita e ajuda a determinar o que podemos detectar.  Este √© o an√°logo cient√≠fico da lei de Conway. <br><br>  Mas o que tudo isso tem a ver com aprendizado profundo ou IA? <br><br>  Bem, desde os primeiros dias do desenvolvimento da IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">, houve um debate de</a> que tudo ser√° "n√£o muito complicado, gra√ßas √† nossa super arma", ou "super arma n√£o ser√° suficiente".  O aprendizado profundo √© o exemplo mais recente de uma super arma que foi usada nas disputas que eu j√° vi.  Nas primeiras vers√µes de tais disputas, a l√≥gica era usada, ou Prolog, ou sistemas especializados, ou alguma outra tecnologia, que era a mais poderosa.  O problema com essas disputas √© que elas n√£o oferecem a oportunidade de dizer exatamente o qu√£o poderoso ser√° qualquer um dos candidatos a super armas.  Obviamente, passamos um cap√≠tulo inteiro revisando evid√™ncias de que a defesa civil pode resolver problemas extremamente complexos.  Definitivamente, parece muito interessante e promissor.  Mas esse foi o caso de sistemas como Prolog, Eurisko ou sistemas especialistas.  Portanto, apenas o fato de um conjunto de id√©ias parecer promissor n√£o significa nada de especial.  Como sabemos que o GO √© realmente diferente dessas id√©ias iniciais?  Existe uma maneira de medir o qu√£o poderoso e promissor √© um conjunto de id√©ias?  Segue-se da lei de Conway que podemos usar a complexidade da estrutura social associada a essas id√©ias como uma m√©trica bruta e heur√≠stica. <br><br>  Portanto, temos duas perguntas.  Primeiro, qu√£o poderoso √© o conjunto de id√©ias relacionadas √† sociedade civil de acordo com essa m√©trica de complexidade social?  Em segundo lugar, qu√£o poderosa √© uma teoria para criar uma IA de uso geral? <br><br>  Sobre a primeira pergunta: quando olhamos para a defesa civil hoje, esse campo parece interessante e em r√°pido desenvolvimento, mas relativamente monol√≠tico.  Tem v√°rias id√©ias profundas e v√°rias grandes confer√™ncias s√£o realizadas, algumas das quais se sobrep√µem muito.  O trabalho no trabalho utiliza o mesmo conjunto de id√©ias: descida estoc√°stica do gradiente (ou seu equivalente pr√≥ximo) para otimizar a fun√ß√£o de custo.  √â √≥timo que essas id√©ias tenham tanto sucesso.  O que n√£o estamos observando at√© agora √© um grande n√∫mero de √°reas menores bem desenvolvidas, cada uma das quais exploraria seu pr√≥prio conjunto de id√©ias profundas, que moveria a sociedade civil em v√°rias dire√ß√µes.  Portanto, de acordo com a m√©trica de complexidade social, aprendizado profundo, sinto muito pelo trocadilho, enquanto continua sendo uma √°rea de pesquisa muito superficial.  Uma pessoa ainda √© capaz de dominar a maioria das id√©ias profundas dessa √°rea. <br><br>  Na segunda pergunta: quanto ser√° necess√°rio um conjunto de id√©ias complexo e poderoso para criar a IA?  Naturalmente, a resposta ser√°: ningu√©m sabe ao certo.  Mas no posf√°cio do livro, estudei algumas das evid√™ncias existentes sobre esse assunto.  Conclu√≠ que, mesmo de acordo com estimativas otimistas, a cria√ß√£o da IA ‚Äã‚Äãexigir√° muitas, muitas id√©ias profundas.  De acordo com a lei de Conway, para chegar a esse ponto, precisamos ver o surgimento de muitas disciplinas inter-relacionadas, com uma estrutura complexa e inesperada que reflete a estrutura de nossas id√©ias mais profundas.  Ainda n√£o observamos uma estrutura social t√£o complexa ao usar o NS e a defesa civil.  Portanto, acredito que, pelo menos, estamos a v√°rias d√©cadas de usar o GO para desenvolver IA de uso geral. <br><br>  Dediquei muito esfor√ßo √† cria√ß√£o de um argumento especulativo, o que, talvez, parece bastante √≥bvio e n√£o leva a uma certa conclus√£o.  Isso certamente decepcionar√° as pessoas que amam a certeza.  Conhe√ßo muitas pessoas on-line que anunciam publicamente suas opini√µes muito definidas e confiantes sobre a IA, geralmente baseadas em argumentos inst√°veis ‚Äã‚Äãe evid√™ncias inexistentes.  Posso dizer honestamente: acho que √© muito cedo para julgar.  Como na velha piada: se voc√™ perguntar a um cientista quanto mais precisamos esperar por qualquer descoberta, e ele disser ‚Äú10 anos‚Äù (ou mais), ent√£o, na verdade, ele quer dizer ‚Äún√£o fa√ßo ideia‚Äù.  Antes do advento da IA, como no caso da fus√£o nuclear controlada e de algumas outras tecnologias, ‚Äú10 anos‚Äù permaneceram por mais de 60 anos.  Por outro lado, o que definitivamente temos no campo da defesa civil √© uma tecnologia eficaz, cujos limites ainda n√£o descobrimos e muitas tarefas fundamentais abertas.  E abre incr√≠veis oportunidades criativas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt464039/">https://habr.com/ru/post/pt464039/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt464021/index.html">O que √© altern√¢ncia de recursos ou como se livrar de morsas excruciantes e galhos de vida longa?</a></li>
<li><a href="../pt464023/index.html">"Fundamentos da programa√ß√£o" definido para um curso gratuito com exemplos em JavaScript</a></li>
<li><a href="../pt464027/index.html">Como sobreviver ao conte√∫do na era da explos√£o de informa√ß√µes</a></li>
<li><a href="../pt464031/index.html">‚ÄúAchados de um Audioman√≠aco‚Äù: placas de som como uma maneira de mergulhar na atmosfera de uma cidade desconhecida</a></li>
<li><a href="../pt464037/index.html">Not√≠cias do mundo do OpenStreetMap n¬∫ 472 (30/07/2019 - 05.08.2019)</a></li>
<li><a href="../pt464041/index.html">Por que os melhores pilotos de ca√ßa costumam ter grandes problemas</a></li>
<li><a href="../pt464043/index.html">Hist√≥ria do conversor Ethernet-CAN</a></li>
<li><a href="../pt464045/index.html">Como corri quase em tempo real em 1997</a></li>
<li><a href="../pt464053/index.html">Nota: algoritmo de sele√ß√£o e rota√ß√£o de trilhas</a></li>
<li><a href="../pt464055/index.html">Estudamos os dados coletados pelo Xiaomi Mi Band para o ano</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👵🏽 📻 👨🏻‍💻 Jet Distributor ok.ru/music 🤰🏼 💆 🧒🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich arbeite in einem Team der Odnoklassniki-Plattform und werde heute über die Architektur, das Design und die Implementierungsdetails des Musikvertri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jet Distributor ok.ru/music</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/434206/"><img src="https://habrastorage.org/webt/m8/yb/sn/m8ybsnu0c1bqakexungs-hkisui.png"><br><br>  Ich arbeite in einem Team der Odnoklassniki-Plattform und werde heute über die Architektur, das Design und die Implementierungsdetails des Musikvertriebsdienstes sprechen. <br><a name="habracut"></a><br><blockquote>  Der Artikel ist eine Abschrift des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Berichts</a> bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Joker 2018</a> . </blockquote><br><h1>  Einige Statistiken </h1><br>  Zunächst ein paar Worte zu OK.  Dies ist ein gigantischer Dienst, der von mehr als 70 Millionen Benutzern genutzt wird.  Sie werden von 7.000 Autos in 4 Rechenzentren bedient.  Vor kurzem haben wir die Verkehrsmarke mit 2 Tb / s durchbrochen, ohne die zahlreichen CDN-Standorte zu berücksichtigen.  Wir schöpfen das Maximum aus unserer Hardware heraus. Die am meisten ausgelasteten Dienste bedienen bis zu 100.000 Anforderungen pro Sekunde von einem Quad-Core-Knoten.  Darüber hinaus sind fast alle Dienste in Java geschrieben. <br><br>  Es gibt viele Abschnitte in OK, einer der beliebtesten ist "Musik".  Darin können Benutzer ihre Titel hochladen, Musik in unterschiedlicher Qualität kaufen und herunterladen.  Die Sektion hat einen wunderbaren Katalog, ein Empfehlungssystem, ein Radio und vieles mehr.  Aber der Hauptzweck des Dienstes ist natürlich das Abspielen von Musik. <br><br>  Der Musikvertreiber ist für die Übertragung von Daten an Benutzer-Player und mobile Anwendungen verantwortlich.  Sie können es im Webinspektor abrufen, wenn Sie sich die Anforderungen an die Domain musicd.mycdn.me ansehen.  Die Distributor-API ist extrem einfach.  Es antwortet auf <code>GET</code> HTTP-Anforderungen und gibt den angeforderten Trackbereich aus. <br><br><img src="https://habrastorage.org/webt/j9/va/ze/j9vazesvr2fuqtpvhec0uj7gbmq.png"><br><br>  In der Spitze erreicht die Last über eine halbe Million Verbindungen 100 Gbit / s.  Tatsächlich ist der Musikdistributor ein Caching-Frontend vor unserem internen Track-Repository, das auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">One Blob Storage</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">One Cold Storage</a> basiert und Petabyte an Daten enthält. <br><br>  Da ich über Caching gesprochen habe, schauen wir uns die Wiedergabestatistiken an.  Wir sehen ein ausgeprägtes TOP. <br><br><img src="https://habrastorage.org/webt/q6/jv/pc/q6jvpcopw2t0xt29sl84lwp1gkg.png"><br><br>  Ungefähr 140 Titel decken 10% aller Spiele pro Tag ab.  Wenn unser Cache-Server einen Cache-Treffer von mindestens 90% haben soll, benötigen wir eine halbe Million Tracks, um in ihn zu passen.  95% - fast eine Million Tracks. <br><br><h1>  Händleranforderungen </h1><br>  Welche Ziele haben wir uns bei der Entwicklung der nächsten Version des Distributors gesetzt? <br><br>  Wir wollten, dass ein Knoten 100.000 Verbindungen aufnehmen kann.  Und dies sind langsame Client-Verbindungen: eine Reihe von Browsern und mobilen Anwendungen über Netzwerke mit unterschiedlichen Geschwindigkeiten.  Gleichzeitig muss der Service wie alle unsere Systeme skalierbar und fehlertolerant sein. <br><br>  Zunächst müssen wir die Bandbreite des Clusters skalieren, um mit der wachsenden Beliebtheit des Dienstes Schritt zu halten und immer mehr Datenverkehr bereitstellen zu können.  Es ist auch erforderlich, die Gesamtkapazität des Cluster-Cache skalieren zu können, da der Cache-Treffer und der Prozentsatz der Anforderungen, die in den Speicher von Tracks fallen, direkt davon abhängen. <br><br>  Heutzutage ist es notwendig, jedes verteilte System horizontal skalieren zu können, dh Maschinen und Rechenzentren hinzuzufügen.  Wir wollten aber auch eine vertikale Skalierung implementieren.  Unser typischer moderner Server enthält 56 Kerne, 0,5 bis 1 TB RAM, eine 10- oder 40-GB-Netzwerkschnittstelle und ein Dutzend SSD-Festplatten. <br><br>  Wenn man von horizontaler Skalierbarkeit spricht, ergibt sich ein interessanter Effekt: Wenn Sie Tausende von Servern und Zehntausende von Festplatten haben, bricht ständig etwas zusammen.  Festplattenfehler sind eine Routine, wir ändern sie bei 20-30 Stück pro Woche.  Und Serverausfälle überraschen niemanden: 2-3 Autos pro Tag werden ersetzt.  Ich musste mich auch mit Rechenzentrumsausfällen befassen, zum Beispiel gab es 2018 drei solcher Ausfälle, und dies ist wahrscheinlich nicht das letzte Mal. <br><br>  Warum bin ich das alles?  Wenn wir Systeme entwerfen, wissen wir, dass sie früher oder später kaputt gehen werden.  Daher untersuchen wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die</a> Fehlerszenarien aller Systemkomponenten immer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sorgfältig</a> .  Die Hauptmethode zur Behebung von Fehlern ist die Datenreplikation: Mehrere Kopien von Daten werden auf verschiedenen Knoten gespeichert. <br><br>  Wir reservieren auch Netzwerkbandbreite.  Dies ist wichtig, da bei einem Ausfall einer Komponente des Systems die Last auf den verbleibenden Komponenten nicht zusammenbrechen kann. <br><br><h1>  Ausbalancieren </h1><br>  Zuerst müssen Sie lernen, wie Sie Benutzerabfragen zwischen Rechenzentren ausgleichen und dies automatisch tun.  Dies ist der Fall, wenn Sie Netzwerkarbeiten durchführen müssen oder wenn das Rechenzentrum ausgefallen ist.  Ein Ausgleich ist jedoch auch in Rechenzentren erforderlich.  Und wir möchten Anforderungen nicht zufällig, sondern mit Gewichten auf Knoten verteilen.  Zum Beispiel, wenn wir eine neue Version eines Dienstes hochladen und einen neuen Knoten reibungslos in Rotation versetzen möchten.  Gewichte helfen auch beim Stresstest sehr: Wir erhöhen das Gewicht und belasten den Knoten viel stärker, um die Grenzen seiner Fähigkeiten zu verstehen.  Und wenn ein Knoten unter Last ausfällt, setzen wir das Gewicht schnell auf Null und entfernen es mithilfe von Ausgleichsmechanismen aus der Rotation. <br><br>  Wie sieht der Anforderungspfad vom Benutzer zum Knoten aus, der die Daten unter Berücksichtigung des Ausgleichs zurückgibt? <br><br><img src="https://habrastorage.org/webt/uu/tz/uf/uutzuf3bnfpetnns91ca-rcf5mc.png"><br><br>  Der Benutzer meldet sich über die Website oder die mobile Anwendung an und erhält die URL des Titels: <br><br> <code>musicd.mycdn.me/v0/stream?id=...</code> <br> <br>  Um die IP-Adresse vom Hostnamen in der URL zu erhalten, kontaktiert der Client unser GSLB-DNS, das alle unsere Rechenzentren und CDN-Sites kennt.  GSLB DNS gibt dem Client die IP-Adresse des Balancers eines der Rechenzentren und der Client stellt eine Verbindung zu diesem her.  Der Balancer kennt alle Knoten in den Rechenzentren und deren Gewicht.  Es stellt im Namen des Benutzers eine Verbindung zu einem der Knoten her.  Wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwenden N4Ware-basierte L4-Balancer</a> .  Noda gibt die Benutzerdaten direkt unter Umgehung des Balancers.  Bei Diensten wie einem Distributor ist der ausgehende Datenverkehr erheblich höher als der eingehende. <br><br>  Wenn ein Rechenzentrum abstürzt, erkennt GSLB DNS dies und entfernt es schnell aus der Rotation: Es gibt den Benutzern nicht mehr die IP-Adresse des Balancers dieses Rechenzentrums.  Wenn ein Knoten im Rechenzentrum ausfällt, wird sein Gewicht zurückgesetzt und der Balancer im Rechenzentrum sendet keine Anforderungen mehr an ihn. <br><br>  Betrachten Sie nun das Ausgleichen von Tracks nach Knoten in einem Rechenzentrum.  Wir werden Rechenzentren als unabhängige autonome Einheiten betrachten, von denen jede leben und arbeiten wird, selbst wenn alle anderen gestorben sind.  Die Tracks müssen gleichmäßig über die Maschinen verteilt sein, damit keine Lastverzerrungen auftreten, und sie müssen auf verschiedene Knoten repliziert werden.  Wenn ein Knoten ausfällt, sollte die Last gleichmäßig auf die verbleibenden Knoten verteilt werden. <br><br>  Dieses Problem kann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf verschiedene Arten gelöst werden</a> .  Wir haben uns für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">konsequentes Hashing entschieden</a> .  Wir wickeln den gesamten möglichen Bereich von Hashes von Spurkennungen in einen Ring ein, und dann wird jede Spur an einem Punkt auf diesem Ring angezeigt.  Dann verteilen wir die Ringbereiche mehr oder weniger gleichmäßig auf die Knoten im Cluster.  Die Knoten, in denen die Spur gespeichert wird, werden ausgewählt, indem die Spuren zu einem Punkt auf dem Ring gehasht und im Uhrzeigersinn bewegt werden. <br><br><img src="https://habrastorage.org/webt/qr/ty/xf/qrtyxfbchjhlp5taqfs0fbicnk0.jpeg"><br><br>  Ein solches Schema hat jedoch einen Nachteil: Wenn beispielsweise der Knoten N2 ausfällt, fällt seine gesamte Last auf die nächste Replik im Ring - N3.  Und wenn es keine doppelte Leistungsspanne gibt - und dies ist wirtschaftlich nicht gerechtfertigt -, wird der zweite Knoten höchstwahrscheinlich auch eine schlechte Zeit haben.  N3 mit hoher Wahrscheinlichkeit wird sich entwickeln, die Last wird auf N4 gehen und so weiter - es wird einen Kaskadenfehler entlang des gesamten Rings geben. <br><br>  Dieses Problem kann durch Erhöhen der Anzahl der Replikate gelöst werden, aber dann nimmt die gesamte nutzbare Kapazität des Clusters im Ring ab.  Deshalb machen wir es anders.  Bei gleicher Anzahl von Knoten ist der Ring in eine wesentlich größere Anzahl von Bereichen unterteilt, die zufällig über den Ring verteilt sind.  Repliken für die Spur werden gemäß dem obigen Algorithmus ausgewählt. <br><br><img src="https://habrastorage.org/webt/kc/uf/5-/kcuf5-1mmekp60d5emkp5ckkgps.png"><br><br>  Im obigen Beispiel ist jeder Knoten für zwei Bereiche verantwortlich.  Wenn einer der Knoten ausfällt, liegt seine gesamte Last nicht auf dem nächsten Knoten im Ring, sondern wird auf die beiden anderen Knoten des Clusters verteilt. <br><br>  Der Ring wird basierend auf einem kleinen Satz von Parametern algorithmisch berechnet und an jedem Knoten bestimmt.  Das heißt, wir speichern es nicht in einer Art Konfiguration.  Wir haben mehr als hunderttausend dieser Bereiche in der Produktion, und im Falle eines Ausfalls eines der Knoten wird die Last absolut gleichmäßig auf alle anderen lebenden Knoten verteilt. <br><br>  Wie sieht die Rückspur für den Benutzer in einem solchen System mit konsistentem Hashing aus? <br><br>  Der Benutzer gelangt über den L4-Balancer zu einem zufälligen Knoten.  Die Knotenauswahl ist zufällig, da der Balancer nichts über die Topologie weiß.  Aber dann weiß jedes Replikat im Cluster davon.  Der Knoten, der die Anforderung empfangen hat, bestimmt, ob es sich um eine Replik der angeforderten Spur handelt.  Wenn nicht, wechselt es mit einem der Replikate in den Proxy-Modus, stellt eine Verbindung zu ihm her und sucht in seinem lokalen Speicher nach Daten.  Wenn der Track nicht vorhanden ist, zieht das Replikat ihn aus dem Track-Speicher, speichert ihn im lokalen Speicher und gibt den Proxy, der die Daten an den Benutzer weiterleitet. <br><br><img src="https://habrastorage.org/webt/c5/pu/wl/c5puwlig-lfxy20leny4y4utqig.png"><br><br>  Wenn das Laufwerk im Replikat ausfällt, werden die Daten aus dem Speicher direkt an den Benutzer übertragen.  Wenn das Replikat fehlschlägt, kennt der Proxy alle anderen Replikate für diesen Track. Er stellt eine Verbindung zu einem anderen Live-Replikat her und empfängt Daten von diesem.  Wir garantieren also, dass ein Benutzer, der einen Track anfordert und mindestens ein Replikat lebt, eine Antwort erhält. <br><br><h1>  Wie funktioniert ein Knoten? </h1><br><img src="https://habrastorage.org/webt/2m/up/ob/2mupob-rqyqsbic50lc-qn2xwqe.png"><br><br>  Ein Knoten ist eine Pipeline aus einer Reihe von Phasen, durch die die Anforderung eines Benutzers geleitet wird.  Zunächst geht die Anfrage an eine externe API (wir senden alles über HTTPS).  Dann wird die Anfrage validiert - Signaturen werden verifiziert.  Dann werden bei Bedarf IDv3-Tags erstellt, beispielsweise beim Kauf eines Tracks.  Die Anforderung geht an die Routing-Phase, in der anhand der Clustertopologie festgelegt wird, wie die Daten zurückgegeben werden: Entweder ist der aktuelle Knoten eine Replik für diese Spur, oder wir werden von einem anderen Knoten aus einen Proxy erstellen.  Im zweiten Fall stellt der Knoten über den Proxy-Client eine Verbindung zum Replikat über die interne HTTP-API her, ohne die Signaturen zu überprüfen.  Das Replikat sucht nach Daten im lokalen Speicher. Wenn es eine Spur findet, gibt es diese von seiner Festplatte ab.  Wenn dies nicht der Fall ist, werden Tracks aus dem Speicher abgerufen, zwischengespeichert und ausgegeben. <br><br><h1>  Knotenlast </h1><br>  Lassen Sie uns abschätzen, welche Last ein Knoten in dieser Konfiguration halten soll.  Lassen Sie uns drei Rechenzentren mit jeweils vier Knoten haben. <br><br><img src="https://habrastorage.org/webt/in/-z/nz/in-znz1gekgg217y9oxdlm5pv-g.png"><br><br>  Der gesamte Dienst sollte 120 Gbit / s, dh 40 Gbit / s pro Rechenzentrum, bereitstellen.  Angenommen, Netzwerker haben Manöver durchgeführt oder es ist ein Unfall aufgetreten, und es sind noch zwei Rechenzentren DC1 und DC3 übrig.  Jetzt sollte jeder von ihnen 60 Gbit / s geben.  Aber hier war es an den Entwicklern, ein Update herauszubringen. In jedem Rechenzentrum waren noch 3 Live-Knoten übrig, und jeder von ihnen sollte 20 Gbit / s liefern. <br><br><img src="https://habrastorage.org/webt/6q/tc/sz/6qtcszoeoi4w1zjxvh_o1u35vni.png"><br><br>  Anfangs gab es in jedem Rechenzentrum 4 Knoten.  Wenn wir zwei Replikate im Rechenzentrum speichern, ist der Knoten, der die Anforderung empfangen hat, mit einer Wahrscheinlichkeit von 50% keine Replik des angeforderten Tracks und ersetzt die Daten.  Das heißt, die Hälfte des Datenverkehrs im Rechenzentrum wird übertragen. <br><br><img src="https://habrastorage.org/webt/yi/aj/tc/yiajtck3angspynaidxuar_t5gm.png"><br><br>  Ein Knoten sollte den Benutzern also 20 Gbit / s geben.  Davon werden 10 Gbit / s von seinen Nachbarn im Rechenzentrum abgezogen.  Das Schema ist jedoch symmetrisch: Der Knoten gibt den Nachbarn im Rechenzentrum die gleichen 10 Gbit / s.  Es stellt sich heraus, dass 30 Gbit / s aus dem Knoten herausgehen, von denen 20 Gbit / s selbst bedient werden sollten, da es sich um eine Replik der angeforderten Daten handelt.  Darüber hinaus werden die Daten entweder von Festplatten oder vom RAM übertragen, der ungefähr 50.000 "heiße" Spuren enthält.  Basierend auf unseren Wiedergabestatistiken können Sie auf diese Weise 60-70% der Last von den Festplatten entfernen und bleiben bei etwa 8 Gbit / s.  Dieser Thread kann durchaus ein Dutzend SSDs liefern. <br><br><h1>  Datenspeicherung auf einem Knoten </h1><br>  Wenn Sie jeden Track in eine separate Datei einfügen, ist der Aufwand für die Verwaltung dieser Dateien enorm.  Selbst ein Neustart der Knoten und das Scannen der Daten auf den Festplatten dauert Minuten, wenn nicht sogar zehn Minuten. <br><br>  Es gibt weniger offensichtliche Einschränkungen für dieses Schema.  Beispielsweise können Sie Tracks nur von Anfang an laden.  Wenn der Benutzer die Wiedergabe aus der Mitte angefordert hat und der Cache fehlgeschlagen ist, können wir kein einzelnes Byte senden, bis wir die Daten aus dem Track-Repository an den gewünschten Speicherort geladen haben.  Darüber hinaus können wir die Titel nur als Ganzes speichern, auch wenn es sich um ein riesiges Hörbuch handelt, das sie in der dritten Minute nicht mehr hören.  Es wird weiterhin totes Gewicht auf der Festplatte liegen, teuren Speicherplatz verschwenden und den Cache-Treffer dieses Knotens reduzieren. <br><br>  Deshalb machen wir das ganz anders: Wir teilen die Spuren in 256-KB-Blöcke auf, da dies mit der Blockgröße in der SSD korreliert und wir bereits mit diesen Blöcken arbeiten.  Eine Festplatte mit 1 TB enthält 4 Millionen Blöcke.  Jede Festplatte in einem Knoten ist ein unabhängiger Speicher, und alle Blöcke jeder Spur sind auf alle Festplatten verteilt. <br><br>  Wir sind nicht sofort zu einem solchen Schema gekommen, zuerst lagen alle Blöcke einer Spur auf einer Platte.  Dies führte jedoch zu einer starken Verzerrung der Last zwischen den Datenträgern, da alle Anforderungen für seine Daten an einen Datenträger gesendet werden, wenn ein beliebter Track auf einen der Datenträger trifft.  Um dies zu verhindern, haben wir die Blöcke jeder Spur auf alle Festplatten verteilt und die Last ausgeglichen. <br><br>  Außerdem vergessen wir nicht, dass wir eine Menge RAM haben, aber wir haben uns entschieden, den semantischen Cache nicht zu verwenden, da wir unter Linux einen wunderbaren Seiten-Cache haben. <br><br>  Wie speichere ich Blöcke auf Festplatten? <br><br>  Zuerst haben wir beschlossen, eine riesige XFS-Datei von der Größe einer Festplatte zu erhalten und alle Blöcke darin abzulegen.  Dann kam die Idee auf, direkt mit einem Blockgerät zu arbeiten.  Wir haben beide Optionen implementiert, verglichen und festgestellt, dass bei der direkten Arbeit mit einem Blockgerät die Aufzeichnung 1,5-mal schneller ist, die Reaktionszeit 2-3-mal kürzer ist und die Gesamtsystemlast 2-mal niedriger ist. <br><br><h1>  Index </h1><br>  Es reicht jedoch nicht aus, Blöcke speichern zu können. Sie müssen einen Index von Blöcken von Musiktiteln zu Blöcken auf der Festplatte verwalten. <br><br><img src="https://habrastorage.org/webt/me/4y/0b/me4y0bk_xbwco9r_5y6smyhmxmc.png"><br><br>  Es stellte sich als ziemlich kompakt heraus, ein Indexeintrag benötigt nur 29 Bytes.  Bei einem 10-TB-Speicher beträgt der Index etwas mehr als 1 GB. <br><br>  Hier gibt es einen interessanten Punkt.  In jedem solchen Datensatz müssen Sie die Gesamtgröße des gesamten Tracks speichern.  Dies ist ein klassisches Beispiel für Denormalisierung.  Der Grund dafür ist, dass wir gemäß der Spezifikation in der HTTP-Bereichsantwort die Gesamtgröße der Ressource zurückgeben und einen Header mit Inhaltslänge bilden müssen.  Wenn dies nicht der Fall wäre, wäre alles noch kompakter. <br><br>  Wir haben eine Reihe von Anforderungen für den Index formuliert: schnell arbeiten (vorzugsweise im RAM gespeichert), kompakt sein und keinen Platz im Seitencache beanspruchen.  Ein anderer Index sollte persistent sein.  Wenn wir es verlieren, verlieren wir Informationen darüber, an welcher Stelle auf der Festplatte welcher Titel gespeichert ist, und dies ist gleichbedeutend mit der Reinigung der Festplatten.  Und im Allgemeinen möchte ich, dass die alten Blöcke, auf die seit langem nicht mehr zugegriffen wurde, irgendwie ersetzt werden, um Platz für populärere Tracks zu schaffen.  Wir haben die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LRU-Verdrängungsrichtlinie</a> gewählt: Blöcke werden einmal pro Minute <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verdrängt</a> , 1% der Blöcke werden frei gehalten.  Natürlich muss die Indexstruktur threadsicher sein, da wir 100.000 Verbindungen pro Knoten haben.  All diese Bedingungen werden von <code>SharedMemoryFixedMap</code> aus unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">One-Nio-</a> Open-Source-Bibliothek ideal erfüllt. <br><br>  Wir setzen den Index auf <code>tmpfs</code> , es funktioniert schnell, aber es gibt eine Nuance.  Beim Neustart des Computers geht alles verloren, was sich auf <code>tmpfs</code> , einschließlich des Index.  Wenn unser Prozess aufgrund der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code> sun.misc.Unsafe</code></a> abstürzte, ist außerdem unklar, in welchem ​​Zustand der Index verblieben ist.  Deshalb machen wir einmal pro Stunde einen Eindruck davon.  Dies reicht jedoch nicht aus: Da wir die Blockextrusion verwenden, müssen wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WAL unterstützen</a> , in dem wir Informationen über extrudierte Blöcke schreiben.  Einträge zu Blöcken in Casts und WALs müssen während der Wiederherstellung irgendwie sortiert werden.  Dazu verwenden wir den Generierungsblock.  Es spielt die Rolle eines globalen Transaktionszählers und wird bei jeder Änderung des Index erhöht.  Schauen wir uns ein Beispiel an, wie das funktioniert. <br><br>  Nehmen Sie einen Index mit drei Einträgen: zwei Blöcke von Spur Nr. 1 und einen Block von Spur Nr. 2. <br><br><img src="https://habrastorage.org/webt/l6/ux/51/l6ux512_lbpedki0bb3g0ouggau.png"><br><br>  Der Strom der Erstellung von Casts wird durch diesen Index geweckt und wiederholt: Das erste und das zweite Tupel fallen in die Besetzung.  Dann wendet sich der Überfüllungsfluss dem Index zu, stellt fest, dass auf den siebten Block schon lange nicht mehr zugegriffen wurde, und beschließt, ihn für etwas anderes zu verwenden.  Der Prozess erzwingt die Blockierung und schreibt einen Datensatz in die WAL.  Er kommt zu Block 9, sieht, dass er schon lange nicht mehr kontaktiert wurde und markiert ihn auch als überfüllt.  Hier greift der Benutzer auf das System zu und es tritt ein Cache-Fehler auf - ein Track wird angefordert, den wir nicht haben.  Wir speichern den Block dieser Spur in unserem Repository und überschreiben Block 9.  Gleichzeitig wird die Generierung inkrementiert und gleich 22. Anschließend wird der Prozess zum Erstellen einer Form aktiviert, der seine Arbeit noch nicht abgeschlossen hat, den letzten Datensatz erreicht und in die Form schreibt.  Als Ergebnis haben wir zwei Live-Aufzeichnungen im Index, eine Besetzung und WAL. <br><br><img src="https://habrastorage.org/webt/sy/vj/0_/syvj0_-kknmn4i5pulf_p8bclc4.png"><br><br>  Wenn der aktuelle Knoten ausfällt, wird der Ausgangszustand des Index wie folgt wiederhergestellt.  Scannen Sie zuerst die WAL und erstellen Sie eine schmutzige Blockkarte.  Die Karte speichert die Zuordnung von der Blocknummer zur Generation, als dieser Block ersetzt wurde. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9p/g5/gn/9pg5gn-8atbixm4swmytkscxwpm.png" width="300"></div><br><br>  Danach beginnen wir mit der Karte als Filter über die Form zu iterieren.  Wir schauen uns die erste Aufzeichnung der Besetzung an, sie bezieht sich auf Block Nummer 3.  Er wird unter den Dreckigen nicht erwähnt, was bedeutet, dass er lebt und in den Index aufgenommen wird.  Wir kommen mit der achtzehnten Generation zu Block Nummer 7, aber die schmutzige Blockkarte sagt uns, dass der Block gerade in der 18. Generation überfüllt war.  Daher fällt es nicht in den Index.  Wir kommen zum letzten Datensatz, der den Inhalt von Block 9 mit 22 Generationen beschreibt.  Dieser Block wird in der Dirty-Block-Map erwähnt, wurde jedoch früher ersetzt.  Es wird also für neue Daten wiederverwendet und gelangt in den Index.  Das Ziel ist erreicht. <br><br><h1>  Optimierungen </h1><br>  Aber das ist noch nicht alles, wir gehen tiefer. <br><br>  Beginnen wir mit dem Seiten-Cache.  Wir haben anfangs damit gerechnet, aber als wir mit dem Auslastungstest der ersten Version begannen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">stellte sich</a> heraus, dass die Trefferquote im Seiten-Cache nicht 20% erreichte.  Sie schlugen vor, dass das Problem im Voraus gelesen werden sollte: Wir speichern keine Dateien, sondern blockieren, während wir eine Reihe von Verbindungen bedienen, und in dieser Konfiguration ist die Arbeit mit der Festplatte zufällig effizient.  Wir lesen fast nie etwas nacheinander.  Glücklicherweise gibt es unter Linux einen Aufruf von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>posix_fadvise</code></a> , mit dem Sie dem Kernel mitteilen können, wie wir mit dem Dateideskriptor arbeiten werden. Insbesondere können wir sagen, dass wir nicht <code>POSIX_FADV_RANDOM</code> müssen, indem <code>POSIX_FADV_RANDOM</code> Flag <code>POSIX_FADV_RANDOM</code> .  Dieser Systemaufruf ist über <a href="">one-nio verfügbar</a> .  Im Betrieb beträgt unser Cache-Treffer 70-80%.  Die Anzahl der physischen Messwerte von Datenträgern verringerte sich um mehr als das Zweifache, die Verzögerung der HTTP-Antwort verringerte sich um 20%. <br><br>  .     heap.    TLB- ,   Huge Pages   Java-.          (GC Time/Safepoint Total Time  20-30% ),     ,    HTTP latency    . <br><br><h1>  </h1><br>       ( ) . <br><br>             .  ,     ,           ,    ,      .        ,   - .   ,    .  ,        ,    .   ,     Daft Punk    №2  sdc,            sdd. <br><br><img src="https://habrastorage.org/webt/9q/pu/9g/9qpu9gxbc-uph2jp7tsjkup4b5a.png"><br><br> ,            .    Linux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> :      ,      . <br><br><img src="https://habrastorage.org/webt/3s/y-/vm/3sy-vmtyncu3miiwjhzyu0j9xi4.png"><br><br>   .        ID.   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WWN</a>           ,   WAL.      ,      ,             . <br><br><h1>   </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Analyse von Problemen in solchen verteilten Systemen ist schwierig, da eine Benutzeranforderung viele Stufen durchläuft und die Grenzen von Knoten überschreitet. Bei CDN wird alles noch komplizierter, da bei CDN der Upstream das Heimdatenzentrum ist. Es kann ziemlich viele solcher Hoffnungen geben. Darüber hinaus bedient das System Hunderttausende von Benutzerverbindungen. Es ist ziemlich schwer zu verstehen, zu welchem ​​Zeitpunkt ein Problem bei der Verarbeitung einer Anfrage eines bestimmten Benutzers vorliegt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir vereinfachen unser Leben so. Beim Login markieren wir alle Anfragen mit einem Tag ähnlich wie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Open Tracing</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zipkin</font></font></a> .      ,    .          ,    ,       HTTP-    .      ,   ,  ,   ,     ,   ,        . <br><br><h1>   </h1><br>         . ,  :  ,     ,    . <br><br><pre> <code class="java hljs">ByteBuffer buffer = ByteBuffer.allocate(size); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> count = fileChannel.read(buffer, position); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (count &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// ... } buffer.flip(); socketChannel.write(buffer);</span></span></code> </pre> <br>        ,       : <br><br><ul><li>       <code>FileChannel.read()</code>    kernel space  user space; </li><li>            <code>SocketChannel.write()</code> ,    user space  kernel space. </li></ul><br>  ,  Linux   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>sendfile()</code></a> ,              ,    user space.  ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">one-nio</a> .                ,      <code>sendfile()</code> —    10 /   <code>sendfile()</code>    0. <br><br>     user-space SSL-     <code>sendfile()</code>      ,        .       .     <code>SocketChannel</code>  <code>FileChannel</code> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Async Profiler</a>         ,         <code>sun.nio.ch.IOUtil</code> ,      <code>read()</code>  <code>write()</code>   .    . <br><br><pre> <code class="java hljs">ByteBuffer bb = Util.getTemporaryDirectBuffer(dst.remaining()); <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> n = readIntoNativeBuffer(fd, bb, position, nd); bb.flip(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) dst.put(bb); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> n; } <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span> { Util.offerFirstTemporaryDirectBuffer(bb); }</code> </pre> <br>    .       heap <code>ByteBuffer</code> ,         ,    ,     heap <code>ByteBuffer</code> ,       .        . <br><br>  .      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">one-nio</a> .   <code>MallocMT</code> —  ,   .    SSL       ,     Java heap,    <code>ByteBuffer</code> ,      <code>FileChannel</code>       .      . <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">final</span></span> Allocator allocator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MallocMT(size, concurrency); <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Socket socket)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (socket.getSslContext() != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> address = allocator.malloc(size); ByteBuffer buf = DirectMemory.wrap(address, size); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> available = channel.read(buf, offset); socket.writeRaw(address, available, flags);</code> </pre><br><h1> 100 000    </h1><br>          .     .       100 .  .      ? <br><br> ,     —                 .   ,   .             ,          .     . <br><br><img src="https://habrastorage.org/webt/mt/vg/eo/mtvgeoszcpcv6zpc-qi_rbqeyhy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Für jede Verbindung wird eine logische Pipeline erstellt, die aus Stufen besteht, die asynchron miteinander interagieren. Jede Stufe hat eine Runde, in der eingehende Anfragen gespeichert werden. Für die Ausführung von Stufen werden kleine gemeinsame Thread-Pools verwendet. Wenn Sie eine Nachricht aus der Anforderungswarteschlange verarbeiten müssen, nehmen wir einen Stream aus dem Pool, verarbeiten die Nachricht und geben den Stream an den Pool zurück. Mit diesem Schema werden Daten vom Speicher zum Client übertragen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein solches Schema ist jedoch nicht ohne Mängel. Backends sind viel schneller als Benutzerverbindungen. Wenn Daten die Pipeline durchlaufen, sammeln sie sich in der langsamsten Phase an, d.h. in der Phase des Schreibens von Blöcken in den Client-Verbindungssocket. Früher oder später wird dies zum Zusammenbruch des Systems führen. Wenn Sie versuchen, die Warteschlangen in diesen Phasen zu begrenzen, wird alles sofort blockiert, da die Pipelines in der Kette zum Socket des Benutzers blockiert werden. Und da sie gemeinsam genutzte Thread-Pools verwenden, blockieren sie alle Threads in ihnen. Benötigen Sie Gegendruck. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dazu haben wir </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetstreams verwendet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Das Wesentliche des Ansatzes besteht darin, dass der Abonnent die Geschwindigkeit der vom Verlag kommenden Daten mithilfe der Nachfrage steuert. Nachfrage bedeutet, wie viel mehr Daten der Teilnehmer zusammen mit der vorherigen Nachfrage, die er bereits signalisiert hat, verarbeiten kann. Der Herausgeber hat das Recht, Daten zu senden, jedoch nicht die derzeit akkumulierte Gesamtnachfrage abzüglich der bereits gesendeten Daten.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Somit schaltet das System dynamisch zwischen Push- und Pull-Modus um. </font><font style="vertical-align: inherit;">Im Push-Modus ist der Abonnent schneller als der Herausgeber, was bedeutet, dass der Herausgeber immer eine unbefriedigte Nachfrage vom Abonnenten hat, jedoch keine Daten. </font><font style="vertical-align: inherit;">Sobald die Daten erscheinen, sendet er sie sofort an den Teilnehmer. </font><font style="vertical-align: inherit;">Der Pull-Modus tritt auf, wenn der Publisher schneller als der Abonnent ist. </font><font style="vertical-align: inherit;">Das heißt, der Verlag würde gerne Daten senden, nur die Nachfrage ist Null. </font><font style="vertical-align: inherit;">Sobald der Abonnent angibt, dass er bereit ist, etwas mehr zu verarbeiten, sendet der Verlag ihm sofort ein Datenelement als Teil der Nachfrage. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unser Förderer verwandelt sich in einen Jetstream. </font><font style="vertical-align: inherit;">Jede Stufe wird zum Herausgeber für die vorherige Stufe und zum Abonnenten für die nächste. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Schnittstelle von Jetstreams sieht extrem einfach aus. </font></font><code>Publisher</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lass uns unterschreiben</font></font><code>Subscriber</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und er sollte nur vier Handler implementieren: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Publisher</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">T</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">subscribe</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Subscriber&lt;? </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">super</span></span></span></span><span class="hljs-function"><span class="hljs-params"> T&gt; s)</span></span></span></span>; } <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Subscriber</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">T</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onSubscribe</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Subscription s)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onNext</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(T t)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Throwable t)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onComplete</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; } <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Subscription</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">request</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params"> n)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cancel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; }</code> </pre> <br> <code>Subscription</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ermöglicht es Ihnen, Nachfrage zu signalisieren und sich abzumelden. </font></font> Nirgendwo ist es einfacher. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Als Datenelement übergeben wir keine Byte-Arrays, sondern eine solche Abstraktion wie Chunk. </font><font style="vertical-align: inherit;">Wir tun dies, um die Daten im Heap möglichst nicht herauszuziehen. </font><font style="vertical-align: inherit;">Chunk ist eine Datenverbindung mit einer sehr eingeschränkten Schnittstelle, mit der Sie nur Daten lesen </font></font><code>ByteBuffer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, in einen Socket oder in eine Datei schreiben können.</font></font><br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Chunk</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">read</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ByteBuffer dst)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Socket socket)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(FileChannel channel, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset)</span></span></span></span>; }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Es gibt viele Implementierungen von Chunks: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die beliebteste, die bei Cache-Treffern und beim Senden von Daten von der Festplatte verwendet wird, ist die Implementierung oben </font></font><code>RandomAccessFile</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Der Block enthält nur einen Link zur Datei, den Versatz in dieser Datei und die Größe der Daten. </font><font style="vertical-align: inherit;">Es durchläuft die gesamte Pipeline, erreicht den Benutzerverbindungssocket und wird dort zu einem Anruf </font></font><code>sendfile()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Das heißt, Speicher wird überhaupt nicht verbraucht.</font></font></li><li>   cache miss   :             .     , —  ,     , —      . </li><li> ,    -      heap.        <code>ByteBuffer</code> . </li></ul><br><br>      API,      ,      .      Typed Actor Model,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> .     ,       ,   ,        .      . <br><br><div class="spoiler"> <b class="spoiler_title"> ,    .</b> <div class="spoiler_text">     .   publisher  subscriber   ,    ,   executor,       . <code>AtomicBoolean</code>  happens before   . <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// Incoming messages final Queue&lt;M&gt; mailbox; // Message processing works here final Executor executor; // To ensure HB relationship between runs final AtomicBoolean on = new AtomicBoolean();</span></span></code> </pre> <br>    : <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">request</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">final</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params"> n)</span></span></span><span class="hljs-function"> </span></span>{ enqueue(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Request(n)); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">enqueue</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">final</span></span></span></span><span class="hljs-function"><span class="hljs-params"> M message)</span></span></span><span class="hljs-function"> </span></span>{ mailbox.offer(message); tryScheduleToExecute(); }</code> </pre> <br>  <code>tryScheduleToExecute()</code> : <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (on.compareAndSet(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { executor.execute(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>); } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (Exception e) { ... } }</code> </pre> <br>  <code>run()</code> : <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (on.get()) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { dequeueAndProcess(); } <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span> { on.set(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!messages.isEmpty()) { tryScheduleToExecute(); } } }</code> </pre> <br>  <code>dequeueAndProcess()</code> : <br><br><pre> <code class="java hljs">M message; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ((message = mailbox.poll()) != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Pattern match if (message instanceof Request) { doRequest(((Request) message).n); } else { … } }</span></span></code> </pre> </div></div><br>     .    ,  <code>volatile</code> , <code>Atomic*</code> , contention  .       100 000    200 . <br><br><h1>  Zusammenfassend </h1><br>  production   12 ,          .        10 /    .     .    Java  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">one-nio</a> . <br><br><img src="https://habrastorage.org/webt/oa/pz/cq/oapzcqjf6y9ccxrnk1wzrpaigdy.jpeg"><br><br>     ,     . 99-  20 .   —    HTTPS-.   —         <code>sendfile()</code>  HTTP. <br><br>    cache hit  production 97%,    latency   ,         ,   ,   . <br><br><img src="https://habrastorage.org/webt/xp/fd/eq/xpfdequddx6cnglrzrgdxtbspuc.jpeg"><br><br>    75-    ,       1 .         —   300 .  Das heißt, 0.7  —   . <br><br>      ,      ,     ,   . ,    . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de434206/">https://habr.com/ru/post/de434206/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de434194/index.html">Fähigkeitsentwicklung für Alice. Erfahrung mit Sprachschnittstellen, Tipps für Anfänger</a></li>
<li><a href="../de434196/index.html">3CX v16 Alpha 2 und Pläne für das neue Jahr</a></li>
<li><a href="../de434198/index.html">Auswahl eines Webserver-Betriebsmodus basierend auf persönlichen Erfahrungen</a></li>
<li><a href="../de434200/index.html">Ist Rust so schrecklich wie es gemalt ist</a></li>
<li><a href="../de434202/index.html">4 Geheimnisse, wie Sie Ihren Job in der Datenwissenschaft nicht verlieren können</a></li>
<li><a href="../de434208/index.html">How Go rettete unseren schwarzen Freitag</a></li>
<li><a href="../de434210/index.html">Analyse des Android-Quizwettbewerbs vom HeadHunter-Stand auf der Mobius 2018 in Moskau</a></li>
<li><a href="../de434212/index.html">Tesla Tower. Was passiert in und in der Nähe eines Wolkenkratzers, wenn ein Blitz einschlägt?</a></li>
<li><a href="../de434214/index.html">Java Dynamic Proxy: Was ist das und wie wird es verwendet?</a></li>
<li><a href="../de434216/index.html">Brute-Force-Angriffe mit Kali Linux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
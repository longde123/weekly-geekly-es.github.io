<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèø üî± ü§öüèª Videoanalyse: Gesichtserkennung, Warteschlangendetektor, Suche nach Objekten auf Video üîÅ üíÉüèº üéå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das taiwanesische Unternehmen 42Ark und der in den USA ans√§ssige Hersteller von ‚Äûintelligenten‚Äú CatFi-Box-Feedern verwenden CCTV-Kameras, um Katzenges...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Videoanalyse: Gesichtserkennung, Warteschlangendetektor, Suche nach Objekten auf Video</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ivideon/blog/401765/"><img src="https://habrastorage.org/files/ab3/8f9/31a/ab38f931a6b1484b9c587a5de062d51d.jpg"><br>  <i>Das taiwanesische Unternehmen 42Ark und der in den USA ans√§ssige Hersteller von ‚Äûintelligenten‚Äú CatFi-Box-Feedern verwenden CCTV-Kameras, um Katzengesichter zu erkennen</i> <br><br>  1941 installierte der deutsche Elektrotechniker Walter Bruch an der Teststelle, an der die V-2-Raketen getestet wurden, ein CCTV-System (Closed Circuit Television).  Dies ist der erste Fall in der Geschichte, in dem Video√ºberwachung in der Praxis eingesetzt wird.  Der Bediener musste die ganze Zeit vor dem Monitor sitzen.  Dies dauerte bis 1951, bis die ersten VTR-Ger√§te (VideoTape Recorder) erschienen, die Bilder auf Magnetband aufzeichneten. <br><br>  Die Aufzeichnung auf dem Medium hat den Bediener nicht vor der Notwendigkeit bewahrt, an dem Prozess teilzunehmen.  Gesichtserkennung, Position von Objekten, sogar Bewegungserkennung - all diese Funktionen wurden von einer Person ausgef√ºhrt, die in Echtzeit vor dem Monitor sa√ü oder das Videoarchiv nachtr√§glich studierte. <br><br>  Das Rad des Fortschritts rollt weiter.  Die Video√ºberwachung erhielt eine Videoanalyse, die den Prozess der Arbeit mit dem System grundlegend ver√§nderte.  Erinnern Sie sich an die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Geschichte</a> √ºber die Katze und das tief lernende neuronale Netzwerk?  Ja, dies ist auch Teil der Videoanalyse, aber winzig.  Heute werden wir √ºber Technologien sprechen, die die Welt der CCTV-Systeme grundlegend ver√§ndern. <br><a name="habracut"></a><br>  <b>Warteschlangenerkennung und Betatest</b> <br><img src="https://habrastorage.org/files/0c7/839/22b/0c783922b1de484dbd3484ec8059534a.jpg"><br>  <i>Die weltweit erste IP-Kamera Neteye 200, die 1996 von Axis entwickelt wurde</i> <br><br>  Die Video√ºberwachung wurde als geschlossenes Sicherheitssystem entwickelt, das nur zur Behebung von Sicherheitsproblemen entwickelt wurde.  Die Einschr√§nkungen der analogen Video√ºberwachung erlaubten keine andere Verwendung von Ger√§ten.  Die Integration der Video√ºberwachung in digitale Systeme hat die M√∂glichkeit er√∂ffnet, durch Analyse der Bildsequenz automatisch verschiedene Daten zu empfangen. <br><br>  Die Wichtigkeit ist schwer zu √ºbersch√§tzen: Im Normalfall beginnt der Bediener nach 12 Minuten kontinuierlicher Beobachtung, bis zu 45% der Ereignisse zu verpassen.  Und bis zu 95% der potenziell st√∂renden Ereignisse werden nach 22 Minuten kontinuierlicher √úberwachung √ºbersehen (gem√§√ü IMS Research, 2002). <br><br>  Es sind komplexe Videoanalysealgorithmen erschienen: Besucher z√§hlen, Conversions z√§hlen, Statistiken √ºber Bargeldtransaktionen und vieles mehr.  Der Beobachtungsoperator verschwindet in diesem System - wir √ºberlassen dem Computer die M√∂glichkeit, zu ‚Äûbeobachten‚Äú und Schlussfolgerungen zu ziehen. <br><br>  Das einfachste Beispiel f√ºr intelligente Video√ºberwachung ist die Bewegungserkennung.  Es ist nicht so wichtig, ob in der Kamera selbst ein eingebauter Detektor vorhanden ist. Wenn Sie beispielsweise die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ivideon Server-</a> Software auf einem Computer installieren, wird der Bewegungsmelder als Software verwendet.  Ein Detektor kann mehrere Video√ºberwachungsbetreiber gleichzeitig ersetzen.  Und bereits in den 2000er Jahren tauchten die ersten Videoanalysesysteme auf, die Objekte und Ereignisse im Rahmen erkennen k√∂nnen. <br><br>  Ivideon entwickelt derzeit mehrere Videoanalysemodule. Seit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ver√∂ffentlichung von OpenAPI</a> sind die Dinge durch die Integration mit Partnern schneller geworden.  Einige der Projekte befinden sich noch in geschlossenen Tests, aber etwas ist bereits fertig.  Dies ist zum einen die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Integration in Registrierkassen</a> zur Kontrolle von Bargeldtransaktionen (bisher basierend auf iiko und Shtrikh-M).  Zweitens wurde ein Warteschlangendetektor entwickelt. <br><br>  Wir hatten einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ivideon-Schalter</a> , der die Anzahl der Kunden im Raum bestimmte.  Mit Analytics konnten wir uns von speziellen Ger√§ten zum Cloud Computing abwenden.  Jetzt brauchen wir keine spezielle Kamera - jede √úberwachungskamera mit einer Aufl√∂sung von 1080p + ist geeignet.  Jetzt wollen wir nicht nur Leute z√§hlen, sondern auch die Warteschlangen bestimmen.  Daher sind sie f√ºr jedes Gesch√§ft, Einkaufszentrum oder B√ºro bereit, in dem Menschen stehen und Warteschlangen bilden, um eine kostenlose Kamera f√ºr den Warteschlangenerkennungstest bereitzustellen.  <a href="">Mailen Sie uns</a> , um am Projekt teilzunehmen. <br><br>  Dar√ºber hinaus arbeitet Ivideon mit Gesichtserkennungstechnologie. <br><br>  <b>Wer erkennt wie</b> <br><img src="https://habrastorage.org/files/74f/568/736/74f5687364af4b3f982f9fad36abeb09.jpg"><br>  <i>Die DeepFace-Technologie wird von Facebook am Beispiel der Erkennung des emotionalen Gesichts von Sylvester Stallone getestet</i> <br><br>  Apple, Facebook, Google, Intel, Microsoft und andere Technologie-Giganten arbeiten an L√∂sungen in diesem Bereich.  An 22 US-Flugh√§fen sind Video√ºberwachungssysteme mit automatischer Gesichtserkennung von Passagieren installiert.  In Australien entwickeln sie ein biometrisches System zur Erkennung von Gesichtern und Fingerabdr√ºcken als Teil eines Programms zur Automatisierung der Pass- und Zollkontrolle. <br><br><img src="https://habrastorage.org/files/beb/5f4/0e5/beb5f40e582d4730a10140d01e146c87.jpeg"><br><br>  Das gr√∂√üte chinesische Internetunternehmen, Baidu, f√ºhrte ein erfolgreiches Experiment zum Stornieren von Tickets mithilfe der Gesichtserkennungstechnologie mit einer Genauigkeit von 99,77% und einer Aufnahme- und Erkennungszeit von 0,6 Sekunden durch.  An den Eing√§ngen zum Park sind St√§nde mit Tablets und speziellen Rahmen angebracht, die das Schie√üen durchf√ºhren.  Wenn ein Tourist zum ersten Mal in den Park kommt, macht das System ein Bild von ihm, um in Zukunft die Gesichtserkennungsfunktion auf dem Foto zu verwenden.  Neue Fotos werden mit Fotos aus der Datenbank verglichen. Auf diese Weise bestimmt das System, ob eine Person das Recht hat, sie zu besuchen. <br><br><img src="https://habrastorage.org/files/7ad/26f/375/7ad26f37537d4b40b4d776b10772ad22.jpg"><br><br>  In China ist die Technologie im Allgemeinen sehr gut.  Im Jahr 2015 startete Alipay, ein Betreiber der Online-Zahlungsplattform, der Teil der Alibaba Holding ist, ein Zahlungsverifizierungssystem auf der Basis von Face ++, einer Cloud-Gesichtserkennungsplattform, die vom chinesischen Startup Megvii entwickelt wurde.  Das System hei√üt Smile to Pay - es erm√∂glicht Alipay-Benutzern, Online-Eink√§ufe mit einem Selfie zu bezahlen (Alipay ermittelt den Eigent√ºmer anhand eines L√§chelns).  UBER in China hat begonnen, ein auf Face ++ basierendes Fahrererkennungssystem zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwenden</a> , um Betrug und Identit√§tsdiebstahl entgegenzuwirken und zus√§tzliche Sicherheit f√ºr die Fahrg√§ste zu gew√§hrleisten. <br><br>  Interessanter ist es jedoch, sich nicht mit ausl√§ndischen L√∂sungen zu befassen, sondern mit in Russland erstellten Dienstleistungen.  Diese Technologien sind dem Endbenutzer viel n√§her (wenn er aus unserem Land stammt), Sie k√∂nnen sie kennenlernen und sich in Zukunft zur Verwendung in Ihrem eigenen Produkt zusammenschlie√üen.  Es gibt viele Gesichtserkennungsunternehmen.  Erinnern wir uns an einige, die nach Geh√∂r bleiben. <br><br><img src="https://habrastorage.org/files/35d/dc5/4b8/35ddc54b85ce4cbd9c246565302e1836.jpg"><br><br>  Das 1999 gegr√ºndete Unternehmen Vokord verwendet FaceControl 3D, um mit synchronen Bildern von Stereokameras zu arbeiten, erstellt ein 3D-Modell des Gesichts im Rahmen und sucht automatisch nach dem Modell, das mit den Modellen in der vorhandenen Datenbank erhalten wurde.  Im Jahr 2016 begann Vokord <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">,</a> einen eigenen mathematischen Gesichtserkennungsalgorithmus zu verwenden, der auf Faltungs-Neuronalen Netzen basiert. Daher funktionieren ihre Algorithmen jetzt mit jeder Video√ºberwachungskamera.  Das Unternehmen behauptet, dass sie die Gesichter (in der Gr√∂√üe von 128 x 128 Pixel) von Personen erkennen k√∂nnen, die dem Stream folgen.  Ende 2016 zeigte der Vocord DeepVo1-Algorithmus die besten Ergebnisse bei den globalen Identifikationstests und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erkannte</a> 75,127% der Personen korrekt. <br><br><img src="https://habrastorage.org/files/b10/944/2f2/b109442f29884a92b744058ae794d844.jpg"><br><br>  VisionLabs wurde 2012 gegr√ºndet und gewann den gr√∂√üten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wettbewerb f√ºr</a> Technologieunternehmen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GoTech</a> in Russland und Osteuropa. Es wurde in die Liste der Finalisten des europ√§ischen Programms ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Challenge UP!</a>  ‚Äú, Entwickelt, um die Markteinf√ºhrung von L√∂sungen und Dienstleistungen auf der Grundlage des Konzepts des Internet der Dinge zu beschleunigen, hat mehrere Millionen Investitionen angezogen und f√ºhrt seine Produkte bereits im kommerziellen Sektor ein.  Vor kurzem hat die Otkritie Bank das Gesichtserkennungssystem VisionLabs eingef√ºhrt, um den Kundenservice und die Wartezeiten in der Schlange zu optimieren.  Es lohnt sich, eine wunderbare Geschichte zu lesen, wie CROC-Spezialisten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eine Katze</a> mit VisionLabs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gefangen</a> haben. <br><br>  VisionLabs, das eines der besten Ergebnisse bei Erkennungs- und Fehlerraten erzielt hat, funktioniert auch mit neuronalen Netzen, die bestimmte Merkmale jedes Gesichts wie Augenform, Nasenform, Ohrmuschelrelief usw. offenbaren.  Mit ihrem Luna-System k√∂nnen Sie all diese Merkmale des Gesichts auf dem Foto in den Archiven finden.  Eine weitere Entscheidung des Unternehmens, Face Is, erkennt das Gesicht des Kunden im Gesch√§ft, findet sein Profil im CRM-System, erf√§hrt daraus die Kaufhistorie und die Interessen des K√§ufers und sendet eine Benachrichtigung mit einem pers√∂nlichen Angebot √ºber den Rabatt auf seine bevorzugte Warengruppe an das Telefon. <br><br>  Die Automatisierung des Einstellungsprozesses f√ºr das Skillaz-Startup und VisionLabs plant, Ende 2017 ein Computererkennungssystem einzuf√ºhren, mit dem das Verhalten von Arbeitssuchenden bewertet wird.  Nach der Analyse der Daten zieht das System R√ºckschl√ºsse auf die beruflichen Qualit√§ten einer Person und die Eignung f√ºr die Stelle.  Die vollst√§ndigen Merkmale des ‚ÄûMietwagen‚Äú -Systems werden vom Unternehmen nicht bekannt gegeben.  Es ist nur bekannt, dass die Geselligkeit des Kandidaten anhand seiner Antworten auf bestimmte Fragen bewertet wird, die vom Online-Interview-System gestellt werden.  Das neuronale Netzwerk sucht nach der Beziehung zwischen dem Verhalten des Kandidaten im Bild von der √úberwachungskamera und dem Schweregrad der einen oder anderen Kompetenz. <br><br>  Das Raster, das aus Dr. Lightman und Sherlock Holmes in einer Person besteht, ber√ºcksichtigt den Gesichtsausdruck des Kandidaten, seine Gesten sowie die Physiognomie.  Es ist erw√§hnenswert, dass die Methode zur Bestimmung des Pers√∂nlichkeitstyps eines Menschen, seiner spirituellen Qualit√§ten, basierend auf der Analyse √§u√üerer Merkmale und seines Ausdrucks, als modernes Beispiel f√ºr Pseudowissenschaften in der modernen psychologischen Wissenschaft angesehen wird.  Wie mit diesem Widerspruch im neuen Produkt umzugehen ist, ist noch unklar. <br><br><img src="https://habrastorage.org/files/5a0/39e/744/5a039e744a0e416894dfe7a8d9386de3.jpg"><br>  <i>NTechLab-Pr√§sentationsfolie, die Salman Radaev niederdr√ºckt</i> <br><br>  NTechLab begann mit einer Anwendung, die die Hunderasse anhand eines Fotos bestimmte.  Sp√§ter schrieben sie den FaceN-Algorithmus, mit dem sie im Herbst 2015 am internationalen Wettbewerb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">The MegaFace Benchmark teilnahmen</a> .  NTechLab gewann zwei von vier Nominierungen und schlug das Google-Team (in einem Jahr wird Vokord im selben Wettbewerb gewinnen und NTechLab wird auf den 4. Platz vorr√ºcken).  Der Erfolg erm√∂glichte es ihnen, den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FindFace-</a> Dienst schnell zu implementieren und nach Personen aus Fotos auf VKontakte zu suchen.  Dies ist jedoch nicht die einzige M√∂glichkeit, die Technologie anzuwenden.  Beim Alfa Future People Festival, das von der Alfa Bank mit FindFace organisiert wurde, konnten Besucher ihre Fotos unter Hunderten von anderen finden, indem sie ein Selfie an einen Chatbot schickten. <br><br>  Dar√ºber hinaus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zeigte</a> NTechLab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein System</a> , mit dem Geschlecht, Alter und Emotionen mithilfe eines Bildes von einer Videokamera in Echtzeit erkannt werden k√∂nnen.  Das System kann die Reaktion des Publikums in Echtzeit auswerten, sodass Sie die Emotionen bestimmen k√∂nnen, die Besucher bei Pr√§sentationen oder Sendungen von Werbebotschaften erleben.  Alle NTechLab-Projekte basieren auf selbstlernenden neuronalen Netzen. <br><br>  <b>Ivideons Weg zur Videoanalyse</b> <br><img src="https://habrastorage.org/files/337/7e9/625/3377e9625d0144298c8f9553c831d499.jpg"><br><br>  Die Gesichtserkennung ist eine der schwierigsten Aufgaben im Bereich der Videoanalyse.  Einerseits scheint alles klar zu sein und wurde schon lange benutzt.  Andererseits sind Identifikationsl√∂sungen in einer Menschenmenge immer noch sehr teuer und bieten keine absolute Genauigkeit. <br>  Seit 2012 arbeitet Ivideon mit Videoanalysealgorithmen.  In diesem Jahr haben wir Anwendungen f√ºr iOS und Android ver√∂ffentlicht, sind in ausl√§ndische M√§rkte eingetreten, haben dezentrale CDN-Netzwerke mit Servern in den USA, den Niederlanden, Deutschland, Korea, Russland, der Ukraine und Kasachstan gestartet und sind der einzige internationale Video√ºberwachungsdienst, der weltweit gleich gut funktioniert.  Im Allgemeinen schien es einfach und schnell zu sein, Ihre Analysen mit Blackjack und Erkennung durchzuf√ºhren ... wir waren jung, das Gras schien gr√ºner und die Luft s√º√ü und tr√§ge. <br><br>  [ <i>Zu dieser Zeit haben wir klassische Algorithmen in Betracht gezogen.</i>  <i>Zuerst m√ºssen Sie die Gesichter im Bild erkennen und lokalisieren: Verwenden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Haar-Kaskaden</a> , suchen Sie nach Regionen mit einer haut√§hnlichen Textur usw.</i>  <i>Angenommen, wir m√ºssen die erste Person finden, die auf sie st√∂√üt, und sie nur im Videostream begleiten.</i>  <i>Hier k√∂nnen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Lucas-Canada-Algorithmus verwenden</a> .</i>  <i>Wir finden das Gesicht durch den Algorithmus und bestimmen dann die charakteristischen Punkte darin.</i>  <i>Wir begleiten die Punkte mit dem Lucas-Canada-Algorithmus.</i>  <i>Nach ihrem Verschwinden glauben wir, dass das Gesicht aus dem Blickfeld verschwunden ist.</i>  <i>Nachdem wir die charakteristischen Merkmale des Gesichts erhalten haben, k√∂nnen wir es mit den in die Datenbank eingebetteten Merkmalen vergleichen.</i> <i><br><br></i>  <i>Um die Flugbahn des Objekts (Gesicht) zu gl√§tten und seine Position im n√§chsten Frame vorherzusagen, verwenden wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Kalman-Filter</a> .</i>  <i>Hierbei ist zu beachten, dass der Kalman-Filter f√ºr lineare Bewegungsmodelle ausgelegt ist.</i>  <i>F√ºr nichtlineare wird der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Partikelfilter-</a> Algorithmus verwendet (als Variante des Partikelfilter + <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mean Shift-</a> Algorithmus).</i> <i><br><br></i>  <i>Sie k√∂nnen auch Hintergrundsubtraktionsalgorithmen verwenden: eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bibliothek</a> mit Beispielen f√ºr die Implementierung von Algorithmen zum Subtrahieren des Hintergrunds + <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> zur Implementierung des Lightweight-Algorithmus zum Subtrahieren des Hintergrunds von ViBe.</i>  <i>Vergessen Sie au√üerdem nicht eine der h√§ufigsten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Viola-Jones-</a> Methoden, die in der OpenCV-Computer-Vision-Bibliothek implementiert sind.</i>  ]] <br><br>  Einfache Gesichtserkennung ist gut, aber nicht genug.  Es ist auch notwendig, eine stabile Verfolgung mehrerer Objekte im Rahmen sicherzustellen, selbst wenn sie sich gemeinsam schneiden oder ein Hindernis vor√ºbergehend ‚Äûverschwinden‚Äú.  Z√§hlen Sie eine beliebige Anzahl von Objekten, die eine bestimmte Zone √ºberqueren, und ber√ºcksichtigen Sie die Schnittrichtungen.  Um zu wissen, wann ein Objekt / Objekt im Rahmen erscheint und verschwindet, bewegen Sie die Maus √ºber die schmutzige Tasse auf dem Tisch und finden Sie im Videoarchiv den Moment, in dem es dort erschien und wer es verlassen hat.  W√§hrend der Verfolgung kann sich ein Objekt sehr stark √§ndern (in Bezug auf Transformationen).  Diese √Ñnderungen sind jedoch von Bild zu Bild so, dass das Objekt identifiziert werden kann. <br><br>  Dar√ºber hinaus wollten wir eine universelle Cloud-L√∂sung f√ºr alle verf√ºgbar machen - von den anspruchsvollsten Benutzern.  Die L√∂sung musste flexibel und skalierbar sein, da wir selbst nicht wissen konnten, was der Benutzer √ºberwachen und was der Benutzer ber√ºcksichtigen wollte.  Es ist durchaus m√∂glich, dass jemand vorgeschlagen h√§tte, eine auf Ivideon basierende Kakerlakensendung mit automatischer Ermittlung des Gewinners zu machen. <br><br>  Nur f√ºnf Jahre sp√§ter haben wir begonnen, einzelne Komponenten der Videoanalyse zu testen. In neuen Artikeln werden wir mehr √ºber diese Projekte sprechen. <br><br>  PS Wir suchen also Freiwillige f√ºr Warteschlangendetektortests.  Sowie Benutzer des SHTRIH-M-Systems zum Testen eines neuen Cash-Management-Systems.  Schreiben Sie in der <a href="">Mail</a> oder in den Kommentaren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de401765/">https://habr.com/ru/post/de401765/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de401739/index.html">REDMOND Multibaker: 25-in-1-Multi-Baker f√ºr Backliebhaber</a></li>
<li><a href="../de401745/index.html">Ein Tippfehler im Code der offiziellen Zerocoin-Brieftasche erlaubte es, Kryptow√§hrungen f√ºr 648.000 US-Dollar zu stehlen</a></li>
<li><a href="../de401751/index.html">Space Shuttle Seitenpfeile</a></li>
<li><a href="../de401753/index.html">Unterwasser-Startsysteme: Wie kommt man aus dem Wasser in die Umlaufbahn?</a></li>
<li><a href="../de401755/index.html">F√ºr 5 US-Dollar in Darknet k√∂nnen Sie in den USA einen "ewigen" Internetzugang kaufen</a></li>
<li><a href="../de401767/index.html">Die chinesische Fabrik ersetzte 90% der Mitarbeiter durch Roboter und erhielt eine Produktivit√§tssteigerung von 250%</a></li>
<li><a href="../de401769/index.html">–†–∞–¥–∏–∫–∞–ª—å–Ω–æ–µ –ø—Ä–æ–¥–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–∏: –≤–µ—â–µ—Å—Ç–≤–∞ –ø—Ä–æ—Ç–∏–≤ —Å—Ç–∞—Ä–µ–Ω–∏—è</a></li>
<li><a href="../de401773/index.html">Was kann ein Geek als Geschenk anbieten? Universelle Auswahl</a></li>
<li><a href="../de401775/index.html">Kolonie. Kapitel 5: Drei Monate zuvor</a></li>
<li><a href="../de401777/index.html">Kommunikationskultur: Wie wir bei Audiomania unser Kommunikationssystem geschaffen haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
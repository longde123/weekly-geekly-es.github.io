<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôèüèª üèÇüèø üöü Comparaison ultime des plates-formes embarqu√©es pour l'IA üë©üèº‚Äçüéì üòî üë∑üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les r√©seaux de neurones capturent le monde. Ils comptent les visiteurs, contr√¥lent la qualit√©, tiennent des statistiques et √©valuent la s√©curit√©. Un t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comparaison ultime des plates-formes embarqu√©es pour l'IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/468421/">  Les r√©seaux de neurones capturent le monde.  Ils comptent les visiteurs, contr√¥lent la qualit√©, tiennent des statistiques et √©valuent la s√©curit√©.  Un tas de startups, √† usage industriel. <br>  Grands cadres.  Qu'est-ce que PyTorch, quel est le deuxi√®me TensorFlow.  Tout devient de plus en plus pratique et pratique, de plus en plus simple ... <br>  Mais il y a un c√¥t√© sombre.  Ils essaient de garder le silence sur elle.  Il n'y a rien de joyeux l√†-dedans, seulement de l'obscurit√© et du d√©sespoir.  Chaque fois que vous voyez un article positif, vous soupirez tristement, car vous comprenez que seule une personne n'a pas compris quelque chose.  Ou je l'ai cach√©. <br>  Parlons de la production sur les appareils embarqu√©s. <br><img src="https://habrastorage.org/webt/hb/pv/jm/hbpvjmosqm6fva4b2n6ytwqtqqq.jpeg"><br><a name="habracut"></a><br><br><h2>  Quel est le probl√®me. </h2><br>  Il semblerait.  Examinez les performances de l'appareil, assurez-vous qu'il est suffisant, ex√©cutez-le et r√©alisez un profit. <br>  Mais, comme toujours, il y a quelques nuances.  Mettons-les dans des √©tag√®res: <br><ol><li>  Production.  Si votre appareil n'est pas fabriqu√© en copies uniques, vous devez vous assurer que le syst√®me ne se bloque pas, que les appareils ne surchaufferont pas, qu'en cas de panne de courant, tout d√©marrera automatiquement.  Et c'est sur une grande f√™te.  Cela ne donne que deux options - soit l'appareil doit √™tre enti√®rement con√ßu en tenant compte de tous les probl√®mes possibles.  Ou vous devez surmonter les probl√®mes de l'appareil source.  Eh bien, par exemple, ce sont ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ).  Ce qui est bien s√ªr de l'√©tain.  Pour r√©soudre les probl√®mes de l'appareil de quelqu'un d'autre en grandes quantit√©s, il est n√©cessaire de d√©penser une quantit√© d'√©nergie irr√©aliste. </li><li>  De vrais rep√®res.  Beaucoup d'escroqueries et de trucs.  NVIDIA dans la plupart des exemples surestime les performances de 30 √† 40%.  Mais non seulement elle s'amuse.  Ci-dessous, je donne de nombreux exemples o√π la productivit√© peut √™tre 4 √† 5 fois inf√©rieure √† celle que vous souhaitez.  Vous ne pouvez pas vous faire "tout fonctionnait bien sur l'ordinateur, ce sera proportionnellement pire ici." <br></li><li>  Prise en charge tr√®s limit√©e de l'architecture de r√©seau neuronal.  Il existe de nombreuses plates-formes mat√©rielles int√©gr√©es qui limitent consid√©rablement les r√©seaux qui peuvent y √™tre ex√©cut√©s (Coral, gyrfalcone, snapdragon).  Le portage sur de telles plateformes sera p√©nible. </li><li>  Support.  Quelque chose ne fonctionne pas pour vous, mais le probl√®me est du c√¥t√© de l'appareil? .. C'est le destin, cela ne fonctionnera pas.  Pour RPi uniquement, la communaut√© ferme la plupart des bogues.  Et, en partie, pour Jetson. </li><li>  Prix  Il semble √† beaucoup que l'embarqu√© est bon march√©.  Mais, en r√©alit√©, avec la croissance des performances des appareils, le prix augmentera de fa√ßon presque exponentielle.  RPi-4 est 5 fois moins cher que Jetson Nano / Google Coral et 2-3 fois plus faible.  Jetson Nano est 5 fois moins cher que Jetson TX2 / Intel NUC, et 2-3 fois plus faible qu'eux. <br></li><li>  Lorgus.  Rappelez-vous cette conception de Zhelyazny?  <s>Il semble que je l'ai d√©fini comme image de titre ...</s> " <i>le Logrus est un labyrinthe tridimensionnel mouvant qui repr√©sente les forces du Chaos dans le multivers.</i> "  Tout cela est une abondance de bugs et de trous, tous ces diff√©rents morceaux de fer, tous les cadres changeants ... C'est normal lorsque l'image du march√© change compl√®tement en 2-3 mois.  Au cours de cette ann√©e, il a chang√© 3-4 fois.  Vous ne pouvez pas entrer deux fois dans la m√™me rivi√®re.  Donc, toutes les pens√©es actuelles sont vraies pour l'√©t√© 2019. </li></ol><br><br><h2>  Qu'est-ce que </h2><br>  <s>Prenons-le dans l'ordre, il n'a pas un go√ªt sucr√© ...</s> Qu'est-ce qui existe maintenant et convient aux neurones?  Il n'y a pas tant d'options, malgr√© leur variabilit√©.  Quelques mots g√©n√©raux pour limiter la recherche: <br><ol><li>  Je n'analyserai pas les neurones / inf√©rences sur les t√©l√©phones.  C'est en soi un sujet √©norme.  Mais comme les t√©l√©phones sont des plates-formes int√©gr√©es avec un ajustement par interf√©rence, je ne pense pas que ce soit mauvais. </li><li>  Je vais parler de Jetson TX1 | TX2.  Dans les conditions actuelles, ce ne sont pas les plateformes les plus optimales pour le prix, mais il y a des situations o√π elles sont toujours pratiques √† utiliser. </li><li>  Je ne garantis pas que la liste inclura toutes les plateformes qui existent aujourd'hui.  Peut-√™tre que j'ai oubli√© quelque chose, peut-√™tre que je ne sais pas quelque chose.  Si vous connaissez des plateformes plus int√©ressantes - √©crivez! </li></ol><br><br>  Alors.  Les principales choses qui sont clairement int√©gr√©es.  Dans l'article, nous les comparerons pr√©cis√©ment: <br><br><img width="800" src="https://habrastorage.org/webt/re/uw/k4/reuwk49r6lwkkhssus1lqwamlyq.jpeg"><br><br><ol><li>  Plateforme <b>Jetson</b> .  Il existe plusieurs appareils pour cela: <br><ul><li>  <b>Jetson Nano</b> - un jouet pas cher et assez moderne (printemps 2019) </li><li>  <b>Jetson Tx1 | Tx2</b> - assez cher mais bon sur les plates-formes de performance et de polyvalence </li></ul><br></li><li>  <b>Raspberry Pi</b> .  En r√©alit√©, seul RPi4 a les performances pour les r√©seaux de neurones.  Mais certaines t√¢ches distinctes peuvent √™tre effectu√©es sur la troisi√®me g√©n√©ration.  J'ai m√™me commenc√© par cr√©er des grilles tr√®s simples. </li><li>  <b>Google Coral</b> Platform.  En fait, pour int√©grer des appareils, il n'y a qu'une seule puce et deux appareils - la carte de d√©veloppement et l'acc√©l√©rateur USB </li><li>  Plateforme <b>Intel Movidius</b> .  Si vous n'√™tes pas une grande entreprise, alors seuls les b√¢tons Movidius 1 | Movidius 2 seront √† votre disposition. </li><li>  Plateforme <b>Gyrfalcone</b> .  Le miracle de la technologie chinoise.  Il y a d√©j√† deux g√©n√©rations - 2801, 2803 </li></ol><br><br>  Divers  Nous en parlerons apr√®s les principales comparaisons: <br><ol><li>  Processeurs Intel.  Tout d'abord, les assemblages NUC. </li><li>  GPU Nvidia Mobile.  Les solutions pr√™tes √† l'emploi peuvent √™tre consid√©r√©es comme non int√©gr√©es.  Et si vous collectez l'incorporation, cela se passera d√©cemment sur les finances. </li><li>  T√©l√©phones portables.  Android se caract√©rise par le fait que pour utiliser des performances maximales, il est n√©cessaire d'utiliser exactement le mat√©riel d'un fabricant particulier.  Ou utilisez quelque chose d'universel, comme la lumi√®re tensorflow.  Pour Apple, la m√™me chose. </li><li>  Jetson AGX Xavier est une version ch√®re de Jetson avec plus de performances. </li><li>  GAP8 - processeurs basse consommation pour des appareils super bon march√©. </li><li>  Chapeau AI Mysterious Grove </li></ol><br><br><h2>  Jetson </h2><br>  Nous travaillons avec Jetson depuis tr√®s longtemps.  En 2014, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">Vasyutka a</a> invent√© les math√©matiques pour le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Swift</a> alors pr√©cis√©ment sur Jetson.  En 2015, lors d'une r√©union avec Artec 3D, nous avons parl√© de ce qu'est une plate-forme cool, apr√®s quoi ils ont sugg√©r√© que nous construisions un prototype bas√© sur elle.  Apr√®s quelques mois, le prototype √©tait pr√™t.  Juste quelques ann√©es de travail de toute l'entreprise, quelques ann√©es de mal√©dictions sur la plate-forme et le paradis ... Et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Artec Leo</a> est n√© - le scanner le plus cool de sa cat√©gorie.  M√™me Nvidia lors de la pr√©sentation de TX2 l'a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">montr√©</a> comme l'un des projets les plus int√©ressants cr√©√©s sur la plateforme. <br>  Depuis lors, TX1 / TX2 / Nano nous avons utilis√© quelque part dans 5-6 projets. <br>  Et, probablement, nous connaissons tous les probl√®mes qui √©taient avec la plate-forme.  Prenons-le dans l'ordre. <br><br><h3>  Jetson tk1 </h3><br>  Je ne parlerai pas sp√©cialement de lui.  La plate-forme √©tait tr√®s efficace en termes de puissance de calcul √† son √©poque.  Mais elle n'√©tait pas √† l'√©picerie.  NVIDIA a vendu les puces <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TegraTK1</a> qui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">soutenaient</a> Jetson.  Mais ces puces √©taient impossibles √† utiliser pour les petits et moyens fabricants.  En r√©alit√©, seuls Google / HTC / Xiaomi / Acer / Google pourraient faire quelque chose sur eux en plus de Nvidia.  Tous les autres int√©gr√©s dans la prod, soit des cartes de d√©bogage, soit pill√© d'autres appareils. <br><br><h3>  Jetson TX1 | TX2 </h3><br>  Nvidia a tir√© les bonnes conclusions, et la g√©n√©ration suivante a √©t√© faite de mani√®re impressionnante.  TX1 | TX2, ce ne sont plus des puces, mais une puce sur la carte. <br><img width="300" src="https://habrastorage.org/getpro/habr/post_images/c2c/6d4/dec/c2c6d4dec3a41c852c05d055b231bd06.jpg" alt="image"><img width="300" src="https://habrastorage.org/getpro/habr/post_images/411/694/e40/411694e401d5c4665e280ab0a6b8a4b6.png" alt="image"><br>  Ils sont plus chers, mais ont un niveau d'√©picerie complet.  Une petite entreprise peut les int√©grer dans son produit, ce produit est pr√©visible et stable.  J'ai personnellement vu comment 3-4 produits ont √©t√© mis en production - et tout s'est bien pass√©. <br>  Je vais parler de TX2, car √† partir de la ligne actuelle, c'est la carte principale. <br>  Mais, bien s√ªr, tous ne remercient pas Dieu.  Quel est le probl√®me: <br><ol><li>  Jetson TX2 est une plate-forme co√ªteuse.  Dans la plupart des produits, vous utiliserez le module principal (si je comprends bien, compte tenu de la taille du lot, le prix sera compris entre 200-250 et 350-400 cu chacun).  Il a besoin d'un CarrierBoard.  Je ne connais pas le march√© actuel, mais auparavant c'√©tait environ 100-300 cu  selon la configuration.  Eh bien, et en plus de votre kit carrosserie. </li><li>  Jetson TX2 n'est pas la plateforme la plus rapide.  Ci-dessous, nous discuterons des vitesses comparatives, l√†, je montrerai pourquoi ce n'est pas la meilleure option. </li><li>  Il est n√©cessaire d'√©liminer beaucoup de chaleur.  Cela est probablement vrai pour presque toutes les plateformes dont nous parlerons.  Le bo√Ætier doit r√©soudre le probl√®me de dissipation thermique.  Les fans </li><li>  C'est une mauvaise plateforme pour les petits partis.  Beaucoup de centaines d'appareils - env.  Commander des cartes m√®res, d√©velopper des designs et des emballages est la norme.  Beaucoup de milliers d'appareils?  Concevez votre carte m√®re - et chic.  Si vous avez besoin de 5-10 - mauvais.  Vous devrez probablement prendre DevBoard.  Ils sont gros, ils sont un peu d√©go√ªtants √† flasher.  Ce n'est pas une plate-forme compatible RPi. </li><li>  Support technique m√©diocre de Nvidia.  J'ai entendu beaucoup de jurons que les r√©ponses sont r√©pondues que ce sont des informations secr√®tes ou des r√©ponses mensuelles. </li><li>  Mauvaise infrastructure en Russie.  Il est difficile de commander, cela prend beaucoup de temps.  Mais en m√™me temps, les concessionnaires fonctionnent bien.  Je suis r√©cemment tomb√© sur un Jetson nano qui a grill√© le jour du lancement - chang√© sans question.  Sam ramass√© par courrier / a apport√© un nouveau.  WAH!  De plus, il a lui-m√™me constat√© que le bureau de Moscou donne de bons conseils.  Mais d√®s que leur niveau de connaissance ne permet pas de r√©pondre √† la question et n√©cessite une demande aupr√®s du bureau international - ils devront attendre longtemps pour obtenir des r√©ponses. </li></ol><br><br>  Ce qui est g√©nial: <br><ol><li>  Beaucoup d'informations, une tr√®s grande communaut√©. </li><li>  Autour de Nvidia, de nombreuses petites entreprises fabriquent des accessoires.  Ils sont ouverts aux n√©gociations, vous pouvez r√©gler leur d√©cision.  Et CarierBoard, et le firmware, et les syst√®mes de refroidissement. </li><li>  Prise en charge de tous les frameworks normaux (TensorFlow | PyTorch) et prise en charge compl√®te de tous les r√©seaux.  La seule conversion que vous pourriez avoir √† faire est de transf√©rer le code vers TensorRT.  Cela permettra d'√©conomiser de la m√©moire, voire d'acc√©l√©rer.  Compar√© √† ce qui sera sur d'autres plateformes, c'est ridicule. </li><li>  Je ne sais pas comment √©lever des planches.  Mais de ceux qui ont fait cela pour Nvidia, j'ai entendu que TX2 est une bonne option.  Il existe des manuels qui correspondent √† la r√©alit√©. </li><li>  Bonne consommation d'√©nergie.  Mais de tout cela, exactement ¬´int√©gr√©¬ª sera avec nous - le pire :) </li><li>  Pied √† coulisse en Russie (expliqu√© ci-dessus pourquoi) </li><li>  Contrairement √† movidius |  RPi |  Corail |  Gyrfalcon est un vrai GPU.  Vous pouvez y conduire non seulement des grilles, mais aussi des algorithmes normaux </li></ol><br><br>  En cons√©quence, c'est une bonne plate-forme pour vous si vous avez des appareils √† pi√®ce, mais pour une raison quelconque, vous ne pouvez pas fournir un ordinateur √† part enti√®re.  Quelque chose d'√©norme?  Biom√©trie - probablement pas.  La reconnaissance des nombres est √† la limite, selon le flux.  Appareils portables avec un prix de plus de 5 000 dollars - possible.  Voitures - non, il est plus facile de mettre une plate-forme plus puissante un peu plus cher. <br>  Il me semble qu'avec la sortie d'une nouvelle g√©n√©ration d'appareils bon march√©, TX2 mourra avec le temps. <br><br>  Les cartes m√®res pour Jetson TX1 | TX2 | TX2i et d'autres ressemblent √† ceci: <br><img src="https://habrastorage.org/getpro/habr/post_images/05c/ad5/2fc/05cad52fc3ba0b3468b7cea85a2f2552.png" alt="image"><br>  Et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici, il y a</a> plus de variations. <br><br><h3>  Jetson nano </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/9af/40b/1d8/9af40b1d8153cf212cbd2f76a533b143.png" alt="image"><br>  Jetson Nano est une chose tr√®s int√©ressante.  Pour Nvidia, il s'agit d'un nouveau facteur de forme qui, en termes de r√©volution, devrait √™tre compar√© au TK1.  Mais les concurrents s'√©puisent d√©j√†.  Il y a d'autres appareils dont nous allons parler.  Il est 2 fois plus faible que TX2, mais 4 fois moins cher.  Plus pr√©cis√©ment ... Les math√©matiques sont compliqu√©es.  Jetson Nano sur la carte de d√©monstration co√ªte 100 dollars (en Europe).  Mais si vous n'achetez qu'une puce, ce sera plus cher.  Et vous devrez l'√©lever (il n'y a pas encore de carte m√®re pour lui).  Et Dieu ne plaise que ce sera 2 fois moins cher sur une grande f√™te que TX2. <br>  En fait, Jetson Nano, sur sa carte de base, est un tel produit publicitaire pour les instituts / revendeurs / amateurs, ce qui devrait stimuler l'int√©r√™t et l'application commerciale.  Par avantages et inconv√©nients (intersecte partiellement avec TX2): <br><ol><li>  La conception est faible et non d√©bogu√©e: <br><ul><li>  Il surchauffe, avec une charge constante se bloque p√©riodiquement / vole.  Une entreprise famili√®re essaie de r√©soudre tous les probl√®mes depuis 3 mois - cela ne fonctionne pas. </li><li>  J'en ai un grill√© lorsqu'il est aliment√© par USB.  J'ai entendu dire qu'un ami avait une sortie USB grill√©e et que la fiche fonctionnait.  Tr√®s probablement quelques probl√®mes avec l'alimentation USB. </li><li>  Si vous emballez la carte d'origine, alors il n'y aura pas assez de radiateur de NVIDIA, par exemple, il surchauffera. </li></ul><br></li><li>  La vitesse n'est en quelque sorte pas suffisante.  Presque 2 fois moins que TX2 (en r√©alit√©, il peut √™tre 1,5, mais cela d√©pend de la t√¢che). </li><li>  Beaucoup de 5 √† 10 appareils sont g√©n√©ralement tr√®s bons.  50-200 - c'est difficile, vous devrez compenser tous les bugs du fabricant, le suspendre √† vos chiens, si vous avez besoin d'ajouter quelque chose comme POE, √ßa fera mal.  Grands partis.  Aujourd'hui, je n'ai pas entendu parler de projets r√©ussis.  Mais il me semble que des difficult√©s peuvent surgir comme avec TK1.  Pour √™tre honn√™te, j'esp√®re que l'ann√©e prochaine, Jetson Nano 2 sortira, o√π ces maladies infantiles seront corrig√©es. </li><li>  Le support est mauvais, identique √† TX2 </li><li>  Mauvaise infrastructure </li></ol><br><br>  Bon: <br><ol><li>  Un budget suffisant par rapport aux concurrents.  Surtout pour les petites f√™tes.  Prix ‚Äã‚Äãavantageux / performance </li><li>  Contrairement √† movidius |  RPi |  Corail |  Gyrfalcon est un vrai GPU.  Vous pouvez y conduire non seulement des grilles, mais aussi des algorithmes normaux </li><li>  Il suffit de d√©marrer n'importe quel r√©seau (identique √† tx2) </li><li>  Consommation √©lectrique (identique √† tx2) </li><li>  Pied √† coulisse en Russie (identique au tx2) </li></ol><br><br>  Nano lui-m√™me est sorti au d√©but du printemps, quelque part en avril / mai, je l'ai pouss√© activement.  Nous avons d√©j√† r√©ussi √† faire deux projets dessus.  En g√©n√©ral, les probl√®mes identifi√©s ci-dessus.  En tant que produit de loisir / produit pour les petits lots - tr√®s cool.  Mais il n'est pas encore clair s'il est possible de faire glisser la production et comment le faire. <br><br><h3>  Parlez de la vitesse de Jetson. </h3><br>  Nous comparerons avec d'autres appareils beaucoup plus tard.  En attendant, il suffit de parler de Jetson et de la vitesse.  Pourquoi Nvidia nous ment.  Comment optimiser vos projets. <br>  Ci-dessous, tout est √©crit sur TensorRT-5.1.  TensorRT-6.0.1 a √©t√© publi√© le 17 septembre 2019, toutes les d√©clarations doivent y √™tre rev√©rifi√©es. <br>  Supposons que nous croyons Nvidia.  Ouvrons leur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">site Web</a> et voyons le temps d'inf√©rence de SSD-mobilenet-v2 √† 300 * 300: <br><img width="800" src="https://habrastorage.org/getpro/habr/post_images/8bd/9aa/098/8bd9aa098ffe1e06c3b78d9f88f64dab.png" alt="image"><br>  Wow, 39 images par seconde (25 ms).  Oui, et le code source est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pr√©sent√©</a> ! <br><br>  Hmm ... Mais pourquoi est-il √©crit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici √†</a> propos de 46 ms? <br><br>  Attendez ... Et ici, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ils</a> √©crivent que 309 ms est natif, et 72ms est port√© ... <br><br><img width="800" src="https://habrastorage.org/getpro/habr/post_images/32f/fd2/526/32ffd25260529f142b84a127c6d7a75c.png" alt="image"><br><br>  O√π est la v√©rit√©? <br>  La v√©rit√© est que tout le monde pense tr√®s diff√©remment: <br><ol><li>  Le SSD se compose de deux parties.  Une partie est le neurone.  La deuxi√®me partie est le post-traitement de ce que le neurone a produit (suppression non maximale) + le pr√©-traitement de ce qui est charg√© en entr√©e. </li><li>  Comme je l'ai dit plus t√¥t, sous Jetson, tout doit √™tre converti en TensorRT.  Il s'agit d'un tel framework natif de NVIDIA.  Sans cela, tout sera mauvais.  Seulement, il y a un probl√®me.  Tout n'y est pas port√©, surtout depuis TensorFlow.  √Ä l'√©chelle mondiale, il existe deux approches: <br><ul><li>  Google, r√©alisant que c'est un probl√®me, a publi√© pour TensorFlow une chose appel√©e "tf-trt".  En fait, c'est un add-on sur tf, qui vous permet de convertir n'importe quelle grille en tensorrt.  Les parties qui ne sont pas prises en charge sont d√©duites sur le CPU, le reste sur le GPU. </li><li>  R√©√©crire tous les calques / trouver leurs analogues </li></ul><br></li></ol><br>  Dans les exemples ci-dessus: <br><ul><li>  Dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> lien, le temps de 300 ms est le flux tensoriel habituel sans optimisation. </li><li>  L√†, 72ms est la version tf-trt.  L√†, tous les nms se font essentiellement sur le processus. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Il s'agit d'une</a> version fan, o√π une personne a transf√©r√© tous les nms et l'a √©crite sur gpu lui-m√™me. </li><li>  Et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ceci</a> ... Ce NVIDIA a d√©cid√© de mesurer toutes les performances sans post-traitement, sans le mentionner explicitement n'importe o√π. </li></ul><br><br>  Vous devez comprendre par vous-m√™me que s'il s'agissait de votre neurone, que personne n'aurait converti avant vous, alors sans probl√®me, vous seriez en mesure de le lancer √† une vitesse de 72 ms.  Et √† une vitesse de 46 ms, assis sur les manuels et sorsa jour-semaine. <br>  Compar√© √† de nombreuses autres options, c'est tr√®s bien.  Mais n'oubliez pas que quoi que vous fassiez - ne croyez jamais aux r√©f√©rences de NVIDIA! <br><br><h2>  FramboisePI 4 </h2><br>  Production? .. Et j'entends comment des dizaines d'ing√©nieurs se mettent √† rire √† la mention des mots ¬´RPI¬ª et ¬´production¬ª tout pr√®s.  Mais, je dois dire - RPI est toujours plus stable que Jetson Nano et Google Coral.  Mais, bien s√ªr, TX2 perd et, apparemment, le gyrfalcone. <br><img src="https://habrastorage.org/getpro/habr/post_images/667/aa5/dbc/667aa5dbc7be87aeda247492035b3c33.jpg" alt="image"><br>  (L'image vient <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'ici</a> . Il me semble que la fixation de ventilateurs au RPi4 est un amusement folklorique distinct.) <br>  De toute la liste, c'est le seul appareil que je n'ai pas tenu entre les mains / que je n'ai pas test√©.  Mais il a d√©marr√© des neurones sur Rpi, Rpi2, Rpi3 (par exemple, il me l'a dit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ).  En g√©n√©ral, Rpi4, si je comprends bien, ne diff√®re que par les performances.  Il me semble que les avantages et les inconv√©nients de RPi savent tout, mais quand m√™me.  Inconv√©nients: <br><br><ol><li>  Autant que je ne voudrais pas, ce n'est pas une solution d'√©picerie.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Surchauffe</a> .  Gel p√©riodique.  Mais en raison de l'immense communaut√©, il existe des centaines de solutions √† chaque probl√®me.  Cela ne rend pas Rpi bon pour des milliers de tirages.  Mais des dizaines / centaines - des notes wai. </li><li>  La vitesse.  C'est l'appareil le plus lent de tous les principaux dont nous parlons. </li><li>  Il n'y a presque aucun support du fabricant.  Ce produit s'adresse aux passionn√©s. </li></ol><br>  Avantages: <br><br><ol><li>  Prix  Non, bien s√ªr, si vous √©levez la planche vous-m√™me, alors en utilisant du gyrfalcone, vous pouvez le rendre moins cher par milliers.  Mais ce n'est probablement pas r√©aliste.  L√† o√π les performances RPi sont suffisantes, ce sera la solution la moins ch√®re. </li><li>  Popularit√©.  Lorsque Caffe2 est sorti, il y avait une version pour Rpi dans la version de base.  Lumi√®re Tensorflow?  Bien s√ªr, cela fonctionne.  I.T.D., I.T.P.  Ce que le fabricant ne fait pas, c'est transf√©rer des utilisateurs.  J'ai couru sur diff√©rents RPi et Caffe et Tensorflow et PyTorch, et un tas de choses plus rares. </li><li>  Commodit√© pour les petites f√™tes / pi√®ces.  Il suffit de flasher le lecteur flash et de courir.  Il y a le WiFi √† bord, contrairement √† JetsonNano.  Vous pouvez simplement l'alimenter via PoE (il semble que vous ayez besoin d'acheter un adaptateur vendu activement). </li></ol><br><br>  Nous parlerons de la vitesse Rpi √† la fin.  √âtant donn√© que le fabricant ne postule que son produit pour les neurones, il existe peu de rep√®res.  Tout le monde comprend que Rpi n'est pas parfait en vitesse.  Mais m√™me lui convient √† certaines t√¢ches. <br>  Nous avions quelques t√¢ches semi-produit que nous avons mises en ≈ìuvre chez Rpi.  L'impression √©tait agr√©able. <br><br><h2>  Movidius 2 </h2><br><img width="800" src="https://habrastorage.org/webt/ki/gq/l3/kigql3xgdsddqwgx-iwrjznthpc.jpeg"><br>  √Ä partir d'ici et ci-dessous, pas de processeurs √† part enti√®re, mais des processeurs con√ßus sp√©cifiquement pour les r√©seaux de neurones.  C'est comme si leurs forces et leurs faiblesses √©taient en m√™me temps. <br>  Alors.  Movidius.  La soci√©t√© a √©t√© achet√©e par Intel en 2016.  Dans le segment qui nous int√©resse, la soci√©t√© a sorti deux produits, Movidius et Movidius 2. Le second est plus rapide, nous ne parlerons que du second. <br>  Non, pas comme √ßa.  La conversation ne devrait pas commencer avec Movidius, mais avec Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenVino</a> .  Je dirais que c'est de l'id√©ologie.  Plus pr√©cis√©ment, le cadre.  En fait, il s'agit d'un ensemble de neurones pr√©-entra√Æn√©s et d'inf√©rences qui sont optimis√©s pour les produits Intel (processeurs, GPU, ordinateurs sp√©ciaux).  Int√©gr√© avec OpenCV, avec le Raspberry Pi, avec un tas d'autres sifflets et pets. <br>  L'avantage d'OpenVino est qu'il a beaucoup de neurones.  Tout d'abord, les d√©tecteurs les plus connus.  Neurones pour la reconnaissance des personnes, des personnes, des chiffres, des lettres, des poses, etc., etc.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3</a> ).  Et ils sont form√©s.  Pas par des ensembles de donn√©es ouverts, mais par des ensembles de donn√©es compil√©s par Intel lui-m√™me.  Ils sont beaucoup plus grands / plus diversifi√©s et mieux ouverts.  Ils peuvent √™tre recycl√©s en fonction de vos cas, puis ils fonctionneront g√©n√©ralement cool. <br>  Est-il possible de faire mieux?  Bien s√ªr que vous le pouvez.  Par exemple, la reconnaissance des chiffres que nous avons faits - a fonctionn√© beaucoup mieux.  Mais nous avons pass√© de nombreuses ann√©es √† le d√©velopper et √† comprendre comment le rendre parfait.         ,      . <br>  OpenVino, ,   .      .  -   ‚Äî   .     .  GAN    .   . ,   ,     ,     -   ,    .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ,    : <br><img src="https://habrastorage.org/getpro/habr/post_images/103/de3/8ad/103de38adbea7450a4f7888ef135303c.png" alt="image"><br>  ,  Intel   OpenVino    .     .  ,       .         ‚Äî      .    70%       OpenVino. <br>      Movidius    .         .       (    ,   ). <br>     . USB , ,   !!!       USB.  . Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> .  -        ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ) <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>   .               -.     -         . <br>      ?..       :) <br>  ,   . OpenVino,   ,   ,    (    Computer Vision  ).      : <br><iframe width="560" height="315" src="https://www.youtube.com/embed/ogHrgixuFzg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br> (   AI 2.0,   OpenVino  ). <br><br> ,     .    Movidius 2. : <br><ol><li>    .  Rpi  Jetson Nano.            ‚Äî  .        .   Third Party ? </li><li>    .     .     . </li><li>    .    . </li><li>     .           USB 3.0 </li><li>    ,        .   -.     .  Movidius      .      . </li></ol><br>  Avantages: <br><ol><li>    .        .    . </li><li>  ,   </li><li>  ,    </li></ol><br>         .          ‚Äî      . <br>      ,     ‚Äú   20-30   ,     ,  ‚Äù ‚Äî       Movidius. <br>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>  .      , . <br><img src="https://habrastorage.org/webt/d0/m-/ec/d0m-ecz9npk5f11jwlr0pzxruwi.jpeg" alt="image"><br>  <b>UPD</b> <br>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> .     .   embedded . PCI-e      .       .   ‚Äî        200 .. .         ‚Ä¶ <br><br><h2> Google Coral </h2><br>  Je suis d√©√ßu.  Non, il n'y a rien que je ne pr√©dis.  Mais je suis d√©√ßu que Google ait d√©cid√© de publier cela.  Les tests sont un miracle au d√©but de l'√©t√©.  Peut-√™tre que quelque chose a chang√© depuis, mais je vais d√©crire mon exp√©rience de cette √©poque. <br>  Mise en place ... Pour flasher Jetson Tk-Tx1-Tx2, vous deviez le brancher sur l'ordinateur h√¥te et sur l'alimentation.  Et c'√©tait suffisant.  Pour flasher Jetson Nano et RPi, il vous suffit de pousser l'image sur la cl√© USB. <br>  Et pour flasher Coral, vous devez coller trois fils dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bon ordre</a> : <br><img src="https://habrastorage.org/webt/de/b4/hs/deb4hsbxm_ra3ajx7_kuoljd0ls.jpeg"><br>  Et n'essayez pas de vous tromper!  Soit dit en passant, il y a des erreurs / un comportement indescriptible dans le guide.  Je ne vais probablement pas les d√©crire, car depuis le d√©but de l'√©t√©, ils auraient pu r√©parer quelque chose.  Je me souviens qu'apr√®s l'installation de Mendel, tout acc√®s via ssh a √©t√© perdu, y compris celui d√©crit par eux, j'ai d√ª modifier manuellement certaines configurations Linux. <br>  Il m'a fallu 2-3 heures pour terminer ce processus. <br>  Ok  Lanc√©.  Pensez-vous qu'il est facile de faire fonctionner votre grille dessus?  Presque rien :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici une</a> liste de ce que vous pouvez laisser aller. <br>  Pour √™tre honn√™te, je ne suis pas arriv√© √† ce point rapidement.  Nous avons pass√© une demi-journ√©e.  Non vraiment.  Vous ne pouvez pas t√©l√©charger le mod√®le √† partir <a href="">du r√©f√©rentiel TF</a> et l'ex√©cuter sur l'appareil.  Ou l√†, il est n√©cessaire de recouper toutes les couches.  Je n'ai pas trouv√© d'instructions. <br>  Alors voil√†.  Il est n√©cessaire de prendre le mod√®le du r√©f√©rentiel d'en haut.  Ils sont peu nombreux (3 mod√®les ont √©t√© ajout√©s depuis le d√©but de l'√©t√©).  Et comment la former?  Ouvrir dans TensorFlow dans un pipeline standard?  HAHAHAHAHAHAHAHAHA.  Bien s√ªr que non !!! <br>  Vous avez un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conteneur Doker</a> sp√©cial et le mod√®le ne s'y entra√Ænera que.  (Probablement, vous pouvez √©galement vous moquer de votre TF ... Mais il y a des instructions, des instructions ... qui ne l'√©taient pas et ne semblent pas l'√™tre.) <br>  T√©l√©charger / installer / lancer.  Qu'est-ce que c'est ... Pourquoi le GPU est-il √† z√©ro? .. PARCE QUE LA FORMATION SERA SUR LE CPU.  Docker n'est que pour lui !!!  Vous voulez plus de plaisir?  Le manuel indique ¬´bas√© sur un processeur √† 6 c≈ìurs avec station de travail √† m√©moire 64G¬ª.  Il semble que ce ne soit qu'un conseil?  Peut-√™tre.  Ce n'est que maintenant que je n'avais pas assez de mes 8 concerts sur ce serveur o√π la plupart des mod√®les s'entra√Ænent.  L'entra√Ænement √† la 4 e heure les a tous consomm√©s.  Un fort sentiment qu'ils avaient quelque chose qui coule.  J'ai essay√© quelques jours avec diff√©rents param√®tres sur diff√©rentes machines, l'effet √©tait un. <br>  Je n'ai pas rev√©rifi√© cela avant de poster l'article.  Pour √™tre honn√™te, cela m'a suffi une fois. <br>  Quoi d'autre √† ajouter?  Que ce code ne g√©n√®re pas de mod√®le?  Pour le g√©n√©rer, vous devez: <br><br><ol><li>  Nombre de retards </li><li>  Le convertir en tflite </li><li>  Compiler vers TPU Edge formel.  Dieu merci, cela se fait sur un ordinateur.  Au printemps, cela ne pouvait se faire qu'en ligne.  Et l√†, il fallait cocher ¬´Je ne l'utiliserai pas pour le mal / je ne viole aucune loi avec ce mod√®le¬ª.  Maintenant, Dieu merci, il n'y a rien de tout cela. </li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/2ef/84d/b88/2ef84db88bcaba5d18a97c23bf5f2605.png" alt="image"><br>  C'est le plus grand d√©go√ªt que j'ai connu √† l'√©gard d'un produit informatique au cours de la derni√®re ann√©e ... <br>  Globalement, Coral devrait avoir la m√™me id√©ologie qu'OpenVino avec Movidius.  Ce n'est que maintenant qu'Intel est sur cette voie depuis plusieurs ann√©es.  Avec d'excellents manuels, support et bons produits ... Et Google.  Eh bien, c'est juste Google ... <br>  Inconv√©nients: <br><ol><li>  Ce tableau n'est pas une √©picerie au niveau AD.  Je n'ai pas entendu parler de la vente de chips =&gt; la production est irr√©aliste </li><li>  Le niveau de d√©veloppement est aussi terrible que possible.  Tout bazhet.  Le pipeline de d√©veloppement ne rentre pas dans les sch√©mas traditionnels. </li><li>  Le ventilateur.  Sur la ¬´puce √©nerg√©tiquement optimale¬ª, ils l'ont mis.  D'accord, je ne parlerai plus de production. </li><li>  Co√ªt.  Plus cher que TX2. </li><li>  Deux grilles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ne peuvent pas √™tre</a> conserv√©es en m√©moire en m√™me temps.  Il est n√©cessaire d'effectuer un t√©l√©chargement-t√©l√©chargement.  Ce qui ralentit l'inf√©rence de plusieurs r√©seaux. </li></ol><br>  Avantages: <br><ol><li>  De tout ce dont nous parlons, le corail est le plus rapide </li><li>  Potentiellement, si la puce est √©lev√©e, elle est plus productive que Movidius.  Et il semble que son architecture soit plus justifi√©e pour les neurones. </li></ol><br><br><h2>  Faucon gerfaut </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/640/86e/595/64086e5959ce67c2a21dc80c3106e49d.png" alt="image"><br>  Les derniers un an et demi ont parl√© de cette b√™te chinoise.  Il y a encore un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">an,</a> je parlais de lui.  Mais parler est une chose et donner des informations en est une autre.  J'ai parl√© avec 3-4 grandes entreprises, o√π les chefs de projet / directeurs m'ont dit √† quel point ce Girfalkon √©tait cool.  Mais ils n'avaient aucune documentation.  Et ils ne l'ont pas vu vivant.  Le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">site ne contient</a> presque aucune information.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">T√©l√©charger √†</a> partir du site au moins quelque chose ne peut que les partenaires (d√©veloppeurs de mat√©riel).  De plus, les informations sur le site sont tr√®s contradictoires.  Dans un endroit, ils √©crivent qu'ils ne prennent en charge que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VGG</a> , dans un autre que seuls leurs neurones sont bas√©s sur GNet (qui, selon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">leurs assurances, sont</a> tr√®s petits et vraiment sans perte de pr√©cision).  Dans le troisi√®me, il est √©crit que tout est converti avec TF | Caffe | PyTorch, et dans le quatri√®me, il est √©crit sur le t√©l√©phone portable et d'autres charmes. <br>  Comprendre la v√©rit√© est presque impossible.  Une fois que je creusais et creusais quelques vid√©os dans lesquelles au moins certains chiffres glissaient: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/AoidCoMK8v0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eS6eCAEL_1A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Si cela est vrai, cela signifie SSD (sur mobile?) Sous 224 * 224 sur la puce GTI2801, ils ont ~ 60 ms, ce qui est assez comparable √† movidius. <br>  Il semble qu'ils aient une puce 2803 beaucoup plus rapide, mais les informations √† ce sujet sont encore moins: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQvVqaVZUQ4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Cet √©t√©, nous avons entre nos mains une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">carte</a> Firefly ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> module y est install√© pour les calculs). <br><br>  Il y avait un espoir que nous pourrions enfin voir en vie.  Mais √ßa n'a pas march√©.  Le tableau √©tait visible, mais ne fonctionnait pas.  En parcourant des phrases anglaises individuelles dans la documentation chinoise, ils ont m√™me presque compris quel √©tait le probl√®me (le syst√®me molet√© initial ne supportait pas le module neuronal, il √©tait n√©cessaire de reconstruire et de tout relancer nous-m√™mes).  Mais cela n'a tout simplement pas fonctionn√©, et on soup√ßonnait d√©j√† que la carte ne correspondrait pas √† notre t√¢che (2 Go de RAM est tr√®s petit pour les r√©seaux + syst√®mes neuronaux. De plus, il n'y avait pas de support pour deux r√©seaux en m√™me temps). <br>  Mais j'ai r√©ussi √† voir la documentation d'origine.  On en comprend trop peu (chinois).  Pour de bon il fallait tester et regarder la source. <br>  Le support technique de RockChip a b√™tement marqu√© pour nous. <br>  Malgr√© cette horreur, il est clair pour moi qu'ici, tout de m√™me, les jambages de RockChip sont ici avant tout.  Et j'ai l'espoir que dans une planche normale, Gyrfalcon peut √™tre assez utilis√©.  Mais en raison du manque d'informations, il m'est difficile de le dire. <br><br>  Inconv√©nients: <br><ol><li>  Pas de ventes ouvertes, interagissez uniquement avec les entreprises </li><li>  Peu d'informations, pas de communaut√©.  Les informations existantes sont souvent en chinois.  Les fonctionnalit√©s de la plateforme ne peuvent pas √™tre pr√©dites √† l'avance </li><li>  Il est tr√®s probable que l'inf√©rence ne concerne pas plus d'un r√©seau √† la fois. </li><li>  Seuls les fabricants de fer peuvent interagir avec l'autogire lui-m√™me.  Les autres doivent rechercher des interm√©diaires / fabricants de cartes. </li></ol><br>  Avantages: <br><ol><li>  Si je comprends bien, le prix d'une puce girfcon est beaucoup moins cher que le reste.  M√™me sous forme de lecteurs flash. </li><li>  Il existe d√©j√† des appareils tiers avec une puce int√©gr√©e.  Par cons√©quent, le d√©veloppement est un peu plus facile que movidius. </li><li>  Ils assurent qu'il existe de nombreuses grilles pr√©-form√©es, le transfert de grilles est beaucoup plus facile que Movidius | Coral.  Mais je ne garantirais pas cela comme la v√©rit√©.  Nous n'avons pas r√©ussi. </li></ol><br>  En bref, la conclusion est la suivante: tr√®s peu d'informations.  Vous ne pouvez pas seulement vous allonger sur cette plateforme.  Et avant de faire quelque chose, vous devez faire un examen approfondi. <br><br><h2>  Vitesses </h2><br>  J'aime vraiment la fa√ßon dont 90% des comparaisons d'appareils int√©gr√©s se r√©duisent √† des comparaisons de vitesse.  Comme vous l'avez compris plus haut, cette caract√©ristique est tr√®s arbitraire.  Pour Jetson Nano, vous pouvez ex√©cuter des neurones en tant que tensorflow pur, vous pouvez utiliser tensorflow-tensorrt, ou vous pouvez utiliser du tensorrt pur.  Les appareils avec une architecture tenseur sp√©ciale (movidius | coral | gyrfalcone) - peuvent √™tre rapides, mais en premier lieu, ils ne peuvent fonctionner qu'avec des architectures standard.  M√™me pour le Raspberry Pi, tout n'est pas si simple.  Les neurones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">xnor.ai</a> acc√©l√®rent une fois et demie.  Mais je ne sais pas √† quel point ils sont honn√™tes et ce qui a √©t√© gagn√© en passant √† l'int8 ou √† d'autres blagues. <br>  En m√™me temps, une autre chose int√©ressante est un tel moment.  Plus le neurone est complexe, plus le dispositif d'inf√©rence est complexe - plus l'acc√©l√©ration finale qui peut √™tre retir√©e est impr√©visible.  Prenez de l'OpenPose.  Il existe un r√©seau non trivial, un post-traitement complexe.  Ceci et cela peuvent √™tre optimis√©s gr√¢ce √†: <br><br><ul><li>  Migration de post-traitement GPU </li><li>  Optimiser le post-traitement </li><li>  Optimisation du r√©seau neuronal pour les fonctionnalit√©s de la plateforme, par exemple: <br><ul><li>  Utilisation de r√©seaux optimis√©s pour la plate-forme </li><li>  Utilisation de modules r√©seau pour la plateforme </li></ul><br></li><li>  Portage vers int8 | int16 | binarisation </li><li>  Utilisation de plusieurs calculatrices (GPU | CPU | etc.).  Je me souviens que sur Jetson TX1, nous avons une fois bien acc√©l√©r√© lorsque nous avons transf√©r√© toutes les fonctionnalit√©s li√©es au streaming vid√©o aux acc√©l√©rateurs int√©gr√©s √† ces fins.  Trite, mais le r√©seau s'est acc√©l√©r√©.  Lors de l'√©quilibrage, de nombreuses combinaisons int√©ressantes apparaissent </li></ul><br>  Parfois, quelqu'un essaie d'√©valuer quelque chose pour toutes les combinaisons possibles.  Mais vraiment, comme il me semble, c'est vain.  Vous devez d'abord d√©cider de la plate-forme, puis essayer ensuite de retirer compl√®tement tout ce qui est possible. <br><br>  Pourquoi suis-je tout cela.  En outre, le test ¬´ <i>combien de temps MobileNet</i> ¬ª est un tr√®s mauvais test.  Il peut dire que la plateforme X est optimale.  Mais lorsque vous essayez de d√©ployer votre neurone et de post-traiter l√†-bas, vous pouvez √™tre tr√®s d√©√ßu. <br>  Mais comparer mobilnet'ov donne quand m√™me quelques informations sur la plateforme.  Pour des t√¢ches simples.  Pour les situations o√π vous comprenez que de toute fa√ßon la t√¢che est plus facile √† r√©duire √† des approches standard.  Lorsque vous souhaitez √©valuer la vitesse de la calculatrice. <br>  Le tableau ci-dessous est extrait de plusieurs endroits: <br><ul><li>  Ces √©tudes sont: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3</a> </li><li>  Pour les SSD, il existe un tel param√®tre ¬´nombre de classes de sortie¬ª.  Et √† partir de ce param√®tre, le taux d'inf√©rence peut varier consid√©rablement.  J'ai essay√© de choisir des √©tudes avec le m√™me nombre de classes.  Mais ce n'est peut-√™tre pas le cas partout. </li><li>  Notre exp√©rience avec TensorRT.  Je savais quels types fonctionnent, lesquels ne fonctionnent pas. </li><li>  Pour le faucon gerfaut, ces vid√©os sont bas√©es sur le fait que mobilnet v2 est l√† + une estimation du co√ªt du changement de zone.  Cette vid√©o dit que 2803 peut √™tre 3-4 fois plus rapide.  Mais pour 2803, il n'y a pas de classification SSD.  En g√©n√©ral, je doute le plus des vitesses √† ce stade. </li><li>  J'ai essay√© de choisir l'√©tude qui donnait la vraie vitesse maximale (je n'ai pas pris la version de Nvidia sans NMS par exemple) </li><li>  Pour Jetson TX2, j'ai utilis√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ces</a> notes, mais il y a 5 classes, sur le m√™me nombre de classes que le reste sera plus lent.  J'ai en quelque sorte compris √† partir de l'exp√©rience / comparaison avec Nano dans les noyaux ce qui devrait √™tre l√† </li><li>  Je n'ai pas pris en compte les blagues √† d√©bit binaire.  Je ne sais pas sur quoi ont travaill√© les t√©moins Movidius et Gyrfalcon. </li></ul><br>  En cons√©quence, nous avons: <br><img src="https://habrastorage.org/webt/it/eb/z7/itebz7bgvqmgcupodynat7rr0hy.png"><br><br><h2>  Comparaison des plateformes </h2><br>  Je vais essayer de rassembler tout ce que j'ai dit ci-dessus dans une seule table.  J'ai soulign√© en jaune les endroits o√π mes connaissances ne suffisent pas pour tirer une conclusion sans ambigu√Øt√©.  Et, en fait 1-6 - c'est une √©valuation comparative des plates-formes.  Le plus proche de 1, mieux c'est. <br><img src="https://habrastorage.org/webt/6s/nm/xh/6snmxh9kx7xaufpayljpzvrfoaw.png"><br>  Je sais que la consommation d'√©nergie est critique pour beaucoup.  Mais il me semble que tout ici est quelque peu ambigu, et je le comprends trop mal - donc je n'y suis pas entr√©.  De plus, l'id√©ologie elle-m√™me semble √™tre la m√™me partout. <br><br><h2>  √âtape lat√©rale </h2><br>  Ce dont nous parlions n'est qu'un petit point dans le vaste espace de variations de votre syst√®me.  Probablement les mots communs qui peuvent caract√©riser ce domaine: <br><ul><li>  Faible consommation d'√©nergie </li><li>  Petite taille </li><li>  Puissance de calcul √©lev√©e </li></ul><br>  Mais, globalement, si vous r√©duisez l'importance d'un des crit√®res, vous pouvez ajouter de nombreux autres appareils √† la liste.  Ci-dessous, je vais passer en revue toutes les approches que j'ai rencontr√©es. <br><br><h2>  Intel </h2><br>  Comme nous l'avons dit lorsque nous avons discut√© de Movidius, Intel a une plate-forme OpenVino.  Il permet un traitement tr√®s efficace des neurones sur les processeurs Intel.  De plus, la plate-forme vous permet de prendre en charge m√™me toutes sortes d'intel-gpu sur une puce.  J'ai maintenant peur de dire exactement quel type de performance existe pour quelles t√¢ches.  Mais, si je comprends bien, une bonne pierre avec un GPU √† bord quite donne une performance de 1080.  Pour certaines t√¢ches, cela peut m√™me √™tre plus rapide. <br><img src="https://habrastorage.org/getpro/habr/post_images/3b3/16a/a09/3b316aa09dd4dcbe22f97e38474f300a.png" alt="image"><br>  Dans ce cas, le facteur de forme, par exemple Intel NUC, est assez compact.  Bon refroidissement, emballage, etc.  La vitesse sera plus rapide que celle du Jetson TX2.  Par disponibilit√© / facilit√© d'achat - beaucoup plus facile.  La stabilit√© de la plate-forme hors de la bo√Æte est plus √©lev√©e. <br>  Deux contre - consommation d'√©nergie et prix.  Le d√©veloppement est un peu plus compliqu√©. <br><br><h2>  Jetson agx </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/0d7/eb9/4e0/0d7eb94e037d0311f8bf2176b3044329.jpg" alt="image"><br>  Ceci est un autre jetson.  Essentiellement la version la plus ancienne.  La vitesse est environ 2 fois plus rapide que celle du Jetson TX2, et les calculs int8 sont pris en charge, ce qui vous permet d'overclocker encore 4 fois.  Au fait, regardez cette <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">photo</a> de Nvidia: <br><img src="https://habrastorage.org/getpro/habr/post_images/800/c4a/bf1/800c4abf1ed98c8ec84815586c503491.png" alt="image"><br>  Ils comparent deux de leurs propres Jetson.  Un en int8, le second en int32.  Je ne sais m√™me pas quels mots dire ici ... En bref: "NE JAMAIS CROIRE √Ä NVIDIA GRAPHICS". <br>  Malgr√© le fait que AGX est bon - il n'atteint pas les GPU normaux de Nvidia en termes de puissance de calcul.  N√©anmoins, en termes d'efficacit√© √©nerg√©tique - ils sont tr√®s cool.  Le principal moins le prix. <br>  Nous-m√™mes n'avons pas travaill√© avec eux, il m'est donc difficile de dire quelque chose de plus d√©taill√©, de d√©crire la gamme de t√¢ches o√π elles sont les plus optimales. <br><br><h2>  Nvidia gpu |  version portable </h2><br>  Si vous supprimez la restriction stricte de la consommation d'√©nergie, le Jetson TX2 ne semble pas optimal.  Comme l'AGX.  Habituellement, les gens ont peur d'utiliser le GPU en production.  Paiement s√©par√©, tout √ßa. <br>  Mais il y a des millions d'entreprises qui vous proposent d'assembler une solution personnalis√©e sur une seule carte.  Ce sont g√©n√©ralement des cartes pour ordinateurs portables / mini-ordinateurs.  Ou, √† la fin, comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ceci</a> : <br><img src="https://habrastorage.org/getpro/habr/post_images/ee9/37d/cdf/ee937dcdf590661d003a1b1201d3ce46.png" alt="image"><br>  L'une des startups dans lesquelles je travaille depuis 2,5 ans ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CherryHome</a> ) a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">emprunt√©</a> cette voie.  Et nous en sommes tr√®s satisfaits. <br>  Moins, comme d'habitude, de consommation d'√©nergie, ce qui n'√©tait pas critique pour nous.  Eh bien, le prix mord un peu. <br><br><h2>  T√©l√©phones portables </h2><br>  Je ne veux pas approfondir ce sujet.  Pour dire tout ce qui se trouve dans les t√©l√©phones portables modernes pour les neurones / quels frameworks / quel mat√©riel, etc., vous aurez besoin de plus d'un article avec cette taille.  Et compte tenu du fait que nous n'avons pouss√© dans cette direction que 2-3 fois, je me consid√®re comme incomp√©tent pour cela.  Donc, juste quelques observations: <br><ol><li>  Il existe de nombreux acc√©l√©rateurs mat√©riels sur lesquels les neurones peuvent √™tre optimis√©s. </li><li>  Il n'y a pas de solution g√©n√©rale qui va bien partout.  Il y a maintenant une tentative de faire de Tensorflow lite une telle solution.  Mais, si je comprends bien, il n'est pas encore devenu un. </li><li>  Certains fabricants ont leurs propres fermes sp√©cifiques.  Il y a un an, nous avons aid√© √† optimiser le cadre de Snapdragon.  Et c'√©tait terrible.  La qualit√© des neurones y est beaucoup plus faible que sur tout ce dont j'ai parl√© aujourd'hui.  Il n'y a pas de prise en charge pour 90% des calques, m√™me les plus basiques, tels que ¬´addition¬ª. </li><li>  Puisqu'il n'y a pas de python, l'inf√©rence des r√©seaux est tr√®s √©trange, illogique et peu pratique. </li><li>  En termes de performances, il arrive que tout soit tr√®s bon (par exemple, sur certains iphone). </li></ol><br>  Il me semble que pour les t√©l√©phones portables embarqu√©s n'est pas la meilleure solution (l'exception est certains syst√®mes de reconnaissance faciale √† petit budget).  Mais j'ai vu quelques cas lorsqu'ils ont √©t√© utilis√©s comme premiers prototypes. <br><br><h2>  Gap8 </h2><br>  √âtait r√©cemment √† une conf√©rence <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Usedata</a> .  Et l√†, l'un des rapports portait sur l'inf√©rence des neurones aux pourcentages les moins chers (GAP8).  Et, comme on dit, le besoin d'inventions est rus√©.  Dans l'histoire, un exemple √©tait tr√®s tir√© par les cheveux.  Mais l'auteur a expliqu√© comment ils avaient pu faire une d√©duction par visage en une seconde environ.  Sur une grille tr√®s simple, essentiellement sans d√©tecteur.  Par des optimisations folles et longues et des √©conomies sur les matchs. <br>  Je n'aime toujours pas de telles t√¢ches.  Aucune recherche, seulement du sang. <br>  Mais, il convient de reconna√Ætre que je peux imaginer des puzzles o√π des pourcentages √† faible consommation donnent un r√©sultat cool.  Probablement pas pour la reconnaissance faciale.  Mais quelque part o√π vous pouvez reconna√Ætre l'image d'entr√©e en 5 √† 10 secondes ... <br><br><h2>  Grove AI HAT </h2><br><img width="400" src="https://habrastorage.org/getpro/habr/post_images/3fa/b99/106/3fab99106dbf03025a9adbb98d7d77d5.jpg" alt="image"><br>  Lors de la pr√©paration de cet article, je suis tomb√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette</a> plateforme embarqu√©e.  Il y a tr√®s peu d'informations √† ce sujet.  Si je comprends bien, aucun soutien.  La productivit√© est √©galement √† z√©ro ... Et pas un seul test de vitesse ... <br><br><h2>  Reconnaissance serveur / √† distance </h2><br>  Chaque fois qu'ils viennent nous voir pour des conseils sur une plateforme embarqu√©e, je veux crier ¬´cours, imb√©ciles!¬ª.  Il est n√©cessaire d'√©valuer soigneusement la n√©cessit√© d'une telle solution.  D√©couvrez toutes les autres options.  Je conseille toujours √† tout le monde de faire un prototype avec une architecture serveur.  Et lors de son fonctionnement, c'est √† vous de d√©cider de mettre en ≈ìuvre ou non un v√©ritable embarqu√©.  Apr√®s tout, embarqu√© c'est: <br><ol><li>  Augmentation du temps de d√©veloppement, souvent 2-3 fois. </li><li>  Support et d√©bogage sophistiqu√©s en production.  Tout d√©veloppement avec ML est une r√©vision constante, une mise √† jour des neurones, des mises √† jour du syst√®me.  L'embarqu√© est encore plus difficile.  Comment recharger le firmware?  Et si vous avez d√©j√† acc√®s √† toutes les unit√©s, alors pourquoi calculer sur elles alors que vous pouvez calculer sur un seul appareil? </li><li>  Complexit√© du syst√®me / risque accru.  Plus de points d'√©chec.  Dans le m√™me temps, alors que le syst√®me ne fonctionne pas dans son ensemble, on peut ne pas comprendre: la plateforme est-elle adapt√©e √† cette t√¢che? </li><li>  Augmentation des prix.  C'est une chose de mettre une planche simple comme nano pi.  Et l'autre est d'acheter TX2. </li></ol><br>  Oui, je sais qu'il y a des t√¢ches o√π les d√©cisions du serveur ne peuvent pas √™tre prises.  Mais, curieusement, ils sont beaucoup plus petits qu'on ne le croit g√©n√©ralement. <br><br><h2>  Conclusions </h2><br>  Dans l'article, j'ai essay√© de me passer de conclusions √©videntes.  C'est plut√¥t une histoire sur ce qui est maintenant.  Pour tirer des conclusions - il est n√©cessaire d'enqu√™ter dans chaque cas.  Et pas seulement les plateformes.  Mais la t√¢che elle-m√™me.  Toute t√¢che peut √™tre l√©g√®rement simplifi√©e / l√©g√®rement modifi√©e / l√©g√®rement aiguis√©e sous l'appareil. <br>  Le probl√®me avec ce sujet est que le sujet change.  De nouveaux dispositifs / cadres / approches arrivent.  Par exemple, si NVIDIA active le support int8 pour Jetson Nano demain, la situation changera radicalement.  Lorsque j'√©cris cet article, je ne peux pas √™tre s√ªr que les informations n'ont pas chang√© il y a deux jours.  Mais j'esp√®re que ma courte histoire vous aidera √† mieux naviguer dans votre prochain projet. <br>  Ce serait cool si vous avez des informations suppl√©mentaires / J'ai rat√© quelque chose / J'ai dit quelque chose de mal - √©crivez les d√©tails ici. <br><br>  ps <br>  D√©j√† quand j'ai presque fini d'√©crire l'article, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">snakers4 a</a> laiss√© tomber un r√©cent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">post</a> de sa cha√Æne de t√©l√©gramme Spark en moi, qui est √† peu pr√®s les m√™mes probl√®mes avec Jetson.  Mais, comme je l'ai √©crit ci-dessus, - dans les conditions de toute consommation d'√©nergie - je mettrais quelque chose comme des zotacs ou IntelNUC.  Et comme jetson int√©gr√© n'est pas la pire plateforme. <br><br><img src="https://habrastorage.org/webt/k_/pg/ih/k_pgiheb6cx6kvxxebl4rc_jdei.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr468421/">https://habr.com/ru/post/fr468421/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr468407/index.html">5G - une technologie susceptible de ralentir le web</a></li>
<li><a href="../fr468409/index.html">Service Workers in Slack Client: Acc√©l√©ration de t√©l√©chargement et mode hors ligne</a></li>
<li><a href="../fr468413/index.html">Acc√©l√©ration instagram.com. 2e partie</a></li>
<li><a href="../fr468417/index.html">3CX v16 Update 3 Beta publi√© - appels vid√©o sur Android et iOS, connexion TLS des trunks SIP</a></li>
<li><a href="../fr468419/index.html">Google Analytics et RGPD: ai-je besoin du consentement de l'utilisateur?</a></li>
<li><a href="../fr468423/index.html">Pourquoi la norme USB a-t-elle d√ª √™tre rendue si compliqu√©e?</a></li>
<li><a href="../fr468427/index.html">Comment √™tre publi√© sur Google Play en 2019</a></li>
<li><a href="../fr468431/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 381 (16-22 septembre 2019)</a></li>
<li><a href="../fr468435/index.html">Travaillez avec la s√©mantique, les liens et l'analyse des pages Web: 16 formules Google Sheets utiles pour les professionnels du r√©f√©rencement</a></li>
<li><a href="../fr468437/index.html">Je reconnais le doux ... par la forme du conduit auditif. Une nouvelle fa√ßon d'identifier les utilisateurs</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
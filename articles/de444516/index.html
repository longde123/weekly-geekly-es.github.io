<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèº üéöÔ∏è üé´ Wolfenstein 3D: Raytracing mit WebGL1 üì´ üë©üèæ‚Äç‚úàÔ∏è üï•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nach dem Erscheinen der Nvidia RTX-Grafikkarten im letzten Sommer hat das Raytracing seine fr√ºhere Popularit√§t wiedererlangt. In den letzten Monaten w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wolfenstein 3D: Raytracing mit WebGL1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/444516/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/885/df3/33c/885df333c0da45fcbb909c01c5da9648.png" alt="Bild"></div><br>  Nach dem Erscheinen der Nvidia RTX-Grafikkarten im letzten Sommer hat das Raytracing seine fr√ºhere Popularit√§t wiedererlangt.  In den letzten Monaten wurde mein Twitter-Feed mit einem endlosen Strom von Grafikvergleichen mit aktiviertem und deaktiviertem RTX gef√ºllt. <br><br>  Nachdem ich so viele sch√∂ne Bilder bewundert hatte, wollte ich versuchen, den klassischen Forward-Renderer selbst mit einem Raytracer zu kombinieren. <br><br>  Da ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unter einem Syndrom der Ablehnung der Entwicklungen anderer Menschen leide</a> , habe ich meine eigene Hybrid-Rendering-Engine basierend auf WebGL1 erstellt.  Sie k√∂nnen hier mit dem Demo-Level-Rendering von Wolfenstein 3D mit den Kugeln (die ich aufgrund von Raytracing verwendet habe) spielen. <br><a name="habracut"></a><br><h3>  Prototyp </h3><br>  Ich habe dieses Projekt mit der Erstellung eines Prototyps begonnen und versucht, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">globale Beleuchtung mit Raytracing von Metro Exodus</a> wiederherzustellen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/262/61a/447/26261a447cd19758715a3cbde356eeb7.png"></div><br>  <i>Der erste Prototyp mit diffuser globaler Beleuchtung (Diffuse GI)</i> <br><br>  Der Prototyp basiert auf einem Forward-Renderer, der die gesamte Geometrie der Szene rendert.  Der zum Rastern der Geometrie verwendete Shader berechnet nicht nur die direkte Beleuchtung, sondern sendet auch zuf√§llige Strahlen von der Oberfl√§che der gerenderten Geometrie aus, um sie mithilfe des Raytracers zu akkumulieren, der die indirekte Reflexion von Licht von nicht gl√§nzenden Oberfl√§chen (Diffuse GI) verwendet. <br><br>  Im Bild oben k√∂nnen Sie sehen, wie alle Kugeln nur durch indirekte Beleuchtung korrekt beleuchtet werden (Lichtstrahlen werden von der Wand hinter der Kamera reflektiert).  Die Lichtquelle selbst ist von einer braunen Wand auf der linken Seite des Bildes bedeckt. <br><br><h3>  Wolfenstein 3D </h3><br>  Der Prototyp verwendet eine sehr einfache Szene.  Es hat nur eine Lichtquelle und es werden nur wenige Kugeln und W√ºrfel gerendert.  Dank dessen ist der Raytracing-Code im Shader sehr einfach.  Der Brute-Force-Zyklus zur √úberpr√ºfung der Kreuzung, bei dem der Strahl auf Schnitt mit allen W√ºrfeln und Kugeln in der Szene getestet wird, ist immer noch schnell genug, damit das Programm ihn in Echtzeit ausf√ºhren kann. <br><br>  Nachdem ich diesen Prototyp erstellt hatte, wollte ich etwas Komplexeres tun, indem ich der Szene mehr Geometrie und viele Lichtquellen hinzuf√ºgte. <br><br>  Das Problem mit einer komplexeren Umgebung ist, dass ich immer noch in der Lage sein muss, Strahlen in der Szene in Echtzeit zu verfolgen.  Normalerweise wird eine BVH-Struktur ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bounding Volume Hierarchy</a> ) verwendet, um den Raytracing-Prozess zu beschleunigen. Meine Entscheidung, dieses Projekt in WebGL1 zu erstellen, lie√ü dies jedoch nicht zu: Es ist unm√∂glich, 16-Bit-Daten in eine Textur in WebGL1 zu laden, und Bin√§roperationen k√∂nnen in einem Shader nicht verwendet werden.  Dies erschwert die vorl√§ufige Berechnung und Anwendung von BVH in WebGL1-Shadern. <br><br>  Deshalb habe ich mich daf√ºr f√ºr die Wolfenstein 3D-Demo entschieden.  2013 habe ich in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shadertoy</a> einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fragment-WebGL-Shader</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erstellt</a> , der nicht nur Wolfenstein-√§hnliche Ebenen rendert, sondern auch alle erforderlichen Texturen prozedural erstellt.  Aus meiner Erfahrung mit diesem Shader wusste ich, dass Wolfensteins gitterbasiertes Level-Design auch als schnelle und einfache Beschleunigungsstruktur verwendet werden kann und dass die Strahlverfolgung auf dieser Struktur sehr schnell sein wird. <br><br>  Unten finden Sie einen Screenshot der Demo, den Sie im Vollbildmodus hier abspielen k√∂nnen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://reindernijhoff.net/wolfrt</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eu/gl/fp/euglfpjgl9503fy-_hjdwmr5hdi.png"></div><br><h3>  Kurzbeschreibung </h3><br>  Die Demo verwendet eine Hybrid-Rendering-Engine.  Um alle Polygone im Rahmen zu rendern, wird die herk√∂mmliche Rasterung verwendet und das Ergebnis dann mit Schatten, diffusem GI und Reflexionen kombiniert, die durch Raytracing erzeugt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8f7/fd8/bb9/8f7fd8bb9324905edf5200fedb28bb7a.png"></div><br>  <i>Schatten</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/524/5b5/6ba/5245b56ba3a1feb02a9401857d625514.png"></div><br>  <i>Diffuse gi</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/885/df3/33c/885df333c0da45fcbb909c01c5da9648.png"></div><br>  <i>Reflexionen</i> <br><br><h3>  Proaktives Rendern </h3><br>  Wolfenstein-Karten k√∂nnen vollst√§ndig in ein zweidimensionales 64 √ó 64-Raster codiert werden.  Die in der Demo verwendete Karte basiert auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Ebene von Episode 1 von</a> Wolfenstein 3D. <br><br>  Beim Start wird die gesamte Geometrie erstellt, die zum √úbergeben des proaktiven Renderings erforderlich ist.  Aus Kartendaten wird ein Maschennetz erzeugt.  Au√üerdem werden Boden- und Deckenebenen sowie separate Maschen f√ºr Lichter, T√ºren und zuf√§llige Kugeln erstellt. <br><br>  Alle f√ºr W√§nde und T√ºren verwendeten Texturen sind in einem einzigen Texturatlas verpackt, sodass alle W√§nde in einem Zeichenaufruf gezeichnet werden k√∂nnen. <br><br><h4>  Schatten und Beleuchtung </h4><br>  Die direkte Beleuchtung wird in dem Shader berechnet, der f√ºr den Vorw√§rts-Rendering-Durchgang verwendet wird.  Jedes Fragment kann (maximal) von vier verschiedenen Quellen beleuchtet werden.  Um zu wissen, welche Quellen das Fragment im Shader beeinflussen k√∂nnen, wird beim Start der Demo die Suchtextur vorberechnet.  Diese Suchtextur hat eine Gr√∂√üe von 64 x 128 und codiert die Positionen der 4 n√§chsten Lichtquellen f√ºr jede Position im Kartenraster. <br><br><pre><code class="cpp hljs">varying vec3 vWorldPos; varying vec3 vNormal; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span></span>{ vec3 ro = vWorldPos; vec3 normal = normalize(vNormal); vec3 light = vec3(<span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;LIGHTS_ENCODED_IN_MAP; i++) { light += sampleLight(i, ro, normal); }</code> </pre> <br>  Um weiche Schatten f√ºr jedes Fragment und jede Lichtquelle zu erhalten, wird eine zuf√§llige Position in der Lichtquelle abgetastet.  Unter Verwendung des Raytracing-Codes im Shader (siehe Abschnitt Raytracing unten) wird ein Schattenstrahl zum Abtastpunkt emittiert, um die Sichtbarkeit der Lichtquelle zu bestimmen. <br><br>  Nach dem Hinzuf√ºgen von (Hilfs-) Reflexionen (siehe Abschnitt Reflexion unten) wird der berechneten Farbe des Fragments ein diffuser GI hinzugef√ºgt, indem eine Suche im diffusen GI-Renderziel durchgef√ºhrt wird (siehe unten). <br><br><h3>  Ray Tracing </h3><br>  Obwohl der Prototyp des Raytracing-Codes f√ºr diffuse GI mit einem pr√§ventiven Shader kombiniert wurde, habe ich mich in der Demo entschieden, diese zu trennen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/58b/8fd/3ab/58b8fd3abd38a86da42e1454df7109de.png"></div><br>  Ich habe sie getrennt, indem ich ein zweites Rendering der gesamten Geometrie in ein separates Renderziel (Diffuse GI Render Target) mit einem anderen Shader durchgef√ºhrt habe, der nur zuf√§llige Strahlen aussendet, um diffuse GI zu sammeln (siehe Abschnitt ‚ÄûDiffuse GI‚Äú unten).  Die in diesem Rendering-Ziel gesammelte Beleuchtung wird zu der im Vorw√§rts-Rendering-Durchgang berechneten direkten Beleuchtung hinzugef√ºgt. <br><br>  Durch Trennen des proaktiven Durchgangs und des diffusen GI k√∂nnen wir weniger als einen diffusen GI-Strahl pro Bildschirmpixel emittieren.  Dies kann durch Verringern der Pufferskala erfolgen (indem Sie den Schieberegler in den Optionen in der oberen rechten Ecke des Bildschirms bewegen). <br><br>  Wenn die Pufferskala beispielsweise 0,5 betr√§gt, wird nur ein Strahl pro vier Bildschirmpixel emittiert.  Dies f√ºhrt zu einer enormen Steigerung der Produktivit√§t.  Mit derselben Benutzeroberfl√§che in der oberen rechten Ecke des Bildschirms k√∂nnen Sie auch die Anzahl der Abtastwerte pro Pixel im Renderziel (SPP) und die Anzahl der Strahlreflexionen √§ndern. <br><br><h4>  Senden Sie einen Strahl aus </h4><br>  Um Strahlen in die Szene emittieren zu k√∂nnen, muss jede Ebenengeometrie ein Format haben, das der Raytracer im Shader verwenden kann.  Die Wolfenstein-Ebene hat ein 64 √ó 64-Raster codiert, sodass es einfach genug ist, alle Daten in eine einzige 64 √ó 64-Textur zu codieren: <br><br><ul><li>  Im roten Kanal der Texturfarbe werden alle Objekte in der entsprechenden Zelle <em>x, y des</em> Kartengitters codiert.  Wenn der Wert des roten Kanals Null ist, befinden sich keine Objekte in der Zelle. Andernfalls wird er von einer Wand (Werte von 1 bis 64), einer T√ºr, einer Lichtquelle oder einer Kugel belegt, deren Schnittpunkt √ºberpr√ºft werden muss. </li><li>  Wenn eine Kugel eine ebene Gitterzelle belegt, werden der Radius und die relativen <em>x-</em> und <em>y-</em> Koordinaten der Kugel innerhalb der Gitterzelle mit Gr√ºn-, Blau- und Alphakanal codiert. </li></ul><br>  Ein Strahl wird in einer Szene durch Durchlaufen einer Textur mit dem folgenden Code emittiert: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">worldHit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n vec3 ro,in vec3 rd,in </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> t_min, in </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> t_max, inout vec3 recPos, inout vec3 recNormal, inout vec3 recColor)</span></span></span><span class="hljs-function"> </span></span>{ vec3 pos = <span class="hljs-built_in"><span class="hljs-built_in">floor</span></span>(ro); vec3 ri = <span class="hljs-number"><span class="hljs-number">1.0</span></span>/rd; vec3 rs = sign(rd); vec3 dis = (pos-ro + <span class="hljs-number"><span class="hljs-number">0.5</span></span> + rs*<span class="hljs-number"><span class="hljs-number">0.5</span></span>) * ri; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;MAXSTEPS; i++ ) { vec3 mm = step(dis.xyz, dis.zyx); dis += mm * rs * ri; pos += mm * rs; vec4 mapType = texture2D(_MapTexture, pos.xz * (<span class="hljs-number"><span class="hljs-number">1.</span></span> / <span class="hljs-number"><span class="hljs-number">64.</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (isWall(mapType)) { ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">true</span></span>; } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">false</span></span>; }</code> </pre> <br>  Ein √§hnlicher Mesh Ray Tracing Code ist in diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wolfenstein Shader</a> auf Shadertoy zu finden. <br><br>  Nach der Berechnung des Schnittpunkts mit der Wand oder T√ºr (unter Verwendung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">des Schnittpunkttests mit einem Parallelogramm</a> ) erhalten wir durch Suchen in demselben Texturatlas, der zum √úbergeben des proaktiven Renderings verwendet wurde, Albedo-Schnittpunkte.  Kugeln haben eine Farbe, die prozedural anhand ihrer <em>x-, y-</em> Koordinaten im Raster und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Farbverlaufsfunktion bestimmt wird</a> . <br><br>  T√ºren sind etwas komplizierter, weil sie sich bewegen.  Damit die Szenendarstellung in der CPU (die zum Rendern von Netzen im Vorw√§rts-Rendering-Durchgang verwendet wird) mit der Szenendarstellung in der GPU (zur Raytracing-Funktion) √ºbereinstimmt, bewegen sich alle T√ºren automatisch und deterministisch, basierend auf dem Abstand von der Kamera zur T√ºr. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3d7/ded/058/3d7ded058d2f62fcf298c9b68b568a69.png"></div><br><br><h4>  Diffuse gi </h4><br>  Die gestreute globale Beleuchtung (diffuses GI) wird berechnet, indem Strahlen im Shader emittiert werden, mit denen die gesamte Geometrie im diffusen GI-Renderziel gezeichnet wird.  Die Richtung dieser Strahlen h√§ngt von der Normalen zur Oberfl√§che ab, die durch Abtasten der kosinusgewichteten Halbkugel bestimmt wird. <br><br>  Mit der Strahlrichtung <em>rd</em> und dem Startpunkt <em>ro</em> kann die reflektierte Beleuchtung unter Verwendung des folgenden Zyklus berechnet werden: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">vec3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getBounceCol</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in vec3 ro, in vec3 rd, in vec3 col)</span></span></span><span class="hljs-function"> </span></span>{ vec3 emitted = vec3(<span class="hljs-number"><span class="hljs-number">0</span></span>); vec3 recPos, recNormal, recColor; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;MAX_RECURSION; i++) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (worldHit(ro, rd, <span class="hljs-number"><span class="hljs-number">0.001</span></span>, <span class="hljs-number"><span class="hljs-number">20.</span></span>, recPos, recNormal, recColor)) { <span class="hljs-comment"><span class="hljs-comment">// if (isLightHit) { // direct light sampling code // return vec3(0); // } col *= recColor; for (int i=0; i&lt;2; i++) { emitted += col * sampleLight(i, recPos, recNormal); } } else { return emitted; } rd = cosWeightedRandomHemisphereDirection(recNormal); ro = recPos; } return emitted; }</span></span></code> </pre> <br>  Um das Rauschen zu reduzieren, wird der Schleife eine direkte Lichtabtastung hinzugef√ºgt.  Dies √§hnelt der Technik, die in meinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weiteren Cornell Box-</a> Shader auf Shadertoy verwendet wird. <br><br><h4>  Reflexion </h4><br>  Dank der M√∂glichkeit, die Szene mit Strahlen im Shader zu verfolgen, ist es sehr einfach, Reflexionen hinzuzuf√ºgen.  In meiner Demo werden Reflexionen hinzugef√ºgt, indem dieselbe <em>oben</em> gezeigte <em>getBounceCol-</em> Methode mit dem reflektierten Strahl der Kamera <em>aufgerufen</em> wird: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifdef</span></span></span><span class="hljs-meta"> REFLECTION col = mix(col, getReflectionCol(ro, reflect(normalize(vWorldPos - _CamPos), normal), albedo), .15); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span></span></code> </pre> <br>  Reflexionen werden im Vorw√§rts-Rendering-Durchgang hinzugef√ºgt, daher sendet ein Reflexionsstrahl immer einen Reflexionsstrahl aus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a88/e84/d6a/a88e84d6a2d0209234d6edaf02fcc441.png"></div><br><h3>  Zeitliches Anti-Aliasing </h3><br>  Da sowohl weiche Schatten im Vorw√§rts-Rendering-Durchgang als auch die diffuse GI-N√§herung ungef√§hr eine Abtastung pro Pixel verwenden, ist das Endergebnis extrem verrauscht.  Um das Rauschen zu reduzieren, wurde tempor√§res Anti-Aliasing (TAA) verwendet, das auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Playdeads</a> TAA: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Temporal Reprojection Anti-Aliasing in INSIDE</a> basiert. <br><br><h4>  Neuprojektion </h4><br>  Die Idee hinter TAA ist ganz einfach: TAA berechnet ein Subpixel pro Frame und mittelt dann seine Werte mit dem korrelierenden Pixel aus dem vorherigen Frame. <br><br>  Um zu wissen, wo sich das aktuelle Pixel im vorherigen Frame befand, wird die Fragmentposition unter Verwendung der Modellansicht-Projektionsmatrix des vorherigen Frames neu projiziert. <br><br><h4>  Lassen Sie Proben fallen und begrenzen Sie Nachbarschaften </h4><br>  In einigen F√§llen ist ein aus der Vergangenheit gespeichertes Beispiel ung√ºltig, z. B. wenn sich die Kamera so bewegt hat, dass ein Fragment des aktuellen Bilds im vorherigen Bild durch Geometrie geschlossen wurde.  Um solche ung√ºltigen Proben zu verwerfen, wird eine Nachbarschaftsbeschr√§nkung verwendet.  Ich habe die einfachste Art der Einschr√§nkung gew√§hlt: <br><br><pre> <code class="cpp hljs">vec3 history = texture2D(_History, uvOld ).rgb; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> x = <span class="hljs-number"><span class="hljs-number">-1.</span></span>; x &lt;= <span class="hljs-number"><span class="hljs-number">1.</span></span>; x+=<span class="hljs-number"><span class="hljs-number">1.</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> y = <span class="hljs-number"><span class="hljs-number">-1.</span></span>; y &lt;= <span class="hljs-number"><span class="hljs-number">1.</span></span>; y+=<span class="hljs-number"><span class="hljs-number">1.</span></span>) { vec3 n = texture2D(_New, vUV + vec2(x,y) / _Resolution).rgb; mx = max(n, mx); mn = min(n, mn); } } vec3 history_clamped = clamp(history, mn, mx);</code> </pre> <br>  Ich habe auch versucht, die Restriktionsmethode basierend auf dem Begrenzungsparallelogramm zu verwenden, sah jedoch keinen gro√üen Unterschied zu meiner L√∂sung.  Dies geschah wahrscheinlich, weil es in der Szene aus der Demo viele identische dunkle Farben und fast keine sich bewegenden Objekte gibt. <br><br><h4>  Kameravibrationen </h4><br>  Um ein Anti-Aliasing zu erhalten, schwingt die Kamera in jedem Bild aufgrund der Verwendung einer (Pseudo-) zuf√§lligen Subpixelverschiebung.  Dies wird durch √Ñndern der Projektionsmatrix implementiert: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">this</span></span>._projectionMatrix[<span class="hljs-number"><span class="hljs-number">2</span></span> * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">0</span></span>] += (<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.getHaltonSequence(frame % <span class="hljs-number"><span class="hljs-number">51</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) - <span class="hljs-number"><span class="hljs-number">.5</span></span>) / renderWidth; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>._projectionMatrix[<span class="hljs-number"><span class="hljs-number">2</span></span> * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>] += (<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.getHaltonSequence(frame % <span class="hljs-number"><span class="hljs-number">41</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) - <span class="hljs-number"><span class="hljs-number">.5</span></span>) / renderHeight;</code> </pre> <br><h3>  Der L√§rm </h3><br>  Rauschen ist die Grundlage der Algorithmen zur Berechnung des diffusen GI und der weichen Schatten.  Die Verwendung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gutem Rauschen</a> wirkt sich stark auf die Bildqualit√§t aus, w√§hrend schlechtes Rauschen Artefakte erzeugt oder die Bildkonvergenz verlangsamt. <br><br>  Ich bef√ºrchte, dass das in dieser Demo verwendete wei√üe Rauschen nicht sehr gut ist. <br><br>  Die Verwendung von gutem Rauschen ist wahrscheinlich der wichtigste Aspekt bei der Verbesserung der Bildqualit√§t in dieser Demo.  Sie k√∂nnen beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blaues Rauschen verwenden</a> . <br><br>  Ich habe Experimente mit Rauschen basierend auf dem Goldenen Schnitt durchgef√ºhrt, aber sie waren erfolglos.  Bisher wird der ber√ºchtigte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hash ohne Sinus von</a> Dave Hoskins verwendet: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">vec2 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">hash2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ vec3 p3 = fract(vec3(g_seed += <span class="hljs-number"><span class="hljs-number">0.1</span></span>) * HASHSCALE3); p3 += dot(p3, p3.yzx + <span class="hljs-number"><span class="hljs-number">19.19</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> fract((p3.xx+p3.yz)*p3.zy); }</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a81/338/42a/a8133842a43266dad1b4e9ee50c59228.png"></div><br><h3>  Ger√§uschreduzierung </h3><br>  Selbst wenn TAA aktiviert ist, zeigt die Demo immer noch viel Rauschen.  Es ist besonders schwierig, die Decke zu rendern, da sie nur durch indirekte Beleuchtung beleuchtet wird.  Dies vereinfacht nicht die Situation, dass die Decke eine gro√üe flache Oberfl√§che ist, die mit einer Volltonfarbe gef√ºllt ist: Wenn sie Textur oder geometrische Details h√§tte, w√ºrde das Ger√§usch weniger wahrnehmbar werden. <br><br>  Ich wollte nicht viel Zeit mit diesem Teil der Demo verbringen, deshalb habe ich versucht, nur einen Rauschunterdr√ºckungsfilter anzuwenden: Median3x3 von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Morgan McGuire und Kyle Witson</a> .  Leider funktioniert dieser Filter nicht sehr gut mit "Pixel Art" -Grafiken f√ºr Wandtexturen: Er entfernt alle Details in der Ferne und rundet die Ecken der Pixel benachbarter W√§nde ab. <br><br>  In einem anderen Experiment habe ich denselben Filter auf das Diffuse GI Render Target angewendet.  Obwohl er das Rauschen leicht reduzierte, gleichzeitig fast ohne die Details der Wandtexturen zu ver√§ndern, entschied ich, dass diese Verbesserung die zus√§tzlichen Millisekunden nicht wert war. <br><br><h3>  Demo </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sie k√∂nnen die Demo hier spielen</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de444516/">https://habr.com/ru/post/de444516/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de444502/index.html">Ist die Quantenkryptographie wirklich zuverl√§ssig?</a></li>
<li><a href="../de444504/index.html">Verwenden Sie jetzt das lokale Paketverzeichnis in Python</a></li>
<li><a href="../de444508/index.html">Wie wir PHP 7 doppelt so schnell wie PHP 5 gemacht haben. Teil 1: Optimierung von Datenstrukturen</a></li>
<li><a href="../de444512/index.html">Erstellen einer grafischen Anwendung zur L√∂sung des Pferdefortschritts</a></li>
<li><a href="../de444514/index.html">Webinar "Sicherheit beim maschinellen Lernen: Nat√ºrliche Probleme der k√ºnstlichen Intelligenz"</a></li>
<li><a href="../de444518/index.html">Auf dem Weg zu einer grundlegenden Theorie des Bewusstseins</a></li>
<li><a href="../de444520/index.html">2. Check Point Erste Schritte R80.20. L√∂sungsarchitektur</a></li>
<li><a href="../de444522/index.html">Die Apokalypse wird abgebrochen</a></li>
<li><a href="../de444524/index.html">Lambdas: von C ++ 11 bis C ++ 20. Teil 1</a></li>
<li><a href="../de444526/index.html">DOTS-Stapel: C ++ & C #</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
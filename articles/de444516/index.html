<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤲🏼 🎚️ 🎫 Wolfenstein 3D: Raytracing mit WebGL1 📫 👩🏾‍✈️ 🕥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nach dem Erscheinen der Nvidia RTX-Grafikkarten im letzten Sommer hat das Raytracing seine frühere Popularität wiedererlangt. In den letzten Monaten w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wolfenstein 3D: Raytracing mit WebGL1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/444516/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/885/df3/33c/885df333c0da45fcbb909c01c5da9648.png" alt="Bild"></div><br>  Nach dem Erscheinen der Nvidia RTX-Grafikkarten im letzten Sommer hat das Raytracing seine frühere Popularität wiedererlangt.  In den letzten Monaten wurde mein Twitter-Feed mit einem endlosen Strom von Grafikvergleichen mit aktiviertem und deaktiviertem RTX gefüllt. <br><br>  Nachdem ich so viele schöne Bilder bewundert hatte, wollte ich versuchen, den klassischen Forward-Renderer selbst mit einem Raytracer zu kombinieren. <br><br>  Da ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unter einem Syndrom der Ablehnung der Entwicklungen anderer Menschen leide</a> , habe ich meine eigene Hybrid-Rendering-Engine basierend auf WebGL1 erstellt.  Sie können hier mit dem Demo-Level-Rendering von Wolfenstein 3D mit den Kugeln (die ich aufgrund von Raytracing verwendet habe) spielen. <br><a name="habracut"></a><br><h3>  Prototyp </h3><br>  Ich habe dieses Projekt mit der Erstellung eines Prototyps begonnen und versucht, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">globale Beleuchtung mit Raytracing von Metro Exodus</a> wiederherzustellen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/262/61a/447/26261a447cd19758715a3cbde356eeb7.png"></div><br>  <i>Der erste Prototyp mit diffuser globaler Beleuchtung (Diffuse GI)</i> <br><br>  Der Prototyp basiert auf einem Forward-Renderer, der die gesamte Geometrie der Szene rendert.  Der zum Rastern der Geometrie verwendete Shader berechnet nicht nur die direkte Beleuchtung, sondern sendet auch zufällige Strahlen von der Oberfläche der gerenderten Geometrie aus, um sie mithilfe des Raytracers zu akkumulieren, der die indirekte Reflexion von Licht von nicht glänzenden Oberflächen (Diffuse GI) verwendet. <br><br>  Im Bild oben können Sie sehen, wie alle Kugeln nur durch indirekte Beleuchtung korrekt beleuchtet werden (Lichtstrahlen werden von der Wand hinter der Kamera reflektiert).  Die Lichtquelle selbst ist von einer braunen Wand auf der linken Seite des Bildes bedeckt. <br><br><h3>  Wolfenstein 3D </h3><br>  Der Prototyp verwendet eine sehr einfache Szene.  Es hat nur eine Lichtquelle und es werden nur wenige Kugeln und Würfel gerendert.  Dank dessen ist der Raytracing-Code im Shader sehr einfach.  Der Brute-Force-Zyklus zur Überprüfung der Kreuzung, bei dem der Strahl auf Schnitt mit allen Würfeln und Kugeln in der Szene getestet wird, ist immer noch schnell genug, damit das Programm ihn in Echtzeit ausführen kann. <br><br>  Nachdem ich diesen Prototyp erstellt hatte, wollte ich etwas Komplexeres tun, indem ich der Szene mehr Geometrie und viele Lichtquellen hinzufügte. <br><br>  Das Problem mit einer komplexeren Umgebung ist, dass ich immer noch in der Lage sein muss, Strahlen in der Szene in Echtzeit zu verfolgen.  Normalerweise wird eine BVH-Struktur ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bounding Volume Hierarchy</a> ) verwendet, um den Raytracing-Prozess zu beschleunigen. Meine Entscheidung, dieses Projekt in WebGL1 zu erstellen, ließ dies jedoch nicht zu: Es ist unmöglich, 16-Bit-Daten in eine Textur in WebGL1 zu laden, und Binäroperationen können in einem Shader nicht verwendet werden.  Dies erschwert die vorläufige Berechnung und Anwendung von BVH in WebGL1-Shadern. <br><br>  Deshalb habe ich mich dafür für die Wolfenstein 3D-Demo entschieden.  2013 habe ich in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shadertoy</a> einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fragment-WebGL-Shader</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erstellt</a> , der nicht nur Wolfenstein-ähnliche Ebenen rendert, sondern auch alle erforderlichen Texturen prozedural erstellt.  Aus meiner Erfahrung mit diesem Shader wusste ich, dass Wolfensteins gitterbasiertes Level-Design auch als schnelle und einfache Beschleunigungsstruktur verwendet werden kann und dass die Strahlverfolgung auf dieser Struktur sehr schnell sein wird. <br><br>  Unten finden Sie einen Screenshot der Demo, den Sie im Vollbildmodus hier abspielen können: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://reindernijhoff.net/wolfrt</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eu/gl/fp/euglfpjgl9503fy-_hjdwmr5hdi.png"></div><br><h3>  Kurzbeschreibung </h3><br>  Die Demo verwendet eine Hybrid-Rendering-Engine.  Um alle Polygone im Rahmen zu rendern, wird die herkömmliche Rasterung verwendet und das Ergebnis dann mit Schatten, diffusem GI und Reflexionen kombiniert, die durch Raytracing erzeugt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8f7/fd8/bb9/8f7fd8bb9324905edf5200fedb28bb7a.png"></div><br>  <i>Schatten</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/524/5b5/6ba/5245b56ba3a1feb02a9401857d625514.png"></div><br>  <i>Diffuse gi</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/885/df3/33c/885df333c0da45fcbb909c01c5da9648.png"></div><br>  <i>Reflexionen</i> <br><br><h3>  Proaktives Rendern </h3><br>  Wolfenstein-Karten können vollständig in ein zweidimensionales 64 × 64-Raster codiert werden.  Die in der Demo verwendete Karte basiert auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Ebene von Episode 1 von</a> Wolfenstein 3D. <br><br>  Beim Start wird die gesamte Geometrie erstellt, die zum Übergeben des proaktiven Renderings erforderlich ist.  Aus Kartendaten wird ein Maschennetz erzeugt.  Außerdem werden Boden- und Deckenebenen sowie separate Maschen für Lichter, Türen und zufällige Kugeln erstellt. <br><br>  Alle für Wände und Türen verwendeten Texturen sind in einem einzigen Texturatlas verpackt, sodass alle Wände in einem Zeichenaufruf gezeichnet werden können. <br><br><h4>  Schatten und Beleuchtung </h4><br>  Die direkte Beleuchtung wird in dem Shader berechnet, der für den Vorwärts-Rendering-Durchgang verwendet wird.  Jedes Fragment kann (maximal) von vier verschiedenen Quellen beleuchtet werden.  Um zu wissen, welche Quellen das Fragment im Shader beeinflussen können, wird beim Start der Demo die Suchtextur vorberechnet.  Diese Suchtextur hat eine Größe von 64 x 128 und codiert die Positionen der 4 nächsten Lichtquellen für jede Position im Kartenraster. <br><br><pre><code class="cpp hljs">varying vec3 vWorldPos; varying vec3 vNormal; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span></span>{ vec3 ro = vWorldPos; vec3 normal = normalize(vNormal); vec3 light = vec3(<span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;LIGHTS_ENCODED_IN_MAP; i++) { light += sampleLight(i, ro, normal); }</code> </pre> <br>  Um weiche Schatten für jedes Fragment und jede Lichtquelle zu erhalten, wird eine zufällige Position in der Lichtquelle abgetastet.  Unter Verwendung des Raytracing-Codes im Shader (siehe Abschnitt Raytracing unten) wird ein Schattenstrahl zum Abtastpunkt emittiert, um die Sichtbarkeit der Lichtquelle zu bestimmen. <br><br>  Nach dem Hinzufügen von (Hilfs-) Reflexionen (siehe Abschnitt Reflexion unten) wird der berechneten Farbe des Fragments ein diffuser GI hinzugefügt, indem eine Suche im diffusen GI-Renderziel durchgeführt wird (siehe unten). <br><br><h3>  Ray Tracing </h3><br>  Obwohl der Prototyp des Raytracing-Codes für diffuse GI mit einem präventiven Shader kombiniert wurde, habe ich mich in der Demo entschieden, diese zu trennen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/58b/8fd/3ab/58b8fd3abd38a86da42e1454df7109de.png"></div><br>  Ich habe sie getrennt, indem ich ein zweites Rendering der gesamten Geometrie in ein separates Renderziel (Diffuse GI Render Target) mit einem anderen Shader durchgeführt habe, der nur zufällige Strahlen aussendet, um diffuse GI zu sammeln (siehe Abschnitt „Diffuse GI“ unten).  Die in diesem Rendering-Ziel gesammelte Beleuchtung wird zu der im Vorwärts-Rendering-Durchgang berechneten direkten Beleuchtung hinzugefügt. <br><br>  Durch Trennen des proaktiven Durchgangs und des diffusen GI können wir weniger als einen diffusen GI-Strahl pro Bildschirmpixel emittieren.  Dies kann durch Verringern der Pufferskala erfolgen (indem Sie den Schieberegler in den Optionen in der oberen rechten Ecke des Bildschirms bewegen). <br><br>  Wenn die Pufferskala beispielsweise 0,5 beträgt, wird nur ein Strahl pro vier Bildschirmpixel emittiert.  Dies führt zu einer enormen Steigerung der Produktivität.  Mit derselben Benutzeroberfläche in der oberen rechten Ecke des Bildschirms können Sie auch die Anzahl der Abtastwerte pro Pixel im Renderziel (SPP) und die Anzahl der Strahlreflexionen ändern. <br><br><h4>  Senden Sie einen Strahl aus </h4><br>  Um Strahlen in die Szene emittieren zu können, muss jede Ebenengeometrie ein Format haben, das der Raytracer im Shader verwenden kann.  Die Wolfenstein-Ebene hat ein 64 × 64-Raster codiert, sodass es einfach genug ist, alle Daten in eine einzige 64 × 64-Textur zu codieren: <br><br><ul><li>  Im roten Kanal der Texturfarbe werden alle Objekte in der entsprechenden Zelle <em>x, y des</em> Kartengitters codiert.  Wenn der Wert des roten Kanals Null ist, befinden sich keine Objekte in der Zelle. Andernfalls wird er von einer Wand (Werte von 1 bis 64), einer Tür, einer Lichtquelle oder einer Kugel belegt, deren Schnittpunkt überprüft werden muss. </li><li>  Wenn eine Kugel eine ebene Gitterzelle belegt, werden der Radius und die relativen <em>x-</em> und <em>y-</em> Koordinaten der Kugel innerhalb der Gitterzelle mit Grün-, Blau- und Alphakanal codiert. </li></ul><br>  Ein Strahl wird in einer Szene durch Durchlaufen einer Textur mit dem folgenden Code emittiert: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">worldHit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n vec3 ro,in vec3 rd,in </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> t_min, in </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> t_max, inout vec3 recPos, inout vec3 recNormal, inout vec3 recColor)</span></span></span><span class="hljs-function"> </span></span>{ vec3 pos = <span class="hljs-built_in"><span class="hljs-built_in">floor</span></span>(ro); vec3 ri = <span class="hljs-number"><span class="hljs-number">1.0</span></span>/rd; vec3 rs = sign(rd); vec3 dis = (pos-ro + <span class="hljs-number"><span class="hljs-number">0.5</span></span> + rs*<span class="hljs-number"><span class="hljs-number">0.5</span></span>) * ri; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;MAXSTEPS; i++ ) { vec3 mm = step(dis.xyz, dis.zyx); dis += mm * rs * ri; pos += mm * rs; vec4 mapType = texture2D(_MapTexture, pos.xz * (<span class="hljs-number"><span class="hljs-number">1.</span></span> / <span class="hljs-number"><span class="hljs-number">64.</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (isWall(mapType)) { ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">true</span></span>; } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">false</span></span>; }</code> </pre> <br>  Ein ähnlicher Mesh Ray Tracing Code ist in diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wolfenstein Shader</a> auf Shadertoy zu finden. <br><br>  Nach der Berechnung des Schnittpunkts mit der Wand oder Tür (unter Verwendung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">des Schnittpunkttests mit einem Parallelogramm</a> ) erhalten wir durch Suchen in demselben Texturatlas, der zum Übergeben des proaktiven Renderings verwendet wurde, Albedo-Schnittpunkte.  Kugeln haben eine Farbe, die prozedural anhand ihrer <em>x-, y-</em> Koordinaten im Raster und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Farbverlaufsfunktion bestimmt wird</a> . <br><br>  Türen sind etwas komplizierter, weil sie sich bewegen.  Damit die Szenendarstellung in der CPU (die zum Rendern von Netzen im Vorwärts-Rendering-Durchgang verwendet wird) mit der Szenendarstellung in der GPU (zur Raytracing-Funktion) übereinstimmt, bewegen sich alle Türen automatisch und deterministisch, basierend auf dem Abstand von der Kamera zur Tür. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3d7/ded/058/3d7ded058d2f62fcf298c9b68b568a69.png"></div><br><br><h4>  Diffuse gi </h4><br>  Die gestreute globale Beleuchtung (diffuses GI) wird berechnet, indem Strahlen im Shader emittiert werden, mit denen die gesamte Geometrie im diffusen GI-Renderziel gezeichnet wird.  Die Richtung dieser Strahlen hängt von der Normalen zur Oberfläche ab, die durch Abtasten der kosinusgewichteten Halbkugel bestimmt wird. <br><br>  Mit der Strahlrichtung <em>rd</em> und dem Startpunkt <em>ro</em> kann die reflektierte Beleuchtung unter Verwendung des folgenden Zyklus berechnet werden: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">vec3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getBounceCol</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in vec3 ro, in vec3 rd, in vec3 col)</span></span></span><span class="hljs-function"> </span></span>{ vec3 emitted = vec3(<span class="hljs-number"><span class="hljs-number">0</span></span>); vec3 recPos, recNormal, recColor; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;MAX_RECURSION; i++) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (worldHit(ro, rd, <span class="hljs-number"><span class="hljs-number">0.001</span></span>, <span class="hljs-number"><span class="hljs-number">20.</span></span>, recPos, recNormal, recColor)) { <span class="hljs-comment"><span class="hljs-comment">// if (isLightHit) { // direct light sampling code // return vec3(0); // } col *= recColor; for (int i=0; i&lt;2; i++) { emitted += col * sampleLight(i, recPos, recNormal); } } else { return emitted; } rd = cosWeightedRandomHemisphereDirection(recNormal); ro = recPos; } return emitted; }</span></span></code> </pre> <br>  Um das Rauschen zu reduzieren, wird der Schleife eine direkte Lichtabtastung hinzugefügt.  Dies ähnelt der Technik, die in meinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weiteren Cornell Box-</a> Shader auf Shadertoy verwendet wird. <br><br><h4>  Reflexion </h4><br>  Dank der Möglichkeit, die Szene mit Strahlen im Shader zu verfolgen, ist es sehr einfach, Reflexionen hinzuzufügen.  In meiner Demo werden Reflexionen hinzugefügt, indem dieselbe <em>oben</em> gezeigte <em>getBounceCol-</em> Methode mit dem reflektierten Strahl der Kamera <em>aufgerufen</em> wird: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifdef</span></span></span><span class="hljs-meta"> REFLECTION col = mix(col, getReflectionCol(ro, reflect(normalize(vWorldPos - _CamPos), normal), albedo), .15); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span></span></code> </pre> <br>  Reflexionen werden im Vorwärts-Rendering-Durchgang hinzugefügt, daher sendet ein Reflexionsstrahl immer einen Reflexionsstrahl aus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a88/e84/d6a/a88e84d6a2d0209234d6edaf02fcc441.png"></div><br><h3>  Zeitliches Anti-Aliasing </h3><br>  Da sowohl weiche Schatten im Vorwärts-Rendering-Durchgang als auch die diffuse GI-Näherung ungefähr eine Abtastung pro Pixel verwenden, ist das Endergebnis extrem verrauscht.  Um das Rauschen zu reduzieren, wurde temporäres Anti-Aliasing (TAA) verwendet, das auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Playdeads</a> TAA: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Temporal Reprojection Anti-Aliasing in INSIDE</a> basiert. <br><br><h4>  Neuprojektion </h4><br>  Die Idee hinter TAA ist ganz einfach: TAA berechnet ein Subpixel pro Frame und mittelt dann seine Werte mit dem korrelierenden Pixel aus dem vorherigen Frame. <br><br>  Um zu wissen, wo sich das aktuelle Pixel im vorherigen Frame befand, wird die Fragmentposition unter Verwendung der Modellansicht-Projektionsmatrix des vorherigen Frames neu projiziert. <br><br><h4>  Lassen Sie Proben fallen und begrenzen Sie Nachbarschaften </h4><br>  In einigen Fällen ist ein aus der Vergangenheit gespeichertes Beispiel ungültig, z. B. wenn sich die Kamera so bewegt hat, dass ein Fragment des aktuellen Bilds im vorherigen Bild durch Geometrie geschlossen wurde.  Um solche ungültigen Proben zu verwerfen, wird eine Nachbarschaftsbeschränkung verwendet.  Ich habe die einfachste Art der Einschränkung gewählt: <br><br><pre> <code class="cpp hljs">vec3 history = texture2D(_History, uvOld ).rgb; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> x = <span class="hljs-number"><span class="hljs-number">-1.</span></span>; x &lt;= <span class="hljs-number"><span class="hljs-number">1.</span></span>; x+=<span class="hljs-number"><span class="hljs-number">1.</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> y = <span class="hljs-number"><span class="hljs-number">-1.</span></span>; y &lt;= <span class="hljs-number"><span class="hljs-number">1.</span></span>; y+=<span class="hljs-number"><span class="hljs-number">1.</span></span>) { vec3 n = texture2D(_New, vUV + vec2(x,y) / _Resolution).rgb; mx = max(n, mx); mn = min(n, mn); } } vec3 history_clamped = clamp(history, mn, mx);</code> </pre> <br>  Ich habe auch versucht, die Restriktionsmethode basierend auf dem Begrenzungsparallelogramm zu verwenden, sah jedoch keinen großen Unterschied zu meiner Lösung.  Dies geschah wahrscheinlich, weil es in der Szene aus der Demo viele identische dunkle Farben und fast keine sich bewegenden Objekte gibt. <br><br><h4>  Kameravibrationen </h4><br>  Um ein Anti-Aliasing zu erhalten, schwingt die Kamera in jedem Bild aufgrund der Verwendung einer (Pseudo-) zufälligen Subpixelverschiebung.  Dies wird durch Ändern der Projektionsmatrix implementiert: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">this</span></span>._projectionMatrix[<span class="hljs-number"><span class="hljs-number">2</span></span> * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">0</span></span>] += (<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.getHaltonSequence(frame % <span class="hljs-number"><span class="hljs-number">51</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) - <span class="hljs-number"><span class="hljs-number">.5</span></span>) / renderWidth; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>._projectionMatrix[<span class="hljs-number"><span class="hljs-number">2</span></span> * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>] += (<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.getHaltonSequence(frame % <span class="hljs-number"><span class="hljs-number">41</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) - <span class="hljs-number"><span class="hljs-number">.5</span></span>) / renderHeight;</code> </pre> <br><h3>  Der Lärm </h3><br>  Rauschen ist die Grundlage der Algorithmen zur Berechnung des diffusen GI und der weichen Schatten.  Die Verwendung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gutem Rauschen</a> wirkt sich stark auf die Bildqualität aus, während schlechtes Rauschen Artefakte erzeugt oder die Bildkonvergenz verlangsamt. <br><br>  Ich befürchte, dass das in dieser Demo verwendete weiße Rauschen nicht sehr gut ist. <br><br>  Die Verwendung von gutem Rauschen ist wahrscheinlich der wichtigste Aspekt bei der Verbesserung der Bildqualität in dieser Demo.  Sie können beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blaues Rauschen verwenden</a> . <br><br>  Ich habe Experimente mit Rauschen basierend auf dem Goldenen Schnitt durchgeführt, aber sie waren erfolglos.  Bisher wird der berüchtigte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hash ohne Sinus von</a> Dave Hoskins verwendet: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">vec2 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">hash2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ vec3 p3 = fract(vec3(g_seed += <span class="hljs-number"><span class="hljs-number">0.1</span></span>) * HASHSCALE3); p3 += dot(p3, p3.yzx + <span class="hljs-number"><span class="hljs-number">19.19</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> fract((p3.xx+p3.yz)*p3.zy); }</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a81/338/42a/a8133842a43266dad1b4e9ee50c59228.png"></div><br><h3>  Geräuschreduzierung </h3><br>  Selbst wenn TAA aktiviert ist, zeigt die Demo immer noch viel Rauschen.  Es ist besonders schwierig, die Decke zu rendern, da sie nur durch indirekte Beleuchtung beleuchtet wird.  Dies vereinfacht nicht die Situation, dass die Decke eine große flache Oberfläche ist, die mit einer Volltonfarbe gefüllt ist: Wenn sie Textur oder geometrische Details hätte, würde das Geräusch weniger wahrnehmbar werden. <br><br>  Ich wollte nicht viel Zeit mit diesem Teil der Demo verbringen, deshalb habe ich versucht, nur einen Rauschunterdrückungsfilter anzuwenden: Median3x3 von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Morgan McGuire und Kyle Witson</a> .  Leider funktioniert dieser Filter nicht sehr gut mit "Pixel Art" -Grafiken für Wandtexturen: Er entfernt alle Details in der Ferne und rundet die Ecken der Pixel benachbarter Wände ab. <br><br>  In einem anderen Experiment habe ich denselben Filter auf das Diffuse GI Render Target angewendet.  Obwohl er das Rauschen leicht reduzierte, gleichzeitig fast ohne die Details der Wandtexturen zu verändern, entschied ich, dass diese Verbesserung die zusätzlichen Millisekunden nicht wert war. <br><br><h3>  Demo </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sie können die Demo hier spielen</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de444516/">https://habr.com/ru/post/de444516/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de444502/index.html">Ist die Quantenkryptographie wirklich zuverlässig?</a></li>
<li><a href="../de444504/index.html">Verwenden Sie jetzt das lokale Paketverzeichnis in Python</a></li>
<li><a href="../de444508/index.html">Wie wir PHP 7 doppelt so schnell wie PHP 5 gemacht haben. Teil 1: Optimierung von Datenstrukturen</a></li>
<li><a href="../de444512/index.html">Erstellen einer grafischen Anwendung zur Lösung des Pferdefortschritts</a></li>
<li><a href="../de444514/index.html">Webinar "Sicherheit beim maschinellen Lernen: Natürliche Probleme der künstlichen Intelligenz"</a></li>
<li><a href="../de444518/index.html">Auf dem Weg zu einer grundlegenden Theorie des Bewusstseins</a></li>
<li><a href="../de444520/index.html">2. Check Point Erste Schritte R80.20. Lösungsarchitektur</a></li>
<li><a href="../de444522/index.html">Die Apokalypse wird abgebrochen</a></li>
<li><a href="../de444524/index.html">Lambdas: von C ++ 11 bis C ++ 20. Teil 1</a></li>
<li><a href="../de444526/index.html">DOTS-Stapel: C ++ & C #</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
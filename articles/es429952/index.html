<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👵 🧖🏾 👐🏽 El pasado, presente y futuro de Docker y otros tiempos de ejecución de contenedores en Kubernetes 🌎 💯 🕺🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : Ya hemos escrito más de una publicación (ver enlaces al final del artículo) sobre tiempos de ejecución de contenedores (tiempos de ejecu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>El pasado, presente y futuro de Docker y otros tiempos de ejecución de contenedores en Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/429952/">  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: Ya hemos escrito más de una publicación (ver enlaces al final del artículo) sobre tiempos de ejecución de contenedores (tiempos de ejecución de contenedores); por regla general, se analizan en el contexto de Kubernetes.</i>  <i>Sin embargo, a menudo estos materiales despertaron las preguntas de los lectores, lo que indica una falta de comprensión de dónde vino el próximo proyecto, cómo está conectado con otros y qué está sucediendo en todo este contenedor "zoológico".</i> <br><br><img src="https://habrastorage.org/webt/cy/td/t5/cytdt5jmmufxrtz_b41os56vneg.png"><br><br>  <i>Un artículo reciente de Phil Estes, Director Técnico de IBM Watson &amp; Cloud Platform para Contenedores y Arquitectura de Linux, proporciona una excelente retrospectiva sobre cómo navegar y obtener una comprensión más amplia de quién ha perdido (o nunca atrapado) el hilo de los eventos.</i>  <i>Siendo uno de los mantenedores de los proyectos Moby y de contenedores, miembro de los comités técnicos de Open Container Initiative (OCI) y Moby, y también con el estatus de Capitán Docker, el autor escribe sobre el pasado, presente y futuro del nuevo mundo maravilloso de tiempos de ejecución de contenedores.</i>  <i>Y para los más vagos, el material comienza con un TL compacto; DR sobre el tema ...</i> <a name="habracut"></a><br><br><h2>  Resultados clave </h2><br><ul><li>  Con el tiempo, la elección entre tiempos de ejecución de contenedores ha crecido, proporcionando más opciones que el popular motor Docker. </li><li>  La Open Container Initiative (OCI) ha estandarizado con éxito el concepto de contenedor y la imagen del contenedor para garantizar la interoperabilidad <i>("interoperabilidad" - aprox. Transl.)</i> Entre entornos de tiempo de ejecución. </li><li>  Kubernetes ha agregado la Interfaz de tiempo de ejecución de contenedor (CRI), que permite que los contenedores se conecten a entornos de tiempo de ejecución con la capa de orquestación subyacente en K8. </li><li>  Las innovaciones en esta área permiten que los contenedores aprovechen la virtualización ligera y otras técnicas de aislamiento únicas para los crecientes requisitos de seguridad. </li><li>  Con OCI y CRI, la interoperabilidad y la elección se han convertido en una realidad en el ecosistema de contenedores de tiempo de ejecución y entornos de orquestación. </li></ul><br>  La tecnología de contenedores ha existido durante bastante tiempo en el mundo de los sistemas operativos Linux: las primeras ideas sobre espacios de nombres separados para sistemas y procesos de archivos aparecieron hace más de una década.  Y en el pasado relativamente reciente, apareció el LXC y se convirtió en la forma estándar para que los usuarios de Linux interactúen con la poderosa tecnología de aislamiento oculta en el kernel de Linux. <br><br>  Sin embargo, incluso a pesar de los intentos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de LXC de</a> ocultar la complejidad de combinar varios "elementos internos" tecnológicos de lo que generalmente llamamos un contenedor hoy en día, los contenedores siguieron siendo una especie de magia y se fortalecieron solo en el mundo de aquellos que tenían un conocimiento especial y no obtuvieron una amplia distribución entre las masas. <br><br>  Todo cambió en 2014 con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Docker</a> , cuando apareció un nuevo contenedor amigable para los desarrolladores para la misma tecnología de kernel de Linux que LXC tenía en servicio; después de todo, las primeras versiones de Docker "detrás de escena" usaron LXC, y los contenedores se convirtieron - un fenómeno de masas real, ya que los desarrolladores estaban imbuidos de la simplicidad y las posibilidades de reutilizar imágenes de contenedores Docker y comandos simples para trabajar con ellos. <br><br>  Por supuesto, Docker no fue el único que quería ganar una participación en el mercado de contenedores cuando la exageración que los acompañó no pensó en disminuir después del primer interés explosivo en 2014.  Con los años, han surgido una variedad de ideas alternativas para entornos de contenedores ejecutables de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CoreOS (rkt)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Intel Clear Containers</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hyper.sh</a> (virtualización basada en contenedores livianos) y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Singularity</a> and <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">shifter</a> en el mundo de la investigación de computación de alto rendimiento (HPC). <br><br>  El mercado continuó creciendo y madurando, y con la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Open Container Initiative (OCI)</a> surgió el esfuerzo de estandarizar las ideas iniciales promovidas por Docker.  Hoy en día, muchos entornos de contenedores ejecutables ya son compatibles con OCI o, en el camino hacia esto, ofrecen a los fabricantes las mismas condiciones para promover sus características y capacidades que se centran en una aplicación en particular. <br><br><h2>  Popularidad de Kubernetes </h2><br>  La siguiente etapa en la evolución de los contenedores fue combinar contenedores informáticos distribuidos a la microservicios con contenedores, y todo esto en el nuevo mundo de iteraciones rápidas de desarrollo e implementación (podemos decir que DevOps), que estaba ganando impulso activamente junto con la popularidad de Docker. <br><br>  Aunque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Mesos</a> y otras plataformas de orquestación de software existían antes de que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kubernetes</a> dominara, los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">K8</a> despegaron rápidamente de un pequeño proyecto de código abierto de Google al proyecto principal de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cloud Native Computing Foundation (CNCF)</a> . <br><br>  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: ¿Sabes que CNCF <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">apareció</a> en 2015 con motivo del lanzamiento de Kubernetes 1.0?</i>  <i>Al mismo tiempo, el proyecto fue transferido por Google a una nueva organización independiente que se convirtió en parte de The Linux Foundation.</i> <br><br><img src="https://habrastorage.org/webt/hu/_u/em/hu_uemcx44qdursrnr_nsc04gie.png"><br>  <i>Evento de lanzamiento de K8s 1.0 patrocinado, entre otros, Mesosphere, CoreOS, Mirantis, OpenStack, Bitnami</i> <br><img src="https://habrastorage.org/webt/lq/rf/ab/lqrfabydpe9_lbh9zv5x8titb48.png"><br>  <i>De las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">noticias</a> sobre el lanzamiento de Kubernetes 1.0 en ZDNet</i> <br><br>  Incluso después de que Docker lanzó la plataforma de orquestación rival, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Swarm</a> , integrada en Docker y que presenta la simplicidad de Docker y un enfoque en la configuración predeterminada de clúster seguro, esto ya no fue suficiente para detener el creciente interés en Kubernetes. <br><br>  Sin embargo, muchos interesados ​​fuera de las comunidades nativas en la nube de rápido crecimiento estaban confundidos.  Un observador promedio no podía entender lo que estaba sucediendo: ¿Kubernetes pelea con Docker o su cooperación?  Debido a que Kubernetes era solo una plataforma de orquestación, se requería un entorno de contenedor ejecutable que lanzara directamente los contenedores orquestados en Kubernetes.  Desde el principio, Kubernetes utilizó el motor Docker y, a pesar de la tensión competitiva entre Swarm y Kubernetes, Docker seguía siendo el tiempo de ejecución predeterminado y era necesario para que el clúster de Kubernetes funcionara. <br><br>  Con una pequeña cantidad de tiempos de ejecución de contenedores distintos de Docker, parecía claro que emparejar el tiempo de ejecución con Kubernetes requeriría una interfaz especialmente escrita, shim, para cada tiempo de ejecución.  La falta de una interfaz clara para implementar tiempos de ejecución de contenedor hizo que fuera muy difícil agregar soporte para nuevos tiempos de ejecución en Kubernetes. <br><br><h2>  Interfaz de tiempo de ejecución de contenedor (CRI) </h2><br>  Para resolver la creciente complejidad de implementar tiempos de ejecución en Kubernetes, la comunidad definió una interfaz - funciones específicas que el tiempo de ejecución del contenedor debería implementar dentro de Kubernetes - nombrándola <a href="">Interfaz de tiempo de ejecución del contenedor (CRI)</a> <i>( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">apareció</a> en Kubernetes 1.5 - aprox. Transl.)</i> .  Este evento no solo ayudó al problema del creciente número de fragmentos de la base de código de Kubernetes que afecta el uso de tiempos de ejecución de contenedores, sino que también ayudó a comprender qué funciones deberían ser compatibles con tiempos de ejecución potenciales si quieren cumplir con CRI. <br><br>  Como puede suponer, CRI espera cosas muy simples del tiempo de ejecución.  Dicho entorno debería ser capaz de iniciar y detener pods, manejar todas las operaciones con contenedores en el contexto de pods (start, stop, pause, kill, delete) y también admitir la gestión de imágenes de contenedores utilizando el registro.  También hay funciones auxiliares para recopilar registros, métricas, etc. <br><br>  Cuando aparecen nuevas características en Kubernetes, si dependen de la capa del tiempo de ejecución del contenedor, dichos cambios se realizan en la API CRI versionada.  Esto a su vez crea una nueva dependencia funcional en Kubernetes y requiere el lanzamiento de nuevas versiones de tiempos de ejecución que admitan nuevas características (un ejemplo reciente son los espacios de nombres de usuario). <br><br><h2>  Paisaje actual de CRI </h2><br>  A partir de 2018, hay varias opciones para usar como tiempos de ejecución de contenedores en Kubernetes.  Como se muestra en la siguiente ilustración, una de las opciones reales sigue siendo Docker con su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dockershim</a> que implementa la API CRI.  Y, de hecho, en la mayoría de las instalaciones de Kubernetes en la actualidad, es él, Docker, quien sigue siendo el tiempo de ejecución predeterminado. <br><br><img src="https://habrastorage.org/webt/p6/9q/0h/p69q0hpabyujabund9bgicx12q4.jpeg"><br><br>  Una de las consecuencias interesantes de la tensión entre la estrategia de orquestación de Docker con Swarm y la comunidad de Kubernetes fue un proyecto conjunto, que tomó la base del tiempo de ejecución de Docker y reunió de él un nuevo proyecto de código abierto desarrollado conjuntamente - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">contenedor</a> .  Con el tiempo, el contenedor fue transferido a CNCF, la misma organización que administra y posee el proyecto Kubernetes.  <i>( <b>Nota traducida</b> : describimos la apariencia del contenedor con más detalle en un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo separado</a> ).</i> <br><br><img src="https://habrastorage.org/webt/yr/o1/wx/yro1wxcji1jh-xettnzp-jiyiu8.png"><br>  <i>Desde el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">anuncio de</a> containerd en el blog de Docker</i> <br><br>  Containerd, al ser una implementación de tiempo de ejecución simple, básica e <i>independiente de la</i> empresa <i>(no obstinada)</i> para Docker y Kubernetes (a través de CRI), comenzó a ganar popularidad como un posible reemplazo para Docker en muchas instalaciones de Kubernetes.  Hasta la fecha, tanto IBM Cloud como Google Cloud tienen clústeres basados ​​en contenedores en acceso temprano / modo beta.  Microsoft Azure también prometió cambiar a contenedor en el futuro, y Amazon todavía está considerando varias opciones para tiempos de ejecución para sus soluciones de contenedor (ECS y EKS), mientras continúa utilizando Docker. <br><br>  Red Hat ha entrado en el espacio de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tiempo de ejecución</a> del contenedor creando una implementación CRI simple llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cri-o</a> basada en la implementación de referencia OCI, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">runc</a> .  Docker y containerd también están basados ​​en runc, pero los creadores de cri-o afirman que sus tiempos de ejecución son "lo suficiente" para Kubernetes y que no necesitan más: simplemente agregaron las funciones más necesarias para implementar Kubernetes CRI sobre el binario runc base.  <i>( <b>Nota traducida</b> : escribimos más sobre el proyecto CRI-O en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este artículo</a> , y aquí sobre su desarrollo posterior en forma de podman).</i> <br><br>  Proyectos de virtualización livianos: Intel Clear Containers e hyper.sh - aparecieron en la naturaleza de OpenStack Foundation, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">contenedores Kata</a> , y ofrecen su visión de contenedores virtualizados para aislamiento adicional usando una implementación de CRI llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">frakti</a> .  Tanto cri-o como containerd también funcionan con contenedores Kata, por lo que su tiempo de ejecución compatible con OCI se puede seleccionar como una opción conectable. <br><br><h2>  Prediciendo el futuro </h2><br>  Decir que sabes que el futuro generalmente no es muy sabio, pero al menos podemos arreglar algunas tendencias emergentes a medida que el ecosistema de contenedores pasa del entusiasmo y la exageración a una etapa más madura de nuestra existencia. <br><br>  Hubo temores tempranos de que el ecosistema del contenedor formaría un entorno fragmentado, cuyos diferentes participantes presentarían ideas diferentes e incompatibles sobre lo que es un contenedor.  Gracias al trabajo de OCI y las acciones responsables de los principales proveedores y participantes, vimos un entorno saludable en la industria entre las ofertas de software que preferían la compatibilidad con OCI. <br><br>  Incluso en entornos más nuevos donde el estándar de uso de Docker encontró menos resistencia debido a las restricciones existentes, por ejemplo, en HPC, todos los intentos de crear entornos de contenedores de contenedores no basados ​​en Docker también llamaron la atención sobre la OCI.  Se están debatiendo si OCI puede ser una solución viable para las necesidades específicas de las comunidades de científicos e investigadores. <br><br>  Además de la estandarización de los tiempos de ejecución de los contenedores de complementos en Kubernetes con CRI, podemos imaginar un mundo en el que los desarrolladores y administradores puedan elegir las herramientas y las pilas de software adecuadas para sus tareas, esperando y observando la interoperabilidad en todo el ecosistema de contenedores. <br><br>  Considere un ejemplo específico para comprender mejor este mundo: <br><br><ul><li>  Un desarrollador con un MacBook usa Docker para Mac para desarrollar su aplicación e incluso usa el soporte Kubernetes incorporado (Docker funciona como CRI runtime aquí) para intentar implementar la nueva aplicación en los pods K8. </li><li>  La aplicación pasa a través de CI / CD en el software del proveedor, que utiliza runc y un código especial (escrito por el proveedor) para empaquetar la imagen OCI y cargarla en el registro corporativo de contenedores para la prueba. </li><li>  La instalación local del clúster de Kubernetes, trabajando con containerd como un tiempo de ejecución CRI, ejecuta un conjunto de pruebas para la aplicación. </li><li>  Esta compañía, por alguna razón, eligió contenedores Kata para ciertas cargas de trabajo en producción, por lo que cuando implementa la aplicación, comienza en pods con containerd configurado para usar contenedores Kata como tiempo de ejecución en lugar de runc. </li></ul><br>  Todo el escenario descrito funciona maravillosamente debido a la compatibilidad con la especificación OCI para entornos e imágenes en tiempo de ejecución, y al hecho de que CRI proporciona la flexibilidad para elegir el tiempo de ejecución. <br><br>  Esta posible flexibilidad y elección hace que el ecosistema de contenedores sea realmente notable y también es una condición muy importante para la madurez de la industria, que ha crecido tan rápidamente desde 2014.  En el umbral de 2019 y los años siguientes, veo un futuro brillante con innovaciones continuas y flexibilidad para aquellos que usan y crean plataformas basadas en contenedores. <br><br>  Se puede encontrar más información sobre este tema en una reciente charla de Phil Estes en QCon NY: “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CRI Runtimes Deep Dive: Who's Running My Kubernetes Pod!?</a>  " <br><br><h2>  PD del traductor </h2><br>  Lea también en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Red Hat reemplaza a Docker con Podman</a> "; </li><li>  "La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">integración de containerd con Kubernetes, en sustitución de Docker, está lista para la producción</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CRI-O: una alternativa a Docker para lanzar contenedores en Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¿Qué y por qué está haciendo Docker Moby para integrarse con Kubernetes?"</a>  " </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Entonces, ¿qué es una cápsula en Kubernetes?</a>  " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es429952/">https://habr.com/ru/post/es429952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es429940/index.html">¿Por qué las plantas necesitan aprendizaje automático?</a></li>
<li><a href="../es429942/index.html">Obtén música VK a través de una API de terceros</a></li>
<li><a href="../es429946/index.html">Locura y éxito del código de base de datos Oracle</a></li>
<li><a href="../es429948/index.html">Por qué se necesitan gerentes de producto en fintech</a></li>
<li><a href="../es429950/index.html">Cómo mantener hábitos saludables de comunicación de equipos remotos</a></li>
<li><a href="../es429954/index.html">El programador para los corredores de apuestas irlandeses.</a></li>
<li><a href="../es429956/index.html">Integración continua en Yandex. Parte 2</a></li>
<li><a href="../es429958/index.html">Cinco reglas fáciles de depuración para principiantes</a></li>
<li><a href="../es429960/index.html">10 razones por las que los clientes se dan de baja de un producto</a></li>
<li><a href="../es429964/index.html">U> X> I> P ... o "Cómo juegan los nombres de las profesiones salto de rana"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍🚒 👩🏿‍🤝‍👩🏼 🕜 Nous évaluons les villes russes par la qualité des routes 🙍🏾 👻 🗿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une fois de plus, en conduisant une voiture dans ma ville natale et en faisant le tour d'une autre fosse, je me suis dit: de si bonnes routes existaie...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous évaluons les villes russes par la qualité des routes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437542/"><img src="https://habrastorage.org/webt/qg/pm/pf/qgpmpfivqp5xqw2c8-qvxjp4-dq.jpeg"><br><br>  Une fois de plus, en conduisant une voiture dans ma ville natale et en faisant le tour d'une autre fosse, je me suis dit: de si bonnes routes existaient-elles partout dans notre pays et j'ai décidé que nous devrions évaluer objectivement la situation avec la qualité des routes dans notre pays. <br><a name="habracut"></a><br><h2>  Formalisation des tâches </h2><br>  En Russie, les exigences de qualité des routes sont décrites dans GOST R 50597-2017 «Routes et routes.  Exigences pour l'état opérationnel acceptables dans les conditions de sécurité routière.  Méthodes de contrôle. "  Ce document définit les exigences pour couvrir la chaussée, les bords de route, les bandes de séparation, les trottoirs, les voies piétonnes, etc., et établit également les types de dommages. <br><br>  Étant donné que la tâche de déterminer tous les paramètres des routes est assez vaste, j'ai décidé de le réduire pour moi-même et de me concentrer uniquement sur le problème de la détermination des défauts dans la couverture de la chaussée.  Dans GOST R 50597-2017, les défauts suivants dans le revêtement de la chaussée sont distingués: <br><br><ul><li>  nids de poule </li><li>  les pauses </li><li>  rabattements </li><li>  quarts </li><li>  peignes </li><li>  suivre </li><li>  liant transpirant </li></ul><br>  J'ai décidé de m'attaquer à ces défauts. <br><br><h2>  Collecte de données </h2><br>  Où puis-je obtenir des photographies qui représentent des sections suffisamment grandes de la chaussée, et même en référence à la géolocalisation?  La réponse est venue en strass - panoramas sur les cartes de Yandex (ou Google), cependant, après un peu de recherche, j'ai trouvé plusieurs autres options alternatives: <br><br><ul><li>  émission de moteurs de recherche d'images pour les demandes pertinentes; </li><li>  photos sur des sites pour recevoir des plaintes (Rosyama, citoyen en colère, vertu, etc.) </li><li>  Opendatascience a incité un projet à détecter les défauts de la route avec un ensemble de données marqué - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github.com/sekilab/RoadDamageDetector</a> </li></ul><br>  Malheureusement, une analyse de ces options a montré qu'elles ne me convenaient pas très bien: l'émission de moteurs de recherche a beaucoup de bruit (beaucoup de photos qui ne sont pas des routes, différents rendus, etc.), les photos des sites pour recevoir des plaintes ne contiennent que des photos avec de grandes violations de la surface asphaltée , il y a pas mal de photos avec de petites violations de couverture et sans violations sur ces sites, l'ensemble de données du projet RoadDamageDetector est collecté au Japon et ne contient pas d'échantillons avec de grandes violations de couverture, ainsi que des routes sans couverture du tout. <br><br>  Étant donné que les options alternatives ne conviennent pas, nous utiliserons des panoramas Yandex (j'ai exclu l'option panorama Google, car le service est présenté dans moins de villes en Russie et est mis à jour moins fréquemment).  Il a décidé de collecter des données dans les villes de plus de 100 000 habitants, ainsi que dans les centres fédéraux.  J'ai fait une liste de noms de villes - il y en avait 176, plus tard il s'avère que seulement 149 d'entre elles ont des panoramas.  Je ne vais pas me plonger dans les fonctionnalités de l'analyse des tuiles, je dirai qu'au final, j'ai obtenu 149 dossiers (un pour chaque ville) dans lesquels il y avait au total 1,7 million de photos.  Par exemple, pour Novokuznetsk, le dossier ressemblait à ceci: <br><br><img src="https://habrastorage.org/webt/aw/fa/73/awfa73gw128fyrvl8au2b_brjb8.png"><br><br>  Par le nombre de photos téléchargées, les villes étaient réparties comme suit: <br><br><div class="spoiler">  <b class="spoiler_title">Table</b> <div class="spoiler_text"><table><tbody><tr><th>  Ville <br></th><th>  Nombre de photos, pcs <br></th></tr><tr><td>  Moscou <br><br></td><td>  86048 <br><br></td></tr><tr><td>  Saint-Pétersbourg <br><br></td><td>  41376 <br><br></td></tr><tr><td>  Saransk <br><br></td><td>  18880 <br><br></td></tr><tr><td>  Podolsk <br><br></td><td>  18560 <br><br></td></tr><tr><td>  Krasnogorsk <br><br></td><td>  18208 <br><br></td></tr><tr><td>  Lyubertsy <br><br></td><td>  17760 <br><br></td></tr><tr><td>  Kaliningrad <br><br></td><td>  16928 <br><br></td></tr><tr><td>  Kolomna <br><br></td><td>  16832 <br><br></td></tr><tr><td>  Mytishchi <br><br></td><td>  16192 <br><br></td></tr><tr><td>  Vladivostok <br><br></td><td>  16096 <br><br></td></tr><tr><td>  Balashikha <br><br></td><td>  15968 <br><br></td></tr><tr><td>  Petrozavodsk <br><br></td><td>  15968 <br><br></td></tr><tr><td>  Ekaterinbourg <br><br></td><td>  15808 <br><br></td></tr><tr><td>  Veliky Novgorod <br><br></td><td>  15744 <br><br></td></tr><tr><td>  Naberezhnye Chelny <br><br></td><td>  15680 <br><br></td></tr><tr><td>  Krasnodar <br><br></td><td>  15520 <br><br></td></tr><tr><td>  Nizhny Novgorod <br><br></td><td>  15488 <br><br></td></tr><tr><td>  Khimki <br><br></td><td>  15296 <br><br></td></tr><tr><td>  Tula <br><br></td><td>  15296 <br><br></td></tr><tr><td>  Novossibirsk <br><br></td><td>  15264 <br><br></td></tr><tr><td>  Tver <br><br></td><td>  15200 <br><br></td></tr><tr><td>  Miass <br><br></td><td>  15104 <br><br></td></tr><tr><td>  Ivanovo <br><br></td><td>  15072 <br><br></td></tr><tr><td>  Vologda <br><br></td><td>  15008 <br><br></td></tr><tr><td>  Joukovski <br><br></td><td>  14976 <br><br></td></tr><tr><td>  Kostroma <br><br></td><td>  14912 <br><br></td></tr><tr><td>  Samara <br><br></td><td>  14880 <br><br></td></tr><tr><td>  Korolev <br><br></td><td>  14784 <br><br></td></tr><tr><td>  Kaluga <br><br></td><td>  14720 <br><br></td></tr><tr><td>  Cherepovets <br><br></td><td>  14720 <br><br></td></tr><tr><td>  Sébastopol <br><br></td><td>  14688 <br><br></td></tr><tr><td>  Pushkino <br><br></td><td>  14528 <br><br></td></tr><tr><td>  Yaroslavl <br><br></td><td>  14464 <br><br></td></tr><tr><td>  Oulianovsk <br><br></td><td>  14400 <br><br></td></tr><tr><td>  Rostov-sur-le-Don <br><br></td><td>  14368 <br><br></td></tr><tr><td>  Domodedovo <br><br></td><td>  14304 <br><br></td></tr><tr><td>  Kamensk-Uralsky <br><br></td><td>  14208 <br><br></td></tr><tr><td>  Pskov <br><br></td><td>  14144 <br><br></td></tr><tr><td>  Yoshkar-Ola <br><br></td><td>  14080 <br><br></td></tr><tr><td>  Kerch <br><br></td><td>  14080 <br><br></td></tr><tr><td>  Mourmansk <br><br></td><td>  13920 <br><br></td></tr><tr><td>  Togliatti <br><br></td><td>  13920 <br><br></td></tr><tr><td>  Vladimir <br><br></td><td>  13792 <br><br></td></tr><tr><td>  Aigle <br><br></td><td>  13792 <br><br></td></tr><tr><td>  Syktyvkar <br><br></td><td>  13728 <br><br></td></tr><tr><td>  Dolgoprudny <br><br></td><td>  13696 <br><br></td></tr><tr><td>  Khanty-Mansiysk <br><br></td><td>  13664 <br><br></td></tr><tr><td>  Kazan <br><br></td><td>  13600 <br><br></td></tr><tr><td>  Engels <br><br></td><td>  13440 <br><br></td></tr><tr><td>  Arkhangelsk <br><br></td><td>  13280 <br><br></td></tr><tr><td>  Bryansk <br><br></td><td>  13216 <br><br></td></tr><tr><td>  Omsk <br><br></td><td>  13120 <br><br></td></tr><tr><td>  Syzran <br><br></td><td>  13088 <br><br></td></tr><tr><td>  Krasnoyarsk <br><br></td><td>  13056 <br><br></td></tr><tr><td>  Shchelkovo <br><br></td><td>  12928 <br><br></td></tr><tr><td>  Penza <br><br></td><td>  12864 <br><br></td></tr><tr><td>  Chelyabinsk <br><br></td><td>  12768 <br><br></td></tr><tr><td>  Cheboksary <br><br></td><td>  12768 <br><br></td></tr><tr><td>  Nizhny Tagil <br><br></td><td>  12672 <br><br></td></tr><tr><td>  Stavropol <br><br></td><td>  12672 <br><br></td></tr><tr><td>  Ramenskoye <br><br></td><td>  12640 <br><br></td></tr><tr><td>  Irkoutsk <br><br></td><td>  12608 <br><br></td></tr><tr><td>  Angarsk <br><br></td><td>  12608 <br><br></td></tr><tr><td>  Tyumen <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Odintsovo <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Ufa <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Magadan <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Perm <br><br></td><td>  12448 <br><br></td></tr><tr><td>  Kirov <br><br></td><td>  12256 <br><br></td></tr><tr><td>  Nizhnekamsk <br><br></td><td>  12224 <br><br></td></tr><tr><td>  Makhachkala <br><br></td><td>  12096 <br><br></td></tr><tr><td>  Nizhnevartovsk <br><br></td><td>  11936 <br><br></td></tr><tr><td>  Koursk <br><br></td><td>  11904 <br><br></td></tr><tr><td>  Sotchi <br><br></td><td>  11872 <br><br></td></tr><tr><td>  Tambov <br><br></td><td>  11840 <br><br></td></tr><tr><td>  Pyatigorsk <br><br></td><td>  11808 <br><br></td></tr><tr><td>  Volgodonsk <br><br></td><td>  11712 <br><br></td></tr><tr><td>  Ryazan <br><br></td><td>  11680 <br><br></td></tr><tr><td>  Saratov <br><br></td><td>  11616 <br><br></td></tr><tr><td>  Dzerzhinsk <br><br></td><td>  11456 <br><br></td></tr><tr><td>  Orenburg <br><br></td><td>  11456 <br><br></td></tr><tr><td>  Monticule <br><br></td><td>  11424 <br><br></td></tr><tr><td>  Volgograd <br><br></td><td>  11264 <br><br></td></tr><tr><td>  Izhevsk <br><br></td><td>  11168 <br><br></td></tr><tr><td>  Chrysostome <br><br></td><td>  11136 <br><br></td></tr><tr><td>  Lipetsk <br><br></td><td>  11072 <br><br></td></tr><tr><td>  Kislovodsk <br><br></td><td>  11072 <br><br></td></tr><tr><td>  Surgut <br><br></td><td>  11040 <br><br></td></tr><tr><td>  Magnitogorsk <br><br></td><td>  10912 <br><br></td></tr><tr><td>  Smolensk <br><br></td><td>  10784 <br><br></td></tr><tr><td>  Khabarovsk <br><br></td><td>  10752 <br><br></td></tr><tr><td>  Kopeysk <br><br></td><td>  10688 <br><br></td></tr><tr><td>  Maykop <br><br></td><td>  10656 <br><br></td></tr><tr><td>  Petropavlovsk-Kamchatsky <br><br></td><td>  10624 <br><br></td></tr><tr><td>  Taganrog <br><br></td><td>  10560 <br><br></td></tr><tr><td>  Barnaul <br><br></td><td>  10528 <br><br></td></tr><tr><td>  Sergiev Posad <br><br></td><td>  10368 <br><br></td></tr><tr><td>  Elista <br><br></td><td>  10304 <br><br></td></tr><tr><td>  Sterlitamak <br><br></td><td>  9920 <br><br></td></tr><tr><td>  Simferopol <br><br></td><td>  9824 <br><br></td></tr><tr><td>  Tomsk <br><br></td><td>  9760 <br><br></td></tr><tr><td>  Orekhovo-Zuevo <br><br></td><td>  9728 <br><br></td></tr><tr><td>  Astrakhan <br><br></td><td>  9664 <br><br></td></tr><tr><td>  Evpatoria <br><br></td><td>  9568 <br><br></td></tr><tr><td>  Noginsk <br><br></td><td>  9344 <br><br></td></tr><tr><td>  Chita <br><br></td><td>  9216 <br><br></td></tr><tr><td>  Belgorod <br><br></td><td>  9120 <br><br></td></tr><tr><td>  Biysk <br><br></td><td>  8928 <br><br></td></tr><tr><td>  Rybinsk <br><br></td><td>  8896 <br><br></td></tr><tr><td>  Severodvinsk <br><br></td><td>  8832 <br><br></td></tr><tr><td>  Voronezh <br><br></td><td>  8768 <br><br></td></tr><tr><td>  Blagoveshchensk <br><br></td><td>  8672 <br><br></td></tr><tr><td>  Novorossiysk <br><br></td><td>  8608 <br><br></td></tr><tr><td>  Ulan-Ude <br><br></td><td>  8576 <br><br></td></tr><tr><td>  Serpukhov <br><br></td><td>  8320 <br><br></td></tr><tr><td>  Komsomolsk-on-Amur <br><br></td><td>  8192 <br><br></td></tr><tr><td>  Abakan <br><br></td><td>  8128 <br><br></td></tr><tr><td>  Norilsk <br><br></td><td>  8096 <br><br></td></tr><tr><td>  Yuzhno-Sakhalinsk <br><br></td><td>  8032 <br><br></td></tr><tr><td>  Obninsk <br><br></td><td>  7904 <br><br></td></tr><tr><td>  Essentuki <br><br></td><td>  7712 <br><br></td></tr><tr><td>  Bataysk <br><br></td><td>  7648 <br><br></td></tr><tr><td>  Volzhsky <br><br></td><td>  7584 <br><br></td></tr><tr><td>  Novocherkassk <br><br></td><td>  7488 <br><br></td></tr><tr><td>  Berdsk <br><br></td><td>  7456 <br><br></td></tr><tr><td>  Arzamas <br><br></td><td>  7424 <br><br></td></tr><tr><td>  Pervouralsk <br><br></td><td>  7392 <br><br></td></tr><tr><td>  Kemerovo <br><br></td><td>  7104 <br><br></td></tr><tr><td>  Elektrostal <br><br></td><td>  6720 <br><br></td></tr><tr><td>  Derbent <br><br></td><td>  6592 <br><br></td></tr><tr><td>  Yakutsk <br><br></td><td>  6528 <br><br></td></tr><tr><td>  Murom <br><br></td><td>  6240 <br><br></td></tr><tr><td>  Nefteyugansk <br><br></td><td>  5792 <br><br></td></tr><tr><td>  Reutov <br><br></td><td>  5696 <br><br></td></tr><tr><td>  Birobidzhan <br><br></td><td>  5440 <br><br></td></tr><tr><td>  Novokuybyshevsk <br><br></td><td>  5248 <br><br></td></tr><tr><td>  Salekhard <br><br></td><td>  5184 <br><br></td></tr><tr><td>  Novokuznetsk <br><br></td><td>  5152 <br><br></td></tr><tr><td>  Novy Urengoy <br><br></td><td>  4736 <br><br></td></tr><tr><td>  Noyabrsk <br><br></td><td>  4416 <br><br></td></tr><tr><td>  Novocheboksarsk <br><br></td><td>  4352 <br><br></td></tr><tr><td>  Yelets <br><br></td><td>  3968 <br><br></td></tr><tr><td>  Kaspiysk <br><br></td><td>  3936 <br><br></td></tr><tr><td>  Stary Oskol <br><br></td><td>  3840 <br><br></td></tr><tr><td>  Artyom <br><br></td><td>  3744 <br><br></td></tr><tr><td>  Zheleznogorsk <br><br></td><td>  3584 <br><br></td></tr><tr><td>  Salavat <br><br></td><td>  3584 <br><br></td></tr><tr><td>  Prokopyevsk <br><br></td><td>  2816 <br><br></td></tr><tr><td>  Gorno-Altaysk <br><br></td><td>  2464 <br><br></td></tr></tbody></table><br></div></div><br><h2>  Préparation d'un ensemble de données pour la formation </h2><br>  Et donc, l'ensemble de données est assemblé, comment maintenant, en ayant une photo de la section de la route et des objets qui l'entourent, découvrez la qualité de l'asphalte représenté dessus?  J'ai décidé de découper un morceau de la photo mesurant 350 * 244 pixels au centre de la photo originale juste en dessous du milieu.  Réduisez ensuite le morceau coupé horizontalement à une taille de 244 pixels.  L'image résultante (taille 244 * 244) sera l'entrée pour l'encodeur convolutionnel: <br><br><img src="https://habrastorage.org/webt/ya/tt/s8/yatts8qbzq9ddnxql_cydrmfeug.png"><br><br>  Afin de mieux comprendre les données que je traite, les 2000 premières photos que j'ai tracées moi-même, les autres photos ont été balisées par les employés de Yandex.Tolki.  Devant eux, j'ai posé une question dans le libellé suivant. <br><br>  Indiquez la surface de la route que vous voyez sur la photo: <br><br><ol><li>  Sol / décombres </li><li>  Pavés, tuiles, trottoirs </li><li>  Rails, voies ferrées </li><li>  Eau, grosses flaques d'eau </li><li>  Asphalte </li><li>  Il n'y a pas de route sur la photo / Objets étrangers / La couverture n'est pas visible à cause des voitures </li></ol><br>  Si l'interprète a choisi «Asphalte», un menu est apparu qui proposait d'évaluer sa qualité: <br><br><ol><li>  Excellente couverture </li><li>  Légères fissures simples / nids de poule simples peu profonds </li><li>  Grandes fissures / fissures de grille / nids de poule mineurs simples </li><li>  Grands nids de poule / nids de poule profonds / revêtement détruit </li></ol><br>  Comme le montrent les tests des tâches, les interprètes de Y. Toloki ne diffèrent pas dans l'intégrité du travail - ils cliquent accidentellement sur les champs avec la souris et considèrent que la tâche est terminée.  J'ai dû ajouter des questions de contrôle (dans la mission, il y avait 46 photographies, dont 12 étaient des contrôles) et permettre une acceptation retardée.  Comme questions de contrôle, j'ai utilisé ces images que j'ai tracées moi-même.  J'ai automatisé l'acceptation différée - Y. Toloka vous permet de télécharger les résultats du travail dans un fichier CSV et de charger les résultats de la vérification des réponses.  La vérification des réponses a fonctionné comme suit - si la tâche contient plus de 5% de réponses incorrectes aux questions de contrôle, alors elle est considérée comme non satisfaite.  De plus, si l'entrepreneur a indiqué une réponse qui est logiquement proche de la vérité, sa réponse est considérée comme correcte. <br>  En conséquence, j'ai obtenu environ 30 000 photos étiquetées, que j'ai décidé de distribuer en trois classes pour la formation: <br><br><ul><li>  «Bon» - photos étiquetées «Asphalte: excellent revêtement» et «Asphalte: petites fissures simples» </li><li>  «Milieu» - photos étiquetées «Pavés, carreaux, trottoirs», «Rails, voies ferrées» et «Asphalte: grandes fissures / fissures de la grille / simples bosses mineures» </li><li>  «Grand» - photos intitulées «Sol / Pierre concassée», «Eau, grandes flaques d'eau» et «Asphalte: un grand nombre de nids de poule / Nids de poule profonds / Chaussée détruite» </li><li>  Photos taguées "Il n'y a pas de route sur la photo / Objets étrangers / La couverture n'est pas visible à cause des voitures" il y en avait très peu (22 pcs.) Et je les ai exclus des travaux ultérieurs </li></ul><br><h2>  Développement et formation des classificateurs </h2><br>  Ainsi, les données sont collectées et étiquetées, nous procédons au développement du classificateur.  Habituellement, pour les tâches de classification d'images, en particulier lors de la formation sur de petits ensembles de données, un codeur convolutionnel prêt à l'emploi est utilisé, à la sortie duquel un nouveau classificateur est connecté.  J'ai décidé d'utiliser un classificateur simple sans couche cachée, une couche d'entrée de taille 128 et une couche de sortie de taille 3. J'ai décidé d'utiliser immédiatement plusieurs options prêtes à l'emploi formées sur ImageNet comme encodeurs: <br><br><ul><li>  Xception </li><li>  Resnet </li><li>  Création </li><li>  Vgg16 </li><li>  Densenet121 </li><li>  Mobilenet </li></ul><br>  Voici la fonction qui crée le modèle Keras avec l'encodeur donné: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(typeModel)</span></span></span><span class="hljs-function">:</span></span> conv_base = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"nasnet"</span></span>): conv_base = keras.applications.nasnet.NASNetMobile(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"xception"</span></span>): conv_base = keras.applications.xception.Xception(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>): conv_base = keras.applications.resnet50.ResNet50(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"inception"</span></span>): conv_base = keras.applications.inception_v3.InceptionV3(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>): conv_base = keras.applications.densenet.DenseNet121(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span>): conv_base = keras.applications.mobilenet_v2.MobileNetV2(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>): conv_base = keras.applications.vgg16.VGG16(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) conv_base.trainable = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> model = Sequential() model.add(conv_base) model.add(Flatten()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, kernel_regularizer=regularizers.l2(<span class="hljs-number"><span class="hljs-number">0.0002</span></span>))) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Pour la formation, j'ai utilisé un générateur avec augmentation (puisque les possibilités de l'augmentation intégrée à Keras me semblaient insuffisantes, j'ai alors utilisé la bibliothèque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Augmentor</a> ): <br><br><ul><li>  Pistes </li><li>  Distorsion aléatoire </li><li>  Tours </li><li>  Échange de couleur </li><li>  Quart de travail </li><li>  Modifier le contraste et la luminosité </li><li>  Ajout de bruit aléatoire </li><li>  Recadrer </li></ul><br>  Après l'augmentation, les photos ressemblaient à ceci: <br><br><img src="https://habrastorage.org/webt/yc/qy/uh/ycqyuh1no4h57-or062y3epc4yy.png"><br><br>  Code générateur: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_datagen</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> train_dir=<span class="hljs-string"><span class="hljs-string">'~/data/train_img'</span></span> test_dir=<span class="hljs-string"><span class="hljs-string">'~/data/test_img'</span></span> testDataGen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span> / <span class="hljs-number"><span class="hljs-number">255</span></span>) train_generator = datagen.flow_from_directory( train_dir, target_size=img_size, batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>, class_mode=<span class="hljs-string"><span class="hljs-string">'categorical'</span></span>) p = Augmentor.Pipeline(train_dir) p.skew(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>) p.random_distortion(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>,grid_width=<span class="hljs-number"><span class="hljs-number">3</span></span>,grid_height=<span class="hljs-number"><span class="hljs-number">3</span></span>,magnitude=<span class="hljs-number"><span class="hljs-number">8</span></span>) p.rotate(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, max_left_rotation=<span class="hljs-number"><span class="hljs-number">5</span></span>, max_right_rotation=<span class="hljs-number"><span class="hljs-number">5</span></span>) p.random_color(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1</span></span>) p.flip_left_right(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>) p.random_brightness(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1.2</span></span>) p.random_contrast(probability=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1</span></span>) p.random_erasing(probability=<span class="hljs-number"><span class="hljs-number">1</span></span>,rectangle_area=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) p.crop_by_size(probability=<span class="hljs-number"><span class="hljs-number">1</span></span>, width=<span class="hljs-number"><span class="hljs-number">244</span></span>, height=<span class="hljs-number"><span class="hljs-number">244</span></span>, centre=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_generator = keras_generator(p,batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>) test_generator = testDataGen.flow_from_directory( test_dir, target_size=img_size, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, class_mode=<span class="hljs-string"><span class="hljs-string">'categorical'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (train_generator, test_generator)</code> </pre> <br>  Le code montre que l'augmentation n'est pas utilisée pour les données de test. <br><br>  Ayant un générateur réglé, vous pouvez commencer à former le modèle, nous le réaliserons en deux étapes: d'abord, former uniquement notre classificateur, puis complètement le modèle entier. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evalModelstep1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(typeModel)</span></span></span><span class="hljs-function">:</span></span> K.clear_session() gc.collect() model=createModel(typeModel) traiGen,testGen=getDatagen() model.fit_generator(generator=traiGen, epochs=<span class="hljs-number"><span class="hljs-number">4</span></span>, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">30000</span></span>/<span class="hljs-number"><span class="hljs-number">16</span></span>, validation_steps=len(testGen), validation_data=testGen, ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evalModelstep2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model)</span></span></span><span class="hljs-function">:</span></span> early_stopping_callback = EarlyStopping(monitor=<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience=<span class="hljs-number"><span class="hljs-number">3</span></span>) model.layers[<span class="hljs-number"><span class="hljs-number">0</span></span>].trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> model.trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-5</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) traiGen,testGen=getDatagen() model.fit_generator(generator=traiGen, epochs=<span class="hljs-number"><span class="hljs-number">25</span></span>, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">30000</span></span>/<span class="hljs-number"><span class="hljs-number">16</span></span>, validation_steps=len(testGen), validation_data=testGen, callbacks=[early_stopping_callback] ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">full_fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model_names=[ <span class="hljs-string"><span class="hljs-string">"xception"</span></span>, <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>, <span class="hljs-string"><span class="hljs-string">"inception"</span></span>, <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>, <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>, <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span> ] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model_names: print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(model_name) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) model = evalModelstep1(model_name) model = evalModelstep2(model) model.save(<span class="hljs-string"><span class="hljs-string">"~/data/models/model_new_"</span></span>+str(model_name)+<span class="hljs-string"><span class="hljs-string">".h5"</span></span>)</code> </pre><br>  Appelez full_fit () et attendez.  Nous attendons depuis longtemps. <br><br>  En conséquence, nous aurons six modèles formés, nous vérifierons l'exactitude de ces modèles sur une partie distincte des données étiquetées; j'ai reçu ce qui suit: <br><br><table><tbody><tr><td><p>  Nom du modèle </p><br></td><td><p>  Précision% </p><br></td></tr><tr><td><p>  Xception </p><br></td><td><p>  87,3 </p><br></td></tr><tr><td><p>  Resnet </p><br></td><td><p>  90,8 </p><br></td></tr><tr><td><p>  Création </p><br></td><td><p>  90,2 </p><br></td></tr><tr><td><p>  Vgg16 </p><br></td><td><p>  89,2 </p><br></td></tr><tr><td><p>  Densenet121 </p><br></td><td><p>  90,6 </p><br></td></tr><tr><td><p>  Mobilenet </p><br></td><td><p>  86,5 </p><br></td></tr></tbody></table><br>  En général, pas beaucoup, mais avec un si petit échantillon de formation, on ne peut pas s'attendre à plus.  Pour augmenter légèrement la précision, j'ai combiné les sorties des modèles en faisant la moyenne: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_meta_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model_names=[ <span class="hljs-string"><span class="hljs-string">"xception"</span></span>, <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>, <span class="hljs-string"><span class="hljs-string">"inception"</span></span>, <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>, <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>, <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span> ] model_input = Input(shape=(<span class="hljs-number"><span class="hljs-number">244</span></span>,<span class="hljs-number"><span class="hljs-number">244</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) submodels=[] i=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model_names: filename= <span class="hljs-string"><span class="hljs-string">"~/data/models/model_new_"</span></span>+str(model_name)+<span class="hljs-string"><span class="hljs-string">".h5"</span></span> submodel = keras.models.load_model(filename) submodel.name = model_name+<span class="hljs-string"><span class="hljs-string">"_"</span></span>+str(i) i+=<span class="hljs-number"><span class="hljs-number">1</span></span> submodels.append(submodel(model_input)) out=average(submodels) model = Model(inputs = model_input,outputs=out) model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  La précision résultante était de 91,3%.  Sur ce résultat, j'ai décidé d'arrêter. <br><br><h2>  Utilisation de Classifier </h2><br>  Enfin le classifieur est prêt et il peut être mis en action!  Je prépare les données d'entrée et lance le classificateur - un peu plus d'une journée et 1,7 million de photos ont été traitées.  Maintenant, la partie amusante est les résultats.  Amenez immédiatement les dix premières et dix dernières villes dans le nombre relatif de routes avec une bonne couverture: <br><br><img src="https://habrastorage.org/webt/mf/vl/xu/mfvlxuvjesvy2leqhplfnik4mm8.png"><br><br><div class="spoiler">  <b class="spoiler_title">Tableau complet (image cliquable)</b> <div class="spoiler_text"> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/9d8/4fd/38c/9d84fd38c07014be4f68499489ce19bc.png"></a> <br></div></div><br><br>  Et voici la cote de qualité des routes par sujets fédéraux: <br><br><img src="https://habrastorage.org/webt/ih/kq/xq/ihkqxqskkfcfib90gc68ivmxo2i.png"><br><br><div class="spoiler">  <b class="spoiler_title">Table complète</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/md/6j/-m/md6j-mv6jt27zsxgu8wkd2pimmy.png"><br></div></div><br>  Évaluation par les districts fédéraux: <br><br><img src="https://habrastorage.org/webt/ro/qq/ry/roqqryu12toajz6cgeals3vzuxc.png"><br><br>  Répartition de la qualité des routes en Russie dans son ensemble: <br><br><img src="https://habrastorage.org/webt/ow/rt/h1/owrth1ro6yu3svxdpwiyfedzeby.png"><br><br>  Eh bien, c'est tout, tout le monde peut tirer des conclusions lui-même. <br><br>  Enfin, je donnerai les meilleures photos de chaque catégorie (qui ont reçu la valeur maximale dans leur classe): <br><br><div class="spoiler">  <b class="spoiler_title">Image</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/k9/yf/dl/k9yfdlmiuynquyqhoxjuowvzcsu.jpeg"><br></div></div><br><br>  PS Dans les commentaires, a souligné à juste titre le manque de statistiques sur les années de réception des photographies.  Je corrige et donne un tableau: <br><table><tbody><tr><td><p>  Année </p><br></td><td><p>  Nombre de photos, pcs </p><br></td></tr><tr><td>  2008 </td><td>  37 </td></tr><tr><td>  2009 </td><td>  13 </td></tr><tr><td>  2010 </td><td>  157030 </td></tr><tr><td>  2011 </td><td>  60724 </td></tr><tr><td>  2012 </td><td>  42387 </td></tr><tr><td>  2013 </td><td>  12148 <br><br></td></tr><tr><td>  2014 </td><td>  141021 <br><br></td></tr><tr><td>  2015 </td><td>  46143 <br><br></td></tr><tr><td>  2016 </td><td>  410385 <br><br></td></tr><tr><td>  2017 </td><td>  324279 <br><br></td></tr><tr><td>  2018 </td><td>  581961 <br><br></td></tr></tbody></table></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr437542/">https://habr.com/ru/post/fr437542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr437532/index.html">L'industrie de la robotique devient enfin plus réaliste</a></li>
<li><a href="../fr437534/index.html">Comment Retentioneering est implémenté dans l'App in the Air</a></li>
<li><a href="../fr437536/index.html">Le meilleur du monde d'Angular pour la semaine - Digest n ° 1 (18 janvier - 25 janvier)</a></li>
<li><a href="../fr437538/index.html">Le réseau neuronal AlphaStar a battu les professionnels StarCraft II avec un score de 10−1</a></li>
<li><a href="../fr437540/index.html">Comment gérer les conflits d'équipe</a></li>
<li><a href="../fr437544/index.html">Quelle est la différence entre les écrans de livres électroniques et les smartphones et tablettes?</a></li>
<li><a href="../fr437546/index.html">Machine Linux dans un domaine Windows AD utilisant sssd et krb5</a></li>
<li><a href="../fr437548/index.html">Non seulement uBlock Origin souffrira de nouvelles API dans Chromium, mais aussi d'autres extensions</a></li>
<li><a href="../fr437550/index.html">Week-end de lecture: 10 matériaux vinyle - de la production à l'écoute et aux soins à domicile</a></li>
<li><a href="../fr437552/index.html">Excursion à la production de Promobot. Entretien avec CTO</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèª üë®üèª‚Äç‚öïÔ∏è üë©üèº‚Äçüé® Operation des maschinellen Lernens in Mail.ru Mail üïë üêö ‚öïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Basierend auf meinen Auftritten bei Highload ++ und DataFest Minsk 2019 

 F√ºr viele ist die Post heute ein wesentlicher Bestandteil des Online-Lebens...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Operation des maschinellen Lernens in Mail.ru Mail</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/476714/"><img src="https://habrastorage.org/webt/k-/h5/xj/k-h5xjc6xswda5namvb8vgzjnns.jpeg"><br><br>  <i>Basierend auf meinen Auftritten bei Highload ++ und DataFest Minsk 2019</i> <br><br>  F√ºr viele ist die Post heute ein wesentlicher Bestandteil des Online-Lebens.  Mit ihrer Hilfe f√ºhren wir Gesch√§ftskorrespondenz, speichern alle wichtigen Informationen in Bezug auf Finanzen, Hotelreservierungen, Checkout und vieles mehr.  Mitte 2018 haben wir eine Produktstrategie f√ºr die E-Mail-Entwicklung formuliert.  Was soll moderne Post sein? <br><br>  E-Mails m√ºssen <b>intelligent sein</b> , dh den Benutzern dabei helfen, auf die zunehmende Menge an Informationen zuzugreifen: Filtern, Strukturieren und Bereitstellen auf die bequemste Weise.  Es sollte <b>n√ºtzlich sein</b> , direkt in der Mailbox verschiedene Probleme l√∂sen zu lassen, zum Beispiel Bu√ügelder zu zahlen (eine Funktion, die ich leider benutze).  Gleichzeitig sollte E-Mail nat√ºrlich den Schutz von Informationen gew√§hrleisten, indem Spam abgeschnitten und vor Hacks gesch√ºtzt wird, d. H. <b>Sicher sein</b> . <br><a name="habracut"></a><br>  Diese Bereiche bestimmen eine Reihe von Schl√ºsselaufgaben, von denen viele durch maschinelles Lernen effektiv gel√∂st werden k√∂nnen.  Hier finden Sie Beispiele f√ºr vorhandene Funktionen, die im Rahmen der Strategie entwickelt wurden - eine f√ºr jede Richtung. <br><br><ul><li>  <b>Intelligente Antwort</b> .  Es gibt eine intelligente Antwortfunktion in der Mail.  Das neuronale Netz analysiert den Text des Buchstabens, versteht seine Bedeutung und seinen Zweck und bietet als Ergebnis die drei am besten geeigneten Antwortoptionen: positiv, negativ und neutral.  Dies hilft, beim Beantworten von Briefen Zeit zu sparen, und es macht oftmals auch Spa√ü, nicht dem Standard zu entsprechen. <br></li><li> <b>Gruppierung von Briefen im</b> Zusammenhang mit Bestellungen in Online-Shops.  Wir kaufen oft im Internet ein und in der Regel k√∂nnen die Gesch√§fte f√ºr jede Bestellung mehrere Briefe versenden.  Zum Beispiel gibt es bei AliExpress, dem gr√∂√üten Dienst, viele Buchstaben f√ºr eine Bestellung, und wir haben festgestellt, dass im Terminal-Fall ihre Nummer 29 erreichen kann. Daher w√§hlen wir unter Verwendung des Named-Entity-Recognition-Modells die Bestellnummer und andere Informationen aus dem Text und der Gruppe aus Alle Buchstaben in einem Thread.  Wir zeigen auch die grundlegenden Informationen zur Bestellung in einer separaten Box, die die Arbeit mit dieser Art von Briefen erleichtert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f1/b29/7f7/3f1b297f73ba953ecda62e89fee2ee9c.png"><br></li><li>  <b>Antiphishing</b> .  Phishing ist eine besonders gef√§hrliche betr√ºgerische Art von E-Mails, mit deren Hilfe Angreifer versuchen, an Finanzinformationen (einschlie√ülich Bankkarten von Benutzern) und Anmeldungen zu gelangen.  Solche Briefe ahmen die echten Briefe des Dienstes nach, auch optisch.  Daher erkennen wir mithilfe von Computer Vision die Logos und den Stil von Briefen gro√üer Unternehmen (z. B. Mail.ru, Sberbank, Alpha) und ber√ºcksichtigen dies zusammen mit Text und anderen Zeichen in unseren Spam- und Phishing-Klassifizierern. <br></li></ul><br><h2>  Maschinelles Lernen </h2><br>  Ein wenig √ºber maschinelles Lernen in der Post im Allgemeinen.  Mail ist ein stark ausgelastetes System: Auf unseren Servern werden durchschnittlich 1,5 Milliarden Briefe pro Tag an 30 Millionen DAU-Benutzer gesendet.  Erf√ºllen Sie alle erforderlichen Funktionen und Merkmale von ca. 30 maschinellen Lernsystemen. <br><br>  Jeder Brief durchl√§uft ein ganzes Klassifizierungsband.  Zuerst schneiden wir Spam ab und hinterlassen gute E-Mails.  Benutzer bemerken die Wirkung von Anti-Spam h√§ufig nicht, da 95-99% des Spam nicht einmal in den entsprechenden Ordner gelangen.  Spam-Erkennung ist ein sehr wichtiger Teil unseres Systems und der schwierigste, da es im Bereich der Spam-Abwehr eine st√§ndige Anpassung zwischen Verteidigungs- und Angriffssystemen gibt, die eine st√§ndige technische Herausforderung f√ºr unser Team darstellt. <br><br>  Als n√§chstes trennen wir Briefe von Menschen und Robotern.  Briefe von Menschen sind am wichtigsten, deshalb stellen wir ihnen Funktionen wie Smart Reply zur Verf√ºgung.  Briefe von Robotern gliedern sich in zwei Teile: Transaktionsbriefe - das sind wichtige Briefe von Dienstleistungen, zum Beispiel die Best√§tigung von Eink√§ufen oder Hotelreservierungen, Finanzen und Informationen - dies sind Gesch√§ftswerbung, Rabatte. <br><br>  Wir glauben, dass Transaktionsbriefe der pers√∂nlichen Korrespondenz gleichwertig sind.  Sie sollten zur Hand sein, denn oft ist es notwendig, Informationen √ºber die Bestellung oder Buchung eines Tickets schnell zu finden, und wir verbringen viel Zeit damit, nach diesen Briefen zu suchen.  Aus praktischen Gr√ºnden teilen wir sie automatisch in sechs Hauptkategorien ein: Reisen, Buchungen, Finanzen, Tickets, Registrierungen und schlie√ülich Bu√ügelder. <br><br>  Newsletter sind die gr√∂√üte und wahrscheinlich weniger wichtige Gruppe, die keine sofortige Reaktion erfordert, da sich nichts Wesentliches im Leben des Benutzers √§ndert, wenn er einen solchen Brief nicht liest.  In unserer neuen Benutzeroberfl√§che gliedern wir sie in zwei Threads: soziale Netzwerke und Newsletter. Auf diese Weise wird das Postfach optisch gel√∂scht und nur wichtige Buchstaben in Sichtweite gelassen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/300/e18/9b9/300e189b9567866cb526eb34be80b3b4.jpg"><br><br><h3>  Bedienung </h3><br>  Eine gro√üe Anzahl von Systemen verursacht im Betrieb viele Schwierigkeiten.  Schlie√ülich verschlechtern sich Modelle im Laufe der Zeit wie jede andere Software: Zeichen gehen kaputt, Maschinen fallen aus, ein Code rollt herum.  Dar√ºber hinaus √§ndern sich die Daten st√§ndig: Es werden neue Daten hinzugef√ºgt, das Benutzerverhalten wird ge√§ndert usw. Daher wird das Modell ohne angemessene Unterst√ºtzung mit der Zeit immer schlechter funktionieren. <br><br>  Wir d√ºrfen nicht vergessen, dass die Auswirkungen auf das √ñkosystem umso gr√∂√üer sind, je tiefer maschinelles Lernen in das Leben der Nutzer eindringt und je mehr finanzielle Verluste oder Gewinne die Marktteilnehmer daraus ziehen k√∂nnen.  Daher stellen sich die Spieler in immer mehr Bereichen auf die Arbeit mit ML-Algorithmen ein (klassische Beispiele sind Werbung, Suche und der bereits erw√§hnte Spam-Schutz). <br><br>  Dar√ºber hinaus haben maschinelle Lernaufgaben eine Besonderheit: Jede, wenn auch unbedeutende, √Ñnderung des Systems kann zu einer Menge Arbeit mit dem Modell f√ºhren: Arbeiten mit Daten, Umschulung, Bereitstellung, die sich √ºber Wochen oder Monate hinziehen kann.  Je schneller die Umgebung ist, in der Ihre Modelle eingesetzt werden, desto mehr Aufwand erfordert der Support.  Ein Team kann viele Systeme erstellen und Spa√ü daran haben und dann fast alle Ressourcen f√ºr den Support aufwenden, ohne etwas Neues tun zu k√∂nnen.  Wir sind einmal in einem Anti-Spam-Team auf eine solche Situation gesto√üen.  Und sie kamen zu dem offensichtlichen Schluss, dass die Wartung automatisiert werden sollte. <br><br><h3>  Automatisierung </h3><br>  Was kann automatisiert werden?  In der Tat fast alles.  Ich habe vier Bereiche identifiziert, die die Infrastruktur des maschinellen Lernens definieren: <br><br><ul><li>  Datenerfassung; <br></li><li>  Weiterbildung; <br></li><li>  Bereitstellung; <br></li><li>  Testen &amp; √úberwachen. <br></li></ul><br>  Wenn die Umgebung instabil ist und sich st√§ndig √§ndert, ist die gesamte Infrastruktur rund um das Modell viel wichtiger als das Modell selbst.  Es mag der gute alte lineare Klassifikator sein, aber wenn Sie die Zeichen richtig anwenden und ein gutes Feedback von den Benutzern erhalten, wird es viel besser funktionieren als State-Of-The-Art-Modelle mit allem Schnickschnack. <br><br><h4>  R√ºckkopplungsschleife </h4><br>  Dieser Zyklus kombiniert Datenerfassung, Weiterbildung und Bereitstellung - und zwar den gesamten Aktualisierungszyklus des Modells.  Warum ist das wichtig?  Schauen Sie sich den Registrierungsplan in der Mail an: <br><br><img src="https://habrastorage.org/webt/8b/nj/qx/8bnjqxedzuj9ubakau7yd1vh_cc.png"><br><br>  Der Entwickler f√ºr maschinelles Lernen hat ein Antibot-Modell eingef√ºhrt, das die Registrierung von Bots in der Mail verhindert.  Das Diagramm f√§llt auf einen Wert, bei dem nur echte Benutzer verbleiben.  Alles ist ganz toll!  Aber vier Stunden vergehen, die Botvods versch√§rfen ihre Skripte und alles kehrt auf den ersten Platz zur√ºck.  In dieser Implementierung hat der Entwickler einen Monat lang Funktionen und ein Schulungsmodell hinzugef√ºgt, aber der Spammer konnte sich in vier Stunden anpassen. <br><br>  Um nicht so schmerzhaft zu sein und sp√§ter nicht alles wiederholen zu m√ºssen, m√ºssen wir uns zun√§chst √ºberlegen, wie die R√ºckkopplungsschleife aussehen wird und was wir tun werden, wenn sich die Umgebung √§ndert.  Beginnen wir mit der Datenerfassung - dies ist der Treibstoff f√ºr unsere Algorithmen. <br><br><h2>  Datenerfassung </h2><br>  Es ist klar, dass moderne neuronale Netze, je mehr Daten, desto besser sind und tats√§chlich Benutzer des Produkts generieren.  Benutzer k√∂nnen uns helfen, indem sie die Daten markieren. Sie k√∂nnen sie jedoch nicht missbrauchen, da Benutzer die Fertigstellung ihrer Modelle irgendwann satt haben und zu einem anderen Produkt wechseln. <br><br>  Einer der h√§ufigsten Fehler (hier beziehe ich mich auf Andrew Ng) ist, dass die Ausrichtung auf die Metriken im Testdatensatz zu stark ist und nicht auf das Feedback des Benutzers, das eigentlich das Hauptma√ü f√ºr die Qualit√§t der Arbeit ist, wenn wir ein Produkt f√ºr den Benutzer erstellen.  Wenn der Benutzer die Arbeit des Modells nicht versteht oder nicht mag, ist alles verderblich. <br><br>  Daher sollte der Nutzer immer abstimmen k√∂nnen, sollte ihm ein Tool zur R√ºckmeldung geben.  Wenn wir der Meinung sind, dass ein finanzbezogener Brief in der Box angekommen ist, m√ºssen wir ihn als "finanzieren" markieren und eine Schaltfl√§che zeichnen, auf die der Benutzer klicken kann, und sagen, dass er nicht finanziert. <br><br><h3>  Feedback-Qualit√§t </h3><br>  Sprechen wir √ºber die Qualit√§t des Nutzerfeedbacks.  Erstens k√∂nnen Sie und der Benutzer unterschiedliche Bedeutungen in ein Konzept einbringen.  Zum Beispiel denken Sie und Produktmanager, dass ‚ÄûFinanzen‚Äú Briefe der Bank sind, und der Benutzer glaubt, dass sich der Brief meiner Gro√ümutter √ºber den Ruhestand auch auf Finanzen bezieht.  Zweitens gibt es Benutzer, die gedankenlos gerne Tasten ohne Logik dr√ºcken.  Drittens kann sich der Benutzer in seinen Schlussfolgerungen zutiefst irren.  Ein anschauliches Beispiel f√ºr unsere Vorgehensweise ist die Einf√ºhrung des <a href="https://ru.wikipedia.org/wiki/%25D0%259D%25D0%25B8%25D0%25B3%25D0%25B5%25D1%2580%25D0%25B8%25D0%25B9%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B5_%25D0%25BF%25D0%25B8%25D1%2581%25D1%258C%25D0%25BC%25D0%25B0">nigerianischen Spamklassifikators</a> , einer sehr lustigen Art von Spam, bei der der Benutzer aufgefordert wird, mehrere Millionen Dollar von einem pl√∂tzlich in Afrika aufgefundenen entfernten Verwandten zu sammeln.  Nach der Einf√ºhrung dieses Klassifikators haben wir die Klicks auf diese Buchstaben auf "Kein Spam" √ºberpr√ºft, und es stellte sich heraus, dass 80% von ihnen saftiger nigerianischer Spam sind, was darauf hindeutet, dass Benutzer √§u√üerst vertrauensw√ºrdig sein k√∂nnen. <br><br>  Und vergessen wir nicht, dass nicht nur Menschen auf die Schaltfl√§chen dr√ºcken k√∂nnen, sondern auch alle m√∂glichen Bots, die sich als Browser ausgeben.  Rohes Feedback ist also nicht gut zum Lernen.  Was kann mit diesen Informationen getan werden? <br><br>  Wir verwenden zwei Ans√§tze: <br><br><ul><li>  <b>Feedback von verwandten ML</b> .  Zum Beispiel haben wir ein Online-Antibotikumsystem, das, wie ich bereits erw√§hnte, aufgrund einer begrenzten Anzahl von Anzeichen eine schnelle Entscheidung trifft.  Und es gibt ein zweites, langsames System, das nachtr√§glich funktioniert.  Sie hat mehr Daten √ºber den Benutzer, √ºber sein Verhalten usw.  Infolgedessen wird die ausgewogenste Entscheidung getroffen bzw. sie weist eine h√∂here Genauigkeit und Vollst√§ndigkeit auf.  Sie k√∂nnen den Unterschied in der Arbeit dieser Systeme in der ersten als Daten f√ºr das Training lenken.  Ein einfacheres System wird daher immer versuchen, einer komplexeren Leistung n√§her zu kommen. <br></li><li>  <b>Klassifizierung von Klicks</b> .  Sie k√∂nnen einfach jeden Klick des Benutzers klassifizieren, seine G√ºltigkeit und Verwendbarkeit bewerten.  Wir tun dies in Anti-Spam-Mails unter Verwendung der Attribute des Benutzers, seines Verlaufs, der Absenderattribute, des Texts selbst und des Ergebnisses der Klassifizierer.  Als Ergebnis erhalten wir ein automatisches System, das Benutzerfeedback validiert.  Und da es viel seltener ge√ºbt werden muss, kann seine Arbeit zur Hauptaufgabe f√ºr alle anderen Systeme werden.  Pr√§zision hat bei diesem Modell oberste Priorit√§t, da das Trainieren eines Modells mit ungenauen Daten mit Konsequenzen verbunden ist. <br></li></ul><br>  W√§hrend wir Daten bereinigen und unsere ML-Systeme neu trainieren, sollten wir die Benutzer nicht vergessen, denn f√ºr uns sind Tausende, Millionen von Fehlern in einem Diagramm Statistiken, und f√ºr einen Benutzer ist jeder Fehler eine Trag√∂die.  Zus√§tzlich zu der Tatsache, dass der Benutzer irgendwie mit Ihrem Fehler im Produkt leben muss, erwartet er nach R√ºckmeldung den Ausschluss einer √§hnlichen Situation in der Zukunft.  Aus diesem Grund sollten Sie Benutzern nicht nur die M√∂glichkeit geben, ihre Stimme abzugeben, sondern auch das Verhalten von ML-Systemen zu korrigieren, indem Sie beispielsweise pers√∂nliche Heuristiken f√ºr jeden Klick auf Feedback erstellen. Bei E-Mails ist es m√∂glicherweise m√∂glich, solche Nachrichten nach Absender und Header f√ºr diesen Benutzer zu filtern. <br><br>  Sie m√ºssen das Modell auch anhand einiger Berichte oder Supportanrufe im halbautomatischen oder manuellen Modus √ºberbr√ºcken, damit auch andere Benutzer nicht unter √§hnlichen Problemen leiden. <br><br><h3>  Heuristik zum Lernen </h3><br>  Es gibt zwei Probleme mit diesen Heuristiken und Kr√ºcken.  Erstens ist es schwierig, die st√§ndig wachsende Anzahl von Kr√ºcken zu warten, ganz zu schweigen von deren Qualit√§t und Langstreckenleistung.  Das zweite Problem ist, dass der Fehler m√∂glicherweise nicht h√§ufig auftritt und ein paar Klicks zum erneuten Trainieren des Modells nicht ausreichen.  Es scheint, dass diese beiden unabh√§ngigen Effekte wesentlich ausgeglichen werden k√∂nnen, wenn der folgende Ansatz angewendet wird. <br><br><ol><li>  Erstellen Sie eine tempor√§re Kr√ºcke. <br></li><li>  Wir leiten die Daten von ihm an das Modell weiter, es wird regelm√§√üig abgerufen, einschlie√ülich der empfangenen Daten.  Hierbei ist es nat√ºrlich wichtig, dass die Heuristik eine hohe Genauigkeit aufweist, um die Qualit√§t der Daten im Trainingssatz nicht zu beeintr√§chtigen. <br></li><li>  Dann legen wir die √úberwachung f√ºr den Betrieb der Kr√ºcke auf, und wenn die Kr√ºcke nach einiger Zeit nicht mehr funktioniert und vollst√§ndig vom Modell abgedeckt wird, k√∂nnen Sie sie sicher entfernen.  Nun ist es unwahrscheinlich, dass dieses Problem erneut auftritt. <br></li></ol><br>  Das Kr√ºckenheer ist also sehr n√ºtzlich.  Die Hauptsache ist, dass ihr Service dringend ist, nicht dauerhaft. <br><br><h2>  Weiterbildung </h2><br>  Umschulung ist der Prozess des Hinzuf√ºgens neuer Daten, die als Ergebnis von R√ºckmeldungen von Benutzern oder anderen Systemen erhalten wurden, und des Trainings des vorhandenen Modells auf diesen.  Es kann verschiedene Probleme bei der Umschulung geben: <br><br><ol><li>  Ein Modell unterst√ºtzt m√∂glicherweise einfach keine Weiterbildung und lernt nur von Grund auf neu. <br></li><li>  Nirgendwo im Buch der Natur steht geschrieben, dass Weiterbildung die Qualit√§t der Arbeit in der Produktion verbessern wird.  Oft geschieht genau das Gegenteil, dh es ist nur eine Verschlechterung m√∂glich. <br></li><li>  √Ñnderungen k√∂nnen unvorhersehbar sein.  Dies ist ein ziemlich subtiler Punkt, den wir f√ºr uns selbst identifiziert haben.  Auch wenn das neue Modell im A / B-Test im Vergleich zum aktuellen Modell √§hnliche Ergebnisse zeigt, bedeutet dies keineswegs, dass es identisch funktioniert.  Ihre Arbeit kann um ein Prozent abweichen, was neue Fehler mit sich bringen oder bereits korrigierte alte zur√ºckgeben kann.  Sowohl wir als auch die Benutzer wissen bereits, wie sie mit aktuellen Fehlern umgehen m√ºssen, und wenn eine gro√üe Anzahl neuer Fehler auftritt, versteht der Benutzer m√∂glicherweise auch nicht, was passiert, da er vorhersehbares Verhalten erwartet. <br></li></ol><br>  Das Wichtigste bei der Umschulung ist daher, das Modell zu verbessern oder zumindest nicht zu verschlechtern. <br><br>  Das erste, woran wir denken, wenn wir √ºber Weiterbildung sprechen, ist der Ansatz des aktiven Lernens.  Was bedeutet das?  Der Klassifikator bestimmt beispielsweise, ob sich das Schreiben auf Finanzen bezieht, und f√ºgt an der Entscheidungsgrenze eine Auswahl von markierten Beispielen hinzu.  Dies funktioniert gut, zum Beispiel in der Werbung, wo es viele R√ºckmeldungen gibt und Sie das Modell online trainieren k√∂nnen.  Und wenn es wenig R√ºckkopplung gibt, erhalten wir eine stark voreingenommene Stichprobe in Bezug auf die Erzeugung der Datenverteilung, anhand derer es unm√∂glich ist, das Verhalten des Modells im Betrieb zu bewerten. <br><br><img src="https://habrastorage.org/webt/wz/1c/0g/wz1c0gfwffg6kh2gnc76v_-70ai.jpeg"><br><br>  In der Tat ist es unser Ziel, alte Muster, bereits bekannte Modelle, zu erhalten und neue zu erwerben.  Hier ist Kontinuit√§t wichtig.  Das Modell, das wir oft mit gro√üen Schwierigkeiten herausgebracht haben, funktioniert bereits, sodass wir uns auf seine Leistung konzentrieren k√∂nnen. <br><br>  In der Post werden verschiedene Modelle verwendet: B√§ume, lineare, neuronale Netze.  F√ºr jeden erstellen wir einen eigenen Umschulungsalgorithmus.  W√§hrend des Umschulungsprozesses erhalten wir nicht nur neue Daten, sondern h√§ufig auch neue Funktionen, die wir in allen folgenden Algorithmen ber√ºcksichtigen werden. <br><br><h3>  Lineare Modelle </h3><br>  Nehmen wir an, wir haben eine logistische Regression.  Wir bilden das Verlustmodell aus folgenden Komponenten: <br><br><ul><li>  LogLoss auf neuen Daten; <br></li><li>  Wir regulieren die Gewichte neuer Zeichen (wir ber√ºhren die alten Zeichen nicht). <br></li><li>  Wir lernen aus alten Daten, um alte Muster zu bewahren. <br></li><li>  und vielleicht das wichtigste: Wir f√ºgen die Harmonische Regularisierung bei, die eine leichte √Ñnderung der Gewichte im Vergleich zum alten Modell gem√§√ü der Norm garantiert. <br></li></ul><br>  Da jede Verlustkomponente Koeffizienten aufweist, k√∂nnen wir die optimalen Werte f√ºr unsere Aufgabe f√ºr die Kreuzvalidierung oder basierend auf den Produktanforderungen ausw√§hlen. <br><br><img src="https://habrastorage.org/webt/kz/ej/-r/kzej-rg5tcarotc9l25xe7x9d8a.jpeg"><br><br><h3>  B√§ume </h3><br>  Gehen wir weiter zu Entscheidungsb√§umen.  Wir haben den folgenden Algorithmus f√ºr die Umschulung von B√§umen aufgenommen: <br><br><ol><li>  Ein Wald von 100-300 B√§umen arbeitet an dem Produkt, das auf dem alten Datensatz trainiert wurde. <br></li><li>  Am Ende l√∂schen wir M = 5 Teile und f√ºgen 2M = 10 neue hinzu, die auf den gesamten Datensatz trainiert wurden, jedoch mit hohem Gewicht aus den neuen Daten, was nat√ºrlich eine inkrementelle √Ñnderung des Modells garantiert. <br></li></ol><br>  Offensichtlich nimmt die Anzahl der B√§ume im Laufe der Zeit erheblich zu und sie m√ºssen regelm√§√üig reduziert werden, um sich an die Zeitvorgaben anzupassen.  Dazu verwenden wir die mittlerweile allgegenw√§rtige Knowledge Destillation (KD).  Kurz √ºber das Prinzip seiner Arbeit. <br><br><ol><li>  Wir haben das aktuelle "komplexe" Modell.  Wir starten es auf dem Trainingsdatensatz und erhalten die Wahrscheinlichkeitsverteilung der Klassen am Ausgang. <br></li><li>  Als N√§chstes bringen wir dem Sch√ºlermodell (in diesem Fall einem Modell mit weniger B√§umen) bei, die Ergebnisse des Modells unter Verwendung der Klassenverteilung als Zielvariable zu wiederholen. <br></li><li>  Hierbei ist zu beachten, dass wir in keiner Weise Datensatzmarkierungen verwenden und daher beliebige Daten verwenden k√∂nnen.  Nat√ºrlich verwenden wir eine Stichprobe von Daten aus dem Kampfstrom als √úbungsbeispiel f√ºr das Sch√ºlermodell.  Das Trainingsset erm√∂glicht es uns, die Genauigkeit des Modells sicherzustellen, und eine Probe des Flusses garantiert eine √§hnliche Leistung auf der Produktionsverteilung, wodurch der Versatz der Trainingsprobe ausgeglichen wird. <br></li></ol><br><img src="https://habrastorage.org/webt/a9/y-/qb/a9y-qbwv-wg1r8w7ohezamjzbi4.jpeg"><br><br>  Die Kombination dieser beiden Techniken (Hinzuf√ºgen von B√§umen und periodisches Reduzieren ihrer Anzahl mithilfe von Knowledge Distillation) stellt die Einf√ºhrung neuer Muster und die vollst√§ndige Kontinuit√§t sicher. <br><br>  Mit Hilfe von KD f√ºhren wir auch die Unterscheidung von Operationen mit Merkmalen eines Modells durch, zum Beispiel das Entfernen von Merkmalen und das Bearbeiten von Durchg√§ngen.  In unserem Fall verf√ºgen wir √ºber eine Reihe wichtiger statistischer Funktionen (Absender, Text-Hashes, URLs usw.), die in einer Datenbank gespeichert sind, deren Eigenschaft abgelehnt werden kann.  Das Modell ist nat√ºrlich nicht bereit f√ºr eine solche Entwicklung von Ereignissen, da es keine Fehlersituationen im Trainingssatz gibt.  In solchen F√§llen kombinieren wir KD- und Augmentationstechniken: Wenn wir f√ºr einen Teil der Daten trainieren, l√∂schen oder nullen wir die erforderlichen Zeichen, und wir nehmen die Bezeichnungen (Ausgaben des aktuellen Modells) als erste, und das Sch√ºlermodell lehrt uns, diese Verteilung zu wiederholen. <br><br><img src="https://habrastorage.org/webt/xz/dc/12/xzdc12577_krj0_-qknhnh8eqvo.jpeg"><br><br>  Wir haben festgestellt, dass der Prozentsatz des Probenflusses umso gr√∂√üer ist, je schwerwiegender die Manipulation der Modelle ist. <br><br>  Um Features zu entfernen, ist die einfachste Operation, nur ein kleiner Teil des Flusses erforderlich, da sich nur ein paar Features √§ndern und das aktuelle Modell am selben Satz studiert wird - der Unterschied ist minimal.  Um das Modell zu vereinfachen (die Anzahl der B√§ume um ein Vielfaches zu reduzieren), sind bereits 50 bis 50 erforderlich, und das Auslassen wichtiger statistischer Merkmale, die die Leistung des Modells erheblich beeintr√§chtigen, erfordert einen noch st√§rkeren Fluss, um die Arbeit des neuen Modells, das gegen Auslassungen resistent ist, f√ºr alle Arten von Buchstaben auszugleichen. <br><br><img src="https://habrastorage.org/webt/xw/b5/ib/xwb5ibcbds7xt3asahheyhpj9v4.jpeg"><br><br><h3>  Fasttext </h3><br>  Fahren wir mit FastText fort.  Lassen Sie mich daran erinnern, dass die Darstellung (Einbettung) eines Wortes aus der Summe der Einbettung des Wortes selbst und aller seiner Buchstaben N-Gramm, normalerweise Trigramme, besteht.  Da Trigramme eine Menge sein k√∂nnen, wird Bucket Hashing verwendet, dh die Umwandlung des gesamten Space in eine bestimmte feste Hashmap.  Als Ergebnis wird die Gewichtsmatrix durch die Dimension der inneren Schicht durch die Anzahl der W√∂rter + Bucket erhalten. <br><br>  W√§hrend der Weiterbildung erscheinen neue Zeichen: W√∂rter und Trigramme.  In der Standard-Nachschulung von Facebook passiert nichts Wesentliches.  Nur alte Gewichte mit Kreuzentropie auf neuen Daten werden neu trainiert.  ,    , ,      ,      .     FastText.     (  ),     -         ,      . <br><br><img src="https://habrastorage.org/webt/ib/0g/v3/ib0gv3rq9xvxitkbimz_6f4yaqs.jpeg"><br><br><h3> CNN </h3><br>     .   CNN   , , ,       .    ,     ,         .         Triplet Loss ( <a href="https://arxiv.org/abs/1503.03832"> </a> ). <br><br><h4> Triplet Loss </h4><br>         Triplet Loss.   ,         .         ,     ,     . <br><br><img src="https://habrastorage.org/webt/h9/uz/cy/h9uzcyjc9y86mc2inrlv0wq3kwm.jpeg"><br><br>    ,       ,       .     ,  .    ,       . <br><br>      -       .        (Finetuning):    ,     .            ,  ‚Äî   .  ,         v1  v2.    . <br><br><img src="https://habrastorage.org/webt/eb/iu/ro/ebiurox9uuibm_meuq8tap3zyzw.jpeg"><br><br><h3>   </h3><br>        ,    ,     .  ,    ,   CNN  Fast Text  .     ,       ( , ,  ).            .                    ,           . <br><br><img src="https://habrastorage.org/webt/ik/42/y4/ik42y4lvyzbhbsuywkmrxwg6bp4.jpeg"><br><br>        .     CNN  Fast Text    ,     ‚Äî          .          Knowledge Distillation. <br><br>           ,             .               ,            ,        . <br><br><h2>  Bereitstellen </h2><br>         ,        . <br><br><h3> /B- </h3><br>    ,     ,  ,   ,     - .          ,  ,      ,    A/B-.              .       5 %,  30 %,  50 %   100 % ,            .   -      ,    ,     ,     .       50 %   ,       ,      . <br><br>   A/B-    .   ,   A/B-   (      6  24      ),         .         ,       /B- (            ),    A/B-  . ,          ,        . <br><br>        ,   A/B-.         , Precision, Recall      ,       .       ,  ,      (Complexity) .    ,       -,      ,   ,      A/B-. <br><br><img src="https://habrastorage.org/webt/jf/nf/mu/jfnfmu8eoxpau1ux_n_ndww9ffi.jpeg"><br><br>             A/B-. <br><br><h3>  &amp;  </h3><br>   ,   ,    , , ,      .    ,   ‚Äî   ,     . <br><br>   ,          ‚Äî       .          ,          .      ,     ‚Äî -      ,     . <br><br>     ,                 .             (     ).  -       .  ,      ,         ¬´¬ª       .    ,     ,        .          . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db1/f2f/6a9/db1f2f6a95922c5c4caf13e5aab1be57.jpg"><br><br>            .     ,       ,      .   KL-           A/B-   ,          . <br><br>               ,       . ,  NER-       -,         ,    .     ! <br><br><h2>  Zusammenfassung </h2><br>       . <br><br><ul><li> <b></b> .    :       ,     .  ,   ‚Äî       ,        ML-.       ,     , ,  . <br></li><li> <b></b> .   ‚Äî  ,     -.    ,              . </li><li> <b></b> .         .      ,            . <br></li></ul><br>  , ,        ML-,          ,     . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de476714/">https://habr.com/ru/post/de476714/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de476704/index.html">So automatisieren Sie das Layout von E-Mails mit denselben Elementen: Wir verwenden intelligente Objekte</a></li>
<li><a href="../de476706/index.html">Cerebras Systems stellte einen Computer mit dem weltweit gr√∂√üten Prozessor 22 √ó 22 Zentimeter vor</a></li>
<li><a href="../de476708/index.html">Slurm Basic in Moskau. Tag drei Die Sammlung der Spionageabwehr und des Clusters, fliegende Pavel Selivanov und "Slurm Inspires!"</a></li>
<li><a href="../de476710/index.html">Registrierung offen: Deep Dive to IT at Mars</a></li>
<li><a href="../de476712/index.html">Service f√ºr zuf√§llige Treffen mit Fremden, aber nicht aus. Zuf√§lliger Kaffee-Startverlauf</a></li>
<li><a href="../de476718/index.html">Geschichte eines nationalen Radios: Mussolini von Rural Radio und Joseph Goebbels warme Lampen</a></li>
<li><a href="../de476720/index.html">Identifizieren potenzieller Mitarbeiter in der Phase des Lebenslaufs</a></li>
<li><a href="../de476722/index.html">Apache NiFi Flow Delivery Automatisierung</a></li>
<li><a href="../de476724/index.html">Installieren Sie Vmware ESXi auf Mac Pro 1.1</a></li>
<li><a href="../de476726/index.html">Absolvent der Innopolis University √ºber das Studium an der Universit√§t von Grenoble, AI, Englisch mit dem Franz√∂sisch und K√§se mit Wanzen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
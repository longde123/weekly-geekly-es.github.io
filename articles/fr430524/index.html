<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìê üìø üîú Architecture de r√©seau de neurones üçÑ üéê üëÇüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traduction d' architectures de r√©seaux neuronaux 

 Les algorithmes des r√©seaux de neurones profonds ont gagn√© en popularit√© aujourd'hui, ce qui est l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Architecture de r√©seau de neurones</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/430524/">  <i>Traduction d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architectures de r√©seaux neuronaux</a></i> <br><br>  Les algorithmes des r√©seaux de neurones profonds ont gagn√© en popularit√© aujourd'hui, ce qui est largement assur√© par une architecture bien pens√©e.  Regardons l'histoire de leur d√©veloppement au cours des derni√®res ann√©es.  Si vous √™tes int√©ress√© par une analyse plus approfondie, reportez-vous √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce travail</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/29b/f51/960/29bf5196085373528be31e27f2489bdd.jpg"><br>  <i>Comparaison des architectures populaires pour la pr√©cision d'une seule r√©colte Top-1 et le nombre d'op√©rations n√©cessaires pour un passage direct.</i>  <i>Plus de d√©tails <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .</i> <br><a name="habracut"></a><br><h3>  Lenet5 </h3><br>  En 1994, l'un des premiers r√©seaux de neurones convolutifs a √©t√© d√©velopp√©, qui a jet√© les bases de l'apprentissage en profondeur.  Cette ≈ìuvre pionni√®re de Yann LeCun, apr√®s de nombreuses it√©rations r√©ussies depuis 1988, s'appelait <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LeNet5</a> ! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b19/9c3/8f2/b199c38f21a72c44d7cd3afbca1c94eb.jpg"><br><br>  L'architecture LeNet5 est devenue fondamentale pour l'apprentissage en profondeur, en particulier en termes de distribution des propri√©t√©s de l'image √† travers l'image.  Des convolutions avec des param√®tres d'apprentissage ont permis d'utiliser plusieurs param√®tres pour extraire efficacement les m√™mes propri√©t√©s de diff√©rents endroits.  √Ä cette √©poque, aucune carte vid√©o ne pouvait acc√©l√©rer le processus d'apprentissage et m√™me les processeurs centraux √©taient lents.  Par cons√©quent, l'avantage cl√© de l'architecture √©tait la possibilit√© d'enregistrer les param√®tres et les r√©sultats des calculs, contrairement √† l'utilisation de chaque pixel comme donn√©es d'entr√©e distinctes pour un grand r√©seau neuronal multicouche.  Dans LeNet5, les pixels ne sont pas utilis√©s dans la premi√®re couche, car les images sont fortement corr√©l√©es spatialement, donc l'utilisation de pixels individuels comme propri√©t√©s d'entr√©e ne vous permettra pas de tirer parti de ces corr√©lations. <br><br>  Caract√©ristiques de LeNet5: <br><br><ul><li>  Un r√©seau de neurones convolutifs qui utilise une s√©quence de trois couches: couches de convolution, couches de mise en commun et couches de non-lin√©arit√© -&gt; depuis la publication des travaux de Lekun, c'est peut-√™tre l'une des principales caract√©ristiques de l'apprentissage profond par rapport aux images. </li><li>  Utilise la convolution pour r√©cup√©rer les propri√©t√©s spatiales. </li><li>  Sous-√©chantillonnage en utilisant la moyenne de la carte spatiale. </li><li>  Non lin√©arit√© sous forme de tangente hyperbolique ou sigmo√Øde. </li><li>  Le classificateur final sous la forme d'un r√©seau neuronal multicouche (MLP). </li><li>  La matrice clairsem√©e de connectivit√© entre les couches r√©duit la quantit√© de calcul. </li></ul><br>  Ce r√©seau neuronal a constitu√© la base de nombreuses architectures ult√©rieures et a inspir√© de nombreux chercheurs. <br><br><h3>  D√©veloppement </h3><br>  De 1998 √† 2010, les r√©seaux neuronaux √©taient en √©tat d'incubation.  La plupart des gens n'ont pas remarqu√© leurs capacit√©s croissantes, bien que de nombreux d√©veloppeurs aient progressivement perfectionn√© leurs algorithmes.  Gr√¢ce √† l'apog√©e des appareils photo pour t√©l√©phones portables et √† la baisse du prix des appareils photo num√©riques, de plus en plus de donn√©es d'entra√Ænement sont devenues disponibles pour nous.  Dans le m√™me temps, les capacit√©s informatiques ont augment√©, les processeurs sont devenus plus puissants et les cartes vid√©o sont devenues le principal outil informatique.  Tous ces processus ont permis le d√©veloppement de r√©seaux de neurones, quoique assez lentement.  L'int√©r√™t pour les t√¢ches qui pourraient √™tre r√©solues √† l'aide de r√©seaux de neurones grandissait, et finalement la situation est devenue √©vidente ... <br><br><h3>  Dan ciresan net </h3><br>  En 2010, Dan Claudiu Ciresan et Jurgen Schmidhuber ont publi√© l'une des premi√®res descriptions de la mise en ≈ìuvre de <a href="">r√©seaux neuronaux GPU</a> .  Leur travail contenait l'impl√©mentation directe et inverse d'un r√©seau neuronal √† 9 couches sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NVIDIA GTX 280</a> . <br><br><h3>  Alexnet </h3><br>  En 2012, Alexei Krizhevsky a publi√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AlexNet</a> , une version approfondie et √©tendue de LeNet, qui a remport√© une large marge au concours ImageNet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aad/4ad/3ca/aad4ad3ca7345f8d7e198c2b131298d1.png"><br><br>  Chez AlexNet, les r√©sultats des calculs LeNet sont mis √† l'√©chelle dans un r√©seau neuronal beaucoup plus grand, qui est capable d'√©tudier des objets beaucoup plus complexes et leurs hi√©rarchies.  Caract√©ristiques de cette solution: <br><br><ul><li>  Utilisation d'unit√©s de rectification lin√©aire (ReLU) comme non-lin√©arit√©s. </li><li>  L'utilisation de techniques de rejet pour ignorer s√©lectivement les neurones individuels pendant la formation, ce qui √©vite la sur-formation du mod√®le. </li><li>  Overlap max pooling, ce qui √©vite les effets de la moyenne du pooling moyen. </li><li>  Utilisation de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NVIDIA GTX 580</a> pour acc√©l√©rer l'apprentissage. </li></ul><br>  √Ä ce moment-l√†, le nombre de c≈ìurs dans les cartes vid√©o avait consid√©rablement augment√©, ce qui leur a permis de r√©duire le temps de formation d'environ 10 fois, et en cons√©quence, il est devenu possible d'utiliser des jeux de donn√©es et des images beaucoup plus grands. <br><br>  Le succ√®s d'AlexNet a lanc√© une petite r√©volution, les r√©seaux de neurones convolutifs se sont transform√©s en cheval de bataille de l'apprentissage en profondeur - ce terme signifie d√©sormais ¬´de grands r√©seaux de neurones qui peuvent r√©soudre des probl√®mes utiles¬ª. <br><br><h3>  Surpasser </h3><br>  En d√©cembre 2013, le laboratoire de NYU de Jan Lekun a publi√© une description d' <a href="">Overfeat</a> , une variante d'AlexNet.  En outre, l'article d√©crivait les cadres de d√©limitation form√©s, et par la suite de nombreux autres travaux sur ce sujet ont √©t√© publi√©s.  Nous pensons qu'il est pr√©f√©rable d'apprendre √† segmenter des objets plut√¥t que d'utiliser des bo√Ætes de d√©limitation artificielles. <br><br><h3>  Vgg </h3><br>  Les r√©seaux <a href="">VGG se</a> sont d√©velopp√©s √† Oxford dans chaque couche convolutionnelle utilis√©e pour la premi√®re fois des filtres 3x3, et ont m√™me combin√© ces couches dans une s√©quence de convolutions. <br><br>  Cela contredit les principes √©nonc√©s dans LeNet, selon lesquels de grandes convolutions ont √©t√© utilis√©es pour extraire les m√™mes propri√©t√©s d'image.  Au lieu des filtres 9x9 et 11x11 utilis√©s dans AlexNet, des filtres beaucoup plus petits ont commenc√© √† √™tre utilis√©s, dangereusement proches des convolutions 1x1, que les auteurs de LeNet ont essay√© d'√©viter, au moins dans les premi√®res couches du r√©seau.  Mais le grand avantage de VGG √©tait la d√©couverte que plusieurs convolutions 3x3 combin√©es dans une s√©quence peuvent √©muler des champs r√©cepteurs plus grands, par exemple 5x5 ou 7x7.  Ces id√©es seront ensuite utilis√©es dans les architectures Inception et ResNet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dec/e8b/308/dece8b308f74450222deece6fcf9d357.jpg"><br><br>  Les r√©seaux VGG utilisent plusieurs couches convolutionnelles 3x3 pour repr√©senter des propri√©t√©s complexes.  Faites attention aux blocs 3, 4 et 5 dans VGG-E: pour extraire des propri√©t√©s plus complexes et les combiner, 256 √ó 256 et 512 √ó 512 s√©quences de filtre 3 √ó 3 sont utilis√©es.  Cela √©quivaut √† un grand classificateur convolutionnel 512x512 avec trois couches!  Cela nous donne un grand nombre de param√®tres et d'excellentes capacit√©s d'apprentissage.  Mais il √©tait difficile d'apprendre de tels r√©seaux; j'ai d√ª les diviser en plus petits, en ajoutant des couches une par une.  La raison en √©tait le manque de moyens efficaces pour r√©gulariser les mod√®les ou certaines m√©thodes pour limiter un grand espace de recherche, ce qui est favoris√© par de nombreux param√®tres. <br><br>  VGG dans de nombreuses couches utilise un grand nombre de propri√©t√©s, donc la formation √©tait <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">co√ªteuse en calcul</a> .  La charge peut √™tre r√©duite en r√©duisant le nombre de propri√©t√©s, comme cela se fait dans les couches de goulot d'√©tranglement de l'architecture Inception. <br><br><h3>  R√©seau en r√©seau </h3><br>  L'architecture de <a href="">r√©seau en r√©seau</a> (NiN) est bas√©e sur une id√©e simple: utiliser des convolutions 1x1 pour augmenter la combinatoire des propri√©t√©s dans les couches convolutives. <br><br>  Dans NiN, apr√®s chaque convolution, des couches MLP spatiales sont utilis√©es pour mieux combiner les propri√©t√©s avant de passer √† la couche suivante.  Il peut sembler que l'utilisation de convolutions 1x1 contredit les principes originaux de LeNet, mais en r√©alit√© cela permet de combiner des propri√©t√©s mieux que de simplement bourrer plus de couches convolutives.  Cette approche est diff√©rente de l'utilisation de pixels nus comme entr√©e pour la couche suivante.  Dans ce cas, les convolutions 1x1 sont utilis√©es pour la combinaison spatiale des propri√©t√©s apr√®s convolution dans le cadre des cartes de propri√©t√©s, vous pouvez donc utiliser beaucoup moins de param√®tres communs √† tous les pixels de ces propri√©t√©s! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d9a/d08/e5c/d9ad08e5c699a2a9cf320c4b8b622ba3.jpg"><br><br>  MLP peut augmenter consid√©rablement l'efficacit√© des couches convolutives individuelles en les combinant en groupes plus complexes.  Cette id√©e a ensuite √©t√© utilis√©e dans d'autres architectures, telles que ResNet, Inception et leurs variantes. <br><br><h3>  GoogLeNet et cr√©ation </h3><br>  Google Christian Szegedy est pr√©occup√© par la r√©duction des calculs dans les r√©seaux de neurones profonds et a donc cr√©√© <a href="">GoogLeNet, la premi√®re architecture Inception</a> . <br><br>  √Ä l'automne 2014, les mod√®les d'apprentissage profond √©taient devenus tr√®s utiles pour cat√©goriser le contenu des images et les cadres des vid√©os.  De nombreux sceptiques ont reconnu les avantages de l'apprentissage en profondeur et des r√©seaux de neurones, et les g√©ants de l'Internet, dont Google, sont devenus tr√®s int√©ress√©s par le d√©ploiement de r√©seaux efficaces et de grande taille sur leurs capacit√©s de serveur. <br><br>  Christian cherchait des moyens de r√©duire la charge de calcul dans les r√©seaux de neurones, atteignant les performances les plus √©lev√©es (par exemple, dans ImageNet).  Ou en pr√©servant la quantit√© de calcul, tout en augmentant la productivit√©. <br><br>  En cons√©quence, la commande a cr√©√© un module Inception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/abf/d01/a92/abfd01a92262ff6e5b9f23380ba8d9cc.jpg"><br><br>  √Ä premi√®re vue, il s'agit d'une combinaison parall√®le de filtres convolutionnels 1x1, 3x3 et 5x5.  Mais le point culminant a √©t√© l'utilisation de blocs de convolution 1x1 (NiN) pour r√©duire le nombre de propri√©t√©s avant de servir dans les blocs parall√®les "chers".  Habituellement, cette partie est appel√©e goulot d'√©tranglement, elle est d√©crite plus en d√©tail dans le chapitre suivant. <br><br>  GoogLeNet utilise une tige sans modules Inception comme couche initiale, et utilise √©galement le regroupement moyen et un classificateur softmax similaire √† NiN.  Ce classificateur effectue extr√™mement peu d'op√©rations par rapport √† AlexNet et VGG.  Il a √©galement aid√© √† cr√©er une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture de r√©seau neuronal tr√®s efficace</a> . <br><br><h3>  Couche de goulot d'√©tranglement </h3><br>  Cette couche r√©duit le nombre de propri√©t√©s (et donc d'op√©rations) dans chaque couche, de sorte que la vitesse d'obtention du r√©sultat peut √™tre maintenue √† un niveau √©lev√©.  Avant de transf√©rer des donn√©es vers des modules convolutifs ¬´co√ªteux¬ª, le nombre de propri√©t√©s est r√©duit, disons, 4 fois.  Cela r√©duit consid√©rablement la quantit√© de calcul, ce qui a rendu l'architecture populaire. <br><br>  Voyons cela.  Supposons que nous ayons 256 propri√©t√©s en entr√©e et 256 en sortie, et que la couche Inception n'effectue que 3x3 convolutions.  On obtient 256x256x3x3 convolutions (589 000 op√©rations de multiplication d'accumulation, c'est-√†-dire des op√©rations MAC).  Cela peut aller au-del√† de nos exigences de vitesse de calcul; disons qu'une couche est trait√©e en 0,5 milliseconde sur Google Server.  R√©duisez ensuite le nombre de propri√©t√©s de pliage √† 64 (256/4).  Dans ce cas, nous effectuons d'abord une convolution 1x1 de 256 -&gt; 64, puis une autre 64 convolution dans toutes les branches Inception, puis appliquons √† nouveau une convolution 1x1 de 64 -&gt; 256 propri√©t√©s.  Nombre d'op√©rations: <br><br><ul><li>  256 √ó 64 √ó 1 √ó 1 = 16 000 </li><li>  64 √ó 64 √ó 3 √ó 3 = 36 000 </li><li>  64 √ó 256 √ó 1 √ó 1 = 16 000 </li></ul><br>  Seulement environ 70 000, ont r√©duit le nombre d'op√©rations de pr√®s de 10 fois!  Mais en m√™me temps, nous n'avons pas perdu la g√©n√©ralisation dans cette couche.  Les couches de goulot d'√©tranglement ont montr√© d'excellentes performances sur l'ensemble de donn√©es ImageNet et ont √©t√© utilis√©es dans des architectures ult√©rieures telles que ResNet.  La raison de leur succ√®s est que les propri√©t√©s d'entr√©e sont corr√©l√©es, ce qui signifie que vous pouvez vous d√©barrasser de la redondance en combinant correctement les propri√©t√©s avec des convolutions 1x1.  Et apr√®s avoir pli√© avec moins de propri√©t√©s, vous pouvez √† nouveau les d√©ployer dans une combinaison significative sur la couche suivante. <br><br><h3>  Inception V3 (et V2) </h3><br>  Christian et son √©quipe se sont r√©v√©l√©s √™tre des chercheurs tr√®s efficaces.  En f√©vrier 2015, l'architecture <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Inception normalis√©e par lots a</a> √©t√© introduite en tant que deuxi√®me version d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Inception</a> .  La normalisation par lots calcule la moyenne et l'√©cart-type de toutes les cartes de distribution des propri√©t√©s dans la couche de sortie et normalise leurs r√©ponses avec ces valeurs.  Cela correspond au "blanchiment" des donn√©es, c'est-√†-dire que les r√©ponses de toutes les cartes neuronales se situent dans la m√™me plage et avec une moyenne nulle.  Cette approche facilite l'apprentissage, car la couche suivante n'est pas tenue de m√©moriser les d√©calages des donn√©es d'entr√©e et ne peut rechercher que les meilleures combinaisons de propri√©t√©s. <br><br>  En d√©cembre 2015, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouvelle version des modules Inception et l'architecture correspondante a √©t√© lanc√©e</a> .  L'article de l'auteur explique mieux l'architecture originale de GoogLeNet, qui en dit beaucoup plus sur les d√©cisions prises.  Id√©es cl√©s: <br><br><ul><li>  Maximiser le flux d'informations dans le r√©seau gr√¢ce √† l'√©quilibre soign√© entre sa profondeur et sa largeur.  Avant chaque regroupement, les cartes de propri√©t√©s augmentent. </li><li>  Avec une profondeur croissante, le nombre de propri√©t√©s ou la largeur de couche augmente √©galement syst√©matiquement. </li><li>  La largeur de chaque couche augmente pour augmenter la combinaison de propri√©t√©s avant la couche suivante. </li><li>  Dans la mesure du possible, seules des convolutions 3x3 sont utilis√©es.  √âtant donn√© que les filtres 5x5 et 7x7 peuvent √™tre d√©compos√©s en utilisant plusieurs 3x3 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/849/96f/d8c/84996fd8cb1040fbf0a18187313a8a81.jpg"><br><br>  Le nouveau module Inception ressemble √† ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/975/b0b/ad7/975b0bad7d65a0b37aedf0dc119d03b8.jpg"></li><li>  Les filtres peuvent √©galement √™tre d√©compos√©s √† l'aide de <a href="">convolutions liss√©es</a> en modules plus complexes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb5/c32/21c/bb5c3221cc8f478de3ac5ef504a13357.jpg"></li><li>  Les modules de cr√©ation peuvent r√©duire la taille des donn√©es en utilisant le regroupement lors des calculs de cr√©ation.  Cela revient √† effectuer une convolution avec des enjamb√©es en parall√®le avec une simple couche de regroupement: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8b/4c1/263/f8b4c1263b3883d751c7dfe3788110ca.jpg"></li></ul><br>  Inception utilise la couche de regroupement avec softmax comme classificateur final. <br><br><h3>  Resnet </h3><br>  En d√©cembre 2015, √† peu pr√®s au moment o√π l'architecture Inception v3 a √©t√© introduite, une r√©volution s'est produite - ils ont publi√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ResNet</a> .  Il contient des id√©es simples: soumettre la sortie de deux couches convolutionnelles r√©ussies Et contourner l'entr√©e pour la couche suivante! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b8a/05d/8b8/b8a05d8b89f55e8d06bb2eae79bd648b.jpg"><br><br>  De telles id√©es ont d√©j√† √©t√© propos√©es, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Mais dans ce cas, les auteurs contournent DEUX couches et appliquent l'approche √† grande √©chelle.  Le contournement d'une couche ne donne pas beaucoup d'avantages, et le contournement de deux est une d√©couverte cl√©.  Cela peut √™tre vu comme un petit classifieur, comme r√©seau en r√©seau! <br><br>  Il s'agissait √©galement du premier exemple de formation d'un r√©seau de plusieurs centaines, voire milliers de couches. <br>  ResNet multicouche a utilis√© une couche de goulot d'√©tranglement similaire √† celle utilis√©e dans Inception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0d0/ecf/124/0d0ecf1248874511ae4dbca5f23afcec.jpg"><br><br>  Cette couche r√©duit le nombre de propri√©t√©s dans chaque couche, en utilisant d'abord une convolution 1x1 avec une sortie inf√©rieure (g√©n√©ralement un quart de l'entr√©e), puis une couche 3x3, puis convoluant √† nouveau 1x1 en un plus grand nombre de propri√©t√©s.  Comme dans le cas des modules Inception, cela permet d'√©conomiser des ressources de calcul tout en conservant une multitude de combinaisons de propri√©t√©s.  Comparez avec les tiges plus complexes et moins √©videntes dans Inception V3 et V4. <br><br>  ResNet utilise une couche de mise en commun avec softmax comme classificateur final. <br>  Chaque jour, des informations suppl√©mentaires sur l'architecture ResNet apparaissent: <br><br><ul><li>  Il peut √™tre consid√©r√© comme un syst√®me de modules simultan√©ment parall√®les et s√©rie: dans de nombreux modules, le signal d'entr√©e est parall√®le, et les signaux de sortie de chaque module sont connect√©s en s√©rie. </li><li>  ResNet peut √™tre consid√©r√© comme plusieurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensembles de modules parall√®les ou s√©rie</a> . </li><li>  Il s'est av√©r√© que ResNet fonctionne g√©n√©ralement avec des blocs de profondeur relativement petits de 20 √† 30 couches travaillant en parall√®le, plut√¥t que de fonctionner s√©quentiellement sur toute la longueur du r√©seau. </li><li>  Puisque le signal de sortie revient et est aliment√© en entr√©e, comme cela est fait dans RNN, ResNet peut √™tre consid√©r√© comme un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le plausible</a> am√©lior√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">du cortex c√©r√©bral</a> . </li></ul><br><h3>  Inception V4 </h3><br>  Christian et son √©quipe ont de nouveau excell√© avec une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouvelle version d'Inception</a> . <br><br>  La tige suivante du module de cr√©ation est la m√™me que dans la cr√©ation V3: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/955/f38/48b955f385c72d21a20af8517d941580.jpg"><br><br>  Dans ce cas, le module Inception est combin√© avec le module ResNet: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f4c/5f2/bd7/f4c5f2bd765082fe56dac5710fc30221.jpg"><br><br>  Cette architecture s'est av√©r√©e, √† mon go√ªt, plus compliqu√©e, moins √©l√©gante et √©galement remplie de solutions heuristiques opaques.  Il est difficile de comprendre pourquoi les auteurs ont pris telle ou telle d√©cision, et il est tout aussi difficile de leur donner une sorte d‚Äô√©valuation. <br><br>  Par cons√©quent, le prix pour un r√©seau neuronal propre et simple, facile √† comprendre et √† modifier, revient √† ResNet. <br><br><h3>  Squeezenet </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SqueezeNet a</a> publi√© r√©cemment.  Il s'agit d'un remake d'une nouvelle fa√ßon de nombreux concepts de ResNet et Inception.  Les auteurs ont d√©montr√© que l'am√©lioration de l'architecture r√©duit la taille du r√©seau et le nombre de param√®tres sans algorithmes de compression complexes. <br><br><h3>  ENet </h3><br>  Toutes les fonctionnalit√©s des architectures r√©centes sont combin√©es en un r√©seau tr√®s efficace et compact, utilisant tr√®s peu de param√®tres et de puissance de calcul, mais donnant en m√™me temps d'excellents r√©sultats.  L'architecture s'appelait <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ENet</a> , elle a √©t√© d√©velopp√©e par Adam Paszke ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Adam Paszke</a> ).  Par exemple, nous l'avons utilis√© pour le marquage tr√®s pr√©cis d'objets √† l'√©cran et l'analyse de sc√®nes.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Quelques exemples d'Enet</a> .  Ces vid√©os ne sont pas li√©es √† l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensemble de donn√©es de formation</a> . <br><br>  Vous trouverez ici les d√©tails techniques d'ENet.  Il s'agit d'un r√©seau bas√© sur un encodeur et un d√©codeur.  L'encodeur est construit sur le sch√©ma de cat√©gorisation CNN habituel, et le d√©codeur est un r√©seau de sur√©chantillonnage con√ßu pour la segmentation en redistribuant les cat√©gories √† l'image de taille d'origine.  Pour la segmentation de l'image, seuls les r√©seaux de neurones ont √©t√© utilis√©s, aucun autre algorithme. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/c54/7fa/18dc547fade22215961a848b2170b104.png"><br><br>  Comme vous pouvez le voir, ENet a la pr√©cision sp√©cifique la plus √©lev√©e par rapport √† tous les autres r√©seaux de neurones. <br><br>  ENet a √©t√© con√ßu pour utiliser le moins de ressources possible d√®s le d√©but.  En cons√©quence, l'encodeur et le d√©codeur n'occupent ensemble que 0,7 Mo avec une pr√©cision fp16.  Et avec une si petite taille, ENet n'est pas inf√©rieur √† la pr√©cision de segmentation ou sup√©rieur √† d'autres solutions de r√©seau purement neuronales. <br><br><h3>  Analyse de module </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Publication d'une</a> √©valuation syst√©matique des modules CNN.  Cela s'est av√©r√© b√©n√©fique: <br><br><ul><li>  Utilisez la non-lin√©arit√© ELU sans normalisation par lots (batchnorm) ou ReLU avec normalisation. </li><li>  Appliquez la transformation apprise de l'espace colorim√©trique RVB. </li><li>  Utilisez une politique de d√©croissance du taux d'apprentissage lin√©aire. </li><li>  Utilisez la somme de la couche de mise en commun moyenne et maximale. </li><li>  Utilisez un mini-paquet 128 ou 256. Si cela est trop pour votre carte vid√©o, r√©duisez la vitesse d'apprentissage proportionnellement √† la taille du paquet. </li><li>  Utilisez des couches enti√®rement connect√©es comme couches convolutives et pr√©visions moyennes pour donner la solution finale. </li><li>  Si vous augmentez la taille de l'ensemble de donn√©es d'entra√Ænement, assurez-vous que vous n'avez pas atteint un plateau d'entra√Ænement.  La propret√© des donn√©es est plus importante que la taille. </li><li>  Si vous ne pouvez pas augmenter la taille de l'image d'entr√©e, r√©duire la foul√©e dans les calques suivants, l'effet sera √† peu pr√®s le m√™me. </li><li>  Si votre r√©seau a une architecture complexe et hautement optimis√©e, comme dans GoogLeNet, modifiez-la avec prudence. </li></ul><br><h3>  Xception </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Xception a</a> introduit une architecture plus simple et plus √©l√©gante dans le module Inception, qui n'est pas moins efficace que ResNet et Inception V4. <br>  Voici √† quoi ressemble le module Xception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/632/40a/deb/63240adebe962726f6d035b5a5d16099.jpg"><br><br>  Tout le monde aimera ce r√©seau en raison de la simplicit√© et de l'√©l√©gance de son architecture: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d64/f09/933/d64f099330f0b9290a99202a50863868.jpg"><br><br>  Il contient 36 √©tapes de convolution, ce qui est similaire √† ResNet-34.  En m√™me temps, le mod√®le et le code sont simples, comme dans ResNet, et beaucoup plus agr√©ables que dans Inception V4. <br><br>  Une impl√©mentation torch7 de ce r√©seau est disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , tandis qu'une impl√©mentation Keras / TF est disponible ici. <br><br>  Curieusement, les auteurs de la r√©cente architecture Xception se sont √©galement inspir√©s de <a href="">nos travaux sur les filtres convolutionnels s√©parables</a> . <br><br><h3>  MobileNets </h3><br>  La nouvelle architecture de M <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">obileNets a</a> √©t√© lanc√©e en avril 2017.  Pour r√©duire le nombre de param√®tres, il utilise des convolutions d√©tachables, les m√™mes que dans Xception.  Il est √©galement indiqu√© dans l'ouvrage que les auteurs ont pu r√©duire consid√©rablement le nombre de param√®tres: environ la moiti√© dans le cas de FaceNet.   : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/689/04b/c1e/68904bc1e353888d4fcd54975a064362.jpg"><br><br>         ,         1 (batch of 1)   Titan Xp.      : <br><br><ul><li> resnet18: 0,002871 </li><li> alexnet: 0,001003 </li><li> vgg16: 0,001698 </li><li> squeezenet: 0,002725 </li><li> mobilenet: 0,033251 </li></ul><br>     !        ,     . <br><br><h3>    </h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FractalNet</a>   ,      ImageNet        ResNet. <br><br><h3>  </h3><br>  ,           .         ,  . <br><br>   ,         ,       ,   ,       ?  ,       . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>    . <br>  ,        .      ,         . <br><br>         , . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  </a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr430524/">https://habr.com/ru/post/fr430524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr430512/index.html">Comment vivent les pigistes: ne travaillez pas avec des clients omniscients et laissez-vous tergiverser</a></li>
<li><a href="../fr430514/index.html">Blockchain Charity - DataArt remporte le hackathon du sommet de la blockchain de Malte</a></li>
<li><a href="../fr430518/index.html">Comment rendre le cadre de la Terre du Milieu: L'Ombre du Mordor</a></li>
<li><a href="../fr430520/index.html">Pr√©sentation de Spring Data MongoDB</a></li>
<li><a href="../fr430522/index.html">Avez-vous besoin d'une culture d'entreprise en informatique? Confession du chef de marque du studio Krasnodar Plarium</a></li>
<li><a href="../fr430526/index.html">Machines √† sous: d'o√π viennent-elles en URSS et comment sont-elles arrang√©es</a></li>
<li><a href="../fr430528/index.html">Programmation avec PyUSB 1.0</a></li>
<li><a href="../fr430530/index.html">Serveur simul√© pour l'automatisation des tests mobiles</a></li>
<li><a href="../fr430532/index.html">S√©curit√© dans les applications iOS</a></li>
<li><a href="../fr430534/index.html">Cr√©ation d'un mod√®le pour Zabbix en utilisant le DVR Trassir SDK comme exemple</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
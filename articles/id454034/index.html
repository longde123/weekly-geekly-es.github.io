<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ· ğŸ‘±ğŸ¿ ğŸ˜¶ Model Pertama: Fashion MNIST Dataset ğŸ’ªğŸ½ ğŸ‘© ğŸ‘ŒğŸ¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kursus lengkap dalam bahasa Rusia dapat ditemukan di tautan ini . 
 Kursus bahasa Inggris asli tersedia di tautan ini . 

 Kuliah baru dijadwalkan set...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Model Pertama: Fashion MNIST Dataset</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/">  Kursus lengkap dalam bahasa Rusia dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . <br>  Kursus bahasa Inggris asli tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>Kuliah baru dijadwalkan setiap 2-3 hari.</i> <br><a name="habracut"></a><br><h2>  Wawancara dengan Sebastian Trun, CEO Udacity </h2><br>  "Jadi, kami masih bersamamu dan bersama kami, seperti sebelumnya, Sebastian."  Kami hanya ingin membahas lapisan yang sepenuhnya terhubung, lapisan padat yang sama.  Sebelum itu, saya ingin mengajukan satu pertanyaan.  Apa saja batasan dan hambatan utama yang akan menghalangi pembelajaran mendalam dan akan memiliki dampak terbesar dalam 10 tahun ke depan?  Semuanya berubah begitu cepat!  Menurut Anda apa yang akan menjadi "hal besar" berikutnya? <br>  - Saya akan mengatakan dua hal.  Yang pertama adalah AI umum untuk lebih dari satu tugas.  Ini bagus!  Orang dapat memecahkan lebih dari satu masalah dan jangan pernah melakukan hal yang sama.  Yang kedua adalah membawa teknologi ke pasar.  Bagi saya, kekhasan pembelajaran mesin adalah bahwa hal itu memberi komputer kemampuan untuk mengamati dan menemukan pola dalam data, membantu orang menjadi lebih baik di bidang - di tingkat ahli!  Pembelajaran mesin dapat digunakan dalam bidang hukum, kedokteran, mobil otonom.  Kembangkan aplikasi semacam itu karena dapat menghasilkan banyak uang, tetapi yang terpenting, Anda memiliki kesempatan untuk menjadikan dunia tempat yang lebih baik. <br>  â€œSaya sangat suka cara Anda mengatakan semuanya menjadi satu gambar pembelajaran mendalam dan penerapannya - ini hanyalah alat yang dapat membantu Anda memecahkan masalah tertentu. <br>  - Ya persis!  Alat yang luar biasa, bukan? <br>  - Ya, ya, saya sepenuhnya setuju dengan Anda! <br>  "Hampir seperti otak manusia!" <br>  - Anda menyebutkan aplikasi medis dalam wawancara pertama kami, di bagian pertama dari kursus video.  Di aplikasi mana, menurut pendapat Anda, penggunaan pembelajaran mendalam menyebabkan kegembiraan dan kejutan terbesar? <br>  - Banyak!  Sangat!  Kedokteran ada dalam daftar singkat bidang-bidang yang secara aktif menggunakan pembelajaran mendalam.  Saya kehilangan saudara perempuan saya beberapa bulan yang lalu, dia menderita kanker, yang sangat menyedihkan.  Saya pikir ada banyak penyakit yang dapat dideteksi sebelumnya - pada tahap awal, memungkinkan untuk menyembuhkannya atau memperlambat proses perkembangannya.  Idenya, pada kenyataannya, adalah untuk mentransfer beberapa alat ke rumah (rumah pintar), sehingga dimungkinkan untuk mendeteksi penyimpangan seperti itu dalam kesehatan jauh sebelum saat ketika orang itu sendiri melihatnya.  Saya juga akan menambahkan - semuanya diulangi, pekerjaan kantor apa pun, di mana Anda melakukan jenis tindakan yang sama berulang kali, misalnya, pembukuan.  Bahkan saya, sebagai CEO, melakukan banyak tindakan berulang.  Akan sangat bagus untuk mengotomatisasi mereka, bahkan bekerja dengan korespondensi surat! <br>  - Saya tidak bisa tidak setuju dengan Anda!  Dalam pelajaran ini, kami akan memperkenalkan siswa ke kursus dengan lapisan jaringan saraf yang disebut lapisan padat.  Bisakah Anda memberi tahu kami secara lebih terperinci apa pendapat Anda tentang lapisan yang terhubung sepenuhnya? <br>  - Jadi, mari kita mulai dengan fakta bahwa setiap jaringan dapat dihubungkan dengan cara yang berbeda.  Beberapa dari mereka mungkin memiliki konektivitas yang sangat ketat, yang memungkinkan Anda untuk mendapatkan manfaat dalam penskalaan dan "menang" melawan jaringan besar.  Terkadang Anda tidak tahu berapa banyak koneksi yang Anda butuhkan, jadi Anda menghubungkan semuanya dengan semuanya - ini disebut lapisan yang terhubung penuh.  Saya menambahkan bahwa pendekatan ini memiliki lebih banyak kekuatan dan potensi daripada sesuatu yang lebih terstruktur. <br>  - Saya sepenuhnya setuju dengan Anda!  Terima kasih telah membantu kami mempelajari lebih banyak tentang lapisan yang terhubung sepenuhnya.  Saya menantikan saat ketika kita akhirnya mulai mengimplementasikannya dan menulis kode. <br>  - Selamat bersenang-senang!  Ini akan sangat menyenangkan! <br><br><h2>  Pendahuluan </h2><br>  - Selamat datang kembali!  Dalam pelajaran terakhir, Anda menemukan cara membangun jaringan saraf pertama Anda menggunakan TensorFlow dan Keras, cara kerja jaringan saraf, dan bagaimana proses pelatihan (pelatihan) bekerja.  Secara khusus, kami melihat bagaimana melatih model untuk mengubah derajat Celsius ke derajat Fahrenheit. <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  - Kami juga berkenalan dengan konsep lapisan yang terhubung penuh (lapisan padat), lapisan paling penting dalam jaringan saraf.  Tetapi dalam pelajaran ini kita akan melakukan banyak hal yang lebih keren!  Dalam pelajaran ini, kita akan mengembangkan jaringan saraf yang dapat mengenali elemen pakaian dan gambar.  Seperti yang kami sebutkan sebelumnya, pembelajaran mesin menggunakan input yang disebut "fitur," dan output yang disebut "label," dimana model belajar dan menemukan algoritma transformasi.  Karena itu, pertama, kita perlu banyak contoh untuk melatih jaringan saraf untuk mengenali berbagai elemen pakaian.  Biarkan saya mengingatkan Anda bahwa contoh untuk pelatihan adalah sepasang nilai - fitur input dan label output, yang diumpankan ke input jaringan saraf.  Dalam contoh baru kami, input akan berupa gambar, dan label keluaran harus menjadi kategori pakaian yang menjadi milik item pakaian yang ditunjukkan dalam gambar.  Untungnya, set data seperti itu sudah ada.  Ini disebut Fashion MNIST.  Kami akan melihat lebih dekat kumpulan data ini di bagian selanjutnya. <br><br><h2>  Mode MNIST Dataset </h2><br>  Selamat datang di dunia dataset MNIST!  Jadi, set kami terdiri dari 28x28 gambar, masing-masing piksel mewakili warna abu-abu. <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br>  Kumpulan data berisi gambar kaus, atasan, sandal, dan bahkan sepatu bot.  Berikut adalah daftar lengkap dari apa yang mengandung dataset MNIST kami: <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br>  Setiap gambar input sesuai dengan salah satu label di atas.  Dataset Mode MNIST berisi 70.000 gambar, jadi kami memiliki tempat untuk memulai dan bekerja.  Dari 70.000 ini, kita akan menggunakan 60.000 untuk melatih jaringan saraf. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Dan kita akan menggunakan 10.000 elemen yang tersisa untuk menguji seberapa baik jaringan saraf kita telah belajar mengenali elemen pakaian.  Nanti kami akan menjelaskan mengapa kami membagi set data menjadi set pelatihan dan satu set tes. <br><br>  Jadi di sini adalah dataset Fashion MNIST kami. <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br>  Ingat, setiap gambar dalam dataset adalah gambar berukuran 28x28 dalam nuansa abu-abu, yang berarti bahwa setiap gambar berukuran 784 byte.  Tugas kita adalah membuat jaringan saraf, yang menerima 784 byte ini pada input, dan pada output kembali ke kategori pakaian dari 10 yang tersedia, elemen yang diserahkan pada input tersebut adalah milik. <br><br><h2>  Jaringan saraf </h2><br>  Dalam pelajaran ini, kita akan menggunakan jaringan saraf yang dalam yang belajar untuk mengklasifikasikan gambar dari dataset Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br>  Gambar di atas menunjukkan seperti apa jaringan saraf kita nantinya.  Mari kita lihat lebih detail. <br><br>  Nilai input dari jaringan saraf kami adalah array satu dimensi dengan panjang 784, array dengan panjang yang persis sama dengan alasan bahwa setiap gambar adalah 28x28 piksel (= total 784 piksel dalam gambar), yang akan dikonversi menjadi array satu dimensi.  Proses mengubah gambar 2D menjadi vektor disebut perataan dan diimplementasikan melalui lapisan perataan - lapisan rata. <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br>  Anda dapat melakukan smoothing dengan membuat layer yang sesuai: <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Lapisan ini mengubah gambar 2D 28x28 piksel (1 byte untuk skala abu-abu per piksel) menjadi array 1D 784 piksel. <br><br>  Nilai input akan sepenuhnya terkait dengan lapisan jaringan <code>dense</code> pertama kami, yang ukurannya kami pilih sama dengan 128 neuron. <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br>  Beginilah ciptaan layer ini di dalam kode tersebut: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br>  Hentikan itu!  Apa itu <code>tf.nn.relu</code> ?  Kami tidak menggunakan ini dalam contoh jaringan saraf kami sebelumnya ketika mengkonversi derajat Celcius ke derajat Fahrenheit!  Intinya adalah bahwa tugas saat ini jauh lebih rumit daripada yang digunakan sebagai contoh pencarian fakta - mengubah derajat Celsius ke derajat Fahrenheit. <br><br>  <code>ReLU</code> adalah fungsi matematika yang kami tambahkan ke lapisan kami yang sepenuhnya terhubung dan yang memberi lebih banyak kekuatan ke jaringan kami.  Sebenarnya, ini adalah ekstensi kecil untuk lapisan kami yang sepenuhnya terhubung, yang memungkinkan jaringan saraf kami untuk memecahkan masalah yang lebih kompleks.  Kami tidak akan memerinci, tetapi sedikit informasi yang lebih terperinci dapat ditemukan di bawah. <br><br>  Akhirnya, lapisan terakhir kami, juga dikenal sebagai lapisan keluaran, terdiri dari 10 neuron.  Ini terdiri dari 10 neuron karena dataset Fashion MNIST kami berisi 10 kategori pakaian.  Masing-masing dari 10 nilai output ini akan mewakili kemungkinan bahwa gambar input berada dalam kategori pakaian ini.  Dengan kata lain, nilai-nilai ini mencerminkan "kepercayaan diri" model dalam kebenaran prediksi dan korelasi gambar yang diajukan dengan spesifik dari 10 kategori pakaian di output.  Misalnya, apa kemungkinan gambar itu menunjukkan gaun, sepatu kets, sepatu, dll. <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br>  Misalnya, jika gambar baju diumpankan ke input jaringan saraf kami, maka model dapat memberi kami hasil seperti yang Anda lihat pada gambar di atas - probabilitas gambar input cocok dengan label output. <br><br>  Jika Anda memperhatikan, Anda akan melihat bahwa probabilitas terbesar - 0,85 mengacu pada tag 6, yang sesuai dengan kemeja.  Model 85% yakin bahwa gambar di baju.  Biasanya, hal-hal yang terlihat seperti kemeja juga akan memiliki peringkat probabilitas tinggi, dan hal-hal yang paling mirip akan memiliki peringkat probabilitas yang lebih rendah. <br><br>  Karena semua 10 nilai output sesuai dengan probabilitas, ketika menjumlahkan semua nilai ini, kami mendapatkan 1. 10 nilai ini juga disebut distribusi probabilitas. <br><br>  Sekarang kita membutuhkan lapisan output untuk menghitung probabilitas untuk setiap label. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Dan kami akan melakukan ini dengan perintah berikut: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br>  Bahkan, setiap kali kita membuat jaringan saraf yang memecahkan masalah klasifikasi, kita selalu menggunakan lapisan yang terhubung penuh sebagai lapisan terakhir dari jaringan saraf.  Lapisan terakhir dari jaringan saraf harus berisi jumlah neuron yang sama dengan jumlah kelas, di mana kita menentukan <code>softmax</code> dan menggunakan fungsi aktivasi softmax. <br><br><h3>  <code>ReLU</code> - fungsi aktivasi neuron </h3><br>  Dalam pelajaran ini, kita berbicara tentang <code>ReLU</code> sebagai sesuatu yang memperluas kemampuan jaringan saraf kita dan memberinya kekuatan tambahan. <br><br>  <code>ReLU</code> adalah fungsi matematika yang terlihat seperti ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="gambar"><br><br>  Fungsi <code>ReLU</code> mengembalikan 0 jika nilai input adalah nilai negatif atau nol, dalam semua kasus lain fungsi akan mengembalikan nilai input asli. <br><br>  <code>ReLU</code> memungkinkan untuk menyelesaikan masalah non-linear. <br><br>  Mengubah derajat Celsius ke derajat Fahrenheit adalah tugas linier, karena ekspresi <code>f = 1.8*c + 32</code> adalah persamaan garis - <code>y = m*x + b</code> .  Tetapi sebagian besar tugas yang ingin kita selesaikan adalah non-linear.  Dalam kasus seperti itu, menambahkan fungsi aktivasi ReLU ke lapisan kami yang terhubung sepenuhnya dapat membantu dengan tugas semacam ini. <br><br>  <code>ReLU</code> hanyalah satu jenis fungsi aktivasi.  Ada beberapa fungsi aktivasi seperti sigmoid, ReLU, ELU, tanh, namun <code>ReLU</code> yang paling sering digunakan sebagai fungsi aktivasi default.  Untuk membuat dan menggunakan model yang menyertakan ReLU, Anda tidak perlu memahami cara kerjanya secara internal.  Jika Anda masih ingin mengerti lebih baik, maka kami merekomendasikan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ini</a> . <br><br>  Mari kita bahas istilah-istilah baru yang diperkenalkan dalam pelajaran ini: <br><br><ul><li>  <b>Smoothing</b> - proses mengubah gambar 2D menjadi vektor 1D; </li><li>  <b>ReLU</b> adalah fungsi aktivasi yang memungkinkan model untuk menyelesaikan masalah non-linear; </li><li>  <b>Softmax</b> - fungsi yang menghitung probabilitas untuk setiap kelas output yang mungkin; </li><li>  <b>Klasifikasi</b> - kelas tugas pembelajaran mesin yang digunakan untuk menentukan perbedaan antara dua atau lebih kategori (kelas). </li></ul><br><h2>  Pelatihan dan pengujian </h2><br>  Saat melatih suatu model, model apa pun dalam pembelajaran mesin, selalu perlu untuk membagi set data menjadi setidaknya dua set yang berbeda - set data yang digunakan untuk pelatihan dan set data yang digunakan untuk pengujian.  Pada bagian ini kita akan mengerti mengapa perlu melakukan ini. <br><br>  Mari kita ingat bagaimana kita mendistribusikan set data kami dari Fashion MNIST yang terdiri dari 70.000 salinan. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Kami mengusulkan membagi 70.000 menjadi dua bagian - di bagian pertama, meninggalkan 60.000 untuk pelatihan, dan di bagian kedua 10.000 untuk pengujian.  Perlunya pendekatan ini disebabkan oleh fakta berikut: setelah model dilatih pada 60.000 salinan, perlu untuk memeriksa hasil dan efektivitas kerjanya pada contoh-contoh yang belum dalam set data di mana model dilatih. <br><br>  Dengan caranya sendiri, itu menyerupai lulus ujian di sekolah.  Sebelum Anda lulus ujian, Anda rajin menyelesaikan masalah kelas tertentu.  Kemudian, dalam ujian, Anda menemukan kelas masalah yang sama, tetapi dengan data input yang berbeda.  Tidak masuk akal untuk mengirimkan data yang sama dengan yang ada selama pelatihan, jika tidak tugas akan dikurangi menjadi mengingat keputusan, dan tidak mencari model solusi.  Itulah sebabnya pada ujian Anda dihadapkan dengan tugas-tugas yang sebelumnya tidak ada dalam kurikulum.  Hanya dengan cara ini kami dapat memverifikasi apakah model telah mempelajari solusi umum atau tidak. <br><br>  Hal yang sama terjadi dengan pembelajaran mesin.  Anda memperlihatkan beberapa data yang mewakili kelas tugas tertentu yang ingin Anda pelajari bagaimana menyelesaikannya.  Dalam kasus kami, dengan kumpulan data dari Fashion MNIST, kami ingin jaringan saraf dapat menentukan kategori di mana elemen pakaian dalam gambar berada.  Itulah sebabnya kami melatih model kami pada 60.000 contoh yang berisi semua kategori item pakaian.  Setelah pelatihan, kami ingin memeriksa keefektifan model, jadi kami memberi makan 10.000 item pakaian lainnya yang modelnya belum â€œlihatâ€.  Jika kami memutuskan untuk tidak melakukan ini, tidak menguji dengan 10.000 contoh, kami tidak akan dapat mengatakan dengan pasti apakah model kami benar-benar dilatih untuk menentukan kelas item pakaian atau jika dia mengingat semua pasangan nilai input + output. <br><br>  Itu sebabnya dalam pembelajaran mesin kami selalu memiliki dataset untuk pelatihan dan dataset untuk pengujian. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TensorFlow</a> adalah kumpulan data pelatihan yang siap digunakan. <br><br>  Kumpulan data biasanya dibagi menjadi beberapa blok, yang masing-masing digunakan pada tahap pelatihan tertentu dan menguji efektivitas jaringan saraf.  Pada bagian ini kita berbicara tentang: <br><br><ul><li>  <b>set data pelatihan</b> : <b>set</b> data yang dimaksudkan untuk melatih jaringan saraf; </li><li>  <b>set data uji</b> : <b>set</b> data yang dirancang untuk memverifikasi efisiensi jaringan saraf; </li></ul><br>  Pertimbangkan dataset lain, yang saya sebut dataset validasi.  Kumpulan data ini tidak digunakan <b>untuk</b> melatih model, hanya <b>selama</b> pelatihan.  Jadi, setelah model kami melewati beberapa siklus pelatihan, kami mengumpankannya set data pengujian kami dan melihat hasilnya.  Sebagai contoh, jika selama pelatihan nilai fungsi kerugian menurun, dan akurasi menurun pada set data uji, maka ini berarti bahwa model kami cukup mengingat pasangan nilai input-output. <br><br>  Set data verifikasi digunakan kembali pada akhir pelatihan untuk mengukur akurasi akhir prediksi model. <br><br>  Untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">informasi</a> lebih <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lanjut tentang set data pelatihan dan tes, lihat Google Crash Course</a> . <br><br><h2>  Bagian praktis dalam CoLab </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tautan ke CoLab asli dalam bahasa Inggris</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke CoLab Rusia</a> . <br><br><h2>  Klasifikasi gambar barang-barang pakaian </h2><br>  Dalam bagian pelajaran ini, kami akan membangun dan melatih jaringan saraf untuk mengklasifikasikan gambar elemen pakaian, seperti gaun, sepatu kets, kemeja, t-shirt, dll. <br><br>  Tidak apa-apa jika beberapa saat tidak jelas.  Tujuan dari kursus ini adalah untuk memperkenalkan Anda kepada TensorFlow dan pada saat yang sama menjelaskan algoritme kerjanya dan mengembangkan pemahaman umum tentang proyek yang menggunakan TensorFlow, alih-alih menggali detail implementasi. <br><br>  Di bagian ini, kami menggunakan <code>tf.keras</code> , API tingkat tinggi untuk membangun dan melatih model di TensorFlow. <br><br><h3>  Menginstal dan mengimpor dependensi </h3><br>  Kita akan membutuhkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dataset TensorFlow</a> , sebuah API yang menyederhanakan pemuatan dan mengakses dataset yang disediakan oleh beberapa layanan.  Kita juga membutuhkan beberapa perpustakaan bantu. <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3>  Impor dataset Mode MNIST </h3><br>  Contoh ini menggunakan dataset Fashion MNIST, yang berisi 70.000 gambar item pakaian dalam 10 kategori dalam skala abu-abu.  Gambar berisi item pakaian dalam resolusi rendah (28x28 piksel), seperti yang ditunjukkan di bawah ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="gambar"><br><br>  Fashion MNIST digunakan sebagai pengganti dataset MNIST klasik - paling sering digunakan sebagai "Halo, Dunia!"  dalam pembelajaran mesin dan visi komputer.  Dataset MNIST berisi gambar angka tulisan tangan (0, 1, 2, dll.) Dalam format yang sama dengan item pakaian dalam contoh kita. <br><br>  Dalam contoh kami, kami menggunakan Fashion MNIST karena variasi dan karena tugas ini lebih menarik dari sudut pandang implementasi daripada memecahkan masalah khas pada set data MNIST.  Kedua set data cukup kecil, oleh karena itu, mereka digunakan untuk memeriksa operabilitas algoritma yang benar.  Kumpulan data hebat untuk memulai mesin pembelajaran, pengujian, dan kode debugging. <br><br>  Kami akan menggunakan 60.000 gambar untuk melatih jaringan dan 10.000 gambar untuk menguji akurasi pelatihan dan klasifikasi gambar.  Anda dapat langsung mengakses dataset Fashion MNIST melalui TensorFlow menggunakan API: <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br>  Dengan memuat set data, kami mendapatkan metadata, set data pelatihan, dan set data uji. <br><br><ul><li>  Model dilatih pada dataset dari `train_dataset` </li><li>  Model ini diuji pada dataset dari `test_dataset` </li></ul><br>  Gambar adalah array <code>2828</code> dua dimensi, di mana nilai-nilai di setiap sel dapat dalam interval <code>[0, 255]</code> .  Label - array bilangan bulat, di mana setiap nilai berada dalam interval <code>[0, 9]</code> .  Label-label ini sesuai dengan kelas gambar output sebagai berikut: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Label </th><th>  Kelas </th></tr><tr><td>  0 </td><td>  Kaos / atas </td></tr><tr><td>  1 </td><td>  Celana pendek </td></tr><tr><td>  2 </td><td>  Sweater </td></tr><tr><td>  3 </td><td>  Pakaian </td></tr><tr><td>  4 </td><td>  Jubah </td></tr><tr><td>  5 </td><td>  Sandal </td></tr><tr><td>  6 </td><td>  Baju </td></tr><tr><td>  7 </td><td>  Sneaker </td></tr><tr><td>  8 </td><td>  Tas </td></tr><tr><td>  9 </td><td>  Boot </td></tr></tbody></table></div><br><br>  Setiap gambar milik satu tag.  Karena nama-nama kelas tidak terkandung dalam kumpulan data asli, mari kita simpan untuk digunakan di masa mendatang ketika kita menggambar gambar: <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4>  Kami meneliti data </h4><br>  Mari kita pelajari format dan struktur data yang disajikan dalam set pelatihan sebelum melatih model.  Kode berikut akan menunjukkan bahwa 60.000 gambar ada dalam dataset pelatihan, dan 10.000 gambar ada dalam dataset uji: <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3>  Pra-pemrosesan data </h3><br>  Nilai setiap piksel dalam gambar adalah dalam kisaran <code>[0,255]</code> .  Agar model bekerja dengan benar, nilai-nilai ini harus dinormalisasi - dikurangi menjadi nilai dalam interval <code>[0,1]</code> .  Oleh karena itu, sedikit lebih rendah, kami mendeklarasikan dan mengimplementasikan fungsi normalisasi, dan kemudian menerapkannya pada setiap gambar dalam set data pelatihan dan pengujian. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4>  Kami mempelajari data yang diproses </h4><br>  Mari kita gambar untuk melihatnya: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br>  Kami menampilkan 25 gambar pertama dari kumpulan data pelatihan dan di bawah setiap gambar kami menunjukkan kelasnya. <br><br>  Pastikan bahwa data dalam format yang benar dan kami siap untuk mulai membuat dan melatih jaringan. <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4>  Membangun model </h4><br>  Membangun jaringan saraf memerlukan lapisan tuning, dan kemudian merakit model dengan fungsi optimasi dan kehilangan. <br><br><h4>  Kustomisasi layer </h4><br>  Elemen dasar dalam membangun jaringan saraf adalah lapisan.  Lapisan mengekstraksi tampilan dari data yang masuk ke inputnya.  Hasil dari pekerjaan beberapa lapisan terhubung, kami mendapatkan pandangan yang masuk akal untuk menyelesaikan masalah. <br><br>  Sebagian besar waktu melakukan pembelajaran mendalam, Anda akan membuat tautan antara lapisan sederhana.  Sebagian besar layer, misalnya, seperti tf.keras.layers.Dense, memiliki serangkaian parameter yang dapat "dipasang" selama proses pembelajaran. <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  Jaringan terdiri dari tiga lapisan: <br><br><ul><li>  <b>input</b> <code>tf.keras.layers.Flatten</code> - layer ini mengubah gambar berukuran 28x28 piksel menjadi 1D-array dengan ukuran 784 (28 * 28).  Pada layer ini, kami tidak memiliki parameter untuk pelatihan, karena layer ini hanya berurusan dengan konversi data input. </li><li>  <b>hidden layer</b> <code>tf.keras.layers.Dense</code> - lapisan 128 neuron yang terhubung erat.  Setiap neuron (simpul) mengambil semua 784 nilai dari lapisan sebelumnya sebagai input, mengubah nilai input sesuai dengan bobot dan perpindahan internal selama pelatihan, dan mengembalikan nilai tunggal ke lapisan berikutnya. </li><li>  <b>output layer</b> <code>ts.keras.layers.Dense</code> - <code>softmax</code> terdiri dari 10 neuron, yang masing-masing mewakili kelas elemen pakaian tertentu.  Seperti pada lapisan sebelumnya, setiap neuron menerima nilai input dari semua 128 neuron dari lapisan sebelumnya.  Berat dan perpindahan masing-masing neuron pada lapisan ini berubah selama pelatihan sehingga nilai yang dihasilkan berada dalam interval <code>[0,1]</code> dan mewakili probabilitas bahwa gambar tersebut termasuk dalam kelas ini.  Jumlah semua nilai output dari 10 neuron adalah 1. </li></ul><br><h4>  Kompilasi model </h4><br>  Sebelum kita mulai melatih model, ada baiknya beberapa pengaturan lagi.  Pengaturan ini dibuat selama perakitan model ketika metode kompilasi dipanggil: <br><br><ul><li>  <b>loss function</b> - sebuah algoritma untuk mengukur seberapa jauh nilai yang diinginkan dari prediksi. </li><li>  <b>fungsi optimisasi</b> - suatu algoritma untuk "menyesuaikan" parameter internal (bobot dan offset) model untuk meminimalkan fungsi kerugian; </li><li>  <b>metrik</b> - digunakan untuk memantau proses pelatihan dan pengujian.  Contoh di bawah ini menggunakan metrik seperti <code></code> , persentase gambar yang telah diklasifikasikan dengan benar. </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3>  Kami melatih model </h3><br>  Pertama, kami menentukan urutan tindakan selama pelatihan pada set data pelatihan: <br><br><ol><li>  Ulangi set data input dalam jumlah tak terbatas kali menggunakan metode <code>dataset.repeat()</code> (parameter <code>epochs</code> , yang dijelaskan di bawah ini, menentukan jumlah semua iterasi pelatihan yang akan dilakukan) </li><li>  Metode <code>dataset.shuffle(60000)</code> semua gambar sehingga pelatihan model kami tidak terpengaruh oleh urutan input data input. </li><li>  Metode <code>dataset.batch(32)</code> memberi <code>model.fit</code> pelatihan <code>model.fit</code> menggunakan blok 32 gambar dan label <code>model.fit</code> kali variabel internal model diperbarui. </li></ol><br>  Pelatihan berlangsung dengan memanggil metode <code>model.fit</code> : <br><br><ul><li>  Mengirim <code>train_dataset</code> ke input model. </li><li>  Model belajar untuk mencocokkan gambar input dengan label. </li><li>  Parameter <code>epochs=5</code> membatasi jumlah sesi pelatihan hingga 5 iterasi pelatihan lengkap pada set data, yang pada akhirnya memberi kita pelatihan tentang 5 * 60.000 = 300.000 contoh. </li></ul><br>  (Anda dapat mengabaikan parameter <code>steps_per_epoch</code> , segera parameter ini akan dikeluarkan dari metode). <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br>  Dan inilah kesimpulannya: <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br>  Selama pelatihan model, nilai fungsi kerugian dan metrik akurasi ditampilkan untuk setiap iterasi pelatihan.  Model ini mencapai akurasi sekitar 0,88 (88%) pada data pelatihan. <br><br><h4>  Periksa akurasi </h4><br>  Mari kita periksa akurasi model apa yang dihasilkan pada data uji.  Kami akan menggunakan semua contoh yang kami miliki di set data uji untuk memeriksa akurasi. <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br>  Kesimpulan: <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br>  Seperti yang Anda lihat, akurasi pada set data uji ternyata kurang dari akurasi pada set data pelatihan.  Ini cukup normal karena model dilatih pada data train_dataset.  Ketika model menemukan gambar yang belum pernah dilihat sebelumnya (dari dataset train_dataset), jelas bahwa efisiensi klasifikasi akan menurun. <br><br><h3>  Prediksikan dan jelajahi </h3><br>  Kita dapat menggunakan model yang terlatih untuk mendapatkan prediksi untuk beberapa gambar. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kesimpulan: </font><font style="vertical-align: inherit;">Pada contoh di atas, model memperkirakan label untuk setiap gambar input uji. </font><font style="vertical-align: inherit;">Mari kita lihat prediksi pertama:</font></font><br><br> <code>(32, 10) <br></code> <br><br><font style="vertical-align: inherit;"></font><br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kesimpulan: </font></font><br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ingat bahwa prediksi model adalah larik 10 nilai. </font><font style="vertical-align: inherit;">Nilai-nilai ini menggambarkan "kepercayaan diri" model bahwa gambar input milik kelas tertentu (item pakaian). </font><font style="vertical-align: inherit;">Kita dapat melihat nilai maksimum sebagai berikut:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kesimpulan: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ini berarti bahwa model itu paling yakin bahwa gambar ini milik kelas berlabel 6 (class_names [6]). </font><font style="vertical-align: inherit;">Kami dapat memeriksa dan memastikan bahwa hasilnya benar dan benar:</font></font><br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kami dapat menampilkan semua gambar input dan prediksi model yang sesuai untuk 10 kelas: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mari kita lihat gambar ke-0, hasil prediksi model dan susunan prediksi. </font></font><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekarang mari kita menampilkan beberapa gambar dengan prediksi masing-masing. </font><font style="vertical-align: inherit;">Prediksi yang benar berwarna biru, prediksi yang salah berwarna merah. </font><font style="vertical-align: inherit;">Nilai di bawah gambar mencerminkan persentase kepercayaan bahwa gambar input sesuai dengan kelas ini. </font><font style="vertical-align: inherit;">Harap dicatat bahwa hasilnya mungkin salah bahkan jika nilai "kepercayaan" tinggi.</font></font><br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Gunakan model yang terlatih untuk memprediksi label untuk satu gambar: </font></font><br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kesimpulan: </font></font><br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model dalam </font></font><code>tf.keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dioptimalkan untuk prediksi dengan blok (koleksi). </font><font style="vertical-align: inherit;">Karenanya, terlepas dari kenyataan bahwa kami menggunakan elemen tunggal, Anda perlu menambahkannya ke daftar:</font></font><br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kesimpulan: </font></font><br><br> <code>(1, 28, 28, 1)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekarang kita akan memprediksi hasilnya:</font></font><br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kesimpulan: </font></font><br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Metode model.predict mengembalikan daftar daftar (array array), masing-masing untuk gambar dari blok input. </font><font style="vertical-align: inherit;">Kami mendapatkan satu-satunya hasil untuk gambar input tunggal kami:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kesimpulan: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Seperti sebelumnya, model ini memprediksi label 6 (kemeja). </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Latihan </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lakukan percobaan dengan berbagai model dan lihat bagaimana akurasi akan berubah. </font><font style="vertical-align: inherit;">Secara khusus, coba ubah pengaturan berikut:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> atur parameter zaman ke 1; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ubah jumlah neuron di lapisan tersembunyi, misalnya, dari nilai rendah 10 menjadi 512 dan lihat bagaimana keakuratan model prakiraan akan berubah; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tambahkan lapisan tambahan antara lapisan rata (lapisan penghalusan) dan lapisan akhir padat, bereksperimenlah dengan jumlah neuron pada lapisan ini; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> jangan menormalkan nilai piksel dan lihat apa yang terjadi. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ingatlah untuk mengaktifkan GPU sehingga semua perhitungan lebih cepat ( </font></font><code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). </font><font style="vertical-align: inherit;">Juga, jika Anda mengalami masalah selama operasi, cobalah mengatur ulang pengaturan lingkungan global:</font></font><br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Derajat Celcius VS MNIST </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Pada tahap ini, kita telah menemukan dua jenis jaringan saraf. Jaringan saraf pertama kami mempelajari cara mengonversi derajat Celsius ke derajat Frenheit, mengembalikan nilai tunggal yang dapat berada dalam rentang nilai numerik yang luas. </font></font><br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jaringan syaraf kedua kami mengembalikan 10 nilai probabilitas yang mencerminkan kepercayaan jaringan bahwa gambar input sesuai dengan kelas tertentu. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jaringan saraf dapat digunakan untuk menyelesaikan berbagai masalah. </font></font><br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kelas masalah pertama yang kami selesaikan dengan prediksi nilai tunggal disebut </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regresi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Konversi derajat Celsius ke derajat Fahrenheit adalah salah satu contoh tugas kelas ini. Contoh lain dari kelas tugas ini adalah tugas menentukan nilai sebuah rumah dengan jumlah kamar, total area, lokasi, dan karakteristik lainnya. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kelas tugas kedua yang kami pelajari dalam pelajaran ini mengelompokkan gambar ke dalam kategori yang tersedia disebut </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">klasifikasi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Menurut data input, model akan mengembalikan distribusi probabilitas ("kepercayaan" model bahwa nilai input milik kelas ini). Dalam pelajaran ini, kami mengembangkan jaringan saraf yang mengklasifikasikan elemen pakaian ke dalam 10 kategori, dan dalam pelajaran berikutnya, kita akan belajar untuk menentukan siapa yang ditampilkan dalam foto - seekor anjing atau kucing, tugas ini juga berkaitan dengan tugas klasifikasi.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mari kita simpulkan dan catat perbedaan antara dua kelas masalah ini - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regresi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dan </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">klasifikasi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Selamat, Anda telah mempelajari dua jenis jaringan saraf! Bersiap-siap untuk kuliah berikutnya, di sana kita akan mempelajari jenis baru dari jaringan saraf - jaringan saraf convolutional (CNN).</font></font><br><br><h3>  Ringkasan </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam pelajaran ini, kami melatih jaringan saraf untuk mengklasifikasikan gambar dengan elemen pakaian. Untuk melakukan ini, kami menggunakan dataset Fashion MNIST, yang berisi 70.000 gambar item pakaian. 60.000 di antaranya kami gunakan untuk melatih jaringan saraf, dan 10.000 sisanya untuk menguji efektivitas kerjanya. Untuk mengirimkan gambar-gambar ini ke input jaringan saraf kami, kami perlu mengkonversi (memuluskan) mereka dari format 2D 28x28 menjadi format 1D dari 784 elemen. Jaringan kami terdiri dari lapisan yang terhubung penuh dari 128 neuron dan lapisan keluaran dari 10 neuron, sesuai dengan jumlah label (kelas, kategori item pakaian). 10 nilai output ini mewakili distribusi probabilitas untuk setiap kelas. </font><i><font style="vertical-align: inherit;">Fungsi</font></i><font style="vertical-align: inherit;"> aktivasi </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menghitung distribusi probabilitas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami juga belajar tentang perbedaan antara </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regresi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dan </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">klasifikasi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regresi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Model yang mengembalikan nilai tunggal, seperti nilai rumah.</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Klasifikasi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Model yang mengembalikan distribusi probabilitas antara beberapa kategori. </font><font style="vertical-align: inherit;">Misalnya, dalam tugas kami dengan Fashion MNIST, nilai output adalah 10 nilai probabilitas, yang masing-masing dikaitkan dengan kelas tertentu (kategori item pakaian). </font><font style="vertical-align: inherit;">Saya mengingatkan Anda bahwa kami menggunakan fungsi aktivasi </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> hanya untuk mendapatkan distribusi probabilitas pada lapisan terakhir.</font></font></li></ul><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Versi video artikel</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Video keluar beberapa hari setelah publikasi dan ditambahkan ke artikel. </font></font><br></div></div><br>  ... dan ajakan bertindak standar - daftar, beri nilai tambah, dan bagikan :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Telegram</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id454034/">https://habr.com/ru/post/id454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id454018/index.html">iOS Digest No. 6 (17 Mei - 30 Mei)</a></li>
<li><a href="../id454024/index.html">Pengontrol biaya MPPT pada STM32F334C8T6</a></li>
<li><a href="../id454028/index.html">Sketsa dengan PHP Russia 2019: kode bersih, ilmu hitam</a></li>
<li><a href="../id454030/index.html">Odigest: menarik bagi desainer untuk minggu ini</a></li>
<li><a href="../id454032/index.html">Router dan Data Passing Clean Swift Architecture</a></li>
<li><a href="../id454036/index.html">6 cara untuk masuk ke neraka solusi siap pakai dan menurunkan satu atau dua juta</a></li>
<li><a href="../id454040/index.html">Konferensi React Russia 2019 sudah 1 Juni</a></li>
<li><a href="../id454042/index.html">Bayar apa yang Anda inginkan: bagaimana model ini menunjukkan dirinya dalam musik, dan siapa yang mencoba menghasilkan uang seperti itu</a></li>
<li><a href="../id454044/index.html">Kreativitas di iPad dan iPhone</a></li>
<li><a href="../id454046/index.html">Motivasi Lakukan sendiri</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
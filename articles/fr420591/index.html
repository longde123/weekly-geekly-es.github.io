<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏢 👨‍👩‍👧 📜 Traduction du livre d'Andrew Un, Passion for Machine Learning, chapitres 20 - 27 🎰 👩🏼 🧜🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="chapitres précédents 
 20 Offset et Scatter: deux sources principales d'erreurs 


 Remarque du traducteur Avant le changement, ce chapitre était inti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traduction du livre d'Andrew Un, Passion for Machine Learning, chapitres 20 - 27</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420591/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chapitres précédents</a> </p><br><h1 id="20-smeschenie-i-razbros-dva-osnovnyh-istochnika-oshibok">  20 Offset et Scatter: deux sources principales d'erreurs </h1><br><p>  <em><u>Remarque du traducteur</u> Avant le changement, ce chapitre était intitulé <strong>«Systématique et aléatoire: deux sources principales d'erreurs»,</strong> c'est-à-dire que j'utilisais les termes «erreurs aléatoires» et «erreurs systématiques» pour traduire le biais et la variance.</em>  <em>Cependant, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">membre</a> du forum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robot @ Phaker,</a> dans un commentaire, a noté à juste titre que dans le domaine de l'apprentissage automatique dans la terminologie russe pour ces termes, les concepts de "déplacement" et de "dispersion" sont fixes.</em>  <em>J'ai regardé le travail de K.V.</em>  <em>Vorontsov, qui est à juste titre l'une des autorités dans le domaine de l'apprentissage automatique en Russie et les ressources de la communauté professionnelle, et a souscrit à la remarque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robot @ Phaker</a> .</em>  <em>Malgré le fait que, de mon point de vue, il existe une analogie profonde et significative entre le «biais» et la «variance» dans la formation des algorithmes et l '«erreur systématique» et «l'erreur aléatoire» d'une expérience physique, en plus, ils sont exprimés de manière égale mathématiquement , néanmoins, il est correct d'utiliser les termes établis dans ce domaine.</em>  <em>Par conséquent, j'ai révisé la traduction de ce chapitre et des suivants, en remplaçant les «Erreurs systématiques et aléatoires» par «Offset and Scatter» et je m'en tiendrai à cette approche à l'avenir.</em> </p><a name="habracut"></a><br><p>  Supposons que vos échantillons de formation, de validation et de test aient la même distribution.  Ensuite, vous devez prendre plus de données pour la formation, cela n'améliorera que la qualité de l'algorithme, est-ce vrai? </p><br><p>  Bien que l'obtention de plus de données ne puisse pas nuire au travail, malheureusement, de nouvelles données n'aident pas toujours autant que vous pourriez vous y attendre.  Dans certains cas, le travail d'obtention de données supplémentaires peut être une perte d'effort.  Comment prendre une décision - dans quels cas ajouter des données et quand ne pas vous en préoccuper. </p><br><p>  Dans l'apprentissage automatique, il existe deux principales sources d'erreur: le biais et la dispersion (variance).  Comprendre de quoi il s'agit vous aidera à décider d'ajouter ou non plus de données, cela vous aidera également à choisir des tactiques pour améliorer la qualité du classificateur. </p><br><p>  Supposons que vous espérez créer un identifiant félin avec une erreur de 5%.  À l'heure actuelle, votre erreur de classificateur sur l'échantillon d'apprentissage est de 15%, sur l'échantillon de validation de 16%.  Dans ce cas, l'ajout de données de formation est peu susceptible d'augmenter considérablement la qualité.  Vous devez vous concentrer sur d'autres modifications du système.  En fait, ajouter plus d'exemples à votre ensemble d'entraînement ne fera que rendre plus difficile pour votre algorithme d'obtenir un bon résultat sur cet ensemble (pourquoi cela sera expliqué dans les chapitres suivants). </p><cut></cut><br><p>  Si le pourcentage de vos erreurs dans l'échantillon d'entraînement est de 15% (ce qui correspond à une précision de 85%), mais que votre objectif est le pourcentage d'erreurs dans 5% (précision de 95%), vous devez d'abord améliorer la qualité de votre algorithme dans l'échantillon d'apprentissage.  La qualité de l'algorithme dans les échantillons de validation / test est généralement pire que la qualité de son travail dans l'échantillon d'apprentissage (dans l'échantillon d'apprentissage).  Vous devez comprendre que les approches qui vous ont conduit à une précision ne dépassant pas 85% dans des exemples que votre algorithme connaît ne vous permettront pas d'obtenir une précision de 95% dans des exemples que cet algorithme n'a même pas vus. </p><cut></cut><br><p>  Supposons, comme indiqué ci-dessus, que le taux d'erreur de votre algorithme soit de 16% (la précision est de 84%) dans l'échantillon de validation.  Nous devons diviser l'erreur de 16% en deux composantes: </p><br><ul><li>  Premièrement, la proportion d'erreurs d'algorithme dans l'échantillon d'apprentissage.  Dans cet exemple, c'est 15%.  Nous l'appelons officieusement <strong>partialité</strong> . </li><li>  Deuxièmement, à quel point l'algorithme fonctionne-t-il pire sur l'échantillon de validation (ou de test) que sur celui d'apprentissage?  Dans notre exemple, il est 1% pire sur l'échantillon de validation que sur l'échantillon d'apprentissage.  Nous le considérerons également officieusement comme une <strong>variance de l'</strong> algorithme. </li></ul><br><p>  <em><u>remarque de l'auteur</u> En statistique, il existe une définition plus précise du biais et de la dispersion (erreurs systématiques et aléatoires), mais cela ne devrait pas nous déranger.</em>  <em>En gros, nous supposons que le biais est une erreur dans votre algorithme dans votre ensemble d'entraînement lorsque vous avez un ensemble d'entraînement très volumineux.</em>  <em>Scatter - c'est à quel point l'algorithme fonctionne pire sur l'échantillon de test par rapport à celui d'apprentissage avec les mêmes réglages de paramètres.</em>  <em>Si vous utilisez l'erreur standard, vous pouvez écrire les formules qui définissent ces deux quantités et prouver que l'erreur totale est égale à la somme du biais et de la dispersion (la somme des erreurs aléatoires et systématiques).</em>  <em>Mais pour nos besoins, en améliorant les algorithmes dans les problèmes d'apprentissage automatique, une définition informelle du biais et de la dispersion suffit.</em> </p><br><p>  Certains changements dans la formation de l'algorithme affectent la première composante du <strong>biais d'</strong> erreur et améliorent les performances de l'algorithme dans l'échantillon d'apprentissage.  Certains changements affectent le deuxième composant - la <strong>variance</strong> et aident à mieux généraliser l'algorithme aux échantillons de validation et de test.  Pour sélectionner les modifications les plus efficaces à apporter au système, il est extrêmement utile de comprendre comment chacun de ces deux composants d'erreur affecte l'erreur système globale. </p><br><p>  <em><u>Remarque de l'auteur:</u> Il existe également certaines approches qui réduisent simultanément le déplacement et la dispersion, apportant des changements importants à l'architecture du système.</em>  <em>Mais ils sont généralement plus difficiles à trouver et à mettre en œuvre.</em> </p><br><p>  Pour sélectionner les modifications les plus efficaces à apporter au système, il est extrêmement utile de comprendre comment chacun de ces deux composants d'erreur affecte l'erreur système globale. </p><br><p>  Le développement de l'intuition pour comprendre comment Contribution contribue à l'erreur et quel Scatter vous aidera à choisir efficacement les moyens d'améliorer votre algorithme. </p><cut></cut><br><h1 id="21-primery-klassifikacii-oshibok">  21 Exemples de classification des erreurs </h1><br><p>  Considérez notre problème de classification des chats.  Un classificateur idéal (par exemple, une personne) peut atteindre une excellente qualité de cette tâche. </p><br><p>  Supposons que la qualité de notre algorithme soit la suivante: </p><br><ul><li>  Erreur dans l'échantillon de formation = 1% </li><li>  Erreur dans l'échantillon de validation = 11% </li></ul><br><p>  Quel est le problème avec ce classificateur?  En appliquant les définitions du chapitre précédent, nous estimons le biais à 1% et l'écart à 10% (= 11% - 1%).  Ainsi, notre algorithme a une large <strong>diffusion</strong> .  Le classificateur a une très faible erreur dans l'échantillon d'apprentissage, mais ne peut pas généraliser les résultats de l'apprentissage à un échantillon de validation.  En d'autres termes, nous avons affaire à un sur- <strong>ajustement</strong> . </p><br><p>  Considérez maintenant cette situation: </p><br><ul><li>  Erreur dans l'échantillon de formation = 15% </li><li>  Erreur dans l'échantillon de validation = 16% </li></ul><br><p>  Ensuite, nous estimons le <strong>biais</strong> à 15% et l' <strong>écart</strong> à 1%.  Ce classificateur a été mal formé dans l'échantillon d'apprentissage, tandis que son erreur dans l'échantillon de validation est légèrement plus importante que dans l'échantillon d'apprentissage.  Ainsi, ce classifieur a un biais important, mais un petit écart.  On peut conclure que cet algorithme est <strong>insuffisant</strong> . </p><cut></cut><br><p>  Nous considérons également la distribution d'erreurs suivante: </p><br><ul><li>  Erreur dans l'échantillon de formation = 15% </li><li>  Erreur dans l'échantillon de validation = 30% </li></ul><br><p>  Dans ce cas, le biais est de 15% et l'écart est également de 15%.  Ce classificateur a un biais et une propagation élevés: il ne fonctionne pas bien dans l'échantillon d'apprentissage, ayant un biais élevé, et sa qualité dans l'échantillon de validation est bien pire que dans l'échantillon d'apprentissage, c'est-à-dire  la dispersion est également importante.  Ce cas est difficile à décrire en termes de recyclage / sous-éducation; ce classificateur est à la fois recyclé et sous-éduqué. </p><cut></cut><br><p>  Enfin, considérez cette situation: </p><br><ul><li>  Erreur dans l'échantillon de formation = 0,5% </li><li>  Erreur dans l'échantillon de validation = 1% </li></ul><br><p>  C'est un excellent classificateur, il a un faible biais et une faible dispersion.  Félicitations aux ingénieurs pour avoir obtenu un excellent résultat! </p><cut></cut><br><h1 id="22-sravnenie-s-optimalnoy-doley-oshibok">  22 Comparaison avec un taux d'erreur optimal </h1><br><p>  Dans notre exemple de reconnaissance des chats, la part d'erreurs idéale est le niveau disponible pour le classifieur «optimal» et ce niveau est proche de 0%.  Une personne qui regarde une photo est presque toujours capable de reconnaître si un chat est présent sur la photo ou non, et nous pouvons espérer que tôt ou tard la machine le fera aussi bien. </p><br><p>  Mais il y a des tâches plus complexes.  Par exemple, imaginez que vous développez un système de reconnaissance vocale et que 14% des enregistrements audio ont tellement de bruit de fond ou de discours tellement illisibles que même une personne ne peut pas comprendre ce qui y a été dit.  Dans ce cas, même le système de reconnaissance vocale le plus «optimal» peut avoir une erreur de l'ordre de 14%. </p><br><p>  Supposons que dans notre tâche de reconnaissance vocale, notre algorithme ait obtenu les résultats suivants: </p><br><ul><li>  Erreur dans l'échantillon de formation = 15% </li><li>  Erreur dans l'échantillon de validation = 30% </li></ul><cut></cut><br><p>  La qualité du classifieur dans l'échantillon d'apprentissage est déjà proche de l'optimale, avec un taux d'erreur de 14%.  Ainsi, dans ce cas, nous n'avons pas beaucoup d'occasions de réduire le <strong>biais</strong> (améliorer l'algorithme dans l'échantillon d'apprentissage).  Cependant, il n'est pas possible de généraliser le fonctionnement de cet algorithme à un échantillon de validation; par conséquent, il existe un grand champ pour les activités de réduction de la <strong>dispersion</strong> . </p><br><p>  Ce cas est similaire au troisième exemple du chapitre précédent, dans lequel l'erreur dans l'échantillon d'apprentissage est également égale à 15% et l'erreur dans l'échantillon de validation est de 30%.  Si le taux d'erreur optimal est d'environ 0%, alors l'erreur dans l'échantillon d'apprentissage de 15% donne beaucoup de place au travail pour améliorer l'algorithme.  Avec cette hypothèse, les efforts pour réduire le <strong>biais</strong> dans l'algorithme peuvent être très fructueux.  Mais si la proportion optimale d'erreurs de classification ne peut pas être inférieure à 14%, une proportion similaire d'erreurs d'algorithme dans l'échantillon d'apprentissage (c'est-à-dire de l'ordre de 14 à 15%) suggère que les possibilités de réduction du <strong>biais sont</strong> presque épuisées. </p><br><p>  Pour les problèmes dans lesquels la proportion optimale d'erreurs de classification diffère sensiblement de zéro, une structuration d'erreur plus détaillée peut être proposée.  Nous continuons à considérer l'exemple ci-dessus avec la reconnaissance vocale, une erreur totale de 30% dans l'échantillon de validation peut être décomposée en les composants suivants (les erreurs dans l'échantillon de test peuvent être analysées de la même manière): </p><cut></cut><br><ul><li>  <strong>Biais optimal (biais inévitable):</strong> 14%.  Imaginez, nous avons décidé que même le meilleur système de reconnaissance vocale possible au monde aurait un taux d'erreur de 14%.  Nous en parlerons comme la partie «inévitable» du décalage de l'algorithme d'apprentissage. </li><li>  <strong>Biais évitable</strong> : 1%.  Cette valeur est calculée comme la différence entre la proportion d'erreurs dans l'échantillon d'apprentissage et la proportion optimale d'erreurs. </li></ul><br><p>  <em><u>remarque de l'auteur:</u> si cette valeur s'avère négative, votre algorithme sur l'échantillon d'apprentissage montre donc une erreur plus petite que celle «optimale».</em>  <em>Cela signifie que vous vous êtes recyclé sur l'ensemble d'entraînement, votre algorithme s'est souvenu des exemples (et de leurs classes) de l'ensemble d'entraînement.</em>  <em>Dans ce cas, vous devez vous concentrer sur les méthodes pour réduire l'écart, plutôt que de réduire davantage le biais.</em> </p><br><ul><li>  <strong>Écart</strong> : 15%.  La différence entre les erreurs dans l'échantillon d'apprentissage et dans l'échantillon de validation </li></ul><br><p>  En rapport avec nos définitions précédentes, le déplacement et le déplacement jetable sont liés comme suit: </p><br><p>  Biais <strong>(biais)</strong> = biais optimal ( <strong>"biais inévitable"</strong> ) + biais jetable ( <strong>"biais évitable"</strong> ) </p><br><p>  <em><u>Note de l'auteur</u> : Ces définitions sont choisies pour mieux expliquer comment la qualité de l'algorithme d'apprentissage peut être améliorée.</em>  <em>Ces définitions diffèrent des définitions formelles de biais et de dispersion adoptées dans les statistiques.</em>  <em>Techniquement, ce que je définis comme «décalage» devrait être appelé «une erreur qui se trouve dans la structure des données (elle ne peut pas être identifiée et éliminée)» et «éliminer le biais» devrait être défini comme «le biais de l'algorithme d'apprentissage qui dépasse le biais optimal». .</em> </p><br><p>  Le biais évitable montre à quel point la qualité de votre algorithme dans l'échantillon d'apprentissage est pire que la qualité du «classificateur optimal». </p><br><p>  L'idée de base de la variance reste la même.  En théorie, nous pouvons toujours réduire l'écart à presque zéro en nous entraînant sur un échantillon d'apprentissage suffisamment grand.  Ainsi, tout écart est «évitable» lorsqu'il y a un échantillon suffisamment grand, il ne peut donc pas y avoir de «écart inévitable» (variance inévitable). </p><cut></cut><br><p>  Prenons un autre exemple dans lequel l'erreur optimale est de 14% et nous avons: </p><br><ul><li>  Erreur dans l'échantillon de formation = 15% </li><li>  Erreur dans l'échantillon de validation = 16% </li></ul><br><p>  Dans le chapitre précédent, nous avons classé un classificateur avec de tels indicateurs comme un classificateur à biais élevé, dans les conditions actuelles, nous disons que le «biais évitable» est de 1% et l'écart est d'environ 1%.  Ainsi, l'algorithme fonctionne déjà assez bien et il n'y a presque pas de réserves pour améliorer la qualité de son travail.  La qualité de cet algorithme n'est que de 2% inférieure à l'optimale. </p><br><p>  À partir de ces exemples, il est clair que la connaissance de l'ampleur de l'erreur fatale est utile pour décider d'autres actions.  En statistique, le <strong>taux d'erreur</strong> optimal est également appelé <strong>taux d'erreur de Bayes</strong> . </p><br><p>  Comment connaître la taille du taux d'erreur optimal?  Pour les tâches qu'une personne gère bien, telles que la reconnaissance d'image ou le décodage de clips audio, vous pouvez demander aux évaluateurs de baliser les données, puis de mesurer la précision du balisage humain dans l'échantillon d'apprentissage.  Cela donnera une estimation du taux d'erreur optimal.  Si vous travaillez sur un problème auquel même une personne a du mal à faire face (par exemple, pour prédire quel film recommander ou quelle publicité montrer à l'utilisateur), dans ce cas, il est plutôt difficile d'évaluer la proportion optimale d'erreurs. </p><br><p>  Dans la section Comparing to Human-Level Performance, chapitres 33 à 35, je vais discuter plus en détail du processus de comparaison de la qualité d'un algorithme d'apprentissage avec le niveau de qualité qu'une personne peut atteindre. </p><cut></cut><br><p>  Dans les derniers chapitres, vous avez appris à évaluer le biais et la dispersion amovibles / irrécupérables en analysant la proportion d'erreurs de classificateur dans les échantillons d'apprentissage et de validation.  Le chapitre suivant examinera comment vous pouvez utiliser les conclusions d'une telle analyse pour décider de vous concentrer sur des méthodes qui réduisent le biais ou sur des méthodes qui réduisent la propagation.  Les approches pour lutter contre les biais sont très différentes des approches pour réduire la dispersion, donc les techniques que vous devez appliquer dans votre projet pour améliorer la qualité dépendent beaucoup de ce qui est actuellement le problème - biais important ou dispersion importante. </p><cut></cut><br><p>  Continuez à lire! </p><br><h1 id="23-ustranenie-smescheniya-i-razbrosa">  23 Élimination des décalages et de la dispersion </h1><br><p>  Voici une formule simple pour éliminer le biais et la dispersion: </p><br><ul><li>  Si vous avez un grand biais évitable, augmentez la complexité de votre modèle (par exemple, augmentez votre réseau neuronal en ajoutant des couches ou (et) des neurones) </li><li>  Si vous avez une large diffusion, ajoutez des exemples à votre ensemble de formation. </li></ul><br><p>  Si vous avez la possibilité d'augmenter la taille du réseau de neurones et d'ajouter un nombre illimité de données à l'ensemble d'entraînement, cela vous aidera à obtenir un bon résultat pour un grand nombre de tâches d'apprentissage automatique. </p><br><p>  Dans la pratique, l'augmentation de la taille du modèle entraînera finalement des difficultés de calcul, car la formation de très grands modèles est lente.  Vous pouvez également épuiser la limite de données disponibles pour la formation.  (Même sur Internet, le nombre d'images avec des chats bien sûr!) </p><br><p>  Différentes architectures de modèles d'algorithmes, par exemple différentes architectures de réseaux de neurones, donneront différentes valeurs de biais et de dispersion, en fonction de votre tâche.  Un axe de recherche récente sur l'apprentissage en profondeur a créé un grand nombre d'architectures innovantes de modèles de réseaux de neurones.  Ainsi, si vous utilisez des réseaux de neurones, la non-fiction peut être une grande source d'inspiration.  Il existe également un grand nombre d'excellentes implémentations d'algorithmes dans les sources ouvertes, par exemple sur GitHub.  Cependant, les résultats des tentatives d'utilisation de nouvelles architectures sont nettement moins prévisibles que la formule simple donnée ci-dessus - augmenter la taille du modèle et ajouter des données. </p><br><p>  L'augmentation de la taille du modèle réduit généralement le biais, mais il peut également entraîner une augmentation de la propagation, et le risque de recyclage augmente également.  Cependant, le problème du recyclage ne se pose que lorsque vous n'utilisez pas la régularisation.  Si vous incluez une méthode de régularisation bien conçue dans votre modèle, vous parvenez généralement à augmenter en toute sécurité la taille du modèle sans autoriser de recyclage. </p><br><p>  Supposons que vous appliquiez un apprentissage approfondi en utilisant la régularisation ou le décrochage L2 ( <em><u>Note du traducteur</u> : vous pouvez lire sur <strong>Dropout</strong> , par exemple, ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://habr.com/company/wunderfund/blog/330814/</a></em> ), en utilisant des paramètres de régularisation qui fonctionnent parfaitement sur échantillon de validation.  Si vous augmentez la taille du modèle, la qualité de votre algorithme reste généralement la même ou augmente;  son déclin significatif est peu probable.  La seule raison pour laquelle nous devons refuser d'augmenter la taille du modèle est la grande surcharge de calcul. </p><br><h1 id="24-kompromiss-mezhdu-smescheniem-i-razbrosom">  24 Le compromis entre compensation et spread </h1><br><p>  Vous avez peut-être entendu parler du «compromis entre décalage et dispersion».  Parmi les nombreux changements qui peuvent être apportés aux algorithmes d'apprentissage, il y a ceux qui réduisent le biais et augmentent la propagation, ou vice versa.  Dans ce cas, ils parlent d'un «compromis» entre le déplacement et la propagation. </p><br><p> ,    —    ()   ,       ,    . ,     ,   . </p><br><p>                      (  ).  ,      ,          ,       . </p><br><p> ,            ,       .     ,  ,  ,  ,    . </p><br><p>     ,   ,       .        . </p><br><p>    ,     ,       . </p><br><h1 id="25-podhody-k-umensheniyu-ustranimogo-smescheniya"> 25      </h1><br><p>        ,     : </p><br><ul><li> <strong>  </strong> (,     ):    ,            .   ,     ,  ,     . </li><li> <strong>  ,   ,    </strong> .         ,         (      ).        ,    .        ;    ,     , ,  ,     . </li><li> <strong>    </strong> (L2 , L1 , Dropout):     , ,    . </li><li> <strong>  </strong> (,   )       :      ,     </li></ul><br><p>     : </p><br><ul><li> <strong>    </strong> :     ,        . </li></ul><br><h1 id="26-analiz-oshibok-na-trenirovochnoy-vyborke"> 26      </h1><br><p>        ,        / . </p><br><p>    ,  ,    ,           ,    ,        .   ,      , . .         . </p><br><p> ,        -         .         ,      ,   100 ,       ,        .      ,       : </p><br><div class="scrollable-table"><table><thead><tr><th>   </th><th>    </th><th>     </th><th>     </th><th>  Commentaires </th></tr></thead><tbody><tr><td>  1 </td><td>  X </td><td></td><td></td><td>    </td></tr><tr><td>  2 </td><td>  X </td><td></td><td>  X </td><td>   </td></tr><tr><td>  3 </td><td></td><td>  X </td><td>  X </td><td>     </td></tr><tr><td>  4 </td><td>  X </td><td></td><td></td><td>   </td></tr><tr><td> %   - </td><td> 75% </td><td> 25% </td><td> 50% </td><td></td></tr></tbody></table></div><br><p>       ,         ,    .       ,           . </p><br><p>      ,      -,      ,    .       ,    - ,   ,     ,  -     .      ,          ,  . </p><br><h1 id="27-podhody-k-umensheniyu-razbrosa"> 27     </h1><br><p>       ,     : </p><br><ul><li> <strong>     </strong> :         ,     ,                  . </li><li> <strong> </strong> (L1 , L2 , dropout):    ,   . </li><li> <strong>  </strong> (. .    ,       ):    ,   .      ,       . </li><li> <strong>    /  </strong> :       ,     .     (,  1000   900)       .   (  1000   100  10  )     ,      ,        .    ,   ,      ,        ,          ,     ,    ,      . ,     ,      . </li><li> <strong>  () </strong> (    / ). <em>  !</em>       , ,  . ,          .        .                  .       ,        . ,              ,     . </li></ul><br><p>       ,     ,    : </p><br><ul><li> <strong>  ,   ,    </strong> : ,        ,     ,        .         . ,      ;    ,     ,     . </li><li> <strong>  </strong> (,   )       :        . </li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420591/">https://habr.com/ru/post/fr420591/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420579/index.html">Processeur 24 cœurs, mais je ne peux pas taper un e-mail</a></li>
<li><a href="../fr420581/index.html">Prévision des ventes immobilières. Conférence à Yandex</a></li>
<li><a href="../fr420585/index.html">Base de données de codes à barres téléchargement gratuit sans inscription (et autres kakis)</a></li>
<li><a href="../fr420587/index.html">Eh bien, où mettre ces moteurs maintenant?</a></li>
<li><a href="../fr420589/index.html">Que rechercher lors du choix d'un système de journalisation et pourquoi nous nous sommes installés sur ELK</a></li>
<li><a href="../fr420593/index.html">Optimisation de la navigation Web mobile (2 succès récents)</a></li>
<li><a href="../fr420595/index.html">Génération automatique de programmes, problème inverse et quelques solutions associées</a></li>
<li><a href="../fr420597/index.html">Délégué à la protection des données - Le GDPR met à jour sa profession</a></li>
<li><a href="../fr420599/index.html">Treize choses que Lem prévoyait</a></li>
<li><a href="../fr420603/index.html">Statistiques du propriétaire de Tesla Model S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
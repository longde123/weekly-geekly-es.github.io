<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¢ ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ğŸ“œ Traduction du livre d'Andrew Un, Passion for Machine Learning, chapitres 20 - 27 ğŸ° ğŸ‘©ğŸ¼ ğŸ§œğŸ»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="chapitres prÃ©cÃ©dents 
 20 Offset et Scatter: deux sources principales d'erreurs 


 Remarque du traducteur Avant le changement, ce chapitre Ã©tait inti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traduction du livre d'Andrew Un, Passion for Machine Learning, chapitres 20 - 27</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420591/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chapitres prÃ©cÃ©dents</a> </p><br><h1 id="20-smeschenie-i-razbros-dva-osnovnyh-istochnika-oshibok">  20 Offset et Scatter: deux sources principales d'erreurs </h1><br><p>  <em><u>Remarque du traducteur</u> Avant le changement, ce chapitre Ã©tait intitulÃ© <strong>Â«SystÃ©matique et alÃ©atoire: deux sources principales d'erreursÂ»,</strong> c'est-Ã -dire que j'utilisais les termes Â«erreurs alÃ©atoiresÂ» et Â«erreurs systÃ©matiquesÂ» pour traduire le biais et la variance.</em>  <em>Cependant, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">membre</a> du forum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robot @ Phaker,</a> dans un commentaire, a notÃ© Ã  juste titre que dans le domaine de l'apprentissage automatique dans la terminologie russe pour ces termes, les concepts de "dÃ©placement" et de "dispersion" sont fixes.</em>  <em>J'ai regardÃ© le travail de K.V.</em>  <em>Vorontsov, qui est Ã  juste titre l'une des autoritÃ©s dans le domaine de l'apprentissage automatique en Russie et les ressources de la communautÃ© professionnelle, et a souscrit Ã  la remarque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robot @ Phaker</a> .</em>  <em>MalgrÃ© le fait que, de mon point de vue, il existe une analogie profonde et significative entre le Â«biaisÂ» et la Â«varianceÂ» dans la formation des algorithmes et l 'Â«erreur systÃ©matiqueÂ» et Â«l'erreur alÃ©atoireÂ» d'une expÃ©rience physique, en plus, ils sont exprimÃ©s de maniÃ¨re Ã©gale mathÃ©matiquement , nÃ©anmoins, il est correct d'utiliser les termes Ã©tablis dans ce domaine.</em>  <em>Par consÃ©quent, j'ai rÃ©visÃ© la traduction de ce chapitre et des suivants, en remplaÃ§ant les Â«Erreurs systÃ©matiques et alÃ©atoiresÂ» par Â«Offset and ScatterÂ» et je m'en tiendrai Ã  cette approche Ã  l'avenir.</em> </p><a name="habracut"></a><br><p>  Supposons que vos Ã©chantillons de formation, de validation et de test aient la mÃªme distribution.  Ensuite, vous devez prendre plus de donnÃ©es pour la formation, cela n'amÃ©liorera que la qualitÃ© de l'algorithme, est-ce vrai? </p><br><p>  Bien que l'obtention de plus de donnÃ©es ne puisse pas nuire au travail, malheureusement, de nouvelles donnÃ©es n'aident pas toujours autant que vous pourriez vous y attendre.  Dans certains cas, le travail d'obtention de donnÃ©es supplÃ©mentaires peut Ãªtre une perte d'effort.  Comment prendre une dÃ©cision - dans quels cas ajouter des donnÃ©es et quand ne pas vous en prÃ©occuper. </p><br><p>  Dans l'apprentissage automatique, il existe deux principales sources d'erreur: le biais et la dispersion (variance).  Comprendre de quoi il s'agit vous aidera Ã  dÃ©cider d'ajouter ou non plus de donnÃ©es, cela vous aidera Ã©galement Ã  choisir des tactiques pour amÃ©liorer la qualitÃ© du classificateur. </p><br><p>  Supposons que vous espÃ©rez crÃ©er un identifiant fÃ©lin avec une erreur de 5%.  Ã€ l'heure actuelle, votre erreur de classificateur sur l'Ã©chantillon d'apprentissage est de 15%, sur l'Ã©chantillon de validation de 16%.  Dans ce cas, l'ajout de donnÃ©es de formation est peu susceptible d'augmenter considÃ©rablement la qualitÃ©.  Vous devez vous concentrer sur d'autres modifications du systÃ¨me.  En fait, ajouter plus d'exemples Ã  votre ensemble d'entraÃ®nement ne fera que rendre plus difficile pour votre algorithme d'obtenir un bon rÃ©sultat sur cet ensemble (pourquoi cela sera expliquÃ© dans les chapitres suivants). </p><cut></cut><br><p>  Si le pourcentage de vos erreurs dans l'Ã©chantillon d'entraÃ®nement est de 15% (ce qui correspond Ã  une prÃ©cision de 85%), mais que votre objectif est le pourcentage d'erreurs dans 5% (prÃ©cision de 95%), vous devez d'abord amÃ©liorer la qualitÃ© de votre algorithme dans l'Ã©chantillon d'apprentissage.  La qualitÃ© de l'algorithme dans les Ã©chantillons de validation / test est gÃ©nÃ©ralement pire que la qualitÃ© de son travail dans l'Ã©chantillon d'apprentissage (dans l'Ã©chantillon d'apprentissage).  Vous devez comprendre que les approches qui vous ont conduit Ã  une prÃ©cision ne dÃ©passant pas 85% dans des exemples que votre algorithme connaÃ®t ne vous permettront pas d'obtenir une prÃ©cision de 95% dans des exemples que cet algorithme n'a mÃªme pas vus. </p><cut></cut><br><p>  Supposons, comme indiquÃ© ci-dessus, que le taux d'erreur de votre algorithme soit de 16% (la prÃ©cision est de 84%) dans l'Ã©chantillon de validation.  Nous devons diviser l'erreur de 16% en deux composantes: </p><br><ul><li>  PremiÃ¨rement, la proportion d'erreurs d'algorithme dans l'Ã©chantillon d'apprentissage.  Dans cet exemple, c'est 15%.  Nous l'appelons officieusement <strong>partialitÃ©</strong> . </li><li>  DeuxiÃ¨mement, Ã  quel point l'algorithme fonctionne-t-il pire sur l'Ã©chantillon de validation (ou de test) que sur celui d'apprentissage?  Dans notre exemple, il est 1% pire sur l'Ã©chantillon de validation que sur l'Ã©chantillon d'apprentissage.  Nous le considÃ©rerons Ã©galement officieusement comme une <strong>variance de l'</strong> algorithme. </li></ul><br><p>  <em><u>remarque de l'auteur</u> En statistique, il existe une dÃ©finition plus prÃ©cise du biais et de la dispersion (erreurs systÃ©matiques et alÃ©atoires), mais cela ne devrait pas nous dÃ©ranger.</em>  <em>En gros, nous supposons que le biais est une erreur dans votre algorithme dans votre ensemble d'entraÃ®nement lorsque vous avez un ensemble d'entraÃ®nement trÃ¨s volumineux.</em>  <em>Scatter - c'est Ã  quel point l'algorithme fonctionne pire sur l'Ã©chantillon de test par rapport Ã  celui d'apprentissage avec les mÃªmes rÃ©glages de paramÃ¨tres.</em>  <em>Si vous utilisez l'erreur standard, vous pouvez Ã©crire les formules qui dÃ©finissent ces deux quantitÃ©s et prouver que l'erreur totale est Ã©gale Ã  la somme du biais et de la dispersion (la somme des erreurs alÃ©atoires et systÃ©matiques).</em>  <em>Mais pour nos besoins, en amÃ©liorant les algorithmes dans les problÃ¨mes d'apprentissage automatique, une dÃ©finition informelle du biais et de la dispersion suffit.</em> </p><br><p>  Certains changements dans la formation de l'algorithme affectent la premiÃ¨re composante du <strong>biais d'</strong> erreur et amÃ©liorent les performances de l'algorithme dans l'Ã©chantillon d'apprentissage.  Certains changements affectent le deuxiÃ¨me composant - la <strong>variance</strong> et aident Ã  mieux gÃ©nÃ©raliser l'algorithme aux Ã©chantillons de validation et de test.  Pour sÃ©lectionner les modifications les plus efficaces Ã  apporter au systÃ¨me, il est extrÃªmement utile de comprendre comment chacun de ces deux composants d'erreur affecte l'erreur systÃ¨me globale. </p><br><p>  <em><u>Remarque de l'auteur:</u> Il existe Ã©galement certaines approches qui rÃ©duisent simultanÃ©ment le dÃ©placement et la dispersion, apportant des changements importants Ã  l'architecture du systÃ¨me.</em>  <em>Mais ils sont gÃ©nÃ©ralement plus difficiles Ã  trouver et Ã  mettre en Å“uvre.</em> </p><br><p>  Pour sÃ©lectionner les modifications les plus efficaces Ã  apporter au systÃ¨me, il est extrÃªmement utile de comprendre comment chacun de ces deux composants d'erreur affecte l'erreur systÃ¨me globale. </p><br><p>  Le dÃ©veloppement de l'intuition pour comprendre comment Contribution contribue Ã  l'erreur et quel Scatter vous aidera Ã  choisir efficacement les moyens d'amÃ©liorer votre algorithme. </p><cut></cut><br><h1 id="21-primery-klassifikacii-oshibok">  21 Exemples de classification des erreurs </h1><br><p>  ConsidÃ©rez notre problÃ¨me de classification des chats.  Un classificateur idÃ©al (par exemple, une personne) peut atteindre une excellente qualitÃ© de cette tÃ¢che. </p><br><p>  Supposons que la qualitÃ© de notre algorithme soit la suivante: </p><br><ul><li>  Erreur dans l'Ã©chantillon de formation = 1% </li><li>  Erreur dans l'Ã©chantillon de validation = 11% </li></ul><br><p>  Quel est le problÃ¨me avec ce classificateur?  En appliquant les dÃ©finitions du chapitre prÃ©cÃ©dent, nous estimons le biais Ã  1% et l'Ã©cart Ã  10% (= 11% - 1%).  Ainsi, notre algorithme a une large <strong>diffusion</strong> .  Le classificateur a une trÃ¨s faible erreur dans l'Ã©chantillon d'apprentissage, mais ne peut pas gÃ©nÃ©raliser les rÃ©sultats de l'apprentissage Ã  un Ã©chantillon de validation.  En d'autres termes, nous avons affaire Ã  un sur- <strong>ajustement</strong> . </p><br><p>  ConsidÃ©rez maintenant cette situation: </p><br><ul><li>  Erreur dans l'Ã©chantillon de formation = 15% </li><li>  Erreur dans l'Ã©chantillon de validation = 16% </li></ul><br><p>  Ensuite, nous estimons le <strong>biais</strong> Ã  15% et l' <strong>Ã©cart</strong> Ã  1%.  Ce classificateur a Ã©tÃ© mal formÃ© dans l'Ã©chantillon d'apprentissage, tandis que son erreur dans l'Ã©chantillon de validation est lÃ©gÃ¨rement plus importante que dans l'Ã©chantillon d'apprentissage.  Ainsi, ce classifieur a un biais important, mais un petit Ã©cart.  On peut conclure que cet algorithme est <strong>insuffisant</strong> . </p><cut></cut><br><p>  Nous considÃ©rons Ã©galement la distribution d'erreurs suivante: </p><br><ul><li>  Erreur dans l'Ã©chantillon de formation = 15% </li><li>  Erreur dans l'Ã©chantillon de validation = 30% </li></ul><br><p>  Dans ce cas, le biais est de 15% et l'Ã©cart est Ã©galement de 15%.  Ce classificateur a un biais et une propagation Ã©levÃ©s: il ne fonctionne pas bien dans l'Ã©chantillon d'apprentissage, ayant un biais Ã©levÃ©, et sa qualitÃ© dans l'Ã©chantillon de validation est bien pire que dans l'Ã©chantillon d'apprentissage, c'est-Ã -dire  la dispersion est Ã©galement importante.  Ce cas est difficile Ã  dÃ©crire en termes de recyclage / sous-Ã©ducation; ce classificateur est Ã  la fois recyclÃ© et sous-Ã©duquÃ©. </p><cut></cut><br><p>  Enfin, considÃ©rez cette situation: </p><br><ul><li>  Erreur dans l'Ã©chantillon de formation = 0,5% </li><li>  Erreur dans l'Ã©chantillon de validation = 1% </li></ul><br><p>  C'est un excellent classificateur, il a un faible biais et une faible dispersion.  FÃ©licitations aux ingÃ©nieurs pour avoir obtenu un excellent rÃ©sultat! </p><cut></cut><br><h1 id="22-sravnenie-s-optimalnoy-doley-oshibok">  22 Comparaison avec un taux d'erreur optimal </h1><br><p>  Dans notre exemple de reconnaissance des chats, la part d'erreurs idÃ©ale est le niveau disponible pour le classifieur Â«optimalÂ» et ce niveau est proche de 0%.  Une personne qui regarde une photo est presque toujours capable de reconnaÃ®tre si un chat est prÃ©sent sur la photo ou non, et nous pouvons espÃ©rer que tÃ´t ou tard la machine le fera aussi bien. </p><br><p>  Mais il y a des tÃ¢ches plus complexes.  Par exemple, imaginez que vous dÃ©veloppez un systÃ¨me de reconnaissance vocale et que 14% des enregistrements audio ont tellement de bruit de fond ou de discours tellement illisibles que mÃªme une personne ne peut pas comprendre ce qui y a Ã©tÃ© dit.  Dans ce cas, mÃªme le systÃ¨me de reconnaissance vocale le plus Â«optimalÂ» peut avoir une erreur de l'ordre de 14%. </p><br><p>  Supposons que dans notre tÃ¢che de reconnaissance vocale, notre algorithme ait obtenu les rÃ©sultats suivants: </p><br><ul><li>  Erreur dans l'Ã©chantillon de formation = 15% </li><li>  Erreur dans l'Ã©chantillon de validation = 30% </li></ul><cut></cut><br><p>  La qualitÃ© du classifieur dans l'Ã©chantillon d'apprentissage est dÃ©jÃ  proche de l'optimale, avec un taux d'erreur de 14%.  Ainsi, dans ce cas, nous n'avons pas beaucoup d'occasions de rÃ©duire le <strong>biais</strong> (amÃ©liorer l'algorithme dans l'Ã©chantillon d'apprentissage).  Cependant, il n'est pas possible de gÃ©nÃ©raliser le fonctionnement de cet algorithme Ã  un Ã©chantillon de validation; par consÃ©quent, il existe un grand champ pour les activitÃ©s de rÃ©duction de la <strong>dispersion</strong> . </p><br><p>  Ce cas est similaire au troisiÃ¨me exemple du chapitre prÃ©cÃ©dent, dans lequel l'erreur dans l'Ã©chantillon d'apprentissage est Ã©galement Ã©gale Ã  15% et l'erreur dans l'Ã©chantillon de validation est de 30%.  Si le taux d'erreur optimal est d'environ 0%, alors l'erreur dans l'Ã©chantillon d'apprentissage de 15% donne beaucoup de place au travail pour amÃ©liorer l'algorithme.  Avec cette hypothÃ¨se, les efforts pour rÃ©duire le <strong>biais</strong> dans l'algorithme peuvent Ãªtre trÃ¨s fructueux.  Mais si la proportion optimale d'erreurs de classification ne peut pas Ãªtre infÃ©rieure Ã  14%, une proportion similaire d'erreurs d'algorithme dans l'Ã©chantillon d'apprentissage (c'est-Ã -dire de l'ordre de 14 Ã  15%) suggÃ¨re que les possibilitÃ©s de rÃ©duction du <strong>biais sont</strong> presque Ã©puisÃ©es. </p><br><p>  Pour les problÃ¨mes dans lesquels la proportion optimale d'erreurs de classification diffÃ¨re sensiblement de zÃ©ro, une structuration d'erreur plus dÃ©taillÃ©e peut Ãªtre proposÃ©e.  Nous continuons Ã  considÃ©rer l'exemple ci-dessus avec la reconnaissance vocale, une erreur totale de 30% dans l'Ã©chantillon de validation peut Ãªtre dÃ©composÃ©e en les composants suivants (les erreurs dans l'Ã©chantillon de test peuvent Ãªtre analysÃ©es de la mÃªme maniÃ¨re): </p><cut></cut><br><ul><li>  <strong>Biais optimal (biais inÃ©vitable):</strong> 14%.  Imaginez, nous avons dÃ©cidÃ© que mÃªme le meilleur systÃ¨me de reconnaissance vocale possible au monde aurait un taux d'erreur de 14%.  Nous en parlerons comme la partie Â«inÃ©vitableÂ» du dÃ©calage de l'algorithme d'apprentissage. </li><li>  <strong>Biais Ã©vitable</strong> : 1%.  Cette valeur est calculÃ©e comme la diffÃ©rence entre la proportion d'erreurs dans l'Ã©chantillon d'apprentissage et la proportion optimale d'erreurs. </li></ul><br><p>  <em><u>remarque de l'auteur:</u> si cette valeur s'avÃ¨re nÃ©gative, votre algorithme sur l'Ã©chantillon d'apprentissage montre donc une erreur plus petite que celle Â«optimaleÂ».</em>  <em>Cela signifie que vous vous Ãªtes recyclÃ© sur l'ensemble d'entraÃ®nement, votre algorithme s'est souvenu des exemples (et de leurs classes) de l'ensemble d'entraÃ®nement.</em>  <em>Dans ce cas, vous devez vous concentrer sur les mÃ©thodes pour rÃ©duire l'Ã©cart, plutÃ´t que de rÃ©duire davantage le biais.</em> </p><br><ul><li>  <strong>Ã‰cart</strong> : 15%.  La diffÃ©rence entre les erreurs dans l'Ã©chantillon d'apprentissage et dans l'Ã©chantillon de validation </li></ul><br><p>  En rapport avec nos dÃ©finitions prÃ©cÃ©dentes, le dÃ©placement et le dÃ©placement jetable sont liÃ©s comme suit: </p><br><p>  Biais <strong>(biais)</strong> = biais optimal ( <strong>"biais inÃ©vitable"</strong> ) + biais jetable ( <strong>"biais Ã©vitable"</strong> ) </p><br><p>  <em><u>Note de l'auteur</u> : Ces dÃ©finitions sont choisies pour mieux expliquer comment la qualitÃ© de l'algorithme d'apprentissage peut Ãªtre amÃ©liorÃ©e.</em>  <em>Ces dÃ©finitions diffÃ¨rent des dÃ©finitions formelles de biais et de dispersion adoptÃ©es dans les statistiques.</em>  <em>Techniquement, ce que je dÃ©finis comme Â«dÃ©calageÂ» devrait Ãªtre appelÃ© Â«une erreur qui se trouve dans la structure des donnÃ©es (elle ne peut pas Ãªtre identifiÃ©e et Ã©liminÃ©e)Â» et Â«Ã©liminer le biaisÂ» devrait Ãªtre dÃ©fini comme Â«le biais de l'algorithme d'apprentissage qui dÃ©passe le biais optimalÂ». .</em> </p><br><p>  Le biais Ã©vitable montre Ã  quel point la qualitÃ© de votre algorithme dans l'Ã©chantillon d'apprentissage est pire que la qualitÃ© du Â«classificateur optimalÂ». </p><br><p>  L'idÃ©e de base de la variance reste la mÃªme.  En thÃ©orie, nous pouvons toujours rÃ©duire l'Ã©cart Ã  presque zÃ©ro en nous entraÃ®nant sur un Ã©chantillon d'apprentissage suffisamment grand.  Ainsi, tout Ã©cart est Â«Ã©vitableÂ» lorsqu'il y a un Ã©chantillon suffisamment grand, il ne peut donc pas y avoir de Â«Ã©cart inÃ©vitableÂ» (variance inÃ©vitable). </p><cut></cut><br><p>  Prenons un autre exemple dans lequel l'erreur optimale est de 14% et nous avons: </p><br><ul><li>  Erreur dans l'Ã©chantillon de formation = 15% </li><li>  Erreur dans l'Ã©chantillon de validation = 16% </li></ul><br><p>  Dans le chapitre prÃ©cÃ©dent, nous avons classÃ© un classificateur avec de tels indicateurs comme un classificateur Ã  biais Ã©levÃ©, dans les conditions actuelles, nous disons que le Â«biais Ã©vitableÂ» est de 1% et l'Ã©cart est d'environ 1%.  Ainsi, l'algorithme fonctionne dÃ©jÃ  assez bien et il n'y a presque pas de rÃ©serves pour amÃ©liorer la qualitÃ© de son travail.  La qualitÃ© de cet algorithme n'est que de 2% infÃ©rieure Ã  l'optimale. </p><br><p>  Ã€ partir de ces exemples, il est clair que la connaissance de l'ampleur de l'erreur fatale est utile pour dÃ©cider d'autres actions.  En statistique, le <strong>taux d'erreur</strong> optimal est Ã©galement appelÃ© <strong>taux d'erreur de Bayes</strong> . </p><br><p>  Comment connaÃ®tre la taille du taux d'erreur optimal?  Pour les tÃ¢ches qu'une personne gÃ¨re bien, telles que la reconnaissance d'image ou le dÃ©codage de clips audio, vous pouvez demander aux Ã©valuateurs de baliser les donnÃ©es, puis de mesurer la prÃ©cision du balisage humain dans l'Ã©chantillon d'apprentissage.  Cela donnera une estimation du taux d'erreur optimal.  Si vous travaillez sur un problÃ¨me auquel mÃªme une personne a du mal Ã  faire face (par exemple, pour prÃ©dire quel film recommander ou quelle publicitÃ© montrer Ã  l'utilisateur), dans ce cas, il est plutÃ´t difficile d'Ã©valuer la proportion optimale d'erreurs. </p><br><p>  Dans la section Comparing to Human-Level Performance, chapitres 33 Ã  35, je vais discuter plus en dÃ©tail du processus de comparaison de la qualitÃ© d'un algorithme d'apprentissage avec le niveau de qualitÃ© qu'une personne peut atteindre. </p><cut></cut><br><p>  Dans les derniers chapitres, vous avez appris Ã  Ã©valuer le biais et la dispersion amovibles / irrÃ©cupÃ©rables en analysant la proportion d'erreurs de classificateur dans les Ã©chantillons d'apprentissage et de validation.  Le chapitre suivant examinera comment vous pouvez utiliser les conclusions d'une telle analyse pour dÃ©cider de vous concentrer sur des mÃ©thodes qui rÃ©duisent le biais ou sur des mÃ©thodes qui rÃ©duisent la propagation.  Les approches pour lutter contre les biais sont trÃ¨s diffÃ©rentes des approches pour rÃ©duire la dispersion, donc les techniques que vous devez appliquer dans votre projet pour amÃ©liorer la qualitÃ© dÃ©pendent beaucoup de ce qui est actuellement le problÃ¨me - biais important ou dispersion importante. </p><cut></cut><br><p>  Continuez Ã  lire! </p><br><h1 id="23-ustranenie-smescheniya-i-razbrosa">  23 Ã‰limination des dÃ©calages et de la dispersion </h1><br><p>  Voici une formule simple pour Ã©liminer le biais et la dispersion: </p><br><ul><li>  Si vous avez un grand biais Ã©vitable, augmentez la complexitÃ© de votre modÃ¨le (par exemple, augmentez votre rÃ©seau neuronal en ajoutant des couches ou (et) des neurones) </li><li>  Si vous avez une large diffusion, ajoutez des exemples Ã  votre ensemble de formation. </li></ul><br><p>  Si vous avez la possibilitÃ© d'augmenter la taille du rÃ©seau de neurones et d'ajouter un nombre illimitÃ© de donnÃ©es Ã  l'ensemble d'entraÃ®nement, cela vous aidera Ã  obtenir un bon rÃ©sultat pour un grand nombre de tÃ¢ches d'apprentissage automatique. </p><br><p>  Dans la pratique, l'augmentation de la taille du modÃ¨le entraÃ®nera finalement des difficultÃ©s de calcul, car la formation de trÃ¨s grands modÃ¨les est lente.  Vous pouvez Ã©galement Ã©puiser la limite de donnÃ©es disponibles pour la formation.  (MÃªme sur Internet, le nombre d'images avec des chats bien sÃ»r!) </p><br><p>  DiffÃ©rentes architectures de modÃ¨les d'algorithmes, par exemple diffÃ©rentes architectures de rÃ©seaux de neurones, donneront diffÃ©rentes valeurs de biais et de dispersion, en fonction de votre tÃ¢che.  Un axe de recherche rÃ©cente sur l'apprentissage en profondeur a crÃ©Ã© un grand nombre d'architectures innovantes de modÃ¨les de rÃ©seaux de neurones.  Ainsi, si vous utilisez des rÃ©seaux de neurones, la non-fiction peut Ãªtre une grande source d'inspiration.  Il existe Ã©galement un grand nombre d'excellentes implÃ©mentations d'algorithmes dans les sources ouvertes, par exemple sur GitHub.  Cependant, les rÃ©sultats des tentatives d'utilisation de nouvelles architectures sont nettement moins prÃ©visibles que la formule simple donnÃ©e ci-dessus - augmenter la taille du modÃ¨le et ajouter des donnÃ©es. </p><br><p>  L'augmentation de la taille du modÃ¨le rÃ©duit gÃ©nÃ©ralement le biais, mais il peut Ã©galement entraÃ®ner une augmentation de la propagation, et le risque de recyclage augmente Ã©galement.  Cependant, le problÃ¨me du recyclage ne se pose que lorsque vous n'utilisez pas la rÃ©gularisation.  Si vous incluez une mÃ©thode de rÃ©gularisation bien conÃ§ue dans votre modÃ¨le, vous parvenez gÃ©nÃ©ralement Ã  augmenter en toute sÃ©curitÃ© la taille du modÃ¨le sans autoriser de recyclage. </p><br><p>  Supposons que vous appliquiez un apprentissage approfondi en utilisant la rÃ©gularisation ou le dÃ©crochage L2 ( <em><u>Note du traducteur</u> : vous pouvez lire sur <strong>Dropout</strong> , par exemple, ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://habr.com/company/wunderfund/blog/330814/</a></em> ), en utilisant des paramÃ¨tres de rÃ©gularisation qui fonctionnent parfaitement sur Ã©chantillon de validation.  Si vous augmentez la taille du modÃ¨le, la qualitÃ© de votre algorithme reste gÃ©nÃ©ralement la mÃªme ou augmente;  son dÃ©clin significatif est peu probable.  La seule raison pour laquelle nous devons refuser d'augmenter la taille du modÃ¨le est la grande surcharge de calcul. </p><br><h1 id="24-kompromiss-mezhdu-smescheniem-i-razbrosom">  24 Le compromis entre compensation et spread </h1><br><p>  Vous avez peut-Ãªtre entendu parler du Â«compromis entre dÃ©calage et dispersionÂ».  Parmi les nombreux changements qui peuvent Ãªtre apportÃ©s aux algorithmes d'apprentissage, il y a ceux qui rÃ©duisent le biais et augmentent la propagation, ou vice versa.  Dans ce cas, ils parlent d'un Â«compromisÂ» entre le dÃ©placement et la propagation. </p><br><p> ,    â€”    ()   ,       ,    . ,     ,   . </p><br><p>                      (  ).  ,      ,          ,       . </p><br><p> ,            ,       .     ,  ,  ,  ,    . </p><br><p>     ,   ,       .        . </p><br><p>    ,     ,       . </p><br><h1 id="25-podhody-k-umensheniyu-ustranimogo-smescheniya"> 25      </h1><br><p>        ,     : </p><br><ul><li> <strong>  </strong> (,     ):    ,            .   ,     ,  ,     . </li><li> <strong>  ,   ,    </strong> .         ,         (      ).        ,    .        ;    ,     , ,  ,     . </li><li> <strong>    </strong> (L2 , L1 , Dropout):     , ,    . </li><li> <strong>  </strong> (,   )       :      ,     </li></ul><br><p>     : </p><br><ul><li> <strong>    </strong> :     ,        . </li></ul><br><h1 id="26-analiz-oshibok-na-trenirovochnoy-vyborke"> 26      </h1><br><p>        ,        / . </p><br><p>    ,  ,    ,           ,    ,        .   ,      , . .         . </p><br><p> ,        -         .         ,      ,   100 ,       ,        .      ,       : </p><br><div class="scrollable-table"><table><thead><tr><th>   </th><th>    </th><th>     </th><th>     </th><th>  Commentaires </th></tr></thead><tbody><tr><td>  1 </td><td>  X </td><td></td><td></td><td>    </td></tr><tr><td>  2 </td><td>  X </td><td></td><td>  X </td><td>   </td></tr><tr><td>  3 </td><td></td><td>  X </td><td>  X </td><td>     </td></tr><tr><td>  4 </td><td>  X </td><td></td><td></td><td>   </td></tr><tr><td> %   - </td><td> 75% </td><td> 25% </td><td> 50% </td><td></td></tr></tbody></table></div><br><p>       ,         ,    .       ,           . </p><br><p>      ,      -,      ,    .       ,    - ,   ,     ,  -     .      ,          ,  . </p><br><h1 id="27-podhody-k-umensheniyu-razbrosa"> 27     </h1><br><p>       ,     : </p><br><ul><li> <strong>     </strong> :         ,     ,                  . </li><li> <strong> </strong> (L1 , L2 , dropout):    ,   . </li><li> <strong>  </strong> (. .    ,       ):    ,   .      ,       . </li><li> <strong>    /  </strong> :       ,     .     (,  1000   900)       .   (  1000   100  10  )     ,      ,        .    ,   ,      ,        ,          ,     ,    ,      . ,     ,      . </li><li> <strong>  () </strong> (    / ). <em>  !</em>       , ,  . ,          .        .                  .       ,        . ,              ,     . </li></ul><br><p>       ,     ,    : </p><br><ul><li> <strong>  ,   ,    </strong> : ,        ,     ,        .         . ,      ;    ,     ,     . </li><li> <strong>  </strong> (,   )       :        . </li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420591/">https://habr.com/ru/post/fr420591/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420579/index.html">Processeur 24 cÅ“urs, mais je ne peux pas taper un e-mail</a></li>
<li><a href="../fr420581/index.html">PrÃ©vision des ventes immobiliÃ¨res. ConfÃ©rence Ã  Yandex</a></li>
<li><a href="../fr420585/index.html">Base de donnÃ©es de codes Ã  barres tÃ©lÃ©chargement gratuit sans inscription (et autres kakis)</a></li>
<li><a href="../fr420587/index.html">Eh bien, oÃ¹ mettre ces moteurs maintenant?</a></li>
<li><a href="../fr420589/index.html">Que rechercher lors du choix d'un systÃ¨me de journalisation et pourquoi nous nous sommes installÃ©s sur ELK</a></li>
<li><a href="../fr420593/index.html">Optimisation de la navigation Web mobile (2 succÃ¨s rÃ©cents)</a></li>
<li><a href="../fr420595/index.html">GÃ©nÃ©ration automatique de programmes, problÃ¨me inverse et quelques solutions associÃ©es</a></li>
<li><a href="../fr420597/index.html">DÃ©lÃ©guÃ© Ã  la protection des donnÃ©es - Le GDPR met Ã  jour sa profession</a></li>
<li><a href="../fr420599/index.html">Treize choses que Lem prÃ©voyait</a></li>
<li><a href="../fr420603/index.html">Statistiques du propriÃ©taire de Tesla Model S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
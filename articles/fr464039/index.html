<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ì üßëüèø‚Äçü§ù‚Äçüßëüèº ‚óæÔ∏è R√©seaux de neurones et apprentissage profond: un tutoriel en ligne, chapitre 6, partie 2: progr√®s r√©cents dans la reconnaissance d'images ü§Ωüèª üôáüèº üöâ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Table des mati√®res 

- Chapitre 1: utiliser les r√©seaux de neurones pour reconna√Ætre les nombres manuscrits 
- Chapitre 2: comment fonctionne l'algori...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>R√©seaux de neurones et apprentissage profond: un tutoriel en ligne, chapitre 6, partie 2: progr√®s r√©cents dans la reconnaissance d'images</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464039/"><div class="spoiler">  <b class="spoiler_title">Table des mati√®res</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 1: utiliser les r√©seaux de neurones pour reconna√Ætre les nombres manuscrits</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 2: comment fonctionne l'algorithme de r√©tropropagation</a> </li><li>  Chapitre 3: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: am√©liorer la m√©thode de formation des r√©seaux de neurones</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: Pourquoi la r√©gularisation contribue-t-elle √† r√©duire le recyclage?</a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 3: comment choisir les hyperparam√®tres de r√©seau neuronal?</a> <br></li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 4: preuve visuelle que les r√©seaux de neurones sont capables de calculer n'importe quelle fonction</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 5: Pourquoi les r√©seaux de neurones profonds sont-ils si difficiles √† former?</a> </li><li>  Chapitre 6: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: Deep Learning</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: progr√®s r√©cents dans la reconnaissance d'images</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Postface: existe-t-il un algorithme simple pour cr√©er de l'intelligence?</a> </li></ul></div></div><br>  En 1998, lorsque la base de donn√©es MNIST est apparue, il a fallu des semaines pour former les ordinateurs les plus avanc√©s, qui ont obtenu des r√©sultats bien pires que les ordinateurs d'aujourd'hui, qui prennent moins d'une heure pour utiliser le GPU.  Par cons√©quent, le MNIST n'est plus une t√¢che qui repousse les limites de la technologie;  la rapidit√© de la formation sugg√®re que cette t√¢che est bien adapt√©e √† l'√©tude de cette technologie.  En attendant, la recherche va plus loin et le travail moderne √©tudie des probl√®mes beaucoup plus complexes.  Dans cette section, je d√©crirai bri√®vement quelques exemples de travaux en cours li√©s √† la reconnaissance d'images √† l'aide de r√©seaux de neurones. <br><br>  Cette section est diff√©rente du reste du livre.  Dans le livre, je me suis concentr√© sur des id√©es vraisemblablement de longue dur√©e - r√©tropropagation, r√©gularisation, r√©seaux convolutionnels.  J'ai essay√© d'√©viter les r√©sultats consid√©r√©s comme √† la mode au moment de la r√©daction, dont la valeur √† long terme semblait douteuse.  En science, ces r√©sultats se r√©v√®lent le plus souvent √©ph√©m√®res, disparaissent rapidement et n'ont pas d'effet √† long terme.  Compte tenu de cela, le sceptique dirait: ¬´Bien s√ªr, les progr√®s r√©cents de la reconnaissance d'image peuvent √™tre consid√©r√©s comme un exemple d'un tel voyage d'une journ√©e?  Dans deux ou trois ans, tout va changer.  Ces r√©sultats sont-ils donc susceptibles d'int√©resser un petit nombre de professionnels en comp√©tition au premier plan?  Pourquoi en discuter? " <br><a name="habracut"></a><br>  Un tel sceptique aura raison en ce que les petits d√©tails des ≈ìuvres r√©centes perdent progressivement de l'importance per√ßue.  Cependant, au cours des derni√®res ann√©es, des am√©liorations incroyables ont √©t√© apport√©es √† la r√©solution de probl√®mes particuli√®rement complexes de reconnaissance d'image √† l'aide de r√©seaux de neurones profonds (GNS).  Imaginez un historien de la science qui r√©dige du mat√©riel sur la vision par ordinateur en 2100.  Ils d√©finiront 2011-2015 (et probablement plusieurs ann√©es apr√®s) comme une p√©riode de perc√©es significatives tir√©es par les r√©seaux de convolution profonde (GSS).  Cela ne signifie pas que le GOS sera toujours utilis√© en 2100, sans parler de d√©tails tels que l'exception, ReLU, etc.  Mais cela signifie tout de m√™me qu'il y a une transition importante dans l'histoire des id√©es √† l'heure actuelle.  Cela revient √† observer la d√©couverte de l'atome, l'invention des antibiotiques: l'invention et la d√©couverte de proportions historiques.  Par cons√©quent, sans entrer dans les d√©tails, il vaut la peine de se faire une id√©e des d√©couvertes int√©ressantes qui se font aujourd'hui. <br><br><h3>  Travail 2012 LRMD </h3><br>  Permettez-moi de commencer par les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travaux de 2012,</a> r√©dig√©s par un groupe de chercheurs de Stanford et de Google.  Je l'appellerai LRMD, par les premi√®res lettres des noms des quatre premiers auteurs.  LRMD a utilis√© NS pour classer les images de la base de donn√©es ImageNet, ce qui est une t√¢che tr√®s difficile de reconnaissance de formes.  Les donn√©es qu'ils ont utilis√©es √† partir de 2011 ImageNet comprenaient 16 millions d'images en couleur, r√©parties en 20 000 cat√©gories.  Les images ont √©t√© t√©l√©charg√©es sur Internet et class√©es par Mechanical Turk d'Amazon.  En voici quelques uns: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/323/b71/89a/323b7189a538cc4532b293b48f587cca.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/bed/423/c27/bed423c2789cb88297bf8946f1e92e82.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/855/3e5/38d/8553e538d4514742d4ebf554eae7c490.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/326/bc0/f49/326bc0f4920430fb06490cab8bb8eeeb.jpg"><br><br>  Ils appartiennent respectivement aux cat√©gories: oreillons, champignon racine brune, lait pasteuris√©, vers ronds.  Si vous voulez vous entra√Æner, je vous recommande de consulter la liste des outils √† main d'ImagNet, o√π des diff√©rences sont faites entre les monticules, les raboteuses, les raboteuses pour le chanfreinage et des dizaines d'autres types de raboteuses, sans parler des autres cat√©gories.  Je ne sais pas pour vous, mais je ne peux pas distinguer avec certitude tous ces outils.  C'est √©videmment beaucoup plus difficile que MNIST!  Le r√©seau LRMD a obtenu un r√©sultat d√©cent avec une pr√©cision de reconnaissance d'image de 15,8% d'ImageNet.  Ce r√©sultat peut ne pas sembler aussi impressionnant, mais il s'agit d'une √©norme am√©lioration par rapport au r√©sultat pr√©c√©dent de 9,3%.  Un tel bond sugg√®re que les NS peuvent offrir une approche efficace pour des t√¢ches de reconnaissance d'image tr√®s complexes, comme ImageNet. <br><br><h3>  Travail 2012 KSH </h3><br>  Les travaux du LRMD en 2012 ont √©t√© suivis des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travaux de</a> Krizhevsky, Sutskever et Hinton (KSH).  KSH a form√© et test√© le GSS en utilisant un sous-ensemble limit√© de donn√©es ImagNet.  Ce sous-ensemble est d√©fini par le concours populaire d'apprentissage automatique - D√©fi de reconnaissance visuelle √† grande √©chelle ImageNet (ILSVRC).  L'utilisation de ce sous-ensemble leur a donn√© un moyen pratique de comparer leur approche avec d'autres techniques de pointe.  L'ensemble ILSVRC 2012 contient environ 1,2 million d'images de 1000 cat√©gories.  Les ensembles de v√©rification et de confirmation contiennent respectivement 150 000 et 50 000 images des 1000 m√™mes cat√©gories. <br><br>  L'un des d√©fis du concours ILSVRC est que de nombreuses images d'ImageNet contiennent plusieurs objets.  Par exemple, sur l'image, le Labrador Retriever court apr√®s un ballon de soccer.  T.N.  La classification ¬´correcte¬ª de l'ILSVRC peut correspondre √† l'√©tiquette du Labrador Retriever.  Est-il n√©cessaire de s√©lectionner des points dans l'algorithme s'il marque l'image comme un ballon de foot?  En raison d'une telle ambigu√Øt√©, l'algorithme √©tait consid√©r√© comme correct si la classification ImageNet √©tait parmi les 5 hypoth√®ses les plus probables de l'algorithme concernant le contenu de l'image.  Selon ce crit√®re, parmi les 5 premiers, l'ESG de KSH a atteint une pr√©cision de 84,7%, bien meilleure que l'adversaire pr√©c√©dent, qui a atteint une pr√©cision de 73,8%.  En utilisant une m√©trique plus rigoureuse, lorsque l'√©tiquette doit correspondre exactement √† la prescription, la pr√©cision KSH atteint 63,3%. <br><br>  Il convient de d√©crire bri√®vement le r√©seau KSH, car il a inspir√© de nombreux travaux qui ont suivi.  Il est √©galement, comme nous le verrons, √©troitement li√© aux r√©seaux que nous avons form√©s dans ce chapitre, bien qu'il soit plus complexe.  KSH a utilis√© GSS form√© sur deux GPU.  Ils ont utilis√© deux GPU car leur carte particuli√®re (NVIDIA GeForce GTX 580) n'avait pas assez de m√©moire pour stocker l'ensemble du r√©seau.  Par cons√©quent, ils ont divis√© le r√©seau en deux parties. <br><br>  Le r√©seau KSH comprend 7 couches de neurones cach√©s.  Les cinq premi√®res couches masqu√©es sont convolutives (certaines utilisent la mise en commun maximale) et les 2 suivantes sont enti√®rement connect√©es.  La couche softmax en sortie est constitu√©e de 1000 neurones correspondant √† 1000 classes d'images.  Voici un croquis du r√©seau, tir√© des travaux de KSH.  Les d√©tails sont d√©crits ci-dessous.  Notez que de nombreuses couches sont divis√©es en 2 parties correspondant √† deux GPU. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/986/143/0bb/9861430bb7c8c79540298a2db5122ec2.jpg"><br><br>  Dans la couche d'entr√©e, il y a un neurone 3x224x224 indiquant les valeurs RVB pour une image de taille 224x224.  Rappelons que ImageNet contient des images de diff√©rentes r√©solutions.  Cela pose un probl√®me, car la couche r√©seau d'entr√©e est g√©n√©ralement de taille fixe.  KSH a r√©solu ce probl√®me en mettant √† l'√©chelle chaque image de sorte que son petit c√¥t√© ait une longueur de 256 pixels.  Ensuite, ils ont d√©coup√© une zone de 256x256 pixels √† partir du milieu de l'image redimensionn√©e.  Enfin, KSH r√©cup√®re des morceaux d'image al√©atoires 224x224 (et leurs r√©flexions horizontales) √† partir d'images 256x256.  Cette coupe al√©atoire est un moyen d'√©largir les donn√©es de formation pour r√©duire le recyclage.  Cela aide particuli√®rement √† former un r√©seau aussi important que KSH.  Et enfin, ces images 224x224 sont utilis√©es comme entr√©e sur le r√©seau.  Dans la plupart des cas, l'image recadr√©e contient l'objet principal de l'image d'origine. <br><br>  Nous passons aux couches cach√©es du r√©seau KSH.  La premi√®re couche cach√©e est convolutive, avec une √©tape de traction maximale.  Il utilise des champs r√©cepteurs locaux de taille 11x11 et un pas de 4 pixels.  Au total, 96 cartes de caract√©ristiques sont obtenues.  Les cartes de personnage sont divis√©es en deux groupes de 48 pi√®ces, les 48 premi√®res cartes se trouvant sur un GPU et la seconde sur l'autre.  Le regroupement maximal dans cette couche et les couches suivantes est effectu√© par des sections 3x3, mais les sections de regroupement peuvent se chevaucher et sont situ√©es √† une distance de seulement 2 pixels les unes des autres. <br><br>  La deuxi√®me couche cach√©e est √©galement convolutive, avec une mise en commun maximale.  Il utilise des champs r√©cepteurs locaux 5x5 et dispose de 256 cartes fonctionnelles, divis√©es en 128 pi√®ces pour chaque GPU.  Les cartes d'entit√©s n'utilisent que 48 canaux entrants, et pas les 96 sorties de la couche pr√©c√©dente, comme d'habitude.  En effet, toute carte de fonction re√ßoit une entr√©e du GPU sur lequel elle est stock√©e.  En ce sens, le r√©seau s'√©loigne de l'architecture convolutionnelle que nous avons d√©crite plus haut dans ce chapitre, bien que, de toute √©vidence, l'id√©e de base reste la m√™me. <br><br>  Les troisi√®me, quatri√®me et cinqui√®me couches sont convolutives, mais sans mise en commun maximale.  Leurs param√®tres: (3) 384 cartes de caract√©ristiques, champs r√©cepteurs locaux 3x3, 256 canaux entrants;  (4) 384 cartes de caract√©ristiques, champs r√©cepteurs locaux 3x3, 192 canaux entrants;  (5) 256 cartes fonctionnelles, champs r√©cepteurs locaux 3x3, 192 canaux entrants.  Sur la troisi√®me couche, les donn√©es sont √©chang√©es entre les GPU (comme indiqu√© dans l'image) afin que les cartes d'entit√©s puissent utiliser les 256 canaux entrants. <br><br>  Les sixi√®me et septi√®me couches cach√©es sont enti√®rement connect√©es, 4096 neurones chacune. <br><br>  La couche de sortie est softmax, se compose de 1000 unit√©s. <br><br>  Le r√©seau KSH b√©n√©ficie de nombreuses techniques.  Au lieu d'utiliser la tangente sigmo√Øde ou hyperbolique comme fonction d'activation, il utilise des ReLU, qui acc√©l√®rent consid√©rablement l'apprentissage.  Le r√©seau KSH contient environ 60 millions de param√®tres de formation et, par cons√©quent, m√™me avec un grand nombre de donn√©es de formation, il est soumis √† un recyclage.  Pour y faire face, les auteurs ont √©largi l'ensemble de formation en recadrant des images au hasard, comme d√©crit ci-dessus.  Ils ont ensuite utilis√© la variante de r√©gularisation L2 et l'exception.  Le r√©seau a √©t√© form√© en utilisant une descente de gradient stochastique bas√©e sur l'√©lan et avec des mini-paquets. <br><br>  Ceci est un bref aper√ßu de la plupart des informations cl√©s de KSH.  J'ai omis certains d√©tails; recherchez-les vous-m√™me dans l'article.  Vous pouvez √©galement regarder le projet d'Alex Krizhevsky <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cuda-convnet</a> (et ses disciples), contenant du code qui met en ≈ìuvre bon nombre des id√©es d√©crites.  <a href="">Une</a> version de ce r√©seau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bas√©e sur Theano a</a> √©galement √©t√© <a href="">d√©velopp√©e</a> .  Vous pouvez reconna√Ætre dans le code des id√©es similaires √† celles que nous avons d√©velopp√©es dans ce chapitre, bien que l'utilisation de plusieurs GPU complique les choses.  Le framework Caffe a sa propre version du r√©seau KSH, voir leurs " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®les de zoo</a> " pour plus de d√©tails. <br><br><h3>  Concours ILSVRC 2014 </h3><br>  Depuis 2012, les progr√®s ont √©t√© assez rapides.  Participez au concours ILSVRC 2014.  Comme en 2012, les participants ont d√ª former des r√©seaux pour 1,2 million d'images de 1000 cat√©gories, et l'une des 5 pr√©dictions probables dans la bonne cat√©gorie √©tait un crit√®re de qualit√©.  <a href="">L'√©quipe gagnante</a> , compos√©e principalement d'employ√©s de Google, a utilis√© le GSS avec 22 couches de neurones.  Ils ont nomm√© leur r√©seau GoogLeNet, d'apr√®s LeNet-5.  Selon le crit√®re pour atteindre les cinq premi√®res options, GoogLeNet a atteint un indicateur de pr√©cision de 93,33%, ce qui a consid√©rablement am√©lior√© les r√©sultats du vainqueur de 2013 (Clarifai, de 88,3%) et du gagnant de 2012 (KSH, de 84,7%). <br><br>  Quelle est la pr√©cision de GoogLeNet √† 93,33%?  En 2014, une √©quipe de recherche a r√©dig√© une <a href="">revue du</a> concours ILSVRC.  L'une des questions abord√©es √©tait de savoir dans quelle mesure les gens seraient capables de faire face √† la t√¢che.  Pour l'exp√©rience, ils ont cr√©√© un syst√®me qui permet aux gens de classer les images avec ILSVRC.  Comme l'un des auteurs de l'ouvrage, Andrei Karpaty, explique, dans une entr√©e informative sur son blog, il √©tait tr√®s difficile d'apporter l'efficacit√© des gens aux indicateurs GoogLeNet: <br><blockquote>  La t√¢che de baliser des images avec cinq cat√©gories sur 1000 possibles est rapidement devenue extr√™mement difficile, m√™me pour ceux de mes amis du laboratoire qui travaillaient depuis longtemps avec ILSVRC et ses cat√©gories.  Tout d'abord, nous voulions soumettre la t√¢che √† Amazon Mechanical Turk.  Ensuite, nous avons d√©cid√© d'essayer d'embaucher des √©tudiants pour de l'argent.  J'ai donc organis√© une f√™te de marquage entre experts de mon laboratoire.  Apr√®s cela, j'ai d√©velopp√© une interface modifi√©e qui a utilis√© les pr√©dictions GoogLeNet pour r√©duire le nombre de cat√©gories de 1000 √† 100. Pourtant, la t√¢che √©tait difficile - les gens ont saut√© les cat√©gories, donnant des erreurs de l'ordre de 13-15%.  En fin de compte, j'ai r√©alis√© que pour me rapprocher encore plus du r√©sultat de GoogLeNet, l'approche la plus efficace serait de m'asseoir et de passer par un processus d'apprentissage incroyablement long et le processus ult√©rieur de balisage approfondi.  Au d√©but, le marquage √©tait √† une vitesse de l'ordre de 1 pi√®ce par minute, mais s'est acc√©l√©r√© dans le temps.  Certaines images √©taient faciles √† reconna√Ætre, tandis que d'autres (par exemple, certaines races de chiens, esp√®ces d'oiseaux ou de singes) n√©cessitaient plusieurs minutes de concentration.  Je suis devenu tr√®s bon pour distinguer les races de chiens.  Sur la base de mon √©chantillon d'images, les r√©sultats suivants ont √©t√© obtenus: GoogLeNet s'est tromp√© dans 6,8% des cas;  mon taux d'erreur √©tait de 5,1%, soit environ 1,7% de mieux. </blockquote><br><br>  En d'autres termes, l'expert, qui a travaill√© tr√®s soigneusement, uniquement en faisant de s√©rieux efforts, a pu l√©g√®rement devancer le STS.  Karpaty rapporte que le deuxi√®me expert, form√© sur moins d'images, a r√©ussi √† r√©duire l'erreur de seulement 12% en choisissant jusqu'√† 5 √©tiquettes par image, ce qui est beaucoup moins que GoogLeNet. <br><br>  Des r√©sultats impressionnants.  Et depuis l'av√®nement de ce travail, plusieurs √©quipes ont rendu compte du d√©veloppement de syst√®mes dont le taux d'erreur lors du choix des 5 meilleures balises √©tait m√™me inf√©rieur √† 5,1%.  Parfois, ces r√©alisations ont √©t√© couvertes par les m√©dias comme l'√©mergence de syst√®mes capables de mieux reconna√Ætre les images que les personnes.  Bien que les r√©sultats soient g√©n√©ralement frappants, il existe de nombreuses nuances qui ne peuvent √™tre consid√©r√©es que la vision par ordinateur fonctionne mieux sur ces syst√®mes que sur les humains.  √Ä bien des √©gards, le concours ILSVRC est une t√¢che tr√®s limit√©e - les r√©sultats d'une recherche d'images sur un r√©seau ouvert ne correspondront pas n√©cessairement √† ce que le programme rencontrera dans une t√¢che pratique.  Et, bien s√ªr, le crit√®re ¬´l'une des cinq meilleures notes¬ª est assez artificiel.  Nous avons encore un long chemin √† parcourir pour r√©soudre le probl√®me de la reconnaissance d'image, sans parler de la t√¢che plus g√©n√©rale de la vision par ordinateur.  Mais c'est quand m√™me tr√®s cool de voir les progr√®s accomplis dans la r√©solution d'une t√¢che aussi difficile en quelques ann√©es seulement. <br><br><h3>  Autres t√¢ches </h3><br>  Je me suis concentr√© sur ImageNet, mais il existe de nombreux autres projets utilisant NS pour la reconnaissance d'images.  Permettez-moi de d√©crire bri√®vement quelques r√©sultats int√©ressants obtenus r√©cemment, juste pour avoir une id√©e du travail moderne. <br><br>  Un <a href="">ensemble de r√©sultats</a> pratiques inspirants a √©t√© obtenu par une √©quipe de Google, qui a appliqu√© GSS √† la t√¢che de reconnaissance des plaques d'adresse dans Google Street View.  Dans leur travail, ils rapportent comment ils ont d√©couvert et reconnu automatiquement pr√®s de 100 millions de plaques d'adresse avec une pr√©cision comparable au travail humain.  Et leur syst√®me est rapide: il a pu d√©crypter les donn√©es de toutes les images de Google Street View en France en moins d'une heure!  Ils √©crivent: "L'obtention de ce nouvel ensemble de donn√©es a consid√©rablement am√©lior√© la qualit√© du g√©ocodage de Google Maps dans plusieurs pays, en particulier l√† o√π il n'y avait pas d'autres sources de g√©ocodage."  Ensuite, ils font une d√©claration plus g√©n√©rale: "Nous pensons que, gr√¢ce √† ce mod√®le, nous avons r√©solu le probl√®me de la reconnaissance optique des s√©quences courtes d'une mani√®re qui est applicable dans de nombreuses applications pratiques." <br><br>  J'ai peut-√™tre donn√© l'impression d'un d√©fil√© de r√©sultats victorieux et inspirants.  Bien entendu, les rapports les plus int√©ressants concernent des choses fondamentales qui ne sont pas encore claires pour nous.  Par exemple, dans les <a href="">travaux de 2013, il a</a> √©t√© d√©montr√© que l'Assembl√©e nationale a, en fait, des angles morts.  Jetez un ≈ìil aux images ci-dessous.  √Ä gauche, l'image d'ImageNet, que le r√©seau de chercheurs a correctement class√©e.  √Ä droite, une image l√©g√®rement modifi√©e (au milieu les diff√©rences sont affich√©es), que le r√©seau n'√©tait plus en mesure de reconna√Ætre correctement.  Et les auteurs ont constat√© que de tels changements "contradictoires" peuvent √™tre s√©lectionn√©s pour n'importe quelle image de la base de donn√©es, et pas seulement pour l'√©lite. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ddf/c77/f29/ddfc77f2996c1fb482fa448f1384d08a.jpg"><br><br>  R√©sultat d√©sagr√©able.  Nous avons utilis√© un r√©seau bas√© sur le m√™me code que le r√©seau KSH - c'est-√†-dire que c'est un tel r√©seau qui est de plus en plus utilis√©.  Et bien que ces NS calculent, en principe, des fonctions continues, des r√©sultats similaires sugg√®rent qu'ils calculent probablement des fonctions presque discr√®tes.  Pire, ils se r√©v√®lent discrets d'une mani√®re qui viole notre notion intuitive de comportement intelligent.  C'est un probl√®me.  De plus, on ne sait pas tr√®s bien ce qui conduit exactement √† la discr√©tion, quel est le probl√®me: dans la fonction de perte?  Quelles fonctions d'activation utiliser?  En architecture r√©seau?  Dans autre chose?  Nous ne le savons pas. <br><br>  Mais ces r√©sultats ne sont pas aussi mauvais qu'ils le semblent.  Bien que de tels changements contradictoires soient assez courants, il est peu probable qu'ils se retrouvent dans la pratique.  Comme indiqu√© dans le travail: <br><blockquote>  L‚Äôexistence de n√©gatifs contradictoires contredit la capacit√© du r√©seau √† atteindre une g√©n√©ralisabilit√© √©lev√©e.  En effet, si le r√©seau pouvait bien se g√©n√©raliser, comment pourrait-il √™tre tromp√© par de tels n√©gatifs contradictoires qui ne se distinguent pas des exemples ordinaires?  L'explication est qu'un ensemble de n√©gatifs comp√©titifs a une probabilit√© extr√™mement faible, et donc n'est pas observ√© (ou presque pas observ√©) dans l'ensemble de donn√©es de formation, cependant, il a une densit√© √©lev√©e (approximativement comme des nombres rationnels), et donc il peut √™tre trouv√© dans presque tous les cas . </blockquote><br><br>  N√©anmoins, il est d√©sagr√©able que nous comprenions si mal le travail de l'Assembl√©e nationale que ce r√©sultat ait √©t√© d√©couvert r√©cemment.  Bien s√ªr, le principal avantage de ces r√©sultats sera qu'ils ont stimul√© l'apparition de travaux ult√©rieurs sur ce sujet.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail r√©cent en 2014 a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> montr√© qu'il est possible pour un r√©seau form√© de cr√©er des images qui ressemblent √† du bruit blanc pour une personne, et le r√©seau les classera dans des cat√©gories bien connues avec un haut degr√© de confiance. Ceci est une autre d√©monstration que nous avons encore beaucoup √† comprendre dans le travail de la NS et dans son utilisation pour la reconnaissance d'image.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais, malgr√© la pr√©sence de r√©sultats similaires, l'image globale est inspirante. </font><font style="vertical-align: inherit;">Nous constatons des progr√®s rapides dans la r√©alisation de tests extr√™mement complexes tels que ImageNet. </font><font style="vertical-align: inherit;">Nous constatons √©galement des progr√®s rapides dans la r√©solution des probl√®mes du monde r√©el, tels que la reconnaissance des plaques d'adresse dans StreetView. </font><font style="vertical-align: inherit;">Mais, malgr√© l'inspiration, il ne suffit pas d'observer les am√©liorations des performances des tests de vitesse ou m√™me des t√¢ches du monde r√©el. </font><font style="vertical-align: inherit;">Il y a des ph√©nom√®nes fondamentaux, dont nous comprenons encore mal l'essence, par exemple, l'existence d'images concurrentielles. </font><font style="vertical-align: inherit;">Et alors que de tels probl√®mes fondamentaux continuent de s'ouvrir (sans parler de les r√©soudre), il serait pr√©matur√© de parler d'approcher la solution du probl√®me de reconnaissance d'image. </font><font style="vertical-align: inherit;">Mais en m√™me temps, ces probl√®mes sont d'excellentes incitations √† poursuivre le travail.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Autres approches des r√©seaux de neurones profonds </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans ce livre, nous nous sommes concentr√©s sur une t√¢che: la classification des nombres MNIST. Une excellente t√¢che qui nous a fait comprendre beaucoup d'id√©es efficaces: descente de gradient stochastique, r√©tropropagation, r√©seaux convolutionnels, r√©gularisation, etc. Cependant, c'est aussi une t√¢che assez √©troite. Apr√®s avoir lu la litt√©rature sur les r√©seaux de neurones, vous rencontrerez de nombreuses id√©es que nous n'avons pas discut√©es: NS r√©currents, machines Boltzmann, mod√®les g√©n√©ratifs, transfert de formation, apprentissage renforc√©, etc., etc. Les r√©seaux de neurones sont un vaste domaine. Cependant, de nombreuses id√©es importantes sont des variantes de ces id√©es dont nous avons d√©j√† discut√©, et elles sont assez faciles √† comprendre. Dans cette section, j'ouvrirai l√©g√®rement le rideau sur ces vastes √©tendues. Leur discussion ne serait pas d√©taill√©e et compl√®te - cela gonflerait extr√™mement le livre. Ce sera impressionniste,une tentative de montrer la richesse conceptuelle de ce domaine, et de relier certains concepts √† ceux que nous avons d√©j√† vus. Dans le texte, je donnerai plusieurs r√©f√©rences √† d'autres sources, quant au mat√©riel de formation continue. Bien s√ªr, beaucoup d'entre eux seront bient√¥t supplant√©s par d'autres, et vous voudrez peut-√™tre chercher de la litt√©rature plus r√©cente. N√©anmoins, je pense que de nombreuses id√©es de base resteront int√©ressantes pendant longtemps.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©seaux de neurones r√©currents (RNS) </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans les r√©seaux de propagation directe que nous avons utilis√©s, il y a une entr√©e qui d√©termine compl√®tement l'activation de tous les neurones dans les couches suivantes. </font><font style="vertical-align: inherit;">C'est une image tr√®s statique: tout dans le r√©seau est fixe et a un caract√®re cristallin fig√©. </font><font style="vertical-align: inherit;">Mais supposons que nous permettons aux √©l√©ments du r√©seau de changer dynamiquement. </font><font style="vertical-align: inherit;">Par exemple, le comportement des neurones cach√©s peut √™tre d√©termin√© non seulement par des activations dans les couches pr√©c√©dentes, mais aussi par des activations qui se sont produites plus t√¥t dans le temps. </font><font style="vertical-align: inherit;">L'activation d'un neurone peut √™tre partiellement d√©termin√©e par son activation ant√©rieure. </font><font style="vertical-align: inherit;">Dans les r√©seaux √† distribution directe, cela ne se produit clairement pas. </font><font style="vertical-align: inherit;">Ou, peut-√™tre, l'activation des neurones cach√©s et de sortie sera d√©termin√©e non seulement par l'entr√©e actuelle du r√©seau, mais aussi par les pr√©c√©dentes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les r√©seaux de neurones avec ce type de comportement variant dans le temps sont appel√©s r√©seaux de neurones r√©currents, ou RNS. Il existe de nombreuses fa√ßons de formaliser math√©matiquement la description informelle du paragraphe pr√©c√©dent. Vous pouvez vous en faire une id√©e en lisant </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'article Wikip√©dia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Au moment de la r√©daction, dans la version anglaise de l'article, au moins 13 mod√®les diff√©rents sont d√©crits [au moment de la traduction en 2019, d√©j√† 18 / env.</font></font> trad.].<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais, si nous mettons de c√¥t√© les d√©tails math√©matiques, l'id√©e g√©n√©rale du RNS est la pr√©sence de changements dynamiques dans le r√©seau qui se produisent au fil du temps. Et, sans surprise, ils sont particuli√®rement utiles pour analyser des donn√©es ou des processus qui changent au fil du temps. Ces donn√©es et processus apparaissent naturellement dans des t√¢ches telles que l'analyse de la parole ou le langage naturel. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'une des fa√ßons actuelles d'utiliser RNS est d'int√©grer plus √©troitement les r√©seaux de neurones avec les m√©thodes traditionnelles de repr√©sentation des algorithmes, avec des concepts tels qu'une machine de Turing et des langages de programmation courants. En </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail depuis 2014</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNS a √©t√© d√©velopp√©, capable d'accepter une description lettre par lettre d'un programme python tr√®s simple et de pr√©dire le r√©sultat de son travail. De mani√®re informelle, le r√©seau apprend √† ¬´comprendre¬ª certains programmes python. </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le deuxi√®me travail de 2014 a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> utilis√© le RNS comme point de d√©part pour le d√©veloppement de la neuromachine de Turing (BDC). Il s'agit d'un ordinateur universel, dont toute la structure peut √™tre entra√Æn√©e par descente de gradient. Ils ont form√© leur BDC √† cr√©er des algorithmes pour plusieurs t√¢ches simples, telles que le tri ou la copie.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ce sont bien s√ªr des mod√®les de jouets tr√®s simples. Apprendre √† ex√©cuter un programme en python comme print (398345 + 42598) ne fait pas d'un r√©seau neuronal un interpr√®te √† part enti√®re de la langue! On ne sait pas √† quel point ces id√©es seront plus fortes. N√©anmoins, les r√©sultats sont assez int√©ressants. Historiquement, les r√©seaux de neurones ont fait un bon travail de reconnaissance des mod√®les qui sont tomb√©s sur des approches algorithmiques conventionnelles. Et vice versa, les approches algorithmiques classiques font un bon travail de r√©solution de probl√®mes complexes pour NS. Aujourd'hui, personne n'essaye d'impl√©menter un serveur web ou une base de donn√©es bas√©e sur NS! Il serait formidable de d√©velopper des mod√®les int√©gr√©s qui int√®grent les points forts des approches NS et algorithmiques traditionnelles. Le RNS et les id√©es qui s'en inspirent peuvent nous aider √† y parvenir.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ces derni√®res ann√©es, le RNS a √©t√© utilis√© pour r√©soudre de nombreux autres probl√®mes. Ils √©taient particuli√®rement utiles dans la reconnaissance vocale. Les approches bas√©es sur le RNS </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√©tablissent des records</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de qualit√© de reconnaissance des phon√®mes. Ils ont √©galement √©t√© </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">utilis√©s pour d√©velopper</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> des mod√®les am√©lior√©s du langage utilis√© par les gens. Des mod√®les de langage am√©lior√©s aident √† reconna√Ætre les ambigu√Øt√©s de la parole qui semblent similaires. Un bon mod√®le de langage peut nous dire que l'expression ¬´en avant vers l'infini¬ª est beaucoup plus probable que l'expression ¬´en avant sans membre¬ª, m√™me si elles semblent similaires. RNS a √©t√© utilis√© pour obtenir des r√©sultats record dans certains tests de langue.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ce travail fait partie de l'utilisation plus large de NS de toutes sortes, pas seulement RNS, pour r√©soudre le probl√®me de la reconnaissance vocale. Par exemple, une approche bas√©e sur GNS a montr√© d' </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">excellents r√©sultats</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans la reconnaissance de la parole continue avec un vocabulaire important. Un autre </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">syst√®me</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bas√© sur GNS </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">est </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">impl√©ment√©</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans le syst√®me d'exploitation Android de Google.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'ai parl√© un peu de ce dont les RNC sont capables, mais je n'ai pas expliqu√© comment ils fonctionnent. </font><font style="vertical-align: inherit;">Vous ne serez peut-√™tre pas surpris d'apprendre que bon nombre des id√©es du monde des r√©seaux de distribution directe peuvent √©galement √™tre utilis√©es dans le RNS. </font><font style="vertical-align: inherit;">En particulier, nous pouvons entra√Æner le RNS en modifiant la descente de gradient et la propagation arri√®re dans le front. </font><font style="vertical-align: inherit;">De nombreuses autres id√©es utilis√©es dans les r√©seaux de distribution directe, depuis les techniques de r√©gularisation jusqu'√† la convolution, l'activation et les fonctions de co√ªt, seront √©galement utiles. </font><font style="vertical-align: inherit;">De plus, bon nombre des id√©es que nous avons d√©velopp√©es dans le cadre du livre peuvent √™tre adapt√©es pour √™tre utilis√©es dans le RNS.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modules de m√©moire √† court terme √† long terme (DCT) </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'un des probl√®mes du RNS est que les premiers mod√®les √©taient tr√®s difficiles √† entra√Æner, plus compliqu√©s que m√™me le GNS. La raison en √©tait les probl√®mes du gradient instable, dont nous avons discut√© au chapitre 5. Rappelons que la manifestation habituelle de ce probl√®me √©tait que le gradient diminue tout le temps lors de la propagation √† travers les couches dans la direction oppos√©e. Cela ralentit extr√™mement l'apprentissage des premi√®res couches. Dans RNS, ce probl√®me devient encore pire, car les gradients se propagent non seulement dans la direction oppos√©e le long des couches, mais √©galement dans la direction oppos√©e dans le temps. Si le r√©seau fonctionne pendant une p√©riode assez longue, le gradient peut devenir extr√™mement instable et sur sa base sera tr√®s difficile √† apprendre. Heureusement, une id√©e connue sous le nom de modules de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m√©moire √† court terme √† long terme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (DCT) </font><font style="vertical-align: inherit;">peut √™tre incluse dans le RNS </font><font style="vertical-align: inherit;">. Pour la premi√®re fois, les modules introduits</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hochreiter et Schmidguber en 1997</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , sp√©cifiquement pour aider √† r√©soudre le probl√®me d'un gradient instable. </font><font style="vertical-align: inherit;">Les DCT facilitent l'obtention de bons r√©sultats dans l'apprentissage des RNS, et de nombreux travaux r√©cents (y compris ceux que j'ai d√©j√† r√©f√©renc√©s) utilisent des DCT ou des id√©es similaires.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©seaux de confiance profonde, mod√®les g√©n√©ratifs et machines Boltzmann </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De nos jours, l'int√©r√™t pour le deep learning a pris un second souffle en 2006, apr√®s la publication d'ouvrages ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) expliquant comment enseigner un type particulier de NS appel√© Deep Trust Network (GDS). </font><font style="vertical-align: inherit;">Le GDS a influenc√© le domaine de la recherche pendant plusieurs ann√©es, mais leur popularit√© a commenc√© √† d√©cliner et les r√©seaux de distribution directe et les SN r√©currents sont devenus √† la mode. </font><font style="vertical-align: inherit;">Malgr√© cela, certaines des propri√©t√©s de GDS les rendent tr√®s int√©ressantes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Premi√®rement, les GDS sont un exemple de mod√®le g√©n√©ratif. Dans un r√©seau de distribution directe, nous sp√©cifions les activations d'entr√©e, et elles d√©terminent l'activation des neurones caract√©ristiques plus bas sur le r√©seau. Le mod√®le g√©n√©ratif peut √™tre utilis√© d'une mani√®re similaire, mais vous pouvez y d√©finir des valeurs de neurones, puis ex√©cuter le r√©seau ¬´dans la direction oppos√©e¬ª, g√©n√©rant des valeurs d'activation d'entr√©e. Plus pr√©cis√©ment, un GDS form√© aux images de chiffres manuscrits peut lui-m√™me g√©n√©rer des images similaires aux chiffres manuscrits (potentiellement et apr√®s certaines actions). En d'autres termes, le GDM dans un sens peut apprendre √† √©crire. En ce sens, les mod√®les g√©n√©ratifs sont similaires au cerveau humain: ils peuvent non seulement lire des nombres, mais aussi les √©crire. </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">Le</font></a><font style="vertical-align: inherit;"> c√©l√®bre </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dicton de </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jeffrey Hinton</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indique que pour la reconnaissance des formes, vous devez d'abord apprendre √† g√©n√©rer des images. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deuxi√®mement, ils sont capables d' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">apprendre sans enseignant</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et presque sans enseignant. Par exemple, lors de la formation sur les images, les GDS peuvent apprendre des signes qui sont utiles pour comprendre d'autres images, m√™me s'il n'y avait aucune marque sur les images de la formation. La capacit√© d'apprendre sans professeur est extr√™mement int√©ressante √† la fois d'un point de vue scientifique fondamental et d'un point de vue pratique - si l'on peut le faire fonctionner suffisamment bien.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Compte tenu de tous ces points attrayants du GDS en tant que mod√®les d'apprentissage en profondeur, pourquoi leur popularit√© a-t-elle diminu√©? En partie d√ª au fait que d'autres mod√®les, tels que la distribution directe et les r√©seaux r√©currents, ont obtenu des r√©sultats √©tonnants, en particulier des perc√©es dans les domaines de la reconnaissance d'image et de la parole. Il n'est pas surprenant que ces mod√®les aient re√ßu une telle attention, et tr√®s m√©rit√©s. Cependant, une conclusion d√©sagr√©able en d√©coule. Le march√© des id√©es fonctionne souvent selon le sch√©ma ¬´le gagnant obtient tout¬ª, et presque toute l'attention est port√©e √† ce qui est le plus √† la mode dans ce domaine actuellement. Il peut √™tre extr√™mement difficile pour les gens de travailler sur des id√©es actuellement impopulaires, m√™me s'il est √©vident qu'elles peuvent pr√©senter un int√©r√™t √† long terme. Mon opinion personnelle est que le GDS et les autres mod√®les g√©n√©ratifs m√©ritent plus d'attention qu'ils n'en re√ßoivent.Je ne serai pas surpris si le GDM ou un mod√®le similaire d√©passe jamais les mod√®les populaires d'aujourd'hui. Lisez</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cet article est</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour une introduction au domaine du GDM. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cet article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> peut √©galement √™tre utile </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Il ne s'agit pas enti√®rement de GDM, mais il a beaucoup de choses utiles sur les machines Boltzmann limit√©es, un composant cl√© de GDM.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Autres id√©es </font></font></h3><br>  Que se passe-t-il d'autre dans le domaine de l'Assembl√©e nationale et de la protection civile?  Une √©norme quantit√© de travail int√©ressant.  Parmi les domaines de recherche actifs figure l'utilisation de NS pour le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">traitement</a> du <a href="">langage</a> naturel, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la traduction automatique</a> et des applications plus inattendues, par exemple l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">informatique musicale</a> .  Il existe de nombreux autres domaines.  Dans de nombreux cas, apr√®s avoir lu ce livre, vous serez en mesure de comprendre les travaux r√©cents, m√™me si, bien s√ªr, vous devrez peut-√™tre combler certaines lacunes dans les connaissances. <br><br>  Je terminerai cette section par une mention d'un travail particuli√®rement int√©ressant.  Elle combine des r√©seaux convolutionnels profonds avec une technique appel√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage par</a> renforcement pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprendre √† jouer √† des jeux vid√©o</a> (et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un autre article</a> √† ce sujet).  L'id√©e est d'utiliser un r√©seau convolutionnel pour simplifier les donn√©es de pixels de l'√©cran de jeu, de les transformer en un ensemble d'attributs plus simple qui peut ensuite √™tre utilis√© pour prendre des d√©cisions sur d'autres actions: ¬´aller √† gauche¬ª, ¬´aller √† droite¬ª, ¬´tirer¬ª, et etc.  Particuli√®rement int√©ressant est qu'un r√©seau a assez bien appris √† jouer √† sept jeux vid√©o classiques diff√©rents, devant des experts dans trois d'entre eux.  Bien s√ªr, cela ressemble √† une astuce, et le travail a √©t√© activement annonc√© sous le titre "Jouer √† des jeux Atari avec apprentissage par renforcement".  Cependant, derri√®re un brillant superficiel, il convient de consid√©rer le fait que le syst√®me prend des donn√©es de pixels brutes - il ne conna√Æt m√™me pas les r√®gles du jeu - et sur leur base est form√© pour prendre des d√©cisions de bonne qualit√© dans plusieurs situations tr√®s diff√©rentes et tr√®s comp√©titives, chacune ayant son propre ensemble complexe de r√®gles.  Assez bien. <br><br><h2>  L'avenir des r√©seaux de neurones </h2><br><h3>  Interfaces d'intention utilisateur </h3><br>  Dans une vieille blague, un professeur impatient dit √† un √©tudiant confus: "N'√©coutez pas mes mots, √©coutez ce que je veux dire."  Historiquement, les ordinateurs ne comprenaient souvent pas, comme un √©l√®ve confus, ce que signifie un utilisateur.  Cependant, la situation √©volue.  Je me souviens encore de la premi√®re fois o√π j'ai √©t√© surpris lorsque j'ai √©crit par erreur une demande √† Google, et le moteur de recherche m'a dit: "Vouliez-vous dire [demande correcte]?"  Le directeur de Google, Larry Page, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">a d√©crit le</a> moteur de recherche parfait comme un syst√®me qui comprend exactement ce que signifient vos requ√™tes et vous donne exactement ce que vous voulez. <br><br>  C'est l'id√©e d'une interface bas√©e sur l'intention de l'utilisateur.  Dans ce document, au lieu de r√©pondre aux demandes litt√©rales des utilisateurs, le moteur de recherche utilisera le MO pour prendre une vague demande des utilisateurs, comprendre exactement ce que cela signifie et agir sur cette base. <br><br>  L'id√©e d'une interface bas√©e sur l'intention de l'utilisateur peut √™tre appliqu√©e plus largement que simplement dans la recherche.  Au cours des prochaines d√©cennies, des milliers d'entreprises cr√©eront des produits dans lesquels MO sera utilis√© pour les interfaces utilisateur, se r√©f√©rant calmement aux actions inexactes des utilisateurs et devinant leurs v√©ritables intentions.  Nous voyons d√©j√† les premiers exemples de telles interfaces bas√©es sur l'intention: Apple Siri;  Wolfram Alpha;  IBM Watson  des syst√®mes qui marquent automatiquement les photos et les vid√©os, etc. <br><br>  La plupart d'entre eux √©choueront.  Le d√©veloppement d'interfaces est une chose compliqu√©e, et je soup√ßonne qu'au lieu d'inspirer des interfaces, de nombreuses entreprises cr√©eront des interfaces sans vie sur la base de MO.  Le meilleur MO au monde ne vous aidera pas si votre interface est nulle.  Cependant, certains produits r√©ussiront.  Au fil du temps, cela entra√Ænera un changement s√©rieux dans notre relation avec les ordinateurs.  Il n'y a pas si longtemps, par exemple, en 2005, les utilisateurs tenaient pour acquis que l'interaction avec les ordinateurs n√©cessite une grande pr√©cision.  La nature litt√©rale de l'ordinateur a servi √† r√©pandre l'id√©e que les ordinateurs sont tr√®s litt√©raux;  le seul point-virgule oubli√© pourrait compl√®tement changer la nature de l'interaction avec l'ordinateur.  Mais je crois qu'au cours des prochaines d√©cennies, nous d√©velopperons plusieurs interfaces r√©ussies bas√©es sur l'intention de l'utilisateur, et cela changera radicalement nos attentes lorsque nous travaillerons avec des ordinateurs. <br><br><h3>  Apprentissage automatique, science des donn√©es et cercle immacul√© de l'innovation </h3><br>  Bien s√ªr, MO n'est pas seulement utilis√© pour cr√©er des interfaces bas√©es sur l'intention de l'utilisateur.  Une autre application int√©ressante de MO est la science des donn√©es, o√π elle est utilis√©e pour rechercher des ¬´inconnues connues¬ª cach√©es dans les donn√©es obtenues.  C'est d√©j√† un sujet √† la mode, sur lequel de nombreux articles ont √©t√© √©crits, donc je ne m'√©tendrai pas dessus pendant longtemps.  Je veux mentionner une cons√©quence de cette mode, qui n'est pas souvent not√©e: √† long terme, il est possible que la plus grande perc√©e dans la r√©gion de Moscou ne soit pas une seule perc√©e conceptuelle.  La plus grande avanc√©e sera que la recherche dans le domaine des OM deviendra rentable gr√¢ce √† l'utilisation de donn√©es dans les domaines scientifiques et autres.  Si une entreprise peut investir un dollar dans la recherche sur les MO et obtenir un dollar et dix cents de revenus assez rapidement, alors beaucoup d'argent sera vers√© dans la r√©gion du MO.  En d'autres termes, MO est le moteur qui nous conduit √† l'√©mergence de plusieurs grands march√©s et domaines de croissance technologique.  En cons√©quence, de grandes √©quipes de personnes expertes dans ce domaine appara√Ætront et auront acc√®s √† des ressources incroyables.  Cela fera avancer l'OM encore plus loin, cr√©era encore plus de march√©s et d'opportunit√©s, ce qui sera le cercle immacul√© de l'innovation. <br><br><h3>  Le r√¥le des r√©seaux de neurones et du deep learning </h3><br>  J'ai d√©crit MO en termes g√©n√©raux comme un moyen de cr√©er de nouvelles opportunit√©s de d√©veloppement technologique.  Quel sera le r√¥le sp√©cifique de l'Assembl√©e nationale et de la soci√©t√© civile dans tout cela? <br><br>  Pour r√©pondre √† la question, il est utile de se tourner vers l'histoire.  Dans les ann√©es 1980, il y a eu un r√©veil joyeux actif et un optimisme associ√© aux r√©seaux de neurones, en particulier apr√®s la popularisation de la propagation arri√®re.  Mais la reprise s'est calm√©e et dans les ann√©es 1990, le b√¢ton MO a √©t√© transf√©r√© √† d'autres technologies, par exemple la m√©thode du vecteur de support.  Aujourd'hui, l'Assembl√©e nationale est √† nouveau sur le cheval, √©tablissant toutes sortes de records et d√©passant de nombreux rivaux dans divers probl√®mes.  Mais qui garantit que demain une nouvelle approche ne sera pas d√©velopp√©e qui √©clipsera √† nouveau l'AN?  Ou, peut-√™tre, les progr√®s dans le domaine de l'Assembl√©e nationale commenceront-ils √† ralentir et rien ne les remplacera? <br><br>  Par cons√©quent, il est beaucoup plus facile de penser √† l'avenir du minist√®re de la D√©fense dans son ensemble que sp√©cifiquement √† l'Assembl√©e nationale.  Une partie du probl√®me est que nous comprenons tr√®s mal l'Assembl√©e nationale.  Pourquoi NS est-il si bon pour compiler des informations?  Comment √©vitent-ils si bien la reconversion, compte tenu du grand nombre d'options?  Pourquoi la descente de gradient stochastique fonctionne-t-elle si bien?  Dans quelle mesure NS fonctionnera-t-il lors de la mise √† l'√©chelle des ensembles de donn√©es?  Par exemple, si nous √©largissons 10 fois la base d'ImageNet, les performances du NS s'am√©lioreront-elles plus ou moins que l'efficacit√© des autres technologies MO?  Toutes ces questions sont simples et fondamentales.  Et jusqu'√† pr√©sent, nous avons une tr√®s mauvaise compr√©hension des r√©ponses √† ces questions.  √Ä cet √©gard, il est difficile de dire quel r√¥le l'Assembl√©e nationale jouera dans l'avenir de la r√©gion de Moscou. <br><br>  Je ferai une pr√©diction: je pense que GO n'ira nulle part.  La capacit√© d'√©tudier les hi√©rarchies de concepts, de construire diff√©rentes couches d'abstractions est apparemment fondamentale pour la connaissance du monde.  Cela ne signifie pas que les r√©seaux GO de demain ne seront pas radicalement diff√©rents de ceux d'aujourd'hui.  Nous pouvons rencontrer des changements majeurs dans leurs composants, architectures ou algorithmes d'apprentissage.  Ces changements peuvent s'av√©rer assez dramatiques pour que nous cessions de consid√©rer les syst√®mes r√©sultants comme des r√©seaux de neurones.  Cependant, ils continueront de s'engager dans la protection civile. <br><br><h3>  NS et GO vont-ils bient√¥t conduire √† l'apparition de l'intelligence artificielle? </h3><br>  Dans ce livre, nous nous sommes concentr√©s sur l'utilisation de NS pour r√©soudre des probl√®mes sp√©cifiques, par exemple, la classification d'images.  D√©veloppons nos requ√™tes: qu'en est-il des ordinateurs √† usage g√©n√©ral?  L'Assembl√©e nationale et la soci√©t√© civile peuvent-elles nous aider √† r√©soudre le probl√®me de la cr√©ation d'une IA √† usage g√©n√©ral?  Et si oui, compte tenu de la rapidit√© des progr√®s dans le domaine de la protection civile, verrons-nous l'√©mergence de l'IA dans un avenir proche? <br><br>  Une r√©ponse d√©taill√©e √† une telle question n√©cessiterait un livre s√©par√©.  Au lieu de cela, permettez-moi de vous proposer une observation bas√©e sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la loi de Conway</a> : <br><blockquote>  Les organisations qui con√ßoivent des syst√®mes se limitent √† une conception qui copie la structure de communication de cette organisation. </blockquote><br><br>  C'est-√†-dire, par exemple, que la loi de Conway stipule que la configuration du Boeing 747 refl√©tera la structure √©largie de Boeing et de ses sous-traitants au moment o√π le mod√®le 747 a √©t√© d√©velopp√©. Ou un autre exemple simple et concret: consid√©rons une entreprise d√©veloppant des logiciels complexes.  Si le panneau de commande du logiciel doit √™tre connect√© √† l'algorithme MO, le concepteur du panneau doit communiquer avec l'expert MO de l'entreprise.  La loi de Conway officialise simplement cette observation. <br><br>  Pour la premi√®re fois quand ils ont entendu la loi de Conway, beaucoup de gens disent: "N'est-ce pas une preuve banale?" Ou "Est-ce le cas?"  Je commencerai par une remarque sur son infid√©lit√©.  R√©fl√©chissons: comment la comptabilit√© de Boeing se refl√®te-t-elle dans le mod√®le 747?  Et le service de nettoyage?  Un personnel nourricier?  La r√©ponse est que ces parties de l'organisation n'apparaissent tr√®s probablement nulle part ailleurs dans le sch√©ma 747.  Par cons√©quent, vous devez comprendre que la loi de Conway ne s'applique qu'aux parties de l'organisation directement impliqu√©es dans la conception et l'ing√©nierie. <br><br>  Qu'en est-il de la remarque sur la banalit√© et les preuves?  Peut-√™tre en est-il ainsi, mais je ne le pense pas, car les organisations s‚Äôefforcent souvent de rejeter la loi de Conway.  Les √©quipes d√©veloppant de nouveaux produits sont souvent gonfl√©es en raison du nombre excessif d'employ√©s ou, √† l'inverse, il leur manque une personne poss√©dant des connaissances critiques.  Pensez √† tous les produits aux fonctionnalit√©s inutiles et compliqu√©es.  Ou pensez √† des produits avec des d√©fauts √©vidents - par exemple, avec une interface utilisateur terrible.  Dans les deux classes de programmes, des probl√®mes surviennent souvent en raison d'un d√©calage entre l'√©quipe n√©cessaire pour sortir un bon produit et l'√©quipe qui s'est vraiment r√©unie.  La loi de Conway peut √™tre √©vidente, mais cela ne signifie pas que les gens ne peuvent pas l‚Äôignorer r√©guli√®rement. <br><br>  La loi de Conway est applicable √† la conception et √† la cr√©ation de syst√®mes dans les cas o√π, d√®s le d√©but, nous imaginons les √©l√©ments constitutifs du produit et comment les fabriquer.  Elle ne peut pas √™tre appliqu√©e directement au d√©veloppement de l'IA, car l'IA n'est pas (encore) une telle t√¢che: nous ne savons pas en quelles parties elle se compose.  Nous ne savons m√™me pas quelles questions de base vous pouvez poser.  En d'autres termes, pour l'instant, l'IA est plus un probl√®me de science que d'ing√©nieurs.  Imaginez que vous devez commencer √† d√©velopper le 747th sans rien savoir des moteurs √† r√©action ou des principes de l'a√©rodynamique.  Vous ne sauriez pas quels experts engager dans votre organisation.  Comme l‚Äôa √©crit Werner von Braun, "la recherche fondamentale est ce que je fais quand je ne sais pas ce que je fais."  Existe-t-il une version de la loi de Conway qui s‚Äôapplique aux t√¢ches plus li√©es √† la science qu‚Äôaux ing√©nieurs? <br><br>  Pour trouver la r√©ponse √† cette question, rappelons l'histoire de la m√©decine.  Au d√©but, la m√©decine √©tait le domaine de praticiens, comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Galen</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hippocrate</a> , qui √©tudiaient tout le corps humain.  Mais avec la croissance du volume de nos connaissances, j'ai d√ª me sp√©cialiser.  Nous avons d√©couvert de nombreuses id√©es profondes - rappeler la th√©orie microbienne des maladies, ou comprendre le principe du fonctionnement des anticorps, ou le fait que le c≈ìur, les poumons, les veines et les art√®res forment le syst√®me cardiovasculaire.  Ces id√©es profondes ont jet√© les bases de disciplines plus √©troites, telles que l'√©pid√©miologie, l'immunologie et l'accumulation de zones de chevauchement li√©es au syst√®me cardiovasculaire.  C'est ainsi que la structure de nos connaissances a form√© la structure sociale de la m√©decine.  Ceci est particuli√®rement visible dans le cas de l'immunologie: l'id√©e de l'existence d'un syst√®me immunitaire digne d'une √©tude distincte √©tait tr√®s anodine.  Nous avons donc tout un domaine de la m√©decine - avec des sp√©cialistes, des conf√©rences, des prix, etc. - organis√© autour de quelque chose qui n'est pas seulement invisible, mais peut-√™tre m√™me pas s√©par√©. <br><br>  Un tel d√©veloppement d'√©v√©nements s'est souvent r√©p√©t√© dans de nombreuses disciplines scientifiques √©tablies: non seulement en m√©decine, mais aussi en physique, math√©matiques, chimie et autres.  Les r√©gions naissent monolithiques, n'ayant que quelques id√©es profondes en stock.  Les premiers experts sont capables de les couvrir tous.  Mais au fil du temps, la solidit√© change.  Nous d√©couvrons beaucoup de nouvelles id√©es profondes, et il y en a trop pour que quelqu'un puisse vraiment les ma√Ætriser toutes.  En cons√©quence, la structure sociale de la r√©gion est en cours de r√©organisation et de division, se concentrant autour de ces id√©es.  Au lieu d'un monolithe, nous avons des champs divis√©s par des champs divis√©s par des champs - une structure sociale complexe et r√©cursive qui se r√©f√®re √† elle-m√™me, dont l'organisation refl√®te les liens entre les id√©es les plus profondes.  C'est ainsi que la structure de nos connaissances forme l'organisation sociale de la science.  Cependant, cette forme sociale √† son tour limite et aide √† d√©terminer ce que nous pouvons d√©tecter.  Ceci est l'analogue scientifique de la loi de Conway. <br><br>  Mais qu'est-ce que tout cela a √† voir avec l'apprentissage en profondeur ou l'IA? <br><br>  Eh bien, depuis les premiers jours du d√©veloppement de l'IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">, il y a eu un d√©bat sur le fait</a> que tout ira "pas trop compliqu√©, gr√¢ce √† notre super-arme", ou "la super-arme ne suffira pas".  L'apprentissage en profondeur est le dernier exemple d'une super-arme qui a √©t√© utilis√©e dans les conflits que j'ai vus.  Dans les premi√®res versions de ces conflits, la logique √©tait utilis√©e, ou Prolog, ou des syst√®mes experts, ou une autre technologie, qui √©tait alors la plus puissante.  Le probl√®me avec de tels diff√©rends est qu'ils ne vous donnent pas la possibilit√© de dire exactement √† quel point les candidats √† la super-arme seront puissants.  Bien s√ªr, nous venons de passer un chapitre entier √† examiner les preuves que la d√©fense civile peut r√©soudre des probl√®mes extr√™mement complexes.  Cela semble d√©finitivement tr√®s int√©ressant et prometteur.  Mais ce fut le cas avec des syst√®mes tels que Prolog ou Eurisko, ou avec des syst√®mes experts.  Par cons√©quent, seul le fait qu'un ensemble d'id√©es semble prometteur ne signifie rien de sp√©cial.  Comment savons-nous que GO est en r√©alit√© diff√©rent de ces premi√®res id√©es?  Existe-t-il un moyen de mesurer la puissance et la promesse d'un ensemble d'id√©es?  Il d√©coule de la loi de Conway que nous pouvons utiliser la complexit√© de la structure sociale associ√©e √† ces id√©es comme une mesure grossi√®re et heuristique. <br><br>  Par cons√©quent, nous avons deux questions.  Premi√®rement, quelle est la puissance de l'ensemble des id√©es li√©es √† la soci√©t√© civile selon cette m√©trique de complexit√© sociale?  Deuxi√®mement, √† quel point une th√©orie doit-elle √™tre puissante pour cr√©er une IA polyvalente? <br><br>  Sur la premi√®re question: quand on regarde la protection civile aujourd'hui, ce domaine semble int√©ressant et en d√©veloppement rapide, mais relativement monolithique.  Il a plusieurs id√©es profondes et plusieurs grandes conf√©rences ont lieu, dont certaines se chevauchent beaucoup.  Work at work utilise le m√™me ensemble d'id√©es: la descente de gradient stochastique (ou son √©quivalent proche) pour optimiser la fonction de co√ªt.  C‚Äôest formidable que ces id√©es soient si r√©ussies.  Ce que nous n'observons pas jusqu'√† pr√©sent, c'est un grand nombre de zones plus petites et bien d√©velopp√©es, chacune explorant son propre ensemble d'id√©es profondes, ce qui ferait avancer la soci√©t√© civile dans de nombreuses directions.  Par cons√©quent, selon la m√©trique de la complexit√© sociale, l'apprentissage en profondeur, d√©sol√© pour le jeu de mots, alors qu'il reste un domaine de recherche tr√®s superficiel.  Une personne est encore capable de ma√Ætriser la plupart des id√©es profondes de ce domaine. <br><br>  Sur la deuxi√®me question: combien un ensemble complexe et puissant d'id√©es sera n√©cessaire pour cr√©er l'IA?  Naturellement, la r√©ponse sera: personne ne sait avec certitude.  Mais dans la postface du livre, j'ai √©tudi√© certaines des preuves existantes √† ce sujet.  J'ai conclu que, m√™me selon des estimations optimistes, la cr√©ation de l'IA n√©cessitera beaucoup, beaucoup d'id√©es profondes.  Selon la loi de Conway, pour atteindre ce point, nous devons voir l'√©mergence de nombreuses disciplines interd√©pendantes, avec une structure complexe et inattendue qui refl√®te la structure de nos id√©es les plus profondes.  Nous n'observons pas encore une structure sociale aussi complexe lorsque nous utilisons la NS et la protection civile.  Par cons√©quent, je crois que nous sommes, au moins, √† plusieurs d√©cennies de l'utilisation de GO pour d√©velopper l'IA √† usage g√©n√©ral. <br><br>  J'ai consacr√© beaucoup d'efforts √† cr√©er un argument sp√©culatif qui, peut-√™tre, semble assez √©vident et ne m√®ne pas √† une certaine conclusion.  Cela d√©cevra s√ªrement les gens √©pris de certitude.  Je rencontre beaucoup de gens en ligne qui annoncent publiquement leurs opinions tr√®s d√©finitives et confiantes sur l'IA, souvent bas√©es sur des arguments fragiles et des preuves inexistantes.  Je peux honn√™tement dire: je pense qu'il est trop t√¥t pour juger.  Comme dans la vieille blague: si vous demandez √† un scientifique combien il nous faut attendre de plus pour toute d√©couverte, et il dit ¬´10 ans¬ª (ou plus), alors en fait il veut dire ¬´je n'en ai aucune id√©e¬ª.  Avant l'av√®nement de l'IA, comme dans le cas de la fusion nucl√©aire contr√¥l√©e et de certaines autres technologies, ¬´10 ans¬ª sont rest√©s pendant plus de 60 ans.  D'un autre c√¥t√©, ce que nous avons d√©finitivement dans le domaine de la protection civile, c'est une technologie efficace, dont nous n'avons pas encore d√©couvert les limites, et de nombreuses t√¢ches fondamentales ouvertes.  Et cela ouvre des opportunit√©s cr√©atives incroyables. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr464039/">https://habr.com/ru/post/fr464039/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr464021/index.html">Qu'est-ce que la bascule de fonction ou comment se d√©barrasser des morses atroces et des branches √† longue dur√©e de vie?</a></li>
<li><a href="../fr464023/index.html">"Bases de la programmation" d√©fini pour un cours gratuit avec des exemples en JavaScript</a></li>
<li><a href="../fr464027/index.html">Comment survivre au contenu √† l'√®re de l'explosion de l'information</a></li>
<li><a href="../fr464031/index.html">¬´Finds of an Audiomaniac¬ª: les cartes son comme moyen de se plonger dans l'atmosph√®re d'une ville inconnue</a></li>
<li><a href="../fr464037/index.html">Nouvelles du monde d'OpenStreetMap n ¬∞ 472 (30/07/2019 - 05.08.2019)</a></li>
<li><a href="../fr464041/index.html">Pourquoi les meilleurs pilotes de chasse ont souvent de gros ennuis</a></li>
<li><a href="../fr464043/index.html">Histoire du convertisseur Ethernet-CAN</a></li>
<li><a href="../fr464045/index.html">Comment je traine presque en temps r√©el en 1997</a></li>
<li><a href="../fr464053/index.html">Nota: Algorithme de s√©lection et de rotation des pistes</a></li>
<li><a href="../fr464055/index.html">Nous √©tudions les donn√©es collect√©es par Xiaomi Mi Band pour l'ann√©e</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
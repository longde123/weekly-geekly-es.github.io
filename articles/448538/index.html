<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìß üö£ ü•£ Cree una soluci√≥n de conmutaci√≥n por error basada en la arquitectura Oracle RAC y AccelStor Shared-Nothing üï∫üèº üéÅ üë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un n√∫mero considerable de aplicaciones empresariales y sistemas de virtualizaci√≥n tienen sus propios mecanismos para construir soluciones tolerantes a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cree una soluci√≥n de conmutaci√≥n por error basada en la arquitectura Oracle RAC y AccelStor Shared-Nothing</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/accelstor/blog/448538/"><p>  Un n√∫mero considerable de aplicaciones empresariales y sistemas de virtualizaci√≥n tienen sus propios mecanismos para construir soluciones tolerantes a fallas.  En particular, Oracle RAC (Oracle Real Application Cluster) es un grupo de dos o m√°s servidores de bases de datos Oracle que trabajan juntos para equilibrar la carga y proporcionar tolerancia a fallas a nivel de servidor / aplicaci√≥n.  Para trabajar en este modo, se requiere un almacenamiento com√∫n, cuya funci√≥n suele ser el almacenamiento. </p><br><p>  Como ya discutimos en uno de nuestros <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culos</a> , en s√≠ mismo el sistema de almacenamiento, a pesar de la presencia de componentes duplicados (incluidos los controladores), todav√≠a tiene puntos de falla, principalmente en forma de un solo conjunto de datos.  Por lo tanto, para construir una soluci√≥n Oracle con mayores requisitos de confiabilidad, el esquema "N servidores - un almacenamiento" debe ser complicado. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/l3/lh/1t/l3lh1tmhqobqcqow6yxo-g3j8lc.png"></div><br><a name="habracut"></a><br><p>  Primero, por supuesto, debe decidir contra qu√© riesgos estamos tratando de asegurarnos.  En este art√≠culo, no consideraremos la protecci√≥n contra amenazas como la llegada de un meteorito.  Por lo tanto, la creaci√≥n de una soluci√≥n de recuperaci√≥n ante desastres dispersa geogr√°ficamente seguir√° siendo un tema para uno de los siguientes art√≠culos.  Aqu√≠ observamos la llamada soluci√≥n de recuperaci√≥n de desastres Cross-Rack, cuando la protecci√≥n se construye a nivel de gabinetes de servidores.  Los gabinetes pueden ubicarse en la misma habitaci√≥n o en diferentes, pero generalmente dentro del mismo edificio. </p><br><p>  Estos gabinetes deben contener todo el conjunto de equipos y software necesarios que garantizar√°n el funcionamiento de las bases de datos Oracle independientemente del estado del "vecino".  En otras palabras, utilizando la soluci√≥n de recuperaci√≥n de desastres Cross-Rack, eliminamos los riesgos de falla: </p><br><ul><li>  Servidores de aplicaciones Oracle </li><li>  Sistemas de almacenamiento </li><li>  Sistemas de conmutaci√≥n </li><li>  Falla completa de todos los equipos en el gabinete: <br><ul><li>  Falla de energ√≠a </li><li>  Falla del sistema de enfriamiento. </li><li>  Factores externos (hombre, naturaleza, etc.) </li></ul></li></ul><br><p>  La duplicaci√≥n de servidores Oracle implica el principio mismo de Oracle RAC y se implementa a trav√©s de la aplicaci√≥n.  La duplicaci√≥n de herramientas de conmutaci√≥n tampoco es un problema.  Pero con la duplicaci√≥n del sistema de almacenamiento, no todo es tan simple. </p><br><p>  La opci√≥n m√°s f√°cil es replicar datos del almacenamiento primario a la copia de seguridad.  Sincr√≥nico o asincr√≥nico, dependiendo de las capacidades de almacenamiento.  La replicaci√≥n asincr√≥nica plantea inmediatamente la cuesti√≥n de garantizar la coherencia de los datos con Oracle.  Pero incluso si hay integraci√≥n de software con la aplicaci√≥n, en cualquier caso, en caso de accidente en el sistema de almacenamiento principal, se requerir√° la intervenci√≥n manual de los administradores para cambiar el cl√∫ster al almacenamiento de respaldo. </p><br><p>  Una opci√≥n m√°s compleja son los "virtualizadores" de software y / o hardware de los sistemas de almacenamiento, que eliminar√°n los problemas de coherencia e intervenci√≥n manual.  Pero la complejidad de la implementaci√≥n y la administraci√≥n posterior, as√≠ como el costo muy indecente de tales soluciones, asustan a muchos. </p><br><p>  Solo para escenarios como la recuperaci√≥n ante desastres Cross-Rack, la matriz All Flash AccelStor NeoSapphire ‚Ñ¢ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">H710 que</a> utiliza la arquitectura Shared-Nothing es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">perfecta</a> .  Este modelo es un sistema de almacenamiento doble que utiliza su propia tecnolog√≠a FlexiRemap¬Æ para trabajar con unidades flash.  Gracias al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FlexiRemap¬Æ</a> NeoSapphire ‚Ñ¢ H710, puede entregar hasta 600K IOPS @ 4K de escritura aleatoria y 1M + IOPS @ 4K de lectura aleatoria, que es inalcanzable con el almacenamiento cl√°sico basado en RAID. </p><br><p>  Pero la caracter√≠stica principal del NeoSapphire ‚Ñ¢ H710 es la ejecuci√≥n de dos nodos como recintos separados, cada uno de los cuales tiene su propia copia de los datos.  La sincronizaci√≥n de nodos se realiza a trav√©s de la interfaz externa InfiniBand.  Gracias a esta arquitectura, los nodos se pueden distribuir en diferentes ubicaciones a distancias de hasta 100 m, lo que proporciona la soluci√≥n de recuperaci√≥n ante desastres Cross-Rack.  Ambos nodos funcionan completamente en modo s√≠ncrono.  Desde el lado del host, el H710 parece un almacenamiento de controlador dual ordinario.  Por lo tanto, no es necesario realizar opciones adicionales de software y hardware y configuraciones particularmente complejas. </p><br><p>  Si compara todas las soluciones de recuperaci√≥n de desastres Cross-Rack descritas anteriormente, la versi√≥n AccelStor se destaca del resto: </p><br><table><tbody><tr><th></th><th>  Arquitectura AccelStor NeoSapphire ‚Ñ¢ Shared Nothing </th><th>  Software o hardware "virtualizador" de almacenamiento </th><th>  Soluci√≥n de replicaci√≥n </th></tr><tr><td colspan="4">  <b>Disponibilidad</b> </td></tr><tr><td>  Falla del servidor </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <b>Sin tiempo de inactividad</b> </td></tr><tr><td>  Falla del interruptor </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <b>Sin tiempo de inactividad</b> </td></tr><tr><td>  Falla de almacenamiento </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <font color="green"><b>Tiempo de inactividad</b></font> </td></tr><tr><td>  Falla de todo el gabinete. </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <b>Sin tiempo de inactividad</b> </td><td>  <font color="green"><b>Tiempo de inactividad</b></font> </td></tr><tr><td colspan="4">  <b>Costo y complejidad.</b> </td></tr><tr><td>  Costo de la soluci√≥n </td><td>  Bajo * </td><td>  <font color="green">Alta</font> </td><td>  <font color="green">Alta</font> </td></tr><tr><td>  Dificultad de implementaci√≥n </td><td>  Bajo </td><td>  <font color="green">Alta</font> </td><td>  <font color="green">Alta</font> </td></tr></tbody></table><br><p>  <i>* AccelStor NeoSapphire ‚Ñ¢ sigue siendo una matriz All Flash, que por definici√≥n no cuesta "3 kopecks", especialmente porque tiene una reserva de capacidad doble.</i>  <i>Sin embargo, al comparar el costo total de la soluci√≥n basada en ella con otros similares de otros proveedores, el costo puede considerarse bajo.</i> </p><br><p>  La topolog√≠a para conectar servidores de aplicaciones y nodos de matriz All Flash se ver√° as√≠: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/5i/gb/cw/5igbcwdvm92bpabsylae4iysdra.png"></div><br><p>  Al planificar la topolog√≠a, tambi√©n se recomienda que duplique los conmutadores de administraci√≥n y las interconexiones del servidor. </p><br><p>  A continuaci√≥n, hablaremos sobre la conexi√≥n a trav√©s de Fibre Channel.  En el caso de usar iSCSI, todo ser√° igual, ajustado para los tipos de interruptores utilizados y configuraciones de matriz ligeramente diferentes. </p><br><h3>  Trabajo preparatorio en la matriz. </h3><br><div class="spoiler">  <b class="spoiler_title">Hardware y software usados</b> <div class="spoiler_text"><p>  <b>Especificaciones del servidor y conmutador</b> </p><br><table><tbody><tr><th>  Componentes </th><th>  Descripci√≥n </th></tr><tr><td>  Servidores Oracle Database 11g </td><td>  Dos </td></tr><tr><td>  Sistema operativo del servidor </td><td>  Oracle Linux </td></tr><tr><td>  Versi√≥n de la base de datos Oracle </td><td>  11 g (RAC) </td></tr><tr><td>  Procesadores por servidor </td><td>  Dos CPU de 16 n√∫cleos Intel¬Æ Xeon¬Æ E5-2667 v2 @ 3.30GHz </td></tr><tr><td>  Memoria f√≠sica por servidor </td><td>  128GB </td></tr><tr><td>  Red FC </td><td>  16 Gb / s FC con m√∫ltiples rutas </td></tr><tr><td>  FC HBA </td><td>  Emulex Lpe-16002B </td></tr><tr><td>  Puertos p√∫blicos dedicados de 1 GbE para la gesti√≥n de cl√∫steres </td><td>  Adaptador ethernet Intel rj45 </td></tr><tr><td>  Conmutador FC de 16 Gb / s </td><td>  Brocade 6505 </td></tr><tr><td>  Puertos privados dedicados de 10 GbE para sincronizaci√≥n de datos </td><td>  Intel X520 </td></tr></tbody></table><br><p>  <b>AccelStor NeoSapphhire ‚Ñ¢ All Flash Array Especificaci√≥n</b> </p><br><table><tbody><tr><th>  Componentes </th><th>  Descripci√≥n </th></tr><tr><td>  Sistema de almacenamiento </td><td>  Modelo de alta disponibilidad NeoSapphire ‚Ñ¢: H710 </td></tr><tr><td>  Versi√≥n de la imagen </td><td>  4.0.1 </td></tr><tr><td>  N√∫mero total de unidades </td><td>  48 </td></tr><tr><td>  Tama√±o de la unidad </td><td>  1.92TB </td></tr><tr><td>  Tipo de unidad </td><td>  SSD </td></tr><tr><td>  Puertos de destino FC </td><td>  16 puertos de 16 Gb (8 por nodo) </td></tr><tr><td>  Puertos de gesti√≥n </td><td>  El cable de ethernet de 1 GbE que se conecta a los hosts a trav√©s de un conmutador de ethernet </td></tr><tr><td>  Puerto de latido </td><td>  El cable Ethernet de 1 GbE que se conecta entre dos nodos de almacenamiento </td></tr><tr><td>  Puerto de sincronizaci√≥n de datos </td><td>  Cable InfiniBand de 56 Gb / s </td></tr></tbody></table><br></div></div><br><p>  Antes de comenzar a usar una matriz, debe inicializarla.  Por defecto, la direcci√≥n de control de ambos nodos es la misma (192.168.1.1).  Debe conectarse a ellos uno a la vez y establecer nuevas direcciones de administraci√≥n (ya diferentes) y configurar la sincronizaci√≥n de tiempo, despu√©s de lo cual los puertos de administraci√≥n se pueden conectar a una sola red.  Despu√©s de eso, los nodos se combinan en un par HA asignando subredes a las conexiones de Interlink. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/c3/kw/sp/c3kwspwqm38yl7ennakzykubswq.jpeg"></div><br><p>  Una vez completada la inicializaci√≥n, puede controlar la matriz desde cualquier nodo. </p><br><p>  A continuaci√≥n, cree los vol√∫menes necesarios y publ√≠quelos para los servidores de aplicaciones. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/6h/4s/gf/6h4sgfinagrbbngoououu-lg1au.png"></div><br><p>  Se recomienda encarecidamente que cree varios vol√∫menes para Oracle ASM, ya que esto aumentar√° el n√∫mero de objetivos para los servidores, lo que finalmente mejorar√° el rendimiento general (m√°s informaci√≥n sobre las colas en otro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> ). </p><br><div class="spoiler">  <b class="spoiler_title">Configuraci√≥n de prueba</b> <div class="spoiler_text"><table><tbody><tr><th>  Nombre del volumen de almacenamiento </th><th>  Tama√±o del volumen </th></tr><tr><td>  Data01 </td><td>  200GB </td></tr><tr><td>  Datos02 </td><td>  200GB </td></tr><tr><td>  Datos03 </td><td>  200GB </td></tr><tr><td>  Datos04 </td><td>  200GB </td></tr><tr><td>  Datos05 </td><td>  200GB </td></tr><tr><td>  Datos06 </td><td>  200GB </td></tr><tr><td>  Datos07 </td><td>  200GB </td></tr><tr><td>  Datos08 </td><td>  200GB </td></tr><tr><td>  Data09 </td><td>  200GB </td></tr><tr><td>  Datos10 </td><td>  200GB </td></tr><tr><td>  Rejilla01 </td><td>  1GB </td></tr><tr><td>  Rejilla02 </td><td>  1GB </td></tr><tr><td>  Rejilla03 </td><td>  1GB </td></tr><tr><td>  Rejilla04 </td><td>  1GB </td></tr><tr><td>  Rejilla05 </td><td>  1GB </td></tr><tr><td>  Rejilla06 </td><td>  1GB </td></tr><tr><td>  Rehacer01 </td><td>  100GB </td></tr><tr><td>  Rehacer02 </td><td>  100GB </td></tr><tr><td>  Rehacer03 </td><td>  100GB </td></tr><tr><td>  Rehacer04 </td><td>  100GB </td></tr><tr><td>  Rehacer05 </td><td>  100GB </td></tr><tr><td>  Rehacer06 </td><td>  100GB </td></tr><tr><td>  Rehacer07 </td><td>  100GB </td></tr><tr><td>  Rehacer08 </td><td>  100GB </td></tr><tr><td>  Rehacer09 </td><td>  100GB </td></tr><tr><td>  Rehacer10 </td><td>  100GB </td></tr></tbody></table><br></div></div><br><h3>  Algunas explicaciones sobre los modos de funcionamiento de la matriz y los procesos que ocurren en situaciones de emergencia. </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/5m/_k/uu/5m_kuurlb-2fy52d8p1tzufcyic.png"></div><br><p>  Cada conjunto de datos de nodo tiene un par√°metro de "n√∫mero de versi√≥n".  Despu√©s de la inicializaci√≥n inicial, es igual e igual a 1. Si por alguna raz√≥n el n√∫mero de versi√≥n es diferente, entonces siempre hay sincronizaci√≥n de los datos de la versi√≥n anterior a la m√°s joven, despu√©s de lo cual el n√∫mero se alinea para la versi√≥n m√°s joven, es decir.  Esto significa que las copias son id√©nticas.  Razones por las que las versiones pueden variar: </p><br><ul><li>  Reinicio programado de uno de los nodos </li><li>  Un accidente en uno de los nodos debido a un apagado repentino (energ√≠a, sobrecalentamiento, etc.). </li><li>  Conexi√≥n rota InfiniBand con incapacidad para sincronizar </li><li>  Accidente en uno de los nodos debido a la corrupci√≥n de datos.  Ya requerir√° la creaci√≥n de un nuevo grupo HA y la sincronizaci√≥n completa del conjunto de datos. </li></ul><br><p>  En cualquier caso, el nodo que permanece en l√≠nea aumenta su n√∫mero de versi√≥n en uno, de modo que despu√©s de reconectarse con el par, sincronice su conjunto de datos. </p><br><p>  Si la conexi√≥n se pierde a trav√©s del enlace Ethernet, Heartbeat cambia temporalmente a InfiniBand y regresa en 10 segundos cuando se restablece. </p><br><h3>  Configuraci√≥n de host </h3><br><p>  Para garantizar la tolerancia a fallos y aumentar el rendimiento, debe habilitar el soporte de MPIO para la matriz.  Para hacer esto, agregue l√≠neas al archivo /etc/multipath.conf y luego vuelva a cargar el servicio multirruta </p><br><div class="spoiler">  <b class="spoiler_title">Texto oculto</b> <div class="spoiler_text">  dispositivos { <br>  dispositivo { <br>  vendedor "AStor" <br>  path_grouping_policy "group_by_prio" <br>  path_selector "longitud de cola 0" <br>  path_checker "tur" <br>  cuenta con "0" <br>  hardware_handler "0" <br>  prio "const" <br>  recuperaci√≥n inmediata <br>  fast_io_fail_tmo 5 <br>  dev_loss_tmo 60 <br>  user_friendly_names s√≠ <br>  detect_prio si <br>  rr_min_io_rq 1 <br>  no_path_retry 0 <br>  } <br>  } <br><br></div></div><br><p>  A continuaci√≥n, para que ASM funcione con MPIO a trav√©s de ASMLib, debe modificar el archivo / etc / sysconfig / oracleasm y luego ejecutar /etc/init.d/oracleasm scandisks </p><br><div class="spoiler">  <b class="spoiler_title">Texto oculto</b> <div class="spoiler_text"><p>  # ORACLEASM_SCANORDER: patrones coincidentes para ordenar el escaneo de disco <br>  ORACLEASM_SCANORDER = "dm" </p><br><br><p>  # ORACLEASM_SCANEXCLUDE: patrones coincidentes para excluir discos del escaneo <br>  ORACLEASM_SCANEXCLUDE = "sd" </p><br><p></p><h4>  Nota </h4><br><p>  <i>Si no desea usar ASMLib, puede usar las reglas UDEV, que son la base de ASMLib.</i> </p><br><p>  <i>A partir de la versi√≥n 12.1.0.2 de Oracle Database, la opci√≥n est√° disponible para la instalaci√≥n como parte del software ASMFD.</i> </p><br></div></div><br><p>  Aseg√∫rese de asegurarse de que los discos creados para Oracle ASM est√©n alineados con el tama√±o del bloque con el que la matriz est√° trabajando f√≠sicamente (4K).  De lo contrario, pueden ocurrir problemas de rendimiento.  Por lo tanto, debe crear vol√∫menes con los par√°metros apropiados: </p><br><p>  <i>parted / dev / mapper / device-name mklabel gpt mkpart primary 2048s 100% align-check √≥ptimo 1</i> </p><br><h3>  Distribuci√≥n de bases de datos en vol√∫menes creados para nuestra configuraci√≥n de prueba </h3><br><table><tbody><tr><th>  Nombre del volumen de almacenamiento </th><th>  Tama√±o del volumen </th><th>  Mapeo de LUN de volumen </th><th>  Detalle del dispositivo de volumen ASM </th><th>  Tama√±o de la unidad de asignaci√≥n </th></tr><tr><td>  Data01 </td><td>  200GB </td><td rowspan="26">  Asigne todos los vol√∫menes de almacenamiento al sistema de almacenamiento todos los puertos de datos </td><td rowspan="10">  Redundancia: normal <br>  Nombre: DGDATA <br>  Prop√≥sito: archivos de datos <br></td><td rowspan="10">  4MB </td></tr><tr><td>  Datos02 </td><td>  200GB </td></tr><tr><td>  Datos03 </td><td>  200GB </td></tr><tr><td>  Datos04 </td><td>  200GB </td></tr><tr><td>  Datos05 </td><td>  200GB </td></tr><tr><td>  Datos06 </td><td>  200GB </td></tr><tr><td>  Datos07 </td><td>  200GB </td></tr><tr><td>  Datos08 </td><td>  200GB </td></tr><tr><td>  Data09 </td><td>  200GB </td></tr><tr><td>  Datos10 </td><td>  200GB </td></tr><tr><td>  <font color="#248dee">Rejilla01</font> </td><td>  <font color="#248dee">1GB</font> </td><td rowspan="3">  <font color="#248dee">Redundancia: normal</font> <font color="#248dee"><br></font>  <font color="#248dee">Nombre: DGGRID1</font> <font color="#248dee"><br></font>  <font color="#248dee">Prop√≥sito: Cuadr√≠cula: CRS y votaci√≥n</font> <br></td><td rowspan="3">  <font color="#248dee">4MB</font> </td></tr><tr><td>  <font color="#248dee">Rejilla02</font> </td><td>  <font color="#248dee">1GB</font> </td></tr><tr><td>  <font color="#248dee">Rejilla03</font> </td><td>  <font color="#248dee">1GB</font> </td></tr><tr><td>  Rejilla04 </td><td>  1GB </td><td rowspan="3">  Redundancia: normal <br>  Nombre: DGGRID2 <br>  Prop√≥sito: Cuadr√≠cula: CRS y votaci√≥n <br></td><td rowspan="3">  4MB </td></tr><tr><td>  Rejilla05 </td><td>  1GB </td></tr><tr><td>  Rejilla06 </td><td>  1GB </td></tr><tr><td>  <font color="#248dee">Rehacer01</font> </td><td>  <font color="#248dee">100GB</font> </td><td rowspan="5">  <font color="#248dee">Redundancia: normal</font> <font color="#248dee"><br></font>  <font color="#248dee">Nombre: DGREDO1</font> <font color="#248dee"><br></font>  <font color="#248dee">Prop√≥sito: Rehacer el registro del hilo 1</font> <font color="#248dee"><br></font> <br></td><td rowspan="5">  <font color="#248dee">4MB</font> </td></tr><tr><td>  <font color="#248dee">Rehacer02</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  <font color="#248dee">Rehacer03</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  <font color="#248dee">Rehacer04</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  <font color="#248dee">Rehacer05</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  Rehacer06 </td><td>  100GB </td><td rowspan="5">  Redundancia: normal <br>  Nombre: DGREDO2 <br>  Prop√≥sito: Rehacer el registro del hilo 2 <br><br></td><td rowspan="5">  4MB </td></tr><tr><td>  Rehacer07 </td><td>  100GB </td></tr><tr><td>  Rehacer08 </td><td>  100GB </td></tr><tr><td>  Rehacer09 </td><td>  100GB </td></tr><tr><td>  Rehacer10 </td><td>  100GB </td></tr></tbody></table><br><div class="spoiler">  <b class="spoiler_title">Configuraciones de base de datos</b> <div class="spoiler_text"><ul><li>  Tama√±o de bloque = 8K </li><li>  Espacio de intercambio = 16 GB </li><li>  Desactivar AMM (gesti√≥n autom√°tica de memoria) </li><li>  Deshabilitar p√°ginas transparentes enormes </li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Otras configuraciones</b> <div class="spoiler_text"><p>  <u># vi /etc/sysctl.conf</u> <br>  ‚úì fs.aio-max-nr = 1048576 <br>  ‚úì fs.file-max = 6815744 <br>  ‚úì kernel.shmmax 103079215104 <br>  ‚úì kernel.shmall 31457280 <br>  ‚úì kernel.shmmn 4096 <br>  ‚úì kernel.sem = 250 32000100128 <br>  ‚úì net.ipv4.ip_local_port_range = 9000 65500 <br>  ‚úì net.core.rmem_default = 262144 <br>  ‚úì net.core.rmem_max = 4194304 <br>  ‚úì net.core.wmem_default = 262144 <br>  ‚úì net.core.wmem_max = 1048586 <br>  ‚úì vm.swappiness = 10 <br>  ‚úì vm.min_free_kbytes = 524288 # no establezca esto si est√° utilizando Linux x86 <br>  ‚úì vm.vfs_cache_pressure = 200 <br>  ‚úì vm.nr_hugepages = 57000 </p><br><br><p>  <u># vi /etc/security/limits.conf</u> <br>  ‚úì rejilla suave nproc 2047 <br>  ‚úì rejilla r√≠gida nproc 16384 <br>  ‚úì grid soft nofile 1024 <br>  ‚úì rejilla r√≠gida nofile 65536 <br>  ‚úì rejilla soft stack 10240 <br>  ‚úì pila r√≠gida de rejilla 32768 <br>  ‚úì oracle soft nproc 2047 <br>  ‚úì oracle hard nproc 16384 <br>  ‚úì oracle soft nofile 1024 <br>  ‚úì nofile duro oracle 65536 <br>  ‚úì pila suave oracle 10240 <br>  ‚úì pila dura oracle 32768 <br>  ‚úì memlock suave 120795954 <br>  ‚úì memlock duro 120795954 <br></p><br><p>  <u>sqlplus "/ como sysdba"</u> <br>  alterar procesos establecidos del sistema = 2000 alcance = spfile; <br>  alter system set open_cursors = 2000 scope = spfile; <br>  alter system set session_cached_cursors = 300 scope = spfile; <br>  alter system set db_files = 8192 scope = spfile; <br></p><br><br></div></div><br><h3>  Prueba de tolerancia a fallos </h3><br><p>  Para fines de demostraci√≥n, se us√≥ HammerDB para emular la carga OLTP.  Configuraci√≥n de HammerDB: </p><br><table><tbody><tr><td>  <b>Cantidad de almacenes</b> </td><td>  256 </td></tr><tr><td>  Transacciones totales por usuario </td><td>  1000000000000 </td></tr><tr><td>  Usuarios virtuales </td><td>  256 </td></tr></tbody></table><br><p>  Como resultado, se obtuvo el indicador 2.1M TPM, que est√° lejos del l√≠mite de rendimiento de la matriz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">H710</a> , pero es el "techo" para la configuraci√≥n actual de hardware de los servidores (principalmente debido a los procesadores) y su n√∫mero.  El prop√≥sito de esta prueba sigue siendo demostrar la tolerancia a fallas de la soluci√≥n como un todo, y no lograr el m√°ximo rendimiento.  Por lo tanto, simplemente construiremos sobre esta figura. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/3o/ds/id/3odsid2wr0ynssl4zuu8idq8dfq.png"></div><br><h3>  Prueba de falla de uno de los nodos </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/tf/og/artfogfilgwzy2vtxlsyvkp98vu.png"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/zk/iv/xt/zkivxtazysrew4hhzjan-vujnma.png"></div><br><p>  Los hosts perdieron algunos de los caminos a la tienda, y continuaron trabajando a trav√©s de los restantes con el segundo nodo.  El rendimiento baj√≥ durante unos segundos debido a la reestructuraci√≥n de los caminos y luego volvi√≥ a la normalidad.  No se produjo interrupci√≥n del servicio. </p><br><h3>  Prueba de falla del gabinete con todo el equipo </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/mq/my/2b/mqmy2bzrge24zhnj217spj2rts4.png"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/eq/nh/-8/eqnh-8pwbhyzqgdleh1tsiafkr0.png"></div><br><p>  En este caso, el rendimiento tambi√©n baj√≥ durante unos segundos debido a la reestructuraci√≥n de las rutas, y luego volvi√≥ a la mitad del valor del indicador original.  El resultado se redujo a la mitad del original debido a la exclusi√≥n de la operaci√≥n de un servidor de aplicaciones.  La interrupci√≥n del servicio tampoco sucedi√≥. </p><br><blockquote>  Si necesita implementar una soluci√≥n de recuperaci√≥n de desastres Cross-Rack tolerante a fallas para Oracle a un costo razonable y con poco esfuerzo de implementaci√≥n / administraci√≥n, entonces trabajar junto con Oracle RAC y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitectura AccelStor Shared-Nothing</a> ser√≠a una de las mejores opciones.  En lugar de Oracle RAC, puede haber cualquier otro software que proporcione agrupaci√≥n, el mismo DBMS o sistemas de virtualizaci√≥n, por ejemplo.  El principio de construir la soluci√≥n seguir√° siendo el mismo.  Y el puntaje final es cero para RTO y RPO. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/448538/">https://habr.com/ru/post/448538/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../448528/index.html">Servicio gratuito de Wireguard VPN en AWS</a></li>
<li><a href="../448530/index.html">C√≥mo dorm√≠a Megaphone en suscripciones m√≥viles</a></li>
<li><a href="../448532/index.html">Centro de datos espaciales. Resumiendo el experimento</a></li>
<li><a href="../448534/index.html">¬øPor qu√© necesitamos interruptores industriales con EMC mejorado?</a></li>
<li><a href="../448536/index.html">Transparencia - La panacea de los Butcherts</a></li>
<li><a href="../448540/index.html">VMware NSX para los m√°s peque√±os. Parte 5. Configurar el equilibrador de carga</a></li>
<li><a href="../448544/index.html">Paquetes en acero. Como se forman</a></li>
<li><a href="../448546/index.html">UITableView tama√±os autom√°ticos de encabezado y pie de p√°gina con AutoLayout</a></li>
<li><a href="../448548/index.html">Construcci√≥n en el arte: de Brueghel a Vasya Lozhkin</a></li>
<li><a href="../448552/index.html">ProLiant Series 100 - El hermano menor perdido</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
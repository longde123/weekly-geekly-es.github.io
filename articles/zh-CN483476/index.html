<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛬 🕟 🧙🏾 机器人运输的道德：手推车的问题，风险和后果 🧓🏻 🀄️ ☹️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="开发机器人车辆的道德方面非常复杂。 开发人员坚信应该在公共道路上进行测试，尽管他们知道这对毫无戒心的道路使用者几乎没有风险。 测试后释放的汽车肯定会发生事故（包括致命事故），这种状况是令人恐惧和沮丧的前景。 同时，成功保证了我们在道路安全方面的巨大进步，并挽救了许多人的生命，这些人如果没有机会用无人...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>机器人运输的道德：手推车的问题，风险和后果</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itelma/blog/483476/"><img src="https://habrastorage.org/getpro/habr/post_images/9da/572/3d5/9da5723d574c33ceb952a3ebf5334b57.jpg" alt="图片"><br><br> 开发机器人车辆的道德方面非常复杂。 开发人员坚信应该在公共道路上进行测试，尽管他们知道这对毫无戒心的道路使用者几乎没有风险。 测试后释放的汽车肯定会发生事故（包括致命事故），这种状况是令人恐惧和沮丧的前景。 同时，成功保证了我们在道路安全方面的巨大进步，并挽救了许多人的生命，这些人如果没有机会用无人机代替更​​危险的人类驾驶，将会丧生。 <br><br> 我们将考虑以下方面： <br><br><ol><li> 了解不同（或相同）情况下人们道德推理的不同方法 </li><li> 法律，社会和保险与危险驾驶，事故和事故之间的关系。 </li><li> 驾车（或驾驶培训）过程中的风险和损失，我们似乎愿意接受一些小收益。 </li><li> 我们认为“最终证明手段合理”的观点如何根据所面临的风险而改变：蓄意的暴行或故意的小风险。 </li><li> 当一小批自动驾驶汽车学会更安全地驾驶时，我们将获得巨大的好处，之后他们的软件将被复制到数百万辆其他汽车中，这对于人类驾驶员而言是不可能的。 </li><li> 测试和开发自动驾驶汽车的现代方法的风险和原则，以及Uber如何违反它们。 </li><li> 如果我们找到正确的方法，将会有很大的好处。 </li></ol><br><a name="habracut"></a><br><br> 最近在亚利桑那州的坦佩发现了涉及Uber车辆的致命交通事故，这一事实只会增加了解这一问题的必要性。 关于如何讨论无人驾驶汽车的道德风险和原则，已经撰写了许多文章并发表了很多意见。 在本文中，我希望对这个问题有一个清晰的认识，并为对此进行讨论提供指导。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ea/921/5cf/7ea9215cf82e51ed5037034af65299a6.jpg" alt="图片"><br><br>  <i>大多数崩溃是单机，可以避免。</i>  <i>然而，我们毫不犹豫地接受了这种可怕的风险。</i> <br><br> 事实证明， <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25BE%25D0%25B1%25D0%25BB%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%25B2%25D0%25B0%25D0%25B3%25D0%25BE%25D0%25BD%25D0%25B5%25D1%2582%25D0%25BA%25D0%25B8">手推车问题</a>给我们的经验教训（即从手推车，而不是无人驾驶的车辆）和衡量导致风险而不是悲剧的行为的组合，可以帮助我们形成更好的理解和法律制度，以解决有关可以和可能的机器人的复杂问题。拯救生命并威胁他们。 如果我们准备接受与在青少年开车之前教青少年相同的风险，那么我们可以挽救数百万人的生命（您可以想象，要代替青少年，赶紧送披萨的人）。 几乎每个从事机器人工作的人都希望他们能够挽救生命，并希望他们尽快开始这样做，但是为此，公众必须了解甚至采用这一领域的工作方法。 为此，我们必须了解我们的道德本能和内部数学，以及风险与悲剧之间的区别。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/57a/d2f/ccb/57ad2fccb3456ac9538215f4505d85fe.png" alt="图片"><br><br> 一年前，当我与朋友在家里吃饭时，我意识到了理解这些问题的困难。 一个朋友非常担心早期原型所包含的风险。 我问他-在测试期间让100个人死亡是合理的，但是使用最终产品将挽救数百万的生命吗？ 在他看来，这显然是错误的，而且他并不孤单。 <br><br> 人类道德是复杂而狡猾的，可以根据情况以不同的方式发挥作用。 在我们的原则中，很少有人能说得很清楚，我们在主观决定中使用的那些原则可能与社会或法院集体决定中使用的那些原则有所不同。 要了解此问题以及如何找到更好的解决方案，我们需要了解人们如何对这种道德进行推理，并有可能改变这种思维方式，以便获得在多数意见中会更好的结果。 <br><br> 答案可能是这样的事实：尽管我们不同意伟大的目标可以证明不道德的手段是正当的，但事实证明，我们愿意承认，即使是适度盈利的目标也可以证明具有不道德的风险的手段正当。 <br><br><h3> 道德类型 </h3><br> 粗略地说，哲学家将道德体系分为两大类。 第一个要求规则和原则的代码，并且将错误定义为违反这些相同的规则和原则，而不管结果如何。 这种系统的复杂名称是“道义性的”，但我们将其称为基于规则的。 另一方面，我们拥有基于结果的系统，该结果可以衡量最终的对与错。 他们也被称为结果论者。 这种制度的一个特定子集是功利主义的，遵循的规则是为最大数量的人实现最大的利益，或为最少的人带来最少的伤害。 <br><br> 有时，我们喜欢功利主义的道德体系，尤其是整个社会。 但是，作为个人，我们倾向于不信任他们，因为他们与“目的证明手段合理”的危险观念联系在一起，并且这种观念在整个历史上引发了许多道德恐怖。 我们大多数人并不严格属于其中一所学校。 如前所述，我们的方法会有所变化，这取决于我们是将自己视为一个独立的人还是整个社会，并且我们会根据自己的个人观点来改变我们的推理方法，这超出了我们愿意承认的范围。 <br><br> 纯粹采用功利主义方法的人会很容易同意，机器将杀死100人，从而节省一百万。在功利主义道德的情况下，甚至没有问题。 同时，许多人很难接受。 我怀疑答案是要了解我们作为个人如何特别关注事件和悲剧，而在社会角色中我们关注风险评估和公益。 <br><br> 读过我的文章的人知道， <a href="https://ideas.4brad.com/barack-obama-wants-solve-robocar-trolley-problems-now">我讨厌“无轨电车问题”在无人驾驶汽车上的标准应用</a> 。 在此应用程序中，人们想象汽车中的软件，该软件应确定在事故中要杀死两个不同人群中的哪个。 现在，机器决定谁应该死，尽管这之前是众神的活动领域，但我们对此感到痛苦。 实际上，这是一种极为罕见的情况，其解决方案未包含在任何优先级列表中。 程序员和公司也不想编写与道德选择有关的算法，他们更希望政客回答此类问题并编写法律，以便他们乐意遵循。 <br><br> 但是，原始的手推车问题具有实际功能，在这种情况下可能会有用。 它的创建是为了帮助我们理解我们自己的思想，并帮助理解基于规则的道德体系与以结果为导向的道德体系之间的区别，也就是说，最终，在手推车问题的帮助下，我们应该对哲学有了更好的理解。 她可以帮助我们更好地了解这种情况。 <br><br> 您可能还记得，在最初的任务中，手推车在刹车破裂的情况下沿着铁轨奔跑。 有人（在这种情况下非常不道德）将5个人绑在主干道上，将1个人绑在主干道上。 您可以拉动开关杀死一个人，但要保存五个人。 多达90％的人选择功利主义（基于结果的）方法，并且更愿意拉杠杆，但有些人拒绝。  （实际上，这些人在课堂练习中更有可能表现为这种行为。在YouTube的<a href="https://www.youtube.com/watch%3Fv%3D1sl5KJ69qiA">Mind Field</a>节目上进行了一项实验，使人们认为他们确实处在急需手推车和人员的情况下。注意，破坏者：大多数对象都惊呆了） <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1sl5KJ69qiA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br> 我想说，解决这个问题的工程解决方案比较简单- <a href="https://www.forbes.com/sites/bradtempleton/2019/02/21/robocar-engineers-prefer-to-solve-the-runaway-trolley-problem-by-fixing-the-brakes-on-the-trolley/">您需要修理手推车制动器</a> 。 无人驾驶汽车工程师将主要致力于确保他们的汽车即使在很少发生的情况下也永远不会陷入这种情况。 <br><br> 哲学家想出的小车问题的变化比原始措辞有趣得多。 在一种选择中，您无需拉动开关，而是将胖子推到栏杆上以停止购物车-很少有人愿意这样做，因为这是故意杀人。 在最极端的版本中，您没有手推车，但是有5位患者急需器官移植。 您可以抓住一个走在街上的人，砍死他并拯救五个人-几乎没有人同意这样做，尽管从功利主义方法的角度来看这是相同的问题。 <br><br> 几乎没有人会这样做，因为在我们当中很少有人严格属于一所特定的道德学校。 对我们而言，改变思想更加困难。 为了理解和解决无人驾驶汽车的测试和生产领域中的问题，我们必须超越自然和个人的直觉，将各种情况视为它们所代表的“公正”单独的悲剧，并思考哪些风险可以接受并且可能是被允许作为一个社会。 <br><br> 此外，我们更不愿为外部过路人所经历的悲剧所拒绝，尽管我们不愿将这些人暴露在较低风险中。 最后，我们更担心独立的机器而不是人会伤害我们。 <br> 人们很有趣，尽管大多数人都害怕死于机器人，但我们更有可能被醉酒的罪犯杀死。 <br><br> 基本上，人们认为为了挽救生命而杀人是错误的，这是无可争议的。 真正的问题是在道路上实际测试和释放无人驾驶车辆是什么—杀人以挽救生命，或为相同目的冒险。 实际上，在大多数情况下，我们同意为挽救生命而冒险，但要取得好的结果。 <br><br><h3> 驾驶道德方面 </h3><br> 那么道德哲学和汽车之间是什么关系呢？ 为了找到答案，我们需要考虑交通事故的道德方面。 个人和整个社会对这个问题有不同的态度。 整个社会，特别是法律，除非有恶意意图（法理学中称为“男子犯罪”），否则不要将任何事物描述为不道德或邪恶。 几乎所有的刑事犯罪都包含恶意，如果不是故意的话，那么减轻处罚（在大多数情况下）。 因此，当有人在汽车中将某人撞死并没有刑事责任时，这种情况并不少见。 驾驶员将面临经济处罚，但已获得保险。 罪魁祸首只会对发生的事情感到内sense，摆脱这种情况。 但是，只有在完全无意地杀害人并且实际上完全违背驾驶员意图的情况下，所有这一切都是正确的。  <a href="https://www.lawyers.com/legal-info/criminal/traffic-violations/when-a-drivers-actions-amount-to-manslaughter.html">没有明确的意图或认真而故意的疏忽，就不可能有谋杀（甚至是无意的）谋杀</a> 。 <br><br> 同时，我们正在努力确定是否存在恶意意图或过失，因为我们非常担心这样的事实：像死亡这样的悲惨事件可能无法得到答复。 但是，如果我们谈论的是事故确实发生的情况（我的意思是说事故发生在谨慎驾驶的通常风险框架内）-没有法律后果，那么可能发生的最严重的事情就是财务后果，这完全由保险支付。 <br><br> 另一方面，考虑超速行驶。 即使经常犯有超速行为，也是非法的，但在某些地方很少受到惩罚。 当您加速时，您知道（或应该知道）是否超过。 这样做会使其他人面临其他风险，尽管幸运的是，通常不会发生任何可怕的事情。 尽管您确实会因超速而受到罚款，但如果超额导致事故，大多数罚款是针对没有伤害任何人的超额罚款。 几乎我们所有人都定期超过速度，而这样做的原因很明显-我们想更快地到达某个地方。 这可能与直觉相反，但我们的系统中故意超速行驶比随机杀人更为不道德和违法，尽管我们作为个人对超速行驶的容忍度更高。 <br><br> 我认为，驾驶中真正的道德问题是我们有意将他人置于危险之中。 或者，更具体而言，这是不可接受的高风险。 任何驾驶行为都意味着其他人将处于危险之中。 实际上，在开车时我们很可能经常使其他人面临最大的风险。 众所周知，开车导致的死亡，伤害和物质损失令人震惊，死于事故的人数比所有战争都要多，这是革命战争以来美国历史上恐怖袭击的结果。 所有这一切都具有极大的风险，但对我们而言，如此重要的决定使我们决定为自己和周围的人承担相对较高的风险。 我们这样做是有目的的，尽管我们经常会忘记它，并且我们当然不会很好地记住这些现象的数学本质。 我们认为在我们的法律和生活中，这种基本风险水平是“可以接受的”。 <br><br>  <b>社会决定错误和非法行为不是特定的受害者，而是他人故意和粗心地暴露于极端风险中。</b> <br><br> 我们有成文的法律禁止您将他人暴露于特殊风险中，并且您将因超速行驶，不正确的车道变更和不小心驾驶而受到罚款。 我们认为这样的行为是不道德的，因为它们是故意的或由于疏忽而犯下的，尽管我们并不认为不道德的死亡并非非故意的。 这并不能阻止那些将其视为巨大悲剧的人，这是绝对自然的反应。 但是，作为一个制定和执行法律的社会，我们对一切事物的看法都不同。 <br><br> 我们发现令人惊讶的许多驾驶风险可以接受： <br><br><ol><li> 重型驾驶 </li><li> 在雨，雪和夜间驾驶 </li><li> 在有很多行人和骑自行车者的地方驾驶 </li><li> 驾驶有轻微机械故障的汽车 </li><li> 无需自动紧急制动和其他先进技术的驾驶 </li><li> 即使我们入睡，也要处于昏昏欲睡的状态（两个州有禁止睡眠的法律） </li><li> 驾驶无忧无虑的青少年刚刚获得许可 </li><li> 成人驾驶学生 </li><li> 以降低的感知力和更长的反应时间来驱动老年人 </li><li> 以低于允许的血液酒精浓度驾驶 </li><li> 在生病状态下驾驶（即使这是违法的） </li><li> 在开车时使用设备和编写消息（尽管这是非法的） </li><li> 在美国，超速驾驶非常普遍，通常与其他汽车相比差距很大 </li></ol><br> 让我们看一个原型无人驾驶汽车。 当开发团队将这样的汽车放在路上时，他们故意使其他交通参与者面临风险。 当然，他们无意造成任何事故，事实上，他们有意防止事故发生。 <br><br> 目前，除少数例外，无人驾驶飞机始终在驾驶员的控制下工作，驾驶员准备在出现问题时着手开展业务。 几乎总是有第二个人来监视系统并偶尔瞥一眼道路。 可以将其与具有学生证的青少年驾驶员在教练的陪同下进行比较。 教练有自己的制动踏板，可以像无人驾驶飞机的驾驶员一样拦截车轮。 十几岁的驾驶员在教练的陪同下，实际上的安全性得分很高，几乎所有无人驾驶车辆的得分都很高-除了优步，我将在后面讨论。 <br><br> 这些青少年驾驶员在通过最低限度的测试后获得了驾照，成为道路上最危险的驾驶员。 我们在旅途中释放他们以使其具有机动性，这也是因为这是使他们变得更加谨慎的成年驾驶员的唯一途径，他们最终将成为成年人。 我们承担着与驾驶十几岁的驾驶员相关的风险，希望将来能变得更加谨慎。 在道路上每一个冒险的少年中，都有一个成年人长大，一个更加谨慎的成年人（实际上少于一个成年人，因为并不是所有的少年都真正达到了这个最安全的年龄）。 <br><br><img src="https://habrastorage.org/webt/vr/dq/bq/vrdqbqrlnxepkvveqq-do1xcoko.jpeg" alt="图片"><br><br> 如前所述，无人机开发团队使人们处于危险之中，但是这种风险带来的好处是巨大的。 短暂的学习之旅将提高以后制造的所有后续汽车的安全性，这最终意味着数百万辆经过改进的汽车。 通过接受测试和开发的主要风险，我们将从未来的风险显着降低中受益。 当汽车开始比人们更安全地驾驶时，人们将选择乘无人驾驶汽车而不是独立驾驶，从而使他人不再处于危险之中，这将降低风险。 当喝酒或与上面列表中的任何项目相关联的人时，尤其如此。 <br><br> 有人认为，我们不仅要考虑特殊风险，还必须考虑必要风险。 因为如果没有必要，将人们置于一般风险之下是错误的。 特别是，有些人认为当前的团队进行了不必要的测试，这是错误的。 也许这是正确的方法（尽管当然，所需的测试数量仍存在争议）。 但是，如果我们考虑人们在旅途中做出冒险决定的原因-从送餐到提前一分钟返回家园，尽管我们可以忍受这些风险，但他们几乎无法满足必要水平。 <br><br> 在这里，我们必须从结果出发进行推理。  ,    ,      ,         .      - ,         .     -,                   .    – ,   – .   . <br><br><h3>   </h3><br>  ,   .         ,      0.1     .  –  ,  1  .       –  0.013   . ,      ,       .           – ,  ,     ,   1/250   .         ,    ,       .     ,                      .     ,    .  ,        ,        <b></b> (  )    ,     .       1.5   ,     .     (    1.7    ),          . <br><br>   ,     « »,      ?       –         ,       ,           .   ,       ,            . <br><br>       ,     .    ,      (    ),      100 000      .    1.5        .    . 100 000     –    ,    10         2-3  . <br><br>   ,      .        ,    ,       ,   ,              ,  .      . ,      ,   ,  «»  ,     .   ,        -,        . , ,            . <br><br><h3>    ? </h3><br>   ?       Waymo.      7  ,    Google.     10          .       ,   ,     ,             –     ,   ,   ,     .  ,                Waymo,   ,      –   ,     ,      .     ,          . <br><br> Tesla    ,      Tesla      .     4.3        2.7     . Tesla      ,        ,       ,   ,         .  ,          ,   (       )       ,  ,          .   , ,     - ,      ,    ,          . , Tesla            ,       ,    .          ,      Uber. <br><br><h3> Uber </h3><br>   2018    Uber    ,  , ,        .       ,            .    <a href="https://ideas.4brad.com/search/node/uber%2520fatality"> </a> ,        ,  ,      ,     99.9%  . Uber         ,   ,          -  ,       ,      .   ,   ,    ,  ,     ,       Uber,    ,    ,    ,  -          ,       .      ,             .    ,    .      ,     —       ,   ,     —      . Uber      18        ,      . <br><br>   ,            ,   ,   ,          .   ,      .  ,   Uber           ,   .    ,       ,     .     - ,    ,       ,    Uber  -  ,        .  Uber        . <br><br>            ,      ,       .  ,          .        ,       ,         .   ,   ,      ,          ,     ,             .               0,07%        ,           ,   ,    . <br><br>           . ,            .   ,  Uber      ( ),  ,          , ,      .        ,   .   ,      –  .     ,             ,       .        ,         ,       .          3  . <br><br><h3> 结论 </h3><br>        ,    –      ,      .     ,    ,   ,        ,   .     ,    ,            ,       . <br><br> <b>  ,     ,   100      ,    .    ,   ,     ,      ,        .</b> <br><br>       ,    .       ,    ,         ,       — ,     —     .  ,   ,     ,     ,   - ,     ,       .   ,     ,       . <br><br>      ,   ,     .    .               ,       ,       . <br><br><hr><br><img src="https://habrastorage.org/webt/4m/5z/_p/4m5z_pc9zhjja8pmtwxvaihckfe.png" alt="图片"><br><br><div class="spoiler">  <b class="spoiler_title">关于ITELMA</b> <div class="spoiler_text"> 我们是一家大型<a href="https://en.wikipedia.org/wiki/Automotive_industry">汽车</a>零部件公司。 该公司拥有约2500名员工，其中包括650名工程师。 <br><br> 我们也许是俄罗斯汽车电子发展最强大的能力中心。 现在，我们正在积极发展，我们开设了许多职位空缺（包括该地区的大约30个职位），例如软件工程师，设计工程师，首席开发工程师（DSP程序员）等。 <br><br> 汽车制造商面临许多有趣的挑战，并推动行业发展。 如果您想成长为专家并向最好的人学习，我们将很高兴见到您加入我们的团队。 我们也准备分享专业知识，这是汽车领域最重要的事情。 问我们任何问题，我们将回答，我们将进行讨论。 </div></div><br>  <b>阅读更多有用的文章：</b> <br><br><ul><li>  <a href="https://habr.com/ru/company/itelma/blog/479736/">相机或激光</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/478640/">开源自动驾驶汽车</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476824/">麦肯锡：重新思考汽车中的软件和电子架构</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476054/">汽车业已掀起另一场操作系统之战</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475576/">车内程序代码</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475448/">现代汽车中的代码行比...更多</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN483476/">https://habr.com/ru/post/zh-CN483476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN483462/index.html">闭嘴拿我的钱</a></li>
<li><a href="../zh-CN483466/index.html">反向传播方法介绍</a></li>
<li><a href="../zh-CN483468/index.html">Flutter集成测试-简单</a></li>
<li><a href="../zh-CN483470/index.html">有效地放置图块（Pro CSS，SVG，图案等）</a></li>
<li><a href="../zh-CN483472/index.html">删除所有内容：如何删除数据并将NVMe SSD恢复为出厂设置</a></li>
<li><a href="../zh-CN483478/index.html">太阳，风和水ver 0.1</a></li>
<li><a href="../zh-CN483480/index.html">填字游戏“感觉像SOC分析师”</a></li>
<li><a href="../zh-CN483482/index.html">美国联邦通信委员会pro V2V，V2I和V2X</a></li>
<li><a href="../zh-CN483484/index.html">“假装”：无人驾驶汽车如何“向右投降”</a></li>
<li><a href="../zh-CN483492/index.html">解决json_encode（PHP）的典型问题</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
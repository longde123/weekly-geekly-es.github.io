<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßö üî° üë®‚Äçüë®‚Äçüë¶ S√≠ntesis de voz de la red neuronal utilizando la arquitectura Tacotron 2, o "Obtener alineaci√≥n o morir en el intento" ü§öüèΩ üïç üèí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A nuestro equipo se le encomend√≥ la tarea: repetir los resultados del trabajo de la red neuronal artificial de s√≠ntesis de voz de la autor√≠a de Tacotr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>S√≠ntesis de voz de la red neuronal utilizando la arquitectura Tacotron 2, o "Obtener alineaci√≥n o morir en el intento"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/436312/"><img src="https://habrastorage.org/webt/yu/y0/2f/yuy02fd0i4fodpxxadfkf0k2ori.jpeg"><br><br>  A nuestro equipo se le encomend√≥ la tarea: repetir los resultados del trabajo de la red neuronal artificial de s√≠ntesis de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">voz de la</a> autor√≠a de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tacotron2</a> DeepMind.  Esta es una historia sobre el camino espinoso que recorrimos durante la implementaci√≥n del proyecto. <br><a name="habracut"></a><br>  La tarea de s√≠ntesis de voz por computadora ha sido de inter√©s para cient√≠ficos y expertos t√©cnicos.  Sin embargo, los m√©todos cl√°sicos no permiten la s√≠ntesis del habla, indistinguible de la humana.  Y aqu√≠, como en muchas otras √°reas, el aprendizaje profundo vino al rescate. <br><br>  Veamos los m√©todos de s√≠ntesis cl√°sicos. <br><br><h2>  S√≠ntesis de voz concatenativa </h2><br>  Este m√©todo se basa en pregrabar fragmentos cortos de audio, que luego se combinan para crear un discurso coherente.  Resulta ser muy limpio y claro, pero completamente desprovisto de componentes emocionales y entonacionales, es decir, suena poco natural.  Y todo porque es imposible obtener una grabaci√≥n de audio de todas las palabras posibles pronunciadas en todas las combinaciones posibles de emociones y prosodia.  Los sistemas de concatenaci√≥n requieren grandes bases de datos y combinaciones de codificaci√≥n para formar palabras.  El desarrollo de un sistema confiable lleva mucho tiempo. <br><br><h2>  S√≠ntesis param√©trica del habla </h2><br>  Las aplicaciones TTS concatenacionales son limitadas debido a los altos requisitos de datos y al tiempo de desarrollo.  Por lo tanto, se desarroll√≥ un m√©todo estad√≠stico que explora la naturaleza de los datos.  Genera voz combinando par√°metros como frecuencia, espectro de amplitud, etc. <br><br>  La s√≠ntesis param√©trica consta de dos etapas. <br><br><ol><li>  Primero, las caracter√≠sticas ling√º√≠sticas, como los fonemas, la duraci√≥n, etc., se extraen del texto. </li><li>  Luego, para el vocoder (sistema que genera formas de onda), se extraen caracter√≠sticas que representan la se√±al de voz correspondiente: cepstrum, frecuencia, espectrograma lineal, espectrograma de tiza. </li><li>  Estos par√°metros configurados manualmente, junto con las caracter√≠sticas ling√º√≠sticas, se transfieren al modelo de vocoder y realiza muchas transformaciones complejas para generar una onda de sonido.  Al mismo tiempo, el vocoder eval√∫a los par√°metros del habla, como fase, prosodia, entonaci√≥n y otros. </li></ol><br>  Si podemos aproximar los par√°metros que definen el habla en cada una de sus unidades, entonces podemos crear un modelo param√©trico.  La s√≠ntesis param√©trica requiere significativamente menos datos y trabajo duro que los sistemas concatenativos. <br><br>  Te√≥ricamente, todo es simple, pero en la pr√°ctica hay muchos artefactos que conducen a un habla amortiguada con un sonido "zumbido", que no se parece en nada a un sonido natural. <br><br>  El hecho es que en cada etapa de la s√≠ntesis codificamos algunas caracter√≠sticas y esperamos obtener un discurso que suene realista.  Pero los datos seleccionados se basan en nuestra comprensi√≥n del habla, y el conocimiento humano no es absoluto, por lo tanto, los signos tomados no ser√°n necesariamente la mejor soluci√≥n posible. <br><br>  Y aqu√≠ Deep Learning entra en escena en todo su esplendor. <br><br>  Las redes neuronales profundas son una herramienta poderosa que, en teor√≠a, puede aproximarse a una funci√≥n compleja arbitraria, es decir, traer un poco de espacio de datos de entrada X al espacio de datos de salida Y. En el contexto de nuestra tarea, estos ser√°n texto y audio con voz, respectivamente. <br><br><h2>  Preprocesamiento de datos </h2><br>  Para comenzar, determinaremos qu√© tenemos como entrada y qu√© queremos obtener en la salida. <br><br>  La entrada ser√° texto y la salida ser√° un espectrograma de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tiza</a> .  Esta es una representaci√≥n de bajo nivel obtenida aplicando la transformada r√°pida de Fourier a una se√±al de audio discreta.  Cabe se√±alar de inmediato que los espectrogramas obtenidos de esta manera todav√≠a <b>deben normalizarse</b> comprimiendo el rango din√°mico.  Esto le permite reducir la relaci√≥n natural entre el sonido m√°s alto y el m√°s bajo de la grabaci√≥n.  En nuestros experimentos, el uso de espectrogramas reducidos al <b>rango [-4; 4]</b> demostr√≥ ser el mejor. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/849/8fe/eb1/8498feeb1bd525506739c85bc5230c65.png"><br>  <i>Figura 1: espectrograma de tiza de la se√±al de audio de voz reducida al rango [-4; 4].</i> <br><br>  Como conjunto de datos de entrenamiento, elegimos el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto de datos LJSpeech</a> , que contiene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">13,100</a> pistas de audio durante 2-10 segundos.  y un archivo con el texto correspondiente al discurso en ingl√©s grabado en audio. <br><br>  El sonido que usa las transformaciones anteriores se codifica en espectrogramas de tiza.  El texto est√° tokenizado y transformado. <br><br>  en una secuencia de enteros.  Debo enfatizar de inmediato que los textos est√°n normalizados: todos los n√∫meros est√°n escritos verbalmente y se descifran las posibles abreviaturas, por ejemplo: ‚ÄúSra.  Robinson "-" Missis Robinson ". <br><br>  Por lo tanto, despu√©s del preprocesamiento, obtenemos conjuntos de matrices numpy de secuencias num√©ricas y espectrogramas de tiza grabados en archivos npy en el disco. <br><br>  Para que en la etapa de entrenamiento coincidan todas las dimensiones en los tensores del parche, agregaremos rellenos a secuencias cortas.  Para secuencias en forma de textos, estas se reservar√°n para el relleno 0, y para los espectrogramas, cuadros cuyos valores son ligeramente m√°s bajos que los espectrogramas m√≠nimos determinados por nosotros.  Esto se recomienda para aislar estos rellenos, separ√°ndolos del ruido y el silencio. <br><br>  Ahora tenemos datos que representan texto y audio que son adecuados para su procesamiento por una red neuronal artificial.  Veamos la arquitectura de Feature prediction net, que por el nombre del elemento central de todo el sistema de s√≠ntesis se llamar√° Tacotron2. <br><br><h2>  Arquitectura </h2><br>  Tacotron 2 no es una red, sino dos: funci√≥n de predicci√≥n de red y NN-vocoder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveNet</a> .  El art√≠culo original, as√≠ como nuestra propia visi√≥n del trabajo realizado, nos permite considerar Feature prediction net como el primer viol√≠n, mientras que el vocoder WaveNet desempe√±a el papel de un sistema perif√©rico. <br><br>  Tacotron2 es una arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">secuencia a secuencia</a> .  Consiste en un <b>codificador</b> (codificador), que crea una idea interna de la se√±al de entrada (s√≠mbolos simb√≥licos), y un <b>decodificador</b> (decodificador), que convierte esta representaci√≥n en un espectrograma de tiza.  Tambi√©n un elemento extremadamente importante de la red es el llamado <b>PostNet</b> , que est√° dise√±ado para mejorar el espectrograma generado por el decodificador. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/744/8c3/587/7448c35878c1640d1e156e745fa2bd96.png"><br>  <i>Figura 2: Arquitectura de red Tacotron 2.</i> <br><br>  Consideremos con m√°s detalle los bloques de red y sus m√≥dulos. <br><br>  La primera capa del <b>codificador</b> es la capa de incrustaci√≥n.  Basado en una secuencia de n√∫meros naturales que representan caracteres, crea vectores multidimensionales (512 dimensiones). <br><br>  A continuaci√≥n, los vectores de incrustaci√≥n se introducen en un bloque de tres capas convolucionales unidimensionales.  Cada capa incluye 512 filtros de longitud 5. Este valor es un buen tama√±o de filtro en este contexto, ya que captura un cierto car√°cter, as√≠ como sus dos vecinos anteriores y dos posteriores.  A cada capa convolucional le sigue la normalizaci√≥n de mini lotes y la activaci√≥n de ReLU. <br><br>  Los tensores obtenidos despu√©s del bloqueo convolucional se aplican a capas de LSTM bidireccionales, 256 neuronas cada una.  Los resultados de env√≠o y devoluci√≥n se concatenan. <br><br>  <b>El decodificador</b> tiene una arquitectura recurrente, es decir, en cada paso posterior, se utiliza la salida del paso anterior.  Aqu√≠ ser√°n un cuadro del espectrograma.  Otro elemento importante, si no clave, de este sistema es el mecanismo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">atenci√≥n</a> suave (entrenada), una t√©cnica relativamente nueva que est√° ganando cada vez m√°s popularidad.  En cada paso del decodificador, la atenci√≥n para formar un vector de contexto y actualizar el peso de la atenci√≥n utiliza: <br><br><ul><li>  la proyecci√≥n del estado oculto anterior de la red RNN del decodificador en una capa totalmente conectada, </li><li>  proyecci√≥n de la salida del codificador en una capa totalmente conectada, </li><li>  as√≠ como pesos de atenci√≥n aditivos (acumulados en cada paso de tiempo del decodificador). </li></ul><br>  La idea de atenci√≥n debe entenderse de la siguiente manera: "qu√© parte de los datos del codificador se debe utilizar en el paso actual del decodificador". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/f4d/410/e47f4d41040e5926c719ef909d21cc99.png"><br>  <i>Figura 3: Esquema del mecanismo de atenci√≥n.</i> <br><br>  En cada paso del decodificador, <i><sub>se</sub></i> calcula el vector de contexto <i>C <sub>i</sub></i> (indicado en la figura anterior como "salidas codificadas atendidas"), que es un producto de la salida del codificador ( <i>h</i> ) y los pesos de atenci√≥n ( <i>Œ±</i> ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b27/8dc/00e/b278dc00e38919c05351ff95c03dc309.png"><br><br>  donde <i>Œ± <sub>ij</sub></i> son los pesos de atenci√≥n calculados por la f√≥rmula: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3cc/344/b9f/3cc344b9f86ba736045a83a7cae8b77e.png"><br><br>  donde <i>e <sub>ij</sub></i> es la llamada "energ√≠a", cuya f√≥rmula de c√°lculo depende del tipo de mecanismo de atenci√≥n que utilice (en nuestro caso, ser√° un tipo h√≠brido, utilizando tanto la atenci√≥n basada en la ubicaci√≥n como la atenci√≥n basada en el contenido).  La energ√≠a se calcula mediante la f√≥rmula: <br><br>  <i>e <sub>ij</sub> = v <sub>aT</sub> tanh (Ws <sub>i-1</sub> + Vh <sub>j</sub> + Uf <sub>i, j</sub> + b)</i> <br><br>  donde: <br><ul><li>  <i>s <sub>i-1</sub></i> : estado oculto anterior de la red LSTM del decodificador, </li><li>  <i>Œ± <sub>i-1</sub></i> - pesos de atenci√≥n anteriores, </li><li>  <i>h <sub>j</sub></i> es el en√©simo estado oculto del codificador, </li><li>  <i>W</i> , <i>V</i> , <i>U</i> , <i>v <sub>a</sub></i> y <i>b</i> son par√°metros de entrenamiento, </li><li>  <i>f <sub>i, j</sub></i> - signos de ubicaci√≥n calculados por la f√≥rmula: <br><br>  <i>f <sub>i</sub> = F * Œ± <sub>i-1</sub></i> <br><br>  donde <i>F</i> es la operaci√≥n de convoluci√≥n. </li></ul><br><br>  Para una comprensi√≥n clara de lo que est√° sucediendo, agregamos que algunos de los m√≥dulos descritos a continuaci√≥n suponen el uso de informaci√≥n del paso anterior del decodificador.  Pero si este es el primer paso, entonces la informaci√≥n ser√° tensores de valores cero, lo cual es una pr√°ctica com√∫n al crear estructuras de recurrencia. <br><br>  Ahora considere <b>el algoritmo de operaci√≥n</b> . <br><br>  Primero, la salida del decodificador del paso de tiempo anterior se alimenta a un peque√±o m√≥dulo PreNet, que es una pila de dos capas completamente conectadas de 256 neuronas, que se alternan con capas de ca√≠da con una tasa de 0.5.  Una caracter√≠stica distintiva de este m√≥dulo es que el abandono se usa en √©l no solo en la etapa de entrenamiento del modelo, sino tambi√©n en la etapa de salida. <br><br>  La salida PreNet en concatenaci√≥n con el vector de contexto obtenido como resultado del mecanismo de atenci√≥n se alimenta a la entrada en una red LSTM unidireccional de dos capas, con 1024 neuronas en cada capa. <br><br>  Luego, la concatenaci√≥n de la salida de las capas LSTM con el mismo vector de contexto (y posiblemente diferente) se alimenta a una capa totalmente conectada con 80 neuronas, que corresponde al n√∫mero de canales del espectrograma.  Esta capa final del decodificador forma el espectrograma predicho cuadro por cuadro.  Y ya su salida se suministra como entrada para el siguiente paso de tiempo del decodificador en PreNet. <br><br>  ¬øPor qu√© mencionamos en el p√°rrafo anterior que el vector de contexto ya puede ser diferente?  Uno de los enfoques posibles es recalcular el vector de contexto despu√©s de obtener el estado latente de la red LSTM en este paso.  Sin embargo, en nuestros experimentos este enfoque no se justific√≥. <br><br>  Adem√°s de la proyecci√≥n en una capa totalmente conectada de 80 neuronas, la concatenaci√≥n de la salida de las capas LSTM con un vector de contexto se alimenta a una capa completamente conectada con una neurona, seguida de la activaci√≥n sigmoidea: esta es una capa de "predicci√≥n de token de parada".  √âl predice la probabilidad de que el marco creado en este paso del decodificador sea final.  Esta capa est√° dise√±ada para generar un espectrograma de longitud no fija, pero arbitraria en la etapa de salida del modelo.  Es decir, en la etapa de salida, este elemento determina el n√∫mero de pasos del decodificador.  Se puede considerar como un clasificador binario. <br><br>  La salida del decodificador de todos sus pasos ser√° el espectrograma predicho.  Sin embargo, esto no es todo.  Para mejorar la calidad del espectrograma, se pasa a trav√©s del m√≥dulo PostNet, que es una pila de cinco capas convolucionales unidimensionales con 512 filtros en cada una y con un tama√±o de filtro de 5. La normalizaci√≥n por lotes y la activaci√≥n tangente siguen a cada capa (excepto la √∫ltima).  Para volver a la dimensi√≥n del espectrograma, pasamos los datos de salida posteriores a la red a trav√©s de una capa totalmente conectada con 80 neuronas y agregamos los datos recibidos con el resultado inicial del decodificador.  Obtenemos el espectrograma de tiza generado a partir del texto.  Ganancia <br><br>  Todos los m√≥dulos convolucionales se regularizan con capas de abandono con una tasa de 0,5 y capas de recurrencia con el m√©todo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zoneout</a> m√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reciente</a> con una tasa de 0,1.  Es bastante simple: en lugar de aplicar el estado latente y el estado de celda obtenido en el paso actual al siguiente paso de tiempo de la red LSTM, reemplazamos parte de los datos con los valores del paso anterior.  Esto se hace tanto en la etapa de entrenamiento como en la etapa de retiro.  En este caso, solo el estado oculto (que se pasa al siguiente paso de LSTM) se expone al m√©todo Zoneout en cada paso, mientras que la salida de la celda LSTM en el paso actual permanece sin cambios. <br><br>  Elegimos PyTorch como marco de aprendizaje profundo.  Aunque en el momento de la implementaci√≥n de la red se encontraba en un estado de prelanzamiento, ya era una herramienta muy poderosa para construir y entrenar redes neuronales artificiales.  En nuestro trabajo, utilizamos otros marcos como TensorFlow y Keras.  Sin embargo, este √∫ltimo se descart√≥ debido a la necesidad de implementar estructuras personalizadas no est√°ndar, y si comparamos TensorFlow y PyTorch, entonces, al usar el segundo, no hay sensaci√≥n de que el modelo est√© arrancado del lenguaje Python.  Sin embargo, no nos comprometemos a afirmar que uno de ellos es mejor y el otro peor.  El uso de un marco particular puede depender de varios factores. <br><br>  La red se entrena mediante el m√©todo de retropropagaci√≥n.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ADAM se</a> usa como optimizador, el error cuadr√°tico medio antes y despu√©s de PostNet, as√≠ como la entrop√≠a cruzada binaria por encima de los valores reales y pronosticados de la capa de predicci√≥n de token de parada, se usan como funciones de error.  El error resultante es una simple suma de estos tres. <br><br>  El modelo fue entrenado en una sola GPU GeForce 1080Ti con 11 GB de memoria. <br><br><h2>  Visualizaci√≥n </h2><br>  Cuando se trabaja con un modelo tan grande, es importante ver c√≥mo va el proceso de aprendizaje.  Y aqu√≠ TensorBoard se convirti√≥ en una herramienta conveniente.  Rastreamos el valor del error en las iteraciones de entrenamiento y validaci√≥n.  Adem√°s, mostramos espectrogramas objetivo, espectrogramas predichos en la etapa de entrenamiento, espectrogramas predichos en la etapa de validaci√≥n y alineaci√≥n, que es un peso de atenci√≥n acumulado aditivamente en todos los pasos del entrenamiento. <br><br>  Es posible que al principio su atenci√≥n no sea demasiado informativa: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4ce/600/7be/4ce6007bef5b7fe17aa8df56472904bc.png"><br>  <i>Figura 4: Un ejemplo de escalas de atenci√≥n mal entrenadas.</i> <br><br>  Pero despu√©s de que todos sus m√≥dulos comiencen a funcionar como un reloj suizo, finalmente obtendr√° algo como esto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8e7/5d9/ff0/8e75d9ff0e0da78915c1a16f623a99e8.png"><br>  <i>Figura 5: Ejemplo de escalas de atenci√≥n exitosamente entrenadas.</i> <br><br>  ¬øQu√© significa esta tabla?  En cada paso del decodificador, intentamos decodificar un cuadro del espectrograma.  Sin embargo, no est√° claro qu√© informaci√≥n necesita usar el codificador en cada paso del decodificador.  Se puede suponer que esta correspondencia ser√° directa.  Por ejemplo, si tenemos una secuencia de texto de entrada de 200 caracteres y un espectrograma correspondiente de 800 cuadros, entonces habr√° 4 cuadros para cada car√°cter.  Sin embargo, debe admitir que el discurso generado sobre la base de tal espectrograma estar√≠a completamente desprovisto de naturalidad.  Pronunciamos algunas palabras m√°s r√°pido, algunas m√°s lento, en alg√∫n lugar donde hacemos una pausa, pero en alg√∫n otro lugar donde no lo hacemos.  Y considerar todos los contextos posibles no es posible.  Es por eso que la atenci√≥n es un elemento clave de todo el sistema: establece la correspondencia entre el paso del decodificador y la informaci√≥n del codificador para obtener la informaci√≥n necesaria para generar un marco espec√≠fico.  Y cuanto mayor sea el valor de los pesos de atenci√≥n, m√°s "se debe prestar atenci√≥n" a la parte correspondiente de los datos del codificador al generar el marco del espectrograma. <br><br>  En la etapa de capacitaci√≥n, tambi√©n ser√° √∫til generar audio, y no solo evaluar visualmente la calidad de los espectrogramas y la atenci√≥n.  Sin embargo, aquellos que han trabajado con WaveNet estar√°n de acuerdo en que usarlo como un vocoder en la etapa de entrenamiento ser√≠a un lujo inaceptable en t√©rminos de tiempo.  Por lo tanto, se recomienda utilizar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el algoritmo Griffin-Lim</a> , que permite la reconstrucci√≥n parcial de la se√±al despu√©s de transformaciones r√°pidas de Fourier.  ¬øPor qu√© parcialmente?  El hecho es que cuando convertimos la se√±al en espectrogramas, perdemos informaci√≥n de fase.  Sin embargo, la calidad del audio as√≠ obtenido ser√° suficiente para entender en qu√© direcci√≥n se est√° moviendo. <br><br><h2>  Lecciones aprendidas </h2><br>  Aqu√≠ compartiremos algunas ideas sobre c√≥mo construir el proceso de desarrollo, envi√°ndolas en el formato de sugerencias.  Algunos de ellos son bastante generales, otros son m√°s espec√≠ficos. <br><br>  <b>Sobre la organizaci√≥n del flujo de trabajo</b> : <br><br><ul><li>  Utilice el sistema de control de versiones, describa clara y claramente todos los cambios.  Esto puede parecer una recomendaci√≥n obvia, pero a√∫n as√≠.  Al buscar la arquitectura √≥ptima, los cambios ocurren constantemente.  Y despu√©s de haber recibido un resultado intermedio satisfactorio, aseg√∫rese de hacerse un punto de control para poder realizar los cambios posteriores de manera segura. <br></li><li>  Desde nuestro punto de vista, en tales arquitecturas uno debe adherirse a los principios de encapsulaci√≥n: una clase - un m√≥dulo Python.  Este enfoque no es com√∫n en las tareas de ML, pero lo ayudar√° a estructurar su c√≥digo y acelerar la depuraci√≥n y el desarrollo.  Tanto en el c√≥digo como en su visi√≥n de la arquitectura, div√≠dala en bloques, bloques en m√≥dulos y m√≥dulos en capas.  Si el m√≥dulo tiene c√≥digo que desempe√±a un rol espec√≠fico, comb√≠nelo en un m√©todo de clase de m√≥dulo.  Estas son verdades comunes, pero no fuimos demasiado flojos para decir sobre ellas nuevamente. <br></li><li>  Proporcione <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">clases de estilo numpy</a> con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> .  Esto simplificar√° enormemente el trabajo tanto para usted como para sus colegas que leer√°n su c√≥digo. <br></li><li>  Dibuja siempre la arquitectura de tu modelo.  En primer lugar, le ayudar√° a darle sentido y, en segundo lugar, una vista lateral de la arquitectura y los hiperpar√°metros del modelo le permitir√°n identificar r√°pidamente las inexactitudes en su enfoque. <br></li><li>  Mejor trabajar en equipo.  Si trabaja solo, re√∫na colegas y discuta su trabajo.  Como m√≠nimo, pueden hacerle una pregunta que lo llevar√° a algunas reflexiones, pero al m√°ximo le se√±alar√°n una inexactitud espec√≠fica que no le permite entrenar con √©xito el modelo. <br></li><li>  Otro truco √∫til ya est√° asociado con el preprocesamiento de datos.  Suponga que decide probar algunas hip√≥tesis y hacer los cambios apropiados al modelo.  Pero reiniciar el entrenamiento, especialmente antes del fin de semana, ser√° arriesgado.  El enfoque puede ser inicialmente incorrecto y perder√° tiempo.  ¬øQu√© hacer entonces?  Aumente el tama√±o de la ventana Transformaci√≥n r√°pida de Fourier.  El par√°metro predeterminado es 1024;  aumentarlo en 4, o incluso 8 veces.  Esto "exprimir√°" los espectrogramas en el n√∫mero apropiado de veces y acelerar√° enormemente el aprendizaje.  El audio recuperado de ellos tendr√° una calidad inferior, ¬øpero esta no es tu tarea ahora?  En 2-3 horas ya puede obtener la alineaci√≥n ("alineaci√≥n" de las escalas de atenci√≥n, como se muestra en la figura anterior), esto indicar√° la correcci√≥n arquitect√≥nica del enfoque y ya se puede probar en grandes datos. <br></li></ul><br>  <b>Modelos de construcci√≥n y entrenamiento</b> : <br><br><ul><li>  Sugerimos que si los lotes no se formaran al azar, pero en funci√≥n de su longitud, acelerar√≠an el proceso de entrenamiento del modelo y mejorar√≠an los espectrogramas generados.  El supuesto l√≥gico, que se basa en la hip√≥tesis de que cuanto m√°s se alimenta una se√±al √∫til (y no relleno) a la red de entrenamiento, mejor.  Sin embargo, este enfoque no se justific√≥ a s√≠ mismo; en nuestros experimentos, no pudimos capacitar a la red de esta manera.  Esto probablemente se deba a la p√©rdida de aleatoriedad en la selecci√≥n de instancias para el entrenamiento. <br></li><li>  Utilice algoritmos modernos de inicializaci√≥n de par√°metros de red con algunos estados iniciales optimizados.  Por ejemplo, en nuestros experimentos, utilizamos la inicializaci√≥n de peso uniforme de Xavier.  Si en su m√≥dulo necesita utilizar la normalizaci√≥n por mini-lote y alguna funci√≥n de activaci√≥n, entonces deben alternar entre s√≠ en este orden.  De hecho, si aplicamos, por ejemplo, la activaci√≥n de ReLU, inmediatamente perdemos toda la se√±al negativa que deber√≠a estar involucrada en el proceso de normalizaci√≥n de los datos de un lote en particular. <br></li><li>  Desde un paso de aprendizaje espec√≠fico, use una tasa de aprendizaje din√°mica.  Esto realmente ayuda a reducir el valor de error y aumentar la calidad de los espectrogramas generados. <br></li><li>  Despu√©s de crear el modelo y los intentos fallidos de entrenarlo en lotes de todo el conjunto de datos, ser√° √∫til intentar volver a entrenarlo en un lote.    ,   alignment,           (    ).  ,      ,      . <br><br>    .        .  ,        ‚Äì      .    ,            .       ,       . </li><li>    RNN-              .      . ,           .        ?             LSTM-     -. <br></li><li>       ,   LSTM-,      ¬´ ¬ª: ¬´ <i>       ,         LSTM-.      ¬´¬ª  bf.   ,        ,    ,   LSTM-     ft  1/2.   ,        :    ,        ¬´¬ª  1/2,         .    bf    ,  1   2:     ft                 </i> ¬ª. <br></li><li>   seq2seq-         .       ‚Äî       ,         .           ?           ,        ( ). <br></li><li> Ahora una recomendaci√≥n espec√≠fica para el marco PyTorch.  Aunque la capa LSTM en el decodificador es esencialmente su propia celda LSTM, que recibe informaci√≥n para solo un elemento de la secuencia en cada paso del decodificador, se recomienda utilizar la clase <code>torch.nn.LSTM</code> lugar de <code>torch.nn.LSTMCell</code> .  La raz√≥n es que el backend LSTM se implementa en la biblioteca CUDNN en C y el LSTMCell en Python.  Este truco te permitir√° aumentar significativamente la velocidad del sistema. </li></ul><br>  Y al final del art√≠culo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">compartiremos ejemplos de generaci√≥n de discurso a partir de textos que no estaban contenidos en el conjunto de capacitaci√≥n.</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436312/">https://habr.com/ru/post/es436312/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436302/index.html">Experiencia de sustituci√≥n real de importaciones utilizando el sistema de almacenamiento ruso AERODISK</a></li>
<li><a href="../es436304/index.html">Zimbra Collaboration Suite y la lucha contra el phishing</a></li>
<li><a href="../es436306/index.html">Machine Learning para Vertica</a></li>
<li><a href="../es436308/index.html">Rostelecom puede convertirse en un monopolista en el mercado de centros de datos</a></li>
<li><a href="../es436310/index.html">Como lo hizo Ivan Metrics, DevOps lo hizo. Objeto de influencia</a></li>
<li><a href="../es436314/index.html">Robo-hotel japon√©s "dispar√≥" la mitad de sus robots debido a los problemas que crean</a></li>
<li><a href="../es436316/index.html">C√≥mo las tarjetas inteligentes ayudan a impulsar proyectos de TI</a></li>
<li><a href="../es436318/index.html">Nuevas funciones de automatizaci√≥n de red en Red Hat Ansible</a></li>
<li><a href="../es436320/index.html">Muchas propiedades u objeto de propiedad: criterios de selecci√≥n</a></li>
<li><a href="../es436322/index.html">@Pythonetc Diciembre 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèº‚Äçüîß üë®üèΩ‚Äçü§ù‚Äçüë®üèª üë®üèæ‚Äçüè≠ Filtrage lin√©aire optimal: de la descente de gradient aux filtres adaptatifs üêß üéë ü§ï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="D√©velopper le sujet des r√©sum√©s dans la sp√©cialit√© du master "Communication et traitement du signal" (TU Ilmenau), je voudrais poursuivre l'un des pri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Filtrage lin√©aire optimal: de la descente de gradient aux filtres adaptatifs</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455497/"><p>  D√©velopper le sujet des r√©sum√©s dans la sp√©cialit√© du master "Communication et traitement du signal" (TU Ilmenau), je voudrais poursuivre l'un des principaux sujets du cours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"Traitement adaptatif et matriciel du signal"</a> .  √Ä savoir, les bases du filtrage adaptatif. </p><br><p>  <u>Pour qui cet article a √©t√© √©crit pour la premi√®re fois:</u> <u><br></u> <br>  1) pour une confr√©rie √©tudiante d'une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sp√©cialit√© autochtone</a> ; <br>  2) pour les enseignants qui pr√©parent des s√©minaires pratiques, mais n'ont pas encore d√©cid√© des outils - voici des exemples en <strong>python</strong> et <strong>Matlab / Octave</strong> ; <br>  3) pour toute personne int√©ress√©e par le sujet du filtrage. </p><br><p>  <u>Que peut-on trouver sous la coupe:</u> <u><br></u> <br>  1) des informations issues de la th√©orie, que j'ai essay√© d'organiser de mani√®re aussi concise que possible, mais, me semble-t-il, informative; <br>  2) exemples d'utilisation de filtres: notamment dans le cadre de l'√©galiseur du r√©seau d'antennes; <br>  3) des liens vers la litt√©rature de base et les biblioth√®ques ouvertes (en python), qui peuvent √™tre utiles pour la recherche. </p><br><p>  En g√©n√©ral, bienvenue et trions tout par points. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2f1/98b/d67/2f198bd673789161db58ad770c629faf.jpg"></p><a name="habracut"></a><br><p>  <em>La personne pensive sur la photo est famili√®re √† beaucoup, je pense, Norbert Wiener.</em>  <em>Pour la plupart, nous √©tudierons le filtre de son nom.</em>  <em>Cependant, on ne peut pas ne pas mentionner notre compatriote - Andrei Nikolaevich Kolmogorov, dont l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article de 1941 a</a> √©galement apport√© une contribution significative au d√©veloppement de la th√©orie du filtrage optimal, qui m√™me dans les sources anglaises est appel√©e la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">th√©orie du filtrage Kolmogorov-Wiener</a> .</em> </p><br><h2 id="chto-rassmatrivaem">  Que pensons-nous? </h2><br><p>  Aujourd'hui, nous envisageons un filtre classique √† r√©ponse impulsionnelle finie (FIR, r√©ponse impulsionnelle finie), qui peut √™tre d√©crit par le circuit simple suivant (Fig. 1). </p><br><p><img src="https://habrastorage.org/webt/to/or/u7/tooru7vj_f6aj0oe9wvpcde28kw.png"></p><br><p>  <em>Fig.1.</em>  <em>Le sch√©ma de filtrage FIR pour √©tudier le filtre de Wiener [1.</em>  <em>p.117]</em> </p><br><p>  Nous √©crirons sous forme matricielle ce qui sera exactement √† la sortie de ce stand: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/43f/615/39b/43f61539ba1f68998b24c39a8c539706.svg" alt="e (n) = d (n) - \ hat {d} (n | \ mathcal {U} _n) = d (n) - \ mathbf {w} ^ H \ mathbf {u} \ qquad (1)"></div><br><p>  D√©chiffrez la notation: </p><br><ul><li><img src="https://habrastorage.org/getpro/habr/post_images/6c5/882/04e/6c588204ed25c8bbb270106d7f08a4dd.svg" alt="e (n)">  Est la diff√©rence (erreur) entre les signaux donn√©s et re√ßus </li><li><img src="https://habrastorage.org/getpro/habr/post_images/771/807/bef/771807bef08a5612654d97e67695cf07.svg" alt="d (n)">  Est un signal pr√©d√©fini </li><li><img src="https://habrastorage.org/getpro/habr/post_images/960/b4e/a48/960b4ea48f3968f42c64eed1af640e1d.svg" alt="\ mathbf {u}">  Est un vecteur d'√©chantillons ou, en d'autres termes, un signal √† l'entr√©e du filtre </li><li><img src="https://habrastorage.org/getpro/habr/post_images/75f/f22/a5a/75ff22a5a4f95cbe489056bf704597f0.svg" alt="\ hat {d} (n | \ mathcal {U} _n)">  Le signal est-il √† la sortie du filtre </li><li><img src="https://habrastorage.org/getpro/habr/post_images/6f6/81f/9be/6f681f9be2ae30d1666fec498b59b3a3.svg" alt="\ mathbf {w} ^ H">  - c'est une conjugaison hermitienne du vecteur de coefficient de filtre - <u>c'est dans leur s√©lection optimale que r√©side l'adaptabilit√© du filtre</u> </li></ul><br><p>  Vous avez probablement d√©j√† devin√© que nous nous efforcerons de rechercher la plus petite diff√©rence entre le signal donn√© et le signal filtr√©, c'est-√†-dire la plus petite erreur.  Cela signifie que nous sommes confront√©s √† une t√¢che d'optimisation. </p><br><h2 id="chto-budem-optimizirovat">  Qu'allons-nous optimiser? </h2><br><p>  Pour optimiser, ou plut√¥t minimiser, nous ne <strong>signifierons</strong> pas seulement <strong>l'</strong> erreur, l' <strong>erreur</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">quadratique moyenne</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MSE - Mean Sqared Error</a> ): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b83/b62/193/b83b62193ca3490681c2cd8910e4d99a.svg" alt="MSE: J (\ mathbf {w}) = E \ {e (n) ^ 2 \} \ qquad (2)"></div><br><p>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/c48/76a/b10/c4876ab1024579fa30ea997a45efd50a.svg" alt="J (\ mathbf {w})">  d√©signe la fonction de co√ªt du vecteur de coefficients de filtre, et <img src="https://habrastorage.org/getpro/habr/post_images/f39/8e4/ded/f398e4ded6db9e55108d575a9b7d2f1f.svg" alt="E \ {* \}">  d√©signe le mat.  en attente. </p><br><p>  Le carr√© dans ce cas est tr√®s agr√©able, car cela signifie que nous sommes confront√©s au probl√®me de la <em>programmation convexe</em> (je n'ai recherch√© qu'un tel analogue de l' <em>optimisation convexe</em> anglaise), ce qui, √† son tour, implique un <u>seul extremum</u> (dans notre cas, un minimum). </p><br><p><img src="https://habrastorage.org/webt/hr/xj/mb/hrxjmbmimv7c2uvvicnuklqn9y0.png"></p><br><p>  <em>Fig.2.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La surface de l'erreur quadratique moyenne</a> .</em> </p><br><p>  Notre fonction d'erreur a une forme canonique [1, p. 121]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5da/121/788/5da121788f801656b55ee459c2f4d56d.svg" alt="J (\ mathbf {w}) = \ sigma ^ 2_d - \ mathbf {w} ^ H \ mathbf {p} - \ mathbf {p} ^ H \ mathbf {w} + \ mathbf {w} ^ H \ mathbf { R} \ mathbf {w} \ qquad (3)"></div><br><p>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/24f/50c/410/24f50c410ab0c2ca3dd302c630c734e8.svg" alt="\ sigma ^ 2_d">  Est la variance du signal attendu, <img src="https://habrastorage.org/getpro/habr/post_images/82c/861/559/82c86155992ccb2e83d6f9f3f9e92737.svg" alt="\ mathbf {p} = E \ {\ mathbf {u} (n) d ^ * (n) \}">  Est le vecteur de corr√©lation crois√©e entre le vecteur d'entr√©e et le signal attendu, et <img src="https://habrastorage.org/getpro/habr/post_images/664/01c/a88/66401ca883516093b2e73b7d519588ac.svg" alt="\ mathbf {R} = E \ {\ mathbf {u} (n) \ mathbf {u} ^ H (n) \}">  Est la matrice d'autocorr√©lation du signal d'entr√©e. </p><br><div class="spoiler">  <b class="spoiler_title">La conclusion de cette formule est l√† (je l'ai essay√©e plus clairement).</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/q6/sw/p5/q6swp5meopsxauj7yvygkwuc7-g.png" width="650"></div></div><br><p>  Comme nous l'avons not√© ci-dessus, si nous parlons de programmation convexe, nous aurons alors un extremum (minimum).  Ainsi, pour trouver la valeur minimale de la fonction de co√ªt (l'erreur quadratique moyenne minimale), il suffit de trouver la tangente de la pente de la tangente ou, en d'autres termes, la <u>d√©riv√©e partielle</u> par <u>rapport</u> √† notre variable √©tudi√©e: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1cd/d0b/114/1cdd0b114b5457761dd27338b4ee57f4.svg" alt="\ frac {\ delta J (\ mathbf {w})} {\ delta w ^ *} = - \ mathbf {p} + \ mathbf {R} \ mathbf {w} \ qquad (4)"></div><br><p>  Dans le meilleur des cas ( <img src="https://habrastorage.org/getpro/habr/post_images/ac6/219/d1c/ac6219d1cc1885e6f5936e40b5c7a980.svg" alt="\ mathbf {w} = \ mathbf {w} _ {opt}">  ), l'erreur devrait, bien s√ªr, √™tre minimale, ce qui signifie que nous assimilons la d√©riv√©e √† z√©ro: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/777/46e/9a7/77746e9a7ab3ff9df3cf340da4b7238d.svg" alt="\ mathbf {R} \ mathbf {w} _ {opt} = \ mathbf {p} \ qquad (5)"></div><br><p>  En fait, le voici, notre po√™le, √† partir duquel nous danserons plus loin: devant nous est un <u>syst√®me d'√©quations lin√©aires</u> . </p><br><h2 id="kak-budem-reshat">  Comment allons-nous d√©cider? </h2><br><p>  Il convient de noter tout de suite que les deux solutions, que nous examinerons ci-dessous, dans ce cas sont th√©oriques et p√©dagogiques, puisque <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  et <img src="https://habrastorage.org/getpro/habr/post_images/1fa/0e8/e9e/1fa0e8e9e33d7dbd533901bbf025bd9f.svg" alt="\ mathbf {p}">  connu √† l'avance (c'est-√†-dire que nous avions la capacit√© pr√©sum√©e de collecter suffisamment de statistiques pour les calculer).  Cependant, l'analyse de tels exemples simplifi√©s est la meilleure √† laquelle vous pouvez penser pour comprendre les approches de base. </p><br><h3 id="analiticheskoe-reshenie">  Solution analytique </h3><br><p>  Ce probl√®me peut √™tre r√©solu, pour ainsi dire, dans le front - en utilisant des matrices inverses: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/759/c3e/052/759c3e052c502aa04fe6da682a41ea2a.svg" alt="\ mathbf {w} _ {opt} = \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (6)"></div><br><p>  Une telle expression est appel√©e <strong>l'</strong> √©quation de Wiener-Hopf - elle nous sert encore de r√©f√©rence. </p><br><blockquote>  Bien s√ªr, pour √™tre compl√®tement m√©ticuleux, il serait probablement plus correct d'√©crire ce cas de mani√®re g√©n√©rale, c'est-√†-dire  pas avec <img src="https://habrastorage.org/getpro/habr/post_images/bd8/f0f/04a/bd8f0f04a92fe1055c350d4e32a8a256.svg" alt="^ {-}">  , et avec <img src="https://habrastorage.org/getpro/habr/post_images/017/3d5/ed9/0173d5ed99b25d00ec4245287142f165.svg" alt="^ +">  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pseudo-inversion</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/003/47f/bca/00347fbca15f40943c7fb7b20c38a3f9.svg" alt="\ mathbf {R} ^ + = \ mathbf {R} ^ H (\ mathbf {R} \ mathbf {R} ^ H) ^ {- 1}"><br><br>  Cependant, la matrice d'autocorr√©lation ne peut pas √™tre non carr√©e ou singuli√®re, donc, √† juste titre, nous pensons qu'il n'y a pas de contradiction. </blockquote><p>  De cette √©quation, il est analytiquement possible de d√©duire ce que la valeur minimale de la fonction de co√ªt sera √©gale (c'est-√†-dire, dans notre cas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MMSE</a> - erreur quadratique moyenne minimale): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c00/d2d/1f9/c00d2d1f9427762a17deae92ae3ea77c.svg" alt="J_ {min} = J (\ mathbf {w} _ {opt}) = \ sigma ^ 2_d - \ mathbf {p} ^ H \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (7)"></div><br><div class="spoiler">  <b class="spoiler_title">La d√©rivation de la formule est l√† (j'ai aussi essay√© de colorer plus color√©).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/ds/vh/nx/dsvhnxoudmo_qd4hesg_qkysdg8.jpeg"></p></div></div><br><p>  Eh bien, il y a une solution. </p><br><h3 id="reshenie-iterativnym-metodom">  Solution it√©rative </h3><br><p>  Cependant, oui, il est possible de r√©soudre un syst√®me d'√©quations lin√©aires sans inverser la matrice d'autocorr√©lation - de mani√®re it√©rative ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pour √©conomiser les calculs</a> ).  √Ä cette fin, consid√©rons la <strong>m√©thode</strong> native et compr√©hensible <strong>de descente √† gradient</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">m√©thode de descente la plus raide / √† gradient</a> ). </p><br><p>  L'essence de l'algorithme peut √™tre r√©duite √† ce qui suit: </p><br><ol><li>  Nous d√©finissons la variable souhait√©e sur une valeur par d√©faut (par exemple, <img src="https://habrastorage.org/getpro/habr/post_images/231/554/6f0/2315546f0e8aa127a8da693d41c53ff6.svg" alt="\ mathbf {w} (0) = \ mathbf {0}">  ) </li><li>  Choisissez une √©tape <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  (comment exactement nous choisissons, nous parlerons ci-dessous). </li><li>  Et puis, pour ainsi dire, nous descendons le long de notre surface d'origine (dans notre cas, c'est la surface MSE) avec une √©tape donn√©e <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  et une certaine vitesse d√©termin√©e par l'amplitude du gradient. </li></ol><br><p>  D'o√π le nom: <em>gradient</em> - gradient ou <em>plus raide</em> - <em>descente</em> pas √† pas - descente. </p><br><p>  Le gradient dans notre cas est d√©j√† connu: en fait, nous l'avons trouv√© en diff√©renciant la fonction de co√ªt (la surface est concave, comparer avec [1, p. 220]).  Nous √©crivons √† quoi ressemblera la formule de mise √† jour it√©rative de la variable souhait√©e (coefficients de filtre) [1, p.  220]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d6/4ff/7eb/6d64ff7eb98c4274e05a33a3eb127933.svg" alt="\ mathbf {w} (n + 1) = \ mathbf {w} (n) - \ mu [- \ mathbf {p} + \ mathbf {R} \ mathbf {w} (n)] \ qquad (8)"></div><br><p>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  Est le num√©ro d'it√©ration. </p><br><p>  Parlons maintenant du choix d'une taille de pas. </p><br><p>  Nous listons les pr√©misses √©videntes: </p><br><ul><li>  l'√©tape ne peut pas √™tre n√©gative ou nulle </li><li>  le pas ne doit pas √™tre trop grand, sinon l'algorithme ne convergera pas (il va, pour ainsi dire, sauter de bord en bord, sans tomber dans l'extr√™me) </li><li>  l'√©tape, bien s√ªr, peut √™tre tr√®s petite, mais ce n'est pas non plus enti√®rement souhaitable - l'algorithme passera plus de temps </li></ul><br><p>  Concernant le filtre de Wiener, des restrictions ont bien s√ªr d√©j√† √©t√© trouv√©es il y a longtemps [1, p. 222-226]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67d/64a/b6c/67d64ab6cf46d3438791ccea853421fb.svg" alt="0 <\ mu <\ frac {2} {\ lambda_ {max}} \ qquad (9)"></div><br><p>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/e5d/fa8/35d/e5dfa835ded907ecd7cf2b56d7061307.svg" alt="\ lambda_ {max}">  Est la plus grande valeur propre de la matrice d'autocorr√©lation <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  . </p><br><blockquote>  Soit dit en passant, les valeurs propres et les vecteurs sont un sujet int√©ressant distinct dans le contexte du filtrage lin√©aire.  Il existe m√™me un <em>filtre propre</em> complet <em>pour</em> ce cas (voir l'annexe 1). </blockquote><p>  Mais ce n'est heureusement pas tout.  Il existe √©galement une solution adaptative optimale: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f4c/3c2/fdf/f4c3c2fdf8ae926094bb67b391cd896b.svg" alt="\ mu (n) = \ frac {\ mathbf {\ gamma} (n) ^ H \ mathbf {\ gamma} (n)} {\ mathbf {\ gamma} (n) ^ H \ mathbf {R} \ mathbf { \ gamma} (n)} \ qquad (10)"></div><br><p>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/1b0/4a6/a31/1b04a6a318f99ec501290f59c0f924ac.svg" alt="\ mathbf {\ gamma} (n) = \ mathbf {p} - \ mathbf {R} \ mathbf {w} (n)">  Est un gradient n√©gatif.  Comme le montre la formule, l'√©tape est recalcul√©e √† chaque it√©ration, c'est-√†-dire qu'elle s'adapte. </p><br><div class="spoiler">  <b class="spoiler_title">La conclusion de la formule est ici (beaucoup de math√©matiques - ne regardez que les m√™mes nerds notoires comme moi).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/au/hq/0s/auhq0sxrspaduxdkclqctns1xtw.jpeg"></p></div></div><br><p>  D'accord, pour la deuxi√®me d√©cision, nous avons √©galement pr√©par√© le terrain. </p><br><h2 id="a-nelzya-li-na-primerah">  Mais est-ce possible avec des exemples? </h2><br><p>  Par souci de clart√©, nous allons effectuer une petite simulation.  Nous utiliserons <strong>Python 3.6.4</strong> . </p><br><blockquote>  Je dirai tout de suite que ces exemples font partie de l'un des devoirs, chacun √©tant propos√© aux √©tudiants pour solution dans les deux semaines.  J'ai r√©√©crit la partie sous python (afin de vulgariser le langage aupr√®s des ing√©nieurs radio).  Peut-√™tre que vous rencontrerez d'autres options sur le Web d'autres anciens √©l√®ves. </blockquote><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.linalg <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> toeplitz <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convmtx</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(h,n)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> toeplitz(np.hstack([h, np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)]),\ np.hstack([h[<span class="hljs-number"><span class="hljs-number">0</span></span>], np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)])) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MSE_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sigmaS, R, p, w)</span></span></span><span class="hljs-function">:</span></span> w = w.reshape(w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) wH = np.conj(w).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) p = p.reshape(p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) pH = np.conj(p).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) MSE = sigmaS - np.dot(wH, p) - np.dot(pH, w) + np.dot(np.dot(wH, R), w) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> MSE[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mu_opt_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(gamma, R)</span></span></span><span class="hljs-function">:</span></span> gamma = gamma.reshape(gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) gammaH = np.conj(gamma).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) mu_opt = np.dot(gammaH, gamma) / np.dot(np.dot(gammaH, R), gamma) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mu_opt[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  Nous utiliserons notre filtre lin√©aire pour le probl√®me d' <u>√©galisation de canal</u> , dont le but principal est de niveler les diff√©rents effets de ce canal sur le signal utile. </p><br><blockquote>  Le code source peut √™tre t√©l√©charg√© dans un fichier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ou <a href="">ici</a> (oui, j'avais un tel passe-temps - √©diter Wikipedia). </blockquote><br><h3 id="model-sistemy">  Mod√®le de syst√®me </h3><br><p>  Supposons qu'il existe un r√©seau d'antennes (nous l'avons d√©j√† examin√© dans un article sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MUSIQUE</a> ). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/61a/9c2/da7/61a9c2da745081459f9001d0252936f1.png"></p><br><p>  <em>Fig.</em>  <em>3. R√©seau d'antennes lin√©aires non directionnelles (ULAA - r√©seau d'antennes lin√©aires uniformes) [2, p.</em>  <em>32].</em> </p><br><p>  D√©finissez les param√®tres initiaux du r√©seau: </p><br><pre> <code class="python hljs">M = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (number of sensors)</span></span></code> </pre> <br><p>  Dans cet article, nous consid√©rerons quelque chose comme un <u>canal √† large bande avec √©vanouissement</u> , dont une caract√©ristique est <u>la propagation par trajets multiples</u> .  Pour de tels cas, une approche est g√©n√©ralement appliqu√©e dans laquelle chaque faisceau est mod√©lis√© en utilisant un retard d'une certaine amplitude (Fig. 4). </p><br><p><img src="https://habrastorage.org/webt/3t/tc/va/3ttcvau0o4njat-1beejefcudpy.png"></p><br><p>  <em>Fig.</em>  <em>4. Le mod√®le du canal large bande avec n retards fixes [3, p.</em>  <em>29].</em>  <em>Comme vous le comprenez, les d√©signations sp√©cifiques ne jouent aucun r√¥le - dans ce qui suit, nous utiliserons des d√©signations l√©g√®rement diff√©rentes.</em> </p><br><p>  Le mod√®le du signal re√ßu pour un capteur est exprim√© comme suit: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a3f/c3f/2f0/a3fc3f2f0cd278622946ce2da28005fd.svg" alt="x (n) = \ sum_ {l = 0} ^ Lh (l) s (n-l) + \ nu (n)"></div><br><p>  Dans ce cas <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  indique le num√©ro de r√©f√©rence, <img src="https://habrastorage.org/getpro/habr/post_images/e9f/c39/8e5/e9fc398e58e24442ddc2cf11684debbc.svg" alt="h (l)">  Est la r√©ponse du canal le long du <em>l-</em> √®me faisceau, <em>L</em> est le nombre de registres de retard, <em>s</em> est le signal (utile) transmis, <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ nu (n)">  - bruit additif. </p><br><p>  Pour plusieurs capteurs, la formule prendra la forme: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c0e/835/aa7/c0e835aa74d5dccf4ccdf625ebcc88b4.svg" alt="\ mathbf {x} (n) = \ mathbf {H} \ mathbf {s} (n) + \ mathbf {\ nu} (n)"></div><br><p>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/b0e/184/0ed/b0e1840edef9169f3e1f52974bea066d.svg" alt="\ mathbf {x} (n)">  et <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ mathbf {\ nu} (n)">  - avoir une dimension <img src="https://habrastorage.org/getpro/habr/post_images/132/724/0f2/1327240f26480a83dffca393bb730c44.svg" alt="M \ fois 1">  dimension <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  est √©gal √† <img src="https://habrastorage.org/getpro/habr/post_images/25e/e63/fbb/25ee63fbb4a32f1a00d5c02aaea9b80c.svg" alt="M \ fois (M-L)">  et la dimension <img src="https://habrastorage.org/getpro/habr/post_images/5e3/d36/045/5e3d360455a5a33db6c17f93c119a694.svg" alt="\ mathbf {s} (n)">  est √©gal <img src="https://habrastorage.org/getpro/habr/post_images/6e2/fc1/636/6e2fc16365ac2698555dd979ed6b5eeb.svg" alt="(M-L) \ fois 1">  . </p><br><p>  Supposons que chaque capteur re√ßoive √©galement un signal avec un certain retard, en raison de l'incidence de l'onde √† un angle.  Matrix <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  dans notre cas, il s'agira d'une matrice convolutionnelle pour le vecteur de r√©ponse de chaque rayon.  Je pense que le code sera plus clair: </p><br><pre> <code class="python hljs">h = np.array([<span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.779</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.722</span></span>, <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">1.862</span></span>]) L = len(h)<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-comment"><span class="hljs-comment"># number of signal sources H = convmtx(h,ML) print(H.shape) print(H)</span></span></code> </pre> <br><p>  La conclusion sera: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) &gt;&gt;&gt; array([[ <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>]])</code> </pre> <br><p>  Ensuite, nous d√©finissons les donn√©es initiales pour le signal et le bruit utiles: </p><br><pre> <code class="python hljs">sigmaS = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (the signal's s(n) power) sigmaN = 0.01 #   (the noise's n(n) power)</span></span></code> </pre> <br><p>  Passons maintenant aux corr√©lations. </p><br><pre> <code class="python hljs">Rxx = (sigmaS)*(np.dot(H,np.matrix(H).H))+(sigmaN)*np.identity(M) p = (sigmaS)*H[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] p = p.reshape((len(p), <span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">La d√©rivation des formules ici (aussi une feuille pour les plus d√©sesp√©r√©s).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/hi/lh/ks/hilhksxoc_rkum_5ibn3m42ukxc.jpeg"></p></div></div><br><p>  Nous trouvons une solution pour Wiener: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Solution of the Wiener-Hopf equation: wopt = np.dot(np.linalg.inv(Rxx), p) MSEopt = MSE_calc(sigmaS, Rxx, p, wopt)</span></span></code> </pre> <br><p>  Passons maintenant √† la m√©thode de descente en gradient. </p><br><p>  Trouvez la plus grande valeur propre afin que la limite sup√©rieure de l'√©tape puisse en √™tre d√©riv√©e (voir formule (9)): </p><br><pre> <code class="python hljs">lamda_max = max(np.linalg.eigvals(Rxx))</code> </pre> <br><p>  Maintenant, d√©finissons un tableau d'√©tapes qui repr√©sentera une certaine fraction du maximum: </p><br><pre> <code class="python hljs">coeff = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>]) mus = <span class="hljs-number"><span class="hljs-number">2</span></span>/lamda_max*coeff <span class="hljs-comment"><span class="hljs-comment"># different step sizes</span></span></code> </pre> <br><p>  D√©finissez le nombre maximum d'it√©rations: </p><br><pre> <code class="python hljs">N_steps = <span class="hljs-number"><span class="hljs-number">100</span></span></code> </pre> <br><p>  Ex√©cutez l'algorithme: </p><br><pre> <code class="python hljs">MSE = np.empty((len(mus), N_steps), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> mu_idx, mu <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(mus): w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): w = w - mu*(np.dot(Rxx, w) - p) MSE[mu_idx, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Maintenant, nous ferons de m√™me, mais pour l'√©tape adaptative (formule (10)): </p><br><pre> <code class="python hljs">MSEoptmu = np.empty((<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps), dtype=complex) w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): gamma = p - np.dot(Rxx,w) mu_opt = mu_opt_calc(gamma, Rxx) w = w - mu_opt*(np.dot(Rxx,w) - p) MSEoptmu[:, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Vous devriez obtenir quelque chose comme ceci: </p><br><div class="spoiler">  <b class="spoiler_title">Dessin</b> <div class="spoiler_text"><pre> <code class="python hljs">x = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps+<span class="hljs-number"><span class="hljs-number">1</span></span>)] plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>), dpi=<span class="hljs-number"><span class="hljs-number">300</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx, item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(coeff): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> item == <span class="hljs-number"><span class="hljs-number">1</span></span>: item = <span class="hljs-string"><span class="hljs-string">''</span></span> plt.loglog(x, np.abs(MSE[idx, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = '</span></span>+str(item)+<span class="hljs-string"><span class="hljs-string">'\mu_{max}$'</span></span>) plt.loglog(x, np.abs(MSEoptmu[<span class="hljs-number"><span class="hljs-number">0</span></span>, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = \mu_{opt}$'</span></span>) plt.loglog(x, np.abs(MSEopt*np.ones((len(x), <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex)),\ label = <span class="hljs-string"><span class="hljs-string">'Wiener solution'</span></span>) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Number of steps'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Mean-Square Error'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Steepest descent'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.minorticks_on() plt.grid(which=<span class="hljs-string"><span class="hljs-string">'major'</span></span>) plt.grid(which=<span class="hljs-string"><span class="hljs-string">'minor'</span></span>, linestyle=<span class="hljs-string"><span class="hljs-string">':'</span></span>) plt.show()</code> </pre> </div></div><br><p><img src="https://habrastorage.org/webt/il/fa/8d/ilfa8dmoxgt4sjitiyvwbdjga6m.png"></p><br><p>  <em>Fig.</em>  <em>5. Courbes d'apprentissage pour les √©tapes de diff√©rentes tailles.</em> </p><br><p>  Fixations pour √©noncer les principaux points de la descente en pente: </p><br><ul><li>  comme pr√©vu, l'√©tape optimale donne la convergence la plus rapide; </li><li>  ne signifie plus mieux: apr√®s avoir d√©pass√© la limite sup√©rieure, nous n'avons pas du tout atteint la convergence. </li></ul><br><p>  Nous avons donc trouv√© le vecteur optimal de coefficients de filtre qui √©galisera le mieux les effets du canal - nous avons <u>form√© l'√©galiseur</u> . </p><br><h2 id="a-est-chto-to-bolee-blizkoe-k-realnosti">  Y a-t-il quelque chose de plus proche de la r√©alit√©? </h2><br><p>  Bien s√ªr!  Nous avons d√©j√† dit √† plusieurs reprises que la collecte de statistiques (c'est-√†-dire le calcul de matrices de corr√©lation et de vecteurs) dans des syst√®mes en temps r√©el est loin d'√™tre toujours un luxe abordable.  Cependant, l'humanit√© s'est adapt√©e √† ces difficult√©s: au lieu d'une approche <em>d√©terministe</em> dans la pratique, <u>des</u> approches <u>adaptatives</u> sont utilis√©es.  Ils peuvent √™tre divis√©s en deux grands groupes [1, p.  246]: </p><br><ul><li>  <em>probabiliste (stochastique)</em> (par exemple <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SG</a> - Gradient stochastique) </li><li>  et bas√© sur la m√©thode des <em>moindres carr√©s</em> (par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LMS</a> - Least Mean Squares ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RLS</a> - Recursive Least Squares) </li></ul><br><p>  Le sujet des filtres adaptatifs est bien repr√©sent√© au sein de la communaut√© open-source (exemples pour python): </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pyroomacoustics</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">padasip</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">adaptfilt</a> </li></ul><br><blockquote>  Dans le deuxi√®me exemple, j'aime particuli√®rement la documentation.  Attention cependant!  Lorsque j'ai test√© le paquet <strong>padasip</strong> , j'ai rencontr√© des difficult√©s dans la gestion des nombres complexes (par d√©faut, float64 y est impliqu√©).  Peut-√™tre que les m√™mes probl√®mes peuvent survenir lorsque vous travaillez avec d'autres impl√©mentations. </blockquote><p>  Bien entendu, les algorithmes ont leurs propres avantages et inconv√©nients, dont la somme d√©termine la port√©e de l'algorithme. </p><br><p>  Jetons un coup d'≈ìil aux exemples: nous allons consid√©rer les trois algorithmes <em>SG</em> , <em>LMS</em> et <em>RLS</em> que nous avons d√©j√† mentionn√©s (nous mod√©liserons en langage MATLAB - j'avoue, il y avait d√©j√† des blancs, et tout r√©√©crire en uniformit√© python pour le bien de ... eh bien ...). </p><br><p>  Une description des algorithmes <em>LMS</em> et <em>RLS</em> peut √™tre trouv√©e, par exemple, dans le dock <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">padasip</a> . </p><br><div class="spoiler">  <b class="spoiler_title">La description de SG peut √™tre trouv√©e ici.</b> <div class="spoiler_text"><p>  La principale diff√©rence avec la descente du gradient est un gradient variable: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/76f/9e3/fbb/76f9e3fbbb4c7643f5af595103791091.svg" alt="\ mathbf {w} [n] = \ mathbf {w} [n-1] + \ mu \ left (\ mathbf {\ hat {p}} [n] - \ mathbf {\ hat {R}} _ {xx } [n] \ mathbf {w} [n-1] \ droite)"></div><br><p>  √† </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/633/bac/0aa/633bac0aae95be15cd31a312b4e0d2c5.svg" alt="\ mathbf {\ hat {R}} _ {xx} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {R}} _ {xx} [n-1 ] + \ mathbf {x} [n] \ mathbf {x} [n] ^ H \ droite)"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f7/bfd/f81/4f7bfdf81571e19eac474c7a8c380093.svg" alt="\ mathbf {\ hat {p}} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {p}} [n-1] + \ mathbf {x} [ n] d [n] ^ * \ droite)"></div></div></div><br><p>  1) Un cas similaire √† celui consid√©r√© ci-dessus. </p><br><div class="spoiler">  <b class="spoiler_title">Sources (MatLab / Octave).</b> <div class="spoiler_text"><p>  Les sources peuvent √™tre t√©l√©charg√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/ff/zm/hq/ffzmhqsrnwvvc0hdrcyzhapropw.png"></p><br><p>  <em>Fig.</em>  <em>6. Courbes d'apprentissage pour LMS, RLS et SG.</em> </p><br><p>  On peut imm√©diatement noter qu'avec sa relative simplicit√©, l'algorithme LMS peut, en principe, ne pas aboutir √† une solution optimale avec un pas relativement important.  RLS donne le r√©sultat le plus rapide, mais il peut √©galement √©chouer avec un <em>facteur d'oubli</em> relativement faible.  Jusqu'√† pr√©sent, SG se porte bien, mais regardons un autre exemple. </p><br><p>  2) Le cas o√π le canal change dans le temps. </p><br><div class="spoiler">  <b class="spoiler_title">Sources (MatLab / Octave).</b> <div class="spoiler_text"><p>  Les sources peuvent √™tre t√©l√©charg√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/v-/9d/sx/v-9dsxxwzr9jnbnswf0dmnvqrcu.png"></p><br><p>  <em>Fig.</em>  <em>7. Courbes d'apprentissage pour LMS, RLS et SG (changements de canaux dans le temps).</em> </p><br><p>  Et ici, l'image est d√©j√† beaucoup plus int√©ressante: avec un fort changement dans la r√©ponse du canal, le LMS semble d√©j√† √™tre la solution la plus fiable.  Qui aurait pens√©.  Bien que RLS avec le bon facteur d'oubli fournisse √©galement un r√©sultat acceptable. </p><br><div class="spoiler">  <b class="spoiler_title">Quelques mots sur la performance.</b> <div class="spoiler_text"><p>  Oui, bien s√ªr, chaque algorithme a sa propre complexit√© de calcul, mais selon mes mesures, mon ancienne machine peut faire face √† un ensemble pour environ 120 Œºs par it√©ration dans le cas de LMS et SG et environ 250 Œºs par it√©ration dans le cas de RLS.  Autrement dit, la diff√©rence est, en g√©n√©ral, comparable. </p></div></div><br><p>  Et c'est tout pour aujourd'hui.  Merci √† tous ceux qui ont regard√©! </p><br><h2 id="literatura">  Litt√©rature </h2><br><ol><li>  Th√©orie du filtre adaptatif Haykin SS.  - Pearson Education India, 2005. </li><li>  Haykin, Simon et KJ Ray Liu.  Manuel sur le traitement des r√©seaux et les r√©seaux de capteurs.  Vol.  63. John Wiley &amp; Sons, 2010. pp.  102-107 </li><li>  Arndt, D. (2015).  Mod√©lisation On Channel pour la r√©ception satellite terrestre mobile (th√®se de doctorat). </li></ol><br><h2 id="prilozhenie-1">  Annexe 1 </h2><br><div class="spoiler">  <b class="spoiler_title">Filtre propre</b> <div class="spoiler_text"><p>  L'objectif principal d'un tel filtre est de maximiser le rapport signal / bruit (SNR). </p><br><p><img src="https://habrastorage.org/webt/kk/v_/uu/kkv_uu-08dppu5i4yhkucc_b0ww.jpeg"></p><br><p>  Mais √† en juger par la pr√©sence de corr√©lations dans les calculs, il s'agit aussi davantage d'une construction th√©orique que d'une solution pratique. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455497/">https://habr.com/ru/post/fr455497/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455483/index.html">Artiste Ai-Da: un robot humano√Øde se pr√©pare pour sa premi√®re exposition personnelle</a></li>
<li><a href="../fr455485/index.html">Check Point Scripts - ex√©cutez des scripts directement √† partir de la Smart Console</a></li>
<li><a href="../fr455487/index.html">Formation Cisco 200-125 CCNA v3.0. Jour 10. Changer les modes de fonctionnement du port</a></li>
<li><a href="../fr455489/index.html">Connexion de solutions audio et vid√©o tierces √† Microsoft Teams</a></li>
<li><a href="../fr455493/index.html">Nouveaut√©s de la version Angular 8</a></li>
<li><a href="../fr455499/index.html">Extraction des dents de sagesse: comment cela se fait-il?</a></li>
<li><a href="../fr455501/index.html">Comment Hollywood utilise secr√®tement l'IA pour prendre des d√©cisions de tournage cl√©s</a></li>
<li><a href="../fr455503/index.html">19 concepts que vous devez apprendre pour devenir un d√©veloppeur Angular efficace</a></li>
<li><a href="../fr455509/index.html">L'histoire de la raison pour laquelle j'utilise toujours jQuery</a></li>
<li><a href="../fr455511/index.html">Le sommeil est la principale ressource pour le cerveau d'un programmeur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
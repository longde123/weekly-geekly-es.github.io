<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕘 👨🏼‍🎤 🤳🏿 Hohe Leistung und native Partitionierung: Zabbix mit TimescaleDB-Unterstützung 🕳️ 👩🏽‍💻 👊🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Zabbix ist ein Überwachungssystem. Wie bei jedem anderen System treten bei allen Überwachungssystemen drei Hauptprobleme auf: Datenerfassung und -vera...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Hohe Leistung und native Partitionierung: Zabbix mit TimescaleDB-Unterstützung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/470902/">  Zabbix ist ein Überwachungssystem.  Wie bei jedem anderen System treten bei allen Überwachungssystemen drei Hauptprobleme auf: Datenerfassung und -verarbeitung, Verlaufsspeicherung und Reinigung. <br><br>  Die Schritte zum Erfassen, Verarbeiten und Aufzeichnen von Daten benötigen Zeit.  Nicht viel, aber bei einem großen System kann dies zu großen Verzögerungen führen.  Das Speicherproblem ist ein Datenzugriffsproblem.  Sie werden für Berichte, Überprüfungen und Auslöser verwendet.  Verzögerungen beim Zugriff auf Daten wirken sich auch auf die Leistung aus.  Wenn die Datenbank wächst, müssen irrelevante Daten gelöscht werden.  Das Entfernen ist eine schwierige Operation, die auch einen Teil der Ressourcen verschlingt. <br><br><img src="https://habrastorage.org/webt/jb/yy/zo/jbyyzopzw6gtfio8uhqbgushzo8.jpeg"><br><br>  Die Probleme von Verzögerungen beim Sammeln und Speichern in Zabbix werden durch Caching gelöst: verschiedene Arten von Caches, Caching in der Datenbank.  Um das dritte Problem zu lösen, ist das Caching nicht geeignet, daher verwendete Zabbix TimescaleDB.  <strong>Andrey Gushchin</strong> , technischer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Supportingenieur</a> bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zabbix SIA,</a> wird darüber sprechen.  Andrey unterstützt Zabbix seit mehr als 6 Jahren und steht direkt vor der Leistung. <br><br>  Wie funktioniert TimescaleDB, welche Leistung kann es im Vergleich zu normalem PostgreSQL bieten?  Welche Rolle spielt Zabbix in TimescaleDB?  Wie läuft man von Grund auf neu und wie migriert man mit PostgreSQL und welche Leistung ist besser?  Über all das unter dem Schnitt. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/umRk94j5M8o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Leistungsherausforderungen </h2><br>  Jedes Überwachungssystem steht vor spezifischen Leistungsherausforderungen.  Ich werde über drei davon sprechen: Sammeln und Verarbeiten von Daten, Speichern, Bereinigen des Verlaufs. <br><br>  <strong>Schnelle Datenerfassung und -verarbeitung.</strong>  Ein gutes Überwachungssystem sollte schnell alle Daten empfangen und nach Triggerausdrücken verarbeiten - nach eigenen Kriterien.  Nach der Verarbeitung sollte das System diese Daten auch schnell in der Datenbank speichern, um sie später verwenden zu können. <br><br>  <strong>Eine Geschichte behalten.</strong>  Ein gutes Überwachungssystem sollte den Verlauf in der Datenbank speichern und einen bequemen Zugriff auf Metriken ermöglichen.  Eine Story wird benötigt, um sie in Berichten, Grafiken, Triggern, Schwellenwerten und berechneten Datenelementen für Warnungen zu verwenden. <br><br>  <strong>Klare Geschichte.</strong>  Manchmal kommt ein Tag, an dem Sie keine Metriken speichern müssen.  Warum benötigen Sie die Daten, die vor 5 Jahren, ein oder zwei Monaten erfasst wurden: Einige Knoten werden gelöscht, einige Hosts oder Metriken werden nicht mehr benötigt, da sie veraltet sind und nicht mehr erfasst werden.  Ein gutes Überwachungssystem sollte historische Daten speichern und von Zeit zu Zeit löschen, damit die Datenbank nicht wächst. <br><br><blockquote>  Das Löschen veralteter Daten ist ein heißes Problem, das einen großen Einfluss auf die Datenbankleistung hat. </blockquote><br><h2>  Zabbix Caching </h2><br>  In Zabbix werden der erste und der zweite Aufruf mithilfe von Caching aufgelöst.  RAM wird zur Datenerfassung und -verarbeitung verwendet.  Zur Speicherung von Storys in Triggern, Diagrammen und berechneten Datenelementen.  Auf der Datenbankseite gibt es ein bestimmtes Caching für die Hauptbeispiele, z. B. Diagramme. <br><br>  Das Caching auf der Seite des Zabbix-Servers selbst ist: <br><br><ul><li>  ConfigurationCache; </li><li>  ValueCache; </li><li>  HistoryCache; </li><li>  TrendsCache. </li></ul><br>  Betrachten wir sie genauer. <br><br><h3>  Konfigurationscache </h3><br>  Dies ist der Hauptcache, in dem wir Metriken, Hosts, Datenelemente und Trigger speichern - alles, was für die Vorverarbeitung und das Sammeln von Daten benötigt wird. <br><br><img src="https://habrastorage.org/webt/g0/zd/er/g0zderqgjgddgeq0frjdyvgj-q0.png"><br><br>  All dies wird im ConfigurationCache gespeichert, um keine unnötigen Abfragen in der Datenbank zu erstellen.  Nach dem Start des Servers aktualisieren wir diesen Cache, erstellen und aktualisieren regelmäßig Konfigurationen. <br><br><h3>  Datenerfassung </h3><br>  Das Schema ist ziemlich groß, aber die Hauptsache darin sind die <strong>Monteure</strong> .  Dies sind die verschiedenen "Poller" - Montageprozesse.  Sie sind für verschiedene Arten von Assemblys verantwortlich: Sie erfassen Daten über SNMP, IPMI und übertragen sie alle an PreProcessing. <br><br><img src="https://habrastorage.org/webt/z2/2r/jq/z22rjqgzyoam-61aadugsmowsbe.jpeg">  <em>Sammler sind orange eingekreist.</em> <br><br>  Zabbix hat Aggregationsdatenelemente berechnet, die zum Aggregieren von Validierungen benötigt werden.  Wenn wir sie haben, nehmen wir die Daten für sie direkt aus ValueCache. <br><br><h3>  PreCrocessing HistoryCache </h3><br>  Alle Kollektoren verwenden ConfigurationCache, um Jobs zu empfangen.  Dann übergeben sie sie an PreProcessing. <br><br><img src="https://habrastorage.org/webt/f9/f-/yc/f9f-ycupjcyofnnz20injlmynty.png"><br><br>  PreProcessing verwendet ConfigurationCache, um PreProcessing-Schritte zu empfangen.  Es verarbeitet diese Daten auf verschiedene Weise. <br><br>  Nachdem wir die Daten mit PreProcessing verarbeitet haben, speichern wir sie im HistoryCache, um sie zu verarbeiten.  Damit ist die Datenerfassung beendet und wir fahren mit dem Hauptprozess in Zabbix fort - dem <strong>History Syncer</strong> , da es sich um eine monolithische Architektur handelt. <br><br>  <em>Hinweis: Die Vorverarbeitung ist ziemlich schwierig.</em>  <em>Seit Version 4.2 wurde es dem Proxy vorgelegt.</em>  <em>Wenn Sie einen sehr großen Zabbix mit einer großen Anzahl von Datenelementen und einer Häufigkeit der Erfassung haben, erleichtert dies die Arbeit erheblich.</em> <br><br><h3>  ValueCache, Verlaufs- und Trendcache </h3><br><blockquote>  Der Verlaufssynchronisator ist der Hauptprozess, der jedes Datenelement, dh jeden Wert, atomar verarbeitet. </blockquote><br>  Der Verlaufssynchronisator übernimmt Werte aus dem Verlaufscache und sucht in der Konfiguration nach Triggern für Berechnungen.  Wenn ja, berechnet es. <br><br>  Der Verlaufssynchronisator erstellt ein Ereignis, eine Eskalation, um bei Bedarf Warnungen zu erstellen, und zeichnet auf.  Wenn es Auslöser für die nachfolgende Verarbeitung gibt, merkt er sich diesen Wert in ValueCache, um nicht auf die Verlaufstabelle zuzugreifen.  ValueCache wird also mit Daten gefüllt, die für die Berechnung von Triggern und berechneten Elementen erforderlich sind. <br><br>  Der Verlaufssyncer schreibt alle Daten in die Datenbank und sie werden auf die Festplatte geschrieben.  Der Verarbeitungsprozess endet hier. <br><br><img src="https://habrastorage.org/webt/u7/v0/08/u7v0080wzx7v_fh8ej-fas7b1wg.jpeg"><br><br><h3>  DB-Caching </h3><br>  Auf der DB-Seite gibt es verschiedene Caches, wenn Sie Diagramme oder Ereignisberichte anzeigen möchten: <br><br><ul><li> <code>Innodb_buffer_pool</code> auf der MySQL-Seite; </li><li>  <code>shared_buffers</code> auf der PostgreSQL-Seite; </li><li>  <code>effective_cache_size</code> auf der Oracle-Seite; </li><li>  <code>shared_pool</code> auf der DB2-Seite. </li></ul><br>  Es gibt viele andere Caches, aber dies sind die wichtigsten für alle Datenbanken.  Mit ihnen können Sie die Daten speichern, die häufig für Abfragen benötigt werden.  Sie haben ihre eigenen Technologien dafür. <br><br><h3>  Die Datenbankleistung ist entscheidend </h3><br>  Der Zabbix-Server sammelt ständig Daten und schreibt sie.  Beim Neustart wird auch aus dem Verlauf gelesen, um ValueCache zu füllen.  Skripte und Berichte verwenden die <strong>Zabbix-API</strong> , die auf der Webschnittstelle basiert.  Die Zabbix-API kontaktiert die Datenbank und erhält die erforderlichen Daten für Diagramme, Berichte, Ereignislisten und aktuelle Probleme. <br><br><img src="https://habrastorage.org/webt/b5/48/rc/b548rcjuhprytj6zcpi_buqdr2c.png"><br><br>  Zur Visualisierung - <strong>Grafana</strong> .  Bei unseren Anwendern ist dies eine beliebte Lösung.  Es kann Anforderungen direkt über die Zabbix-API und an die Datenbank senden und schafft eine gewisse Wettbewerbsfähigkeit für den Empfang von Daten.  Daher benötigen wir eine feinere und bessere Optimierung der Datenbank, um der schnellen Ausgabe von Ergebnissen und Tests zu entsprechen. <br><br><h2>  Haushälterin </h2><br>  Die dritte Leistungsherausforderung in Zabbix besteht darin, mit Housekeeper die Geschichte zu klären.  Es folgt allen Einstellungen - die Datenelemente geben an, wie stark die Dynamik von Änderungen (Trends) in Tagen beibehalten werden soll. <br><br>  Wir berechnen TrendsCache im laufenden Betrieb.  Wenn die Daten eintreffen, aggregieren wir sie in einer Stunde und schreiben sie in Tabellen für die Dynamik von Trendänderungen. <br><br>  Die Haushälterin startet und löscht Informationen aus der Datenbank mit den üblichen "Auswahlen".  Dies ist nicht immer effektiv, was aus den Leistungsdiagrammen interner Prozesse hervorgeht. <br><br><img src="https://habrastorage.org/webt/m0/3q/x_/m03qx_0sgbs_2bpjc_toewzmsbo.png"><br><br>  Ein rotes Diagramm zeigt an, dass der Verlaufssyncer ständig beschäftigt ist.  Die orangefarbene Tabelle oben zeigt die Haushälterin, die ständig läuft.  Er erwartet, dass die Datenbank alle von ihm angegebenen Zeilen löscht. <br><br>  Wann soll die Haushälterin ausgeschaltet werden?  Zum Beispiel gibt es eine "Artikel-ID" und Sie müssen die letzten fünftausend Zeilen in einer bestimmten Zeit löschen.  Dies geschieht natürlich nach Index.  Normalerweise ist das Dataset jedoch sehr groß, und die Datenbank liest immer noch von der Festplatte und hebt sie in den Cache.  Dies ist immer eine sehr teure Operation für die Datenbank und kann je nach Größe der Datenbank zu Leistungsproblemen führen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w4/c4/y7/w4c4y7m_lwigpvwzq4bfsftktw8.png" width="500"></div><br><br>  Haushälterin ist nur eine Trennung.  In der Weboberfläche gibt es eine Einstellung in der "Administration general" für Housekeeper.  Deaktivieren Sie die interne Verwaltung für den internen Trendverlauf und dies wird nicht mehr verwaltet. <br><br>  Die Haushälterin wurde ausgeschaltet, die Grafiken wurden geebnet - was könnte in diesem Fall das Problem sein und was könnte bei der Lösung des dritten Leistungsaufrufs helfen? <br><br><h2>  Partitionierung - Partitionierung oder Partitionierung </h2><br>  Normalerweise wird die Partitionierung in jeder von mir aufgelisteten relationalen Datenbank anders konfiguriert.  Jedes hat seine eigene Technologie, aber sie sind im Allgemeinen ähnlich.  Das Erstellen einer neuen Partition führt häufig zu bestimmten Problemen. <br><br>  Partitionen werden normalerweise abhängig vom „Setup“ konfiguriert - der Datenmenge, die an einem Tag erstellt wird.  In der Regel ist die Partitionierung an einem Tag verfügbar, dies ist ein Minimum.  Für Trends der neuen Partition - für 1 Monat. <br><br>  Bei einem sehr großen „Setup“ können sich die Werte ändern.  Wenn das kleine „Setup“ bis zu 5.000 nvps (neue Werte pro Sekunde) beträgt, liegt der Durchschnitt zwischen 5.000 und 25.000, das große über 25.000 nvps.  Dies sind große und sehr große Installationen, die eine sorgfältige Konfiguration der Datenbank erfordern. <br><br>  Bei sehr großen Installationen ist ein eintägiger Lauf möglicherweise nicht optimal.  Ich habe auf MySQL-Partitionen 40 GB oder mehr pro Tag gesehen.  Dies ist eine sehr große Datenmenge, die zu Problemen führen kann und reduziert werden muss. <br><br><h3>  Was gibt Partitionierung? </h3><br>  <strong>Partitionierungstabellen</strong> .  Oft sind dies separate Dateien auf der Festplatte.  Der Abfrageplan wählt eine Partition optimaler aus.  Partitionierung wird normalerweise über einen Bereich verwendet - für Zabbix gilt dies auch.  Wir verwenden dort "Zeitstempel" - Zeit vom Beginn der Ära.  Wir haben gewöhnliche Zahlen.  Sie legen den Anfang und das Ende des Tages fest - dies ist eine Partition. <br><br>  <strong>Schnell löschen</strong> - <code>DELETE</code> .  Es wird eine einzelne Datei / Untertabelle ausgewählt, keine Auswahl der zu löschenden Zeilen. <br><br>  <strong>Beschleunigt das Abrufen von</strong> <code>SELECT</code> <strong>Daten sichtbar</strong> - verwendet eine oder mehrere Partitionen, nicht die gesamte Tabelle.  Wenn Sie vor zwei Tagen nach Daten fragen, werden diese schneller aus der Datenbank ausgewählt, da Sie sie in den Cache laden und nur eine Datei und keine große Tabelle ausgeben müssen. <br><br>  Häufig beschleunigen viele Datenbanken auch <code>INSERT</code> Einfügungen in die untergeordnete Tabelle. <br><br><h2>  Timescaledb </h2><br>  In Version 4.2 haben wir unsere Aufmerksamkeit auf TimescaleDB gerichtet.  Dies ist eine Erweiterung für PostgreSQL mit einer nativen Schnittstelle.  Die Erweiterung arbeitet effektiv mit Zeitreihendaten, ohne die Vorteile relationaler Datenbanken zu verlieren.  TimescaleDB partitioniert auch automatisch. <br><br>  TimescaleDB hat das Konzept einer <strong>von</strong> Ihnen erstellten <strong>Hypertabelle</strong> .  Es enthält <strong>Chunks</strong> - Partitionen.  Chunks sind automatisch gesteuerte Fragmente einer Hypertabelle, die andere Fragmente nicht beeinflussen.  Jeder Block hat seinen eigenen Zeitbereich. <br><br><img src="https://habrastorage.org/webt/0p/0g/mh/0p0gmhmshsg_htxuboh2w1xdmeo.jpeg"><br><br><h3>  TimescaleDB vs PostgreSQL </h3><br>  TimescaleDB arbeitet sehr effizient.  Erweiterungshersteller behaupten, dass sie einen korrekteren Anforderungsverarbeitungsalgorithmus verwenden, insbesondere &lt;code&gt; Einfügungen &lt;/ code&gt;.  Wenn die Abmessungen der Datensatzeinfügung zunehmen, behält der Algorithmus eine konstante Leistung bei. <br><br><img src="https://habrastorage.org/webt/_n/1v/vo/_n1vvoqc1hghllux5r_u7i_23q4.png"><br><br>  Nach 200 Millionen Zeilen beginnt PostgreSQL normalerweise stark zu sinken und verliert an Leistung bis zu 0. Mit TimescaleDB können Sie effizient „Einfügungen“ für jede Datenmenge einfügen. <br><br><h3>  Installation </h3><br>  Die Installation von TimescaleDB ist für alle Pakete einfach genug.  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> beschreibt alles im Detail - es hängt von den offiziellen PostgreSQL-Paketen ab.  TimescaleDB kann auch manuell kompiliert und kompiliert werden. <br><br>  Für die Zabbix-Datenbank aktivieren wir einfach die Erweiterung: <br><br><pre> <code class="sql hljs">echo "<span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> EXTENSION <span class="hljs-keyword"><span class="hljs-keyword">IF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXISTS</span></span> timescaledb <span class="hljs-keyword"><span class="hljs-keyword">CASCADE</span></span>;" | sudo -u postgres psql zabbix</code> </pre> <br>  Sie aktivieren die <code>extension</code> und erstellen sie für die Zabbix-Datenbank.  Der letzte Schritt besteht darin, eine Hypertabelle zu erstellen. <br><br><h3>  Verlaufstabellen nach TimescaleDB migrieren </h3><br>  <code>create_hypertable</code> gibt es eine spezielle Funktion <code>create_hypertable</code> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_unit'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_log'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_text'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_str'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'trends'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'trends_unit'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> config <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> db_extension=<span class="hljs-string"><span class="hljs-string">'timescaledb'</span></span>, hk_history_global=<span class="hljs-number"><span class="hljs-number">1</span></span>, hk_trends_global=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br>  Die Funktion hat drei Parameter.  Die erste ist eine <strong>Tabelle in der Datenbank,</strong> für die Sie eine Hypertabelle erstellen müssen.  Das zweite ist das <strong>Feld</strong> , in dem <code>chunk_time_interval</code> - das Intervall der Partitionsblöcke, die Sie verwenden möchten.  In meinem Fall beträgt das Intervall einen Tag - 86.400. <br><br>  Der dritte Parameter ist <code><strong>migrate_data</strong></code> .  Wenn <code>true</code> , werden alle aktuellen Daten in zuvor erstellte Chunks übertragen.  Ich selbst habe <code>migrate_data</code> .  Ich hatte ungefähr 1 TB, was mehr als eine Stunde dauerte.  Selbst in einigen Fällen habe ich beim Testen die historischen Daten von Zeichentypen gelöscht, die für die Speicherung optional waren, um sie nicht zu übertragen. <br><br>  Der letzte Schritt ist <code><strong>UPDATE</strong></code> : Wir setzen <code>db_extension</code> in <code>db_extension</code> damit die Datenbank versteht, dass es diese Erweiterung gibt.  Zabbix aktiviert es und verwendet die Syntax und Abfragen, die bereits an die Datenbank gesendet wurden, korrekt - die Funktionen, die für TimescaleDB erforderlich sind. <br><br><h2>  Eisenkonfiguration </h2><br>  Ich habe zwei Server benutzt.  Der erste ist ein <strong>VMware-Computer</strong> .  Es ist klein genug: 20 Intel® Xeon® Prozessoren E5-2630 v 4 bei 2,20 GHz, 16 GB RAM und eine 200 GB SSD. <br><br>  Ich habe PostgreSQL 10.8 mit Debian 10.8-1.pgdg90 + 1 und dem xfs-Dateisystem darauf installiert.  Ich habe alles minimal konfiguriert, um diese bestimmte Datenbank zu verwenden, abzüglich dessen, was Zabbix selbst verwenden wird. <br><br>  Auf demselben Computer befanden sich ein Zabbix-Server, PostgreSQL und <strong>Ladeagenten</strong> .  Ich hatte 50 Wirkstoffe, die das <code>LoadableModule</code> um sehr schnell verschiedene Ergebnisse zu generieren: Zahlen, Zeichenfolgen.  Ich habe die Datenbank mit vielen Daten verstopft. <br><br>  Anfänglich enthielt die Konfiguration <strong>5.000</strong> Datenelemente pro Host.  Fast jedes Element enthielt einen Trigger, so dass es realen Installationen ähnelte.  In einigen Fällen gab es mehr als einen Auslöser.  Es gab <strong>3.000-7.000 Trigger pro</strong> Netzwerkknoten. <br><br>  Das Intervall zum Aktualisieren von Datenelementen beträgt <strong>4-7 Sekunden</strong> .  Ich habe die Last selbst reguliert, indem ich nicht nur 50 Agenten verwendet habe, sondern auch mehr hinzugefügt habe.  Außerdem habe ich mithilfe von Datenelementen die Last dynamisch angepasst und das Aktualisierungsintervall auf 4 s reduziert. <br><br><h3>  PostgreSQL  35.000 nvps </h3><br>  Der erste Lauf auf dieser Hardware hatte ich auf reinem PostgreSQL - 35.000 Werte pro Sekunde.  Wie Sie sehen, dauert das Einfügen von Daten Sekundenbruchteile - alles ist in Ordnung und schnell.  Das einzige, was eine 200-GB-SSD schnell auffüllt. <br><br><img src="https://habrastorage.org/webt/wp/pk/vq/wppkvqe33kjs-udv8qc75jynloq.jpeg"><br><br>  Dies ist das Standard-Dashboard für die Leistung von Zabbix-Servern. <br><br><img src="https://habrastorage.org/webt/nu/h1/jl/nuh1jlhlz3cyoxyrc94cybshjos.png"><br><br>  Das erste blaue Diagramm gibt die Anzahl der Werte pro Sekunde an.  Das zweite Diagramm rechts zeigt das Laden von Montageprozessen.  Der dritte ist das Laden der internen Montageprozesse: Verlaufssynchronisierer und Housekeeper, die hier schon seit einiger Zeit ausgeführt werden. <br><br>  Das vierte Diagramm zeigt die Verwendung von HistoryCache.  Dies ist ein Puffer vor dem Einfügen in die Datenbank.  Das grüne fünfte Diagramm zeigt die Verwendung von ValueCache, dh wie viele ValueCache-Treffer für Trigger mehrere tausend Werte pro Sekunde sind. <br><br><h3>  PostgreSQL  50.000 nvps </h3><br>  Dann habe ich die Last auf derselben Hardware auf 50.000 Werte pro Sekunde erhöht. <br><br><img src="https://habrastorage.org/webt/wj/47/u6/wj47u6j2fycdpnx55-mrrqrwcp4.jpeg"><br><br>  Beim Laden von der Haushälterin wurde für 2-3 s eine Einfügung von 10 Tausend Werten aufgezeichnet. <br><br><img src="https://habrastorage.org/webt/fn/qo/go/fnqogopttou4hwlygqckfoieht0.png"><br>  <em>Die Haushälterin beginnt bereits, sich in den Weg zu stellen.</em> <br><br>  Die dritte Grafik zeigt, dass die Belastung von Trappern und Verlaufssynchronisierern im Allgemeinen immer noch bei 60% liegt.  In der vierten Tabelle füllt sich HistoryCache bereits während der Arbeit von Housekeeper ziemlich aktiv.  Es ist zu 20% voll - es sind ungefähr 0,5 GB. <br><br><h3>  PostgreSQL  80.000 nvps </h3><br>  Dann habe ich die Last auf 80.000 Werte pro Sekunde erhöht.  Dies sind ungefähr 400.000 Datenelemente und 280.000 Trigger. <br><br><img src="https://habrastorage.org/webt/8q/zh/5z/8qzh5zsbwvouradg7j-qxeksqfi.jpeg"><br>  <em>Der Einsatz zum Laden von 30 Verlaufssynchronisatoren ist bereits recht hoch.</em> <br><br>  Ich habe auch verschiedene Parameter erhöht: Verlaufssyncer, Caches. <br><br><img src="https://habrastorage.org/webt/xs/3m/ia/xs3miafccbymaddfyzzj2l4e494.png"><br><br>  Auf meiner Hardware hat sich die Last der Verlaufssynchronisatoren auf das Maximum erhöht.  HistoryCache schnell mit Daten gefüllt - die Daten für die Verarbeitung im Puffer gesammelt. <br><br>  Während dieser ganzen Zeit habe ich beobachtet, wie der Prozessor, der Arbeitsspeicher und andere Systemparameter verwendet wurden, und festgestellt, dass die Festplattenauslastung maximiert wurde. <br><br><img src="https://habrastorage.org/webt/zy/el/im/zyelimg6_immdsthjxburb1gjmw.jpeg"><br><br>  Ich habe das <strong>Beste aus dem Laufwerk</strong> dieser Hardware und dieser virtuellen Maschine herausgeholt.  Bei dieser Intensität begann PostgreSQL, Daten ziemlich aktiv zu sichern, und die Festplatte hatte keine Zeit mehr, um zu schreiben und zu lesen. <br><br><h3>  Zweiter Server </h3><br>  Ich habe einen anderen Server genommen, der bereits 48 Prozessoren und 128 GB RAM hatte.  Optimieren Sie es - stellen Sie den 60-Verlaufs-Syncer ein und erzielen Sie eine akzeptable Leistung. <br><br><img src="https://habrastorage.org/webt/hl/ae/ig/hlaeigh1dtxphardj6hkwmtas8w.png"><br><br>  Tatsächlich ist dies bereits eine Leistungsbeschränkung, bei der etwas getan werden muss. <br><br><h3>  TimescaleDB.  80.000 nvps </h3><br>  Meine Hauptaufgabe ist es, die Funktionen von TimescaleDB anhand der Zabbix-Last zu testen.  80.000 Werte pro Sekunde sind eine Menge, die Häufigkeit der Erfassung von Metriken (außer natürlich Yandex) und ein ziemlich großes "Setup". <br><br><img src="https://habrastorage.org/webt/c-/45/yc/c-45yc-ctmrtj7o5td-ajwrtpdm.png"><br><br>  In jedem Diagramm ist ein Fehler aufgetreten - dies ist nur eine Datenmigration.  Nach Fehlern auf dem Zabbix-Server hat sich das Boot-Profil des Verlaufssyncers stark geändert - es ist dreimal gesunken. <br><br><blockquote>  Mit TimescaleDB können Sie Daten fast dreimal schneller einfügen und weniger HistoryCache verwenden. </blockquote><br>  Dementsprechend werden Ihnen die Daten rechtzeitig zugestellt. <br><br><h3>  TimescaleDB.  120.000 nvps </h3><br>  Dann habe ich die Anzahl der Datenelemente auf 500.000 erhöht. Die Hauptaufgabe bestand darin, die Funktionen von TimescaleDB zu überprüfen. Ich habe den berechneten Wert von 125.000 Werten pro Sekunde erhalten. <br><br><img src="https://habrastorage.org/webt/hi/hd/ce/hihdcemwxqcqfxnv3n5-4ypmvic.png"><br><br>  Dies ist ein funktionierendes „Setup“, das lange funktionieren kann.  Da meine Festplatte jedoch nur 1,5 TB groß war, habe ich sie in ein paar Tagen gefüllt. <br><br><img src="https://habrastorage.org/webt/vk/51/wz/vk51wzryy45k4sycilxbcj-pjcq.png"><br><br>  Gleichzeitig wurden gleichzeitig neue TimescaleDB-Partitionen erstellt. <br><br>  Für die Leistung ist dies völlig unsichtbar.  Wenn beispielsweise Partitionen in MySQL erstellt werden, ist alles anders.  Normalerweise geschieht dies nachts, weil es das allgemeine Einfügen blockiert, mit Tabellen arbeitet und zu einer Verschlechterung des Dienstes führen kann.  Bei TimescaleDB ist dies nicht der Fall. <br><br>  Als Beispiel zeige ich ein Diagramm aus dem Set in der Community.  TimescaleDB ist im Bild enthalten, wodurch die Belastung für die Verwendung von io.weight auf dem Prozessor gesunken ist.  Die Verwendung von Elementen interner Prozesse hat ebenfalls abgenommen.  Und dies ist eine normale virtuelle Maschine auf normalen Pfannkuchenplatten, keine SSD. <br><br><img src="https://habrastorage.org/webt/e6/bm/a-/e6bma-otl8o5mcrt9z8wkrsq5du.jpeg"><br><br><h2>  Schlussfolgerungen </h2><br>  <strong>TimescaleDB ist eine gute Lösung für kleine „Setups“</strong> , die auf der Festplattenleistung basieren.  Damit können Sie weiterhin gut arbeiten, bis die Datenbank schneller auf Bügeln migriert wird. <br><br>  TimescaleDB ist einfach zu konfigurieren, bietet eine Leistungssteigerung, funktioniert gut mit Zabbix und <strong>hat Vorteile gegenüber PostgreSQL</strong> . <br><br>  Wenn Sie PostgreSQL verwenden und nicht vorhaben, es zu ändern, empfehle ich die <strong>Verwendung von PostgreSQL mit der Erweiterung TimescaleDB in Verbindung mit Zabbix</strong> .  Diese Lösung funktioniert effektiv bis zum mittleren "Setup". <br><br><blockquote><p>  Wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sagen</a> "hohe Leistung" - wir meinen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++</a> .  Warten Sie darauf, sich kurz mit den Technologien und Praktiken vertraut zu machen, mit denen Dienste Millionen von Benutzern bedienen können.  Wir haben bereits eine Liste mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Berichten</a> für den 7. und 8. November zusammengestellt, aber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mitaps</a> können weiterhin angeboten werden. <br><br>  Abonnieren Sie unseren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Newsletter</a> und unser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegramm</a> , in denen wir die Chips der bevorstehenden Konferenz enthüllen und erfahren, wie Sie das Beste daraus machen können. </p></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470902/">https://habr.com/ru/post/de470902/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470882/index.html">Warum hast du meine Maus oder ein Brettspiel als Modell für soziale Interaktion erwischt?</a></li>
<li><a href="../de470884/index.html">Schreiben und Lesen von Daten in der Bitcoin-Blockchain</a></li>
<li><a href="../de470888/index.html">Russische und internationale Gesetzgebung im Bereich des Schutzes personenbezogener Daten</a></li>
<li><a href="../de470892/index.html">Einfache Implementierung eines kleinen CAM auf einem FPGA</a></li>
<li><a href="../de470894/index.html">Kugel</a></li>
<li><a href="../de470904/index.html">Der weichste und pelzigste Weg in maschinellem Lernen und tiefen neuronalen Netzen</a></li>
<li><a href="../de470908/index.html">Zum ersten Mal auf der Welt wurde mit Hilfe additiver Technologien eine großformatige Triebwerksbaugruppe für Flugzeuge erhalten</a></li>
<li><a href="../de470910/index.html">Was kann mit Anmerkungen zu Microservice-Verträgen getan werden?</a></li>
<li><a href="../de470916/index.html">Der „billigste“ elektronische Kontrollpunkt in Russland, der über ein Smartphone gesteuert wird</a></li>
<li><a href="../de470918/index.html">F # 9: Geben Sie Option ein</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
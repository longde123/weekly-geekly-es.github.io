<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔠 📶 👩🏿‍🎓 Traduction du livre d'Andrew Un, Passion for Machine Learning, Chapitres 30 - 32 🚫 🛐 👨🏻‍💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="chapitres précédents 
 30. Interprétation de la courbe d'apprentissage: biais important 


 Supposons que votre courbe d'erreur sur un échantillon de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traduction du livre d'Andrew Un, Passion for Machine Learning, Chapitres 30 - 32</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483750/"><p>  <a href="https://habr.com/ru/post/429832/">chapitres précédents</a> </p><br><h1 id="30-interpretaciya-krivoy-obucheniya-bolshoe-smeschenie">  30. Interprétation de la courbe d'apprentissage: biais important </h1><br><p>  Supposons que votre courbe d'erreur sur un échantillon de validation ressemble à ceci: <br><img src="https://habrastorage.org/webt/fi/oy/fz/fioyfz5q4qb98cjga-aesqkuxea.png" alt="image"></p><br><p>  Nous avons déjà dit que si une erreur d'algorithme dans l'échantillon de validation atteint un plateau, il est peu probable que vous atteigniez le niveau de qualité souhaité simplement en ajoutant des données. </p><br><p>  Mais il est difficile d'imaginer à quoi ressemblera l'extrapolation de la courbe de la dépendance de la qualité de l'algorithme sur l'échantillon de validation (erreur Dev) lors de l'ajout de données.  Et si l'échantillon de validation est petit, répondre à cette question est encore plus difficile du fait que la courbe peut être bruyante (avoir une large répartition des points). </p><br><p>  Supposons que nous ayons ajouté à notre graphique une courbe de la dépendance de l'ampleur de l'erreur sur la quantité de données de l'échantillon de test et obtenu l'image suivante: </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/webt/gf/3e/m-/gf3em-wuh6vtvru1w-pyd2lypog.png" alt="image"></p><br><p>  En regardant ces deux courbes, vous pouvez être absolument sûr que l'ajout de nouvelles données à lui seul ne donnera pas l'effet souhaité (cela ne permettra pas d'augmenter la qualité de l'algorithme).  Où tirer cette conclusion? <br>  Rappelons les deux points suivants: </p><br><ul><li>  Si nous ajoutons plus de données à l'ensemble d'apprentissage, l'erreur d'algorithme dans l'ensemble d'apprentissage ne peut qu'augmenter.  Ainsi, la ligne bleue de notre graphique ne changera pas ou se déplacera et s'éloignera du niveau de qualité souhaité de notre algorithme (ligne verte). </li><li>  La ligne d'erreur rouge dans l'échantillon de validation est généralement plus élevée que la ligne d'erreur bleue de l'algorithme dans l'échantillon d'apprentissage.  Ainsi, dans toutes les circonstances envisageables, l'ajout de données n'entraînera pas une nouvelle diminution de la ligne rouge, elle ne la rapprochera pas du niveau d'erreur souhaité.  Cela est presque impossible, étant donné que même l'erreur dans l'échantillon d'apprentissage est plus élevée que souhaité. </li></ul><br><p>  La prise en compte des deux courbes de la dépendance de l'erreur de l'algorithme sur la quantité de données dans les échantillons de validation et d'apprentissage sur le même graphique vous permet d'extrapoler avec plus de confiance la courbe d'erreur de l'algorithme d'apprentissage à partir de la quantité de données dans l'échantillon de validation. </p><cut></cut><br><p>  Supposons que nous ayons une estimation de la qualité souhaitée de l'algorithme sous la forme d'un niveau optimal d'erreurs dans notre système.  Dans ce cas, les graphiques ci-dessus sont une illustration d'un cas standard de «manuel» de l'apparence de la courbe d'apprentissage avec un niveau élevé de biais amovible.  À la plus grande taille de l'échantillon d'apprentissage, correspondant vraisemblablement à toutes les données dont nous disposons, il existe un grand écart entre l'erreur d'algorithme dans l'échantillon d'apprentissage et la qualité souhaitée de l'algorithme, ce qui indique un niveau élevé de biais évité.  De plus, l'écart entre l'erreur dans l'échantillon d'apprentissage et l'erreur dans l'échantillon de validation est faible, ce qui indique une petite dispersion. </p><br><p>  Plus tôt, nous avons discuté des erreurs d'algorithmes formés sur des échantillons de formation et de validation uniquement au point le plus à droite au-dessus du graphique, ce qui correspond à l'utilisation de toutes les données de formation dont nous disposons.  La courbe des dépendances de l'erreur sur la quantité de données de l'échantillon d'apprentissage, construites pour différentes tailles de l'échantillon utilisé pour la formation, nous donne une image plus complète de la qualité de l'algorithme formé sur différentes tailles de l'échantillon d'apprentissage. </p><cut></cut><br><h1 id="31-interpretaciya-krivoy-obucheniya-ostalnye-sluchai">  31. Interprétation de la courbe d'apprentissage: autres cas </h1><br><p>  Considérez la courbe d'apprentissage: <br><img src="https://habrastorage.org/webt/mh/q1/ws/mhq1wskh19gbk_pu7hifvuhodg4.png" alt="image"></p><br><p>  Y a-t-il un biais élevé, une analyse syntaxique élevée, ou les deux à la fois? </p><br><p>  La courbe d'erreur bleue sur les données d'entraînement est relativement faible, la courbe d'erreur rouge sur les données de validation est significativement plus élevée que l'erreur bleue sur les données d'entraînement.  Ainsi, dans ce cas, le biais est faible, mais l'écart est important.  L'ajout de données de formation supplémentaires peut aider à combler l'écart entre l'erreur dans l'échantillon de validation et l'erreur dans l'échantillon de formation. </p><cut></cut><br><p>  Considérez maintenant ce tableau: </p><br><p><img src="https://habrastorage.org/webt/oy/uv/dg/oyuvdgzaf9bj_fvz8ywfpjn4zgq.png" alt="image"></p><br><p>  Dans ce cas, l'erreur dans l'échantillon d'apprentissage est importante; elle est nettement supérieure à l'algorithme correspondant au niveau de qualité souhaité.  L'erreur dans l'échantillon de validation est également significativement plus élevée que l'erreur dans l'échantillon d'apprentissage.  Ainsi, nous avons affaire simultanément à un biais et une dispersion importants.  Vous devriez chercher des moyens de réduire et de compenser et de disperser votre algorithme. </p><br><h1 id="32-postroenie-krivyh-obucheniya">  32. Construire des courbes d'apprentissage </h1><br><p>  Supposons que vous ayez un très petit échantillon de formation, composé de seulement 100 exemples.  Vous entraînez votre algorithme à l'aide d'un sous-ensemble sélectionné au hasard de 10 exemples, puis de 20 exemples, puis de 30 et ainsi de suite à 100, augmentant le nombre d'exemples avec un intervalle de dix exemples.  Ensuite, en utilisant ces 10 points, vous construisez votre courbe d'apprentissage.  Vous pouvez constater que la courbe semble bruyante (valeurs supérieures ou inférieures à celles attendues) pour les échantillons d'entraînement plus petits. </p><br><p>  Lorsque vous entraînez l'algorithme avec seulement 10 exemples sélectionnés au hasard, vous n'aurez peut-être pas de chance et cela se révélera être un sous-échantillon de formation particulièrement «mauvais» avec une plus grande part d'exemples ambigus / mal marqués.  Ou, à l'inverse, vous pouvez rencontrer un sous-échantillon de formation particulièrement «bon».  La présence d'un petit échantillon d'apprentissage implique que la valeur des erreurs dans les échantillons de validation et d'apprentissage peut être sujette à des fluctuations aléatoires. </p><cut></cut><br><p>  Si les données utilisées pour votre application utilisant l'apprentissage automatique sont fortement biaisées vers une classe (comme avec le problème de classification des chats, dans lequel la proportion d'exemples négatifs est beaucoup plus grande que la proportion de positifs), ou si nous avons affaire à un grand nombre de classes (telles que reconnaissance de 100 espèces animales différentes), la chance d'obtenir un échantillon de formation particulièrement «non représentatif» ou médiocre augmente également.  Par exemple, si 80% de vos exemples sont des exemples négatifs (y = 0), et seulement 20% sont des exemples positifs (y = 1), alors il y a de fortes chances qu'un sous-ensemble de formation de 10 exemples contienne uniquement des exemples négatifs, dans ce cas très il est difficile d'obtenir quelque chose de raisonnable à partir de l'algorithme entraîné. </p><br><p>  Si, en raison du bruit de la courbe d'apprentissage dans l'échantillon d'apprentissage, il est difficile de faire une évaluation des tendances, on peut proposer les deux solutions suivantes: </p><br><ul><li><p>  Au lieu de former un seul modèle pour 10 exemples de formation, sélectionner avec remplacement plusieurs (disons 3 à 10) sous-échantillons de formation aléatoires différents dans l'échantillon initial composé de 100 exemples.  Former le modèle sur chacun d'eux et calculer pour chacun de ces modèles l'erreur sur l'échantillon de validation et d'apprentissage.  Comptez et tracez l'erreur moyenne sur les échantillons d'apprentissage et de validation. </p><cut></cut><br><p>  <u><em>Remarque de l'auteur:</em></u> <em>Un échantillon avec remplacement signifie ce qui suit: sélectionnez au hasard les 10 premiers exemples différents parmi 100 pour former le premier sous-échantillon de formation.</em>  <em>Ensuite, pour former le deuxième sous-échantillon de formation, prenez à nouveau 10 exemples, mais en excluant ceux sélectionnés dans le premier sous-échantillon (encore une fois sur une centaine d'exemples).</em>  <em>Ainsi, un exemple spécifique peut apparaître dans les deux sous-échantillons.</em>  <em>Cela distingue un échantillon avec remplacement d'un échantillon sans remplacement; dans le cas d'un échantillon sans remplacement, le deuxième sous-échantillon d'apprentissage serait sélectionné parmi seulement 90 exemples qui ne faisaient pas partie du premier sous-échantillon.</em>  <em>En pratique, la méthode de sélection des exemples avec ou sans substitution ne devrait pas être d'une grande importance, mais la sélection d'exemples avec substitution est une pratique courante.</em> </p><br></li><li><p>  Si votre échantillon d'apprentissage est biaisé vers l'une des classes, ou s'il comprend plusieurs classes, choisissez un sous-échantillon «équilibré» composé de 10 exemples d'apprentissage, choisis au hasard parmi 100 échantillons d'échantillons.  Par exemple, vous pouvez être sûr que 2/10 exemples sont positifs et 8/10 négatifs.  Pour résumer, vous pouvez être sûr que la proportion d'exemples de chaque classe dans l'ensemble de données observées est aussi proche que possible de leur part dans l'échantillon de formation initiale. </p><cut></cut><br><p>  Je ne m'embêterais avec aucune de ces méthodes jusqu'à ce que la représentation graphique des courbes d'erreur conduise à la conclusion que ces courbes sont excessivement bruyantes, ce qui ne nous permet pas de voir des tendances compréhensibles.  Si vous avez un grand échantillon de formation - disons environ 10 000 exemples et que la distribution de vos cours n'est pas très biaisée, vous n'aurez peut-être pas besoin de ces méthodes. </p><br></li></ul><br><p>  Enfin, la construction d'une courbe d'apprentissage peut être coûteuse d'un point de vue informatique: par exemple, vous devez former dix modèles, dans les 1000 premiers exemples, dans le second 2000, et ainsi de suite jusqu'au dernier contenant 10000 exemples.  La formation de modèles sur de petites quantités de données est beaucoup plus rapide que la formation de modèles sur de grands échantillons.  Ainsi, au lieu de répartir uniformément les tailles des sous-échantillons d'apprentissage sur une échelle linéaire, comme décrit ci-dessus (1000, 2000, 3000, ..., 10000), vous pouvez former des modèles avec une augmentation non linéaire du nombre d'exemples, par exemple, 1000, 2000, 4000, 6000 et 10 000 exemples.  Cela devrait tout de même vous donner une compréhension claire de la tendance de la dépendance de la qualité du modèle au nombre d'exemples de formation dans les courbes d'apprentissage.  Bien sûr, cette technique n'est pertinente que si le coût de calcul de la formation de modèles supplémentaires est élevé. </p><cut></cut><br><p>  <a href="https://habr.com/ru/post/484680/"><em>suite</em></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483750/">https://habr.com/ru/post/fr483750/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483740/index.html">Configuration du routage dynamique (en particulier BGP) sur le tunnel OpenVPN sous Linux (et probablement * BSD)</a></li>
<li><a href="../fr483742/index.html">Rechercher des bugs comme mode de vie</a></li>
<li><a href="../fr483744/index.html">Vente du Nouvel An</a></li>
<li><a href="../fr483746/index.html">Station Gateway: passage à la ligne lunaire, accès à la station martienne</a></li>
<li><a href="../fr483748/index.html">La négligence des utilisateurs de PayPal leur permettant de voler leur compte et leur argent [Corrigé]</a></li>
<li><a href="../fr483754/index.html">Comment mesurer l'amélioration de l'équipe?</a></li>
<li><a href="../fr483756/index.html">Nous faisons des requêtes HTTP, dégradons gracieusement (et pas un seul écart)</a></li>
<li><a href="../fr483758/index.html">Les 10 premières entreprises de développement d'applications mobiles peuvent s'associer en 2020</a></li>
<li><a href="../fr483762/index.html">GitLab 12.6 publié avec les cotes de sécurité du projet et les documents de sortie</a></li>
<li><a href="../fr483766/index.html">Les tribunaux comme outil de piratage social ou un peu sur la fiabilité des informations dans les bases de données WHOIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
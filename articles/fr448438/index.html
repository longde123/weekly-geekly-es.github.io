<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤯 👩🏽‍🤝‍👩🏼 🚵 Limiter la vitesse de traitement des demandes ou comment ne pas organiser une attaque DDoS sur votre client 📜 🤷🏿 🔸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parfois, lors du développement d'un produit à haute charge, une situation survient lorsqu'il est nécessaire de traiter non autant de demandes que poss...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Limiter la vitesse de traitement des demandes ou comment ne pas organiser une attaque DDoS sur votre client</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448438/"><p> Parfois, lors du développement d'un produit à haute charge, une situation survient lorsqu'il est nécessaire de traiter non autant de demandes que possible, mais plutôt de limiter le nombre de demandes par unité de temps.  Dans notre cas, il s'agit du nombre de notifications push envoyées aux utilisateurs finaux.  En savoir plus sur les algorithmes de limitation de débit, leurs avantages et leurs inconvénients - sous la coupe. </p><br><a name="habracut"></a><br><p>  D'abord, un peu de nous.  Pushwoosh est un service B2B de communication entre nos clients et leurs utilisateurs.  Nous proposons aux entreprises des solutions complètes pour communiquer avec les utilisateurs via des notifications push, des e-mails et d'autres canaux de communication.  En plus d'envoyer réellement des messages, nous proposons des outils pour segmenter l'audience, collecter et traiter des statistiques, et bien plus encore.  Pour ce faire, nous avons créé à partir de zéro un produit à haute charge à la jonction de nombreuses technologies, dont seulement une petite partie sont PHP, Golang, PostgreSQL, MongoDB, Apache Kafka.  Beaucoup de nos solutions sont uniques, par exemple, les notifications à haut débit.  Nous traitons plus de 2 milliards de demandes d'API par jour, nous avons plus de 3 milliards d'appareils dans notre base de données et, pendant toute la durée, nous avons envoyé plus de 500 milliards de notifications à ces appareils. </p><br><p>  Et ici, nous arrivons à une situation où les notifications doivent être envoyées à des millions d'appareils pas aussi rapidement que possible (comme dans le haut débit déjà mentionné), mais en limitant artificiellement la vitesse afin que les serveurs de nos clients auxquels les utilisateurs se rendent lorsqu'ils ouvrent la notification ne tombent pas dans le même temps charge. <br></p><br><p>  Ici, divers algorithmes de limitation de débit viennent à notre aide, ce qui nous permet de limiter le nombre de requêtes par unité de temps.  En règle générale, cela est utilisé, par exemple, lors de la conception d'une API, car nous pouvons ainsi protéger le système contre les excès accidentels ou malveillants de demandes, ce qui entraîne un retard ou un déni de service à d'autres clients.  Si la limitation de débit est mise en œuvre, tous les clients sont limités à un nombre fixe de demandes par unité de temps.  De plus, la limitation de débit peut être utilisée lors de l'accès à des parties du système associées à des données sensibles;  Ainsi, si un attaquant y accède, il ne pourra pas accéder rapidement à toutes les données. <br></p><br><p>  Il existe de nombreuses façons d'implémenter la limitation de débit.  Dans cet article, nous examinerons les avantages et les inconvénients de divers algorithmes, ainsi que les problèmes pouvant survenir lors de la mise à l'échelle de ces solutions. <br></p><br><h2>  Algorithmes de limite de vitesse de traitement des demandes </h2><br><h3>  Seau qui fuit (Seau qui fuit) </h3><br><p>  <i>Leaky Bucket</i> est un algorithme qui fournit l'approche la plus simple et la plus intuitive pour limiter la vitesse de traitement à l'aide d'une file d'attente, qui peut être représentée comme un "bucket" contenant des requêtes.  Lorsqu'une demande est reçue, elle est ajoutée à la fin de la file d'attente.  À intervalles réguliers, le premier élément de la file d'attente est traité.  Ceci est également connu comme la file d'attente <abbr title="Premier entré - premier sorti">FIFO</abbr> .  Si la file d'attente est pleine, les demandes supplémentaires sont rejetées (ou «fuite»). <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fo/jw/hy/fojwhyst1w3e6fij2eh6lsb04y8.gif" alt="Seau de jetons de rendu"></div><br><p>  L'avantage de cet algorithme est qu'il lisse les explosions et traite les demandes à environ la même vitesse, qu'il est facile à implémenter sur un seul serveur ou équilibreur de charge, qu'il est efficace dans l'utilisation de la mémoire, car la taille de la file d'attente pour chaque utilisateur est limitée. <br>  Cependant, avec une forte augmentation du trafic, la file d'attente peut être remplie d'anciennes demandes et priver le système de la possibilité de traiter des demandes plus récentes.  Il ne garantit pas non plus que les demandes seront traitées dans un délai déterminé.  De plus, si vous chargez des équilibreurs pour fournir une tolérance aux pannes ou augmenter le débit, vous devez mettre en œuvre une stratégie de coordination et garantir une restriction globale entre eux. <br></p><br><p>  Il existe une variante de cet algorithme - <i>Token Bucket</i> («bucket with tokens» ou «marker basket algorithm»). <br></p><br><p>  Dans une telle implémentation, les jetons sont ajoutés au «compartiment» à une vitesse constante, et lors du traitement de la demande, le jeton du «compartiment» est supprimé;  s'il n'y a pas assez de jetons, la demande est rejetée.  Vous pouvez simplement utiliser l'horodatage comme jetons. <br></p><br><p>  Il existe des variantes utilisant plusieurs «seaux», tandis que les tailles et le taux de réception des jetons peuvent être différents pour des «seaux» individuels.  S'il n'y a pas assez de jetons dans le premier "compartiment" pour traiter la demande, alors leur présence dans le second, etc., est vérifiée, mais la priorité du traitement de la demande est réduite (en règle générale, cela est utilisé dans la conception des interfaces réseau lorsque, par exemple, vous pouvez modifier la valeur du champ Paquet traité par <abbr title="Point de code des services différenciés">DSCP</abbr> ). <br></p><br><p>  La principale différence avec l'implémentation de <i>Leaky Bucket</i> est que les jetons peuvent s'accumuler lorsque le système est inactif et que des rafales peuvent se produire plus tard, tandis que les demandes seront traitées (car il y a suffisamment de jetons), tandis que <i>Leaky Bucket est</i> garanti pour lisser la charge même en cas de panne. <br></p><br><h3>  Fenêtre fixe </h3><br><p>  Cet algorithme utilise une fenêtre de n secondes pour suivre les demandes.  En règle générale, des valeurs telles que 60 secondes (minutes) ou 3600 secondes (heures) sont utilisées.  Chaque demande entrante augmente le compteur de cette fenêtre.  Si le compteur dépasse une certaine valeur de seuil, la demande est rejetée.  En règle générale, la fenêtre est déterminée par la limite inférieure de l'intervalle de temps actuel, c'est-à-dire que lorsque la fenêtre a une largeur de 60 secondes, la demande arrivant à 12:00:03 ira à la fenêtre 12:00:00. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w3/lz/di/w3lzdijb2gk80a6rltf7rs2ejz8.gif" alt="Fenêtre fixe de rendu"></div><br><p>  L'avantage de cet algorithme est qu'il permet le traitement des requêtes les plus récentes, sans dépendre du traitement des anciennes.  Cependant, une seule rafale de trafic près de la bordure de la fenêtre peut doubler le nombre de demandes traitées, car elle autorise les demandes pour la fenêtre actuelle et la fenêtre suivante pendant une courte période.  De plus, si de nombreux utilisateurs attendent la réinitialisation du compteur de fenêtres, par exemple, à la fin de l'heure, ils peuvent provoquer une augmentation de la charge à ce moment du fait qu'ils accéderont à l'API en même temps. <br></p><br><h3>  Bûche coulissante </h3><br><p>  Cet algorithme implique le suivi des horodatages de chaque demande utilisateur.  Ces enregistrements sont stockés, par exemple, dans un ensemble ou une table de hachage et triés par heure;  les enregistrements en dehors de l'intervalle surveillé sont rejetés.  Lorsqu'une nouvelle demande arrive, nous calculons le nombre d'enregistrements pour déterminer la fréquence des demandes.  Si la demande est en dehors de la quantité autorisée, elle est rejetée. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nv/8a/9z/nv8a9zz0_ycg7sm4htfair2fk44.gif" alt="Journal coulissant de visualisation"></div><br><p>  L'avantage de cet algorithme est qu'il n'est pas soumis à des problèmes qui se posent aux bords de la <i>fenêtre fixe</i> , c'est-à-dire que la limite de vitesse sera strictement respectée.  De plus, étant donné que les demandes de chaque client sont surveillées individuellement, il n'y a pas de croissance de charge maximale à certains points, ce qui est un autre problème de l'algorithme précédent. <br></p><br><p>  Cependant, le stockage d'informations sur chaque demande peut être coûteux.En outre, chaque demande nécessite de calculer le nombre de demandes précédentes, potentiellement sur l'ensemble du cluster, ce qui fait que cette approche ne s'adapte pas bien pour gérer de grandes quantités de trafic et les attaques par déni de service. <br></p><br><h3>  Fenêtre coulissante </h3><br><p>  Il s'agit d'une approche hybride qui combine le faible coût de traitement d'une <i>fenêtre fixe</i> et la gestion avancée des situations limites <i>Sliding Log</i> .  Comme dans la <i>fenêtre fixe</i> simple, nous suivons le compteur de chaque fenêtre, puis prenons en compte la valeur pondérée de la fréquence de demande de la fenêtre précédente en fonction de l'horodatage actuel pour lisser les rafales de trafic.  Par exemple, si 25% du temps de la fenêtre courante s'est écoulé, alors nous prenons en compte 75% des demandes de la précédente.  La quantité relativement faible de données nécessaires pour le suivi de chaque clé nous permet d'évoluer et de travailler dans un grand cluster. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jx/yz/ps/jxyzpszmkozfruckcg2s5lhsmd0.gif" alt="Fenêtre coulissante de visualisation"></div><br><p>  Cet algorithme vous permet de mettre à l'échelle la limitation de débit tout en conservant de bonnes performances.  De plus, c'est un moyen compréhensible de transmettre aux clients des informations sur la limitation du nombre de demandes, et évite également les problèmes qui surviennent lors de la mise en œuvre d'autres algorithmes de limitation de débit. <br></p><br><h2>  Limitation de débit dans les systèmes distribués </h2><br><h3>  Politiques de synchronisation </h3><br><p>  Si vous souhaitez définir la limitation de débit globale lors de l'accès à un cluster composé de plusieurs nœuds, vous devez mettre en œuvre une stratégie de restriction.  Si chaque nœud ne suivait que sa propre restriction, l'utilisateur pouvait la contourner en envoyant simplement des demandes à différents nœuds.  En fait, plus le nombre de nœuds est élevé, plus la probabilité que l'utilisateur soit en mesure de dépasser la limite globale est grande. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nb/iq/30/nbiq30phqg_b0zibtuoagajyl50.gif" alt="Visualisation du manque de synchronisation"></div><br><p>  Le moyen le plus simple de définir des limites consiste à configurer une «session persistante» sur l'équilibreur afin que l'utilisateur soit dirigé vers le même nœud.  Les inconvénients de cette méthode sont le manque de tolérance aux pannes et les problèmes de mise à l'échelle lorsque les nœuds de cluster sont surchargés. <br></p><br><p>  La meilleure solution, qui permet des règles plus flexibles pour l'équilibrage de charge, est d'utiliser un entrepôt de données centralisé (de votre choix).  Il peut stocker des compteurs du nombre de demandes pour chaque fenêtre et utilisateur.  Les principaux problèmes de cette approche sont l'augmentation du temps de réponse due aux demandes de stockage et aux conditions de concurrence. <br></p><br><h3>  Conditions de course </h3><br><p>  Un des plus gros problèmes avec un entrepôt de données centralisé est la possibilité de conditions de course en compétition.  Cela se produit lorsque vous utilisez l'approche get-then-set naturelle, dans laquelle vous extrayez le compteur actuel, l'incrémentez, puis renvoyez la valeur résultante au magasin.  Le problème avec ce modèle est que pendant le temps nécessaire pour terminer le cycle complet de ces opérations (c'est-à-dire lire, incrémenter et écrire), d'autres demandes peuvent arriver, à chacune desquelles le compteur sera stocké avec une valeur non valide (inférieure).  Cela permet à l'utilisateur d'envoyer plus de demandes que l'algorithme de limitation de débit ne fournit. <br></p><br><p>  Une façon d'éviter ce problème consiste à définir un verrou autour de la clé en question, empêchant ainsi l'accès à la lecture ou à l'écriture de tout autre processus sur le compteur.  Cependant, cela peut rapidement devenir un goulot d'étranglement des performances et n'évolue pas bien, en particulier lors de l'utilisation de serveurs distants, tels que Redis, comme magasin de données supplémentaire. <br></p><br><p>  Une bien meilleure approche est «set - then - get», basée sur les opérateurs atomiques, qui vous permet d'augmenter et de vérifier rapidement les valeurs du compteur sans interférer avec les opérations atomiques. <br></p><br><h3>  Optimisation des performances </h3><br><p>  Un autre inconvénient de l'utilisation d'un entrepôt de données centralisé est l'augmentation du temps de réponse en raison du retard dans la vérification des compteurs utilisés pour mettre en œuvre la limitation de débit (temps <i>aller-retour</i> , ou «retard <i>aller-retour</i> »).  Malheureusement, même la vérification d'un stockage rapide tel que Redis entraînera des retards supplémentaires de quelques millisecondes par demande. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vn/y_/oc/vny_ocyqyqddljb5lbqnd5wlrgw.gif" alt="Temps aller-retour de visualisation"></div><br><p>  Pour faire la définition d'une contrainte avec un délai minimum, il est nécessaire d'effectuer des vérifications en mémoire locale.  Cela peut être fait en assouplissant les conditions de vérification de la vitesse et éventuellement en utilisant un modèle cohérent. <br></p><br><p>  Par exemple, chaque nœud peut créer un cycle de synchronisation des données dans lequel il se synchronisera avec le référentiel.  Chaque nœud transmet périodiquement la valeur du compteur pour chaque utilisateur et la fenêtre affectée, au magasin, qui mettra à jour atomiquement les valeurs.  Ensuite, le nœud peut recevoir de nouvelles valeurs et mettre à jour les données dans la mémoire locale.  Ce cycle permettra à terme à tous les nœuds du cluster d'être à jour. <br></p><br><p>  La période pendant laquelle les nœuds sont synchronisés doit être personnalisable.  Des intervalles de synchronisation plus courts entraîneront moins de divergence de données lorsque la charge est répartie uniformément sur plusieurs nœuds du cluster (par exemple, dans le cas où l'équilibreur détermine les nœuds selon le principe du «round-robin»), tandis que des intervalles plus longs créent moins de charge de lecture / écriture pour le stockage et réduire le coût à chaque nœud pour recevoir des données synchronisées. <br></p><br><h2>  Comparaison des algorithmes de limitation de débit </h2><br><p>  Plus précisément, dans notre cas, nous ne devons pas rejeter les demandes des clients pour l'API, mais sur la base des données, au contraire, ne les créons pas;  cependant, nous n'avons pas le droit de «perdre» les demandes.  Pour ce faire, lors de l'envoi d'une notification, nous utilisons le paramètre send_rate, qui indique le nombre maximum de notifications que nous enverrons par seconde lors de l'envoi. <br></p><br><p>  Ainsi, un certain Worker effectue un travail dans le temps imparti (dans mon exemple, la lecture d'un fichier), qui reçoit l'interface RateLimitingInterface en entrée, indiquant s'il est possible d'exécuter une demande à un moment donné et combien de temps elle s'exécutera. <br></p><br><pre><code class="php hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RateLimitingInterface</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> int $rate Expected send rate */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__construct</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(int $rate)</span></span></span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $currentTime Current timestamp in microseconds * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> bool */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">canDoWork</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $currentTime)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bool</span></span></span></span>; }</code> </pre> <br><p>  Tous les exemples de code peuvent être trouvés sur GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br></p><br><p>  Je vais immédiatement expliquer pourquoi vous devez transférer une tranche de temps vers Worker.  Le fait est qu'il est trop coûteux d'exécuter un démon distinct pour traiter l'envoi d'un message avec une limite de vitesse, donc send_rate est en fait utilisé comme paramètre "nombre de notifications par unité de temps", qui est de 0,01 à 1 seconde selon la charge. <br></p><br><p>  En fait, nous traitons jusqu'à 100 requêtes différentes avec send_rate par seconde, allouant 1 / N secondes pour chaque quantum de temps, où N est le nombre de push traités par ce démon.  Le paramètre qui nous intéresse le plus lors du traitement est de savoir si send_rate sera respecté (les petites erreurs sont autorisées dans un sens ou dans l'autre) et la charge sur notre matériel (nombre minimum d'accès au stockage, consommation CPU et mémoire). <br></p><br><p>  Pour commencer, essayons de déterminer à quels moments Worker fonctionne vraiment.  Pour simplifier, cet exemple a traité un fichier de 10 000 lignes avec send_rate = 1000 (c'est-à-dire que nous lisons 1 000 lignes par seconde dans le fichier). <br></p><br>  Dans les captures d'écran, les marqueurs marquent les moments et le nombre d'appels de fgets pour tous les algorithmes.  En réalité, cela peut être un appel à une base de données, à une ressource tierce ou à toute autre requête, dont nous voulons limiter le nombre par unité de temps. <br><br><p>  Sur l'échelle X - le temps depuis le début du traitement, de 0 à 10 secondes, chaque seconde est divisée en dixièmes, donc le calendrier est de 0 à 100). <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tb/vk/9u/tbvk9usi0mai17koyki16flm6im.png" alt="Fonctionnement du seau à jetons"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/77/t0/av/77t0avq7kqwhkm_4tqlcurek4qc.png" alt="Fonctionnement de l'algorithme de fenêtre fixe"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w9/xo/yi/w9xoyihrbuezu0exbewj8mru9mm.png" alt="Le fonctionnement de l'algorithme Sliding Log"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ye/u0/etyeu0hvzzd4hygu8outelbr2ru.png" alt="Fonctionnement de l'algorithme de fenêtre coulissante"></div><br><p>  Nous voyons que malgré le fait que tous les algorithmes gèrent l'observance de send_rate (pour cela, ils sont destinés), la <i>fenêtre fixe</i> et le <i>journal coulissant</i> "distribuent" la charge entière presque simultanément, ce qui ne nous convient pas beaucoup, tandis que <i>Token Bucket</i> et <i>Sliding Windows le</i> répartit uniformément par unité de temps (à l'exception de la charge de pointe au moment du démarrage, en raison du manque de données sur la charge aux heures précédentes). <br></p><br><p>  En raison du fait qu'en réalité, le code ne fonctionne généralement pas avec le système de fichiers local, mais avec un stockage tiers, la réponse peut être retardée, il peut y avoir des problèmes de réseau et de nombreux autres problèmes, nous allons essayer de vérifier comment tel ou tel algorithme se comportera lorsque les demandes prendront un certain temps n'était pas.  Par exemple, après 4 et 6 secondes. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fj/lj/gg/fjljggb06hkp7yannsyvtt3b_rw.png" alt="Delay Token Bucket Operation"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qq/jp/nw/qqjpnw6rtcp7wmgmnsu3omlqkrw.png" alt="Fonctionnement de la fenêtre fixe avec un retard"></div><br><p>  Ici, il peut sembler que la <i>fenêtre fixe</i> ne fonctionne pas correctement et traite 2 fois plus que les requêtes attendues dans les premières et de 7 à 8 secondes, mais en fait ce n'est pas le cas, car le temps est compté à partir du moment du lancement sur le graphique, et l'algorithme utilise le timestamp Unix actuel . <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yh/0k/-k/yh0k-ko8ragfy0mb1n4vcjj8c2o.png" alt="Opération de journalisation différée"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wh/jx/ww/whjxwwdpzkgxx1hikrb2ogpag-o.png" alt="Fonctionnement de la fenêtre coulissante avec retard"></div><br><p>  En général, rien n'a fondamentalement changé, mais nous voyons que le <i>seau à jetons</i> lisse la charge plus en douceur et ne dépasse jamais la limite de débit spécifiée, mais le <i>journal de glissement</i> en cas d'indisponibilité peut dépasser la valeur autorisée. <br></p><br><h2>  Conclusion </h2><br><p>  Nous avons examiné tous les algorithmes de base pour implémenter la limitation de débit, chacun ayant ses avantages et ses inconvénients et convenant à diverses tâches.  Nous espérons qu'après avoir lu cet article, vous choisirez l'algorithme le plus approprié pour résoudre votre problème. <br></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr448438/">https://habr.com/ru/post/fr448438/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr448424/index.html">55 ans plus tard: les emblématiques consoles IBM System / 360 culte</a></li>
<li><a href="../fr448430/index.html">Contenu pro 2019: trois rapports et une chanson</a></li>
<li><a href="../fr448432/index.html">Rayonnement adhésif: radioactivité induite, contamination radioactive, décontamination ...</a></li>
<li><a href="../fr448434/index.html">Principales sociétés de développement d'applications mobiles</a></li>
<li><a href="../fr448436/index.html">Couche de convolution: techniques d'optimisation de la multiplication matricielle</a></li>
<li><a href="../fr448440/index.html">Des centaines de milliers de paiements effectués par des citoyens au STSI et au FSSP étaient du domaine public</a></li>
<li><a href="../fr448442/index.html">SSD GIGABYTE Aorus RGB M.2: petite télécommande uniforme pour LED RGB (1 partie)</a></li>
<li><a href="../fr448444/index.html">Se débarrasser de la peur du premier emploi</a></li>
<li><a href="../fr448448/index.html">Rapport SWIFT: le volume de fonds volés par des pirates informatiques dans les banques a décuplé de 100 millions de dollars trois ans après le piratage</a></li>
<li><a href="../fr448450/index.html">Outils d'analyse Web pour un spécialiste du marketing novice, un distributeur de produits et des analyses</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
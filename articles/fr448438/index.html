<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¤¯ ğŸ‘©ğŸ½â€ğŸ¤â€ğŸ‘©ğŸ¼ ğŸšµ Limiter la vitesse de traitement des demandes ou comment ne pas organiser une attaque DDoS sur votre client ğŸ“œ ğŸ¤·ğŸ¿ ğŸ”¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parfois, lors du dÃ©veloppement d'un produit Ã  haute charge, une situation survient lorsqu'il est nÃ©cessaire de traiter non autant de demandes que poss...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Limiter la vitesse de traitement des demandes ou comment ne pas organiser une attaque DDoS sur votre client</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448438/"><p> Parfois, lors du dÃ©veloppement d'un produit Ã  haute charge, une situation survient lorsqu'il est nÃ©cessaire de traiter non autant de demandes que possible, mais plutÃ´t de limiter le nombre de demandes par unitÃ© de temps.  Dans notre cas, il s'agit du nombre de notifications push envoyÃ©es aux utilisateurs finaux.  En savoir plus sur les algorithmes de limitation de dÃ©bit, leurs avantages et leurs inconvÃ©nients - sous la coupe. </p><br><a name="habracut"></a><br><p>  D'abord, un peu de nous.  Pushwoosh est un service B2B de communication entre nos clients et leurs utilisateurs.  Nous proposons aux entreprises des solutions complÃ¨tes pour communiquer avec les utilisateurs via des notifications push, des e-mails et d'autres canaux de communication.  En plus d'envoyer rÃ©ellement des messages, nous proposons des outils pour segmenter l'audience, collecter et traiter des statistiques, et bien plus encore.  Pour ce faire, nous avons crÃ©Ã© Ã  partir de zÃ©ro un produit Ã  haute charge Ã  la jonction de nombreuses technologies, dont seulement une petite partie sont PHP, Golang, PostgreSQL, MongoDB, Apache Kafka.  Beaucoup de nos solutions sont uniques, par exemple, les notifications Ã  haut dÃ©bit.  Nous traitons plus de 2 milliards de demandes d'API par jour, nous avons plus de 3 milliards d'appareils dans notre base de donnÃ©es et, pendant toute la durÃ©e, nous avons envoyÃ© plus de 500 milliards de notifications Ã  ces appareils. </p><br><p>  Et ici, nous arrivons Ã  une situation oÃ¹ les notifications doivent Ãªtre envoyÃ©es Ã  des millions d'appareils pas aussi rapidement que possible (comme dans le haut dÃ©bit dÃ©jÃ  mentionnÃ©), mais en limitant artificiellement la vitesse afin que les serveurs de nos clients auxquels les utilisateurs se rendent lorsqu'ils ouvrent la notification ne tombent pas dans le mÃªme temps charge. <br></p><br><p>  Ici, divers algorithmes de limitation de dÃ©bit viennent Ã  notre aide, ce qui nous permet de limiter le nombre de requÃªtes par unitÃ© de temps.  En rÃ¨gle gÃ©nÃ©rale, cela est utilisÃ©, par exemple, lors de la conception d'une API, car nous pouvons ainsi protÃ©ger le systÃ¨me contre les excÃ¨s accidentels ou malveillants de demandes, ce qui entraÃ®ne un retard ou un dÃ©ni de service Ã  d'autres clients.  Si la limitation de dÃ©bit est mise en Å“uvre, tous les clients sont limitÃ©s Ã  un nombre fixe de demandes par unitÃ© de temps.  De plus, la limitation de dÃ©bit peut Ãªtre utilisÃ©e lors de l'accÃ¨s Ã  des parties du systÃ¨me associÃ©es Ã  des donnÃ©es sensibles;  Ainsi, si un attaquant y accÃ¨de, il ne pourra pas accÃ©der rapidement Ã  toutes les donnÃ©es. <br></p><br><p>  Il existe de nombreuses faÃ§ons d'implÃ©menter la limitation de dÃ©bit.  Dans cet article, nous examinerons les avantages et les inconvÃ©nients de divers algorithmes, ainsi que les problÃ¨mes pouvant survenir lors de la mise Ã  l'Ã©chelle de ces solutions. <br></p><br><h2>  Algorithmes de limite de vitesse de traitement des demandes </h2><br><h3>  Seau qui fuit (Seau qui fuit) </h3><br><p>  <i>Leaky Bucket</i> est un algorithme qui fournit l'approche la plus simple et la plus intuitive pour limiter la vitesse de traitement Ã  l'aide d'une file d'attente, qui peut Ãªtre reprÃ©sentÃ©e comme un "bucket" contenant des requÃªtes.  Lorsqu'une demande est reÃ§ue, elle est ajoutÃ©e Ã  la fin de la file d'attente.  Ã€ intervalles rÃ©guliers, le premier Ã©lÃ©ment de la file d'attente est traitÃ©.  Ceci est Ã©galement connu comme la file d'attente <abbr title="Premier entrÃ© - premier sorti">FIFO</abbr> .  Si la file d'attente est pleine, les demandes supplÃ©mentaires sont rejetÃ©es (ou Â«fuiteÂ»). <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fo/jw/hy/fojwhyst1w3e6fij2eh6lsb04y8.gif" alt="Seau de jetons de rendu"></div><br><p>  L'avantage de cet algorithme est qu'il lisse les explosions et traite les demandes Ã  environ la mÃªme vitesse, qu'il est facile Ã  implÃ©menter sur un seul serveur ou Ã©quilibreur de charge, qu'il est efficace dans l'utilisation de la mÃ©moire, car la taille de la file d'attente pour chaque utilisateur est limitÃ©e. <br>  Cependant, avec une forte augmentation du trafic, la file d'attente peut Ãªtre remplie d'anciennes demandes et priver le systÃ¨me de la possibilitÃ© de traiter des demandes plus rÃ©centes.  Il ne garantit pas non plus que les demandes seront traitÃ©es dans un dÃ©lai dÃ©terminÃ©.  De plus, si vous chargez des Ã©quilibreurs pour fournir une tolÃ©rance aux pannes ou augmenter le dÃ©bit, vous devez mettre en Å“uvre une stratÃ©gie de coordination et garantir une restriction globale entre eux. <br></p><br><p>  Il existe une variante de cet algorithme - <i>Token Bucket</i> (Â«bucket with tokensÂ» ou Â«marker basket algorithmÂ»). <br></p><br><p>  Dans une telle implÃ©mentation, les jetons sont ajoutÃ©s au Â«compartimentÂ» Ã  une vitesse constante, et lors du traitement de la demande, le jeton du Â«compartimentÂ» est supprimÃ©;  s'il n'y a pas assez de jetons, la demande est rejetÃ©e.  Vous pouvez simplement utiliser l'horodatage comme jetons. <br></p><br><p>  Il existe des variantes utilisant plusieurs Â«seauxÂ», tandis que les tailles et le taux de rÃ©ception des jetons peuvent Ãªtre diffÃ©rents pour des Â«seauxÂ» individuels.  S'il n'y a pas assez de jetons dans le premier "compartiment" pour traiter la demande, alors leur prÃ©sence dans le second, etc., est vÃ©rifiÃ©e, mais la prioritÃ© du traitement de la demande est rÃ©duite (en rÃ¨gle gÃ©nÃ©rale, cela est utilisÃ© dans la conception des interfaces rÃ©seau lorsque, par exemple, vous pouvez modifier la valeur du champ Paquet traitÃ© par <abbr title="Point de code des services diffÃ©renciÃ©s">DSCP</abbr> ). <br></p><br><p>  La principale diffÃ©rence avec l'implÃ©mentation de <i>Leaky Bucket</i> est que les jetons peuvent s'accumuler lorsque le systÃ¨me est inactif et que des rafales peuvent se produire plus tard, tandis que les demandes seront traitÃ©es (car il y a suffisamment de jetons), tandis que <i>Leaky Bucket est</i> garanti pour lisser la charge mÃªme en cas de panne. <br></p><br><h3>  FenÃªtre fixe </h3><br><p>  Cet algorithme utilise une fenÃªtre de n secondes pour suivre les demandes.  En rÃ¨gle gÃ©nÃ©rale, des valeurs telles que 60 secondes (minutes) ou 3600 secondes (heures) sont utilisÃ©es.  Chaque demande entrante augmente le compteur de cette fenÃªtre.  Si le compteur dÃ©passe une certaine valeur de seuil, la demande est rejetÃ©e.  En rÃ¨gle gÃ©nÃ©rale, la fenÃªtre est dÃ©terminÃ©e par la limite infÃ©rieure de l'intervalle de temps actuel, c'est-Ã -dire que lorsque la fenÃªtre a une largeur de 60 secondes, la demande arrivant Ã  12:00:03 ira Ã  la fenÃªtre 12:00:00. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w3/lz/di/w3lzdijb2gk80a6rltf7rs2ejz8.gif" alt="FenÃªtre fixe de rendu"></div><br><p>  L'avantage de cet algorithme est qu'il permet le traitement des requÃªtes les plus rÃ©centes, sans dÃ©pendre du traitement des anciennes.  Cependant, une seule rafale de trafic prÃ¨s de la bordure de la fenÃªtre peut doubler le nombre de demandes traitÃ©es, car elle autorise les demandes pour la fenÃªtre actuelle et la fenÃªtre suivante pendant une courte pÃ©riode.  De plus, si de nombreux utilisateurs attendent la rÃ©initialisation du compteur de fenÃªtres, par exemple, Ã  la fin de l'heure, ils peuvent provoquer une augmentation de la charge Ã  ce moment du fait qu'ils accÃ©deront Ã  l'API en mÃªme temps. <br></p><br><h3>  BÃ»che coulissante </h3><br><p>  Cet algorithme implique le suivi des horodatages de chaque demande utilisateur.  Ces enregistrements sont stockÃ©s, par exemple, dans un ensemble ou une table de hachage et triÃ©s par heure;  les enregistrements en dehors de l'intervalle surveillÃ© sont rejetÃ©s.  Lorsqu'une nouvelle demande arrive, nous calculons le nombre d'enregistrements pour dÃ©terminer la frÃ©quence des demandes.  Si la demande est en dehors de la quantitÃ© autorisÃ©e, elle est rejetÃ©e. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nv/8a/9z/nv8a9zz0_ycg7sm4htfair2fk44.gif" alt="Journal coulissant de visualisation"></div><br><p>  L'avantage de cet algorithme est qu'il n'est pas soumis Ã  des problÃ¨mes qui se posent aux bords de la <i>fenÃªtre fixe</i> , c'est-Ã -dire que la limite de vitesse sera strictement respectÃ©e.  De plus, Ã©tant donnÃ© que les demandes de chaque client sont surveillÃ©es individuellement, il n'y a pas de croissance de charge maximale Ã  certains points, ce qui est un autre problÃ¨me de l'algorithme prÃ©cÃ©dent. <br></p><br><p>  Cependant, le stockage d'informations sur chaque demande peut Ãªtre coÃ»teux.En outre, chaque demande nÃ©cessite de calculer le nombre de demandes prÃ©cÃ©dentes, potentiellement sur l'ensemble du cluster, ce qui fait que cette approche ne s'adapte pas bien pour gÃ©rer de grandes quantitÃ©s de trafic et les attaques par dÃ©ni de service. <br></p><br><h3>  FenÃªtre coulissante </h3><br><p>  Il s'agit d'une approche hybride qui combine le faible coÃ»t de traitement d'une <i>fenÃªtre fixe</i> et la gestion avancÃ©e des situations limites <i>Sliding Log</i> .  Comme dans la <i>fenÃªtre fixe</i> simple, nous suivons le compteur de chaque fenÃªtre, puis prenons en compte la valeur pondÃ©rÃ©e de la frÃ©quence de demande de la fenÃªtre prÃ©cÃ©dente en fonction de l'horodatage actuel pour lisser les rafales de trafic.  Par exemple, si 25% du temps de la fenÃªtre courante s'est Ã©coulÃ©, alors nous prenons en compte 75% des demandes de la prÃ©cÃ©dente.  La quantitÃ© relativement faible de donnÃ©es nÃ©cessaires pour le suivi de chaque clÃ© nous permet d'Ã©voluer et de travailler dans un grand cluster. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jx/yz/ps/jxyzpszmkozfruckcg2s5lhsmd0.gif" alt="FenÃªtre coulissante de visualisation"></div><br><p>  Cet algorithme vous permet de mettre Ã  l'Ã©chelle la limitation de dÃ©bit tout en conservant de bonnes performances.  De plus, c'est un moyen comprÃ©hensible de transmettre aux clients des informations sur la limitation du nombre de demandes, et Ã©vite Ã©galement les problÃ¨mes qui surviennent lors de la mise en Å“uvre d'autres algorithmes de limitation de dÃ©bit. <br></p><br><h2>  Limitation de dÃ©bit dans les systÃ¨mes distribuÃ©s </h2><br><h3>  Politiques de synchronisation </h3><br><p>  Si vous souhaitez dÃ©finir la limitation de dÃ©bit globale lors de l'accÃ¨s Ã  un cluster composÃ© de plusieurs nÅ“uds, vous devez mettre en Å“uvre une stratÃ©gie de restriction.  Si chaque nÅ“ud ne suivait que sa propre restriction, l'utilisateur pouvait la contourner en envoyant simplement des demandes Ã  diffÃ©rents nÅ“uds.  En fait, plus le nombre de nÅ“uds est Ã©levÃ©, plus la probabilitÃ© que l'utilisateur soit en mesure de dÃ©passer la limite globale est grande. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nb/iq/30/nbiq30phqg_b0zibtuoagajyl50.gif" alt="Visualisation du manque de synchronisation"></div><br><p>  Le moyen le plus simple de dÃ©finir des limites consiste Ã  configurer une Â«session persistanteÂ» sur l'Ã©quilibreur afin que l'utilisateur soit dirigÃ© vers le mÃªme nÅ“ud.  Les inconvÃ©nients de cette mÃ©thode sont le manque de tolÃ©rance aux pannes et les problÃ¨mes de mise Ã  l'Ã©chelle lorsque les nÅ“uds de cluster sont surchargÃ©s. <br></p><br><p>  La meilleure solution, qui permet des rÃ¨gles plus flexibles pour l'Ã©quilibrage de charge, est d'utiliser un entrepÃ´t de donnÃ©es centralisÃ© (de votre choix).  Il peut stocker des compteurs du nombre de demandes pour chaque fenÃªtre et utilisateur.  Les principaux problÃ¨mes de cette approche sont l'augmentation du temps de rÃ©ponse due aux demandes de stockage et aux conditions de concurrence. <br></p><br><h3>  Conditions de course </h3><br><p>  Un des plus gros problÃ¨mes avec un entrepÃ´t de donnÃ©es centralisÃ© est la possibilitÃ© de conditions de course en compÃ©tition.  Cela se produit lorsque vous utilisez l'approche get-then-set naturelle, dans laquelle vous extrayez le compteur actuel, l'incrÃ©mentez, puis renvoyez la valeur rÃ©sultante au magasin.  Le problÃ¨me avec ce modÃ¨le est que pendant le temps nÃ©cessaire pour terminer le cycle complet de ces opÃ©rations (c'est-Ã -dire lire, incrÃ©menter et Ã©crire), d'autres demandes peuvent arriver, Ã  chacune desquelles le compteur sera stockÃ© avec une valeur non valide (infÃ©rieure).  Cela permet Ã  l'utilisateur d'envoyer plus de demandes que l'algorithme de limitation de dÃ©bit ne fournit. <br></p><br><p>  Une faÃ§on d'Ã©viter ce problÃ¨me consiste Ã  dÃ©finir un verrou autour de la clÃ© en question, empÃªchant ainsi l'accÃ¨s Ã  la lecture ou Ã  l'Ã©criture de tout autre processus sur le compteur.  Cependant, cela peut rapidement devenir un goulot d'Ã©tranglement des performances et n'Ã©volue pas bien, en particulier lors de l'utilisation de serveurs distants, tels que Redis, comme magasin de donnÃ©es supplÃ©mentaire. <br></p><br><p>  Une bien meilleure approche est Â«set - then - getÂ», basÃ©e sur les opÃ©rateurs atomiques, qui vous permet d'augmenter et de vÃ©rifier rapidement les valeurs du compteur sans interfÃ©rer avec les opÃ©rations atomiques. <br></p><br><h3>  Optimisation des performances </h3><br><p>  Un autre inconvÃ©nient de l'utilisation d'un entrepÃ´t de donnÃ©es centralisÃ© est l'augmentation du temps de rÃ©ponse en raison du retard dans la vÃ©rification des compteurs utilisÃ©s pour mettre en Å“uvre la limitation de dÃ©bit (temps <i>aller-retour</i> , ou Â«retard <i>aller-retour</i> Â»).  Malheureusement, mÃªme la vÃ©rification d'un stockage rapide tel que Redis entraÃ®nera des retards supplÃ©mentaires de quelques millisecondes par demande. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vn/y_/oc/vny_ocyqyqddljb5lbqnd5wlrgw.gif" alt="Temps aller-retour de visualisation"></div><br><p>  Pour faire la dÃ©finition d'une contrainte avec un dÃ©lai minimum, il est nÃ©cessaire d'effectuer des vÃ©rifications en mÃ©moire locale.  Cela peut Ãªtre fait en assouplissant les conditions de vÃ©rification de la vitesse et Ã©ventuellement en utilisant un modÃ¨le cohÃ©rent. <br></p><br><p>  Par exemple, chaque nÅ“ud peut crÃ©er un cycle de synchronisation des donnÃ©es dans lequel il se synchronisera avec le rÃ©fÃ©rentiel.  Chaque nÅ“ud transmet pÃ©riodiquement la valeur du compteur pour chaque utilisateur et la fenÃªtre affectÃ©e, au magasin, qui mettra Ã  jour atomiquement les valeurs.  Ensuite, le nÅ“ud peut recevoir de nouvelles valeurs et mettre Ã  jour les donnÃ©es dans la mÃ©moire locale.  Ce cycle permettra Ã  terme Ã  tous les nÅ“uds du cluster d'Ãªtre Ã  jour. <br></p><br><p>  La pÃ©riode pendant laquelle les nÅ“uds sont synchronisÃ©s doit Ãªtre personnalisable.  Des intervalles de synchronisation plus courts entraÃ®neront moins de divergence de donnÃ©es lorsque la charge est rÃ©partie uniformÃ©ment sur plusieurs nÅ“uds du cluster (par exemple, dans le cas oÃ¹ l'Ã©quilibreur dÃ©termine les nÅ“uds selon le principe du Â«round-robinÂ»), tandis que des intervalles plus longs crÃ©ent moins de charge de lecture / Ã©criture pour le stockage et rÃ©duire le coÃ»t Ã  chaque nÅ“ud pour recevoir des donnÃ©es synchronisÃ©es. <br></p><br><h2>  Comparaison des algorithmes de limitation de dÃ©bit </h2><br><p>  Plus prÃ©cisÃ©ment, dans notre cas, nous ne devons pas rejeter les demandes des clients pour l'API, mais sur la base des donnÃ©es, au contraire, ne les crÃ©ons pas;  cependant, nous n'avons pas le droit de Â«perdreÂ» les demandes.  Pour ce faire, lors de l'envoi d'une notification, nous utilisons le paramÃ¨tre send_rate, qui indique le nombre maximum de notifications que nous enverrons par seconde lors de l'envoi. <br></p><br><p>  Ainsi, un certain Worker effectue un travail dans le temps imparti (dans mon exemple, la lecture d'un fichier), qui reÃ§oit l'interface RateLimitingInterface en entrÃ©e, indiquant s'il est possible d'exÃ©cuter une demande Ã  un moment donnÃ© et combien de temps elle s'exÃ©cutera. <br></p><br><pre><code class="php hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RateLimitingInterface</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> int $rate Expected send rate */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__construct</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(int $rate)</span></span></span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $currentTime Current timestamp in microseconds * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> bool */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">canDoWork</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $currentTime)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bool</span></span></span></span>; }</code> </pre> <br><p>  Tous les exemples de code peuvent Ãªtre trouvÃ©s sur GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br></p><br><p>  Je vais immÃ©diatement expliquer pourquoi vous devez transfÃ©rer une tranche de temps vers Worker.  Le fait est qu'il est trop coÃ»teux d'exÃ©cuter un dÃ©mon distinct pour traiter l'envoi d'un message avec une limite de vitesse, donc send_rate est en fait utilisÃ© comme paramÃ¨tre "nombre de notifications par unitÃ© de temps", qui est de 0,01 Ã  1 seconde selon la charge. <br></p><br><p>  En fait, nous traitons jusqu'Ã  100 requÃªtes diffÃ©rentes avec send_rate par seconde, allouant 1 / N secondes pour chaque quantum de temps, oÃ¹ N est le nombre de push traitÃ©s par ce dÃ©mon.  Le paramÃ¨tre qui nous intÃ©resse le plus lors du traitement est de savoir si send_rate sera respectÃ© (les petites erreurs sont autorisÃ©es dans un sens ou dans l'autre) et la charge sur notre matÃ©riel (nombre minimum d'accÃ¨s au stockage, consommation CPU et mÃ©moire). <br></p><br><p>  Pour commencer, essayons de dÃ©terminer Ã  quels moments Worker fonctionne vraiment.  Pour simplifier, cet exemple a traitÃ© un fichier de 10 000 lignes avec send_rate = 1000 (c'est-Ã -dire que nous lisons 1 000 lignes par seconde dans le fichier). <br></p><br>  Dans les captures d'Ã©cran, les marqueurs marquent les moments et le nombre d'appels de fgets pour tous les algorithmes.  En rÃ©alitÃ©, cela peut Ãªtre un appel Ã  une base de donnÃ©es, Ã  une ressource tierce ou Ã  toute autre requÃªte, dont nous voulons limiter le nombre par unitÃ© de temps. <br><br><p>  Sur l'Ã©chelle X - le temps depuis le dÃ©but du traitement, de 0 Ã  10 secondes, chaque seconde est divisÃ©e en dixiÃ¨mes, donc le calendrier est de 0 Ã  100). <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tb/vk/9u/tbvk9usi0mai17koyki16flm6im.png" alt="Fonctionnement du seau Ã  jetons"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/77/t0/av/77t0avq7kqwhkm_4tqlcurek4qc.png" alt="Fonctionnement de l'algorithme de fenÃªtre fixe"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w9/xo/yi/w9xoyihrbuezu0exbewj8mru9mm.png" alt="Le fonctionnement de l'algorithme Sliding Log"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ye/u0/etyeu0hvzzd4hygu8outelbr2ru.png" alt="Fonctionnement de l'algorithme de fenÃªtre coulissante"></div><br><p>  Nous voyons que malgrÃ© le fait que tous les algorithmes gÃ¨rent l'observance de send_rate (pour cela, ils sont destinÃ©s), la <i>fenÃªtre fixe</i> et le <i>journal coulissant</i> "distribuent" la charge entiÃ¨re presque simultanÃ©ment, ce qui ne nous convient pas beaucoup, tandis que <i>Token Bucket</i> et <i>Sliding Windows le</i> rÃ©partit uniformÃ©ment par unitÃ© de temps (Ã  l'exception de la charge de pointe au moment du dÃ©marrage, en raison du manque de donnÃ©es sur la charge aux heures prÃ©cÃ©dentes). <br></p><br><p>  En raison du fait qu'en rÃ©alitÃ©, le code ne fonctionne gÃ©nÃ©ralement pas avec le systÃ¨me de fichiers local, mais avec un stockage tiers, la rÃ©ponse peut Ãªtre retardÃ©e, il peut y avoir des problÃ¨mes de rÃ©seau et de nombreux autres problÃ¨mes, nous allons essayer de vÃ©rifier comment tel ou tel algorithme se comportera lorsque les demandes prendront un certain temps n'Ã©tait pas.  Par exemple, aprÃ¨s 4 et 6 secondes. <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fj/lj/gg/fjljggb06hkp7yannsyvtt3b_rw.png" alt="Delay Token Bucket Operation"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qq/jp/nw/qqjpnw6rtcp7wmgmnsu3omlqkrw.png" alt="Fonctionnement de la fenÃªtre fixe avec un retard"></div><br><p>  Ici, il peut sembler que la <i>fenÃªtre fixe</i> ne fonctionne pas correctement et traite 2 fois plus que les requÃªtes attendues dans les premiÃ¨res et de 7 Ã  8 secondes, mais en fait ce n'est pas le cas, car le temps est comptÃ© Ã  partir du moment du lancement sur le graphique, et l'algorithme utilise le timestamp Unix actuel . <br></p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yh/0k/-k/yh0k-ko8ragfy0mb1n4vcjj8c2o.png" alt="OpÃ©ration de journalisation diffÃ©rÃ©e"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wh/jx/ww/whjxwwdpzkgxx1hikrb2ogpag-o.png" alt="Fonctionnement de la fenÃªtre coulissante avec retard"></div><br><p>  En gÃ©nÃ©ral, rien n'a fondamentalement changÃ©, mais nous voyons que le <i>seau Ã  jetons</i> lisse la charge plus en douceur et ne dÃ©passe jamais la limite de dÃ©bit spÃ©cifiÃ©e, mais le <i>journal de glissement</i> en cas d'indisponibilitÃ© peut dÃ©passer la valeur autorisÃ©e. <br></p><br><h2>  Conclusion </h2><br><p>  Nous avons examinÃ© tous les algorithmes de base pour implÃ©menter la limitation de dÃ©bit, chacun ayant ses avantages et ses inconvÃ©nients et convenant Ã  diverses tÃ¢ches.  Nous espÃ©rons qu'aprÃ¨s avoir lu cet article, vous choisirez l'algorithme le plus appropriÃ© pour rÃ©soudre votre problÃ¨me. <br></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr448438/">https://habr.com/ru/post/fr448438/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr448424/index.html">55 ans plus tard: les emblÃ©matiques consoles IBM System / 360 culte</a></li>
<li><a href="../fr448430/index.html">Contenu pro 2019: trois rapports et une chanson</a></li>
<li><a href="../fr448432/index.html">Rayonnement adhÃ©sif: radioactivitÃ© induite, contamination radioactive, dÃ©contamination ...</a></li>
<li><a href="../fr448434/index.html">Principales sociÃ©tÃ©s de dÃ©veloppement d'applications mobiles</a></li>
<li><a href="../fr448436/index.html">Couche de convolution: techniques d'optimisation de la multiplication matricielle</a></li>
<li><a href="../fr448440/index.html">Des centaines de milliers de paiements effectuÃ©s par des citoyens au STSI et au FSSP Ã©taient du domaine public</a></li>
<li><a href="../fr448442/index.html">SSD GIGABYTE Aorus RGB M.2: petite tÃ©lÃ©commande uniforme pour LED RGB (1 partie)</a></li>
<li><a href="../fr448444/index.html">Se dÃ©barrasser de la peur du premier emploi</a></li>
<li><a href="../fr448448/index.html">Rapport SWIFT: le volume de fonds volÃ©s par des pirates informatiques dans les banques a dÃ©cuplÃ© de 100 millions de dollars trois ans aprÃ¨s le piratage</a></li>
<li><a href="../fr448450/index.html">Outils d'analyse Web pour un spÃ©cialiste du marketing novice, un distributeur de produits et des analyses</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
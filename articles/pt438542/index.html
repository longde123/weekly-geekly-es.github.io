<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✅ 👩🏿‍🚒 👩‍🏫 Como criamos um serviço de recomendação para a seleção de roupas em redes neurais 👎🏼 👨‍👩‍👧‍👦 👩‍❤️‍💋‍👩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, quero falar sobre como criamos um sistema de pesquisa de roupas semelhantes (mais precisamente roupas, sapatos e bolsas) a partir de fot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como criamos um serviço de recomendação para a seleção de roupas em redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438542/"><img src="https://habrastorage.org/webt/bh/ne/uw/bhneuwiip47lykb6jg-yigfnk3o.png" alt="imagem"><br><br>  Neste artigo, quero falar sobre como criamos um sistema de pesquisa de roupas semelhantes (mais precisamente roupas, sapatos e bolsas) a partir de fotografias.  Ou seja, em termos comerciais, um serviço de recomendação baseado em redes neurais. <br><br>  Como a maioria das soluções de TI modernas, podemos comparar o desenvolvimento do nosso sistema com o conjunto do construtor Lego, quando tomamos muitos pequenos detalhes, instruções e criamos um modelo pronto a partir disso.  Aqui está uma instrução: quais detalhes levar e como aplicá-los para que sua GPU possa selecionar produtos similares de uma fotografia, você encontrará neste artigo. <br><br>  De que partes nosso sistema é construído: <br><br><ul><li>  detector e classificador de roupas, sapatos e bolsas em imagens; </li><li>  rastreador, indexador ou módulo para trabalhar com catálogos eletrônicos de lojas; </li><li>  módulo de busca de imagens semelhantes; </li><li>  API JSON para interação conveniente com qualquer dispositivo e serviço; </li><li>  interface da web ou aplicativo móvel para visualizar os resultados. </li></ul><br>  No final do artigo, descreveremos todos os “ancinhos” que adotamos durante o desenvolvimento e recomendações sobre como neutralizá-los. <br><br><h3>  Declaração do problema e criação do rubricador </h3><br>  A tarefa e o principal caso de uso do sistema parecem bastante simples e claros: <br><br><ul><li>  o usuário envia para a entrada (por exemplo, por meio de um aplicativo móvel) uma fotografia na qual existem artigos de vestuário e / ou bolsas e / ou sapatos; </li><li>  o sistema determina (detecta) todos esses objetos; </li><li>  encontra para cada um deles os produtos mais relevantes (relevantes) em lojas on-line reais; </li><li>  dá ao usuário produtos com a capacidade de acessar uma página específica do produto para compra. </li></ul><br>  Simplificando, o objetivo do nosso sistema é responder à famosa pergunta: "E você não tem o mesmo, apenas com botões de madrepérola?" <br><a name="habracut"></a><br>  Antes de avançar para o conjunto de codificação, marcação e treinamento de redes neurais, você precisa determinar claramente as categorias que estarão dentro do seu sistema, ou seja, aquelas que a rede neural detectará.  É importante entender que quanto mais ampla e detalhada a lista de categorias, mais universal ela é, pois um grande número de categorias pequenas e estreitas, como minivestido, midi-dress, maxi-dress, sempre pode ser combinado com um toque em uma categoria do tipo de vestido MAS NÃO vice-versa.  Em outras palavras, o rubricador precisa ser bem pensado e compilado no início do projeto, para não refazer o mesmo trabalho três vezes depois.  Compilamos o rubricador, baseando-se em várias lojas grandes, como Lamoda.ru, Amazon.com, e tentamos torná-lo o mais amplo possível, por um lado, e o mais versátil possível, por outro, para facilitar a associação de categorias de detectores a diferentes categorias no futuro. lojas on-line (falarei mais sobre como criar esse grupo na seção rastreador e indexador).  Aqui está um exemplo do que aconteceu. <br><br><img src="https://habrastorage.org/webt/bg/ku/zq/bgkuzqn0q-wovsd8x8aq7hlwlio.png" alt="imagem"><br>  <i>Categorias de exemplo</i> <br><br>  No momento, em nosso catálogo, existem apenas 205 categorias: roupas femininas, roupas masculinas, sapatos femininos, sapatos masculinos, bolsas, roupas para recém-nascidos.  A versão completa do nosso classificador está disponível <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no link</a> . <br><br><h3>  Indexador ou módulo para trabalhar com catálogos eletrônicos de lojas </h3><br>  Para procurar produtos similares no futuro, precisamos criar uma base extensa do que procuraremos.  Em nossa experiência, a qualidade da pesquisa de imagens semelhantes depende diretamente do tamanho da base de pesquisa, que deve exceder pelo menos 100 mil imagens e, de preferência, 1 milhão de imagens.  Se você adicionar 1-2 pequenas lojas online ao banco de dados, provavelmente não obterá resultados impressionantes simplesmente porque em 80% dos casos não há nada realmente semelhante ao item desejado no seu catálogo. <br><br>  Portanto, para criar um grande banco de dados de imagens, você precisa processar catálogos de várias lojas online, e é isso que este processo inclui: <br><br><ul><li>  Primeiro, você precisa encontrar os feeds XML das lojas on-line, geralmente você pode encontrá-los disponíveis gratuitamente na Internet, ou solicitando na própria loja ou em vários agregadores, como o Admitad; </li><li>  o feed é processado (analisado) por um programa especial - um rastreador, que baixa todas as imagens do feed, as coloca no disco rígido (mais precisamente, no armazenamento de rede ao qual o servidor está conectado), grava todas as meta-informações sobre os produtos no banco de dados; </li><li>  então, outro processo é iniciado - o indexador, que calcula vetores binários de 128 dimensões dimensionais para cada imagem.  Você pode combinar o rastreador e o indexador em um módulo ou programa, mas historicamente desenvolvemos que esses eram processos diferentes.  Isso ocorreu principalmente devido ao fato de inicialmente calcularmos descritores (hashes) para cada imagem distribuída em uma grande frota de máquinas, pois esse era um processo que consumia muitos recursos.  Se você trabalha apenas com redes neurais, a primeira máquina com uma GPU é suficiente para você; </li><li>  vetores binários são gravados no banco de dados, todos os processos são concluídos e pronto - o banco de dados do seu produto está pronto para pesquisas adicionais; </li><li>  mas ainda resta um pequeno truque: como todas as lojas possuem catálogos diferentes com categorias diferentes, é necessário comparar as categorias de todos os feeds contidos no banco de dados com as categorias do detector (mais precisamente, o classificador) de mercadorias, que chamamos de processo de mapeamento.  Essa é uma rotina manual, mas um trabalho muito útil, durante o qual o operador, editando manualmente um arquivo XML comum, compara as categorias de feeds no banco de dados com as categorias do detector.  Aqui está o resultado: </li></ul><br><img src="https://habrastorage.org/webt/wb/je/hp/wbjehp3opuvabmnniuv8alvxwqm.png" alt="imagem"><br>  <i>Exemplo de arquivo de mapeamento de categoria: catalogador-classificador</i> <br><br><h3>  Detecção e classificação </h3><br>  Para encontrar algo semelhante ao que nossos olhos encontraram na foto, precisamos detectar esse "algo" primeiro (ou seja, localizar e selecionar o objeto).  Percorremos um longo caminho na criação de um detector, começando pelo treinamento em cascatas OpenCV que não funcionavam para essa tarefa e terminando com a tecnologia moderna para detectar e classificar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">R-FCN</a> e o classificador com base na rede neural <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ResNet</a> . <br><br>  Como os dados usados ​​para treinamento e teste (os chamados exemplos de treinamento e teste), tiramos todos os tipos de imagens da Internet: <br><br><ul><li>  pesquise imagens do Google / Yandex; </li><li>  conjuntos de dados marcados por terceiros; </li><li>  redes sociais; </li><li>  sites de revistas de moda; </li><li>  Lojas na Internet de roupas, sapatos, bolsas. </li></ul><br>  A marcação foi realizada usando uma ferramenta samopisny, o resultado da marcação foram conjuntos de imagens e arquivos * .seg, que armazenam as coordenadas dos objetos e os rótulos das classes.  Em média, de 100 a 200 imagens foram rotuladas para cada categoria, o número total de imagens em 205 classes foi de 65.000. <br><br>  Depois que as amostras de treinamento e teste estiverem prontas, fizemos uma verificação dupla da marcação, fornecendo todas as imagens para outro operador.  Isso nos permitiu filtrar um grande número de erros que afetam fortemente a qualidade do treinamento da rede neural, ou seja, o detector e o classificador.  Começamos a treinar a rede neural usando ferramentas padrão e "decolamos" o próximo instantâneo da rede neural "no calor do dia" em alguns dias.  Em média, o tempo de treinamento do detector e classificador no volume de dados de 65.000 imagens em uma GPU Titan X é de cerca de 3 dias. <br><br>  Uma rede neural pronta deve, de alguma forma, ser verificada quanto à qualidade, ou seja, para avaliar se a versão atual da rede se tornou melhor que a anterior e por quanto.  Como fizemos: <br><br><ul><li>  a amostra de teste consistia em 12.000 imagens e foi apresentada exatamente da mesma maneira que o treinamento; </li><li>  escrevemos uma pequena ferramenta que executou toda a amostra de teste no detector e compilamos uma tabela desse tipo (a versão completa da tabela está disponível <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ); </li><li>  essa tabela é adicionada ao Excel em uma nova guia e comparada com a anterior manualmente ou usando as fórmulas internas do Excel; </li><li>  na saída, obtemos os indicadores gerais do detector e classificador TPR / FPR em todo o sistema em e para cada categoria separadamente. </li></ul><br><img src="https://habrastorage.org/webt/vq/ou/it/vqouitv0rpqps36tme91uu5ynpw.png" alt="imagem"><br>  <i>Exemplo de uma tabela de relatório sobre a qualidade do detector e classificador</i> <br><br><h3>  Módulo de Pesquisa de Imagens Similares </h3><br>  Depois de detectarmos os itens de vestuário na fotografia, iniciamos o mecanismo de busca de imagens semelhantes, eis como funciona: <br><br><ul><li>  para todos os fragmentos de imagem cortada (produtos detectados), os vetores de recursos binários da rede neural de 128 bits são calculados em forma e cor (de onde vêm, veja abaixo); </li><li>  os mesmos vetores calculados anteriormente no estágio de indexação para todas as imagens de mercadorias armazenadas no banco de dados já estão carregados na RAM do computador (já que para pesquisar por similares, será necessário fazer um grande número de pesquisas e comparações aos pares, carregamos o banco de dados inteiro imediatamente na memória, o que nos permitiu aumentar a velocidade de pesquisa é dezenas de vezes, enquanto a base de cerca de 100 mil produtos não cabe mais que 2-3 GB de RAM); </li><li>  os coeficientes de pesquisa para essa categoria vêm da interface ou das propriedades codificadas, por exemplo, na categoria "vestido", pesquisamos mais em cores do que em forma (por exemplo, pesquisa de forma de cor 8 a 2) e na categoria "sapatos de salto alto" Cor de forma 1 para 1, pois forma e cor são igualmente importantes aqui; </li><li>  Além disso, os vetores da colheita (fragmentos) da imagem de entrada são comparados em pares com a imagem do banco de dados, levando em consideração os coeficientes (a distância de Hamming entre os vetores é comparada); </li><li>  como resultado, uma matriz de produtos similares do banco de dados é formada para cada fragmento de produto cortado e um peso é atribuído a cada produto (de acordo com uma fórmula simples, levando em consideração a normalização, de modo que todos os pesos estejam na faixa de 0 a 1) para a possibilidade de saída para a interface, bem como para mais informações. triagem; </li><li>  uma matriz de produtos similares é exibida na interface via web-JSON-API. </li></ul><br>  As redes neurais para a formação de vetores de redes neurais em forma e cor são treinadas da seguinte maneira. <br><br><ol><li>  Para treinar a rede neural, tiramos todas as imagens marcadas, recortamos os fragmentos de acordo com a marcação e os distribuímos em pastas de acordo com a classe: ou seja, todos os suéteres em uma pasta, todas as camisetas em outra e todos os sapatos de salto alto na terceira, etc. d.  Em seguida, treinamos um classificador comum com base nesta amostra.  Assim, meio que “explicamos” para a rede neural nossa compreensão da forma do objeto. </li><li>  Para treinar a rede neural em cores, pegamos todas as imagens marcadas, recortamos os fragmentos de acordo com a marcação e os distribuímos em pastas de acordo com a cor: ou seja, colocamos todas as camisetas, sapatos, bolsas etc. na pasta "verde".  cor verde (como resultado, todos os objetos de cor verde geralmente se acumulam em uma pasta), na pasta “despojado” colocamos todas as coisas em uma tira e na pasta “vermelho-branco” todas as coisas vermelho-branco.  Em seguida, treinamos um classificador separado para essas classes, como se “explicasse” à rede neural sua compreensão da cor de uma coisa. </li></ol><br><img src="https://habrastorage.org/webt/b8/0-/qg/b80-qglyjgkpn6trfxxdm6b55gm.png" alt="imagem"><br>  <i>Um exemplo de marcação de imagens por cor para obter vetores de redes neurais de sinais por cor.</i> <br><br>  Curiosamente, essa tecnologia funciona bem mesmo em fundos complexos, isto é, quando fragmentos de coisas são cortados não claramente ao longo do contorno (máscara), mas ao longo de uma moldura retangular que o marcador definiu. <br><br>  A busca de similares é baseada na extração de vetores de características binárias da rede neural, desta maneira: a saída da penúltima camada é obtida, compactada, normalizada e binarizada.  Em nosso trabalho, compactamos em um vetor de 128 bits.  Você pode fazê-lo de maneira um pouco diferente, por exemplo, conforme descrito no artigo do Yahoo, “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep Learning of Binary Hash Codes for Fast Image Retrieval</a> ”, mas a essência de todos os algoritmos é a mesma: imagens semelhantes à imagem são pesquisadas comparando-se as propriedades que a rede neural opera dentro das camadas. <br><br>  Inicialmente, como uma tecnologia para procurar imagens semelhantes, usamos hashes ou descritores de imagem com base em (mais precisamente calculados) certos algoritmos matemáticos, como o operador Sobel (ou contorno), o algoritmo SIFT (ou pontos singulares), construindo um histograma ou comparando o número de ângulos em uma imagem .  Essa tecnologia funcionou e deu um resultado mais ou menos sadio, mas os hashes não se comparam à tecnologia de busca de imagens semelhantes com base nas propriedades alocadas por uma rede neural.  Se você tentar explicar a diferença em duas palavras, o algoritmo de comparação de imagens com base em hash é uma “calculadora” configurada para comparar imagens usando alguma fórmula e funciona continuamente.  Uma comparação usando recursos de uma rede neural é "inteligência artificial", treinada por uma pessoa para resolver um problema específico de uma certa maneira.  Você pode dar um exemplo tão grosseiro: se você procurar suéteres com listras em preto e branco, provavelmente encontrará todas as coisas em preto e branco como semelhantes.  E se você pesquisar usando uma rede neural, então: <br><br><ul><li>  em primeiro lugar, você encontrará todos os suéteres com listras preto e branco, </li><li>  então todos os suéteres preto e branco </li><li>  e depois todos os suéteres listrados. </li></ul><br><h3>  API JSON para interação conveniente com qualquer dispositivo e serviço </h3><br>  Criamos uma WEB-JSON-API simples e conveniente para comunicar nosso sistema com quaisquer dispositivos e sistemas, o que, obviamente, não é uma inovação, mas um bom padrão de desenvolvimento forte. <br><br><h3>  Interface da Web ou aplicativo móvel para visualizar resultados </h3><br>  Para verificar visualmente os resultados, bem como demonstrar o sistema para os clientes, desenvolvemos interfaces simples: <br><br><ul><li>  interface da web, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://demo.likethis.me/</a> </li><li>  aplicação móvel está disponível <a href="">aqui</a> </li></ul><br><h3>  Erros que foram confirmados no projeto </h3><br><ul><li>  Inicialmente, é necessário definir com mais clareza a tarefa e, com base na tarefa, selecionar fotografias para o layout.  Se você precisar pesquisar fotos UGC (Conteúdo Gerado pelo Usuário) - este é um caso e exemplos de layout.  Se você precisar de uma pesquisa de fotos em revistas brilhantes, esse é um caso diferente e, se você precisar de uma pesquisa de fotos em que um objeto grande esteja localizado em um fundo branco, essa é uma história separada e uma amostra completamente diferente.  Misturamos tudo em uma pilha, o que afetou a qualidade do detector e classificador. </li><li>  Nas fotografias, você deve sempre marcar TODOS os objetos, pelo menos pelo menos de alguma maneira se adequa à sua tarefa, por exemplo, ao escolher uma seleção de guarda-roupa semelhante, você deve marcar imediatamente todos os acessórios (miçangas, óculos, pulseiras etc.), cabeça chapéus, etc.  Porque agora que temos um grande conjunto de treinamento, para adicionar outra categoria, precisamos redistribuir TODAS as fotos, e esse é um trabalho muito volumoso. </li><li>  Provavelmente, a detecção é melhor realizada com uma rede de máscaras, a transição para a Mask-CNN e uma solução moderna baseada em Detectron é uma das áreas do desenvolvimento do sistema. </li><li>  Seria bom decidir imediatamente como você determinará a qualidade da seleção de imagens semelhantes - existem 2 métodos: "a olho" e este é o método mais simples e barato e o 2º - método "científico", quando você coleta dados de "especialistas" (pessoas, que estou testando seu algoritmo de pesquisa semelhante) e com base nesses dados, forme uma amostra de teste e um catálogo especificamente para pesquisar imagens semelhantes.  Este método é bom em teoria e parece bastante convincente (para você e para os clientes), mas, na prática, sua implementação é difícil e bastante cara. </li></ul><br><h3>  Conclusão e outros planos de desenvolvimento </h3><br>  Essa tecnologia está pronta e adequada para uso, agora opera em um de nossos clientes na loja online como um serviço de recomendação.  Recentemente, também começamos a desenvolver um sistema semelhante em outro setor (ou seja, agora estamos trabalhando com outros tipos de mercadorias). <br><br>  De planos imediatos: a transferência da rede para o Mask-CNN, bem como a remarcação e a remarcação de imagens para melhorar a qualidade do detector e classificador. <br><br>  Concluindo, quero dizer que, de acordo com nossos sentimentos, essa tecnologia e as redes neurais em geral são capazes de resolver até 80% das tarefas complexas e altamente intelectuais que nosso cérebro realiza diariamente.  A única questão é quem é o primeiro a implementar essa tecnologia e a descarregar uma pessoa do trabalho rotineiro, liberando espaço para criatividade e desenvolvimento, que é, em nossa opinião, o maior objetivo do homem! <br><br><h3>  Referências </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tecnologia R-FCN</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Rede Neural ResNet</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pesquise imagens semelhantes usando uma rede neural</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt438542/">https://habr.com/ru/post/pt438542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt438530/index.html">Hipster Podcasts # 1</a></li>
<li><a href="../pt438534/index.html">Modbus no microcontrolador russo K1986BE92QI</a></li>
<li><a href="../pt438536/index.html">Sob o capô do chatbot: o que o RocketBot pode e como funciona</a></li>
<li><a href="../pt438538/index.html">Teamlead Conf 2019 Msk: sobre outro formato de comunicação</a></li>
<li><a href="../pt438540/index.html">Tendências em gerenciamento de documentos e armazenamento de dados para 2019</a></li>
<li><a href="../pt438544/index.html">Assistimos a filmes em casa: 10 materiais sobre a construção de um home theater e a escolha de equipamentos</a></li>
<li><a href="../pt438546/index.html">Análise de abordagens de ligação de módulo no Node.js</a></li>
<li><a href="../pt438548/index.html">Lombok, sources.jar e depuração conveniente</a></li>
<li><a href="../pt438550/index.html">Outro manifesto</a></li>
<li><a href="../pt438554/index.html">Gerenciando estado e eventos entre componentes no GameObject</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úÖ üë©üèø‚Äçüöí üë©‚Äçüè´ Como criamos um servi√ßo de recomenda√ß√£o para a sele√ß√£o de roupas em redes neurais üëéüèº üë®‚Äçüë©‚Äçüëß‚Äçüë¶ üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, quero falar sobre como criamos um sistema de pesquisa de roupas semelhantes (mais precisamente roupas, sapatos e bolsas) a partir de fot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como criamos um servi√ßo de recomenda√ß√£o para a sele√ß√£o de roupas em redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438542/"><img src="https://habrastorage.org/webt/bh/ne/uw/bhneuwiip47lykb6jg-yigfnk3o.png" alt="imagem"><br><br>  Neste artigo, quero falar sobre como criamos um sistema de pesquisa de roupas semelhantes (mais precisamente roupas, sapatos e bolsas) a partir de fotografias.  Ou seja, em termos comerciais, um servi√ßo de recomenda√ß√£o baseado em redes neurais. <br><br>  Como a maioria das solu√ß√µes de TI modernas, podemos comparar o desenvolvimento do nosso sistema com o conjunto do construtor Lego, quando tomamos muitos pequenos detalhes, instru√ß√µes e criamos um modelo pronto a partir disso.  Aqui est√° uma instru√ß√£o: quais detalhes levar e como aplic√°-los para que sua GPU possa selecionar produtos similares de uma fotografia, voc√™ encontrar√° neste artigo. <br><br>  De que partes nosso sistema √© constru√≠do: <br><br><ul><li>  detector e classificador de roupas, sapatos e bolsas em imagens; </li><li>  rastreador, indexador ou m√≥dulo para trabalhar com cat√°logos eletr√¥nicos de lojas; </li><li>  m√≥dulo de busca de imagens semelhantes; </li><li>  API JSON para intera√ß√£o conveniente com qualquer dispositivo e servi√ßo; </li><li>  interface da web ou aplicativo m√≥vel para visualizar os resultados. </li></ul><br>  No final do artigo, descreveremos todos os ‚Äúancinhos‚Äù que adotamos durante o desenvolvimento e recomenda√ß√µes sobre como neutraliz√°-los. <br><br><h3>  Declara√ß√£o do problema e cria√ß√£o do rubricador </h3><br>  A tarefa e o principal caso de uso do sistema parecem bastante simples e claros: <br><br><ul><li>  o usu√°rio envia para a entrada (por exemplo, por meio de um aplicativo m√≥vel) uma fotografia na qual existem artigos de vestu√°rio e / ou bolsas e / ou sapatos; </li><li>  o sistema determina (detecta) todos esses objetos; </li><li>  encontra para cada um deles os produtos mais relevantes (relevantes) em lojas on-line reais; </li><li>  d√° ao usu√°rio produtos com a capacidade de acessar uma p√°gina espec√≠fica do produto para compra. </li></ul><br>  Simplificando, o objetivo do nosso sistema √© responder √† famosa pergunta: "E voc√™ n√£o tem o mesmo, apenas com bot√µes de madrep√©rola?" <br><a name="habracut"></a><br>  Antes de avan√ßar para o conjunto de codifica√ß√£o, marca√ß√£o e treinamento de redes neurais, voc√™ precisa determinar claramente as categorias que estar√£o dentro do seu sistema, ou seja, aquelas que a rede neural detectar√°.  √â importante entender que quanto mais ampla e detalhada a lista de categorias, mais universal ela √©, pois um grande n√∫mero de categorias pequenas e estreitas, como minivestido, midi-dress, maxi-dress, sempre pode ser combinado com um toque em uma categoria do tipo de vestido MAS N√ÉO vice-versa.  Em outras palavras, o rubricador precisa ser bem pensado e compilado no in√≠cio do projeto, para n√£o refazer o mesmo trabalho tr√™s vezes depois.  Compilamos o rubricador, baseando-se em v√°rias lojas grandes, como Lamoda.ru, Amazon.com, e tentamos torn√°-lo o mais amplo poss√≠vel, por um lado, e o mais vers√°til poss√≠vel, por outro, para facilitar a associa√ß√£o de categorias de detectores a diferentes categorias no futuro. lojas on-line (falarei mais sobre como criar esse grupo na se√ß√£o rastreador e indexador).  Aqui est√° um exemplo do que aconteceu. <br><br><img src="https://habrastorage.org/webt/bg/ku/zq/bgkuzqn0q-wovsd8x8aq7hlwlio.png" alt="imagem"><br>  <i>Categorias de exemplo</i> <br><br>  No momento, em nosso cat√°logo, existem apenas 205 categorias: roupas femininas, roupas masculinas, sapatos femininos, sapatos masculinos, bolsas, roupas para rec√©m-nascidos.  A vers√£o completa do nosso classificador est√° dispon√≠vel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no link</a> . <br><br><h3>  Indexador ou m√≥dulo para trabalhar com cat√°logos eletr√¥nicos de lojas </h3><br>  Para procurar produtos similares no futuro, precisamos criar uma base extensa do que procuraremos.  Em nossa experi√™ncia, a qualidade da pesquisa de imagens semelhantes depende diretamente do tamanho da base de pesquisa, que deve exceder pelo menos 100 mil imagens e, de prefer√™ncia, 1 milh√£o de imagens.  Se voc√™ adicionar 1-2 pequenas lojas online ao banco de dados, provavelmente n√£o obter√° resultados impressionantes simplesmente porque em 80% dos casos n√£o h√° nada realmente semelhante ao item desejado no seu cat√°logo. <br><br>  Portanto, para criar um grande banco de dados de imagens, voc√™ precisa processar cat√°logos de v√°rias lojas online, e √© isso que este processo inclui: <br><br><ul><li>  Primeiro, voc√™ precisa encontrar os feeds XML das lojas on-line, geralmente voc√™ pode encontr√°-los dispon√≠veis gratuitamente na Internet, ou solicitando na pr√≥pria loja ou em v√°rios agregadores, como o Admitad; </li><li>  o feed √© processado (analisado) por um programa especial - um rastreador, que baixa todas as imagens do feed, as coloca no disco r√≠gido (mais precisamente, no armazenamento de rede ao qual o servidor est√° conectado), grava todas as meta-informa√ß√µes sobre os produtos no banco de dados; </li><li>  ent√£o, outro processo √© iniciado - o indexador, que calcula vetores bin√°rios de 128 dimens√µes dimensionais para cada imagem.  Voc√™ pode combinar o rastreador e o indexador em um m√≥dulo ou programa, mas historicamente desenvolvemos que esses eram processos diferentes.  Isso ocorreu principalmente devido ao fato de inicialmente calcularmos descritores (hashes) para cada imagem distribu√≠da em uma grande frota de m√°quinas, pois esse era um processo que consumia muitos recursos.  Se voc√™ trabalha apenas com redes neurais, a primeira m√°quina com uma GPU √© suficiente para voc√™; </li><li>  vetores bin√°rios s√£o gravados no banco de dados, todos os processos s√£o conclu√≠dos e pronto - o banco de dados do seu produto est√° pronto para pesquisas adicionais; </li><li>  mas ainda resta um pequeno truque: como todas as lojas possuem cat√°logos diferentes com categorias diferentes, √© necess√°rio comparar as categorias de todos os feeds contidos no banco de dados com as categorias do detector (mais precisamente, o classificador) de mercadorias, que chamamos de processo de mapeamento.  Essa √© uma rotina manual, mas um trabalho muito √∫til, durante o qual o operador, editando manualmente um arquivo XML comum, compara as categorias de feeds no banco de dados com as categorias do detector.  Aqui est√° o resultado: </li></ul><br><img src="https://habrastorage.org/webt/wb/je/hp/wbjehp3opuvabmnniuv8alvxwqm.png" alt="imagem"><br>  <i>Exemplo de arquivo de mapeamento de categoria: catalogador-classificador</i> <br><br><h3>  Detec√ß√£o e classifica√ß√£o </h3><br>  Para encontrar algo semelhante ao que nossos olhos encontraram na foto, precisamos detectar esse "algo" primeiro (ou seja, localizar e selecionar o objeto).  Percorremos um longo caminho na cria√ß√£o de um detector, come√ßando pelo treinamento em cascatas OpenCV que n√£o funcionavam para essa tarefa e terminando com a tecnologia moderna para detectar e classificar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">R-FCN</a> e o classificador com base na rede neural <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ResNet</a> . <br><br>  Como os dados usados ‚Äã‚Äãpara treinamento e teste (os chamados exemplos de treinamento e teste), tiramos todos os tipos de imagens da Internet: <br><br><ul><li>  pesquise imagens do Google / Yandex; </li><li>  conjuntos de dados marcados por terceiros; </li><li>  redes sociais; </li><li>  sites de revistas de moda; </li><li>  Lojas na Internet de roupas, sapatos, bolsas. </li></ul><br>  A marca√ß√£o foi realizada usando uma ferramenta samopisny, o resultado da marca√ß√£o foram conjuntos de imagens e arquivos * .seg, que armazenam as coordenadas dos objetos e os r√≥tulos das classes.  Em m√©dia, de 100 a 200 imagens foram rotuladas para cada categoria, o n√∫mero total de imagens em 205 classes foi de 65.000. <br><br>  Depois que as amostras de treinamento e teste estiverem prontas, fizemos uma verifica√ß√£o dupla da marca√ß√£o, fornecendo todas as imagens para outro operador.  Isso nos permitiu filtrar um grande n√∫mero de erros que afetam fortemente a qualidade do treinamento da rede neural, ou seja, o detector e o classificador.  Come√ßamos a treinar a rede neural usando ferramentas padr√£o e "decolamos" o pr√≥ximo instant√¢neo da rede neural "no calor do dia" em alguns dias.  Em m√©dia, o tempo de treinamento do detector e classificador no volume de dados de 65.000 imagens em uma GPU Titan X √© de cerca de 3 dias. <br><br>  Uma rede neural pronta deve, de alguma forma, ser verificada quanto √† qualidade, ou seja, para avaliar se a vers√£o atual da rede se tornou melhor que a anterior e por quanto.  Como fizemos: <br><br><ul><li>  a amostra de teste consistia em 12.000 imagens e foi apresentada exatamente da mesma maneira que o treinamento; </li><li>  escrevemos uma pequena ferramenta que executou toda a amostra de teste no detector e compilamos uma tabela desse tipo (a vers√£o completa da tabela est√° dispon√≠vel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ); </li><li>  essa tabela √© adicionada ao Excel em uma nova guia e comparada com a anterior manualmente ou usando as f√≥rmulas internas do Excel; </li><li>  na sa√≠da, obtemos os indicadores gerais do detector e classificador TPR / FPR em todo o sistema em e para cada categoria separadamente. </li></ul><br><img src="https://habrastorage.org/webt/vq/ou/it/vqouitv0rpqps36tme91uu5ynpw.png" alt="imagem"><br>  <i>Exemplo de uma tabela de relat√≥rio sobre a qualidade do detector e classificador</i> <br><br><h3>  M√≥dulo de Pesquisa de Imagens Similares </h3><br>  Depois de detectarmos os itens de vestu√°rio na fotografia, iniciamos o mecanismo de busca de imagens semelhantes, eis como funciona: <br><br><ul><li>  para todos os fragmentos de imagem cortada (produtos detectados), os vetores de recursos bin√°rios da rede neural de 128 bits s√£o calculados em forma e cor (de onde v√™m, veja abaixo); </li><li>  os mesmos vetores calculados anteriormente no est√°gio de indexa√ß√£o para todas as imagens de mercadorias armazenadas no banco de dados j√° est√£o carregados na RAM do computador (j√° que para pesquisar por similares, ser√° necess√°rio fazer um grande n√∫mero de pesquisas e compara√ß√µes aos pares, carregamos o banco de dados inteiro imediatamente na mem√≥ria, o que nos permitiu aumentar a velocidade de pesquisa √© dezenas de vezes, enquanto a base de cerca de 100 mil produtos n√£o cabe mais que 2-3 GB de RAM); </li><li>  os coeficientes de pesquisa para essa categoria v√™m da interface ou das propriedades codificadas, por exemplo, na categoria "vestido", pesquisamos mais em cores do que em forma (por exemplo, pesquisa de forma de cor 8 a 2) e na categoria "sapatos de salto alto" Cor de forma 1 para 1, pois forma e cor s√£o igualmente importantes aqui; </li><li>  Al√©m disso, os vetores da colheita (fragmentos) da imagem de entrada s√£o comparados em pares com a imagem do banco de dados, levando em considera√ß√£o os coeficientes (a dist√¢ncia de Hamming entre os vetores √© comparada); </li><li>  como resultado, uma matriz de produtos similares do banco de dados √© formada para cada fragmento de produto cortado e um peso √© atribu√≠do a cada produto (de acordo com uma f√≥rmula simples, levando em considera√ß√£o a normaliza√ß√£o, de modo que todos os pesos estejam na faixa de 0 a 1) para a possibilidade de sa√≠da para a interface, bem como para mais informa√ß√µes. triagem; </li><li>  uma matriz de produtos similares √© exibida na interface via web-JSON-API. </li></ul><br>  As redes neurais para a forma√ß√£o de vetores de redes neurais em forma e cor s√£o treinadas da seguinte maneira. <br><br><ol><li>  Para treinar a rede neural, tiramos todas as imagens marcadas, recortamos os fragmentos de acordo com a marca√ß√£o e os distribu√≠mos em pastas de acordo com a classe: ou seja, todos os su√©teres em uma pasta, todas as camisetas em outra e todos os sapatos de salto alto na terceira, etc. d.  Em seguida, treinamos um classificador comum com base nesta amostra.  Assim, meio que ‚Äúexplicamos‚Äù para a rede neural nossa compreens√£o da forma do objeto. </li><li>  Para treinar a rede neural em cores, pegamos todas as imagens marcadas, recortamos os fragmentos de acordo com a marca√ß√£o e os distribu√≠mos em pastas de acordo com a cor: ou seja, colocamos todas as camisetas, sapatos, bolsas etc. na pasta "verde".  cor verde (como resultado, todos os objetos de cor verde geralmente se acumulam em uma pasta), na pasta ‚Äúdespojado‚Äù colocamos todas as coisas em uma tira e na pasta ‚Äúvermelho-branco‚Äù todas as coisas vermelho-branco.  Em seguida, treinamos um classificador separado para essas classes, como se ‚Äúexplicasse‚Äù √† rede neural sua compreens√£o da cor de uma coisa. </li></ol><br><img src="https://habrastorage.org/webt/b8/0-/qg/b80-qglyjgkpn6trfxxdm6b55gm.png" alt="imagem"><br>  <i>Um exemplo de marca√ß√£o de imagens por cor para obter vetores de redes neurais de sinais por cor.</i> <br><br>  Curiosamente, essa tecnologia funciona bem mesmo em fundos complexos, isto √©, quando fragmentos de coisas s√£o cortados n√£o claramente ao longo do contorno (m√°scara), mas ao longo de uma moldura retangular que o marcador definiu. <br><br>  A busca de similares √© baseada na extra√ß√£o de vetores de caracter√≠sticas bin√°rias da rede neural, desta maneira: a sa√≠da da pen√∫ltima camada √© obtida, compactada, normalizada e binarizada.  Em nosso trabalho, compactamos em um vetor de 128 bits.  Voc√™ pode faz√™-lo de maneira um pouco diferente, por exemplo, conforme descrito no artigo do Yahoo, ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep Learning of Binary Hash Codes for Fast Image Retrieval</a> ‚Äù, mas a ess√™ncia de todos os algoritmos √© a mesma: imagens semelhantes √† imagem s√£o pesquisadas comparando-se as propriedades que a rede neural opera dentro das camadas. <br><br>  Inicialmente, como uma tecnologia para procurar imagens semelhantes, usamos hashes ou descritores de imagem com base em (mais precisamente calculados) certos algoritmos matem√°ticos, como o operador Sobel (ou contorno), o algoritmo SIFT (ou pontos singulares), construindo um histograma ou comparando o n√∫mero de √¢ngulos em uma imagem .  Essa tecnologia funcionou e deu um resultado mais ou menos sadio, mas os hashes n√£o se comparam √† tecnologia de busca de imagens semelhantes com base nas propriedades alocadas por uma rede neural.  Se voc√™ tentar explicar a diferen√ßa em duas palavras, o algoritmo de compara√ß√£o de imagens com base em hash √© uma ‚Äúcalculadora‚Äù configurada para comparar imagens usando alguma f√≥rmula e funciona continuamente.  Uma compara√ß√£o usando recursos de uma rede neural √© "intelig√™ncia artificial", treinada por uma pessoa para resolver um problema espec√≠fico de uma certa maneira.  Voc√™ pode dar um exemplo t√£o grosseiro: se voc√™ procurar su√©teres com listras em preto e branco, provavelmente encontrar√° todas as coisas em preto e branco como semelhantes.  E se voc√™ pesquisar usando uma rede neural, ent√£o: <br><br><ul><li>  em primeiro lugar, voc√™ encontrar√° todos os su√©teres com listras preto e branco, </li><li>  ent√£o todos os su√©teres preto e branco </li><li>  e depois todos os su√©teres listrados. </li></ul><br><h3>  API JSON para intera√ß√£o conveniente com qualquer dispositivo e servi√ßo </h3><br>  Criamos uma WEB-JSON-API simples e conveniente para comunicar nosso sistema com quaisquer dispositivos e sistemas, o que, obviamente, n√£o √© uma inova√ß√£o, mas um bom padr√£o de desenvolvimento forte. <br><br><h3>  Interface da Web ou aplicativo m√≥vel para visualizar resultados </h3><br>  Para verificar visualmente os resultados, bem como demonstrar o sistema para os clientes, desenvolvemos interfaces simples: <br><br><ul><li>  interface da web, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://demo.likethis.me/</a> </li><li>  aplica√ß√£o m√≥vel est√° dispon√≠vel <a href="">aqui</a> </li></ul><br><h3>  Erros que foram confirmados no projeto </h3><br><ul><li>  Inicialmente, √© necess√°rio definir com mais clareza a tarefa e, com base na tarefa, selecionar fotografias para o layout.  Se voc√™ precisar pesquisar fotos UGC (Conte√∫do Gerado pelo Usu√°rio) - este √© um caso e exemplos de layout.  Se voc√™ precisar de uma pesquisa de fotos em revistas brilhantes, esse √© um caso diferente e, se voc√™ precisar de uma pesquisa de fotos em que um objeto grande esteja localizado em um fundo branco, essa √© uma hist√≥ria separada e uma amostra completamente diferente.  Misturamos tudo em uma pilha, o que afetou a qualidade do detector e classificador. </li><li>  Nas fotografias, voc√™ deve sempre marcar TODOS os objetos, pelo menos pelo menos de alguma maneira se adequa √† sua tarefa, por exemplo, ao escolher uma sele√ß√£o de guarda-roupa semelhante, voc√™ deve marcar imediatamente todos os acess√≥rios (mi√ßangas, √≥culos, pulseiras etc.), cabe√ßa chap√©us, etc.  Porque agora que temos um grande conjunto de treinamento, para adicionar outra categoria, precisamos redistribuir TODAS as fotos, e esse √© um trabalho muito volumoso. </li><li>  Provavelmente, a detec√ß√£o √© melhor realizada com uma rede de m√°scaras, a transi√ß√£o para a Mask-CNN e uma solu√ß√£o moderna baseada em Detectron √© uma das √°reas do desenvolvimento do sistema. </li><li>  Seria bom decidir imediatamente como voc√™ determinar√° a qualidade da sele√ß√£o de imagens semelhantes - existem 2 m√©todos: "a olho" e este √© o m√©todo mais simples e barato e o 2¬∫ - m√©todo "cient√≠fico", quando voc√™ coleta dados de "especialistas" (pessoas, que estou testando seu algoritmo de pesquisa semelhante) e com base nesses dados, forme uma amostra de teste e um cat√°logo especificamente para pesquisar imagens semelhantes.  Este m√©todo √© bom em teoria e parece bastante convincente (para voc√™ e para os clientes), mas, na pr√°tica, sua implementa√ß√£o √© dif√≠cil e bastante cara. </li></ul><br><h3>  Conclus√£o e outros planos de desenvolvimento </h3><br>  Essa tecnologia est√° pronta e adequada para uso, agora opera em um de nossos clientes na loja online como um servi√ßo de recomenda√ß√£o.  Recentemente, tamb√©m come√ßamos a desenvolver um sistema semelhante em outro setor (ou seja, agora estamos trabalhando com outros tipos de mercadorias). <br><br>  De planos imediatos: a transfer√™ncia da rede para o Mask-CNN, bem como a remarca√ß√£o e a remarca√ß√£o de imagens para melhorar a qualidade do detector e classificador. <br><br>  Concluindo, quero dizer que, de acordo com nossos sentimentos, essa tecnologia e as redes neurais em geral s√£o capazes de resolver at√© 80% das tarefas complexas e altamente intelectuais que nosso c√©rebro realiza diariamente.  A √∫nica quest√£o √© quem √© o primeiro a implementar essa tecnologia e a descarregar uma pessoa do trabalho rotineiro, liberando espa√ßo para criatividade e desenvolvimento, que √©, em nossa opini√£o, o maior objetivo do homem! <br><br><h3>  Refer√™ncias </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tecnologia R-FCN</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Rede Neural ResNet</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pesquise imagens semelhantes usando uma rede neural</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt438542/">https://habr.com/ru/post/pt438542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt438530/index.html">Hipster Podcasts # 1</a></li>
<li><a href="../pt438534/index.html">Modbus no microcontrolador russo K1986BE92QI</a></li>
<li><a href="../pt438536/index.html">Sob o cap√¥ do chatbot: o que o RocketBot pode e como funciona</a></li>
<li><a href="../pt438538/index.html">Teamlead Conf 2019 Msk: sobre outro formato de comunica√ß√£o</a></li>
<li><a href="../pt438540/index.html">Tend√™ncias em gerenciamento de documentos e armazenamento de dados para 2019</a></li>
<li><a href="../pt438544/index.html">Assistimos a filmes em casa: 10 materiais sobre a constru√ß√£o de um home theater e a escolha de equipamentos</a></li>
<li><a href="../pt438546/index.html">An√°lise de abordagens de liga√ß√£o de m√≥dulo no Node.js</a></li>
<li><a href="../pt438548/index.html">Lombok, sources.jar e depura√ß√£o conveniente</a></li>
<li><a href="../pt438550/index.html">Outro manifesto</a></li>
<li><a href="../pt438554/index.html">Gerenciando estado e eventos entre componentes no GameObject</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
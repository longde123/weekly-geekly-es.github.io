<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåî üíü üåú √úbersicht √ºber NeurIPS-2018 (ex. NIPS) ‚úåüèº ‚ú¥Ô∏è üëç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anfang Dezember fand in Montreal die 32. j√§hrliche Konferenz √ºber neuronale Informationsverarbeitungssysteme zum Thema maschinelles Lernen statt. Laut...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úbersicht √ºber NeurIPS-2018 (ex. NIPS)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/434694/"> Anfang Dezember fand in Montreal die 32. j√§hrliche Konferenz √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neuronale Informationsverarbeitungssysteme zum</a> Thema maschinelles Lernen statt.  Laut einer inoffiziellen Rangliste ist diese Konferenz die Top-1-Veranstaltung dieses Formats weltweit.  Alle Konferenztickets in diesem Jahr waren in Rekordzeit von 13 Minuten ausverkauft.  Wir haben ein gro√ües Team von MTS-Datenwissenschaftlern, aber nur eine von ihnen - Marina Yaroslavtseva ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">magoli</a> ) - hatte das Gl√ºck, nach Montreal zu kommen.  Zusammen mit Danila Savenkov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">danila_savenkov</a> ), die kein Visum hatte und die Konferenz aus Moskau verfolgte, werden wir √ºber die Werke sprechen, die uns am interessantesten erschienen.  Dieses Beispiel ist sehr subjektiv, aber es wird Sie hoffentlich interessieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c10/868/6af/c108686af497e18c338a44c475d6d64e.png" alt="Bild"><br><a name="habracut"></a><br>  <b>Relationale wiederkehrende neuronale Netze</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  Bei der Arbeit mit Sequenzen ist es oft sehr wichtig, wie die Elemente der Sequenz miteinander in Beziehung stehen.  Die Standardarchitektur von Wiederholungsnetzwerken (GRU, LSTM) kann die Beziehung zwischen zwei Elementen, die ziemlich weit voneinander entfernt sind, kaum modellieren.  Bis zu einem gewissen Grad hilft Aufmerksamkeit, damit umzugehen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://youtu.be/SysgYptB198</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://youtu.be/quoGRI-1l0A</a> ), aber dies ist immer noch nicht ganz richtig.  Mit Achtung k√∂nnen Sie das Gewicht bestimmen, mit dem der verborgene Zustand aus jedem der Schritte der Sequenz den endg√ºltigen verborgenen Zustand und dementsprechend die Vorhersage beeinflusst.  Wir interessieren uns f√ºr die Beziehung der Elemente der Sequenz. <br><br>  Letztes Jahr schlug Google erneut auf NIPS vor, die Wiederholung ganz aufzugeben und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Selbstaufmerksamkeit zu nutzen</a> .  Der Ansatz erwies sich als sehr gut, allerdings haupts√§chlich f√ºr seq2seq-Aufgaben (der Artikel liefert Ergebnisse zur maschinellen √úbersetzung). <br><br>  Der diesj√§hrige Artikel verwendet die Idee der Selbstaufmerksamkeit als Teil von LSTM.  Es gibt nicht viele √Ñnderungen: <br><br><ol><li>  Wir √§ndern den Zellzustandsvektor in die "Speicher" -Matrix M. Bis zu einem gewissen Grad besteht die Speichermatrix aus vielen Zellzustandsvektoren (vielen Speicherzellen).  Wenn wir ein neues Element der Sequenz erhalten, legen wir fest, um wie viel dieses Element jede der Speicherzellen aktualisieren soll. </li><li>  F√ºr jedes Element der Sequenz aktualisieren wir diese Matrix mithilfe der Aufmerksamkeit f√ºr Produkte mit mehreren Kopfpunkten (MHDPA, √ºber diese Methode k√∂nnen Sie im genannten Artikel von Google lesen).  Das MHPDA-Ergebnis f√ºr das aktuelle Element der Sequenz und der Matrix M wird durch ein vollst√§ndig verbundenes Netz, das Sigmoid, gef√ºhrt, und dann wird die Matrix M auf die gleiche Weise wie der Zellzustand in LSTM aktualisiert </li></ol><br>  Es wird argumentiert, dass das Netz durch MHDPA die Verbindung von Sequenzelementen ber√ºcksichtigen kann, selbst wenn sie voneinander entfernt sind. <br><br>  Als Spielzeugproblem wird das Modell in der Folge von Vektoren gebeten, den N-ten Vektor anhand des Abstands vom M-ten als euklidischen Abstand zu ermitteln.  Zum Beispiel gibt es eine Folge von 10 Vektoren, und wir bitten Sie, einen zu finden, der sich in der N√§he des f√ºnften auf dem dritten Platz befindet.  Es ist klar, dass es zur Beantwortung dieser Frage des Modells notwendig ist, die Abst√§nde von allen Vektoren zum f√ºnften irgendwie zu bewerten und zu sortieren.  Hier besiegt das von den Autoren vorgeschlagene Modell LSTM und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DNC</a> zuversichtlich.  Dar√ºber hinaus vergleichen die Autoren ihr Modell mit anderen Architekturen zu Learning to Execute (wir erhalten ein paar Codezeilen, geben das Ergebnis ein), Mini-Pacman, Language Modeling und berichten √ºberall √ºber die besten Ergebnisse. <br><br>  <b>Multivariate Zeitreihen-Imputation mit generativen kontradiktorischen Netzwerken</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> (obwohl sie hier im Artikel nicht verlinkt sind) <br><br>  In mehrdimensionalen Zeitreihen gibt es in der Regel eine Vielzahl von Auslassungen, die die Verwendung fortschrittlicher statistischer Methoden verhindern.  Standardl√∂sungen - F√ºllen mit Mittelwert / Null, L√∂schen unvollst√§ndiger F√§lle, Wiederherstellen von Daten basierend auf Matrixerweiterungen in dieser Situation funktionieren h√§ufig nicht, da sie Zeitabh√§ngigkeiten und die komplexe Verteilung mehrdimensionaler Zeitreihen nicht reproduzieren k√∂nnen. <br><br>  Die F√§higkeit generativer gegnerischer Netzwerke (GANs), jede Verteilung von Daten nachzuahmen, ist allgemein bekannt, insbesondere bei der Aufgabe, Gesichter zu ‚Äûvervollst√§ndigen‚Äú und S√§tze zu generieren.  In der Regel erfordern solche Modelle jedoch entweder eine erste Schulung f√ºr einen vollst√§ndigen Datensatz ohne L√ºcken oder ber√ºcksichtigen nicht die Konsistenz der Daten. <br><br>  Die Autoren schlagen vor, das GAN durch ein neues Element zu erg√§nzen - die Gated Recurrent Unit for Imputation (GRUI).  Der Hauptunterschied zur √ºblichen GRU besteht darin, dass die GRUI aus Daten in Intervallen unterschiedlicher L√§nge zwischen den Beobachtungen lernen und den Effekt der Beobachtungen in Abh√§ngigkeit von ihrer zeitlichen Entfernung vom aktuellen Punkt anpassen kann.  Es wird ein spezieller D√§mpfungsparameter Œ≤ berechnet, dessen Wert von 0 bis 1 variiert und je kleiner die Zeitverz√∂gerung zwischen der aktuellen Beobachtung und der vorherigen nicht leeren ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ab/c71/63b/6abc7163bf3ff1b16310104100b53236.png" alt="Bild"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/203/a64/599/203a6459932c852ad827db0d9574ef2c.png" alt="Bild"><br><br>  Sowohl der Diskriminator als auch der GAN-Generator bestehen aus einer GRUI-Schicht und einer vollst√§ndig verbundenen Schicht.  Wie in GANs √ºblich, lernt der Generator, die Quelldaten zu simulieren (in diesem Fall f√ºllen Sie einfach die L√ºcken in den Zeilen aus), und der Diskriminator lernt, die mit dem Generator gef√ºllten Zeilen von den realen zu unterscheiden. <br><br>  Wie sich herausstellte, stellt dieser Ansatz Daten auch in Zeitreihen mit einem sehr gro√üen Anteil an Auslassungen sehr angemessen wieder her (in der folgenden Tabelle - MSE-Datenwiederherstellung im KDD-Datensatz in Abh√§ngigkeit vom Prozentsatz der Auslassungen und der Wiederherstellungsmethode. In den meisten F√§llen bietet die GAN-basierte Methode die gr√∂√üte Genauigkeit Erholung). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/188/737/e57/188737e575173058d1c0a79482b8679d.png" alt="Bild"><br><br>  <b>Zur Dimensionalit√§t von Worteinbettungen</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  Die Worteinbettung / Vektordarstellung von W√∂rtern ist ein Ansatz, der h√§ufig f√ºr verschiedene NLP-Anwendungen verwendet wird: von Empfehlungssystemen bis zur Analyse der emotionalen F√§rbung von Texten und maschineller √úbersetzung. <br><br>  Dar√ºber hinaus bleibt die Frage offen, wie ein so wichtiger Hyperparameter wie die Dimension von Vektoren optimal eingestellt werden kann.  In der Praxis wird es meistens durch empirisch ersch√∂pfende Suche ausgew√§hlt oder standardm√§√üig festgelegt, beispielsweise auf der Ebene von 300. Gleichzeitig erlaubt eine zu kleine Dimension nicht, alle signifikanten Beziehungen zwischen W√∂rtern widerzuspiegeln, und eine zu gro√üe Dimension kann zu einer Umschulung f√ºhren. <br><br>  Die Autoren der Studie schlagen ihre L√∂sung f√ºr dieses Problem vor, indem sie den PIP-Verlustparameter minimieren, ein neues Ma√ü f√ºr den Unterschied zwischen den beiden Einbettungsoptionen. <br>  Die Berechnung basiert auf PIP-Matrizen, die die Skalarprodukte aller Paare von Vektordarstellungen von W√∂rtern im Korpus enthalten.  Der PIP-Verlust wird als Frobenius-Norm zwischen den PIP-Matrizen zweier Einbettungen berechnet: trainiert auf Daten (trainierte Einbettung E_hat) und ideal, trainiert auf verrauschte Daten (Orakel-Einbettung E). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/135/a0a/1f2/135a0a1f216137c64ab73f9d2b86f0dc.png" alt="Bild" width="300" height="200"></div><br><br>  Es scheint einfach zu sein: Sie m√ºssen eine Dimension ausw√§hlen, die den PIP-Verlust minimiert. Der einzige unverst√§ndliche Moment ist, wo Sie die Orakel-Einbettung erhalten.  In den Jahren 2015-2017 wurde eine Reihe von Arbeiten ver√∂ffentlicht, in denen gezeigt wurde, dass verschiedene Methoden zur Konstruktion von Einbettungen (word2vec, GloVe, LSA) die Signalmatrix des Falls implizit faktorisieren (die Dimension verringern).  Im Fall von word2vec (Skip-Gramm) ist die Signalmatrix <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PMI</a> , im Fall von GloVe ist es die Log-Count-Matrix.  Es wird vorgeschlagen, ein nicht sehr gro√ües W√∂rterbuch zu verwenden, eine Signalmatrix zu erstellen und SVD zu verwenden, um eine Orakeleinbettung zu erhalten.  Somit ist die Orakel-Einbettungsdimension gleich dem Signalmatrixrang (in der Praxis liegt die Dimension f√ºr ein W√∂rterbuch mit 10.000 W√∂rtern in der Gr√∂√üenordnung von 2.000).  Unsere empirische Signalmatrix ist jedoch immer verrauscht und wir m√ºssen auf knifflige Schemata zur√ºckgreifen, um eine Orakeleinbettung zu erhalten und den PIP-Verlust durch eine verrauschte Matrix abzusch√§tzen. <br><br>  Die Autoren argumentieren, dass es zur Auswahl der optimalen Einbettungsdimension ausreicht, ein W√∂rterbuch mit 10.000 W√∂rtern zu verwenden, was nicht sehr viel ist und es Ihnen erm√∂glicht, dieses Verfahren in angemessener Zeit auszuf√ºhren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/454/806/a20/454806a208dd7c10df8b9cbd365c440a.png" alt="Bild"><br><br>  Wie sich herausstellte, stimmt die auf diese Weise berechnete Einbettungsdimension in den meisten F√§llen mit einem Fehler von bis zu 5% mit der optimalen Dimension √ºberein, die auf der Grundlage von Expertensch√§tzungen ermittelt wurde.  Es stellte sich heraus (erwartet), dass Word2Vec und GloVe praktisch nicht umgeschult wurden (der PIP-Verlust f√§llt bei sehr gro√üen Dimensionen nicht ab), aber LSA wird ziemlich stark umgeschult. <br><br>  Mit dem von den Autoren auf dem Github ver√∂ffentlichten Code kann nach der optimalen Dimension von Word2Vec (Sprunggramm), GloVe, LSA gesucht werden. <br><br>  <b>FRAGE: Frequenzunabh√§ngige Wortrepr√§sentation</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  Die Autoren sprechen dar√ºber, wie Einbettungen f√ºr seltene und beliebte W√∂rter unterschiedlich funktionieren.  Mit popul√§r meine ich nicht Stoppw√∂rter (wir betrachten sie √ºberhaupt nicht), sondern informative W√∂rter, die nicht sehr selten sind. <br><br>  Die Beobachtungen sind wie folgt: <br><br>  Wenn wir √ºber popul√§re W√∂rter sprechen, spiegelt sich ihre N√§he im Kosinusma√ü sehr gut wider <br><br><ol><li>  ihre semantische Affinit√§t.  Bei seltenen W√∂rtern ist dies nicht der Fall (was erwartet wird), und (was weniger erwartet wird) Top-n der einem seltenen Wort am n√§chsten liegenden Kosinusw√∂rter sind ebenfalls selten und gleichzeitig semantisch nicht miteinander verbunden.  Das hei√üt, seltene und h√§ufige W√∂rter im Raum der Einbettungen leben an verschiedenen Orten (in verschiedenen Kegeln, wenn wir √ºber Kosinus sprechen). </li><li>  W√§hrend des Trainings werden die Vektoren beliebter W√∂rter viel h√§ufiger aktualisiert und sind im Durchschnitt doppelt so weit von der Initialisierung entfernt wie die Vektoren seltener W√∂rter.  Dies f√ºhrt dazu, dass die Einbettung seltener W√∂rter im Durchschnitt n√§her am Ursprung liegt.  Um ehrlich zu sein, habe ich immer geglaubt, dass Einbettungen seltener W√∂rter im Durchschnitt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">l√§nger dauern</a> und ich nicht wei√ü, wie ich mich auf die Aussage der Autoren beziehen soll =) </li></ol><br>  Unabh√§ngig von der Beziehung zwischen den L2-Normen f√ºr Einbettungen ist die Trennbarkeit von popul√§ren und seltenen W√∂rtern kein sehr gutes Ph√§nomen.  Wir m√∂chten, dass Einbettungen die Semantik eines Wortes widerspiegeln, nicht seine H√§ufigkeit. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7e/f4d/e70/c7ef4de7034a8347269fa40d6bdc7005.png" alt="Bild"><br><br>  Das Bild zeigt Word2Vec beliebte (rot) und seltene (blau) W√∂rter nach SVD.  Beliebt bezieht sich hier auf die Top 20% der W√∂rter in der H√§ufigkeit. <br><br>  Wenn das Problem nur in den L2-Normen f√ºr Einbettungen liege, k√∂nnten wir sie normalisieren und gl√ºcklich leben, aber wie ich im ersten Absatz sagte, werden seltene W√∂rter auch durch Kosinusn√§he (in Polarkoordinaten) von popul√§ren W√∂rtern getrennt. <br><br>  Die Autoren schlagen nat√ºrlich GAN vor.  Lassen Sie uns das Gleiche wie zuvor tun, aber einen Diskriminator hinzuf√ºgen, der versucht, zwischen popul√§ren und seltenen W√∂rtern zu unterscheiden (wiederum betrachten wir die Top-n% der W√∂rter in der H√§ufigkeit als popul√§r). <br><br>  Es sieht ungef√§hr so ‚Äã‚Äãaus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/0a3/0b7/f0e0a30b77a9071ff63fa208401fad56.png" alt="Bild"><br><br>  Die Autoren testen den Ansatz in Bezug auf die Aufgaben Wort√§hnlichkeit, maschinelle √úbersetzung, Textklassifizierung und Sprachmodellierung und √ºberall dort, wo sie besser abschneiden als die Basislinie.  In Bezug auf die Wort√§hnlichkeit wird angegeben, dass die Qualit√§t bei seltenen W√∂rtern besonders deutlich zunimmt. <br><br>  Ein Beispiel: Staatsb√ºrgerschaft.  Skip-Gramm-Probleme: Gl√ºckseligkeit, Pakistans, Entlassung, Verst√§rkung.  FRAGE-Themen: Bev√∂lkerung, Rechte, W√ºrde, B√ºrger.  Die W√∂rter B√ºrger und B√ºrger in FRAGE stehen an 79. bzw. 7. Stelle (in der N√§he der Staatsb√ºrgerschaft), in Skip-Gramm sind sie nicht in den Top 10000. <br><br>  Aus irgendeinem Grund haben die Autoren den Code nur f√ºr maschinelle √úbersetzung und Sprachmodellierung ver√∂ffentlicht. Wort√§hnlichkeits- und Textklassifizierungsaufgaben im Repository sind leider nicht vertreten. <br><br>  <b>Un√ºberwachte modal√ºbergreifende Ausrichtung von Sprach- und Texteinbettungsr√§umen</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  Code: kein Code, aber ich m√∂chte <br><br>  J√ºngste Studien haben gezeigt, dass zwei Vektorr√§ume, die mithilfe von Einbettungsalgorithmen (z. B. word2vec) auf Textk√∂rpern in zwei verschiedenen Sprachen trainiert wurden, ohne Markup und Inhaltsabgleich zwischen den beiden Geb√§uden miteinander abgeglichen werden k√∂nnen.  Dieser Ansatz wird insbesondere f√ºr die maschinelle √úbersetzung bei Facebook verwendet.  Eine der Schl√ºsseleigenschaften beim Einbetten von R√§umen wird verwendet: In ihnen sollten √§hnliche W√∂rter geometrisch nahe beieinander liegen, und ungleiche W√∂rter sollten im Gegenteil weit voneinander entfernt sein.  Es wird angenommen, dass im Allgemeinen die Struktur des Vektorraums unabh√§ngig von der Sprache, in der der Korpus unterrichtet wurde, erhalten bleibt. <br><br>  Die Autoren des Artikels gingen noch weiter und wendeten einen √§hnlichen Ansatz auf das Gebiet der automatischen Spracherkennung und -√ºbersetzung an.  Es wird vorgeschlagen, den Vektorraum separat f√ºr den Textkorpus in der interessierenden Sprache (z. B. Wikipedia), separat f√ºr den Korpus der aufgezeichneten Sprache (im Audioformat), m√∂glicherweise in einer anderen Sprache, die zuvor in W√∂rter unterteilt war, zu trainieren und diese beiden R√§ume dann auf dieselbe Weise wie mit zwei zu vergleichen Textf√§lle. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d07/950/b6f/d07950b6f9bac05e9ce48dd80bb24838.png" alt="Bild"><br><br>  F√ºr den Textkorpus wird word2vec verwendet, und f√ºr die Sprache basiert ein √§hnlicher Ansatz, der von Speech2vec genannt wird, auf LSTM und den f√ºr word2vec verwendeten Methoden (CBOW / skip-gram), sodass angenommen wird, dass W√∂rter genau nach kontextuellen und semantischen Merkmalen kombiniert werden klingt nicht. <br><br>  Nachdem beide Vektorr√§ume trainiert wurden und es zwei S√§tze von Einbettungen gibt - S (auf dem Sprachk√∂rper), bestehend aus n Einbettungen der Dimension d1 und T (auf dem Textk√∂rper), bestehend aus m Einbettungen der Dimension d2, m√ºssen Sie sie vergleichen.  Idealerweise haben wir ein W√∂rterbuch, das bestimmt, welcher Vektor aus S welchem ‚Äã‚ÄãVektor aus T entspricht. Dann werden zum Vergleich zwei Matrizen gebildet: k Einbettungen werden aus S ausgew√§hlt, die eine Matrix X der Gr√∂√üe d1 xk bilden;  aus T werden auch k Einbettungen ausgew√§hlt, die (gem√§√ü dem W√∂rterbuch) entsprechen, die zuvor aus S ausgew√§hlt wurden, und eine Matrix Y der Gr√∂√üe d2 x k wird erhalten.  Als n√§chstes m√ºssen Sie eine lineare Abbildung W finden, so dass: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/db3/59e/e40/db359ee40ad9f907c6461d378db3d7aa.png" alt="Bild" width="300" height="200"></div><br><br>  Da der Artikel jedoch den unbeaufsichtigten Ansatz ber√ºcksichtigt, gibt es zun√§chst kein W√∂rterbuch. Daher wird ein Verfahren zum Generieren eines synthetischen W√∂rterbuchs vorgeschlagen, das aus zwei Teilen besteht.  Zun√§chst erhalten wir die erste Ann√§herung von W mithilfe eines dom√§nen-kontradiktorischen Trainings (ein Wettbewerbsmodell wie GAN, jedoch anstelle des Generators - eine lineare Abbildung von W, mit der wir versuchen, S und T voneinander zu unterscheiden, und der Diskriminator versucht, den tats√§chlichen Ursprung der Einbettung zu bestimmen).  Basierend auf den W√∂rtern, deren Einbettungen am besten zueinander passten und am h√§ufigsten in beiden Geb√§uden vorkommen, wird dann ein W√∂rterbuch gebildet.  Danach erfolgt die Verfeinerung von W gem√§√ü der obigen Formel. <br><br>  Dieser Ansatz liefert Ergebnisse, die mit dem Lernen mit beschrifteten Daten vergleichbar sind. Dies kann sehr n√ºtzlich sein, um Sprache aus seltenen Sprachen zu erkennen und zu √ºbersetzen, f√ºr die es zu wenige parallele Sprach-Text-F√§lle gibt oder die fehlen. <br><br>  <b>Erkennung tiefer Anomalien mithilfe geometrischer Transformationen</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  Ein eher ungew√∂hnlicher Ansatz bei der Erkennung von Anomalien, der nach Ansicht der Autoren andere Ans√§tze stark zunichte macht. <br><br>  Die Idee ist folgende: Lassen Sie uns K verschiedene geometrische Transformationen (eine Kombination aus Verschiebungen, 90-Grad-Drehung und Reflexion) entwickeln und auf jedes Bild des Originaldatensatzes anwenden.  Das Bild, das als Ergebnis der i-ten Transformation erhalten wurde, geh√∂rt nun zur Klasse i, dh es gibt insgesamt K Klassen, von denen jede durch die Anzahl der Bilder dargestellt wird, die urspr√ºnglich im Datensatz enthalten waren.  Jetzt werden wir eine Mehrklassenklassifizierung f√ºr ein solches Markup unterrichten (die Autoren haben sich f√ºr ein breites Resnet entschieden). <br><br>  Jetzt k√∂nnen wir K Vektoren y (Ti (x)) der Dimension K f√ºr ein neues Bild erhalten, wobei Ti die i-te Transformation ist, x das Bild ist, y die Modellausgabe ist.  Die grundlegende Definition von ‚ÄûNormalit√§t‚Äú lautet wie folgt: <br><br>  Hier haben wir f√ºr Bild x die vorhergesagten Wahrscheinlichkeiten der richtigen Klassen f√ºr alle Transformationen hinzugef√ºgt.  Je gr√∂√üer die ‚ÄûNormalit√§t‚Äú ist, desto wahrscheinlicher ist es, dass das Bild aus derselben Verteilung wie das Trainingsmuster stammt.  Die Autoren behaupten, dass dies bereits sehr cool funktioniert, bieten aber dennoch einen komplexeren Weg, der noch ein wenig besser funktioniert.  Wir nehmen an, dass der Vektor y (Ti (x)) f√ºr jede Ti-Transformation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dirichlet-</a> verteilt ist, und nehmen den Wahrscheinlichkeitslogarithmus als Ma√ü f√ºr die ‚ÄûNormalit√§t‚Äú des Bildes.  Die Dirichlet-Verteilungsparameter werden anhand eines Trainingssatzes gesch√§tzt. <br><br>  Die Autoren berichten √ºber die unglaubliche Leistungssteigerung im Vergleich zu anderen Ans√§tzen. <br><br>  <b>Ein einfaches, einheitliches Framework zum Erkennen von Stichproben und Angriffen, die nicht in der Verteilung sind</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  Die Identifizierung in der Stichprobe f√ºr die Anwendung des Fallmodells, das sich erheblich von der Verteilung der Trainingsstichprobe unterscheidet, ist eine der Hauptanforderungen f√ºr die Erzielung zuverl√§ssiger Klassifizierungsergebnisse.  Gleichzeitig sind neuronale Netze daf√ºr bekannt, dass sie Objekte mit einem hohen Ma√ü an Sicherheit (und f√§lschlicherweise) klassifizieren, die im Training nicht angetroffen oder absichtlich besch√§digt wurden (gegnerische Beispiele). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e0/780/f35/1e0780f3540fcb4ba894f38a40c31cbb.png" alt="Bild"><br><br>  Die Autoren des Artikels bieten eine neue Methode zur Identifizierung dieser und anderer "schlechter" F√§lle.  Der Ansatz wird wie folgt implementiert: Zuerst wird ein neuronales Netzwerk mit der √ºblichen Softmax-Ausgabe trainiert, dann wird die Ausgabe seiner vorletzten Schicht genommen und der generative Klassifikator darauf trainiert.  Es sei x - das der Modelleingabe f√ºr ein bestimmtes Klassifizierungsobjekt zugef√ºhrt wird, y - die entsprechende Klassenbezeichnung, und es sei angenommen, dass wir einen vorab trainierten Softmax-Klassifizierer der Form haben: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/223/898/826/223898826445e2677c03a2078b182208.png" alt="Bild" width="300" height="200"></div><br><br>  Wobei wc und bc die Gewichte und Konstanten der Softmax-Schicht f√ºr Klasse c sind und f (.) Die Ausgabe des vorletzten Sojabohnen-DNN ist. <br><br>  Ferner wird ohne √Ñnderungen an dem vorab trainierten Klassifikator ein √úbergang zum generativen Klassifikator vorgenommen, n√§mlich eine Diskriminanzanalyse.  Es wird angenommen, dass Merkmale, die der vorletzten Schicht des Softmax-Klassifikators entnommen wurden, eine mehrdimensionale Normalverteilung aufweisen, von der jede Komponente einer Klasse entspricht.  Dann kann die bedingte Verteilung durch den Vektor der Mittelwerte der mehrdimensionalen Verteilung und ihrer Kovarianzmatrix spezifiziert werden: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ada/0d8/e70/ada0d8e70536c7993a6061b154f3c0eb.png" alt="Bild" width="300" height="200"></div><br><br>  Um die Parameter des generativen Klassifikators zu bewerten, werden empirische Mittelwerte f√ºr jede Klasse sowie die Kovarianz f√ºr F√§lle aus der Trainingsstichprobe {(x1, y1), ..., (xN, yN)} berechnet: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ada/0d8/e70/ada0d8e70536c7993a6061b154f3c0eb.png" alt="Bild" width="300" height="200"></div><br><br>  Dabei ist N die Anzahl der F√§lle der entsprechenden Klasse im Trainingssatz.  Dann wird ein Ma√ü f√ºr die Zuverl√§ssigkeit an der Testprobe berechnet - der Mahalanobis-Abstand zwischen dem Testfall und der diesem Fall am n√§chsten liegenden normalen Klassenverteilung. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/095/928/03b/09592803b18f664fad5940fc81d47f77.png" alt="Bild" width="400" height="300"></div><br><br>  Wie sich herausstellte, funktioniert eine solche Metrik bei atypischen oder besch√§digten Objekten viel zuverl√§ssiger, ohne hohe Sch√§tzungen wie die Softmax-Schicht abzugeben.  Bei den meisten Vergleichen mit verschiedenen Daten zeigte die vorgeschlagene Methode Ergebnisse, die den aktuellen Stand der Technik √ºbertrafen, indem beide F√§lle gefunden wurden, die nicht im Training waren und absichtlich verw√∂hnt wurden. <br><br>  Dar√ºber hinaus betrachten die Autoren eine weitere interessante Anwendung ihrer Methodik: Verwenden Sie den generativen Klassifikator, um neue Klassen hervorzuheben, die sich nicht im Training f√ºr den Test befanden, und aktualisieren Sie dann die Parameter des Klassifikators selbst, damit er diese neue Klasse in Zukunft bestimmen kann. <br><br>  <b>Widerspr√ºchliche Beispiele, die sowohl Computer Vision als auch zeitlich begrenzte Menschen zum Narren halten</b> <br>  Zusammenfassung: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://arxiv.org/abs/1802.08195</a> <br><br>     adversarial examples     .     ,           .          adversarial example      . ,         ,   , ,         , ,  ,      adversarial attacks. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/859/b13/cf0/859b13cf0bb3c14ac58eeab39b5a0945.png" alt="Bild"><br><br>         adversarial examples.   adversarial examples  ,         (   ,           ). <br><br> ,   adversarial example,        . ,        ,         63          .    accuracy      10% ,   adversarial.        ,  adversarial             ,     .   ,     perturbation   perturbation   ,  accuracy        . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/966/f4d/e03/966f4de0389283dd83f73a1be2cf36cb.png" alt="Bild"><br><br>   adv ‚Äî adversarial example, image ‚Äî  , flip ‚Äî   + adversarial perturbation,   . <br><br> <b>Sanity Checks for Saliency Maps</b> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Abstract</a> <br><br>   ‚Äî      .     deep learning,     saliency maps. Saliency maps                 .    saliency map,       ,      ‚Äú‚Äù. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aa5/2c5/659/aa52c5659d4c00d7666661797671c4b9.png" alt="Bild"><br><br>     : ‚Äú      saliency maps?‚Äù    ,   : <br><br><ol><li> Saliency map      </li><li> Saliency map    ,     </li></ol><br>     ,      : cascading randomization ( ,     ,   saliency map)  independent randomization (  ).     :      ,     saliency maps. <br>    saliency map     ,   ,       saliency maps. : ‚ÄúTo our surprise, some widely deployed saliency methods are independent of both the data the model was trained on, and the model parameters‚Äù, ‚Äî  . , ,   saliency maps,     ,  cascading randomization: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/965/eaa/ca7/965eaaca7902d24ef5369a63d493b4ff.png" alt="Bild"><br><br>      ,           .     ,   saliency maps    . <br><br>    ,  ‚Äî  saliency maps          ,      ,      confirmation bias.         ,          . <br><br> <b>An intriguing failing of convolutional neural networks and the CoordConv solution</b> <br> Abstract: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://arxiv.org/abs/1807.03247</a> <br> :           ,     10 . <br><br>        Uber.        ,  ,     ,     .           ,           : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ed/408/c14/6ed408c1456a509c86a6260df5c5a23b.png" alt="Bild"><br><br>    :    (     CoodrConv )   i  j,          : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2a/87e/8cb/a2a87e8cb6b7d283396a0fb3ef11fe30.png" alt="Bild"><br><br> , : <br><br><ol><li>       ImageNet'.         , ,   ,    ,         </li><li> CoordConv   object detection.        MNIST,      Faster R-CNN,    IoU  21% </li><li>   CoordConv  GAN    . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fee/a18/425/feea18425335abbb7d784669a1b82bcd.png" alt="Bild"><br><br>  GAN'   :                 LSUN.       ,     ‚Äî     c.  ,   GAN'    , ,         .   CoordConv         ,      .    LSUN   d ,     ,  CoordConv GAN,    <br></li><li> 4.  CoordConv  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">A2C</a>     (  ) . </li></ol><br>        ,       ,     .   CoordConv      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">U-net</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://arxiv.org/abs/1812.01429,%2520">https://arxiv.org/abs/1812.01429, https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/69274</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/mjDelta/Kaggle-RSNA-Pneumonia-Detection-Challenge</a> . <br><br>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">  </a> . <br><br> <b>Regularizing by the Variance of the Activations' Sample-Variances</b> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Abstract</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> <br><br>     batch normalization.          - .      :       S1  S2    : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e5f/2ea/97a/e5f2ea97aaebf6af472880bc2190b2cc.png" alt="Bild" width="300" height="200"></div><br><br>  wobei œÉ2 Probenvarianzen in S1 bzw. S2 sind, ist Œ≤ der trainierte positive Koeffizient.  Die Autoren nennen dieses Ding Varianzkonstanzverlust (VCL) und addieren es zum Gesamtverlust. <br><br>  Im Abschnitt √ºber Experimente beschweren sich die Autoren dar√ºber, dass die Ergebnisse der Artikel anderer Personen nicht reproduziert werden, und verpflichten sich, einen reproduzierbaren Code (angelegt) zu erstellen.  Zun√§chst experimentierten sie mit einem kleinen 11-Lagen-Netz am Datensatz kleiner Bilder (CIFAR-10 und CIFAR-100).  Wir haben festgestellt, dass VCL beweist, wenn Sie Leaky ReLU oder ELU als Aktivierungen verwenden, aber die Batch-Normalisierung mit ReLU besser funktioniert.  Dann erh√∂hen sie die Anzahl der Ebenen um das Zweifache und wechseln zu Tiny Imagenet - einer vereinfachten Version von Imagenet mit 200 Klassen und einer Aufl√∂sung von 64 x 64.  Bei der Validierung √ºbertrifft VCL die Batch-Normalisierung im Grid mit ELU sowie ResNet-110 und DenseNet-40, √ºbertrifft jedoch Wide-ResNet-32.  Ein interessanter Punkt ist, dass die besten Ergebnisse erzielt werden, wenn die Teilmengen S1 und S2 aus zwei Stichproben bestehen. <br><br>  Dar√ºber hinaus testen die Autoren VCL in Feed-Forward-Netzwerken, und VCL gewinnt etwas h√§ufiger als ein Netzwerk mit Batch-Normalisierung oder ohne Regularisierung. <br><br>  <b>DropMax: Adaptiver Variations-Softmax</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenfassung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  In dem Mehrklassenklassifizierungsproblem wird vorgeschlagen, bei jeder Iteration des Gradientenabfalls f√ºr jede Probe eine zuf√§llige Anzahl falscher Klassen zuf√§llig fallen zu lassen.  Dar√ºber hinaus wird auch die Wahrscheinlichkeit trainiert, mit der wir die eine oder andere Klasse f√ºr das eine oder andere Objekt fallen lassen.  Infolgedessen stellt sich heraus, dass sich das Netzwerk auf die Unterscheidung zwischen den am schwierigsten zu trennenden Klassen konzentriert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2d/f45/914/b2df45914519d3b6dd1d4f12d5513775.png" alt="Bild"><br><br>  Experimente mit MNIST-, CIFAR- und Imagenet-Untergruppen zeigen, dass DropMax eine bessere Leistung als Standard-SoftMax und einige seiner Modifikationen aufweist. <br><br>  <b>Genaue verst√§ndliche Modelle mit paarweisen Interaktionen</b> <br>  (Freunde lassen Freunde keine Black-Box-Modelle bereitstellen: Die Bedeutung der Verst√§ndlichkeit beim maschinellen Lernen) <br><br>  Zusammenfassung: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.cs.cornell.edu/~yinlou/papers/lou-kdd13.pdf</a> <br>  Code: Es ist nicht da.  Ich bin sehr daran interessiert, wie die Autoren einen so leicht zwingenden Namen mit einem Mangel an Code versehen.  Akademiker, Sir =) <br><br>  Sie k√∂nnen sich dieses Paket beispielsweise ansehen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/dswah/pyGAM</a> .  Vor nicht allzu langer Zeit wurden Feature-Interaktionen hinzugef√ºgt (was GAM tats√§chlich von GA2M unterscheidet). <br><br>  Dieser Artikel wurde im Rahmen des Workshops ‚ÄûInterpretierbarkeit und Robustheit in Audio, Sprache und Sprache‚Äú vorgestellt, obwohl er sich der Interpretierbarkeit von Modellen im Allgemeinen und nicht dem Bereich der Ton- und Sprachanalyse widmet. Wahrscheinlich war jeder in gewissem Ma√üe mit dem Dilemma konfrontiert, zwischen Modellinterpretierbarkeit und zu w√§hlen seine Genauigkeit.  Wenn wir die √ºbliche lineare Regression verwenden, k√∂nnen wir anhand der Koeffizienten verstehen, wie sich jede unabh√§ngige Variable auf die abh√§ngige auswirkt.  Wenn wir Black-Box-Modelle verwenden, z. B. Gradientenverst√§rkung ohne Einschr√§nkung der Komplexit√§t oder tiefe neuronale Netze, ist ein korrekt abgestimmtes Modell f√ºr geeignete Daten sehr genau, aber die Verfolgung und Erkl√§rung aller Muster, die das in den Daten gefundene Modell enth√§lt, ist problematisch.  Dementsprechend wird es schwierig sein, dem Kunden das Modell zu erkl√§ren und zu verfolgen, ob er etwas gelernt hat, das wir nicht m√∂chten.  Die folgende Tabelle enth√§lt Sch√§tzungen der relativen Interpretierbarkeit und Genauigkeit verschiedener Modelltypen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fca/429/548/fca42954836ae74af472d4baacf732f1.png" alt="Bild"><br><br>  Ein Beispiel f√ºr eine Situation, in der eine schlechte Interpretierbarkeit des Modells mit gro√üen Risiken verbunden ist: In einem der medizinischen Datens√§tze wurde das Problem der Vorhersage der Wahrscheinlichkeit, dass der Patient an einer Lungenentz√ºndung stirbt, gel√∂st.  Das folgende interessante Muster wurde in den Daten gefunden: Wenn eine Person Asthma bronchiale hat, ist die Wahrscheinlichkeit, an einer Lungenentz√ºndung zu sterben, geringer als bei Menschen ohne diese Krankheit.  Als sich die Forscher an praktizierende √Ñrzte wandten, stellte sich heraus, dass ein solches Muster tats√§chlich besteht, da Menschen mit Asthma im Falle einer Lungenentz√ºndung die schnellste Hilfe und die st√§rksten Medikamente erhalten.  Wenn wir xgboost auf diesen Datensatz trainiert h√§tten, h√§tte er dieses Muster h√∂chstwahrscheinlich erkannt, und unser Modell w√ºrde Patienten mit Asthma als Gruppe mit geringem Risiko klassifizieren und dementsprechend eine niedrigere Priorit√§t und Behandlungsintensit√§t f√ºr sie empfehlen. <br><br>  Die Autoren des Artikels bieten eine Alternative, die gleichzeitig interpretierbar und genau ist - dies ist GA2M, eine Unterart verallgemeinerter additiver Modelle. <br><br>  Klassisches GAM kann als weitere Verallgemeinerung von GLM betrachtet werden: Ein Modell ist eine Summe, deren Term den Einfluss nur einer unabh√§ngigen Variablen auf die abh√§ngige Variable widerspiegelt. Der Einfluss wird jedoch nicht durch einen Gewichtskoeffizienten wie in GLM ausgedr√ºckt, sondern durch eine glatte nichtparametrische Funktion (in der Regel st√ºckweise definiert) Funktionen - Splines oder B√§ume von geringer Tiefe, einschlie√ülich "St√ºmpfe").  Aufgrund dieser Funktion k√∂nnen GAMs komplexere Beziehungen modellieren als ein einfaches lineares Modell.  Andererseits k√∂nnen gelernte Abh√§ngigkeiten (Funktionen) visualisiert und interpretiert werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/643/828/ca8/643828ca8aaeb0f0728ba2d094de7e43.png" alt="Bild"><br><br>  Standard-GAMs erreichen jedoch h√§ufig immer noch nicht die Genauigkeit von Black-Box-Algorithmen.  Um dies zu beheben, bieten die Autoren des Artikels einen Kompromiss an - um der Modellgleichung zus√§tzlich zu den Funktionen einer Variablen eine kleine Anzahl von Funktionen zweier Variablen hinzuzuf√ºgen - sorgf√§ltig ausgew√§hlte Paare, deren Interaktion f√ºr die Vorhersage der abh√§ngigen Variablen von Bedeutung ist.  Somit wird GA2M erhalten. <br><br>  Zuerst wird ein Standard-GAM erstellt (ohne die Interaktion von Variablen zu ber√ºcksichtigen), und dann werden schrittweise Variablenpaare hinzugef√ºgt (das verbleibende GAM wird als Zielvariable verwendet).  F√ºr den Fall, dass viele Variablen vorhanden sind und die Aktualisierung des Modells nach jedem Schritt rechenintensiv ist, wird ein FAST-Ranking-Algorithmus vorgeschlagen, mit dem Sie potenziell n√ºtzliche Paare vorab ausw√§hlen und eine vollst√§ndige Aufz√§hlung vermeiden k√∂nnen. <br><br>  Dieser Ansatz erm√∂glicht es uns, Qualit√§t in der N√§he von Modellen mit unbegrenzter Komplexit√§t zu erzielen.  Die Tabelle zeigt die Fehlerrate verallgemeinerter additiver Modelle im Vergleich zu einer zuf√§lligen Gesamtstruktur zur L√∂sung des Klassifizierungsproblems in verschiedenen Datens√§tzen. In den meisten F√§llen unterscheidet sich die Qualit√§t der Vorhersage f√ºr GA2M mit FAST und f√ºr zuf√§llige Gesamtstrukturen nicht signifikant. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/809/a50/e5b809a50067cbfcd2f7bbb04f98630e.png" alt="Bild"><br><br>  Ich m√∂chte auf die Merkmale der Arbeit von Akademikern aufmerksam machen, die anbieten, diese Verst√§rkungen und Tiefschneidungen an den Ofen zu senden.  Bitte beachten Sie, dass die Datens√§tze, auf denen die Ergebnisse dargestellt werden, nicht mehr als 20.000 Objekte enthalten (alle Datens√§tze aus dem UCI-Repository).  Es stellt sich nat√ºrlich die Frage: Gibt es f√ºr solche Experimente im Jahr 2018 wirklich keinen offenen Datensatz normaler Gr√∂√üe?  Sie k√∂nnen noch weiter gehen und einen Datensatz mit 50 Objekten vergleichen. Es besteht die M√∂glichkeit, dass sich das konstante Modell nicht wesentlich von einer zuf√§lligen Gesamtstruktur unterscheidet. <br><br>  Der n√§chste Punkt ist die Regularisierung.  Bei einer Vielzahl von Zeichen ist es sehr einfach, auch ohne Wechselwirkungen umzuschulen.  Die Autoren glauben m√∂glicherweise, dass dieses Problem nicht besteht, und das einzige Problem ist das Black-Box-Modell.  Zumindest in dem Artikel wird von Regularisierung nirgendwo gesprochen, obwohl dies offensichtlich notwendig ist. <br><br>  Und das letzte, was die Interpretierbarkeit betrifft.  Selbst lineare Modelle sind nicht interpretierbar, wenn wir viele Funktionen haben.  Wenn Sie 10 Tausend normalverteilte Gewichte haben (bei Verwendung der L2-Regularisierung ist dies ungef√§hr so), ist es unm√∂glich, genau zu sagen, welche Vorzeichen f√ºr die Tatsache verantwortlich sind, dass Predict_Proba 0,86 ergibt.  Zur Interpretierbarkeit wollen wir nicht nur ein lineares Modell, sondern ein lineares Modell mit geringen Gewichten.  Es scheint, dass dies durch L1-Regularisierung erreicht werden kann, aber auch hier ist es nicht so einfach.  Aus einer Reihe stark korrelierter Merkmale wird die L1-Regularisierung fast zuf√§llig eines ausw√§hlen.  Der Rest erh√§lt eine Gewichtung von 0, obwohl, wenn eines dieser Merkmale Vorhersagef√§higkeit besitzt, die anderen eindeutig nicht nur Rauschen sind.  In Bezug auf die Modellinterpretation kann dies in Ordnung sein. In Bezug auf das Verst√§ndnis der Beziehung zwischen Merkmalen und der Zielvariablen ist dies sehr schlecht.  Das hei√üt, selbst bei linearen Modellen ist nicht alles so einfach. Weitere Details zu interpretierbaren und glaubw√ºrdigen Modellen finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  <b>Visualisierung f√ºr maschinelles Lernen: UMAP</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Absorbieren</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> <br><br>  Am Tag der Tutorials war einer der ersten, der durchgef√ºhrt wurde, "Visualisierung f√ºr maschinelles Lernen" von Google Brain.  Im Rahmen des Tutorials wurden wir √ºber die Geschichte der Visualisierungen informiert, beginnend mit dem Ersteller der ersten Grafiken, sowie √ºber verschiedene Merkmale des menschlichen Gehirns und die Wahrnehmung und Techniken, mit denen die Aufmerksamkeit auf das Wichtigste im Bild gelenkt werden kann, selbst wenn es viele kleine Details enth√§lt - zum Beispiel das Hervorheben Form, Farbe, Rahmen usw. wie im Bild unten.  Ich werde diesen Teil √ºberspringen, aber es gibt eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gute Bewertung</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/751/f0f/c31/751f0fc318a4bb3edadf59e35ecc7ba9.png" alt="Bild"><br><br>  Pers√∂nlich interessierte mich am meisten das Thema der Visualisierung mehrdimensionaler Datens√§tze, insbesondere der UMAP-Ansatz (Uniform Manifold Approximation and Projection) - eine neue nichtlineare Methode zur Dimensionsreduzierung.  Es wurde im Februar dieses Jahres vorgeschlagen, so dass es bisher nur wenige Menschen verwenden, aber es sieht sowohl in Bezug auf die Arbeitszeit als auch in Bezug auf die Qualit√§t der Klassentrennung in zweidimensionalen Visualisierungen vielversprechend aus.  In verschiedenen Datens√§tzen ist UMAP t-SNE und anderen Methoden in Bezug auf die Geschwindigkeit 2-10 Mal voraus. Je gr√∂√üer die Datendimension, desto gr√∂√üer ist die Leistungsl√ºcke: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b82/045/a12/b82045a12b1cb8782c5c9fb64dfa46b9.png" alt="Bild"><br><br>  Dar√ºber hinaus ist die UMAP-Betriebszeit im Gegensatz zu t-SNE nahezu unabh√§ngig von der Dimension des neuen Raums, in den wir unseren Datensatz einbetten (siehe Abbildung unten), was ihn zu einem geeigneten Werkzeug f√ºr andere Aufgaben (neben der Visualisierung) macht - insbesondere f√ºr um die Abmessung vor dem Training des Modells zu reduzieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0c6/f14/56a/0c6f1456a68537b5e12f58f6e1dfb740.png" alt="Bild"><br><br>  Gleichzeitig haben Tests an verschiedenen Datens√§tzen gezeigt, dass UMAP f√ºr die Visualisierung nicht schlechter funktioniert und t-SNE stellenweise besser ist: Beispielsweise sind Klassen in MNIST- und Fashion MNIST-Datens√§tzen in der Version mit UMAP besser getrennt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f35/4b4/869/f354b48691226fd262e3f92af9fe398f.png" alt="Bild"><br><br>  Ein zus√§tzliches Plus ist eine praktische Implementierung: Die UMAP-Klasse erbt von den sklearn-Klassen, sodass Sie sie als regul√§ren Transformator in der sklearn-Pipeline verwenden k√∂nnen.  Dar√ºber hinaus wird argumentiert, dass UMAP besser interpretierbar ist als t-SNE  unterh√§lt eine globale Datenstruktur besser. <br><br>  In Zukunft planen die Autoren, Unterst√ºtzung f√ºr halb√ºberwachtes Training hinzuzuf√ºgen. Wenn wir also Tags f√ºr mindestens einige der Objekte haben, k√∂nnen wir UMAP basierend auf diesen Informationen erstellen. <br><br>  Welche Artikel haben Ihnen gefallen?  Schreiben Sie Kommentare, stellen Sie Fragen, wir werden sie beantworten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de434694/">https://habr.com/ru/post/de434694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de434684/index.html">Rost 2019 und dar√ºber hinaus: Wachstumsbeschr√§nkungen</a></li>
<li><a href="../de434686/index.html">Vorlesung √ºber JavaScript und Node.js in KPI</a></li>
<li><a href="../de434688/index.html">FreeBSD plant, zu ZFSonLinux zu wechseln</a></li>
<li><a href="../de434690/index.html">Haiku-Betriebssystem: Portieren von Anwendungen und Erstellen von Paketen</a></li>
<li><a href="../de434692/index.html">Die 25 teuersten US-Startups, die 2018 starben</a></li>
<li><a href="../de434696/index.html">Mitarbeiter von IT-Giganten haben herausgefunden, wie sie die Richtlinien ihrer Unternehmen beeinflussen k√∂nnen</a></li>
<li><a href="../de434698/index.html">Pessimismus √ºber Multithreading</a></li>
<li><a href="../de434700/index.html">Vorteile der folgenden Styleguides bei der Entwicklung von Angular-Anwendungen</a></li>
<li><a href="../de434702/index.html">Warum moderne SSD mich zum Absturz bringt</a></li>
<li><a href="../de434704/index.html">Gr√ºnde f√ºr den R√ºckgang der Kosten des Mobilfunkverkehrs in Russland und die Prognose f√ºr 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
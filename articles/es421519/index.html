<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçü§ù‚Äçüë®üèæ üå∞ üë®üèº‚Äçüé® El libro "Apache Kafka. Procesamiento de flujo y an√°lisis de datos " ü¶ë üë®üèº‚ÄçüöÄ üçå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durante el trabajo de cualquier aplicaci√≥n empresarial, se generan datos: estos son archivos de registro, m√©tricas, informaci√≥n sobre la actividad del...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>El libro "Apache Kafka. Procesamiento de flujo y an√°lisis de datos "</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/421519/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/t6/ej/tx/t6ejtxboknf_ha_u7radv1gzrls.jpeg" align="left" alt="imagen"></a>  Durante el trabajo de cualquier aplicaci√≥n empresarial, se generan datos: estos son archivos de registro, m√©tricas, informaci√≥n sobre la actividad del usuario, mensajes salientes, etc. La manipulaci√≥n adecuada de todos estos datos no es menos importante que los datos en s√≠.  Si eres un arquitecto, desarrollador o ingeniero graduado que quiere resolver tales problemas, pero a√∫n no est√°s familiarizado con Apache Kafka, entonces de este maravilloso libro aprender√°s c√≥mo trabajar con esta plataforma de transmisi√≥n gratuita que te permite procesar colas de datos en tiempo real. <br><br><h3>  ¬øPara qui√©n es este libro? </h3><br>  ‚ÄúApache Kafka.  Procesamiento de flujo y an√°lisis de datos ‚Äùfue escrito para desarrolladores que usan la API de Kafka en su trabajo, as√≠ como para ingenieros de procesos (tambi√©n llamados SRE, DevOps o administradores de sistemas) que est√°n involucrados en la instalaci√≥n, configuraci√≥n, configuraci√≥n y monitoreo de su operaci√≥n durante la operaci√≥n industrial.  Tampoco nos olvidamos de los arquitectos de datos e ingenieros anal√≠ticos, los responsables del dise√±o y la creaci√≥n de toda la infraestructura de datos de la empresa.  Algunos cap√≠tulos, en particular 3, 4 y 11, est√°n dirigidos a desarrolladores de Java.  Para comprenderlos, es importante que el lector est√© familiarizado con los conceptos b√°sicos del lenguaje de programaci√≥n Java, incluidos temas como el manejo de excepciones y la competencia. <br><a name="habracut"></a><br>  Otros cap√≠tulos, especialmente 2, 8, 9 y 10, suponen que el lector tiene experiencia con Linux y est√° familiarizado con la configuraci√≥n de la red y el almacenamiento de Linux.  El resto del libro de Kafka y las arquitecturas de software se discuten en t√©rminos m√°s generales, por lo que no se requiere ning√∫n conocimiento especial de los lectores. <br><br>  Otra categor√≠a de personas que pueden estar interesadas en este libro son los gerentes y arquitectos que trabajan no directamente con Kafka, sino con aquellos que trabajan con √©l.  No es menos importante que entiendan cu√°les son las garant√≠as de la plataforma y qu√© compromisos tendr√°n que hacer sus subordinados y colegas al crear sistemas basados ‚Äã‚Äãen Kafka.  Este libro ser√° √∫til para aquellos gerentes que deseen capacitar a sus empleados para trabajar con Kafka o para asegurarse de que el equipo de desarrollo posea la informaci√≥n necesaria. <br><br><h3>  Cap√≠tulo 2. Instalando Kafka </h3><br>  Apache Kafka es una aplicaci√≥n Java que puede ejecutarse en muchos sistemas operativos, incluidos Windows, MacOS, Linux y otros. En este cap√≠tulo, nos centraremos en instalar Kafka en Linux, ya que es la plataforma que se instala con mayor frecuencia en este sistema operativo.  Linux tambi√©n es el sistema operativo recomendado para la implementaci√≥n de Kafka de uso general.  Para obtener informaci√≥n sobre c√≥mo instalar Kafka en Windows y MacOS, consulte el Ap√©ndice A. <br><br>  <b>Instalar java</b> <br><br>  Antes de instalar ZooKeeper o Kafka, debe instalar y configurar el entorno Java.  Se recomienda que use Java 8, y esta puede ser una versi√≥n, incluida en su sistema operativo o descargada directamente desde java.com.  Aunque ZooKeeper y Kafka trabajar√°n con Java Runtime Edition, es m√°s conveniente utilizar el Kit de desarrollo de Java (JDK) completo al desarrollar utilidades y aplicaciones.  Estos pasos de instalaci√≥n suponen que tiene instalada la versi√≥n 8.0.51 de JDK en el directorio /usr/java/jdk1.8.0_51. <br><br>  <b>Instalar ZooKeeper</b> <br><br>  Apache Kafka usa ZooKeeper para almacenar metadatos sobre el cl√∫ster de Kafka, as√≠ como detalles sobre clientes consumidores (Fig. 2.1).  Aunque ZooKeeper tambi√©n se puede iniciar utilizando scripts incluidos en la distribuci√≥n Kafka, instalar la versi√≥n completa del repositorio ZooKeeper desde la distribuci√≥n es muy simple. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/a-/ye/ed/a-yeeda4ysojxtp4kcwlnmufwlc.png" alt="imagen"></div><br>  Kafka ha sido probado exhaustivamente con la versi√≥n estable 3.4.6 del repositorio ZooKeeper, que se puede descargar desde apache.org. <br><br>  <b>Servidor independiente</b> <br><br>  El siguiente ejemplo muestra c√≥mo instalar ZooKeeper con configuraciones b√°sicas en el directorio / usr / local / zookeeper y guardar los datos en el directorio / var / lib / zookeeper: <br><br><pre><code class="hljs delphi"># tar -zxf zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span>.tar.gz # mv zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper # mkdir -p /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper # cat &gt; /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/conf/zoo.cfg &lt;&lt; EOF &gt; tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> &gt; dataDir=/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper &gt; clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> &gt; EOF # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED # <span class="hljs-keyword"><span class="hljs-keyword">export</span></span> JAVA_HOME=/usr/java/jdk1.<span class="hljs-number"><span class="hljs-number">8.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED #</code> </pre> <br>  Ahora puede verificar que se supone que ZooKeeper funciona sin conexi√≥n conect√°ndose al puerto del cliente y enviando el comando srvr de cuatro letras: <br><br><pre> <code class="hljs pgsql"># telnet localhost <span class="hljs-number"><span class="hljs-number">2181</span></span> Trying ::<span class="hljs-number"><span class="hljs-number">1.</span></span>.. Connected <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> localhost. <span class="hljs-keyword"><span class="hljs-keyword">Escape</span></span> <span class="hljs-type"><span class="hljs-type">character</span></span> <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-string"><span class="hljs-string">'^]'</span></span>. srvr Zookeeper <span class="hljs-keyword"><span class="hljs-keyword">version</span></span>: <span class="hljs-number"><span class="hljs-number">3.4</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span><span class="hljs-number"><span class="hljs-number">-1569965</span></span>, built <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> <span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">20</span></span>/<span class="hljs-number"><span class="hljs-number">2014</span></span> <span class="hljs-number"><span class="hljs-number">09</span></span>:<span class="hljs-number"><span class="hljs-number">09</span></span> GMT Latency min/avg/max: <span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span> Received: <span class="hljs-number"><span class="hljs-number">1</span></span> Sent: <span class="hljs-number"><span class="hljs-number">0</span></span> Connections: <span class="hljs-number"><span class="hljs-number">1</span></span> Outstanding: <span class="hljs-number"><span class="hljs-number">0</span></span> Zxid: <span class="hljs-number"><span class="hljs-number">0x0</span></span> Mode: standalone Node count: <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Connection</span></span> closed <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">foreign</span></span> host. #</code> </pre> <br>  <b>ZooKeeper Ensemble</b> <br><br>  El cl√∫ster ZooKeeper se llama conjunto.  Debido a la naturaleza del algoritmo en s√≠, se recomienda que el conjunto incluya un n√∫mero impar de servidores, por ejemplo, 3, 5, etc., ya que para que ZooKeeper pueda responder a las solicitudes, la mayor√≠a de los miembros del conjunto deben funcionar (qu√≥rum).  Esto significa que un conjunto de tres nodos puede funcionar con un nodo inactivo.  Si el conjunto tiene tres nodos, puede haber dos. <br><br>  Para configurar el funcionamiento de los servidores ZooKeeper en el conjunto, deben tener una configuraci√≥n √∫nica con una lista de todos los servidores, y cada servidor en el directorio de datos debe tener un archivo myid con el identificador de este servidor.  Si los hosts en el conjunto se llaman zoo1.example.com, zoo2.example.com y zoo3.example.com, entonces el archivo de configuraci√≥n puede verse as√≠: <br><br><pre> <code class="hljs pgsql">tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> dataDir=/var/lib/zookeeper clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> initLimit=<span class="hljs-number"><span class="hljs-number">20</span></span> syncLimit=<span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>=zoo1.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>=zoo2.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.3</span></span>=zoo3.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span></code> </pre> <br>  En esta configuraci√≥n, initLimit es la cantidad de tiempo que los nodos esclavos pueden conectarse al maestro.  El valor syncLimit limita el retraso de los nodos esclavos del maestro.  Ambos valores se especifican en unidades tickTime, es decir, initLimit = 20 ¬∑ 2000 ms = 40 s.  La configuraci√≥n tambi√©n enumera todos los servidores de conjunto.  Est√°n en el formato server.X = hostname: peerPort: leaderPort con los siguientes par√°metros: <br><br><ul><li>  X es el identificador del servidor.  Debe ser un n√∫mero entero, pero el recuento puede no ser cero y no ser secuencial; </li><li>  hostname: nombre de host o direcci√≥n IP del servidor; </li><li>  peerPort: puerto TCP a trav√©s del cual los servidores de conjunto se comunican entre s√≠; </li><li>  leaderPort: puerto TCP a trav√©s del cual se selecciona el host. </li></ul><br>  Es suficiente que los clientes puedan conectarse al conjunto a trav√©s del puerto clientPort, pero los miembros del conjunto deben poder intercambiar mensajes entre ellos en los tres puertos. <br><br>  Adem√°s de un √∫nico archivo de configuraci√≥n, cada servidor en el directorio dataDir debe tener un archivo myid.  Debe contener el identificador del servidor correspondiente al que figura en el archivo de configuraci√≥n.  Despu√©s de completar estos pasos, puede iniciar los servidores e interactuar√°n entre s√≠ en el conjunto. <br><br><h3>  Instalaci√≥n de Kafka Broker </h3><br>  Despu√©s de completar la configuraci√≥n de Java y ZooKeeper, puede continuar con la instalaci√≥n de Apache Kafka.  La √∫ltima versi√≥n de Apache Kafka se puede descargar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">kafka.apache.org/downloads.html</a> . <br><br>  En el siguiente ejemplo, instale la plataforma Kafka en el directorio / usr / local / kafka, config√∫rela para usar el servidor ZooKeeper lanzado anteriormente y guarde los segmentos de registro de mensajes en el directorio / tmp / kafka-logs: <br><br><pre> <code class="hljs pgsql"># tar -zxf kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>.tgz # mv kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka # mkdir /tmp/kafka-logs # export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br>  Despu√©s de iniciar el agente Kafka, puede probar su funcionamiento realizando operaciones simples con el cl√∫ster, incluida la creaci√≥n de un tema de prueba, la generaci√≥n de mensajes y su consumo. <br><br>  Crear y verificar hilos: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test Created topic </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"test"</span></span></span><span class="hljs-meta">. # /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test Topic:test PartitionCount:1 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 #</span></span></code> </pre> <br>  Generando mensajes para el tema de prueba: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-producer.sh --broker-list localhost:<span class="hljs-number"><span class="hljs-number">9092</span></span> --topic test Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^D #</code> </pre> <br>  Consumir mensajes del tema de prueba: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:<span class="hljs-number"><span class="hljs-number">2181</span></span> --topic test --from-beginning Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^C Consumed <span class="hljs-number"><span class="hljs-number">2</span></span> messages #</code> </pre> <br><h3>  Configuraci√≥n de corredor </h3><br>  El ejemplo de configuraci√≥n de intermediario suministrado con la distribuci√≥n Kafka es bastante adecuado para una ejecuci√≥n de prueba de un servidor independiente, pero para la mayor√≠a de las instalaciones no ser√° suficiente.  Hay muchas opciones de configuraci√≥n de Kafka que rigen todos los aspectos de la instalaci√≥n y la configuraci√≥n.  Puede dejar los valores predeterminados para muchos de ellos, ya que se relacionan con los matices de configurar un agente Kafka que no son aplicables hasta que trabaje con un escenario espec√≠fico que requiera su uso. <br><br><h3>  Configuraci√≥n b√°sica del agente </h3><br>  Hay varias configuraciones del agente Kafka que debe tener en cuenta al implementar la plataforma en cualquier entorno, a excepci√≥n de un agente independiente en un servidor separado.  Estos par√°metros se relacionan con la configuraci√≥n principal del intermediario, y la mayor√≠a de ellos deben cambiarse para que el intermediario pueda trabajar en un cl√∫ster con otros intermediarios. <br><br>  <b>broker.id</b> <br><br>  Cada agente de Kafka debe tener un identificador entero especificado por el par√°metro broker.id.  Por defecto, este valor es 0, pero puede ser cualquier n√∫mero.  Lo principal es que no se repite dentro del mismo cl√∫ster de Kafka.  La elecci√≥n del n√∫mero puede ser arbitraria y, si es necesario, para la comodidad del mantenimiento, puede transferirse de un agente a otro.  Es deseable que este n√∫mero est√© de alguna manera conectado con el host, luego la correspondencia de los identificadores de intermediario con los hosts con seguimiento ser√° m√°s transparente.  Por ejemplo, si sus nombres de host contienen n√∫meros √∫nicos (por ejemplo, host1.example.com, host2.example.com, etc.), estos n√∫meros ser√≠an una buena opci√≥n para los valores de broker.id. <br><br>  <b>puerto</b> <br><br>  Un archivo de configuraci√≥n t√≠pico inicia Kafka con un escucha en el puerto TCP 9092. Este puerto se puede cambiar a cualquier otro disponible cambiando el puerto del par√°metro de configuraci√≥n.  Tenga en cuenta que al elegir un puerto con un n√∫mero inferior a 1024, Kafka debe ejecutarse como root.  No se recomienda ejecutar Kafka como root. <br><br>  <b>zookeeper.connect</b> <br><br>  La ruta que utiliza ZooKeeper para almacenar los metadatos del intermediario se establece mediante el par√°metro de configuraci√≥n zookeeper.connect.  En la configuraci√≥n de muestra, ZooKeeper se ejecuta en el puerto 2181 en el host local, que se indica como localhost: 2181.  El formato de este par√°metro es una lista de l√≠neas separadas por punto y coma con el nombre de host del formulario: puerto / ruta, que incluye: <br><br><ul><li>  hostname: nombre de host o direcci√≥n IP del servidor ZooKeeper; </li><li>  puerto: n√∫mero de puerto del cliente para el servidor; </li><li>  / ruta: una ruta opcional de ZooKeeper utilizada como la nueva ruta ra√≠z (chroot) del cl√∫ster Kafka.  Si no se especifica, se utiliza la ruta ra√≠z. </li></ul><br>  Si la ruta de chroot especificada no existe, se crear√° cuando se inicie el intermediario. <br><br>  <b>log.dirs</b> <br><br>  Kafka guarda todos los mensajes en el disco duro, y estos segmentos del registro se almacenan en los directorios especificados en la configuraci√≥n log.dirs.  Es una lista de rutas separadas por comas en el sistema local.  Si se especifican varias rutas, el intermediario guardar√° secciones en ellas de acuerdo con el principio de las menos utilizadas, con la preservaci√≥n de los segmentos de registro de una secci√≥n a lo largo de una ruta.  Tenga en cuenta que el intermediario colocar√° la nueva secci√≥n en el directorio en el que actualmente se almacenan la menor cantidad de particiones y no se utiliza el menor espacio, de modo que no se garantiza la distribuci√≥n uniforme de datos entre las secciones. <br><br>  <b>num.recovery.threads.per.data.dir</b> <br><br>  Kafka utiliza un grupo de subprocesos personalizado para procesar segmentos de registro.  Actualmente se aplica: <br><br><ul><li>  durante el inicio normal: para abrir los segmentos de registro de cada secci√≥n; </li><li>  comenzar despu√©s de una falla: para verificar y truncar los segmentos de registro de cada secci√≥n; </li><li>  Parar: para cerrar suavemente los segmentos de registro. </li></ul><br>  Por defecto, solo se usa un hilo por directorio de registro.  Dado que esto solo ocurre al iniciar y detener, tiene sentido usar m√°s para paralelizar las operaciones.  ¬°Al recuperarse de un apagado incorrecto, los beneficios de usar este enfoque pueden alcanzar varias horas si se reinicia el corredor con una gran cantidad de particiones!  Recuerde que el valor de este par√°metro se determina en funci√≥n de un directorio de registro a partir del n√∫mero especificado utilizando log.dirs.  Es decir, si el valor del par√°metro num.recovery.threads.per.data.dir es 8 y se especifican tres rutas en log.dirs, entonces el n√∫mero total de subprocesos es 24. <br><br>  <b>auto.create.topics.enable</b> <br><br>  Seg√∫n la configuraci√≥n predeterminada de Kafka, el corredor deber√≠a crear autom√°ticamente un tema cuando: <br><br><ul><li>  el fabricante comienza a escribir en la l√≠nea de asunto; </li><li>  el consumidor comienza a leer el tema del mensaje; </li><li>  cualquier cliente solicita metadatos del tema. </li></ul><br>  En muchos casos, este comportamiento puede ser indeseable, especialmente debido al hecho de que no hay forma de verificar la existencia de un tema utilizando el protocolo Kafka sin hacer que se cree.  Si controla la creaci√≥n de eso expl√≠citamente, manualmente o mediante el sistema de inicializaci√≥n, puede establecer el par√°metro auto.create.topics.enable en falso. <br><br><h3>  Configuraci√≥n de tema predeterminada </h3><br>  La configuraci√≥n del servidor Kafka establece una gran cantidad de configuraciones predeterminadas para los temas creados.  Algunos de estos par√°metros, incluido el n√∫mero de secciones y los par√°metros de guardado de mensajes, se pueden configurar para cada tema por separado utilizando las herramientas de administrador (discutidas en el Cap√≠tulo 9).  Los valores predeterminados en la configuraci√≥n del servidor deben establecerse iguales a los valores de referencia que son adecuados para la mayor√≠a de los temas del cl√∫ster. <br><br>  <b>n√∫mero de particiones</b> <br><br>  El par√°metro num.partitions determina con cu√°ntas secciones se crea un nuevo tema, principalmente cuando la creaci√≥n autom√°tica por temas est√° habilitada (que es el comportamiento predeterminado).  El valor predeterminado de este par√°metro es 1. Tenga en cuenta que el n√∫mero de secciones para un tema solo puede aumentarse, pero no reducirse.  Esto significa que si requiere menos particiones que las indicadas en n√∫mero de particiones, tendr√° que crearlo con cuidado manualmente (esto se trata en el Cap√≠tulo 9). <br><br>  Como se discuti√≥ en el Cap√≠tulo 1, las secciones son una forma de escalar temas en un cl√∫ster de Kafka, por lo que es importante que tenga tantos como necesite para equilibrar la carga de los mensajes en todo el cl√∫ster a medida que se agregan los corredores.  Muchos usuarios prefieren que el n√∫mero de particiones sea igual o el n√∫mero de intermediarios en el cl√∫ster.  Esto hace posible distribuir uniformemente las secciones entre los corredores, lo que conducir√° a una distribuci√≥n uniforme de la carga entre los mensajes.  Sin embargo, este no es un requisito obligatorio, porque la presencia de varios temas le permite equilibrar la carga. <br><br>  <b>log.retention.ms</b> <br><br>  La mayor√≠a de las veces, el almacenamiento de mensajes en Kafka es limitado en el tiempo.  El valor predeterminado se especifica en el archivo de configuraci√≥n utilizando el par√°metro log.retention.hours y es igual a 168 horas, o 1 semana.  Sin embargo, puede usar otros dos par√°metros: log.retention.minutes y log.retention.ms.  Los tres par√°metros determinan lo mismo: el per√≠odo de tiempo despu√©s del cual se eliminan los mensajes.  Pero se recomienda usar el par√°metro log.retention.ms, porque si se especifican varios par√°metros, la prioridad pertenece a la unidad de medida m√°s peque√±a, por lo que siempre se usar√° el valor de log.retention.ms. <br><br>  <b>log.retention.bytes</b> <br><br>  Otra forma de limitar la validez de los mensajes se basa en el tama√±o total (en bytes) de los mensajes almacenados.  El valor se establece utilizando el par√°metro log.retention.bytes y se aplica por separado.  Esto significa que en el caso de un tema de ocho secciones e igual a 1 GB del valor de log.retention.bytes, la cantidad m√°xima de datos almacenados para este tema ser√° de 8 GB.  Tenga en cuenta que la cantidad de almacenamiento depende de las secciones individuales y no del tema.  Esto significa que si aumenta el n√∫mero de secciones para el tema, la cantidad m√°xima de datos guardados al usar log.retention.bytes tambi√©n aumentar√°. <br><br>  <b>log.segment.bytes</b> <br><br>  La configuraci√≥n de registro mencionada se refiere a segmentos de registro, no a mensajes individuales.  A medida que el agente Kafka genera mensajes, se agregan al final del segmento de diario actual de la secci√≥n correspondiente.  Cuando el segmento de registro alcanza el tama√±o especificado por el par√°metro log.segment.bytes y es igual a 1 GB de forma predeterminada, este segmento se cierra y se abre uno nuevo.  Despu√©s del cierre, el segmento de diario se puede retirar.  Cuanto menor sea el tama√±o de los segmentos de registro, m√°s a menudo tendr√° que cerrar archivos y crear nuevos, lo que reduce la eficiencia general de las escrituras en disco. <br><br>  El dimensionamiento de segmentos de registro es importante cuando los temas se caracterizan por una baja frecuencia de generaci√≥n de mensajes.  Por ejemplo, si un tema recibe solo 100 MB de mensajes por d√≠a, y el par√°metro log.segment.bytes se establece en el valor predeterminado, tarda 10 d√≠as en completar un segmento.  Y dado que los mensajes no pueden declararse inv√°lidos hasta que se cierre el segmento de registro, entonces con el valor de 604.8 millones (1 semana) del par√°metro log.retention.ms, los mensajes pueden acumularse en 17 d√≠as antes de que el segmento de registro cerrado se retire de la circulaci√≥n.  Esto se debe a que cuando cierra un segmento con mensajes que se han acumulado durante 10 d√≠as, debe almacenarlo durante otros 7 d√≠as antes de poder retirarlo de acuerdo con las reglas temporales adoptadas, ya que el segmento no se puede eliminar antes de que caduque el √∫ltimo mensaje. . <br><br>  <b>log.segment.ms</b> <br><br>  Otra forma de controlar el cierre de segmentos de registro es mediante el uso del par√°metro log.segment.ms, que especifica el per√≠odo de tiempo despu√©s del cual se cierra el segmento de registro.  Al igual que los par√°metros log.retention.bytes y log.retention.ms, los par√°metros log.segment.bytes y log.segment.ms no son mutuamente excluyentes.  Kafka cierra el segmento de registro cuando se agota el tiempo o se alcanza el l√≠mite de tama√±o especificado, dependiendo de cu√°l de estos eventos ocurra primero.  De manera predeterminada, el valor del par√°metro log.segment.ms no est√° establecido, como resultado de lo cual el cierre de los segmentos de registro est√° determinado por su tama√±o. <br><br>  <b>message.max.bytes</b> <br><br>  El agente de Kafka permite utilizar el par√°metro message.max.bytes para limitar el tama√±o m√°ximo de los mensajes generados.  El valor predeterminado para este par√°metro es 1,000,000 (1 MB).  Un fabricante que intente enviar un mensaje m√°s grande recibir√° una notificaci√≥n de error del agente, pero el mensaje no ser√° aceptado.  Como en el caso de todos los dem√°s tama√±os en bytes especificados en la configuraci√≥n del agente, estamos hablando del tama√±o del mensaje comprimido, por lo que los fabricantes pueden enviar mensajes, cuyo tama√±o sin comprimir es mucho mayor si pueden comprimirse a los l√≠mites especificados por message.max.bytes . <br><br>  Aumentar el tama√±o del mensaje puede afectar seriamente el rendimiento.  Un tama√±o de mensaje mayor significa que los subprocesos de intermediario que procesan las conexiones de red y las solicitudes tardar√°n m√°s en cada solicitud.  Los mensajes m√°s grandes tambi√©n aumentan la cantidad de datos escritos en el disco, lo que afecta el rendimiento de E / S. <br><br><h3>  Selecci√≥n de hardware </h3><br>  Elegir el hardware adecuado para el corredor Kafka es m√°s un arte que una ciencia.  La plataforma Kafka en s√≠ misma no tiene requisitos estrictos de hardware; funcionar√° sin problemas en ning√∫n sistema.  Pero si hablamos de rendimiento, entonces est√° influenciado por varios factores: capacidad y rendimiento de los discos, RAM, red y CPU. <br><br>  Primero debe decidir qu√© tipos de rendimiento son m√°s importantes para su sistema, despu√©s de lo cual puede elegir la configuraci√≥n de hardware √≥ptima que se ajuste al presupuesto. <br><br><h3>  Rendimiento de disco </h3><br>  El rendimiento de los discos de los intermediarios, que se utilizan para almacenar segmentos de registro, afecta directamente el rendimiento de los clientes de fabricaci√≥n.  Los mensajes de Kafka deben enviarse al almacenamiento local que confirme su grabaci√≥n.  Solo entonces la operaci√≥n de env√≠o puede considerarse exitosa.  Esto significa que cuanto m√°s r√°pido se realicen las operaciones de escritura en el disco, menor ser√° el retraso en la generaci√≥n de mensajes. <br><br>  La acci√≥n obvia en caso de problemas con el ancho de banda de los discos es usar discos duros con placas giratorias (HDD) o unidades de estado s√≥lido (SSD).  Los SSD tienen √≥rdenes de magnitud de menor tiempo de b√∫squeda / acceso y mayor rendimiento.  Los discos duros son m√°s econ√≥micos y tienen una mayor capacidad relativa.  El rendimiento del HDD se puede mejorar debido a su mayor n√∫mero en el intermediario, o mediante el uso de varios directorios de datos, o mediante la instalaci√≥n de discos en una matriz de discos independientes con redundancia (matriz redundante de discos independientes, RAID).  Otros factores influyen en el rendimiento, por ejemplo, la tecnolog√≠a de fabricaci√≥n de un disco duro (por ejemplo, SAS o SATA), as√≠ como las caracter√≠sticas del controlador del disco duro. <br><br><h3>  Capacidad de disco </h3><br>  La capacidad es otro aspecto del almacenamiento.  La cantidad requerida de espacio en disco est√° determinada por la cantidad de mensajes que deben almacenarse al mismo tiempo.  Si se espera que el corredor reciba 1 TB de tr√°fico por d√≠a, entonces con 7 d√≠as de almacenamiento, necesitar√° almacenamiento disponible para segmentos de registro de al menos 7 TB.  Tambi√©n debe considerar una saturaci√≥n de al menos el 10% para otros archivos, sin contar el b√∫fer para posibles fluctuaciones de tr√°fico o su crecimiento con el tiempo. <br><br>  La capacidad de almacenamiento es uno de los factores que deben considerarse al determinar el tama√±o √≥ptimo del cl√∫ster de Kafka y decidir su expansi√≥n.  El tr√°fico total del cl√∫ster puede equilibrarse en varias secciones para cada tema, lo que le permite utilizar intermediarios adicionales para aumentar la capacidad disponible en los casos en que la densidad de datos por intermediario no sea suficiente.  La decisi√≥n sobre cu√°nto espacio en disco se necesita tambi√©n est√° determinada por la estrategia de replicaci√≥n seleccionada para el cl√∫ster (discutido con m√°s detalle en el Cap√≠tulo 6). <br><br><h3>  El recuerdo </h3><br>  En el modo normal de operaci√≥n, el consumidor Kafka lee desde el final de la secci√≥n, y el consumidor compensa constantemente el tiempo perdido y solo ligeramente por detr√°s de los fabricantes, si es que lo hace.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al mismo tiempo, los mensajes le√≠dos por el consumidor se almacenan de manera √≥ptima en el cach√© de p√°ginas del sistema, de modo que las operaciones de lectura son m√°s r√°pidas que si el intermediario tuviera que volver a leerlas desde el disco. Por lo tanto, cuanto mayor sea la cantidad de RAM disponible para la memoria cach√© de la p√°gina, mayor ser√° el rendimiento de los clientes consumidores.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka en s√≠ no necesita asignar grandes cantidades de RAM en el mont√≥n para la JVM. </font><font style="vertical-align: inherit;">Incluso un agente que procesa X mensajes por segundo con una velocidad de transferencia de datos de X megabits por segundo puede funcionar con un mont√≥n de 5 GB. </font><font style="vertical-align: inherit;">La RAM restante del sistema se utilizar√° para la memoria cach√© de la p√°gina y beneficiar√° a Kafka debido a la capacidad de almacenar en cach√© los segmentos de registro utilizados. </font><font style="vertical-align: inherit;">Es por eso que no se recomienda colocar Kafka en un sistema donde ya se est√©n ejecutando otras aplicaciones importantes, ya que tendr√°n que compartir el cach√© de la p√°gina, lo que reducir√° la productividad de los consumidores de Kafka.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Datos de red </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La cantidad m√°xima de tr√°fico que Kafka puede manejar est√° determinada por el ancho de banda de red disponible. A menudo, este es un factor clave (junto con la cantidad de almacenamiento en disco) para elegir un tama√±o de cl√∫ster. Esta elecci√≥n se dificulta por el desequilibrio inherente de Kafka (debido al apoyo de varios consumidores) entre el tr√°fico de red entrante y saliente. Un productor puede generar 1 MB de mensajes por segundo para un tema determinado, pero el n√∫mero de consumidores puede llegar a ser cualquier cosa, agregando un factor apropiado para el tr√°fico saliente. Otras operaciones de red, como la replicaci√≥n de cl√∫ster (ver cap√≠tulo 6) y la duplicaci√≥n (discutida en el cap√≠tulo 8), aumentan los requisitos de red. Con el uso intensivo de la interfaz de red, el retraso de replicaci√≥n del cl√∫ster es bastante posible, lo que causar√° la inestabilidad de su estado.</font></font><br><br><h3>  CPU </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El poder de c√°lculo no es tan importante como el espacio en disco y la RAM, pero tambi√©n afecta en cierta medida el rendimiento general del agente. </font><font style="vertical-align: inherit;">Idealmente, los clientes deber√≠an comprimir los mensajes para optimizar el uso de la red y el disco. </font><font style="vertical-align: inherit;">Sin embargo, el agente de Kafka debe descomprimir todos los paquetes de mensajes para verificar las sumas de verificaci√≥n de mensajes individuales y asignar compensaciones. </font><font style="vertical-align: inherit;">Luego necesita comprimir el paquete de mensajes nuevamente para guardarlo en el disco. </font><font style="vertical-align: inherit;">Para eso es que Kafka necesita la mayor parte de su potencia inform√°tica. </font><font style="vertical-align: inherit;">Sin embargo, esto no debe considerarse como el factor principal en la elecci√≥n del hardware.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kafka en la nube </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka a menudo se instala en un entorno de computaci√≥n en la nube como Amazon Web Services (AWS). AWS proporciona muchos nodos inform√°ticos virtuales, todos con varias combinaciones de CPU, RAM y espacio en disco. Para seleccionar la configuraci√≥n de host virtual adecuada, primero debe considerar los factores de rendimiento de Kafka. Puede comenzar con la cantidad requerida de almacenamiento de datos y luego tener en cuenta el rendimiento requerido de los generadores. Si necesita una latencia muy baja, es posible que necesite nodos virtuales optimizados para E / S con almacenamiento local basado en SSD. De lo contrario, puede haber suficiente almacenamiento remoto (por ejemplo, AWS Elastic Block Store). Despu√©s de tomar estas decisiones, puede elegir entre las opciones disponibles para la CPU y la RAM.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En la pr√°ctica, esto significa que si AWS est√° habilitado, puede seleccionar nodos virtuales de los tipos m4 o r3. </font><font style="vertical-align: inherit;">Un nodo virtual de tipo m4 permite un almacenamiento m√°s largo, pero con menos ancho de banda para escribir en el disco, ya que se basa en el almacenamiento de bloques adaptativo. </font><font style="vertical-align: inherit;">El rendimiento de un nodo virtual como r3 es mucho mayor debido al uso de SSD locales, pero este √∫ltimo limita la cantidad de datos disponibles para el almacenamiento. </font><font style="vertical-align: inherit;">Las ventajas de ambas opciones combinan tipos significativamente m√°s caros de nodos virtuales i2 y d2.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kafka Clusters </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un servidor Kafka separado es muy adecuado para el desarrollo local o la creaci√≥n de prototipos de sistemas, pero la configuraci√≥n de varios intermediarios para trabajar juntos como un cl√∫ster es mucho m√°s rentable (Fig. 2.2). </font><font style="vertical-align: inherit;">El principal beneficio de esto es la capacidad de escalar la carga en m√∫ltiples servidores. </font><font style="vertical-align: inherit;">El segundo m√°s importante es la capacidad de usar la replicaci√≥n para proteger contra la p√©rdida de datos debido a fallas de sistemas individuales. </font><font style="vertical-align: inherit;">La replicaci√≥n tambi√©n brinda la capacidad de realizar trabajos de mantenimiento en un Kafka o sistema subyacente mientras se mantiene la accesibilidad del cliente. </font><font style="vertical-align: inherit;">En esta secci√≥n, solo consideraremos configurar el cl√∫ster de Kafka. </font><font style="vertical-align: inherit;">Para obtener m√°s informaci√≥n sobre la replicaci√≥n de datos, consulte el Cap√≠tulo 6.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vo/c-/cc/voc-cc5ywmwoh4ttiidnzt1gdk4.png" alt="imagen"></div><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øCu√°ntos corredores deber√≠an ser? </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El tama√±o del grupo Kafka est√° determinado por varios factores. El primero de ellos es la cantidad de espacio en disco requerido para almacenar mensajes y la cantidad de espacio disponible en un intermediario separado. Si un cl√∫ster necesita almacenar 10 TB de datos y un agente independiente puede almacenar 2 TB, entonces el tama√±o m√≠nimo del grupo es de cinco agentes. Adem√°s, el uso de la replicaci√≥n puede aumentar los requisitos de almacenamiento en al menos un 100% (dependiendo de su relaci√≥n) (consulte el Cap√≠tulo 6). Esto significa que cuando se usa la replicaci√≥n, el mismo cl√∫ster tendr√° que contener al menos diez intermediarios.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otro factor a considerar es la capacidad del cl√∫ster para procesar solicitudes. Por ejemplo, cu√°les son las capacidades de las interfaces de red y si pueden hacer frente al tr√°fico de clientes con m√∫ltiples consumidores de datos o fluctuaciones de tr√°fico durante el almacenamiento de datos (es decir, en caso de picos de tr√°fico durante los per√≠odos pico). Si la interfaz de red de un agente individual se utiliza al 80% en la carga m√°xima, y ‚Äã‚Äãhay dos consumidores de datos, entonces no podr√°n hacer frente al tr√°fico m√°ximo con menos de dos agentes. Si se usa la replicaci√≥n en un cl√∫ster, desempe√±a el papel de un consumidor de datos adicional que debe considerarse. Puede ser √∫til aumentar el n√∫mero de intermediarios en el cl√∫ster para lidiar con problemas de rendimiento causados ‚Äã‚Äãpor un menor rendimiento del disco o RAM disponible.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Configuraci√≥n de corredores </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Solo hay dos requisitos de configuraci√≥n para los corredores cuando trabajan como parte de un solo cl√∫ster de Kafka. </font><font style="vertical-align: inherit;">Primero, la configuraci√≥n de todos los corredores debe tener el mismo valor para el par√°metro zookeeper.connect. </font><font style="vertical-align: inherit;">Define el conjunto de ZooKeeper y la ruta de almacenamiento para el cl√∫ster de metadatos. </font><font style="vertical-align: inherit;">En segundo lugar, cada uno de los corredores de cl√∫ster debe tener un valor √∫nico para broker.id. </font><font style="vertical-align: inherit;">Si dos intermediarios con el mismo valor de broker.id intentan unirse al cl√∫ster, el segundo intermediario escribir√° un mensaje de error en el registro y no se iniciar√°. </font><font style="vertical-align: inherit;">Hay otros par√°metros de configuraci√≥n de intermediarios utilizados durante la operaci√≥n del cl√∫ster, a saber, los par√°metros para la gesti√≥n de replicaci√≥n descritos en los cap√≠tulos posteriores.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Afina el sistema operativo </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aunque la mayor√≠a de las distribuciones de Linux tienen configuraciones de configuraci√≥n de kernel preconfiguradas que son bastante buenas para la mayor√≠a de las aplicaciones, puede hacer algunos cambios para mejorar el rendimiento del agente Kafka. </font><font style="vertical-align: inherit;">B√°sicamente, se relacionan con los subsistemas de memoria virtual y la red, as√≠ como con puntos espec√≠ficos con respecto al punto de montaje del disco para guardar segmentos de los registros. </font><font style="vertical-align: inherit;">Estos par√°metros generalmente se configuran en el archivo /etc/sysctl.conf, pero es mejor consultar la documentaci√≥n de una distribuci√≥n de Linux espec√≠fica para conocer todos los matices de ajustar la configuraci√≥n del kernel.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Memoria virtual </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por lo general, el sistema de memoria virtual de Linux se ajusta a la carga del sistema. Pero puede hacer algunos ajustes al trabajo tanto con el √°rea de intercambio como con las p√°ginas de memoria "sucias", para adaptarlo mejor a los detalles de la carga de Kafka. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al igual que con la mayor√≠a de las aplicaciones, especialmente aquellas en las que el ancho de banda es importante, es mejor evitar el intercambio (casi) a toda costa. El costo de intercambiar p√°ginas de memoria al disco afecta significativamente todos los aspectos del rendimiento de Kafka. Adem√°s, Kafka usa activamente la memoria cach√© de la p√°gina del sistema, y ‚Äã‚Äãsi el subsistema de memoria virtual se est√° intercambiando en el disco, entonces la memoria cach√© de la p√°gina no tiene suficiente memoria.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una forma de evitar el intercambio es no asignarle espacio en la configuraci√≥n. La b√∫squeda no es un requisito obligatorio, sino un seguro en caso de cualquier accidente en el sistema. Puede evitar que el sistema interrumpa inesperadamente la ejecuci√≥n del proceso debido a la falta de memoria. Por lo tanto, se recomienda que el valor del par√°metro vm.swappiness sea muy peque√±o, por ejemplo 1. Este par√°metro representa la probabilidad (en porcentaje) de que el subsistema de memoria virtual use el intercambio en lugar de eliminar p√°ginas del cach√© de p√°ginas. Es mejor reducir el tama√±o de la memoria cach√© de la p√°gina que usar el intercambio.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tambi√©n tiene sentido corregir lo que hace el n√∫cleo del sistema con p√°ginas sucias que deben vaciarse en el disco. La capacidad de respuesta de Kafka a los fabricantes depende del rendimiento de las E / S de disco. Es por eso que los segmentos de registro generalmente se encuentran en discos r√°pidos: discos separados con tiempos de respuesta r√°pidos (por ejemplo, SSD) o subsistemas de disco con una gran cantidad de NVRAM para el almacenamiento en cach√© (por ejemplo, RAID). Como resultado, es posible reducir el n√∫mero de p√°ginas "sucias", al llegar a las cuales se inicia un volcado de fondo de ellas en el disco. Para hacer esto, establezca el par√°metro vm.dirty_background_ratio en un valor menor que el valor predeterminado (igual a 10). Significa una fracci√≥n de la memoria total del sistema (en porcentaje), y en muchos casos se puede establecer en 5. Sin embargo, no debe ser igual a 0,dado que en este caso el kernel vaciar√° continuamente las p√°ginas al disco y, por lo tanto, perder√° la capacidad de almacenar temporalmente las operaciones de escritura del disco con fluctuaciones temporales de rendimiento de los componentes de hardware subyacentes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El n√∫mero total de p√°ginas "sucias", cuando se excede, el n√∫cleo del sistema inicia por la fuerza el lanzamiento de operaciones s√≠ncronas para volcarlas en el disco, puede aumentarse aumentando el par√°metro vm.dirty_ratio a un valor que excede el valor predeterminado de 20 (tambi√©n un porcentaje de la memoria total del sistema ) Existe un amplio rango de valores posibles para este par√°metro, pero los m√°s razonables son entre 60 y 80. Cambiar este par√°metro es algo arriesgado en t√©rminos tanto del volumen de acciones que no se transfieren al disco como de la probabilidad de pausas de E / S prolongadas en caso de un inicio forzado de operaciones de reinicio sincr√≥nico. Al elegir valores m√°s altos para el par√°metro vm.dirty_ratio, se recomienda encarecidamente que utilice la replicaci√≥n en el cl√∫ster Kafka para protegerse contra fallas del sistema.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al elegir los valores de estos par√°metros, tiene sentido controlar el n√∫mero de p√°ginas "sucias" durante la operaci√≥n del cl√∫ster Kafka bajo carga durante la operaci√≥n industrial o la simulaci√≥n. Puede determinarlo mirando el archivo / proc / vmstat:</font></font><br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># cat /proc/vmstat | egrep </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"dirty|writeback"</span></span></span><span class="hljs-meta"> nr_dirty 3875 nr_writeback 29 nr_writeback_temp 0 #</span></span></code> </pre> <br><h3>  Conducir </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adem√°s de la elecci√≥n del hardware para el subsistema del disco duro, as√≠ como la configuraci√≥n de la matriz RAID si se usa, el sistema de archivos utilizado para estas unidades es el m√°s afectado. Hay muchos sistemas de archivos diferentes, pero EXT4 (cuarto sistema de archivos extendido - el cuarto sistema de archivos extendido) o XFS (Extents File System - el sistema de archivos basado en extensiones) se usa con mayor frecuencia como el local. EXT4 funciona bastante bien, pero requiere opciones de ajuste fino potencialmente inseguras. Entre ellos, establecer un intervalo de fijaci√≥n m√°s largo que el valor predeterminado (5), para reducir la frecuencia de descarga al disco. EXT4 tambi√©n introdujo la asignaci√≥n de bloques retrasados, lo que aumenta la probabilidad de p√©rdida de datos y da√±os en el sistema de archivos en caso de falla del sistema.El sistema de archivos XFS tambi√©n utiliza un algoritmo de asignaci√≥n diferido, pero es m√°s seguro que EXT4. El rendimiento de XFS para la carga t√≠pica de Kafka tambi√©n es mayor, y no hay necesidad de ajustarlo m√°s all√° del autom√°tico realizado por el propio sistema de archivos. Tambi√©n es m√°s eficiente con las escrituras de disco por lotes combinadas para aumentar el rendimiento de E / S.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Independientemente del sistema de archivos seleccionado como punto de montaje para los segmentos de registro, se recomienda que especifique la opci√≥n de montaje noatime. Los metadatos del archivo contienen tres marcas de fecha / hora: hora de creaci√≥n (ctime), √∫ltima hora de modificaci√≥n (mtime) y √∫ltimo archivo accedido (atime). Por defecto, el valor del atributo atime se actualiza cada vez que se lee un archivo. Esto aumenta significativamente el n√∫mero de escrituras en el disco. El atributo atime generalmente no es muy √∫til, a menos que la aplicaci√≥n necesite informaci√≥n sobre si se accedi√≥ al archivo despu√©s de su √∫ltimo cambio (en este caso, se puede aplicar el par√°metro en tiempo real). Kafka no utiliza el atributo atime en absoluto, por lo que puede deshabilitarlo de forma segura. Establecer el par√°metro noatime en un punto de montaje evita las actualizaciones de las marcas de fecha / hora,pero no afecta el manejo correcto de los atributos ctime y mtime.</font></font><br><br><h3>     </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ajustar la configuraci√≥n predeterminada de la pila de red de Linux es algo com√∫n para cualquier aplicaci√≥n que genere mucho tr√°fico de red, ya que el n√∫cleo predeterminado no es adecuado para la transmisi√≥n a alta velocidad de grandes cantidades de datos. De hecho, los cambios recomendados para Kafka no son diferentes de los recomendados para la mayor√≠a de los servidores web y otras aplicaciones de red. Primero, debe cambiar el tama√±o (predeterminado y m√°ximo) de la memoria asignada para las memorias intermedias de env√≠o y recepci√≥n para cada socket. Esto aumentar√° significativamente la productividad en caso de transferir grandes cantidades de datos. Los par√°metros correspondientes para las memorias intermedias de env√≠o y recepci√≥n predeterminadas para cada socket se denominan net.core.wmem_default y net.core.rmem_default, respectivamente, y un valor razonable es 2 097 152 (2 MB). Tener en cuentaque el tama√±o m√°ximo no significa asignar dicho espacio para cada b√∫fer, sino que solo le permite hacerlo si es necesario.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adem√°s de configurar sockets, debe establecer por separado los tama√±os de los buffers de env√≠o y recepci√≥n para los sockets TCP utilizando los par√°metros net.ipv4.tcp_wmem y net.ipv4.tcp_rmem. Incluyen tres enteros separados por espacios que definen el tama√±o m√≠nimo, el tama√±o predeterminado y el tama√±o m√°ximo, respectivamente. Un ejemplo de estos par√°metros, 4096 65536 2048000, significa que el tama√±o m√≠nimo del b√∫fer es de 4 KB, el tama√±o predeterminado es de 64 KB y el m√°ximo es de 2 MB. El tama√±o m√°ximo no puede exceder los valores especificados para todos los sockets por los par√°metros net.core.wmem_max y net.core.rmem_max. Dependiendo de la carga real de sus corredores, Kafka puede necesitar aumentar los valores m√°ximos para aumentar el almacenamiento en b√∫fer de las conexiones de red.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hay varios otros par√°metros de red √∫tiles. </font><font style="vertical-align: inherit;">Puede habilitar el escalado de la ventana TCP configurando el par√°metro net.ipv4.tcp_window_scaling en 1, lo que permitir√° a los clientes transferir datos de manera m√°s eficiente y proporcionar√° la capacidad de almacenar estos datos en el lado del intermediario. </font><font style="vertical-align: inherit;">El valor del par√°metro net.ipv4.tcp_max_syn_backlog es mayor que el valor predeterminado de 1024, lo que permite aumentar el n√∫mero de conexiones simult√°neas. </font><font style="vertical-align: inherit;">Un valor de net.core.netdev_max_backlog que excede el valor predeterminado de 1000 puede ayudar en caso de r√°fagas de tr√°fico de red, especialmente a velocidades de conexi√≥n de red del orden de gigabits, debido a un aumento en el n√∫mero de paquetes en cola para su posterior procesamiento por el n√∫cleo.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Explotaci√≥n industrial </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Cuando llegue el momento de llevar a Kafka de la prueba a la producci√≥n, solo hay algunas cosas m√°s para encargarse de establecer un servicio de mensajer√≠a confiable. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Opciones de recolecci√≥n de basura </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El ajuste fino de la recolecci√≥n de basura de Java para una aplicaci√≥n siempre ha sido una especie de arte, que requiere informaci√≥n detallada sobre el uso de la memoria de la aplicaci√≥n y una cantidad considerable de observaciones, prueba y error. Afortunadamente, esto ha cambiado desde el lanzamiento de Java 7 y el advenimiento del recolector de basura Garbage First (G1). G1 puede adaptarse autom√°ticamente a diferentes tipos de carga y garantizar la coherencia de las pausas para la recolecci√≥n de basura durante todo el ciclo de vida de la aplicaci√≥n. Tambi√©n maneja f√°cilmente una gran pila, ya que la divide en peque√±as zonas, en lugar de recolectar basura en todo el mont√≥n con cada pausa. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En funcionamiento normal, todo este G1 requiere una configuraci√≥n m√≠nima. Para ajustar su rendimiento, se utilizan dos par√°metros.</font></font><br><br><ul><li> MaxGCPauseMillis.         .     ‚Äî   G1    .      200 .  ,  G1       ,    ,    , ,      200 . </li><li> InitiatingHeapOccupancyPercent.        ,       .     45.  ,  G1       ,    45 % ,       (Eden),    . </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El agente de Kafka utiliza la memoria de almacenamiento din√°mico de manera muy eficiente y crea objetos, por lo que puede establecer valores m√°s bajos para estos par√°metros. </font><font style="vertical-align: inherit;">Los par√°metros de recolecci√≥n de basura dados en esta secci√≥n se consideran bastante adecuados para un servidor con 64 GB de RAM, donde Kafka trabaj√≥ con un mont√≥n de 5 GB. </font><font style="vertical-align: inherit;">Este intermediario podr√≠a funcionar con el valor 20 del par√°metro MaxGCPauseMillis. </font><font style="vertical-align: inherit;">Y el valor del par√°metro InitiatingHeapOccupancyPercent se establece en 35, de modo que la recolecci√≥n de basura se inicia un poco antes que en el valor predeterminado. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El script de inicio de Kafka no usa el recolector de basura G1 de manera predeterminada, sino un nuevo recolector de basura paralelo y un recolector de basura de etiquetado y limpieza competitivo. </font><font style="vertical-align: inherit;">Esto se puede cambiar f√°cilmente a trav√©s de variables de entorno. </font><font style="vertical-align: inherit;">Modificamos el comando de ejecuci√≥n anterior de la siguiente manera:</font></font><br><br><pre> <code class="hljs pgsql"># export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true" # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dise√±o del centro de datos </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuando se utilizan sistemas orientados al desarrollo, la ubicaci√≥n f√≠sica de los corredores de Kafka en el centro de datos no importa mucho, ya que la inaccesibilidad parcial o total del cl√∫ster por per√≠odos cortos de tiempo no afecta mucho el trabajo. Sin embargo, en la operaci√≥n industrial, un simple proceso de salida de datos significa la p√©rdida de dinero debido a la incapacidad de atender a los usuarios o recibir telemetr√≠a de sus acciones. Al mismo tiempo, la importancia de utilizar la replicaci√≥n en el cl√∫ster de Kafka (ver Cap√≠tulo 6), as√≠ como la ubicaci√≥n f√≠sica de los corredores en los bastidores del centro de datos, est√° creciendo. Si no se ocupa de esto antes de implementar Kafka, puede requerir un costoso trabajo de reubicaci√≥n del servidor.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El corredor de Kafka no sabe nada acerca de la colocaci√≥n del bastidor durante la asignaci√≥n de nuevas particiones a los corredores, lo que significa que no puede tener en cuenta la posible ubicaci√≥n de dos corredores en el mismo bastidor f√≠sico o en la misma zona de disponibilidad (cuando trabaja en un servicio en la nube, por ejemplo, AWS) Como resultado, puede poner accidentalmente todas las r√©plicas de una secci√≥n en correspondencia con los corredores que usan la misma red y conexiones de alimentaci√≥n en el mismo bastidor. En caso de falla de este bastidor, las secciones ser√°n inaccesibles para los clientes. Adem√°s, como resultado de elecciones "no limpias" del nodo maestro, esto puede conducir a una p√©rdida de datos adicional para la recuperaci√≥n (ver detalles en el Cap√≠tulo 6).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pr√°ctica recomendada: instalar cada agente Kafka en un cl√∫ster en un bastidor separado, o al menos usar varios puntos cr√≠ticos de servicios de infraestructura, como energ√≠a y red. </font><font style="vertical-align: inherit;">Por lo general, esto significa al menos el uso de servidores de energ√≠a de respaldo para los corredores (que se conectan a dos circuitos de suministro de energ√≠a diferentes) y conmutadores de red duales con una interfaz unificada a los servidores para cambiar a otra interfaz sin interrupciones. </font><font style="vertical-align: inherit;">De vez en cuando, puede ser necesario realizar mantenimiento en el hardware del bastidor o gabinete y apagarlos, por ejemplo, mover el servidor o reemplazar el cableado.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Hospedar aplicaciones en ZooKeeper </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka usa ZooKeeper para almacenar metadatos sobre corredores, temas y secciones. Escribir en ZooKeeper se realiza solo cuando se cambian las listas de miembros de grupos de consumidores o los cambios en el cl√∫ster Kafka. El volumen de tr√°fico es m√≠nimo, por lo que el uso de un conjunto ZooKeeper dedicado para un grupo Kafka no est√° justificado. De hecho, un conjunto de ZooKeeper a menudo se usa para varios grupos de Kafka (usando la nueva ruta ra√≠z de ZooKeeper para cada grupo, como se describi√≥ anteriormente en este cap√≠tulo).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sin embargo, cuando los consumidores y ZooKeeper trabajan con ciertas configuraciones, hay un matiz. Para corregir las compensaciones, los consumidores pueden usar ZooKeeper o Kafka, y el intervalo entre las fijaciones se puede ajustar. Si los consumidores usan ZooKeeper para las compensaciones, cada consumidor realizar√° una operaci√≥n de escritura ZooKeeper despu√©s de un tiempo espec√≠fico para cada secci√≥n que consume. El per√≠odo de tiempo habitual para corregir las compensaciones es de 1 minuto, ya que es despu√©s de este tiempo que un grupo de consumidores lee mensajes duplicados en caso de una falla del consumidor. Estas confirmaciones pueden constituir una parte significativa del tr√°fico de ZooKeeper, especialmente en un cl√∫ster con muchos consumidores, por lo que deben considerarse. Si el conjunto de ZooKeeper no puede manejar esta cantidad de tr√°fico, es posible que deba aumentar el intervalo de confirmaci√≥n. Sin embargo recomendadopara que los consumidores que trabajan con las bibliotecas actuales de Kafka utilicen Kafka para corregir las compensaciones y no dependan de ZooKeeper.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adem√°s de usar un conjunto para varios grupos de Kafka, no se recomienda compartir el conjunto con otras aplicaciones si se puede evitar. Kafka es muy sensible a la duraci√≥n del retraso y la latencia de ZooKeeper, y la interrupci√≥n de la comunicaci√≥n con el conjunto puede causar un comportamiento impredecible de los corredores. Como resultado, varios corredores pueden desconectarse al mismo tiempo en caso de p√©rdida de conexiones a ZooKeeper, lo que conducir√° a la desconexi√≥n de las particiones. Esto tambi√©n crear√° una carga adicional en el administrador de cl√∫ster, lo que puede causar errores no obvios durante mucho tiempo despu√©s de una falla de comunicaci√≥n, por ejemplo, cuando se intenta detener el intermediario de forma controlada. Otras aplicaciones que crean una carga en el administrador de cl√∫ster como resultado del uso activo o el funcionamiento incorrecto deben trasladarse a conjuntos separados.</font></font><br><br><h3>  Resumen </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En este cap√≠tulo, hablamos sobre c√≥mo instalar y ejecutar Apache Kafka. </font><font style="vertical-align: inherit;">Analizamos c√≥mo elegir el hardware adecuado para los corredores y descubrimos los problemas espec√≠ficos de la configuraci√≥n para la operaci√≥n industrial. </font><font style="vertical-align: inherit;">Ahora que tenemos un cl√∫ster de Kafka, podemos repasar los problemas b√°sicos de las aplicaciones cliente de Kafka. </font><font style="vertical-align: inherit;">Los pr√≥ximos dos cap√≠tulos se dedicar√°n a crear clientes tanto para generar mensajes para Kafka (cap√≠tulo 3) como para su consumo posterior (cap√≠tulo 4).</font></font><br><br>  ¬ªSe puede encontrar m√°s informaci√≥n sobre el libro en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el sitio web del editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Contenidos</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Extracto</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><br></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cup√≥n de 20% de descuento para Habrozhitelami - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apache Kafka</font></font></b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es421519/">https://habr.com/ru/post/es421519/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es421501/index.html">Hacker ha encontrado una manera de rastrear a los visitantes a los sitios de la competencia.</a></li>
<li><a href="../es421503/index.html">C√≥mo escribir instrucciones para ser entendido</a></li>
<li><a href="../es421505/index.html">Mini Life Hacks para trabajar con Yandex. Directo</a></li>
<li><a href="../es421507/index.html">¬øCu√°les fueron los soldadores para √≥ptica?</a></li>
<li><a href="../es421513/index.html">Introducci√≥n de scrum suave por parte de los propios desarrolladores (resolvemos las contradicciones, configuramos el equipo, evitamos conflictos)</a></li>
<li><a href="../es421521/index.html">Monstruos despu√©s de las vacaciones: AMD Threadripper 2990WX 32-Core y 2950X 16-Core (parte 3 - pruebas)</a></li>
<li><a href="../es421523/index.html">Unidad: conociendo los Objetos Scriptables</a></li>
<li><a href="../es421525/index.html">Un poco sobre las diferencias entre los hosteleros rusos y extranjeros</a></li>
<li><a href="../es421527/index.html">Lanzamiento de difusi√≥n del proyecto "Servidor en las nubes"</a></li>
<li><a href="../es421529/index.html">Netflix, Uber, Google y usted en MBLT DEV 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
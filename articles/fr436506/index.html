<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍🚀 🕴🏽 💆🏾 Comment créer un IA-raciste sans trop d'effort 👩🏽‍🎓 👨🏾‍🏫 💸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une leçon d'avertissement. 

 Faisons un classificateur de tonalité! 

 L'analyse des sentiments (analyse des sentiments) est une tâche très courante ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment créer un IA-raciste sans trop d'effort</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436506/"> Une leçon d'avertissement. <br><br>  <b>Faisons un classificateur de tonalité!</b> <br><br>  L'analyse des sentiments (analyse des sentiments) est une tâche très courante dans le traitement du langage naturel (PNL), et cela n'est pas surprenant.  Il est important pour une entreprise de comprendre ce que les gens disent: positif ou négatif.  Une telle analyse est utilisée pour surveiller les réseaux sociaux, les commentaires des clients et même dans le trading boursier algorithmique (en conséquence, les bots <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">achètent des actions Berkshire Hathaway après avoir publié des critiques positives sur le rôle d'Anne Hathaway dans le dernier film</a> ). <br><br>  La méthode d'analyse est parfois trop simplifiée, mais c'est l'un des moyens les plus simples d'obtenir des résultats mesurables.  Soumettez simplement le texte - et le résultat est positif et négatif.  Pas besoin de traiter l'arbre d'analyse, de construire un graphique ou une autre représentation complexe. <br><a name="habracut"></a><br>  Voilà ce que nous allons faire.  Nous suivrons la voie de la moindre résistance et ferons le classificateur le plus simple, qui semble probablement très familier à tous ceux qui sont impliqués dans des développements pertinents dans le domaine de la PNL.  Par exemple, un tel modèle peut être trouvé dans l'article <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  Nous n'essayons pas du tout de contester leurs résultats ou de critiquer le modèle;  nous donnons simplement une méthode bien connue de représentation vectorielle des mots. <br><br>  Plan de travail: <br><br><ul><li>  Introduire une <b>représentation vectorielle</b> typique <b>des mots</b> pour travailler avec des significations (significations). </li><li>  Introduisez <b>des ensembles de données de formation et de test</b> avec des listes standard de mots positifs et négatifs. </li><li>  <b>Entraînez</b> le <b>classificateur de</b> descente de gradient à reconnaître d'autres mots positifs et négatifs en fonction de leur représentation vectorielle. </li><li>  Utilisez ce classificateur pour calculer les <b>notes de tonalité</b> des phrases de texte. </li><li>  <b>Pour voir le monstre</b> que nous avons créé. </li></ul><br>  Et puis nous verrons, "comment créer un IA-raciste sans efforts particuliers."  Bien sûr, vous ne pouvez pas laisser le système sous une forme aussi monstrueuse, alors nous allons: <br><br><ul><li>  <b>Évaluer le problème</b> statistiquement, afin qu'il devienne possible de mesurer les progrès au fur et à mesure qu'il est résolu. </li><li>  <b>Améliorez les données</b> pour obtenir un modèle sémantique plus précis et moins raciste. </li></ul><br><h1>  Dépendances logicielles </h1><br>  Ce didacticiel est écrit en Python et repose sur une pile d'apprentissage machine Python typique: <code>numpy</code> et <code>scipy</code> pour l'informatique numérique, <code>pandas</code> pour la gestion des données et <code>scikit-learn</code> pour l'apprentissage machine.  Au final, nous <code>seaborn</code> également <code>matplotlib</code> et <code>seaborn</code> pour construire des diagrammes. <br><br>  En principe, <code>scikit-learn</code> peut être remplacé par TensorFlow ou Keras, ou quelque chose comme ça: ils sont également capables de former le classifieur en descente de gradient.  Mais nous n'avons pas besoin de leurs abstractions, car ici la formation se déroule en une seule étape. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment">#     %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  Étape 1. Représentation vectorielle des mots </h1><br>  Les représentations vectorielles sont souvent utilisées en cas de saisie de texte.  Les mots deviennent des vecteurs dans un espace multidimensionnel, où les vecteurs adjacents représentent des significations similaires.  En utilisant des représentations vectorielles, vous pouvez comparer les mots par (grossièrement) leur signification, et pas seulement par des correspondances exactes. <br><br>  Un apprentissage réussi nécessite des centaines de gigaoctets de texte.  Heureusement, diverses équipes de recherche ont déjà effectué ce travail et fourni des modèles pré-formés de représentations vectorielles disponibles en téléchargement. <br><br>  Les deux ensembles de données les plus connus pour la langue anglaise sont <b>word2vec</b> (formé sur les textes de Google News) et <b>GloVe</b> (sur les pages Web Common Crawl).  Chacun d'eux donnera un résultat similaire, mais nous prendrons le modèle GloVe car il a une source de données plus transparente. <br><br>  GloVe est disponible en trois tailles: 6 milliards, 42 milliards et 840 milliards. Le dernier modèle est le plus puissant, mais nécessite des ressources de traitement importantes.  La version de 42 milliards est assez bonne, et le dictionnaire est soigneusement coupé à 1 million de mots.  Nous sommes sur le chemin de la moindre résistance, alors prenez la version 42 milliards. <br><br><blockquote>  <b>- Pourquoi est-il si important d'utiliser un modèle «bien connu»?</b> <br><br>  "Je suis content que vous ayez posé des questions à ce sujet, hypothétique interlocuteur!"  À chaque étape, nous essayons de faire quelque chose d'extrêmement typique, et le meilleur modèle pour la représentation vectorielle des mots pour une raison quelconque n'a pas encore été déterminé.  J'espère que cet article suscitera le désir d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des modèles modernes de haute qualité</a> , en particulier ceux qui prennent en compte une erreur algorithmique et tentent de la corriger.  Cependant, plus à ce sujet plus tard. </blockquote><br>  Téléchargez glove.42B.300d.zip depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de GloVe</a> et extrayez le fichier <code>data/glove.42B.300d.txt</code> .  Ensuite, nous définissons une fonction de lecture des vecteurs dans un format simple. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""  DataFrame      ,   word2vec, GloVe, fastText  ConceptNet Numberbatch.            . """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  Étape 2. Dictionnaire de tonalité standard d'or </h1><br>  Maintenant, nous avons besoin d'informations sur les mots considérés comme positifs et ceux qui sont négatifs.  Il existe de nombreux dictionnaires de ce type, mais nous prendrons un dictionnaire très simple (Hu et Liu, 2004), qui est utilisé dans l'article de <i>Deep Averaging Networks</i> . <br><br>  Téléchargez le dictionnaire depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bing Liu</a> et extrayez les données dans <code>data/positive-words.txt</code> et <code>data/negative-words.txt</code> . <br><br>  Ensuite, nous déterminons comment lire ces fichiers et les affecter en tant que <code>neg_words</code> <code>pos_words</code> et <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""       (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)      Latin-1.      ,    - .    ,    ';'   ,   . """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  Étape 3. Nous formons le modèle pour prédire la tonalité </h1><br>  Sur la base des vecteurs de mots positifs et négatifs, nous utilisons la commande Pandas <code>.loc[]</code> pour rechercher des représentations vectorielles de tous les mots. <br><br>  Certains mots manquent dans le dictionnaire GloVe.  Le plus souvent, ce sont des fautes de frappe comme «fanciner».  Ici, nous voyons un tas de <code>NaN</code> , qui indique l'absence d'un vecteur, et supprimez-les avec la commande <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Nous créons maintenant des tableaux de données en entrée (représentations vectorielles) et en sortie (1 pour les mots positifs et -1 pour les négatifs).  Nous vérifions également que les vecteurs sont attachés aux mots afin de pouvoir interpréter les résultats. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Attends.</b>  <b>Certains mots ne sont ni positifs ni négatifs, ils sont neutres.</b>  <b>Ne faut-il pas créer une troisième classe pour les mots neutres?</b> <br><br>  "Je pense qu'il aurait été utile."  Plus tard, nous verrons quels problèmes surviennent en raison de l'attribution de la tonalité aux mots neutres.  Si nous pouvons identifier de manière fiable des mots neutres, alors il est tout à fait possible d'augmenter la complexité du classificateur à trois catégories.  Mais vous devez trouver un dictionnaire de mots neutres, car dans le dictionnaire de Liu, il n'y a que des mots positifs et négatifs. <br><br>  J'ai donc essayé ma version avec 800 exemples de mots et augmenté le poids pour prédire les mots neutres.  Mais les résultats finaux n'étaient pas très différents de ce que vous verrez maintenant. <br><br>  <b>- Comment cette liste distingue-t-elle les mots positifs et négatifs?</b>  <b>Cela ne dépend-il pas du contexte?</b> <br><br>  - Bonne question.  L'analyse des clés générales n'est pas aussi simple qu'il y paraît.  La frontière est assez arbitraire à certains endroits.  Dans cette liste, le mot «impudent» est marqué comme «mauvais» et «ambitieux» comme «bon».  «Bande dessinée» est mauvais et «drôle» est bon.  Un «remboursement» est bon, bien qu'il soit généralement mentionné dans un mauvais contexte lorsque vous devez de l'argent à quelqu'un ou que vous le devez. <br><br>  Tout le monde comprend que la tonalité est déterminée par le contexte, mais dans un modèle simple, vous devez ignorer le contexte et espérer que la tonalité moyenne sera devinée correctement. </blockquote><br>  En utilisant la fonction <code>train_test_split</code> , <code>train_test_split</code> divisons simultanément les vecteurs d'entrée, les valeurs de sortie et les étiquettes en données d'apprentissage et de test, tout en laissant 10% pour les tests. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Créez maintenant un classificateur et passez des vecteurs à travers les itérations.  Nous utilisons la fonction de perte logistique pour que le classificateur final puisse déduire la probabilité que le mot soit positif ou négatif. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  Nous évaluons le classificateur sur des vecteurs de test.  Il montre une précision de 95%.  Pas mal. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  Nous définissons la fonction de prédiction de tonalité pour certains mots, puis nous l'utilisons pour quelques exemples de données de test. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba  log-    predictions = model.predict_log_proba(vecs) #        #  log-    . return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) #  20      words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  tonalité </th></tr></thead><tbody><tr><th>  agiter </th><td>  -9,931679 </td></tr><tr><th>  interrompre </th><td>  -9,634706 </td></tr><tr><th>  fermement </th><td>  1.466919 </td></tr><tr><th>  imaginaire </th><td>  -2.989215 </td></tr><tr><th>  fiscalité </th><td>  0,468522 </td></tr><tr><th>  mondialement connu </th><td>  6.908561 </td></tr><tr><th>  bon marché </th><td>  9.237223 </td></tr><tr><th>  déception </th><td>  -8,737182 </td></tr><tr><th>  totalitaire </th><td>  -10,851580 </td></tr><tr><th>  belligérant </th><td>  -8.328674 </td></tr><tr><th>  se fige </th><td>  -8,456981 </td></tr><tr><th>  péché </th><td>  -7,839670 </td></tr><tr><th>  fragile </th><td>  -4.018289 </td></tr><tr><th>  dupe </th><td>  -4.309344 </td></tr><tr><th>  non résolu </th><td>  -2.816172 </td></tr><tr><th>  habilement </th><td>  2,333609 </td></tr><tr><th>  diabolise </th><td>  -2.102152 </td></tr><tr><th>  insouciant </th><td>  8.747150 </td></tr><tr><th>  impopulaire </th><td>  -7,887475 </td></tr><tr><th>  sympathiser </th><td>  1.790899 </td></tr></tbody></table><br>  On voit que le classificateur fonctionne.  Il a appris à généraliser la tonalité des mots en dehors des données d'entraînement. <br><br><h1>  Étape 4. Obtenez un score de tonalité pour le texte. </h1><br>  Il existe de nombreuses façons d'ajouter des vecteurs à une estimation globale.  Encore une fois, nous suivons le chemin de la moindre résistance, il suffit donc de prendre la valeur moyenne. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex  ,     (\w)   #   (.+?)    (\b).   #       . def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  Il y a beaucoup à demander pour l'optimisation: <br><br><ul><li>  Introduire une relation inverse entre le poids du mot et sa fréquence, de sorte que les mêmes prépositions n'affectent pas beaucoup la tonalité. </li><li>  Réglage pour que les phrases courtes ne se terminent pas par des valeurs de tonalité extrêmes. </li><li>  Phrases comptables. </li><li>  Un algorithme de segmentation de mots plus fiable que les apostrophes ne renversent pas. </li><li>  Comptabilisation des négatifs comme «non satisfait». </li></ul><br>  Mais tout nécessite un code supplémentaire et ne changera pas fondamentalement les résultats.  Au moins maintenant, vous pouvez comparer grossièrement différentes offres: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  Étape 5. Voici le monstre que nous avons créé </h1><br>  Toutes les phrases n'ont pas une tonalité prononcée.  Voyons ce qui se passe avec les phrases neutres: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  J'ai déjà rencontré un tel phénomène lors de l'analyse des avis de restaurants en tenant compte des représentations vectorielles des mots.  Sans raison apparente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">, tous les restaurants mexicains ont un score global inférieur</a> . <br><br>  Les représentations vectorielles capturent de subtiles différences sémantiques dans leur contexte.  Par conséquent, ils reflètent les préjugés de notre société. <br><br>  Voici quelques autres suggestions neutres: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Bon sang ... <br><br>  Le système associé aux noms des gens des sentiments complètement différents.  Vous pouvez consulter ces exemples et bien d'autres et voir que la tonalité est généralement plus élevée pour les noms stéréotypés blancs et inférieure pour les noms stéréotypés noirs. <br><br>  Ce test a été utilisé par Caliscan, Bryson et Narayanan dans leur article de recherche publié dans la revue <i>Science</i> en avril 2017.  Cela prouve que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sémantique du corpus linguistique contient les préjugés de la société</a> .  Nous utiliserons cette méthode. <br><br><h1>  Étape 6. Évaluation du problème </h1><br>  Nous voulons comprendre comment éviter de telles erreurs.  Passons plus de données dans le classificateur et mesurons statistiquement son «biais». <br><br>  Ici, nous avons quatre listes de noms qui reflètent des origines ethniques différentes, principalement aux États-Unis.  Les deux premiers sont des listes de noms à prédominance «blanche» et «noire», adaptés sur la base d'un article de Kaliskan et al. J'ai également ajouté des noms espagnols et musulmans de l'arabe et de l'ourdou. <br><br>  Ces données sont utilisées pour vérifier le biais de l'algorithme pendant le processus de construction de ConceptNet: elles peuvent être trouvées dans le module <code>conceptnet5.vectors.evaluation.bias</code> .  L'idée est d'étendre le dictionnaire à d'autres groupes ethniques, en tenant compte non seulement des noms, mais aussi des noms de famille. <br><br>  Voici les listes: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment">#           . 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], #         . 'Hispanic': [ 'Juan', 'José', 'Miguel', 'Luís', 'Jorge', 'Santiago', 'Matías', 'Sebastián', 'Mateo', 'Nicolás', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tomás', 'Juana', 'Ana', 'Luisa', 'María', 'Elena', 'Sofía', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], #       # ,   .     . # #          # -   .    #   ,    . # #       . 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  À l'aide de Pandas, nous compilerons un tableau des noms, de leur origine ethnique prédominante et de leur tonalité: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) #           return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Exemples de données: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  tonalité </th><th>  le groupe </th></tr></thead><tbody><tr><th>  mohammed </th><td>  0,834974 </td><td>  Arabe / Musulman </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  Arabe / Musulman </td></tr><tr><th>  terryl </th><td>  -2.858010 </td><td>  Noir </td></tr><tr><th>  josé </th><td>  0,432956 </td><td>  Hispanique </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hispanique </td></tr><tr><th>  écheveau </th><td>  0,391858 </td><td>  Blanc </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  Blanc </td></tr></tbody></table><br>  Nous allons faire un graphique de la distribution de la tonalité pour chaque nom. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  Ou sous forme d'histogramme avec des intervalles de confiance pour la moyenne de 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Enfin, exécutez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">package de</a> statistiques <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">statsmodels</a> sérieux.  Il montrera à quel point le biais de l'algorithme est important (avec un tas d'autres statistiques). <br><br><br>  <font color="gray">Résultats de la régression OLS</font> <br><table><tbody><tr><th>  Dep.  Variable: </th><td>  sentiment </td><th>  R au carré: </th><td>  0,208 </td></tr><tr><th>  Modèle: </th><td>  OLS </td><th>  Adj.  R au carré: </th><td>  0,192 </td></tr><tr><th>  Méthode: </th><td>  Les moindres carrés </td><th>  Statistique F: </th><td>  04/13 </td></tr><tr><th>  Date: </th><td>  Jeu, 13 juil 2017 </td><th>  Prob (statistique F): </th><td>  1.31e-07 </td></tr><tr><th>  Heure: </th><td>  11:31:17 </td><th>  Log-vraisemblance: </th><td>  -356,78 </td></tr><tr><th>  Non.  Observations: </th><td>  153 </td><th>  AIC: </th><td>  721,6 </td></tr><tr><th>  Résidus Df: </th><td>  149 </td><th>  BIC: </th><td>  733,7 </td></tr><tr><th>  Modèle Df: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Type de covariance: </th><td>  nonrobust </td><th></th><td></td></tr></tbody></table><br>  La statistique F est le rapport entre la variation entre les groupes et la variation au sein des groupes, qui peut être considérée comme une évaluation générale du biais. <br><br>  Immédiatement en dessous, il est indiqué la probabilité que nous voyions la statistique F maximale avec l'hypothèse nulle: c'est-à-dire en l'absence de différence entre les options comparées.  La probabilité est très, très faible.  Dans un article scientifique, nous qualifierions le résultat de "très statistiquement significatif". <br><br>  Nous devons améliorer la valeur F.  Le plus bas sera le mieux. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  Étape 7. Essayer d'autres données. </h1><br>  Nous avons maintenant la possibilité de mesurer numériquement le biais nocif du modèle.  Essayons de l'ajuster.  Pour ce faire, vous devez répéter un tas de choses qui n'étaient que des étapes distinctes dans un bloc-notes Python. <br><br>  Si j'écrivais du bon code, je n'utiliserais pas de variables globales telles que le <code>model</code> et les <code>embeddings</code> .  Mais le code spaghetti actuel vous permet de mieux examiner chaque étape et de comprendre ce qui se passe.  Nous réutilisons une partie du code et définissons au moins une fonction pour répéter certaines étapes: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""      . """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment">#        Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  Nous essayons word2vec </h3><br>  On peut supposer que seul GloVe a le problème.  Il y a probablement beaucoup de sites douteux dans la base de données Common Crawl et au moins 20 copies du dictionnaire urbain d'argot de rue.  Peut-être que sur une base différente, ce sera mieux: qu'en est-il du bon vieux word2vec formé sur Google News? <br><br>  Il semble que la source la plus fiable pour les données word2vec soit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce fichier sur Google Drive</a> .  Téléchargez-le et enregistrez-le sous <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   ConceptNet   word2vec   Pandas     from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) #  word2vec    w2v.index = [label.casefold() for label in w2v.index] #  ,    w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  Word2vec s'est donc avéré encore pire avec une valeur F supérieure à 15. <br><br>  En principe, il était insensé de s'attendre à ce que les <i>informations</i> soient mieux protégées contre les biais. <br><br><h3>  Essayer ConceptNet Numberbatch </h3><br>  Enfin, je peux parler de mon propre projet sur la représentation vectorielle des mots. <br><br>  ConceptNet avec la fonction de présentation vectorielle est le graphe de connaissances sur lequel je travaille.  Il normalise les représentations vectorielles au stade de la formation, identifiant et supprimant certaines sources de racisme et de sexisme algorithmiques.  Cette méthode de correction du biais est basée sur un article scientifique de Bulukbashi et al. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">«Debiasing Word Embeddings»</a> et est généralisée pour éliminer plusieurs types de biais en même temps.  À ma connaissance, c'est le seul système sémantique dans lequel il y a quelque chose comme ça. <br><br>  De temps en temps, nous exportons des vecteurs précalculés depuis ConceptNet - ces versions sont appelées <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ConceptNet Numberbatch</a> .  En avril 2017, la première version avec correction du biais a été publiée, nous allons donc charger les vecteurs de langue anglaise et recycler notre modèle. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , l'enregistrons dans le répertoire <code>data/</code> et recyclons le modèle: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  Alors, ConceptNet Numberbatch a-t-il complètement résolu le problème?  Plus de racisme algorithmique?  <b>Non.</b> <br><br>  Le racisme est-il devenu beaucoup moins?  <b>Certainement</b> . <br><br>  Les plages de clés pour les groupes ethniques se chevauchent beaucoup plus que dans les vecteurs GloVe ou word2vec.  Par rapport à GloVe, la valeur de F a diminué de plus de trois fois, et par rapport à word2vec - de plus de quatre fois.  Et en général, nous voyons des différences de tonalité beaucoup plus petites lors de la comparaison de différents noms: cela devrait être le cas, car les noms ne devraient vraiment pas affecter le résultat de l'analyse. <br><br>  Mais une légère corrélation subsiste.  Je peux peut-être récupérer des données et des paramètres d'entraînement tels que le problème semble être résolu.  Mais ce sera une mauvaise option, car <i>en fait le</i> problème demeure, car dans ConceptNet nous n'avons pas identifié et compensé toutes les causes du racisme algorithmique.  Mais c'est un bon début. <br><br><h3>  Pas d'embûches </h3><br>  Veuillez noter qu'avec le passage à ConceptNet Numberbatch, la précision de la prédiction de la tonalité s'est améliorée. <br><br>  Quelqu'un aurait pu suggérer que la correction du racisme algorithmique aggraverait les résultats d'une autre manière.  Mais non.  Vous pouvez avoir des données meilleures et moins racistes.      .     word2vec  GloVe        . <br><br><h1>   </h1><br> ,      . -    . <br><br>                . ,         . <br><br>         ,        . ,       —    .      ,    .         (recall),         —   . <br><br>                    ,   -   .    .   ,   ,   . ,       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr436506/">https://habr.com/ru/post/fr436506/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr436496/index.html">PVS-Studio pour Java</a></li>
<li><a href="../fr436498/index.html">Software AG: pas seulement ARIS</a></li>
<li><a href="../fr436500/index.html">Comment le cadre de Rise of the Tomb Raider est rendu</a></li>
<li><a href="../fr436502/index.html">Abonnement Pampers ou comment vendre plus aux mêmes clients</a></li>
<li><a href="../fr436504/index.html">Système en emballage ou contenu de l'emballage sous puce?</a></li>
<li><a href="../fr436508/index.html">10 millions de dollars d'investissements et les louanges de Wozniak - créer un ordinateur éducatif pour les enfants</a></li>
<li><a href="../fr436510/index.html">Données de base en détail</a></li>
<li><a href="../fr436512/index.html">Comment nous trouvons les versions problématiques avec Graphite et Moira. Découvrez Yandex.Money</a></li>
<li><a href="../fr436514/index.html">Créer des histoires pour Instagram à partir de PHP</a></li>
<li><a href="../fr436518/index.html">Haiku β1 - rendre le / b / OS génial à nouveau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚ÄçüöÄ üï¥üèΩ üíÜüèæ Comment cr√©er un IA-raciste sans trop d'effort üë©üèΩ‚Äçüéì üë®üèæ‚Äçüè´ üí∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une le√ßon d'avertissement. 

 Faisons un classificateur de tonalit√©! 

 L'analyse des sentiments (analyse des sentiments) est une t√¢che tr√®s courante ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment cr√©er un IA-raciste sans trop d'effort</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436506/"> Une le√ßon d'avertissement. <br><br>  <b>Faisons un classificateur de tonalit√©!</b> <br><br>  L'analyse des sentiments (analyse des sentiments) est une t√¢che tr√®s courante dans le traitement du langage naturel (PNL), et cela n'est pas surprenant.  Il est important pour une entreprise de comprendre ce que les gens disent: positif ou n√©gatif.  Une telle analyse est utilis√©e pour surveiller les r√©seaux sociaux, les commentaires des clients et m√™me dans le trading boursier algorithmique (en cons√©quence, les bots <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ach√®tent des actions Berkshire Hathaway apr√®s avoir publi√© des critiques positives sur le r√¥le d'Anne Hathaway dans le dernier film</a> ). <br><br>  La m√©thode d'analyse est parfois trop simplifi√©e, mais c'est l'un des moyens les plus simples d'obtenir des r√©sultats mesurables.  Soumettez simplement le texte - et le r√©sultat est positif et n√©gatif.  Pas besoin de traiter l'arbre d'analyse, de construire un graphique ou une autre repr√©sentation complexe. <br><a name="habracut"></a><br>  Voil√† ce que nous allons faire.  Nous suivrons la voie de la moindre r√©sistance et ferons le classificateur le plus simple, qui semble probablement tr√®s familier √† tous ceux qui sont impliqu√©s dans des d√©veloppements pertinents dans le domaine de la PNL.  Par exemple, un tel mod√®le peut √™tre trouv√© dans l'article <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  Nous n'essayons pas du tout de contester leurs r√©sultats ou de critiquer le mod√®le;  nous donnons simplement une m√©thode bien connue de repr√©sentation vectorielle des mots. <br><br>  Plan de travail: <br><br><ul><li>  Introduire une <b>repr√©sentation vectorielle</b> typique <b>des mots</b> pour travailler avec des significations (significations). </li><li>  Introduisez <b>des ensembles de donn√©es de formation et de test</b> avec des listes standard de mots positifs et n√©gatifs. </li><li>  <b>Entra√Ænez</b> le <b>classificateur de</b> descente de gradient √† reconna√Ætre d'autres mots positifs et n√©gatifs en fonction de leur repr√©sentation vectorielle. </li><li>  Utilisez ce classificateur pour calculer les <b>notes de tonalit√©</b> des phrases de texte. </li><li>  <b>Pour voir le monstre</b> que nous avons cr√©√©. </li></ul><br>  Et puis nous verrons, "comment cr√©er un IA-raciste sans efforts particuliers."  Bien s√ªr, vous ne pouvez pas laisser le syst√®me sous une forme aussi monstrueuse, alors nous allons: <br><br><ul><li>  <b>√âvaluer le probl√®me</b> statistiquement, afin qu'il devienne possible de mesurer les progr√®s au fur et √† mesure qu'il est r√©solu. </li><li>  <b>Am√©liorez les donn√©es</b> pour obtenir un mod√®le s√©mantique plus pr√©cis et moins raciste. </li></ul><br><h1>  D√©pendances logicielles </h1><br>  Ce didacticiel est √©crit en Python et repose sur une pile d'apprentissage machine Python typique: <code>numpy</code> et <code>scipy</code> pour l'informatique num√©rique, <code>pandas</code> pour la gestion des donn√©es et <code>scikit-learn</code> pour l'apprentissage machine.  Au final, nous <code>seaborn</code> √©galement <code>matplotlib</code> et <code>seaborn</code> pour construire des diagrammes. <br><br>  En principe, <code>scikit-learn</code> peut √™tre remplac√© par TensorFlow ou Keras, ou quelque chose comme √ßa: ils sont √©galement capables de former le classifieur en descente de gradient.  Mais nous n'avons pas besoin de leurs abstractions, car ici la formation se d√©roule en une seule √©tape. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment">#     %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  √âtape 1. Repr√©sentation vectorielle des mots </h1><br>  Les repr√©sentations vectorielles sont souvent utilis√©es en cas de saisie de texte.  Les mots deviennent des vecteurs dans un espace multidimensionnel, o√π les vecteurs adjacents repr√©sentent des significations similaires.  En utilisant des repr√©sentations vectorielles, vous pouvez comparer les mots par (grossi√®rement) leur signification, et pas seulement par des correspondances exactes. <br><br>  Un apprentissage r√©ussi n√©cessite des centaines de gigaoctets de texte.  Heureusement, diverses √©quipes de recherche ont d√©j√† effectu√© ce travail et fourni des mod√®les pr√©-form√©s de repr√©sentations vectorielles disponibles en t√©l√©chargement. <br><br>  Les deux ensembles de donn√©es les plus connus pour la langue anglaise sont <b>word2vec</b> (form√© sur les textes de Google News) et <b>GloVe</b> (sur les pages Web Common Crawl).  Chacun d'eux donnera un r√©sultat similaire, mais nous prendrons le mod√®le GloVe car il a une source de donn√©es plus transparente. <br><br>  GloVe est disponible en trois tailles: 6 milliards, 42 milliards et 840 milliards. Le dernier mod√®le est le plus puissant, mais n√©cessite des ressources de traitement importantes.  La version de 42 milliards est assez bonne, et le dictionnaire est soigneusement coup√© √† 1 million de mots.  Nous sommes sur le chemin de la moindre r√©sistance, alors prenez la version 42 milliards. <br><br><blockquote>  <b>- Pourquoi est-il si important d'utiliser un mod√®le ¬´bien connu¬ª?</b> <br><br>  "Je suis content que vous ayez pos√© des questions √† ce sujet, hypoth√©tique interlocuteur!"  √Ä chaque √©tape, nous essayons de faire quelque chose d'extr√™mement typique, et le meilleur mod√®le pour la repr√©sentation vectorielle des mots pour une raison quelconque n'a pas encore √©t√© d√©termin√©.  J'esp√®re que cet article suscitera le d√©sir d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des mod√®les modernes de haute qualit√©</a> , en particulier ceux qui prennent en compte une erreur algorithmique et tentent de la corriger.  Cependant, plus √† ce sujet plus tard. </blockquote><br>  T√©l√©chargez glove.42B.300d.zip depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de GloVe</a> et extrayez le fichier <code>data/glove.42B.300d.txt</code> .  Ensuite, nous d√©finissons une fonction de lecture des vecteurs dans un format simple. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""  DataFrame      ,   word2vec, GloVe, fastText  ConceptNet Numberbatch.            . """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  √âtape 2. Dictionnaire de tonalit√© standard d'or </h1><br>  Maintenant, nous avons besoin d'informations sur les mots consid√©r√©s comme positifs et ceux qui sont n√©gatifs.  Il existe de nombreux dictionnaires de ce type, mais nous prendrons un dictionnaire tr√®s simple (Hu et Liu, 2004), qui est utilis√© dans l'article de <i>Deep Averaging Networks</i> . <br><br>  T√©l√©chargez le dictionnaire depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bing Liu</a> et extrayez les donn√©es dans <code>data/positive-words.txt</code> et <code>data/negative-words.txt</code> . <br><br>  Ensuite, nous d√©terminons comment lire ces fichiers et les affecter en tant que <code>neg_words</code> <code>pos_words</code> et <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""       (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)      Latin-1.      ,    - .    ,    ';'   ,   . """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  √âtape 3. Nous formons le mod√®le pour pr√©dire la tonalit√© </h1><br>  Sur la base des vecteurs de mots positifs et n√©gatifs, nous utilisons la commande Pandas <code>.loc[]</code> pour rechercher des repr√©sentations vectorielles de tous les mots. <br><br>  Certains mots manquent dans le dictionnaire GloVe.  Le plus souvent, ce sont des fautes de frappe comme ¬´fanciner¬ª.  Ici, nous voyons un tas de <code>NaN</code> , qui indique l'absence d'un vecteur, et supprimez-les avec la commande <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Nous cr√©ons maintenant des tableaux de donn√©es en entr√©e (repr√©sentations vectorielles) et en sortie (1 pour les mots positifs et -1 pour les n√©gatifs).  Nous v√©rifions √©galement que les vecteurs sont attach√©s aux mots afin de pouvoir interpr√©ter les r√©sultats. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Attends.</b>  <b>Certains mots ne sont ni positifs ni n√©gatifs, ils sont neutres.</b>  <b>Ne faut-il pas cr√©er une troisi√®me classe pour les mots neutres?</b> <br><br>  "Je pense qu'il aurait √©t√© utile."  Plus tard, nous verrons quels probl√®mes surviennent en raison de l'attribution de la tonalit√© aux mots neutres.  Si nous pouvons identifier de mani√®re fiable des mots neutres, alors il est tout √† fait possible d'augmenter la complexit√© du classificateur √† trois cat√©gories.  Mais vous devez trouver un dictionnaire de mots neutres, car dans le dictionnaire de Liu, il n'y a que des mots positifs et n√©gatifs. <br><br>  J'ai donc essay√© ma version avec 800 exemples de mots et augment√© le poids pour pr√©dire les mots neutres.  Mais les r√©sultats finaux n'√©taient pas tr√®s diff√©rents de ce que vous verrez maintenant. <br><br>  <b>- Comment cette liste distingue-t-elle les mots positifs et n√©gatifs?</b>  <b>Cela ne d√©pend-il pas du contexte?</b> <br><br>  - Bonne question.  L'analyse des cl√©s g√©n√©rales n'est pas aussi simple qu'il y para√Æt.  La fronti√®re est assez arbitraire √† certains endroits.  Dans cette liste, le mot ¬´impudent¬ª est marqu√© comme ¬´mauvais¬ª et ¬´ambitieux¬ª comme ¬´bon¬ª.  ¬´Bande dessin√©e¬ª est mauvais et ¬´dr√¥le¬ª est bon.  Un ¬´remboursement¬ª est bon, bien qu'il soit g√©n√©ralement mentionn√© dans un mauvais contexte lorsque vous devez de l'argent √† quelqu'un ou que vous le devez. <br><br>  Tout le monde comprend que la tonalit√© est d√©termin√©e par le contexte, mais dans un mod√®le simple, vous devez ignorer le contexte et esp√©rer que la tonalit√© moyenne sera devin√©e correctement. </blockquote><br>  En utilisant la fonction <code>train_test_split</code> , <code>train_test_split</code> divisons simultan√©ment les vecteurs d'entr√©e, les valeurs de sortie et les √©tiquettes en donn√©es d'apprentissage et de test, tout en laissant 10% pour les tests. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Cr√©ez maintenant un classificateur et passez des vecteurs √† travers les it√©rations.  Nous utilisons la fonction de perte logistique pour que le classificateur final puisse d√©duire la probabilit√© que le mot soit positif ou n√©gatif. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  Nous √©valuons le classificateur sur des vecteurs de test.  Il montre une pr√©cision de 95%.  Pas mal. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  Nous d√©finissons la fonction de pr√©diction de tonalit√© pour certains mots, puis nous l'utilisons pour quelques exemples de donn√©es de test. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba  log-    predictions = model.predict_log_proba(vecs) #        #  log-    . return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) #  20      words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  tonalit√© </th></tr></thead><tbody><tr><th>  agiter </th><td>  -9,931679 </td></tr><tr><th>  interrompre </th><td>  -9,634706 </td></tr><tr><th>  fermement </th><td>  1.466919 </td></tr><tr><th>  imaginaire </th><td>  -2.989215 </td></tr><tr><th>  fiscalit√© </th><td>  0,468522 </td></tr><tr><th>  mondialement connu </th><td>  6.908561 </td></tr><tr><th>  bon march√© </th><td>  9.237223 </td></tr><tr><th>  d√©ception </th><td>  -8,737182 </td></tr><tr><th>  totalitaire </th><td>  -10,851580 </td></tr><tr><th>  bellig√©rant </th><td>  -8.328674 </td></tr><tr><th>  se fige </th><td>  -8,456981 </td></tr><tr><th>  p√©ch√© </th><td>  -7,839670 </td></tr><tr><th>  fragile </th><td>  -4.018289 </td></tr><tr><th>  dupe </th><td>  -4.309344 </td></tr><tr><th>  non r√©solu </th><td>  -2.816172 </td></tr><tr><th>  habilement </th><td>  2,333609 </td></tr><tr><th>  diabolise </th><td>  -2.102152 </td></tr><tr><th>  insouciant </th><td>  8.747150 </td></tr><tr><th>  impopulaire </th><td>  -7,887475 </td></tr><tr><th>  sympathiser </th><td>  1.790899 </td></tr></tbody></table><br>  On voit que le classificateur fonctionne.  Il a appris √† g√©n√©raliser la tonalit√© des mots en dehors des donn√©es d'entra√Ænement. <br><br><h1>  √âtape 4. Obtenez un score de tonalit√© pour le texte. </h1><br>  Il existe de nombreuses fa√ßons d'ajouter des vecteurs √† une estimation globale.  Encore une fois, nous suivons le chemin de la moindre r√©sistance, il suffit donc de prendre la valeur moyenne. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex  ,     (\w)   #   (.+?)    (\b).   #       . def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  Il y a beaucoup √† demander pour l'optimisation: <br><br><ul><li>  Introduire une relation inverse entre le poids du mot et sa fr√©quence, de sorte que les m√™mes pr√©positions n'affectent pas beaucoup la tonalit√©. </li><li>  R√©glage pour que les phrases courtes ne se terminent pas par des valeurs de tonalit√© extr√™mes. </li><li>  Phrases comptables. </li><li>  Un algorithme de segmentation de mots plus fiable que les apostrophes ne renversent pas. </li><li>  Comptabilisation des n√©gatifs comme ¬´non satisfait¬ª. </li></ul><br>  Mais tout n√©cessite un code suppl√©mentaire et ne changera pas fondamentalement les r√©sultats.  Au moins maintenant, vous pouvez comparer grossi√®rement diff√©rentes offres: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  √âtape 5. Voici le monstre que nous avons cr√©√© </h1><br>  Toutes les phrases n'ont pas une tonalit√© prononc√©e.  Voyons ce qui se passe avec les phrases neutres: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  J'ai d√©j√† rencontr√© un tel ph√©nom√®ne lors de l'analyse des avis de restaurants en tenant compte des repr√©sentations vectorielles des mots.  Sans raison apparente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">, tous les restaurants mexicains ont un score global inf√©rieur</a> . <br><br>  Les repr√©sentations vectorielles capturent de subtiles diff√©rences s√©mantiques dans leur contexte.  Par cons√©quent, ils refl√®tent les pr√©jug√©s de notre soci√©t√©. <br><br>  Voici quelques autres suggestions neutres: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Bon sang ... <br><br>  Le syst√®me associ√© aux noms des gens des sentiments compl√®tement diff√©rents.  Vous pouvez consulter ces exemples et bien d'autres et voir que la tonalit√© est g√©n√©ralement plus √©lev√©e pour les noms st√©r√©otyp√©s blancs et inf√©rieure pour les noms st√©r√©otyp√©s noirs. <br><br>  Ce test a √©t√© utilis√© par Caliscan, Bryson et Narayanan dans leur article de recherche publi√© dans la revue <i>Science</i> en avril 2017.  Cela prouve que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">s√©mantique du corpus linguistique contient les pr√©jug√©s de la soci√©t√©</a> .  Nous utiliserons cette m√©thode. <br><br><h1>  √âtape 6. √âvaluation du probl√®me </h1><br>  Nous voulons comprendre comment √©viter de telles erreurs.  Passons plus de donn√©es dans le classificateur et mesurons statistiquement son ¬´biais¬ª. <br><br>  Ici, nous avons quatre listes de noms qui refl√®tent des origines ethniques diff√©rentes, principalement aux √âtats-Unis.  Les deux premiers sont des listes de noms √† pr√©dominance ¬´blanche¬ª et ¬´noire¬ª, adapt√©s sur la base d'un article de Kaliskan et al. J'ai √©galement ajout√© des noms espagnols et musulmans de l'arabe et de l'ourdou. <br><br>  Ces donn√©es sont utilis√©es pour v√©rifier le biais de l'algorithme pendant le processus de construction de ConceptNet: elles peuvent √™tre trouv√©es dans le module <code>conceptnet5.vectors.evaluation.bias</code> .  L'id√©e est d'√©tendre le dictionnaire √† d'autres groupes ethniques, en tenant compte non seulement des noms, mais aussi des noms de famille. <br><br>  Voici les listes: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment">#           . 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], #         . 'Hispanic': [ 'Juan', 'Jos√©', 'Miguel', 'Lu√≠s', 'Jorge', 'Santiago', 'Mat√≠as', 'Sebasti√°n', 'Mateo', 'Nicol√°s', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tom√°s', 'Juana', 'Ana', 'Luisa', 'Mar√≠a', 'Elena', 'Sof√≠a', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], #       # ,   .     . # #          # -   .    #   ,    . # #       . 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  √Ä l'aide de Pandas, nous compilerons un tableau des noms, de leur origine ethnique pr√©dominante et de leur tonalit√©: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) #           return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Exemples de donn√©es: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  tonalit√© </th><th>  le groupe </th></tr></thead><tbody><tr><th>  mohammed </th><td>  0,834974 </td><td>  Arabe / Musulman </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  Arabe / Musulman </td></tr><tr><th>  terryl </th><td>  -2.858010 </td><td>  Noir </td></tr><tr><th>  jos√© </th><td>  0,432956 </td><td>  Hispanique </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hispanique </td></tr><tr><th>  √©cheveau </th><td>  0,391858 </td><td>  Blanc </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  Blanc </td></tr></tbody></table><br>  Nous allons faire un graphique de la distribution de la tonalit√© pour chaque nom. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  Ou sous forme d'histogramme avec des intervalles de confiance pour la moyenne de 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Enfin, ex√©cutez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">package de</a> statistiques <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">statsmodels</a> s√©rieux.  Il montrera √† quel point le biais de l'algorithme est important (avec un tas d'autres statistiques). <br><br><br>  <font color="gray">R√©sultats de la r√©gression OLS</font> <br><table><tbody><tr><th>  Dep.  Variable: </th><td>  sentiment </td><th>  R au carr√©: </th><td>  0,208 </td></tr><tr><th>  Mod√®le: </th><td>  OLS </td><th>  Adj.  R au carr√©: </th><td>  0,192 </td></tr><tr><th>  M√©thode: </th><td>  Les moindres carr√©s </td><th>  Statistique F: </th><td>  04/13 </td></tr><tr><th>  Date: </th><td>  Jeu, 13 juil 2017 </td><th>  Prob (statistique F): </th><td>  1.31e-07 </td></tr><tr><th>  Heure: </th><td>  11:31:17 </td><th>  Log-vraisemblance: </th><td>  -356,78 </td></tr><tr><th>  Non.  Observations: </th><td>  153 </td><th>  AIC: </th><td>  721,6 </td></tr><tr><th>  R√©sidus Df: </th><td>  149 </td><th>  BIC: </th><td>  733,7 </td></tr><tr><th>  Mod√®le Df: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Type de covariance: </th><td>  nonrobust </td><th></th><td></td></tr></tbody></table><br>  La statistique F est le rapport entre la variation entre les groupes et la variation au sein des groupes, qui peut √™tre consid√©r√©e comme une √©valuation g√©n√©rale du biais. <br><br>  Imm√©diatement en dessous, il est indiqu√© la probabilit√© que nous voyions la statistique F maximale avec l'hypoth√®se nulle: c'est-√†-dire en l'absence de diff√©rence entre les options compar√©es.  La probabilit√© est tr√®s, tr√®s faible.  Dans un article scientifique, nous qualifierions le r√©sultat de "tr√®s statistiquement significatif". <br><br>  Nous devons am√©liorer la valeur F.  Le plus bas sera le mieux. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  √âtape 7. Essayer d'autres donn√©es. </h1><br>  Nous avons maintenant la possibilit√© de mesurer num√©riquement le biais nocif du mod√®le.  Essayons de l'ajuster.  Pour ce faire, vous devez r√©p√©ter un tas de choses qui n'√©taient que des √©tapes distinctes dans un bloc-notes Python. <br><br>  Si j'√©crivais du bon code, je n'utiliserais pas de variables globales telles que le <code>model</code> et les <code>embeddings</code> .  Mais le code spaghetti actuel vous permet de mieux examiner chaque √©tape et de comprendre ce qui se passe.  Nous r√©utilisons une partie du code et d√©finissons au moins une fonction pour r√©p√©ter certaines √©tapes: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""      . """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment">#        Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  Nous essayons word2vec </h3><br>  On peut supposer que seul GloVe a le probl√®me.  Il y a probablement beaucoup de sites douteux dans la base de donn√©es Common Crawl et au moins 20 copies du dictionnaire urbain d'argot de rue.  Peut-√™tre que sur une base diff√©rente, ce sera mieux: qu'en est-il du bon vieux word2vec form√© sur Google News? <br><br>  Il semble que la source la plus fiable pour les donn√©es word2vec soit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce fichier sur Google Drive</a> .  T√©l√©chargez-le et enregistrez-le sous <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   ConceptNet   word2vec   Pandas     from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) #  word2vec    w2v.index = [label.casefold() for label in w2v.index] #  ,    w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  Word2vec s'est donc av√©r√© encore pire avec une valeur F sup√©rieure √† 15. <br><br>  En principe, il √©tait insens√© de s'attendre √† ce que les <i>informations</i> soient mieux prot√©g√©es contre les biais. <br><br><h3>  Essayer ConceptNet Numberbatch </h3><br>  Enfin, je peux parler de mon propre projet sur la repr√©sentation vectorielle des mots. <br><br>  ConceptNet avec la fonction de pr√©sentation vectorielle est le graphe de connaissances sur lequel je travaille.  Il normalise les repr√©sentations vectorielles au stade de la formation, identifiant et supprimant certaines sources de racisme et de sexisme algorithmiques.  Cette m√©thode de correction du biais est bas√©e sur un article scientifique de Bulukbashi et al. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Debiasing Word Embeddings¬ª</a> et est g√©n√©ralis√©e pour √©liminer plusieurs types de biais en m√™me temps.  √Ä ma connaissance, c'est le seul syst√®me s√©mantique dans lequel il y a quelque chose comme √ßa. <br><br>  De temps en temps, nous exportons des vecteurs pr√©calcul√©s depuis ConceptNet - ces versions sont appel√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ConceptNet Numberbatch</a> .  En avril 2017, la premi√®re version avec correction du biais a √©t√© publi√©e, nous allons donc charger les vecteurs de langue anglaise et recycler notre mod√®le. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , l'enregistrons dans le r√©pertoire <code>data/</code> et recyclons le mod√®le: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  Alors, ConceptNet Numberbatch a-t-il compl√®tement r√©solu le probl√®me?  Plus de racisme algorithmique?  <b>Non.</b> <br><br>  Le racisme est-il devenu beaucoup moins?  <b>Certainement</b> . <br><br>  Les plages de cl√©s pour les groupes ethniques se chevauchent beaucoup plus que dans les vecteurs GloVe ou word2vec.  Par rapport √† GloVe, la valeur de F a diminu√© de plus de trois fois, et par rapport √† word2vec - de plus de quatre fois.  Et en g√©n√©ral, nous voyons des diff√©rences de tonalit√© beaucoup plus petites lors de la comparaison de diff√©rents noms: cela devrait √™tre le cas, car les noms ne devraient vraiment pas affecter le r√©sultat de l'analyse. <br><br>  Mais une l√©g√®re corr√©lation subsiste.  Je peux peut-√™tre r√©cup√©rer des donn√©es et des param√®tres d'entra√Ænement tels que le probl√®me semble √™tre r√©solu.  Mais ce sera une mauvaise option, car <i>en fait le</i> probl√®me demeure, car dans ConceptNet nous n'avons pas identifi√© et compens√© toutes les causes du racisme algorithmique.  Mais c'est un bon d√©but. <br><br><h3>  Pas d'emb√ªches </h3><br>  Veuillez noter qu'avec le passage √† ConceptNet Numberbatch, la pr√©cision de la pr√©diction de la tonalit√© s'est am√©lior√©e. <br><br>  Quelqu'un aurait pu sugg√©rer que la correction du racisme algorithmique aggraverait les r√©sultats d'une autre mani√®re.  Mais non.  Vous pouvez avoir des donn√©es meilleures et moins racistes.      .     word2vec  GloVe        . <br><br><h1>   </h1><br> ,      . -    . <br><br>                . ,         . <br><br>         ,        . ,       ‚Äî    .      ,    .         (recall),         ‚Äî   . <br><br>                    ,   -   .    .   ,   ,   . ,       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr436506/">https://habr.com/ru/post/fr436506/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr436496/index.html">PVS-Studio pour Java</a></li>
<li><a href="../fr436498/index.html">Software AG: pas seulement ARIS</a></li>
<li><a href="../fr436500/index.html">Comment le cadre de Rise of the Tomb Raider est rendu</a></li>
<li><a href="../fr436502/index.html">Abonnement Pampers ou comment vendre plus aux m√™mes clients</a></li>
<li><a href="../fr436504/index.html">Syst√®me en emballage ou contenu de l'emballage sous puce?</a></li>
<li><a href="../fr436508/index.html">10 millions de dollars d'investissements et les louanges de Wozniak - cr√©er un ordinateur √©ducatif pour les enfants</a></li>
<li><a href="../fr436510/index.html">Donn√©es de base en d√©tail</a></li>
<li><a href="../fr436512/index.html">Comment nous trouvons les versions probl√©matiques avec Graphite et Moira. D√©couvrez Yandex.Money</a></li>
<li><a href="../fr436514/index.html">Cr√©er des histoires pour Instagram √† partir de PHP</a></li>
<li><a href="../fr436518/index.html">Haiku Œ≤1 - rendre le / b / OS g√©nial √† nouveau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
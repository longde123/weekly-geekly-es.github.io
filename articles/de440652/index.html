<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§Ωüèø üèÇüèæ ‚öíÔ∏è Computervideo in 755 Megapixeln: Plenoptik gestern, heute und morgen üöè üìÄ üëãüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor einiger Zeit hatte der Autor die Gelegenheit, einen Vortrag bei VGIK zu halten, und es waren viele Leute aus dem Kamerahaus im Publikum. Das Publi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Computervideo in 755 Megapixeln: Plenoptik gestern, heute und morgen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440652/"><img src="https://habrastorage.org/getpro/habr/post_images/edf/637/bcd/edf637bcd51db4e6b8b3e8c13c3491f0.png"><br><br>  Vor einiger Zeit hatte der Autor die Gelegenheit, einen Vortrag bei VGIK zu halten, und es waren viele Leute aus dem Kamerahaus im Publikum.  Das Publikum wurde gefragt: ‚ÄûMit welcher maximalen Aufl√∂sung haben Sie geschossen?‚Äú, Und es stellte sich heraus, dass etwa eine dritte Aufnahme 4K oder 8 Megapixel, der Rest - nicht mehr als 2K oder 2 Megapixel.  Es war eine Herausforderung!  Ich musste √ºber die Kamera mit einer Aufl√∂sung von 755 Megapixeln (Rohaufl√∂sung, um genau zu sein, da sie eine endg√ºltige 4K hat) und welche bezaubernden M√∂glichkeiten dies f√ºr professionelle Aufnahmen bietet, erz√§hlen. <br><br>  Die Kamera selbst sieht so aus (eine Art kleiner Elefant): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/824/93c/286/82493c2865db1d6519d69121b0ba8d9c.png"><br><br>  Au√üerdem werde ich ein schreckliches Geheimnis er√∂ffnen, um dieses Bild aufzunehmen, suchten wir nach einem besseren Blickwinkel und einer gr√∂√üeren Person.  Ich habe diese Kamera zuf√§llig live gesp√ºrt, ich werde sagen, dass sie <b>viel</b> gr√∂√üer aussieht.  Das Bild unten mit Yon Karafin, mit dem wir ungef√§hr gleich gro√ü sind, spiegelt das Ausma√ü der Katastrophe genauer wider: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb5/954/8b6/eb59548b69bc178ace2a379120ca6b33.png"><br><br>  Wer k√ºmmert sich im Prinzip um die F√§higkeiten des berechneten Videos, √ºber das sie selten schreiben - die ganze Wahrheit ist unter dem Strich!  ) <br><a name="habracut"></a><br>  Diskussionen √ºber die M√∂glichkeiten der Plenoptik erinnern mich an Diskussionen √ºber das erste Flugzeug: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d04/b2f/00f/d04b2f00fc8d68a6b3d830665fdfb433.png"><br><br><hr><br>  Was die Leute sagten: <br>  - <i>Es ist sehr teuer ...</i> <br>  - <i>JA!</i> <br>  - <i>Es ist v√∂llig unpraktisch und zahlt sich jetzt nicht aus ...</i> <br>  - <i>JA!</i> <br>  - <i>Es ist gef√§hrlich zu benutzen ...</i> <br>  - <i>Verdammt, JA!</i> <br>  - <i>Es sieht elend aus!</i> <br>  - <i>Verdammt, JA, aber es <b>fliegt, siehst du, LE-TA-ET !!!</b></i> <br><hr><br>  Nach 50 Jahren f√ºhrten diese Experimente zu einer grundlegend neuen, bequemen und ziemlich sicheren Art, sich √ºber die Ozeane zu bewegen (und nicht nur). <br><br>  Die Situation ist hier die gleiche.  Absolut das gleiche!  Jetzt erfordert es unvern√ºnftige Kosten, die verdammt unpraktisch zu bedienen sind und elend aussehen, aber es fliegt wirklich!  Und sich der Prinzipien und neuen Perspektiven bewusst zu sein - es ist einfach unglaublich inspirierend (zumindest Ihr bescheidener Diener)! <br><br>  Das Monster auf dem Foto oben erinnert etwas an die ersten Kameras, die ebenfalls gro√ü waren, ein riesiges Objektiv hatten und auf einem speziellen Rahmen gedreht wurden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/feb/153/d5e/feb153d5ebe10e4c0a529270d7244fcc.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fernsehaufnahmen der Olympischen Spiele 1936</a> zu Beginn des Fernsehens</i> <br><br>  Hier sieht viel aus, auch ein riesiges Objektiv (weil es auch nicht genug Licht gibt), eine schwere Kamera mit einer speziellen Federung, riesige Gr√∂√üen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b38/770/bbe/b38770bbefae6795d4fb673436906e6f.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lytro ist bereit, das Filmemachen f√ºr immer zu ver√§ndern</a></i> <br><br>  Aus dem Interessanten: Der ‚ÄûKoffer‚Äú unten ist ein Fl√ºssigkeitsk√ºhlsystem, bei dessen Ausfall die Kamera keine weiteren Bilder aufnehmen kann. <br><br>  Das gro√üe Rechteck unter dem Objektiv (auf dem ersten Foto oben deutlich sichtbar) ist nicht die Hintergrundbeleuchtung, sondern das Lidar - ein Laser-Entfernungsmesser, der eine dreidimensionale Szene vor der Kamera liefert. <br><br>  Ein dickes schwarzes Tourniquet unten links im Hintergrund ist ein B√ºndel von Glasfaserkabeln mit einem Durchmesser von etwa 4 Zentimetern, durch das die Kamera einen ungeheuren Informationsstrom an einen speziellen Speicher sendet. <br><br>  Diejenigen in diesem Thema haben bereits das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lytro-Kino</a> erkannt, von dem 3 St√ºcke geschaffen wurden.  Die erste, die normalerweise in allen Bildern erscheint, ist an einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lidar</a> unter der Linse leicht zu erkennen.  Nach 1,5 Jahren wurde eine zweite Kammer mit korrigierten strukturellen Problemen des ersten und der beiden Lidare geschaffen (und leider schreibt fast niemand dar√ºber).  Dar√ºber hinaus war der Entwicklungsfortschritt beispielsweise von Lidaren in 1,5 Jahren so gro√ü, dass zwei Lidare der zweiten Kammer zehnmal mehr Punkte ergaben als ein Lidar der ersten.  Die dritte Kamera sollte ungef√§hr die gleichen Aufl√∂sungseigenschaften haben (um die Anforderungen der Filmemacher zu erf√ºllen), aber halb so gro√ü sein (was f√ºr den praktischen Gebrauch entscheidend ist).  Aber ... aber dazu sp√§ter mehr. <br><br>  In jedem Fall m√∂chte ich darauf hinweisen, dass das Licht nicht darauf konvergierte, da es die herausragende Rolle, die Lytro bei der Popularisierung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">plenoptischen Schie√ütechnologie</a> gespielt hat, in jeder Hinsicht anerkannte.  Eine √§hnliche Kamera wurde am <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fraunhofer-Institut hergestellt</a> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raytrix</a> , ein Hersteller von plenoptischen Kameras <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, existiert sicher</a> , und ich durfte das Lytro-Kino nicht fotografieren, da ich gro√üe Angst vor mehreren chinesischen Unternehmen hatte, die aktiv in dieser Richtung arbeiteten (es wurden keine neuen Informationen dar√ºber gefunden). <br><br>  Schreiben wir daher die Punkte auf, die alle Vorteile der Plenoptik bieten und √ºber die sie fast nicht schreiben.  Aber gerade deshalb ist es garantiert erfolgreich. <br><br><h1>  Anstatt vorzustellen </h1><br>  Nur auf Habr√© und nur auf Lytro wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf ca. 300 Seiten erw√§hnt</a> , daher werden wir kurz sein. <br><br>  Das Schl√ºsselkonzept f√ºr die plenoptische Aufnahme ist das Lichtfeld, dh wir fixieren nicht die Pixelfarbe an jedem Punkt, sondern eine zweidimensionale Pixelmatrix, die aus einem miserablen zweidimensionalen Rahmen einen normalen vierdimensionalen Rahmen macht (normalerweise mit sehr geringer Aufl√∂sung in t und s): <br><br><img src="https://habrastorage.org/webt/kr/tg/ex/krtgexrapzcv70xbte74_cepamo.png"><br><br>  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">englischen Wikipedia</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dann in der russischen</a> in Artikeln √ºber das Lichtfeld hei√üt es, dass "der Ausdruck" Lichtfeld " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von A. Gershun</a> im Jahr 1936 verwendet wurde."  Fairerweise stellen wir fest, dass dies nicht <s>zuf√§llig eine</s> ‚Äûverwendete Phrase‚Äú war, sondern der Name eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kleinen Buches mit</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">178 Seiten</a> , das ‚ÄûLichtfeld‚Äú genannt wurde: <br><br><img width="300" src="https://habrastorage.org/webt/ba/lw/q_/balwq_fptbhjelv24etahctr5-8.png"><br><br>  Und schon damals waren diese Werke durchaus in der Natur angewendet und der Autor erhielt 6 Jahre sp√§ter auf dem H√∂hepunkt des Krieges 1942 den Stalin-Preis zweiten Grades f√ºr die Blackout-Methode. <br><br>  In der Praxis bietet das Aufnehmen eines vierdimensionalen Rahmens des Lichtfelds eine Reihe von Mikrolinsen vor dem Sensor der Kamera: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/90f/203/fb4/90f203fb49d7e464638a4f164e96fb26.gif"></a> <br>  <i>Quelle: <a href="">plenoptic.inf (Sie k√∂nnen klicken und in voller Aufl√∂sung sehen)</a></i> <br><br>  Gerade weil wir eine Reihe von Mikrolinsen mit einem geringen Abstand zwischen ihnen haben, war es m√∂glich, Lytro Cinema zu erstellen, dessen Sensor aus einer Reihe von Sensoren zusammengesetzt wurde, deren Grenzen an den Rand der Linsen fallen.  Eine Fl√ºssigkeitsk√ºhlung war erforderlich, um ein sehr hei√ües Massiv abzuk√ºhlen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f2c/bc4/c3a/f2cbc4c3ad04cfa63d0fd1976fda10a8.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verwenden fokussierter plenoptischer Kameras f√ºr die Erfassung umfassender Bilder</a></i> <br><br>  Als Ergebnis erhalten wir die ber√ºhmteste M√∂glichkeit von Plenoptikkameras, √ºber die nur die Faulen nicht geschrieben haben - um die Fokussierentfernung nach der Aufnahme zu √§ndern (diese niedlichen V√∂gel w√ºrden nicht auf den Fokus warten): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb2/49a/815/eb249a815ede8955910d24aadc495a66.gif"><br>  <i>Quelle: Lytro</i> <br><br>  Und es wurde wenig dar√ºber geschrieben, wie Plenoptik in einer f√ºr einen Film geeigneten Aufl√∂sung aussieht (wird durch Klicken ge√∂ffnet): <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/0bf/247/057/0bf2470573938428dae4ae4f2c8ca217.png"></a> <br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Watch Lytro Change Cinematography Forever</a></i> <br><br>  Ich √∂ffne ein weiteres Geheimnis: Der berechnete Fokus ist die Spitze des Eisbergs der Plenoptik.  Noch interessanter sind die 90% der M√∂glichkeiten, die meiner Meinung nach unter dem Interesse von Journalisten liegen.  Viele von ihnen verdienen separate Artikel, aber lassen Sie uns zumindest die Ungerechtigkeit korrigieren und sie zumindest nennen.  Lass uns gehen! <br><br><h1>  Berechnete Aperturform </h1><br>  Da es sich um Defokussierung handelt, ist der sogenannte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bokeh-Effekt</a> zu erw√§hnen, bei dem die Blendung nicht unbedingt rund ist <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b6/f15/b53/4b6f15b5341de52d29714f789d5f5a52.png"><br><br>  F√ºr Fotografen ist das sogenannte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bokeh Kit erh√§ltlich</a> , mit dem Sie verschiedene Formen blenden k√∂nnen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a8/f3d/c8c/8a8f3dc8cc02ff1ccd7e00272aec9a9f.png"><br><br>  Auf diese Weise erhalten Sie h√ºbsche Bilder, und das Foto unten zeigt deutlich, dass die Glitzer in Form von Herzen sogar Steine ‚Äã‚Äãim Vordergrund haben, nur die Herzen sind kleiner.  Und es ist klar, dass es √§u√üerst schwierig ist, in Photoshop auf √§hnliche Weise auf nat√ºrliche Weise zu verwischen. Zumindest ist es ratsam, eine Tiefenkarte zu verwenden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c14/ca9/61f/c14ca961fa1bce2cb067c228dba7f342.png"><br><br>  Gleichzeitig ist es f√ºr die Plenoptik relativ einfach, eine andere Blende zu ‚Äûberechnen‚Äú: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1df/6b2/b1c/1df6b2b1cf75edf87faaa0e1c9e689e1.png"><br><br>  Also!  Wir haben die Fokussierentfernung berechnet, die Form der Blende berechnet, sind weiter gegangen, es ist dort interessanter! <br><br><h1>  Berechnetes Stereo </h1><br>  Ein sehr n√ºtzliches Merkmal des plenoptischen Sensors, von dem fast niemand spricht, das ihm aber bereits ein zweites Leben gibt, ist die F√§higkeit, ein Bild aus verschiedenen Punkten zu berechnen.  Die Position des Punktes wird tats√§chlich durch die Gr√∂√üe der Linse bestimmt.  Wenn das Objektiv klein ist, kann sich der Rahmen wie in diesem Beispiel leicht nach links und rechts verschieben (dieses Stereofoto ist sichtbar, wenn Sie auf die Brust des n√§chsten Vogels schauen): <br><br><img width="750" src="https://habrastorage.org/getpro/habr/post_images/2bc/0ef/292/2bc0ef292a64c5ba65b626d374f8f0a8.gif"><br>  <i>Quelle: Lytro</i> <br><br>  Wenn das Objektiv gro√ü ist, wie zum Beispiel Lytro Cinema, kann der Aufnahmepunkt um 10 Zentimeter verschoben werden.  Ich m√∂chte Sie daran erinnern, dass wir zwischen unseren Augen ungef√§hr 6,5 Zentimeter haben, dh mit einem maximalen Abstand von 10 cm k√∂nnen Sie sowohl den allgemeinen Plan (und er ist ‚Äûdreidimensional‚Äú als wenn Sie mit Ihren Augen schauen) als auch die Nahaufnahme (mit jeder Parallaxe ohne Unbehagen) aufnehmen.  Tats√§chlich bedeutet dies, dass wir mit einem Objektiv vollst√§ndige Stereovideos aufnehmen k√∂nnen.  Dar√ºber hinaus wird es nicht nur Stereo sein, sondern Stereo mit perfekter Qualit√§t, und das klingt heute fantastisch - mit einem variablen Abstand zwischen den optischen Achsen virtueller Kameras NACH der Aufnahme.  Sowohl das als auch eine andere - absolut undenkbare M√∂glichkeiten, die eine Situation mit Stereoaufnahmen in Zukunft grundlegend ver√§ndern k√∂nnen. <br><br>  Da die Zukunft irgendwie im dreidimensionalen Schie√üen liegt, wollen wir uns n√§her mit diesen beiden Punkten befassen.  Es ist kein Geheimnis, dass heute die meisten 3D-Filme, insbesondere Blockbuster, nicht entfernt, sondern in 3D konvertiert werden.  Dies geschieht, weil beim Aufnehmen eine lange Liste von Problemen auftritt (unten ist ein Teil der Liste): <br><br><ul><li>  Die Frames k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">relativ zueinander gedreht, vertikal verschoben oder vergr√∂√üert werden</a> (sagen Sie nicht, dass dies leicht zu beheben ist, sehen Sie, wie oft solche Frames in Filmver√∂ffentlichungen fallen - dies ist ein leiser Horror ... und Kopfschmerzen).  Also - die plenoptische Stereoanlage ist PERFEKT ausgerichtet, selbst wenn der Bediener beschlossen hat, den Plan zu vergr√∂√üern (aufgrund der Mechanik der beiden Kameras ist es √§u√üerst schwierig, die Ann√§herung streng synchron zu machen). <br></li><li>  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farbe der</a> Bilder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kann variieren</a> , insbesondere wenn f√ºr die Aufnahme ein geringer Abstand zwischen den optischen Achsen der Kameras erforderlich ist und Sie einen Strahlteiler verwenden m√ºssen (es gab einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausf√ºhrlichen Beitrag</a> dazu).  Es stellt sich heraus, dass wir in einer Situation, in der wir bei der Aufnahme eines Fackelobjekts (das Auto im Hintergrund an einem sonnigen Tag) mit der √ºberwiegenden Mehrheit der Kameras zur Unterhaltung in der Postproduktion verdammt sind und mit Plenoptik ein PERFEKTES Bild mit jeglicher Blendung erhalten.  Dies ist ein Feiertag! <br></li><li>  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sch√§rfe der</a> Rahmen kann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">variieren</a> - wiederum ein sp√ºrbares Problem bei Strahlteilern, das bei der Plenoptik v√∂llig fehlt.  Mit welcher Sch√§rfe ben√∂tigt wird, berechnen wir damit absolut PERFEKT aus den Winkeln. <br></li><li>  Frames k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der Zeit schweben</a> .  Kollegen, die mit dem Stalingrad-Material gearbeitet haben, sprachen √ºber die Diskrepanz zwischen den Zeitstempeln der Tracks um 4 Frames, weshalb der Cracker immer noch relevant ist.  Wir haben in 105 Filmen mehr als 500 Szenen mit Zeitunterschieden gefunden.  Der Zeitunterschied ist leider schwer zu erkennen, insbesondere in Szenen mit Zeitlupe, und gleichzeitig das schmerzhafteste Artefakt nach unseren Messungen.  Im Falle der Plenoptik haben wir eine PERFEKTE Zeitsynchronisation. <br></li><li>  Ein weiteres Problem beim Aufnehmen von 3D sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu gro√üe Parallaxen, die beim Betrachten</a> auf einem gro√üen Bildschirm <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unangenehm sind</a> , wenn Ihre Augen bei Objekten ‚Äûjenseits der Unendlichkeit‚Äú zur Seite divergieren oder bei einigen Objekten im Vordergrund zu konvergieren k√∂nnen.  Die korrekte Parallaxenberechnung ist ein separates schwieriges Thema, √ºber das die Bediener gut verf√ºgen sollten, und ein Objekt, das versehentlich in den Rahmen gelangt, kann die Aufnahme ruinieren und es unangenehm machen.  Bei der Plenoptik w√§hlen wir selbst die Parallaxe NACH der Aufnahme, sodass jede Szene mit der PERFEKTEN Parallaxe berechnet werden kann. Dar√ºber hinaus kann dieselbe bereits aufgenommene Szene problemlos f√ºr gro√üe und kleine Bildschirme berechnet werden.  Dies ist die sogenannte Parallaxen√§nderung, die in der Regel √§u√üerst schwierig und teuer ist, ohne Qualit√§tsverlust zu verursachen, insbesondere wenn Sie durchscheinende Objekte oder R√§nder im Vordergrund hatten. <br></li></ul><br>  Im Allgemeinen ist die F√§higkeit, die perfekte Stereoanlage zu berechnen, die eigentliche Grundlage f√ºr die n√§chste Welle der 3D-Popularit√§t, da in den letzten 100 Jahren 5 solcher Wellen unterschieden wurden.  Gemessen an den Fortschritten bei Laserprojektion und Plenoptik werden wir f√ºr maximal 10 Jahre (wenn die Hauptpatente von Lytro in China auslaufen oder etwas fr√ºher) in China ein neues Eisen und ein neues Qualit√§tsniveau f√ºr 3D-Filme erwarten. <br><br>  Also!  Sie haben die perfekt berechnete Stereoanlage von einem Objektiv (was f√ºr die meisten √ºbrigens unm√∂glich ist).  Und sie haben es nicht nur verstanden, sondern auch die Parallaxe nacherz√§hlt, selbst wenn das Objekt im Vordergrund unscharf ist.  Lass uns tiefer gehen! <br><br><h1>  Berechneter Aufnahmepunkt </h1><br>  Das √Ñndern des Aufnahmepunkts hat eine Anwendung in normalen 2D-Videos. <br><br>  Wenn Sie am Set waren oder zumindest Fotos gesehen haben, haben Sie wahrscheinlich auf die Schienen geachtet, auf denen die Kamera f√§hrt.  Oft muss man sie f√ºr eine Szene in mehrere Richtungen legen, was eine sp√ºrbare Zeit in Anspruch nimmt.  Schienen sorgen f√ºr einen reibungslosen Betrieb der Kamera.  Ja, nat√ºrlich gibt es eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Steadicam</a> , aber in vielen F√§llen haben die Schienen leider keine Alternative. <br><br>  Die M√∂glichkeit, den Aufnahmepunkt in Lytro zu √§ndern, wurde verwendet, um zu demonstrieren, dass gen√ºgend R√§der vorhanden sind.  Wenn sich die Kamera bewegt, bilden wir eine virtuelle ‚ÄûR√∂hre‚Äú mit einem Raumdurchmesser von 10 cm, in der wir den Aufnahmepunkt √§ndern k√∂nnen.  Mit diesem Rohr k√∂nnen Sie kleine Schwankungen ausgleichen.  Dies wird in diesem Video gut gezeigt: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/4qXE4sA-hLQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Dar√ºber hinaus m√ºssen Sie manchmal das umgekehrte Problem l√∂sen, dh w√§hrend der Bewegung Schwingungen hinzuf√ºgen.  Zum Beispiel gab es nicht genug Dynamik und der Regisseur entschied sich f√ºr eine Explosion.  Es dauert nicht lange, einen Ton anzulegen, aber es ist ratsam, die Kamera synchron zu sch√ºtteln, und es ist besser, das Bild nicht nur flach zu bewegen, es wird sichtbar, sondern es ‚Äûehrlich‚Äú zu sch√ºtteln.  Mit der Plenoptik kann der Aufnahmepunkt vollst√§ndig ‚Äûehrlich‚Äú gesch√ºttelt werden - mit einer √Ñnderung des Aufnahmepunkts, des Winkels, der Bewegungsunsch√§rfe usw.  Es wird eine v√∂llige Illusion geben, dass die Kamera heftig zitterte, die sanft und sicher auf R√§dern fuhr.  Stimmen Sie zu - eine erstaunliche Gelegenheit!  Die Steadicam der n√§chsten Generation wird Wunder zeigen. <br><br>  Damit dies Realit√§t wird, m√ºssen Sie nat√ºrlich warten, bis die Gr√∂√üe der plenoptischen Kamera auf einen vern√ºnftigen Wert reduziert ist.  Angesichts der Tatsache, wie viel Geld in die Miniaturisierung und die Erh√∂hung der Aufl√∂sung von Sensoren f√ºr Smartphones und Tablets investiert wird, scheint das Warten nicht so lange zu dauern.  Und es wird m√∂glich sein, eine neue plenoptische Kamera zu erstellen!  Jedes Jahr wird es einfacher und einfacher. <br><br>  Also!  Der Aufnahmepunkt wurde berechnet und gegebenenfalls bewegt, wodurch die Kamera stabilisiert oder destabilisiert wurde.  Lass uns weiter gehen! <br><br><h1>  Berechnete Beleuchtung </h1><br>  Da wir √ºber eine Explosion in der N√§he sprechen ... <br><br>  Manchmal ist es notwendig, die Beleuchtung des Motivs zu √§ndern, z. B. einen Blitz realistisch hinzuzuf√ºgen.  Postproduktionsstudios wissen genau, was f√ºr ein schwieriges Problem dies ist, auch wenn die Kleidung unseres Charakters relativ einfach ist. <br><br>  Hier ist ein Beispiel f√ºr ein Video mit einer Blitz√ºberlagerung unter Ber√ºcksichtigung der Kleidung, ihrer Schatten usw. (wird durch Klicken ge√∂ffnet): <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/9f9/5d9/71b/9f95d971be215c71291ab04052bf4c24.png"></a> <br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Interview mit Yon Karafin</a></i> <br><br>  Unter der Haube sieht es aus wie ein Plug-In f√ºr Nuke, das mit einem vollst√§ndigen dreidimensionalen Modell des Schauspielers arbeitet und es unter Ber√ºcksichtigung der normalen Karte, Materialien, Bewegungsunsch√§rfe usw. neu beleuchtet: <br><br><img width="650" src="https://habrastorage.org/getpro/habr/post_images/657/214/4b7/6572144b7afc8bc6638984b17ce45d88.png"><br><br><img width="650" src="https://habrastorage.org/getpro/habr/post_images/631/766/a83/631766a838c01a2759931f89b44dd2c7.png"><br>  <i>Quelle: Lytro Materials</i> <br><br>  Also!  Die neue Beleuchtung des bereits erfassten Objekts wurde berechnet.  Lass uns weiter gehen! <br><br><h1>  Berechnete Aufl√∂sung </h1><br>  Diejenigen, die mit dem ersten Lytro experimentierten, bemerkten oft - ja, das Spielzeug ist cool, aber die Aufl√∂sung ist f√ºr normale Fotografie v√∂llig unzureichend. <br><br>  In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserem letzten Artikel</a> √ºber Habr wurde beschrieben, wie kleine Verschiebungen des Aufnahmepunkts dazu beitragen k√∂nnen, die Aufl√∂sung signifikant zu erh√∂hen.  Frage: Sind diese Algorithmen auf die Plenoptik anwendbar?  Antwort: Ja!  Dar√ºber hinaus lassen sich Super-Resolution-Algorithmen leichter mit plenoptischen Bildern bearbeiten, da eine Tiefenkarte vorhanden ist, alle Pixel gleichzeitig aufgenommen werden und die Verschiebungen recht genau bekannt sind.  Das hei√üt, die Situation der Plenoptik ist einfach magisch im Vergleich zu den Bedingungen, unter denen Super Resolution-Algorithmen in gew√∂hnlichem 2D arbeiten.  Das Ergebnis ist entsprechend: <br><br><img width="650" src="https://habrastorage.org/getpro/habr/post_images/bc9/6cd/e55/bc96cde55e276f4420757de5359467b1.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Naive, intelligente und hochaufl√∂sende plenoptische Rahmenwiederherstellung</a> aus dem technischen Bericht von Adobe ‚ÄûSuperaufl√∂sung mit plenoptischer Kamera 2.0‚Äú</i> <br><br>  Das einzige gro√üe Problem (wirklich gro√ü!) Ist die Datenmenge und der Rechenaufwand, der erforderlich ist.  Trotzdem ist es heute v√∂llig realistisch, eine Computerfarm nachts zu laden und morgen dort, wo sie ben√∂tigt wird, doppelt so viel Aufl√∂sung zu erhalten. <br><br>  Also - die berechnete Aufl√∂sung herausgefunden!  Lass uns weiter gehen! <br><br><h1>  Berechnete Umgebung </h1><br>  Eine separate Aufgabe, die sich in der Postproduktion ergibt, insbesondere wenn es sich um ein fantastisches oder Fantasy-Projekt handelt, besteht darin, die aufgenommenen Objekte sorgf√§ltig in eine dreidimensionale Szene zu kleben.  Weltweit gibt es kein gro√ües Problem.  Heutzutage ist das dreidimensionale Scannen des Aufnahmebereichs die Norm. Alles, was √ºbrig bleibt, ist, das Aufnahmemodell und die dreidimensionale Szene sorgf√§ltig zu kombinieren, damit es keine Klassiker des Genres gibt, wenn die Beine der Schauspieler manchmal leicht in den bemalten unebenen Boden fallen (dieser Pfosten ist auf dem kleinen Bildschirm nicht sehr sichtbar, aber deutlich zu sehen im Kino, besonders irgendwo in IMAX). <br><br>  Nicht ohne Humor wurde als Beispiel f√ºr den Betrieb der Kamera die Szene verwendet, in der die Mondlandung aufgenommen wurde (‚Äûdreidimensionale Schatten‚Äú sind an Stellen deutlich sichtbar, die die Kamera nicht sieht): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/094/809/2b9/0948092b96926ae88866cd222e67f0fe.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mond |</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lytro |</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VR Playhouse |</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lightfield Postproduktion</a></i> <br><br>  Da ein Mehrwinkelvideo per Definition in einer plenoptischen Kamera aufgenommen wird, ist das Erstellen einer Tiefenkarte kein gro√ües Problem.  Und wenn die Kamera mit dem Lidar kombiniert wird, nehmen wir sofort eine dreidimensionale Szene auf, was die Kombination von echten Aufnahmen und Grafiken in der n√§chsten Phase kategorisch vereinfacht. <br><br>  Also haben wir die dreidimensionale Szene gez√§hlt (Lidar-Daten und Plenoptik-Daten kombiniert).  Nun, Sie haben es erraten, wird die Darstellung der Mondvermessung noch besser sein!  Mach weiter. <br><br><h1>  Berechneter Chroma Key </h1><br>  Das ist aber noch nicht alles! <br><br>  Die √ºbliche Technologie eines modernen Filmsets sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gr√ºne Bildschirme</a> , wenn an Orten, an denen ein Computerhintergrund auf gr√ºnen Sperrholzschildern angebracht werden soll, oder gr√ºne Banner gezogen werden.  Dies geschieht so, dass es keine Probleme an den durchscheinenden R√§ndern gibt, wenn sich der Hintergrund √§ndert.    4           ‚Äî   (       )   . <br><br>     ,        ,           ,  ,         .       ,      ,     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/719/321/028/719321028fe5117bbd95f2a5eb53eef4.gif"><br> <i>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   </a></i> <br><br>  Lytro   ,        (    <b>    </b> -      ‚Äî    !),        (         challenge),                ,        ( ,       ,    ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e3c/ca5/ecd/e3cca5ecdfa044f5a126210adee71c5f.jpg"><br><br>   ,        ?    .  , ,   (  ).  ,                         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> . <br><br>                 ¬´ ¬ª,         .      .     ,                      2D .   . <br><br> ,       ,  ! <br><br><h1>   </h1><br>    ‚Äî     .        ,    ,  ,        ,       .    ,          ¬´¬ª . <br><br>    ,   ¬´¬ª   ¬´¬ª , ,      ,       ,    ,       ,    ( Lytro Cinema  300 fps,   ,    ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/77a/c8f/887/77ac8f887c64f3d1032dff17ed4a8ade.png"><br><br>    ¬´¬ª   ,     ,     ,     ¬´¬ª  ¬´¬ª         ,       (     ,   ,       ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb7/cd2/51a/eb7cd251a31f2c79d3f8184af7126321.gif"><br> <i>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://vimeo.com/114743605</a></i> <br><br>     ,           ,    : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/52c/e3a/ebc/52ce3aebcee45ffc1d48baca9ea3033b.gif"><br> <i>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://vimeo.com/114743605</a></i> <br><br> ,  .  ! <br><br><h1>      </h1><br>  Wenn es heute um Plenoptik geht, gibt es normalerweise typische Gespr√§che im Stil von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûDer Chef ist weg: Der Gips wird entfernt, der Kunde geht!‚Äú.</a>  Lytro hat Google letztes Jahr g√ºnstig gekauft, die Pelican Imaging-Experimente gingen nicht in die Massenproduktion und im Allgemeinen blieb alles nur eine sch√∂ne Theorie ... <br><br><img width="300" src="https://habrastorage.org/getpro/habr/post_images/db1/c6c/d34/db1c6cd34bdfed6d5b6775a934a20e57.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pelican Imaging: Smartphone Plenoptic Camera Module f√ºr 20 Dollar</a></i> <br><br>  Also!  Ger√ºchte √ºber den Tod von Plenoptikern sind stark √ºbertrieben.  Sehr stark! <br><br>  Im Gegenteil, derzeit werden plenoptische Sensoren in einem noch <b>nie</b> dagewesenen Ma√üstab hergestellt und eingesetzt. <br><br>  Das ber√ºchtigte Google-Unternehmen ohne gro√üe Fanfare ver√∂ffentlichte Google Pixel 2 und Google Pixel 3 mit plenoptischen Sensoren.  Wenn Sie auf das Telefon schauen, k√∂nnen Sie deutlich sehen, dass die Kamera eine Kamera hat: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/683/8ba/197/6838ba19764118b6b5a264770ce5f8dc.png"><br><br>  Gleichzeitig verwischt das Telefon den Hintergrund jedoch sehr gut, im Allgemeinen nicht schlechter als seine Kollegen mit zwei, drei, drei und vier Augen (stimmen Sie zu, dass das folgende Foto besonders von diesem Effekt profitiert): <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/78d/e6e/e8a/78de6ee8a7b0a719ae7c3cc108ac305f.png"></a> <br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Google Blog (Sie k√∂nnen klicken und eine gr√∂√üere Gr√∂√üe sehen, haupts√§chlich an den R√§ndern des Vordergrundobjekts)</a></i> <br><br>  Wie machen sie das ?! <br><br>  Eine Quelle magischer Wunder, die in letzter Zeit unvermeidlich war, wird genutzt - nicht-kindliche Magie neuronaler Netze? <br><br>  Neuronale Netze, insbesondere in Pixel 3, werden bei dieser Aufgabe ebenfalls aktiv verwendet, dazu sp√§ter mehr.  Das Geheimnis der Effektqualit√§t besteht darin, dass der Sensor des Smartphones plenoptisch ist, obwohl das Objektiv nur zwei Pixel abdeckt, wie im Bild gezeigt: <br><br><img width="400" src="https://habrastorage.org/getpro/habr/post_images/852/c36/209/852c36209a7528f576e20dc37e0ef1f3.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Google Blog</a></i> <br><br>  Als Ergebnis erhalten wir ein Mikrostereobild, hier ist eine sehr leichte Verschiebung in der Bewegung sichtbar (das rechte Bild ist animiert und bewegt sich auf und ab, da das Telefon beim Aufnehmen so gehalten wurde): <br><br><img src="https://habrastorage.org/webt/pq/bw/ip/pqbwipy4ne_96amqgpvbinmnehy.gif"><br><br>  Aber selbst diese extrem kleine Verschiebung reicht aus, um eine Tiefenkarte f√ºr das aufgenommene Foto zu erstellen (√ºber die Verwendung von Subpixel-Verschiebungen wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in einem fr√ºheren Artikel berichtet</a> ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/066/2be/93e/0662be93e0e02b6f87f7c3fa8b1f8e7c.png"><br><br>  Gleichzeitig k√∂nnen durch den Einsatz von maschinellem Lernen die Ergebnisse erheblich verbessert werden, und dies ist bereits in Pixel 3 implementiert. Im folgenden Beispiel bedeutet "Gelernt" Stereo + Gelernt. Mehr dazu gibt es hoffentlich einen separaten Beitrag: <br><br><img width="230" src="https://habrastorage.org/getpro/habr/post_images/566/8e0/05b/5668e005b8efd21ce9f216ed9d16edf1.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/988/e31/9d2/988e319d2619f39a50d19cde8904d891.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/638/a17/966/638a1796697b9f2a675c509ff870465f.png"><br><br><img width="230" src="https://habrastorage.org/getpro/habr/post_images/110/4df/a5e/1104dfa5e50f1d476bc1ee7024520834.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/1ed/beb/daa/1edbebdaa7934c6525005fd8118fbd83.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/77e/ef2/942/77eef2942f1e6b6af44ccc720ae2c3a5.png"><br><br><img width="230" src="https://habrastorage.org/getpro/habr/post_images/429/442/99e/42944299e72b7eb720f3babc5a757b79.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/da3/fe1/3ea/da3fe13eacb3cd5b0a558db1d843b686.png"><img width="230" src="https://habrastorage.org/getpro/habr/post_images/c6f/a27/c4b/c6fa27c4bac8b9c5cb122e0c69ab814d.png"><br><br>  F√ºr diejenigen, die die Tiefe in voller Aufl√∂sung betrachten m√∂chten, gibt es weitere Beispiele <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in einer speziellen Galerie</a> . <br><br>  Es ist deutlich zu sehen, dass nicht alles perfekt ist, und wir haben typische Artefakte, die typisch f√ºr die Erstellung einer Tiefenkarte aus Stereo sind (die √ºbrigens auch bei Pixels zwei√§ugigen Kollegen verf√ºgbar sind), und ein wenig Parallaxeneffekte.  Es ist jedoch bereits klar, dass die Qualit√§t der Tiefe v√∂llig ausreicht, um das Bild sicher nach Tiefe zu segmentieren und weitere Effekte zu erzielen, Objekte sicherer zur Szene hinzuzuf√ºgen und so weiter.  Die Ergebnisse der gemessenen Tiefe sind um eine Gr√∂√üenordnung besser als die Ergebnisse, die auf verschiedenen Annahmen basieren (willk√ºrlich neuronale Netze). <br><br>  Herzlichen Gl√ºckwunsch an alle, die bis zu diesem Punkt gelesen haben!  Sie leben w√§hrend der Ver√∂ffentlichung von plenoptischen Kameras in einem erfolgreichen Massenmarktprodukt, auch wenn Sie nicht einmal davon wissen! <br><br>  Die Geschichte endet nat√ºrlich nicht dort: <br><br><ul><li>  Erstens ist es interessant, dass die Plenoptik ‚Äûfast kostenlos‚Äú war, da bei modernen Smartphone-Kameras mit Miniaturisierung des Sensors und einer Erh√∂hung der Aufl√∂sung ein katastrophaler Mangel an Lichtfluss auftritt, sodass jedes Pixel mit einer Mikrolinse bedeckt ist.  Das hei√üt, ein solcher Sensor kostet nicht mehr (das ist sehr wichtig!), Obwohl wir eine Aufl√∂sung, die wir gerade <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aufgrund einer anderen Technologie</a> erh√∂ht haben, etwas opfern.  Durch die Anwendung von zwei Technologien wird das Ergebnis in 2D besser (weniger Rauschen, h√∂here Aufl√∂sung, HDR) und gleichzeitig durch die gemessene Tiefe erg√§nzt, dh es wird 3D.  Der Preis der Ausgabe ist ein dramatischer Anstieg der Anzahl der Berechnungen pro Frame.  Aber f√ºr Fotos ist dies bereits heute m√∂glich und funktioniert bereits in echten Smartphones. <br></li><li>  Zweitens sagte ein Google-Mitarbeiter auf einer Konferenz, dass er daran denke, 4 Pixel mit einem Objektiv abzudecken. Danach wird die Qualit√§t der Tiefenkarte dramatisch h√∂her sein, da es 2 Stereopaare mit einer 1,4-mal gr√∂√üeren Stereobasis (zwei Diagonalen) geben wird. Dies wird die Qualit√§t der Tiefenkarte dramatisch verbessern. darunter viele Stereo-Artefakte an den Grenzen.  Mitbewerber k√∂nnen diese Qualit√§t nur erreichen, wenn sie mindestens 3 Kameras hintereinander platzieren.  Eine solche Qualit√§tssteigerung ist f√ºr AR wichtig. <br></li><li>  Drittens ist Google nicht mehr allein. Hier ist ein Beispiel f√ºr eine Beschreibung einer √§hnlichen Technologie im Vivo V11 Pro. Sie haben gerade ein √§hnliches Bild gesehen: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/096/4b1/ff8/0964b1ff86f0970e6e7c1ef3611ec11d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Was ist Dual Pixel-Technologie?</a></i> <br><br><ul><li>  Schlie√ülich ist in den letzten Jahren die Zahl der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ver√∂ffentlichungen zur Interpolation von Lichtfelddaten um</a> Lawinen gestiegen.  Und das ist wunderbar, denn um die Rechenkomplexit√§t drastisch zu reduzieren, wird nicht-kindliche Mathematik ben√∂tigt. </li></ul><br>  Plenoptics wird auch im Autofokus von professionellen Kameras verwendet, beispielsweise bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Canon</a> (Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DPAF</a> - Dual Pixel Auto Focus).  Wer h√§tte gedacht, dass ein theoretischer Witz von vor 30 Jahren - die F√§higkeit, Stereo mit einem Objektiv aufzunehmen - die erste Massenanwendung von Plenoptik w√§re ... <br><br>  Generell - das Thema ging an die Produkte! <br><br>  Sie fliegt schon!  Sie sehen, <b>LE-TA-ET!</b> <br><br><hr><br><h1>  Zusammenfassend </h1><br><h2>  Filmoptik im Kino </h2><br>  Oben haben wir zwei F√§lle des Einsatzes von Plenoptik untersucht - in der Filmproduktion und in Smartphones.  Dies ist keine vollst√§ndige Liste. Beispielsweise ist die Plenoptik in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mikroskopie</a> sehr relevant. Sie k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">berechnete Stereomikroskopaufnahmen</a> mit einer gro√üen "ehrlichen" Sch√§rfentiefe erstellen.  Die Plenoptik ist f√ºr Industriekameras relevant, insbesondere wenn Sie Fotos von durchscheinenden mehrstufigen Objekten usw. aufnehmen m√ºssen.  Aber irgendwie ein anderes Mal. <br><br><hr><br>  Denken Sie daran, dass f√ºr die Verwendung in der Filmproduktion relevant sind: <br><br><ol><li>  Berechnete Fokusentfernung <br></li><li>  Berechnetes Bokeh <br></li><li>  Berechnete Aufl√∂sung <br></li><li>  Computed Perfect Stereo <br></li><li>  Berechneter Aufnahmepunkt <br></li><li>  Berechnete Beleuchtung <br></li><li>  Berechnete Umgebung <br></li><li>  Berechneter Greenscreen <br></li><li>  Berechneter Verschluss <br></li></ol><hr><br>  In den kommenden Jahren kann durch Miniaturisierung und erh√∂hte Aufl√∂sung von Sensoren eine Technologie entwickelt werden, mit der eine praktische, grundlegend neue Filmkamera erstellt werden kann, mit der Sie Material zum Anwenden von Spezialeffekten schneller (ohne Greenscreen) und mit weniger Einstellungen entfernen k√∂nnen (mehr Punkte sind einfacher zu reparieren).  Die neuen Funktionen sind so interessant, dass solche Kameras zum Erfolg verurteilt sind, wenn der plenoptische Sensor mit einer geeigneten Filmaufl√∂sung kompakt gemacht werden kann. <br><br>  <b>Wann kann eine solche Kamera erscheinen?</b> <br><br>  Eine vorsichtige Antwort ist in den n√§chsten 10 Jahren. <br><br>  <b>Wovon h√§ngt der Begriff ab?</b> <br><br>  Aus vielen Faktoren.  Gute Frage: Wie wird die Situation mit der M√∂glichkeit sein, Lytro-Patente zu lizenzieren, die Google jetzt besitzt?  Dies kann kritisch sein.  Gl√ºcklicherweise laufen die wichtigsten in 10 Jahren ab (hier erinnern wir uns nicht h√∂flich an die chinesischen Lytro-Kollegen, die den Prozess beschleunigen k√∂nnen).  Auch die Arbeit mit riesigen Datenmengen, die von der plenoptischen Kamera erzeugt werden, sollte vereinfacht werden: Mit modernen Wolken wird dies immer einfacher.  Von den guten Nachrichten - einmal dank Lytro, in einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sehr beliebten Kompositionsprogramm</a> , das in einer Vielzahl von Studios f√ºr die Stereoverarbeitung verwendet wird, wurde das plenoptische Datenformat unterst√ºtzt.  Wie sie sagen, ist Lytro gestorben, aber die M√∂glichkeit, Plug-Ins f√ºr Nuke mit Unterst√ºtzung f√ºr plenoptische Videos zu schreiben, blieb uns erhalten.  Dies vereinfacht den ‚ÄûEintritt‚Äú in diesen Markt mit einem professionellen Produkt, da es wichtig ist, dass die Studios sofort mit dem Format neuer Kameras arbeiten k√∂nnen, ohne Personal und in denselben Programmen zu schulen. <br><br><h2>  Plenoptika in Smartphones </h2><br>  Wenn wir √ºber Smartphones sprechen, sieht alles noch besser aus.  Am relevantesten f√ºr diese Branche ist die F√§higkeit der plenoptischen Kamera, die Tiefe mit einem einzigen Sensor (m√∂glicherweise schnell) zu messen, und diese Funktion wird bald eine gro√üe Nachfrage sein. <br><br>  <b>Wann kann eine solche Kamera erscheinen?</b> <br><br>  Existiert bereits.  Und morgen wird die Technologie von anderen Herstellern wiederholt.  Dar√ºber hinaus wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Augmented Reality</a> auf Smartphones und Tablets der Haupttreiber der n√§chsten Stufe sein, der es heute an Genauigkeit und der F√§higkeit mangelt, eine dreidimensionale Szene zu "sehen". <br><br>  <b>Wovon h√§ngt der Begriff ab?</b> <br><br>  Die M√∂glichkeit, die Entfernung mit dem Hauptsensor in Echtzeit zu messen, wird mit Google Pixel wahrscheinlich bald verf√ºgbar sein, da sich Google seit langem in diese Richtung entwickelt (siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projekt Tango</a> , das geschlossen ist, dessen Gesch√§ft jedoch weiterlebt).  Und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ARCore</a> sieht ebenso vielversprechend aus wie das konkurrierende <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ARKit</a> .  Und der Durchbruch muss, wie Sie jetzt erraten haben, nicht lange warten, da der Wert des Sensorpixels exponentiell abf√§llt, die Durchschnittsgeschwindigkeit in 10 Jahren 10-mal genannt wird und wir einen 2-mal-Abfall ben√∂tigen.  Dann z√§hlen Sie selbst.  Nicht morgen, aber nicht lange. <br><br><h1>  Anstelle einer Schlussfolgerung </h1><br>  Denken Sie daran, dass wir ganz am Anfang √ºber einen Vortrag bei VGIK gesprochen haben?  Ich muss sagen, dass ich nicht mit der Reaktion darauf gerechnet habe, die am Ende war.  Um es in einem Wort auszudr√ºcken, es war Trauer.  Wenn in zwei Worten, dann universelle Trauer.  Und zuerst verstand ich nicht, was los war.  Der Operator, der nach der Vorlesung auftauchte, erkl√§rte mir die Situation sehr gut.  Es war nicht einmal so, dass die Kamerakunst nachlie√ü.  Obwohl es ein gro√üartiges Beispiel gab: Ein Filmfragment f√ºr ungef√§hr 6 Sekunden, wenn sich eine Person der T√ºr der Wohnung n√§hert, klopft, eine andere Person die T√ºr √∂ffnet, gr√º√üt und sich ein wenig vorw√§rts bewegt, w√§hrend die Kamera auf den Korridor, dann auf den T√ºrrahmen fokussiert und dann sofort fokussiert auf die Person, die es entdeckt hat, und dann in den Raum.  Und der Bediener muss die Kamera perfekt beherrschen, damit er bei einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kino√§hnlichen geringen Sch√§rfentiefe</a> den Zoom meisterhaft bedienen und dabei die Hintergrundbeleuchtung, die Zusammensetzung des Rahmens, die Reisekrankheit beim Fotografieren mit den H√§nden und weitere 1000 wichtige Kleinigkeiten ber√ºcksichtigen kann.  Also.  Es ist nicht einmal so, dass dies einfacher wird.  Das ist sogar gut.  Weniger Aufnahmen werden durch die Tatsache verdorben, dass der Bediener irgendwo keine Zeit hatte oder vers√§umt hat.  Er erz√§hlte, wie k√ºrzlich er eine Serie in 4K f√ºr den Sender gedreht hat.  Und der Bestand an Aufl√∂sungen erwies sich als gro√ü.  Infolgedessen schnitt der Regisseur die Rahmen in der Postproduktion, und an einigen Stellen wurden nur Fragmente des Rahmens f√ºr Unterbrechungen verwendet.  Infolgedessen war die Komposition einfach schrecklich und dieser Betreiber wollte seinen Namen aus dem Abspann entfernen. <br><br>  Die oben beschriebenen Merkmale von Kameras f√ºr Filmemacher bedeuten die √úbertragung vieler Effekte von der Drehphase auf die Postproduktion.  Und es wird sehr traurig sein, wenn diejenigen, die die aufgenommenen Szenen verarbeiten, Analphabeten in Sachen Komposition, Fokusentfernungskontrolle usw. sind.  Wenn sie lesen und schreiben k√∂nnen, sind dies neue fantastische M√∂glichkeiten. <br><br>  <b>Wir w√ºnschen uns allen mehr Kompetenz, was in dieser sich schnell ver√§ndernden Welt nicht immer einfach ist!</b> <br><br>  <b>Und <s>Karthago wird ...</s> bis zum Ende des Jahrhunderts <s>wird das</s> gesamte Video dreidimensional sein!</b> <br><br><h1>  Danksagung </h1><br>  Ich m√∂chte mich herzlich bedanken bei: <br><br><ul><li>  Labor f√ºr Computergrafik VMK Moscow State University  MV Lomonosov f√ºr seinen Beitrag zur Entwicklung der Computergrafik in Russland und nicht nur <br></li><li>  Unsere Kollegen aus der Videogruppe, dank derer Sie diesen Artikel gesehen haben, <br></li><li>  pers√∂nlich Konstantin Kozhemyakov, der viel getan hat, um diesen Artikel besser und visueller zu machen, <br></li><li>  Jon Karafin, als er Leiter des Lichtfeldvideos in Lytro war, dank dessen wir fast angefangen haben, an der Verbesserung ihres Produkts zu arbeiten (und nicht aus Gr√ºnden gestartet sind, die au√üerhalb unserer Kontrolle oder von uns liegen), <br></li><li>  Lytro f√ºr ihren Beitrag zur Popularisierung von Lichtfeldern und ihre F√§higkeiten, Google, das die fallende Flagge eroberte, und andere Unternehmen, die Produkte auf der Basis dieser interessanten Technologie herstellen, <br></li><li>  und schlie√ülich vielen Dank an Sergey Lavrushkin, Roman Kazantsev, Ivan Molodetsky, Evgeny Kuptsov, Jegor Sklyarov, Evgeny Lyapustin und Denis Kondranin f√ºr eine gro√üe Anzahl vern√ºnftiger Kommentare und Korrekturen, die diesen Text viel besser gemacht haben! <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440652/">https://habr.com/ru/post/de440652/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440642/index.html">JetBrains Nacht in Moskau, 13. April</a></li>
<li><a href="../de440644/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 352 (11. - 17. Februar 2019)</a></li>
<li><a href="../de440646/index.html">Frontend Weekly Digest (11. - 17. Februar 2019)</a></li>
<li><a href="../de440648/index.html">√úberblick √ºber die russische Gesetzgebung im Bereich der Barrierefreiheit im Internet</a></li>
<li><a href="../de440650/index.html">Wie Bewusstsein funktioniert: Schlussfolgerungen aus dem Buch von Alexander Nevzorov</a></li>
<li><a href="../de440654/index.html">Python lernen: Argparse-Modul</a></li>
<li><a href="../de440656/index.html">Professionelle Containerisierung von Node.js-Anwendungen mit Docker</a></li>
<li><a href="../de440658/index.html">Exploring Docker, Teil 4: Reduzieren der Gr√∂√üe von Bildern und Beschleunigen ihrer Montage</a></li>
<li><a href="../de440660/index.html">Docker lernen, Teil 5: Befehle</a></li>
<li><a href="../de440662/index.html">React Tutorial Teil 18: Die sechste Phase der Arbeit an einer TODO-Anwendung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
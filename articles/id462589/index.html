<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📝 👨‍👨‍👧 🧓 Buat saluran pipa untuk memproses data streaming. Bagian 2 👨🏻‍💻 👩🏼‍🎓 🌫️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya. Kami membagikan terjemahan dari bagian akhir artikel, disiapkan khusus untuk siswa kursus Data Engineer . Bagian pertama dapat ditemuka...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Buat saluran pipa untuk memproses data streaming. Bagian 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/462589/">  Halo semuanya.  Kami membagikan terjemahan dari bagian akhir artikel, disiapkan khusus untuk siswa kursus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Data Engineer</a> .  Bagian pertama dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . <br><br>  <b><i>Apache Beam dan DataFlow untuk jaringan pipa real-time</i></b> <br><br><img src="https://habrastorage.org/webt/9t/uy/au/9tuyauggjylmprwx7lxswwbqggi.png"><br><br><h2>  Pengaturan Google Cloud </h2><br><blockquote>  Catatan: Saya menggunakan Google Cloud Shell untuk memulai pipeline dan menerbitkan data log pengguna, karena saya punya masalah menjalankan pipeline di Python 3. Google Cloud Shell menggunakan Python 2, yang lebih kompatibel dengan Apache Beam. </blockquote><br>  Untuk memulai conveyor, kita perlu mempelajari sedikit pengaturannya.  Bagi Anda yang belum pernah menggunakan GCP sebelumnya, Anda harus menyelesaikan 6 langkah berikut di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">halaman</a> ini. <a name="habracut"></a><br><br>  Setelah itu, kami perlu mengunggah skrip kami ke Google Cloud Storage dan menyalinnya ke Google Cloud Shel kami.  Mengunggah ke penyimpanan cloud cukup sepele (deskripsi dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ).  Untuk menyalin file kami, kami dapat membuka Google Cloud Shel dari toolbar dengan mengklik ikon pertama di sebelah kiri pada Gambar 2 di bawah ini. <br><br><img src="https://habrastorage.org/webt/su/hz/hq/suhzhqrmyvi6c5hneokqhhhqjuw.png"><br>  <i>Gambar 2</i> <br><br>  Perintah yang kita butuhkan untuk menyalin file dan menginstal perpustakaan yang diperlukan tercantum di bawah ini. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Copy file from cloud storage gsutil cp gs://&lt;YOUR-BUCKET&gt;/ * . sudo pip install apache-beam[gcp] oauth2client==3.0.0 sudo pip install -U pip sudo pip install Faker==1.0.2 # Environment variables BUCKET=&lt;YOUR-BUCKET&gt; PROJECT=&lt;YOUR-PROJECT&gt;</span></span></code> </pre> <br><h2>  Membuat database dan tabel kami </h2><br>  Setelah kita menyelesaikan semua langkah konfigurasi, hal selanjutnya yang perlu kita lakukan adalah membuat dataset dan tabel di BigQuery.  Ada beberapa cara untuk melakukan ini, tetapi yang paling mudah adalah menggunakan konsol Google Cloud dengan terlebih dahulu membuat dataset.  Anda bisa mengikuti langkah-langkah di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan</a> berikut untuk membuat tabel dengan skema.  Tabel kami akan memiliki <b>7 kolom yang</b> sesuai dengan komponen setiap log pengguna.  Untuk kenyamanan, kami akan mendefinisikan semua kolom sebagai string (tipe string), dengan pengecualian variabel timelocal, dan beri nama sesuai dengan variabel yang kami buat sebelumnya.  Tata letak tabel kita akan terlihat seperti Gambar 3. <br><br><img src="https://habrastorage.org/webt/zw/ts/pz/zwtspziwiubrmz0c860bmvoe3so.png"><br>  <i>Gambar 3. Tata letak tabel</i> <br><br><h2>  Publikasikan data log pengguna </h2><br>  Pub / Sub adalah komponen penting dari pipa kami karena memungkinkan beberapa aplikasi independen untuk saling berinteraksi.  Secara khusus, ini berfungsi sebagai perantara yang memungkinkan kami untuk mengirim dan menerima pesan antar aplikasi.  Hal pertama yang perlu kita lakukan adalah membuat topik.  Cukup buka Pub / Sub di konsol dan tekan CREATE TOPIC. <br><br>  Kode di bawah ini memanggil skrip kami untuk menghasilkan data log yang ditentukan di atas, dan kemudian menghubungkan dan mengirim log ke Pub / Sub.  Satu-satunya hal yang perlu kita lakukan adalah membuat objek <b>PublisherClient</b> , tentukan path ke topik menggunakan metode <code>topic_path</code> dan panggil fungsi <code>publish</code> dengan <code>topic_path</code> dan data.  Harap perhatikan bahwa kami mengimpor <code>generate_log_line</code> dari skrip <code>stream_logs</code> kami, jadi pastikan bahwa file-file ini berada di folder yang sama, jika tidak Anda akan mendapatkan kesalahan impor.  Kemudian kita dapat menjalankan ini melalui konsol google kita menggunakan: <br><br><pre> <code class="python hljs">python publish.py</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> stream_logs <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> generate_log_line <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pubsub_v1 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time PROJECT_ID=<span class="hljs-string"><span class="hljs-string">"user-logs-237110"</span></span> TOPIC = <span class="hljs-string"><span class="hljs-string">"userlogs"</span></span> publisher = pubsub_v1.PublisherClient() topic_path = publisher.topic_path(PROJECT_ID, TOPIC) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">publish</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(publisher, topic, message)</span></span></span><span class="hljs-function">:</span></span> data = message.encode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> publisher.publish(topic_path, data = data) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">callback</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(message_future)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># When timeout is unspecified, the exception method waits indefinitely. if message_future.exception(timeout=30): print('Publishing message on {} threw an Exception {}.'.format( topic_name, message_future.exception())) else: print(message_future.result()) if __name__ == '__main__': while True: line = generate_log_line() print(line) message_future = publish(publisher, topic_path, line) message_future.add_done_callback(callback) sleep_time = random.choice(range(1, 3, 1)) time.sleep(sleep_time)</span></span></code> </pre> <br>  Segera setelah file dimulai, kita dapat mengamati output data log ke konsol, seperti yang ditunjukkan pada gambar di bawah ini.  Script ini akan berfungsi sampai kita menggunakan <b>CTRL + C</b> untuk menyelesaikannya. <br><br><img src="https://habrastorage.org/webt/ho/4c/6n/ho4c6n5yfnnv8pvetgkidvut-q0.png"><br>  <i>Gambar 4. Output dari <code>publish_logs.py</code></i> <i><br></i> <br><br><h2>  Menulis kode untuk saluran pipa kami </h2><br>  Sekarang kami telah menyiapkan segalanya, kami dapat melanjutkan ke bagian yang paling menarik - menulis kode pipa kami menggunakan Beam dan Python.  Untuk membuat pipa Beam, kita perlu membuat objek pipa (p).  Setelah kami membuat objek pipa, kami dapat menerapkan beberapa fungsi satu demi satu menggunakan operator <code>pipe (|)</code> .  Secara umum, alur kerjanya terlihat seperti gambar di bawah ini. <br><br><pre> <code class="python hljs">[Final Output PCollection] = ([Initial Input PCollection] | [First Transform] | [Second Transform] | [Third Transform])</code> </pre> <br>  Dalam kode kami, kami akan membuat dua fungsi yang ditentukan pengguna.  Fungsi <code>regex_clean</code> , yang memindai data dan mengambil baris terkait berdasarkan daftar POLA menggunakan fungsi pencarian ulang.  Fungsi mengembalikan string yang dipisahkan koma.  Jika Anda bukan ahli ekspresi reguler, saya sarankan Anda membaca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tutorial</a> ini dan berlatih di notepad untuk memeriksa kode.  Setelah itu, kita mendefinisikan fungsi ParDo kustom yang disebut <b>Split</b> , yang merupakan variasi dari transformasi Beam untuk pemrosesan paralel.  Dengan Python, ini dilakukan dengan cara khusus - kita harus membuat kelas yang mewarisi dari kelas DoFn Beam.  Fungsi Split mengambil string yang diurai dari fungsi sebelumnya dan mengembalikan daftar kamus dengan kunci yang sesuai dengan nama kolom di tabel BigQuery kami.  Ada sesuatu yang perlu diperhatikan tentang fungsi ini: Saya harus mengimpor <code>datetime</code> di dalam fungsi untuk membuatnya berfungsi.  Saya menerima kesalahan impor di awal file, yang aneh.  Daftar ini kemudian diteruskan ke fungsi <b>WriteToBigQuery</b> , yang hanya menambahkan data kami ke tabel.  Kode untuk Pekerjaan Batch DataFlow dan Streaming Pekerjaan DataFlow ditampilkan di bawah ini.  Satu-satunya perbedaan antara batch dan stream code adalah bahwa dalam pemrosesan batch kami membaca CSV dari <code>src_path</code> menggunakan fungsi <code>ReadFromText</code> dari Beam. <br><br><h2>  Pekerjaan Batch DataFlow (pemrosesan paket) </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> apache_beam <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> beam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apache_beam.options.pipeline_options <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PipelineOptions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> bigquery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys PROJECT=<span class="hljs-string"><span class="hljs-string">'user-logs-237110'</span></span> schema = <span class="hljs-string"><span class="hljs-string">'remote_addr:STRING, timelocal:STRING, request_type:STRING, status:STRING, body_bytes_sent:STRING, http_referer:STRING, http_user_agent:STRING'</span></span> src_path = <span class="hljs-string"><span class="hljs-string">"user_log_fileC.txt"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">regex_clean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> PATTERNS = [<span class="hljs-string"><span class="hljs-string">r'(^\S+\.[\S+\.]+\S+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r'(?&lt;=\[).+?(?=\])'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(\S+)\s(\S+)\s*(\S*)\"'</span></span>,<span class="hljs-string"><span class="hljs-string">r'\s(\d+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r"(?&lt;=\[).\d+(?=\])"</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"[AZ][az]+'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(http|https)://[az]+.[az]+.[az]+'</span></span>] result = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> match <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> PATTERNS: <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: reg_match = re.search(match, data).group() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> reg_match: result.append(reg_match) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: result.append(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print(<span class="hljs-string"><span class="hljs-string">"There was an error with the regex search"</span></span>) result = [x.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] result = [x.replace(<span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] res = <span class="hljs-string"><span class="hljs-string">','</span></span>.join(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Split</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime element = element.split(<span class="hljs-string"><span class="hljs-string">","</span></span>) d = datetime.strptime(element[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"%d/%b/%Y:%H:%M:%S"</span></span>) date_string = d.strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d %H:%M:%S"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [{ <span class="hljs-string"><span class="hljs-string">'remote_addr'</span></span>: element[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">'timelocal'</span></span>: date_string, <span class="hljs-string"><span class="hljs-string">'request_type'</span></span>: element[<span class="hljs-number"><span class="hljs-number">2</span></span>], <span class="hljs-string"><span class="hljs-string">'status'</span></span>: element[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'body_bytes_sent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">4</span></span>], <span class="hljs-string"><span class="hljs-string">'http_referer'</span></span>: element[<span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'http_user_agent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">6</span></span>] }] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> p = beam.Pipeline(options=PipelineOptions()) (p | <span class="hljs-string"><span class="hljs-string">'ReadData'</span></span> &gt;&gt; beam.io.textio.ReadFromText(src_path) | <span class="hljs-string"><span class="hljs-string">"clean address"</span></span> &gt;&gt; beam.Map(regex_clean) | <span class="hljs-string"><span class="hljs-string">'ParseCSV'</span></span> &gt;&gt; beam.ParDo(Split()) | <span class="hljs-string"><span class="hljs-string">'WriteToBigQuery'</span></span> &gt;&gt; beam.io.WriteToBigQuery(<span class="hljs-string"><span class="hljs-string">'{0}:userlogs.logdata'</span></span>.format(PROJECT), schema=schema, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND) ) p.run() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: logger = logging.getLogger().setLevel(logging.INFO) main()</code> </pre> <br><br><h2>  Pekerjaan Streaming DataFlow </h2><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apache_beam.options.pipeline_options <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PipelineOptions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pubsub_v1 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> bigquery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> apache_beam <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> beam <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> argparse <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re PROJECT=<span class="hljs-string"><span class="hljs-string">"user-logs-237110"</span></span> schema = <span class="hljs-string"><span class="hljs-string">'remote_addr:STRING, timelocal:STRING, request_type:STRING, status:STRING, body_bytes_sent:STRING, http_referer:STRING, http_user_agent:STRING'</span></span> TOPIC = <span class="hljs-string"><span class="hljs-string">"projects/user-logs-237110/topics/userlogs"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">regex_clean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> PATTERNS = [<span class="hljs-string"><span class="hljs-string">r'(^\S+\.[\S+\.]+\S+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r'(?&lt;=\[).+?(?=\])'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(\S+)\s(\S+)\s*(\S*)\"'</span></span>,<span class="hljs-string"><span class="hljs-string">r'\s(\d+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r"(?&lt;=\[).\d+(?=\])"</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"[AZ][az]+'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(http|https)://[az]+.[az]+.[az]+'</span></span>] result = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> match <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> PATTERNS: <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: reg_match = re.search(match, data).group() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> reg_match: result.append(reg_match) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: result.append(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print(<span class="hljs-string"><span class="hljs-string">"There was an error with the regex search"</span></span>) result = [x.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] result = [x.replace(<span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] res = <span class="hljs-string"><span class="hljs-string">','</span></span>.join(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Split</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime element = element.split(<span class="hljs-string"><span class="hljs-string">","</span></span>) d = datetime.strptime(element[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"%d/%b/%Y:%H:%M:%S"</span></span>) date_string = d.strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d %H:%M:%S"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [{ <span class="hljs-string"><span class="hljs-string">'remote_addr'</span></span>: element[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">'timelocal'</span></span>: date_string, <span class="hljs-string"><span class="hljs-string">'request_type'</span></span>: element[<span class="hljs-number"><span class="hljs-number">2</span></span>], <span class="hljs-string"><span class="hljs-string">'body_bytes_sent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'status'</span></span>: element[<span class="hljs-number"><span class="hljs-number">4</span></span>], <span class="hljs-string"><span class="hljs-string">'http_referer'</span></span>: element[<span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'http_user_agent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">6</span></span>] }] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(argv=None)</span></span></span><span class="hljs-function">:</span></span> parser = argparse.ArgumentParser() parser.add_argument(<span class="hljs-string"><span class="hljs-string">"--input_topic"</span></span>) parser.add_argument(<span class="hljs-string"><span class="hljs-string">"--output"</span></span>) known_args = parser.parse_known_args(argv) p = beam.Pipeline(options=PipelineOptions()) (p | <span class="hljs-string"><span class="hljs-string">'ReadData'</span></span> &gt;&gt; beam.io.ReadFromPubSub(topic=TOPIC).with_output_types(bytes) | <span class="hljs-string"><span class="hljs-string">"Decode"</span></span> &gt;&gt; beam.Map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>)) | <span class="hljs-string"><span class="hljs-string">"Clean Data"</span></span> &gt;&gt; beam.Map(regex_clean) | <span class="hljs-string"><span class="hljs-string">'ParseCSV'</span></span> &gt;&gt; beam.ParDo(Split()) | <span class="hljs-string"><span class="hljs-string">'WriteToBigQuery'</span></span> &gt;&gt; beam.io.WriteToBigQuery(<span class="hljs-string"><span class="hljs-string">'{0}:userlogs.logdata'</span></span>.format(PROJECT), schema=schema, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND) ) result = p.run() result.wait_until_finish() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: logger = logging.getLogger().setLevel(logging.INFO) main()</code> </pre><br><h2>  Konveyor mulai </h2><br>  Kita dapat memulai jalur pipa dengan beberapa cara berbeda.  Jika kami mau, kami bisa menjalankannya secara lokal dari terminal, dari jarak jauh masuk ke GCP. <br><br><pre> <code class="python hljs">python -m main_pipeline_stream.py \ --input_topic <span class="hljs-string"><span class="hljs-string">"projects/user-logs-237110/topics/userlogs"</span></span> \ --streaming</code> </pre> <br>  Namun, kami akan meluncurkannya menggunakan DataFlow.  Kita dapat melakukan ini menggunakan perintah di bawah ini dengan mengatur parameter yang diperlukan berikut ini. <br><br><ul><li>  <code>project</code> - ID proyek GCP Anda. </li><li>  <code>runner</code> adalah <code>runner</code> pipa yang akan menganalisis program Anda dan membangun pipa Anda.  Untuk berjalan di cloud, Anda harus menentukan DataflowRunner. </li><li>  <code>staging_location</code> - Jalur ke penyimpanan cloud Cloud Dataflow untuk mengindeks paket kode yang diperlukan oleh penangan proses. </li><li>  <code>temp_location</code> - path ke Cloud Dataflow penyimpanan cloud untuk meng-host file pekerjaan sementara yang dibuat selama operasi pipa. </li><li> <code>streaming</code> </li> </ul><br><pre> <code class="python hljs">python main_pipeline_stream.py \ --runner DataFlow \ --project $PROJECT \ --temp_location $BUCKET/tmp \ --staging_location $BUCKET/staging --streaming</code> </pre><br>  Ketika perintah ini sedang berjalan, kita bisa pergi ke tab DataFlow di konsol google dan melihat pipeline kita.  Dengan mengklik pada pipeline, kita akan melihat sesuatu yang mirip dengan Gambar 4. Untuk keperluan debugging, akan sangat berguna untuk pergi ke log dan kemudian ke Stackdriver untuk melihat log detail.  Ini membantu saya menyelesaikan masalah dengan saluran pipa di sejumlah kasus. <br><br><img src="https://habrastorage.org/webt/7p/ai/vu/7paivucaa-lfkgvfzta6aozjs1q.png"><br>  <i>Gambar 4: Konveyor Balok</i> <br><br><h2>  Akses data kami di BigQuery </h2><br>  Jadi, kita seharusnya sudah memulai jalur pipa dengan data yang masuk ke tabel kita.  Untuk menguji ini, kita bisa pergi ke BigQuery dan melihat datanya.  Setelah menggunakan perintah di bawah ini, Anda akan melihat beberapa baris pertama dari kumpulan data.  Sekarang kami memiliki data yang disimpan di BigQuery, kami dapat melakukan analisis lebih lanjut, serta berbagi data dengan rekan kerja dan mulai menjawab pertanyaan bisnis. <br><br><pre> <code class="python hljs">SELECT * FROM `user-logs<span class="hljs-number"><span class="hljs-number">-237110.</span></span>userlogs.logdata` LIMIT <span class="hljs-number"><span class="hljs-number">10</span></span>;</code> </pre> <br><img src="https://habrastorage.org/webt/ch/je/x_/chjex_xkpbc61hjrcft2qq06uuo.png"><br>  <i>Gambar 5: BigQuery</i> <br><br><h2>  Kesimpulan </h2><br>  Kami berharap posting ini akan berfungsi sebagai contoh yang berguna untuk membuat pipa data streaming, serta menemukan cara untuk membuat data lebih mudah diakses.  Menyimpan data dalam format ini memberi kita banyak keuntungan.  Sekarang kita dapat mulai menjawab pertanyaan-pertanyaan penting, misalnya, berapa banyak orang yang menggunakan produk kita?  Apakah basis pengguna bertambah seiring waktu?  Aspek apa dari produk yang paling berinteraksi dengan orang?  Dan adakah kesalahan yang seharusnya tidak terjadi?  Ini adalah masalah yang akan menarik bagi organisasi.  Berdasarkan gagasan yang muncul dari jawaban atas pertanyaan-pertanyaan ini, kami akan dapat meningkatkan produk dan meningkatkan minat pengguna. <br><br>  Balok sangat berguna untuk jenis latihan ini, dan juga memiliki sejumlah kasus penggunaan menarik lainnya.  Misalnya, Anda dapat menganalisis data tentang kutu tukar secara real time dan melakukan transaksi berdasarkan analisis, mungkin Anda memiliki data sensor yang berasal dari kendaraan, dan Anda ingin menghitung perhitungan tingkat lalu lintas.  Anda juga dapat, misalnya, menjadi perusahaan game yang mengumpulkan data pengguna dan menggunakannya untuk membuat dasbor untuk melacak metrik kunci.  Oke, tuan-tuan, topik ini sudah untuk posting lain, terima kasih sudah membaca, dan bagi mereka yang ingin melihat kode lengkap, di bawah ini adalah tautan ke GitHub saya. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://github.com/DFoly/User_log_pipeline</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><br></a> <br><br>  Itu saja.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Baca bagian pertama</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id462589/">https://habr.com/ru/post/id462589/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id462577/index.html">Pengalaman Pengembangan Nim Saya</a></li>
<li><a href="../id462581/index.html">Bagaimana kami mengatur penyewaan elektronik pertama dan apa yang menyebabkannya</a></li>
<li><a href="../id462583/index.html">Temui Pointer Detektor Sampah Deterministik</a></li>
<li><a href="../id462585/index.html">Pembuatan CRUD cepat dengan sarang, @ nestjsx / kasar dan TestMace</a></li>
<li><a href="../id462587/index.html">AirTest IDE dan Image Recognition - Otomatisasi pengujian game seluler berdasarkan pengenalan gambar</a></li>
<li><a href="../id462593/index.html">Di sisi lain dudukan</a></li>
<li><a href="../id462595/index.html">Audit dan pengujian surat: apa yang harus Anda perhatikan saat tata letak</a></li>
<li><a href="../id462597/index.html">Mengetik naskah dan bereaksi</a></li>
<li><a href="../id462601/index.html">Mencadangkan server windows di AWS</a></li>
<li><a href="../id462605/index.html">Jejak Italia dalam kriptografi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
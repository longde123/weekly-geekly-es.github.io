<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚èπÔ∏è üòü üìó Und mehr √ºber Sorten üõéÔ∏è üéë üé∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Und mehr √ºber Sorten 
 Ich w√ºrde es wagen, dieses Thema noch einmal anzusprechen. Ich beginne mit einem Link zu einem Artikel von Mikhail Opanasenko (...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Und mehr √ºber Sorten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/467473/"><h1>  Und mehr √ºber Sorten </h1><br>  Ich w√ºrde es wagen, dieses Thema noch einmal anzusprechen.  Ich beginne mit einem Link zu einem Artikel von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mikhail Opanasenko (oms7)</a> , der sowohl hinsichtlich des Arbeitsaufwands als auch der Anzahl der zitierten Links sehr beeindruckend ist.  Er begann, sein Material vorzubereiten, ohne √ºber diese Ver√∂ffentlichung Bescheid zu wissen, was nach seiner Einarbeitung zu der Notwendigkeit f√ºhrte, es inhaltlich zu verarbeiten.  F√ºr diejenigen, die diesen Artikel bereits gelesen haben, informiere ich Sie, dass in meinem Material verschiedene Arten von Daten untersucht werden, insbesondere Zeichenfolgen und reelle Zahlen, die Boost- und BSD-Bibliotheken verwendet werden und einige andere Themen, die im Artikel fehlen, erw√§hnt werden. <br><a name="habracut"></a><br>  Es gibt Dutzende verschiedener M√∂glichkeiten, Datenelemente in der richtigen Reihenfolge anzuordnen.  Unter ihnen gibt es solche, die schnell arbeiten, so dass sie beispielsweise jedes Datenarray im RAM des Computers in maximal wenigen Minuten sortieren k√∂nnen.  Insbesondere kann gesagt werden, dass durch schnelles Sortieren eine Milliarde Ganzzahlen in einem guten modernen Personal Computer in weniger als hundert Sekunden organisiert werden.  Wenn Sie primitive, langsame Methoden verwenden, z. B. Blasensortierung oder Auswahlsortierung, um eine gr√∂√üere Anzahl von Elementen zu sortieren, kann die f√ºr eine solche Datenverarbeitung aufgewendete Zeit alle Erwartungen √ºbertreffen - eine solche ‚ÄûVerarbeitung‚Äú kann tats√§chlich mehrere Tage, Wochen und sogar Jahre dauern.  Dieser gro√üe Unterschied wird durch die Tatsache verursacht, dass die Sortierzeit durch schnelle Methoden ungef√§hr proportional zu <i>N</i> log <i>N</i> und primitiv - <i>N</i> <sup>2 ist</sup> .  Mit zunehmendem <i>N wird der</i> Unterschied zwischen den beiden Werten sehr deutlich.  Daher ist es sinnvoll, primitive Methoden nur f√ºr die Arbeit mit kleinen Daten zu verwenden, beispielsweise auf modernen Computern mit bis zu mehreren tausend Elementen.  Es ist auch selbstverst√§ndlich, sie zum Unterrichten der Grundlagen des Programmierens und des logischen Denkens zu verwenden, da sie viel einfacher sind als schnelle Methoden. <br><br>  Ich m√∂chte die Sortiermethoden verstehen, die in den aktuellen Standardbibliotheken vorhanden sind.  Finden Sie heraus, wie gro√ü der Unterschied zwischen ihnen in Bezug auf ihre Hauptmerkmale, Arbeitsgeschwindigkeit und auch ihre charakteristischen Merkmale ist.  Dar√ºber hinaus werden wir auf dem Weg zum Vergleich und f√ºr den Verstand einige Methoden betrachten, die nicht schwer zu implementieren sind.  Es ist auch erw√§hnenswert, dass der Optimierer des GCC-Compilers und m√∂glicherweise anderer guter Compiler sehr gut mit Sortierungen zusammenarbeitet und den Code mehrmals beschleunigt (manchmal sogar mehr als f√ºnfmal). <br><br>  Beginnen wir mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der</a> Blasensortiermethode als der einfachsten und langsamsten.  Nach dieser Methode m√ºssen Sie das Datenarray immer wieder durchgehen, benachbarte Elemente vergleichen und ihre Positionen √§ndern, wenn die Reihenfolge zwischen ihnen unterbrochen ist.  Nach jedem Durchgang befindet sich mindestens ein Element (das gr√∂√üte oder kleinste - abh√§ngig von der ausgew√§hlten Reihenfolge) an seiner Stelle.  Neben der Einfachheit hat dieses Verfahren einen weiteren Vorteil: Es ben√∂tigt keinen zus√§tzlichen Speicher.  Ein weiteres Merkmal der Blasenmethode ist: Sie verarbeitet die bereits bestellten Daten sehr schnell und macht sie in einigen F√§llen zu einer der schnellsten Methoden.  Wenn die Daten nur teilweise geordnet sind, funktioniert diese Methode schneller, in den meisten F√§llen jedoch nur geringf√ºgig.  F√ºr Tests habe ich die folgende <a href="">Implementierung verwendet</a> . <br><br>  Eine andere langsame Methode ist die Auswahlsortierung.  Hier werden bei jedem Durchgang zuerst die gr√∂√üten und kleinsten Elemente in den Daten gefunden, und dann werden diese Elemente an den Extrempositionen platziert, die der ausgew√§hlten Reihenfolge entsprechen.  Beim n√§chsten Durchgang sortieren wir die Daten ohne diese extremen Elemente.  Diese Methode ist so einfach wie das Sortieren von Blasen und erfordert keinen zus√§tzlichen Speicher, ist jedoch sp√ºrbar schneller.  Dar√ºber hinaus f√ºhrt das Sortieren nach dieser Methode eine Mindestanzahl von Permutationen von Datenelementen auf.  Wenn Permutationen viel langsamer als Vergleiche sind, kann daher die Reihenfolge nach dem Auswahlverfahren akzeptabel sein, wenn die Anzahl der Datenelemente gering ist.  Hier ist meine <a href="">Implementierung</a> .  Diese Sortierung wird h√§ufiger durchgef√ºhrt, wobei nur ein Element pro Durchgang installiert wird.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Heap-</a> Sortierung (oder Pyramiden-Sortierung), die sp√§ter erl√§utert wird, ist die am weitesten fortgeschrittene Version der betreffenden Sortierung. <br><br>  Der Code f√ºr die zuletzt betrachtete langsame Methode, die Einf√ºgesortierung, ist wahrscheinlich der k√ºrzeste aller Codes, die die Sortierung implementieren. Daher wird diese Methode manchmal von komplexen schnellen Sortierungen in F√§llen verwendet, in denen die Anzahl der zu sortierenden Elemente gering ist (mehrere Zehner).  Es √§hnelt dem Sortieren nach einer Blase, da hier und da die benachbarten Elemente nacheinander verglichen werden.  Das Sortieren nach Einf√ºgungen sucht jedoch nach dem n√§chsten Element f√ºr die richtige Position im bereits sortierten Teil der Daten und schiebt das extreme Element nicht nur an die extreme Position.  Bei diesem Ansatz wird auch kein zus√§tzlicher Speicher ben√∂tigt.  Wie bei der Blasensortierung ist die Einf√ºgungssortierung bei bestellten Daten sehr schnell und bei teilweise geordneten Daten schneller.  Im letzteren Fall deutlich schneller als die Blase.  Normalerweise ist das Sortieren nach Einf√ºgungen etwas schneller als das Sortieren nach Auswahl.  Und im Gegensatz zu letzterem ist es wie die Blasensortierung stabil.  Am schlimmsten ist, dass die Einf√ºgesortierung mit Daten in umgekehrter Reihenfolge funktioniert, wodurch sie manchmal die langsamste der langsamsten werden.  F√ºr Tests wurde die folgende <a href="">Implementierung</a> verwendet.  Sie kann etwas beschleunigt werden, wenn Sie nicht die lineare, sondern die bin√§re Suche verwenden, z. B. mit der Funktion std :: bsearch.  Eine signifikante Beschleunigung kann durch Verwendung einer Listentypstruktur erreicht werden, bei der das Einf√ºgen eines Elements sehr schnell erfolgt.  Sie k√∂nnen auch feststellen, dass dies die nat√ºrlichste Sortierung ist - sie wird beispielsweise normalerweise beim Kartenspielen intuitiv verwendet. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Shell-</a> Sortierung ist die einfachste unter den schnellen Methoden und eignet sich gut f√ºr Sch√ºler, die gerade erst mit dem Programmieren beginnen.  Es ist nur eine Modifikation der Blasensortierung.  Der einzige Unterschied zwischen ihnen besteht darin, dass bei der Shell-Sortierung der Abstand zwischen den verglichenen Elementen von Gang zu Gang variiert, vom gr√∂√üeren im ersten Durchgang bis zum 1 im letzten Durchgang, sodass die Shell-Methode in diesen letzten Durchg√§ngen zur primitiven Blasensortierung ausartet.  Donald Shell ver√∂ffentlichte den grundlegenden Sortieralgorithmus, der 1959 seinen Namen erhielt.  Somit ist dies eine der ersten universellen Sortierungen, die schnell arbeiten.  Zum Vergleich wurde der schnelle Sortieralgorithmus zwei Jahre sp√§ter ver√∂ffentlicht, und Tims beliebte Sortierung oder introspektive Sortierung wurde erst in den 90er Jahren bekannt.  Mit der Shell-Sortierung sind einige interessante ungel√∂ste mathematische Probleme verbunden, von denen das wichtigste darin besteht, die Verschiebungen zwischen den verglichenen Elementen optimal auszuw√§hlen.  Einige Aufzeichnungssequenzen wurden gefunden, zum Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">A102549</a> .  Solche Sequenzen werden durch kolossale Berechnungen gefunden, so dass sie eine sehr kurze L√§nge haben. A102549 besteht nur aus 8 Elementen, was nur f√ºr Daten bis zu etwa 3.000 Elementen ausreicht.  F√ºr Big Data m√ºssen Fortsetzungen fast zuf√§llig betrachtet werden.  Verwendete Werte nahe den Potenzen von 2, <i>e</i> , 2,25 und 3. Primzahlen nahe den Potenzen von 2 zeigten die schlechtesten Ergebnisse und waren den besten deutlich unterlegen.  Die anderen drei Optionen erwiesen sich jedoch als ungef√§hr gleich in Bezug auf die Auswirkungen auf die Leistung und wahrscheinlich sehr nahe am Optimum.  Dar√ºber hinaus ergab die Verwendung von Primzahlen in diesen drei F√§llen keine greifbaren Vorteile.  Es ist merkw√ºrdig, dass die auf Wikipedia vorgeschlagenen Verzerrungen (mit einer Basis von 2,25), die auf Verweisen auf die entsprechenden Werke beruhen, nicht die besten Ergebnisse bei den Tests zeigten, obwohl ihre Unterschiede zu den besten sehr unbedeutend waren (nicht mehr als 5-10%).  Die Verwendung von A102549 als Ausgangspunkt ergab ebenfalls keine erkennbaren Ergebnisse.  Mikhail Opanasenko versuchte auch, die Shell-Sortierung zu entschl√ºsseln und erzielte ein interessantes Ergebnis, dass die durch die Formel <i>s <sub>n + 1</sub> = 10s <sub>n</sub> / 3</i> ausgew√§hlten Verschiebungen einen sehr guten Effekt ergeben und vielleicht sogar nahezu ideal sind.  Meine Ergebnisse best√§tigen dies.  In vielen F√§llen waren es solche Verzerrungen, die das beste Ergebnis erbrachten, obwohl dies nicht immer der Fall war und die L√ºcke zum n√§chsten Ergebnis recht gering war (etwa 5%).  Mein <a href="">Code</a> zum Implementieren von Shell-Sortierungen verwendet kleine Tabellen mit Offsets. Wenn Sie jedoch keine Primzahlen verwenden, k√∂nnen diese Offsets f√ºr Tabellen fast sofort berechnet werden, wie dies bei der Implementierung einer der angegebenen Varianten dieser Sortierung der Fall war. <br><br>  Es ist interessant, dass wenn wir Offsets in der N√§he der Dreierpotenzen auf etwas andere Weise nehmen und einen etwas anderen Algorithmus verwenden (siehe <a href="">Implementierung</a> ), bei 32-Bit-Zahlen Geschwindigkeiten nahe am Besten erzielt werden, bei l√§ngeren Zahlen und Leitungen jedoch manchmal eine erhebliche Verlangsamung mehr als 100%.  Die Ergebnisse f√ºr den besten von oms7 verwendeten Algorithmus sind ebenfalls in der folgenden Tabelle aufgef√ºhrt. Obwohl er in der Reihenfolge gute Ergebnisse zeigt, bleibt er in Bezug auf die absoluten Werte deutlich hinter den F√ºhrenden zur√ºck. <br><br>  Wird es jemals einen Weg geben, die besten Offsets zu finden?  Vielleicht, aber ich wage zu behaupten, dass es nicht bald ist.  Die Shell-Sortierung wird im Linux-Kernel verwendet, und in mindestens einer C-Bibliothek wird der Code f√ºr die Standardfunktion qsort () verwendet.  Es wurde theoretisch bewiesen, dass die optimale Sortiergeschwindigkeit von Shell in der Reihenfolge nur geringf√ºgig langsamer ist als die ‚Äûechten‚Äú schnellen logarithmischen Methoden.  In der Tat wird die Abh√§ngigkeit der durchschnittlichen Datenverarbeitungszeit von ihrer Gr√∂√üe f√ºr eine optimale Shell-Sortierung durch die Formel ‚àΩ <i>N</i> (log <i>N</i> / log log <i>N</i> ) <sup>2 beschrieben</sup> , die selbst f√ºr sehr gro√ües <i>N</i> der f√ºr andere schnelle Methoden typischen Formel ‚àΩ <i>N</i> log <i>N</i> sehr nahe kommt.  Normalerweise ist die Shell-Sortierung in der Reihenfolge oft sogar schneller als theoretisch schnellere Methoden und ergibt sich nur geringf√ºgig, wenn ziemlich gro√üe Arrays (in der Gr√∂√üenordnung von 10 Millionen Elementen) verarbeitet werden.  Diese Sortierung ben√∂tigt absolut keinen zus√§tzlichen Speicher und verh√§lt sich stabil f√ºr eine Vielzahl von Optionen zum F√ºllen von Daten, verglichen mit einer schnellen Sortierung.  Die Shell-Methode besitzt nicht die Stabilit√§tseigenschaft. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die schnelle</a> Sortierung ist nur geringf√ºgig komplexer als der Shell-Algorithmus und immer noch eine der schnellsten Methoden zum Organisieren zuf√§llig gestreuter Daten.  Diese Sortierung weist jedoch mehrere Nachteile auf.  Sie braucht zus√§tzliches Ged√§chtnis und in sehr seltenen F√§llen arbeitet es extrem langsam, entsprechend einer quadratischen Abh√§ngigkeit.  Die Hauptidee dieser Methode besteht darin, die Daten in zwei Teile zu teilen: Die Daten in einem Teil sollten mehr oder weniger (abh√§ngig von der ausgew√§hlten Reihenfolge) als im anderen sein.  Es gibt verschiedene Methoden f√ºr diese Trennung.  Idealerweise sollten bei jeder Teilung beide Teile ungef√§hr gleich gro√ü sein, und am schlimmsten, wenn sich herausstellt, dass eines der Teile w√§hrend der Teilung nur aus einem Element besteht.  Betrachten wir mehrere Implementierungen von schnellen Sortieralgorithmen, insbesondere <a href="">die Hoar-Methode</a> , bei der ein Referenzelement, das Daten in zwei Teile teilt, aus der Mitte der sortierten Daten ausgew√§hlt wird. <br><br>  Wir betrachten auch den extrem kompakten <a href="">Lomuto-Algorithmus</a> , der manchmal etwas (etwa 1%) schneller ist als die betrachtete Hoare-Methode.  In typischen Sonderf√§llen, beispielsweise bei geordneten, inversen oder malovarianten Daten, zeigt die Lomuto-Methode jedoch extreme Langsamkeit.  Unter den Optionen, die f√ºr eine schnelle Sortierung in Betracht gezogen wurden, erwies sich dies als die gierigste f√ºr die Stapelgr√∂√üe w√§hrend praktischer L√§ufe: Beim Sortieren relativ kleiner Arrays hatte nur diese Sortierung nicht gen√ºgend 8 Megabyte f√ºr den Stapel, ich musste diese Gr√∂√üe durch ulimit mehr einstellen.  Diese Gier nach dem Stapel f√ºhrt zu gro√üen Verlangsamungen bei der Verarbeitung von Big Data (zig Millionen Zeilen), und ich habe Schwierigkeiten, seine Natur zu nennen.  Ich kann nur sagen, dass es besser ist, diese Sortierung aus dem n√§chsten Absatz nicht mit solchen Daten zu verwenden. <br><br>  Die Lomuto-Methode w√§hlt das letzte Element als Referenzelement aus, es ist jedoch m√∂glich, eine schnelle Sortierung ohne <a href="">unterst√ºtzendes Element</a> zu implementieren, genauer gesagt, die Auswahl eines solchen Elements erfolgt hier aufgrund einer bereits durchgef√ºhrten Datenhalbierung.  Es stellte sich heraus, dass diese Sortierung nach Geschwindigkeitseigenschaften der Lomuto-Methode nahe kommt, obwohl sie normalerweise etwas schneller ist und in extremen F√§llen merklich schneller als Lomuto, aber langsamer als Hoar. <br><br>  Im Jahr 2009 wurde ein Schnell-Sortier- <a href="">Algorithmus mit</a> zwei Ankern ver√∂ffentlicht, der zum Standard f√ºr die Java-Sprache wurde.  Dieser Algorithmus reduziert die Anzahl der Permutationen um 20% im Vergleich zu den besten typischen, aber die Anzahl der Vergleiche √§ndert sich nicht.  Sein Autor ist Vladimir Yaroslavsky.  Es funktioniert in der Regel wirklich schneller als andere schnelle Sorten.  Ich habe es ein wenig optimiert, indem ich die seit langem bekannte Tatsache verwendet habe, dass Swap in der x86-Architektur normalerweise schneller als die Zuweisung funktioniert und f√ºr C ++ - Zeichenfolgen viel, viel schneller ist.  Alle bisher ber√ºcksichtigten schnellen Sortierungen haben nicht die Stabilit√§tseigenschaft. <br><br>  Zus√§tzlicher Speicher f√ºr die schnelle Sortierung ist erforderlich, um rekursive Aufrufe zu organisieren.  Der zweite derartige Aufruf kann jedoch durch eine Schleife ersetzt werden, indem die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schwanzrekursion</a> optimiert wird, was in Bezug auf die Geschwindigkeit m√∂glicherweise keine Gewinne bringt, aber die Gr√∂√üe der verwendeten zus√§tzlichen Daten erheblich verringert.  Ich habe die Hoar-Sortieroption mit dieser Optimierung implementiert.  Dar√ºber hinaus k√∂nnen Sie in Systemprogrammen den Stapelzeiger √ºberpr√ºfen. Wenn er sich einem kritischen Wert n√§hert, k√∂nnen Sie einfach alle rekursiven Aufrufe zur√ºcksetzen und erneut mit dem Sortieren beginnen. In diesem Fall ist es offensichtlich, dass Sie die Option f√ºr die schnelle Sortierung verwenden m√ºssen, die beispielsweise bei fast geordneten Daten nicht langsamer wird , die oben vorgeschlagene Version von Hoar.  Die Bek√§mpfung der Verwendung von zus√§tzlichem Speicher kann als Hauptidee der schnellen Sortierung aus der Standard-C-Sprachbibliothek in GCC angesehen werden.  Es gab im Allgemeinen die Rekursion auf.  Stattdessen verwenden sie ihre Simulation, mit der ein Drittel die Belastung des Stapels reduzieren kann.  Der Code war ziemlich gro√ü, ungef√§hr 150 Zeilen.  √úber diese Sortierung wird es unten noch ein wenig Material geben. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Hash-</a> Sortierung kann sehr schnell sein, nahe ‚àΩ <i>N.</i>  Manchmal kann es jedoch zu einer quadratischen Abh√§ngigkeit kommen.  Die Geschwindigkeit dieser Sortiermethode h√§ngt stark von der Eingabe ab.  Wenn die Daten durch die Hash-Funktion gleichm√§√üig √ºber das Hilfsarray verteilt werden, erhalten wir die schnellste lineare Beziehung.  Und wenn alle Daten in der N√§he mehrerer weit voneinander entfernter "Massenschwerpunkte" gruppiert sind oder wenn es viele identische Datenelemente gibt, dh wenn viele Hash-Kollisionen auftreten, erhalten wir die schlimmste Abh√§ngigkeit vom Typ ‚àΩ <i>N</i> <sup>2</sup> .  Wie bei der Baumsortierung ben√∂tigen Sie zum Sortieren des Hashs eine Menge zus√§tzlicher Daten. In der folgenden Codeliste ben√∂tigen Sie beispielsweise 12 zus√§tzliche Bytes f√ºr jede sortierbare Ganzzahl (int32, x86-64).  Eine interessante Eigenschaft der Hash-Sortierung ist das Fehlen von Vergleichsoperationen zwischen Datenelementen, was diese Sortierung von allen oben betrachteten unterscheidet.  Genauer gesagt werden diese Operationen nur f√ºr Kollisionen ben√∂tigt.  Wenn Sie Daten sortieren, bei denen der Schl√ºssel mit dem gesamten Datenelement √ºbereinstimmt, k√∂nnen Sie einen zus√§tzlichen Z√§hler f√ºr die Anzahl identischer Elemente verwenden. Dies ist jedoch eher eine zweifelhafte Optimierung.  Sie k√∂nnen auch einen Bin√§rbaum anstelle einer Liste zum Speichern von Hash-Kollisionsdaten verwenden. Dies beschleunigt die Arbeit f√ºr einzelne Einzelf√§lle bei vielen Kollisionen erheblich. Insgesamt verlangsamt sich die Verwendung eines Bin√§rbaums jedoch in vielen F√§llen und dies trotz der Tatsache, dass in diesem Fall das Element Daten m√ºssen fast 100 Bytes zus√§tzlicher Informationen speichern.  Ich habe <a href="">drei Optionen f√ºr die</a> Hash-Sortierung mithilfe eines Bin√§rbaums implementiert: Eine verwendet einen ungeordneten Baum und die anderen beiden verwenden Standardb√§ume aus den Standard- und Boost-Bibliotheken.  Die Hash-Sortierung ist praktisch nicht zum Sortieren von Textzeichenfolgen geeignet, au√üer f√ºr sehr kurze, da es unm√∂glich ist, eine gute Hash-Funktion f√ºr solche Daten zu erstellen.  Ich konnte den Standard-C ++ - Hash (unordered_multiset) nicht zum Sortieren anpassen: Ich habe versucht, monotone Hash-Funktionen und Ordnungsbeziehungen anstelle von Gleichheit zu verwenden - dies hat nicht funktioniert. <br><br>  Die Array-Sortierung ist der vorherigen sehr √§hnlich.  Es wird auch ein Hilfsarray verwendet, in das Werte von der Hash-Funktion eingegeben werden.  Im Falle einer Kollision muss das fortlaufende Fragment der belegten Elemente nach links oder rechts verschoben werden, um die durch die Hash-Funktion f√ºr das neue Element angegebene Position freizugeben.  Um eine gute Geschwindigkeit zu erzielen, muss das Hilfsarray mehrmals (von 2-3) gr√∂√üer sein als das urspr√ºngliche.  Mit zunehmender Gr√∂√üe des Hilfsarrays steigt die Geschwindigkeit in Abh√§ngigkeit von den sortierten Daten und der damit verbundenen Hash-Funktion nur bis zu einem bestimmten Grenzwert an und nimmt dann (normalerweise von 4 bis 5) ab.  Die Betriebsgeschwindigkeit entspricht in etwa der des Hashs, ist jedoch bei guten Daten etwas schneller und bei schlechten Daten sp√ºrbar langsamer.  Diese Art ben√∂tigt auch viel zus√§tzlichen Speicher.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn wir die Anzahl der Elemente im sortierten Array auf etwas mehr als vier Milliarden beschr√§nken, ben√∂tigt ein dreifaches Hilfsarray die gleiche Menge zus√§tzlicher Daten wie das Sortieren mit einem Hash, und ein dreifaches ben√∂tigt 28 Bytes, was deutlich weniger ist als beim Sortieren nach einem Baum oder viel weniger als ein Hash mit B√§umen. Diese Sortierung ist auch f√ºr die Arbeit mit Strings fast ungeeignet. Es gibt keinen Wikipedia-Artikel √ºber einen solchen Algorithmus, aber hier ist meine </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Implementierung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interessant ist , </font><font style="vertical-align: inherit;">dass in einem guten Bewertung in Wikipedia, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in der </font><font style="vertical-align: inherit;">Regel gibt es keine Erw√§hnung solcher Zwischen Techniken, wie das Array sortieren und Hash, die zwischen Methoden auf einem Vergleich der Elemente basieren nat√ºrlich platziert sind, und Methoden basierend auf dem absoluten Wert der Elemente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine der schnellsten Sortierungen, bei denen √ºberhaupt keine Vergleiche verwendet werden, ist die seit dem 19. Jahrhundert bekannte </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">bitweise Sortierung</font></a><font style="vertical-align: inherit;"> .</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Radix-Sortierung). Ihre Idee ist sehr einfach - Sie m√ºssen mit Gruppen von Bits der Datendarstellung arbeiten (f√ºr Tests habe ich Gruppen von 8, 11 und 16 Bits genommen). F√ºr jede Gruppe werden Tabellen erstellt und die Ergebnisse auf relativ einfache Weise kombiniert. Es gibt zwei Hauptmethoden f√ºr die bitweise Sortierung. Es ist bequemer, die Ziffern zum Sortieren von Zahlen von rechts nach links zu verwenden (dies ist die Option LSD - Least Significant Digit) und zum Sortieren von Zeichenfolgen von links nach rechts (dies ist die Option MSD - Most Significant Digit). Die bitweise Sortierung ist h√§ufig erheblich schneller als jede andere Datenbestellmethode. √úberraschenderweise ist die Unterst√ºtzung f√ºr die bitweise Sortierung immer noch nicht sehr bedeutsam: Sie befindet sich weder im Boost noch in der Standard-C ++ - Bibliothek. Mir ist nicht einmal die Version f√ºr eine bekannte Bibliothek f√ºr die Arbeit mit C ++ - Zahlen oder Zeichenfolgen bekannt. Diese Art hatnat√ºrlich und Nachteile. Es ist sehr empfindlich gegen√ºber der Art der zu sortierenden Daten. Sie m√ºssen beispielsweise eine eigene Version dieser Sortierung f√ºr Daten jeder Gr√∂√üe haben, spezielle Optionen f√ºr vorzeichenlose und vorzeichenbehaftete Ganzzahlen festlegen und die Unterst√ºtzung f√ºr die Arbeit mit reellen Zahlen kann einen erheblichen Aufwand erfordern. Wenn die Reihenfolge vom niedrigstwertigen bis zum wichtigsten Byte verwendet wird, ben√∂tigt die Variante normalerweise zus√§tzlichen Speicher, etwas mehr als f√ºr die Anfangsdaten (dies ist erheblich weniger als f√ºr die Sortierung nach einem Hash oder Array und noch mehr nach einem Baum). Dar√ºber hinaus ist diese Option zum Sortieren langer Zeichenfolgen von geringem Nutzen. Mein Code f√ºr diese ArtSie m√ºssen spezielle Optionen f√ºr vorzeichenlose und vorzeichenbehaftete Ganzzahlen festlegen, und die Unterst√ºtzung f√ºr die Arbeit mit reellen Zahlen kann einen erheblichen Aufwand erfordern. Bei Verwendung der Reihenfolge vom niedrigstwertigen bis zum wichtigsten Byte ben√∂tigt die Variante normalerweise zus√§tzlichen Speicher, etwas mehr als f√ºr die Anfangsdaten (dies ist erheblich weniger als beim Sortieren nach einem Hash oder Array und noch mehr nach einem Baum). Dar√ºber hinaus ist diese Option zum Sortieren langer Zeichenfolgen von geringem Nutzen. Mein Code f√ºr diese ArtSie m√ºssen spezielle Optionen f√ºr vorzeichenlose und vorzeichenbehaftete Ganzzahlen festlegen, und die Unterst√ºtzung f√ºr die Arbeit mit reellen Zahlen kann einen erheblichen Aufwand erfordern. Wenn die Reihenfolge vom niedrigstwertigen bis zum wichtigsten Byte verwendet wird, ben√∂tigt die Variante normalerweise zus√§tzlichen Speicher, etwas mehr als f√ºr die Anfangsdaten (dies ist erheblich weniger als f√ºr die Sortierung nach einem Hash oder Array und noch mehr nach einem Baum). Dar√ºber hinaus ist diese Option zum Sortieren langer Zeichenfolgen von geringem Nutzen. Mein Code f√ºr diese ArtDiese Option eignet sich nicht zum Sortieren langer Zeichenfolgen. Mein Code f√ºr diese ArtDiese Option eignet sich nicht zum Sortieren langer Zeichenfolgen. Mein Code f√ºr diese Art</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> basiert es auf dem Code aus dem erw√§hnten oms7-Artikel. Die Option f√ºr die umgekehrte Bytereihenfolge ist vielseitiger und eignet sich sehr gut zum Sortieren von Zeichenfolgen. Diese Option kann ohne Verwendung zus√§tzlichen Speichers implementiert werden (der Preis hierf√ºr ist der Verlust der Stabilit√§tseigenschaft), wie dies in der Funktion radixsort () der bsd-Bibliothek der Fall ist. Mein </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√ºr diese Option basiert sie ebenfalls auf dem oms7-Code. Sie verwendet zus√§tzlichen Speicher, etwas gr√∂√üere Quelldaten, hat die Stabilit√§tseigenschaft, ist jedoch nicht f√ºr Zeichenfolgen optimiert und weist daher deutlich schlechtere Leistungseigenschaften auf als die √§hnliche Funktion sradixsort () aus der bereits erw√§hnten bsd-Bibliothek . Diese Sortierung kann √ºberraschend schlechte Ergebnisse zeigen, wenn mit kleinen numerischen Arrays gearbeitet wird, die mehrere Gr√∂√üenordnungen langsamer als gerade Blasen arbeiten, obwohl es sich um sehr kleine Werte von nicht mehr als einigen Millisekunden handelt und dieser Unterschied nicht leicht zu bemerken ist. Dies liegt an der Tatsache, dass Hilfsarrays kleiner Gr√∂√üe verwendet werden. Beim Sortieren von Daten kleiner Gr√∂√üe k√∂nnen diese kleinen Gr√∂√üen jedoch gr√∂√üer sein als die sortierten Daten selbst.Um Verlangsamungen zu vermeiden, verwendet die Option "von links nach rechts" in solchen F√§llen die Einf√ºgesortierung anstelle der Hauptsortierung. Zusammenfassend ist anzumerken, dass dies die einzige mir bekannte relativ beliebte Sortierung ist, die immer zuverl√§ssig mit einer Geschwindigkeit von ‚àΩ arbeitet</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , aber der Proportionalit√§tskoeffizient h√§ngt hier von der Gr√∂√üe der Datenelemente ab und kann f√ºr Zeichenfolgen oder lange Zahlen durchaus erkennbar sein. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ausf√ºhrungsbeispiel MSD radix Sortieranlage zu sortieren ist </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Strahl</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eine Datenstruktur , </font><font style="vertical-align: inherit;">die effektiv zuzuordnen Schl√ºssel assoziative Array erm√∂glicht. Meine </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Implementierung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> erwies sich trotz der Optimierung der Speichernutzung immer noch als sehr gierig. Durch die Geschwindigkeit wurden die besten Ergebnisse beim Sortieren langer Zeilen erzielt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Weiter werden wir einige Sortierungen betrachten, die in Standardbibliotheken zu finden sind.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beginnen wir mit der schnellen aus der Standard-C-Bibliothek (qsort, eine Variante von GCC), √ºber die ich bereits geschrieben habe. Ich kann hier nur hinzuf√ºgen, dass diese Sortierung sowie andere C-Sortierungen (z. B. die folgenden aus der BSD-Bibliothek) f√ºr die Arbeit mit Objektdaten, insbesondere C ++ - Zeichenfolgen, ungeeignet sind, da es sich bei diesen Daten nicht um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">POD handelt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Mit der Quelle kann das Problem leicht gel√∂st werden, indem memcpy-Operationen durch regul√§re Zuweisungen ersetzt werden. M√∂glicherweise stellen Sie auch fest, dass diese Sortierung in einigen Standard-C-Bibliotheken nicht unbedingt schnell ist, sondern durch andere ersetzt werden kann. In der aktuellen Version f√ºr GCC hat diese Sortierung sogar die Stabilit√§tseigenschaft. Es gab manchmal √úberraschungen mit den erw√§hnten c-Sortierungen beim Sammeln von Daten, zum Beispiel, wenn mit dem Typ std :: vector √ºber ein funktionales Objekt gearbeitet wurde, konnten sie Schwierigkeiten verursachen - ich kann empfehlen, sie mit Objektdaten mit Vorsicht zu verwenden. Laut den L√§ufen ist diese Sortierung manchmal relativ langsam: Sie ist in der Geschwindigkeit anderen Implementierungen der schnellen Sortierung beim Arbeiten mit Zahlen merklich unterlegen, aber beim Arbeiten mit Si-Strings ist es besser, wenn nur das Sortieren mit zwei Kontrollpunkten manchmal voranschreitet.aber in langen Schlangen √ºberholt die Standard-Qsort sie fast immer. Das Interessanteste wurde entdeckt, als ich versuchte, eine Milliarde Ganzzahlen damit zu sortieren - es stellte sich heraus, dass das Ausf√ºllen von Typ 7 zu einer Zeitabh√§ngigkeit nahe einem quadratischen Gesetz f√ºhrt, dh zu einer m√∂glichen "Verarbeitung", die bis zu mehreren Jahren dauert (ich habe nicht auf das Ende gewartet und es gestoppt bei 21 Stunden laufen). Mit weniger Daten kann diese Sortierung normalerweise Ankerpunkte ausw√§hlen, mit denen sie schnell funktioniert.Mit weniger Daten kann diese Sortierung normalerweise Ankerpunkte ausw√§hlen, mit denen sie schnell funktioniert.Mit weniger Daten kann diese Sortierung normalerweise Ankerpunkte ausw√§hlen, mit denen sie schnell funktioniert.</font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Introspektive</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sortierung wird in der C ++ - Standardbibliothek verwendet, obwohl die genaue Methode in std :: sort von der Implementierung abh√§ngt, sofern nur Informationen zu GCC bereitgestellt werden. Laut den L√§ufen ist dies die zweitschnellste nach dem Spread-Sortieren, wenn mit Zahlen gearbeitet wird, und der Vorteil des Spread-Sortierens ist gering (von fast 0 bis 30%), aber beim String-Sortieren ist alles viel schlimmer - es kann 3-4 mal niedriger sein als bei den F√ºhrenden . Dies ist eigentlich eine schnelle Sortierung, bei der zwei Sonderf√§lle ber√ºcksichtigt werden: 1) Wenn die Anzahl der Rekursionen zu gro√ü geworden ist, erfolgt die Umstellung auf Sortierung nach Heap. 2) Wenn die Anzahl der zu sortierenden Elemente gering ist, erfolgt das Umschalten auf Sortieren nach Einf√ºgungen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stabile Sortierung aus der C ++ - Standardbibliothek ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">std :: stabile_sort</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) hat, wie der Name schon sagt, die Eigenschaft der Stabilit√§t - es beh√§lt die relative Reihenfolge zwischen Elementen mit demselben Schl√ºssel bei. Diese Eigenschaft ist relativ selten notwendig, obwohl ich dar√ºber eher unbegr√ºndet schreibe, nur aufgrund meiner eigenen Erfahrung. Es kann zus√§tzlichen Speicher verwenden, was es schneller macht. √úberraschenderweise ist diese Sortierung oft schneller als std :: sort. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In der sehr beliebten Python-Sprache wird standardm√§√üig </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tims</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sortierung verwendet </font><font style="vertical-align: inherit;">. F√ºr Tests habe ich die Version aus dem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Github-Repository verwendet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Es zeigt rekordverd√§chtige gute Ergebnisse bei teilweise geordneten Daten, ist aber im Durchschnitt immer noch merklich langsamer als die f√ºhrenden Unternehmen. Normalerweise ist seine Geschwindigkeit der Durchschnitt zwischen schneller Sortierung und Shell-Sortierung, obwohl er in den Linien manchmal nahe an den F√ºhrenden liegt. Es hat die Eigenschaft der Stabilit√§t. Es implementiert einen relativ komplizierten Algorithmus, in dessen Standardimplementierung 2015 ein Fehler entdeckt wurde, f√ºr dessen Manifestation jedoch eine eher unrealistische Situation erforderlich ist. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die BSD C-Bibliothek verf√ºgt √ºber eine bitweise Sortierung ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">radixsort)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) und seine stabile Version (sradixsort). Leider k√∂nnen beide Arten nur f√ºr C-Strings verwendet werden. Wie aus den Testdaten hervorgeht, ist dies heute der schnellste Weg, um Zeichenfolgen zu sortieren. Daher ist es √ºberraschend, dass es keine Standardoption f√ºr C ++ - Zeichenfolgen gibt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die BSD - </font><font style="vertical-align: inherit;">C - </font><font style="vertical-align: inherit;">Bibliothek hat mehr Sortier </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">merge</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">den mergesort</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Diese Sortierung ist als eine der schnellsten f√ºr Daten mit sequenziellem Zugriff (Dateien, Listen) bekannt und wird wahrscheinlich in der C ++ - Standardbibliothek zum Sortieren von Listen (std :: list und std :: forward_list) verwendet. Sie war √ºbrigens seit 1948 bekannt und einer ihrer Entwickler war ein sehr bekannter Mathematiker und Spezialist f√ºr die ersten Computersysteme von Neumann. Von den schnellen Methoden unterscheidet sich diese Sortierung nicht durch die besten Eigenschaften, obwohl sie in der Regel etwas schneller ist als die Shell-Methoden. Es ben√∂tigt zus√§tzlichen Speicher und wird in der Regel nachhaltig implementiert. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Au√üerdem wird immer noch nach einem </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Haufen</font></a><font style="vertical-align: inherit;"> sortiert</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Heapsort). Der Heap wird normalerweise f√ºr eine optimale Warteschlange mit Priorit√§ten verwendet, kann aber auch zum Sortieren verwendet werden. Sortierhaufen ben√∂tigen keinen zus√§tzlichen Speicher, verf√ºgen jedoch nicht √ºber die Stabilit√§tseigenschaft. Die Geschwindigkeit f√ºr Zahlen ist erheblich (bis zu 3-6 Mal) langsamer als bei Shell-Methoden, aber bei nicht sehr kurzen Zeilenreihen werden sehr gute Ergebnisse erzielt, da Shell-Methoden √ºberholt werden (mit zunehmender Zeilenl√§nge w√§chst der Vorteil). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Heap-Sortierung ist auch in der C ++ - Standardbibliothek verf√ºgbar. Eine solche Sortierung erfolgt in zwei Vorg√§ngen: Erstellen des Heaps (std :: make_heap) und anschlie√üendes Sortieren ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">std :: sort_heap)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Im Gegensatz zur bsd-Bibliothek ist das Sortieren hier nur eine der Operationen f√ºr den Heap. Normalerweise ist diese Sortieroption etwas schneller als die vorherige (die bsd-Option zeigt bessere Ergebnisse nur bei kurzen Zahlen und langen S-Zeilen).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit der Standard-C ++ - Bibliothek k√∂nnen Sie den bin√§r ausgeglichenen Baum (std :: multiset) sortieren - f√ºllen Sie einfach den Baum und gehen Sie dann umher. Diese Methode kann als nicht rekursive schnelle Sortierung betrachtet werden. Ein Problem ergibt sich aus der Tatsache, dass der Standardspeicher-Allokator bemerkenswert langsam ist. Um die besten Ergebnisse zu erzielen, m√ºssen Sie Ihren eigenen Allokator verwenden, der um etwa 10 bis 30% schneller wird. Es kann auch angemerkt werden, dass ein solches Verfahren viel zus√§tzlichen Speicher ben√∂tigt, mit g ++ f√ºr jedes Datenelement. Zus√§tzlich dazu m√ºssen Sie 32 Bytes (auf der x86-64-Architektur) speichern - es w√§re interessant zu versuchen, einen solchen Baum als B√ºndel zu speichern, d. H. Ohne zus√§tzlichen Byte Wenn Sie boost :: container :: multiset verwenden, ben√∂tigen Sie weniger Speicher: nur 24 zus√§tzliche Bytes pro Datenelement. Wie Boost,und die Standardbibliothek zeigte eine unangenehme √úberraschung - dabei ben√∂tigten sie manchmal mehr Speicher als n√∂tig. M√∂glicherweise liegt dies am Ausgleich von Bin√§rb√§umen. Codes -</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Boost-Bibliothek verf√ºgt √ºber </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spreadort</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einen Algorithmus, der im 21. Jahrhundert erfunden wurde. Dies ist die schnellste Gesamtmethode, die heute in bekannten Bibliotheken verf√ºgbar ist. Diese Sortierung verwendet einige bitweise Ideen und kann ebenso wie die Art der Argumente ziemlich launisch sein. Normalerweise zeigt diese Sortierung Rekordergebnisse, die manchmal deutlich besser sind als die der engsten Wettbewerber. Die einzige Ausnahme ist die Sortierung von C-Zeilen, bei der sie den bitweisen Methoden aus der bsd-Bibliothek deutlich unterlegen ist. Beim Sortieren langer C-Linien kann dies anderen Methoden unterlegen sein, z. B. Spin-Sortieren oder schnelles Sortieren mit zwei Ankerpunkten. Die Spread-Sortierung (Boost v1.62) zeigte ein sehr unangenehmes </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problem</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Beim Sortieren kleiner (bis zu 1000 Elemente) C-String-Arrays funktioniert dies mit Fehlern. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gibt auch einen neuen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pdqsort-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Algorithmus </font><font style="vertical-align: inherit;">, der, wie vom Autor angegeben, die introspektive Sortierung verbessert. Dieser neue Algorithmus, der auf Wikipedia noch nicht beschrieben ist. Die Ergebnisse - zwar nicht schlecht, aber nicht besonders beeindruckend. Es ist langsamer als std :: sort bei kurzen Ganzzahlen, aber schneller bei Zeichenfolgen und langen Ganzzahlen. In beiden F√§llen ist der Unterschied eher unbedeutend. Die besten Ergebnisse f√ºr diese Sortierung wurden f√ºr lange C ++ - Zeichenfolgen erzielt - hier ist sie der Spread-Sortierung unterlegen, wenn auch nur der f√ºhrenden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In Boost finden Sie immer noch </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spinsort</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Dies ist auch ein neuer Algorithmus, der im Gegensatz zum vorherigen die Stabilit√§tseigenschaft besitzt und der auch in Wikipedia noch nicht beschrieben ist. Normalerweise ist er dem Anf√ºhrer nahe, aber mit einer merklichen Verz√∂gerung hinter sich. Es erfordert, wenn auch nicht zu viel, zus√§tzlichen Speicher. </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Lassen Sie uns</font></a></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mit </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">flat_stable_sort</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus derselben Boost-Bibliothek </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">enden</font></a><font style="vertical-align: inherit;"> . Dies ist ein weiterer neuer robuster Algorithmus, der in Wikipedia noch nicht beschrieben ist. Dies ist bei weitem die schnellste Methode, aber den meisten anderen schnellen Bibliotheksmethoden etwas unterlegen. Es ben√∂tigt sehr wenig zus√§tzlichen Speicher (ben√∂tigt jedoch immer eine Tabelle mit fester Gr√∂√üe von 8 KB) und ist h√§ufig sp√ºrbar schneller als die Shell-Methode. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Betrachten Sie die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tabelle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zeit (in ms) des Betriebs dieser Algorithmen auf einem Computer mit 8 GB RAM mit einem AMD Phenom ‚Ñ¢ II X4 955 @ 3,214 MHz-Prozessor. Der Computer hat insgesamt mehrere Monate gearbeitet, und die Gesamtgr√∂√üe der gesammelten Daten in zwei mit Tabellen geladenen JSON-Dateien betr√§gt fast 400 KB. Die Zeitangaben ergeben sich aus dem Durchschnitt der Anzahl der L√§ufe, bei kleineren Gr√∂√üen waren diese L√§ufe gr√∂√üer. Wenn Sie ziemlich kompliziert mit dem Cache arbeiten, √§ndert sich die Geschwindigkeit der Berechnungen, sodass die erzielten Ergebnisse bestenfalls ungef√§hr sind (ich kann davon ausgehen, dass Timing-Ungenauigkeiten bis zu 20% erreichen k√∂nnen). Ich glaube, dass auf den besten modernen Prozessoren f√ºr PCs das Ergebnis 2-3 Mal schneller erzielt werden kann, aber denken Sie daran, dass viel mehr moderne Prozessoren durch Umschalten zwischen verschiedenen Frequenzen und dem mit ihnen erzielten Ergebnis arbeiten.wird noch n√§her sein.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diese und die folgende Tabelle sind interaktiv. Zus√§tzlich zu den absoluten Werten der Timings k√∂nnen Sie auch deren Werte relativ zum Durchschnitt, Median, Minimum und Maximum anzeigen. Sie k√∂nnen die Genauigkeit der Zeichen √§ndern. Sie k√∂nnen auch Zeitbeziehungen f√ºr verschiedene Arten von F√ºllungen und Datentypen abrufen. Letzteres kann beispielsweise zeigen, dass das Sortieren von C-Strings sp√ºrbar schneller ist als das Sortieren von C ++ - Strings. Unter Sortiermethoden k√∂nnen Sie auch eine Vielzahl von Teilmengen ausw√§hlen und zusammenstellen. Sie k√∂nnen die Sortierung nat√ºrlich nach jeder Spalte festlegen. Leider wei√ü ich nicht, wie man Javascript in dem Artikel auf dem Hub verwendet, so dass die Tabellen nur als Referenz verf√ºgbar sind. F√ºr den Fall, dass github.io √ºberladen ist, gebe ich auch Backup-Links zur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ersten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zweiten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tabelle.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Zeit wird in Millisekunden gemessen, aber im Gesetz der Zeitabh√§ngigkeit werden Formeln f√ºr Mikrosekunden angegeben, um zu kleine Koeffizienten zu vermeiden. </font><font style="vertical-align: inherit;">Wenn wir also den Wert f√ºr </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in der Formel einsetzen </font><font style="vertical-align: inherit;">, muss das Ergebnis auch durch 1000 geteilt werden, um eine Zahl aus der Tabelle zu erhalten, die der entsprechenden nahe kommt. </font><font style="vertical-align: inherit;">Das Gesetz der Zeitabh√§ngigkeit wird auf der Grundlage der erhaltenen Zeitpunkte aus einem Vergleich zweier Ergebnisse abgeleitet (normalerweise werden die extremen genommen). </font><font style="vertical-align: inherit;">Sie k√∂nnen die Qualit√§t des abgeleiteten Gesetzes √ºberpr√ºfen, indem Sie die Option der relativen Abweichung des tats√§chlichen Werts von der Ausgabe verwenden.</font></font><br><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Einige allgemeine Schlussfolgerungen aus den Ergebnissen dieser Tabelle: </font></font><br></p><ul><li><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'de', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script> Die besten Shell-Sortierungen f√ºr Daten mit bis zu 10 Millionen Elementen k√∂nnen Timsort und sogar einige schnelle Sortierungen √ºberholen. </li><li>  Timsort ist sehr nahe an der Geschwindigkeit qsort (clib), manchmal √ºberholt es etwas und manchmal umgekehrt; </li><li>  Heapsort und insbesondere Treesort verlangsamen sich oft merklich, aber vor dem Hintergrund einer Blase oder sogar einer Wahl ist klar, dass dies immer noch schnelle Methoden sind.  Interessanterweise haben beide Methoden oft sehr √§hnliche Eigenschaften - beide bauen B√§ume.  Es ist leicht zu bemerken, dass die Abh√§ngigkeiten von Heapsort und TreeSort, obwohl nicht eindeutig quadratisch, offensichtlich nicht <i>N</i> log <i>N sind</i> , sondern viel schlechter - verglichen mit der Shell-Sortierung, die sich mit zunehmendem Datenvolumen viel besser verh√§lt als Heapsort oder TreeSort. dass sie selbst langsamer ist als <i>N</i> log <i>N.</i>  Daher stimmen die praktischen Implementierungen von Heap- und Baumsortierungen nicht mit ihren theoretischen Spezifikationen √ºberein. </li><li>  Die Daten zum Sortieren von Zeichenfolgen zeigen, dass die Gesetze der Zeitabh√§ngigkeiten hier nicht dieselben sind wie f√ºr Zahlen - die L√§nge der Zeichenfolgen, die hier sortiert werden, √ºberlappen diese Gesetze irgendwie.  Leider kenne ich die Formeln f√ºr bekannte Sortierungen nicht, die bei der Arbeit mit Zeichenfolgen genaue Gesetze der Zeitabh√§ngigkeiten ergeben w√ºrden. </li><li>  Es ist interessant, dass die Geschwindigkeit der Arbeit mit reellen Zahlen ungef√§hr der Geschwindigkeit ganzzahliger Zahlen entspricht. Dies ist eine Folge der Tatsache, dass in der modernen x86-Architektur sehr effektive Optimierungen f√ºr die Arbeit mit dem Stapel vorgenommen werden. </li><li>  hash_sort zeigte recht mittelm√§√üige Ergebnisse. Dies ist m√∂glich, da aufgrund der Verwendung von zus√§tzlichem Speicher die Leistung von Prozessor-Caches stark abnimmt.  Bei kleinen zuf√§lligen Daten (weniger als einhunderttausend Elemente) √ºberholt die Hash-Sortierung die besten schnellen Sortierungen.  Sie k√∂nnen auch feststellen, dass es aufgrund von Caches wieder m√∂glich ist. Einige der Ergebnisse dieser Sortierung sind sehr seltsam, z. B. werden 10 <sup>5</sup> , 10 <sup>6</sup> und 10 <sup>7</sup> 32-Bit-Ganzzahlen, wenn teilweise geordnete F√ºllungen verwendet werden, ungef√§hr gleich sortiert Zeit!  Eine Art fast Quanteneffekt.  :) Ich bin mir sicher, dass Sie bei der Suche andere schwer zu erkl√§rende Ergebnisse finden k√∂nnen. </li></ul><br><p>  Ich werde einige weitere Schlussfolgerungen zu einigen Sonderf√§llen hinzuf√ºgen: <br></p><ul><li>  Einige Arten der Datenauff√ºllung weisen Schwachstellen in Quicksorts auf.  Die Auswahl eines St√ºtzelements auf komplizierte Weise macht die Wahrscheinlichkeit, in eine schlechte Reihenfolge f√ºr das Sortieren zu fallen, jedoch praktisch Null.  Sie k√∂nnen auch ein Unterst√ºtzungselement f√ºr jeden Durchgang auf unterschiedliche Weise oder zuf√§llig ausw√§hlen.  Vielleicht tun sie dies in qsort (clib).  Die betrachtete Hoare-Methode arbeitet sehr langsam nur bei speziell entworfenen Sequenzen, die w√§hrend der praktischen Arbeit zuf√§llig auftreten - dies ist ein Fall mit einer Wahrscheinlichkeit von 2 <sup><i>N</i> -3</sup> / <i>N</i> <sup><i>N</i></sup> , dh ein fast absolut unm√∂gliches Ereignis.  Wenn wir Sequenzen betrachten, bei denen die Hoar-Methode nicht so langsam wie m√∂glich arbeitet, sondern nur mit einer signifikanten Verlangsamung, dann gibt es viel mehr solcher F√§lle, was jedoch die Wahrscheinlichkeit l√§sst, dass ein unannehmbar langsamer Datenverarbeitungsfall immer noch praktisch unbedeutend ist, obwohl er in seinem Unterschied zu sehr √§rgerlich ist Null.  Es ist auch fast unm√∂glich, versehentlich Daten zu erhalten, bei denen eine schnelle Sortierung mit zwei Kontrollpunkten nach dem quadratischen Gesetz langsam funktioniert.  Die schnellen Sortieroptionen von Lomuto ohne und ohne Unterst√ºtzungselement zeigen in fast allen bestimmten F√ºllf√§llen sehr schlechte Ergebnisse. </li><li>  In einigen besonderen F√§llen liefert die langsamste "Blasensortierung" hervorragende Ergebnisse, und einige der schnellsten und schnellsten Sortierungen sind im Gegenteil sehr schlecht. </li><li>  Die Hash-Sortierung zeigte bei F√ºllungen der Typen 8 und 9 ein sehr schlechtes Ergebnis. Dies liegt daran, dass die monotone Sequenz von aufeinanderfolgenden Werten ausgehend vom kleineren Wert genommen wird und 1% der Zufallszahlen aus dem Bereich vom unteren bis zum maximalen Wert entnommen werden, der alle aufeinanderfolgenden 99% der Daten langweilt in ein Hash-Element.  Dieser Fall zeigt sehr gut die Probleme, die auftreten k√∂nnen, wenn diese Sortierung oder Sortierung mit einem Array mit unbekannten Daten verwendet wird. </li><li>  Die Auswahlsortierung verh√§lt sich bei allen Arten der F√ºllung sehr stabil. Die Sortierung von Haufen und B√§umen ist ebenfalls recht stabil, ohne offensichtliche Spitzen und Einbr√ºche.  Dies gilt nat√ºrlich sowohl f√ºr Shell-Sortierungen als auch f√ºr die meisten anderen schnellen Methoden aus Standardbibliotheken. </li></ul><br>  Jetzt ist es Zeit, √ºber die Datentypen zu sprechen, die mit Sortieralgorithmen verwendet werden: <br><br><ol><li>  Ganzzahlen 32-Bit-Vorzeichen (int32_t), aber nur nicht negative wurden verwendet.  Andere numerische Daten wurden ebenfalls nur nicht negativ aufgenommen - dies verringert nicht die Allgemeinheit der Ergebnisse, erleichtert jedoch das Abrufen f√ºr einige Algorithmen erheblich. </li><li>  Ganzzahlen, 64-Bit-Vorzeichen (int64_t); </li><li>  Ganzzahlen, 128-Bit-Vorzeichen (__int128 - wird von mindestens GCC unterst√ºtzt); </li><li>  Strukturen von f√ºnf ganzen Zahlen (int32_t), von denen eine als Schl√ºssel verwendet wird (INT1P4).  Beim Sortieren solcher Daten beginnt die Anzahl der Permutationen die Rechenzeit signifikanter zu beeinflussen, daher gewinnen Verfahren mit weniger Permutationen einen gewissen Vorteil; </li><li>  reelle Zahlen wie doppelte Genauigkeit, doppelte (Gleitkommazahlen); </li><li>  kurze Strings C ++ und C. Strings von 1 bis 16 wurden genommen (Strings kurz und C-Strings kurz); </li><li>  Strings C und C ++ mittlerer L√§nge, deren L√§nge 1 bis 256 betr√§gt (Strings und C-Strings); </li><li>  lange Zeilen C und C ++, deren L√§nge 1 bis 2 <sup>20</sup> betr√§gt (dies ist etwas mehr als eine Million), und die Zeilen werden so ausgew√§hlt, dass ihre durchschnittliche L√§nge 512 nicht √ºberschreitet, sodass die Zeilen nur zum zuf√§lligen F√ºllen ausgew√§hlt wurden, in anderen F√§llen wurden die Zeilen einfach genommen L√§ngen von 1 bis 512 (Saiten lang und C-Saiten lang). </li></ol><br><p>  Und auch dar√ºber, wie das Quellarray zum Sortieren gef√ºllt wird: <br><br></p><ol><li>  durch Zufall; </li><li>  streng aufsteigend (bestellt); </li><li>  streng absteigend (umgekehrte Reihenfolge, umgekehrt); </li><li>  Zufallswerte im Bereich von 0 bis 99 (kleine Variation, geringe Variation 100); </li><li>  zuf√§llige Folge von 0 und 1 (kleine Variation, geringe Variation 2); </li><li>  Konstante 0 (kleine Streuung, geringe Variation 1); </li><li>  Die Sequenz, die die qsort (Hoare) -Version zur langsamsten Ausf√ºhrung f√ºhrt.  Es ist merkw√ºrdig, dass es unter allen Sequenzen der L√§nge <i>N</i> genau 2 <sup><i>N</i> -3</sup> solcher Sequenzen gibt; </li><li>  streng aufsteigend, mit der Einf√ºgung von 1% Zufallszahlen (teilweise geordnet); </li><li>  streng absteigend, mit einer Einf√ºgung von 1% Zufallsvariablen (teilweise umgekehrt). </li></ol><br>  Es sollte betont werden, dass zuf√§llige Daten der typischste Fall beim F√ºllen eines Arrays sind. Alle anderen Methoden sind √§u√üerst selten und im normalen Betrieb eines bestimmten Arrays sogar fast unm√∂glich. <br><br>  Schauen wir uns <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die</a> Testergebnisse an, bei denen Sortierungen mit allen m√∂glichen Datensequenzen funktionieren.  Die Anzahl solcher Sequenzen entspricht der Fakult√§t ihrer L√§nge, daher gibt es f√ºr Sequenzen der L√§nge 12 479'001'600 Varianten - ein guter moderner PC berechnet ihre Anzahl in weniger als einer Minute.  Wenn wir Sequenzen der L√§nge 14 nehmen, erhalten wir bereits 87'178'291'200 Varianten f√ºr mehrere Stunden Computerbetrieb.  Daher zeigt die folgende Tabelle die durchschnittliche Zeit (in Prozessorzyklen, die durch den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RDTSC-</a> Befehl erhalten wurden) einer Sortierung, wenn alle Permutationen bis zu nur 12 sortiert werden. In den Daten werden die vorherigen numerischen Typen und kurzen Zeichenfolgen verwendet.  Nat√ºrlich k√∂nnte man feststellen, dass Sequenzen mit sich wiederholenden Elementen nicht ber√ºcksichtigt werden.  Ich wage jedoch vorzuschlagen, dass ihre Anwesenheit die Ergebnisse qualitativ nicht ver√§ndern w√ºrde, aber ihren Empfang erheblich verlangsamen k√∂nnte. <br><br>  Die Ergebnisse f√ºr solch kleine Daten sind nicht sehr repr√§sentativ, insbesondere f√ºr komplexe Sortiermethoden, aber sie erg√§nzen immer noch die Idee des Sortierverhaltens.  Soweit ich wei√ü, ersetzen einige Sorten ihren Hauptalgorithmus durch einen anderen, wenn sie mit kleinen Arrays arbeiten - dies sind verteilte Sorten, schnell mit zwei Ankerpunkten und radix_msd (die letzten beiden verwenden Einf√ºgungen).  Einige Sortierungen (flat_stable und radix) verwenden kleine Tabellen. Bei winzigen Datengr√∂√üen sind diese Tabellen jedoch viel gr√∂√üer als die Daten selbst, was diese Methoden im Vergleich zu anderen erheblich verlangsamt und zu seltsamen Ergebnissen f√ºhrt.  Seltsame Ergebnisse werden auch mit anderen bitweisen Sortierungen sowie mit Hash- und Array-Sortierungen erzielt.  Solche ungew√∂hnlichen Ergebnisse lassen sich leicht dadurch erkl√§ren, dass die Vorbereitungszeit f√ºr Daten vor dem Sortieren f√ºr diese Methoden f√ºr kleine Daten l√§nger ist als die Sortierzeit selbst.  Bei der Messung derart kleiner Zeitintervalle (Nanosekunden) ist der Einfluss verschiedener Fehler auf das angezeigte Gesetz nat√ºrlich viel h√∂her als in der vorherigen Tabelle.  Daher erwiesen sich die Gesetze als sehr ungef√§hr, oft ‚Äûmit einer Drift‚Äú zu √ºbertriebenen Werten.  Letzteres erkl√§rt sich teilweise aus der Tatsache, dass bei der Arbeit mit kleinen Daten die Sortierzeit selbst mit der Zeit des Aufrufs der Sortierfunktion und mehreren notwendigen Hilfsoperationen zur Zeitmessung vergleichbar wird.  Das Programm versucht, den genannten Overhead von der Ausgabe zu subtrahieren, aber es stellt sich heraus, dass dies ziemlich ungef√§hr erfolgt.  Bei alledem wage ich anzunehmen, dass Sie durch den Vergleich der Ergebnisse f√ºr verschiedene Datentypen und die Ber√ºcksichtigung der gemachten Kommentare manchmal Annahmen treffen k√∂nnen, die nicht sehr weit von der Genauigkeit entfernt sind. <br><br>  Abschlie√üend eine weitere Tabelle, die zeigt, wie viele verschiedene Testmethoden zum Sortieren von zus√§tzlichem Speicher erforderlich sind.  Dieser Wert h√§ngt nat√ºrlich vom System ab.  In meinen Tests ist dies, wie ich bereits geschrieben habe, x86-64, GCC.  Der Buchstabe T bedeutet die Gr√∂√üe des Typs in Bytes (die L√§nge der Zeichenfolge ist in dieser Gr√∂√üe nicht enthalten: f√ºr C-Zeilen ist es die Gr√∂√üe des Zeigers, f√ºr C ++ - Zeilen ist es die Gr√∂√üe des Deskriptors, 32 Bytes f√ºr x86-64 GCC), der Buchstabe L ist die Mitte Die L√§nge des Typs in Bytes (f√ºr Zahlen ist dies T und f√ºr Zeichenfolgen ist es die durchschnittliche L√§nge der Zeichenfolge), der Buchstabe A kann 1 oder 0 sein - dies ist die Ausrichtung an der 64-Bit-Grenze, und der Buchstabe M ist die Ausrichtung vom Standardspeicher-Allokator (es wird angenommen) richtet sich nach einer 32-Byte-Grenze).  Das Symbol <sup>*</sup> bedeutet, dass die Daten f√ºr diese Art der Sortierung nur auf der Grundlage der Analyse des Lesens des VmRSS-Felds aus / proc / PID / status erhalten wurden (das erw√§hnte Feld ist die Gr√∂√üe des Prozessprogramms). <br><br><div class="spoiler">  <b class="spoiler_title">Zus√§tzliche Speichertabelle</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Methode </th><th>  Sucht </th></tr><tr><td>  Array * 1 </td><td align="center">  (T + 1/8) <i>N.</i> </td></tr><tr><td>  Array * k, k&gt; 1 </td><td align="center">  (T + 4k) <i>N.</i> </td></tr><tr><td>  Blase </td><td align="center">  0 </td></tr><tr><td>  clib_qsort </td><td align="center">  ‚âàT <i>N</i> / 2 bis ‚âàT <i>N</i> <sup>*</sup> </td></tr><tr><td>  flat_stable </td><td align="center">  ‚âàT <i>N</i> / 256 </td></tr><tr><td>  Hash </td><td align="center">  (T + 8 + 4A) <i>N.</i> </td></tr><tr><td>  hashbt </td><td align="center">  (T + 12) <i>N.</i> </td></tr><tr><td>  hashbt_boost </td><td align="center">  (56 + T + 4A + M) <i>N.</i> </td></tr><tr><td>  hashbt_std </td><td align="center">  (80 + T + 4A + M) <i>N.</i> </td></tr><tr><td>  Heapsort </td><td align="center">  0 </td></tr><tr><td>  Einf√ºgen </td><td align="center">  0 </td></tr><tr><td>  mergesort_bsd </td><td align="center">  ‚âàTlog <sub>2</sub> <i>N</i> bis T <i>N</i> <sup>*</sup> </td></tr><tr><td>  pdq </td><td align="center">  Tlog <i>n</i> </td></tr><tr><td>  Quicksort </td><td align="center">  ~ 16 log <sub>2</sub> <i>N</i> bis 16 <i>N.</i> </td></tr><tr><td>  quicksort_tco </td><td align="center">  von 0 bis <i>N.</i> </td></tr><tr><td>  radix </td><td align="center">  ‚âàT <i>N.</i> </td></tr><tr><td>  radix8_trie </td><td align="center">  von ‚âàT <i>N</i> + 24L bis ‚âà (T + 24L + 12) <i>N.</i> </td></tr><tr><td>  radix_bsd </td><td align="center">  0 </td></tr><tr><td>  radix_msd </td><td align="center">  ‚âàT <i>N.</i> </td></tr><tr><td>  Auswahl </td><td align="center">  0 </td></tr><tr><td>  Shell </td><td align="center">  0 </td></tr><tr><td>  drehen </td><td align="center">  T <i>N</i> / 2 </td></tr><tr><td>  verbreiten </td><td align="center">  ‚âà0 </td></tr><tr><td>  sradix_bsd </td><td align="center">  ‚âàT <i>N</i> <sup>*</sup> </td></tr><tr><td>  stlsort </td><td align="center">  von 0 bis ‚âàTlog <sub>2</sub> <i>N</i> <sup>*</sup> </td></tr><tr><td>  stabil </td><td align="center">  von 0 bis ‚âàT <i>N</i> / 2 <sup>*</sup> </td></tr><tr><td>  Timsort </td><td align="center">  von 0 bis ‚âàT <i>N</i> <sup>*</sup> </td></tr><tr><td>  tree_boost </td><td align="center">  (T + 24) <i>N.</i> </td></tr><tr><td>  tree_stl </td><td align="center">  (T + 32) <i>N.</i> </td></tr></tbody></table></div><br></div></div><br>  Es gibt nat√ºrlich auch andere Sortiermethoden, sowohl primitive als auch schnelle.  Die Boost-Bibliothek verf√ºgt √ºber parallele Algorithmen, mit denen Sie das Vorhandensein zus√§tzlicher Prozessorkerne im System nutzen k√∂nnen.  Sie k√∂nnen auch das selbstordnende Container boost :: container :: flat_multiset anstelle von std :: multiset verwenden, es funktioniert jedoch sehr langsam. <br><br>  Ich nutze diese Gelegenheit, um einige Kommentare zur Boost-Bibliothek im Allgemeinen abzugeben.  Ich empfehle nicht vorbei zu gehen.  Sogar die Funktionen, die in der Standardbibliothek in Boost enthalten sind, sind in der Regel besser implementiert und manchmal (wie beispielsweise regul√§re Ausdr√ºcke) viel besser.  Wenn wir √ºber Container sprechen, sind sie beim Boost merklich gr√∂√üer, und diejenigen, die mit den Standardcontainern √ºbereinstimmen, sind manchmal etwas schneller und haben oft kleine, aber nette Verbesserungen.  Boost pr√ºft Typen gr√ºndlicher, was manchmal dazu beitragen kann, fast schwer fassbare Fehler zu erkennen, die sich normalerweise nicht manifestieren, aber unter bestimmten Umst√§nden unerwartet aktiviert werden k√∂nnen.  Zu den Nachteilen von Boost geh√∂ren bedingungslos v√∂llig unlesbare und umfangreiche Nachrichten √ºber Kompilierungsfehler bei vielen Konstruktionen aus dieser Bibliothek - dies gilt jedoch in geringerem Ma√üe f√ºr die Standardbibliothek.  Es ist Zeit f√ºr C ++ - Entwickler, etwas dagegen zu unternehmen. <br><br>  Alle Dateien mit Tests und einigen anderen verwandten Materialien k√∂nnen aus meinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository</a> entnommen werden.  Wenn sich jemand f√ºr Rohdaten interessiert, k√∂nnen Sie diese <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> herunterladen (1,4 MB).  Ich freue mich √ºber Kommentare, Kritik und Erg√§nzungen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de467473/">https://habr.com/ru/post/de467473/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de467459/index.html">Wie ein Mikrocontroller Daten mit 1,6 Gbit / s lesen kann</a></li>
<li><a href="../de467461/index.html">RubyRussia 2019. Julian Pokrovsky: Wie man einen Monolithen optimiert</a></li>
<li><a href="../de467463/index.html">Nur Teilung oder wie man eine mathematische Theorie erstellt und 400.000 Dollar damit verdient. Serie Drei, Finale</a></li>
<li><a href="../de467465/index.html">Spart die Cloud Ultra-Budget-Smartphones?</a></li>
<li><a href="../de467471/index.html">Soul Mikrotik gegen seelenloses ILV und den gleichen Anbieter</a></li>
<li><a href="../de467475/index.html">Geben Sie Thread.Abort () an .NET Core zur√ºck. Anwendungsbereitstellung mit der Version von CoreCLR und CoreFX</a></li>
<li><a href="../de467477/index.html">Kubernetes 1.16: Highlights √úbersicht</a></li>
<li><a href="../de467479/index.html">Kir Shatrov: Shopify hat mit Rails angefangen und hier lieben sie diesen Rahmen aufrichtig.</a></li>
<li><a href="../de467485/index.html">Probleml√∂sung mit pwnable.kr 23 - md5 Rechner. Wir besch√§ftigen uns mit Stack Canary. C-Bibliotheken in Python verbinden</a></li>
<li><a href="../de467487/index.html">√úber die Zukunft von Blockchain- und Kryptow√§hrungszahlungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
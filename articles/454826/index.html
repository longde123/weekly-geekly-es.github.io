<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎀 🐽 👝 Reduzca las copias de seguridad en un 99.5% con hashget 🤵🏼 🌺 👹</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="hashget es un deduplicador gratuito basado en opera, una utilidad similar a un archivador, que puede reducir significativamente el tamaño de las copia...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reduzca las copias de seguridad en un 99.5% con hashget</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454826/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hashget</a> es un <em>deduplicador</em> gratuito basado en opera, una utilidad similar a un archivador, que puede reducir significativamente el tamaño de las copias de seguridad, así como organizar esquemas de copia de seguridad incrementales y diferenciales y más. </p><br><p>  Este es un artículo de revisión para describir las características.  El uso del propio hashget (bastante simple) se describe en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentación</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">README</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">wiki</a> del proyecto. </p><br><h1 id="sravnenie">  Comparación </h1><br><p>  De acuerdo con la ley del género, comenzaré de inmediato con la intriga, comparando los resultados: </p><br><div class="scrollable-table"><table><thead><tr><th>  Muestra de datos </th><th>  tamaño desempaquetado </th><th>  .tar.gz </th><th>  hashget .tar.gz </th></tr></thead><tbody><tr><td>  Wordpress-5.1.1 </td><td>  43 Mb </td><td>  11 Mb (26%) </td><td>  155 Kb ( <strong>0.3%</strong> ) </td></tr><tr><td>  Kernel de Linux 5.0.4 </td><td>  934 Mb </td><td>  161 Mb (20%) </td><td>  4,7 Mb ( <strong>0,5%</strong> ) </td></tr><tr><td>  Debian 9 (LAMP) LXC VM </td><td>  724 Mb </td><td>  165 Mb (23%) </td><td>  4,1 Mb ( <strong>0,5%</strong> ) </td></tr></tbody></table></div><br><h1 id="predystoriya-kakim-dolzhen-byt-idealnyy-i-effektivnyy-bekap">  Antecedentes de lo que debería ser una copia de seguridad ideal y efectiva </h1><br><p>  Cada vez que hacía una copia de seguridad de una máquina virtual recién creada, me perseguía la sensación de que estaba haciendo algo mal.  ¿Por qué obtengo una copia de seguridad pesada de un sistema en el que mi invaluable creatividad imperecedera es un index.html de una sola línea con el texto "Hola mundo"? </p><a name="habracut"></a><br><p>  ¿Por qué hay 16 megabytes / usr / sbin / mysqld en mi copia de seguridad?  ¿Es realmente en este mundo que tengo el honor de almacenar este archivo importante, y si no puedo hacerlo, se perderá para la humanidad?  Lo más probable es que no.  Se almacena en servidores Debian altamente confiables (cuya confiabilidad y continuidad no se pueden comparar con lo que puedo proporcionar), así como en copias de seguridad (millones de ellas) de otros administradores.  ¿Realmente necesitamos crear más de 10,000,000 de la primera copia de este importante archivo para aumentar la confiabilidad? </p><br><p> En general, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hashget</a> resuelve este problema.  Al empacar, crea una copia de seguridad muy pequeña.  Al desempacar: un sistema completamente desempaquetado, similar al que sería con <code>tar -c</code> / <code>tar -x</code> .  (En otras palabras, este es un embalaje sin pérdidas) </p><br><h1 id="kak-rabotaet-hashget">  Cómo funciona el hashget </h1><br><p>  Hashget tiene los conceptos de paquete y HashPackage, con su ayuda realiza deduplicación. </p><br><p>  <em>Paquete</em>  Un archivo (generalmente un archivo .deb o .tar.gz) que se puede descargar de manera confiable desde la red y del que se pueden obtener uno o más archivos. </p><br><p>  <em>HashPackage</em> es un pequeño archivo JSON que representa el paquete, que incluye la URL del paquete y la suma hash (sha256) de los archivos que contiene.  Por ejemplo, para el paquete mariadb-server-core de 5 megabytes de tamaño, el tamaño del paquete hash es de solo 6 kilobytes.  Unas mil veces más pequeño. </p><br><p>  <em>Deduplicación</em> : creación de un archivo sin archivos duplicados (si el deduplicador sabe dónde se puede descargar el paquete original, reduce los duplicados del archivo). </p><br><h2 id="zapakovka">  Embalaje </h2><br><p>  Al empaquetar, se ven todos los archivos del directorio empaquetado, se consideran sus sumas hash y, si la suma se encuentra en uno de los HashPackage conocidos, los metadatos del archivo (nombre, hash, permisos, etc.) se guardan en un archivo especial .hashget-restore.json, que también se incluirá en el archivo. </p><br><p>  El empaque en sí en el caso más simple no parece más complicado que el alquitrán: </p><br><pre> <code class="plaintext hljs">hashget -zf /tmp/mybackup.tar.gz --pack /path/to/data</code> </pre> <br><h2 id="raspakovka">  Desempacando </h2><br><p>  El desempaque se realiza en dos etapas.  Primero, el desempaque de alquitrán habitual: </p><br><pre> <code class="plaintext hljs">tar -xf mybackup.tar.gz -C /path/to/data</code> </pre> <br><p>  luego restaurar desde la red: </p><br><pre> <code class="plaintext hljs">hashget -u /path/to/data</code> </pre> <br><p>  Al recuperarse, el hashget lee el archivo .hashget-restore.json, descarga los paquetes necesarios, los descomprime y extrae los archivos necesarios, configurándolos en las rutas correctas, con el propietario / grupo / permisos necesarios. </p><br><h1 id="bolee-slozhnye-veschi">  Cosas más complicadas </h1><br><p>  Lo que se describe arriba ya es suficiente para aquellos que "quieren como alquitrán, pero para empacar mi Debian en 4 megabytes".  Más adelante veremos cosas más difíciles. </p><br><h2 id="indeksirovanie">  Indexación </h2><br><p>  Si un hashget no tenía un solo HashPackage, entonces simplemente no podría deduplicar nada. </p><br><p>  También puede crear un HashPackage manualmente (simplemente: <code>hashget --submit https://wordpress.org/wordpress-5.1.1.zip -p my</code> ), pero hay una manera más conveniente. </p><br><p>  Para obtener el hashpackage que necesita, hay un paso de <em>indexación</em> (se realiza automáticamente cuando se <code>--pack</code> comando <code>--pack</code> ) y <em>heurística</em> .  Al indexar, el hashget "alimenta" cada archivo encontrado a todas las heurísticas existentes que le interesan.  La heurística puede indexar cualquier paquete para crear un HashPackage. </p><br><p>  Por ejemplo, una heurística de Debian adora el archivo / var / lib / dpkg / status y detecta los paquetes debian instalados, y si no están indexados (HashPackage no se ha creado para ellos), los descarga e indexa.  El resultado es un efecto muy agradable: el hashget siempre deduplicará efectivamente los sistemas operativos Debian, incluso si tienen los paquetes más recientes. </p><br><h2 id="fayly-podskazki-hinty">  Archivos de sugerencias </h2><br><p>  Si su red utiliza algún tipo de paquete propietario o un paquete público que no está incluido en la heurística de hashget, puede agregarle un simple archivo de sugerencia hashget-hint.json de la siguiente manera: </p><br><pre> <code class="plaintext hljs">{ "project": "wordpress.org", "url": "https://ru.wordpress.org/wordpress-5.1.1-ru_RU.zip" }</code> </pre> <br><p>  Además, cada vez que se crea el archivo, el paquete se indexará (si no es así anteriormente) y los archivos del paquete se deduplicarán del archivo.  No se necesita programación, todo se puede hacer desde vim y guardar en cada copia de seguridad.  Tenga en cuenta que, gracias al enfoque mediante hashes, si algunos archivos del paquete se cambian localmente (por ejemplo, se cambia el archivo de configuración), los archivos modificados se guardarán en el archivo "tal cual" y no se reducirán. </p><br><p>  Si algunos de sus propios paquetes se actualizan periódicamente, pero los cambios no son muy grandes, solo puede insinuar las versiones principales.  Por ejemplo, en la versión 1.0 hicieron una pista indicando mypackage-1.0.tar.gz, y será completamente deduplicada, luego lanzaron la versión 1.1, que es ligeramente diferente, pero no actualizaron la pista.  Nada de qué preocuparse.  Solo se deduplican los archivos que coinciden (que se pueden restaurar) con la versión 1.0. </p><br><p>  Una heurística que procesa un archivo de pistas es un buen ejemplo para comprender el mecanismo interno de la heurística.  Solo procesa archivos hashget-hint.json (o .hashget-hint.json con un punto) e ignora a todos los demás.  Al usar este archivo, determina qué URL del paquete debe indexarse ​​y hashget lo indexa (si esto no se ha hecho antes) </p><br><h2 id="hashserver">  Hashver </h2><br><p>  Sería bastante lento realizar una indexación completa al crear copias de seguridad.  Para hacer esto, debe descargar cada paquete, descomprimir, indexar.  Por lo tanto, el hashget usa un esquema con un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HashServer</a> .  Si se instala un paquete Debian, si no se encuentra en el HashPackage local, primero se intenta descargar el HashPackage del servidor hash.  Y solo si esto no funciona: el propio hashget descarga y procesa el paquete (y lo carga en el servidor hash, de modo que el servidor hash lo proporcione más adelante). </p><br><p>  HashServer: un elemento opcional del esquema, no crítico, se usa exclusivamente para acelerar y reducir la carga en los repositorios.  Se desconecta fácilmente (con la opción <code>--hashserver</code> sin parámetros).  Además, puede <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">crear</a> fácilmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">su propio servidor hash</a> . </p><br><h2 id="inkrementalnye-i-differencialnye-bekapy-zaplanirovannoe-ustarevanie">  Copias de seguridad incrementales y diferenciales, obsolescencia planificada </h2><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El hashget</a> hace que sea muy simple hacer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">copias de seguridad incrementales y diferenciales</a> .  ¿Por qué no indexamos nuestra copia de seguridad (con todos nuestros archivos únicos)?  Un equipo: ¡ <code>--submit</code> y listo!  La próxima copia de seguridad que creará el hashget no incluirá archivos de este archivo. </p><br><p>  Pero este no es un enfoque muy bueno, porque puede resultar que durante la recuperación tendremos que eliminar todas las copias de seguridad de hashget para todo el historial (si cada una tiene al menos un archivo único).  Hay un mecanismo para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la obsolescencia de la copia de seguridad programada</a> para esto.  Al indexar, puede especificar la fecha de vencimiento de HashPackage - <code>--expires 2019-06-01</code> , y en esta fecha (desde las 00:00), no se utilizará.  El archivo en sí no se puede eliminar después de esta fecha (aunque el hashget puede mostrar convenientemente las URL de todas las copias de seguridad que tenemos podridas en ese momento o en cualquier fecha). </p><br><p>  Por ejemplo, si realiza una copia de seguridad completa el primer día y la indexa con una vida útil antes de fin de mes, obtendremos un esquema de copia de seguridad diferencial. </p><br><p>  Si también indexamos nuevas copias de seguridad, habrá un esquema de copias de seguridad incrementales. </p><br><p>  A diferencia de los esquemas tradicionales, el hashget le permite usar varias fuentes básicas.  La copia de seguridad se reducirá debido a la reducción de los archivos de las copias de seguridad anteriores (si corresponde) y debido a los archivos públicos (lo que se puede descargar). </p><br><p>  Si por alguna razón no confiamos en la confiabilidad de los recursos de Debian ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://snapshot.debian.org/</a> ) o usamos otra distribución, podemos hacer una copia de seguridad completa con todos los paquetes una vez y luego confiar en ella ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">deshabilitando la heurística</a> )  Ahora, si todos los servidores de nuestras distribuciones resultan inaccesibles para nosotros (en la Internet de recuerdo o durante el apocalipsis zombie), pero nuestras copias de seguridad están en orden, podemos recuperarnos de cualquier copia de seguridad de diferencia breve que se base solo en nuestras copias de seguridad anteriores. </p><br><blockquote>  Hashget se basa únicamente en fuentes confiables de recuperación a su discreción.  Lo que consideras confiable: se usarán. </blockquote><br><h2 id="filepool-i-glacier">  FilePool y Glacier </h2><br><p>  El mecanismo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FilePool le</a> permite no acceder constantemente a servidores externos para descargar paquetes, sino usar paquetes de un directorio local o servidor corporativo, por ejemplo: </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool /tmp/pool</code> </pre> <br><p>  o </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool http://myhashdb.example.com/</code> </pre> <br><p>  Para crear un grupo en un directorio local, simplemente cree un directorio y cargue archivos en él, el hashget encontrará lo que necesita por hash.  Para hacer que el grupo sea accesible a través de HTTP, debe crear enlaces simbólicos de una manera especial, esto se hace con un comando ( <code>hashget-admin --build /var/www/html/hashdb/ --pool /tmp/pool</code> ).  HTTP FilePool es un archivo estático, por lo que cualquier servidor web simple puede servirlo, la carga en el servidor es casi cero. </p><br><p>  Gracias a FilePool, no solo los recursos http (s) se pueden usar como recursos básicos, sino también, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">por ejemplo</a> , Amazon Glacier. </p><br><p>  Después de la carga de respaldo al glaciar, obtenemos su ID de carga y la usamos como una URL.  Por ejemplo: </p><br><pre> <code class="plaintext hljs">hashget --submit Glacier_Upload_ID --file /tmp/my-glacier-backup.tar.gz --project glacier --hashserver --expires 2019-09-01</code> </pre> <br><p>  Ahora las nuevas copias de seguridad (diferenciales) dependerán de esta copia de seguridad y serán más cortas.  Después de desempacar el tar, podemos ver en qué recursos se basa: </p><br><pre> <code class="plaintext hljs">hashget --info /tmp/unpacked/ list</code> </pre> <br><p>  y simplemente use el script de shell para descargar todos estos archivos del glaciar en el grupo y ejecute la recuperación habitual: hashget -u / tmp / unpacked --pool / tmp / pool </p><br><h3 id="stoit-li-ovchinka-vydelki">  ¿Vale la pena el juego? </h3><br><p>  En el caso más simple, simplemente pagará menos por las copias de seguridad (si las almacena en algún lugar de la nube por dinero).  Quizás, mucho, mucho menos. </p><br><p>  Pero este no es el único.  La cantidad entra en calidad.  Puede usar esto para obtener una actualización del esquema de copia de seguridad de alta calidad.  Por ejemplo, dado que nuestras copias de seguridad ahora son más cortas, no puede hacer una copia de seguridad mensual, sino diaria.  Guárdelos no seis meses, como antes, sino 5 años.  Anteriormente, se almacenaban en un almacenamiento "frío" lento pero barato (Glacier), ahora puede almacenar en caliente, desde donde siempre puede descargar rápidamente una copia de seguridad y recuperarla en minutos, no en un día. </p><br><p>  Puede aumentar la confiabilidad del almacenamiento de respaldo.  Si ahora los almacenamos en una tienda, al reducir el volumen de las copias de seguridad, podemos almacenar en 2-3 tiendas y sobrevivir de forma segura si una de ellas se daña. </p><br><h3 id="kak-poprobovat-i-nachat-polzovatsya">  ¿Cómo probar y empezar a usar? </h3><br><p>  Vamos a la página de gitlab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://gitlab.com/yaroslaff/hashget</a> , lo instalamos con un comando ( <code>pip3 install hashget[plugins]</code> ) y simplemente leemos y ejecutamos el inicio rápido.  Creo que todas las cosas simples que hacer: tomará 10-15 minutos.  Luego, puede intentar sacudir sus máquinas virtuales, crear archivos de sugerencias si es necesario, apretar más, jugar con grupos, una base de datos de hash local y un servidor de hash, si es interesante, y al día siguiente ver cuál será el tamaño de la copia de seguridad incremental de ayer. </p><br><h3 id="restic--hashget">  Restic + HashGet </h3><br><p>  <em>(Este capítulo se agregó más tarde. Gracias a los comentaristas por sus críticas y motivación).</em> </p><br><p>  Existe una buena herramienta conveniente para las copias de seguridad: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">restic</a> .  También puede realizar deduplicación, pero solo dentro del repositorio, no puede deduplicación externa, lo que el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hashget</a> hace <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fácilmente</a> .  ¡Pero en combinación de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">restic + hashget</a> , logramos usar las ventajas de ambos enfoques! </p><br><p>  Preparación (descomprimir wordpress e indexarlo): </p><br><pre> <code class="plaintext hljs"># wget -q https://wordpress.org/wordpress-5.2.2.tar.gz # hashget --submit https://wordpress.org/wordpress-5.2.2.tar.gz -p my --file wordpress-5.2.2.tar.gz --hashserver # tar -xf wordpress-5.2.2.tar.gz # du -sh wordpress 46M wordpress</code> </pre> <br><p>  Agregar instantánea a restic vía </p><br><pre> <code class="plaintext hljs"># hashget -X exclude-list --prepack wordpress --hashserver Saved: 1468 files, 1 pkgs, size: 40.5M. Download: 10.7M # restic --exclude-file exclude-list backup wordpress password is correct scan [/tmp/wp/wordpress] scanned 193 directories, 367 files in 0:02 [0:04] 100.00% 700.829 KiB / 700.829 KiB 560 / 560 items 0 errors ETA 0:00 duration: 0:04 snapshot 76b54230 saved # du -sh /tmp/restic-repo/ 2,1M /tmp/restic-repo/</code> </pre> <br><p>  En esta etapa, agregamos una instantánea del catálogo (más de 40 Mb), y el tamaño del repositorio aumentó solo 1 Mb. </p><br><p>  La recuperación se realiza mediante dos comandos: </p><br><pre> <code class="plaintext hljs"># restic restore 76b54230 -t unpacked password is correct restoring &lt;Snapshot 76b54230 of [/tmp/wp/wordpress] at 2019-06-19 04:30:55.760618336 +0700 +07 by root@braconnier&gt; to unpacked # hashget -u unpacked/wordpress/ --hashserver Recovered 1468/1468 files 40.5M bytes (0 downloaded, 0 from pool, 10.7M cached) in 1.56s</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/454826/">https://habr.com/ru/post/454826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../454810/index.html">Aire fresco en Marte: doble una molécula de CO2 y obtenga oxígeno</a></li>
<li><a href="../454816/index.html">Configuración del paquete php-fpm + nginx en WSL</a></li>
<li><a href="../454818/index.html">Rekko Challenge: cómo ocupar el segundo lugar en la competencia para la creación de sistemas de recomendación</a></li>
<li><a href="../454820/index.html">Búsqueda de Azure</a></li>
<li><a href="../454824/index.html">El amplificador operacional más simple en elementos discretos</a></li>
<li><a href="../454828/index.html">Crear una imagen de mosaico</a></li>
<li><a href="../454830/index.html">3 cualidades clave para un gerente de producto exitoso: Alexander Belyaev</a></li>
<li><a href="../454832/index.html">¿Por qué una semana laboral de cuatro días es una mala historia?</a></li>
<li><a href="../454834/index.html">Los términos reales del estudio de la escritura táctil con baja motivación.</a></li>
<li><a href="../454840/index.html">Cuidado de mudarse a los Países Bajos con su esposa e hipoteca. Parte 2: preparar documentos y mudarse</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
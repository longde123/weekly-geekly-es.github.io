<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÇ ü¶Ç üçê Tout ce que vous saviez sur word2vec n'est pas vrai ‚úùÔ∏è üò£ üòò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'explication classique de word2vec en tant qu'architecture Skip-gram √† √©chantillon n√©gatif dans l'article scientifique d'origine et d'innombrables ar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tout ce que vous saviez sur word2vec n'est pas vrai</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454926/">  L'explication classique de word2vec en tant qu'architecture Skip-gram √† √©chantillon n√©gatif dans l'article scientifique d'origine et d'innombrables articles de blog ressemble √† ceci: <br><br><pre><code class="plaintext hljs">while(1) { 1. vf = vector of focus word 2. vc = vector of focus word 3. train such that (vc . vf = 1) 4. for(0 &lt;= i &lt;= negative samples): vneg = vector of word *not* in context train such that (vf . vneg = 0) }</code> </pre> <br>  En effet, si vous google [skipgram word2vec], ce que nous voyons: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Page Wikip√©dia qui d√©crit l'algorithme √† un niveau √©lev√©</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Page Tensorflow avec la m√™me explication</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vers le blog Data Science avec une description du m√™me algorithme</a> , et la liste continue. </li></ul><br>  <b>Mais toutes ces impl√©mentations sont fausses</b> . <br><a name="habracut"></a><br>  L'impl√©mentation originale de word2vec en C fonctionne diff√©remment et est <i>fondamentalement diff√©rente</i> de cela.  Ceux qui impl√©mentent professionnellement des syst√®mes avec des incorporations de mots √† partir de word2vec font l'une des choses suivantes: <br><br><ol><li>  Appelez directement l'impl√©mentation d'origine de C. <br></li><li>  Utilisez l'impl√©mentation <code>gensim</code> , qui est <i>translitt√©r√©e</i> de la source C dans la mesure o√π les noms de variables correspondent. </li></ol><br>  En effet, <code>gensim</code> est la <i>seule v√©ritable impl√©mentation C que je connaisse</i> . <br><br><h3>  Impl√©mentation C </h3><br>  L'impl√©mentation C prend en charge <i>deux vecteurs pour chaque mot</i> .  Un vecteur pour le mot est mis au point et le second pour le mot dans son contexte.  (Cela vous semble familier? D'accord, les d√©veloppeurs de GloVe ont emprunt√© une id√©e √† word2vec sans mentionner ce fait!) <br><br>  L'impl√©mentation en code C est exceptionnellement comp√©tente: <br><br><ul><li>  Le tableau <code>syn0</code> contient le vecteur d'int√©gration du mot s'il appara√Æt comme un mot au point.  Voici une <b>initialisation al√©atoire</b> . <br><br><pre> <code class="cpp hljs">https:<span class="hljs-comment"><span class="hljs-comment">//github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L369 for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) { next_random = next_random * (unsigned long long)25214903917 + 11; syn0[a * layer1_size + b] = (((next_random &amp; 0xFFFF) / (real)65536) - 0.5) / layer1_size; }</span></span></code> </pre> </li><li>  Un autre tableau <code>syn1neg</code> contient le vecteur du mot lorsqu'il appara√Æt en tant que mot de contexte.  Ici, l' <b>initialisation est nulle</b> . <br></li><li>  Pendant l'entra√Ænement (Skip-gram, √©chantillon n√©gatif, bien que d'autres cas soient √† peu pr√®s les m√™mes), nous s√©lectionnons d'abord le mot de focus.  Il est maintenu tout au long de la formation sur des exemples positifs et n√©gatifs.  Les gradients du vecteur de mise au point sont accumul√©s dans le tampon et appliqu√©s au mot de mise au point apr√®s une formation sur des exemples positifs et n√©gatifs. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (negative &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (d = <span class="hljs-number"><span class="hljs-number">0</span></span>; d &lt; negative + <span class="hljs-number"><span class="hljs-number">1</span></span>; d++) { <span class="hljs-comment"><span class="hljs-comment">// if we are performing negative sampling, in the 1st iteration, // pick a word from the context and set the dot product target to 1 if (d == 0) { target = word; label = 1; } else { // for all other iterations, pick a word randomly and set the dot //product target to 0 next_random = next_random * (unsigned long long)25214903917 + 11; target = table[(next_random &gt;&gt; 16) % table_size]; if (target == 0) target = next_random % (vocab_size - 1) + 1; if (target == word) continue; label = 0; } l2 = target * layer1_size; f = 0; // find dot product of original vector with negative sample vector // store in f for (c = 0; c &lt; layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2]; // set g = sigmoid(f) (roughly, the actual formula is slightly more complex) if (f &gt; MAX_EXP) g = (label - 1) * alpha; else if (f &lt; -MAX_EXP) g = (label - 0) * alpha; else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]) * alpha; // 1. update the vector syn1neg, // 2. DO NOT UPDATE syn0 // 3. STORE THE syn0 gradient in a temporary buffer neu1e for (c = 0; c &lt; layer1_size; c++) neu1e[c] += g * syn1neg[c + l2]; for (c = 0; c &lt; layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1]; } // Finally, after all samples, update syn1 from neu1e https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L541 // Learn weights input -&gt; hidden for (c = 0; c &lt; layer1_size; c++) syn0[c + l1] += neu1e[c];</span></span></code> </pre> </li></ul><br><h3>  Pourquoi une initialisation al√©atoire et nulle? </h3><br>  Encore une fois, comme cela n'est pas expliqu√© du tout dans les articles originaux <i>et partout sur Internet</i> , je ne peux que sp√©culer. <br><br>  L'hypoth√®se est que lorsque des √©chantillons n√©gatifs proviennent de l'ensemble du texte et ne sont pas pond√©r√©s par la fr√©quence, vous pouvez choisir <i>n'importe quel mot</i> , et le plus souvent un mot dont le <i>vecteur n'est pas du tout form√©</i> .  Si ce vecteur a une signification, alors il mettra au hasard le mot vraiment important au point. <br><br>  L'essentiel est de mettre tous les exemples n√©gatifs √† z√©ro, de sorte que <i>seuls les vecteurs qui se produisent plus ou moins souvent</i> affectent la pr√©sentation d'un autre vecteur. <br><br>  C'est en fait assez d√©licat, et je n'avais jamais pens√© √† l'importance des strat√©gies d'initialisation. <br><br><h3>  Pourquoi est-ce que j'√©cris ceci </h3><br>  J'ai pass√© deux mois de ma vie √† essayer de reproduire word2vec comme d√©crit dans la publication scientifique originale et d'innombrables articles sur Internet, mais j'ai √©chou√©.  Je n'ai pas pu obtenir les m√™mes r√©sultats que word2vec, m√™me si j'ai fait de mon mieux. <br><br>  Je ne pouvais pas imaginer que les auteurs de la publication aient litt√©ralement fabriqu√© un algorithme qui ne fonctionne pas, alors que l'impl√©mentation fait quelque chose de compl√®tement diff√©rent. <br><br>  Finalement, j'ai d√©cid√© d'√©tudier la source.  Pendant trois jours, j'√©tais confiant d'avoir mal compris le code, car litt√©ralement tout le monde sur Internet parlait d'une impl√©mentation diff√©rente. <br><br>  Je ne sais pas pourquoi la publication et les articles originaux sur Internet ne disent rien sur le <i>v√©ritable</i> m√©canisme de word2vec, j'ai donc d√©cid√© de publier moi-m√™me ces informations. <br><br>  Cela explique √©galement le choix radical de GloVe de d√©finir des vecteurs s√©par√©s pour le contexte n√©gatif - ils ont juste fait ce que fait word2vec, mais en ont parl√© aux gens :). <br><br>  Est-ce une astuce scientifique?  Je ne sais pas, une question difficile.  Mais pour √™tre honn√™te, je suis incroyablement en col√®re.  Probablement, je ne pourrai plus jamais prendre au s√©rieux l'explication des algorithmes en machine learning: la prochaine fois j'irai <i>imm√©diatement</i> regarder les sources. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr454926/">https://habr.com/ru/post/fr454926/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr454916/index.html">Architecture de r√©seau neuronal pour impl√©menter l'algorithme RL avec la possibilit√© de d√©finir simultan√©ment des actions en cours d'ex√©cution</a></li>
<li><a href="../fr454918/index.html">Comment combiner le dos de deux d√©taillants sur SAP en 12 heures</a></li>
<li><a href="../fr454920/index.html">Performances frontales: analyse des mesures importantes</a></li>
<li><a href="../fr454922/index.html">Contes sur les clients √©trangers et leurs caract√©ristiques du travail en Russie apr√®s la loi PD</a></li>
<li><a href="../fr454924/index.html">Param√®tres d'authentification dans Veeam Backup pour Microsoft Office 365 v3</a></li>
<li><a href="../fr454928/index.html">Fa√ßon de contourner l'√©cran de verrouillage de Windows sur les sessions RDP</a></li>
<li><a href="../fr454932/index.html">Investissements et logiciels: 5 terminaux de trading pour n√©gocier en bourse</a></li>
<li><a href="../fr454936/index.html">Vivaldi: le blocage des publicit√©s devrait √™tre le choix de l'utilisateur</a></li>
<li><a href="../fr454938/index.html">D√©veloppement de son propre noyau pour l'int√©gration dans un syst√®me de processeur bas√© sur FPGA</a></li>
<li><a href="../fr454940/index.html">Assurance sant√© voyage: instructions d√©taill√©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
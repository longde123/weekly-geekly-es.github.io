<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë®‚Äçüë¶ üóìÔ∏è üñïüèª Application pratique d'ELK. Configurer logstash ‚òéÔ∏è üíπ üò´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pr√©sentation 
 D√©ployer le prochain syst√®me, face √† la n√©cessit√© de traiter un grand nombre de journaux diff√©rents. Comme l'outil choisi ELK. Cet arti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Application pratique d'ELK. Configurer logstash</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451264/"><h1>  Pr√©sentation </h1><br>  D√©ployer le prochain syst√®me, face √† la n√©cessit√© de traiter un grand nombre de journaux diff√©rents.  Comme l'outil choisi ELK.  Cet article pr√©sente notre exp√©rience de l'optimisation de cette pile. <br><br>  Nous n'avons pas pour objectif de d√©crire toutes ses possibilit√©s, mais nous voulons nous concentrer pr√©cis√©ment sur la r√©solution de probl√®mes pratiques.  Cela est d√ª au fait qu'en pr√©sence d'une quantit√© suffisamment importante de documentation et d'images pr√™tes √† l'emploi, il existe de nombreux pi√®ges, du moins nous les avons trouv√©s. <br><a name="habracut"></a><br>  Nous avons d√©ploy√© la pile via docker-compose.  De plus, nous avions un docker-compose.yml bien √©crit, ce qui nous a permis d'augmenter la pile sans presque aucun probl√®me.  Et il nous a sembl√© que la victoire √©tait d√©j√† proche, maintenant nous allons tordre un peu pour r√©pondre √† nos besoins et c'est tout. <br><br>  Malheureusement, une tentative de r√©glage du syst√®me pour recevoir et traiter les journaux de notre application n'a pas √©t√© couronn√©e de succ√®s.  Par cons√©quent, nous avons d√©cid√© qu'il valait la peine d'explorer chaque composante s√©par√©ment, puis de revenir √† leurs relations. <br><br>  Nous avons donc commenc√© avec logstash. <br><br><h1>  Environnement, d√©ploiement, lancement de Logstash dans le conteneur </h1><br>  Pour le d√©ploiement, nous utilisons docker-compose, les exp√©riences d√©crites ici ont √©t√© men√©es sur MacOS et Ubuntu 18.0.4. <br><br>  L'image logstash enregistr√©e avec nous dans le docker-compose.yml d'origine est docker.elastic.co/logstash/logstash:6.3.2 <br><br>  Nous l'utiliserons pour des exp√©riences. <br><br>  Pour ex√©cuter logstash, nous avons √©crit un docker-compose.yml distinct.  Bien s√ªr, il √©tait possible de lancer l'image √† partir de la ligne de commande, mais nous avons r√©solu un probl√®me sp√©cifique, o√π tout de docker-compose est lanc√©. <br><br><h2>  En bref sur les fichiers de configuration </h2><br>  Comme il ressort de la description, logstash peut √™tre ex√©cut√© √† la fois pour un canal, dans ce cas, il doit transf√©rer le fichier * .conf ou pour plusieurs canaux, dans ce cas, il doit √™tre transf√©r√© le fichier pipelines.yml, qui, √† son tour, sera li√© aux fichiers .conf pour chaque canal. <br>  Nous sommes all√©s dans la deuxi√®me voie.  Il nous a sembl√© plus universel et √©volutif.  Par cons√©quent, nous avons cr√©√© pipelines.yml et cr√©√© le r√©pertoire pipelines dans lequel nous placerons les fichiers .conf pour chaque canal. <br><br>  √Ä l'int√©rieur du conteneur, il y a un autre fichier de configuration - logstash.yml.  On ne le touche pas, on l'utilise tel quel. <br><br>  Ainsi, la structure de nos r√©pertoires: <br><br><img src="https://habrastorage.org/webt/ci/zd/49/cizd49eci9alvlbi1fwk8nyyaky.png"><br><br>  Pour obtenir l'entr√©e, pour l'instant, nous pensons que c'est TCP sur le port 5046, et pour la sortie, nous utiliserons stdout. <br><br>  Voici une configuration si simple pour la premi√®re ex√©cution.  Depuis la t√¢che initiale est de lancer. <br><br>  Nous avons donc ce docker-compose.yml <br><br><pre><code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre> <br>  Que voyons-nous ici? <br><br><ol><li>  Les r√©seaux et les volumes ont √©t√© pris √† partir du docker-compose.yml d'origine (celui o√π la pile enti√®re est lanc√©e) et je pense qu'ils n'affectent pas de mani√®re significative l'image globale ici. </li><li>  Nous cr√©ons un service logstash √† partir de l'image docker.elastic.co/logstash/logstash:6.3.2 et lui donnons le nom logstash_one_channel. </li><li>  Nous transmettons le port 5046 √† l'int√©rieur du conteneur au m√™me port interne. </li><li>  Nous mappons notre fichier de param√®tres de canal ./config/pipelines.yml au fichier /usr/share/logstash/config/pipelines.yml √† l'int√©rieur du conteneur, o√π logstash le r√©cup√©rera et le rendra en lecture seule, juste au cas o√π. </li><li>  Nous affichons le r√©pertoire ./config/pipelines, o√π nous avons les fichiers avec les param√®tres de canal, dans le r√©pertoire / usr / share / logstash / config / pipelines et le rendons en lecture seule. </li></ol><br><img src="https://habrastorage.org/webt/5u/s3/dw/5us3dwu8forutzwmtlfnlcjt-ic.png"><br><br>  Fichier Pipelines.yml <br><br><pre> <code class="plaintext hljs">- pipeline.id: HABR pipeline.workers: 1 pipeline.batch.size: 1 path.config: "./config/pipelines/habr_pipeline.conf"</code> </pre><br>  Ici, un canal avec l'identifiant HABR et le chemin vers son fichier de configuration sont d√©crits. <br><br>  Et enfin le fichier "./config/pipelines/habr_pipeline.conf" <br><br><pre> <code class="plaintext hljs">input { tcp { port =&gt; "5046" } } filter { mutate { add_field =&gt; [ "habra_field", "Hello Habr" ] } } output { stdout { } }</code> </pre><br>  N'entrons pas dans sa description pour l'instant, essayons de lancer: <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br>  Que voyons-nous? <br><br>  Le conteneur a d√©marr√©.  On peut v√©rifier son fonctionnement: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br>  Et nous voyons la r√©ponse dans la console de conteneur: <br><br><img src="https://habrastorage.org/webt/uj/oy/tz/ujoytzcsc_mmiagm05savxahnzm.jpeg"><br><br>  Mais en m√™me temps, nous voyons √©galement: <br><br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,790] <font color="¬´CC0000¬ª">[ERREUR] [logstash.licensechecker.licensereader] Impossible de r√©cup√©rer les informations de licence √† partir du serveur de licences {: message =&gt; "Elasticsearch inaccessible: [http: // elasticsearch: 9200 /]</font> [Manticore :: ResolutionFailure] elasticsearch ", ... <br><br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,894] [INFO] [logstash.pipeline] Le <font color="green">pipeline a d√©marr√© avec succ√®s</font> {: pipeline_id =&gt; ". Monitoring-logstash" ,: thread =&gt; "# &lt;Thread: 0x119abb86 run&gt;"} <br><br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,988] [INFO] [logstash.agent] Pipelines en cours d'ex√©cution {: count =&gt; 2 ,: running_pipelines =&gt; [: HABR ,: ". Monitoring-logstash"] ,: non_running_pipelines =&gt; [ ]} <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 00,015] <font color="¬´CC0000¬ª">[ERREUR] [logstash.inputs.metrics] X-Pack est install√© sur Logstash mais pas sur Elasticsearch.</font>  <font color="¬´CC0000¬ª">Veuillez installer X-Pack sur Elasticsearch pour utiliser la fonction de surveillance.</font>  <font color="¬´CC0000¬ª">D'autres fonctionnalit√©s peuvent √™tre disponibles.</font> <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 00,526] [INFO] [logstash.agent] Point de terminaison de l'API Logstash d√©marr√© avec succ√®s {: port =&gt; 9600} <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,478] [INFO] [logstash.outputs.elasticsearch] Ex√©cution d'un contr√¥le d'int√©grit√© pour voir si une connexion Elasticsearch fonctionne {: healthcheck_url =&gt; http: // elasticsearch: 9200 / ,: path =&gt; "/"} <br>  l <font color="¬´#38B9C7¬ª">ogstash_one_channel |</font>  [2019-04-29T11: 29: 04,487] <font color="orange">[WARN] [logstash.outputs.elasticsearch] Tentative de ressusciter la connexion √† une instance ES morte, mais a obtenu une erreur.</font>  <font color="orange">{: url =&gt; ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">elasticsearch</a> : 9200 /¬ª ,: error_type =&gt; LogStash :: Outputs :: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError ,: error =&gt; ¬´Elasticsearch Unreachable: [http: // elasticsearch: 9200 / ] [Manticore :: ResolutionFailure] elasticsearch ‚Äù}</font> <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,704] [INFO] [logstash.licensechecker.licensereader] Ex√©cution d'un contr√¥le d'int√©grit√© pour voir si une connexion Elasticsearch fonctionne {: healthcheck_url =&gt; http: // elasticsearch: 9200 / ,: path =&gt; "/"} <br>  <font color="¬´#38B9C7¬ª">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,710] <font color="orange">[AVERTISSEMENT] [logstash.licensechecker.licensereader] Vous avez tent√© de ressusciter la connexion √† une instance ES morte, mais vous avez obtenu une erreur.</font>  <font color="orange">{: url =&gt; ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">elasticsearch</a> : 9200 /¬ª ,: error_type =&gt; LogStash :: Outputs :: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError ,: error =&gt; ¬´Elasticsearch Unreachable: [http: // elasticsearch: 9200 / ] [Manticore :: ResolutionFailure] elasticsearch ‚Äù}</font> <br><br>  Et notre journal grimpe tout le temps. <br><br>  Ici, j'ai mis en √©vidence en vert un message indiquant que le pipeline a d√©marr√© avec succ√®s, en rouge - un message d'erreur et en jaune - un message concernant une tentative de contact avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">elasticsearch</a> : 9200. <br>  Cela se produit du fait que logstash.conf inclus dans l'image contient une v√©rification de la disponibilit√© d'elasticsearch.  Apr√®s tout, logstash suppose qu'il fonctionne dans le cadre de la pile Elk, et nous l'avons s√©par√©. <br><br>  Vous pouvez travailler, mais pas pratique. <br><br>  La solution consiste √† d√©sactiver cette v√©rification via la variable d'environnement XPACK_MONITORING_ENABLED. <br><br>  Apportez une modification √† docker-compose.yml et ex√©cutez-le √† nouveau: <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre><br>  Maintenant, tout va bien.  Le conteneur est pr√™t pour l'exp√©rimentation. <br><br>  On peut encore taper dans la console suivante: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br>  Et voyez: <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "message" =&gt; "13123123123123123123123213123213", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T11:43:44.582Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "host" =&gt; "gateway", logstash_one_channel | "port" =&gt; 49418 logstash_one_channel | }</code> </pre><br><h1>  Travailler dans un seul canal </h1><br>  Nous avons donc commenc√©.  Vous pouvez maintenant prendre le temps de configurer directement logstash.  Nous ne toucherons pas au fichier pipelines.yml pour le moment, nous verrons ce que vous pouvez obtenir en travaillant avec un seul canal. <br><br>  Je dois dire que le principe g√©n√©ral de travailler avec le fichier de configuration de canal est bien d√©crit dans le guide officiel, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> <br>  Si vous voulez lire en russe, nous avons utilis√© cet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article ici</a> (mais la syntaxe de la requ√™te est ancienne l√†-bas, nous devons en tenir compte). <br><br>  Allons s√©quentiellement √† partir de la section Input.  Nous avons d√©j√† vu des travaux sur TCP.  Quoi d'autre pourrait √™tre int√©ressant ici? <br><br><h2>  Tester les messages √† l'aide de Heartbeat </h2><br>  Il existe une opportunit√© int√©ressante pour g√©n√©rer des messages de test automatiques. <br>  Pour ce faire, vous devez inclure le plugin heartbean dans la section d'entr√©e. <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" } }</code> </pre><br>  Allumez, commencez une fois par minute pour recevoir <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "@timestamp" =&gt; 2019-04-29T13:52:04.567Z, logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "HeartBeat!", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "host" =&gt; "a0667e5c57ec" logstash_one_channel | }</code> </pre><br>  Nous voulons obtenir plus souvent, nous devons ajouter le param√®tre d'intervalle. <br>  C'est ainsi que nous recevrons un message toutes les 10 secondes. <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" interval =&gt; 10 } }</code> </pre><br><h2>  R√©cup√©ration des donn√©es d'un fichier </h2><br>  Nous avons √©galement d√©cid√© de voir le mode fichier.  Si cela fonctionne normalement avec le fichier, il est possible qu'aucun agent ne soit n√©cessaire, enfin, au moins pour une utilisation locale. <br><br>  Selon la description, le mode de fonctionnement doit √™tre similaire √† tail -f, c'est-√†-dire  lit les nouvelles lignes ou, en option, lit le fichier entier. <br><br>  Donc, ce que nous voulons obtenir: <br><br><ol><li>  Nous voulons obtenir des lignes qui sont ajout√©es √† un fichier journal. </li><li>  Nous voulons recevoir des donn√©es qui sont √©crites dans plusieurs fichiers journaux, tout en pouvant partager ce qui en est issu. </li><li>  Nous voulons v√©rifier qu'au red√©marrage de logstash, il ne recevra plus ces donn√©es. </li><li>  Nous voulons v√©rifier que si logstash est d√©sactiv√© et que les donn√©es continuent d'√™tre √©crites dans des fichiers, alors lorsque nous l'ex√©cuterons, nous obtiendrons ces donn√©es. </li></ol><br>  Pour mener l'exp√©rience, ajoutez une autre ligne √† docker-compose.yml, ouvrant le r√©pertoire dans lequel nous avons plac√© les fichiers. <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input</code> </pre><br>  Et changez la section d'entr√©e dans habr_pipeline.conf <br><br><pre> <code class="plaintext hljs">input { file { path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br>  Nous commen√ßons: <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br>  Pour cr√©er et enregistrer des fichiers journaux, nous utiliserons la commande: <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:53.876Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br>  Ouais, √ßa marche! <br><br>  En m√™me temps, nous voyons que nous avons ajout√© automatiquement le champ du chemin.  Donc, √† l'avenir, nous pouvons filtrer les enregistrements par celui-ci. <br><br>  Essayons encore: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'2'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:59.906Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "2", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br><br>  Et maintenant, dans un autre fichier: <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number2.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:29:26.061Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log" logstash_one_channel | }</code> </pre><br>  Super!  Le fichier a √©t√© r√©cup√©r√©, le chemin √©tait correct, tout va bien. <br><br>  Arr√™tez logstash et red√©marrez.  Attendons.  Le silence.  C'est-√†-dire  Nous ne recevons plus ces enregistrements. <br><br>  Et maintenant l'exp√©rience la plus audacieuse. <br><br>  Nous mettons logstash et ex√©cutons: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'3'</span></span> &gt;&gt; logs/number2.log <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'4'</span></span> &gt;&gt; logs/number1.log</code> </pre><br>  Ex√©cutez √† nouveau logstash et voyez: <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "3", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.589Z logstash_one_channel | } logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "4", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.856Z logstash_one_channel | }</code> </pre><br>  Hourra!  Tout a √©t√© ramass√©. <br><br>  Mais, nous devons mettre en garde contre les √©l√©ments suivants.  Si le conteneur avec logstash est supprim√© (docker stop logstash_one_channel &amp;&amp; docker rm logstash_one_channel), rien ne sera r√©cup√©r√©.  √Ä l'int√©rieur du conteneur, la position du fichier dans lequel il a √©t√© lu a √©t√© enregistr√©e.  S'il est ex√©cut√© √† partir de z√©ro, il n'acceptera que les nouvelles lignes. <br><br><h3>  Lire les fichiers existants </h3><br>  Supposons que nous ex√©cutions logstash pour la premi√®re fois, mais nous avons d√©j√† des journaux et nous aimerions les traiter. <br>  Si nous ex√©cutons logstash avec la section d'entr√©e que nous avons utilis√©e ci-dessus, nous n'obtiendrons rien.  Seuls les retours √† la ligne seront trait√©s par logstash. <br><br>  Pour extraire des lignes de fichiers existants, ajoutez une ligne suppl√©mentaire √† la section d'entr√©e: <br><br><pre> <code class="plaintext hljs">input { file { start_position =&gt; "beginning" path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br>  De plus, il y a une nuance, cela n'affecte que les nouveaux fichiers que logstash n'a pas encore vus.  Pour les m√™mes fichiers qui tombaient d√©j√† dans le champ de vision de logstash, il s'est d√©j√† souvenu de leur taille et n'acceptera d√©sormais que de nouvelles entr√©es. <br><br>  Arr√™tons-nous sur l'√©tude de la section d'entr√©e.  Il y a beaucoup plus d'options, mais pour nous, pour de nouvelles exp√©riences, c'est suffisant. <br><br><h2>  Routage et conversion de donn√©es </h2><br>  Essayons de r√©soudre le probl√®me suivant, disons que nous avons des messages d'un canal, certains d'entre eux sont informatifs, et en partie un message d'erreur.  Diff√©rent dans la balise.  Certaines INFO, d'autres ERREUR. <br><br>  Nous devons les s√©parer √† la sortie.  C'est-√†-dire  Nous √©crivons des messages d'information dans un canal et des messages d'erreur dans un autre. <br><br>  Pour ce faire, passez de la section d'entr√©e au filtre et √† la sortie. <br><br>  En utilisant la section filtre, nous analyserons le message entrant, en en tirant du hachage (paires cl√©-valeur), avec lequel vous pouvez d√©j√† travailler, c'est-√†-dire  d√©monter par conditions.  Et dans la section sortie, nous s√©lectionnons les messages et les envoyons √† notre cha√Æne. <br><br><h3>  Analyser un message √† l'aide de grok </h3><br>  Afin d'analyser les cha√Ænes de texte et d'en obtenir un ensemble de champs, il existe un plugin sp√©cial dans la section filtre - grok. <br><br>  Ne visant pas √† donner ici une description d√©taill√©e ici (pour cela je me r√©f√®re √† la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation officielle</a> ), je vais donner mon exemple simple. <br><br>  Pour ce faire, vous devez d√©cider du format des lignes d'entr√©e.  Je les ai: <br><br>  1 message INFO1 <br>  2 Message d'erreur 2 <br><br>  C'est-√†-dire  L'identifiant vient d'abord, puis INFO / ERREUR, puis un mot sans espaces. <br>  Pas difficile, mais assez pour comprendre comment √ßa marche. <br><br>  Donc, dans la section filtre, dans le plugin grok, nous devons d√©finir un mod√®le pour analyser nos lignes. <br><br>  Cela ressemblera √† ceci: <br><br><pre> <code class="plaintext hljs">filter { grok { match =&gt; { "message" =&gt; ["%{INT:message_id} %{LOGLEVEL:message_type} %{WORD:message_text}"] } } }</code> </pre><br>  Il s'agit essentiellement d'une expression r√©guli√®re.  Des mod√®les pr√™ts √† l'emploi sont utilis√©s, tels que INT, LOGLEVEL, WORD.  Leur description, ainsi que d'autres mod√®les, peuvent √™tre trouv√©s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici.</a> <br><br>  Maintenant, en passant par ce filtre, notre cha√Æne se transformera en un hachage de trois champs: message_id, message_type, message_text. <br><br>  Ils seront affich√©s dans la section de sortie. <br><br><h3>  Routage des messages dans la section de sortie √† l'aide de la commande if </h3><br>  Dans la section de sortie, comme nous nous en souvenons, nous allions diviser les messages en deux flux.  Certains - dont iNFO, nous sortirons sur la console, et avec des erreurs, nous sortirons dans un fichier. <br><br>  Comment divisons-nous ces messages?  La condition du probl√®me invite d√©j√† la solution - nous avons d√©j√† le champ message_type s√©lectionn√©, qui ne peut prendre que deux valeurs INFO et ERROR.  C'est pour lui que nous ferons un choix en utilisant l'instruction if. <br><br><pre> <code class="plaintext hljs">if [message_type] == "ERROR" { #     } else { #    stdout }</code> </pre><br>  La description de l'utilisation des champs et des op√©rateurs se trouve dans cette section du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">manuel officiel</a> . <br><br>  Maintenant, √† propos de la conclusion proprement dite. <br><br>  La sortie vers la console, tout est clair ici - stdout {} <br><br>  Et voici la sortie du fichier - rappelez-vous que nous l'ex√©cutons √† partir du conteneur et que pour que le fichier dans lequel nous √©crivons le r√©sultat soit accessible de l'ext√©rieur, nous devons ouvrir ce r√©pertoire dans docker-compose.yml. <br><br>  Total: <br><br>  La section de sortie de notre fichier ressemble √† ceci: <br><br><pre> <code class="plaintext hljs"> output { if [message_type] == "ERROR" { file { path =&gt; "/usr/share/logstash/output/test.log" codec =&gt; line { format =&gt; "custom format: %{message}"} } } else {stdout { } } }</code> </pre><br>  Dans docker-compose.yml, ajoutez un autre volume √† la sortie: <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input - ./output:/usr/share/logstash/output</code> </pre><br>  Nous commen√ßons, nous essayons, nous voyons la division en deux flux. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451264/">https://habr.com/ru/post/fr451264/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451254/index.html">Cat√©gorie: unboxing iron IaaS provider</a></li>
<li><a href="../fr451256/index.html">Qu'est-ce qu'un syst√®me de reporting id√©al. Est-il r√©aliste de comprendre ce qui se passe dans l'entreprise?</a></li>
<li><a href="../fr451258/index.html">Attrape-moi si tu peux. Lettre du directeur</a></li>
<li><a href="../fr451260/index.html">10 √©v√©nements th√©matiques de l'Universit√© ITMO</a></li>
<li><a href="../fr451262/index.html">Scientifiques de Stanford: un gadget plac√© dans l'oreille pourra surveiller le fonctionnement du cerveau</a></li>
<li><a href="../fr451266/index.html">Mod√©lisation tridimensionnelle dans le monde moderne</a></li>
<li><a href="../fr451268/index.html">Victor Gamov √† propos de Kafka Streams IQ sur jug.msk.ru</a></li>
<li><a href="../fr451270/index.html">B = Attention, ou comment cr√©er du temps</a></li>
<li><a href="../fr451272/index.html">Si vous frappez d√©j√† √† la porte: comment prot√©ger les informations sur les appareils</a></li>
<li><a href="../fr451274/index.html">Arme parfaite, guerre des perspectives et un √™tre humain atteignant le plafond</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👴 🌨️ 🥒 System.IO.Pipelines: E / S de alto desempenho no .NET 🧑🏻‍🤝‍🧑🏻 👋🏽 👩🏾‍🤝‍👨🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="System.IO.Pipelines é uma nova biblioteca que simplifica a organização do código no .NET. É difícil garantir alto desempenho e precisão se você precis...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>System.IO.Pipelines: E / S de alto desempenho no .NET</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/423105/">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">System.IO.Pipelines</a> é uma nova biblioteca que simplifica a organização do código no .NET.  É difícil garantir alto desempenho e precisão se você precisar lidar com códigos complexos.  A tarefa do System.IO.Pipelines é simplificar o código.  Mais detalhes sob o corte! <br><br><img src="https://habrastorage.org/webt/nq/me/p-/nqmep-tqvyyv5nlkpcxjnmlw8z4.jpeg"><a name="habracut"></a><br><br>  A biblioteca surgiu como resultado dos esforços da equipe de desenvolvimento do .NET Core para tornar o Kestrel um dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">servidores da Web mais rápidos do setor</a> .  Ele foi originalmente concebido como parte da implementação do Kestrel, mas evoluiu para uma API reutilizável, disponível na versão 2.1 como uma API BCL de primeira classe (System.IO.Pipelines). <br><br><h2>  Que problemas ela resolve? </h2><br>  Para analisar corretamente os dados de um fluxo ou soquete, você precisa escrever uma grande quantidade de código padrão.  Ao mesmo tempo, existem muitas armadilhas que complicam o próprio código e seu suporte. <br><br><h2>  Que dificuldades surgem hoje? </h2><br>  Vamos começar com uma tarefa simples.  Precisamos escrever um servidor TCP que receba mensagens delimitadas por linha (\ n) do cliente. <br><br><h2>  Servidor TCP com NetworkStream </h2><br>  DESVIO: como em qualquer tarefa que exija alto desempenho, cada caso específico deve ser considerado com base nos recursos do seu aplicativo.  Pode não fazer sentido gastar recursos no uso de várias abordagens, que serão discutidas mais adiante, se a escala do aplicativo de rede não for muito grande. <br><br>  O código .NET regular antes de usar pipelines é algo como isto: <br><br><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> buffer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1024</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> stream.ReadAsync(buffer, <span class="hljs-number"><span class="hljs-number">0</span></span>, buffer.Length); <span class="hljs-comment"><span class="hljs-comment">// Process a single line from the buffer ProcessLine(buffer); }</span></span></code> </pre> <br>  veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sample1.cs</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github</a> <br><br>  Esse código provavelmente funcionará com testes locais, mas possui vários erros: <br><br><ul><li>  Talvez após uma única chamada para o ReadAsync, a mensagem inteira não seja recebida (até o final da linha). </li><li>  Ele ignora o resultado do método stream.ReadAsync () - a quantidade de dados realmente transferida para o buffer. </li><li>  O código não controla o recebimento de várias linhas em uma única chamada ReadAsync. </li></ul><br>  Esses são os erros mais comuns de leitura de dados de streaming.  Para evitá-los, é necessário fazer várias alterações: <br><br><ul><li>  Você precisa armazenar em buffer os dados recebidos até que uma nova linha seja encontrada. </li><li>  É necessário analisar todas as linhas retornadas ao buffer. </li></ul><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> buffer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1024</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesBuffered = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesRead = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> stream.ReadAsync(buffer, bytesBuffered, buffer.Length - bytesBuffered); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (bytesRead == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// EOF break; } // Keep track of the amount of buffered bytes bytesBuffered += bytesRead; var linePosition = -1; do { // Look for a EOL in the buffered data linePosition = Array.IndexOf(buffer, (byte)'\n', bytesConsumed, bytesBuffered - bytesConsumed); if (linePosition &gt;= 0) { // Calculate the length of the line based on the offset var lineLength = linePosition - bytesConsumed; // Process the line ProcessLine(buffer, bytesConsumed, lineLength); // Move the bytesConsumed to skip past the line we consumed (including \n) bytesConsumed += lineLength + 1; } } while (linePosition &gt;= 0); } }</span></span></code> </pre> <br>  veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sample2.cs</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github</a> <br><br>  Repito: isso pode funcionar com testes locais, mas às vezes existem cadeias maiores que 1 Kb (1024 bytes).  É necessário aumentar o tamanho do buffer de entrada até que uma nova linha seja encontrada. <br><br>  Além disso, coletamos buffers em uma matriz ao processar seqüências longas.  Podemos melhorar esse processo com o ArrayPool, que evita a realocação de buffers durante a análise de longas filas do cliente. <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] buffer = ArrayPool&lt;<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>&gt;.Shared.Rent(<span class="hljs-number"><span class="hljs-number">1024</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesBuffered = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer var bytesRemaining = buffer.Length - bytesBuffered; if (bytesRemaining == 0) { // Double the buffer size and copy the previously buffered data into the new buffer var newBuffer = ArrayPool&lt;byte&gt;.Shared.Rent(buffer.Length * 2); Buffer.BlockCopy(buffer, 0, newBuffer, 0, buffer.Length); // Return the old buffer to the pool ArrayPool&lt;byte&gt;.Shared.Return(buffer); buffer = newBuffer; bytesRemaining = buffer.Length - bytesBuffered; } var bytesRead = await stream.ReadAsync(buffer, bytesBuffered, bytesRemaining); if (bytesRead == 0) { // EOF break; } // Keep track of the amount of buffered bytes bytesBuffered += bytesRead; do { // Look for a EOL in the buffered data linePosition = Array.IndexOf(buffer, (byte)'\n', bytesConsumed, bytesBuffered - bytesConsumed); if (linePosition &gt;= 0) { // Calculate the length of the line based on the offset var lineLength = linePosition - bytesConsumed; // Process the line ProcessLine(buffer, bytesConsumed, lineLength); // Move the bytesConsumed to skip past the line we consumed (including \n) bytesConsumed += lineLength + 1; } } while (linePosition &gt;= 0); } }</span></span></code> </pre> <br>  <i>veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sample3.cs</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github</a></i> <br><br>  O código funciona, mas agora o tamanho do buffer mudou, como resultado, muitas cópias dele aparecem.  Também é usada mais memória, pois a lógica não reduz o buffer após o processamento das linhas.  Para evitar isso, você pode salvar a lista de buffers, em vez de alterar o tamanho do buffer sempre que uma string chegar a mais de 1 Kb. <br><br>  Além disso, não aumentamos o tamanho do buffer de 1 KB, até que esteja completamente vazio.  Isso significa que transferiremos buffers cada vez menores para o ReadAsync, como resultado, o número de chamadas para o sistema operacional aumentará. <br><br>  Vamos tentar eliminar isso e alocaremos um novo buffer assim que o tamanho do existente se tornar menor que 512 bytes: <br><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">BufferSegment</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] Buffer { <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> Count { <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> Remaining =&gt; Buffer.Length - Count; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minimumBufferSize = <span class="hljs-number"><span class="hljs-number">512</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segments = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;BufferSegment&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumedBufferIndex = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segment = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> BufferSegment { Buffer = ArrayPool&lt;<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>&gt;.Shared.Rent(<span class="hljs-number"><span class="hljs-number">1024</span></span>) }; segments.Add(segment); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer if (segment.Remaining &lt; minimumBufferSize) { // Allocate a new segment segment = new BufferSegment { Buffer = ArrayPool&lt;byte&gt;.Shared.Rent(1024) }; segments.Add(segment); } var bytesRead = await stream.ReadAsync(segment.Buffer, segment.Count, segment.Remaining); if (bytesRead == 0) { break; } // Keep track of the amount of buffered bytes segment.Count += bytesRead; while (true) { // Look for a EOL in the list of segments var (segmentIndex, segmentOffset) = IndexOf(segments, (byte)'\n', bytesConsumedBufferIndex, bytesConsumed); if (segmentIndex &gt;= 0) { // Process the line ProcessLine(segments, segmentIndex, segmentOffset); bytesConsumedBufferIndex = segmentOffset; bytesConsumed = segmentOffset + 1; } else { break; } } // Drop fully consumed segments from the list so we don't look at them again for (var i = bytesConsumedBufferIndex; i &gt;= 0; --i) { var consumedSegment = segments[i]; // Return all segments unless this is the current segment if (consumedSegment != segment) { ArrayPool&lt;byte&gt;.Shared.Return(consumedSegment.Buffer); segments.RemoveAt(i); } } } } (int segmentIndex, int segmentOffest) IndexOf(List&lt;BufferSegment&gt; segments, byte value, int startBufferIndex, int startSegmentOffset) { var first = true; for (var i = startBufferIndex; i &lt; segments.Count; ++i) { var segment = segments[i]; // Start from the correct offset var offset = first ? startSegmentOffset : 0; var index = Array.IndexOf(segment.Buffer, value, offset, segment.Count - offset); if (index &gt;= 0) { // Return the buffer index and the index within that segment where EOL was found return (i, index); } first = false; } return (-1, -1); }</span></span></code> </pre> <br>  <i>veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sample4.cs</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github</a></i> <br><br>  Como resultado, o código é significativamente complicado.  Durante a pesquisa do delimitador, rastreamos os buffers preenchidos.  Para fazer isso, use uma Lista, que exibe dados em buffer ao procurar um novo separador de linhas.  Como resultado, ProcessLine e IndexOf aceitarão List em vez de byte [], deslocamento e contagem.  A lógica de análise começará a processar um segmento do buffer ou vários. <br><br>  E agora o servidor processará mensagens parciais e usará a memória compartilhada para reduzir o consumo geral de memória.  No entanto, várias alterações precisam ser feitas: <br><br><ol><li>  No ArrayPoolbyte, usamos apenas Byte [] - matrizes gerenciadas de maneira padrão.  Em outras palavras, quando as funções ReadAsync ou WriteAsync são executadas, o período de validade dos buffers é vinculado ao tempo da operação assíncrona (para interagir com as próprias APIs de E / S do sistema operacional).  Como a memória fixada não pode ser movida, isso afeta o desempenho do coletor de lixo e pode causar fragmentação da matriz.  Pode ser necessário alterar a implementação do pool, dependendo de quanto tempo as operações assíncronas aguardarão a execução. </li><li>  A taxa de transferência pode ser aprimorada quebrando o link entre a lógica de leitura e o processo.  Temos o efeito do processamento em lote, e agora a lógica de análise poderá ler grandes quantidades de dados, processando grandes blocos de buffers, em vez de analisar linhas individuais.  Como resultado, o código fica ainda mais complicado: <br><br><ul><li>  É necessário criar dois ciclos que funcionam independentemente um do outro.  O primeiro lerá os dados do soquete e o segundo analisará os buffers. </li><li>  O que é necessário é uma maneira de dizer à lógica de análise que os dados estão se tornando disponíveis. </li><li>  Também é necessário determinar o que acontece se o loop lê os dados do soquete muito rapidamente.  Precisamos de uma maneira de ajustar o ciclo de leitura se a lógica de análise não o acompanhar.  Isso geralmente é chamado de "controle de fluxo" ou "resistência ao fluxo". </li><li>  Devemos garantir que os dados sejam transmitidos com segurança.  Agora, o conjunto de buffers é usado tanto pelo ciclo de leitura quanto pelo ciclo de análise; eles funcionam independentemente um do outro em threads diferentes. </li><li>  A lógica de gerenciamento de memória também está envolvida em duas partes diferentes de código: emprestando dados do buffer pool, que lê dados do soquete, e retornando do buffer pool, que é a lógica de análise. </li><li>  É preciso ter muito cuidado com o retorno de buffers após a execução da lógica de análise.  Caso contrário, existe a chance de retornarmos o buffer no qual a lógica de leitura do soquete ainda está sendo gravada. </li></ul></li></ol><br>  A complexidade começa a atravessar o telhado (e isso está longe de todos os casos!).  Para criar uma rede de alto desempenho, você precisa escrever um código muito complexo. <br><br>  O objetivo do System.IO.Pipelines é simplificar esse procedimento. <br><br><h4>  Servidor TCP e System.IO.Pipelines </h4><br>  Vamos ver como o System.IO.Pipelines funciona: <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Socket socket</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> pipe = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Pipe(); Task writing = FillPipeAsync(socket, pipe.Writer); Task reading = ReadPipeAsync(pipe.Reader); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Task.WhenAll(reading, writing); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">FillPipeAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Socket socket, PipeWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minimumBufferSize = <span class="hljs-number"><span class="hljs-number">512</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Allocate at least 512 bytes from the PipeWriter Memory&lt;byte&gt; memory = writer.GetMemory(minimumBufferSize); try { int bytesRead = await socket.ReceiveAsync(memory, SocketFlags.None); if (bytesRead == 0) { break; } // Tell the PipeWriter how much was read from the Socket writer.Advance(bytesRead); } catch (Exception ex) { LogError(ex); break; } // Make the data available to the PipeReader FlushResult result = await writer.FlushAsync(); if (result.IsCompleted) { break; } } // Tell the PipeReader that there's no more data coming writer.Complete(); } async Task ReadPipeAsync(PipeReader reader) { while (true) { ReadResult result = await reader.ReadAsync(); ReadOnlySequence&lt;byte&gt; buffer = result.Buffer; SequencePosition? position = null; do { // Look for a EOL in the buffer position = buffer.PositionOf((byte)'\n'); if (position != null) { // Process the line ProcessLine(buffer.Slice(0, position.Value)); // Skip the line + the \n character (basically position) buffer = buffer.Slice(buffer.GetPosition(1, position.Value)); } } while (position != null); // Tell the PipeReader how much of the buffer we have consumed reader.AdvanceTo(buffer.Start, buffer.End); // Stop reading if there's no more data coming if (result.IsCompleted) { break; } } // Mark the PipeReader as complete reader.Complete(); }</span></span></code> </pre> <br>  <i>veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sample5.cs</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github</a></i> <br><br>  A versão em pipeline do nosso leitor de linha possui dois loops: <br><br><ul><li>  FillPipeAsync lê do soquete e grava no PipeWriter. </li><li>  O ReadPipeAsync lê no PipeReader e analisa as linhas recebidas. </li></ul><br>  Ao contrário dos primeiros exemplos, não há buffers especialmente atribuídos.  Essa é uma das principais funções do System.IO.Pipelines.  Todas as tarefas de gerenciamento de buffer são transferidas para as implementações do PipeReader / PipeWriter. <br><br>  O procedimento é simplificado: usamos o código apenas para lógica de negócios, em vez de implementar um gerenciamento de buffer complexo. <br><br>  No primeiro loop, PipeWriter.GetMemory (int) é chamado primeiro para obter uma certa quantidade de memória do gravador principal.  Em seguida, PipeWriter.Advance (int) é chamado, o que informa ao PipeWriter quantos dados são realmente gravados no buffer.  Isso é seguido por uma chamada para PipeWriter.FlushAsync () para que PipeReader possa acessar os dados. <br><br>  O segundo loop consome os buffers que foram escritos pelo PipeWriter, mas originalmente recebidos do soquete.  Quando a solicitação para PipeReader.ReadAsync () é retornada, obtemos um ReadResult contendo duas mensagens importantes: dados lidos no formato ReadOnlySequence, bem como o tipo de dados lógicos IsCompleted, que informa ao leitor se o gravador terminou de trabalhar (EOF).  Quando o terminador de linha (EOL) for encontrado e a sequência for analisada, dividiremos o buffer em partes para pular o fragmento que já foi processado.  Depois disso, PipeReader.AdvanceTo é chamado e informa ao PipeReader quantos dados foram consumidos. <br><br>  No final de cada ciclo, o leitor e o escritor são concluídos.  Como resultado, o canal principal libera toda a memória alocada. <br><br><h2>  System.io.pipelines </h2><br><h4>  Leitura parcial </h4><br>  Além de gerenciar a memória, o System.IO.Pipelines desempenha outra função importante: verifica os dados no canal, mas não os consome. <br><br>  O PipeReader possui duas APIs principais: ReadAsync e AdvanceTo.  O ReadAsync recebe dados do canal, AdvanceTo informa ao PipeReader que esses buffers não são mais necessários pelo leitor, para que você possa se livrar deles (por exemplo, retorne-os ao buffer pool principal). <br><br>  A seguir, é apresentado um exemplo de um analisador HTTP que lê dados de buffers de dados parciais do canal até receber uma linha inicial adequada. <br><br><img src="https://habrastorage.org/webt/9c/lp/d8/9clpd8h1r6b1m1jrwultkuggw6i.png"><br><br><h2>  ReadOnlySequenceT </h2><br>  A implementação do canal armazena uma lista de buffers relacionados passados ​​entre o PipeWriter e o PipeReader.  PipeReader.ReadAsync expõe ReadOnlySequence, que é um novo tipo de BCL e consiste em um ou mais segmentos ReadOnlyMemory &lt;T&gt;.  É semelhante ao Span ou Memory, que nos dá a oportunidade de examinar matrizes e strings. <br><br><img src="https://habrastorage.org/webt/79/y0/kw/79y0kwylohggq941soblji6qd2o.png"><br><br>  Dentro do canal, existem indicadores que mostram onde o leitor e o gravador estão localizados no conjunto geral de dados destacados e também os atualizam à medida que os dados são gravados e lidos.  SequencePosition é um ponto único em uma lista vinculada de buffers e é usado para separar eficientemente ReadOnlySequence &lt;T&gt;. <br><br>  Como o ReadOnlySequence &lt;T&gt; suporta um ou mais segmentos, a operação padrão da lógica de alto desempenho é separar caminhos rápidos e lentos com base no número de segmentos. <br><br>  Como exemplo, aqui está uma função que converte ASCII ReadOnlySequence em uma cadeia de caracteres: <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">string</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetAsciiString</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">ReadOnlySequence&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt; buffer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (buffer.IsSingleSegment) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Encoding.ASCII.GetString(buffer.First.Span); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>.Create((<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)buffer.Length, buffer, (span, sequence) =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segment <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sequence) { Encoding.ASCII.GetChars(segment.Span, span); span = span.Slice(segment.Length); } }); }</code> </pre> <br>  veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sample6.cs</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github</a> <br><br><h4>  Resistência ao fluxo e controle de fluxo </h4><br>  Idealmente, a leitura e a análise trabalham juntas: o fluxo de leitura consome dados da rede e os coloca em buffers, enquanto o fluxo de análise cria estruturas de dados adequadas.  A análise geralmente leva mais tempo do que apenas copiar blocos de dados da rede.  Como resultado, o fluxo de leitura pode sobrecarregar facilmente o fluxo de análise.  Portanto, o fluxo de leitura será forçado a diminuir a velocidade ou consumir mais memória para salvar dados para o fluxo de análise.  Para garantir o desempenho ideal, é necessário um equilíbrio entre a frequência de pausa e a alocação de uma grande quantidade de memória. <br><br>  Para resolver esse problema, o pipeline possui duas funções de controle de fluxo de dados: PauseWriterThreshold e ResumeWriterThreshold.  PauseWriterThreshold determina quantos dados precisam ser armazenados em buffer antes que PipeWriter.FlushAsync seja pausado.  ResumeWriterThreshold determina quanta memória o leitor pode consumir antes do gravador retomar a operação. <br><br><img src="https://habrastorage.org/webt/qf/yj/5u/qfyj5u6aahkadlp8nk1gtc9bqr4.png"><br><br>  PipeWriter.FlushAsync "bloqueia" quando a quantidade de dados no fluxo em pipeline excede o limite definido em PauseWriterThreshold e "desbloqueia" quando cai abaixo do limite definido em ResumeWriterThreshold.  Para evitar exceder o limite de consumo, apenas dois valores são usados. <br><br><h4>  Planejamento de E / S </h4><br>  Ao usar async / waitit, as operações subseqüentes geralmente são chamadas nos threads do pool ou no SynchronizationContext atual. <br><br>  Ao executar a E / S, é muito importante monitorar cuidadosamente onde é executada, a fim de aproveitar melhor o cache do processador.  Isso é crítico para aplicativos de alto desempenho, como servidores da web.  O System.IO.Pipelines usa o PipeScheduler para determinar onde executar retornos de chamada assíncronos.  Isso permite controlar com precisão quais fluxos usar para E / S. <br><br>  Um exemplo de uma aplicação prática é o transporte Kestrel Libuv, no qual os retornos de chamada de E / S são executados em canais dedicados do loop de eventos. <br><br><h2>  Existem outros benefícios para o modelo PipeReader. </h2><br><ul><li>  Alguns sistemas básicos suportam “espera sem buffer”: você não precisa alocar um buffer até que os dados disponíveis apareçam no sistema básico.  Portanto, no Linux com epoll, você não pode fornecer um buffer de leitura até que os dados estejam prontos.  Isso evita a situação quando há muitos threads aguardando dados e você precisa reservar imediatamente uma quantidade enorme de memória. </li><li>  O pipeline padrão facilita a gravação de testes de unidade de código de rede: a lógica de análise é separada do código de rede, e os testes de unidade executam essa lógica apenas em buffers na memória, em vez de consumi-la diretamente da rede.  Também facilita o teste de padrões complexos enviando dados parciais.  O ASP.NET Core o utiliza para testar vários aspectos das ferramentas de análise http do Kestrel. </li><li>  Os sistemas que permitem que o código do usuário use os principais buffers do SO (por exemplo, APIs de E / S do Windows registradas) são inicialmente adequados para o uso de pipelines porque a implementação do PipeReader sempre fornece buffers. </li></ul><br><h4>  Outros tipos relacionados </h4><br>  Também adicionamos vários novos tipos simples de BCL ao System.IO.Pipelines: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MemoryPoolT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">IMemoryOwnerT</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MemoryManagerT</a> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ArrayPoolT</a> foi adicionado no .NET Core 1.0 e, no .NET Core 2.1, agora existe uma representação abstrata mais geral para um pool que funciona com qualquer MemoryT.  Obtemos um ponto de extensibilidade que nos permite implementar estratégias de distribuição mais avançadas, bem como controlar o gerenciamento de buffer (por exemplo, use buffers predefinidos em vez de matrizes gerenciadas exclusivamente). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">IBufferWriterT</a> é um receptor para registrar dados em buffer sincronizados (implementados pelo PipeWriter). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">IValueTaskSource</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ValueTaskT</a> existe desde o lançamento do .NET Core 1.1, mas no .NET Core 2.1 ele adquiriu ferramentas extremamente eficazes que fornecem operações assíncronas ininterruptas sem distribuição.  Veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui para</a> mais informações. </li></ul><br><h2>  Como usar transportadores? </h2><br>  As APIs estão no pacote de nuget <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">System.IO.Pipelines</a> . <br><br>  Para um exemplo de aplicativo de servidor .NET Server 2.1 que usa pipelines para processar mensagens em minúsculas (do exemplo acima), consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  Pode ser iniciado usando o dotnet run (ou Visual Studio).  No exemplo, espera-se que os dados sejam transmitidos do soquete na porta 8087 e, em seguida, as mensagens recebidas serão gravadas no console.  Você pode usar um cliente, como netcat ou putty, para conectar-se à porta 8087.  Envie uma mensagem em minúscula e veja como ela funciona. <br><br>  Atualmente, o pipeline é executado no Kestrel e no SignalR, e esperamos que ele encontre aplicativos mais amplos em muitas bibliotecas de rede e componentes da comunidade .NET no futuro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt423105/">https://habr.com/ru/post/pt423105/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt423093/index.html">Aumentamos a aleatoriedade do fato de que [provavelmente] [quase] por acidente</a></li>
<li><a href="../pt423095/index.html">Novidades da apresentação da Apple</a></li>
<li><a href="../pt423097/index.html">Tarefas e soluções para o lutador PostgreSQL</a></li>
<li><a href="../pt423101/index.html">Implantando o armazenamento LINSTOR para Proxmox</a></li>
<li><a href="../pt423103/index.html">Podcasts em Python: foi tudo o que descobrimos</a></li>
<li><a href="../pt423107/index.html">Convidamos você para a reunião Go in Production</a></li>
<li><a href="../pt423109/index.html">O que a Apple apresentou e o que os desenvolvedores do iOS pensam sobre isso</a></li>
<li><a href="../pt423115/index.html">Efeitos aprimorados com o modo de mesclagem da camada de segundo plano CSS</a></li>
<li><a href="../pt423117/index.html">Viver mais ou envelhecer mais devagar: uma abordagem tecnológica para a velhice</a></li>
<li><a href="../pt423119/index.html">DIY TTL arcade machine ... em 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
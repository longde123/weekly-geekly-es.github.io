<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïç üñåÔ∏è üíù Arquitetura de rede neural üê´ üë®üèª‚Äçüéì üà¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tradu√ß√£o de arquiteturas de redes neurais 

 Atualmente, os algoritmos de redes neurais profundas ganharam grande popularidade, o que √© amplamente gar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Arquitetura de rede neural</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/430524/">  <i>Tradu√ß√£o de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arquiteturas de redes neurais</a></i> <br><br>  Atualmente, os algoritmos de redes neurais profundas ganharam grande popularidade, o que √© amplamente garantido pela arquitetura bem pensada.  Vamos dar uma olhada na hist√≥ria de seu desenvolvimento nos √∫ltimos anos.  Se voc√™ estiver interessado em uma an√°lise mais profunda, consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este trabalho</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/29b/f51/960/29bf5196085373528be31e27f2489bdd.jpg"><br>  <i>Compara√ß√£o de arquiteturas populares para a melhor precis√£o de uma colheita e o n√∫mero de opera√ß√µes necess√°rias para uma passagem direta.</i>  <i>Mais detalhes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .</i> <br><a name="habracut"></a><br><h3>  Lenet5 </h3><br>  Em 1994, uma das primeiras redes neurais convolucionais foi desenvolvida, que lan√ßou as bases para o aprendizado profundo.  Este trabalho pioneiro de Yann LeCun, ap√≥s muitas itera√ß√µes bem-sucedidas desde 1988, foi chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LeNet5</a> ! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b19/9c3/8f2/b199c38f21a72c44d7cd3afbca1c94eb.jpg"><br><br>  A arquitetura LeNet5 tornou-se fundamental para o aprendizado profundo, especialmente em termos da distribui√ß√£o das propriedades da imagem por toda a imagem.  Convolu√ß√µes com par√¢metros de aprendizado permitiram o uso de v√°rios par√¢metros para extrair eficientemente as mesmas propriedades de lugares diferentes.  Naqueles anos, n√£o havia placas de v√≠deo que pudessem acelerar o processo de aprendizado, e at√© os processadores centrais eram lentos.  Portanto, a principal vantagem da arquitetura era a capacidade de salvar par√¢metros e resultados de c√°lculos, em contraste com o uso de cada pixel como dados de entrada separados para uma grande rede neural multicamada.  No LeNet5, os pixels n√£o s√£o usados ‚Äã‚Äãna primeira camada, porque as imagens s√£o fortemente correlacionadas espacialmente, portanto, o uso de pixels individuais como propriedades de entrada n√£o permitir√° que voc√™ aproveite essas correla√ß√µes. <br><br>  Recursos do LeNet5: <br><br><ul><li>  Uma rede neural convolucional usando uma sequ√™ncia de tr√™s camadas: camadas de convolu√ß√£o, camadas de pool e camadas de n√£o linearidade -&gt; desde a publica√ß√£o do trabalho de Lekun, essa talvez seja uma das principais caracter√≠sticas do aprendizado profundo em rela√ß√£o √†s imagens. </li><li>  Usa convolu√ß√£o para recuperar propriedades espaciais. </li><li>  Subamostragem usando a m√©dia do mapa espacial. </li><li>  N√£o linearidade na forma de tangente hiperb√≥lica ou sigm√≥ide. </li><li>  O classificador final na forma de uma rede neural multicamada (MLP). </li><li>  A matriz esparsa de conectividade entre as camadas reduz a quantidade de computa√ß√£o. </li></ul><br>  Essa rede neural formou a base de muitas arquiteturas subseq√ºentes e inspirou muitos pesquisadores. <br><br><h3>  Desenvolvimento </h3><br>  De 1998 a 2010, as redes neurais estavam em estado de incuba√ß√£o.  A maioria das pessoas n√£o percebeu suas capacidades crescentes, embora muitos desenvolvedores aprimorassem gradualmente seus algoritmos.  Gra√ßas ao auge das c√¢meras de celular e ao baixo custo das c√¢meras digitais, mais e mais dados de treinamento se tornaram dispon√≠veis para n√≥s.  Ao mesmo tempo, os recursos de computa√ß√£o aumentaram, os processadores se tornaram mais poderosos e as placas de v√≠deo se tornaram a principal ferramenta de computa√ß√£o.  Todos esses processos permitiram o desenvolvimento de redes neurais, embora de maneira bastante lenta.  O interesse em tarefas que poderiam ser resolvidas com a ajuda de redes neurais estava crescendo e, finalmente, a situa√ß√£o se tornou √≥bvia ... <br><br><h3>  Dan ciresan net </h3><br>  Em 2010, Dan Claudiu Ciresan e Jurgen Schmidhuber publicaram uma das primeiras descri√ß√µes da implementa√ß√£o de <a href="">redes neurais</a> da <a href="">GPU</a> .  O trabalho deles continha a implementa√ß√£o direta e reversa de uma rede neural de 9 camadas na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NVIDIA GTX 280</a> . <br><br><h3>  Alexnet </h3><br>  Em 2012, Alexei Krizhevsky publicou o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AlexNet</a> , uma vers√£o detalhada e ampliada do LeNet, que venceu por uma ampla margem no concurso ImageNet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aad/4ad/3ca/aad4ad3ca7345f8d7e198c2b131298d1.png"><br><br>  Na AlexNet, os resultados dos c√°lculos do LeNet s√£o redimensionados em uma rede neural muito maior, capaz de estudar objetos muito mais complexos e suas hierarquias.  Recursos desta solu√ß√£o: <br><br><ul><li>  Uso de unidades de retifica√ß√£o linear (ReLU) como n√£o linearidades. </li><li>  O uso de t√©cnicas de descarte para ignorar seletivamente neur√¥nios individuais durante o treinamento, o que evita o excesso de treinamento do modelo. </li><li>  Sobreposi√ß√£o de pool m√°ximo, que evita os efeitos da m√©dia de pool m√©dio. </li><li>  Usando o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NVIDIA GTX 580</a> para acelerar o aprendizado. </li></ul><br>  Naquela √©poca, o n√∫mero de n√∫cleos nas placas de v√≠deo havia crescido significativamente, o que lhes permitiu reduzir o tempo de treinamento em cerca de 10 vezes e, como resultado, tornou-se poss√≠vel usar conjuntos de dados e imagens muito maiores. <br><br>  O sucesso da AlexNet lan√ßou uma pequena revolu√ß√£o: redes neurais convolucionais se transformaram em um cavalo de batalha de aprendizado profundo - este termo agora significa "grandes redes neurais que podem resolver problemas √∫teis". <br><br><h3>  Overfeat </h3><br>  Em dezembro de 2013, o laborat√≥rio da NYU de Jan Lekun publicou uma descri√ß√£o do <a href="">Overfeat</a> , uma variante do AlexNet.  Al√©m disso, o artigo descreveu as caixas delimitadoras treinadas e, posteriormente, muitos outros trabalhos sobre esse t√≥pico foram publicados.  Acreditamos que √© melhor aprender a segmentar objetos, em vez de usar caixas delimitadoras artificiais. <br><br><h3>  Vgg </h3><br>  Nas redes <a href="">VGG</a> desenvolvidas em Oxford, em cada camada convolucional, pela primeira vez, foram utilizados filtros 3x3, e mesmo essas camadas foram combinadas em uma sequ√™ncia de convolu√ß√µes. <br><br>  Isso contradiz os princ√≠pios estabelecidos no LeNet, segundo os quais grandes convolu√ß√µes foram usadas para extrair as mesmas propriedades de imagem.  Em vez dos filtros 9x9 e 11x11 usados ‚Äã‚Äãno AlexNet, come√ßaram a ser usados ‚Äã‚Äãfiltros muito menores, perigosamente pr√≥ximos √†s convolu√ß√µes 1x1, que os autores da LeNet tentaram evitar, pelo menos nas primeiras camadas da rede.  Mas a grande vantagem do VGG foi a descoberta de que v√°rias convolu√ß√µes 3x3 combinadas em uma sequ√™ncia podem emular campos receptivos maiores, por exemplo, 5x5 ou 7x7.  Essas id√©ias ser√£o usadas posteriormente nas arquiteturas Inception e ResNet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dec/e8b/308/dece8b308f74450222deece6fcf9d357.jpg"><br><br>  As redes VGG usam v√°rias camadas convolucionais 3x3 para representar propriedades complexas.  Preste aten√ß√£o aos blocos 3, 4 e 5 no VGG-E: para extrair propriedades mais complexas e combin√°-las, s√£o usadas seq√º√™ncias de filtro 256 √ó 256 e 512 √ó 512 3 √ó 3.  Isso √© equivalente a um classificador convolucional grande de 512x512 com tr√™s camadas!  Isso nos d√° um grande n√∫mero de par√¢metros e excelentes habilidades de aprendizado.  Mas foi dif√≠cil aprender essas redes; tive que dividi-las em redes menores, adicionando camadas uma a uma.  O motivo foi a falta de maneiras eficazes de regularizar modelos ou de alguns m√©todos para limitar um grande espa√ßo de pesquisa, promovido por muitos par√¢metros. <br><br>  O VGG em muitas camadas usa um grande n√∫mero de propriedades, portanto, o treinamento era <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">computacionalmente caro</a> .  A carga pode ser reduzida reduzindo o n√∫mero de propriedades, como √© feito nas camadas de gargalo da arquitetura Inception. <br><br><h3>  Rede em rede </h3><br>  A arquitetura <a href="">Rede em rede</a> (NiN) √© baseada em uma id√©ia simples: usando convolu√ß√µes 1x1 para aumentar a combinat√≥ria de propriedades em camadas convolucionais. <br><br>  No NiN, ap√≥s cada convolu√ß√£o, as camadas espaciais de MLP s√£o usadas para combinar melhor as propriedades antes de passar para a pr√≥xima camada.  Pode parecer que o uso de convolu√ß√µes 1x1 contradiga os princ√≠pios originais do LeNet, mas, na realidade, permite combinar propriedades melhor do que apenas encher camadas mais convolucionais.  Essa abordagem √© diferente de usar pixels nus como entrada para a pr√≥xima camada.  Nesse caso, convolu√ß√µes 1x1 s√£o usadas para combina√ß√£o espacial de propriedades ap√≥s a convolu√ß√£o na estrutura dos mapas de propriedades, para que voc√™ possa usar muito menos par√¢metros comuns a todos os pixels dessas propriedades! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d9a/d08/e5c/d9ad08e5c699a2a9cf320c4b8b622ba3.jpg"><br><br>  O MLP pode aumentar bastante a efic√°cia das camadas convolucionais individuais, combinando-as em grupos mais complexos.  Essa ideia foi usada posteriormente em outras arquiteturas, como ResNet, Inception e suas variantes. <br><br><h3>  GoogLeNet e Inicia√ß√£o </h3><br>  O Google Christian Szegedy est√° preocupado com a redu√ß√£o de c√°lculos em redes neurais profundas e, como resultado, criou o <a href="">GoogLeNet, a primeira arquitetura de Inicia√ß√£o</a> . <br><br>  No outono de 2014, os modelos de aprendizado profundo tornaram-se muito √∫teis na categoriza√ß√£o do conte√∫do da imagem e dos quadros dos v√≠deos.  Muitos c√©ticos reconheceram os benef√≠cios do aprendizado profundo e das redes neurais, e os gigantes da Internet, incluindo o Google, ficaram muito interessados ‚Äã‚Äãem implantar redes grandes e eficientes nas capacidades de seus servidores. <br><br>  Christian estava procurando maneiras de reduzir a carga computacional nas redes neurais, alcan√ßando o desempenho mais alto (por exemplo, no ImageNet).  Ou preservando a quantidade de computa√ß√£o, mas ainda aumentando a produtividade. <br><br>  Como resultado, o comando criou um m√≥dulo de Inicia√ß√£o: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/abf/d01/a92/abfd01a92262ff6e5b9f23380ba8d9cc.jpg"><br><br>  √Ä primeira vista, essa √© uma combina√ß√£o paralela de filtros convolucionais 1x1, 3x3 e 5x5.  Mas o destaque foi o uso dos blocos de convolu√ß√£o 1x1 (NiN) para reduzir o n√∫mero de propriedades antes de servir nos blocos paralelos "caros".  Geralmente, essa parte √© chamada de gargalo, √© descrita em mais detalhes no pr√≥ximo cap√≠tulo. <br><br>  O GoogLeNet usa uma haste sem m√≥dulos de inicia√ß√£o como a camada inicial e tamb√©m usa pool m√©dio e um classificador softmax semelhante ao NiN.  Este classificador executa muito poucas opera√ß√µes em compara√ß√£o com AlexNet e VGG.  Tamb√©m ajudou a criar uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arquitetura de rede neural muito eficiente</a> . <br><br><h3>  Camada de gargalo </h3><br>  Essa camada reduz o n√∫mero de propriedades (e, portanto, opera√ß√µes) em cada camada, para que a velocidade de obten√ß√£o do resultado possa ser mantida em um n√≠vel alto.  Antes de transferir dados para m√≥dulos convolucionais "caros", o n√∫mero de propriedades √© reduzido, digamos, 4 vezes.  Isso reduz bastante a quantidade de computa√ß√£o, o que tornou a arquitetura popular. <br><br>  Vamos descobrir.  Suponha que tenhamos 256 propriedades na entrada e 256 na sa√≠da e permita que a camada de Inicia√ß√£o execute apenas convolu√ß√µes 3x3.  Temos convolu√ß√µes 256x256x3x3 (589.000 opera√ß√µes de multiplica√ß√£o de acumula√ß√£o, ou seja, opera√ß√µes MAC).  Isso pode ir al√©m de nossos requisitos de velocidade computacional; digamos que uma camada seja processada em 0,5 milissegundos no Google Server.  Em seguida, reduza o n√∫mero de propriedades para dobrar para 64 (256/4).  Nesse caso, primeiro executamos uma convolu√ß√£o 1x1 de 256 -&gt; 64, depois outra convolu√ß√£o 64 em todas as ramifica√ß√µes do Inception e, em seguida, novamente aplicamos uma convolu√ß√£o 1x1 de 64 -&gt; 256 propriedades.  N√∫mero de opera√ß√µes: <br><br><ul><li>  256 √ó 64 √ó 1 √ó 1 = 16.000 </li><li>  64 √ó 64 √ó 3 √ó 3 = 36.000 </li><li>  64 √ó 256 √ó 1 √ó 1 = 16.000 </li></ul><br>  Apenas cerca de 70.000 reduziram o n√∫mero de opera√ß√µes em quase 10 vezes!  Mas, ao mesmo tempo, n√£o perdemos a generaliza√ß√£o nessa camada.  As camadas de gargalo mostraram excelente desempenho no conjunto de dados do ImageNet e foram usadas em arquiteturas posteriores, como o ResNet.  A raz√£o do sucesso deles √© que as propriedades de entrada est√£o correlacionadas, o que significa que voc√™ pode se livrar da redund√¢ncia combinando corretamente as propriedades com as convolu√ß√µes 1x1.  E depois de dobrar com menos propriedades, voc√™ poder√° implant√°-las novamente em uma combina√ß√£o significativa na pr√≥xima camada. <br><br><h3>  Inicia√ß√£o V3 (e V2) </h3><br>  Christian e sua equipe provaram ser pesquisadores muito eficazes.  Em fevereiro de 2015, a arquitetura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Inception normalizada em lote</a> foi introduzida como a segunda vers√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Inception</a> .  A normaliza√ß√£o em lote calcula a m√©dia e o desvio padr√£o de todos os mapas de distribui√ß√£o de propriedades na camada de sa√≠da e normaliza suas respostas com esses valores.  Isso corresponde ao "branqueamento" dos dados, ou seja, as respostas de todos os mapas neurais est√£o no mesmo intervalo e com m√©dia zero.  Essa abordagem facilita o aprendizado, porque a pr√≥xima camada n√£o √© necess√°ria para lembrar as compensa√ß√µes dos dados de entrada e pode procurar apenas as melhores combina√ß√µes de propriedades. <br><br>  Em dezembro de 2015, uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nova vers√£o dos m√≥dulos Inception e a arquitetura correspondente foram lan√ßadas</a> .  O artigo do autor explica melhor a arquitetura original do GoogLeNet, que conta muito mais sobre as decis√µes tomadas.  Ideias-chave: <br><br><ul><li>  Maximizar o fluxo de informa√ß√µes na rede devido ao cuidadoso equil√≠brio entre sua profundidade e largura.  Antes de cada pool, os mapas de propriedades aumentam. </li><li>  Com o aumento da profundidade, o n√∫mero de propriedades ou a largura da camada tamb√©m aumenta sistematicamente. </li><li>  A largura de cada camada aumenta para aumentar a combina√ß√£o de propriedades antes da pr√≥xima camada. </li><li>  Na medida do poss√≠vel, apenas convolu√ß√µes 3x3 s√£o usadas.  Dado que os filtros 5x5 e 7x7 podem ser decompostos usando m√∫ltiplos 3x3 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/849/96f/d8c/84996fd8cb1040fbf0a18187313a8a81.jpg"><br><br>  O novo m√≥dulo de inicia√ß√£o √© assim: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/975/b0b/ad7/975b0bad7d65a0b37aedf0dc119d03b8.jpg"></li><li>  Os filtros tamb√©m podem ser decompostos usando <a href="">convolu√ß√µes suavizadas</a> em m√≥dulos mais complexos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb5/c32/21c/bb5c3221cc8f478de3ac5ef504a13357.jpg"></li><li>  Os m√≥dulos de inicia√ß√£o podem reduzir o tamanho dos dados usando o pool durante os c√°lculos de inicia√ß√£o.  √â semelhante a realizar convolu√ß√£o com passos paralelos a uma camada de pool simples: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8b/4c1/263/f8b4c1263b3883d751c7dfe3788110ca.jpg"></li></ul><br>  O in√≠cio usa a camada de pool com softmax como classificador final. <br><br><h3>  Resnet </h3><br>  Em dezembro de 2015, aproximadamente ao mesmo tempo em que a arquitetura Inception v3 foi introduzida, ocorreu uma revolu√ß√£o - eles publicaram a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ResNet</a> .  Ele cont√©m id√©ias simples: envie a sa√≠da de duas camadas convolucionais bem-sucedidas e ignore a entrada da pr√≥xima camada! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b8a/05d/8b8/b8a05d8b89f55e8d06bb2eae79bd648b.jpg"><br><br>  Tais id√©ias j√° foram propostas, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  Mas, neste caso, os autores ignoram DUAS camadas e aplicam a abordagem em larga escala.  Ignorar uma camada n√£o oferece muitos benef√≠cios e ignorar duas √© uma descoberta fundamental.  Isso pode ser visto como um pequeno classificador, como rede em rede! <br><br>  Foi tamb√©m o primeiro exemplo de treinamento de uma rede de v√°rias centenas, at√© milhares de camadas. <br>  O MulNet ResNet usou uma camada de gargalo semelhante √† usada no Inception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0d0/ecf/124/0d0ecf1248874511ae4dbca5f23afcec.jpg"><br><br>  Essa camada reduz o n√∫mero de propriedades em cada camada, primeiro usando uma convolu√ß√£o 1x1 com uma sa√≠da menor (geralmente um quarto da entrada), depois uma camada 3x3 e, novamente, convertendo 1x1 em um n√∫mero maior de propriedades.  Como no caso dos m√≥dulos Inception, isso economiza recursos computacionais enquanto mant√©m uma variedade de combina√ß√µes de propriedades.  Compare com os caules mais complexos e menos √≥bvios no Inception V3 e V4. <br><br>  O ResNet usa uma camada de pool com softmax como classificador final. <br>  Todos os dias, informa√ß√µes adicionais sobre a arquitetura ResNet s√£o exibidas: <br><br><ul><li>  Pode ser considerado como um sistema de m√≥dulos paralelos e seriais simultaneamente: em muitos m√≥dulos o sinal de entrada √© paralelo e os sinais de sa√≠da de cada m√≥dulo s√£o conectados em s√©rie. </li><li>  O ResNet pode ser considerado como v√°rios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjuntos de m√≥dulos paralelos ou seriais</a> . </li><li>  Descobriu-se que o ResNet geralmente opera com blocos de profundidade relativamente pequenos de 20 a 30 camadas trabalhando em paralelo, em vez de executar seq√ºencialmente ao longo de todo o comprimento da rede. </li><li>  Como o sinal de sa√≠da volta e √© alimentado como entrada, como √© feito na RNN, o ResNet pode ser considerado um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelo plaus√≠vel</a> aprimorado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do c√≥rtex cerebral</a> . </li></ul><br><h3>  In√≠cio V4 </h3><br>  Christian e sua equipe se destacaram novamente com uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nova vers√£o do Inception</a> . <br><br>  O m√≥dulo de cria√ß√£o a seguir √© o mesmo que no Inception V3: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/955/f38/48b955f385c72d21a20af8517d941580.jpg"><br><br>  Nesse caso, o m√≥dulo Inception √© combinado com o m√≥dulo ResNet: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f4c/5f2/bd7/f4c5f2bd765082fe56dac5710fc30221.jpg"><br><br>  Essa arquitetura acabou sendo, para mim, mais complicada, menos elegante e tamb√©m cheia de solu√ß√µes heur√≠sticas opacas.  √â dif√≠cil entender por que os autores tomaram essas ou aquelas decis√µes e √© igualmente dif√≠cil fazer qualquer tipo de avalia√ß√£o. <br><br>  Portanto, o pr√™mio por uma rede neural limpa e simples, f√°cil de entender e modificar, vai para o ResNet. <br><br><h3>  Squeezenet </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SqueezeNet</a> publicado recentemente.  Este √© um remake de uma nova maneira de muitos conceitos do ResNet e do Inception.  Os autores demonstraram que melhorar a arquitetura reduz o tamanho da rede e o n√∫mero de par√¢metros sem algoritmos de compacta√ß√£o complexos. <br><br><h3>  ENet </h3><br>  Todos os recursos das arquiteturas recentes s√£o combinados em uma rede muito eficiente e compacta, usando muito poucos par√¢metros e poder de computa√ß√£o, mas, ao mesmo tempo, oferecendo excelentes resultados.  A arquitetura foi chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ENet</a> , foi desenvolvida por Adam Paszke ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Adam Paszke</a> ).  Por exemplo, n√≥s o usamos para marcar objetos de maneira muito precisa na tela e analisar cenas.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Alguns exemplos de Enet</a> .  Esses v√≠deos n√£o est√£o relacionados ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados de treinamento</a> . <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui</a> voc√™ pode encontrar os detalhes t√©cnicos da ENet.  √â uma rede baseada em codificador e decodificador.  O codificador √© constru√≠do no esquema usual de categoriza√ß√£o da CNN e o decodificador √© uma rede de upsampling projetada para segmenta√ß√£o, espalhando as categorias de volta √† imagem em tamanho original.  Para a segmenta√ß√£o de imagens, foram utilizadas apenas redes neurais, sem outros algoritmos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/c54/7fa/18dc547fade22215961a848b2170b104.png"><br><br>  Como voc√™ pode ver, o ENet tem a maior precis√£o espec√≠fica em compara√ß√£o com todas as outras redes neurais. <br><br>  O ENet foi projetado para usar o m√≠nimo de recursos poss√≠vel desde o in√≠cio.  Como resultado, o codificador e o decodificador juntos ocupam apenas 0,7 MB com precis√£o fp16.  E com um tamanho t√£o pequeno, o ENet n√£o √© inferior √† precis√£o da segmenta√ß√£o ou superior a outras solu√ß√µes de rede puramente neurais. <br><br><h3>  An√°lise de m√≥dulo </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Publicou uma</a> avalia√ß√£o sistem√°tica dos m√≥dulos da CNN.  Acabou sendo ben√©fico: <br><br><ul><li>  Use a n√£o linearidade da ELU sem normaliza√ß√£o do lote (batchnorm) ou ReLU com normaliza√ß√£o. </li><li>  Aplique a transforma√ß√£o aprendida do espa√ßo de cores RGB. </li><li>  Use uma pol√≠tica de redu√ß√£o linear da taxa de aprendizado. </li><li>  Use a soma da camada m√©dia e m√°xima do pool. </li><li>  Use um mini-pacote de 128 ou 256. Se isso for demais para sua placa de v√≠deo, reduza a velocidade de aprendizado proporcionalmente ao tamanho do pacote. </li><li>  Use camadas totalmente conectadas como camadas convolucionais e previs√µes m√©dias para fornecer a solu√ß√£o final. </li><li>  Se voc√™ aumentar o tamanho do conjunto de dados de treinamento, verifique se voc√™ n√£o atingiu um plat√¥ no treinamento.  A limpeza dos dados √© mais importante que o tamanho. </li><li>  Se voc√™ n√£o puder aumentar o tamanho da imagem de entrada, reduzir o passo nas camadas subseq√ºentes, o efeito ser√° aproximadamente o mesmo. </li><li>  Se sua rede possui uma arquitetura complexa e altamente otimizada, como no GoogLeNet, modifique-a com cuidado. </li></ul><br><h3>  Xception </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A Xception</a> introduziu uma arquitetura mais simples e elegante no m√≥dulo Inception, que n√£o √© menos eficiente que o ResNet e o Inception V4. <br>  √â assim que o m√≥dulo Xception se parece: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/632/40a/deb/63240adebe962726f6d035b5a5d16099.jpg"><br><br>  Qualquer pessoa gostar√° desta rede devido √† simplicidade e eleg√¢ncia de sua arquitetura: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d64/f09/933/d64f099330f0b9290a99202a50863868.jpg"><br><br>  Ele cont√©m 36 etapas de convolu√ß√£o e √© semelhante ao ResNet-34.  Ao mesmo tempo, o modelo e o c√≥digo s√£o simples, como no ResNet, e muito mais agrad√°veis ‚Äã‚Äãdo que no Inception V4. <br><br>  Uma implementa√ß√£o torch7 dessa rede est√° dispon√≠vel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , enquanto uma implementa√ß√£o Keras / TF est√° dispon√≠vel aqui. <br><br>  Curiosamente, os autores da recente arquitetura Xception tamb√©m foram inspirados pelo <a href="">nosso trabalho em filtros convolucionais separ√°veis</a> . <br><br><h3>  MobileNets </h3><br>  A nova arquitetura do M <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">obileNets</a> foi lan√ßada em abril de 2017.  Para reduzir o n√∫mero de par√¢metros, ele usa convolu√ß√µes destac√°veis, o mesmo que no Xception.  Tamb√©m √© afirmado no trabalho que os autores foram capazes de reduzir bastante o n√∫mero de par√¢metros: cerca de metade no caso do FaceNet.   : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/689/04b/c1e/68904bc1e353888d4fcd54975a064362.jpg"><br><br>         ,         1 (batch of 1)   Titan Xp.      : <br><br><ul><li> resnet18: 0,002871 </li><li> alexnet: 0,001003 </li><li> vgg16: 0,001698 </li><li> squeezenet: 0,002725 </li><li> mobilenet: 0,033251 </li></ul><br>     !        ,     . <br><br><h3>    </h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FractalNet</a>   ,      ImageNet        ResNet. <br><br><h3>  </h3><br>  ,           .         ,  . <br><br>   ,         ,       ,   ,       ?  ,       . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>    . <br>  ,        .      ,         . <br><br>         , . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt430524/">https://habr.com/ru/post/pt430524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt430512/index.html">Como vivem os freelancers: n√£o trabalhe com clientes oniscientes e permita-se procrastinar</a></li>
<li><a href="../pt430514/index.html">Caridade Blockchain - DataArt vence a Hackathon Summit de Blockchain de Malta</a></li>
<li><a href="../pt430518/index.html">Como renderizar o quadro da Terra M√©dia: Sombra de Mordor</a></li>
<li><a href="../pt430520/index.html">Apresentando o Spring Data MongoDB</a></li>
<li><a href="../pt430522/index.html">Voc√™ precisa de uma cultura corporativa em TI? Confiss√£o do gerente de marca do est√∫dio Krasnodar Plarium</a></li>
<li><a href="../pt430526/index.html">M√°quinas ca√ßa-n√≠queis: de onde eles vieram na URSS e como est√£o organizados</a></li>
<li><a href="../pt430528/index.html">Programando com PyUSB 1.0</a></li>
<li><a href="../pt430530/index.html">Servidor simulado para automa√ß√£o de teste m√≥vel</a></li>
<li><a href="../pt430532/index.html">Seguran√ßa em aplicativos iOS</a></li>
<li><a href="../pt430534/index.html">Criando um modelo para o Zabbix usando o DVR Trassir SDK como exemplo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
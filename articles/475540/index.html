<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï• üåÖ ü•™ Tenga cuidado con las vulnerabilidades que traen soluciones alternativas. Parte 1: FragmentSmack / SegmentSmack üì´ üç≤ üßëüèæ‚Äçü§ù‚Äçüßëüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! Mi nombre es Dmitry Samsonov, trabajo como administrador l√≠der del sistema en Odnoklassniki. Tenemos m√°s de 7 mil servidores f√≠sicos, 11...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tenga cuidado con las vulnerabilidades que traen soluciones alternativas. Parte 1: FragmentSmack / SegmentSmack</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/475540/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/kc/qy/tg/kcqytg4znoagvdqffwtwxhwzcjs.jpeg"></div><br><br>  Hola a todos!  Mi nombre es Dmitry Samsonov, trabajo como administrador l√≠der del sistema en Odnoklassniki.  Tenemos m√°s de 7 mil servidores f√≠sicos, 11 mil contenedores en nuestra nube y 200 aplicaciones, que en diferentes configuraciones forman 700 cl√∫steres diferentes.  La gran mayor√≠a de los servidores ejecuta CentOS 7. <br>  Informaci√≥n de vulnerabilidad de FragmentSmack lanzada el 14 de agosto de 2018 <br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CVE-2018-5391</a> ) y SegmentSmack ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CVE-2018-5390</a> ).  Estas son vulnerabilidades con un vector de ataque de red y una calificaci√≥n bastante alta (7.5), que amenaza con la denegaci√≥n de servicio (DoS) debido al agotamiento de recursos (CPU).  En ese momento no se propuso una soluci√≥n en el kernel para FragmentSmack, adem√°s, sali√≥ mucho m√°s tarde que la publicaci√≥n de informaci√≥n sobre la vulnerabilidad.  Para eliminar SegmentSmack, se propuso actualizar el kernel.  El paquete de actualizaci√≥n en s√≠ se lanz√≥ el mismo d√≠a, todo lo que quedaba era instalarlo. <br>  No, no estamos en absoluto en contra de la actualizaci√≥n del kernel.  Sin embargo, hay matices ... <br><a name="habracut"></a><br><h4>  ¬øC√≥mo actualizamos el n√∫cleo en el producto? </h4><br>  En general, nada complicado: <br><ol><li>  Descargar paquetes </li><li>  Inst√°lelos en varios servidores (incluidos los servidores que alojan nuestra nube); </li><li>  Aseg√∫rate de que nada est√© roto; </li><li>  Aseg√∫rese de que todas las configuraciones est√°ndar del n√∫cleo se apliquen sin errores; </li><li>  Espera unos d√≠as; </li><li>  Verificar el rendimiento del servidor; </li><li>  Cambie la implementaci√≥n de nuevos servidores a un nuevo kernel; </li><li>  Actualizar todos los servidores por centros de datos (un centro de datos a la vez para minimizar el efecto para los usuarios en caso de problemas); </li><li>  Reinicia todos los servidores. </li></ol><br>  Repita para todas las ramas de los n√∫cleos que tenemos.  Por el momento esto es: <br><br><ul><li>  Stock CentOS 7 3.10 - para la mayor√≠a de los servidores comunes; </li><li>  Vanilla 4.19 es para nuestra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nube √∫nica</a> porque necesitamos BFQ, BBR, etc. </li><li>  Elrepo kernel-ml 5.2 es para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">distribuidores altamente cargados</a> , porque 4.19 sol√≠a comportarse de manera inestable y las caracter√≠sticas necesitan las mismas. </li></ul><br>  Como habr√°s adivinado, reiniciar miles de servidores lleva m√°s tiempo.  Como no todas las vulnerabilidades son cr√≠ticas para todos los servidores, solo reiniciamos aquellas a las que se puede acceder directamente desde Internet.  En la nube, para no limitar la flexibilidad, no vinculamos contenedores accesibles externamente a servidores individuales con un nuevo n√∫cleo, sino que reiniciamos todos los hosts sin excepci√≥n.  Afortunadamente, el procedimiento es m√°s f√°cil all√≠ que con los servidores normales.  Por ejemplo, los contenedores sin estado pueden simplemente moverse a otro servidor durante el reinicio. <br><br>  Sin embargo, todav√≠a hay mucho trabajo y puede llevar varias semanas, y en caso de problemas con la nueva versi√≥n, hasta varios meses.  Los atacantes son conscientes de esto, por lo que se necesita el plan B. <br><br><h4>  FragmentSmack / SegmentSmack.  Soluci√≥n alternativa </h4><br>  Afortunadamente, para algunas vulnerabilidades, dicho plan "B" existe, y se llama soluci√≥n alternativa.  Muy a menudo, este es un cambio en la configuraci√≥n del kernel / aplicaci√≥n, que puede minimizar el posible efecto o eliminar por completo la explotaci√≥n de vulnerabilidades. <br><br>  En el caso de FragmentSmack / SegmentSmack <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> se propuso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la</a> siguiente soluci√≥n: <br><br><blockquote>  " <i>Puede cambiar los valores predeterminados de 4MB y 3MB en net.ipv4.ipfrag_high_thresh y net.ipv4.ipfrag_low_thresh (y sus an√°logos para ipv6 net.ipv6.ipfrag_high_thresh y net.ipv6.ipfrag_low_thresh) en 256 kB y 192 kB, respectivamente.</i>  <i>Las pruebas muestran una ca√≠da de leve a significativa en el uso de la CPU durante un ataque, dependiendo del equipo, la configuraci√≥n y las condiciones.</i>  <i>Sin embargo, puede haber alg√∫n impacto en el rendimiento debido a ipfrag_high_thresh = 262144 bytes, ya que solo dos fragmentos de 64K pueden caber en la cola de reconstrucci√≥n a la vez.</i>  <i>Por ejemplo, existe el riesgo de que las aplicaciones que funcionan con paquetes UDP grandes se rompan</i> ‚Äù. </blockquote><br>  Los par√°metros <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en</a> s√≠ mismos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en la documentaci√≥n del n√∫cleo se</a> describen a continuaci√≥n: <br><br><blockquote><code>ipfrag_high_thresh - LONG INTEGER <br> Maximum memory used to reassemble IP fragments.</code> </blockquote> <br><p></p><blockquote> <code>ipfrag_low_thresh - LONG INTEGER <br> Maximum memory used to reassemble IP fragments before the kernel <br> begins to remove incomplete fragment queues to free up resources. <br> The kernel still accepts new fragments for defragmentation.</code> </blockquote> <br>  No tenemos grandes UDP en los servicios de producci√≥n.  No hay tr√°fico fragmentado en la LAN; hay tr√°fico, pero no significativo, en la WAN.  Nada es un buen augurio: ¬°puedes usar una soluci√≥n alternativa! <br><br><h4>  FragmentSmack / SegmentSmack.  Primera sangre </h4><br>  El primer problema que encontramos fue que los contenedores en la nube a veces solo aplicaban parcialmente la nueva configuraci√≥n (solo ipfrag_low_thresh), y a veces no los usaban en absoluto, simplemente se bloquearon al principio.  No fue posible reproducir el problema de forma estable (manualmente, todas las configuraciones se aplicaron sin ninguna dificultad).  Comprender por qu√© el contenedor se cae al principio tampoco es tan simple: no se encontraron errores.  Una cosa era segura: revertir la configuraci√≥n resuelve el problema de soltar contenedores. <br><br>  ¬øPor qu√© no es suficiente usar Sysctl en el host?  El contenedor vive en su espacio de nombres de red dedicado, por lo que al menos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte de los par√°metros Sysctl de la red</a> en el contenedor pueden diferir del host. <br><br>  ¬øC√≥mo se aplican exactamente las configuraciones de Sysctl en el contenedor?  Dado que tenemos contenedores sin privilegios, cambiar cualquier configuraci√≥n de Sysctl yendo al contenedor en s√≠ fallar√°, simplemente no habr√° suficientes derechos.  En ese momento, nuestra nube usaba Docker (ahora <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Podman</a> ) para lanzar contenedores.  La ventana acoplable a trav√©s de la API pas√≥ los par√°metros del nuevo contenedor, incluidas las configuraciones necesarias de Sysctl. <br>  En el curso de enumerar las versiones, result√≥ que la API de Docker no arroj√≥ todos los errores (al menos en la versi√≥n 1.10).  Al intentar iniciar el contenedor a trav√©s de "Docker Run", finalmente vimos al menos algo: <br><br> <code>write /proc/sys/net/ipv4/ipfrag_high_thresh: invalid argument docker: Error response from daemon: Cannot start container &lt;...&gt;: [9] System error: could not synchronise with container process.</code> <br> <br>  El valor del par√°metro no es v√°lido.  Pero por que?  ¬øY por qu√© no es v√°lido solo a veces?  Result√≥ que Docker no garantizaba la aplicaci√≥n de los par√°metros de Sysctl (la √∫ltima versi√≥n probada era 1.13.1), por lo que a veces ipfrag_high_thresh intent√≥ establecerse en 256K cuando ipfrag_low_thresh todav√≠a era 3M, es decir, el l√≠mite superior era m√°s bajo que el inferior, lo que provoc√≥ un error. <br><br>  En ese momento, ya usamos nuestro propio mecanismo para reconfigurar el contenedor despu√©s de comenzar (congelar el contenedor a trav√©s del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">congelador cgroup</a> y ejecutar comandos en el espacio de nombres del contenedor a trav√©s de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ip netns</a> ), y tambi√©n agregamos par√°metros Sysctl a esta parte.  El problema ha sido resuelto. <br><br><h4>  FragmentSmack / SegmentSmack.  Primera sangre 2 </h4><br>  Antes de que supi√©ramos c√≥mo usar Workaround en la nube, comenzaron a llegar las primeras quejas de los usuarios.  En ese momento, pasaron varias semanas desde el inicio de la soluci√≥n en los primeros servidores.  La investigaci√≥n inicial mostr√≥ que se recibieron quejas sobre servicios individuales y no todos los servidores de estos servicios.  El problema ha recuperado un car√°cter extremadamente vago. <br><br>  En primer lugar, por supuesto, intentamos revertir la configuraci√≥n de Sysctl, pero esto no tuvo ning√∫n efecto.  Varias manipulaciones con el servidor y la configuraci√≥n de la aplicaci√≥n tampoco ayudaron.  Reiniciar ayud√≥.  Reiniciar para Linux es tan poco natural como era una condici√≥n normal para trabajar con Windows en los viejos tiempos.  Sin embargo, ayud√≥, y descartamos todo a un "error en el n√∫cleo" al aplicar la nueva configuraci√≥n en Sysctl.  Qu√© fr√≠volo fue ... <br><br>  Tres semanas despu√©s, el problema recurri√≥.  La configuraci√≥n de estos servidores era bastante simple: Nginx en modo proxy / equilibrador.  El tr√°fico es un poco.  Nueva introducci√≥n: el n√∫mero de errores 504 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tiempo de espera de la puerta de enlace</a> ) aumenta cada d√≠a en los clientes.  El gr√°fico muestra la cantidad de 504 errores por d√≠a para este servicio: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xk/hk/rj/xkhkrjedsakcdrx6m_z8hgcgjsw.png"></div><br><br>  Todos los errores son aproximadamente del mismo backend, aproximadamente el que est√° en la nube.  El gr√°fico del consumo de memoria para fragmentos de paquetes en este backend fue el siguiente: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jy/fb/gt/jyfbgtoqrbqwv6cird2zawvatza.png"></div><br><br>  Esta es una de las manifestaciones m√°s llamativas del problema en los gr√°ficos del sistema operativo.  En la nube, al mismo tiempo, se solucion√≥ otro problema de red con la configuraci√≥n de QoS (Control de tr√°fico).  En el gr√°fico del consumo de memoria para fragmentos de paquetes, se ve√≠a exactamente igual: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/09/nf/4r/09nf4rxogxv9xppeumwujvmcr3m.png"></div><br><br>  La suposici√≥n era simple: si se ven iguales en los gr√°ficos, entonces tienen la misma raz√≥n.  Adem√°s, cualquier problema con este tipo de memoria es extremadamente raro. <br><br>  La esencia del problema solucionado fue que usamos el programador de paquetes fq con la configuraci√≥n predeterminada en QoS.  Por defecto, para una conexi√≥n, le permite agregar 100 paquetes a la cola, y algunas conexiones en una situaci√≥n de escasez de canales comenzaron a obstruir la cola hasta el fallo.  En este caso, los paquetes caen.  En las estad√≠sticas tc (tc -s qdisc), esto se puede ver de la siguiente manera: <br><br> <code>qdisc fq 2c6c: parent 1:2c6c limit 10000p flow_limit 100p buckets 1024 orphan_mask 1023 quantum 3028 initial_quantum 15140 refill_delay 40.0ms <br> Sent 454701676345 bytes 491683359 pkt (dropped 464545, overlimits 0 requeues 0) <br> backlog 0b 0p requeues 0 <br> 1024 flows (1021 inactive, 0 throttled) <br> 0 gc, 0 highprio, 0 throttled, 464545 flows_plimit</code> <br> <br>  "464545 flows_plimit" son los paquetes descartados debido a que exceden el l√≠mite de la cola de una conexi√≥n, y "464545 descartados" es la suma de todos los paquetes descartados de este programador.  Despu√©s de aumentar la longitud de la cola a 1 mil y reiniciar los contenedores, el problema dej√≥ de aparecer.  Puedes sentarte en una silla y tomar un batido. <br><br><h4>  FragmentSmack / SegmentSmack.  √öltima sangre </h4><br>  Primero, unos meses despu√©s del anuncio de vulnerabilidades en el kernel, finalmente apareci√≥ una soluci√≥n para FragmentSmack (recuerdo que con el anuncio en agosto se lanz√≥ una soluci√≥n solo para SegmentSmack), que nos dio la oportunidad de abandonar Workaround, lo que nos caus√≥ muchos problemas.  Algunos de los servidores durante este tiempo ya logramos transferir a un nuevo kernel, y ahora tuvimos que comenzar desde el principio.  ¬øPor qu√© actualizamos el kernel sin esperar la soluci√≥n FragmentSmack?  El hecho es que el proceso de protecci√≥n contra estas vulnerabilidades coincidi√≥ (y se fusion√≥) con el proceso de actualizaci√≥n de CentOS (que lleva incluso m√°s tiempo que actualizar solo el n√∫cleo).  Adem√°s, SegmentSmack es una vulnerabilidad m√°s peligrosa, y una soluci√≥n apareci√≥ de inmediato, por lo que el punto fue en cualquier caso.  Sin embargo, no pod√≠amos simplemente actualizar el kernel en CentOS, porque la vulnerabilidad FragmentSmack, que apareci√≥ durante CentOS 7.5, se solucion√≥ solo en la versi√≥n 7.6, por lo que tuvimos que detener la actualizaci√≥n a 7.5 y comenzar de nuevo con la actualizaci√≥n a 7.6.  Y asi es. <br><br>  En segundo lugar, nos han devuelto quejas de usuarios poco frecuentes sobre problemas.  Ahora ya sabemos con certeza que todos ellos est√°n conectados con la descarga de archivos de clientes a algunos de nuestros servidores.  Y a trav√©s de estos servidores hubo un n√∫mero muy peque√±o de cargas de la masa total. <br><br>  Como recordamos de la historia anterior, la reversi√≥n de Sysctl no ayud√≥.  Reiniciar ayud√≥, pero temporalmente. <br>  Las sospechas con Sysctl no se levantaron, pero esta vez fue necesario recopilar la mayor cantidad de informaci√≥n posible.  Adem√°s, hab√≠a una falta extrema de la capacidad de reproducir el problema con la carga del cliente para examinar con mayor precisi√≥n lo que estaba sucediendo. <br><br>  El an√°lisis de todas las estad√≠sticas y registros disponibles no nos acerc√≥ a comprender lo que estaba sucediendo.  Hubo una falta aguda de la capacidad de reproducir el problema para "sentir" una conexi√≥n particular.  Finalmente, los desarrolladores de la versi√≥n especial de la aplicaci√≥n lograron lograr una reproducci√≥n estable de los problemas en el dispositivo de prueba cuando se conectan a trav√©s de Wi-Fi.  Este fue un gran avance en la investigaci√≥n.  El cliente se conect√≥ a Nginx, que se aproximaba al backend, que era nuestra aplicaci√≥n Java. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xw/g8/4a/xwg84aziibg7aaglsv6hdc2vyn8.png"></div><br><br>  El di√°logo con problemas fue el siguiente (corregido en el lado del proxy Nginx): <br><br><ol><li>  Cliente: solicitud de informaci√≥n sobre la descarga de un archivo. </li><li>  Servidor Java: respuesta. </li><li>  Cliente: POST con archivo. </li><li>  Servidor Java: error. </li></ol><br>  Al mismo tiempo, el servidor Java escribe en el registro que se recibieron 0 bytes de datos del cliente y el proxy Nginx que la solicitud tard√≥ m√°s de 30 segundos (30 segundos es el tiempo de espera de la aplicaci√≥n del cliente).  ¬øPor qu√© tiempo de espera y por qu√© 0 bytes?  Desde el punto de vista de HTTP, todo funciona como deber√≠a, pero la POST con el archivo parece desaparecer de la red.  Y desaparece entre el cliente y Nginx.  ¬°Es hora de armarse con Tcpdump!  Pero primero debe comprender la configuraci√≥n de la red.  El proxy nginx est√° detr√°s del equilibrador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">N3ware</a> L3.  La tunelizaci√≥n se usa para entregar paquetes desde el equilibrador L3 al servidor, que agrega sus encabezados a los paquetes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hs/ge/mf/hsgemfebrlkpjzvtz-cdrghudxu.png"></div><br><br>  Al mismo tiempo, la red llega a este servidor en forma de tr√°fico etiquetado con Vlan, que tambi√©n agrega sus campos a los paquetes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-a/ns/ap/-ansap0a5oyjsnqrf0onvsxg0tw.png"></div><br><br>  Y este tr√°fico puede estar fragmentado (el porcentaje muy peque√±o de tr√°fico fragmentado entrante del que hablamos al evaluar los riesgos de la soluci√≥n alternativa), lo que tambi√©n cambia el contenido de los encabezados: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gd/yx/48/gdyx48_bc15aj2xmhn5kb0_omci.png"></div><br><br>  Una vez m√°s: los paquetes est√°n encapsulados por una etiqueta Vlan, encapsulados por un t√∫nel, fragmentados.  Para comprender mejor c√≥mo sucede esto, rastreemos la ruta del paquete desde el cliente al proxy Nginx. <br><br><ol><li>  El paquete llega al equilibrador L3.  Para un enrutamiento correcto dentro del centro de datos, el paquete se encapsula en el t√∫nel y se env√≠a a la tarjeta de red. </li><li>  Como los encabezados de paquete + t√∫nel no caben en la MTU, el paquete se corta en fragmentos y se env√≠a a la red. </li><li>  El interruptor despu√©s del equilibrador L3 al recibir el paquete agrega una etiqueta Vlan y lo env√≠a m√°s. </li><li>  El conmutador antes de que el proxy Nginx vea (de acuerdo con la configuraci√≥n del puerto) que el servidor espera un paquete encapsulado en Vlan, por lo que lo env√≠a tal cual, sin quitar la etiqueta Vlan. </li><li>  Linux recibe fragmentos de paquetes individuales y los pega en un paquete grande. </li><li>  Luego, el paquete llega a la interfaz Vlan, donde se elimina la primera capa: encapsulaci√≥n Vlan. </li><li>  Luego, Linux lo env√≠a a la interfaz del t√∫nel, donde se elimina otra capa: la encapsulaci√≥n del t√∫nel. </li></ol><br>  La dificultad es pasar todo esto como par√°metros a tcpdump. <br>  Comencemos desde el final: ¬øhay alg√∫n paquete IP limpio (sin encabezados adicionales) de los clientes con vlan y encapsulaci√≥n de t√∫nel eliminados? <br><br> <code>tcpdump host &lt;ip &gt;</code> <br> <br>  No, no hab√≠a tales paquetes en el servidor.  Por lo tanto, el problema deber√≠a ser anterior.  ¬øHay paquetes con solo la encapsulaci√≥n Vlan eliminada? <br><br> <code>tcpdump ip[32:4]=0xx390x2xx</code> <br> <br>  0xx390x2xx es la direcci√≥n IP del cliente en formato hexadecimal. <br>  32: 4: direcci√≥n y longitud del campo en el que se escribe SCR IP en el paquete Tunnel. <br><br>  La direcci√≥n del campo tuvo que ser seleccionada por la fuerza bruta, ya que Internet escribe alrededor de 40, 44, 50, 54, pero no hab√≠a una direcci√≥n IP.  Tambi√©n puede ver uno de los paquetes en hexadecimal (el par√°metro -xx o -XX en tcpdump) y calcular qu√© direcci√≥n conoce la IP. <br><br>  ¬øHay fragmentos de paquetes sin la encapsulaci√≥n Vlan y Tunnel eliminada? <br><br> <code>tcpdump ((ip[6:2] &gt; 0) and (not ip[6] = 64)) <br></code> <br>  Esta magia nos mostrar√° todos los fragmentos, incluido el √∫ltimo.  Probablemente, lo mismo se puede filtrar por IP, pero no lo intent√©, porque no hay muchos paquetes de este tipo, y los que necesitaba se encontraban f√°cilmente en la secuencia general.  Aqu√≠ est√°n: <br><br> <code>14:02:58.471063 In 00:de:ff:1a:94:11 ethertype IPv4 (0x0800), length 1516: (tos 0x0, ttl 63, <b>id 53652, offset 0</b> , flags [+], proto IPIP (4), length 1500) <br> 11.11.11.11 &gt; 22.22.22.22: truncated-ip - 20 bytes missing! (tos 0x0, ttl 50, id 57750, offset 0, flags [DF], proto TCP (6), length 1500) <br> 33.33.33.33.33333 &gt; 44.44.44.44.80: Flags [.], seq 0:1448, ack 1, win 343, options [nop,nop,TS val 11660691 ecr 2998165860], length 1448 <br> 0x0000: 0000 0001 0006 00de fb1a 9441 0000 0800 ...........A.... <br> 0x0010: 4500 05dc d194 2000 3f09 d5fb 0a66 387d E.......?....f8} <br> 0x0020: 1x67 7899 4500 06xx e198 4000 3206 6xx4 .faEE.....@.2.m. <br> 0x0030: b291 x9xx x345 2541 83b9 0050 9740 0x04 .......A...P.@.. <br> 0x0040: 6444 4939 8010 0257 8c3c 0000 0101 080x dDI9...W.\...... <br> 0x0050: 00b1 ed93 b2b4 6964 xxd8 ffe1 006a 4578 ......ad.....j <b>Ex</b> <br> 0x0060: 6966 0000 4x4d 002a 0500 0008 0004 0100 <b>if</b> ..MM.*........ <br> <br> 14:02:58.471103 In 00:de:ff:1a:94:11 ethertype IPv4 (0x0800), length 62: (tos 0x0, ttl 63, <b>id 53652, offset 1480</b> , flags [none], proto IPIP (4), length 40) <br> 11.11.11.11 &gt; 22.22.22.22: ip-proto-4 <br> 0x0000: 0000 0001 0006 00de fb1a 9441 0000 0800 ...........A.... <br> 0x0010: 4500 0028 d194 00b9 3f04 faf6 2x76 385x E..(....?....f8} <br> 0x0020: 1x76 6545 xxxx 1x11 2d2c 0c21 8016 8e43 .faE...D-,.!...C <br> 0x0030: x978 e91d x9b0 d608 0000 0000 0000 7c31 .x............|Q <br> 0x0040: 881d c4b6 0000 0000 0000 0000 0000 ..............</code> <br> <br>  Estos son dos fragmentos de un paquete (el mismo ID 53652) con una fotograf√≠a (la palabra Exif es visible en el primer paquete).  Debido al hecho de que hay paquetes a este nivel, pero no pegados en vertederos, el problema est√° claramente en el ensamblaje.  ¬°Finalmente, hay evidencia documental de esto! <br><br>  El decodificador de paquetes no revel√≥ ning√∫n problema que impidiera el ensamblaje.  Probado aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hpd.gasmi.net</a> .  Al principio, cuando intenta meter algo all√≠, al decodificador no le gusta el formato del paquete.  Result√≥ que hab√≠a algunos dos octetos adicionales entre Srcmac y Ethertype (no relacionados con la informaci√≥n del fragmento).  Despu√©s de quitarlos, el decodificador funcion√≥.  Sin embargo, no mostr√≥ problemas. <br>  Di lo que quieras, excepto por esos mismos Sysctl, no se encontr√≥ nada m√°s.  Quedaba por encontrar una manera de identificar servidores problem√°ticos para comprender la escala y decidir sobre nuevas acciones.  R√°pidamente encontr√© el contador correcto: <br><br> <code>netstat -s | grep "packet reassembles failed‚Äù</code> <br> <br>  Est√° en snmpd bajo OID = 1.3.6.1.2.1.4.31.1.1.16.1 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ipSystemStatsReasmFails</a> ). <br><br><blockquote>  <i>"El n√∫mero de fallas detectadas por el algoritmo de reensamblado de IP (por cualquier raz√≥n: tiempo de espera agotado, errores, etc.)".</i> </blockquote><br>  Entre el grupo de servidores en los que se estudi√≥ el problema, en dos este contador aument√≥ m√°s r√°pido, en dos, m√°s lento, y en dos no aument√≥ en absoluto.  Una comparaci√≥n de la din√°mica de este contador con la din√°mica de los errores HTTP en el servidor Java revel√≥ una correlaci√≥n.  Es decir, el contador podr√≠a configurarse para monitoreo. <br><br>  Tener un indicador confiable de los problemas es muy importante para que pueda determinar con precisi√≥n si la reversi√≥n de Sysctl ayuda, ya que sabemos por la historia anterior que esto no est√° claro de inmediato desde la aplicaci√≥n.  Este indicador permitir√≠a identificar todas las √°reas problem√°ticas en la producci√≥n antes de que los usuarios lo encuentren. <br>  Despu√©s de la reversi√≥n de Sysctl, los errores de monitoreo se detuvieron, por lo que se demostr√≥ la causa de los problemas y el hecho de que la reversi√≥n ayuda. <br><br>  Revertimos la configuraci√≥n de fragmentaci√≥n en otros servidores, donde el nuevo monitoreo se incendi√≥, y en alg√∫n lugar asignamos a√∫n m√°s memoria para los fragmentos que antes por defecto (esto era udp-statistics, cuya p√©rdida parcial no era notable en el contexto general). <br><br><h4>  Las preguntas mas importantes </h4><br>  ¬øPor qu√© los paquetes se fragmentan en nuestro equilibrador L3?  La mayor√≠a de los paquetes que llegan de los usuarios a los balanceadores son SYN y ACK.  Los tama√±os de estas bolsas son peque√±os.  Pero dado que la proporci√≥n de dichos paquetes es muy grande, en su contexto no notamos la presencia de paquetes grandes que comenzaron a fragmentarse. <br><br>  La raz√≥n fue el script de configuraci√≥n advmss roto en servidores con interfaces Vlan (en ese momento hab√≠a muy pocos servidores con tr√°fico etiquetado en producci√≥n).  Advmss le permite transmitir al cliente informaci√≥n de que los paquetes en nuestra direcci√≥n deben ser m√°s peque√±os para que despu√©s de pegarles los encabezados de t√∫nel no tengan que fragmentarse. <br><br>  ¬øPor qu√© no ayud√≥ Sysctl rollback, sino que reinici√≥ la ayuda?  La reversi√≥n de Sysctl cambi√≥ la cantidad de memoria disponible para pegar paquetes.  Al mismo tiempo, aparentemente el hecho mismo del desbordamiento de la memoria para los fragmentos condujo a la inhibici√≥n de las conexiones, lo que llev√≥ al hecho de que los fragmentos se retrasaron en la cola durante mucho tiempo.  Es decir, el proceso se est√° repitiendo. <br>  Rebut anul√≥ la memoria y todo estaba en orden. <br><br>  ¬øPodr√≠a prescindir de la soluci√≥n?  S√≠, pero existe un gran riesgo de dejar a los usuarios desatendidos en caso de un ataque.  Por supuesto, el uso de Workaround como resultado condujo a varios problemas, incluida la inhibici√≥n de uno de los servicios por parte de los usuarios, pero sin embargo, creemos que las acciones estaban justificadas. <br><br>  Muchas gracias a Andrei Timofeev ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">atimofeyev</a> ) por ayudar con la investigaci√≥n, y a Alexei Krenev ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">devicex</a> ) por el trabajo tit√°nico de actualizar Centos y kernels en los servidores.  El proceso, que en este caso tuvo que iniciarse varias veces desde el principio, por lo que se prolong√≥ durante muchos meses. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/475540/">https://habr.com/ru/post/475540/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../475514/index.html">IOS killer: jailbreak usando checkra1n en preguntas y respuestas</a></li>
<li><a href="../475518/index.html">Empresa canadiense desarroll√≥ material que te hace invisible</a></li>
<li><a href="../475520/index.html">Transici√≥n CSS de la propiedad de altura de 0px a auto</a></li>
<li><a href="../475522/index.html">HP: su unidad original no es en absoluto original. ¬øQui√©n tiene la culpa y qu√© hacer?</a></li>
<li><a href="../475536/index.html">Curr√≠culum vitae para un traductor aut√≥nomo</a></li>
<li><a href="../475542/index.html">C√≥mo ha cambiado el marketing por correo electr√≥nico desde 2013: 4 tendencias principales y estad√≠sticas actuales</a></li>
<li><a href="../475544/index.html">Cat√°logos de productos, servicios y m√°s.</a></li>
<li><a href="../475546/index.html">S√≠ndromes adictivos IT</a></li>
<li><a href="../475548/index.html">Emparejamiento aburrido sin desequilibrio y colas: una gu√≠a pr√°ctica</a></li>
<li><a href="../475550/index.html">Sistemas ac√∫sticos para salas de tipo abierto.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
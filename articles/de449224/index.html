<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸš½ ğŸŒƒ ğŸ¹ Ãœber die Tendenz der kÃ¼nstlichen Intelligenz ğŸ¡ ğŸŒ” ğŸ‘©ğŸ¾â€ğŸ¤â€ğŸ‘©ğŸ»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="tl; dr: 


- Maschinelles Lernen sucht nach Mustern in Daten. KÃ¼nstliche Intelligenz kann jedoch â€voreingenommenâ€œ sein - das heiÃŸt, die falschen Muste...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ãœber die Tendenz der kÃ¼nstlichen Intelligenz</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/449224/"><p><img src="https://habrastorage.org/webt/ba/yy/oo/bayyoozdv865jlg9zqjczextnbg.png"></p><br><h2 id="tldr">  tl; dr: </h2><br><ul><li> Maschinelles Lernen sucht nach Mustern in Daten.  KÃ¼nstliche Intelligenz kann jedoch â€voreingenommenâ€œ sein - das heiÃŸt, die falschen Muster finden.  Beispielsweise kann ein Hautkrebserkennungssystem anhand von Fotos Bildern, die in einer Arztpraxis aufgenommen wurden, besondere Aufmerksamkeit widmen.  Maschinelles Lernen weiÃŸ nicht, wie <em>es geht</em> : Seine Algorithmen zeigen nur Muster in Zahlen an, und wenn die Daten nicht reprÃ¤sentativ sind, wird dies auch das Ergebnis ihrer Verarbeitung sein.  Und das Auffinden solcher Fehler kann aufgrund der Mechanik des maschinellen Lernens schwierig sein. <a name="habracut"></a></li><li>  Der offensichtlichste und beÃ¤ngstigendste Problembereich ist die menschliche Vielfalt.  Es gibt viele GrÃ¼nde, warum Daten Ã¼ber Personen bereits in der Erfassungsphase ihre ObjektivitÃ¤t verlieren kÃ¶nnen.  Sie sollten jedoch nicht glauben, dass dieses Problem nur Menschen betrifft: Genau die gleichen Schwierigkeiten treten auf, wenn Sie versuchen, eine Ãœberschwemmung in einem Lagerhaus oder einer ausgefallenen Gasturbine zu finden.  Einige Systeme weisen mÃ¶glicherweise Vorurteile hinsichtlich der Hautfarbe auf, andere sind gegen Siemens-Sensoren voreingenommen. </li><li>  Solche Probleme sind fÃ¼r maschinelles Lernen nicht neu und fÃ¼r ihn alles andere als einzigartig.  In komplexen Strukturen werden falsche Annahmen getroffen, und es ist immer schwer zu verstehen, warum eine Entscheidung getroffen wurde.  Es ist notwendig, auf komplexe Weise damit umzugehen: Erstellen Sie Tools und Prozesse zur ÃœberprÃ¼fung - und schulen Sie die Benutzer, damit sie den Empfehlungen der KI nicht blind folgen.  Maschinelles Lernen macht einige Dinge wirklich viel besser als wir, aber Hunde sind zum Beispiel viel effektiver als Menschen beim AufspÃ¼ren von Drogen, was kein Grund ist, sie als Zeugen zu bringen und aufgrund ihrer Aussagen Urteile zu fÃ¤llen.  Und Hunde sind Ã¼brigens viel schlauer als jedes maschinelle Lernsystem. </li></ul><br><hr><br><p>  Maschinelles Lernen ist heute einer der wichtigsten grundlegenden Technologietrends.  Dies ist eine der wichtigsten MÃ¶glichkeiten, wie Technologie die Welt um uns herum im nÃ¤chsten Jahrzehnt verÃ¤ndern wird.  Einige Aspekte dieser Ã„nderungen sind besorgniserregend.  Zum Beispiel die mÃ¶glichen Auswirkungen des maschinellen Lernens auf den Arbeitsmarkt oder seine Verwendung fÃ¼r unethische Zwecke (zum Beispiel autoritÃ¤re Regime).  Es gibt ein weiteres Problem, dem dieser Beitrag gewidmet ist: die <strong>Tendenz der kÃ¼nstlichen Intelligenz</strong> . </p><br><p>  Das ist eine schwierige Geschichte. </p><br><p><img src="https://habrastorage.org/webt/ca/fy/5q/cafy5qhpw0dvjtmf7v8xcrz9voy.png"><br>  <em>Google AI kann Katzen finden.</em>  <em>Diese Nachricht von 2012 war dann etwas Besonderes.</em> </p><br><h2 id="chto-takoe-predvzyatost-ii">  Was ist KI-Voreingenommenheit? </h2><br><blockquote>  <em>"Rohdaten" sind sowohl ein Widerspruch als auch eine schlechte Idee.</em>  <em>Daten mÃ¼ssen gut und sorgfÃ¤ltig aufbereitet werden.</em>  - Jeffrey Boker </blockquote><p>  Irgendwann vor 2013 mussten Sie die logischen Schritte beschreiben, um ein System zu schaffen, das beispielsweise Katzen auf Fotos erkennt.  So finden Sie Ecken in einem Bild, erkennen Augen, analysieren Texturen auf Fell, zÃ¤hlen Pfoten usw.  Sammeln Sie dann alle Komponenten - und stellen Sie fest, dass dies alles nicht wirklich funktioniert.  So etwas wie ein mechanisches Pferd - theoretisch kann es gemacht werden, aber in der Praxis ist es zu kompliziert zu beschreiben.  Am Ausgang haben Sie Hunderte (oder sogar Tausende) handgeschriebene Regeln.  Und kein einziges Arbeitsmodell. </p><br><p>  Mit dem Aufkommen des maschinellen Lernens haben wir aufgehÃ¶rt, â€manuelleâ€œ Regeln zum Erkennen eines Objekts zu verwenden.  Stattdessen nehmen wir tausend Stichproben des â€einenâ€œ X, tausend Stichproben des â€anderenâ€œ Y und zwingen den Computer, auf der Grundlage ihrer statistischen Analyse ein Modell zu erstellen.  Dann geben wir diesem Modell einige Beispieldaten und es bestimmt mit einiger Genauigkeit, ob es zu einem der SÃ¤tze passt.  Maschinelles Lernen generiert ein Modell basierend auf Daten, nicht mit Hilfe der Person, die es schreibt.  Die Ergebnisse sind beeindruckend, insbesondere im Bereich der Bild- und Mustererkennung. Deshalb setzt die gesamte Tech-Industrie jetzt auf maschinelles Lernen (ML). </p><br><p>  Aber nicht so einfach.  In der realen Welt enthalten Ihre Tausenden von Beispielen fÃ¼r X oder Y auch A, B, J, L, O, R und sogar L. Sie kÃ¶nnen ungleichmÃ¤ÃŸig verteilt sein, und einige von ihnen kÃ¶nnen so oft gefunden werden, dass das System ihnen mehr Aufmerksamkeit schenkt als zu Objekten, die Sie interessieren. </p><br><p>  Was bedeutet das in der Praxis?  Mein Lieblingsbeispiel ist, wenn Bilderkennungssysteme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf einen grasbewachsenen HÃ¼gel schauen und â€Schafâ€œ sagen</a> .  Es ist verstÃ¤ndlich, warum: Die meisten Beispielfotos der â€Schafeâ€œ wurden auf den Wiesen aufgenommen, auf denen sie leben, und in diesen Bildern nimmt das Gras viel mehr Platz ein als die kleinen weiÃŸen Flusen, und es ist das Gras des Systems, das als das wichtigste angesehen wird. </p><br><p>  Es gibt ernstere Beispiele.  Aus jÃ¼ngster Zeit - ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projekt</a> zur Erkennung von Hautkrebs auf Fotografien.  Es stellte sich heraus, dass Dermatologen die Aufstellung hÃ¤ufig zusammen mit den Manifestationen von Hautkrebs fotografieren, um die GrÃ¶ÃŸe der Formationen zu bestimmen.  Auf Beispielen von Fotografien gesunder Haut gibt es keine Lineale.  FÃ¼r das KI-System sind solche Lineale (genauer gesagt Pixel, die wir als â€Linealâ€œ definieren) zu einem der Unterschiede zwischen BeispielsÃ¤tzen geworden und manchmal wichtiger als ein kleiner Hautausschlag.  So erkannte ein System zur Identifizierung von Hautkrebs manchmal stattdessen die Linie. </p><br><p>  Der entscheidende Punkt hierbei ist, dass das System kein semantisches VerstÃ¤ndnis dafÃ¼r hat, was es betrachtet.  Wir betrachten eine Reihe von Pixeln und sehen ein Schaf, eine Haut oder Herrscher in ihnen und das System - nur eine Zahlenreihe.  Sie sieht keinen dreidimensionalen Raum, sie sieht weder Objekte noch Texturen noch Schafe.  Sie sieht nur Muster in den Daten. </p><br><p>  Die Schwierigkeit bei der Diagnose solcher Probleme besteht darin, dass das neuronale Netzwerk (das von Ihrem maschinellen Lernsystem generierte Modell) aus Tausenden von Hunderttausenden von Knoten besteht.  Es gibt keine einfache MÃ¶glichkeit, in ein Modell zu schauen und zu sehen, wie es eine Entscheidung trifft.  Das Vorhandensein einer solchen Methode wÃ¼rde bedeuten, dass der Prozess einfach genug ist, um alle Regeln manuell zu beschreiben, ohne maschinelles Lernen zu verwenden.  Die Menschen befÃ¼rchten, dass maschinelles Lernen zu einer Art Black Box geworden ist.  (Ich werde etwas spÃ¤ter erklÃ¤ren, warum dieser Vergleich immer noch zu viel ist.) </p><br><p>  Im Allgemeinen ist dies das Problem der Verzerrung der kÃ¼nstlichen Intelligenz oder des maschinellen Lernens: Ein System zum Auffinden von Mustern in Daten kann falsche Muster finden, aber Sie bemerken es mÃ¶glicherweise nicht.  Dies ist ein grundlegendes Merkmal der Technologie, und es ist fÃ¼r jeden offensichtlich, der in der wissenschaftlichen Gemeinschaft und in groÃŸen Technologieunternehmen damit arbeitet.  Aber seine Konsequenzen sind komplex, ebenso wie unsere mÃ¶glichen LÃ¶sungen fÃ¼r diese Konsequenzen. </p><br><p>  Lassen Sie uns zuerst Ã¼ber die Konsequenzen sprechen. </p><br><p><img src="https://habrastorage.org/webt/ty/zu/2e/tyzu2ewswsiwlpon-fb5inbwggo.png"><br>  <em>KI kann fÃ¼r uns implizit eine Entscheidung zugunsten bestimmter Personengruppen treffen, basierend auf einer groÃŸen Anzahl unauffÃ¤lliger Signale</em> </p><br><h2 id="scenarii-predvzyatosti-ii">  KI-Bias-Szenarien </h2><br><p>  Das offensichtlichste und beÃ¤ngstigendste ist, dass sich dieses Problem in Bezug auf die menschliche Vielfalt manifestieren kann.  Vor kurzem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wurde das GerÃ¼cht verbreitet</a> , Amazon habe versucht, ein maschinelles Lernsystem fÃ¼r das erste Screening von Bewerbern aufzubauen.  Da es unter Amazon-Arbeitnehmern mehr MÃ¤nner gibt, gibt es auch hÃ¤ufiger Beispiele fÃ¼r â€erfolgreiche Einstellungenâ€œ als MÃ¤nner, und es gab mehr MÃ¤nner bei der Auswahl der vom System vorgeschlagenen LebenslÃ¤ufe.  Amazon hat dies bemerkt und das System nicht in der Produktion freigegeben. </p><br><p>  Das Wichtigste in diesem Beispiel ist, dass das System angeblich mÃ¤nnliche Kandidaten bevorzugt hat, obwohl das Geschlecht nicht im Lebenslauf aufgefÃ¼hrt war.  <strong>Das System sah andere Muster in Beispielen fÃ¼r â€erfolgreiche Einstellungâ€œ: Beispielsweise kÃ¶nnen Frauen spezielle WÃ¶rter verwenden, um Erfolge zu beschreiben, oder spezielle Hobbys haben.</strong>  <strong>NatÃ¼rlich wusste das System nicht, was â€Hockeyâ€œ ist, wer â€Menschenâ€œ sind oder was â€Erfolgâ€œ ist - es fÃ¼hrte lediglich eine statistische Analyse des Textes durch.</strong>  Aber die Muster, die sie sah, wÃ¤ren hÃ¶chstwahrscheinlich von der Person unbemerkt geblieben, und einige von ihnen (zum Beispiel die Tatsache, dass Menschen unterschiedlichen Geschlechts den Erfolg unterschiedlich beschreiben), wÃ¤re fÃ¼r uns wahrscheinlich schwierig zu sehen, selbst wenn wir sie betrachten. </p><br><p>  Weiter schlimmer.  Ein maschinelles Lernsystem, das Krebs auf blasser Haut sehr gut findet, kann bei dunkler Haut schlechter funktionieren oder umgekehrt.  Nicht unbedingt aufgrund von Voreingenommenheit, sondern weil Sie wahrscheinlich ein separates Modell fÃ¼r eine andere Hautfarbe erstellen mÃ¼ssen, indem Sie andere Eigenschaften auswÃ¤hlen.  <strong>Maschinelle Lernsysteme sind selbst in einem so engen Bereich wie der Bilderkennung nicht austauschbar.</strong>  Sie mÃ¼ssen das System einrichten, manchmal einfach durch Ausprobieren, um die Funktionen in den Daten, an denen Sie interessiert sind, gut zu erkennen, bis Sie die gewÃ¼nschte Genauigkeit erreicht haben.  MÃ¶glicherweise bemerken Sie jedoch nicht, dass das System in 98% der FÃ¤lle genau ist, wenn Sie mit einer Gruppe arbeiten, und nur in 91% (obwohl dies genauer ist als die von einer Person durchgefÃ¼hrte Analyse) in der anderen. </p><br><p>  Bisher habe ich hauptsÃ¤chlich Beispiele in Bezug auf Menschen und ihre Eigenschaften verwendet.  Die Diskussion um dieses Problem konzentriert sich hauptsÃ¤chlich auf dieses Thema.  Es ist jedoch wichtig zu verstehen, dass die Voreingenommenheit gegenÃ¼ber Menschen nur ein Teil des Problems ist.  Wir werden maschinelles Lernen fÃ¼r viele Dinge verwenden, und ein Stichprobenfehler wird fÃ¼r alle relevant sein.  Wenn Sie jedoch mit Personen arbeiten, hÃ¤ngt die Datenverzerrung mÃ¶glicherweise nicht mit diesen zusammen. </p><br><p>  Um dies zu verstehen, kehren wir zum Beispiel mit Hautkrebs zurÃ¼ck und betrachten drei hypothetische MÃ¶glichkeiten des Systemausfalls. </p><br><ol><li>  Inhomogene Verteilung von Menschen: Eine unausgewogene Anzahl von Hautaufnahmen in verschiedenen FarbtÃ¶nen, die zu falsch positiven oder falsch negativen Ergebnissen im Zusammenhang mit der Pigmentierung fÃ¼hren. </li><li>  Die Daten, auf denen das System trainiert wird, enthalten ein hÃ¤ufig anzutreffendes und heterogen verteiltes Merkmal, das nicht mit Menschen zusammenhÃ¤ngt und keinen diagnostischen Wert hat: ein Lineal auf Fotos von Hautkrebsmanifestationen oder Gras auf Fotos von Schafen.  In diesem Fall ist das Ergebnis anders, wenn das System Pixel im Bild von etwas findet, das das menschliche Auge als â€Linealâ€œ definiert. </li><li>  Die Daten enthalten ein Merkmal eines Drittanbieters, das eine Person nicht sehen kann, selbst wenn sie danach sucht. </li></ol><br><p>  Was bedeutet das?  Wir wissen a priori, dass Daten von verschiedenen Personengruppen unterschiedlich dargestellt werden kÃ¶nnen, und wir kÃ¶nnen zumindest planen, nach solchen Ausnahmen zu suchen.  Mit anderen Worten, es gibt eine Reihe sozialer GrÃ¼nde anzunehmen, dass Daten zu Personengruppen bereits eine gewisse Verzerrung enthalten.  Wenn wir uns das Foto mit dem Lineal ansehen, werden wir dieses Lineal sehen - wir haben es zuvor einfach ignoriert, wissend, dass es keine Rolle spielt, und vergessen, dass das System nichts weiÃŸ. </p><br><p>  Aber was wÃ¤re, wenn alle Ihre Fotos von ungesunder Haut in einem BÃ¼ro aufgenommen wÃ¼rden, in dem GlÃ¼hbirnen verwendet werden, und das bei fluoreszierendem Licht gesund ist?  Was ist, wenn Sie nach dem Entfernen gesunder Haut vor dem Aufnehmen ungesunder Aufnahmen das Betriebssystem des Telefons aktualisiert haben und Apple oder Google den RauschunterdrÃ¼ckungsalgorithmus ein wenig geÃ¤ndert haben?  Eine Person kann dies nicht bemerken, egal wie sehr sie nach solchen Merkmalen sucht.  Aber dann wird das Maschinennutzungssystem es sofort sehen und verwenden.  Sie weiÃŸ nichts. </p><br><p>  WÃ¤hrend wir Ã¼ber falsche Korrelationen gesprochen haben, kann es vorkommen, dass die Daten korrekt und die Ergebnisse korrekt sind, Sie sie jedoch aus ethischen, rechtlichen oder administrativen GrÃ¼nden nicht verwenden mÃ¶chten.  In einigen LÃ¤ndern ist es beispielsweise nicht mÃ¶glich, Frauen einen Rabatt auf die Versicherung zu gewÃ¤hren, obwohl Frauen beim Fahren mÃ¶glicherweise sicherer sind.  Wir kÃ¶nnen uns leicht ein System vorstellen, das bei der Analyse historischer Daten weiblichen Namen geringere Risikofaktoren zuweist.  Ok, lassen Sie uns die Namen aus der Auswahl entfernen.  Denken Sie jedoch an das Beispiel bei Amazon: Das System kann das Geschlecht anhand anderer Faktoren bestimmen (obwohl es nicht weiÃŸ, welches Geschlecht und welche Maschine es ist), und Sie werden dies erst bemerken, wenn die RegulierungsbehÃ¶rde die von Ihnen angebotenen Tarife rÃ¼ckwirkend analysiert und Ihnen keine GebÃ¼hren berechnet dir geht es gut </p><br><p>  SchlieÃŸlich wird oft impliziert, dass wir solche Systeme nur fÃ¼r Projekte verwenden, die sich auf Menschen und soziale Interaktionen beziehen.  Es ist nicht so.  Wenn Sie Gasturbinen herstellen, mÃ¶chten Sie wahrscheinlich maschinelles Lernen auf Telemetrie anwenden, die von Dutzenden oder Hunderten von Sensoren auf Ihrem Produkt Ã¼bertragen wird (Audio, Video, Temperatur und andere Sensoren erzeugen Daten, die sehr einfach angepasst werden kÃ¶nnen, um ein Modell fÃ¼r maschinelles Lernen zu erstellen )  Hypothetisch kann man sagen: â€Hier sind die Daten von tausend ausgefallenen Turbinen, die vor ihrem Ausfall erhalten wurden, aber hier sind die Daten von tausend ausgefallenen Turbinen, die nicht kaputt gegangen sind.  Erstellen Sie ein Modell, um zu sagen, was der Unterschied zwischen ihnen ist. â€œ  Stellen Sie sich nun vor, dass Siemens-Sensoren 75% der schlechten und nur 12% der guten Turbinen kosten (es besteht kein Zusammenhang mit AusfÃ¤llen).  Das System wird ein Modell zur Lokalisierung von Turbinen mit Siemens-Sensoren erstellen.  Ups! </p><br><p><img src="https://habrastorage.org/webt/yh/ie/og/yhieogd7yvobqtecoevgxe_pydk.png"><br>  Bild - Moritz Hardt, UC Berkeley </p><br><h2 id="upravlenie-predvzyatostyu-ii">  AI Bias Management </h2><br><p>  Was kÃ¶nnen wir dagegen tun?  Sie kÃ¶nnen das Problem von drei Seiten angehen: </p><br><ol><li>  Methodische Genauigkeit bei der Erfassung und Verwaltung von Daten fÃ¼r das Training des Systems. </li><li>  Technische Werkzeuge zur Analyse und Diagnose des Modellverhaltens. </li><li>  Schulung, Ausbildung und Vorsicht bei der EinfÃ¼hrung von maschinellem Lernen in Produkte. </li></ol><br><p>  In Molieres Buch "Der HÃ¤ndler im Adel" gibt es einen Witz: Einem Mann wurde gesagt, dass Literatur in Prosa und Poesie unterteilt ist, und er bewundert mit Bewunderung, dass er sein ganzes Leben lang Prosa gesprochen hat, ohne es zu wissen.  Wahrscheinlich fÃ¼hlen sich Statistiker heute irgendwie so: Ohne es zu merken, widmeten sie ihre Karriere der kÃ¼nstlichen Intelligenz und Stichprobenfehlern.  Um nach einem Stichprobenfehler zu suchen und sich darÃ¼ber Sorgen zu machen, ist dies kein neues Problem. Wir mÃ¼ssen uns nur systematisch seiner LÃ¶sung nÃ¤hern.  Wie oben erwÃ¤hnt, ist es in einigen FÃ¤llen wirklich einfacher, dies zu tun, indem die mit Personendaten verbundenen Probleme untersucht werden.  Wir gehen a priori davon aus, dass wir Vorurteile Ã¼ber verschiedene Personengruppen haben, aber es fÃ¤llt uns schwer, uns ein Vorurteil Ã¼ber Siemens-Sensoren vorzustellen. </p><br><p>  Das Neue daran ist natÃ¼rlich, dass die Menschen nicht mehr direkt an statistischen Analysen beteiligt sind.  Es wird von Maschinen ausgefÃ¼hrt, die groÃŸe komplexe Modelle erstellen, die schwer zu verstehen sind.  Das Thema Transparenz ist einer der Hauptaspekte des Bias-Problems.  Wir befÃ¼rchten, dass das System nicht nur voreingenommen ist, sondern dass es keine MÃ¶glichkeit gibt, seine Voreingenommenheit zu erkennen, und dass sich maschinelles Lernen von anderen Formen der Automatisierung unterscheidet, die aus klaren logischen Schritten bestehen sollen, die Ã¼berprÃ¼ft werden kÃ¶nnen. </p><br><p>  Hier gibt es zwei Probleme.  Vielleicht kÃ¶nnen wir trotzdem ein Audit von maschinellen Lernsystemen durchfÃ¼hren.  Und die PrÃ¼fung eines anderen Systems ist eigentlich gar nicht einfacher. </p><br><p>  Erstens ist einer der Bereiche der modernen Forschung auf dem Gebiet des maschinellen Lernens die Suche nach Methoden zur Identifizierung der wichtigen FunktionalitÃ¤t maschineller Lernsysteme.  Gleichzeitig ist maschinelles Lernen (in seinem gegenwÃ¤rtigen Zustand) ein vÃ¶llig neues Gebiet der Wissenschaft, das sich schnell verÃ¤ndert. Sie sollten also nicht glauben, dass Dinge, die heute unmÃ¶glich sind, nicht bald ganz real werden kÃ¶nnen.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenAI-</a> Projekt ist ein interessantes Beispiel dafÃ¼r. </p><br><p>  Zweitens ist die Idee, dass es mÃ¶glich ist, den Entscheidungsprozess in bestehenden Systemen oder Organisationen zu Ã¼berprÃ¼fen und zu verstehen, theoretisch gut, in der Praxis jedoch mittelmÃ¤ÃŸig.  Zu verstehen, wie Entscheidungen in einer groÃŸen Organisation getroffen werden, ist alles andere als einfach.  Selbst wenn es dort einen formalen Entscheidungsprozess gibt, spiegelt dieser nicht wider, wie Menschen tatsÃ¤chlich interagieren, und tatsÃ¤chlich haben sie oft keinen logischen systematischen Ansatz, um ihre Entscheidungen zu treffen.  Wie mein Kollege <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vijay Pande sagte</a> , sind <strong>Menschen auch Black Boxes</strong> . </p><br><p>  Nehmen Sie tausend Menschen in mehreren sich Ã¼berschneidenden Unternehmen und Institutionen, und das Problem wird noch komplizierter.  Wir wissen nach der Tatsache, dass das Space Shuttle bei ihrer RÃ¼ckkehr auseinanderfallen sollte und einige Leute innerhalb der NASA Informationen hatten, die ihnen Grund zu der Annahme gaben, dass etwas Schlimmes passieren kÃ¶nnte, aber das <em>gesamte</em> System wusste es nicht.  Die NASA hat sogar gerade ein Ã¤hnliches Audit bestanden, nachdem sie das vorherige Shuttle verloren hatte, und dennoch ein weiteres - aus einem sehr Ã¤hnlichen Grund.  Es ist leicht zu sagen, dass Organisationen und Menschen klare logische Regeln befolgen, die Ã¼berprÃ¼ft, verstanden und geÃ¤ndert werden kÃ¶nnen - aber die Erfahrung beweist das Gegenteil.  Dies ist der " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehler der staatlichen Planungskommission</a> ". </p><br><p>  <strong>Ich vergleiche maschinelles Lernen oft mit Datenbanken, insbesondere relationalen - einer neuen grundlegenden Technologie, die die MÃ¶glichkeiten der Informatik und der Welt um sie herum verÃ¤ndert hat und zu einem Teil von allem geworden ist, was wir stÃ¤ndig nutzen, ohne es zu merken.</strong>  Datenbanken haben ebenfalls Probleme und eine Ã¤hnliche Eigenschaft: Das System kann auf falschen Annahmen oder auf schlechten Daten basieren, ist jedoch schwer zu bemerken, und Benutzer des Systems tun das, was es ihnen sagt, ohne Fragen zu stellen.  Es gibt eine Menge alter Witze Ã¼ber Steuerarbeiter, die Ihren Namen einmal falsch geschrieben haben, und es ist viel schwieriger, sie davon zu Ã¼berzeugen, den Fehler zu korrigieren, als den Namen tatsÃ¤chlich zu Ã¤ndern.  Dies kann auf verschiedene Arten gedacht werden, aber es ist nicht klar, wie am besten: wie wÃ¤re es mit einem technischen Problem in SQL oder mit einem Fehler in der Oracle-Version oder mit dem Ausfall bÃ¼rokratischer Institutionen?  Wie schwierig ist es, einen Fehler im Prozess zu finden, der dazu gefÃ¼hrt hat, dass das System nicht Ã¼ber eine Funktion wie die Korrektur von Tippfehlern verfÃ¼gt?  KÃ¶nnte dies verstanden werden, bevor sich Leute beschweren? </p><br><p>  Noch einfacher ist dieses Problem, das durch Geschichten veranschaulicht wird, wenn Fahrer aufgrund veralteter Daten im Navigator zu den FlÃ¼ssen fahren.  Ok, Karten mÃ¼ssen stÃ¤ndig aktualisiert werden.  Aber wie viel ist TomTom dafÃ¼r verantwortlich, dass Ihr Auto ins Meer blÃ¤st? </p><br><p>  Ich sage dies zu der Tatsache, dass ja - die Tendenz des maschinellen Lernens Probleme verursachen wird.  Diese Probleme Ã¤hneln jedoch denen, auf die wir in der Vergangenheit gestoÃŸen sind, und sie kÃ¶nnen ungefÃ¤hr so â€‹â€‹gut wahrgenommen und gelÃ¶st werden (oder auch nicht) wie in der Vergangenheit. , ,      ,      ,    .  , -        -  ,     ,   .       â€œ â€    ,    ,     ,    ,   .       .     ,      .   . </p><br><h2 id="zaklyuchenie">  Fazit </h2><br><blockquote> <em>    ,     , â€”       ,       .</em> </blockquote><p>   ,   Â« Â»       .      ,        â€”  .      HAL9000  Skynet â€”  -,     <em></em> .  Aber nein.   ,     , ,   .       ,         ,  â€¦ .    .     ,    ,     ,    -   .        ,     â€”     ,     ,    . </p><br><p>      , â€”  ,     â€”         .      ,     ,              . </p><br><p> , ,  Â«  â€”  ,       Â»   .     ,    Â«   Â».      ,     ,   ,     .   ,     .         , â€”  , ,      ,                .  ,  ,      . </p><br><hr><br><p> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ãœbersetzung: </font></font></strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diana Letskaya</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Redaktion: </font></font></strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alexey Ivanov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Community: </font></font></strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">@PonchikNews</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449224/">https://habr.com/ru/post/de449224/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449210/index.html">So funktioniert HPE SimpliVity 380 fÃ¼r VDI: Tests mit hoher Belastung</a></li>
<li><a href="../de449214/index.html">Klusterkit</a></li>
<li><a href="../de449216/index.html">Betrug automatisierter Ãœberwachungskameras</a></li>
<li><a href="../de449218/index.html">10 kritische FÃ¤higkeiten fÃ¼r jeden DevOps-Ingenieur</a></li>
<li><a href="../de449220/index.html">DrumHero: Wie ich das erste Spiel in meinem Leben gemacht habe</a></li>
<li><a href="../de449232/index.html">Ãœberwachung des Solarenergieverbrauchs per Computer / Server</a></li>
<li><a href="../de449234/index.html">Kostenloser Wireguard VPN-Dienst unter AWS</a></li>
<li><a href="../de449236/index.html">Ok Google: Wie komme ich durch das Captcha?</a></li>
<li><a href="../de449240/index.html">Die Geschichte eines jungen Daida-Dienstes (Abonnementkunst)</a></li>
<li><a href="../de449246/index.html">AX200 - Intel Wi-Fi 6</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
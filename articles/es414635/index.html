<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤩 📭 🤒 AI, curso práctico. Preprocesamiento y adición de imágenes. 🤸🏼 ✔️ 👓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El preprocesamiento es un término general para todas las manipulaciones realizadas con datos antes de transferir su modelo, incluido el centrado, la n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso práctico. Preprocesamiento y adición de imágenes.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/414635/">  El preprocesamiento es un término general para todas las manipulaciones realizadas con datos antes de transferir su modelo, incluido el centrado, la normalización, el desplazamiento, la rotación, el recorte, etc. Como regla general, se requiere preprocesamiento en dos casos. <br><br><ul><li>  <b>Limpieza de datos</b> .  Suponga que algunos artefactos están presentes en las imágenes.  Para facilitar el entrenamiento del modelo, los artefactos deben eliminarse en la etapa de preprocesamiento. </li><li>  <b>Adición de datos</b> .  A veces, los conjuntos de datos pequeños no son suficientes para la formación de modelos profundos de alta calidad.  Un enfoque de suplemento de datos es muy útil para resolver este problema.  Este es el proceso de transformar cada muestra de datos de varias maneras y agregar tales muestras modificadas al conjunto de datos.  De esta forma, se puede aumentar el tamaño efectivo del conjunto de datos. </li></ul><br>  Consideremos algunos posibles métodos de transformación durante el preprocesamiento y su implementación a través de Keras. <br><br><img src="https://habrastorage.org/webt/l-/qv/i5/l-qvi5bbsdqfjdcfheqqzjhrpzu.jpeg"><a name="habracut"></a><br><h2>  <font color="#0071c5">Datos</font> </h2><br>  En este y en los artículos siguientes, se utilizará un conjunto de datos para analizar el color emocional de las imágenes.  Contiene 1.500 ejemplos de imágenes, divididas en dos clases: positiva y negativa.  Veamos algunos ejemplos. <br><br><img src="https://habrastorage.org/webt/mu/rf/_g/murf_geogu_lj6a9q4xoa4pn3si.jpeg"><br>  <i>Ejemplos negativos</i> <br><br><img src="https://habrastorage.org/webt/nn/1_/vt/nn1_vtdtnxjci9mlhxxh25f4c5a.jpeg"><br>  <i>Ejemplos positivos</i> <br><br><h2>  <font color="#0071c5">Transformaciones de limpieza</font> </h2><br>  Ahora considere un conjunto de posibles transformaciones comúnmente utilizadas para limpiar datos, su implementación e impacto en las imágenes. <br><br>  Todos los fragmentos de código se pueden encontrar en el libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Preprocessing.ipynb</a> . <br><br><h3>  <font color="#0071c5">Reescalado</font> </h3><br>  Las imágenes generalmente se almacenan en formato RGB (Rojo Verde Azul).  En este formato, la imagen está representada por una matriz tridimensional (o de tres canales). <br><br><img src="https://habrastorage.org/webt/gk/bw/4w/gkbw4wlsomht08_atrneom6ugru.jpeg"><br>  <i>Descomposición RGB de la imagen.</i>  <i>Gráfico tomado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wikiwand</a></i> <br><br>  Una dimensión se usa para canales (rojo, verde y azul), las otras dos representan la ubicación.  Por lo tanto, cada píxel se codifica con tres números.  Cada número generalmente se almacena como un tipo entero sin signo de 8 bits (0 a 255). <br><br>  <b>El cambio de escala</b> es una operación que cambia el rango numérico de datos simplemente dividiéndolo por una constante predeterminada.  En redes neuronales profundas, puede ser necesario limitar los datos de entrada a un rango de 0 a 1 debido a un posible desbordamiento, problemas de optimización, estabilidad, etc. <br><br>  Por ejemplo, volvemos a escalar nuestros datos del rango [0;  255] al rango [0;  1]  En lo sucesivo, utilizaremos la clase Keras <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>ImageDataGenerator</i></a> , que le permite realizar todas las transformaciones sobre la marcha. <br><br>  Creemos dos instancias de esta clase: una para los datos transformados y la otra para la fuente: <br><br><img src="https://habrastorage.org/webt/pf/0_/hv/pf0_hvqdqdqsqtwwaqw5nznhrhc.png"><br>  (o para datos predeterminados).  Solo es necesario especificar la constante de escala.  Además, la clase <i>ImageDataGenerator le</i> permite transmitir datos directamente desde una carpeta en su disco duro utilizando el método <i>flow_from_directory</i> . <br><br>  Todos los parámetros se pueden encontrar en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentación</a> , pero los parámetros principales son: la ruta a la secuencia y el tamaño de la imagen objetivo (si la imagen no coincide con el tamaño objetivo, el generador simplemente la corta o la construye).  Finalmente, obtenemos una muestra del generador y consideramos los resultados. <br><br>  Visualmente, ambas imágenes son idénticas, pero la razón de esto es porque las herramientas Python * cambian el tamaño de las imágenes automáticamente <br><br><img src="https://habrastorage.org/webt/5s/o6/9o/5so69otm8hi5utmf09himqmoigm.jpeg"><br><br>  al rango predeterminado para que puedan mostrarse en la pantalla.  Considere los datos sin procesar (matrices).  Como puede ver, los macizos sin procesar difieren exactamente 255 veces. <br><br><h3>  <font color="#0071c5">Escala de grises</font> </h3><br>  Otro tipo de transformación que puede ser útil es la <i>escala de grises</i> , que convierte una imagen RGB de color en una imagen en la que todos los colores se representan en tonos de gris.  El procesamiento de imágenes convencional puede usar la traducción en escala de grises en combinación con un umbral posterior.  Este par de transformaciones puede rechazar píxeles ruidosos y definir formas en la imagen.  Hoy, todas estas operaciones son realizadas por la red neuronal convolucional (CNN), pero la conversión en escala de grises como un paso de preprocesamiento puede ser útil.  Ejecute este paso en Keras con la misma clase de generador. <br><br><img src="https://habrastorage.org/webt/uh/ay/li/uhaylivvkd5aznb1k-l9hzeeabw.jpeg"><br><br>  Aquí creamos solo una instancia de la clase y tomamos dos generadores diferentes.  El segundo generador establece el parámetro <i>color_mode</i> en "escala de grises" (el valor predeterminado es "RGB"). <br><br><h3>  <font color="#0071c5">Muestras de centrado</font> </h3><br>  Ya hemos visto que los valores de los datos sin procesar están en el rango de 0 a 255. Por lo tanto, una muestra es una matriz tridimensional de números de 0 a 255. A la luz de los principios de estabilidad de optimización (deshacerse del problema de la desaparición o saturación de valores), <i>puede ser necesario normalizar el conjunto de datos para que el promedio de cada muestra de datos sea 0</i> . <br><br><img src="https://habrastorage.org/webt/eh/6s/jg/eh6sjgccinzuviy9vrzklcbzqas.jpeg"><br><br>  Para esto, es necesario calcular el valor promedio sobre toda la muestra y restarlo de cada número en la muestra dada. <br>  En Keras, esto se hace usando el parámetro <i>samplewise_center</i> . <br><br><h3>  <font color="#0071c5">Normalización de la desviación estándar de las muestras.</font> </h3><br>  Esta etapa de preprocesamiento se basa en la misma idea que el centrado de las muestras, pero en lugar de establecer el promedio en 0 desde, establece la desviación estándar en 1. <br><br><img src="https://habrastorage.org/webt/_e/aq/4k/_eaq4kpjy1ox6l70homarb0tlxe.png"><br><br>  La normalización de la desviación <i>estándar</i> se controla mediante el parámetro <i>samplewise_std_normalization</i> .  Cabe señalar que estos dos métodos de normalización de muestras a menudo se usan juntos. <br><br>  Esta transformación se puede utilizar en modelos de aprendizaje profundo para mejorar la estabilidad de la optimización al reducir el impacto de los gradientes explosivos. <br><br><h3>  <font color="#0071c5">Centrado de funciones</font> </h3><br>  Las dos secciones anteriores utilizaron una técnica de normalización que analizó cada muestra individual de datos.  Existe un enfoque alternativo para el procedimiento de normalización.  Considere cada número en la matriz de imágenes como un signo.  Entonces <i>cada imagen es un vector de características</i> .  Hay muchos de esos vectores en el conjunto de datos;  por lo tanto, podemos considerarlos como una <i>distribución</i> desconocida.  Esta distribución es multiparamétrica, y su dimensión será igual al número de características, es decir, ancho × alto × 3. Aunque se desconoce la distribución real de los datos, puede intentar normalizarla restando la distribución promedio.  Cabe señalar que el valor promedio es un vector de la misma dimensión, es decir, también es una imagen.  En otras palabras, promediamos sobre todo el conjunto de datos, y no sobre una muestra. <br><br>  Hay un parámetro especial de Keras llamado <i>featurewise_centering</i> , pero, desafortunadamente, a partir de agosto de 2017, hubo un error en su implementación;  por lo tanto, lo implementamos nosotros mismos.  Primero, consideramos todo el conjunto de datos en la memoria (podemos pagarlo, ya que estamos tratando con un pequeño conjunto de datos).  Lo hicimos configurando el tamaño del paquete al tamaño del conjunto de datos.  Luego calculamos la imagen promedio sobre todo el conjunto de datos y finalmente la restamos de la imagen de prueba. <br><br><img src="https://habrastorage.org/webt/sm/wn/of/smwnofa7izsr-kyhn2r8mwab-dw.jpeg"><br><br><h3>  <font color="#0071c5">Normalización de la desviación estándar de los síntomas.</font> </h3><br>  La idea de normalizar la desviación estándar es exactamente la misma que la idea de centrar.  La única diferencia es que en lugar de restar el promedio, dividimos por la desviación estándar.  Visualmente, el resultado no es muy diferente.  Sucedió lo mismo <br><br><img src="https://habrastorage.org/webt/im/j-/ge/imj-gegeoxxc_1dsd6km4vshs9e.png"><br>  durante el cambio de escala, dado que la normalización de la desviación estándar no es más que un cambio de escala con una constante calculada de cierta manera, y con un cambio de escala simple, la constante se especifica manualmente.  Tenga en cuenta que una idea similar de normalizar los paquetes de datos es el núcleo de una técnica moderna de aprendizaje profundo llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">BatchNormalization</a> . <br><br><img src="https://habrastorage.org/webt/lf/lc/rg/lflcrgjs6a42y7u1vvtna5nz8jy.jpeg"><br><br><h2>  <font color="#0071c5">Transformación con la adición.</font> </h2><br>  En esta sección, observamos varias transformaciones dependientes de datos que usan explícitamente la naturaleza gráfica de los datos.  Estos tipos de transformaciones a menudo se usan en procedimientos de adición de datos. <br><br><h3>  <font color="#0071c5">Rotación</font> </h3><br>  Este tipo de transformación gira la imagen en cierta dirección (en sentido horario o antihorario). <br><br>  El parámetro que permite la rotación se llama <i>rotación_rango</i> .  Indica el rango en grados desde el cual el ángulo de rotación se selecciona aleatoriamente con una distribución uniforme.  Cabe señalar que durante la rotación, el tamaño de la imagen no cambia.  Por lo tanto, algunas partes de la imagen pueden recortarse y otras llenarse. <br><br><img src="https://habrastorage.org/webt/vh/d8/s-/vhd8s-j4ojpyqrcat9rc3jzegm4.png"><br><br>  El modo de relleno se establece utilizando el parámetro <i>fill_mode</i> .  Es compatible con varios métodos de relleno, pero aquí usamos el método <i>constante</i> como ejemplo. <br><br><img src="https://habrastorage.org/webt/t3/bo/4f/t3bo4fjn4tm96ergzw_ucahbouq.jpeg"><br><br><h3>  <font color="#0071c5">Desplazamiento horizontal</font> </h3><br>  Este tipo de transformación desplaza la imagen en una determinada dirección a lo largo del eje horizontal (izquierda o derecha). <br><br><img src="https://habrastorage.org/webt/gw/j9/bh/gwj9bh9j8viw1eif_x1vpkpbh_s.png"><br><br>  El tamaño del cambio se puede determinar utilizando el parámetro <i>width_shift_range</i> y se puede medir como parte del ancho total de la imagen. <br><br><h3>  <font color="#0071c5">Desplazamiento vertical</font> </h3><br><img src="https://habrastorage.org/webt/re/pe/65/repe65wt5ekksezxikypdtglpyc.jpeg"><br><br>  Desplaza la imagen a lo largo del eje vertical (arriba o abajo).  El parámetro que controla el rango de desplazamiento se denomina generador de cambio de <i>altura</i> y también se mide como parte de la altura total de la imagen. <br><br><h3>  <font color="#0071c5">Poda</font> </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Una conversión de recorte</a> o recorte desplaza cada punto en la dirección vertical en una cantidad proporcional a la distancia desde ese punto hasta el borde de la imagen.  Tenga en cuenta que en el caso general, la dirección no tiene que ser vertical y es arbitraria. <br><br><img src="https://habrastorage.org/webt/mc/9w/0-/mc9w0-6flw4ewwlqyrs9gczpzlg.jpeg"><br><br>  El parámetro que controla el desplazamiento se llama <i>shear_range</i> y corresponde al ángulo de desviación (en radianes) entre la línea horizontal en la imagen original y la imagen (en el sentido matemático) de esta línea en la imagen transformada. <br><br><h3>  <font color="#0071c5">Acercar / Alejar</font> </h3><br><img src="https://habrastorage.org/webt/bd/ut/i6/bduti6xglamlgqkaiv2ck2ef5he.png"><br>  Este tipo de transformación se aproxima o elimina la imagen original.  El parámetro <i>zoom_range</i> controla el factor de zoom. <br><br><img src="https://habrastorage.org/webt/ij/nj/4l/ijnj4ln-l8raqleq-lbmwkumewc.jpeg"><br><br>  Por ejemplo, si <i>zoom_range</i> es 0.5, entonces el factor de zoom se seleccionará del rango [0.5, 1.5]. <br><br><img src="https://habrastorage.org/webt/wn/vd/zo/wnvdzog-l-clsbupmziwcszoh9o.jpeg"><br><br><h3>  <font color="#0071c5">Volteo horizontal</font> </h3><br><img src="https://habrastorage.org/webt/qj/xr/r9/qjxrr9l5ktaubq2t_9cagdp7es0.png"><br><br>  Voltea la imagen en relación con el eje vertical.  Se puede activar o desactivar utilizando el parámetro <i>horizontal_flip</i> . <br><br><h3>  <font color="#0071c5">Volteo vertical</font> </h3><br><img src="https://habrastorage.org/webt/fb/im/g1/fbimg1quzp5t83brbi8ztfv42jk.jpeg"><br><br>  Voltea la imagen alrededor del eje horizontal.  El parámetro <i>vertical_flip</i> (de tipo booleano) controla la presencia o ausencia de esta transformación. <br><br><h2>  <font color="#0071c5">Combinación</font> </h2><br>  Aplicamos todos los tipos descritos de transformaciones del complemento al mismo tiempo y vemos qué sucede.  Recuerde que los parámetros para todas las transformaciones se seleccionan aleatoriamente de un cierto rango;  por lo tanto, debemos obtener un conjunto de muestras con un grado significativo de diversidad. <br><br>  Iniciamos <i>ImageDataGenerator</i> con todos los parámetros disponibles y verificamos el hidrante rojo en la imagen. <br><br><img src="https://habrastorage.org/webt/05/tg/el/05tgelnzqacfl5gkwkpgzrrr8qe.jpeg"><br><br>  Tenga en cuenta que el modo de relleno <i>constante</i> se usó solo para una mejor visualización.  Ahora usaremos un modo de relleno más avanzado llamado <i>más cercano</i> ;  Este modo asigna el color del píxel existente más cercano al píxel vacío. <br><br><img src="https://habrastorage.org/webt/l-/qv/i5/l-qvi5bbsdqfjdcfheqqzjhrpzu.jpeg"><br><h2>  <font color="#0071c5">Conclusión</font> </h2><br>  Este artículo proporciona una descripción general de las técnicas básicas para el preprocesamiento de imágenes, tales como: escala, normalización, rotación, desplazamiento y recorte.  También demostraron la implementación de estas técnicas de transformación utilizando Keras y su introducción en el proceso de aprendizaje profundo tanto técnica (clase <i>ImageDataGenerator</i> ) como ideológicamente (suplemento de datos). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es414635/">https://habr.com/ru/post/es414635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es414625/index.html">Data Center World: ¿vale la pena el viaje?</a></li>
<li><a href="../es414627/index.html">Desarrollo seguro en PHDays 8: Resultados de la reunión comunitaria PDUG</a></li>
<li><a href="../es414629/index.html">La Organización Mundial de la Salud reconoce oficialmente la existencia de la adicción al juego</a></li>
<li><a href="../es414631/index.html">Resumen del libro Guía práctica para las pruebas en DevOps, Katrina Clokie</a></li>
<li><a href="../es414633/index.html">Hay S.L.O.N.a en partes. Introducir ITAM y no ahogarse (Parte 2)</a></li>
<li><a href="../es414637/index.html">El iPhone transmitirá automáticamente las coordenadas cuando llame al 911</a></li>
<li><a href="../es414639/index.html">Servicios de hackers en Internet oscuro</a></li>
<li><a href="../es414641/index.html">Domar XBRL: notas del analista</a></li>
<li><a href="../es414643/index.html">Codificación de la tienda: ganadores del hackathon M.SMART</a></li>
<li><a href="../es414645/index.html">ONETRAK - pulseras inteligentes y más</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕞 👿 🛋️ 深度学习。 联合学习 👈🏼 👩‍⚖️ 👸🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="嗨，habrozhiteli！ 我们最近将这本书交给了Andrew W. Trask，为进一步精通深度学习技术奠定了基础。 它从描述神经网络的基础开始，然后详细研究其他层和体系结构。 

 我们对“联合学习”这一段落进行了评论 

 联合学习的思想源于以下事实：难以获得足以教授强大的深度学习模型的大...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>深度学习。 联合学习</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/458800/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/webt/xs/t-/oc/xst-oc7auy1he8nhwbj7bbkhxwk.jpeg" align="left" alt="图片"></a> 嗨，habrozhiteli！ 我们最近将这本书交给了Andrew W. Trask，为进一步精通深度学习技术奠定了基础。 它从描述神经网络的基础开始，然后详细研究其他层和体系结构。 <br><br> 我们对“联合学习”这一段落进行了评论 <br><br> 联合学习的思想源于以下事实：难以获得足以教授强大的深度学习模型的大量数据，这些数据包含用于解决问题的有用信息（例如，用于使用MRI诊断肿瘤疾病）。 除了训练模型所需的有用信息外，数据集还包含与当前任务无关的其他信息，但向某人透露这些信息可能有害。 <br><br> 联合学习是一种用于在安全环境中封闭模型并在不移动数据的情况下进行教学的技术。 考虑一个例子。 <br><a name="habracut"></a><br><pre><code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Counter <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> codecsnp.random.seed(<span class="hljs-number"><span class="hljs-number">12345</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> codecs.open(<span class="hljs-string"><span class="hljs-string">'spam.txt'</span></span>,<span class="hljs-string"><span class="hljs-string">"r"</span></span>,encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>,errors=<span class="hljs-string"><span class="hljs-string">'ignore'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: ←     http:<span class="hljs-comment"><span class="hljs-comment">//www2.aueb.gr/users/ion/data/enron-spam/ raw = f.readlines() vocab, spam, ham = (set(["&lt;unk&gt;"]), list(), list()) for row in raw: spam.append(set(row[:-2].split(" "))) for word in spam[-1]: vocab.add(word) with codecs.open('ham.txt',"r",encoding='utf-8',errors='ignore') as f: raw = f.readlines() for row in raw: ham.append(set(row[:-2].split(" "))) for word in ham[-1]: vocab.add(word) vocab, w2i = (list(vocab), {}) for i,w in enumerate(vocab): w2i[w] = i def to_indices(input, l=500): indices = list() for line in input: if(len(line) &lt; l): line = list(line) + ["&lt;unk&gt;"] * (l - len(line)) idxs = list() for word in line: idxs.append(w2i[word]) indices.append(idxs) return indices</span></span></code> </pre> <br><h3> 学习检测垃圾邮件。 </h3><br>  <b>假设我们需要训练一个模型来从人们的电子邮件中检测垃圾邮件</b> <br><br> 在这种情况下，我们正在谈论电子邮件分类。 我们将在名为Enron的公共数据集上训练我们的第一个模型。 这是在安然听证会期间发布的大量电子邮件（现在是标准的电子邮件分析机构）。 一个有趣的事实：我熟悉一些人，根据他们的活动性质，他们必须阅读/评论此数据集，并且他们注意到人们在这些信中互相发送了各种信息（通常是非常个人的信息）。 但是由于该军团在审判期间公开，因此现在可以不受限制地使用。 <br><br> 上一节和本节中的代码仅实现准备操作。 输入文件（ham.txt和spam.txt）可在该书的网页： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">www.manning.com/books/grokking-deep-learning</a>和GitHub存储库中找到： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">github.com/iamtrask/Grokking-Deep-Learning</a> 。 我们需要对其进行预处理，以便准备将其从第13章转移到Embedding类，在第13章中，我们创建了深度学习框架。 和以前一样，该语料库中的所有单词都将转换为索引列表。 另外，我们将所有字母的长度都限制为500个单词，或者修剪它们或添加标记。 因此，我们得到了一个矩形数据集。 <br><br><pre> <code class="javascript hljs">spam_idx = to_indices(spam) ham_idx = to_indices(ham) train_spam_idx = spam_idx[<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">-1000</span></span>] train_ham_idx = ham_idx[<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">-1000</span></span>] test_spam_idx = spam_idx[<span class="hljs-number"><span class="hljs-number">-1000</span></span>:] test_ham_idx = ham_idx[<span class="hljs-number"><span class="hljs-number">-1000</span></span>:] train_data = list() train_target = list() test_data = list() test_target = list() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(max(len(train_spam_idx),len(train_ham_idx))): train_data.append(train_spam_idx[i%len(train_spam_idx)]) train_target.append([<span class="hljs-number"><span class="hljs-number">1</span></span>]) train_data.append(train_ham_idx[i%len(train_ham_idx)]) train_target.append([<span class="hljs-number"><span class="hljs-number">0</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(max(len(test_spam_idx),len(test_ham_idx))): test_data.append(test_spam_idx[i%len(test_spam_idx)]) test_target.append([<span class="hljs-number"><span class="hljs-number">1</span></span>]) test_data.append(test_ham_idx[i%len(test_ham_idx)]) test_target.append([<span class="hljs-number"><span class="hljs-number">0</span></span>]) def train(model, input_data, target_data, batch_size=<span class="hljs-number"><span class="hljs-number">500</span></span>, iterations=<span class="hljs-number"><span class="hljs-number">5</span></span>): n_batches = int(len(input_data) / batch_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> iter <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(iterations): iter_loss = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_batches): #         model.weight.data[w2i[<span class="hljs-string"><span class="hljs-string">'&lt;unk&gt;'</span></span>]] *= <span class="hljs-number"><span class="hljs-number">0</span></span> input = Tensor(input_data[b_i*bs:(b_i+<span class="hljs-number"><span class="hljs-number">1</span></span>)*bs], autograd=True) target = Tensor(target_data[b_i*bs:(b_i+<span class="hljs-number"><span class="hljs-number">1</span></span>)*bs], autograd=True) pred = model.forward(input).sum(<span class="hljs-number"><span class="hljs-number">1</span></span>).sigmoid() loss = criterion.forward(pred,target) loss.backward() optim.step() iter_loss += loss.data[<span class="hljs-number"><span class="hljs-number">0</span></span>] / bs sys.stdout.write(<span class="hljs-string"><span class="hljs-string">"\r\tLoss:"</span></span> + str(iter_loss / (b_i+<span class="hljs-number"><span class="hljs-number">1</span></span>))) print() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model def test(model, test_input, test_output): model.weight.data[w2i[<span class="hljs-string"><span class="hljs-string">'&lt;unk&gt;'</span></span>]] *= <span class="hljs-number"><span class="hljs-number">0</span></span> input = Tensor(test_input, autograd=True) target = Tensor(test_output, autograd=True) pred = model.forward(input).sum(<span class="hljs-number"><span class="hljs-number">1</span></span>).sigmoid() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ((pred.data &gt; <span class="hljs-number"><span class="hljs-number">0.5</span></span>) == target.data).mean()</code> </pre> <br> 定义了辅助函数train（）和test（）之后，我们可以初始化神经网络并通过编写几行代码来对其进行训练。 经过三轮迭代，网络能够以99.45％的准确度对控制数据集进行分类（控制数据集具有很好的平衡性，因此该结果可以认为是出色的）： <br><br><pre> <code class="javascript hljs">model = Embedding(vocab_size=len(vocab), dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) model.weight.data *= <span class="hljs-number"><span class="hljs-number">0</span></span> criterion = MSELoss() optim = SGD(parameters=model.get_parameters(), alpha=<span class="hljs-number"><span class="hljs-number">0.01</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">3</span></span>): model = train(model, train_data, train_target, iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) print(<span class="hljs-string"><span class="hljs-string">"% Correct on Test Set: "</span></span> + \ str(test(model, test_data, test_target)*<span class="hljs-number"><span class="hljs-number">100</span></span>)) ______________________________________________________________________________ Loss:<span class="hljs-number"><span class="hljs-number">0.037140416860871446</span></span> % Correct on Test <span class="hljs-built_in"><span class="hljs-built_in">Set</span></span>: <span class="hljs-number"><span class="hljs-number">98.65</span></span> Loss:<span class="hljs-number"><span class="hljs-number">0.011258669226059114</span></span> % Correct on Test <span class="hljs-built_in"><span class="hljs-built_in">Set</span></span>: <span class="hljs-number"><span class="hljs-number">99.15</span></span> Loss:<span class="hljs-number"><span class="hljs-number">0.008068268387986223</span></span> % Correct on Test <span class="hljs-built_in"><span class="hljs-built_in">Set</span></span>: <span class="hljs-number"><span class="hljs-number">99.45</span></span></code> </pre> <br><h3> 让我们将模型设为联邦 </h3><br>  <b>上面，完成了最常见的深度学习。</b>  <b>现在增加隐私</b> <br><br> 在上一节中，我们实现了一个电子邮件分析示例。 现在，将所有电子邮件放在一个位置。 这是一种很好的旧工作方法（至今仍在世界范围内广泛使用）。 首先，我们将模仿联邦教育的环境，其中有几种不同的字母集合： <br><br><pre> <code class="javascript hljs">bob = (train_data[<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">1000</span></span>], train_target[<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">1000</span></span>]) alice = (train_data[<span class="hljs-number"><span class="hljs-number">1000</span></span>:<span class="hljs-number"><span class="hljs-number">2000</span></span>], train_target[<span class="hljs-number"><span class="hljs-number">1000</span></span>:<span class="hljs-number"><span class="hljs-number">2000</span></span>]) sue = (train_data[<span class="hljs-number"><span class="hljs-number">2000</span></span>:], train_target[<span class="hljs-number"><span class="hljs-number">2000</span></span>:])</code> </pre> <br> 没什么复杂的。 现在，我们可以执行与以前相同的训练过程，但是已经对三个单独的数据集进行了训练。 每次迭代之后，我们将平均Bob，Alice和Sue模型中的值，并评估结果。 请注意，一些联合学习方法涉及在每个软件包（或软件包集合）之后进行合并； 我决定使代码尽可能简单： <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">3</span></span>): print(<span class="hljs-string"><span class="hljs-string">"Starting Training Round..."</span></span>) print(<span class="hljs-string"><span class="hljs-string">"\tStep 1: send the model to Bob"</span></span>) bob_model = train(copy.deepcopy(model), bob[<span class="hljs-number"><span class="hljs-number">0</span></span>], bob[<span class="hljs-number"><span class="hljs-number">1</span></span>], iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) print(<span class="hljs-string"><span class="hljs-string">"\n\tStep 2: send the model to Alice"</span></span>) alice_model = train(copy.deepcopy(model), alice[<span class="hljs-number"><span class="hljs-number">0</span></span>], alice[<span class="hljs-number"><span class="hljs-number">1</span></span>], iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) print(<span class="hljs-string"><span class="hljs-string">"\n\tStep 3: Send the model to Sue"</span></span>) sue_model = train(copy.deepcopy(model), sue[<span class="hljs-number"><span class="hljs-number">0</span></span>], sue[<span class="hljs-number"><span class="hljs-number">1</span></span>], iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) print(<span class="hljs-string"><span class="hljs-string">"\n\tAverage Everyone's New Models"</span></span>) model.weight.data = (bob_model.weight.data + \ alice_model.weight.data + \ sue_model.weight.data)/<span class="hljs-number"><span class="hljs-number">3</span></span> print(<span class="hljs-string"><span class="hljs-string">"\t% Correct on Test Set: "</span></span> + \ str(test(model, test_data, test_target)*<span class="hljs-number"><span class="hljs-number">100</span></span>)) print(<span class="hljs-string"><span class="hljs-string">"\nRepeat!!\n"</span></span>)</code> </pre> <br><br> 以下是结果片段。 这种模型的准确性几乎达到了与先前模型相同的水平，并且从理论上讲，我们无法访问训练数据-是吗？ 无论如何，但是每个人都会在学习过程中改变模型，对吗？ 我们真的不能从他们的数据集中得到任何东西吗？ <br><br><pre> <code class="javascript hljs">Starting Training Round... Step <span class="hljs-number"><span class="hljs-number">1</span></span>: send the model to Bob Loss:<span class="hljs-number"><span class="hljs-number">0.21908166249699718</span></span> ...... Step <span class="hljs-number"><span class="hljs-number">3</span></span>: Send the model to Sue Loss:<span class="hljs-number"><span class="hljs-number">0.015368461608470256</span></span> Average Everyone<span class="hljs-string"><span class="hljs-string">'s New Models % Correct on Test Set: 98.8</span></span></code> </pre> <br><h3> 破解联邦模型 </h3><br>  <b>让我们看一下如何从训练数据集中提取信息的简单示例。</b> <br><br> 当每个人只有少数培训示例时，联合学习会遇到两个大问题，尤其是难以解决的问题：速度和保密性。 事实证明，如果某人只有几个训练示例（或者仅通过几个例子对发送给您的模型进行了训练：一个训练包），您仍然可以学到很多有关源数据的知识。 如果您想象自己有10,000人（每个人的数据量都很小），那么您将花费大部分时间来回发送模型，而无需花费太多的培训（尤其是模型很大的时候）。 <br><br> 但是，让我们不要超越自己。 让我们看看在用户更新一个包装上的重量后您可以找到什么： <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> copy bobs_email = [<span class="hljs-string"><span class="hljs-string">"my"</span></span>, <span class="hljs-string"><span class="hljs-string">"computer"</span></span>, <span class="hljs-string"><span class="hljs-string">"password"</span></span>, <span class="hljs-string"><span class="hljs-string">"is"</span></span>, <span class="hljs-string"><span class="hljs-string">"pizza"</span></span>] bob_input = np.array([[w2i[x] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> bobs_email]]) bob_target = np.array([[<span class="hljs-number"><span class="hljs-number">0</span></span>]]) model = Embedding(vocab_size=len(vocab), dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) model.weight.data *= <span class="hljs-number"><span class="hljs-number">0</span></span> bobs_model = train(copy.deepcopy(model), bob_input, bob_target, iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br> 鲍勃通过收件箱中的电子邮件创建和训练模型。 但是碰巧的是，他通过给自己发送一封信来保存密码，该信上写着：“我的计算机密码是披萨。” 天真鲍勃！ 在查看了哪些权重发生了变化之后，我们可以找出鲍勃字母的字典（并理解其含义）： <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(bobs_model.weight.data - model.weight.data): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(v != <span class="hljs-number"><span class="hljs-number">0</span></span>): print(vocab[i])</code> </pre> <br> 用这种简单的方法，我们找出了鲍勃的绝密密码（可能还有他的烹饪偏好）。 怎么办？ 如果很容易找出导致重量变化的训练数据，如何信任联合学习？ <br><br><pre> <code class="javascript hljs">is pizza computer password my</code> </pre> <br>  »这本书的更多信息可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在出版商的网站上找到</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">目录</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">摘录</a> <br><br> 优惠券上的Habrozhiteli预购书有30％的折扣<b>-Grokking Deep Learning</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN458800/">https://habr.com/ru/post/zh-CN458800/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN458790/index.html">CatBoost简介。 Yandex报告</a></li>
<li><a href="../zh-CN458792/index.html">“疲倦”的员工：有没有出路？</a></li>
<li><a href="../zh-CN458794/index.html">7月18日在Redmadrobot举行的业务分析师会议</a></li>
<li><a href="../zh-CN458796/index.html">如何为繁重的工作量做好站点准备：5个实用技巧和有用工具</a></li>
<li><a href="../zh-CN458798/index.html">营养机器人或我想如何从健身教练那里拿面包</a></li>
<li><a href="../zh-CN458804/index.html">机器学习和人工智能文摘</a></li>
<li><a href="../zh-CN458808/index.html">哈伯死后报告：报纸下跌</a></li>
<li><a href="../zh-CN458810/index.html">美国将Corel和Parallels出售给KKR投资集团</a></li>
<li><a href="../zh-CN458812/index.html">JVM TI：如何为虚拟机制作插件</a></li>
<li><a href="../zh-CN458814/index.html">为需求未定的产品启动网站</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
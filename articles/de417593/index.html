<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßë‚Äçü§ù‚Äçüßë ‚úçüèΩ üåò NewSQL = NoSQL + ACID üîå üç∞ üêè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bis vor kurzem wurden in Odnoklassniki etwa 50 TB Echtzeitdaten in SQL Server gespeichert. F√ºr ein solches Volume ist es nahezu unm√∂glich, mit SQL DBM...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NewSQL = NoSQL + ACID</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/417593/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t5/hc/h2/t5hch2mr-lw9ffeahr_9gaxizlg.jpeg" width="600"></div><br>  Bis vor kurzem wurden in Odnoklassniki etwa 50 TB Echtzeitdaten in SQL Server gespeichert.  F√ºr ein solches Volume ist es nahezu unm√∂glich, mit SQL DBMS einen schnellen, zuverl√§ssigen und sogar ausfallsicheren Zugriff auf Rechenzentren bereitzustellen.  Normalerweise verwenden sie in solchen F√§llen eines der NoSQL-Repositorys, aber nicht alles kann auf NoSQL √ºbertragen werden: Einige Entit√§ten ben√∂tigen Garantien f√ºr ACID-Transaktionen. <br><br>  Dies f√ºhrte dazu, dass wir NewSQL-Speicher verwendeten, dh ein DBMS, das Fehlertoleranz, Skalierbarkeit und Leistung von NoSQL-Systemen bietet, aber gleichzeitig ACID-Garantien bewahrt, die klassischen Systemen vertraut sind.  Es gibt nur wenige funktionierende industrielle Systeme in dieser neuen Klasse, daher haben wir ein solches System selbst implementiert und in den kommerziellen Betrieb versetzt. <br><br>  Wie es funktioniert und was passiert ist - lesen Sie unter dem Schnitt. <br><a name="habracut"></a><br>  Heute hat Odnoklassniki mehr als 70 Millionen Besucher pro Monat.  Wir geh√∂ren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu den f√ºnf</a> gr√∂√üten sozialen Netzwerken der Welt und zu den zwanzig Websites, auf denen Benutzer die meiste Zeit verbringen.  Infrastruktur "OK" bew√§ltigt sehr hohe Lasten: mehr als eine Million HTTP-Anforderungen / Sek. An die Fronten.  Teile der Serverflotte in einer Menge von mehr als 8000 Teilen befinden sich nahe beieinander - in vier Moskauer Rechenzentren, wodurch eine Netzwerklatenz von weniger als 1 ms zwischen ihnen m√∂glich ist. <br><br>  Wir verwenden Cassandra seit 2010, beginnend mit Version 0.6.  Heute sind mehrere Dutzend Cluster in Betrieb.  Der schnellste Cluster verarbeitet mehr als 4 Millionen Vorg√§nge pro Sekunde und der gr√∂√üte speichert 260 TB. <br><br>  All dies sind jedoch gew√∂hnliche NoSQL-Cluster, die zum Speichern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schwach konsistenter</a> Daten verwendet werden.  Wir wollten jedoch den konsistenten Hauptspeicher Microsoft SQL Server ersetzen, der seit der Gr√ºndung von Odnoklassniki verwendet wird.  Der Speicher bestand aus mehr als 300 SQL Server Standard Edition-Computern, die 50 TB Daten enthielten - Gesch√§ftseinheiten.  Diese Daten werden im Rahmen von ACID-Transaktionen ge√§ndert und erfordern eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hohe Konsistenz</a> . <br><br>  Um Daten auf SQL Server-Knoten zu verteilen, haben wir sowohl die vertikale als auch die horizontale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Partitionierung</a> (Sharding) verwendet.  In der Vergangenheit haben wir ein einfaches Daten-Sharding-Schema verwendet: Jede Entit√§t war einem Token zugeordnet - eine Funktion der ID der Entit√§t.  Entit√§ten mit demselben Token wurden auf demselben SQL Server platziert.  Die Master-Detail-Typ-Beziehung wurde so implementiert, dass die Token der Haupt- und generierten Datens√§tze immer √ºbereinstimmten und sich auf demselben Server befanden.  In einem sozialen Netzwerk werden fast alle Datens√§tze im Auftrag eines Benutzers generiert. Dies bedeutet, dass alle Benutzerdaten in einem funktionalen Subsystem auf einem Server gespeichert sind.  Das hei√üt, Tabellen eines SQL Servers waren fast immer an einer Gesch√§ftstransaktion beteiligt, wodurch die Datenkonsistenz mithilfe lokaler ACID-Transaktionen sichergestellt werden konnte, ohne dass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">langsame und unzuverl√§ssige</a> verteilte ACID-Transaktionen erforderlich waren. <br><br>  Dank Sharding und der Beschleunigung von SQL: <br><br><ul><li>  Wir verwenden keine Fremdschl√ºsseleinschr√§nkungen, da sich die Entit√§ts-ID beim Sharding auf einem anderen Server befinden kann. </li><li>  Aufgrund der zus√§tzlichen Belastung der DBMS-CPU werden keine gespeicherten Prozeduren und Trigger verwendet. </li><li>  Wir verwenden keine JOINs wegen all der oben genannten und vieler zuf√§lliger Lesevorg√§nge von der Festplatte. </li><li>  Au√üerhalb einer Transaktion verwenden wir zur Reduzierung von Deadlocks die Isolationsstufe Read Uncommitted. </li><li>  Wir f√ºhren nur kurze Transaktionen durch (durchschnittlich k√ºrzer als 100 ms). </li><li>  Aufgrund der gro√üen Anzahl von Deadlocks verwenden wir kein mehrzeiliges UPDATE und DELETE - wir aktualisieren nur einen Datensatz. </li><li>  Wir f√ºhren Abfragen immer nur √ºber Indizes aus. Eine Abfrage mit einem Plan f√ºr einen vollst√§ndigen Tabellenscan bedeutet f√ºr uns eine √úberlastung der Datenbank und deren Ausfall. </li></ul><br>  Diese Schritte erm√∂glichten es, die maximale Leistung von SQL-Servern zu erreichen.  Die Probleme wurden jedoch immer gr√∂√üer.  Schauen wir sie uns an. <br><br><h2>  SQL-Probleme </h2><br><ul><li>  Da wir propriet√§res Sharding verwendet haben, haben Administratoren manuell neue Shards hinzugef√ºgt.  W√§hrend dieser ganzen Zeit haben skalierbare Datenreplikate keine Anforderungen erf√ºllt. </li><li>  Wenn die Anzahl der Datens√§tze in der Tabelle zunimmt, nimmt die Einf√ºge- und √Ñnderungsgeschwindigkeit ab. Wenn Sie einer vorhandenen Tabelle Indizes hinzuf√ºgen, sinkt die Geschwindigkeit um ein Vielfaches. Die Erstellung und Neuerstellung von Indizes geht mit Ausfallzeiten einher. </li><li>  Wenn nur wenige Windows for SQL Server in der Produktion sind, ist die Verwaltung Ihrer Infrastruktur schwierig </li></ul><br>  Das Hauptproblem ist jedoch <br><br><h2>  Fehlertoleranz </h2><br>  Classic SQL Server weist eine schlechte Fehlertoleranz auf.  Angenommen, Sie haben nur einen Datenbankserver, der alle drei Jahre ausf√§llt.  Zu diesem Zeitpunkt funktioniert die Site 20 Minuten lang nicht. Dies ist akzeptabel.  Wenn Sie 64 Server haben, funktioniert die Site nicht alle drei Wochen.  Und wenn Sie 200 Server haben, funktioniert die Site nicht jede Woche.  Das ist ein Problem. <br><br>  Was kann getan werden, um die Ausfallsicherheit von SQL Server zu verbessern?  Wikipedia bietet uns an, einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">leicht zug√§nglichen Cluster</a> zu erstellen: Wenn eine der Komponenten ausf√§llt, gibt es eine doppelte. <br><br>  Dies erfordert eine Flotte teurer Ger√§te: Mehrfachredundanz, Glasfaser, gemeinsamer Speicher und die Einbeziehung einer Reserve funktionieren nicht zuverl√§ssig: Etwa 10% der Einschl√ºsse schlagen mit einem Sicherungsknoten durch die Engine hinter dem Hauptknoten fehl. <br><br>  Der Hauptnachteil eines solchen hoch zug√§nglichen Clusters ist jedoch die Nullverf√ºgbarkeit bei Ausfall des Rechenzentrums, in dem es sich befindet.  Odnoklassniki verf√ºgt √ºber vier Rechenzentren, in denen wir im Falle eines vollst√§ndigen Unfalls Arbeit leisten m√ºssen. <br><br>  Zu diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zweck</a> k√∂nnen Sie die in SQL Server integrierte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Multi-Master-</a> Replikation verwenden.  Diese L√∂sung ist aufgrund der Softwarekosten viel teurer und weist bekannte Probleme bei der Replikation auf - unvorhersehbare Transaktionsverz√∂gerungen w√§hrend der synchronen Replikation und Verz√∂gerungen bei der Verwendung der Replikation (und infolgedessen verlorene √Ñnderungen) w√§hrend der asynchronen.  Die implizite <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">manuelle L√∂sung von Konflikten</a> macht diese Option f√ºr uns v√∂llig unanwendbar. <br><br>  All diese Probleme erforderten eine radikale L√∂sung, und wir gingen zu einer detaillierten Analyse √ºber.  Hier m√ºssen wir uns mit den grundlegenden Funktionen von SQL Server vertraut machen - Transaktionen. <br><br><h2>  Einfache Transaktion </h2><br>  Betrachten Sie aus Sicht eines angewandten SQL-Programmierers die einfachste Transaktion: Hinzuf√ºgen eines Fotos zu einem Album.  Alben und Fotos werden auf verschiedenen Platten gespeichert.  Das Album hat einen √∂ffentlichen Fototheke.  Dann wird eine solche Transaktion in die folgenden Schritte unterteilt: <br><br><ol><li>  Wir sperren das Album per Schl√ºssel. </li><li>  Erstellen Sie einen Eintrag in der Fototabelle. </li><li>  Wenn das Foto einen √∂ffentlichen Status hat, wird der √∂ffentliche Fotoz√§hler im Album aufgel√∂st, der Datensatz aktualisiert und die Transaktion festgeschrieben. </li></ol><br>  Oder in Form von Pseudocode: <br><br><pre><code class="hljs pgsql">TX.<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>("Albums", id); Album album = albums.<span class="hljs-keyword"><span class="hljs-keyword">lock</span></span>(id); Photo photo = photos.<span class="hljs-keyword"><span class="hljs-keyword">create</span></span>(‚Ä¶); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (photo.status == <span class="hljs-built_in"><span class="hljs-built_in">PUBLIC</span></span> ) { album.incPublicPhotosCount(); } album.<span class="hljs-keyword"><span class="hljs-keyword">update</span></span>(); TX.<span class="hljs-keyword"><span class="hljs-keyword">commit</span></span>();</code> </pre> <br>  Wir sehen, dass das h√§ufigste Gesch√§ftstransaktionsszenario darin besteht, Daten aus der Datenbank in den Speicher des Anwendungsservers zu lesen, etwas zu √§ndern und die neuen Werte wieder in der Datenbank zu speichern.  Normalerweise aktualisieren wir bei einer solchen Transaktion mehrere Entit√§ten, mehrere Tabellen. <br><br>  Bei der Ausf√ºhrung einer Transaktion kann es zu einer wettbewerbsbedingten √Ñnderung derselben Daten von einem anderen System kommen.  Beispielsweise kann Antispam entscheiden, dass der Benutzer verd√§chtig ist und daher alle Fotos des Benutzers nicht mehr √∂ffentlich sein sollten. Sie sollten zur Moderation gesendet werden. Dies bedeutet, dass photo.status auf einen anderen Wert ge√§ndert und die entsprechenden Z√§hler abgeschraubt werden.  Wenn dieser Vorgang ohne Garantien f√ºr die Atomizit√§t der Anwendung und die Isolierung konkurrierender Modifikationen wie bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ACID erfolgt</a> , ist das Ergebnis offensichtlich nicht das, was ben√∂tigt wird - entweder zeigt der Fotoz√§hler den falschen Wert an oder es werden nicht alle Fotos zur Moderation gesendet. <br><br>  Es gibt viele √§hnliche Codes, die verschiedene Gesch√§ftseinheiten im Rahmen einer Transaktion w√§hrend der gesamten Existenz von Odnoklassniki manipulieren.  Aus der Erfahrung mit der Migration auf NoSQL mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eventueller Konsistenz</a> wissen wir, dass die gr√∂√üten Schwierigkeiten (und Zeitkosten) darin bestehen, Code zu entwickeln, der auf die Aufrechterhaltung der Datenkonsistenz abzielt.  Daher haben wir die Hauptanforderung f√ºr ein neues Repository betrachtet, um echte logische ACID-Transaktionen f√ºr die Anwendungslogik bereitzustellen. <br><br>  Weitere ebenso wichtige Anforderungen waren: <br><br><ul><li>  Wenn das Rechenzentrum ausf√§llt, sollten sowohl Lesen als auch Schreiben in den neuen Speicher verf√ºgbar sein. </li><li>  Aktuelle Entwicklungsgeschwindigkeit beibehalten.  Das hei√üt, wenn Sie mit einem neuen Repository arbeiten, sollte die Codemenge ungef√§hr gleich sein, es sollte nicht erforderlich sein, dem Repository etwas hinzuzuf√ºgen, Algorithmen zur L√∂sung von Konflikten zu entwickeln, Sekund√§rindizes zu verwalten usw. </li><li>  Die Geschwindigkeit des neuen Speichers sollte sowohl beim Lesen von Daten als auch bei der Verarbeitung von Transaktionen hoch genug sein, was effektiv die Unanwendbarkeit von akademisch strengen, universellen, aber langsamen L√∂sungen wie beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zweiphasigen Commits bedeutete</a> . </li><li>  Automatische Skalierung im laufenden Betrieb. </li><li>  Mit gew√∂hnlichen billigen Servern, ohne exotische Eisenst√ºcke kaufen zu m√ºssen. </li><li>  Die M√∂glichkeit, den Speicher von den Entwicklern des Unternehmens zu entwickeln.  Mit anderen Worten, ihren eigenen oder Open Source-basierten L√∂sungen, vorzugsweise in Java, wurde Vorrang einger√§umt. </li></ul><br><h2>  Entscheidungen, Entscheidungen </h2><br>  Bei der Analyse m√∂glicher L√∂sungen kamen wir zu zwei m√∂glichen Architekturoptionen: <br><br>  Der erste besteht darin, einen beliebigen SQL Server zu verwenden und die erforderliche Fehlertoleranz, den Skalierungsmechanismus, den Failovercluster, die Konfliktl√∂sung und verteilte, zuverl√§ssige und schnelle ACID-Transaktionen zu implementieren.  Wir haben diese Option als nicht trivial und zeitaufw√§ndig eingestuft. <br><br>  Die zweite M√∂glichkeit besteht darin, ein vorgefertigtes NoSQL-Repository mit implementierter Skalierung, einem Failover-Cluster und Konfliktl√∂sung zu verwenden und Transaktionen und SQL selbst zu implementieren.  Auf den ersten Blick scheint selbst die Aufgabe der Implementierung von SQL, ganz zu schweigen von ACID-Transaktionen, jahrelang eine Aufgabe zu sein.  Aber dann merkten wir , dass eine Reihe von SQL - Funktionen , die wir in der Praxis verwenden, weit weg von ANSI SQL bis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cassandra CQL</a> weit von ANSI SQL.  Bei n√§herer Betrachtung von CQL stellten wir fest, dass es nah genug an dem war, was wir brauchten. <br><br><h2>  Cassandra und CQL </h2><br>  Also, was ist interessant an Cassandra, welche F√§higkeiten hat es? <br><br>  Zun√§chst k√∂nnen Sie hier Tabellen mit Unterst√ºtzung f√ºr verschiedene Datentypen erstellen. Sie k√∂nnen SELECT oder UPDATE f√ºr den Prim√§rschl√ºssel ausf√ºhren. <br><br><pre> <code class="hljs sql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> photos (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span> <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span> <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, owner <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span>,‚Ä¶); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> photos <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">id</span></span>=?; <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> photos <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">id</span></span>=?;</code> </pre> <br>  Um konsistente Replikatdaten sicherzustellen, verwendet Cassandra einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quorum-Ansatz</a> .  Im einfachsten Fall bedeutet dies, dass, wenn drei Replikate derselben Zeile auf verschiedenen Knoten des Clusters platziert werden, der Datensatz als erfolgreich angesehen wird, wenn die meisten Knoten (d. H. Zwei von drei) den Erfolg dieser Schreiboperation best√§tigen.  Die Daten einer Reihe gelten als konsistent, wenn beim Lesen die meisten Knoten abgefragt und best√§tigt wurden.  Somit ist bei Vorhandensein von drei Replikaten eine vollst√§ndige und sofortige Datenkonsistenz im Falle eines Ausfalls eines Knotens garantiert.  Dieser Ansatz erm√∂glichte es uns, ein noch zuverl√§ssigeres Schema zu implementieren: Senden Sie immer Anforderungen an alle drei Replikate und warten Sie auf eine Antwort der beiden schnellsten.  Die sp√§te Antwort des dritten Replikats wird dann verworfen.  Ein Knoten, der mit einer Antwort zu sp√§t kommt, kann schwerwiegende Probleme haben - Bremsen, Speicherbereinigung in der JVM, direkte Speicherr√ºckgewinnung im Linux-Kernel, Hardwarefehler, Trennung vom Netzwerk.  Dies hat jedoch keine Auswirkungen auf die Vorg√§nge oder Daten des Kunden. <br><br>  Der Ansatz, wenn wir uns drei Knoten zuwenden und eine Antwort von zwei erhalten, wird als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spekulation bezeichnet</a> : Eine Anfrage nach zus√§tzlichen Bemerkungen wird gesendet, noch bevor sie ‚Äûabf√§llt‚Äú. <br><br>  Ein weiterer Vorteil von Cassandra ist Batchlog - ein Mechanismus, der entweder die vollst√§ndige Anwendung oder die vollst√§ndige Nichtanwendung des von Ihnen vorgenommenen √Ñnderungspakets garantiert.  Dies erm√∂glicht es uns, A in ACID zu l√∂sen - Atomizit√§t sofort. <br><br>  Die Transaktionen in Cassandra sind den sogenannten " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lightweight-Transaktionen</a> " am n√§chsten.  Sie sind jedoch weit entfernt von "echten" ACID-Transaktionen: Tats√§chlich ist es eine Gelegenheit, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CAS</a> auf Daten von nur einem Datensatz zu erstellen, wobei ein Konsens √ºber das schwere Protokoll Paxos erzielt wird.  Daher ist die Geschwindigkeit solcher Transaktionen gering. <br><br><h2>  Was wir in Cassandra vermisst haben </h2><br>  Also mussten wir echte ACID-Transaktionen in Cassandra implementieren.  Damit k√∂nnten wir leicht zwei weitere praktische Funktionen des klassischen DBMS implementieren: konsistente schnelle Indizes, mit denen wir Datenabtastungen nicht nur f√ºr den Prim√§rschl√ºssel und den √ºblichen Generator monotoner Auto-Inkrement-IDs durchf√ºhren k√∂nnen. <br><br><h4>  C * eins </h4><br>  So wurde das neue <b>C * One</b> DBMS geboren, das aus drei Arten von Serverknoten besteht: <br><br><ul><li>  Speicher - die (fast) Standard-Cassandra-Server, die f√ºr die Speicherung von Daten auf lokalen Laufwerken verantwortlich sind.  Wenn die Last und die Datenmenge zunehmen, kann ihre Anzahl leicht auf zehn oder Hunderte skaliert werden. </li><li>  Transaktionskoordinatoren - Aktiviert die Transaktionsausf√ºhrung. </li><li>  Clients sind Anwendungsserver, die Gesch√§ftsvorg√§nge implementieren und Transaktionen initiieren.  Es kann Tausende solcher Kunden geben. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/eb6/f4f/498/eb6f4f4983f44dcbe63cd545e87f8d1a.png"><br><br>  Alle Servertypen befinden sich in einem gemeinsamen Cluster. Verwenden Sie das interne Cassandra-Nachrichtenprotokoll, um miteinander zu kommunizieren, und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">klatschen Sie</a> , um Clusterinformationen auszutauschen.  Mithilfe von Heartbeat lernen Server gegenseitige Fehler kennen, unterst√ºtzen ein einziges Datenschema - Tabellen, deren Struktur und Replikation.  Partitionierungsschema, Clustertopologie usw. <br><br><h4>  Kunden </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/b83/9ff/971/b839ff971b0049d56d55bd309f44ae4e.png"><br><br>  Anstelle von Standardtreibern wird der Fat Client-Modus verwendet.  Ein solcher Knoten speichert keine Daten, kann jedoch als Koordinator f√ºr die Ausf√ºhrung von Abfragen fungieren, dh der Client selbst f√ºhrt die Funktion des Koordinators seiner Anforderungen aus: Er fragt Replikat-Repositorys ab und l√∂st Konflikte.  Dies ist nicht nur zuverl√§ssiger und schneller als ein Standardtreiber, der die Kommunikation mit einem Remote-Koordinator erfordert, sondern erm√∂glicht Ihnen auch die Steuerung der √úbertragung von Anforderungen.  Au√üerhalb einer auf dem Client ge√∂ffneten Transaktion werden Anforderungen an den Speicher gesendet.  Wenn der Client die Transaktion ge√∂ffnet hat, werden alle Anforderungen innerhalb der Transaktion an den Transaktionskoordinator gesendet. <br><img src="https://habrastorage.org/getpro/habr/post_images/d39/d43/483/d39d43483590319f4d49e41a25316058.png"><br><br><h2>  C * Ein Transaktionskoordinator </h2><br>  Der Koordinator ist das, was wir f√ºr C * One von Grund auf neu implementiert haben.  Er ist verantwortlich f√ºr die Verwaltung von Transaktionen, Sperren und der Reihenfolge, in der Transaktionen angewendet werden. <br><br>  F√ºr jede Transaktion, die bearbeitet wird, generiert der Koordinator einen Zeitstempel: Jede nachfolgende Transaktion ist gr√∂√üer als die vorherige Transaktion.  Da das Konfliktl√∂sungssystem in Cassandra auf Zeitstempeln basiert (von zwei widerspr√ºchlichen Datens√§tzen wird der aktuelle mit dem neuesten Zeitstempel als relevant angesehen), wird der Konflikt immer zugunsten der nachfolgenden Transaktion gel√∂st.  Daher haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lamport-Uhren</a> implementiert - eine kosteng√ºnstige M√∂glichkeit, Konflikte in einem verteilten System zu l√∂sen. <br><br><h2>  Schl√∂sser </h2><br>  Um die Isolation sicherzustellen, haben wir uns f√ºr die einfachste Methode entschieden - pessimistische Sperren f√ºr den Prim√§rschl√ºssel des Datensatzes.  Mit anderen Worten, bei einer Transaktion muss der Datensatz zuerst gesperrt, erst dann gelesen, ge√§ndert und gespeichert werden.  Erst nach einem erfolgreichen Commit kann ein Datensatz entsperrt werden, damit konkurrierende Transaktionen ihn verwenden k√∂nnen. <br><br>  Das Implementieren dieser Sperre ist in einer nicht zugewiesenen Umgebung einfach.  In einem verteilten System gibt es zwei Hauptmethoden: entweder verteilte Sperren f√ºr den Cluster implementieren oder Transaktionen verteilen, sodass Transaktionen mit einem einzelnen Datensatz immer von demselben Koordinator ausgef√ºhrt werden. <br><br>  Da in unserem Fall die Daten bereits von lokalen Transaktionsgruppen in SQL verteilt werden, wurde beschlossen, den Koordinatoren lokale Transaktionsgruppen zuzuweisen: Ein Koordinator f√ºhrt alle Transaktionen mit einem Token von 0 bis 9 aus, der zweite mit einem Token von 10 bis 19 usw.  Infolgedessen wird jede der Koordinatorinstanzen zu einem Transaktionsgruppenstamm. <br><br>  Dann k√∂nnen die Sperren als banale HashMap im Speicher des Koordinators implementiert werden. <br><br><h2>  Koordinatorfehler </h2><br>  Da ein Koordinator ausschlie√ülich eine Gruppe von Transaktionen bedient, ist es sehr wichtig, die Tatsache des Ausfalls schnell festzustellen, damit ein wiederholter Versuch, die Transaktion auszuf√ºhren, abgelaufen ist.  Um es schnell und zuverl√§ssig zu machen, haben wir ein vollst√§ndig verbundenes Quorum-Hearbeat-Protokoll angewendet: <br><br>  Jedes Rechenzentrum verf√ºgt √ºber mindestens zwei Koordinatorknoten.  In regelm√§√üigen Abst√§nden sendet jeder Koordinator eine Heartbeat-Nachricht an die anderen Koordinatoren und informiert sie √ºber deren Funktionsweise sowie √ºber die Heartbeat-Nachrichten, von denen die Koordinatoren im Cluster zum letzten Mal stammen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cde/1e4/ccd/cde1e4ccd6d23620eda08adc231aeec7.jpg"><br><br>  Nachdem jeder Koordinator √§hnliche Informationen von den anderen in der Zusammensetzung seiner Heartbeat-Nachrichten erhalten hat, entscheidet er selbst, welche Clusterknoten funktionieren und welche nicht. Dies richtet sich nach dem Quorum-Prinzip: Wenn der Knoten X von der Mehrheit der Knoten im Cluster Informationen √ºber den normalen Empfang von Nachrichten vom Knoten Y erhalten hat, dann Y funktioniert.  Umgekehrt ist Y fehlgeschlagen, sobald die Mehrheit den Verlust von Nachrichten vom Knoten Y meldet.  Es ist merkw√ºrdig, dass wenn ein Quorum dem Knoten X mitteilt, dass er keine weiteren Nachrichten von ihm empf√§ngt, sich der Knoten X selbst als fehlgeschlagen betrachtet. <br><br>  Herzschlagnachrichten werden mit einer hohen Frequenz von etwa 20 Mal pro Sekunde mit einer Dauer von 50 ms gesendet.  In Java ist es aufgrund der vergleichbaren L√§nge der vom Garbage Collector verursachten Pausen schwierig, eine Anwendungsantwort von 50 ms zu gew√§hrleisten.  Mit dem G1-Garbage Collector konnten wir eine solche Reaktionszeit erreichen, mit der wir das Ziel f√ºr die Dauer der GC-Pausen angeben k√∂nnen.  Manchmal, ziemlich selten, geht die Pause des Kollektors jedoch √ºber 50 ms hinaus, was zu einer falschen Fehlererkennung f√ºhren kann.  Um dies zu verhindern, meldet der Koordinator den Ausfall des Remote-Knotens nicht, wenn die erste Heartbeat-Nachricht von ihm verschwindet, nur wenn mehrere nacheinander verschwinden. Daher konnten wir den Knotenausfall des Koordinators in 200 ms erkennen. <br><br>  Es reicht jedoch nicht aus, schnell zu verstehen, welcher Knoten nicht mehr funktioniert.  Sie m√ºssen etwas dagegen tun. <br><br><h2>  Reservierung </h2><br>  Das klassische Schema geht davon aus, dass im Falle der Weigerung eines Meisters, eine Neuwahl mit einem der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">modischen</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">universellen</a> Algorithmen zu starten.  Solche Algorithmen weisen jedoch bekannte Probleme mit der Zeitkonvergenz und der Dauer des Wahlprozesses selbst auf.  Mit dem Ersatzschaltbild der Koordinatoren in einem vollst√§ndig verbundenen Netzwerk konnten wir solche zus√§tzlichen Verz√∂gerungen vermeiden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e90/45e/007/e9045e00777362a5846eb78ef15bedea.png"><br><br>  Angenommen, wir m√∂chten eine Transaktion in Gruppe 50 ausf√ºhren. Wir werden im Voraus ein Substitutionsschema festlegen, dh welche Knoten Transaktionen der Gruppe 50 ausf√ºhren, wenn der Hauptkoordinator ausf√§llt.  Unser Ziel ist es, das System bei einem Ausfall des Rechenzentrums betriebsbereit zu halten.  Wir bestimmen, dass die erste Reserve ein Knoten aus einem anderen Rechenzentrum ist und die zweite Reserve ein Knoten aus dem dritten.  Dieses Schema wird einmal ausgew√§hlt und √§ndert sich erst, wenn sich die Clustertopologie √§ndert, dh bis neue Knoten in das Schema eintreten (was sehr selten vorkommt).  Das Verfahren zur Auswahl eines neuen aktiven Masters bei Ausfall des alten ist immer das folgende: Die erste Reserve wird zum aktiven Master, und wenn sie nicht mehr funktioniert, wird die zweite Reserve. <br><br>  Ein solches Schema ist zuverl√§ssiger als der universelle Algorithmus, da es zur Aktivierung eines neuen Masters ausreicht, die Tatsache des Ausfalls des alten zu bestimmen. <br><br>  Aber wie werden Kunden verstehen, welcher der Master jetzt arbeitet?  F√ºr 50 ms ist es nicht m√∂glich, Informationen an Tausende von Kunden zu senden.  Eine Situation ist m√∂glich, wenn ein Client eine Anforderung zum √ñffnen einer Transaktion sendet, ohne zu wissen, dass dieser Assistent nicht mehr funktioniert, und die Anforderung nach einer Zeit√ºberschreitung h√§ngen bleibt.  Um dies zu verhindern, senden Kunden spekulativ eine Anfrage zum sofortigen √ñffnen einer Transaktion an den Gruppenmaster und seine beiden Reserven, aber nur derjenige, der derzeit der aktive Master ist, wird diese Anfrage beantworten.  Der Client f√ºhrt die gesamte nachfolgende Kommunikation innerhalb der Transaktion nur mit dem aktiven Master durch. <br><br>  Die Sicherungsmaster erhalten Anforderungen f√ºr nicht eigene Transaktionen in der Warteschlange ungeborener Transaktionen, wo sie f√ºr einige Zeit gespeichert werden.  Wenn der aktive Master stirbt, verarbeitet der neue Master Anforderungen zum √ñffnen von Transaktionen aus seiner Warteschlange und antwortet dem Client.  Wenn es dem Client bereits gelungen ist, eine Transaktion mit dem alten Master zu √∂ffnen, wird die zweite Antwort ignoriert (und eine solche Transaktion wird offensichtlich nicht abgeschlossen und vom Client wiederholt). <br><br><h2>  Wie eine Transaktion funktioniert </h2><br>  Angenommen, ein Client hat einem Koordinator eine Anforderung zum √ñffnen einer Transaktion f√ºr eine solche Entit√§t mit einem solchen Prim√§rschl√ºssel gesendet.  Der Koordinator sperrt diese Entit√§t und legt sie in der Sperrtabelle im Speicher ab.  Bei Bedarf liest der Koordinator diese Entit√§t aus dem Speicher und speichert die empfangenen Daten in einem Transaktionsstatus im Speicher des Koordinators. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4d1/dfb/dcd/4d1dfbdcd92e4b05ca49ef5168177eb8.png"><br><br>  Wenn der Client die Daten in der Transaktion √§ndern m√∂chte, sendet er dem Koordinator eine Anforderung zum Aktualisieren der Entit√§t und legt die neuen Daten in der Transaktionsstatustabelle im Speicher ab.  Damit ist die Aufzeichnung abgeschlossen - die Aufzeichnung wird nicht im Repository durchgef√ºhrt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/00e/803/570/00e803570a0fbe19cb76786cbc6f0142.png"><br><br>  Wenn ein Client im Rahmen einer aktiven Transaktion seine eigenen ge√§nderten Daten anfordert, verh√§lt sich der Koordinator folgenderma√üen: <br><br><ul><li>  Befindet sich die ID bereits in der Transaktion, werden die Daten aus dem Speicher entnommen. </li><li>  Wenn sich keine ID im Speicher befindet, werden die fehlenden Daten von den Speicherknoten gelesen und mit den bereits im Speicher befindlichen Daten kombiniert. Das Ergebnis wird an den Client zur√ºckgegeben. </li></ul><br>  Somit kann der Client seine eigenen √Ñnderungen lesen, w√§hrend andere Clients diese √Ñnderungen nicht sehen, da sie nur im Speicher des Koordinators gespeichert sind und sich noch nicht in Cassandra-Knoten befinden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8e/140/5f7/d8e1405f7995228ec3d061af59f1f685.png"><br><br>  Wenn der Client ein Commit sendet, wird der Status im Speicher des Dienstes vom Koordinator im protokollierten Stapel gespeichert und bereits in Form eines protokollierten Stapels an die Cassandra-Repositorys gesendet.  Repositorys tun alles, damit dieses Paket atomar (vollst√§ndig) angewendet werden kann, und senden eine Antwort an den Koordinator zur√ºck, der die Sperren aufhebt und dem Client den Erfolg der Transaktion best√§tigt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/090/739/9fc/0907399fc025879f16174ff26163a937.png"><br><br>  Um zum Koordinator zur√ºckzukehren, reicht es aus, den vom Status der Transaktion belegten Speicher freizugeben. <br><br>  Als Ergebnis der oben genannten Verbesserungen haben wir die Prinzipien von ACID implementiert: <br><br><ul><li>  <b>Atomizit√§t</b> .  Dies ist eine Garantie daf√ºr, dass keine Transaktion teilweise an das System gebunden wird, alle Unteroperationen abgeschlossen werden oder keine einzige ausgef√ºhrt wird.  Wir halten uns aufgrund der protokollierten Charge in Cassandra an dieses Prinzip. </li><li>  <b>Konsistenz.</b>  Jede erfolgreiche Transaktion erfasst per Definition nur akzeptable Ergebnisse.  Wenn nach dem √ñffnen einer Transaktion und dem Ausf√ºhren eines Teils der Vorg√§nge festgestellt wird, dass das Ergebnis nicht g√ºltig ist, wird ein Rollback durchgef√ºhrt. </li><li>  <b>Isolierung</b> .  Wenn eine Transaktion ausgef√ºhrt wird, sollten parallele Transaktionen das Ergebnis nicht beeinflussen.  Konkurrierende Transaktionen werden mithilfe pessimistischer Sperren des Koordinators isoliert.  Bei Lesevorg√§ngen au√üerhalb der Transaktion wird das Prinzip der Isolation auf der Ebene Read Committed eingehalten. </li><li>  <b>Nachhaltigkeit</b> .  Unabh√§ngig von den Problemen auf den unteren Ebenen - Systemabschaltung, Hardwarefehler - m√ºssen √Ñnderungen, die durch eine erfolgreich abgeschlossene Transaktion vorgenommen wurden, nach Wiederaufnahme des Betriebs gespeichert bleiben. </li></ul><br><h2>  Index lesen </h2><br>  Nehmen Sie einen einfachen Tisch: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> photos ( id <span class="hljs-type"><span class="hljs-type">bigint</span></span> <span class="hljs-keyword"><span class="hljs-keyword">primary key</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">owner</span></span> <span class="hljs-type"><span class="hljs-type">bigint</span></span>, modified <span class="hljs-type"><span class="hljs-type">timestamp</span></span>, ‚Ä¶)</code> </pre> <br>  Sie hat eine ID (Prim√§rschl√ºssel), einen Eigent√ºmer und ein √Ñnderungsdatum.  Sie m√ºssen eine sehr einfache Anfrage stellen - w√§hlen Sie die Daten des Eigent√ºmers mit dem √Ñnderungsdatum "f√ºr den letzten Tag" aus. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> owner=? <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> modified&gt;?</code> </pre> <br>  Damit eine solche Abfrage schnell funktioniert, m√ºssen Sie in klassischem SQL-DBMS einen Index nach Spalten erstellen (Eigent√ºmer, ge√§ndert).  Wir k√∂nnen das ganz einfach machen, da wir jetzt ACID-Garantien haben! <br><br><h2>  Indizes in C * One </h2><br>  Es gibt eine Quelltabelle mit Fotos, in der die Datensatz-ID der Prim√§rschl√ºssel ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/039/5b3/a78/0395b3a784329992b88ba0618a94a7f1.jpg"><br><br>  F√ºr den C * -Index erstellt One eine neue Tabelle, die eine Kopie des Originals ist.  Der Schl√ºssel entspricht dem Indexausdruck und enth√§lt auch den Prim√§rschl√ºssel des Datensatzes aus der Quelltabelle: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/92a/8c2/93e/92a8c293e8c145dc37f49a5126e68095.jpg"><br><br>  Jetzt kann die Anfrage nach dem "Eigent√ºmer f√ºr den letzten Tag" als Auswahl aus einer anderen Tabelle umgeschrieben werden: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> i1_test <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> owner=? <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> modified&gt;?</code> </pre> <br>  Die Konsistenz der Daten aus der Originalfototabelle und dem Index i1 wird vom Koordinator automatisch beibehalten.  Allein basierend auf dem Datenschema generiert und speichert der Koordinator die √Ñnderung beim Empfang der √Ñnderung nicht nur in der Haupttabelle, sondern auch in den Kopier√§nderungen.  Mit der Indextabelle werden keine zus√§tzlichen Aktionen ausgef√ºhrt, Protokolle werden nicht gelesen, Sperren werden nicht verwendet.  Das hei√üt, das Hinzuf√ºgen von Indizes verbraucht fast keine Ressourcen und hat praktisch keinen Einfluss auf die Geschwindigkeit, mit der √Ñnderungen angewendet werden. <br><br>  Mit ACID konnten wir Indizes ‚Äûwie in SQL‚Äú implementieren.  Sie sind konsistent, k√∂nnen skaliert werden, schnell arbeiten, zusammengesetzt und in die CQL-Abfragesprache integriert werden.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um Indizes zu unterst√ºtzen, m√ºssen Sie keine √Ñnderungen am Anwendungscode vornehmen. </font><font style="vertical-align: inherit;">Alles ist einfach wie in SQL. </font><font style="vertical-align: inherit;">Und am wichtigsten ist, dass Indizes die Ausf√ºhrungsgeschwindigkeit von √Ñnderungen an der urspr√ºnglichen Transaktionstabelle nicht beeinflussen.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Was ist passiert? </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben C * One vor drei Jahren entwickelt und in Betrieb genommen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was haben wir am Ende bekommen? Lassen Sie uns dies am Beispiel eines Subsystems zum Verarbeiten und Speichern von Fotos bewerten, einer der wichtigsten Arten von Daten in einem sozialen Netzwerk. Es geht nicht um die K√∂rper der Fotos selbst, sondern um alle Arten von Metainformationen. In Odnoklassniki gibt es derzeit etwa 20 Milliarden solcher Datens√§tze. Das System verarbeitet 80.000 Leseanforderungen pro Sekunde und bis zu 8.000 ACID-Transaktionen pro Sekunde, die mit Daten√§nderungen verbunden sind. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bei Verwendung von SQL mit Replikationsfaktor = 1 (jedoch in RAID 10) wurden die Foto-Metainformationen auf einem gut zug√§nglichen Cluster von 32 Computern mit Microsoft SQL Server (plus 11 Sicherungen) gespeichert. Au√üerdem wurden 10 Server zum Speichern von Sicherungen zugewiesen. Insgesamt 50 teure Autos. Gleichzeitig arbeitete das System ohne Reserve bei Nennlast.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nach der Migration auf das neue System haben wir den Replikationsfaktor = 3 erhalten - eine Kopie in jedem Rechenzentrum. Das System besteht aus 63 Cassandra-Speicherknoten und 6 Koordinatormaschinen mit insgesamt 69 Servern. Diese Maschinen sind jedoch viel billiger. Ihre Gesamtkosten betragen etwa 30% der Systemkosten in SQL. In diesem Fall wird die Last bei 30% gehalten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit der Einf√ºhrung von C * One nahmen auch die Verz√∂gerungen ab: In SQL dauerte der Schreibvorgang etwa 4,5 ms. In C * One - ungef√§hr 1,6 ms. Die Transaktionsdauer betr√§gt durchschnittlich weniger als 40 ms, das Festschreiben erfolgt in 2 ms, die Lese- und Schreibdauer betr√§gt durchschnittlich 2 ms. Das 99. Perzentil - nur 3-3,1 ms, die Anzahl der Zeit√ºberschreitungen verringerte sich um das 100-fache - alles aufgrund der weit verbreiteten Verwendung von Spekulationen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bisher wurden die meisten SQL Server-Knoten au√üer Betrieb genommen, neue Produkte werden nur mit C * One entwickelt. </font><font style="vertical-align: inherit;">Wir haben C * One f√ºr die Arbeit in unserer </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One-Cloud</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> angepasst </font><font style="vertical-align: inherit;">, wodurch wir die Bereitstellung neuer Cluster beschleunigen, die Konfiguration vereinfachen und den Betrieb automatisieren konnten. </font><font style="vertical-align: inherit;">Ohne Quellcode w√§re es viel schwieriger und kr√ºckenherstellender. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt arbeiten wir daran, unsere anderen Speichereinrichtungen in die Cloud zu √ºbertragen - aber das ist eine ganz andere Geschichte.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de417593/">https://habr.com/ru/post/de417593/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de417583/index.html">Morgen ICFP Contest 2018, Prost! (+ n√ºtzlich f√ºr die erstmalige Teilnahme)</a></li>
<li><a href="../de417585/index.html">Wie komme ich in das Programmkomitee einer Klassenkonferenz und warum brauchst du es?</a></li>
<li><a href="../de417587/index.html">Medien: Cyberangriffe in gro√üem Ma√üstab beschleunigten das Wachstum der Kapitalisierung von Unternehmen aus der Informationssicherheitsbranche</a></li>
<li><a href="../de417589/index.html">Sieben einfache Regeln, um das Internet f√ºr alle zug√§nglich zu machen</a></li>
<li><a href="../de417591/index.html">Wie man Englisch in einem Jahr alleine "lernt" oder einen Artikel f√ºr diejenigen, die nicht mit Englisch gearbeitet haben</a></li>
<li><a href="../de417595/index.html">Antiquit√§ten: Palm OS, effizienter Code und ekelhafte Fotos</a></li>
<li><a href="../de417597/index.html">Vertrauensw√ºrdiger Speicher mit DRBD9 und Proxmox (Teil 2: iSCSI + LVM)</a></li>
<li><a href="../de417599/index.html">Fintech Digest: Finanzaufsichtsbeh√∂rden ben√∂tigen KI, um unter modernen Bedingungen arbeiten zu k√∂nnen</a></li>
<li><a href="../de417601/index.html">W√§hlen Sie einen Server. Was ist zu suchen? Checkliste</a></li>
<li><a href="../de417603/index.html">Ank√ºndigung eines mobilen Mitaps: Was tun, wenn die Anwendung gro√ü geworden ist?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
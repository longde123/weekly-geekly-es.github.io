<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ò£Ô∏è üçç ü§• Equilibrio de tr√°fico VoIP tolerante a fallas. Cambio de carga entre centros de datos en la hora pico üîº üë®üèΩ‚Äçüíª üçã</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Algunas palabras sobre lo que hacemos. DINS est√° involucrado en el desarrollo y soporte del servicio UCaaS en el mercado internacional para clientes c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Equilibrio de tr√°fico VoIP tolerante a fallas. Cambio de carga entre centros de datos en la hora pico</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dins/blog/436404/"><p>  Algunas palabras sobre lo que hacemos.  DINS est√° involucrado en el desarrollo y soporte del servicio UCaaS en el mercado internacional para clientes corporativos.  El servicio lo utilizan tanto peque√±as empresas como nuevas empresas, y grandes empresas.  Los clientes se conectan a trav√©s de Internet a trav√©s del protocolo SIP a trav√©s de TCP, TLS o WSS.  Esto crea una carga bastante grande: casi 1,5 millones de conexiones desde dispositivos finales: tel√©fonos Polycom / Cisco / Yealink y clientes de software para PC / Mac / IOS / Android. </p><br><p>  En este art√≠culo, hablo sobre c√≥mo se organizan los puntos de entrada VoIP. </p><a name="habracut"></a><br><h3 id="predystoriya">  Antecedentes </h3><br><p>  En el per√≠metro del sistema (entre los dispositivos terminales y el n√∫cleo) se encuentran los SBC comerciales (Controlador de borde de sesi√≥n). </p><br><p>  Desde 2012, hemos estado utilizando soluciones de Acme Packet, que luego adquiri√≥ Oracle.  Antes de eso, usamos NatPASS. </p><br><p>  Enumere brevemente la funcionalidad que utilizamos: </p><br><p>  ‚Ä¢ transversal NAT; <br>  ‚Ä¢ B2BUA; <br>  ‚Ä¢ Normalizaci√≥n SIP (encabezados permitidos / no permitidos, reglas de manipulaci√≥n de encabezados, etc.) <br>  ‚Ä¢ Descarga de TLS y SRTP; <br>  ‚Ä¢ Conversi√≥n de transporte (dentro del sistema usamos SIP sobre UDP); <br>  ‚Ä¢ Monitoreo MOS (a trav√©s de RTCP-XR); <br>  ‚Ä¢ ACL, detecci√≥n de fuerza bruta; <br>  ‚Ä¢ Tr√°fico de registro reducido debido al aumento de la caducidad del contacto (bajo vencimiento en el lado de acceso, alto en el lado central); <br>  ‚Ä¢ Aceleraci√≥n de mensajes SIP por m√©todo. </p><br><p> Los sistemas comerciales tienen sus ventajas obvias (funcionalidad lista para usar, soporte comercial) y desventajas (precio, tiempo de entrega, falta de oportunidades o plazos demasiado largos para implementar las nuevas funciones que necesitamos, plazos para resolver problemas, etc.).  Poco a poco, los defectos comenzaron a ser superados, y se hizo evidente que era necesario desarrollar nuestras propias soluciones. </p><br><p>  El desarrollo se lanz√≥ hace un a√±o y medio.  En el subsistema de frontera, tradicionalmente distinguimos 2 componentes principales: SIP y servidores de medios;  equilibradores de carga sobre cada componente.  Estoy trabajando en puntos de entrada / equilibradores aqu√≠, as√≠ que intentar√© hablar sobre ellos. </p><br><h4 id="trebovaniya">  Requisitos </h4><br><ul><li>  Tolerancia a fallas: el sistema debe proporcionar un servicio en caso de falla de una o m√°s instancias en el centro de datos o en todo el centro de datos </li><li>  Facilidad de servicio: queremos poder cambiar cargas de un centro de datos a otro </li><li>  Escalabilidad: quiero aumentar la capacidad de forma r√°pida y econ√≥mica </li></ul><br><h4 id="balansirovka">  Equilibrio </h4><br><p>  Seleccionamos IPVS (tambi√©n conocido como LVS) en modo IPIP (t√∫nel de tr√°fico).  No entrar√© en un an√°lisis comparativo de NAT / DR / TUN / L3DSR, (puede leer sobre los modos, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ), solo mencionar√© las razones: </p><br><ul><li>  No queremos imponer a los backends el requisito de estar en la misma subred que LVS (los pools contienen backends de nuestros propios y remotos centros de datos); </li><li>  El servidor debe recibir la IP de origen original del cliente (o su NAT), en otras palabras, la fuente de NAT no es adecuada; </li><li>  El backend debe admitir el trabajo simult√°neo con varios VIP. </li></ul><br><p>  Estamos equilibrando el tr√°fico de medios (result√≥ ser muy dif√≠cil, lo vamos a rechazar), por lo que el esquema de implementaci√≥n actual en el centro de datos es el siguiente: <br><br><img src="https://habrastorage.org/webt/fk/vh/wg/fkvhwgftogjrev-a931o3a9qk-e.png"><br><br>  La estrategia actual de equilibrio de IPVS es "sed" (retraso m√°s corto esperado), m√°s sobre eso.  A diferencia de Weighted Round Robin / Weighted Least-Connection, le permite no transferir tr√°fico a backends con pesos m√°s bajos hasta que se alcanza un cierto umbral.  El retraso esperado m√°s corto se calcula utilizando la f√≥rmula (Ci + 1) / Ui, donde Ci es el n√∫mero de conexiones en el backend i, Ui es el peso del backend.  Por ejemplo, si hay backends en el grupo con pesos de 50,000 y 2, las conexiones nuevas ser√°n distribuidas por los primeros hasta que cada servidor alcance las 25,000 conexiones o hasta que se alcance el umbral, un l√≠mite en el n√∫mero total de conexiones. <br>  Lea m√°s sobre estrategias de equilibrio en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">man ipvsadm</a> . </p><br><p>  El conjunto de IPVS tiene este aspecto (aqu√≠ y a continuaci√≥n, se enumeran las direcciones IP ficticias): </p><br><pre><code class="plaintext hljs"># ipvsadm -ln Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 1.1.1.1:5060 sed -&gt; 10.11.100.181:5060 Tunnel 50000 5903 4 -&gt; 10.11.100.192:5060 Tunnel 50000 5905 1 -&gt; 10.12.100.137:5060 Tunnel 2 0 0 -&gt; 10.12.100.144:5060 Tunnel 2 0 0</code> </pre> <br><p>  La carga en el VIP se distribuye a servidores con un peso de 50,000 (se implementan en el mismo centro de datos que una instancia espec√≠fica de LVS), si se sobrecargan o entran en una lista negra, la carga ir√° a la parte de respaldo del grupo: servidores con un peso de 2, que se encuentran en centro de datos vecino. </p><br><p>  Exactamente el mismo grupo, pero con escalas, por el contrario, est√° configurado en el centro de datos vecino (en el sistema de producci√≥n, el n√∫mero de backends, por supuesto, es mucho mayor). </p><br><p>  La sincronizaci√≥n de conexiones a trav√©s de la sincronizaci√≥n de ipvs permite que el LVS de respaldo conozca todas las conexiones actuales. </p><br><p>  Para la sincronizaci√≥n entre centros de datos, se aplic√≥ una t√©cnica "sucia", que sin embargo funciona bien.  La sincronizaci√≥n IPVS funciona solo a trav√©s de multidifusi√≥n, lo que nos result√≥ dif√≠cil entregar correctamente a la DC vecina.  En lugar de multidifusi√≥n, duplicamos el tr√°fico de sincronizaci√≥n a trav√©s del TEE objetivo de iptables desde el maestro ipvs al t√∫nel ip-ip al servidor en el DC vecino, y puede haber varios hosts / centros de datos objetivo: </p><br><pre> <code class="plaintext hljs">#### start ipvs sync master role: ipvsadm --start-daemon master --syncid 10 --sync-maxlen 1460 --mcast-interface sync01 --mcast-group 224.0.0.81 --mcast-port 8848 --mcast-ttl 1 #### duplicate all sync packets to remote LVS servers using iptables TEE target: iptables -t mangle -A POSTROUTING -d 224.0.0.81/32 -o sync01 -j TEE --gateway 172.20.21.10 # ip-ip remote lvs server 1 iptables -t mangle -A POSTROUTING -d 224.0.0.81/32 -o sync01 -j TEE --gateway 172.20.21.14 # ip-ip remote lvs server 2 #### start ipvs sync backup role: ipvsadm --start-daemon backup --syncid 10 --sync-maxlen 1460 --mcast-interface sync01 --mcast-group 224.0.0.81 --mcast-port 8848 --mcast-ttl 1 #### be ready to receive sync sync packets from remote LVS servers: iptables -t mangle -A PREROUTING -d 224.0.0.81/32 -i loc02_srv01 -j TEE --gateway 127.0.0.1 iptables -t mangle -A PREROUTING -d 224.0.0.81/32 -i loc02_srv02 -j TEE --gateway 127.0.0.1</code> </pre> <br><p>  De hecho, cada uno de nuestros servidores LVS desempe√±a ambos roles a la vez (maestro y respaldo), por un lado, es conveniente, ya que elimina el cambio de rol al cambiar el tr√°fico, por el otro es necesario, ya que cada DC procesa su tr√°fico grupal de manera predeterminada VIP p√∫blicos. </p><br><h4 id="pereklyuchenie-nagruzki-mezhdu-data-centrami">  Cambio de carga entre centros de datos </h4><br><p>  En funcionamiento normal, cada direcci√≥n IP p√∫blica se anuncia en Internet desde cualquier lugar (en este diagrama, desde dos centros de datos).  El tr√°fico entrante al VIP se enruta al DC que necesitamos en este momento utilizando el atributo BGP MED (Discriminador de salida m√∫ltiple) con diferentes valores para DC activo y DC de respaldo.  Al mismo tiempo, Backup DC siempre est√° listo para aceptar tr√°fico si algo le sucede al activo: <br><br><img src="https://habrastorage.org/webt/ir/s6/ht/irs6htkfhrve2zzevsl0cwcg4k4.png"><br><br>  Al cambiar los valores de los BGP MED y usar la sincronizaci√≥n IPVS entre ubicaciones, tenemos la oportunidad de transferir sin problemas el tr√°fico de los servidores de un centro de datos a otro, sin afectar las llamadas telef√≥nicas establecidas, que tarde o temprano terminar√°n naturalmente.  El proceso est√° completamente automatizado (para cada VIP tenemos un bot√≥n en la consola de administraci√≥n), y se ve as√≠: </p><br><ol><li><p>  SIP-VIP est√° activo en DC1 (izquierda), el cl√∫ster en DC2 (derecha) es redundante, gracias a la sincronizaci√≥n ipvs, tiene informaci√≥n sobre las conexiones establecidas en su memoria.  A la izquierda, los VIP activos se anuncian con un valor de MED 100, a la derecha, con un valor de 500: <br><br><img src="https://habrastorage.org/webt/v6/di/th/v6dithpguub8rbq7ggurj_vdlxi.png"></p><br></li><li><p>  El bot√≥n de cambio provoca un cambio en el llamado  "Target_state" (un concepto interno que declara los valores de BGP MED en un momento dado).  Aqu√≠ no esperamos que DC1 est√© en orden y listo para procesar el tr√°fico, por lo tanto, LVS en DC2 entra en el estado de "fuerza activa", lo que reduce el valor de MED a 50 y arrastra el tr√°fico sobre s√≠ mismo.  Si los backends en DC1 est√°n activos y disponibles, las llamadas no se interrumpir√°n.  Todas las nuevas conexiones TCP (registros) se enviar√°n a backends en DC2: <br><br><img src="https://habrastorage.org/webt/lx/zo/cb/lxzocb7gt-zzrznicu5k9hiju2k.png"></p><br></li><li><p>  DC1 recibi√≥ una nueva replicaci√≥n target_state y estableci√≥ el valor de respaldo MEDs (500).  Cuando DC2 se entera de esto, normaliza su valor (50 =&gt; 100).  Queda por esperar la finalizaci√≥n de todas las llamadas activas en DC1 y romper las conexiones tcp establecidas.  Las instancias de SBC en DC1 introducen los servicios necesarios en el llamado  Estado de "apagado correcto": "503" responde a las siguientes solicitudes SIP y se desconecta, pero no acepta nuevas conexiones.  Adem√°s, estas instancias entran en la lista negra en LVS.  Cuando se rompe, el cliente establece un nuevo registro / conexi√≥n, que ya viene en DC2: <br><br><img src="https://habrastorage.org/webt/by/rq/uf/byrquf_81kp8zvvryrrjzdtcl-a.png"></p><br></li><li><p>  El proceso finaliza cuando todo el tr√°fico en DC2. <br><br><img src="https://habrastorage.org/webt/1m/dm/h8/1mdmh8styniixoof0cragfatdqq.png"></p><br></li><li><p>  DC1 y DC2 cambiaron roles. <br><br><img src="https://habrastorage.org/webt/wu/t3/ts/wut3ts2mq5iznucnkesz2r3mnra.png"></p><br></li></ol><br><p>  En condiciones de alta carga constante en los puntos de entrada, result√≥ ser muy conveniente poder cambiar el tr√°fico en cualquier momento.  El mismo mecanismo se inicia autom√°ticamente si la copia de seguridad DC de repente comienza a recibir tr√°fico.  Al mismo tiempo, para proteger contra el aleteo, la conmutaci√≥n se activa solo una vez en una direcci√≥n y el bloqueo se establece en conmutaci√≥n autom√°tica, para eliminarlo, se requiere intervenci√≥n humana. </p><br><h4 id="chto-vnutri">  Que hay dentro </h4><br><p>  Cl√∫ster VRRP y administrador de IPVS: Keepalived.  Keepalived es responsable de cambiar los VIP dentro del cl√∫ster, as√≠ como tambi√©n de la revisi√≥n / lista negra del estado del backends. </p><br><p>  Pila BGP: ExaBGP.  Es responsable de los anuncios de rutas a direcciones VIP y de la colocaci√≥n de los correspondientes BGP MED.  Totalmente controlado por el servidor de gesti√≥n.  Un demonio BGP confiable escrito en Python se est√° desarrollando activamente; realiza su tarea al 100%. </p><br><p>  Servidor de gesti√≥n (API / Monitoreo / gesti√≥n de subcomponentes): Pyro4 + Flask.  Es un servidor de aprovisionamiento para Keepalived y ExaBGP, administra todas las dem√°s configuraciones del sistema (sysctl / iptables / ipset / etc), proporciona monitoreo (gnlpy), agrega y elimina backends a pedido (se comunican con su API). </p><br><h4 id="cifry">  Figuras </h4><br><p>  Una m√°quina virtual con cuatro n√∫cleos Intel Xeon Gold 6140 CPU @ 2.30GHz sirve un flujo de tr√°fico de 300Mbps / 210Kpps (a trav√©s de ellos se procesan aproximadamente 3 mil llamadas simult√°neas en hora pico).  Utilizaci√≥n de la CPU al mismo tiempo: 60%. </p><br><p>  Ahora esto es suficiente para atender el tr√°fico de hasta 100 mil dispositivos terminales (tel√©fonos de escritorio).  Para atender todo el tr√°fico (m√°s de 1 mill√≥n de dispositivos terminales), estamos construyendo alrededor de 10 pares de dichos grupos en varios centros de datos. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436404/">https://habr.com/ru/post/es436404/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436392/index.html">Beneficios de analizar aplicaciones de nivel 7 en firewalls. Parte 1. Conceptos b√°sicos</a></li>
<li><a href="../es436394/index.html">Demis Hassabis: el gran intelecto que cre√≥ el gran intelecto</a></li>
<li><a href="../es436396/index.html">¬øPuedo usar la programaci√≥n funcional en mi lenguaje?</a></li>
<li><a href="../es436398/index.html">Agua</a></li>
<li><a href="../es436400/index.html">Configure el entorno de desarrollo para aprender HTML, CSS, PHP en Windows</a></li>
<li><a href="../es436406/index.html">C√≥mo convertirte en desarrollador de juegos si eres un agente de bienes ra√≠ces</a></li>
<li><a href="../es436408/index.html">Modelado num√©rico: la historia de un proyecto</a></li>
<li><a href="../es436412/index.html">Recorrido fotogr√°fico por la nueva oficina de Facebook de Boston</a></li>
<li><a href="../es436416/index.html">Migrar de Mongo a Postgres: la experiencia del peri√≥dico The Guardian</a></li>
<li><a href="../es436420/index.html">El vertedero m√°s grande de la historia: 2.700 millones de cuentas, de las cuales 773 millones son √∫nicas.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
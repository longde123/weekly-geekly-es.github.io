<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤴 💅🏿 🤦🏾 Tiefes Ranking für den Vergleich zweier Bilder 🛩️ 😦 🤜</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Ich präsentiere Ihnen die Übersetzung des Artikels „ Bildähnlichkeit mit Deep Ranking“ von Akarsh Zingade. 

 Deep-Ranking-Algorithmus 
 D...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tiefes Ranking für den Vergleich zweier Bilder</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457928/">  Hallo Habr!  Ich präsentiere Ihnen die Übersetzung des Artikels <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">„</a> Bildähnlichkeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mit Deep Ranking“</a> von Akarsh Zingade. <br><br><h2>  Deep-Ranking-Algorithmus </h2><br>  Das Konzept der " <i>Ähnlichkeit der beiden Bilder</i> " wurde nicht eingeführt, daher wollen wir dieses Konzept zumindest im Rahmen des Artikels einführen. <br><br>  <b>Die Ähnlichkeit zweier Bilder</b> ergibt sich aus dem Vergleich zweier Bilder nach bestimmten Kriterien.  Sein quantitatives Maß bestimmt den Ähnlichkeitsgrad zwischen den Intensitätsdiagrammen zweier Bilder.  Unter Verwendung eines Ähnlichkeitsmaßes werden einige Merkmale, die die Bilder beschreiben, verglichen.  Als Maß für die Ähnlichkeit die Hamming-Distanz, die euklidische Distanz, die Manhattan-Distanz usw. <br><a name="habracut"></a><br>  <b>Deep Ranking</b> - Untersucht die feinkörnige Bildähnlichkeit und charakterisiert das feinteilige Bildähnlichkeitsverhältnis mithilfe eines Satzes von Tripletts. <br><br><h3>  Was ist ein Triplett? </h3><br>  Das Triplett enthält das Anforderungsbild, das positive und das negative Bild.  Wo ein positives Bild eher einem Anforderungsbild als einem negativen ähnelt. <br><br>  <b>Ein Beispiel für eine Reihe von Drillingen:</b> <br><br><img src="https://cdn-images-1.medium.com/max/1000/0*vw4M7uZ5exyLZfLv." alt="Bild"><br><br>  Die erste, zweite und dritte Zeile entspricht dem Bild der Anfrage.  Die zweite Zeile (positive Bilder) ähnelt eher Anforderungsbildern als die dritte (negative Bilder). <br><br><h3>  Deep Ranking Netzwerkarchitektur </h3><br>  Das Netzwerk besteht aus 3 Teilen: Triplett-Abtastung, ConvNet und einer Rangfolge. <br>  Das Netzwerk akzeptiert Tripletts von Bildern als Eingabe.  Ein Bildtriplett enthält ein Anforderungsbild <math> </math> $ inline $ p_i $ inline $   positives Bild <math> </math> $ inline $ p_i ^ + $ inline $   und negatives Bild <math> </math> $ inline $ p_i ^ - $ inline $   die unabhängig voneinander an drei identische tiefe neuronale Netze übertragen werden. <br><br>  Die oberste Rangschicht - bewertet die Triplettverlustfunktion.  Dieser Fehler wird in den unteren Schichten korrigiert, um die Verlustfunktion zu minimieren. <br><img src="https://cdn-images-1.medium.com/max/1000/0*ICR1FjUFC8xHXoh1." alt="Bild"><br><br>  Schauen wir uns nun die mittlere Schicht genauer an: <br><br><img src="https://cdn-images-1.medium.com/max/1000/0*tOd5HC3R-kFqobpM." alt="Bild"><br><br>  ConvNet kann ein beliebiges tiefes neuronales Netzwerk sein (in diesem Artikel wird eine der Implementierungen des Faltungs-neuronalen Netzwerks VGG16 erläutert).  ConvNet enthält Faltungsschichten, eine maximale Poolschicht, lokale Normalisierungsschichten und vollständig verbundene Schichten. <br>  Die anderen beiden Teile empfangen Bilder mit einer reduzierten Abtastrate und führen die Faltungsstufe und das maximale Pooling durch.  Dann findet die Normalisierungsstufe der drei Teile statt und am Ende werden sie mit einer linearen Schicht mit anschließender Normalisierung kombiniert. <br><br><h3>  Triplettbildung </h3><br>  Es gibt verschiedene Möglichkeiten, eine Triplett-Datei zu erstellen, z. B. eine Expertenbewertung.  In diesem Artikel wird jedoch der folgende Algorithmus verwendet: <br><br><ol><li>  Jedes Bild in der Klasse bildet ein Anforderungsbild. </li><li>  Jedes Bild mit Ausnahme des Anforderungsbildes bildet ein positives Bild.  Sie können jedoch die Anzahl der positiven Bilder für jede Bildanforderung begrenzen </li><li>  Ein negatives Bild wird zufällig aus einer Klasse ausgewählt, die keine Anforderungsbildklasse ist </li></ol><br><h3>  Triplettverlustfunktion </h3><br>  Ziel ist es, eine Funktion zu trainieren, die den ähnlichsten Bildern einen kleinen und den verschiedenen Bildern einen großen Abstand zuweist.  Dies kann ausgedrückt werden als: <br><img src="https://cdn-images-1.medium.com/max/1000/0*kC_DghyAeP7ulsGL." alt="Bild"><br>  Wobei <b>l</b> der Verlustkoeffizient für Tripletts ist, ist <b>g</b> der Spaltkoeffizient zwischen dem Abstand zwischen zwei Bildpaaren: <math> </math> $ inline $ p_i $ inline $   , <math> </math> $ inline $ p_i ^ + $ inline $   ) und ( <math> </math> $ inline $ p_i $ inline $   , <math> </math> $ inline $ p_i ^ - $ inline $   ), <b>f</b> - Einbettungsfunktion, die das Bild in einem Vektor anzeigt, <math> </math> $ inline $ p_i $ inline $   Ist das Bild der Anfrage, <math> </math> $ inline $ p_i ^ + $ inline $   Ist ein positives Bild, <math> </math> $ inline $ p_i ^ - $ inline $   Ist ein negatives Bild und <b>D</b> ist der euklidische Abstand zwischen zwei euklidischen Punkten. <br><br><h3>  Implementierung eines Deep Ranking-Algorithmus </h3><br>  Implementierung mit Keras. <br><br>  Drei parallele Netzwerke werden für Abfragen, positive und negative Bilder verwendet. <br><br>  Die Implementierung besteht aus drei Hauptteilen: <br><br><ol><li>  Implementierung von drei parallelen mehrskaligen neuronalen Netzen </li><li>  Implementierung der Verlustfunktion </li><li>  Triplett-Erzeugung </li></ol><br>  Das Erlernen von drei parallelen tiefen Netzwerken verbraucht viel Speicher.  Anstelle von drei parallelen tiefen Netzwerken, die ein Anforderungsbild, ein positives und ein negatives Bild empfangen, werden diese Bilder nacheinander einem tiefen neuronalen Netzwerk am Eingang eines neuronalen Netzwerks zugeführt.  Der auf die Verlustschicht übertragene Tensor enthält in jeder Zeile einen Bildanhang.  Jede Zeile entspricht jedem Eingabebild in einem Paket.  Da das Anforderungsbild, das positive Bild und das negative Bild nacheinander übertragen werden, entspricht die erste Zeile dem Anforderungsbild, die zweite dem positiven Bild und die dritte dem negativen Bild und wird dann bis zum Ende des Pakets wiederholt.  Somit erhält die Rangfolge eine Einbettung aller Bilder.  Danach wird die Verlustfunktion berechnet. <br><br>  Um die Rangfolge zu implementieren, müssen wir unsere eigene Verlustfunktion schreiben, die den euklidischen Abstand zwischen dem Anforderungsbild und dem positiven Bild sowie den euklidischen Abstand zwischen dem Anforderungsbild und dem negativen Bild berechnet. <br><br><div class="spoiler">  <b class="spoiler_title">Implementierung der Verlustberechnungsfunktion</b> <div class="spoiler_text"><pre><code class="python hljs">_EPSILON = K.epsilon() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_loss_tensor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_pred = K.clip(y_pred, _EPSILON, <span class="hljs-number"><span class="hljs-number">1.0</span></span>-_EPSILON) loss = tf.convert_to_tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>,dtype=tf.float32) <span class="hljs-comment"><span class="hljs-comment"># initialise the loss variable to zero g = tf.constant(1.0, shape=[1], dtype=tf.float32) # set the value for constant 'g' for i in range(0,batch_size,3): try: q_embedding = y_pred[i+0] # procure the embedding for query image p_embedding = y_pred[i+1] # procure the embedding for positive image n_embedding = y_pred[i+2] # procure the embedding for negative image D_q_p = K.sqrt(K.sum((q_embedding - p_embedding)**2)) # calculate the euclidean distance between query image and positive image D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2)) # calculate the euclidean distance between query image and negative image loss = (loss + g + D_q_p - D_q_n ) # accumulate the loss for each triplet except: continue loss = loss/(batch_size/3) # Average out the loss zero = tf.constant(0.0, shape=[1], dtype=tf.float32) return tf.maximum(loss,zero)</span></span></code> </pre> <br></div></div><br>  Die Paketgröße sollte immer ein Vielfaches von 3 sein. Da ein Triplett 3 Bilder enthält und Triplettbilder nacheinander übertragen werden (wir senden jedes Bild nacheinander an ein tiefes neuronales Netzwerk). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Rest des Codes ist hier</a> <br><br><div class="spoiler">  <b class="spoiler_title">Referenzliste</b> <div class="spoiler_text">  [1] Objekterkennung aus lokalen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">skalierungsinvarianten</a> Merkmalen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.cs.ubc.ca/~lowe/papers/iccv99.pdf</a> <br><br>  [2] Histogramme orientierter Gradienten für die menschliche Erkennung - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kurse.engr.illinois.edu/ece420/fa2017/hog_for_human_detection.pdf</a> <br><br>  [3] Lernen feinkörniger Bildähnlichkeit mit Deep Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">static.googleusercontent.com/media/research.google.com/de//pubs/archive/42945.pdf</a> <br><br>  [4] ImageNet-Klassifizierung mit Deep Convolutional Neural Networks- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a> <br><br>  [5] Ausfall: Ein einfacher Weg, um eine Überanpassung neuronaler Netze zu verhindern - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a> <br><br>  [6] ImageNet: Eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">umfangreiche</a> hierarchische Bilddatenbank - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.image-net.org/papers/imagenet_cvpr09.pdf</a> <br><br>  [7] Fast Multiresolution Image <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Querying-grail.cs.washington.edu/projects/query/mrquery.pdf</a> <br><br>  [8] Abrufen von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildern in</a> großem Maßstab mit komprimierten Fisher-Vektoren - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.401.9140&amp;rep=rep1&amp;type=pdf</a> <br><br>  [9] Jenseits zahlreicher Funktionen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raumpyramiden-</a> Matching zur Erkennung von Kategorien <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">natürlicher Szenen - ieeexplore.ieee.org/document/1641019</a> <br><br>  [10] Verbesserte konsistente Stichprobe, gewichteter Minhash und L1-Skizze - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">static.googleusercontent.com/media/research.google.com/de//pubs/archive/36928.pdf</a> <br><br>  [11] Online-Lernen der Bildähnlichkeit in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">großem</a> Maßstab durch Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">jmlr.csail.mit.edu/papers/volume11/chechik10a/chechik10a.pdf</a> <br><br>  [12] Lernen feinkörniger Bildähnlichkeit mit Deep Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">users.eecs.northwestern.edu/~jwa368/pdfs/deep_ranking.pdf</a> <br><br>  [13] Bildähnlichkeit mit Deep Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">medium.com/@akarshzingade/image-similarity-using-deep-ranking-c1bd83855978</a> <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457928/">https://habr.com/ru/post/de457928/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457906/index.html">Ärzte glauben, dass in naher Zukunft Geräte zur Herstellung von Impfstoffen in Haushalten und Apotheken erhältlich sein werden</a></li>
<li><a href="../de457910/index.html">WebFPGA - Verilog-Entwicklung im Browser</a></li>
<li><a href="../de457916/index.html">Die Lösung von WorldSkills-Aufgaben des Netzwerkmoduls in der Kompetenz von "CCA". Teil 2 - Grundeinstellung</a></li>
<li><a href="../de457920/index.html">Jet World: Freier freier Zugang zu den Berichten der Konferenz Joker 2018 + Überprüfung der Top Ten</a></li>
<li><a href="../de457926/index.html">Vergleich der agilen Zertifizierung, Teil 1 - ICAgile, Scrum.org, ScrumAlliance und PMI</a></li>
<li><a href="../de457930/index.html">Statisch sichere dynamische Eingabe à la Python</a></li>
<li><a href="../de457932/index.html">Analyse des IDS Bypass-Wettbewerbs an den Positive Hack Days 9</a></li>
<li><a href="../de457936/index.html">Wir laden Sie zur ersten Zabbix-Konferenz in Russland ein</a></li>
<li><a href="../de457940/index.html">Wie man in die Gegenpartei blickt</a></li>
<li><a href="../de457942/index.html">Was ich über Optimierung in Python gelernt habe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
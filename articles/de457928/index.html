<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¥ üíÖüèø ü§¶üèæ Tiefes Ranking f√ºr den Vergleich zweier Bilder üõ©Ô∏è üò¶ ü§ú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Ich pr√§sentiere Ihnen die √úbersetzung des Artikels ‚Äû Bild√§hnlichkeit mit Deep Ranking‚Äú von Akarsh Zingade. 

 Deep-Ranking-Algorithmus 
 D...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tiefes Ranking f√ºr den Vergleich zweier Bilder</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457928/">  Hallo Habr!  Ich pr√§sentiere Ihnen die √úbersetzung des Artikels <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚Äû</a> Bild√§hnlichkeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mit Deep Ranking‚Äú</a> von Akarsh Zingade. <br><br><h2>  Deep-Ranking-Algorithmus </h2><br>  Das Konzept der " <i>√Ñhnlichkeit der beiden Bilder</i> " wurde nicht eingef√ºhrt, daher wollen wir dieses Konzept zumindest im Rahmen des Artikels einf√ºhren. <br><br>  <b>Die √Ñhnlichkeit zweier Bilder</b> ergibt sich aus dem Vergleich zweier Bilder nach bestimmten Kriterien.  Sein quantitatives Ma√ü bestimmt den √Ñhnlichkeitsgrad zwischen den Intensit√§tsdiagrammen zweier Bilder.  Unter Verwendung eines √Ñhnlichkeitsma√ües werden einige Merkmale, die die Bilder beschreiben, verglichen.  Als Ma√ü f√ºr die √Ñhnlichkeit die Hamming-Distanz, die euklidische Distanz, die Manhattan-Distanz usw. <br><a name="habracut"></a><br>  <b>Deep Ranking</b> - Untersucht die feink√∂rnige Bild√§hnlichkeit und charakterisiert das feinteilige Bild√§hnlichkeitsverh√§ltnis mithilfe eines Satzes von Tripletts. <br><br><h3>  Was ist ein Triplett? </h3><br>  Das Triplett enth√§lt das Anforderungsbild, das positive und das negative Bild.  Wo ein positives Bild eher einem Anforderungsbild als einem negativen √§hnelt. <br><br>  <b>Ein Beispiel f√ºr eine Reihe von Drillingen:</b> <br><br><img src="https://cdn-images-1.medium.com/max/1000/0*vw4M7uZ5exyLZfLv." alt="Bild"><br><br>  Die erste, zweite und dritte Zeile entspricht dem Bild der Anfrage.  Die zweite Zeile (positive Bilder) √§hnelt eher Anforderungsbildern als die dritte (negative Bilder). <br><br><h3>  Deep Ranking Netzwerkarchitektur </h3><br>  Das Netzwerk besteht aus 3 Teilen: Triplett-Abtastung, ConvNet und einer Rangfolge. <br>  Das Netzwerk akzeptiert Tripletts von Bildern als Eingabe.  Ein Bildtriplett enth√§lt ein Anforderungsbild <math> </math> $ inline $ p_i $ inline $   positives Bild <math> </math> $ inline $ p_i ^ + $ inline $   und negatives Bild <math> </math> $ inline $ p_i ^ - $ inline $   die unabh√§ngig voneinander an drei identische tiefe neuronale Netze √ºbertragen werden. <br><br>  Die oberste Rangschicht - bewertet die Triplettverlustfunktion.  Dieser Fehler wird in den unteren Schichten korrigiert, um die Verlustfunktion zu minimieren. <br><img src="https://cdn-images-1.medium.com/max/1000/0*ICR1FjUFC8xHXoh1." alt="Bild"><br><br>  Schauen wir uns nun die mittlere Schicht genauer an: <br><br><img src="https://cdn-images-1.medium.com/max/1000/0*tOd5HC3R-kFqobpM." alt="Bild"><br><br>  ConvNet kann ein beliebiges tiefes neuronales Netzwerk sein (in diesem Artikel wird eine der Implementierungen des Faltungs-neuronalen Netzwerks VGG16 erl√§utert).  ConvNet enth√§lt Faltungsschichten, eine maximale Poolschicht, lokale Normalisierungsschichten und vollst√§ndig verbundene Schichten. <br>  Die anderen beiden Teile empfangen Bilder mit einer reduzierten Abtastrate und f√ºhren die Faltungsstufe und das maximale Pooling durch.  Dann findet die Normalisierungsstufe der drei Teile statt und am Ende werden sie mit einer linearen Schicht mit anschlie√üender Normalisierung kombiniert. <br><br><h3>  Triplettbildung </h3><br>  Es gibt verschiedene M√∂glichkeiten, eine Triplett-Datei zu erstellen, z. B. eine Expertenbewertung.  In diesem Artikel wird jedoch der folgende Algorithmus verwendet: <br><br><ol><li>  Jedes Bild in der Klasse bildet ein Anforderungsbild. </li><li>  Jedes Bild mit Ausnahme des Anforderungsbildes bildet ein positives Bild.  Sie k√∂nnen jedoch die Anzahl der positiven Bilder f√ºr jede Bildanforderung begrenzen </li><li>  Ein negatives Bild wird zuf√§llig aus einer Klasse ausgew√§hlt, die keine Anforderungsbildklasse ist </li></ol><br><h3>  Triplettverlustfunktion </h3><br>  Ziel ist es, eine Funktion zu trainieren, die den √§hnlichsten Bildern einen kleinen und den verschiedenen Bildern einen gro√üen Abstand zuweist.  Dies kann ausgedr√ºckt werden als: <br><img src="https://cdn-images-1.medium.com/max/1000/0*kC_DghyAeP7ulsGL." alt="Bild"><br>  Wobei <b>l</b> der Verlustkoeffizient f√ºr Tripletts ist, ist <b>g</b> der Spaltkoeffizient zwischen dem Abstand zwischen zwei Bildpaaren: <math> </math> $ inline $ p_i $ inline $   , <math> </math> $ inline $ p_i ^ + $ inline $   ) und ( <math> </math> $ inline $ p_i $ inline $   , <math> </math> $ inline $ p_i ^ - $ inline $   ), <b>f</b> - Einbettungsfunktion, die das Bild in einem Vektor anzeigt, <math> </math> $ inline $ p_i $ inline $   Ist das Bild der Anfrage, <math> </math> $ inline $ p_i ^ + $ inline $   Ist ein positives Bild, <math> </math> $ inline $ p_i ^ - $ inline $   Ist ein negatives Bild und <b>D</b> ist der euklidische Abstand zwischen zwei euklidischen Punkten. <br><br><h3>  Implementierung eines Deep Ranking-Algorithmus </h3><br>  Implementierung mit Keras. <br><br>  Drei parallele Netzwerke werden f√ºr Abfragen, positive und negative Bilder verwendet. <br><br>  Die Implementierung besteht aus drei Hauptteilen: <br><br><ol><li>  Implementierung von drei parallelen mehrskaligen neuronalen Netzen </li><li>  Implementierung der Verlustfunktion </li><li>  Triplett-Erzeugung </li></ol><br>  Das Erlernen von drei parallelen tiefen Netzwerken verbraucht viel Speicher.  Anstelle von drei parallelen tiefen Netzwerken, die ein Anforderungsbild, ein positives und ein negatives Bild empfangen, werden diese Bilder nacheinander einem tiefen neuronalen Netzwerk am Eingang eines neuronalen Netzwerks zugef√ºhrt.  Der auf die Verlustschicht √ºbertragene Tensor enth√§lt in jeder Zeile einen Bildanhang.  Jede Zeile entspricht jedem Eingabebild in einem Paket.  Da das Anforderungsbild, das positive Bild und das negative Bild nacheinander √ºbertragen werden, entspricht die erste Zeile dem Anforderungsbild, die zweite dem positiven Bild und die dritte dem negativen Bild und wird dann bis zum Ende des Pakets wiederholt.  Somit erh√§lt die Rangfolge eine Einbettung aller Bilder.  Danach wird die Verlustfunktion berechnet. <br><br>  Um die Rangfolge zu implementieren, m√ºssen wir unsere eigene Verlustfunktion schreiben, die den euklidischen Abstand zwischen dem Anforderungsbild und dem positiven Bild sowie den euklidischen Abstand zwischen dem Anforderungsbild und dem negativen Bild berechnet. <br><br><div class="spoiler">  <b class="spoiler_title">Implementierung der Verlustberechnungsfunktion</b> <div class="spoiler_text"><pre><code class="python hljs">_EPSILON = K.epsilon() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_loss_tensor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_pred = K.clip(y_pred, _EPSILON, <span class="hljs-number"><span class="hljs-number">1.0</span></span>-_EPSILON) loss = tf.convert_to_tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>,dtype=tf.float32) <span class="hljs-comment"><span class="hljs-comment"># initialise the loss variable to zero g = tf.constant(1.0, shape=[1], dtype=tf.float32) # set the value for constant 'g' for i in range(0,batch_size,3): try: q_embedding = y_pred[i+0] # procure the embedding for query image p_embedding = y_pred[i+1] # procure the embedding for positive image n_embedding = y_pred[i+2] # procure the embedding for negative image D_q_p = K.sqrt(K.sum((q_embedding - p_embedding)**2)) # calculate the euclidean distance between query image and positive image D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2)) # calculate the euclidean distance between query image and negative image loss = (loss + g + D_q_p - D_q_n ) # accumulate the loss for each triplet except: continue loss = loss/(batch_size/3) # Average out the loss zero = tf.constant(0.0, shape=[1], dtype=tf.float32) return tf.maximum(loss,zero)</span></span></code> </pre> <br></div></div><br>  Die Paketgr√∂√üe sollte immer ein Vielfaches von 3 sein. Da ein Triplett 3 Bilder enth√§lt und Triplettbilder nacheinander √ºbertragen werden (wir senden jedes Bild nacheinander an ein tiefes neuronales Netzwerk). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Rest des Codes ist hier</a> <br><br><div class="spoiler">  <b class="spoiler_title">Referenzliste</b> <div class="spoiler_text">  [1] Objekterkennung aus lokalen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">skalierungsinvarianten</a> Merkmalen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.cs.ubc.ca/~lowe/papers/iccv99.pdf</a> <br><br>  [2] Histogramme orientierter Gradienten f√ºr die menschliche Erkennung - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kurse.engr.illinois.edu/ece420/fa2017/hog_for_human_detection.pdf</a> <br><br>  [3] Lernen feink√∂rniger Bild√§hnlichkeit mit Deep Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">static.googleusercontent.com/media/research.google.com/de//pubs/archive/42945.pdf</a> <br><br>  [4] ImageNet-Klassifizierung mit Deep Convolutional Neural Networks- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a> <br><br>  [5] Ausfall: Ein einfacher Weg, um eine √úberanpassung neuronaler Netze zu verhindern - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a> <br><br>  [6] ImageNet: Eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">umfangreiche</a> hierarchische Bilddatenbank - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.image-net.org/papers/imagenet_cvpr09.pdf</a> <br><br>  [7] Fast Multiresolution Image <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Querying-grail.cs.washington.edu/projects/query/mrquery.pdf</a> <br><br>  [8] Abrufen von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildern in</a> gro√üem Ma√üstab mit komprimierten Fisher-Vektoren - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.401.9140&amp;rep=rep1&amp;type=pdf</a> <br><br>  [9] Jenseits zahlreicher Funktionen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raumpyramiden-</a> Matching zur Erkennung von Kategorien <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nat√ºrlicher Szenen - ieeexplore.ieee.org/document/1641019</a> <br><br>  [10] Verbesserte konsistente Stichprobe, gewichteter Minhash und L1-Skizze - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">static.googleusercontent.com/media/research.google.com/de//pubs/archive/36928.pdf</a> <br><br>  [11] Online-Lernen der Bild√§hnlichkeit in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gro√üem</a> Ma√üstab durch Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">jmlr.csail.mit.edu/papers/volume11/chechik10a/chechik10a.pdf</a> <br><br>  [12] Lernen feink√∂rniger Bild√§hnlichkeit mit Deep Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">users.eecs.northwestern.edu/~jwa368/pdfs/deep_ranking.pdf</a> <br><br>  [13] Bild√§hnlichkeit mit Deep Ranking- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">medium.com/@akarshzingade/image-similarity-using-deep-ranking-c1bd83855978</a> <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457928/">https://habr.com/ru/post/de457928/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457906/index.html">√Ñrzte glauben, dass in naher Zukunft Ger√§te zur Herstellung von Impfstoffen in Haushalten und Apotheken erh√§ltlich sein werden</a></li>
<li><a href="../de457910/index.html">WebFPGA - Verilog-Entwicklung im Browser</a></li>
<li><a href="../de457916/index.html">Die L√∂sung von WorldSkills-Aufgaben des Netzwerkmoduls in der Kompetenz von "CCA". Teil 2 - Grundeinstellung</a></li>
<li><a href="../de457920/index.html">Jet World: Freier freier Zugang zu den Berichten der Konferenz Joker 2018 + √úberpr√ºfung der Top Ten</a></li>
<li><a href="../de457926/index.html">Vergleich der agilen Zertifizierung, Teil 1 - ICAgile, Scrum.org, ScrumAlliance und PMI</a></li>
<li><a href="../de457930/index.html">Statisch sichere dynamische Eingabe √† la Python</a></li>
<li><a href="../de457932/index.html">Analyse des IDS Bypass-Wettbewerbs an den Positive Hack Days 9</a></li>
<li><a href="../de457936/index.html">Wir laden Sie zur ersten Zabbix-Konferenz in Russland ein</a></li>
<li><a href="../de457940/index.html">Wie man in die Gegenpartei blickt</a></li>
<li><a href="../de457942/index.html">Was ich √ºber Optimierung in Python gelernt habe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
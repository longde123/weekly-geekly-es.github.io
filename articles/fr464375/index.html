<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ…ğŸ½ ğŸ† ğŸ—ºï¸ Fonctionnement des moteurs de recherche ğŸ‘©ğŸ½ ğŸ¦„ ğŸ£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous avons triÃ© les vieilles lettres et sommes tombÃ©s sur un article Ã©crit par Ilya Segalovich iseg pour le magazine Â«World of InternetÂ» en 2002. Il y...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Fonctionnement des moteurs de recherche</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/464375/">  <i>Nous avons triÃ© les vieilles lettres et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">sommes tombÃ©s</a> sur un article Ã©crit par Ilya Segalovich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">iseg</a> pour le magazine Â«World of InternetÂ» en 2002.</i>  <i>Il y compare Internet et les moteurs de recherche aux merveilles du monde, rÃ©flÃ©chit sur les technologies de recherche et retrace leur histoire.</i>  <i>MalgrÃ© la charge de travail, Ilya a Ã©crit un article en un temps record et a mÃªme fourni un glossaire suffisamment dÃ©taillÃ©, ce qui est particuliÃ¨rement intÃ©ressant Ã  lire aujourd'hui.</i>  <i>Nous n'avons pas pu trouver une version Ã©lectronique du magazine avec l'article, alors nous le publions aujourd'hui sur notre blog, dont le premier auteur, soit dit en passant, Ã©tait Ilya.</i> <br><br><img src="https://habrastorage.org/webt/a4/5i/mg/a45imgha_o5s5nye3vil9lydf28.jpeg"><br><br><a name="habracut"></a>  Des centaines de <i>moteurs</i> de <i>recherche ont Ã©tÃ©</i> Ã©crits dans le monde, et si vous comptez les fonctions de recherche mises en Å“uvre dans une variÃ©tÃ© de programmes, vous devez en suivre des milliers.  Et peu importe la faÃ§on dont le processus de recherche est mis en Å“uvre, quel que soit le modÃ¨le mathÃ©matique sur lequel il repose, les idÃ©es et les programmes qui mettent en Å“uvre la recherche sont assez simples.  Bien que cette simplicitÃ©, apparemment, appartient Ã  la catÃ©gorie dont ils disent Â«simple mais fonctionneÂ».  D'une maniÃ¨re ou d'une autre, mais ce sont les moteurs de recherche qui sont devenus l'une des deux nouvelles merveilles du monde, donnant Ã  Homo Sapiens un accÃ¨s illimitÃ© et instantanÃ© Ã  l'information.  Le premier miracle, Ã©videmment, peut Ãªtre considÃ©rÃ© comme Internet en tant que tel, avec ses capacitÃ©s de communication universelle. <br><br><h3>  Moteurs de recherche historiques </h3><br>  Il est largement admis que chaque nouvelle gÃ©nÃ©ration de programmes est plus parfaite que la prÃ©cÃ©dente.  Disons qu'avant tout Ã©tait imparfait, mais maintenant l' <i>intelligence</i> presque <i>artificielle</i> rÃ¨gne partout.  Un autre point de vue extrÃªme est que Â«tout ce qui est nouveau est bien oubliÃ© l'ancienÂ».  Je pense qu'en ce qui concerne les moteurs de recherche, la vÃ©ritÃ© se situe quelque part entre les deux. <br><br>  Mais qu'est-ce qui a vraiment changÃ© ces derniÃ¨res annÃ©es?  Pas des algorithmes ou des structures de donnÃ©es, pas des modÃ¨les mathÃ©matiques.  Bien qu'eux aussi.  Le paradigme de l'utilisation des systÃ¨mes a changÃ©.  Autrement dit, une femme au foyer, Ã  la recherche d'un fer Ã  repasser moins cher, et un diplÃ´mÃ© d'un pensionnat auxiliaire dans l'espoir de trouver un mÃ©canicien automobile se sont accrochÃ©s Ã  l'Ã©cran avec la ligne de recherche.  En plus de l'apparition d'un facteur impossible dans l'Ã¨re prÃ©-Internet - un facteur de la demande totale de moteurs de recherche - quelques changements supplÃ©mentaires sont apparus.  PremiÃ¨rement, il est devenu clair que les gens non seulement Â«pensent avec des motsÂ», mais aussi Â«recherchent des motsÂ».  Dans la rÃ©ponse du systÃ¨me, ils s'attendent Ã  voir le mot tapÃ© dans la chaÃ®ne de requÃªte.  Et le second: il est difficile de Â«recycler un chercheurÂ» Ã  Â«recycler pour chercherÂ», tout comme il est difficile de se recycler pour parler ou Ã©crire.  Les rÃªves des annÃ©es 60 et 80 sur le raffinement itÃ©ratif des requÃªtes, sur la comprÃ©hension du langage naturel, sur la recherche par le sens, sur la gÃ©nÃ©ration d'une rÃ©ponse cohÃ©rente Ã  une question peuvent difficilement rÃ©sister aujourd'hui Ã  l'Ã©preuve cruelle de la rÃ©alitÃ©. <br><br><h3>  Algorithme + structure de donnÃ©es = moteur de recherche </h3><br>  Comme tout programme, le moteur de recherche fonctionne avec des structures de donnÃ©es et exÃ©cute un algorithme.  La variÃ©tÃ© des algorithmes n'est pas trÃ¨s grande, mais elle l'est.  Outre les ordinateurs quantiques, qui nous promettent une percÃ©e magique dans la "complexitÃ© algorithmique" de la recherche, et dont l'auteur ne sait presque rien, il existe quatre classes d'algorithmes de recherche.  Trois algorithmes sur quatre nÃ©cessitent une Â«indexationÂ», traitement prÃ©alable des documents, qui crÃ©e un fichier auxiliaire, autrement dit Â«l'indexÂ», conÃ§u pour simplifier et accÃ©lÃ©rer la recherche elle-mÃªme.  Ce sont des algorithmes de <i>fichiers inversÃ©s, des arborescences de suffixes, des signatures</i> .  Dans un cas dÃ©gÃ©nÃ©rÃ©, il n'y a pas d'Ã©tape d'indexation prÃ©liminaire et la recherche est effectuÃ©e en visualisant sÃ©quentiellement les documents.  Une telle recherche est appelÃ©e <i>directe</i> . <br><br><h3>  Recherche directe </h3><br>  Sa version la plus simple est familiÃ¨re Ã  beaucoup, et il n'y a aucun programmeur qui n'Ã©crirait pas un tel code au moins une fois dans sa vie: <br><div class="scrollable-table"><table><tbody><tr><td width="310"><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">char</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">strstr</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">char</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *big,         </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">char</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *little)</span></span></span><span class="hljs-function"> </span></span>{     <span class="hljs-keyword"><span class="hljs-keyword">char</span></span> *x, *y, *z;     <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (x = big; *x; x++) {         <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (y = little, z = x;                 *y; ++y, ++z)         {             <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*y != *z)                 <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>;         }         <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!*y)             <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x;     }     <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; }</code> </pre> </td><td> <code>  . <br>     C   big        x       little.  ,     y  z,    .        ,   !</code> </td> </tr></tbody></table></div>  MalgrÃ© son apparente simplicitÃ©, la recherche directe s'est intensifiÃ©e au cours des 30 derniÃ¨res annÃ©es.  Un nombre considÃ©rable d'idÃ©es ont Ã©tÃ© avancÃ©es qui rÃ©duisent parfois le temps de recherche.  Ces algorithmes sont dÃ©crits en dÃ©tail dans une variÃ©tÃ© de littÃ©rature, il y a leurs rÃ©sumÃ©s et comparaisons.  De bons examens des mÃ©thodes de recherche directe peuvent Ãªtre trouvÃ©s dans des manuels tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sedgwick</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cormen</a> .  Il convient de garder Ã  l'esprit que les nouveaux algorithmes et leurs options amÃ©liorÃ©es apparaissent en permanence. <br><br>  Bien que regarder directement tous les textes soit une tÃ¢che assez lente, vous ne devriez pas penser que les algorithmes de recherche directe ne sont pas utilisÃ©s sur Internet.  Le moteur de recherche norvÃ©gien Fast (www.fastsearch.com) a utilisÃ© une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">puce</a> qui implÃ©mente la logique de recherche directe d'expressions rÃ©guliÃ¨res simplifiÃ©es et a placÃ© 256 de ces puces sur une seule carte.  Cela a permis Ã  Fast de traiter un nombre assez important de demandes par unitÃ© de temps. <br><br>  De plus, il existe de nombreux programmes qui combinent la recherche d'index pour trouver un bloc de texte avec une recherche directe supplÃ©mentaire Ã  l'intÃ©rieur du bloc.  Par exemple, l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aperÃ§u est</a> trÃ¨s populaire, y compris sur Runet. <br><br>  En gÃ©nÃ©ral, les algorithmes directs ont fondamentalement des caractÃ©ristiques distinctives gagnant-gagnant.  Par exemple, des possibilitÃ©s illimitÃ©es de recherche approximative et floue.  En effet, toute indexation est toujours associÃ©e Ã  la simplification et Ã  la normalisation des termes, et, par consÃ©quent, Ã  la perte d'informations.  La recherche directe fonctionne directement sur les documents originaux sans aucune distorsion. <br><br><h3>  Fichier inversÃ© </h3><br>  Cette structure de donnÃ©es simple, malgrÃ© son nom Ã©tranger mystÃ©rieux, est intuitivement familiÃ¨re Ã  toute personne alphabÃ©tisÃ©e et Ã  tout programmeur de base de donnÃ©es qui n'a mÃªme pas traitÃ© la recherche en texte intÃ©gral.  La premiÃ¨re catÃ©gorie de personnes sait ce que c'est, selon les Â«concordancesÂ» - listes exhaustives classÃ©es par ordre alphabÃ©tique de mots d'un texte ou appartenant Ã  un auteur (par exemple, Â«Concordance aux versets par A. S. PushkinÂ», Â«Dictionnaire-Concordance du journalisme par F. M. DostoÃ¯evskiÂ») )  Ces derniers traitent une forme ou une autre de la liste inversÃ©e chaque fois qu'ils construisent ou utilisent Â«l'index de base de donnÃ©es par champ clÃ©Â». <br><br>  Nous illustrerons cette structure Ã  l'aide de la merveilleuse concordance russe - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Â«SymphonieÂ»</a> , publiÃ©e par le Patriarcat de Moscou sur le texte de la traduction synodale de la Bible. <br><br><img src="https://habrastorage.org/webt/um/z7/zn/umz7znedr_ubbqvcxyupo1lk8t4.png"><br><br>  Ceci est une liste alphabÃ©tique de mots.  Pour chaque mot, toutes les Â«positionsÂ» dans lesquelles ce mot apparaÃ®t sont rÃ©pertoriÃ©es.  L'algorithme de recherche consiste Ã  trouver le bon mot et Ã  charger dans la mÃ©moire une liste de positions dÃ©jÃ  Ã©largie. <br><br>  Pour Ã©conomiser de l'espace disque et accÃ©lÃ©rer la recherche, recourez gÃ©nÃ©ralement Ã  deux astuces.  Tout d'abord, vous pouvez Ã©conomiser sur les dÃ©tails de la position elle-mÃªme.  En effet, plus une telle position est dÃ©taillÃ©e, par exemple, dans le cas de "Symphony" c'est "livre + chapitre + vers", plus il faudra d'espace pour stocker le fichier inversÃ©. <br><br>  Dans la version la plus dÃ©taillÃ©e, dans le fichier inversÃ©, vous pouvez stocker le numÃ©ro de mot et le dÃ©calage en octets depuis le dÃ©but du texte, ainsi que la couleur et la taille de la police, et bien plus encore.  Le plus souvent, ils indiquent simplement le numÃ©ro du document, disons un livre de la Bible, et le nombre d'utilisations de ce mot.  C'est une telle structure simplifiÃ©e qui est considÃ©rÃ©e comme fondamentale dans la thÃ©orie classique de la recherche d'informations - Information Retrieval (IR). <br><br>  La deuxiÃ¨me mÃ©thode de compression (sans rapport avec la premiÃ¨re): pour organiser les positions pour chaque mot dans l'ordre croissant des adresses et pour chaque position pour stocker non pas son adresse complÃ¨te, mais la diffÃ©rence par rapport Ã  la prÃ©cÃ©dente.  Voici Ã  quoi ressemblera cette liste pour notre page en supposant que nous nous souvenons de la position jusqu'au numÃ©ro de chapitre: <br><br> <code>: [.1],[+11],[0],[+2],[+4],[+2],[+4],..</code> <br> <br>  De plus, une mÃ©thode simple de compression est imposÃ©e Ã  la mÃ©thode de diffÃ©rence de stockage des adresses: pourquoi allouer un nombre fixe "Ã©norme" d'octets Ã  un petit entier, car vous pouvez lui donner presque autant d'octets qu'il le mÃ©rite.  Ici, il convient de mentionner les codes Golomb ou la fonction intÃ©grÃ©e du langage Perl populaire: <code>pack(â€œwâ€)</code> . <br><br>  Dans la littÃ©rature, il existe Ã©galement une artillerie plus lourde d'algorithmes de conditionnement de la plus large gamme: arithmÃ©tique, Huffman, LZW, etc. Les progrÃ¨s dans ce domaine sont continus.  En pratique, ils sont rarement utilisÃ©s dans les moteurs de recherche: le gain est faible et la puissance du processeur est dÃ©pensÃ©e de maniÃ¨re inefficace. <br><br>  En raison de toutes les astuces dÃ©crites, la taille du fichier inversÃ©, en rÃ¨gle gÃ©nÃ©rale, est de 7 Ã  30 pour cent de la taille du texte source, en fonction des dÃ©tails d'adressage. <br><br><h3>  Inscrite dans le livre rouge </h3><br>  ProposÃ© Ã  plusieurs reprises autres que des algorithmes de recherche inversÃ©s et directs et des structures de donnÃ©es.  Tout d'abord, ce sont des arbres de suffixes (voir les livres de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Manber</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gonnet</a> ), ainsi que des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">signatures</a> . <br><br>  Le premier d'entre eux fonctionnait sur Internet, Ã©tant un algorithme brevetÃ© du systÃ¨me de recherche <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenText</a> .  J'ai rencontrÃ© des indices de suffixe dans les moteurs de recherche nationaux. <br><br>  La seconde - la mÃ©thode de signature - est une conversion de document en blocs de blocs des <i>valeurs de hachage de</i> ses mots - la "signature" et la visualisation sÃ©quentielle des "signatures" pendant la recherche. <br><br>  Aucune des deux mÃ©thodes n'a Ã©tÃ© largement adoptÃ©e et ne mÃ©ritait donc pas une discussion dÃ©taillÃ©e dans ce court article. <br><br><h3>  ModÃ¨les mathÃ©matiques </h3><br>  Environ 3 moteurs de recherche et modules sur 5 fonctionnent sans aucun modÃ¨le mathÃ©matique.  Plus prÃ©cisÃ©ment, leurs dÃ©veloppeurs ne se donnent pas pour tÃ¢che d'implÃ©menter un modÃ¨le abstrait et / ou ignorent son existence.  Le principe ici est simple: si seulement le programme trouve quelque chose.  Quoi qu'il en soit.  Et puis l'utilisateur le dÃ©couvrira. <br><br>  Cependant, dÃ¨s qu'il s'agit d'amÃ©liorer la qualitÃ© de la recherche, sur une grande quantitÃ© d'informations, sur le flux des requÃªtes des utilisateurs, en plus des coefficients apposÃ©s empiriquement, il s'avÃ¨re utile de fonctionner avec une sorte d'appareil thÃ©orique simple.  <i>Le modÃ¨le de recherche</i> est une certaine simplification de la rÃ©alitÃ©, sur la base de laquelle une formule est obtenue (qui n'est plus nÃ©cessaire Ã  personne), qui permet au programme de prendre une dÃ©cision: quel document est considÃ©rÃ© comme trouvÃ© et comment le classer.  AprÃ¨s l'adoption du modÃ¨le, les coefficients acquiÃ¨rent souvent une signification physique et deviennent plus comprÃ©hensibles pour le dÃ©veloppeur lui-mÃªme, et il devient plus intÃ©ressant de les sÃ©lectionner. <br><br>  Toute la variÃ©tÃ© des modÃ¨les de recherche d'information traditionnelle (IR) est gÃ©nÃ©ralement divisÃ©e en trois types: thÃ©orie des ensembles (boolÃ©en, ensembles flous, boolÃ©en Ã©tendu), <abbr title="Dans la littÃ©rature nationale, les modÃ¨les algÃ©briques sont souvent appelÃ©s linÃ©aires.">algÃ©brique</abbr> (vecteur, vecteur gÃ©nÃ©ralisÃ©, sÃ©mantique latente, rÃ©seau neuronal) et probabiliste. <br><br>  La famille boolÃ©enne de modÃ¨les, en fait, est la premiÃ¨re qui vient Ã  l'esprit d'un programmeur qui implÃ©mente la recherche en texte intÃ©gral.  Il y a un mot - un document est considÃ©rÃ© comme trouvÃ©, non - pas trouvÃ©.  En fait, le modÃ¨le boolÃ©en classique est un pont reliant la thÃ©orie de la recherche d'informations Ã  la thÃ©orie de la recherche et de la manipulation des donnÃ©es. <br><br>  La critique du modÃ¨le boolÃ©en, assez juste, consiste en son extrÃªme rigiditÃ© et son inadÃ©quation au classement.  Par consÃ©quent, en 1957, Joyce et Needham (Joyce et Needham) ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">suggÃ©rÃ© de</a> prendre en compte les caractÃ©ristiques de frÃ©quence des mots afin que "... l'opÃ©ration de comparaison soit le rapport de la distance entre les vecteurs ...".  <i>Le modÃ¨le vectoriel a</i> Ã©tÃ© implÃ©mentÃ© avec succÃ¨s en 1968 par le pÃ¨re fondateur de la science de la recherche d'informations Gerard Salton (Gerard Salton) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">*</a> dans le moteur de recherche SMART (Salton's Magical Automatic Retriever of Text).  Le classement dans ce modÃ¨le est basÃ© sur l'observation statistique naturelle que plus la frÃ©quence locale d'un terme dans un document (TF) est Ã©levÃ©e et plus Â«rareÂ» (c'est-Ã -dire l' <i>occurrence de retour dans les documents</i> ) d'un terme dans une collection (IDF), plus le poids de ce document par rapport au terme est Ã©levÃ© . <br><br><hr><a name="salton"></a>  <sup>* Gerard Salton (Sahlman) 1927-1995.</sup>  <sup>Il est Selton, il est Zalton et mÃªme Zalman, il est Gerard, Gerard, Gerard ou mÃªme Gerald, selon le goÃ»t du traducteur et les fautes de frappe faites.</sup> <sup><br></sup>  <sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.cs.cornell.edu/Info/Department/Annual95/Faculty/Salton.html</a></sup> <sup><br></sup>  <sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20040128014253/">http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salton:Gerald.html</a></sup> <sup><br></sup>  <sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20011117024624/">http://www.cs.virginia.edu/~clv2m/salton.txt</a></sup> <sup><br></sup> <br>  La dÃ©signation de Tsahal a Ã©tÃ© introduite par Karen Sparck-Jones (Karen Spark-Jones) en 1972 dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> sur le <i>terme spÃ©cificitÃ©</i> .  DÃ©sormais, la dÃ©signation TF * IDF est largement utilisÃ©e comme synonyme du modÃ¨le vectoriel. <br><br>  Enfin, en 1977, Robertson et Sparck-Jones ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Robertson</a> et Spark-Jones) ont Ã©tayÃ© et mis en Å“uvre un <i>modÃ¨le probabiliste</i> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">proposÃ©</a> en 1960), qui a Ã©galement jetÃ© les bases d'une famille entiÃ¨re.  <i>La pertinence</i> dans ce modÃ¨le est considÃ©rÃ©e comme la probabilitÃ© que ce document puisse intÃ©resser l'utilisateur.  Cela implique la prÃ©sence d'un ensemble initial dÃ©jÃ  existant de documents pertinents sÃ©lectionnÃ©s par l'utilisateur ou reÃ§us automatiquement sous une hypothÃ¨se simplifiÃ©e.  La probabilitÃ© d'Ãªtre pertinente pour chaque document subsÃ©quent est calculÃ©e sur la base du rapport de l'occurrence des termes de l'ensemble pertinent au reste de la partie Â«non pertinenteÂ» de la collection.  Bien que les modÃ¨les probabilistes aient un certain avantage thÃ©orique, car ils classent les documents par ordre dÃ©croissant de Â«probabilitÃ© d'Ãªtre pertinentÂ», dans la pratique, ils n'ont pas reÃ§u beaucoup de distribution. <br><br>  Je ne vais pas entrer dans les dÃ©tails et Ã©crire des formules volumineuses pour chaque modÃ¨le.  Leur rÃ©sumÃ©, ainsi que la discussion, prend 35 pages sous forme compressÃ©e dans le livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Â«Modern Information SearchÂ»</a> .  Il est seulement important de noter que dans chacune des familles le modÃ¨le le plus simple procÃ¨de de l'hypothÃ¨se d'indÃ©pendance des mots et a une condition de filtrage simple: les documents qui ne contiennent pas de mots de requÃªte ne sont jamais trouvÃ©s.  Les modÃ¨les avancÃ©s (Â«alternatifsÂ») de chacune des familles ne considÃ¨rent pas le mot de requÃªte comme indÃ©pendant, mais vous permettent en outre de rechercher des documents qui ne contiennent pas un seul mot de la requÃªte. <br><br><h3>  Recherchez "par sens" </h3><br>  La capacitÃ© Ã  trouver et classer des documents qui ne contiennent pas de mots de la requÃªte est souvent considÃ©rÃ©e comme un signe d'intelligence artificielle ou une recherche par sens et se rapporte a priori aux avantages du modÃ¨le.  La question de savoir s'il en est ainsi ou non, nous laisserons en dehors du champ d'application de cet article. <br><br>  Par exemple, je n'en dÃ©crirai qu'un, peut-Ãªtre le modÃ¨le le plus populaire qui fonctionne par sens.  Dans la thÃ©orie de la recherche d'informations, ce modÃ¨le est appelÃ© <i>indexation sÃ©mantique latente</i> (en d'autres termes, rÃ©vÃ©lant des significations cachÃ©es).  Ce modÃ¨le algÃ©brique est basÃ© sur la dÃ©composition singuliÃ¨re d'une matrice rectangulaire associant les mots aux documents.  L'Ã©lÃ©ment de la matrice est une rÃ©ponse en frÃ©quence, reflÃ©tant le degrÃ© de connexion du mot et du document, par exemple, TF * IDF.  Au lieu de la matrice d'origine de la millioniÃ¨me dimension, les auteurs de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mÃ©thode de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Furnas</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deerwester ont</a> suggÃ©rÃ© d'utiliser <abbr title="Pour les grandes collections, le nombre de Â«significationsÂ» est portÃ© Ã  300.">50</abbr> Ã  <abbr title="Pour les grandes collections, le nombre de Â«significationsÂ» est portÃ© Ã  300.">150</abbr> Â«significations cachÃ©esÂ» correspondant aux premiers <i>composants principaux de sa dÃ©composition singuliÃ¨re</i> . <br><br><blockquote>  <u>Une dÃ©composition singuliÃ¨re d'une</u> matrice rÃ©elle A de tailles m * n est appelÃ©e toute dÃ©composition de la forme A = USV, oÃ¹ U est la matrice orthogonale de tailles m * m, V est la matrice orthogonale de tailles n * n, S est la matrice diagonale de tailles m * n, dont les Ã©lÃ©ments sont <i>s <sub>ij</sub></i> = 0 si <i>i n'est</i> pas Ã©gal Ã  <i>j</i> , et <i>s <sub>ii</sub> = s <sub>i</sub></i> &gt; = 0. Les quantitÃ©s si sont appelÃ©es les nombres singuliers de la matrice et sont Ã©gales aux valeurs arithmÃ©tiques des racines carrÃ©es des valeurs propres correspondantes de la matrice AA <sup>T.</sup>  Dans la littÃ©rature anglaise, la dÃ©composition singuliÃ¨re est communÃ©ment appelÃ©e <u>dÃ©composition SVD</u> . </blockquote><br>  Il a Ã©tÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prouvÃ©</a> il y a longtemps que si nous laissons les k premiers nombres singuliers en considÃ©ration (assimilons le reste Ã  zÃ©ro), nous obtenons l'approximation la plus proche possible de la matrice initiale de rang k (en un sens, son Â«interprÃ©tation sÃ©mantique la plus proche du rang kÂ»).  En diminuant le rang, nous filtrons les dÃ©tails non pertinents;  de plus en plus, nous essayons de reflÃ©ter toutes les nuances de la structure des donnÃ©es rÃ©elles. <br><br>  Les opÃ©rations de recherche ou de recherche de <i>documents similaires sont</i> grandement simplifiÃ©es, car chaque mot et chaque document est associÃ© Ã  un vecteur relativement court de k significations (lignes et colonnes des matrices correspondantes).  Cependant, en raison de la faible signification des Â«significationsÂ», ou <abbr title="AprÃ¨s nos expÃ©riences avec LSI, il s'est avÃ©rÃ© que Â«signifiant numÃ©ro 1Â» dans Runet - tous les documents en anglais, Â«signifiant numÃ©ro 3Â» - tous les forums, etc.">pour une autre</abbr> raison, l'utilisation de LSI dans le front pour la recherche n'est pas encore gÃ©nÃ©ralisÃ©e.  Bien qu'Ã  des fins auxiliaires (filtrage automatique, classification, sÃ©paration des collections, abaissement prÃ©alable des dimensions pour d'autres modÃ¨les), cette mÃ©thode semble trouver application. <br><br><h3>  Ã‰valuation de la qualitÃ© </h3><blockquote>  La vÃ©rification de la cohÃ©rence a montrÃ© que le chevauchement des documents pertinents entre deux Ã©valuateurs est de l'ordre de 40% en moyenne ... rappel et prÃ©cision croisÃ©s d'environ 65% ... Cela implique une limite pratique supÃ©rieure de 65% pour les performances du systÃ¨me de recherche. <br>  <b>Donna harman</b> <br>  <b>Ce que nous avons appris et non appris de TREC</b> <br><br><div class="spoiler">  <b class="spoiler_title">La traduction</b> <div class="spoiler_text">  "... un contrÃ´le de stabilitÃ© a montrÃ© que le chevauchement des documents pertinents entre deux Ã©valuateurs est d'environ 40% en moyenne ... l'exactitude et l'exhaustivitÃ© mesurÃ©es entre les Ã©valuateurs sont d'environ 65% ... Cela impose une limite pratique supÃ©rieure Ã  la qualitÃ© de la recherche dans la rÃ©gion de 65% ..." <br></div></div></blockquote><br>  Quel que soit le modÃ¨le, le moteur de recherche a besoin d'un Â«rÃ©glageÂ» - une Ã©valuation de la qualitÃ© de la recherche et du rÃ©glage des paramÃ¨tres.  L'Ã©valuation de la qualitÃ© est une idÃ©e fondamentale de la thÃ©orie de la recherche.  Car c'est grÃ¢ce Ã  l'Ã©valuation de la qualitÃ© que nous pouvons parler de l'applicabilitÃ© ou de l'inapplicabilitÃ© d'un modÃ¨le particulier et mÃªme discuter de leurs aspects thÃ©oriques. <br><br>  En particulier, l'une des limites naturelles de la qualitÃ© de la recherche est l'observation faite dans l'Ã©pigraphe: les opinions de deux Â«assesseursÂ» (experts Ã©mettant un verdict de pertinence) ne coÃ¯ncident pas en moyenne trÃ¨s largement entre elles!  Cela implique Ã©galement la limite supÃ©rieure naturelle de la qualitÃ© de la recherche, car la qualitÃ© est mesurÃ©e par comparaison avec lâ€™opinion de lâ€™Ã©valuateur. <br><br>  <abbr title="Mais pas nÃ©cessairement - il existe des mÃ©triques &quot;alternatives&quot;!">Habituellement,</abbr> deux paramÃ¨tres sont mesurÃ©s pour Ã©valuer la qualitÃ© d'une recherche: <br><br><ul><li>  prÃ©cision - la proportion de matÃ©riel pertinent dans la rÃ©ponse d'un moteur de recherche </li><li>  exhaustivitÃ© (rappel) - la proportion de documents pertinents trouvÃ©s dans le nombre total de documents de collecte pertinents </li></ul><br>  Ces paramÃ¨tres ont Ã©tÃ© utilisÃ©s et sont utilisÃ©s rÃ©guliÃ¨rement pour sÃ©lectionner des modÃ¨les et leurs paramÃ¨tres dans le cadre de la confÃ©rence d'Ã©valuation de la rÃ©cupÃ©ration de texte (TREC) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">*</a> crÃ©Ã©e par l'American Institute of Standards (NIST).  Ã€ partir de 1992, un consortium de 25 groupes, Ã  la fin de l'annÃ©e 12 de son existence, la confÃ©rence a accumulÃ© un matÃ©riel important sur lequel les moteurs de recherche sont encore perfectionnÃ©s.  Pour chaque confÃ©rence rÃ©guliÃ¨re, de nouveaux documents sont en cours de prÃ©paration (ce que l'on appelle la Â«pisteÂ») dans chacun des domaines d'intÃ©rÃªt.  La Â«pisteÂ» comprend une collection de documents et de demandes.  Je vais donner des exemples: <br><br>  - Suivi des demandes alÃ©atoires ( <i>ad hoc</i> ) - prÃ©sent Ã  toutes les confÃ©rences <br>  - Recherche multilingue <br>  - Routage et filtrage <br>  - Recherche de haute prÃ©cision (avec une seule rÃ©ponse, effectuÃ©e Ã  temps) <br>  - Interaction utilisateur <br>  - Â«CheminÂ» en langage naturel <br>  - RÃ©ponses aux Â«questionsÂ» <br>  - Recherche dans les textes "sales" (juste scannÃ©s) <br>  - Recherche vocale <br>  - Recherche dans un trÃ¨s grand boÃ®tier (20 Go, 100 Go, etc.) <br>  - WEB corps (lors des derniÃ¨res confÃ©rences, il est reprÃ©sentÃ© par une sÃ©lection pour le domaine .gov) <br>  - Recherche distribuÃ©e et fusion des rÃ©sultats de recherche de diffÃ©rents systÃ¨mes <br><br><hr><a name="conf"></a>  <sup>* Les documents de la confÃ©rence sont accessibles au public Ã  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">trec.nist.gov/pubs.html</a> .</sup> <br><br><h3>  Pas seulement la recherche </h3><br>  Comme le montrent les Â«cheminsÂ» TREC, un certain nombre de tÃ¢ches sont Ã©troitement liÃ©es Ã  la recherche elle-mÃªme, soit partageant une idÃ©ologie commune (classification, routage, filtrage, annotation), soit faisant partie intÃ©grante du processus de recherche (regroupement des rÃ©sultats, expansion et rÃ©trÃ©cissement des requÃªtes, rÃ©troaction, Annotation "dÃ©pendante de la requÃªte", interface de recherche et langages de requÃªte).  Il n'y a pas un seul moteur de recherche qui n'aurait pas Ã  rÃ©soudre en pratique au moins une de ces tÃ¢ches. <br><br>  Souvent, la prÃ©sence de l'une ou l'autre propriÃ©tÃ© supplÃ©mentaire est un argument dÃ©cisif dans la concurrence des moteurs de recherche.  Par exemple, de brÃ¨ves annotations consistant en des citations informatives d'un document avec lesquelles certains moteurs de recherche accompagnent les rÃ©sultats de leur travail les aident Ã  garder une longueur d'avance sur la concurrence. <br><br>  Il est impossible de parler de toutes les tÃ¢ches et de la faÃ§on de les rÃ©soudre.  Par exemple, considÃ©rez l 'Â«extension de requÃªteÂ», qui est gÃ©nÃ©ralement effectuÃ©e en effectuant la recherche de termes associÃ©s.  La solution Ã  ce problÃ¨me est possible sous deux formes - locale (dynamique) et globale (statique).  Les techniciens locaux s'appuient sur le texte de la requÃªte et analysent uniquement les documents qui s'y trouvent.  Les Â«extensionsÂ» globales peuvent fonctionner avec les thÃ©saurus, Ã  la fois a priori (linguistiques) et construits automatiquement tout au long de la collection de documents.  Selon l'opinion gÃ©nÃ©ralement acceptÃ©e, les modifications globales des requÃªtes via les thÃ©saurus fonctionnent de maniÃ¨re inefficace, ce qui rÃ©duit la prÃ©cision de la recherche.  Une approche globale plus efficace repose sur des classifications statiques construites manuellement, telles que les rÃ©pertoires WEB.  Cette approche est largement utilisÃ©e dans les moteurs de recherche Internet dans les opÃ©rations de rÃ©trÃ©cissement ou d'expansion des requÃªtes. <br><br>  Souvent, la mise en Å“uvre de fonctionnalitÃ©s supplÃ©mentaires est basÃ©e sur des principes et des modÃ¨les identiques ou trÃ¨s similaires Ã  la recherche elle-mÃªme. , ,   ,                (   â€“    TF*IDF),     .    <i> </i> (relevance feedback),     <i></i> ()   ,    . <br><br>  ,    ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Â«Term Vector DatabaseÂ»</a>   ,     Â«Â»  (   ). <br><br><h3>  </h3><br>            ,    .         .     ,    (, , ),  .   ,     (,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> )         ,            .    ,    ,     : <br><br> â€”     <br> â€” <i></i> ( ):  ,   <br> â€”    ( <i>-</i> ) <br> â€” <i></i> (, <i></i> ):  <i></i>   Â«Â»,      ,      <br> â€”    ()    (, ) <br> â€” <i></i> :      <br> â€”  <i> </i> <br><br>           <i></i> , <i></i>   <i></i> .        -   (LSI,  ),   -     ,      . <br><br><h3>    </h3><blockquote> â€œThings that work well on TREC often do not produce good results on the webâ€¦ Some argue that on the web, users should specify more accurately what they want and add more words to their query. We disagree vehemently with this position. If a user issues a query like Â«Bill ClintonÂ» they should get reasonable results since there is a enormous amount of high quality information available on this topicâ€ <br> <b>Sergei Brin, Larry Page <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20040614144734/">The Anatomy of a Large-Scale Hypertextual Web Search Engine</a></b> <br><br><div class="spoiler">  <b class="spoiler_title">La traduction</b> <div class="spoiler_text"> Â«,     TREC,     â€¦  ,         ,   ,     .        .    Â« Â»,     ,           ...Â» </div></div><br> Â«I was struck when a Google person told me at SIGIR that the most recent Google ranking algorithm completely ignores anything discovered at TREC, because all the good Ad Hoc ranking algorithms developed over the 10 years of TREC get trashed by spamÂ» <br> <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mark Sanderson</a></b> <br><br><div class="spoiler">  <b class="spoiler_title">La traduction</b> <div class="spoiler_text"> Â«  ,  -  Google  ,         TREC,    ,    Â« Â»   ...Â» </div></div></blockquote><br>    ,     :         ? <br><br>  ,  ,    ,    -  ,     (    ,   . .)    .  <i></i> (off-page)    ,    Ì ,    .   , ,  ,  ,      â€“       . <br><br> C        ,        -.  ,    Â«Â»  ,         .   <i> </i> ,   ,  <i></i> , Â« Â»    ,     ,   . <br><br>    ,                  ,  , , ,     .        (     <i> </i> â€“     ),        .             . <br><br>                . <br><br><h3>   </h3><br>        .          ,   1999-2000         .             (     )      ,     . <br><br>    (  )        ,   .  ,      <i> </i> .         1998 .     <i></i> ,  ,      .            1998   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>PageRank</i></a> â€“  ,  ,            .       ,    (,   ,         80- ),       . <br><br>  ,  PageRank,    (  ,   )    â€“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HITS</a> , <abbr title="   ,        ."></abbr>       -  .     ,    (. . ) ,  . <br><br>  ,  ,    ,       .  ,        ,      :    ,       . .     ,      :    (,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.teoma.com</a> ),    ..,    <i></i> .      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>   . <br><br><h3>   </h3><br>            ,   .     ,  Google  Fast,       .  : Â«Â» ,   ,     100 ,     30%     â€“   .           . <br><br>   ,       ,  :     ,   ..   ,     ,       ,   Â«  Â». <br><br>        .                :       ;    â€“    . <br><br>          â€“   ,    ,  ,       . .   : , , , ,    . . ,                . <br><br>  ,    ,    ,         : , ,     . <br><br> ,       ,                 .          -  . <br><br>     Udi Manber ( ) (      agrep)  1994  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ,  Andrei Broder ( )  1997- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>       Â«Â» (  shingles, Â«Â», Â«Â»).    . <br><br><img src="https://habrastorage.org/webt/lr/zz/i0/lrzzi0rqbw5drhtoz6kf7qcdre4.png"><br><br>        ( <i></i> ).   ,  , ,     .        (,    ,      9)   ,   , , 25.      ,        . ,      â€“   ,    , ,  ,    (  )   :  !         25     ! <br><br> ,       ,      ..       :    Â«     Â»   !       . (     ; ,  0%;  .) <br><br>      ,     <i> </i> ,      <i>-</i> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>    .     ,            ( <i> </i> ),         -. <br><br><h3>    </h3><br>         .               ,   .         . <br><br>       ,        ,     .  ,   1997  (  Inktomi)    32-  (Linux, Solaris, FreeBSD, Win32)       .       AltaVista,       Â«Â» 64-  Alpha. <br><br>     (, ,    c)        <i></i>  <i></i> .              .      ,  ,    ,   ,       . Pruning ( . , )   ,           .    pruning,           ,      . <br><br>   â€“     ,   ,         .       ,         . <br><br> ,     (,     - )  <abbr title="  Google   2001 â€“  2002 ."></abbr>     . ,   ,   ,      ,      :   ,    . <br><br>          ,    , ,               . , ,  ,     .     , , ,  2-4 ,     ,   ,      ,       .       . <br><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text">  (assesor, ) â€“    ,    <i></i> ,   . <br><br>   (boolean, , , ) â€“  ,    ,    . <br><br>   â€“   ,         ,  <i></i> â€“    . <br><br>   â€“   ,                 . <br><br>   (off-page, ) â€“      ,  ,            . <br><br>   (doorways, hallways) â€“ ,         ( <i> </i> ).         . <br><br>  (tagging, part of speech disambiguation, ) â€“     <i></i> c  ;           Â« Â». <br><br>  (duplicates) â€“    ,    , ;   (near duplicates, -),     ,   . <br><br>   â€“   ,            ,    . <br><br>   (inverted file,  ,  ,  ) â€“   ,      ,       ,    . <br><br>  (index, ) â€“ . <i></i> . <br><br>   (citation index) â€“   ()  ,        , ,  . <br><br>  (indexing, ) â€“      ( <i></i> ) â€“   ,    . <br><br>   (Information Retrieval, IR) â€“   ,       .      ,     .   ,    .       Â« Â»,      ,          .  <i> </i>     ,  ,    (),    , ,     . <br><br>  (cloaking) â€“  <i> </i> ,       ( )        ,    ,  . <br><br>   â€“ . <i> </i> . <br><br> -  â€“   <i>  </i> ,   .         . <br><br>  (lemmatization, ) â€“      ,   . <br><br>    â€“ . <i>  </i> . <br><br>  â€“  <i>  </i> ,              . <br><br>     (inverted document frequency, IDF,    ,   ) â€“     ( <i> </i> ); <i>Â«Â»</i> ,             ,   . <br><br>   â€“     ,    <i></i>  ,  <i> </i>  , ,    .    <i> </i> â€“   ,         . <br><br>  â€“ . <i></i> . <br><br>  â€“  ,     <i></i>  <i></i> () . <br><br>    â€“  <i> </i> ,   ,    . <br><br>    (similar document search) â€“  <i> </i> ,     <i></i>       ,   . <br><br>   (search engine, SE, - , ,  ,  , Â«Â», Â«Â») â€“ ,    ,   . <br><br>   (query, ) â€“   . <br><br>  (polysemy, homography, , , <i></i> ) â€”         . <br><br>  (recall, ) â€“   ,     ,        . <br><br> - (near-duplicates,  ) â€“ . <i></i> . <br><br>  (pruning) â€“           <i></i> . <br><br>   â€“     ,    ( <i></i> ). <br><br> -  â€“ . <i> </i> . <br><br>    (term specificity, term discriminating power, ,  ) â€“     .         ,      .        ,    . <br><br>   (regualr expression, pattern, Â«Â»,  Â«Â», Â«Â») â€“   <i> </i> ,      ,   ,   . .    â€“ ,   <i></i>  . <br><br>  (relevance, relevancy) â€“   . <br><br>  (signature, ) â€“  <i>-</i>    .    <b> </b>            <i>-</i>  . <br><br>  (inflection) â€“     ,      ,      (),     .    <i></i> ,          . <i></i>    (declension),   â€“  (conjugation). <br><br>  (derivation) â€“         .         ,   . <br><br>  â€“ . <i> </i> . <br><br>    (spam, ,   ) â€“     <i> </i>    . <br><br>   â€“ . <i>PageRank</i> . <br><br>  â€“    . <br><br> - (stop-words) â€“  ,     ,               / <i></i> . <br><br>  ,   (suffix trees, suffix arrays, PAT-arrays) â€“ <i></i> ,      <i></i>    ,   <b></b> (trie). <b></b>      Â«Â»,      (     )     .     <i></i> ,      â€“ ,  .       ,  ,    . <br><br>  (tokenization, lexical analysis,  ,  ) â€“    ,    <i></i> ,   , ,   . <br><br>  (precision) â€”  <i></i>     . <br><br> - (hash-value) â€“  <b>-</b> (hash-function),     (, )    . <br><br>  ()   (document frequency,   ,  ) â€“    ,   . <br><br>   (term frequency, TF) â€“     . <br><br>  â€“ (shingle) â€“ <i>-</i>      . <br><br> PageRank â€“    ()    ,       â€”  .          . <br><br> TF*IDF â€“        <i> </i> ;  ,  <b> </b>      <b> </b> â€“  . </div></div><br><h4>  Les rÃ©fÃ©rences </h4> <sup><a name="baezo-yates"></a><br> Modern Information Retrieval <br> Baezo-Yates R. and Ribeiro-Neto B. <br> ACM Press Addison Wesley, 1999 <br><a name="bharat"></a><br> The Connectivity Server: fast access to linkage information on the Web <br> K. Bharat, A. Broder, M. Henzinger, P. Kumara, and S. Venkatasubramanian <br> WWW7, 1998 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www7.scu.edu.au/programme/fullpapers/1938/com1938.htm</a> <br><a name="brin"></a><br> The Anatomy of a Large-Scale Hypertextual Web Search Engine <br> S.Brin and L. Page <br> WWW7, 1998 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20040614144734/">http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm</a> <br><a name="broder"></a><br> Syntactic Clustering of the Web <br> Andrei Z. Broder, Steven C. Glassman, Mark S. Manasse <br> WWW6, 1997 <br><a name="deerwester"></a><br> Indexing by Latent Semantic Analysis <br> S. Deerwester, ST Dumais, GW Furnas, TK Landauer, R. Harshman <br> JASIS, 1990 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20010802133759/">http://citeseer.nj.nec.com/deerwester90indexing.html</a> <br><a name="eckart"></a><br> The approximation of one matrix by another of lower rank <br> C. Eckart, G. Young <br> Psychometrika, 1936 <br><a name="faloutsos"></a><br> Description and performance analysis of signature file methods <br> C. Faloutsos, S. Christodoulakis <br> ACM TOIS 1987 <br><a name="fastpmc"></a><br> FAST PMC â€” The Pattern Matching Chip <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/19990908203501/">http://www.fast.no/product/fastpmc.html</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.idi.ntnu.no/grupper/KS-grp/microarray/slides/heggebo.pdf</a> (   ,  web.archive.org    â€“ . .) <br><a name="furnas"></a><br> Information retrieval using a Singular Value Decomposition Model of Latent Semantic Structure <br> GW Furnas, S. Deerwester, ST Dumais, TK Landauer, RA Harshman, LA Streeter, and KE Lochbaum <br> ACM SIGIR, 1988 <br><a name="glimpse"></a><br> Glimpse, Webglimpse, Unix-based search softwareâ€¦ <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20010509114708/">http://webglimpse.org</a> <br><a name="gonnet"></a><br> Examples of PAT applied to the Oxford English Dictionary <br> Gonnet G. <br> University of Waterloo, 1987 <br><a name="harman"></a><br> What we have learned, and not learned, from TREC <br> Donna Harman <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20030702130753/">http://irsg.eu.org/irsg2000online/papers/harman.htm</a> <br><a name="joyce"></a><br> The Thesaurus Approach to Information Retrieval <br> T. Joyce and RM Needham <br> American Documentation, 1958 <br><a name="kleinberg"></a><br> Authoritative Sources in a Hyperlinked Environment <br> Jon M. Kleinberg <br> JACM, 1998 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20020601183351/">http://citeseer.nj.nec.com/87928.html</a> <br><a name="ilyinsky"></a><br> An efficient method to detect duplicates of Web documents with the use of inverted index <br> S. Ilyinsky, M. Kuzmin, A. Melkov, I. Segalovich <br> WWW2002, 2002 <br><a name="manber1990"></a><br> Suffix Arrays: A New Method for On-line String Searches <br> U. Manber, G. Myers <br> 1st ACM-SIAM Symposium on Discrete Algorithms, 1990 <br><a name="manber1994"></a><br> Finding similar files in a large file system <br> U. Manber <br> USENIX Conference, 1994 <br><a name="maron"></a><br> ME Maron and JL Kuhns <br> On relevance, probabilistic indexing and information retrieval <br> Journal of the ACM, 1960 <br><a name="opentext"></a><br> Open Text Corporation <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.opentext.com</a> <br><a name="robertson"></a><br> SE Robertson and Sparck Jones K. <br> Relevance Weighting of Search Terms <br> JASIS, 1976 <br><a name="sedgewick"></a><br> Algorithms in C++, Robert Sedgewick <br> Addison-Wesley, 1992 <br><a name="spark-jones"></a><br> A Statistical Interpretation of Term Specificity and Its Application in Retrieval <br> Karen Sparck Jones <br> Journal of Documentation, 1972 <br><a name="stata"></a><br> The Term Vector Database: fast access to indexing terms for Web pages <br> R. Stata, K. Bharat, F. Maghoul <br> WWW9, 2000 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://web.archive.org/web/20020607145018/">http://www9.org/w9cdrom/159/159.html</a> <br><a name="strzalkowski"></a><br> Natural Language Information Retrieval <br> Tomek Strzalkowski (ed.) <br> Kluwer Academic Publishers, 1999 <br><a name="cormen"></a><br> :   , . , . , . <br> , 2000 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.ozon.ru/context/detail/id/33769775/</a> <br><a name="symphony"></a><br>   -       .  .. , .., .. <br> -  , 1995</sup> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr464375/">https://habr.com/ru/post/fr464375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr464365/index.html">Security Week 34: vulnÃ©rabilitÃ©s extraordinaires dans Windows</a></li>
<li><a href="../fr464367/index.html">Et une autre escalade des privilÃ¨ges locaux du client Steam Windows 0day</a></li>
<li><a href="../fr464369/index.html">Quel bloqueur utilisez-vous? RÃ©sultats</a></li>
<li><a href="../fr464371/index.html">/etc/resolv.conf pour les pods Kubernetes, option ndots: 5, car cela peut nuire aux performances de l'application</a></li>
<li><a href="../fr464373/index.html">Edge-to-edge sur Android: bien faire les choses</a></li>
<li><a href="../fr464377/index.html">Assembleur sale pirate 6502</a></li>
<li><a href="../fr464381/index.html">Voyage en Alaska ou KDD'19 Ã  travers les yeux d'un tÃ©moin oculaire</a></li>
<li><a href="../fr464383/index.html">Comment je mets les choses en ordre dans un projet oÃ¹ il y a une forÃªt de mains directes (paramÃ¨tres tslint, plus joli, etc.)</a></li>
<li><a href="../fr464385/index.html">Python comme cas ultime de C ++. Partie 1/2</a></li>
<li><a href="../fr464387/index.html">Empreinte russe dans la saga scandinave des jeux vidÃ©o, fin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí• üò∑ üíø Wie wir die Zeit f√ºr die Entwicklung von Bewertungsmodellen f√ºnfmal verk√ºrzt haben, indem wir zu Python gewechselt sind ü§¥üèø üêÆ ‚úãüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jetzt reden alle viel √ºber k√ºnstliche Intelligenz und ihre Anwendung in allen Bereichen des Unternehmens. Es gibt jedoch einige Bereiche, in denen sei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir die Zeit f√ºr die Entwicklung von Bewertungsmodellen f√ºnfmal verk√ºrzt haben, indem wir zu Python gewechselt sind</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/idfinance/blog/421091/"><img src="https://habrastorage.org/webt/-z/kh/d3/-zkhd3-g2bfo-piumvjuva0iei4.png" alt="Bild"><br><br>  Jetzt reden alle viel √ºber k√ºnstliche Intelligenz und ihre Anwendung in allen Bereichen des Unternehmens.  Es gibt jedoch einige Bereiche, in denen seit der Antike ein Modelltyp dominiert hat, die sogenannte ‚ÄûWhite Box‚Äú - die logistische Regression.  Ein solcher Bereich ist die Bewertung von Bankkrediten. <br><a name="habracut"></a><br>  Daf√ºr gibt es mehrere Gr√ºnde: <br><br><ul><li>  Regressionskoeffizienten k√∂nnen im Gegensatz zu ‚ÄûBlack Boxes‚Äú wie Boosting, die mehr als 500 Variablen enthalten k√∂nnen, leicht erkl√§rt werden </li><li>  Maschinelles Lernen wird vom Management aufgrund der Schwierigkeit bei der Interpretation von Modellen immer noch nicht als vertrauensw√ºrdig eingestuft </li><li>  Es gibt ungeschriebene Anforderungen der Regulierungsbeh√∂rde an die Interpretierbarkeit von Modellen: Beispielsweise kann die Zentralbank jederzeit um eine Erkl√§rung bitten - warum ein Darlehen an den Kreditnehmer abgelehnt wurde </li><li> Unternehmen verwenden externe Data Mining-Programme (z. B. Rapid Miner, SAS Enterprise Miner, STATISTICA oder ein anderes Paket), mit denen Sie schnell lernen k√∂nnen, wie Sie Modelle ohne Programmierkenntnisse erstellen </li></ul><br>  Diese Gr√ºnde machen es in einigen Bereichen fast unm√∂glich, komplexe Modelle des maschinellen Lernens zu verwenden. Daher ist es wichtig, das Maximum aus einer einfachen logistischen Regression herauszuholen, die leicht zu erkl√§ren und zu interpretieren ist. <br><br>  In diesem Beitrag werden wir dar√ºber sprechen, wie wir beim Erstellen von Scoring externe Data Mining-Pakete zugunsten von Open Source-L√∂sungen in Form von Python aufgegeben, die Entwicklungsgeschwindigkeit um ein Vielfaches erh√∂ht und auch die Qualit√§t aller Modelle verbessert haben. <br><br><h3>  Bewertungsprozess </h3><br>  Der klassische Prozess der Erstellung von Bewertungsmodellen f√ºr die Regression sieht folgenderma√üen aus: <br><br><img src="https://habrastorage.org/webt/jn/e2/da/jne2da4ifmsjuhgui2piws8kbsi.png" alt="Bild"><br><br>  Es kann von Unternehmen zu Unternehmen unterschiedlich sein, aber die Hauptphasen bleiben konstant.  Wir m√ºssen immer eine Gruppierung von Variablen durchf√ºhren (im Gegensatz zum Paradigma des maschinellen Lernens, bei dem in den meisten F√§llen nur eine kategoriale Codierung erforderlich ist), deren √úberpr√ºfung anhand des Informationswerts (IV) und das manuelle Hochladen aller Koeffizienten und Klassen f√ºr die sp√§tere Integration in DSL. <br>  Dieser Ansatz zum Erstellen von Scoring-Karten hat in den 90er Jahren gut funktioniert, aber die Technologien klassischer Data Mining-Pakete sind sehr veraltet und erlauben nicht die Verwendung neuer Techniken, wie beispielsweise die L2-Regularisierung bei der Regression, die die Qualit√§t von Modellen erheblich verbessern kann. <br><br>  Als Studie haben wir uns einmal entschlossen, alle Schritte, die Analysten beim Erstellen von Scores ausf√ºhren, zu reproduzieren, sie mit dem Wissen von Data Scientists zu erg√§nzen und den gesamten Prozess so weit wie m√∂glich zu automatisieren. <br><br><h3>  Python-Verbesserung </h3><br>  Als Entwicklungswerkzeug haben wir Python wegen seiner Einfachheit und guten Bibliotheken ausgew√§hlt und begonnen, alle Schritte der Reihe nach zu spielen. <br><br>  Der erste Schritt besteht darin, Daten zu sammeln und Variablen zu generieren - diese Phase ist ein wesentlicher Bestandteil der Arbeit von Analysten. <br><br>  In Python k√∂nnen Sie gesammelte Daten mit pymysql aus der Datenbank laden. <br><br><div class="spoiler">  <b class="spoiler_title">Code zum Herunterladen aus der Datenbank</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">con</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> conn = pymysql.connect( host=<span class="hljs-string"><span class="hljs-string">'10.100.10.100'</span></span>, port=<span class="hljs-number"><span class="hljs-number">3306</span></span>, user=<span class="hljs-string"><span class="hljs-string">'******* '</span></span>, password=<span class="hljs-string"><span class="hljs-string">'*****'</span></span>, db=<span class="hljs-string"><span class="hljs-string">'mysql'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> conn; df = pd.read_sql(<span class="hljs-string"><span class="hljs-string">''' SELECT * FROM idf_ru.data_for_scoring '''</span></span>, con=con())</code> </pre> <br></div></div><br>  Als n√§chstes ersetzen wir die seltenen und fehlenden Werte durch eine separate Kategorie, um eine √úberanpassung zu verhindern, w√§hlen das Ziel aus, l√∂schen die zus√§tzlichen Spalten und teilen sie nach Zug und Test. <br><br><div class="spoiler">  <b class="spoiler_title">Datenaufbereitung</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">filling</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df)</span></span></span><span class="hljs-function">:</span></span> cat_vars = df.select_dtypes(include=[object]).columns num_vars = df.select_dtypes(include=[np.number]).columns df[cat_vars] = df[cat_vars].fillna(<span class="hljs-string"><span class="hljs-string">'_MISSING_'</span></span>) df[num_vars] = df[num_vars].fillna(np.nan) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">replace_not_frequent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cols, perc_min=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, value_to_replace = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"_ELSE_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> else_df = pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cols: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i != <span class="hljs-string"><span class="hljs-string">'date_requested'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> i != <span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>: t = df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) q = list(t[t.values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>].index) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> q: else_df = else_df.append(pd.DataFrame([[i, q]], columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>])) df.loc[df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)[df[i]].values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>, i] =value_to_replace else_df = else_df.set_index(<span class="hljs-string"><span class="hljs-string">'var'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df, else_df cat_vars = df.select_dtypes(include=[object]).columns df = filling(df) df, else_df = replace_not_frequent_2(df, cat_vars) df.drop([<span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'target_value'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bchg_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'last_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bcacr_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_bonuses_got'</span></span> ], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=<span class="hljs-number"><span class="hljs-number">0.33</span></span>, stratify=df.y, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>)</code> </pre> <br></div></div><br>  Jetzt beginnt die wichtigste Phase bei der Bewertung der Regression - Sie m√ºssen WOE-Binning f√ºr numerische und kategoriale Variablen schreiben.  Im √∂ffentlichen Bereich fanden wir keine guten und geeigneten Optionen f√ºr uns und beschlossen, selbst zu schreiben.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dieser</a> Artikel von 2017 wurde als Grundlage f√ºr das numerische Binning verwendet, ebenso wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser</a> kategorische Artikel, den sie selbst von Grund auf neu geschrieben haben.  Die Ergebnisse waren beeindruckend (Gini im Test stieg im Vergleich zu den Binning-Algorithmen externer Data Mining-Programme um 3-5). <br><br>  Danach k√∂nnen Sie sich die Grafiken oder Tabellen ansehen (die wir dann in Excel schreiben), wie die Variablen in Gruppen unterteilt sind, und die Monotonie √ºberpr√ºfen: <br><br><img src="https://habrastorage.org/webt/da/ij/2u/daij2uewkyujfn3jhdapc-yyfia.png" alt="Bild"><br><br><img src="https://habrastorage.org/webt/c6/if/3u/c6if3uqy--eqewru4nm9au1gwgw.png" alt="Bild"><br><br><div class="spoiler">  <b class="spoiler_title">Bean Charts rendern</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_bin</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ev, for_excel=False)</span></span></span><span class="hljs-function">:</span></span> ind = np.arange(len(ev.index)) width = <span class="hljs-number"><span class="hljs-number">0.35</span></span> fig, ax1 = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) ax2 = ax1.twinx() p1 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], width, color=(<span class="hljs-number"><span class="hljs-number">24</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">192</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">196</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) p2 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'EVENT'</span></span>], width, bottom=ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], color=(<span class="hljs-number"><span class="hljs-number">246</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) ax1.set_ylabel(<span class="hljs-string"><span class="hljs-string">'Event Distribution'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) ax2.set_ylabel(<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) plt.title(list(ev.VAR_NAME)[<span class="hljs-number"><span class="hljs-number">0</span></span>], fontsize=<span class="hljs-number"><span class="hljs-number">20</span></span>) ax2.plot(ind, ev[<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>], marker=<span class="hljs-string"><span class="hljs-string">'o'</span></span>, color=<span class="hljs-string"><span class="hljs-string">'blue'</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Legend plt.legend((p2[0], p1[0]), ('bad', 'good'), loc='best', fontsize=10) #Set xticklabels q = list() for i in range(len(ev)): try: mn = str(round(ev.MIN_VALUE[i], 2)) mx = str(round(ev.MAX_VALUE[i], 2)) except: mn = str((ev.MIN_VALUE[i])) mx = str((ev.MAX_VALUE[i])) q.append(mn + '-' + mx) plt.xticks(ind, q, rotation='vertical') for tick in ax1.get_xticklabels(): tick.set_rotation(60) plt.savefig('{}.png'.format(ev.VAR_NAME[0]), dpi=500, bbox_inches = 'tight') plt.show() def plot_all_bins(iv_df): for i in [x.replace('WOE_','') for x in X_train.columns]: ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) plot_bin(ev)</span></span></code> </pre> <br></div></div><br>  Eine Funktion zum manuellen Binning wurde separat geschrieben, was beispielsweise bei der Variablen ‚ÄûOS-Version‚Äú n√ºtzlich ist, bei der alle Android- und iOS-Telefone manuell gruppiert wurden. <br><br><div class="spoiler">  <b class="spoiler_title">Manuelle Binning-Funktion</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">adjust_binning</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, bins_dict)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(bins_dict)): key = list(bins_dict.keys())[i] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> type(list(bins_dict.values())[i])==dict: df[key] = df[key].map(list(bins_dict.values())[i]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment">#Categories labels categories = list() for j in range(len(list(bins_dict.values())[i])): if j == 0: categories.append('&lt;'+ str(list(bins_dict.values())[i][j])) try: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') except: categories.append('(' + str(list(bins_dict.values())[i][j])) elif j==len(list(bins_dict.values())[i])-1: categories.append(str(list(bins_dict.values())[i][j]) +'&gt;') else: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') values = [df[key].min()] + list(bins_dict.values())[i] + [df[key].max()] df[key + '_bins'] = pd.cut(df[key], values, include_lowest=True, labels=categories).astype(object).fillna('_MISSING_').astype(str) df[key] = df[key + '_bins']#.map(df.groupby(key + '_bins')[key].agg('median')) df.drop([key + '_bins'], axis=1, inplace=True) return df bins_dict = { 'equi_delinquencyDays': [ 200,400,600] 'loan_purpose': {'medicine':'1_group', 'repair':'1_group', 'helpFriend':'2_group'} } df = adjust_binning(df, bins_dict)</span></span></code> </pre> <br></div></div><br>  Der n√§chste Schritt ist die Auswahl der Variablen nach Informationswert.  Der Standardwert ist 0,1 (alle unten aufgef√ºhrten Variablen haben keine gute Vorhersagekraft). <br><br>  Nach der √úberpr√ºfung auf Korrelation wurde durchgef√ºhrt.  Von den beiden korrelierenden Variablen m√ºssen Sie die mit weniger IV entfernen.  Die abgeschnittene Entfernung wurde 0,75 genommen. <br><br><img src="https://habrastorage.org/webt/sv/7g/f0/sv7gf0nt_7sayq8jgjsjo_bfmpy.png" alt="Bild"><br><br><div class="spoiler">  <b class="spoiler_title">Korrelationsentfernung</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_correlated_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.75</span></span></span></span><span class="hljs-function"><span class="hljs-params">, exclude = [])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create correlation matrix corr_matrix = df.corr().abs() # Select upper triangle of correlation matrix upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # Plotting All correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('All correlations', fontsize=20) sns.heatmap(X_train.corr(), annot=True) # Plotting highly correlated try: f, ax = plt.subplots(figsize=(15, 10)) plt.title('High correlated', fontsize=20) sns.heatmap(corr_matrix[(corr_matrix&gt;cut_off) &amp; (corr_matrix!=1)].dropna(axis=0, how='all').dropna(axis=1, how='all'), annot=True, linewidths=.5) except: print ('No highly correlated features found') # Find index of feature columns with correlation greater than cut_off to_drop = [column for column in upper.columns if any(upper[column] &gt; cut_off)] to_drop = [column for column in to_drop if column not in exclude] print ('Dropped columns:', to_drop, '\n') df2 = df.drop(to_drop, axis=1) print ('Features left after correlation check: {}'.format(len(df.columns)-len(to_drop)), '\n') print ('Not dropped columns:', list(df2.columns), '\n') # Plotting final correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('Final correlations', fontsize=20) sns.heatmap(df2.corr(), annot=True) plt.show() return df2</span></span></code> </pre> <br></div></div><br>  Zus√§tzlich zur Auswahl nach IV haben wir eine rekursive Suche nach der optimalen Anzahl von Variablen nach der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RFE-</a> Methode von sklearn hinzugef√ºgt. <br>  Wie wir in der Grafik sehen, √§ndert sich die Qualit√§t nach 13 Variablen nicht, was bedeutet, dass die zus√§tzlichen gel√∂scht werden k√∂nnen.  Bei der Regression werden mehr als 15 Variablen in der Bewertung als schlechte Form angesehen, die in den meisten F√§llen mithilfe von RFE korrigiert wird. <br><br><img src="https://habrastorage.org/webt/4y/sm/2c/4ysm2cgo50qcscs2rigxeksod6y.png" alt="Bild"><br><div class="spoiler">  <b class="spoiler_title">RFE</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RFE_feature_selection</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf_lr, X, y)</span></span></span><span class="hljs-function">:</span></span> rfecv = RFECV(estimator=clf_lr, step=<span class="hljs-number"><span class="hljs-number">1</span></span>, cv=StratifiedKFold(<span class="hljs-number"><span class="hljs-number">5</span></span>), verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'roc_auc'</span></span>) rfecv.fit(X, y) print(<span class="hljs-string"><span class="hljs-string">"Optimal number of features : %d"</span></span> % rfecv.n_features_) <span class="hljs-comment"><span class="hljs-comment"># Plot number of features VS. cross-validation scores f, ax = plt.subplots(figsize=(14, 9)) plt.xlabel("Number of features selected") plt.ylabel("Cross validation score (nb of correct classifications)") plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_) plt.show() mask = rfecv.get_support() X = X.ix[:, mask] return X</span></span></code> </pre> <br></div></div><br>  Als n√§chstes wurde eine Regression erstellt und ihre Metriken wurden anhand von Kreuzvalidierung und Teststichproben bewertet.  Normalerweise schaut sich jeder den Gini-Koeffizienten an (ein guter Artikel √ºber ihn <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ). <br><br><img src="https://habrastorage.org/webt/kb/mm/uf/kbmmufj5bxr4jybxad88d1pyggg.png" alt="Bild"><br><br><div class="spoiler">  <b class="spoiler_title">Simulationsergebnisse</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf, X_test, y_test, feat_to_show=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">30</span></span></span></span><span class="hljs-function"><span class="hljs-params">, is_normalize=False, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#cm = confusion_matrix(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test) print ('ROC_AUC: ', round(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]), 3)) print ('Gini: ', round(2*roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]) - 1, 3)) print ('F1_score: ', round(f1_score(y_test, clf.predict(X_test)), 3)) print ('Log_loss: ', round(log_loss(y_test, clf.predict(X_test)), 3)) print ('\n') print ('Classification_report: \n', classification_report(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test)) skplt.metrics.plot_confusion_matrix(y_test, pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), title="Confusion Matrix", normalize=is_normalize,figsize=(8,8),text_fontsize='large') display(eli5.show_weights(clf, top=20, feature_names = list(X_test.columns))) clf_lr = LogisticRegressionCV(random_state=1, cv=7) clf_lr.fit(X_train, y_train) plot_score(clf_lr, X_test, y_test, cut_off=0.5)</span></span></code> </pre> <br></div></div><br>  Wenn wir sicherstellen, dass die Modellqualit√§t zu uns passt, m√ºssen alle Ergebnisse (Regressionskoeffizienten, Bin-Gruppen, Gini-Stabilit√§tsdiagramme und -Variablen usw.) in Excel geschrieben werden.  Zu diesem Zweck ist es zweckm√§√üig, xlsxwriter zu verwenden, der sowohl mit Daten als auch mit Bildern arbeiten kann. <br><br>  Beispiele f√ºr Excel-Tabellen: <br><br><img src="https://habrastorage.org/webt/um/fg/fn/umfgfnwv9fo7hxo8lqq8fwyppes.png" alt="Bild"><br><br><img src="https://habrastorage.org/webt/xw/ym/1y/xwym1ynrybf7uhvlagzjrjshz_y.png" alt="Bild"><br><br><div class="spoiler">  <b class="spoiler_title">Rekord in Excel</b> <div class="spoiler_text"><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#WRITING writer = pd.ExcelWriter('PDL_Score_20180815-3.xlsx', engine='xlsxwriter') workbook = writer.book worksheet = workbook.add_worksheet('Sample information') bold = workbook.add_format({'bold': True}) percent_fmt = workbook.add_format({'num_format': '0.00%'}) worksheet.set_column('A:A', 20) worksheet.set_column('B:B', 15) worksheet.set_column('C:C', 10) # Sample worksheet.write('A2', 'Sample conditions', bold) worksheet.write('A3', 1) worksheet.write('A4', 2) worksheet.write('A5', 3) worksheet.write('A6', 4) # Model worksheet.write('A8', 'Model development', bold) worksheet.write('A9', 1) #labels worksheet.write('C8', 'Bads') worksheet.write('D8', 'Goods') worksheet.write('B9', 'Train') worksheet.write('B10', 'Valid') worksheet.write('B11', 'Total') # goods and bads worksheet.write('C9', y_train.value_counts()[1]) worksheet.write('C10', y_test.value_counts()[1]) worksheet.write('D9', y_train.value_counts()[0]) worksheet.write('D10', y_test.value_counts()[0]) worksheet.write('C11', y.value_counts()[1]) worksheet.write('D11', y.value_counts()[0]) # NPL worksheet.write('A13', 2) worksheet.write('B13', 'NPL') worksheet.write('C13', (y.value_counts()[1]/(y.value_counts()[1]+y.value_counts()[0])), percent_fmt) worksheet.write('A16', 3) worksheet.write('C15', 'Gini') worksheet.write('B16', 'Train') worksheet.write('B17', 'Valid') worksheet.write('B18', 'CV Scores') worksheet.write('C18', str([round(sc, 2) for sc in scores])) worksheet.write('C16', round(2*roc_auc_score(y_train, clf_lr.predict_proba(X_train)[:,1]) - 1, 3)) worksheet.write('C17', round(2*roc_auc_score(y_test, clf_lr.predict_proba(X_test)[:,1]) - 1, 3)) # Regreesion coefs feat.to_excel(writer, sheet_name='Regression coefficients', index=False) worksheet2 = writer.sheets['Regression coefficients'] worksheet2.set_column('A:A', 15) worksheet2.set_column('B:B', 50) #WOE ivs[['VAR_NAME', 'Variable range', 'WOE', 'COUNT', 'WOE_group']].to_excel(writer, sheet_name='WOE', index=False) worksheet3 = writer.sheets['WOE'] worksheet3.set_column('A:A', 50) worksheet3.set_column('B:B', 60) worksheet3.set_column('C:C', 30) worksheet3.set_column('D:D', 20) worksheet3.set_column('E:E', 12) for num, i in enumerate([x.replace('WOE_','') for x in X_train.columns]): ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) worksheet3.insert_image('G{}'.format(num*34+1), '{}.png'.format(i)) df3.to_excel(writer, sheet_name='Data', index=False) table.to_excel(writer, sheet_name='Scores by buckets', header = True, index = True) worksheet4 = writer.sheets['Scores by buckets'] worksheet4.set_column('A:A', 20) worksheet4.insert_image('J1', 'score_distribution.png') Ginis.to_excel(writer, sheet_name='Gini distribution', header = True, index = True) worksheet5 = writer.sheets['Gini distribution'] worksheet5.insert_image('E1', 'gini_stability.png') writer.save()</span></span></code> </pre> <br></div></div><br>  Am Ende wird das endg√ºltige Excel erneut vom Management gepr√ºft. Anschlie√üend wird es der IT zur Einbettung des Modells in die Produktion √ºbergeben. <br><br><h3>  Zusammenfassung </h3><br>  Wie wir gesehen haben, k√∂nnen fast alle Phasen des Scorings automatisiert werden, sodass Analysten keine Programmierkenntnisse ben√∂tigen, um Modelle zu erstellen.  In unserem Fall muss der Analyst nach dem Erstellen dieses Frameworks nur Daten erfassen und mehrere Parameter angeben (geben Sie die Zielvariable an, welche Spalten entfernt werden sollen, die Mindestanzahl von Bins, den Grenzkoeffizienten f√ºr die Korrelation von Variablen usw.). Danach k√∂nnen Sie das Skript in Python ausf√ºhren. Dadurch wird das Modell erstellt und Excel mit den gew√ºnschten Ergebnissen erstellt. <br>  Nat√ºrlich ist es manchmal erforderlich, den Code f√ºr die Anforderungen eines bestimmten Projekts zu korrigieren, und Sie k√∂nnen das Skript w√§hrend der Modellierung nicht mit einer einzigen Schaltfl√§che ausf√ºhren, aber selbst jetzt sehen wir dank Techniken wie optimalem und monotonem Binning und Korrelationspr√ºfung eine bessere Qualit√§t als die auf dem Markt verwendeten Data Mining-Pakete , RFE, regulierte Version der Regression usw. <br><br>  Dank der Verwendung von Python konnten wir die Entwicklungszeit f√ºr das Scoring von Karten erheblich reduzieren und die Arbeitskosten f√ºr Analysten senken. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421091/">https://habr.com/ru/post/de421091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421081/index.html">Zu wenige Menschen achten auf diesen wirtschaftlichen Trend.</a></li>
<li><a href="../de421083/index.html">Vergessene Kunst, Verpackungen f√ºr Grafikkarten zu dekorieren</a></li>
<li><a href="../de421085/index.html">Elon Musk ist nicht die Zukunft</a></li>
<li><a href="../de421087/index.html">So richten Sie die Bereitstellung von Webanwendungen unter Go for Gitlab auf VDS ein</a></li>
<li><a href="../de421089/index.html">Russische Anbieter haben herausgefunden, wie ein Teil der Kosten des ‚ÄûFr√ºhlingspakets‚Äú an Google √ºbertragen werden kann.</a></li>
<li><a href="../de421093/index.html">Wie ich Spring Framework studiere - Teil 2 (Hilfe f√ºr Anf√§nger - die Arbeit der Anf√§nger selbst)</a></li>
<li><a href="../de421095/index.html">Unter dem neuen Gesetzentwurf zur Sperrung vor dem Prozess k√∂nnten 19 Millionen Standorte fallen</a></li>
<li><a href="../de421097/index.html">Zusammensetzung der UIViewController und Navigation zwischen ihnen (und nicht nur)</a></li>
<li><a href="../de421099/index.html">Ist es schwer sich zu konzentrieren? Vielleicht ist es nicht deine Schuld</a></li>
<li><a href="../de421101/index.html">"Testerkalender" f√ºr August. Lies ein Buch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
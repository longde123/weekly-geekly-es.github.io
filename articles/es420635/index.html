<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ò∏Ô∏è üôÖüèæ üèÆ AI, curso pr√°ctico. El modelo b√°sico para reconocer emociones en im√°genes. „Ä∞Ô∏è üëÇüèø üèÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En este art√≠culo, construiremos un modelo b√°sico de una red neuronal convolucional que sea capaz de realizar el reconocimiento de las emociones en las...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°ctico. El modelo b√°sico para reconocer emociones en im√°genes.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/420635/"><img src="https://habrastorage.org/webt/kp/it/ob/kpitobaccifc3jg-td-z6lgmz9i.jpeg"><br><br>  En este art√≠culo, construiremos un modelo b√°sico de una red neuronal convolucional que sea capaz de realizar el <i>reconocimiento de las emociones</i> en las im√°genes.  El reconocimiento de las emociones en nuestro caso es una tarea de clasificaci√≥n binaria, cuyo prop√≥sito es dividir las im√°genes en positivas y negativas. <br><br>  Aqu√≠ puede encontrar todo el c√≥digo, los documentos del cuaderno y otros materiales, incluido el Dockerfile. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Datos</font> </h2><br>  El primer paso en pr√°cticamente todas las tareas de aprendizaje autom√°tico es comprender los datos.  Hag√°moslo <br><br><h3>  <font color="#0071c5">Estructura del conjunto de datos</font> </h3><br>  Los datos sin procesar se pueden descargar <a href="">aqu√≠</a> (en el documento <i>Baseline.ipynb</i> , todas las acciones en esta secci√≥n se realizan autom√°ticamente).  Inicialmente, los datos est√°n en el archivo del formato Zip *.  Desempaquete y familiar√≠cese con la estructura de los archivos recibidos. <br><br><img src="https://habrastorage.org/webt/wm/wj/ne/wmwjne07sdpbzoitoa0xxz1zcie.png"><br><br>  Todas las im√°genes se almacenan dentro del cat√°logo del "conjunto de datos 50:50" y se distribuyen entre sus dos subdirectorios, cuyo nombre corresponde a su clase: Negativo y Positivo.  Tenga en cuenta que la tarea est√° un poco <i>desequilibrada</i> : el 53 por ciento de las im√°genes son positivas y solo el 47 por ciento son negativas.  T√≠picamente, los datos en problemas de clasificaci√≥n se consideran desequilibrados si el n√∫mero de ejemplos en diferentes clases var√≠a de manera muy significativa.  Hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">varias formas de</a> trabajar con datos desequilibrados, por ejemplo, sobremuestreo, sobremuestreo, cambio del peso de los datos, etc. En nuestro caso, el desequilibrio es insignificante y no deber√≠a afectar dr√°sticamente el proceso de aprendizaje.  Solo es necesario recordar que el clasificador ingenuo, siempre produciendo el valor "positivo", proporcionar√° un valor de precisi√≥n de aproximadamente el 53 por ciento para este conjunto de datos. <br><br>  Veamos algunas im√°genes de cada clase. <br><br>  <b>Negativo</b> <br><br><img src="https://habrastorage.org/webt/q4/5d/fc/q45dfcprljvv5tnm0aqvwwgs0uy.jpeg"><br><br><img src="https://habrastorage.org/webt/ep/0p/4q/ep0p4qkimflvz7euzaam1bc39a8.jpeg"><br><br><img src="https://habrastorage.org/webt/dj/ep/px/djeppxcpw5hgct0melwhlvjafsu.jpeg"><br><br>  <b>Positivo</b> <br><br><img src="https://habrastorage.org/webt/w6/rs/5j/w6rs5je45iwv-m22jf4vjomcs1s.jpeg"><br><br><img src="https://habrastorage.org/webt/fa/r4/af/far4afuqyyajc3xfqjwnj98xkbo.jpeg"><br><br><img src="https://habrastorage.org/webt/ky/ae/q2/kyaeq2nx8wqpkmnba9y2mugejai.jpeg"><br><br>  A primera vista, las im√°genes de diferentes clases son realmente diferentes entre s√≠.  Sin embargo, hagamos un estudio m√°s profundo e intentemos encontrar malos ejemplos: im√°genes similares pertenecientes a diferentes clases. <br><br>  Por ejemplo, tenemos alrededor de 90 im√°genes de serpientes etiquetadas como negativas y alrededor de 40 im√°genes muy similares de serpientes etiquetadas como positivas. <br><br>  <b>Imagen positiva de una serpiente.</b> <br><br><img src="https://habrastorage.org/webt/-m/es/5g/-mes5gboq8vn6p28etujmipmjme.jpeg"><br><br>  <b>Imagen negativa de una serpiente</b> <br><br><img src="https://habrastorage.org/webt/np/1f/dv/np1fdvdekusz5cokd96cjou7smu.jpeg"><br><br>  La misma dualidad ocurre con las ara√±as (130 im√°genes negativas y 20 positivas), la desnudez (15 im√°genes negativas y 45 positivas) y algunas otras clases.  Uno tiene la sensaci√≥n de que el marcado de las im√°genes fue realizado por diferentes personas, y su percepci√≥n de la misma imagen puede diferir.  Por lo tanto, el etiquetado contiene su inconsistencia inherente.  Estas dos im√°genes de serpientes son casi id√©nticas, mientras que diferentes expertos las atribuyen a diferentes clases.  Por lo tanto, podemos concluir que es casi imposible garantizar una precisi√≥n del 100% cuando se trabaja con esta tarea debido a su naturaleza.  Creemos que una estimaci√≥n m√°s realista de la precisi√≥n ser√≠a un valor del 80 por ciento; este valor se basa en la proporci√≥n de im√°genes similares encontradas en diferentes clases durante una verificaci√≥n visual preliminar. <br><br><h3>  <font color="#0071c5">Separaci√≥n del proceso de capacitaci√≥n / verificaci√≥n.</font> </h3><br>  Siempre nos esforzamos por crear el mejor modelo posible.  Sin embargo, ¬øcu√°l es el significado de este concepto?  Hay muchos criterios diferentes para esto, como: calidad, tiempo de entrega (aprendizaje + obtenci√≥n de resultados) y consumo de memoria.  Algunos de ellos se pueden medir de manera f√°cil y objetiva (por ejemplo, el tiempo y el tama√±o de la memoria), mientras que otros (calidad) son mucho m√°s dif√≠ciles de determinar.  Por ejemplo, su modelo puede demostrar una precisi√≥n del 100 por ciento al aprender de ejemplos que se han utilizado muchas veces, pero no funcionan con ejemplos nuevos.  Este problema se llama <i>sobreajuste</i> y es uno de los m√°s importantes en el aprendizaje autom√°tico.  Tambi√©n existe el problema de la <i>falta</i> de <i>ajuste</i> : en este caso, el modelo no puede aprender de los datos presentados y muestra malas predicciones incluso cuando se utiliza un conjunto de datos de entrenamiento fijo. <br><br>  Para resolver el problema del sobreajuste, se utiliza la llamada t√©cnica de <i>mantener parte de las muestras</i> .  Su idea principal es dividir los datos de origen en dos partes: <br><br><ul><li>  <i>Un conjunto de entrenamiento</i> , que generalmente constituye la mayor parte del conjunto de datos y se utiliza para entrenar el modelo. </li><li>  <i>El conjunto de pruebas suele</i> ser una peque√±a parte de los datos de origen, que se divide en dos partes antes de realizar todos los procedimientos de capacitaci√≥n.  Este conjunto no se utiliza en absoluto en el entrenamiento y se considera como nuevos ejemplos para probar el modelo despu√©s de completar el entrenamiento. </li></ul><br>  Con este m√©todo, podemos observar qu√© tan bien <i>generaliza</i> nuestro modelo (es decir, funciona con ejemplos previamente desconocidos). <br><br>  Este art√≠culo utilizar√° una proporci√≥n de 4/1 para los conjuntos de entrenamiento y prueba.  Otra t√©cnica que utilizamos es la llamada <i>estratificaci√≥n</i> .  Este t√©rmino se refiere a la partici√≥n de cada clase independientemente de todas las dem√°s clases.  Este enfoque permite mantener el mismo equilibrio entre el tama√±o de las clases en los conjuntos de entrenamiento y prueba.  La estratificaci√≥n utiliza impl√≠citamente la suposici√≥n de que la distribuci√≥n de ejemplos no cambia cuando los datos de origen cambian y permanece igual cuando se usan nuevos ejemplos. <br><br><img src="https://habrastorage.org/webt/pn/gq/lz/pngqlzmf15cnm-4cwjvblndwpsg.png"><br><br>  Ilustramos el concepto de estratificaci√≥n con un ejemplo simple.  Supongamos que tenemos cuatro grupos de datos / clases con un n√∫mero apropiado de objetos: ni√±os (5), adolescentes (10), adultos (80) y personas mayores (5);  ver foto a la derecha (de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wikipedia</a> ).  Ahora necesitamos dividir estos datos en dos conjuntos de muestras en una proporci√≥n de 3/2.  Al utilizar la estratificaci√≥n de ejemplos, la selecci√≥n de objetos se realizar√° independientemente de cada grupo: 2 objetos del grupo de ni√±os, 4 objetos del grupo de adolescentes, 32 objetos del grupo de adultos y 2 objetos del grupo de personas mayores.  El nuevo conjunto de datos contiene 40 objetos, que son exactamente 2/5 de los datos originales.  Al mismo tiempo, el equilibrio entre las clases en el nuevo conjunto de datos corresponde a su equilibrio en los datos de origen. <br><br>  Todas las acciones anteriores se implementan en una funci√≥n, que se llama <i>prepare_data</i> ;  Esta funci√≥n se puede encontrar en el archivo Python <i>utils.py</i> .  Esta funci√≥n carga los datos, los divide en conjuntos de entrenamiento y prueba usando un n√∫mero aleatorio fijo (para reproducci√≥n posterior), y luego distribuye los datos en consecuencia entre los directorios en el disco duro para su uso posterior. <br><br><h3>  <font color="#0071c5">Pretratamiento y aumento</font> </h3><br>  En uno de los art√≠culos anteriores, se describieron las acciones de preprocesamiento y las posibles razones para su uso en forma de aumento de datos.  Las redes neuronales convolucionales son modelos bastante complejos, y se requieren grandes cantidades de datos para entrenarlos.  En nuestro caso, solo hay 1600 ejemplos; esto, por supuesto, no es suficiente. <br><br>  Por lo tanto, queremos expandir el conjunto de datos utilizados por el <i>aumento de</i> datos.  De acuerdo con la informaci√≥n contenida en el art√≠culo sobre preprocesamiento de datos, la biblioteca Keras * brinda la capacidad de aumentar los datos sobre la marcha al leerlos desde el disco duro.  Esto se puede hacer a trav√©s de la clase <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageDataGenerator</a> . <br><br><img src="https://habrastorage.org/webt/3m/j8/oe/3mj8oewbjg3j8eriel5opmj43cc.png"><br><br>  Aqu√≠ se crean dos instancias de los generadores.  La primera instancia es para entrenamiento y usa muchas transformaciones aleatorias, como rotaci√≥n, cambio, convoluci√≥n, escala y rotaci√≥n horizontal, mientras lee datos del disco y los transfiere al modelo.  Como resultado, el modelo recibe los ejemplos convertidos, y cada ejemplo recibido por el modelo es √∫nico debido a la naturaleza aleatoria de esta conversi√≥n.  La segunda copia es para verificaci√≥n, y solo ampl√≠a las im√°genes.  Los generadores de aprendizaje y prueba solo tienen una transformaci√≥n com√∫n: el zoom.  Para asegurar la estabilidad computacional del modelo, es necesario usar el rango [0;  1] en lugar de [0;  255]. <br><br><h2>  <font color="#0071c5">Arquitectura modelo</font> </h2><br>  Despu√©s de estudiar y preparar los datos iniciales, sigue la etapa de creaci√≥n del modelo.  Dado que tenemos disponible una peque√±a cantidad de datos, vamos a construir un modelo relativamente simple para poder entrenarlo adecuadamente y eliminar la situaci√≥n de sobreajuste.  Probemos con la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitectura de</a> estilo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VGG</a> , pero usemos menos capas y filtros. <br><br><img src="https://habrastorage.org/webt/xa/dl/ae/xadlae7ebpbynxk60facw3_bxho.png"><br><br><img src="https://habrastorage.org/webt/2b/xr/cy/2bxrcyazsu_gasst_aqr5ao7ayu.png"><br><br>  La arquitectura de red consta de las siguientes partes: <br>  <b>[Capa de convoluci√≥n + capa de convoluci√≥n + selecci√≥n de valor m√°ximo] √ó 2</b> <br>  La primera parte contiene dos capas convolucionales superpuestas con 64 filtros (con tama√±o 3 y paso 2) y una capa para seleccionar el valor m√°ximo (con tama√±o 2 y paso 2) ubicado despu√©s de ellos.  Esta parte tambi√©n se conoce com√∫nmente como <i>una unidad de extracci√≥n de caracter√≠sticas</i> , ya que los filtros extraen eficientemente caracter√≠sticas significativas de los datos de entrada (consulte el art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descripci√≥n general de redes neuronales convolucionales para la clasificaci√≥n de im√°genes</a> para obtener m√°s informaci√≥n). <br><br>  <b>Alineaci√≥n</b> <br><br>  Esta parte es obligatoria, ya que los tensores de cuatro dimensiones se obtienen a la salida de la parte convolucional (ejemplos, altura, ancho y canales).  Sin embargo, para una capa ordinaria totalmente conectada, necesitamos un tensor bidimensional (ejemplos, caracter√≠sticas) como entrada.  Por lo tanto, es necesario <i>alinear el</i> tensor alrededor de los √∫ltimos tres ejes para combinarlos en un eje.  De hecho, esto significa que consideramos cada punto en cada mapa de entidades como una propiedad separada y los alineamos en un vector.  La siguiente figura muestra un ejemplo de una imagen 4 √ó 4 con 128 canales, que se alinea en un vector extendido con una longitud de 1024 elementos. <br><br><img src="https://habrastorage.org/webt/zs/-f/_h/zs-f_h8_mr6flzz62vo21qttt0u.png"><br><br>  <b>[Capa completa + m√©todo de exclusi√≥n] √ó 2</b> <br><br>  Aqu√≠ est√° la <i>parte de clasificaci√≥n de la</i> red.  Ella toma una vista alineada de las caracter√≠sticas de las im√°genes e intenta clasificarlas de la mejor manera posible.  Esta parte de la red consta de dos bloques superpuestos que consisten en una capa totalmente conectada y <i>un m√©todo de exclusi√≥n</i> .  Ya nos hemos familiarizado con las capas totalmente conectadas, por lo general, son capas con una conexi√≥n totalmente conectada.  Pero, ¬øqu√© es el "m√©todo de exclusi√≥n"?  El m√©todo de exclusi√≥n es una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">t√©cnica de regularizaci√≥n</a> que ayuda a prevenir el sobreajuste.  Uno de los posibles signos de sobreajuste son los valores extremadamente diferentes de los coeficientes de peso (√≥rdenes de magnitud).  Hay muchas formas de resolver este problema, incluida la reducci√≥n de peso y el m√©todo de eliminaci√≥n.  La idea del m√©todo de eliminaci√≥n es desconectar neuronas aleatorias durante el entrenamiento (la lista de neuronas desconectadas debe actualizarse despu√©s de cada paquete / era de entrenamiento).  Esto evita fuertemente obtener valores completamente diferentes para los coeficientes de ponderaci√≥n, de esta manera la red se regulariza. <br><br><img src="https://habrastorage.org/webt/1x/g5/vw/1xg5vwjp4syjmujonokwl9i-ilo.png"><br><br>  Un ejemplo de la aplicaci√≥n del m√©todo de exclusi√≥n (la figura est√° tomada del art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">M√©todo de exclusi√≥n: una forma f√°cil de evitar el sobreajuste en redes neuronales</a> ): <br><br>  <b>M√≥dulo sigmoide</b> <br><br>  La capa de salida debe corresponder a la declaraci√≥n del problema.  En este caso, estamos lidiando con el problema de clasificaci√≥n binaria, por lo que necesitamos una neurona de salida con una funci√≥n de activaci√≥n <i>sigmoidea</i> , que estima la probabilidad P de pertenecer a la clase con el n√∫mero 1 (en nuestro caso, ser√°n im√°genes positivas).  Entonces, la probabilidad de pertenecer a la clase con el n√∫mero 0 (im√°genes negativas) se puede calcular f√°cilmente como 1 - P. <br><br><h2>  <font color="#0071c5">Configuraciones y opciones de entrenamiento</font> </h2><br>  Elegimos la arquitectura del modelo y la especificamos utilizando la biblioteca Keras para el lenguaje Python.  Adem√°s, antes de comenzar el entrenamiento modelo, es necesario <i>compilarlo</i> . <br><br><img src="https://habrastorage.org/webt/th/pv/l8/thpvl8hahgpnyucfsfhxpk5qq8w.png"><br><br>  En la etapa de compilaci√≥n, el modelo est√° ajustado para el entrenamiento.  En este caso, se deben especificar tres par√°metros principales: <br><br><ul><li>  <i>El optimizador</i>  En este caso, utilizamos el optimizador predeterminado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Adam</a> *, que es un tipo de algoritmo estoc√°stico de descenso de gradiente con un momento y velocidad de aprendizaje adaptativa (para obtener m√°s informaci√≥n, consulte la entrada del blog de S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descripci√≥n general de los algoritmos de optimizaci√≥n de descenso de gradiente</a> ). </li><li>  <i>Funci√≥n de p√©rdida</i> .  Nuestra tarea es un problema de clasificaci√≥n binaria, por lo que ser√≠a apropiado utilizar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">entrop√≠a cruzada binaria</a> como una funci√≥n de p√©rdida. </li><li>  <i>M√©tricas</i>  Este es un argumento opcional con el que puede especificar m√©tricas adicionales para realizar un seguimiento durante el proceso de capacitaci√≥n.  En este caso, necesitamos rastrear la precisi√≥n junto con la funci√≥n objetivo. </li></ul><br>  Ahora estamos listos para entrenar al modelo.  Tenga en cuenta que el procedimiento de capacitaci√≥n se realiza utilizando los generadores inicializados en la secci√≥n anterior. <br><br>  El n√∫mero de eras es otro hiperpar√°metro que se puede personalizar.  Aqu√≠ simplemente le asignamos un valor de 10. Tambi√©n queremos guardar el modelo y el historial de aprendizaje para poder descargarlo m√°s tarde. <br><br><img src="https://habrastorage.org/webt/mt/3o/cd/mt3ocd0xfdxmshq_7tv1xptw5de.png"><br><br><h2>  <font color="#0071c5">Calificaci√≥n</font> </h2><br>  Ahora veamos qu√© tan bien funciona nuestro modelo.  En primer lugar, consideramos el cambio en las m√©tricas en el proceso de aprendizaje. <br><br><img src="https://habrastorage.org/webt/d-/_j/1l/d-_j1lty0qibl5gkwrhy3avbgzq.png"><br><br>  En la figura, puede ver que la entrop√≠a cruzada de verificaci√≥n y precisi√≥n no disminuye con el tiempo.  Adem√°s, la m√©trica de precisi√≥n para el conjunto de entrenamiento y prueba simplemente fluct√∫a alrededor del valor de un clasificador aleatorio.  La precisi√≥n final para el conjunto de prueba es del 55 por ciento, que es solo un poco mejor que una estimaci√≥n aleatoria. <br><br>  Veamos c√≥mo se distribuyen las predicciones del modelo entre clases.  Para este prop√≥sito, es necesario crear y visualizar una <i>matriz de imprecisiones</i> usando la funci√≥n correspondiente del paquete Sklearn * para el lenguaje Python. <br>  Cada celda en la matriz de imprecisiones tiene su propio nombre: <br><br><img src="https://habrastorage.org/webt/p4/9j/mj/p49jmjgtuc4fhqxfd_szqm6qvtw.png"><br><br><ul><li>  La tasa positiva verdadera = TPR (celda superior derecha) representa la proporci√≥n de ejemplos positivos (clase 1, es decir, emociones <i>positivas</i> en nuestro caso), clasificados correctamente como positivos. </li><li>  La tasa de falsos positivos = FPR (celda inferior derecha) representa la proporci√≥n de ejemplos positivos que se clasifican incorrectamente como <i>negativos</i> (clase 0, es decir, emociones negativas). </li><li>  La tasa negativa verdadera = TNR (celda inferior izquierda) representa la proporci√≥n de ejemplos negativos que se clasifican correctamente como negativos. </li><li>  La tasa negativa falsa = FNR (celda superior izquierda) representa la proporci√≥n de ejemplos negativos que se clasifican incorrectamente como positivos. </li></ul><br>  En nuestro caso, tanto TPR como FPR est√°n cerca de 1. Esto significa que casi todos los objetos se clasificaron como positivos.  Por lo tanto, nuestro modelo no est√° muy alejado del modelo base ingenuo con predicciones constantes de una clase m√°s grande (en nuestro caso, estas son im√°genes positivas). <br><br>  Otra m√©trica interesante que es interesante observar es la curva de rendimiento del receptor (curva ROC) y el √°rea bajo esta curva (ROC AUC).  Una definici√≥n formal de estos conceptos se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  En pocas palabras, la curva ROC muestra qu√© tan bien funciona el clasificador binario. <br><br>  El clasificador de nuestra red neuronal convolucional tiene un m√≥dulo sigmoide como salida, que asigna la probabilidad del ejemplo a la clase 1. Ahora suponga que nuestro clasificador muestra un buen trabajo y asigna valores de baja probabilidad para ejemplos de la clase 0 (el histograma verde en la figura a continuaci√≥n) valores de alta probabilidad para ejemplos Clase 1 (histograma azul). <br><br><img src="https://habrastorage.org/webt/wq/e_/us/wqe_usitkajallhk1ymcsq472pu.png"><br><br>  La curva ROC muestra c√≥mo el indicador TPR depende del indicador FPR cuando se mueve el umbral de clasificaci√≥n de 0 a 1 (figura derecha, parte superior).  Para una mejor comprensi√≥n del concepto de umbral, recuerde que tenemos la probabilidad de pertenecer a la clase 1 para cada ejemplo.  Sin embargo, la probabilidad a√∫n no es una etiqueta de clase.  Por lo tanto, debe compararse con un umbral para determinar a qu√© clase pertenece el ejemplo.  Por ejemplo, si el valor umbral es 1, todos los ejemplos deben clasificarse como pertenecientes a la clase 0, ya que el valor de probabilidad no puede ser mayor que 1, mientras que los valores de los indicadores FPR y TPR ser√°n iguales a 0 (dado que ninguna de las muestras se clasifica como positiva )  Esta situaci√≥n corresponde al punto m√°s a la izquierda en la curva ROC.  En el otro lado de la curva hay un punto en el que el valor umbral es 0: esto significa que todas las muestras se clasifican como pertenecientes a la clase 1, y los valores de TPR y FPR son iguales a 1. Los puntos intermedios muestran el comportamiento de la dependencia TPR / FPR cuando el valor umbral cambia. <br><br>  La l√≠nea diagonal en el gr√°fico corresponde a un clasificador aleatorio.  Cuanto mejor funcione nuestro clasificador, m√°s cerca estar√° su curva del punto superior izquierdo del gr√°fico.  Por lo tanto, el indicador objetivo de la calidad del clasificador es el √°rea bajo la curva ROC (indicador ROC AUC).  El valor de este indicador debe ser lo m√°s cercano posible a 1. El valor de AUC de 0.5 corresponde a un clasificador aleatorio. <br><br>  El AUC en nuestro modelo (ver la figura anterior) es 0.57, lo cual est√° lejos de ser el mejor resultado. <br><br><img src="https://habrastorage.org/webt/oo/vu/-t/oovu-t0vyxvlbgb4zgp4qyvodsw.png"><br><br>  Todas estas m√©tricas indican que el modelo resultante es solo un poco mejor que el clasificador aleatorio.  Hay varias razones para esto, las principales se describen a continuaci√≥n: <br><br><ul><li>  Muy peque√±a cantidad de datos para el entrenamiento, insuficiente para resaltar los rasgos caracter√≠sticos de las im√°genes.  Incluso el aumento de datos no podr√≠a ayudar en este caso. </li><li>  Un modelo de red neuronal convolucional relativamente complejo (en comparaci√≥n con otros modelos de aprendizaje autom√°tico) con una gran cantidad de par√°metros. </li></ul><br><h2>  <font color="#0071c5">Conclusi√≥n</font> </h2><br>  En este art√≠culo, creamos un modelo simple de red neuronal convolucional para reconocer las emociones en las im√°genes.  Al mismo tiempo, en la etapa de entrenamiento, se utilizaron varios m√©todos para el aumento de datos, y el modelo tambi√©n se evalu√≥ utilizando un conjunto de m√©tricas como precisi√≥n, curva ROC, AUC ROC y matriz de inexactitud.  El modelo mostr√≥ resultados, solo algunos de los mejores al azar.       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420635/">https://habr.com/ru/post/es420635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420625/index.html">KDD 2018, D√≠a uno, tutoriales</a></li>
<li><a href="../es420627/index.html">Programaci√≥n as√≠ncrona C #: ¬øC√≥mo le va con el rendimiento?</a></li>
<li><a href="../es420629/index.html">PHP Digest No. 137 (6 al 20 de agosto de 2018)</a></li>
<li><a href="../es420631/index.html">No tenemos miedo a las "nubes"</a></li>
<li><a href="../es420633/index.html">Escribir un exportador GeoIP para Prometheus con visualizaciones en Grafana en 15 minutos</a></li>
<li><a href="../es420637/index.html">Revisi√≥n de la impresora 3D WANHAO D9 / 300: video</a></li>
<li><a href="../es420639/index.html">Akka antipatterns: demasiados actores</a></li>
<li><a href="../es420641/index.html">El soporte t√©cnico de 3CX responde: copia de seguridad y restauraci√≥n de 3CX desde la l√≠nea de comandos</a></li>
<li><a href="../es420643/index.html">Casi todo es igual, solo 10 veces m√°s barato</a></li>
<li><a href="../es420645/index.html">Ingenieros de contrataci√≥n realistas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
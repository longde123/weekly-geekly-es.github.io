<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå¶Ô∏è üßëüèΩ ‚ùáÔ∏è Herramientas de Apple Machine Learning üëµ ‚ö´Ô∏è ‚¨õÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En los √∫ltimos a√±os, el tema de la inteligencia artificial y el aprendizaje autom√°tico ha dejado de ser algo para las personas del mundo de la ficci√≥n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Herramientas de Apple Machine Learning</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/418307/"><p><img src="https://habrastorage.org/webt/si/by/p7/sibyp7evcy3vtvyh7jthlpqh68m.png"></p><br><p>  En los √∫ltimos a√±os, el tema de la inteligencia artificial y el aprendizaje autom√°tico ha dejado de ser algo para las personas del mundo de la ficci√≥n y ha entrado firmemente en la vida cotidiana.  Las redes sociales ofrecen asistir a eventos que nos interesan, los autos en las carreteras aprendieron a moverse sin conductor, y un asistente de voz en el tel√©fono le dice cu√°ndo es mejor salir de casa para evitar atascos y si llevar un paraguas con usted. </p><br><p>  En este art√≠culo, consideraremos las herramientas de aprendizaje autom√°tico que ofrecen los desarrolladores de Apple, analizaremos lo que la compa√±√≠a mostr√≥ como nuevo en esta √°rea en WWDC18 e intentaremos entender c√≥mo poner todo esto en pr√°ctica. </p><a name="habracut"></a><br><h2 id="mashinnoe-obuchenie">  Aprendizaje autom√°tico </h2><br><p>  Entonces, el aprendizaje autom√°tico es un proceso durante el cual un sistema, usando ciertos algoritmos de an√°lisis de datos y procesando una gran cantidad de ejemplos, identifica patrones y los usa para predecir las caracter√≠sticas de los nuevos datos. </p><br><p>  El aprendizaje autom√°tico naci√≥ de la teor√≠a de que las computadoras pueden aprender por s√≠ mismas, a√∫n no programadas para realizar ciertas acciones.  En otras palabras, a diferencia de los programas convencionales con instrucciones predefinidas para resolver problemas espec√≠ficos, el aprendizaje autom√°tico le permite al sistema aprender a reconocer patrones y hacer predicciones de manera independiente. </p><br><h2 id="bnns-i-cnn">  BNNS y CNN </h2><br><p>  Apple ha estado utilizando la tecnolog√≠a de aprendizaje autom√°tico en sus dispositivos durante bastante tiempo: Mail identifica correos electr√≥nicos no deseados, Siri lo ayuda a encontrar r√°pidamente respuestas a sus preguntas, Photos reconoce los rostros en las im√°genes. </p><br><p> En WWDC16, la compa√±√≠a introdujo dos API basadas en redes neuronales: subrutinas b√°sicas de redes neuronales (BNNS) y redes neuronales convolucionales (CNN).  BNNS es parte del sistema Accelerate, que es la base para realizar c√°lculos r√°pidos en la CPU, y CNN es la biblioteca Metal Performance Shaders que utiliza la GPU.  Puede obtener m√°s informaci√≥n sobre estas tecnolog√≠as, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </p><br><h2 id="core-ml-i-turi-create">  Core ML y Turi Create </h2><br><p>  El a√±o pasado, Apple anunci√≥ un marco que facilita enormemente el trabajo con tecnolog√≠as de aprendizaje autom√°tico: Core ML.  Se basa en la idea de tomar un modelo de datos previamente capacitado e integrarlo en su aplicaci√≥n en solo unas pocas l√≠neas de c√≥digo. </p><br><p><img src="https://habrastorage.org/webt/eg/dl/rz/egdlrzk40ao2z5a_eijvug8dhbc.png"></p><br><p>  Con Core ML, puede implementar muchas funciones: </p><br><ul><li>  definici√≥n de objetos en una foto y video; </li><li>  ingreso de texto predictivo; </li><li>  seguimiento y reconocimiento de rostros; </li><li>  an√°lisis de movimiento; </li><li>  definici√≥n de c√≥digo de barras; </li><li>  comprensi√≥n y reconocimiento de texto; </li><li>  reconocimiento de im√°genes en tiempo real; </li><li>  estilizaci√≥n de imagen; </li><li>  y mucho mas </li></ul><br><p>  Core ML, a su vez, utiliza Metal de bajo nivel, Acelerar y BNNS, y por lo tanto los resultados de los c√°lculos son muy r√°pidos. </p><br><p>  El n√∫cleo admite redes neuronales, modelos lineales generalizados, ingenier√≠a de caracter√≠sticas, algoritmos de toma de decisiones basados ‚Äã‚Äãen √°rboles (conjuntos de √°rboles), m√©todos de m√°quinas de vectores de soporte, modelos de tuber√≠as. </p><br><p>  Pero Apple no mostr√≥ inicialmente sus propias tecnolog√≠as para crear y entrenar modelos, sino que solo hizo un convertidor para otros marcos populares: Caffe, Keras, scikit-learn, XGBoost, LIBSVM. </p><br><p>  El uso de herramientas de terceros a menudo no era la tarea m√°s f√°cil, los modelos entrenados eran bastante grandes y la capacitaci√≥n en s√≠ misma requer√≠a mucho tiempo. </p><br><p>  A finales de a√±o, la compa√±√≠a present√≥ Turi Create, un marco de aprendizaje modelo cuya idea principal era la facilidad de uso y el soporte para una gran cantidad de escenarios: clasificaci√≥n de im√°genes, definici√≥n de objetos, sistemas de recomendaci√≥n y muchos otros.  Pero Turi Create, a pesar de su relativa facilidad de uso, solo era compatible con Python. </p><br><h2 id="create-ml">  Crear ML </h2><br><p>  Y este a√±o, Apple, adem√°s de Core ML 2, finalmente mostr√≥ su propia herramienta para entrenar modelos: el marco Create ML usando las tecnolog√≠as nativas de Apple: Xcode y Swift. </p><br><p>  Funciona r√°pido, y crear modelos de modelos con Create ML es realmente f√°cil. </p><br><p>  En WWDC, se anunci√≥ el impresionante rendimiento de Create ML y Core ML 2 utilizando la aplicaci√≥n Memrise como ejemplo.  Si antes tom√≥ 24 horas entrenar un modelo con 20 mil im√°genes, entonces Crear ML reduce este tiempo a 48 minutos en el MacBook Pro y hasta 18 minutos en el iMac Pro.  El tama√±o del modelo entrenado disminuy√≥ de 90 MB a 3 MB. </p><br><p>  Create ML le permite usar im√°genes, textos y objetos estructurados como tablas, por ejemplo, como datos de origen. </p><br><p><img src="https://habrastorage.org/webt/uk/di/2e/ukdi2ewm3e2ax6bbr3ceu_fymlu.png"></p><br><h2 id="klassifikaciya-izobrazheniy">  Clasificaci√≥n de la imagen </h2><br><p>  Primero, veamos c√≥mo funciona la clasificaci√≥n de im√°genes.  Para entrenar el modelo, necesitamos un conjunto de datos inicial: tomamos tres grupos de fotos de animales: perros, gatos y p√°jaros y los distribuimos en carpetas con los nombres correspondientes, que se convertir√°n en los nombres de las categor√≠as del modelo.  Cada grupo contiene 100 im√°genes con una resoluci√≥n de hasta 1920 √ó 1080 p√≠xeles y un tama√±o de hasta 1Mb.  Las fotograf√≠as deben ser lo m√°s diferentes posible para que el modelo entrenado no se base en signos como el color de la imagen o el espacio circundante. </p><br><p><img src="https://habrastorage.org/webt/w8/oz/_9/w8oz_9t_3_0fyz86xusotsdp9zi.png"></p><br><p>  Adem√°s, para verificar qu√© tan bien un modelo entrenado maneja el reconocimiento de objetos, necesita un conjunto de datos de prueba: im√°genes que no est√°n en el conjunto de datos original. </p><br><p>  Apple proporciona dos formas de interactuar con Create ML: usando la interfaz de usuario en MacOS Playground Xcode y program√°ticamente usando CreateMLUI.framework y CreateML.framework.  Usando el primer m√©todo, es suficiente escribir un par de l√≠neas de c√≥digo, transferir las im√°genes seleccionadas al √°rea especificada y esperar mientras el modelo aprende. </p><br><p><img src="https://habrastorage.org/webt/b6/zb/w_/b6zbw_ihfbmt2lx0ovib4nmkfsk.gif"></p><br><p>  En el Macbook Pro 2017 en la configuraci√≥n m√°xima, el entrenamiento tom√≥ 29 segundos para 10 iteraciones, y el tama√±o del modelo entrenado fue de 33Kb.  Se ve impresionante. </p><br><p>  Tratemos de descubrir c√≥mo logramos alcanzar esos indicadores y qu√© es "bajo el cap√≥". <br>  La tarea de clasificar im√°genes es uno de los usos m√°s populares de las redes neuronales convolucionales.  Primero, vale la pena explicar cu√°les son. </p><br><p>  Una persona, al ver una imagen de un animal, puede atribuirla r√°pidamente a una determinada clase en funci√≥n de cualquier caracter√≠stica distintiva.  Una red neuronal act√∫a de manera similar al buscar caracter√≠sticas b√°sicas.  Tomando la matriz inicial de p√≠xeles como entrada, pasa informaci√≥n secuencialmente a trav√©s de grupos de capas convolucionales y construye abstracciones cada vez m√°s complejas.  En cada capa posterior, ella aprende a resaltar ciertas caracter√≠sticas: primero son l√≠neas, luego conjuntos de l√≠neas, formas geom√©tricas, partes del cuerpo, etc.  En la √∫ltima capa obtenemos la conclusi√≥n de una clase o grupo de clases probables. </p><br><p>  En el caso de Create ML, el entrenamiento de redes neuronales no se realiza desde cero.  El marco utiliza una red neuronal previamente entrenada en un gran conjunto de datos, que ya incluye una gran cantidad de capas y tiene una alta precisi√≥n. </p><br><p><img src="https://habrastorage.org/webt/go/qu/el/goquell4agcijc9duege4cg1ydw.png"></p><br><p>  Esta tecnolog√≠a se llama transferencia de aprendizaje.  Con √©l, puede cambiar la arquitectura de una red previamente capacitada para que sea adecuada para resolver un nuevo problema.  La red modificada se entrena en un nuevo conjunto de datos. </p><br><p>  Crea ML durante los extractos de entrenamiento de la foto sobre 1000 caracter√≠sticas distintivas.  Esta puede ser la forma de los objetos, el color de las texturas, la ubicaci√≥n de los ojos, los tama√±os y muchos otros. <br>  Cabe se√±alar que el conjunto de datos inicial en el que se entrena la red neuronal utilizada, como la nuestra, puede contener fotograf√≠as de gatos, perros y p√°jaros, pero estas categor√≠as no est√°n asignadas espec√≠ficamente.  Todas las categor√≠as forman una jerarqu√≠a.  Por lo tanto, es simplemente imposible aplicar esta red en su forma pura: es necesario volver a entrenarla en nuestros datos. </p><br><p>  Al final del proceso, vemos cu√°n exactamente nuestro modelo fue entrenado y probado despu√©s de varias iteraciones.  Para mejorar los resultados, podemos aumentar el n√∫mero de im√°genes en el conjunto de datos original o cambiar el n√∫mero de iteraciones. </p><br><p><img src="https://habrastorage.org/webt/k1/rz/to/k1rzto4lzngwwfo46taxa9vnbms.png"></p><br><p>  A continuaci√≥n, podemos probar el modelo nosotros mismos en un conjunto de datos de prueba.  Las im√°genes deben ser √∫nicas, es decir.  No ingrese el conjunto fuente. </p><br><p><img src="https://habrastorage.org/webt/lw/u8/el/lwu8eld5v8q6jwqyeaygwkyzvwi.png"></p><br><p>  Para cada imagen, se muestra un indicador de <em>confianza</em> : con qu√© precisi√≥n, con la ayuda de nuestro modelo, se reconoci√≥ la categor√≠a. </p><br><p>  Para casi todas las fotos, con raras excepciones, esta cifra fue del 100%.  Agregu√© espec√≠ficamente la imagen que ves arriba al conjunto de datos de prueba y, como puedes ver, Create ML reconoci√≥ en ella el 86% del perro y el 13% del ave. </p><br><p>  Se completa la capacitaci√≥n modelo, y todo lo que nos queda es guardar el archivo * .mlmodel y agregarlo a su proyecto. </p><br><p><img src="https://habrastorage.org/webt/vd/ey/xb/vdeyxbibcdbgd3f2jb6ozsrpa_u.png"></p><br><p>  Para probar el modelo, escrib√≠ una aplicaci√≥n simple usando el marco Vision.  Le permite trabajar con modelos Core ML y resolver problemas al usarlos, como la clasificaci√≥n de im√°genes o la detecci√≥n de objetos. </p><br><p>  Nuestra aplicaci√≥n reconocer√° la imagen de la c√°mara del dispositivo y mostrar√° la categor√≠a y el porcentaje de confianza en la clasificaci√≥n. </p><br><p>  Inicializamos el modelo Core ML para trabajar con Vision y configuramos la consulta: </p><br><pre><code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setupVision</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> visionModel = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? <span class="hljs-type"><span class="hljs-type">VNCoreMLModel</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: <span class="hljs-type"><span class="hljs-type">AnimalsClassifier</span></span>().model) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">fatalError</span></span>(<span class="hljs-string"><span class="hljs-string">"Can't load VisionML model"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> request = <span class="hljs-type"><span class="hljs-type">VNCoreMLRequest</span></span>(model: visionModel) { (request, error) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> results = request.results <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.handleRequestResults(results) } requests = [request] }</code> </pre> <br><p>  Agregue un m√©todo que procesar√° los resultados de VNCoreMLRequest.  Solo mostramos aquellos con un indicador de confianza de m√°s del 70%: </p><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">handleRequestResults</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> results: [</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">Any</span></span></span></span><span class="hljs-function"><span class="hljs-params">])</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> categoryText: <span class="hljs-type"><span class="hljs-type">String?</span></span> <span class="hljs-keyword"><span class="hljs-keyword">defer</span></span> { <span class="hljs-type"><span class="hljs-type">DispatchQueue</span></span>.main.async { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.categoryLabel.text = categoryText } } <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> foundObject = results .compactMap({ $<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? <span class="hljs-type"><span class="hljs-type">VNClassificationObservation</span></span> }) .first(<span class="hljs-keyword"><span class="hljs-keyword">where</span></span>: { $<span class="hljs-number"><span class="hljs-number">0</span></span>.confidence &gt; <span class="hljs-number"><span class="hljs-number">0.7</span></span> }) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { categoryText = <span class="hljs-literal"><span class="hljs-literal">nil</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> category = categoryTitle(identifier: foundObject.identifier) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> confidence = <span class="hljs-string"><span class="hljs-string">"\(round(foundObject.confidence * 100 * 100) / 100)%"</span></span> categoryText = <span class="hljs-string"><span class="hljs-string">"\(category) \(confidence)"</span></span> }</code> </pre><br><p>  Y el √∫ltimo: agregaremos el m√©todo de delegado AVCaptureVideoDataOutputSampleBufferDelegate, que se llamar√° con cada nuevo fotograma de la c√°mara y ejecutaremos la solicitud: </p><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">captureOutput</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pixelBuffer = <span class="hljs-type"><span class="hljs-type">CMSampleBufferGetImageBuffer</span></span>(sampleBuffer) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> requestOptions: [<span class="hljs-type"><span class="hljs-type">VNImageOption</span></span>: <span class="hljs-type"><span class="hljs-type">Any</span></span>] = [:] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cameraIntrinsicData = <span class="hljs-type"><span class="hljs-type">CMGetAttachment</span></span>( sampleBuffer, key: kCMSampleBufferAttachmentKey_CameraIntrinsicMatrix, attachmentModeOut: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>) { requestOptions = [.cameraIntrinsics:cameraIntrinsicData] } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageRequestHandler = <span class="hljs-type"><span class="hljs-type">VNImageRequestHandler</span></span>( cvPixelBuffer: pixelBuffer, options: requestOptions) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> imageRequestHandler.perform(requests) } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(error) } }</code> </pre> <br><p>  Veamos qu√© tan bien el modelo hace frente a su tarea: </p><br><p><img src="https://habrastorage.org/webt/fy/5k/fl/fy5kflqc3p02w0mo0dwgaar3vle.gif"></p><br><p>  La categor√≠a se determina con una precisi√≥n bastante alta, y esto es especialmente sorprendente cuando se considera cu√°n r√°pido fue el entrenamiento y cu√°n peque√±o era el conjunto de datos original.  Peri√≥dicamente, contra un fondo oscuro, el modelo revela p√°jaros, pero creo que esto se puede resolver f√°cilmente aumentando el n√∫mero de im√°genes en el conjunto de datos original o aumentando el nivel m√≠nimo aceptable de confianza. </p><br><p>  Si queremos volver a entrenar el modelo para clasificar otra categor√≠a, simplemente agregue un nuevo grupo de im√°genes y repita el proceso; tomar√° unos minutos. </p><br><p>  Como experimento, hice otro conjunto de datos, en el que cambi√© todas las fotos de gatos en la foto de un gato desde diferentes √°ngulos, pero en el mismo fondo y en el mismo entorno.  En este caso, el modelo casi siempre cometi√≥ errores y reconoci√≥ la categor√≠a en una habitaci√≥n vac√≠a, aparentemente confiando en el color como una caracter√≠stica clave. </p><br><p>  Otra caracter√≠stica interesante introducida en Vision solo este a√±o es la capacidad de reconocer objetos en la imagen en tiempo real.  Est√° representado por la clase VNRecognizedObjectObservation, que le permite obtener la categor√≠a de un objeto y su ubicaci√≥n: boundingBox. </p><br><p><img src="https://habrastorage.org/webt/fo/96/cb/fo96cbqh0flkktb9umjrfxxofu4.jpeg"></p><br><p>  Ahora Crear ML no permite crear modelos para implementar esta funcionalidad.  Apple sugiere usar Turi Create en este caso.  El proceso no es mucho m√°s complicado que el anterior: debe preparar carpetas de categor√≠as con fotos y un archivo en el que para cada imagen se indicar√°n las coordenadas del rect√°ngulo donde se encuentra el objeto. </p><br><h2 id="natural-language-processing">  Procesamiento del lenguaje natural </h2><br><p>  La siguiente funci√≥n Create ML es entrenar modelos para clasificar textos en lenguaje natural, por ejemplo, para determinar el color emocional de las oraciones o detectar spam. </p><br><p><img src="https://habrastorage.org/webt/xv/fq/48/xvfq489qejhdwl_uitxcc-2yyii.png"></p><br><p>  Para crear un modelo, debemos recopilar una tabla con el conjunto de datos original: oraciones o textos completos asignados a una determinada categor√≠a, y entrenar el modelo con el objeto MLTextClassifier: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> data = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MLDataTable</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">contentsOf: URL(fileURLWithPath: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"/Users/CreateMLTest/texts.json"</span></span></span></span></span><span class="hljs-function">)) </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">let</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">trainingData, testingData</span></span></span><span class="hljs-function">)</span></span> = data.randomSplit(<span class="hljs-keyword"><span class="hljs-keyword">by</span></span>: <span class="hljs-number"><span class="hljs-number">0.8</span></span>, seed: <span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> textClassifier = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MLTextClassifier</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">trainingData: trainingData, textColumn: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"text"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, labelColumn: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"label"</span></span></span></span></span><span class="hljs-function">) </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> textClassifier.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">to: URL(fileURLWithPath: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"/Users/CreateMLTest/TextClassifier.mlmodel"</span></span></span></span></span><span class="hljs-function">))</span></span></code> </pre> <br><p>  En este caso, el modelo entrenado es del tipo Clasificador de texto: </p><br><p><img src="https://habrastorage.org/webt/kg/j1/ws/kgj1wst4121ojpwfk73yehmte_m.png"></p><br><h2 id="tablichnye-dannye">  Datos tabulares </h2><br><p>  Echemos un vistazo m√°s de cerca a otra caracter√≠stica de Create ML: entrenar un modelo utilizando datos estructurados (tablas). </p><br><p>  Escribiremos una aplicaci√≥n de prueba que prediga el precio de un apartamento en funci√≥n de su ubicaci√≥n en el mapa y otros par√°metros especificados. </p><br><p>  Entonces, tenemos una tabla con datos abstractos sobre apartamentos en Mosc√∫ en forma de archivo csv: se conoce el √°rea de cada apartamento, piso, n√∫mero de habitaciones y coordenadas (latitud y longitud).  Adem√°s, se conoce el costo de cada apartamento.  Cuanto m√°s cerca del centro o mayor sea el √°rea, mayor ser√° el precio. </p><br><p><img src="https://habrastorage.org/webt/hd/-w/77/hd-w77qhysj80_kapqbqddwdhyi.png"></p><br><p>  La tarea de Create ML ser√° construir un modelo capaz de predecir el precio de un apartamento basado en estas caracter√≠sticas.  Tal tarea en el aprendizaje autom√°tico se llama tarea de regresi√≥n y es un ejemplo cl√°sico de aprendizaje con un maestro. </p><br><p>  Create ML admite muchos modelos: regresi√≥n lineal, regresi√≥n de √°rbol de decisi√≥n, clasificador de √°rbol, regresi√≥n log√≠stica, clasificador de bosque aleatorio, regresi√≥n de √°rboles potenciados, etc. </p><br><p>  Utilizaremos el objeto MLRegressor, que seleccionar√° la mejor opci√≥n en funci√≥n de los datos de entrada. <br>  Primero, inicialice el objeto MLDataTable con el contenido de nuestro archivo csv: </p><br><pre> <code class="hljs lisp">let trainingFile = URL(<span class="hljs-name"><span class="hljs-name">fileURLWithPath</span></span>: <span class="hljs-string"><span class="hljs-string">"/Users/CreateMLTest/Apartments.csv"</span></span>) let apartmentsData = try MLDataTable(<span class="hljs-name"><span class="hljs-name">contentsOf</span></span>: trainingFile)</code> </pre> <br><p>  Dividimos el conjunto de datos inicial en datos para capacitaci√≥n y pruebas de modelos en un porcentaje de 80/20: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (trainingData, testData) = apartmentsData.randomSplit(<span class="hljs-keyword"><span class="hljs-keyword">by</span></span>: <span class="hljs-number"><span class="hljs-number">0.8</span></span>, seed: <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  Creamos el modelo MLRegressor, que indica los datos para el entrenamiento y el nombre de la columna cuyos valores queremos predecir.  El tipo de regresor espec√≠fico de la tarea (lineal, √°rbol de decisi√≥n, √°rbol impulsado o bosque aleatorio) se seleccionar√° autom√°ticamente en funci√≥n del estudio de los datos de entrada.  Tambi√©n podemos especificar columnas de caracter√≠sticas: columnas de par√°metros espec√≠ficos para el an√°lisis, pero en este ejemplo esto no es necesario, utilizaremos todos los par√°metros.  Al final, guarde el modelo entrenado y agregue al proyecto: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> <span class="hljs-type"><span class="hljs-type">MLRegressor</span></span>(trainingData: apartmentsData, targetColumn: <span class="hljs-string"><span class="hljs-string">"Price"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> modelPath = <span class="hljs-type"><span class="hljs-type">URL</span></span>(fileURLWithPath: <span class="hljs-string"><span class="hljs-string">"/Users/CreateMLTest/ApartmentsPricer.mlmodel"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> model.write(to: modelPath, metadata: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/xv/ci/-e/xvci-e7bhoxwfpvwtjdmwqwwhv0.png"></p><br><p>  En este ejemplo, vemos que el tipo de modelo ya es un regresor de tuber√≠a, y el campo Descripci√≥n contiene el tipo de regresor seleccionado autom√°ticamente - Modelo de regresi√≥n de √°rbol impulsado.  Los par√°metros de Entradas y Salidas corresponden a las columnas de la tabla, pero su tipo de datos se ha convertido en Doble. </p><br><p>  Ahora verifique el resultado. <br>  Inicialice el objeto modelo: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> model = <span class="hljs-type"><span class="hljs-type">ApartmentsPricer</span></span>()</code> </pre> <br><p>  Llamamos al m√©todo de predicci√≥n, pas√°ndole los par√°metros especificados: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> area = Double(areaSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> floor = Double(floorSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> rooms = Double(roomsSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> latitude = annotation.coordinate.latitude <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> longitude = annotation.coordinate.longitude <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> prediction = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? model.prediction( area: area, floor: floor, rooms: rooms, latitude: latitude, longitude: longitude)</code> </pre><br><p>  Mostramos el valor predicho del costo: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> price = prediction?.price priceLabel.text = formattedPrice(price)</code> </pre> <br><p>  Al cambiar un punto en el mapa o los valores de los par√°metros, obtenemos el precio del apartamento muy cerca de nuestros datos de prueba: </p><br><p><img src="https://habrastorage.org/webt/pu/j-/v1/puj-v1m8x0ghkxrh1fwogdejxfu.png"></p><br><h2 id="zaklyuchenie">  Conclusi√≥n </h2><br><p>  El marco Crear ML es ahora una de las formas m√°s f√°ciles de trabajar con tecnolog√≠as de aprendizaje autom√°tico.  Todav√≠a no permite crear modelos para resolver algunos problemas: reconocimiento de objetos en una imagen, estilizaci√≥n de una foto, determinaci√≥n de im√°genes similares, reconocimiento de acciones f√≠sicas basadas en datos de un aceler√≥metro o giroscopio, que Turi Create, por ejemplo, maneja. </p><br><p>  Pero vale la pena se√±alar que Apple ha hecho un progreso bastante serio en esta √°rea durante el a√±o pasado y, seguro, pronto veremos el desarrollo de las tecnolog√≠as descritas. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es418307/">https://habr.com/ru/post/es418307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es418295/index.html">Casi todo lo que quer√≠a saber sobre punto flotante en ARM, pero ten√≠a miedo de preguntar</a></li>
<li><a href="../es418297/index.html">Revisi√≥n de tel√©fono inteligente Neffos N1</a></li>
<li><a href="../es418301/index.html">La gran confrontaci√≥n de Marte en 2018: c√≥mo observar y qu√© esperar</a></li>
<li><a href="../es418303/index.html">Vanessa-Automation: una herramienta para probar soluciones de aplicaciones en la plataforma 1C: Enterprise</a></li>
<li><a href="../es418305/index.html">¬øCu√°ntos objetos emite Python al ejecutar scripts?</a></li>
<li><a href="../es418309/index.html">C√≥mo el sat√©lite astron√≥mico de Planck cambi√≥ para siempre nuestra percepci√≥n del universo</a></li>
<li><a href="../es418311/index.html">Analice el port√°til Dell Latitude 7390: superh√©roe corporativo</a></li>
<li><a href="../es418313/index.html">Las 10 mejores herramientas de prueba de API</a></li>
<li><a href="../es418315/index.html">Sin un solo "oops": los 10 mejores informes de DevOops 2017</a></li>
<li><a href="../es418317/index.html">2048 est√° prohibido. No RosKomNadzor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
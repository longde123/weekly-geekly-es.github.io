<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôëÔ∏è ‚úãüèæ ü•Ç De barba, de √≥culos escuros e de perfil: situa√ß√µes dif√≠ceis para a vis√£o computacional üëÜüèΩ üéß ü§öüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tecnologias e modelos para o nosso futuro sistema de vis√£o computacional foram criados e aprimorados gradualmente em v√°rios projetos de nossa empresa ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>De barba, de √≥culos escuros e de perfil: situa√ß√µes dif√≠ceis para a vis√£o computacional</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/449120/"><img src="https://habrastorage.org/getpro/habr/post_images/027/06d/ef1/02706def16ee17a808ab04bef455cb83.jpg"><br><br>  Tecnologias e modelos para o nosso futuro sistema de vis√£o computacional foram criados e aprimorados gradualmente em v√°rios projetos de nossa empresa - no Mail, Cloud e Search.  Amadurecido como um bom queijo ou conhaque.  Depois que percebemos que nossas redes neurais mostravam excelentes resultados de reconhecimento e decidimos reuni-las em um √∫nico produto b2b - Vision - que agora usamos a n√≥s mesmos e nos oferecemos para us√°-lo. <br><br>  Hoje, nossa tecnologia de vis√£o computacional na plataforma Mail.Ru Cloud Solutions funciona com sucesso e resolve problemas pr√°ticos muito complexos.  √â baseado em v√°rias redes neurais treinadas em nossos conjuntos de dados e especializadas na solu√ß√£o de problemas aplicados.  Todos os servi√ßos est√£o girando em nossas capacidades de servidor.  Voc√™ pode integrar a API p√∫blica do Vision em seus aplicativos, atrav√©s dos quais todos os recursos do servi√ßo est√£o dispon√≠veis.  A API √© r√°pida - gra√ßas √†s GPUs do servidor, o tempo m√©dio de resposta em nossa rede √© de 100 ms. <br><br>  Por baixo do corte, h√° uma hist√≥ria detalhada e muitos exemplos de Vis√£o. <br><a name="habracut"></a><br>  Como exemplo de um servi√ßo no qual n√≥s mesmos usamos as tecnologias de reconhecimento de rosto acima mencionadas, podemos citar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Eventos</a> .  Um de seus componentes √© o suporte para fotos Vision, que instalamos em v√°rias confer√™ncias.  Se voc√™ for a um estande de fotos, tirar uma foto com a c√¢mera embutida e digitar seu e-mail, o sistema encontrar√° imediatamente entre o conjunto de fotos aquelas das quais os fot√≥grafos regulares da confer√™ncia o capturaram e, se desejar, enviar√° as fotos encontradas por e-mail.  E n√£o se trata de fotos em etapas - a Vision reconhece voc√™ mesmo em segundo plano na multid√£o de visitantes.  Obviamente, eles n√£o s√£o reconhecidos pela pr√≥pria foto, s√£o apenas tablets em belas montanhas-russas que simplesmente fotografam convidados em suas c√¢meras embutidas e transmitem informa√ß√µes aos servidores, onde toda a magia do reconhecimento ocorre.  E observamos repetidamente como √© surpreendente a efic√°cia da tecnologia, mesmo entre os especialistas em reconhecimento de imagens.  Abaixo falaremos sobre alguns exemplos. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3gE-OeSmoKo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h1>  1. Nosso modelo de reconhecimento facial </h1><br><h3>  1.1  Rede neural e velocidade de processamento </h3><br>  Para reconhecimento, usamos uma modifica√ß√£o do modelo de rede neural ResNet 101. O pool m√©dio no final √© substitu√≠do por uma camada totalmente conectada, semelhante √† maneira como foi feita no ArcFace.  No entanto, o tamanho das representa√ß√µes vetoriais √© 128, n√£o 512. Nosso conjunto de treinamento cont√©m cerca de 10 milh√µes de fotos de 273.593 pessoas. <br><br>  O modelo funciona muito r√°pido, gra√ßas a uma arquitetura de configura√ß√£o do servidor cuidadosamente selecionada e √† computa√ß√£o da GPU.  S√£o necess√°rios 100 ms para obter uma resposta da API em nossas redes internas - isso inclui detec√ß√£o de rosto (detec√ß√£o de rosto na foto), reconhecimento e retorno do PersonID na resposta da API.  Com grandes volumes de dados recebidos - fotos e v√≠deos - levar√° muito mais tempo para transferir dados para o servi√ßo e receber uma resposta. <br><br><h3>  1.2  Estimativa da efici√™ncia do modelo </h3><br>  Mas determinar a efici√™ncia das redes neurais √© uma tarefa muito mista.  A qualidade do trabalho deles depende de quais conjuntos de dados os modelos foram treinados e se foram otimizados para trabalhar com dados espec√≠ficos. <br><br>  Come√ßamos a avaliar a precis√£o do nosso modelo com o popular teste de verifica√ß√£o LFW, mas √© muito pequeno e simples.  Depois de atingir 99,8% de precis√£o, n√£o √© mais √∫til.  Existe uma boa competi√ß√£o para avaliar os modelos de reconhecimento - o Megaface alcan√ßou gradualmente 82% do ranking 1. O teste do Megaface consiste em um milh√£o de fotos - distratores - e o modelo deve ser capaz de distinguir v√°rios milhares de fotos de celebridades do conjunto de dados Facescrub dos distratores.  No entanto, ap√≥s termos eliminado o teste de erros do Megaface, descobrimos que na vers√£o limpa atingimos uma precis√£o de 98% no ranking 1 (fotos de celebridades geralmente s√£o bastante espec√≠ficas).  Portanto, eles criaram um teste de identifica√ß√£o separado, semelhante ao Megaface, mas com fotos de pessoas "comuns".  Melhorou ainda mais a precis√£o do reconhecimento em seus conjuntos de dados e foi muito al√©m.  Al√©m disso, usamos o teste de qualidade de agrupamento, que consiste em v√°rios milhares de fotografias;  Simula a marca√ß√£o de rostos na nuvem do usu√°rio.  Nesse caso, clusters s√£o grupos de indiv√≠duos semelhantes, um grupo para cada pessoa reconhec√≠vel.  Verificamos a qualidade do trabalho em grupos reais (verdadeiro). <br><br>  Obviamente, qualquer modelo possui erros de reconhecimento.  Por√©m, essas situa√ß√µes geralmente s√£o resolvidas ajustando os limites para condi√ß√µes espec√≠ficas (para todas as confer√™ncias usamos os mesmos limites e, por exemplo, para ACSs, precisamos aumentar significativamente os limites para que haja menos falsos positivos).  A grande maioria dos participantes da confer√™ncia foi reconhecida por nossos estandes de fotos Vision corretamente.  √Äs vezes, algu√©m olhava para a visualiza√ß√£o cortada e dizia: "Seu sistema estava errado, n√£o sou eu".  Em seguida, abrimos a fotografia inteira e constatamos que esse visitante realmente estava na fotografia, mas eles n√£o a tiraram, mas outra pessoa, apenas um homem apareceu acidentalmente em segundo plano na zona de desfoque.  Al√©m disso, a rede neural geralmente reconhece corretamente mesmo quando uma parte do rosto n√£o est√° vis√≠vel, ou uma pessoa est√° de perfil, ou mesmo semifacial.  O sistema pode reconhecer uma pessoa, mesmo que ela caia no campo da distor√ß√£o √≥ptica, por exemplo, ao fotografar com uma lente grande angular. <br><br><h3>  1.3  Testando exemplos em situa√ß√µes dif√≠ceis </h3><br>  Abaixo est√£o exemplos da opera√ß√£o de nossa rede neural.  Na entrada, as fotos s√£o enviadas, as quais ela deve marcar usando o PersonID - um identificador exclusivo para a pessoa.  Se duas ou mais imagens tiverem o mesmo identificador, de acordo com os modelos, essas fotos mostrar√£o uma pessoa. <br><br>  Imediatamente, observamos que durante o teste, temos acesso a v√°rios par√¢metros e limites de modelos que podemos configurar para alcan√ßar um resultado espec√≠fico.  A API p√∫blica √© otimizada para m√°xima precis√£o em casos comuns. <br><br>  Vamos come√ßar com o mais simples, com reconhecimento de rosto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21e/973/ba9/21e973ba959f23ab2b8592e795fb8bcb.png"><br><br>  Bem, isso foi f√°cil demais.  N√≥s complicamos a tarefa, adicionamos barba e alguns anos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/24e/a74/347/24ea7434773548d5dc23cdff03887b0f.png"><br><br>  Algu√©m dir√° que isso n√£o foi muito dif√≠cil, porque em ambos os casos a face √© vis√≠vel na sua totalidade, o algoritmo possui muitas informa√ß√µes sobre a face.  Ok, coloque Tom Hardy de perfil.  Essa tarefa √© muito mais complicada e investimos muito em sua solu√ß√£o bem-sucedida, mantendo um baixo n√≠vel de erros: selecionamos uma amostra de treinamento, pensamos na arquitetura da rede neural, aprimoramos as fun√ß√µes de perda e melhoramos o processamento preliminar de fotos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/df6/191/445/df619144560539d45c09176174349b9d.png"><br><br>  Vamos colocar um chap√©u nele: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/40c/2e5/48b/40c2e548b16ea8a2015b0b7f0ff53b62.png"><br><br>  A prop√≥sito, este √© um exemplo de uma situa√ß√£o particularmente dif√≠cil, j√° que o rosto √© muito coberto aqui, e na imagem inferior tamb√©m h√° uma sombra profunda que esconde os olhos.  Na vida real, as pessoas muitas vezes mudam de apar√™ncia com a ajuda de √≥culos escuros.  Fa√ßa o mesmo com o Tom. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/27e/792/5db/27e7925dbb402d2ba1957e812279de7c.png"><br><br>  Bem, vamos tentar enviar fotos de diferentes idades, e desta vez colocaremos experi√™ncia em outro ator.  Vamos dar um exemplo muito mais complexo quando as altera√ß√µes relacionadas √† idade s√£o especialmente pronunciadas.  A situa√ß√£o n√£o √© exagerada, acontece o tempo todo quando voc√™ precisa comparar uma fotografia no seu passaporte com a cara do portador.  Afinal, a primeira foto fica presa no passaporte quando o propriet√°rio tem 20 anos e 45 pessoas podem mudar: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/59f/d37/109/59fd37109369ee642fa75ff107be9726.png"><br><br>  Voc√™ acha que o principal especial em miss√µes imposs√≠veis n√£o mudou muito com a idade?  Eu acho que mesmo poucas pessoas combinariam as fotos superior e inferior, o garoto mudou muito ao longo dos anos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f3c/f57/20c/f3cf5720c2aeced56746035af7687531.png"><br><br>  As redes neurais enfrentam mudan√ßas na apar√™ncia com muito mais frequ√™ncia.  Por exemplo, √†s vezes as mulheres podem mudar bastante sua imagem com a ajuda de cosm√©ticos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/47e/c03/e0747ec033917573a028028e04a0cf24.png"><br><br>  Agora vamos complicar ainda mais a tarefa: cubra diferentes partes do rosto em fotos diferentes.  Nesses casos, o algoritmo n√£o pode comparar as amostras inteiras.  No entanto, o Vision lida bem com essas situa√ß√µes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f99/14b/600/f9914b600d274f8f29ecbd229e937e9e.png"><br><br>  A prop√≥sito, existem muitos rostos nas fotografias, por exemplo, mais de 100 pessoas podem se encaixar em uma imagem comum do sal√£o.  Essa √© uma situa√ß√£o dif√≠cil para redes neurais, pois muitos rostos podem ser iluminados de maneira diferente, algu√©m fora da zona de nitidez.  No entanto, se a foto foi tirada com resolu√ß√£o e qualidade suficientes (pelo menos 75 pixels por quadrado cobrindo o rosto), o Vision poder√° identific√°-la e reconhec√™-la. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/362/3a9/b8e/3623a9b8e23fd68b025f6bc9c81f22d2.png"><br><br>  A peculiaridade de relatar fotografias e imagens de c√¢meras de vigil√¢ncia √© que as pessoas geralmente ficam emba√ßadas porque estavam fora do campo de nitidez ou se moviam naquele momento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/819/db8/c4e/819db8c4e234677690cfc86c7be73a02.png"><br><br>  Al√©m disso, a intensidade da ilumina√ß√£o pode variar bastante de imagem para imagem.  Isso tamb√©m costuma se transformar em um obst√°culo; muitos algoritmos t√™m grande dificuldade em processar corretamente imagens muito escuras e muito claras, sem mencionar a compara√ß√£o exata.  Deixe-me lembr√°-lo que, para alcan√ßar esse resultado, voc√™ precisa definir limites de uma certa maneira, essa possibilidade ainda n√£o est√° dispon√≠vel ao p√∫blico.  Para todos os clientes, usamos a mesma rede neural, com limites adequados para as tarefas mais pr√°ticas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db0/423/6a3/db04236a312641cc7ed888bc279cbf66.png"><br><br>  Recentemente, lan√ßamos uma nova vers√£o do modelo que reconhece rostos asi√°ticos com alta precis√£o.  Anteriormente, esse era um grande problema, que era chamado de "racismo de aprendizado de m√°quina" (ou "redes neurais").  As redes neurais europ√©ias e americanas reconheceram bem os rostos europeus, e as coisas foram muito piores com os mongol√≥ides e os negr√≥ides.  Provavelmente na mesma China, a situa√ß√£o era exatamente o oposto.  √â tudo sobre conjuntos de dados de treinamento que refletem os tipos dominantes de pessoas em um pa√≠s espec√≠fico.  No entanto, a situa√ß√£o est√° mudando, hoje esse problema est√° longe de ser t√£o agudo.  A vis√£o n√£o tem dificuldades com representantes de diferentes ra√ßas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/be8/750/da9/be8750da9407b7ca4c2cd11dac314ef3.png"><br><br>  O reconhecimento de faces √© apenas uma das muitas aplica√ß√µes de nossa tecnologia; o Vision pode ser ensinado a reconhecer qualquer coisa.  Por exemplo, n√∫meros de carros, inclusive em condi√ß√µes dif√≠ceis para algoritmos: em √¢ngulos agudos, n√∫meros sujos e dif√≠ceis de ler. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b22/ddb/39d/b22ddb39d2fe119db6eb50db37df829b.png"><br><br><h1>  2. Casos de uso pr√°tico </h1><br><h3>  2.1  Controle de acesso f√≠sico: quando dois passam no mesmo passe </h3><br>  Com a ajuda da Vision, √© poss√≠vel implementar sistemas de contabilidade para a chegada e sa√≠da de funcion√°rios.  Um sistema tradicional baseado em passes eletr√¥nicos tem desvantagens √≥bvias, por exemplo, voc√™ pode passar por dois emblemas juntos.  Se o sistema de controle de acesso (ACS) for complementado pelo Vision, ele registrar√° honestamente quem veio e foi quando. <br><br><h3>  2.2  Rastreamento de tempo </h3><br>  Esse caso de uso do Vision est√° intimamente relacionado ao anterior.  Se complementarmos o sistema de controle de acesso com nosso servi√ßo de reconhecimento de rosto, ele poder√° n√£o apenas observar viola√ß√µes do controle de acesso, mas tamb√©m registrar a perman√™ncia real dos funcion√°rios no edif√≠cio ou nas instala√ß√µes.  Em outras palavras, a Vision ajudar√° a considerar honestamente quem e quanto veio trabalhar e deixou com ela, e quem at√© pulou, mesmo que seus colegas o cobrissem na frente de seus superiores. <br><br><h3>  2.3  An√°lise de v√≠deo: rastreamento e seguran√ßa de pessoas </h3><br>  Ao rastrear pessoas que usam o Vision, voc√™ pode avaliar com precis√£o a perviedade real de √°reas comerciais, esta√ß√µes de trem, cruzamentos, ruas e muitos outros locais p√∫blicos.  Nosso rastreamento tamb√©m pode ser de grande ajuda para controlar o acesso, por exemplo, a um armaz√©m ou outras instala√ß√µes importantes do escrit√≥rio.  E, √© claro, rastrear pessoas e rostos ajuda a resolver problemas de seguran√ßa.  Pegou algu√©m roubando da sua loja?  Adicione-o ao PersonID, que retornou o Vision, na lista negra do seu software de an√°lise de v√≠deo, e na pr√≥xima vez em que o sistema alertar imediatamente a seguran√ßa se esse tipo aparecer novamente. <br><br><h3>  2.4  No com√©rcio </h3><br>  Varejo e v√°rias empresas de servi√ßos est√£o interessadas no reconhecimento de filas.  Usando o Vision, voc√™ pode reconhecer que essa n√£o √© uma multid√£o aleat√≥ria de pessoas, mas uma fila e determinar sua dura√ß√£o.  E ent√£o o sistema informa as pessoas respons√°veis ‚Äã‚Äãsobre a fila para entender a situa√ß√£o: esse √© um fluxo de visitantes e √© preciso chamar funcion√°rios adicionais ou algu√©m est√° invadindo suas responsabilidades profissionais. <br><br>  Outra tarefa interessante √© a separa√ß√£o dos funcion√°rios da empresa no sal√£o e dos visitantes.  Normalmente, o sistema aprende a separar objetos em certas roupas (c√≥digo de vestimenta) ou com alguma caracter√≠stica distintiva (len√ßo de assinatura, crach√° no peito etc.).  Isso ajuda a avaliar com mais precis√£o a presen√ßa (para que os funcion√°rios sozinhos n√£o ‚Äúencerrem‚Äù as estat√≠sticas das pessoas no sal√£o). <br><br>  Usando o reconhecimento facial, voc√™ pode avaliar seu p√∫blico-alvo: qual √© a lealdade dos visitantes, ou seja, quantas pessoas retornam √† sua institui√ß√£o e com que frequ√™ncia.  Calcule quantos visitantes √∫nicos chegam at√© voc√™ em um m√™s.  Para otimizar os custos de atra√ß√£o e reten√ß√£o, voc√™ pode descobrir e alterar a participa√ß√£o, dependendo do dia da semana e at√© da hora do dia. <br><br>  Os franqueadores e as empresas de rede podem solicitar uma avalia√ß√£o da qualidade da marca de v√°rios pontos de venda a partir de fotografias: a presen√ßa de logotipos, letreiros, p√¥steres, banners e assim por diante. <br><br><h3>  2.5  No transporte </h3><br>  Outro exemplo de seguran√ßa atrav√©s da an√°lise de v√≠deo √© a identifica√ß√£o de itens deixados nos aeroportos ou nas esta√ß√µes de trem.  A vis√£o pode ser treinada para reconhecer objetos de centenas de classes: m√≥veis, bolsas, malas, guarda-chuvas, v√°rios tipos de roupas, garrafas e assim por diante.  Se o seu sistema de an√°lise de v√≠deo detectar um objeto sem dono e o reconhecer usando o Vision, ele enviar√° um sinal ao servi√ßo de seguran√ßa.  Uma tarefa semelhante est√° relacionada √† detec√ß√£o autom√°tica de situa√ß√µes fora do padr√£o em locais p√∫blicos: algu√©m ficou doente, algu√©m fumou no lugar errado, ou a pessoa caiu nos trilhos, e assim por diante - todos esses padr√µes do sistema de an√°lise de v√≠deo podem reconhecer atrav√©s da API Vision. <br><br><h3>  2.6  Workflow </h3><br>  Outra aplica√ß√£o interessante do Vision que estamos desenvolvendo atualmente √© o reconhecimento de documentos e sua an√°lise autom√°tica em bancos de dados.  Em vez de dirigir manualmente (ou pior ainda, entrar) s√©ries, n√∫meros, datas de emiss√£o, n√∫meros de contas, dados banc√°rios, datas e locais de nascimento e muitos outros dados formalizados, voc√™ pode digitalizar documentos e envi√°-los automaticamente por um canal seguro atrav√©s da API na nuvem, onde o sistema estar√° em movimento, esses documentos ser√£o reconhecidos, analisados ‚Äã‚Äãe retornar√£o uma resposta com os dados no formato desejado para entrada autom√°tica no banco de dados.  Hoje, a Vision j√° sabe como classificar documentos (inclusive em PDF) - distingue passaportes, SNILS, TIN, certid√µes de nascimento, certid√µes de casamento e outros. <br><br>  Obviamente, em todas essas situa√ß√µes a rede neural n√£o √© capaz de lidar imediatamente.  Em cada caso, um novo modelo √© criado para um cliente espec√≠fico, muitos fatores, nuances e requisitos s√£o levados em considera√ß√£o, conjuntos de dados s√£o selecionados, configura√ß√µes de teste de treinamento s√£o iteradas. <br><br><h1>  3. Esquema de trabalho da API </h1><br>  O "port√£o de entrada" do Vision para os usu√°rios √© a API REST.  Na entrada, ele pode tirar fotos, arquivos de v√≠deo e transmiss√µes de c√¢meras de rede (fluxos RTSP). <br><br>  Para usar o Vision, voc√™ precisa se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">registrar</a> no Mail.ru Cloud Solutions e obter tokens de acesso (client_id + client_secret).  A autentica√ß√£o do usu√°rio √© realizada usando o protocolo OAuth.  Os dados de origem nos corpos das solicita√ß√µes POST s√£o enviados para a API.  E, em resposta, o cliente recebe o resultado do reconhecimento da API no formato JSON, e a resposta √© estruturada: cont√©m informa√ß√µes sobre os objetos encontrados e suas coordenadas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/bc3/859/d8cbc3859777f8f0a40712ef8e8a4e17.png"><br><br><div class="spoiler">  <b class="spoiler_title">Exemplo de resposta</b> <div class="spoiler_text"><pre><code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-attr"><span class="hljs-attr">"body"</span></span>:{ <span class="hljs-attr"><span class="hljs-attr">"objects"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_0"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_2"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person9"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">149</span></span>,<span class="hljs-number"><span class="hljs-number">60</span></span>,<span class="hljs-number"><span class="hljs-number">234</span></span>,<span class="hljs-number"><span class="hljs-number">181</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9999</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.45</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person10"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">159</span></span>,<span class="hljs-number"><span class="hljs-number">70</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">171</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9998</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.32</span></span> } ] } { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_3"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person11"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">157</span></span>,<span class="hljs-number"><span class="hljs-number">60</span></span>,<span class="hljs-number"><span class="hljs-number">232</span></span>,<span class="hljs-number"><span class="hljs-number">111</span></span>], <span class="hljs-attr"><span class="hljs-attr">"aliases"</span></span>:[<span class="hljs-string"><span class="hljs-string">"person12"</span></span>, <span class="hljs-string"><span class="hljs-string">"person13"</span></span>] <span class="hljs-string"><span class="hljs-string">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9998</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.32</span></span> } ] }, { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_4"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"undefined"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">147</span></span>,<span class="hljs-number"><span class="hljs-number">50</span></span>,<span class="hljs-number"><span class="hljs-number">222</span></span>,<span class="hljs-number"><span class="hljs-number">121</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9997</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.26</span></span> } ] } ], <span class="hljs-attr"><span class="hljs-attr">"aliases_changed"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"htmlencoded"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-attr"><span class="hljs-attr">"last_modified"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span> }</code> </pre> <br></div></div><br>  A resposta tem um par√¢metro interessante de grandiosidade - essa √© a ‚Äúfrieza‚Äù condicional do rosto na foto, com ele selecionamos a melhor foto de rosto da sequ√™ncia.  N√≥s treinamos a rede neural para prever a probabilidade de que a imagem seja como nas redes sociais.  Quanto melhor a imagem e mais suave o rosto, maior a grandiosidade. <br><br>  A API Vision usa um conceito como espa√ßo.  Esta √© uma ferramenta para criar diferentes conjuntos de faces.  Exemplos de espa√ßos s√£o listas em preto e branco, listas de visitantes, funcion√°rios, clientes etc. Para cada token no Vision, voc√™ pode criar at√© 10 espa√ßos, em cada espa√ßo pode haver at√© 50 mil PersonID, ou seja, at√© 500 mil para um token .  Al√©m disso, o n√∫mero de tokens por conta n√£o √© limitado. <br><br>  Hoje, a API suporta os seguintes m√©todos de detec√ß√£o e reconhecimento: <br><br><ul><li>  Reconhecer / Definir - defini√ß√£o e reconhecimento de rostos.  Atribui automaticamente um PersonID a cada face exclusiva, retorna o PersonID e as coordenadas das faces encontradas. <br></li><li>  Excluir - exclua um PersonID espec√≠fico do banco de dados de pessoas. <br></li><li>  Truncar - limpa todo o espa√ßo do PersonID, √∫til se tiver sido usado como teste e voc√™ precisar redefinir a base para produ√ß√£o. <br></li><li>  Detectar - defini√ß√£o de objetos, cenas, matr√≠culas, atra√ß√µes, filas, etc. Retorna a classe de objetos encontrados e suas coordenadas <br></li><li>  Detectar documentos - detecta tipos espec√≠ficos de documentos da Federa√ß√£o Russa (distingue passaporte, snls, pousada etc.). <br></li></ul><br>  Al√©m disso, em breve concluiremos o trabalho nos m√©todos de OCR, determinando sexo, idade e emo√ß√µes, al√©m de resolver tarefas de merchandising, ou seja, controlar automaticamente a exibi√ß√£o de mercadorias nas lojas.  Voc√™ pode encontrar a documenta√ß√£o completa da API aqui: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://mcs.mail.ru/help/vision-api</a> <br><br><h1>  4. Conclus√£o </h1><br>  Agora, atrav√©s da API p√∫blica, voc√™ pode acessar o reconhecimento facial em fotos e v√≠deos, ele suporta a defini√ß√£o de v√°rios objetos, n√∫meros de carros, atra√ß√µes, documentos e cenas inteiras.  Cen√°rios de aplica√ß√£o - Mar.  Venha, teste nosso servi√ßo, defina as tarefas mais complicadas para ele.  As primeiras 5.000 transa√ß√µes s√£o gratuitas.  Pode ser o "ingrediente que falta" para seus projetos. <br><br>  O acesso √† API pode ser obtido instantaneamente ao se registrar e conectar-se ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vision</a> .  Todos os usu√°rios do Habra - um c√≥digo promocional para transa√ß√µes adicionais.  Escreva em um endere√ßo de e-mail pessoal no qual a conta foi registrada! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt449120/">https://habr.com/ru/post/pt449120/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt449108/index.html">UDB. O que √© isso? Parte 7. M√≥dulo de controle de tempo e redefini√ß√£o</a></li>
<li><a href="../pt449110/index.html">Corrigido um erro relacionado √† incapacidade de usar o alfabeto cir√≠lico nos nomes das pastas IMAP</a></li>
<li><a href="../pt449112/index.html">N√≥s nos aposentamos - discutimos gadgets de √°udio populares que j√° est√£o "desatualizados"</a></li>
<li><a href="../pt449114/index.html">Reagir em Œªambda</a></li>
<li><a href="../pt449118/index.html">P√≠lula do Dem√¥nio do Kremlin</a></li>
<li><a href="../pt449122/index.html">Lamentando a aus√™ncia em C ++ de uma est√°tica completa se ou ...</a></li>
<li><a href="../pt449124/index.html">T√£o dif√≠cil de encontrar, f√°cil de perder e imposs√≠vel de emitir</a></li>
<li><a href="../pt449128/index.html">Principais empresas de desenvolvimento de jogos do mundo</a></li>
<li><a href="../pt449132/index.html">Os 17 principais plugins do Android Studio</a></li>
<li><a href="../pt449134/index.html">Zoo afl</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
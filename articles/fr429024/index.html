<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍉 🐛 ➿ Créer des GIF avec OpenCV 👶🏼 📤 💃🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ce tutoriel vous montrera comment créer des GIF animés en utilisant OpenCV, Python et ImageMagick. Combinez ensuite ces méthodes pour créer un générat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Créer des GIF avec OpenCV</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429024/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/g1/sx/hd/g1sxhdlqfra2bohbg5d7yjliv6g.gif"></div><br><br>  Ce tutoriel vous montrera comment créer des GIF animés en utilisant OpenCV, Python et ImageMagick.  Combinez ensuite ces méthodes pour créer un générateur de mèmes avec OpenCV! <br><br>  Nous devons tous rire de temps en temps.  Et peut-être que la meilleure façon de trouver lulza est avec les mèmes.  Certains de mes favoris: <br><br><ul><li>  Kermit la grenouille: «Mais ce n'est pas mon affaire» </li><li>  Chat grincheux </li><li>  Échec épique </li><li>  Good guy greg </li></ul><br>  <b>Mais pour moi personnellement, aucun de ces mèmes ne peut être comparé au mème "Deal With It" ("Traitez-le" ou "Comprenez-le vous-même"), dont un exemple est donné au début de l'article.</b> <br><a name="habracut"></a><br>  Il est généralement utilisé dans les cas suivants: <br><br><ol><li>  Comme réponse ou objection à quelqu'un qui n'approuve pas quelque chose que vous avez fait / dit («Traitez-le») </li><li>  Mettre vos lunettes comme si vous partiez et laisser la personne seule avec le problème («Comprenez-le vous-même») </li></ol><br>  Il y a quelques années, j'ai lu un article amusant sur le blog de l'auteur, dont je ne me souviens pas comment générer de tels mèmes en utilisant la vision par ordinateur.  La semaine dernière, je ne pouvais pas trouver ce guide nulle part, donc en tant que blogueur, expert en vision par ordinateur et expert sur les mèmes, j'ai décidé d'écrire un tutoriel moi-même!  (Au fait, si vous connaissez accidentellement la source d'origine, faites-le moi savoir afin que je puisse remercier l'auteur. <b>UPD:</b> Je viens de trouver l'article original du blog de Kirk Kaiser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MakeArtWithPython</a> ). <br><br>  Développer un générateur de mèmes sur OpenCV nous apprendra un certain nombre de compétences pratiques précieuses, notamment: <br><br><ol><li>  Détection des visages à l'aide de techniques d'apprentissage approfondi </li><li>  Utilisation de la bibliothèque dlib pour détecter les repères faciaux et extraire les zones des yeux </li><li>  Comment calculer l'angle de rotation entre les yeux en fonction des informations reçues </li><li>  Et enfin, comment générer des GIF animés en utilisant OpenCV (avec un peu d'aide d'ImageMagick) </li></ol><br>  Ce guide doit être amusant et divertissant - et en même temps vous enseigner de précieuses compétences en programmation de vision par ordinateur qui sont utiles dans le monde réel. <br><br><h1>  Création de GIF avec OpenCV </h1><br>  Dans la première partie du guide, nous discuterons des conditions et des dépendances nécessaires pour ce projet, y compris la configuration appropriée de l'environnement de développement. <br><br>  Ensuite, considérez la structure du projet / catalogue pour notre générateur OpenCV GIF. <br><br>  Dès que nous comprendrons la structure du projet, nous considérerons: 1) notre fichier de configuration;  2) le script Python responsable de la création de GIF avec OpenCV. <br><br>  Enfin, nous évaluerons les résultats du programme sur le mème populaire «Deal With It». <br><br><h4>  Prérequis et dépendances </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/ad6/c3e/193/ad6c3e193373bc04c877e60070d73071.png"><br>  <b>Fig.</b>  <b>1. Nous utiliserons OpenCV, dlib et ImageMagick pour créer des GIF</b> <br><br><h3>  Opencv et dlib </h3><br>  OpenCV est nécessaire pour déterminer les visages dans le cadre et le traitement d'image de base.  Suivez l'un de mes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">guides d'installation d'OpenCV si OpenCV n'est</a> pas installé sur le système. <br><br>  Nous utilisons Dlib pour détecter les repères faciaux, ce qui nous permet de trouver deux yeux sur le visage et de mettre des lunettes de soleil.  Vous pouvez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">installer dlib en utilisant cette instruction</a> . <br><br><h4>  Imagemagick </h4><br>  Si vous n'êtes pas familier avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ImageMagick</a> , alors en vain.  Il s'agit d'un outil en ligne de commande multiplateforme avec de nombreuses fonctionnalités de traitement d'image. <br><br>  Voulez-vous convertir PNG / JPG en PDF avec une seule commande?  Pas de problème. <br><br>  Il existe plusieurs images à partir desquelles vous devez créer un PDF de plusieurs pages?  Facilement. <br><br>  Besoin de dessiner des polygones, des lignes et d'autres formes?  Et c'est possible. <br><br>  Que diriez-vous de l'étalonnage des couleurs par lots ou du redimensionnement de toutes les images avec une seule commande?  Pour ce faire, vous n'avez pas besoin d'écrire quelques lignes en Python pour OpenCV. <br><br>  ImageMagick génère également des GIF à partir de n'importe quelle image. <br><br>  Pour installer ImageMagick sur Ubuntu (ou Raspbian), utilisez simplement apt: <br><br>  Création de GIF avec OpenCVShell <br><br><pre><code class="bash hljs">$ sudo apt-get install imagemagick</code> </pre> <br>  Sur macOS, vous pouvez utiliser HomeBrew: <br><br><pre> <code class="bash hljs">$ brew install imagemagick</code> </pre> <br><h4>  imutils </h4><br>  Dans la plupart des articles, des cours et des livres, j'utilise mon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">package de</a> traitement d'image <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">imutils</a> pratique.  Il est installé sur un système ou un environnement virtuel utilisant pip: <br><br><pre> <code class="bash hljs">$ pip install imutils</code> </pre> <br><h2>  Structure du projet </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/e42/281/af0/e42281af07fb94c9ae60a526098f662d.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. La structure du projet comprend deux répertoires, un fichier de configuration et un script Python</font></i> <br><br>  Il existe deux catalogues dans notre projet: <br><br><ul><li>  <code>images/</code> : exemples d'images d'entrée pour lesquelles nous voulons créer un GIF animé.  J'ai trouvé quelques images avec moi, mais n'hésitez pas à ajouter les vôtres. </li><li>  <code>assets/</code> : ce dossier contient notre détecteur de visage, détecteur de repère de visage et toutes les images + masques associés.  Avec ces ressources, nous mettrons des points et du texte sur les images originales du premier dossier. </li></ul><br>  En raison du grand nombre de paramètres configurables, j'ai décidé de créer un fichier de configuration JSON qui: 1) facilitera l'édition des paramètres;  2) nécessitera moins d'arguments de ligne de commande.  Tous les paramètres de configuration requis pour ce projet sont contenus dans <code>config.json</code> . <br><br>  Considérez le contenu de <code>config.json</code> et <code>create_gif.py</code> . <br><br><a name="1"></a>  <font color="gray">Remarque</font>  <font color="gray">Per.: Le code du projet et le manuel de 17 pages sur la vision par ordinateur, l'apprentissage automatique et OpenCV sont publiés <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">après l'enregistrement</a> (miroir: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">code source</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">manuel</a> ).</font> <br><br><h2>  Génération de GIF avec OpenCV </h2><br>  Alors, continuons et commençons à créer notre générateur GIF OpenCV! <br><br><h4>  Contenu du fichier de configuration JSON </h4><br>  Commençons par le fichier de configuration JSON, puis passons au script Python. <br><br>  Ouvrez un nouveau fichier <code>config.json</code> et insérez les paires clé / valeur suivantes: <br><br>  Création de GIF avec OpenCVPython <br><br><pre> <code class="python hljs">{ <span class="hljs-string"><span class="hljs-string">"face_detector_prototxt"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deploy.prototxt"</span></span>, <span class="hljs-string"><span class="hljs-string">"face_detector_weights"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/res10_300x300_ssd_iter_140000.caffemodel"</span></span>, <span class="hljs-string"><span class="hljs-string">"landmark_predictor"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/shape_predictor_68_face_landmarks.dat"</span></span>,</code> </pre> <br>  Ce sont des fichiers de modèle de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">détecteur de visage OpenCV en apprentissage profond</a> . <br><br>  La dernière ligne est le chemin vers le prédicteur de face dlib. <br><br>  Et maintenant, nous avons quelques chemins vers les fichiers image: <br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">"sunglasses"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/sunglasses.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"sunglasses_mask"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/sunglasses_mask.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"deal_with_it"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deal_with_it.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"deal_with_it_mask"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deal_with_it_mask.png"</span></span>,</code> </pre> <br>  Ce sont les chemins d'accès à nos lunettes de soleil, du texte et des masques assortis pour eux, qui sont indiqués ci-dessous. <br><br>  Tout d'abord, des lunettes de soleil fantaisie et un masque: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c18/c4c/647/c18c4c6471e203aedea66a80c9080192.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">3. Vous n'aimez pas les lunettes avec pixels?</font></i>  <i><font color="gray">Juste supporter ça</font></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/58b/91a/d9c/58b91ad9c2e66238b3f3ac22fe1ee439.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">4. Vous ne comprenez pas pourquoi vous avez besoin d'un masque pour lunettes de soleil?</font></i>  <i><font color="gray">Il suffit de le supporter - ou de lire le reste de l'article pour la réponse.</font></i> <br><br>  Et maintenant, notre texte est «DEAL AVEC ELLE» et le masque: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ec3/4e4/923/ec34e4923e2d05a5b33c065de8f5af66.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">5. Détestez-vous Helvetica Neue Condensed?</font></i>  <i><font color="gray">Traitez-le</font></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c6c/f70/819/c6cf708198bda68d849029b3ded02265.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">6: Ce masque vous permet de dessiner une bordure autour du texte.</font></i>  <i><font color="gray">Oh, peut-être que vous ne voulez pas, voulez-vous une frontière?</font></i>  <i><font color="gray">Eh bien, supporte ça</font></i> <br><br>  Des masques sont nécessaires pour superposer l'image correspondante sur la photo: nous y reviendrons plus tard. <br><br>  Maintenant, définissez certains paramètres pour le générateur de memes: <br><br><pre> <code class="python hljs"> <span class="hljs-string"><span class="hljs-string">"min_confidence"</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-string"><span class="hljs-string">"steps"</span></span>: <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-string"><span class="hljs-string">"delay"</span></span>: <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-string"><span class="hljs-string">"final_delay"</span></span>: <span class="hljs-number"><span class="hljs-number">250</span></span>, <span class="hljs-string"><span class="hljs-string">"loop"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"temp_dir"</span></span>: <span class="hljs-string"><span class="hljs-string">"temp"</span></span> }</code> </pre> <br>  Voici les définitions de chacun des paramètres: <br><br><ul><li>  <code>min_confidence</code> : <code>min_confidence</code> minimale de détection de visage requise. </li><li>  <code>steps</code> : nombre d'images dans l'animation finale.  Chaque «étape» déplace les lunettes de soleil de la bordure supérieure vers la cible (c'est-à-dire jusqu'aux yeux). </li><li>  <code>delay</code> : délai entre les images en centièmes de seconde. </li><li>  <code>final_delay</code> : retard de la dernière image en centièmes de seconde (utile dans ce contexte, car nous voulons que le texte s'affiche plus longtemps que le reste des images). </li><li>  <code>loop</code> : une valeur nulle indique que le GIF se répète pour toujours, sinon spécifiez un entier positif pour le nombre de répétitions de l'animation. </li><li>  <code>temp_dir</code> : le répertoire temporaire dans lequel chacune des images sera stockée avant de créer le GIF final. </li></ul><br><h4>  Mèmes, GIF et OpenCV </h4><br>  Nous avons créé le fichier de configuration JSON, passons maintenant au vrai code. <br><br>  Ouvrez un nouveau fichier, nommez-le <code>create_gif.py</code> et collez le code suivant: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    from imutils import face_utils from imutils import paths import numpy as np import argparse import imutils import shutil import json import dlib import cv2 import sys import os</span></span></code> </pre> <br>  Ici, nous importons les packages nécessaires.  En particulier, nous utiliserons imutils, dlib et OpenCV.  Pour installer ces dépendances, consultez la section Prérequis et dépendances ci-dessus. <br><br>  Maintenant, le script a les packages nécessaires, définissons donc la fonction <code>overlay_image</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">overlay_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bg, fg, fgMask, coords)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     (, )  #    (sH, sW) = fg.shape[:2] (x, y) = coords #          #  ,   , **  # ,    overlay = np.zeros(bg.shape, dtype="uint8") overlay[y:y + sH, x:x + sW] = fg # - , **  ** # ,    ,    # ,       alpha = np.zeros(bg.shape[:2], dtype="uint8") alpha[y:y + sH, x:x + sW] = fgMask alpha = np.dstack([alpha] * 3) #  -   , #   - output = alpha_blend(overlay, bg, alpha) #   return output</span></span></code> </pre> <br>  La fonction <code>overlay_image</code> impose un premier plan ( <code>fg</code> ) sur le dessus de l'image d'arrière-plan ( <code>bg</code> ) aux coordonnées de coordonnées <i>(</i> coordonnées <i>(x, y)</i> ), réalisant une transparence alpha sur le masque de premier plan <code>fgMask</code> . <br><br>  Pour vous familiariser avec les bases d'OpenCV, telles que l'utilisation de masques, assurez-vous de lire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce guide</a> . <br><br>  Pour terminer le processus de fusion, effectuez une fusion alpha: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">alpha_blend</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(fg, bg, alpha)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  ,    - #        [0, 1] fg = fg.astype("float") bg = bg.astype("float") alpha = alpha.astype("float") / 255 #  - fg = cv2.multiply(alpha, fg) bg = cv2.multiply(1 - alpha, bg) #     ,    output = cv2.add(fg, bg) #   return output.astype("uint8")</span></span></code> </pre> <br>  Cette implémentation du mélange alpha est également disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le blog LearnOpenCV</a> . <br><br>  Essentiellement, nous convertirons le premier plan, l'arrière-plan et le canal alpha en nombres à virgule flottante dans la plage <i>[0, 1]</i> .  Ensuite, nous effectuons un mélange alpha, ajoutons le premier plan et l'arrière-plan pour obtenir le résultat que nous retournons à la fonction appelante. <br><br>  Nous allons également créer une fonction d'assistance qui permet de générer des GIF à partir d'un ensemble de chemins d'image à l'aide d'ImageMagick et de la commande <code>convert</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_gif</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputPath, outputPath, delay, finalDelay, loop)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#        imagePaths = sorted(list(paths.list_images(inputPath))) #      lastPath = imagePaths[-1] imagePaths = imagePaths[:-1] #   imagemagick 'convert'  #  GIF      #   ( ) cmd = "convert -delay {} {} -delay {} {} -loop {} {}".format( delay, " ".join(imagePaths), finalDelay, lastPath, loop, outputPath) os.system(cmd)</span></span></code> </pre> <br>  La fonction <code>create_gif</code> prend un ensemble d'images et les recueille dans des animations GIF avec un délai spécifié entre les images et les boucles.  ImageMagick traite tout cela - nous enveloppons simplement la commande <code>convert</code> dans une fonction qui traite dynamiquement divers paramètres. <br><br>  Pour voir les arguments de <code>convert</code> disponibles, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">consultez la documentation</a> .  Vous y verrez combien de fonctions cette équipe a! <br><br>  Plus précisément dans cette fonction, nous: <br><br><ul><li>  Prenez <code>imagePaths</code> . </li><li>  Choisissez le chemin de la dernière image, qui aura un délai séparé. </li><li>  Réaffectez <code>imagePaths</code> pour exclure le dernier chemin. </li><li>  Nous assemblons une commande avec des arguments de ligne de commande, puis demandons au système d'exploitation de <code>convert</code> pour créer des animations GIF. </li></ul><br>  Attribuez au script ses propres arguments de ligne de commande: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      ap = argparse.ArgumentParser() ap.add_argument("-c", "--config", required=True, help="path to configuration file") ap.add_argument("-i", "--image", required=True, help="path to input image") ap.add_argument("-o", "--output", required=True, help="path to output GIF") args = vars(ap.parse_args())</span></span></code> </pre> <br>  Nous avons trois arguments de ligne de commande qui sont traités au moment de l'exécution: <br><br><ul><li>  <code>--config</code> : chemin d'accès au fichier de configuration JSON.  Nous avons examiné le fichier de configuration dans la section précédente. </li><li>  <code>--image</code> : chemin d'accès à l'image d'entrée par rapport à laquelle l'animation est créée (c'est-à-dire détection d'un visage, ajout de lunettes de soleil, puis texte). </li><li>  <code>--output</code> : chemin vers le GIF résultant. </li></ul><br>  Chacun de ces arguments est requis lors de l'exécution du script sur la ligne de commande / le terminal. <br><br>  Téléchargez le fichier de configuration, ainsi que les lunettes et le masque correspondant: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    JSON, #     config = json.loads(open(args["config"]).read()) sg = cv2.imread(config["sunglasses"]) sgMask = cv2.imread(config["sunglasses_mask"]) #    (  ),   #  ,  ,     #   GIF- shutil.rmtree(config["temp_dir"], ignore_errors=True) os.makedirs(config["temp_dir"])</span></span></code> </pre> <br>  Ici, nous chargeons le fichier de configuration (qui pourrait être disponible à l'avenir sous forme de dictionnaire Python).  Chargez ensuite les lunettes de soleil et le masque. <br><br>  S'il reste quelque chose du script précédent, supprimez le répertoire temporaire, puis recréez le répertoire temporaire vide.  Le dossier temporaire contiendra chaque image individuelle de l'animation GIF. <br><br>  Maintenant, chargez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">détecteur de visage d'apprentissage profond OpenCV</a> en mémoire: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># load our OpenCV face detector and dlib facial landmark predictor print("[INFO] loading models...") detector = cv2.dnn.readNetFromCaffe(config["face_detector_prototxt"], config["face_detector_weights"]) predictor = dlib.shape_predictor(config["landmark_predictor"])</span></span></code> </pre> <br>  Pour ce faire, appelez <code>cv2.dnn.readNetFromCaffe</code> .  Le module <code>dnn</code> est uniquement disponible dans OpenCV 3.3 ou version ultérieure.  Un détecteur de visage détectera la présence de visages dans l'image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a91/d3a/0cd/a91d3a0cde3dcb3cac9799c823e47c8c.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. Fonctionnement du détecteur de visage à l'aide d'OpenCV DNN</font></i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chargez</a> ensuite le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prédicteur de repère dlib face</a> .  Il vous permettra de localiser les structures individuelles: yeux, sourcils, nez, bouche et menton: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/056/816/890/0568168909b7f01d2f70f6e58faa9ed9.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. Les repères découverts par dlib se superposent à mon visage</font></i> <br><br>  Plus loin dans ce script, nous n'extrayons que le contour des yeux. <br><br>  Passons à autre chose, trouvons le visage: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       image = cv2.imread(args["image"]) (H, W) = image.shape[:2] blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0)) #        print("[INFO] computing object detections...") detector.setInput(blob) detections = detector.forward() #       ,  #  ,      i = np.argmax(detections[0, 0, :, 2]) confidence = detections[0, 0, i, 2] #    if confidence &lt; config["min_confidence"]: print("[INFO] no reliable faces found") sys.exit(0)</span></span></code> </pre> <br>  Dans ce bloc, nous procédons comme suit: <br><br><ul><li>  Téléchargez l' <code>image</code> originale. </li><li>  Nous construisons un <code>blob</code> à envoyer au détecteur de visage d'un réseau neuronal.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cet article</a> décrit le fonctionnement de <code>blobFromImage</code> d'OpenCV. </li><li>  Exécutez la procédure de détection de visage. </li><li>  Nous trouvons la personne ayant la valeur de probabilité la plus élevée et la comparons avec le seuil de probabilité minimum acceptable.  Si les critères ne sont pas remplis, quittez simplement le script.  Sinon, continuez. </li></ul><br>  Maintenant, nous allons extraire le visage et calculer les points de repère: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   (x, y)  #    box = detections[0, 0, i, 3:7] * np.array([W, H, W, H]) (startX, startY, endX, endY) = box.astype("int") #    dlib    #       rect = dlib.rectangle(int(startX), int(startY), int(endX), int(endY)) shape = predictor(image, rect) shape = face_utils.shape_to_np(shape) #        ,  #     (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"] (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"] leftEyePts = shape[lStart:lEnd] rightEyePts = shape[rStart:rEnd]</span></span></code> </pre> <br>  Pour extraire le visage et trouver des repères faciaux, nous procédons comme suit: <br><br><ul><li>  Nous extrayons les coordonnées de la boîte englobante autour du visage. </li><li>  Créez un objet <code>rectangle</code> dans dlib et appliquez la localisation de face. </li><li>  Nous <code>leftEyePts</code> coordonnées <i>(x, y)</i> de <code>leftEyePts</code> et <code>rightEyePts</code> , respectivement. </li></ul><br>  Compte tenu des coordonnées des yeux, vous pouvez calculer où et comment placer les lunettes de soleil: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       leftEyeCenter = leftEyePts.mean(axis=0).astype("int") rightEyeCenter = rightEyePts.mean(axis=0).astype("int") #      dY = rightEyeCenter[1] - leftEyeCenter[1] dX = rightEyeCenter[0] - leftEyeCenter[0] angle = np.degrees(np.arctan2(dY, dX)) - 180 #      ,  #      sg = imutils.rotate_bound(sg, angle) #     **  ,    #   —       # 90%       sgW = int((endX - startX) * 0.9) sg = imutils.resize(sg, width=sgW) #      ( ,   #  ),      #     - —   #       , #     sgMask = cv2.cvtColor(sgMask, cv2.COLOR_BGR2GRAY) sgMask = cv2.threshold(sgMask, 0, 255, cv2.THRESH_BINARY)[1] sgMask = imutils.rotate_bound(sgMask, angle) sgMask = imutils.resize(sgMask, width=sgW, inter=cv2.INTER_NEAREST)</span></span></code> </pre> <br>  Tout d'abord, nous calculons le centre de chaque œil, puis l'angle entre les centroïdes.  La même opération est effectuée avec l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">alignement</a> horizontal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">du visage dans le cadre</a> . <br><br>  Vous pouvez maintenant faire pivoter et redimensionner les lunettes.  Notez que nous utilisons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la fonction rotation_liée</a> , pas seulement la <code>rotate</code> , afin que OpenCV ne coupe pas les parties qui ne sont pas visibles après la conversion affine. <br><br>  Les mêmes opérations qui ont été appliquées aux lunettes s'appliquent au masque.  Mais vous devez d'abord le convertir en nuances de gris et binariser, car les masques sont toujours binaires.  Ensuite, nous faisons pivoter et redimensionnons le masque de la même manière que pour les lunettes. <br><br>  <i><b>Remarque:</b> notez que lors du redimensionnement du masque, nous utilisons l'interpolation pour les points voisins les plus proches, car le masque ne doit avoir que deux valeurs (0 et 255).</i>  <i>D'autres méthodes d'interpolation sont plus esthétiques, mais ne conviennent pas aux masques.</i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ici,</a> vous pouvez obtenir des informations supplémentaires sur l'interpolation aux points voisins les plus proches.</i> <br><br>  Les trois autres blocs de code créent des cadres pour l'animation GIF: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    ,   #  N       #    steps = np.linspace(0, rightEyeCenter[1], config["steps"], dtype="int") # start looping over the steps for (i, y) in enumerate(steps): #      #  ,    **    #  ,       #   shiftX = int(sg.shape[1] * 0.25) shiftY = int(sg.shape[0] * 0.35) y = max(0, y - shiftY) # add the sunglasses to the image output = overlay_image(image, sg, sgMask, (rightEyeCenter[0] - shiftX, y))</span></span></code> </pre> <br>  Les verres tombent du haut de l'image.  Sur chaque image, ils sont affichés plus près du visage jusqu'à ce qu'ils couvrent leurs yeux.  En utilisant la variable <code>"steps"</code> dans le fichier de configuration JSON, nous générons des coordonnées y pour chaque trame.  Pour ce faire, sans trop d'effort, nous utilisons la fonction <code>linspace</code> de NumPy. <br><br>  Les lignes avec un léger décalage vers la gauche et vers le haut peuvent sembler un peu étranges, mais elles sont nécessaires pour s'assurer que les lunettes couvrent les yeux dans leur ensemble, et ne se déplacent pas seulement au point où se trouve le centre de l'œil.  J'ai déterminé empiriquement des pourcentages pour calculer le décalage le long de chaque axe.  La ligne suivante n'assure aucune valeur négative. <br><br>  En utilisant la fonction <code>overlay_image</code> , <code>overlay_image</code> générons la trame de <code>output</code> finale. <br><br>  Maintenant, appliquez le texte "DEAL WITH IT" en utilisant un autre masque: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    ,    #  "DEAL WITH IT"   if i == len(steps) - 1: #   "DEAL WITH IT"  , #   dwi = cv2.imread(config["deal_with_it"]) dwiMask = cv2.imread(config["deal_with_it_mask"]) dwiMask = cv2.cvtColor(dwiMask, cv2.COLOR_BGR2GRAY) dwiMask = cv2.threshold(dwiMask, 0, 255, cv2.THRESH_BINARY)[1] #       80%   #  oW = int(W * 0.8) dwi = imutils.resize(dwi, width=oW) dwiMask = imutils.resize(dwiMask, width=oW, inter=cv2.INTER_NEAREST) #  ,   ,  #   oX = int(W * 0.1) oY = int(H * 0.8) output = overlay_image(output, dwi, dwiMask, (oX, oY))</span></span></code> </pre> <br>  À la dernière étape, nous imposons le texte, qui est en réalité une autre image. <br><br>  J'ai décidé d'utiliser une image car les capacités de rendu des polices OpenCV sont assez limitées.  De plus, je voulais ajouter une ombre et une bordure autour du texte, qu'OpenCV ne sait pas encore comment. <br><br>  Dans le reste de ce code, nous chargeons à la fois l'image et le masque, puis effectuons un mélange alpha pour générer le résultat final. <br><br>  Il ne reste plus qu'à enregistrer chaque image sur le disque avec la création ultérieure d'animation GIF: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      p = os.path.sep.join([config["temp_dir"], "{}.jpg".format( str(i).zfill(8))]) cv2.imwrite(p, output) #      ,     #   GIF- print("[INFO] creating GIF...") create_gif(config["temp_dir"], args["output"], config["delay"], config["final_delay"], config["loop"]) #  --    print("[INFO] cleaning up...") shutil.rmtree(config["temp_dir"], ignore_errors=True)</span></span></code> </pre> <br>  Nous écrivons le résultat sur le disque.  Après avoir généré toutes les images, nous appelons la fonction <code>create_gif</code> pour créer le fichier d'animation GIF.  N'oubliez pas qu'il s'agit d'un shell qui transmet des paramètres à l'outil de ligne de commande de <code>convert</code> ImageMagick. <br><br>  Enfin, supprimez le répertoire de sortie temporaire et les fichiers d'image individuels. <br><br><h2>  Résultats </h2><br>  Maintenant, la partie amusante: voyons ce que notre générateur de mèmes a créé! <br><br>  Assurez-vous de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">télécharger le</a> code source, des exemples d'images et des modèles d'apprentissage approfondi.  Ouvrez ensuite un terminal et exécutez la commande suivante: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian.jpg \ --output adrian_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/dca/b24/46e/dcab2446ec5dc96065e37a473375eea6.gif"><br>  <i><font color="gray">Figure 9. Animation GIF générée avec OpenCV et ImageMagick avec ce script Python</font></i> <br><br>  Ici, vous pouvez voir le GIF créé en utilisant OpenCV et ImageMagick.  Les actions suivantes y sont effectuées: <br><br><ol><li>  Détection correcte de mon visage. </li><li>  Localisation des yeux et calcul de leurs centres. </li><li>  Les lunettes tombent correctement sur le visage. </li></ol><br>  Les lecteurs de mon blog savent que je suis un gros nerd à Jurassic Park et le mentionnent souvent dans mes livres, mes cours et mes guides d'étude. <br><br>  Vous n'aimez pas <i>Jurassic Park</i> ? <br><br>  Ok, voici ma réponse: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian_jp.jpg \ --output adrian_jp_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/da9/0d7/740/da90d7740e8ac813b9f99a727b9e04bc.gif"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">10. Animation GIF OpenCV basée sur une photographie de la récente projection de Jurassic World 2</font></i> <br><br>  Me voici au spectacle "Jurassic World: 2" dans un T-shirt thématique, avec un verre de lumière et un livre de collection. <br><br>  Histoire amusante: <br><br>  Il y a cinq ou six ans, ma femme et moi avons visité le parc à thème Epcot Center à Disney World, en Floride. <br><br>  Nous avons décidé de faire un voyage pour nous éloigner des hivers rigoureux du Connecticut et nous avions désespérément besoin de soleil. <br><br>  Malheureusement, en Floride, il pleuvait tout le temps et la température dépassait à peine 10 ° C. <br><br>  Près des jardins canadiens, Trisha a pris une photo de moi: elle dit que je ressemble à un vampire avec une peau pâle, des vêtements sombres et une capuche, sur le fond des jardins luxuriants derrière: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/vampire.jpg \ --output vampire_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/ad1/1ce/ca2/ad11ceca2ed48792a5aa28c0c8dc7f40.gif"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">11. En utilisant OpenCV et Python, vous pouvez créer ce meme ou un autre GIF animé</font></i> <br><br>  Le même soir, Trisha a publié une photo sur les réseaux sociaux - j'ai dû la supporter. <br><br>  Ceux d'entre vous qui ont assisté à PyImageConf 2018 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lire la critique</a> ) savent que je suis toujours ouvert aux blagues.  Voici un exemple: <br><br>  <i>Question: Pourquoi le coq traverse-t-il la route?</i> <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/rooster.jpg \ --output rooster_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/5dd/e92/ef0/5dde92ef04cb35436e87b0b70cc5926d.gif"><br>  <i><font color="gray">Fig.</font></i> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">12. Le visage est reconnu même avec un faible contraste, et OpenCV traite correctement la photo et abaisse les lunettes de soleil</font></font></font></i> <br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Réponse: Je ne dirai pas la réponse - supporte cela. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Enfin, nous concluons le guide d'aujourd'hui par un bon mème. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il y a environ six ans, mon père et moi avons adopté un petit beagle, Gemma. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ici, vous pouvez voir Gemma sur mon épaule:</font></font><br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/pupper.jpg \ --output pupper_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/08a/b5a/728/08ab5a728e8bd48ac2550a2962e76165.gif"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">13. Gemma est délicieuse. </font><font style="vertical-align: inherit;">Tu ne crois pas? </font><font style="vertical-align: inherit;">Alors "acceptez-le!" </font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ne convenez pas qu'elle est mignonne? </font><font style="vertical-align: inherit;">Traitez-le.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Vous avez une erreur AttributeError? </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ne t'inquiète pas! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vous avez vu cette erreur:</font></font><br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian.jpg \ --output adrian_out.gif ... Traceback (most recent call last): File <span class="hljs-string"><span class="hljs-string">"create_gif.py"</span></span>, line 142, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;module&gt; (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[<span class="hljs-string"><span class="hljs-string">"left_eye"</span></span>] AttributeError: module <span class="hljs-string"><span class="hljs-string">'imutils.face_utils'</span></span> has no attribute <span class="hljs-string"><span class="hljs-string">'FACIAL_LANDMARKS_IDXS'</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ... alors il vous suffit de mettre à jour le paquet imutils: </font></font><br><br><pre> <code class="bash hljs">$ pip install --upgrade imutils Collecting imutils ... Successfully installed imutils-0.5.1</code> </pre> <br>  Pourquoi? <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par défaut, il </font></font><code>imutils.face_utils</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">utilise un détecteur de point de repère de 68 points intégré à dlib (comme dans cet article). </font><font style="vertical-align: inherit;">Il existe </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un détecteur 5 points plus rapide</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui fonctionne désormais également avec les imutils. </font><font style="vertical-align: inherit;">J'ai récemment mis à jour des imutils pour prendre en charge les deux détecteurs (vous pouvez donc voir une erreur).</font></font><br><br><h1>  Résumé </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le didacticiel d'aujourd'hui, vous avez appris à créer des GIF à l'aide d'OpenCV. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour rendre la leçon amusante, nous avons utilisé OpenCV pour générer l'animation GIF «Deal With It», un mème populaire (et mon préféré) qui se trouve sous une forme ou une autre sur presque tous les sites de réseaux sociaux. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le processus, nous avons utilisé la vision par ordinateur et l'apprentissage en profondeur pour résoudre plusieurs problèmes pratiques:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Identification des personnes </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Prévoyez des repères sur le visage </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Identification des zones du visage (dans ce cas, l'œil) </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Calcul de l'angle entre les yeux pour aligner le visage </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Créez des mélanges transparents avec le mélange alpha </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Enfin, nous avons pris un ensemble d'images générées et créé un GIF animé en utilisant OpenCV et ImageMagick. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'espère que vous avez apprécié le tutoriel d'aujourd'hui! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si cela vous a plu, laissez un commentaire et faites le moi savoir. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eh bien, si vous ne l'aimiez pas, cela n'a pas d'importance, il suffit de le supporter.</font></font> ;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429024/">https://habr.com/ru/post/fr429024/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429014/index.html">Git sous-arbre en détail</a></li>
<li><a href="../fr429016/index.html">Volvo et Baidu développeront ensemble des véhicules sans pilote</a></li>
<li><a href="../fr429018/index.html">Pourquoi la nouvelle conception de Gmail est-elle si lente?</a></li>
<li><a href="../fr429020/index.html">Qu'est-ce qu'un setter fluide</a></li>
<li><a href="../fr429022/index.html">GridGain on Highload: où parler des SGBD distribués, en mémoire et open source</a></li>
<li><a href="../fr429028/index.html">Korolev. Médecine pour le web</a></li>
<li><a href="../fr429030/index.html">Logomachine crée des logos gratuits par commentaire</a></li>
<li><a href="../fr429032/index.html">Splunk Essentials pour l'application Financial Services Industry, ou comment Splunk entre sur le marché de l'analyse financière</a></li>
<li><a href="../fr429034/index.html">Quelques histoires sur les programmeurs underground</a></li>
<li><a href="../fr429038/index.html">Rust News # 2 (octobre 2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
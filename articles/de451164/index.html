<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüöí üéÇ üòä Auf der Suche nach freien Parkpl√§tzen mit Python üë©üèª‚Äçü§ù‚Äçüë®üèø üéÖüèø üíò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich lebe in einer guten Stadt. Aber wie bei vielen anderen wird die Suche nach einem Parkplatz immer zum Test. Freie Pl√§tze sind schnell besetzt, und ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Auf der Suche nach freien Parkpl√§tzen mit Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451164/"><img src="https://habrastorage.org/webt/vz/x5/od/vzx5odyqel0ow-z2qolfdo1htd4.gif" alt="Bild"><br><br>  Ich lebe in einer guten Stadt.  Aber wie bei vielen anderen wird die Suche nach einem Parkplatz immer zum Test.  Freie Pl√§tze sind schnell besetzt, und selbst wenn Sie eigene haben, wird es f√ºr Freunde schwierig sein, Sie anzurufen, da sie nirgendwo parken k√∂nnen. <br><br>  Also habe ich beschlossen, die Kamera aus dem Fenster zu richten und Deep Learning zu verwenden, damit mein Computer mir sagt, wann der Platz verf√ºgbar ist: <br><br><img src="https://habrastorage.org/webt/lx/md/gy/lxmdgyxkvnwtwc5nsqccy83mp34.gif" alt="Bild"><br><br>  Es mag kompliziert klingen, aber tats√§chlich ist das Schreiben eines funktionierenden Prototyps mit tiefem Lernen schnell und einfach.  Alle notwendigen Komponenten sind bereits vorhanden - Sie m√ºssen nur wissen, wo Sie sie finden und wie Sie sie zusammensetzen k√∂nnen. <br><br>  Also lasst uns Spa√ü haben und ein genaues kostenloses Parkbenachrichtigungssystem mit Python und Deep Learning schreiben <a name="habracut"></a><br><br><h3>  Aufgabe zerlegen </h3><br>  Wenn wir eine schwierige Aufgabe haben, die wir mit maschinellem Lernen l√∂sen m√∂chten, besteht der erste Schritt darin, sie in eine Folge einfacher Aufgaben aufzuteilen.  Dann k√∂nnen wir verschiedene Werkzeuge verwenden, um jedes von ihnen zu l√∂sen.  Durch die Kombination mehrerer einfacher L√∂sungen erhalten wir ein System, das zu etwas Komplexem f√§hig ist. <br><br>  So habe ich meine Aufgabe gebrochen: <br><br><img src="https://habrastorage.org/webt/q7/gi/hi/q7gihifth7-k9mad7fhgbj4itcc.jpeg" alt="Bild"><br><br>  Der auf das Fenster gerichtete Videostream von der Webcam wird in die F√∂rderereingabe eingegeben: <br><br><img src="https://habrastorage.org/webt/aa/wk/ig/aawkigsexhbk5s4slqmvksvofcm.gif" alt="Bild"><br><br>  √úber die Pipeline √ºbertragen wir jedes Bild des Videos einzeln. <br><br>  Der erste Schritt besteht darin, alle m√∂glichen Parkpl√§tze im Rahmen zu erkennen.  Bevor wir nach unbesetzten Pl√§tzen suchen k√∂nnen, m√ºssen wir nat√ºrlich verstehen, in welchen Teilen des Bildes sich Parkpl√§tze befinden. <br><br>  Dann m√ºssen Sie auf jedem Rahmen alle Autos finden.  Auf diese Weise k√∂nnen wir die Bewegung jeder Maschine von Bild zu Bild verfolgen. <br><br>  Der dritte Schritt besteht darin, festzustellen, welche Pl√§tze von Maschinen belegt sind und welche nicht.  Kombinieren Sie dazu die Ergebnisse der ersten beiden Schritte. <br><br>  Schlie√ülich sollte das Programm eine Warnung senden, wenn der Parkplatz frei wird.  Dies wird durch √Ñnderungen der Position der Maschinen zwischen den Bildern des Videos bestimmt. <br><br>  Jeder dieser Schritte kann auf unterschiedliche Weise mit unterschiedlichen Technologien ausgef√ºhrt werden.  Es gibt keinen einzigen richtigen oder falschen Weg, um diesen F√∂rderer zusammenzusetzen, verschiedene Ans√§tze haben ihre Vor- und Nachteile.  Lassen Sie uns jeden Schritt genauer behandeln. <br><br><h3>  Wir erkennen Parkpl√§tze </h3><br>  Folgendes sieht unsere Kamera: <br><br><img src="https://habrastorage.org/webt/2u/zl/xt/2uzlxtgxbn6jvfkhfy0e523ow88.png" alt="Bild"><br><br>  Wir m√ºssen dieses Bild irgendwie scannen und eine Liste der Parkpl√§tze erhalten: <br><br><img src="https://habrastorage.org/webt/m-/bq/xb/m-bqxb9ybcjc44blvsuzhnw6xyk.png" alt="Bild"><br><br>  Die L√∂sung ‚Äûin der Stirn‚Äú w√§re, die Positionen aller Parkpl√§tze einfach manuell fest zu codieren, anstatt sie automatisch zu erkennen.  In diesem Fall m√ºssen wir den gesamten Vorgang erneut ausf√ºhren, wenn wir die Kamera bewegen oder nach Parkpl√§tzen in einer anderen Stra√üe suchen m√∂chten.  Es klingt so lala, also suchen wir nach einer automatischen Methode, um Parkpl√§tze zu erkennen. <br><br>  Alternativ k√∂nnen Sie im Bild nach Parkuhren suchen und davon ausgehen, dass sich neben jeder Parkuhr ein Parkplatz befindet: <br><br><img src="https://habrastorage.org/webt/qi/g8/cj/qig8cjwmp7dmduejcddjk6tnoiw.png" alt="Bild"><br><br>  Bei diesem Ansatz ist jedoch nicht alles so reibungslos.  Erstens hat nicht jeder Parkplatz eine Parkuhr, und tats√§chlich sind wir mehr daran interessiert, Parkpl√§tze zu finden, f√ºr die Sie nicht bezahlen m√ºssen.  Zweitens sagt uns die Position der Parkuhr nichts dar√ºber aus, wo sich der Parkplatz befindet, sondern l√§sst uns nur eine Annahme treffen. <br><br>  Eine andere Idee besteht darin, ein Objekterkennungsmodell zu erstellen, das nach auf der Stra√üe gezeichneten Parkmarkierungen sucht: <br><br><img src="https://habrastorage.org/webt/bo/vv/nu/bovvnu6rsl-zimlr1gtpp1a_egm.png" alt="Bild"><br><br>  Aber dieser Ansatz ist so lala.  Erstens sind in meiner Stadt alle diese Markierungen sehr klein und aus der Ferne schwer zu erkennen, so dass es schwierig sein wird, sie mit einem Computer zu erkennen.  Zweitens ist die Stra√üe voller allerlei anderer Linien und Markierungen.  Es wird schwierig sein, Parkmarken von Fahrspurtrennern und Fu√üg√§nger√ºberwegen zu trennen. <br><br>  Wenn Sie auf ein Problem sto√üen, das auf den ersten Blick schwierig erscheint, nehmen Sie sich ein paar Minuten Zeit, um einen anderen L√∂sungsansatz zu finden, mit dem Sie einige technische Probleme umgehen k√∂nnen.  Was gibt es einen Parkplatz?  Dies ist nur ein Ort, an dem ein Auto lange Zeit geparkt ist.  Vielleicht m√ºssen wir Parkpl√§tze √ºberhaupt nicht erkennen.  Warum erkennen wir nicht einfach die Autos, die lange still stehen und gehen nicht davon aus, dass sie auf dem Parkplatz stehen? <br><br>  Mit anderen Worten, Parkpl√§tze befinden sich dort, wo Autos lange stehen: <br><br><img src="https://habrastorage.org/webt/b8/tb/ua/b8tbuafyf4uci3jy61jnjlwanqa.png" alt="Bild"><br><br>  Wenn wir also die Autos erkennen und herausfinden k√∂nnen, welche sich nicht zwischen den Rahmen bewegen, k√∂nnen wir erraten, wo sich die Parkpl√§tze befinden.  So einfach ist das - gehen Sie zur Maschinenerkennung! <br><br><h3>  Autos erkennen </h3><br>  Das Erkennen von Autos auf einem Videorahmen ist eine klassische Objekterkennungsaufgabe.  Es gibt viele Ans√§tze des maschinellen Lernens, die wir zur Erkennung verwenden k√∂nnten.  Hier sind einige davon in der Reihenfolge von der "alten Schule" zur "neuen Schule": <br><br><ul><li>  Sie k√∂nnen den Detektor basierend auf HOG (Histogramm orientierter Gradienten, Histogramme gerichteter Gradienten) trainieren und ihn durch das gesamte Bild f√ºhren, um alle Autos zu finden.  Dieser alte Ansatz, bei dem kein tiefes Lernen verwendet wird, funktioniert relativ schnell, kommt jedoch mit Maschinen, die sich auf unterschiedliche Weise befinden, nicht sehr gut zurecht. </li><li>  Sie k√∂nnen den CNN-basierten Detektor (Convolutional Neural Network, ein Convolutional Neural Network) trainieren und ihn durch das gesamte Bild f√ºhren, bis wir alle Maschinen gefunden haben.  Dieser Ansatz funktioniert genau, aber nicht so effizient, da wir das Bild mehrmals mit CNN scannen m√ºssen, um alle Maschinen zu finden.  Und obwohl wir Maschinen auf unterschiedliche Weise finden k√∂nnen, ben√∂tigen wir viel mehr Trainingsdaten als f√ºr einen HOG-Detektor. </li><li>  Sie k√∂nnen einen neuen Ansatz mit Deep Learning wie Mask R-CNN, Faster R-CNN oder YOLO verwenden, der die Genauigkeit von CNN und eine Reihe technischer Tricks kombiniert, die die Erkennungsgeschwindigkeit erheblich erh√∂hen.  Solche Modelle funktionieren relativ schnell (auf der GPU), wenn wir viele Daten haben, um das Modell zu trainieren. </li></ul><br>  Im allgemeinen Fall ben√∂tigen wir die einfachste L√∂sung, die ordnungsgem√§√ü funktioniert und die geringste Menge an Trainingsdaten erfordert.  Dies muss nicht der neueste und schnellste Algorithmus sein.  Insbesondere in unserem Fall ist Mask R-CNN jedoch eine vern√ºnftige Wahl, obwohl es recht neu und schnell ist. <br><br>  Die R-CNN-Architektur der Maske ist so konzipiert, dass sie Objekte im gesamten Bild erkennt, Ressourcen effektiv verbraucht und nicht den Schiebefensteransatz verwendet.  Mit anderen Worten, es funktioniert ziemlich schnell.  Mit einer modernen GPU k√∂nnen wir Objekte in Videos in hoher Aufl√∂sung mit einer Geschwindigkeit von mehreren Bildern pro Sekunde erkennen.  F√ºr unser Projekt sollte dies ausreichen. <br><br>  Dar√ºber hinaus bietet Mask R-CNN viele Informationen zu jedem erkannten Objekt.  Die meisten Erkennungsalgorithmen geben f√ºr jedes Objekt nur einen Begrenzungsrahmen zur√ºck.  Die Maske R-CNN gibt uns jedoch nicht nur die Position jedes Objekts, sondern auch dessen Umriss (Maske): <br><br><img src="https://habrastorage.org/webt/n2/b0/hp/n2b0hpwgwpkn6ahfhqetvbhq1rg.png" alt="Bild"><br><br>  Um Mask R-CNN zu trainieren, ben√∂tigen wir viele Bilder von Objekten, die wir erkennen m√∂chten.  Wir k√∂nnten nach drau√üen gehen, Fotos von Autos machen und sie auf Fotos markieren, was mehrere Arbeitstage erfordern w√ºrde.  Gl√ºcklicherweise geh√∂ren Autos zu den Objekten, die Menschen h√§ufig erkennen m√∂chten. Daher existieren bereits mehrere √∂ffentliche Datens√§tze mit Bildern von Autos. <br><br>  Eines davon ist das beliebte SOCO- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dataset</a> (kurz f√ºr Common Objects In Context), dessen Bilder mit Objektmasken versehen sind.  Dieser Datensatz enth√§lt √ºber 12.000 Bilder mit bereits gekennzeichneten Maschinen.  Hier ist ein Beispielbild aus dem Datensatz: <br><br><img src="https://habrastorage.org/webt/dv/lz/7l/dvlz7ltgwmudog9-b2f6i7tlmhe.jpeg" alt="Bild"><br><br>  Solche Daten eignen sich hervorragend zum Trainieren eines auf Mask R-CNN basierenden Modells. <br><br>  Aber halt die Pferde, es gibt noch bessere Neuigkeiten!  Wir sind nicht die ersten, die ihr Modell anhand des COCO-Datensatzes trainieren wollten - viele Menschen haben dies bereits vor uns getan und ihre Ergebnisse geteilt.  Anstatt unser Modell zu trainieren, k√∂nnen wir daher ein fertiges Modell nehmen, das bereits Autos erkennt.  F√ºr unser Projekt werden wir das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Open-Source-Modell von Matterport verwenden.</a> <br><br>  Wenn wir dem Eingang dieses Modells ein Bild von der Kamera geben, erhalten wir dies bereits ‚Äûout of the box‚Äú: <br><br><img src="https://habrastorage.org/webt/vy/kq/50/vykq50pcxhyt_vkmfzmxk_fgl5g.png" alt="Bild"><br><br>  Das Modell erkannte nicht nur Autos, sondern auch Objekte wie Ampeln und Personen.  Es ist lustig, dass sie den Baum als Zimmerpflanze erkannte. <br><br>  F√ºr jedes erkannte Objekt gibt das Mask R-CNN-Modell 4 Dinge zur√ºck: <br><br><ul><li>  Art des erkannten Objekts (Ganzzahl).  Das vorgefertigte COCO-Modell kann 80 verschiedene gemeinsame Objekte wie Autos und Lastwagen erkennen.  Eine vollst√§ndige Liste finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier.</a> </li><li>  Der Grad des Vertrauens in die Erkennungsergebnisse.  Je h√∂her die Zahl, desto st√§rker ist das Modell von der Erkennung des Objekts √ºberzeugt. </li><li>  Ein Begrenzungsrahmen f√ºr ein Objekt in Form von XY-Koordinaten von Pixeln im Bild. </li><li>  Eine ‚ÄûMaske‚Äú, die anzeigt, welche Pixel innerhalb des Begrenzungsrahmens Teil des Objekts sind.  Mithilfe der Maskendaten k√∂nnen Sie den Umriss des Objekts ermitteln. </li></ul><br>  Unten finden Sie den Python-Code zum Erkennen des Begrenzungsrahmens f√ºr Maschinen mithilfe der vorab trainierten Modelle Mask R-CNN und OpenCV: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,    ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR ( OpenCV)  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). #      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) print("Cars found in frame of video:") #     . for box in car_boxes: print("Car:", box) y1, x1, y2, x2 = box #  . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1) #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #    . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Nach dem Ausf√ºhren dieses Skripts wird auf dem Bildschirm ein Bild mit einem Rahmen um jeden erkannten Computer angezeigt: <br><br><img src="https://habrastorage.org/webt/_p/il/0r/_pil0reoz3gj7dtqboav_rgerl8.jpeg" alt="Bild"><br><br>  Au√üerdem werden die Koordinaten jeder Maschine in der Konsole angezeigt: <br><br><pre> <code class="python hljs">Cars found <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> frame of video: Car: [<span class="hljs-number"><span class="hljs-number">492</span></span> <span class="hljs-number"><span class="hljs-number">871</span></span> <span class="hljs-number"><span class="hljs-number">551</span></span> <span class="hljs-number"><span class="hljs-number">961</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">450</span></span> <span class="hljs-number"><span class="hljs-number">819</span></span> <span class="hljs-number"><span class="hljs-number">509</span></span> <span class="hljs-number"><span class="hljs-number">913</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">411</span></span> <span class="hljs-number"><span class="hljs-number">774</span></span> <span class="hljs-number"><span class="hljs-number">470</span></span> <span class="hljs-number"><span class="hljs-number">856</span></span>]</code> </pre><br>  So haben wir gelernt, Autos im Bild zu erkennen. <br><br><h3>  Wir erkennen leere Parkpl√§tze </h3><br>  Wir kennen die Pixelkoordinaten jeder Maschine.  Wenn wir mehrere aufeinanderfolgende Frames durchsehen, k√∂nnen wir leicht feststellen, welches der Autos sich nicht bewegt hat, und davon ausgehen, dass es Parkpl√§tze gibt.  Aber wie kann man verstehen, dass das Auto den Parkplatz verlassen hat? <br><br>  Das Problem ist, dass sich die Rahmen der Maschinen teilweise √ºberlappen: <br><br><img src="https://habrastorage.org/webt/7t/vi/4q/7tvi4q1rgvkfkaljrsp8sjathr0.jpeg" alt="Bild"><br><br>  Wenn Sie sich also vorstellen, dass jeder Rahmen einen Parkplatz darstellt, kann sich herausstellen, dass er teilweise von der Maschine belegt ist, obwohl er tats√§chlich leer ist.  Wir m√ºssen einen Weg finden, um den Schnittgrad zweier Objekte zu messen, um nur nach den ‚Äûleersten‚Äú Frames zu suchen. <br><br>  Wir werden ein Ma√ü namens Intersection Over Union (Verh√§ltnis von Schnittfl√§che zu Gesamtfl√§che) oder IoU verwenden.  IoU kann ermittelt werden, indem die Anzahl der Pixel berechnet wird, an denen sich zwei Objekte schneiden, und durch die Anzahl der von diesen Objekten belegten Pixel dividiert wird: <br><br><img src="https://habrastorage.org/webt/zs/c0/sz/zsc0szsct8xjwkx5eo-6ieynfuc.png" alt="Bild"><br><br>  So k√∂nnen wir verstehen, wie sich der sehr begrenzende Rahmen des Autos mit dem Rahmen des Parkplatzes schneidet.  Auf diese Weise k√∂nnen Sie leicht feststellen, ob das Parken kostenlos ist.  Wenn der IoU-Wert niedrig ist, wie z. B. 0,15, nimmt das Auto einen kleinen Teil des Parkplatzes ein.  Und wenn es hoch ist, wie 0,6, bedeutet dies, dass das Auto den gr√∂√üten Teil des Platzes einnimmt und Sie dort nicht parken k√∂nnen. <br><br>  Da IoU in der Bildverarbeitung h√§ufig verwendet wird, ist es sehr wahrscheinlich, dass die entsprechenden Bibliotheken diese Ma√ünahme implementieren.  In unserer Bibliothek Mask R-CNN ist sie als Funktion mrcnn.utils.compute_overlaps () implementiert. <br><br>  Wenn wir eine Liste von Begrenzungsrahmen f√ºr Parkpl√§tze haben, k√∂nnen Sie eine √úberpr√ºfung auf das Vorhandensein von Autos in diesem Rahmen hinzuf√ºgen, indem Sie eine oder zwei ganze Codezeilen hinzuf√ºgen: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,        . overlaps = mrcnn.utils.compute_overlaps(car_boxes, parking_areas) print(overlaps)</span></span></code> </pre><br>  Das Ergebnis sollte ungef√§hr so ‚Äã‚Äãaussehen: <br><br><pre> <code class="python hljs">[ [<span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07673165</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.02332112</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] ]</code> </pre><br>  In diesem zweidimensionalen Array spiegelt jede Zeile einen Rahmen des Parkplatzes wider.  Und jede Spalte gibt an, wie stark sich jeder Ort mit einer der erkannten Maschinen schneidet.  Ein Ergebnis von 1,0 bedeutet, dass der gesamte Platz vollst√§ndig vom Auto belegt ist, und ein niedriger Wert wie 0,02 zeigt an, dass das Auto ein wenig an seinen Platz geklettert ist, aber Sie k√∂nnen trotzdem darauf parken. <br><br>  Um nicht belegte Pl√§tze zu finden, m√ºssen Sie nur jede Zeile in diesem Array √ºberpr√ºfen.  Wenn alle Zahlen nahe Null sind, ist der Platz h√∂chstwahrscheinlich frei! <br><br>  Beachten Sie jedoch, dass die Objekterkennung bei Echtzeitvideos nicht immer perfekt funktioniert.  Obwohl das auf Mask R-CNN basierende Modell ziemlich genau ist, kann es von Zeit zu Zeit ein oder zwei Autos in einem Frame des Videos vermissen.  Bevor Sie behaupten, dass der Platz frei ist, m√ºssen Sie daher sicherstellen, dass dies auch f√ºr die n√§chsten 5 bis 10 n√§chsten Videobilder der Fall ist.  Auf diese Weise k√∂nnen wir Situationen vermeiden, in denen das System f√§lschlicherweise einen leeren Platz aufgrund eines Fehlers in einem Bild des Videos markiert.  Sobald wir sicherstellen, dass der Platz f√ºr mehrere Frames frei bleibt, k√∂nnen Sie eine Nachricht senden! <br><br><h3>  SMS senden </h3><br>  Der letzte Teil unseres F√∂rderers sendet SMS-Benachrichtigungen, wenn ein freier Parkplatz angezeigt wird. <br><br>  Das Senden einer Nachricht von Python ist sehr einfach, wenn Sie Twilio verwenden.  Twilio ist eine beliebte API, mit der Sie SMS aus nahezu jeder Programmiersprache mit nur wenigen Codezeilen senden k√∂nnen.  Wenn Sie einen anderen Dienst bevorzugen, k√∂nnen Sie ihn nat√ºrlich nutzen.  Ich habe nichts mit Twilio zu tun, es ist nur das erste, was mir in den Sinn kommt. <br><br>  Um Twilio zu verwenden, melden Sie sich f√ºr ein Testkonto an, erstellen Sie eine Twilio-Telefonnummer und erhalten Sie Informationen zur Kontoauthentifizierung.  Installieren Sie dann die Client-Bibliothek: <br><br><pre> <code class="python hljs">$ pip3 install twilio</code> </pre><br>  Verwenden Sie danach den folgenden Code, um die Nachricht zu senden: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment">#   Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_source_phone_number = '   Twilio' #    Twilio. client = Client(twilio_account_sid, twilio_auth_token) #  SMS. message = client.messages.create( body=" ", from_=twilio_source_phone_number, to=" ,   " )</span></span></code> </pre><br>  Kopieren Sie diesen Code einfach dorthin, um die M√∂glichkeit zum Senden von Nachrichten an unser Skript hinzuzuf√ºgen.  Sie m√ºssen jedoch sicherstellen, dass die Nachricht nicht in jedem Frame gesendet wird, in dem Sie den freien Speicherplatz sehen k√∂nnen.  Daher haben wir ein Flag, das im installierten Zustand das Senden von Nachrichten f√ºr einige Zeit oder bis ein anderer Ort frei ist, nicht zul√§sst. <br><br><h3>  Alles zusammenf√ºgen </h3><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #  Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_phone_number = '   Twilio' destination_phone_number = ',   ' client = Client(twilio_account_sid, twilio_auth_token) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,   ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #         . free_space_frames = 0 #    SMS? sms_sent = False #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). if parked_car_boxes is None: #     ‚Äî ,       . #            . parked_car_boxes = get_car_boxes(r['rois'], r['class_ids']) else: #   ,  . ,   . #     . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,         . overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes) # ,    ,      . free_space = False #        . for parking_area, overlap_areas in zip(parked_car_boxes, overlaps): #        #    (, ). max_IoU_overlap = np.max(overlap_areas) #         . y1, x1, y2, x2 = parking_area # ,   ,   IoU. if max_IoU_overlap &lt; 0.15: #  !     . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3) # ,        . free_space = True else: #     ‚Äî   . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1) #   IoU  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"{max_IoU_overlap:0.2}", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255)) #       ,   . #   ,  ,     #      . if free_space: free_space_frames += 1 else: #   ,  . free_space_frames = 0 #       ,  ,   . if free_space_frames &gt; 10: #   SPACE AVAILABLE!!  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"SPACE AVAILABLE!", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED) #  ,     . if not sms_sent: print("SENDING SMS!!!") message = client.messages.create( body="Parking space open - go go go!", from_=twilio_phone_number, to=destination_phone_number ) sms_sent = True #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #  'q',  . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre><br>  Um diesen Code auszuf√ºhren, m√ºssen Sie zuerst Python 3.6+, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Matterport Mask R-CNN</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV</a> installieren. <br><br>  Ich habe den Code speziell so einfach wie m√∂glich geschrieben.  Wenn er zum Beispiel im ersten Frame ein Auto sieht, kommt er zu dem Schluss, dass alle geparkt sind.  Versuchen Sie, damit zu experimentieren, und pr√ºfen Sie, ob Sie die Zuverl√§ssigkeit verbessern k√∂nnen. <br><br>  Durch einfaches √Ñndern der Bezeichner der Objekte, nach denen das Modell sucht, k√∂nnen Sie den Code in etwas v√∂llig anderes verwandeln.  Stellen Sie sich zum Beispiel vor, Sie arbeiten in einem Skigebiet.  Nach einigen √Ñnderungen k√∂nnen Sie dieses Skript in ein System verwandeln, das Snowboarder, die von einer Rampe springen, automatisch erkennt und Videos mit coolen Spr√ºngen aufzeichnet.  Wenn Sie in einem Naturschutzgebiet arbeiten, k√∂nnen Sie auch ein System erstellen, das Zebras z√§hlt.  Sie sind nur durch Ihre Vorstellungskraft begrenzt. <br><br>  Weitere solche Artikel finden Sie im Telegrammkanal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neuron</a> (@neurondata) <br><br>  Link zur alternativen √úbersetzung: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tproger.ru/translations/parking-searching/</a> <br><br>  Alles Wissen.  Experimentieren Sie! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451164/">https://habr.com/ru/post/de451164/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451152/index.html">Der Widerstand in der Gate-Schaltung oder wie man es richtig macht</a></li>
<li><a href="../de451154/index.html">Lokales autonomes Datenerfassungssystem (Fortsetzung)</a></li>
<li><a href="../de451158/index.html">Stromkreise. Schaltungstypen</a></li>
<li><a href="../de451160/index.html">Apache Kafka und Streaming mit Spark Streaming</a></li>
<li><a href="../de451162/index.html">Fehlerkorrektur - Physikalische Konstanten in der gegenw√§rtigen und neuen Version des Internationalen Einheitensystems (SI)</a></li>
<li><a href="../de451166/index.html">Was bieten die neuen Repositories f√ºr AI- und MO-Systeme?</a></li>
<li><a href="../de451170/index.html">Jeff Bezos k√ºndigte Pl√§ne an, den Mond zu erobern</a></li>
<li><a href="../de451172/index.html">Julia: Funktionen und Strukturen als Funktionen</a></li>
<li><a href="../de451174/index.html">Anpassung von Programmen f√ºr ZX Spectrum an TR-DOS mit modernen Mitteln. Teil 1</a></li>
<li><a href="../de451176/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 458 (23.04.2019 - 09.04.2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
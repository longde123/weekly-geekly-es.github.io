<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💂🏼 👈🏾 👻 Bagaimana cara berteman PyTorch dan C ++. Menggunakan TorchScript 🍮 👎 🕵🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sekitar setahun yang lalu, pengembang PyTorch memperkenalkan komunitas TorchScript , sebuah alat yang memungkinkan Anda untuk membuat solusi yang dapa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana cara berteman PyTorch dan C ++. Menggunakan TorchScript</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/480328/"><p> Sekitar setahun yang lalu, pengembang PyTorch memperkenalkan komunitas <strong>TorchScript</strong> , sebuah alat yang memungkinkan Anda untuk membuat solusi yang dapat diasingkan dari pipa dengan python dengan beberapa klik mouse yang dapat disematkan dalam sistem C ++.  Di bawah ini saya membagikan pengalaman penggunaannya dan mencoba menggambarkan perangkap yang ditemui di sepanjang jalan ini.  Saya akan memberikan perhatian khusus pada implementasi proyek di Windows, karena meskipun penelitian dalam ML biasanya dilakukan di Ubuntu, solusi terakhirnya sering (tiba-tiba!) Diperlukan di bawah "windows". </p><br><p>  Kode contoh untuk mengekspor model dan proyek C ++ menggunakan model dapat ditemukan di <a href="https://github.com/IlyaOvodov/TorchScriptTutorial">repositori di GitHub</a> . </p><br><p> <a href="https://habr.com/ru/company/ods/blog/480328/"><img src="https://habrastorage.org/webt/3k/u1/ub/3ku1ubmzigl3j016ezncczdonqm.jpeg"></a> </p><a name="habracut"></a><br><a name="continue"></a><br><p>  Pengembang PyTorch tidak tertipu.  Alat baru ini benar-benar memungkinkan Anda untuk mengubah proyek penelitian di PyTorch menjadi kode yang tertanam dalam sistem C ++ dalam beberapa hari kerja, dan dengan beberapa keterampilan lebih cepat. </p><br><p>  TorchScript muncul di PyTorch versi 1.0 dan terus berkembang dan berubah.  Jika versi pertama setahun yang lalu penuh dengan bug dan lebih bersifat eksperimental, maka versi saat ini setidaknya pada poin kedua sangat berbeda: Anda tidak dapat menyebutnya eksperimental lagi, ini cukup cocok untuk penggunaan praktis.  Saya akan fokus padanya. </p><br><p>  Inti dari TorchScript adalah kompiler mandiri (bebas-Python) sendiri dari bahasa mirip-python, serta alat untuk mengonversi program yang ditulis dengan Python dan PyTorch ke dalamnya, metode untuk menyimpan dan memuat modul yang dihasilkan, dan perpustakaan untuk menggunakannya dalam C ++.  Agar berhasil, Anda harus menambahkan beberapa DLL ke proyek dengan berat total sekitar 70MB (untuk Windows) untuk bekerja pada CPU dan 300MB untuk versi GPU.  TorchScript mendukung sebagian besar fitur PyTorch dan fitur utama bahasa python.  Tetapi perpustakaan pihak ketiga, seperti OpenCV atau NumPy, harus dilupakan.  Untungnya, banyak fungsi dari NumPy memiliki analog di PyTorch. </p><br><h2 id="konvertiruem-payplayn-na-pytorch-model-na-torchscript">  Ubah pipeline menjadi model PyTorch di TorchScript </h2><br><p>  TorchScript menawarkan dua cara untuk mengonversi kode Python ke format internalnya: tracing dan scripting (tracing dan scripting).  Mengapa dua?  Tidak, jelas, tentu saja, bahwa dua lebih baik dari satu ... </p><br><p><img src="https://habrastorage.org/webt/lh/xp/ww/lhxpwwynynljq2_sxj35jhpp9yc.jpeg"></p><br><p>  Tetapi dalam kasus metode-metode ini, ternyata, seperti dalam aforisme terkenal, tentang penyimpangan kiri dan kanan: keduanya lebih buruk.  Yah, dunia ini tidak sempurna.  Hanya dalam situasi tertentu, Anda harus memilih yang lebih cocok. </p><br><p>  Metode penelusuran sangat sederhana.  Sampel data diambil (biasanya diinisialisasi dengan angka acak), dikirim ke fungsi atau metode kelas yang menarik minat kami, dan PyTorch membuat dan menyimpan grafik perhitungan dengan cara yang sama seperti yang biasanya dilakukan saat melatih jaringan saraf.  Voila - skrip siap: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision model = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.eval() sample = torch.rand(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>) scripted_model = torch.jit.trace(model, sample)</code> </pre> <br><p>  Contoh di atas menghasilkan objek dari kelas ScriptModule.  Itu bisa diselamatkan </p><br><pre> <code class="python hljs">scripted_model.save(<span class="hljs-string"><span class="hljs-string">'my_script.pth'</span></span>)</code> </pre> <br><p>  dan kemudian memuatnya <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">ke dalam program C ++</a> (lebih lanjut tentang itu di <a href="https://habr.com/ru/company/ods/blog/480328/">bawah</a> ) atau ke dalam kode Python alih-alih objek asli: </p><br><div class="spoiler">  <b class="spoiler_title">Contoh kode Python menggunakan model yang disimpan</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, ToTensor, Normalize transforms = Compose([ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.485</span></span>, <span class="hljs-number"><span class="hljs-number">0.456</span></span>, <span class="hljs-number"><span class="hljs-number">0.406</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.229</span></span>, <span class="hljs-number"><span class="hljs-number">0.224</span></span>, <span class="hljs-number"><span class="hljs-number">0.225</span></span>])]) img = cv2.resize(cv2.imread(<span class="hljs-string"><span class="hljs-string">'pics/cat.jpg'</span></span>), (<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) x = transforms(img).unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># add batch dimension scripted_model = torch.jit.load('my_script.pth') y = scripted_model(x) print(y[0].argmax(), y[0][y[0].argmax()])</span></span></code> </pre> <br><pre> <code class="plaintext hljs">tensor(282) tensor(12.8130, grad_fn=&lt;SelectBackward&gt;)</code> </pre> </div></div><br><p>  <code>ScriptModule</code> dihasilkan dapat muncul di mana saja <code>nn.Module</code> umumnya digunakan. </p><br><p>  Dengan cara yang dijelaskan, Anda dapat melacak instance dari kelas dan fungsi <code>nn.Module</code> (dalam kasus terakhir, turunan dari <code>torch._C.Function</code> Kelas <code>torch._C.Function</code> ). </p><br><p>  Metode ini (pelacakan) memiliki keuntungan penting: cara ini Anda dapat mengkonversi hampir semua kode Python yang tidak menggunakan pustaka eksternal.  Tetapi ada kelemahan yang sama pentingnya: untuk cabang mana pun, hanya cabang yang dieksekusi pada data uji yang akan diingat: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_abs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> -x my_abs_traced = torch.jit.trace(my_abs, torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>)) print(my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">c:\miniconda3\lib\site-packages\ipykernel_launcher.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! tensor(1) tensor(-1)</code> </pre> <br><p>  Ups!  Ini sepertinya bukan yang kita inginkan, bukan?  Sangat bagus bahwa setidaknya pesan peringatan (TracerWarning) dikeluarkan.  Perlu memperhatikan pesan-pesan seperti itu. </p><br><p>  Di sini metode kedua datang ke bantuan kami - scripting: </p><br><pre> <code class="python hljs">my_abs_script = torch.jit.script(my_abs) print(my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">tensor(1) tensor(1)</code> </pre> <br><p>  Hore, hasil yang diharapkan diterima!  Scripting secara rekursif menganalisis kode Python dan mengubahnya menjadi kode dalam bahasanya sendiri.  Pada output, kita juga mendapatkan kelas <code>ScriptModule</code> (untuk modul) atau <code>torch._C.Function</code> (untuk fungsi).  Tampaknya, ini dia, kebahagiaan!  Tetapi masalah lain muncul: bahasa internal TorchScript sangat diketik, tidak seperti Python.  Jenis setiap variabel ditentukan oleh penugasan pertama, jenis argumen fungsi secara default adalah <code>Tensor</code> .  Karena itu, misalnya, pola yang sudah dikenal </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> y = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = x <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><p>  Pelacakan akan gagal. </p><br><div class="spoiler">  <b class="spoiler_title">Kesalahan penelusuran terlihat seperti ini</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-9-25414183a687&gt; in &lt;module&gt;() ----&gt; 1 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ RuntimeError: Variable 'y' previously has type None but is now being assigned to a value of type Tensor : at &lt;ipython-input-8-75677614fca6&gt;:4:8 def my_func(x): y = None if x.max() &gt; 0: y = x ~ &lt;--- HERE return y</code> </pre> </div></div><br><p>  Perlu dicatat bahwa, meskipun kesalahan terjadi ketika <code>torch.jit.script</code> dipanggil, tempat yang menyebabkannya dalam kode skrip juga ditunjukkan. </p><br><p>  Bahkan poin setelah konstanta mulai berperan: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = <span class="hljs-number"><span class="hljs-number">1.25</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: y = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">akan memberikan kesalahan</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-10-0a5f18586763&gt; in &lt;module&gt;() 5 y = 0 6 return y ----&gt; 7 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in _rcb(name) 1240 # closure rcb fails 1241 result = closure_rcb(name) -&gt; 1242 if result: 1243 return result 1244 return stack_rcb(name) RuntimeError: bool value of Tensor with more than one value is ambiguous</code> </pre> </div></div><br><p>  Karena itu perlu untuk menulis bukan <code>0</code> , tetapi <code>0.</code> sehingga jenis di kedua cabang adalah sama!  Manja, Anda tahu, dengan python Anda! </p><br><p>  Ini hanyalah awal dari daftar perubahan yang perlu Anda buat untuk kode python sehingga dapat berhasil diubah menjadi modul TorchScript.  Saya akan membuat daftar kasus yang paling umum secara lebih rinci <a href="https://habr.com/ru/company/ods/blog/480328/">nanti</a> .  Pada prinsipnya, tidak ada ilmu roket di sini dan kode Anda dapat diperbaiki.  Tetapi paling sering saya tidak ingin memperbaiki modul pihak ketiga, termasuk yang standar dari <code>torchvision</code> , dan seperti biasa mereka biasanya tidak cocok untuk skrip. </p><br><p>  Untungnya, kedua teknologi dapat dikombinasikan: apa yang sedang ditulis sedang ditulis dan apa yang tidak sedang dituliskan sedang melacak: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(MyModule, self).__init__() self.resnet = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       torch.jit.script(my_module) #    -   resnet34. #     self.resnet  ScriptModule. self.resnet.eval() # NB:     !  -  ! self.resnet = torch.jit.trace(self.resnet, torch.rand((1,3,224,224), dtype=torch.float)) def forward(self, x): if x.shape[2] &lt; 224 or x.shape[3] &lt; 224: return torch.tensor(0) else: return self.resnet(x) my_module = MyModule() my_module = torch.jit.script(my_module)</span></span></code> </pre> <br><p>  Pada contoh di atas, penelusuran digunakan untuk menyertakan modul yang tidak dapat skrip dalam modul di mana tidak ada cukup jejak dan skrip diperlukan.  Ada situasi sebaliknya.  Misalnya, jika kita perlu mengunggah model ke ONNX, tracing digunakan.  Tetapi model yang dilacak mungkin menyertakan fungsi TorchScript, sehingga logika yang membutuhkan cabang dan loop dapat diimplementasikan di sana!  Contoh diberikan dalam <a href="https://pytorch.org/docs/stable/onnx.html">dokumentasi resmi untuk torch.onnx</a> . </p><br><p>  Fitur-fitur yang disediakan oleh PyTorch untuk membuat modul-modul TorchScript dijelaskan secara lebih terperinci dalam <a href="https://pytorch.org/docs/stable/jit.html">dokumentasi resmi</a> dan <code>torch.jit</code> .  Secara khusus, saya tidak menyebutkan cara mudah untuk menggunakan <code>torch.jit.trace</code> dan <code>torch.jit.script</code> dalam bentuk dekorator, tentang kekhasan debugging kode skrip.  Ini dan banyak lagi ada di dokumentasi. </p><br><h2 id="anchorcppanchorvklyuchaem-model-v-proekt-na-c"><a name="cpp"></a>  Kami menyertakan model dalam proyek C ++ </h2><br><p>  Sayangnya, <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">dokumentasi resmi</a> terbatas pada contoh bentuk "tambahkan 2 tensor yang dihasilkan menggunakan <code>torch.ones</code> ".  Saya menyiapkan contoh <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">proyek yang lebih dekat dengan kenyataan</a> yang mengirimkan gambar dari OpenCV ke jaringan saraf dan menerima hasilnya dalam bentuk tensor respons, tupel variabel, gambar dengan hasil segmentasi. </p><br><p>  Agar contoh berfungsi, Anda memerlukan skrip klasifikasi yang disimpan menggunakan ResNet34 dan segmentasi menggunakan DeepLabV3.  Untuk menyiapkan skrip ini, Anda perlu menjalankan <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/prepare_scripts.ipynb">notepad jupyter ini</a> . </p><br><p>  Kami membutuhkan perpustakaan <code>torchlib</code> .  Anda bisa mendapatkannya dengan beberapa cara: </p><br><ol><li>  Jika Anda sudah menginstal PyTorch menggunakan <code>pip install</code> , Anda dapat menemukannya di direktori Python: <code>&lt;Miniconda3&gt;\Lib\site-packages\torch</code> ; </li><li>  Jika Anda memiliki PyTorch yang dikompilasi dari sumber, maka ada di sana: <code>&lt;My Pytorch repo&gt;\build\lib.win-amd64-3.6\torch</code> ; </li><li>  Terakhir, Anda dapat mengunduh <a href="https://pytorch.org/">perpustakaan</a> secara terpisah dari <a href="https://pytorch.org/">pytorch.org</a> dengan memilih Language = C ++, dan unzip arsip. </li></ol><br><p>  Kode C ++ cukup sederhana.  Itu perlu: </p><br><ol><li>  Sertakan file header <br><pre> <code class="plaintext hljs">#include &lt;torch/script.h&gt;</code> </pre> </li><li>  Unduh Model <br><pre> <code class="plaintext hljs">torch::jit::script::Module module = torch::jit::load("../resnet34_infer.pth");</code> </pre> </li><li>  Siapkan data <br><pre> <code class="plaintext hljs">torch::Tensor tensor = torch::from_blob(img.data, { img.rows, img.cols, 3 }, torch::kByte);</code> </pre> </li><li>  Call <code>forward</code> berfungsi dan dapatkan hasilnya <br><pre> <code class="plaintext hljs">auto output = module.forward( { tensor } )</code> </pre> </li><li>  Dapatkan data dari hasilnya.  Cara melakukan ini tergantung pada apa yang dikembalikan jaringan saraf.  Ngomong-ngomong, dalam kasus umum, ia juga dapat menerima tidak hanya satu gambar, oleh karena itu lebih baik untuk melihat <a href="">kode sumber dari</a> seluruh <a href="">contoh</a> , ada beberapa opsi.  Misalnya, untuk mendapatkan data dari tensor satu dimensi dari tipe float: <br><pre> <code class="plaintext hljs">float* data = static_cast&lt;float*&gt;(output.toTensor().data_ptr());</code> </pre> </li><li>  Ada satu lagi kehalusan.  Jangan lupa untuk memasukkan analog <code>with torch.no_grad()</code> dalam kode agar tidak membuang sumber daya untuk menghitung dan menyimpan gradien yang tidak kita butuhkan.  Sayangnya, perintah ini tidak dapat dimasukkan dalam skrip, jadi Anda harus menambahkannya ke kode C ++: <br><pre> <code class="plaintext hljs">torch::NoGradGuard no_grad;</code> </pre> </li></ol><br><p>  Cara membangun proyek menggunakan CMake dijelaskan dalam <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">panduan resmi</a> .  Tetapi topik proyek di Visual Studio tidak diungkapkan di sana, jadi saya akan menjelaskannya secara lebih rinci.  Anda harus mengubah pengaturan proyek secara manual: </p><br><ol><li>  Saya menguji pada Visual Studio 2017. Saya tidak bisa mengatakan tentang versi lain. </li><li>  Toolset v14.11 v141 harus diinstal (tanda centang <code>"VC++ 2017 version 15.4 v14.11 toolset"</code> di penginstal VS). </li><li>  Platform harus <code>x64</code> . </li><li>  Secara <code>General → Platform Toolset</code> pilih <code>v141(Visual Studio 2017)</code> </li><li>  Dalam <code>C/C++ → General → Additional Include Directories</code> tambahkan <code>&lt;libtorch dir&gt;\include</code> </li><li>  Di <code>Linker → General → Additional Library Directories</code> tambahkan <code>&lt;libtorch dir&gt;\lib</code> </li><li>  Di <code>Linker → Input → Additional Dependencies</code> tambahkan <code>torch.lib; c10.lib</code>  <code>torch.lib; c10.lib</code> .  Di Internet, mereka menulis bahwa <code>caffe2.lib</code> mungkin masih diperlukan, dan untuk GPU dan yang lainnya dari <code>&lt;libtorch dir&gt;\lib</code> , tetapi dalam versi saat ini, menambahkan dua perpustakaan ini sudah cukup bagi saya.  Mungkin ini informasi yang sudah ketinggalan zaman. </li><li>  Mereka juga menulis bahwa Anda perlu mengatur <code>C/C++ → Language → Conformance Mode</code> = <code>No</code> , tapi saya tidak melihat perbedaannya. </li></ol><br><p>  Juga, variabel <code>__cplusplus</code> TIDAK boleh dinyatakan dalam proyek.  Mencoba menambahkan opsi <a href="https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus%3Fview%3Dvs-2017"><code>  /Zc:__cplusplus</code></a> akan menghasilkan kesalahan kompilasi dalam file <code>ivalue.h</code> . </p><br><p>  Dalam <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">proyek terlampir,</a> pengaturan jalur (tidak hanya ke TorchLib, tetapi juga ke OpenCV dan CUDA) dikeluarkan dalam <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props">file props</a> , sebelum perakitan, Anda harus mendaftarkannya di sana sesuai dengan konfigurasi lokal Anda.  Faktanya, itu saja. </p><br><h2 id="anchortipsanchorchto-eschyo-sleduet-imet-v-vidu"><a name="tips"></a>  Apa lagi yang perlu diingat </h2><br><p>  Jika proses yang dijelaskan itu tampak terlalu sederhana bagi Anda, intuisi Anda tidak menipu Anda.  Ada sejumlah nuansa yang perlu dipertimbangkan untuk mengkonversi model PyTorch yang ditulis dengan Python ke TorchScript.  Saya akan daftar di bawah ini yang harus saya hadapi.  Saya sudah menyebutkan beberapa, tapi saya ulangi untuk mengumpulkan semuanya di satu tempat. </p><br><p><img src="https://habrastorage.org/webt/iv/xy/q-/ivxyq-lqqw8s1aqd_cy4t4uwj5i.jpeg"></p><br><ul><li>  Jenis variabel yang diteruskan ke fungsi adalah Tensor secara default.  Jika dalam beberapa kasus (sangat sering) hal ini tidak dapat diterima, Anda harus mendeklarasikan tipe secara manual menggunakan anotasi tipe MyPy-style, seperti ini: </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds: List[Tensor], cls_thresh: float)</span></span></span><span class="hljs-function">-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><p>  atau lebih: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds, cls_thresh)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># type: (List[Tensor], float)-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><ul><li>  Variabel diketik dengan kuat dan jenisnya, jika tidak ditentukan secara eksplisit, ditentukan oleh penugasan pertama.  Konstruksi yang dikenali dari form <code>x=[]; for ...: x.append(y)</code>  <code>x=[]; for ...: x.append(y)</code> harus diedit, karena  pada saat menugaskan <code>[]</code> kompiler tidak dapat mengetahui tipe apa yang akan ada dalam daftar.  Oleh karena itu, Anda harus menentukan jenis secara eksplisit, misalnya: </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> List x: List[float] = []</code> </pre> <br><p>  atau ("misalnya") lainnya </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dict, Tuple, List x: Dict[int: Tuple[float, List[Tensor], List[List[int]]]] = {}</code> </pre> <br><ul><li>  Dalam contoh di atas, itu adalah nama-nama yang perlu diimpor, karena nama-nama ini dijahit ke dalam kode TorchScript.  Alternatif, pendekatan yang tampaknya legal </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> typing x: typing.List[torch.Tensor] = []</code> </pre> <br><p>  akan menghasilkan kesalahan <em>ketik typing.List konstruktor tipe tidak dikenal</em> saat scripting </p><br><ul><li>  Desain akrab lainnya yang harus Anda pisahkan: </li></ul><br><pre> <code class="python hljs">x = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  Ada dua opsi.  Atau tetapkan Tensor dua kali (fakta bahwa dimensi berbeda tidak menakutkan): </p><br><pre> <code class="python hljs">x = torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  dan jangan lupa mencari apa yang akan rusak setelah penggantian seperti itu.  Atau cobalah untuk menulis dengan jujur: </p><br><pre> <code class="python hljs">x: Optional[Tensor] = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  tetapi kemudian dengan penggunaan lebih lanjut dari <code>x</code> mana tensor diharapkan, kita kemungkinan besar akan mendapatkan kesalahan: <em>Diharapkan nilai tipe 'Tensor' untuk argumen 'x' tetapi sebaliknya ditemukan tipe 'Opsional [Tensor]'.</em> </p><br><ul><li><p>  Jangan lupa untuk menulis, misalnya, <code>x=0.</code> selama tugas pertama <code>x=0.</code>  bukannya <code>x=0</code> , dll, jika variabel <code>x</code> harus bertipe <code>float</code> . </p><br></li><li><p>  Jika di suatu tempat kami menggunakan inisialisasi gaya lama dari tensor melalui <code>x = torch.Tensor(...)</code> , Anda harus berpisah dengannya dan menggantinya dengan versi yang lebih muda dengan huruf kecil <code>x = torch.tensor(...)</code> .  Kalau tidak, selama scripting itu akan terbang: <em>Unin builtin op: aten :: Tensor.</em>  <em>Berikut adalah beberapa saran: aten :: tensor</em> .  Tampaknya mereka bahkan menjelaskan apa masalahnya, dan jelas apa yang perlu dilakukan.  Namun, jelas jika Anda sudah tahu jawaban yang benar. </p><br></li><li><p>  Kode ditulis dalam konteks modul di mana <code>torch.jit.script</code> dipanggil.  Oleh karena itu, jika di suatu tempat, di dalam usus dari kelas atau fungsi yang <code>math.pow</code> , misalnya, <code>math.pow</code> , Anda harus menambahkan <code>import math</code> ke modul kompilasi.  Dan lebih baik untuk skrip kelas di mana ia dideklarasikan: baik menggunakan dekorator <code>@torch.jit.script</code> , atau dengan mendeklarasikan fungsi tambahan di sebelahnya yang membuat ScriptModule keluar dari itu.  Jika tidak, kami mendapatkan pesan kesalahan <em>matematika nilai yang tidak ditentukan</em> ketika kami mencoba untuk mengkompilasi kelas dari modul di mana, tampaknya, impor <code>math</code> dibuat. </p><br></li><li><p>  Jika di suatu tempat Anda memiliki konstruksi formulir <code>my_tensor[my_tensor &lt; 10] = 0</code> atau serupa, maka Anda akan mendapatkan kesalahan samar ketika membuat skrip: </p><br><pre> <code class="plaintext hljs">*aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'Tensor' for argument 'values' but instead found type 'int'.* *aten::index_put_(Tensor(a!) self, Tensor[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'List[Tensor]' for argument 'indices' but instead found type 'List[Optional[Tensor]]'.*</code> </pre> <br><p>  Yang Anda butuhkan adalah mengganti nomor dengan tensor: <code>my_tensor[my_tensor &lt; 10] = torch.tensor(0.).to(my_tensor.device)</code> .  Dan jangan lupa a) tentang korespondensi jenis <code>my_tensor</code> dan tensor yang dibuat (dalam hal ini, float) dan b) tentang <code>.to(my_tensor.device)</code> .  Jika Anda lupa yang kedua, semuanya akan dituliskan, tetapi sudah dalam proses bekerja dengan GPU, Anda akan kesal, yang akan terlihat seperti kata-kata <em>error CUDA</em> samar <em>: akses memori ilegal ditemukan</em> , tanpa menunjukkan di mana kesalahan terjadi! </p><br></li><li><p>  Jangan lupa bahwa secara default <code>nn.Module</code> dan, karenanya, model dari torchvision dibuat dalam "mode kereta" (Anda tidak akan mempercayainya, tetapi ternyata <a href="https://fooobar.com/questions/16769103/error-when-converting-pytorch-model-to-torchscript/25666033">ada mode seperti itu</a> ).  Dalam hal ini, Dropout dan trik lain dari mode kereta api digunakan, yang memecah jejak atau menyebabkan hasil yang tidak memadai ketika dieksekusi.  Ingat untuk memanggil <code>model.eval()</code> sebelum membuat skrip atau melacak. </p><br></li><li><p>  Untuk fungsi dan kelas biasa, Anda perlu mengetikkan skripnya, untuk nn.Module - sebuah instance </p><br></li><li><p>  Mencoba dalam metode skrip untuk mengakses variabel global </p><br></li></ul><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> ... x = r &lt; cls_thresh ...</code> </pre> <br><p>  akan menghasilkan kesalahan <em>penulisan nilai</em> bentuk <em>python tipe 'float' tidak dapat digunakan sebagai nilai</em> .  Kita perlu membuat variabel sebagai atribut dalam konstruktor: </p><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> ... self.cls_thresh = cls_thresh ... x = r &lt; self.cls_thresh ...</code> </pre> <br><ul><li>  Kehalusan lain muncul jika atribut class digunakan sebagai parameter slice: </li></ul><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ... self.num_layers = num_layers <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (p3, p4, p5, p6, p7)[:self.num_layers]</code> </pre> <br><p>  menyebabkan scripting error <em>tuple slice index harus konstanta integer</em> .  Penting untuk menunjukkan bahwa atribut num_layers adalah konstan dan tidak akan berubah: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> num_layers: torch.jit.Final[int] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><ul><li>  Dalam beberapa kasus, di mana tensor yang digunakan sesuai dengan normal, Anda perlu memberikan nomor secara eksplisit: </li></ul><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i])</code> </pre> <br><p>  melempar kesalahan saat membuat skrip <em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em>  .  Nah, di sini dari pesan kesalahan jelas apa yang harus dilakukan: </p><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i].item())</code> </pre> <br><p>  Masalah di atas terjadi saat melacak.  Itu karena mereka bahwa biasanya tidak mungkin untuk hanya mengkompilasi solusi yang sudah jadi di TorchScript, dan Anda harus memijat kode sumber untuk waktu yang lama (jika kode sumber sesuai untuk diedit), atau gunakan penelusuran.  Namun jejaknya memiliki nuansa tersendiri: </p><br><ul><li>  Konstruksi bentuk tidak berfungsi dalam penelusuran </li></ul><br><pre> <code class="plaintext hljs">tensor_a.to(tensor_b.device)</code> </pre> <br><p>  Perangkat tempat tensor dimuat diperbaiki pada saat penelusuran dan tidak berubah selama eksekusi.  Masalah ini dapat diatasi sebagian dengan mendeklarasikan tensor sebagai anggota <code>nn.Module</code> type <code>Parameter</code> .  Kemudian, ketika memuat model, itu akan boot ke perangkat yang ditentukan dalam fungsi <code>torch.jit.load</code> . </p><br><h2 id="epilog">  Epilog </h2><br><p>  Semua hal di atas tentu saja menciptakan masalah.  Tetapi TorchScript memungkinkan Anda untuk menggabungkan dan mengirim ke solusi sebagai satu keseluruhan model itu sendiri dan kode Python yang menyediakan pra dan pasca pemrosesan.  Ya, dan waktu untuk menyiapkan solusi untuk kompilasi, meskipun menghadapi kesulitan di atas, jauh lebih murah daripada biaya untuk membuat solusi, tetapi di sini PyTorch menawarkan keuntungan besar, sehingga permainan ini layak untuk dijadikan lilin. </p><br><p><img src="https://habrastorage.org/webt/v0/3m/qt/v03mqtayxdfh5be4ut3nrr0c86q.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id480328/">https://habr.com/ru/post/id480328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id480316/index.html">Cara mengurangi konsumsi modul wifi hingga sepuluh kali atau lebih</a></li>
<li><a href="../id480318/index.html">Pilihan acara gratis mendatang untuk pengembang di Moskow # 3 (16-24 Desember)</a></li>
<li><a href="../id480320/index.html">Sepuluh tahun ONYX di Rusia - bagaimana teknologi, pembaca, dan pasar telah berubah selama ini</a></li>
<li><a href="../id480324/index.html">Implementasi Tipe String di CPython</a></li>
<li><a href="../id480326/index.html">F5 Networks Corporation mengirimkan surat kepada pelanggannya untuk memberi tahu mereka tentang situasi saat ini dengan NGINX</a></li>
<li><a href="../id480330/index.html">Alat penilaian karyawan yang ideal</a></li>
<li><a href="../id480332/index.html">Analisis data pemungutan suara blockchain 2019 di Duma Kota Moskow</a></li>
<li><a href="../id480334/index.html">QtQML / panel korelasi cepat</a></li>
<li><a href="../id480338/index.html">Cara kerja rendering game 3D: rasterization dan ray tracing</a></li>
<li><a href="../id480340/index.html">Saya menentang manajer yang tidak kompeten, dan kemudian dia dipromosikan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
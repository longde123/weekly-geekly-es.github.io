<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§™ üëù ‚õàÔ∏è Kapselneurale Netze ü§© ü§≤üèø ü§º</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im Jahr 2017 ver√∂ffentlichte Jeffrey Hinton (einer der Begr√ºnder des Ansatzes der Fehlerr√ºck√ºbertragung) einen Artikel, in dem Kapsel-Neuronale Netze ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kapselneurale Netze</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417223/"> Im Jahr 2017 ver√∂ffentlichte Jeffrey Hinton (einer der Begr√ºnder des Ansatzes der Fehlerr√ºck√ºbertragung) einen Artikel, in dem Kapsel-Neuronale Netze beschrieben und ein Algorithmus f√ºr das dynamische Routing zwischen Kapseln vorgeschlagen wurden, um die vorgeschlagene Architektur zu vermitteln. <br><br>  Klassische Faltungs-Neuronale Netze haben Nachteile.  Die interne Darstellung von Faltungsdaten neuronaler Netze ber√ºcksichtigt keine r√§umlichen Hierarchien zwischen einfachen und komplexen Objekten.  Wenn also die Augen, die Nase und die Lippen eines Faltungsnetzwerks zuf√§llig im Bild angezeigt werden, ist dies ein deutliches Zeichen f√ºr das Vorhandensein eines Gesichts.  Und die Rotation des Objekts beeinflusst die Erkennungsqualit√§t, w√§hrend das menschliche Gehirn dieses Problem leicht l√∂st. <br><br><img src="https://habrastorage.org/webt/6y/cp/9f/6ycp9faaapjxfuhwflzs76i1-_e.png"><br>  F√ºr ein neuronales Faltungsnetzwerk sind 2 Bilder √§hnlich [2] <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/pm/pc/zt/pmpcztp7wilcwljmiveqo37evcg.jpeg"><br>  Tausende von Beispielen werden ben√∂tigt, um die Objekterkennung aus verschiedenen CNN-Winkeln zu trainieren. <br><br><img src="https://habrastorage.org/webt/-m/ek/sz/-mekszzwa4bdl7z6eszrfno7kjw.png"><br>  Kapselnetzwerke reduzieren den Erkennungsfehler eines Objekts aus einem anderen Winkel um 45%. <br><br><h3>  Verschreibungspflichtige Kapseln </h3><br>  Kapseln kapseln Informationen √ºber den Zustand der Funktion, die in Vektorform vorliegen.  Kapseln codieren die Wahrscheinlichkeit, ein Objekt zu erkennen, als die L√§nge des Ausgabevektors.  Der Status der erkannten Funktion wird als die Richtung codiert, in die der Vektor zeigt (‚ÄûInstanzerstellungsparameter‚Äú).  Wenn sich die erkannte Funktion durch das Bild bewegt oder sich der Zustand des Bildes √§ndert, bleibt die Wahrscheinlichkeit unver√§ndert (die L√§nge des Vektors √§ndert sich nicht), aber die Ausrichtung √§ndert sich. <br><br>  Stellen Sie sich vor, eine Kapsel erkennt ein Gesicht in einem Bild und gibt einen 3D-Vektor mit einer L√§nge von 0,99 aus.  Bewegen Sie dann das Gesicht im Bild.  Der Vektor dreht sich in seinem Raum und stellt einen sich √§ndernden Zustand dar. Seine L√§nge bleibt jedoch fest, da die Kapsel sicher ist, dass sie ein Gesicht erkannt hat. <br><br><img src="https://habrastorage.org/webt/nw/ky/qt/nwkyqtzc1l2dpyfpqzdakpfdfy8.png"><br><br>  Unterschiede zwischen Kapseln und Neuronen. [2] <br><br>  Ein k√ºnstliches Neuron kann in drei Schritten beschrieben werden: <br><br>  1. Skalargewichtung von Eingabeskalaren <br>  2. Summe der gewichteten Eingabeskalare <br>  3. nichtlineare Skalartransformation. <br><br>  Die Kapsel hat zus√§tzlich zur neuen Phase der affinen Transformation der Eingabe die Vektorformen der obigen 3 Schritte: <br><br>  1. Matrixmultiplikation von Eingangsvektoren <br>  2. Skalargewichtung von Eingabevektoren <br>  3. Summe der gewichteten Eingabevektoren <br>  4. Vektor-Nichtlinearit√§t. <br><br>  Eine weitere in CapsNet eingef√ºhrte Innovation ist eine neue nichtlineare Aktivierungsfunktion, die einen Vektor nimmt und dann seine L√§nge nicht mehr als 1 "ausgibt", aber die Richtung nicht √§ndert. <br><br><img src="https://habrastorage.org/webt/c8/p5/zz/c8p5zzuf4qe1f8cdvywiub1o2jk.png"><br><br>  Die rechte Seite der Gleichung (blaues Rechteck) skaliert den Eingabevektor so, dass der Vektor eine Blockl√§nge hat, und die linke Seite (rotes Rechteck) f√ºhrt eine zus√§tzliche Skalierung durch. <br><br>  Das Kapsel-Design basiert auf der Konstruktion eines k√ºnstlichen Neurons, erweitert es jedoch auf eine Vektorform, um leistungsf√§higere repr√§sentative F√§higkeiten bereitzustellen.  Matrixgewichte werden auch eingef√ºhrt, um hierarchische Beziehungen zwischen Merkmalen verschiedener Schichten zu codieren.  Die √Ñquivarianz der neuronalen Aktivit√§t wird in Bezug auf √Ñnderungen der Eingabedaten und die Invarianz der Wahrscheinlichkeiten der Erkennung von Zeichen erreicht. <br><br><h3>  Dynamisches Routing zwischen Kapseln </h3><br><br><img src="https://habrastorage.org/webt/14/dr/9q/14dr9qzg_8mvvntwgiq5l8r23u0.png"><br><br>  Der dynamische Routing-Algorithmus [1]. <br><br>  Die erste Zeile besagt, dass diese Prozedur Kapseln auf der unteren Ebene l und ihre Ausgaben u_hat sowie die Anzahl der Routing-Iterationen r nimmt.  Die letzte Zeile besagt, dass der Algorithmus die Ausgabe einer √ºbergeordneten Kapsel v_j erzeugt. <br><br>  Die zweite Zeile enth√§lt einen neuen Koeffizienten b_ij, den wir bisher noch nicht gesehen haben.  Dieser Koeffizient ist ein tempor√§rer Wert, der iterativ aktualisiert wird. Nach Abschluss der Prozedur wird sein Wert in c_ij gespeichert.  Zu Beginn des Trainings wird der Wert von b_ij auf Null initialisiert. <br><br>  Zeile 3 besagt, dass die Schritte 4 bis 7 r-mal wiederholt werden. <br>  Der Schritt in Zeile 4 berechnet den Wert des Vektors c_i, der alle Routinggewichte f√ºr die untere Kapsel i darstellt. <br><br>  Nachdem die Gewichte c_ij f√ºr die Kapseln der unteren Ebene berechnet wurden, gehen Sie zu Zeile 5, wo wir uns die Kapseln einer h√∂heren Ebene ansehen.  Dieser Schritt berechnet eine lineare Kombination von Eingabevektoren, die unter Verwendung der im vorherigen Schritt definierten Routing-Koeffizienten c_ij gewichtet wurden. <br><br>  Dann durchlaufen in Zeile 6 die Vektoren des letzten Schritts eine nichtlineare Transformation, die die Richtung des Vektors garantiert, aber seine L√§nge sollte 1 nicht √ºberschreiten. Dieser Schritt erzeugt den Ausgabevektor v_j f√ºr alle h√∂heren Ebenen der Kapsel. [2] <br>  Die Grundidee ist, dass die √Ñhnlichkeit zwischen Eingabe und Ausgabe als Skalarprodukt zwischen Eingabe und Ausgabe der Kapsel gemessen wird und sich dann der Routing-Koeffizient √§ndert.  Es wird empfohlen, drei Routing-Iterationen zu verwenden. <br><br><h3>  Fazit </h3><br>  Kapselneurale Netze sind eine vielversprechende Architektur neuronaler Netze, die die Bilderkennung bei sich √§ndernden Winkeln und hierarchischen Strukturen verbessert.  Kapselneurale Netze werden durch dynamisches Routing zwischen Kapseln trainiert.  Kapselnetzwerke reduzieren den Erkennungsfehler eines Objekts aus einem anderen Winkel um 45% im Vergleich zu CNN. <br><br><div class="spoiler">  <b class="spoiler_title">Links</b> <div class="spoiler_text">  [1] MATRIXKAPSELN MIT EM ROUTING.  Geoffrey Hinton, Sara Sabour und Nicholas Frosst.  2017. <br>  [2] Hintons Kapselnetzwerke verstehen.  Max Pechyonkin <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de417223/">https://habr.com/ru/post/de417223/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de417209/index.html">Neuronale Netze von Grund auf neu. √úbersicht der Kurse und Artikel in russischer Sprache, kostenlos und ohne Anmeldung</a></li>
<li><a href="../de417211/index.html">Tabelle zum Erlernen der Grundlagen elektrischer Schaltkreise. Warum nicht?</a></li>
<li><a href="../de417215/index.html">Alles, was Sie √ºber den Garbage Collector in Python wissen m√ºssen</a></li>
<li><a href="../de417219/index.html">Vergiss Burger King! Es gibt ein Leck von Dokumenten, das viel gef√§hrlicher ist</a></li>
<li><a href="../de417221/index.html">3DTouch - Skalen auf dem iPhone: Erste Schritte</a></li>
<li><a href="../de417225/index.html">Satz von Boshernitsan</a></li>
<li><a href="../de417227/index.html">Was ist mit dem Fermi-Paradoxon passiert?</a></li>
<li><a href="../de417229/index.html">Ein paar Gr√ºnde, PascalABC.Net zu vergessen</a></li>
<li><a href="../de417231/index.html">Corporate Merch mit menschlicher Benutzeroberfl√§che</a></li>
<li><a href="../de417233/index.html">Google Code-in 2017</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
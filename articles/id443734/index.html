<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😻 🛀🏻 🕣 Jaringan saraf memiliki strategi klasifikasi gambar yang luar biasa sederhana. 🌠 ⚛️ 🧜🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jaringan saraf convolutional melakukan pekerjaan yang sangat baik untuk mengklasifikasikan gambar yang terdistorsi, tidak seperti manusia. 


 Dalam a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jaringan saraf memiliki strategi klasifikasi gambar yang luar biasa sederhana.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/443734/"><h3>  Jaringan saraf convolutional melakukan pekerjaan yang sangat baik untuk mengklasifikasikan gambar yang terdistorsi, tidak seperti manusia. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/2e6/a7c/4c8/2e6a7c4c8f0ba811e57fa24193375289.jpg"><br><br>  Dalam artikel ini saya akan menunjukkan mengapa jaringan neural dalam yang canggih dapat dengan sempurna mengenali gambar yang terdistorsi dan bagaimana ini membantu mengungkapkan strategi yang sangat sederhana yang digunakan oleh jaringan saraf untuk mengklasifikasikan foto-foto alami.  Penemuan ini, yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diterbitkan</a> dalam ICLR 2019, memiliki banyak konsekuensi: pertama, mereka menunjukkan bahwa jauh lebih mudah untuk menemukan solusi " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ImageNet</a> " daripada yang diperkirakan.  Kedua, mereka membantu kami menciptakan sistem klasifikasi gambar yang lebih mudah dipahami dan dimengerti.  Ketiga, mereka menjelaskan beberapa fenomena yang diamati dalam jaringan saraf convolutional modern (SNA), misalnya, kecenderungan mereka untuk mencari tekstur (lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">karya</a> kami yang lain di ICLR 2019 dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">entri blog yang</a> sesuai), dan mengabaikan penataan ruang bagian-bagian dari objek. <br><a name="habracut"></a><br><h2>  Model lama yang bagus "kantong kata-kata" </h2><br>  Di masa lalu yang indah, sebelum munculnya pembelajaran yang mendalam, pengenalan gambar alami cukup sederhana: kami mendefinisikan serangkaian fitur visual utama ("kata-kata"), menentukan seberapa sering setiap fitur visual muncul dalam gambar ("tas"), dan mengklasifikasikan gambar berdasarkan ini angka.  Oleh karena itu, model seperti itu dalam visi komputer disebut "bag of words" (bag-of-words atau BoW).  Sebagai contoh, misalkan kita memiliki dua fitur visual, mata manusia dan pena, dan kami ingin mengklasifikasikan gambar menjadi dua kelas, "orang" dan "burung".  Model BoW yang paling sederhana adalah sebagai berikut: untuk setiap mata yang ditemukan dalam gambar, kami meningkatkan kesaksian yang mendukung "orang" dengan 1. Dan sebaliknya, untuk setiap pena kami menambah kesaksian yang mendukung "burung" dengan 1. Kelas mana yang mendapatkan lebih banyak bukti, ini dia. <br><br>  Sifat yang mudah digunakan dari model BoW yang sederhana adalah interpretabilitas dan kejelasan proses pengambilan keputusan: kita dapat dengan tepat memeriksa fitur tertentu dari gambar yang mendukung kelas tertentu, integrasi spasial fitur sangat sederhana (dibandingkan dengan integrasi fitur non-linear dalam jaringan saraf yang dalam), oleh karena itu cukup pahami bagaimana model membuat keputusannya. <br><br>  Model BoW tradisional sangat populer dan bekerja sangat baik sebelum invasi pembelajaran yang mendalam, tetapi dengan cepat keluar dari mode karena efisiensi yang relatif rendah.  Tetapi apakah kita yakin bahwa jaringan saraf menggunakan strategi keputusan yang berbeda secara fundamental dari BoW? <br><br><h2>  Kedalaman Menafsirkan Jaringan dengan Fitur-fitur Tas (BagNet) </h2><br>  Untuk menguji asumsi ini, kami menggabungkan interpretabilitas dan kejelasan model BoW dengan efisiensi jaringan saraf.  Strateginya terlihat seperti ini: <br><ul><li>  Bagilah gambar menjadi potongan-potongan kecil qx q. </li><li>  Kami melewati potongan melalui jaringan saraf untuk mendapatkan bukti keanggotaan kelas (log) untuk masing-masing bagian. </li><li>  Ringkaslah bukti di semua bagian untuk mendapatkan solusi di tingkat keseluruhan gambar. </li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/474/6f5/363/4746f53632bd9e3e7477de9ecb76d396.png"><br><br>  Untuk menerapkan strategi ini, dengan cara paling sederhana, kami menggunakan arsitektur standar ResNet-50 dan mengganti hampir semua konvolusi 3x3 dengan konvolusi 1x1.  Akibatnya, setiap elemen tersembunyi di lapisan convolutional terakhir "melihat" hanya sebagian kecil dari gambar (yaitu, bidang persepsi mereka jauh lebih kecil dari ukuran gambar).  Jadi kami menghindari markup yang dikenakan gambar dan sedekat mungkin dengan SNA standar, sambil menerapkan strategi yang telah direncanakan.  Kami menyebut arsitektur yang dihasilkan BagNet-q, di mana q menunjukkan ukuran bidang persepsi lapisan paling atas (kami menguji model dengan q = 9, 17, dan 33).  BagNet-q beroperasi sekitar 2,5 lebih lama dari ResNet-50. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b5e/4b6/1c4/b5e4b61c431e103ac9a6ec3fe4b02894.jpg"><br><br>  Kinerja BagNet pada data dari basis data ImageNet sangat mengesankan bahkan ketika menggunakan potongan-potongan kecil: fragmen 17x17 piksel sudah cukup untuk mencapai efisiensi tingkat AlexNet, dan fragmen 33x33 piksel cukup untuk mencapai akurasi 87%, memasuki posisi ke-5.  Anda dapat meningkatkan efisiensi dengan menempatkan paket 3x3 lebih hati-hati dan menyesuaikan hyperparameter. <br><br>  Ini adalah hasil utama pertama kami: ImageNet dapat diselesaikan hanya dengan menggunakan serangkaian fitur gambar kecil.  Hubungan spasial yang jauh dari bagian-bagian komposisi, seperti bentuk benda atau interaksi antara bagian-bagian objek, dapat sepenuhnya diabaikan;  mereka sama sekali tidak diperlukan untuk menyelesaikan masalah. <br><br>  Fitur luar biasa dari BagNet'ov adalah transparansi sistem pengambilan keputusan mereka.  Misalnya, Anda dapat mengetahui fitur gambar apa yang paling khas untuk kelas tertentu.  Misalnya, tench, ikan besar, biasanya dikenali oleh gambar jari-jari pada latar belakang hijau.  Mengapa  Karena pada sebagian besar foto dalam kategori ini ada seorang nelayan memegang piala sebagai trofi.  Dan ketika BagNet salah mengenali gambar sebagai garis, ini biasanya terjadi karena di suatu tempat di foto ada jari pada latar belakang hijau. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/175/197/727/175197727cc15da939117f5c2502d82c.jpg"><br>  <i>Bagian paling khas dari gambar.</i>  <i>Baris atas di setiap sel sesuai dengan pengenalan yang benar, dan bagian bawah dengan fragmen yang mengganggu yang menyebabkan pengakuan yang salah</i> <br><br>  Kami juga mendapatkan "peta panas" yang tepat, yang menunjukkan bagian gambar mana yang berkontribusi pada keputusan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/89b/510/f5b/89b510f5b5d816a2a1d8590f4487abf6.jpg"><br>  <i>Heatmaps bukan perkiraan, mereka secara akurat menunjukkan kontribusi setiap bagian dari gambar.</i> <br><br>  BagNet menunjukkan bahwa Anda bisa mendapatkan akurasi tinggi dengan ImageNet hanya atas dasar korelasi statistik yang lemah antara fitur gambar lokal dan kategori objek.  Jika ini cukup, lalu mengapa jaringan saraf standar ResNet-50 mempelajari sesuatu yang secara fundamental berbeda?  Mengapa ResNet-50 harus mempelajari hubungan skala besar yang kompleks seperti bentuk objek, jika kelimpahan fitur lokal gambar cukup untuk menyelesaikan masalah? <br><br>  Untuk menguji hipotesis bahwa SNA modern mematuhi strategi yang mirip dengan operasi jaringan BoW yang paling sederhana, kami menguji berbagai jaringan - ResNet, DenseNet, dan VGG pada "tanda" BagNet berikut: <br><ul><li>  Solusi tidak tergantung pada pengocokan spasial dari fitur gambar (ini hanya dapat diperiksa pada model VGG). </li><li>  Modifikasi bagian gambar yang berbeda tidak boleh saling bergantung (dalam arti pengaruhnya terhadap keanggotaan kelas). </li><li>  Kesalahan yang dibuat oleh SNA standar dan BagNet'ami harus serupa. </li><li>  SNS dan BagNet standar harus peka terhadap fitur serupa. </li></ul><br><br>  Dalam keempat percobaan, kami menemukan perilaku yang mirip dari SNS dan BagNet.  Misalnya, dalam percobaan terakhir, kami menunjukkan bahwa BagNet paling sensitif (jika, misalnya, mereka tumpang tindih) ke tempat yang sama dalam gambar seperti SNA.  Bahkan, peta panas BagNet (peta sensitivitas spasial) lebih baik memprediksi sensitivitas DenseNet-169 daripada peta panas yang diperoleh dengan metode atribusi seperti DeepLift (penghitungan langsung peta panas untuk DenseNet-169).  Tentu saja, SNA tidak persis mengulangi perilaku BagNet, tetapi beberapa penyimpangan menunjukkan.  Secara khusus, semakin dalam jaringan, semakin besar ukuran fitur menjadi dan semakin jauh ketergantungan.  Oleh karena itu, jaringan syaraf yang dalam memang merupakan peningkatan dari model-model BagNet, tetapi saya tidak berpikir bahwa dasar klasifikasi mereka entah bagaimana berubah. <br><br><h2>  Melampaui klasifikasi BoW </h2><br>  Mengamati pengambilan keputusan SNA dalam gaya strategi BoW dapat menjelaskan beberapa fitur aneh SNA.  Pertama, ini menjelaskan mengapa SNA sangat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">terikat dengan tekstur</a> .  Kedua, mengapa SNA tidak sensitif untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mencampur</a> bagian-bagian gambar.  Ini bahkan dapat menjelaskan keberadaan stiker permusuhan dan gangguan permusuhan: sinyal yang membingungkan dapat ditempatkan di mana saja pada gambar, dan SNS pasti akan menangkap sinyal ini, terlepas dari apakah itu sesuai dengan sisa gambar. <br><br>  Bahkan, pekerjaan kami menunjukkan bahwa SNA, ketika mengenali gambar, menggunakan banyak undang-undang statistik yang lemah dan tidak melanjutkan untuk mengintegrasikan bagian-bagian gambar di tingkat objek, seperti yang dilakukan orang.  Hal yang sama kemungkinan besar benar untuk tugas-tugas lain dan modalitas sensorik. <br><br>  Kita perlu merencanakan arsitektur, tugas, dan metode pelatihan kita dengan hati-hati untuk mengatasi kecenderungan menggunakan korelasi statistik yang lemah.  Salah satu pendekatan adalah menerjemahkan distorsi pelatihan SNA dari fitur lokal kecil ke fitur yang lebih global.  Yang lain adalah untuk menghapus atau mengganti fitur-fitur yang seharusnya tidak mengandalkan jaringan saraf, yang kami lakukan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">publikasi</a> lain untuk ICLR 2019, menggunakan preprocessing transfer gaya untuk menghilangkan tekstur objek alami. <br><br>  Namun, salah satu masalah terbesar tetap klasifikasi gambar: jika fitur lokal cukup, tidak ada insentif untuk mempelajari "fisika" nyata dari dunia alami.  Kita perlu merestrukturisasi tugas sedemikian rupa untuk menggerakkan model untuk mempelajari sifat fisik benda.  Untuk melakukan ini, kemungkinan besar, Anda harus melampaui pengajaran pengamatan murni untuk korelasi data input dan output sehingga model dapat mengekstraksi hubungan sebab akibat. <br><br>  Bersama-sama, hasil kami menunjukkan bahwa SNA dapat mengikuti strategi klasifikasi yang sangat sederhana.  Fakta bahwa penemuan semacam itu dapat dilakukan pada tahun 2019 menekankan betapa sedikitnya kita masih memahami fitur internal dari kerja jaringan saraf yang dalam.  Kurangnya pemahaman tidak memungkinkan kita untuk mengembangkan model dan arsitektur yang ditingkatkan secara fundamental yang menjembatani kesenjangan antara persepsi manusia dan mesin.  Memperdalam pemahaman kita akan memungkinkan kita menemukan cara untuk mempersempit kesenjangan ini.  Ini bisa sangat berguna: mencoba menggeser SNA ke arah sifat fisik benda, kami tiba-tiba mencapai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">resistensi terhadap kebisingan di</a> tingkat manusia.  Saya mengharapkan munculnya sejumlah besar hasil menarik lainnya di jalur kami menuju pengembangan SNA, yang benar-benar memahami sifat fisik dan kausal dari dunia kita. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id443734/">https://habr.com/ru/post/id443734/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id443722/index.html">Desain dan penamaan antrian</a></li>
<li><a href="../id443724/index.html">AMD Radeon VII: Chip High-End (Bagian 1)</a></li>
<li><a href="../id443726/index.html">Fitur Pengaturan Palo Alto Networks: SSL VPN</a></li>
<li><a href="../id443728/index.html">Google Plus berhenti bekerja. Jadi apa</a></li>
<li><a href="../id443730/index.html">Ctrl-Alt-Del: keusangan programer yang direncanakan</a></li>
<li><a href="../id443736/index.html">Menyiapkan Alat Manajemen Jaringan (NUT) dari awal untuk mengelola UPS yang terhubung secara lokal</a></li>
<li><a href="../id443738/index.html">Cara mendapatkan pekerjaan di Jerman untuk profesional TI</a></li>
<li><a href="../id443740/index.html">Rilis pertama alat pengujian pencarian produk terbuka</a></li>
<li><a href="../id443744/index.html">Encyclopedia of Lighting oleh Naughty Dog</a></li>
<li><a href="../id443746/index.html">Pasar Game, Tren dan Prediksi - Analisis Hebat dari App Annie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
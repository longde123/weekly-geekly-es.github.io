<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§æ ü§µüèæ ü§ó Estamos haciendo un proyecto de aprendizaje autom√°tico en Python. Parte 2 üçÇ üèè ‚öíÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un recorrido completo de aprendizaje autom√°tico en Python: segunda parte 

 Reunir todas las partes de un proyecto de aprendizaje autom√°tico puede ser...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Estamos haciendo un proyecto de aprendizaje autom√°tico en Python. Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/425907/"><img src="https://habrastorage.org/getpro/habr/post_images/225/910/6f3/2259106f3ccc19ae2b8b1ec9f316c4f2.png"><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Un recorrido completo de aprendizaje autom√°tico en Python: segunda parte</a></i> <br><br>  Reunir todas las partes de un proyecto de aprendizaje autom√°tico puede ser complicado.  En esta serie de art√≠culos, revisaremos todas las etapas de la implementaci√≥n del proceso de aprendizaje autom√°tico utilizando datos reales y descubriremos c√≥mo se combinan entre s√≠ las diversas t√©cnicas. <br><br>  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer art√≠culo,</a> limpiamos y estructuramos los datos, realizamos un an√°lisis exploratorio, recopilamos un conjunto de atributos para usar en el modelo y establecimos una l√≠nea de base para evaluar los resultados.  Con la ayuda de este art√≠culo, aprenderemos c√≥mo implementar en Python y comparar varios modelos de aprendizaje autom√°tico, realizar ajustes hiperparam√©tricos para optimizar el mejor modelo y evaluar el rendimiento del modelo final en un conjunto de datos de prueba. <br><br>  Todo el c√≥digo del proyecto est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en GitHub</a> , y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> est√° el segundo cuaderno relacionado con el art√≠culo actual.  ¬°Puede usar y modificar el c√≥digo como lo desee! <br><a name="habracut"></a><br><h2>  Evaluaci√≥n y selecci√≥n de modelos </h2><br>  Memo: Estamos trabajando en una tarea de regresi√≥n controlada, utilizando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la informaci√≥n energ√©tica de los edificios en Nueva York</a> para crear un modelo que prediga qu√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">puntaje Energy Star</a> recibir√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un</a> edificio en particular.  Estamos interesados ‚Äã‚Äãtanto en la precisi√≥n del pron√≥stico como en la interpretabilidad del modelo. <br><br>  Hoy puede elegir entre los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">muchos modelos de aprendizaje autom√°tico disponibles</a> , y esta abundancia puede ser intimidante.  Por supuesto, hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">revisiones comparativas</a> en la red que lo ayudar√°n a navegar al elegir un algoritmo, pero prefiero probar algunas en el trabajo y ver cu√°l es mejor.  En su mayor parte, el aprendizaje autom√°tico se basa en resultados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">emp√≠ricos en lugar de te√≥ricos</a> , y es casi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">imposible comprender de antemano qu√© modelo es m√°s preciso</a> . <br><br>  En general, se recomienda que comience con modelos simples e interpretables, como la regresi√≥n lineal, y si los resultados no son satisfactorios, contin√∫e con m√©todos m√°s complejos, pero generalmente m√°s precisos.  Este gr√°fico (muy anti-cient√≠fico) muestra la relaci√≥n entre la precisi√≥n e interpretabilidad de algunos algoritmos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a1/602/9a1/1a16029a1b75b5ba4022d477615f352f.png"><br>  <i>Interpretabilidad y precisi√≥n ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fuente</a> ).</i> <br><br>  Evaluaremos cinco modelos de diversos grados de complejidad: <br><br><ul><li>  Regresi√≥n lineal. </li><li>  El m√©todo de k-vecinos m√°s cercanos. </li><li>  "Bosque al azar". </li><li>  Aumento de gradiente. </li><li>  M√©todo de vectores de soporte. </li></ul><br>  Consideraremos no el aparato te√≥rico de estos modelos, sino su implementaci√≥n.  Si le interesa la teor√≠a, consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Introducci√≥n al aprendizaje estad√≠stico</a> (disponible de forma gratuita) o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje autom√°tico pr√°ctico con Scikit-Learn y TensorFlow</a> .  En ambos libros, la teor√≠a se explica perfectamente y se muestra la efectividad del uso de los m√©todos mencionados en los lenguajes R y Python, respectivamente. <br><br><h4>  Rellene los valores faltantes </h4><br>  Aunque cuando borramos los datos, eliminamos las columnas en las que faltan m√°s de la mitad de los valores, todav√≠a tenemos muchos valores.  Los modelos de aprendizaje autom√°tico no pueden funcionar con datos faltantes, por lo que debemos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">completarlos</a> . <br><br>  Primero, consideramos los datos y recordamos c√≥mo se ven: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Read in data into dataframes train_features = pd.read_csv('data/training_features.csv') test_features = pd.read_csv('data/testing_features.csv') train_labels = pd.read_csv('data/training_labels.csv') test_labels = pd.read_csv('data/testing_labels.csv') Training Feature Size: (6622, 64) Testing Feature Size: (2839, 64) Training Labels Size: (6622, 1) Testing Labels Size: (2839, 1)</span></span></code> </pre> <br>  Cada valor de <code>NaN</code> es un registro faltante en los datos.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Puede completarlos de diferentes maneras</a> , y utilizaremos el m√©todo de imputaci√≥n mediana bastante simple, que reemplaza los datos faltantes con los valores promedio de las columnas correspondientes. <br><br>  En el siguiente c√≥digo, crearemos un <code>Imputer</code> Scikit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">-Learn</a> Imputer con una estrategia mediana.  Luego lo entrenamos en los datos de entrenamiento (usando <code>imputer.fit</code> ), y lo aplicamos para completar los valores faltantes en los conjuntos de entrenamiento y prueba (usando <code>imputer.transform</code> ).  Es decir, los registros que faltan en los <i>datos de</i> la <i>prueba</i> se completar√°n con el valor medio correspondiente de los <i>datos de entrenamiento</i> . <br><br>  Hacemos el llenado y no entrenamos el modelo sobre los datos tal como est√°n, para evitar el problema de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fuga de datos de prueba</a> cuando la informaci√≥n del conjunto de datos de prueba ingresa al entrenamiento. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create an imputer object with a median filling strategy imputer = Imputer(strategy='median') # Train on the training features imputer.fit(train_features) # Transform both training data and testing data X = imputer.transform(train_features) X_test = imputer.transform(test_features) Missing values in training features: 0 Missing values in testing features: 0</span></span></code> </pre> <br>  Ahora todos los valores est√°n llenos, no hay huecos. <br><br><h4>  Escalado de caracter√≠sticas </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El escalado</a> es el proceso general de cambiar el rango de una caracter√≠stica.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Este es un paso necesario</a> , porque los signos se miden en diferentes unidades, lo que significa que cubren diferentes rangos.  Esto distorsiona en gran medida los resultados de algoritmos tales como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el</a> m√©todo del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vector de soporte</a> y el m√©todo vecino k-m√°s cercano, que tienen en cuenta las distancias entre las mediciones.  Y el escalado le permite evitar esto.  Aunque los m√©todos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la regresi√≥n lineal y el "bosque aleatorio"</a> no requieren la escala de las caracter√≠sticas, es mejor no descuidar este paso al comparar varios algoritmos. <br><br>  Escalaremos usando cada atributo a un rango de 0 a 1. Tomamos todos los valores del atributo, seleccionamos el m√≠nimo y lo dividimos por la diferencia entre el m√°ximo y el m√≠nimo (rango).  Este m√©todo de escala a menudo se llama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">normalizaci√≥n, y la otra forma principal es la estandarizaci√≥n</a> . <br><br>  Este proceso es f√°cil de implementar manualmente, por lo que utilizaremos el objeto <code>MinMaxScaler</code> de Scikit-Learn.  El c√≥digo para este m√©todo es id√©ntico al c√≥digo para completar los valores faltantes, solo se usa la escala en lugar de pegar.  Recuerde que aprendemos el modelo solo en el conjunto de entrenamiento y luego transformamos todos los datos. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create the scaler object with a range of 0-1 scaler = MinMaxScaler(feature_range=(0, 1)) # Fit on the training data scaler.fit(X) # Transform both the training and testing data X = scaler.transform(X) X_test = scaler.transform(X_test)</span></span></code> </pre> <br>  Ahora, cada atributo tiene un valor m√≠nimo de 0 y un m√°ximo de 1. Rellenar los valores faltantes y escalar los atributos: estas dos etapas son necesarias en casi cualquier proceso de aprendizaje autom√°tico. <br><br><h4>  Implementamos modelos de aprendizaje autom√°tico en Scikit-Learn </h4><br>  Despu√©s de todo el trabajo preparatorio, el proceso de creaci√≥n, capacitaci√≥n y ejecuci√≥n de modelos es relativamente simple.  Utilizaremos la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scikit-Learn</a> en Python, que est√° bellamente documentada y con una sintaxis elaborada para construir modelos.  Al aprender a crear un modelo en Scikit-Learn, puede implementar r√°pidamente todo tipo de algoritmos. <br><br>  Ilustraremos el proceso de creaci√≥n, capacitaci√≥n ( <code>.fit</code> ) y prueba ( <code>.predict</code> ) usando el aumento de gradiente: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-comment"><span class="hljs-comment"># Create the model gradient_boosted = GradientBoostingRegressor() # Fit the model on the training data gradient_boosted.fit(X, y) # Make predictions on the test data predictions = gradient_boosted.predict(X_test) # Evaluate the model mae = np.mean(abs(predictions - y_test)) print('Gradient Boosted Performance on the test set: MAE = %0.4f' % mae) Gradient Boosted Performance on the test set: MAE = 10.0132</span></span></code> </pre> <br>  Solo una l√≠nea de c√≥digo para crear, entrenar y probar.  Para construir otros modelos, usamos la misma sintaxis, cambiando solo el nombre del algoritmo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/215/58f/ab4/21558fab42e2669b96132dff6a5b2691.png"><br><br>  Para evaluar los modelos objetivamente, calculamos el nivel base usando el valor medio de la meta y obtuvimos 24.5.  Y los resultados fueron mucho mejores, por lo que nuestro problema puede resolverse mediante el aprendizaje autom√°tico. <br><br>  En nuestro caso, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aumento de gradiente</a> (MAE = 10.013) result√≥ ser ligeramente mejor que el "bosque aleatorio" (10.014 MAE).  Aunque estos resultados no pueden considerarse completamente honestos, porque para los hiperpar√°metros usamos principalmente los valores predeterminados.  La efectividad de los modelos depende en gran medida de estos ajustes, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">especialmente en el m√©todo del vector de soporte</a> .  Sin embargo, en funci√≥n de estos resultados, elegiremos el aumento de gradiente y comenzaremos a optimizarlo. <br><br><h2>  Optimizaci√≥n del modelo hiperparam√©trico. </h2><br>  Despu√©s de elegir un modelo, puede optimizarlo para la tarea a resolver ajustando los hiperpar√°metros. <br><br>  Pero antes que nada, comprendamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">qu√© son los hiperpar√°metros y c√≥mo se diferencian de los par√°metros ordinarios</a> . <br><br><ul><li>  Los hiperpar√°metros del modelo pueden considerarse la configuraci√≥n del algoritmo, que establecemos antes del inicio de su entrenamiento.  Por ejemplo, el hiperpar√°metro es el n√∫mero de √°rboles en el "bosque aleatorio", o el n√∫mero de vecinos en el m√©todo k-vecinos m√°s cercanos. </li><li>  Par√°metros del modelo: lo que aprende durante el entrenamiento, por ejemplo, pesos en regresi√≥n lineal. </li></ul><br>  Al controlar el hiperpar√°metro, influimos en los resultados del modelo, cambiando el equilibrio entre su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">subeducaci√≥n y su reentrenamiento</a> .  El aprendizaje insuficiente es una situaci√≥n en la que el modelo no es lo suficientemente complejo (tiene muy pocos grados de libertad) para estudiar la correspondencia de signos y objetivos.  Un modelo poco entrenado tiene un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">alto</a> sesgo, que puede corregirse complicando el modelo. <br><br>  La reentrenamiento es una situaci√≥n en la que el modelo recuerda esencialmente los datos de entrenamiento.  El modelo reentrenado tiene una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">alta</a> varianza, que se puede ajustar limitando la complejidad del modelo a trav√©s de la regularizaci√≥n.  Los modelos poco entrenados y reentrenados no podr√°n generalizar bien los datos de prueba. <br><br>  La dificultad para elegir los hiperpar√°metros correctos es que para cada tarea habr√° un conjunto √≥ptimo √∫nico.  Por lo tanto, la √∫nica forma de elegir la mejor configuraci√≥n es probar diferentes combinaciones en el nuevo conjunto de datos.  Afortunadamente, Scikit-Learn tiene una serie de m√©todos que le permiten evaluar con eficacia los hiperpar√°metros.  Adem√°s, proyectos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TPOT</a> intentan optimizar la b√∫squeda de hiperpar√°metros utilizando enfoques como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la programaci√≥n gen√©tica</a> .  En este art√≠culo, nos limitamos a usar Scikit-Learn. <br><br><h4>  B√∫squeda aleatoria de verificaci√≥n cruzada </h4><br>  Implementemos un m√©todo de ajuste de hiperpar√°metros llamado b√∫squedas aleatorias de validaci√≥n cruzada: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">B√∫squeda aleatoria</a> : una t√©cnica para seleccionar hiperpar√°metros.  Definimos una cuadr√≠cula y luego seleccionamos al azar varias combinaciones de ella, en contraste con la b√∫squeda de cuadr√≠cula, en la que probamos sucesivamente cada combinaci√≥n.  Por cierto, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la b√∫squeda aleatoria funciona casi tan bien como la b√∫squeda de cuadr√≠cula</a> , pero mucho m√°s r√°pido. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La verificaci√≥n cruzada</a> es una forma de evaluar la combinaci√≥n seleccionada de hiperpar√°metros.  En lugar de dividir los datos en conjuntos de entrenamiento y prueba, lo que reduce la cantidad de datos disponibles para el entrenamiento, utilizaremos la validaci√≥n cruzada de bloque k (validaci√≥n cruzada de plegado en K).  Para hacer esto, dividiremos los datos de entrenamiento en k bloques, y luego ejecutaremos el proceso iterativo, durante el cual primero entrenaremos el modelo en bloques k-1, y luego compararemos el resultado al aprender en el bloque k-√©simo.  Repetiremos el proceso k veces, y al final obtendremos el valor de error promedio para cada iteraci√≥n.  Esta ser√° la evaluaci√≥n final. </li></ul><br>  Aqu√≠ hay una ilustraci√≥n gr√°fica de la validaci√≥n cruzada de bloque k en k = 5: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e17/94b/51e/e1794b51eded0314afd9f594a8e9ee5e.png"><br><br>  Todo el proceso de b√∫squeda aleatoria de validaci√≥n cruzada se ve as√≠: <br><br><ol><li>  Establecemos una cuadr√≠cula de hiperpar√°metros. </li><li>  Seleccione aleatoriamente una combinaci√≥n de hiperpar√°metros. </li><li>  Crea un modelo usando esta combinaci√≥n. </li><li>  Evaluamos el resultado del modelo utilizando la validaci√≥n cruzada de bloque k. </li><li>  Decidimos qu√© hiperpar√°metros dan el mejor resultado. </li></ol><br>  ¬°Por supuesto, todo esto no se hace manualmente, sino que usa <code>RandomizedSearchCV</code> de Scikit-Learn! <br><br><h4>  Digresi√≥n peque√±a: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√©todos de aumento de gradiente</a> </h4><br>  Utilizaremos un modelo de regresi√≥n basado en el aumento de gradiente.  Este es un m√©todo colectivo, es decir, el modelo consiste en numerosos "estudiantes d√©biles", en este caso, de √°rboles de decisi√≥n separados.  Si los estudiantes aprenden en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">algoritmos</a> paralelos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">como "bosque aleatorio"</a> , y luego el resultado de la predicci√≥n se selecciona mediante votaci√≥n, entonces en los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">algoritmos de impulso</a> como el aumento de gradiente, los estudiantes reciben capacitaci√≥n secuencial y cada uno de ellos se "enfoca" en los errores cometidos por los predecesores. <br><br>  En los √∫ltimos a√±os, los algoritmos de refuerzo se han vuelto populares y, a menudo, ganan en competencias de aprendizaje autom√°tico.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El aumento de gradiente</a> es una de las implementaciones en las que se utiliza Gradient Descent para minimizar el costo de la funci√≥n.  La implementaci√≥n del aumento de gradiente en Scikit-Learn no se considera tan efectiva como en otras bibliotecas, por ejemplo, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">XGBoost</a> , pero funciona bien en peque√±os conjuntos de datos y proporciona pron√≥sticos bastante precisos. <br><br><h4>  Volver a la configuraci√≥n hiperparam√©trica </h4><br>  En la regresi√≥n que usa el aumento de gradiente, hay muchos hiperpar√°metros que deben configurarse, para obtener m√°s detalles, le remito a la documentaci√≥n de Scikit-Learn.  Optimizaremos: <br><br><ul><li>  <code>loss</code> : minimizaci√≥n de la funci√≥n de p√©rdida; </li><li>  <code>n_estimators</code> : el n√∫mero de √°rboles de decisi√≥n d√©biles utilizados (√°rboles de decisi√≥n); </li><li>  <code>max_depth</code> : profundidad m√°xima de cada √°rbol de decisi√≥n; </li><li>  <code>min_samples_leaf</code> : el n√∫mero m√≠nimo de ejemplos que deber√≠an estar en el nodo hoja del √°rbol de decisi√≥n; </li><li>  <code>min_samples_split</code> : la cantidad m√≠nima de ejemplos necesarios para dividir el nodo del √°rbol de decisi√≥n; </li><li>  <code>max_features</code> : el n√∫mero m√°ximo de caracter√≠sticas que se utilizan para separar nodos. </li></ul><br>  No estoy seguro de si alguien realmente comprende c√≥mo funciona todo, y la √∫nica forma de encontrar la mejor combinaci√≥n es probar diferentes opciones. <br><br>  En este c√≥digo, creamos una cuadr√≠cula de hiperpar√°metros, luego creamos un objeto <code>RandomizedSearchCV</code> y buscamos mediante la validaci√≥n cruzada de 4 bloques para 25 combinaciones diferentes de hiperpar√°metros: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Loss function to be optimized loss = ['ls', 'lad', 'huber'] # Number of trees used in the boosting process n_estimators = [100, 500, 900, 1100, 1500] # Maximum depth of each tree max_depth = [2, 3, 5, 10, 15] # Minimum number of samples per leaf min_samples_leaf = [1, 2, 4, 6, 8] # Minimum number of samples to split a node min_samples_split = [2, 4, 6, 10] # Maximum number of features to consider for making splits max_features = ['auto', 'sqrt', 'log2', None] # Define the grid of hyperparameters to search hyperparameter_grid = {'loss': loss, 'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'min_samples_split': min_samples_split, 'max_features': max_features} # Create the model to use for hyperparameter tuning model = GradientBoostingRegressor(random_state = 42) # Set up the random search with 4-fold cross validation random_cv = RandomizedSearchCV(estimator=model, param_distributions=hyperparameter_grid, cv=4, n_iter=25, scoring = 'neg_mean_absolute_error', n_jobs = -1, verbose = 1, return_train_score = True, random_state=42) # Fit on the training data random_cv.fit(X, y) After performing the search, we can inspect the RandomizedSearchCV object to find the best model: # Find the best combination of settings random_cv.best_estimator_ GradientBoostingRegressor(loss='lad', max_depth=5, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=500)</span></span></code> </pre> <br>  Puede usar estos resultados para una b√∫squeda de cuadr√≠cula seleccionando par√°metros para la cuadr√≠cula que est√©n cerca de estos valores √≥ptimos.  Pero es poco probable que un ajuste adicional mejore significativamente el modelo.  Hay una regla general: la construcci√≥n competente de caracter√≠sticas tendr√° un impacto mucho mayor en la precisi√≥n del modelo que la configuraci√≥n de hiperpar√°metro m√°s costosa.  Esta es la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ley de la disminuci√≥n de la rentabilidad en relaci√≥n con el aprendizaje autom√°tico</a> : el dise√±o de atributos proporciona el mayor rendimiento, y el ajuste hiperparam√©trico solo ofrece beneficios modestos. <br><br>  Para cambiar el n√∫mero de estimadores (√°rboles de decisi√≥n) mientras se conservan los valores de otros hiperpar√°metros, se puede realizar un experimento que demuestre el papel de esta configuraci√≥n.  La implementaci√≥n se da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , pero aqu√≠ est√° el resultado: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aca/18e/d51/aca18ed519f22d26c6b78af3324b8614.png"><br><br>  A medida que aumenta el n√∫mero de √°rboles utilizados por el modelo, disminuye el nivel de errores durante el entrenamiento y las pruebas.  Pero los errores de aprendizaje disminuyen mucho m√°s r√°pido y, como resultado, el modelo se vuelve a entrenar: muestra excelentes resultados en los datos de entrenamiento, pero funciona peor en los datos de las pruebas. <br><br>  En los datos de la prueba, la precisi√≥n siempre disminuye (porque el modelo ve las respuestas correctas para el conjunto de datos de entrenamiento), pero una ca√≠da significativa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">indica una nueva</a> capacitaci√≥n.  Este problema se puede resolver aumentando la cantidad de datos de entrenamiento o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reduciendo la complejidad del modelo utilizando hiperpar√°metros</a> .  Aqu√≠ no tocaremos los hiperpar√°metros, pero le recomiendo que siempre preste atenci√≥n al problema del reciclaje. <br><br>  Para nuestro modelo final, tomaremos 800 evaluadores, porque esto nos dar√° el nivel m√°s bajo de error en la validaci√≥n cruzada.  ¬°Ahora prueba el modelo! <br><br><h2>  Evaluaci√≥n utilizando datos de prueba </h2><br>  Como personas responsables, nos aseguramos de que nuestro modelo de ninguna manera obtuviera acceso a los datos de las pruebas durante la capacitaci√≥n.  Por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lo</a> tanto, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">podemos usar la precisi√≥n cuando trabajamos con datos de prueba como un indicador de</a> calidad del modelo cuando se admite en tareas reales. <br><br>  Alimentamos los datos de prueba del modelo y calculamos el error.  Aqu√≠ hay una comparaci√≥n de los resultados del algoritmo de aumento de gradiente predeterminado y nuestro modelo personalizado: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make predictions on the test set using default and final model default_pred = default_model.predict(X_test) final_pred = final_model.predict(X_test) Default model performance on the test set: MAE = 10.0118. Final model performance on the test set: MAE = 9.0446.</span></span></code> </pre> <br>  El ajuste hiperparam√©trico ayud√≥ a mejorar la precisi√≥n del modelo en aproximadamente un 10%.  Dependiendo de la situaci√≥n, esto puede ser una mejora muy significativa, pero lleva mucho tiempo. <br><br>  Puede comparar el tiempo de entrenamiento para ambos modelos usando el <code>%timeit</code> magic <code>%timeit</code> en Jupyter Notebooks.  Primero, mida la duraci√≥n predeterminada del modelo: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> default_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">1.09</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">153</span></span> ms per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Un segundo para estudiar es muy decente.  Pero el modelo ajustado no es tan r√°pido: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> final_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">12.1</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">1.33</span></span> s per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Esta situaci√≥n ilustra el aspecto fundamental del aprendizaje autom√°tico: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se trata de compromisos</a> .  Es constantemente necesario elegir un equilibrio entre precisi√≥n e interpretabilidad, entre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desplazamiento y dispersi√≥n</a> , entre precisi√≥n y tiempo de operaci√≥n, etc.  La combinaci√≥n correcta est√° completamente determinada por la tarea espec√≠fica.  En nuestro caso, un aumento de 12 veces en la duraci√≥n del trabajo en t√©rminos relativos es grande, pero en t√©rminos absolutos es insignificante. <br><br>  Obtuvimos los resultados finales del pron√≥stico, ahora analic√©moslos y descubramos si hay desviaciones notables.  A la izquierda hay un gr√°fico de la densidad de los valores predichos y reales, a la derecha hay un histograma del error: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/817/ea7/f23/817ea7f2371b83ff0ae6ae5fa02b5a1e.png" width="350"><img src="https://habrastorage.org/getpro/habr/post_images/f49/f42/5cc/f49f425cc56d717a1e75b9478d1a24d1.png" width="340"><br><br>  El pron√≥stico del modelo repite bien la distribuci√≥n de los valores reales, mientras que en los datos de entrenamiento, el pico de densidad se ubica m√°s cerca del valor medio (66) que del pico de densidad real (aproximadamente 100).  Los errores tienen una distribuci√≥n casi normal, aunque hay varios valores negativos grandes cuando el pron√≥stico del modelo es muy diferente de los datos reales.  En el pr√≥ximo art√≠culo, examinaremos con m√°s detalle la interpretaci√≥n de los resultados. <br><br><h2>  Conclusi√≥n </h2><br>  En este art√≠culo, examinamos varias etapas para resolver el problema del aprendizaje autom√°tico: <br><br><ul><li>  Relleno de valores faltantes y funciones de escala. </li><li>  Evaluaci√≥n y comparaci√≥n de los resultados de varios modelos. </li><li>  Ajuste hiperparam√©trico mediante b√∫squeda aleatoria de cuadr√≠cula y validaci√≥n cruzada. </li><li>  Evaluaci√≥n del mejor modelo utilizando datos de prueba. </li></ul><br>  Los resultados indican que podemos utilizar el aprendizaje autom√°tico para predecir el puntaje Energy Star basado en las estad√≠sticas disponibles.  Con la ayuda del aumento de gradiente, se logr√≥ un error de 9.1 en los datos de prueba.  El ajuste hiperparam√©trico puede mejorar en gran medida los resultados, pero a costa de una desaceleraci√≥n significativa.  Esta es una de las muchas compensaciones a considerar en el aprendizaje autom√°tico. <br><br>  En el pr√≥ximo art√≠culo, intentaremos descubrir c√≥mo funciona nuestro modelo.  Tambi√©n veremos los principales factores que influyen en el Energy Star Score.  Si sabemos que el modelo es preciso, intentaremos comprender por qu√© predice de esta manera y qu√© nos dice sobre el problema en s√≠. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es425907/">https://habr.com/ru/post/es425907/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es425897/index.html">Caracter√≠sticas del uso de la biblioteca RxJs en un sistema bancario en l√≠nea</a></li>
<li><a href="../es425899/index.html">Hormiguero o fortaleza? Estoy construyendo una casa por el precio de un apartamento. 1 parte</a></li>
<li><a href="../es425901/index.html">Estaci√≥n meteorol√≥gica en Arduino de la A a la Z. Parte 1</a></li>
<li><a href="../es425903/index.html">Las vacaciones nos llegan: SCRF duplic√≥ la banda ISM de 868 MHz</a></li>
<li><a href="../es425905/index.html">C√≥mo escribir c√≥digo de ensamblador con instrucciones superpuestas (otra t√©cnica para ofuscar el c√≥digo de bytes)</a></li>
<li><a href="../es425911/index.html">Transferir CRM en la nube a la versi√≥n en caja</a></li>
<li><a href="../es425915/index.html">C√≥mo las comunicaciones transfronterizas pueden reemplazar los sem√°foros y acortar el camino al trabajo</a></li>
<li><a href="../es425917/index.html">Justice Fighter evita que Waymo patente la tecnolog√≠a LIDAR clave</a></li>
<li><a href="../es425919/index.html">Mapas hexagonales en Unity: guardar y cargar, texturas, distancias</a></li>
<li><a href="../es425921/index.html">Reuni√≥n de la comunidad .NET en CLRium # 4 + en l√≠nea</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
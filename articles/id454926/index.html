<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👈🏾 🚵🏽 🚸 Semua yang Anda ketahui tentang word2vec tidak benar 🧑🏼‍🤝‍🧑🏻 🚶🏽 🧑🏻‍🤝‍🧑🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Penjelasan klasik dari word2vec sebagai arsitektur Skip-gram sampel negatif dalam artikel ilmiah asli dan posting blog yang tak terhitung jumlahnya te...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Semua yang Anda ketahui tentang word2vec tidak benar</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454926/">  Penjelasan klasik dari word2vec sebagai arsitektur Skip-gram sampel negatif dalam artikel ilmiah asli dan posting blog yang tak terhitung jumlahnya terlihat seperti ini: <br><br><pre><code class="plaintext hljs">while(1) { 1. vf = vector of focus word 2. vc = vector of focus word 3. train such that (vc . vf = 1) 4. for(0 &lt;= i &lt;= negative samples): vneg = vector of word *not* in context train such that (vf . vneg = 0) }</code> </pre> <br>  Memang, jika Anda google [word2vec skipgram], apa yang kita lihat: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Halaman Wikipedia yang menggambarkan algoritme di tingkat tinggi</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Halaman Tensorflow dengan penjelasan yang sama</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menuju Ilmu Data blog dengan deskripsi algoritma yang sama</a> , dan daftarnya terus berjalan. </li></ul><br>  <b>Tetapi semua implementasi ini salah</b> . <br><a name="habracut"></a><br>  Implementasi asli word2vec di C bekerja secara berbeda dan secara <i>fundamental berbeda</i> dari ini.  Mereka yang secara profesional menerapkan sistem dengan embeddings kata dari word2vec melakukan salah satu dari yang berikut: <br><br><ol><li>  Langsung menyebut implementasi asli C. <br></li><li>  Gunakan implementasi <code>gensim</code> , yang <i>ditransliterasikan</i> dari sumber C sejauh nama-nama variabel cocok. </li></ol><br>  Memang, <code>gensim</code> adalah <i>satu</i> - <i>satunya implementasi C yang benar yang saya tahu</i> . <br><br><h3>  Implementasi C </h3><br>  Implementasi C sebenarnya mendukung <i>dua vektor untuk setiap kata</i> .  Satu vektor untuk kata dalam fokus, dan yang kedua untuk kata dalam konteks.  (Tampaknya familier? Benar, pengembang GloVe meminjam ide dari word2vec tanpa menyebutkan fakta ini!) <br><br>  Implementasi dalam kode C sangat kompeten: <br><br><ul><li>  Array <code>syn0</code> berisi embedding vektor kata jika itu tampil sebagai kata dalam fokus.  Inilah <b>inisialisasi acak</b> . <br><br><pre> <code class="cpp hljs">https:<span class="hljs-comment"><span class="hljs-comment">//github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L369 for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) { next_random = next_random * (unsigned long long)25214903917 + 11; syn0[a * layer1_size + b] = (((next_random &amp; 0xFFFF) / (real)65536) - 0.5) / layer1_size; }</span></span></code> </pre> </li><li>  Array <code>syn1neg</code> lain berisi vektor kata ketika muncul sebagai kata konteks.  Di sini <b>inisialisasi adalah nol</b> . <br></li><li>  Selama pelatihan (Lewati-gram, sampel negatif, meskipun kasus lain hampir sama), kami pertama-tama memilih kata fokus.  Itu dipertahankan sepanjang pelatihan tentang contoh-contoh positif dan negatif.  Gradien vektor fokus terakumulasi dalam buffer dan diterapkan ke kata fokus setelah pelatihan pada contoh positif dan negatif. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (negative &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (d = <span class="hljs-number"><span class="hljs-number">0</span></span>; d &lt; negative + <span class="hljs-number"><span class="hljs-number">1</span></span>; d++) { <span class="hljs-comment"><span class="hljs-comment">// if we are performing negative sampling, in the 1st iteration, // pick a word from the context and set the dot product target to 1 if (d == 0) { target = word; label = 1; } else { // for all other iterations, pick a word randomly and set the dot //product target to 0 next_random = next_random * (unsigned long long)25214903917 + 11; target = table[(next_random &gt;&gt; 16) % table_size]; if (target == 0) target = next_random % (vocab_size - 1) + 1; if (target == word) continue; label = 0; } l2 = target * layer1_size; f = 0; // find dot product of original vector with negative sample vector // store in f for (c = 0; c &lt; layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2]; // set g = sigmoid(f) (roughly, the actual formula is slightly more complex) if (f &gt; MAX_EXP) g = (label - 1) * alpha; else if (f &lt; -MAX_EXP) g = (label - 0) * alpha; else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]) * alpha; // 1. update the vector syn1neg, // 2. DO NOT UPDATE syn0 // 3. STORE THE syn0 gradient in a temporary buffer neu1e for (c = 0; c &lt; layer1_size; c++) neu1e[c] += g * syn1neg[c + l2]; for (c = 0; c &lt; layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1]; } // Finally, after all samples, update syn1 from neu1e https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L541 // Learn weights input -&gt; hidden for (c = 0; c &lt; layer1_size; c++) syn0[c + l1] += neu1e[c];</span></span></code> </pre> </li></ul><br><h3>  Mengapa inisialisasi acak dan nol? </h3><br>  Sekali lagi, karena ini tidak dijelaskan sama sekali dalam artikel asli <i>dan di mana saja di Internet</i> , saya hanya bisa berspekulasi. <br><br>  Hipotesisnya adalah ketika sampel negatif berasal dari keseluruhan teks dan tidak diperhitungkan berdasarkan frekuensi, Anda dapat memilih <i>kata apa saja</i> , dan paling sering kata yang <i>vektornya tidak dilatih sama sekali</i> .  Jika vektor ini memiliki makna, maka secara acak akan menggeser kata yang sangat penting menjadi fokus. <br><br>  Intinya adalah untuk mengatur semua contoh negatif menjadi nol, sehingga <i>hanya vektor yang muncul lebih atau kurang sering</i> akan mempengaruhi penyajian vektor lain. <br><br>  Ini sebenarnya cukup rumit, dan saya tidak pernah memikirkan betapa pentingnya strategi inisialisasi. <br><br><h3>  Kenapa saya menulis ini </h3><br>  Saya menghabiskan dua bulan hidup saya mencoba mereproduksi word2vec seperti yang dijelaskan dalam publikasi ilmiah asli dan banyak artikel di Internet, tetapi gagal.  Saya tidak dapat mencapai hasil yang sama dengan word2vec, meskipun saya mencoba yang terbaik. <br><br>  Saya tidak dapat membayangkan bahwa para penulis publikasi secara harfiah membuat sebuah algoritma yang tidak berfungsi, sementara implementasinya melakukan sesuatu yang sangat berbeda. <br><br>  Pada akhirnya, saya memutuskan untuk mempelajari sumbernya.  Selama tiga hari saya yakin bahwa saya salah mengerti kode, karena secara harfiah semua orang di Internet berbicara tentang implementasi yang berbeda. <br><br>  Saya tidak tahu mengapa publikasi asli dan artikel di Internet tidak mengatakan apa-apa tentang mekanisme <i>sebenarnya</i> dari word2vec, jadi saya memutuskan untuk mempublikasikan informasi ini sendiri. <br><br>  Ini juga menjelaskan pilihan radikal GloVe untuk mengatur vektor terpisah untuk konteks negatif - mereka hanya melakukan apa yang dilakukan word2vec, tetapi memberi tahu orang-orang tentang hal itu :). <br><br>  Apakah ini trik ilmiah?  Saya tidak tahu, pertanyaan yang sulit.  Tapi jujur ​​saja, saya sangat marah.  Mungkin, saya tidak akan pernah lagi dapat menganggap serius penjelasan algoritma dalam pembelajaran mesin: lain kali saya akan <i>segera</i> melihat sumbernya. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id454926/">https://habr.com/ru/post/id454926/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id454916/index.html">Arsitektur jaringan saraf untuk mengimplementasikan algoritma RL dengan kemampuan untuk mengatur tindakan yang berjalan secara bersamaan</a></li>
<li><a href="../id454918/index.html">Cara menggabungkan punggung dua pengecer di SAP dalam 12 jam</a></li>
<li><a href="../id454920/index.html">Kinerja Ujung Depan: Parsing Metrik Penting</a></li>
<li><a href="../id454922/index.html">Kisah tentang pelanggan asing dan fitur-fitur mereka bekerja di Rusia setelah UU PD</a></li>
<li><a href="../id454924/index.html">Pengaturan Otentikasi di Veeam Backup untuk Microsoft Office 365 v3</a></li>
<li><a href="../id454928/index.html">Cara untuk Memintas Layar Kunci Windows pada Sesi RDP</a></li>
<li><a href="../id454930/index.html">Pengumpulan sampah di V8: cara kerja Orinoco GC baru</a></li>
<li><a href="../id454936/index.html">Vivaldi: Pemblokiran iklan harus menjadi pilihan pengguna</a></li>
<li><a href="../id454938/index.html">Pengembangan intinya sendiri untuk ditanamkan dalam sistem prosesor berbasis FPGA</a></li>
<li><a href="../id454940/index.html">Asuransi kesehatan perjalanan: petunjuk terperinci</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
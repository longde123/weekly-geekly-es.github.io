<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüë©‚Äçüëß‚Äçüë¶ ü•¶ üèòÔ∏è Identifizierung und Klassifizierung toxischer Kommentare. Vortrag in Yandex üôåüèº üîã ‚èèÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alle modernen Moderationssysteme verwenden entweder Crowdsourcing oder maschinelles Lernen, das bereits zu einem Klassiker geworden ist. Beim n√§chsten...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifizierung und Klassifizierung toxischer Kommentare. Vortrag in Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/414993/">  Alle modernen Moderationssysteme verwenden entweder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Crowdsourcing</a> oder maschinelles Lernen, das bereits zu einem Klassiker geworden ist.  Beim n√§chsten ML-Training in Yandex sprachen Konstantin Kotik, Igor Galitsky und Alexey Noskov √ºber ihre Teilnahme am Wettbewerb zur Massenidentifizierung beleidigender Kommentare.  Der Wettbewerb fand auf der Kaggle-Plattform statt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3mL9iP8g3fA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Hallo allerseits!  Mein Name ist Konstantin Kotik, ich bin Datenwissenschaftler bei der Firma Button of Life, Student der Physikabteilung und der Graduate School of Business der Moskauer Staatlichen Universit√§t. <br><a name="habracut"></a><br>  Heute erz√§hlen Ihnen unsere Kollegen Igor Galitsky und Alexei Noskov √ºber den Wettbewerb ‚ÄûToxic Comment Classification Challenge‚Äú, bei dem unser DecisionGuys-Team unter 4551 Teams den 10. Platz belegte. <br><br>  Eine Online-Diskussion von Themen, die uns wichtig sind, kann schwierig sein.  Die Beleidigungen, Aggressionen und Bel√§stigungen, die online auftreten, zwingen viele Menschen h√§ufig dazu, die Suche nach verschiedenen geeigneten Meinungen zu f√ºr sie interessanten Themen aufzugeben und sich nicht zu √§u√üern. <br><br>  Viele Plattformen haben Schwierigkeiten, effektiv online zu kommunizieren. Dies f√ºhrt jedoch h√§ufig dazu, dass viele Communities einfach Benutzerkommentare schlie√üen. <br><br>  Ein Forschungsteam von Google und einem anderen Unternehmen arbeitet an Tools zur Verbesserung der Online-Diskussion. <br><br>  Einer der Tricks, auf die sie sich konzentrieren, ist die Untersuchung negativer Online-Verhaltensweisen wie toxischer Kommentare.  Dies sind Kommentare, die beleidigend oder respektlos sein oder den Benutzer einfach zwingen k√∂nnen, die Diskussion zu verlassen. <br><br><img src="https://habrastorage.org/webt/y2/o4/oz/y2o4ozi061ri0lyir_c9szxsmko.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Bisher hat diese Gruppe eine √∂ffentliche API entwickelt, mit der der Grad der Toxizit√§t eines Kommentars bestimmt werden kann. Die aktuellen Modelle machen jedoch immer noch Fehler.  Und in diesem Wettbewerb wurden wir, die Kegglers, aufgefordert, ein Modell zu entwickeln, das Kommentare identifizieren konnte, die Bedrohungen, Hass, Beleidigungen und dergleichen enthielten.  Und im Idealfall musste dieses Modell besser sein als das aktuelle Modell f√ºr ihre API. <br><br>  Wir haben die Aufgabe der Textverarbeitung: Kommentare zu identifizieren und dann zu klassifizieren.  Als Trainings- und Testbeispiele wurden Kommentare von den Wikipedia-Diskussionsseiten bereitgestellt.  Es gab ungef√§hr 160.000 Kommentare im Zug, 154.000 im Test. <br><br><img src="https://habrastorage.org/webt/u5/ys/we/u5yswe0_sb618cfq9rlilpykuke.jpeg" width="700"><br><br>  Das Trainingsmuster wurde wie folgt markiert.  Jeder Kommentar hat sechs Bezeichnungen.  Etiketten nehmen den Wert 1 an, wenn der Kommentar diese Art von Toxizit√§t enth√§lt, andernfalls 0.  Und es kann sein, dass alle Labels Null sind, ein angemessener Kommentarfall.  Oder es kann sein, dass ein Kommentar mehrere Arten von Toxizit√§t enth√§lt, sofort eine Bedrohung und Obsz√∂nit√§t. <br><br>  Aufgrund der Tatsache, dass wir auf Sendung sind, kann ich keine konkreten Beispiele f√ºr diese Klassen demonstrieren.  In Bezug auf die Testprobe war es f√ºr jeden Kommentar erforderlich, die Wahrscheinlichkeit jeder Art von Toxizit√§t vorherzusagen. <br><br>  Die Qualit√§tsmetrik ist die √ºber die Toxizit√§tstypen gemittelte ROC-AUC, d. H. Das arithmetische Mittel der ROC-AUC f√ºr jede Klasse separat. <br><br><img src="https://habrastorage.org/webt/17/cm/gk/17cmgklewbzg00esfhzii641og4.jpeg" width="700"><br><br>  Hier ist die Verteilung der Objekte nach Klassen im Trainingssatz.  Es ist ersichtlich, dass die Daten sehr unausgewogen sind.  Ich muss sofort sagen, dass unser Team anhand einer Stichprobe von Methoden f√ºr die Arbeit mit unausgeglichenen Daten, z. B. √úber- oder Unterabtastung, Punkte erzielt hat. <br><br><img src="https://habrastorage.org/webt/og/t6/gy/ogt6gyfkpmslose73rrxl4v_7ci.jpeg" width="700"><br><br>  Beim Erstellen des Modells habe ich eine zweistufige Datenvorverarbeitung verwendet.  Die erste Stufe ist die grundlegende Vorverarbeitung der Daten. Dies sind die Transformationen der Ansicht auf der Folie. Dadurch wird der Text in Kleinbuchstaben geschrieben und Links, IP-Adressen, Zahlen und Satzzeichen gel√∂scht. <br><br><img src="https://habrastorage.org/webt/xb/5v/kq/xb5vkq8juiimjekysw3e0we4vgq.jpeg" width="700"><br><br>  F√ºr alle Modelle wurde diese grundlegende Datenvorverarbeitung verwendet.  In der zweiten Phase wurde eine teilweise Vorverarbeitung der Daten durchgef√ºhrt - Ersetzen von Emoticons durch die entsprechenden W√∂rter, Entschl√ºsseln von Abk√ºrzungen, Korrigieren von Tippfehlern in der Obsz√∂nit√§t, Bringen der verschiedenen Arten von Matten in dieselbe Form und L√∂schen von Bildern.  In einigen Kommentaren wurden Links zu Bildern angegeben, wir haben sie einfach entfernt. <br><br>  F√ºr jedes der Modelle wurde eine teilweise Vorverarbeitung der Daten und ihrer verschiedenen Elemente verwendet.  All dies wurde getan, damit die Basismodelle die Kreuzkorrelation zwischen den Basismodellen beim Aufbau einer weiteren Zusammensetzung verringern. <br>  Kommen wir zum interessantesten Teil - dem Erstellen eines Modells. <br><br>  Ich habe sofort den klassischen Ansatz der Wortsack aufgegeben.  Aufgrund der Tatsache, dass bei diesem Ansatz jedes Wort ein separates Attribut ist.  Dieser Ansatz ber√ºcksichtigt nicht die allgemeine Wortreihenfolge, es wird angenommen, dass die W√∂rter unabh√§ngig sind.  Bei diesem Ansatz erfolgt die Erzeugung des Textes so, dass eine gewisse Verteilung in W√∂rtern vorliegt. Ein Wort wird zuf√§llig aus dieser Verteilung ausgew√§hlt und in den Text eingef√ºgt. <br><br>  Nat√ºrlich gibt es komplexere generative Prozesse, aber das Wesentliche √§ndert sich nicht - dieser Ansatz ber√ºcksichtigt nicht die allgemeine Wortreihenfolge.  Sie k√∂nnen zu Engrammen gehen, aber dort wird nur die Fensterreihenfolge der W√∂rter ber√ºcksichtigt und nicht allgemein.  Daher verstand ich auch meine Teamkollegen, dass sie etwas Kl√ºgeres verwenden mussten. <br><br><img src="https://habrastorage.org/webt/7q/1q/2v/7q1q2v5h2q8c8ngog4foqvsabbm.jpeg" width="700"><br><h5>  <sub><sup><a href="">Link</a></sup></sub> </h5><br>  Das erste, was mir in den Sinn kam, war die Verwendung einer Vektordarstellung mit Doc2vec.  Dies ist Word2vec plus ein Vektor, der die Eindeutigkeit eines bestimmten Dokuments ber√ºcksichtigt.  Im Originalartikel wird dieser Vektor als ID-Absatz bezeichnet. <br><br>  Dann wurde gem√§√ü einer solchen Vektordarstellung die logistische Regression untersucht, wobei jedes Dokument durch einen 10.000-dimensionalen Vektor dargestellt wurde.  Die Qualit√§tsbewertung wurde an einer Kreuzvalidierung von zehn Falten durchgef√ºhrt, sie wurde geschichtet, und es ist wichtig zu beachten, dass die logistische Regression f√ºr jede Klasse untersucht wurde und sechs Klassifizierungsprobleme separat gel√∂st wurden.  Am Ende war das Ergebnis eine Wahrscheinlichkeitsverteilung nach Klassen. <br><br>  Die logistische Regression wurde sehr lange trainiert.  Ich passte im Allgemeinen nicht in den RAM.  In Igor's Einrichtungen verbrachten sie einen Tag irgendwo, um das Ergebnis zu erhalten, wie auf einer Rutsche.  Aus diesem Grund haben wir uns aufgrund hoher Erwartungen sofort geweigert, Doc2vec zu verwenden, obwohl es um 1000 verbessert werden k√∂nnte, wenn ein Kommentar mit zus√§tzlicher Datenvorverarbeitung durchgef√ºhrt w√ºrde. <br><br><img src="https://habrastorage.org/webt/kt/0i/ks/kt0iksctnlf6kobgk1e0xnkomee.jpeg" width="700"><br><br>  Die intelligenteren, die wir und die anderen Wettbewerber verwendeten, waren wiederkehrende neuronale Netze.  Sie erhalten nacheinander W√∂rter am Eingang und aktualisieren ihren verborgenen Zustand nach jedem Wort.  Igor und ich haben das wiederkehrende GRU-Netzwerk f√ºr die Worteinbettung von fastText verwendet. Dies ist insofern besonders, als es viele unabh√§ngige Probleme bei der bin√§ren Klassifizierung l√∂st.  Prognostizieren Sie das Vorhandensein oder Fehlen des Kontextworts unabh√§ngig voneinander. <br><br>  Wir haben auch eine Qualit√§tsbewertung zur Kreuzvalidierung von zehn Falten durchgef√ºhrt, die hier nicht geschichtet wurde, und hier wurde die Wahrscheinlichkeitsverteilung sofort nach Klassen ermittelt.  Jedes Problem der bin√§ren Klassifikation wurde nicht separat gel√∂st, sondern es wurde sofort ein sechsdimensionaler Vektor erzeugt.  Es war eines der besten Einzelmodelle. <br><br>  Sie fragen, was war das Erfolgsgeheimnis? <br><br><img src="https://habrastorage.org/webt/aq/ik/nm/aqiknmpv8txoen1uollbhmy3iz8.jpeg" width="700"><br><br>  Es bestand aus Mischen, es gab viel davon, mit Stapeln und Vernetzen im Ansatz.  Der Netzwerkansatz muss als gerichteter Graph dargestellt werden. <br><br><img src="https://habrastorage.org/webt/uj/hl/9r/ujhl9rp1pse-y-0euvxutavnrpa.jpeg" width="700"><br><br>  Zu Beginn des Wettbewerbs bestand das DecisionGuys-Team aus zwei Personen.  Dann dr√ºckte Pavel Pleskov im ODS Slack-Kanal den Wunsch aus, sich mit jemandem aus den Top 200 zusammenzutun.  Zu dieser Zeit waren wir irgendwo auf dem 157. Platz und Pavel Pleskov auf dem 154. Platz, irgendwo in der Nachbarschaft.  Igor bemerkte seinen Wunsch mitzumachen und ich lud ihn ins Team ein.  Dann schloss sich Andrey Litvinov uns an, dann lud Pavel Gro√ümeister Alexei Noskov in unser Team ein.  Igor - Eugene.  Und der letzte Partner unseres Teams war der Bulgare Atanas Atanasov, und dies war das Ergebnis eines menschlichen internationalen Ensembles. <br><br>  Jetzt wird Igor Galitsky erz√§hlen, wie er gru unterrichtet hat, und ausf√ºhrlicher √ºber die Ideen und Ans√§tze von Pavel Pleskov, Andrei Litvinov und Atanas Atanasov sprechen. <br><br>  Igor Galitsky: <br>  - Ich bin Datenwissenschaftler bei Epoch8 und werde √ºber die meisten von uns verwendeten Architekturen sprechen. <br><br><img src="https://habrastorage.org/webt/l1/ah/jz/l1ahjzsk3hgrivbmffam4eb_9vy.jpeg" width="700"><br><br>  Alles begann mit dem Standard-Didirectional Gru mit zwei Ebenen, fast alle Teams verwendeten es, und fastText, die EL-Aktivierungsfunktion, wurde als Einbettung verwendet. <br><br>  Es gibt nichts Besonderes zu sagen, einfache Architektur ohne Schnickschnack.  Warum hat sie uns so gute Ergebnisse gebracht, mit denen wir einige Zeit in den Top 150 geblieben sind?  Wir hatten eine gute Vorverarbeitung des Textes.  Es war notwendig, weiterzumachen. <br><br><img src="https://habrastorage.org/webt/ni/ny/dx/ninydx6a2wsofsa-qdqncx904ou.jpeg" width="700"><br><br>  Paul hatte seinen eigenen Ansatz.  Nach dem Mischen mit unserem ergab sich ein deutlicher Anstieg.  Davor hatten wir eine Mischung aus Gruppe und Modell auf Doc2vec, es gab 61 LB. <br><br><img src="https://habrastorage.org/webt/hq/uk/lg/hquklgojqvgbhidth4gqgv5lctg.jpeg" width="700"><br><br>  Ich erz√§hle Ihnen von den Ans√§tzen von Atanas Atanasov, er ist direkt ein Enthusiast von neuen Artikeln.  Hier ist gru mit Aufmerksamkeit, alle Parameter auf der Folie.  Er hatte viele wirklich coole Ans√§tze, aber bis zum letzten Moment nutzte er seine Vorverarbeitung und alle Gewinne wurden ausgeglichen.  Geschwindigkeit auf der Rutsche. <br><br><img src="https://habrastorage.org/webt/1f/3w/_h/1f3w_hiemppymuwtyvt4xjd04so.jpeg" width="700"><br><br>  Dann gab es eine hierarchische Aufmerksamkeit, die noch schlechtere Ergebnisse zeigte, da es sich zun√§chst um ein Netzwerk zur Klassifizierung von Dokumenten handelte, die aus S√§tzen bestanden.  Er hat es vermasselt, aber der Ansatz ist nicht sehr. <br><br><img src="https://habrastorage.org/webt/dp/pn/su/dppnsuijdyfefmos-rmpecohrsu.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Es gab einen interessanten Ansatz, wir k√∂nnen zun√§chst von Anfang an und von Ende an Features aus dem Angebot erhalten.  Mit Hilfe von Faltungs- und Faltungsschichten erhalten wir Merkmale links und rechts vom Baum.  Dies ist vom Anfang bis zum Ende des Satzes, dann verschmelzen sie und laufen erneut durch gru. <br><br><img src="https://habrastorage.org/webt/j7/gp/vr/j7gpvrmt3s3tf04qidvcfobmzvs.jpeg" width="700"><br><br>  Auch Bi-GRU mit Aufmerksamkeitsblock.  Dies ist eines der besten auf privat war ein ziemlich tiefes Netzwerk, zeigte gute Ergebnisse. <br><br><img src="https://habrastorage.org/webt/d9/tw/_v/d9tw_v7n_nkvuxnxctppb2lvbyo.jpeg" width="700"><br><br>  Der n√§chste Ansatz besteht darin, Funktionen so weit wie m√∂glich hervorzuheben.  Nach der Schicht des wiederkehrenden Netzwerks machen wir drei weitere parallele Faltungsschichten.  Und hier haben wir nicht so lange S√§tze genommen, sie auf 250 gek√ºrzt, aber aufgrund von drei Windungen ergab dies ein gutes Ergebnis. <br><br><img src="https://habrastorage.org/webt/ft/hq/xy/fthqxy5pglwimem_-h46ieewheq.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Es war das tiefste Netzwerk.  Wie Atanas sagte, wollte er nur etwas Gro√ües und Interessantes lehren.  Als gew√∂hnliches Faltungsraster, das aus Textmerkmalen gelernt hat, sind die Ergebnisse nichts Besonderes. <br><br><img src="https://habrastorage.org/webt/pq/d6/eh/pqd6eh0_hxzqvb6hkwkjzkyws1u.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Dies ist ein ziemlich interessanter neuer Ansatz. 2017 gab es einen Artikel zu diesem Thema, der f√ºr ImageNet verwendet wurde. Dort konnten wir das vorherige Ergebnis um 25% verbessern.  Sein Hauptmerkmal ist, dass eine kleine Schicht parallel zum Faltungsblock gestartet wird, die die Gewichte f√ºr jede Faltung in diesem Block lehrt.  Sie ging sehr cool vor, obwohl sie die S√§tze gek√ºrzt hatte. <br><br>  Das Problem ist, dass die maximale L√§nge der S√§tze in diesen Aufgaben 1.500 W√∂rter erreichte, es gab sehr gro√üe Kommentare.  Andere Teams hatten auch Gedanken dar√ºber, wie sie dieses gro√üe Angebot einfangen und finden k√∂nnen, weil nicht alles sehr vorangetrieben ist.  Und viele sagten, dass es am Ende des Satzes eine sehr wichtige Infa gab.  Leider wurde dies bei all diesen Ans√§tzen nicht ber√ºcksichtigt, da der Anfang ber√ºcksichtigt wurde.  Vielleicht w√ºrde dies zu einer weiteren Steigerung f√ºhren. <br><br><img src="https://habrastorage.org/webt/mn/aq/om/mnaqomuiugd3p8_bpnrphhxrcmm.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Hier ist die AC-BLSTM-Architektur.  Die Quintessenz ist, dass, wenn die untere Unterteilung in zwei Teile zus√§tzlich zur Aufmerksamkeit ein kluges Ziehen ist, aber parallel dazu immer noch normal ist und dies alles konkretisiert wird.  Auch gute Ergebnisse. <br><br><img src="https://habrastorage.org/webt/tw/qa/-c/twqa-cw8om3ingxliha5wrf3brg.jpeg" width="700"><br><br>  Und Atanas sein ganzer Zoo von Models, dann war es eine coole Mischung.  Zus√§tzlich zu den Modellen selbst habe ich einige Textfunktionen hinzugef√ºgt, normalerweise L√§nge, Anzahl der Gro√übuchstaben, Anzahl der schlechten W√∂rter, Anzahl der Zeichen, alles hinzugef√ºgt.  Kreuzvalidierung von f√ºnf Falten und ausgezeichnete Ergebnisse auf privatem LB 0.9867. <br><br><img src="https://habrastorage.org/webt/jk/m-/ev/jkm-evezbsayfconwk3cc1uke2s.jpeg" width="700"><br><h5>  <sub><sup><a href="">Link</a></sup></sub> </h5><br>  Und beim zweiten Ansatz unterrichtete er mit einer anderen Einbettung, aber die Ergebnisse waren schlechter.  Meistens haben alle fastText verwendet. <br><br>  Ich wollte √ºber den Ansatz unseres anderen Kollegen Andrei mit dem Spitznamen Laol bei ODS sprechen.  Er hat viele √∂ffentliche Kernel unterrichtet, er hat sie getrunken, als w√§re er aus sich heraus, und das hat wirklich sehr coole Ergebnisse gebracht.  Sie k√∂nnten das alles nicht tun, aber nehmen Sie einfach ein paar verschiedene √∂ffentliche Kernel, selbst auf tf-idf gibt es alle Arten von gru-Konvolution√§ren. <br><br><img src="https://habrastorage.org/webt/re/gq/cg/regqcgtzm_teedu_brcisgw2hkw.jpeg" width="700"><br><h5>  <sub><sup><a href="">Link</a></sup></sub> </h5><br>  Er hatte einen der besten Ans√§tze, mit denen wir lange in den Top 15 blieben, bis Alexey und Atanas zu uns kamen, er kombinierte das Mischen und Stapeln von all dem.  Und auch ein sehr cooler Moment, den meines Wissens keines der Teams genutzt hat, haben wir dann auch Features aus den Ergebnissen der Organisator-API gemacht.  Dar√ºber erz√§hl Alex weiter. <br><br>  Alexey Noskov: <br>  - Hallo.  Ich erz√§hle Ihnen von dem Ansatz, den ich verwendet habe, und wie wir ihn abgeschlossen haben. <br><br><img src="https://habrastorage.org/webt/st/ol/im/stolimynmwutbmyfpce9qgmcvjg.jpeg" width="700"><br><br>  F√ºr mich war alles einfach genug: 10-fache Kreuzvalidierung, Modelle, die auf verschiedenen Vektoren mit unterschiedlicher Vorverarbeitung vorab trainiert wurden, damit sie mehr Vielfalt im Ensemble hatten, eine kleine Erweiterung und zwei Entwicklungszyklen.  Die erste, die im Grunde genommen am Anfang funktionierte, trainierte eine bestimmte Anzahl von Modellen, untersuchte Kreuzvalidierungsfehler, anhand welcher Beispiele offensichtliche Fehler auftreten, und korrigierte die Vorverarbeitung auf dieser Grundlage, da nur klarer ist, wie sie behoben werden k√∂nnen. <br><br>  Und der zweite Ansatz, der am Ende mehr verwendet wurde, lehrte einige Modelle, betrachtete Korrelationen, fand Bl√∂cke von Modellen, die schwach miteinander korreliert sind, und st√§rkte den Teil, der aus ihnen bestand.  Dies ist die Kreuzvalidierungskorrelationsmatrix zwischen meinen Modellen. <br><br><img src="https://habrastorage.org/webt/lu/e2/ul/lue2ullofbhfzn1v1x0zk92wam4.jpeg" width="700"><br><br>  Es ist ersichtlich, dass es an einigen Stellen eine Blockstruktur aufweist, w√§hrend einige Modelle von guter Qualit√§t waren, sie schwach mit den anderen korrelierten und sehr gute Ergebnisse erzielt wurden, als ich diese Modelle als Grundlage nahm und ihnen verschiedene Variationen beibrachte, die sich in verschiedenen unterscheiden Hyperparameter oder Vorverarbeitung und dann dem Ensemble hinzugef√ºgt. <br><br><img src="https://habrastorage.org/webt/r_/m3/5l/r_m35le0i7o8cujs5osoyq8t9h4.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Zur Erweiterung hat die Idee, die Pavel Ostyakov im Forum ver√∂ffentlicht hat, am meisten ausgel√∂st.  Es bestand darin, dass wir einen Kommentar aufnehmen, ihn in eine andere Sprache √ºbersetzen und dann zur√ºck k√∂nnen.  Durch die doppelte √úbersetzung wird eine Neuformulierung erhalten, etwas geht etwas verloren, aber insgesamt wird ein √§hnlicher, leicht unterschiedlicher Text erhalten, der auch klassifiziert werden kann und dadurch den Datensatz erweitert. <br><br>  Und der zweite Ansatz, der nicht so viel geholfen hat, aber auch geholfen hat, ist, dass Sie versuchen k√∂nnen, zwei willk√ºrliche Kommentare zu nehmen, die normalerweise nicht sehr lang sind, sie zu kleben und eine Kombination von Etiketten oder ein wenig Lust als Etikett auf das Ziel zu nehmen, wenn es nur eines gibt Sie enthielten ein Etikett. <br><br>  Beide Ans√§tze haben gut funktioniert, wenn sie nicht im Voraus auf den gesamten Satz angewendet wurden, sondern um die Beispiele zu √§ndern, auf die die Erweiterung in jeder Epoche angewendet werden sollte.  In jeder √Ñra, in der ein Stapel gebildet wird, w√§hlen wir beispielsweise 30% der Beispiele aus, f√ºr die √úbersetzungen verwendet werden.  Vielmehr w√§hlen wir im Voraus, irgendwo parallel, bereits im Speicher, einfach die Version f√ºr die √úbersetzung basierend darauf aus und f√ºgen sie w√§hrend des Trainings dem Stapel hinzu. <br><br><img src="https://habrastorage.org/webt/gp/84/92/gp8492suelagjk9stcprkcgdi_y.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erster Link</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zweiter Link</a></sup></sub> </h5><br>  Ein interessanter Unterschied waren die bei BPE trainierten Modelle.  Es gibt ein SentencePiece - einen Google-Tokenizer, mit dem Sie sich in Token aufteilen k√∂nnen, in denen es √ºberhaupt kein UNK gibt.  Ein begrenztes W√∂rterbuch, in dem eine Zeichenfolge in einige Token unterteilt ist.  Wenn die Anzahl der W√∂rter im realen Text gr√∂√üer als die Zielgr√∂√üe des W√∂rterbuchs ist, beginnen sie, in kleinere Teile zu zerfallen, und es wird ein Zwischenansatz zwischen den Modellen auf Zeichenebene und auf Wortebene erhalten. <br><br>  Dort werden zwei Hauptkonstruktionsalgorithmen verwendet: BPE und Unigram.  F√ºr den BPE-Algorithmus war es einfach genug, vorab trainierbare Einbettungen im Netzwerk zu finden, und mit einem festen Vokabular - ich hatte gerade ein gutes 50.000-Vokabular - konnte ich auch Modelle trainieren, die ein gutes (unh√∂rbares - ca. Ed.) Ergaben. als √ºblich auf fastText, aber sie waren sehr schwach mit allen anderen korreliert und gaben einen guten Schub. <br><br><img src="https://habrastorage.org/webt/ny/et/hs/nyeths5qlmvbeegudjhpi3jgrpy.jpeg" width="700"><br><br>  Dies ist ein klassisches Stapelschema.  In der Regel habe ich vor dem Kombinieren zum gr√∂√üten Teil des Wettbewerbs einfach alle meine Modelle ohne Gewichte gemischt.  Dies ergab die besten Ergebnisse.  Aber nach der Fusion konnte ich ein etwas komplexeres Schema bekommen, was am Ende einen guten Schub gab. <br><br><img src="https://habrastorage.org/webt/zg/vu/th/zgvuthkjtwku6kiaaexiagevq7s.jpeg" width="700"><br><br>  Ich hatte eine gro√üe Anzahl von Modellen.  Einfach alle in eine Art Stapler werfen?  Es hat nicht sehr gut funktioniert, er hat umgeschult, aber da die Modelle Gruppen waren, die ziemlich stark korreliert waren, habe ich sie einfach in diese Gruppen zusammengefasst. Innerhalb jeder Gruppe habe ich gemittelt und 5-7 Gruppen sehr √§hnlicher Modelle erhalten, von denen als Merkmale f√ºr Die n√§chste Ebene verwendete gemittelte Werte.  Ich habe LightGBM darauf trainiert, 20 Starts mit verschiedenen Beispielen abgeh√∂rt, ein bisschen Metafunktionalit√§t hochgeladen, √§hnlich wie Atanas, und am Ende hat es endlich funktioniert, was der einfachen Mittelwertbildung einen gewissen Schub verlieh. <br><br><img src="https://habrastorage.org/webt/of/vg/b0/ofvgb0ucc3da92cftyrou5ngvye.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a></sup></sub> </h5><br>  Vor allem habe ich die API hinzugef√ºgt, die Andrei gefunden hat und die einen √§hnlichen Satz von Labels enth√§lt.  Die Organisatoren bauten zun√§chst Modelle f√ºr sie.  Da es urspr√ºnglich anders war und die Teilnehmer es nicht verwendeten, war es unm√∂glich, es einfach mit denen zu vergleichen, die wir vorhersagen mussten.  Aber wenn es sich als Meta-Feature in ein gut funktionierendes Stacking st√ºrzen w√ºrde, w√ºrde es einen wunderbaren Schub geben, insbesondere in der TOXIC-Klasse, die anscheinend am schwierigsten in der Rangliste war und es uns erm√∂glichte, am Ende buchst√§blich am letzten Tag an mehrere Stellen zu springen . <br><br><img src="https://habrastorage.org/webt/g-/ip/8f/g-ip8f1wpu7jq35ilzgcbnuphhk.jpeg" width="700"><br><br>  Da wir vor den endg√ºltigen Einreichungen festgestellt haben, dass das Stapeln und die API f√ºr uns so gut funktionieren, hatten wir wenig Zweifel daran, wie gut dies auf privat portiert werden w√ºrde.  Es hat sehr verd√§chtig gut funktioniert, daher haben wir zwei Einreichungen nach dem folgenden Prinzip ausgew√§hlt: eine - eine Mischung aus Modellen ohne zuvor empfangene API sowie das Stapeln mit Metaphysik aus der API.  Hier stellte sich heraus, dass 0,9880 √∂ffentlich und 0,9874 privat waren.  Hier sind meine Noten verwirrt. <br><br><img src="https://habrastorage.org/webt/cg/d2/4o/cgd24objdrwraciizrqugzuf8t8.jpeg" width="700"><br><br>  Und die zweite ist eine Mischung aus Modellen ohne API, ohne Stacking und ohne LightGBM, da bef√ºrchtet wurde, dass dies eine Art geringf√ºgige Umschulung f√ºr die √ñffentlichkeit ist, und wir k√∂nnten damit losfliegen.  Es ist passiert, sie sind nicht weggeflogen und als Ergebnis haben wir mit dem Ergebnis von 0,9876 auf privat den zehnten Platz erreicht.  Das ist alles. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414993/">https://habr.com/ru/post/de414993/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414979/index.html">Bitcoin MAST Konzept</a></li>
<li><a href="../de414981/index.html">Ungeschriebene Bibliothek</a></li>
<li><a href="../de414983/index.html">Alan Kay: Was hat Xerox PARC so besonders gemacht und wer sieht heute noch so aus?</a></li>
<li><a href="../de414989/index.html">Weltraumm√ºllsatellit von ISS gestartet</a></li>
<li><a href="../de414991/index.html">Erkennung und Erkennung von Objekten von der Kamera in ROS mithilfe des Pakets find_object_2d</a></li>
<li><a href="../de414995/index.html">Amateurnotizen oder Die Geschichte, wie der Scala FPGA-Entwickler konfiguriert hat</a></li>
<li><a href="../de414997/index.html">ML-Blitz: Analyse der Aufgaben der ersten Qualifikationsrunde</a></li>
<li><a href="../de414999/index.html">3D Watchman und Thermistor Tester</a></li>
<li><a href="../de415001/index.html">Der Fahrer des Uber-Roboterautos, der einen Radfahrer abgeschossen hatte, sah sich zum Zeitpunkt der Kollision die Voice-Show an</a></li>
<li><a href="../de415003/index.html">Uneingeschr√§nkter Datei-Upload bei Apple.com</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
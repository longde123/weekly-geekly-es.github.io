<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍🏭 🥙 👨🏻‍🌾 AERODISK Engine: Catastrophic. Bagian 2. Metrocluster 🉑 🤲🏾 📕</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo pembaca Habr! Dalam artikel sebelumnya, kami berbicara tentang alat toleransi bencana sederhana dalam sistem penyimpanan ENERGI AERODISK - tentan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AERODISK Engine: Catastrophic. Bagian 2. Metrocluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/aerodisk/blog/460305/"><p><img src="https://habrastorage.org/webt/ft/el/xz/ftelxzp4fmlci1fn9endwmjffew.jpeg"></p><br><p>  Halo pembaca Habr!  Dalam artikel sebelumnya, kami berbicara tentang alat toleransi bencana sederhana dalam sistem penyimpanan ENERGI AERODISK - tentang replikasi.  Pada artikel ini, kita akan membahas topik yang lebih kompleks dan menarik - metro cluster, yaitu alat perlindungan bencana otomatis untuk dua pusat data, yang memungkinkan pusat data bekerja dalam mode aktif-aktif.  Kami akan memberi tahu, menunjukkan, merusak, dan memperbaikinya. </p><a name="habracut"></a><br><h2 id="kak-obychno-v-nachale-teoriya">  Seperti biasa, di awal teori </h2><br><p>  Cluster metro adalah kluster yang ditempatkan di beberapa situs dalam kota atau distrik.  Kata "cluster" jelas mengisyaratkan kepada kita bahwa kompleks itu otomatis, yaitu, beralih dari node cluster jika terjadi kegagalan secara otomatis. </p><br><p>  Di sinilah perbedaan utama antara kluster metro dan replikasi biasa.  Otomatisasi operasi.  Yaitu, dalam kasus insiden tertentu (kegagalan pusat data, saluran rusak, dll.), Sistem penyimpanan akan secara independen melakukan tindakan yang diperlukan untuk menjaga ketersediaan data.  Saat menggunakan replika biasa, tindakan ini dilakukan sepenuhnya atau sebagian secara manual oleh administrator. </p><br><h3 id="dlya-chego-eto-nuzhno">  Untuk apa ini? </h3><br><p> Tujuan utama yang dikejar pelanggan menggunakan satu atau beberapa implementasi dari metro cluster adalah untuk meminimalkan RTO (Recovery Time Objective).  Artinya, meminimalkan waktu pemulihan layanan TI setelah kegagalan.  Jika Anda menggunakan replikasi normal, waktu pemulihan akan selalu lebih lama dari waktu pemulihan dengan metro cluster.  Mengapa  Sangat sederhana.  Administrator harus berada di tempat kerja dan mengganti replikasi dengan tangan, dan cluster metro melakukan ini secara otomatis. </p><br><p>  Jika Anda tidak memiliki administrator khusus yang bertugas yang tidak tidur, makan, merokok atau sakit, dan melihat status penyimpanan 24 jam sehari, maka tidak ada cara untuk memastikan bahwa administrator akan tersedia untuk pengalihan manual selama kegagalan. </p><br><p>  Dengan demikian, RTO dengan tidak adanya metro cluster atau <del>  admin abadi level 99 </del>  Layanan administrator yang bertugas akan sama dengan jumlah waktu pengalihan semua sistem dan periode waktu maksimum setelah mana administrator dijamin untuk mulai bekerja dengan sistem penyimpanan dan sistem terkait. </p><br><p>  Dengan demikian, kami sampai pada kesimpulan yang jelas bahwa metro cluster harus digunakan jika persyaratan untuk RTO adalah menit, bukan jam atau hari, yaitu, ketika dalam kasus penurunan pusat data terburuk, departemen TI harus menyediakan waktu untuk mengembalikan akses ke TI kepada bisnis. -layanan dalam hitungan menit, atau bahkan detik. </p><br><h3 id="kak-eto-rabotaet">  Bagaimana cara kerjanya? </h3><br><p>  Di tingkat yang lebih rendah, kluster metro menggunakan mekanisme replikasi data sinkron, yang kami jelaskan di artikel sebelumnya (lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan</a> ).  Karena replikasi sinkron, persyaratan untuk itu sesuai, atau lebih tepatnya: </p><br><ul><li>  serat sebagai fisika, 10 gigabit Ethernet (atau lebih tinggi); </li><li>  jarak antara pusat data tidak lebih dari 40 kilometer; </li><li>  Keterlambatan saluran optik antara pusat data (antara sistem penyimpanan) hingga 5 milidetik (secara optimal 2). </li></ul><br><p>  Semua persyaratan ini bersifat penasehat, yaitu, kluster metro akan beroperasi walaupun persyaratan ini tidak terpenuhi, tetapi harus dipahami bahwa konsekuensi dari ketidakpatuhan terhadap persyaratan ini sama dengan perlambatan kedua sistem penyimpanan di kluster metro. </p><br><p>  Jadi, replika sinkron digunakan untuk mentransfer data antara sistem penyimpanan, dan bagaimana replika secara otomatis beralih, dan yang paling penting, bagaimana cara menghindari split-brain?  Untuk ini, pada level di atas, entitas tambahan digunakan - arbiter. </p><br><h3 id="kak-rabotaet-arbitr-i-v-chem-ego-zadacha">  Bagaimana cara wasit bekerja dan apa tugasnya? </h3><br><p>  Arbiter adalah mesin virtual kecil, atau kluster perangkat keras, yang harus dijalankan pada platform ketiga (misalnya, di kantor) dan menyediakan akses ke penyimpanan melalui ICMP dan SSH.  Setelah peluncuran, arbiter harus mengatur IP, dan kemudian dari sisi penyimpanan menunjukkan alamatnya, ditambah alamat pengendali jarak jauh yang berpartisipasi dalam cluster metro.  Setelah itu, wasit siap bekerja. </p><br><p>  Arbiter terus-menerus memonitor semua sistem penyimpanan di metro cluster dan, jika sistem penyimpanan tidak tersedia, setelah mengkonfirmasikan tidak dapat diaksesnya dari anggota cluster lain (salah satu sistem penyimpanan "langsung"), ia membuat keputusan untuk memulai prosedur untuk beralih aturan dan pemetaan replikasi. </p><br><p>  Poin yang sangat penting.  Arbiter harus selalu berada di situs yang berbeda dari yang di mana penyimpanan berada, yaitu, tidak di pusat data-1, di mana penyimpanan 1 berada, atau di pusat data-2, di mana penyimpanan 2 dipasang. </p><br><p>  Mengapa  Karena satu-satunya cara seorang wasit dengan bantuan salah satu sistem penyimpanan yang masih hidup dapat dengan jelas dan akurat menentukan jatuhnya salah satu dari dua situs di mana sistem penyimpanan dipasang.  Cara lain untuk menempatkan arbiter dapat menyebabkan otak terbelah. </p><br><h3 id="teper-pogruzimsya-v-detali-raboty-arbitra">  Sekarang selami rincian arbiter </h3><br><p>  Arbiter menjalankan beberapa layanan yang secara konstan diinterogasi oleh semua pengontrol penyimpanan.  Jika hasil survei berbeda dari yang sebelumnya (tersedia / tidak dapat diakses), maka dicatat dalam database kecil, yang juga berfungsi sebagai penengah. </p><br><p>  <strong>Pertimbangkan logika arbiter secara lebih rinci.</strong> </p><br><p>  <u>Langkah 1. Penentuan tidak dapat diaksesnya.</u>  Sinyal peristiwa tentang kegagalan sistem penyimpanan adalah tidak adanya ping dari kedua pengontrol sistem penyimpanan yang sama selama 5 detik. </p><br><p>  <u>Langkah 2. Mulai prosedur switching.</u>  Setelah arbiter memahami bahwa salah satu sistem penyimpanan tidak tersedia, ia mengirim permintaan ke sistem penyimpanan "langsung" untuk memastikan bahwa sistem penyimpanan "mati" benar-benar mati. </p><br><p>  Setelah menerima perintah seperti itu dari arbiter, sistem penyimpanan kedua (langsung) juga memeriksa ketersediaan sistem penyimpanan pertama yang jatuh dan, jika tidak, mengirimkan konfirmasi arbiter dari tebakannya.  Penyimpanan benar-benar tidak tersedia. </p><br><p>  Setelah menerima konfirmasi tersebut, arbiter memulai prosedur jarak jauh untuk mengalihkan replikasi dan meningkatkan pemetaan pada replika yang aktif (utama) pada penyimpanan yang dijatuhkan, dan mengirimkan perintah ke penyimpanan kedua untuk membuat replika ini dari sekunder ke primer dan meningkatkan pemetaan.  Nah, sistem penyimpanan kedua, masing-masing, melakukan prosedur ini, setelah itu memberikan akses ke LUN yang hilang dari dirinya sendiri. </p><br><p>  Mengapa saya perlu verifikasi tambahan?  Untuk kuorum.  Artinya, sebagian besar dari jumlah ganjil total (3) anggota cluster harus mengkonfirmasi jatuhnya salah satu node cluster.  Hanya dengan demikian keputusan ini akan tepat.  Ini diperlukan untuk menghindari pergantian yang salah dan, dengan demikian, otak terbelah. </p><br><p>  Langkah 2 dalam waktu memakan waktu sekitar 5 - 10 detik, jadi, dengan mempertimbangkan waktu yang diperlukan untuk menentukan tidak dapat diaksesnya (5 detik), dalam 10 - 15 detik setelah kecelakaan, LUN dengan penyimpanan yang jatuh akan secara otomatis tersedia untuk bekerja dengan penyimpanan langsung. </p><br><p>  Jelas bahwa untuk menghindari terputusnya host, Anda juga harus menjaga pengaturan timeout yang benar pada host.  Batas waktu yang disarankan setidaknya 30 detik.  Ini tidak akan memungkinkan host untuk memutuskan sambungan dari sistem penyimpanan selama transfer beban selama kecelakaan dan akan dapat menjamin bahwa tidak ada gangguan input-output. </p><br><blockquote>  Sebentar, ternyata, jika semuanya baik-baik saja dengan cluster metro, mengapa Anda perlu replikasi reguler? </blockquote><p>  Padahal, semuanya tidak sesederhana itu. </p><br><h3 id="rassmotrim-plyusy-i-minusy-metroklastera">  Pertimbangkan pro dan kontra dari kluster metro </h3><br><p>  Jadi, kami menyadari bahwa keuntungan nyata dari kluster metro dibandingkan dengan replikasi konvensional adalah: </p><br><ul><li>  Otomatisasi penuh memberikan waktu pemulihan minimum jika terjadi bencana; </li><li>  Dan hanya itu :-). </li></ul><br><p>  Dan sekarang, perhatian, kontra: </p><br><ul><li>  Biaya keputusan.  Meskipun cluster metro dalam sistem Aerodisk tidak memerlukan lisensi tambahan (lisensi yang sama digunakan untuk replika), biaya solusi masih akan lebih tinggi daripada menggunakan replikasi sinkron.  Penting untuk menerapkan semua persyaratan untuk replika sinkron, ditambah persyaratan untuk kluster metro yang terkait dengan peralihan tambahan dan situs tambahan (lihat perencanaan kluster metro); </li><li>  Kompleksitas keputusan.  Cluster metro jauh lebih kompleks daripada replika biasa, dan membutuhkan lebih banyak perhatian dan tenaga untuk perencanaan, konfigurasi, dan dokumentasi. </li></ul><br><p>  Pada akhirnya.  <strong>Metro cluster, tentu saja, solusi yang sangat teknologi dan baik ketika Anda benar-benar perlu menyediakan RTO dalam hitungan detik atau menit.</strong>  Tetapi jika tidak ada tugas seperti itu, dan RTO dalam hitungan jam tidak masalah untuk bisnis, maka tidak ada gunanya menembak burung pipit dari meriam.  Replikasi kerja-petani yang biasa sudah cukup, karena cluster metro akan mengeluarkan biaya tambahan dan menyulitkan infrastruktur TI. </p><br><h2 id="planirovanie-metroklastera">  Perencanaan Metro Cluster </h2><br><p>  Bagian ini tidak mengklaim sebagai panduan komprehensif untuk desain cluster metro, tetapi hanya menunjukkan arah utama yang harus dikerjakan jika Anda memutuskan untuk membangun sistem seperti itu.  Oleh karena itu, dengan implementasi aktual dari metro cluster, pastikan untuk melibatkan pabrik sistem penyimpanan (yaitu, kami) dan sistem terkait lainnya untuk konsultasi. </p><br><h3 id="ploschadki">  Platform </h3><br><p>  Seperti yang ditunjukkan di atas, minimal tiga situs diperlukan untuk kluster metro.  Dua pusat data, tempat sistem penyimpanan dan sistem terkait akan bekerja, serta platform ketiga tempat arbiter akan bekerja. </p><br><p>  Jarak yang disarankan antara pusat data tidak lebih dari 40 kilometer.  Jarak yang lebih besar cenderung menyebabkan penundaan tambahan, yang sangat tidak diinginkan dalam kasus cluster metro.  Ingat, penundaan harus mencapai 5 milidetik, meskipun diinginkan untuk memenuhi 2. </p><br><p>  Penundaan juga disarankan untuk diperiksa selama proses perencanaan.  Setiap penyedia dewasa yang kurang lebih menyediakan serat antara pusat data, pemeriksaan kualitas dapat diatur dengan cukup cepat. </p><br><p>  Adapun penundaan sebelum arbiter (yaitu, antara platform ketiga dan dua yang pertama), ambang batas yang disarankan hingga 200 milidetik, yaitu, koneksi VPN korporat reguler melalui Internet cocok. </p><br><h3 id="kommutaciya-i-set">  Switching dan Jaringan </h3><br><p>  Tidak seperti skema replikasi, di mana cukup untuk menghubungkan sistem penyimpanan dari situs yang berbeda, skema dengan metro cluster memerlukan penghubung host dengan kedua sistem penyimpanan di situs yang berbeda.  Untuk memperjelas perbedaannya, kedua skema tercantum di bawah ini. </p><br><p><img src="https://habrastorage.org/webt/qq/tg/x-/qqtgx-ze1zjj9fhbb7drzz6zabw.png"></p><br><p><img src="https://habrastorage.org/webt/l3/vs/es/l3vsesenlgm7lalbws0gdqhysuy.png"></p><br><p>  Seperti yang dapat Anda lihat dari diagram, host di situs 1 melihat SHD1 dan SHD 2. Selain itu, host platform 2 melihat SHD 2 dan SHD1.  Artinya, setiap host melihat kedua sistem penyimpanan.  Ini adalah prasyarat untuk pengoperasian kluster metro. </p><br><p>  Tentu saja, tidak perlu menarik setiap host dengan kabel optik ke pusat data yang berbeda, tidak ada port dan tali yang cukup.  Semua koneksi ini harus dilakukan melalui switch Ethernet 10G + atau FibreChannel 8G + (FC hanya untuk menghubungkan host dan penyimpanan untuk IO, saluran replikasi saat ini hanya tersedia melalui IP (Ethernet 10G +). </p><br><p>  Sekarang beberapa kata tentang topologi jaringan.  Poin penting adalah konfigurasi subnet yang benar.  Anda harus segera mengidentifikasi beberapa subnet untuk jenis lalu lintas berikut: </p><br><ul><li>  Subnet untuk replikasi di mana data antara sistem penyimpanan akan disinkronkan.  Mungkin ada beberapa, dalam hal ini tidak masalah, semuanya tergantung pada topologi jaringan saat ini (sudah diterapkan).  Jika ada dua dari mereka, maka jelas rute di antara mereka harus dikonfigurasi; </li><li>  Subnet penyimpanan tempat host akan mengakses sumber daya penyimpanan (jika iSCSI).  Harus ada satu subnet di setiap pusat data; </li><li>  Subnet kontrol, yaitu, tiga subnet yang dapat dirutekan di tiga lokasi dari mana manajemen penyimpanan dilakukan, dan ada juga seorang wasit. </li></ul><br><p>  Kami tidak mempertimbangkan subnet untuk mengakses sumber daya host di sini, karena mereka sangat bergantung pada tugas. </p><br><p>  Memisahkan lalu lintas yang berbeda ke dalam subnet yang berbeda sangat penting (sangat penting untuk memisahkan replika dari I / O), karena jika Anda mencampur semua lalu lintas menjadi satu subnet "tebal", maka lalu lintas ini tidak mungkin untuk dikendalikan, dan dalam kondisi dua pusat data masih dapat menyebabkan perbedaan opsi tumbukan jaringan.  Kami tidak akan membahas masalah ini banyak dalam kerangka artikel ini, karena Anda dapat membaca tentang perencanaan jaringan yang membentang antara pusat data tentang sumber daya dari produsen peralatan jaringan, di mana ia dijelaskan dengan sangat rinci. </p><br><h3 id="konfiguraciya-arbitra">  Konfigurasi Wasit </h3><br><p>  Arbiter harus menyediakan akses ke semua antarmuka manajemen penyimpanan melalui protokol ICMP dan SSH.  Anda juga harus mempertimbangkan toleransi kesalahan arbiter.  Ada nuansa. </p><br><p>  Toleransi kesalahan arbiter sangat diinginkan, tetapi opsional.  Dan apa yang terjadi jika wasit jatuh pada waktu yang salah? </p><br><ul><li>  Pengoperasian cluster metro dalam mode normal tidak akan berubah, karena  arbtir tidak mempengaruhi pengoperasian cluster metro dalam mode normal dengan cara apa pun (tugasnya adalah untuk mengalihkan beban di antara pusat data secara tepat waktu) </li><li>  Selain itu, jika arbiter karena satu dan lain alasan jatuh dan "membangunkan" kecelakaan di pusat data, maka tidak ada peralihan yang akan terjadi, karena tidak akan ada orang yang memberikan perintah yang diperlukan untuk beralih dan mengatur kuorum.  Dalam hal ini, metro cluster akan berubah menjadi skema replikasi reguler, yang harus diganti dengan tangan saat terjadi bencana, yang akan memengaruhi RTO. </li></ul><br><p>  Apa yang mengikuti dari ini?  Jika Anda benar-benar perlu memastikan RTO minimum, Anda harus memastikan toleransi kesalahan arbiter.  Ada dua opsi untuk ini: </p><br><ul><li>  Jalankan mesin virtual dengan arbiter pada hypervisor failover, karena semua hypervisor dewasa mendukung failover; </li><li>  Jika di situs ketiga (di kantor bersyarat) <del>  kemalasan untuk menempatkan cluster normal </del>  Karena tidak ada cluster hypervizor yang ada, kami telah menyediakan versi perangkat keras dari arbiter, yang dibuat dalam kotak 2U, di mana dua server x-86 biasa bekerja dan yang dapat bertahan dari kegagalan lokal. </li></ul><br><p>  Kami sangat merekomendasikan bahwa arbiter menjadi toleran terhadap kesalahan meskipun fakta bahwa cluster metro tidak memerlukannya dalam mode normal.  Namun baik teori maupun praktik menunjukkan bahwa jika Anda membangun infrastruktur tahan bencana yang benar-benar andal, maka lebih baik memainkannya dengan aman.  Lebih baik untuk melindungi diri Anda dan bisnis Anda dari "hukum kekejaman", yaitu, dari kegagalan arbiter dan salah satu situs di mana sistem penyimpanan berada. </p><br><h3 id="arhitektura-resheniya">  Arsitektur Solusi </h3><br><p>  Mempertimbangkan persyaratan di atas, kami memperoleh arsitektur solusi umum berikut. </p><br><p><img src="https://habrastorage.org/webt/di/wt/oq/diwtoqu2jdf7ik-nsigr4ypx37s.png"></p><br><p>  LUN harus didistribusikan secara merata di dua lokasi untuk menghindari kemacetan yang parah.  Pada saat yang sama, ketika ukuran di kedua pusat data, perlu untuk meletakkan tidak hanya volume ganda (yang diperlukan untuk menyimpan data secara bersamaan pada dua sistem penyimpanan), tetapi juga kinerja ganda di IOPS dan MB / s, untuk mencegah degradasi aplikasi jika terjadi kegagalan salah satu pusat data - Ov. </p><br><p>  Secara terpisah, kami mencatat bahwa dengan pendekatan yang tepat untuk ukuran (yaitu, asalkan kami telah memberikan batas atas yang tepat untuk IOPS dan MB / s, serta sumber daya CPU dan RAM yang diperlukan), jika salah satu sistem penyimpanan gagal di cluster metro, tidak akan ada penurunan kinerja yang serius di bawah pekerjaan sementara pada satu sistem penyimpanan. </p><br><p>  Hal ini disebabkan oleh kenyataan bahwa di bawah kondisi dua situs secara bersamaan, replikasi sinkron bekerja "makan" setengah dari kinerja perekaman, karena setiap transaksi harus ditulis ke dua sistem penyimpanan (mirip dengan RAID-1/10).  Jadi, jika salah satu sistem penyimpanan gagal, efek replikasi sementara (sampai sistem penyimpanan gagal naik) menghilang, dan kami mendapatkan peningkatan dua kali lipat dalam kinerja penulisan.  Setelah LUN sistem penyimpanan yang gagal dihidupkan kembali pada sistem penyimpanan yang berfungsi, peningkatan dua kali lipat ini menghilang karena beban dari LUN sistem penyimpanan lain, dan kami kembali ke tingkat kinerja yang sama dengan yang kami miliki sebelum "drop", tetapi hanya dalam kerangka satu platform. </p><br><p>  Dengan bantuan ukuran yang kompeten, dimungkinkan untuk memberikan kondisi di mana pengguna tidak akan merasakan kegagalan dari keseluruhan sistem penyimpanan sama sekali.  Tetapi sekali lagi, ini membutuhkan ukuran yang sangat hati-hati, untuk yang, kebetulan, Anda dapat menghubungi kami secara gratis :-). </p><br><h2 id="nastroyka-metroklastera">  Pengaturan Metro Cluster </h2><br><p>  Menyiapkan cluster metro sangat mirip dengan mengatur replikasi reguler, yang kami jelaskan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel sebelumnya</a> .  Karena itu, kami hanya fokus pada perbedaan.  Kami membuat dudukan di laboratorium berdasarkan arsitektur di atas, hanya dalam versi minimal: dua sistem penyimpanan yang dihubungkan oleh 10G Ethernet satu sama lain, dua sakelar 10G dan satu host yang memeriksa sakelar di kedua port penyimpanan dengan port 10G.  Arbiter berjalan di mesin virtual. </p><br><p><img src="https://habrastorage.org/webt/gy/-v/ci/gy-vci08eyyimjl6lwa2mciot8k.png"></p><br><p>  Saat mengatur IP virtual (VIP) untuk replika, pilih tipe VIP untuk cluster metro. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/ym/aw/89/ymaw89gofhplngagm5nvveg4oe0.png"></a> </p><br><p>  Kami membuat dua tautan replikasi untuk dua LUN dan mendistribusikannya di dua sistem penyimpanan: LUN TEST Primer pada SHD1 (tautan METRO), LUN TEST2 Primer pada SHD2 (tautan METRO2). </p><br><p><img src="https://habrastorage.org/webt/rz/7w/6e/rz7w6esdq4bued37xobjg1obcha.jpeg"></p><br><p>  Bagi mereka, kami menetapkan dua target identik (dalam kasus kami iSCSI, tetapi FC juga didukung, logika pengaturannya sama). </p><br><p>  SHD1: </p><br><p><img src="https://habrastorage.org/webt/d8/r-/dw/d8r-dw3gglptcowecdjabpewdve.jpeg"></p><br><p>  SHD2: </p><br><p><img src="https://habrastorage.org/webt/lf/ys/_6/lfys_6aohva42tp89ddqcjhakes.jpeg"></p><br><p>  Untuk koneksi replikasi, mereka membuat pemetaan pada setiap sistem penyimpanan. </p><br><p>  SHD1: </p><br><p><img src="https://habrastorage.org/webt/fw/qe/5q/fwqe5qqhcir_4rlbj3usmea1hgg.jpeg"></p><br><p>  SHD2: </p><br><p><img src="https://habrastorage.org/webt/rn/68/ap/rn68apxwkixmyh3dpv70vo-9pk8.jpeg"></p><br><p>  Multipath yang dikonfigurasi dan disajikan ke host. </p><br><p><img src="https://habrastorage.org/webt/gx/ii/wj/gxiiwjndb_fzeywc5hrxdfbqnrk.jpeg"></p><br><p><img src="https://habrastorage.org/webt/c6/df/5j/c6df5jjxnggdqk8wnjfbebb1rty.jpeg"></p><br><h3 id="nastraivaem-arbitra">  Konfigurasikan wasit </h3><br><p>  Anda tidak perlu melakukan sesuatu yang khusus dengan arbiter itu sendiri, Anda hanya perlu mengaktifkannya di platform ketiga, memberinya IP dan mengonfigurasi akses melalui ICMP dan SSH.  Konfigurasi itu sendiri dilakukan dari sistem penyimpanan itu sendiri.  Dalam hal ini, cukup untuk mengkonfigurasi arbiter sekali pada salah satu pengontrol penyimpanan di metro cluster, pengaturan ini akan didistribusikan ke semua pengontrol secara otomatis. </p><br><p>  Di bagian Replikasi Jarak Jauh &gt;&gt; Metrocluster (pada sembarang pengontrol) &gt;&gt; Konfigurasikan tombol. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/sy/h0/x-/syh0x-gywrz2yu8w9mk0us5mwcg.jpeg"></a> </p><br><p>  Kami memperkenalkan IP arbiter, serta antarmuka kontrol dari dua pengontrol sistem penyimpanan jarak jauh. </p><br><p><img src="https://habrastorage.org/webt/rs/u2/dt/rsu2dt3tt18k1it_qvmdsdnxldy.jpeg"></p><br><p>  Setelah itu, Anda harus mengaktifkan semua layanan (tombol "Restart Everything").  Jika terjadi konfigurasi ulang di masa mendatang, layanan harus dimulai ulang agar pengaturan dapat berlaku. </p><br><p><img src="https://habrastorage.org/webt/kj/sb/7u/kjsb7u9rrzlk6cttl7amr_ebxma.jpeg"></p><br><p>  Periksa apakah semua layanan berjalan. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/oh/mw/xl/ohmwxl5jry0dufgfamey0ddxris.jpeg"></a> </p><br><p>  <strong>Ini melengkapi pengaturan cluster metro.</strong> </p><br><h2 id="krash-test">  Tes kerusakan </h2><br><p>  Tes kerusakan dalam kasus kami akan sangat sederhana dan cepat, karena fungsi replikasi (switching, konsistensi, dll.) Dipertimbangkan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel sebelumnya</a> .  Oleh karena itu, untuk menguji keandalan cluster metro, cukup bagi kita untuk memeriksa otomatisasi deteksi kecelakaan, switching, dan tidak adanya kehilangan rekaman (I / O berhenti). </p><br><p>  Untuk melakukan ini, kami meniru kegagalan lengkap dari salah satu sistem penyimpanan dengan mematikan secara fisik kedua pengontrolnya, dengan mulai menyalin awal file besar ke LUN, yang harus diaktifkan pada sistem penyimpanan lainnya. </p><br><p><img src="https://habrastorage.org/webt/f-/lb/fo/f-lbfonzy8n4iawaihumetqtkmo.png"></p><br><p>  Nonaktifkan satu penyimpanan.  Pada sistem penyimpanan kedua, kita melihat peringatan dan pesan di log bahwa koneksi dengan sistem tetangga telah hilang.  Jika Anda telah mengkonfigurasi peringatan untuk pemantauan SMTP atau SNMP, maka administrator akan menerima peringatan yang sesuai. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/ae/jo/xv/aejoxv6piwk4fvl-nc1leklbxce.jpeg"></a> </p><br><p>  Tepat 10 detik kemudian (terlihat di kedua tangkapan layar), tautan replikasi METRO (yang merupakan Pratama pada sistem penyimpanan yang macet) secara otomatis menjadi Pratama pada sistem penyimpanan yang berjalan.  Dengan menggunakan pemetaan yang ada, LUN TEST tetap tersedia untuk tuan rumah, rekaman sedikit merosot (dalam 10 persen yang dijanjikan), tetapi tidak pecah. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/v_/gj/d9/v_gjd9sgoi5hwrgjdkwxwtdomeu.jpeg"></a> </p><br><p><img src="https://habrastorage.org/webt/ih/lq/rg/ihlqrgv7dq-4fv6dlnhair6nib4.jpeg"></p><br><p>  <strong>Tes selesai dengan sukses.</strong> </p><br><h2 id="podvodim-itog">  Untuk meringkas </h2><br><p>  Implementasi metrocluster saat ini dalam sistem penyimpanan Seri-A Engine AERODISK sepenuhnya memungkinkan penyelesaian masalah di mana perlu untuk menghilangkan atau meminimalkan waktu henti layanan TI dan memastikan operasi mereka 24/7/365 dengan biaya tenaga kerja minimal. </p><br><p>  , ,    ,      …       ,      ,    .      ,         ,        ,         . </p><br><p> ,   . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id460305/">https://habr.com/ru/post/id460305/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id460287/index.html">Visualisasi berita runet</a></li>
<li><a href="../id460291/index.html">Masalah pemrosesan batch permintaan dan solusinya (bagian 1)</a></li>
<li><a href="../id460295/index.html">Apa maksud tidak aman di Rust?</a></li>
<li><a href="../id460297/index.html">WeakRef - proposal untuk menambah standar skrip ECMAS</a></li>
<li><a href="../id460301/index.html">Lampu LED daya tinggi generasi baru</a></li>
<li><a href="../id460307/index.html">Pengalaman modeling dari tim Computer Vision Mail.ru</a></li>
<li><a href="../id460311/index.html">Saatnya teori uang baru</a></li>
<li><a href="../id460313/index.html">Apakah lagu hit yang berbeda memiliki kesamaan?</a></li>
<li><a href="../id460319/index.html">Perburuan Inspektur Luar Angkasa</a></li>
<li><a href="../id460321/index.html">Galeri notebook ML dan Data Science terbaik</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèø üë©üèº‚Äçüé§ üî® ¬øNecesita la tienda Stylish Crossell: la experiencia de Retail Rocket en an√°lisis de im√°genes para formular recomendaciones? ü§õüèΩ üë©üèø‚Äçüöí üõ¢Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El inter√©s en el an√°lisis de im√°genes para generar recomendaciones est√° creciendo cada d√≠a. Decidimos descubrir qu√© tan real trae este tema de tendenc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øNecesita la tienda Stylish Crossell: la experiencia de Retail Rocket en an√°lisis de im√°genes para formular recomendaciones?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/retailrocket/blog/441366/">  El inter√©s en el an√°lisis de im√°genes para generar recomendaciones est√° creciendo cada d√≠a.  Decidimos descubrir qu√© tan real trae este tema de tendencia.  Hablamos de probar el uso del aprendizaje profundo (Deep Learning) para mejorar las recomendaciones de productos relacionados. <br><br><img src="https://habrastorage.org/webt/nf/3h/1g/nf3h1gbxcrdaxxge_wmw3mkbvjo.jpeg"><br><br>  En este art√≠culo, describimos la experiencia de aplicar tecnolog√≠a de an√°lisis de im√°genes para mejorar el algoritmo de productos relacionados.  Puede leerlo de dos maneras: aquellos que no est√©n interesados ‚Äã‚Äãen los detalles t√©cnicos del uso de redes neuronales pueden saltarse los cap√≠tulos sobre la creaci√≥n de un conjunto de datos e implementar soluciones y pasar directamente a las pruebas AB y sus resultados.  Y aquellos que tienen una comprensi√≥n b√°sica de conceptos tales como incrustaciones, una capa de una red neuronal, etc., estar√°n interesados ‚Äã‚Äãen todo el material. <a name="habracut"></a><br><br><h2>  Aprendizaje profundo en el contexto del an√°lisis de im√°genes </h2><br>  En nuestra pila de tecnolog√≠a, Deep Learning se utiliza con bastante √©xito para resolver algunos problemas.  Durante alg√∫n tiempo no nos atrevimos a aplicarlo en el contexto del an√°lisis de im√°genes, pero recientemente aparecieron varias premisas que nos hicieron cambiar de opini√≥n: <br><br><ul><li>  mayor inter√©s de la comunidad en el an√°lisis de im√°genes utilizando m√©todos de aprendizaje profundo; </li><li>  se defini√≥ un c√≠rculo de marcos "maduros" y redes neuronales pre-entrenadas, desde el cual se pod√≠a comenzar de manera bastante r√°pida y simple; </li><li>  El an√°lisis de im√°genes en los sistemas de recomendaci√≥n a menudo se ha utilizado como una caracter√≠stica de marketing que garantiza mejoras "sin precedentes"; </li><li>  Las necesidades alimentarias comenzaron a aparecer en este tipo de investigaci√≥n. </li></ul><br>  En el contexto de la intersecci√≥n de los sistemas de recomendaci√≥n y el an√°lisis de im√°genes, puede haber muchas aplicaciones de aprendizaje profundo, sin embargo, en la primera etapa, identificamos por nosotros mismos tres formas principales de desarrollar esta √°rea: <br><br><ol><li>  Una mejora general en la calidad de las recomendaciones, por ejemplo, productos relacionados para un vestido, es m√°s cualitativamente adecuada en color y estilo. </li><li>  Encontrar productos en la base de productos de una tienda usando una fotograf√≠a (Recuperaci√≥n en la tienda) es un mecanismo que le permite encontrar productos en la base de datos de una tienda usando una foto cargada. </li><li> Determinaci√≥n de las propiedades / atributos del producto a partir de la foto (Etiquetado de atributos), cuando los atributos significativos se determinan a partir de la foto, por ejemplo, el tipo de producto: una camiseta, chaqueta, pantal√≥n, etc. </li></ol><br>  La direcci√≥n m√°s prioritaria y prometedora para nosotros es la primera opci√≥n, y decidimos explorarla. <br><br><h3>  ¬øPor qu√© elegiste un algoritmo para productos relacionados? </h3><br>  Cualquier sistema de recomendaci√≥n tiene dos algoritmos b√°sicos de productos est√°ticos: alternativas y productos relacionados.  Y si todo est√° claro con las alternativas: estos son productos similares al modelo original (por ejemplo, diferentes tipos de camisas), entonces, con productos relacionados, todo es mucho m√°s complicado.  Aqu√≠ es importante no equivocarse con la correspondencia entre los productos b√°sicos y recomendados, por ejemplo, el cargador debe ajustarse al tel√©fono, el color del vestido a los zapatos, etc .;  debe tener en cuenta los comentarios, por ejemplo, no recomiende un tel√©fono al cargador, a pesar de que se compran juntos;  y pensar en un mont√≥n de otros matices que surgen en la pr√°ctica.  En gran parte debido a la presencia de varios matices, nuestra elecci√≥n recay√≥ en productos relacionados.  Adem√°s, solo en productos relacionados es posible formar un aspecto completo, si hablamos del segmento de la moda. <br><br><blockquote>  Formulamos nuestro principal objetivo de investigaci√≥n como "Comprender si el algoritmo actual para productos relacionados puede mejorarse significativamente utilizando m√©todos de aprendizaje profundo para el an√°lisis de im√°genes" </blockquote><br>  Noto que antes de eso no usamos la informaci√≥n de la imagen para calcular las recomendaciones del producto, y aqu√≠ est√° el por qu√©: <br><br><ul><li>  Durante la existencia de la plataforma Retail Rocket, hemos adquirido una gran experiencia en el campo de las recomendaciones de productos.  Y la conclusi√≥n principal que recibimos durante este tiempo es que el uso correcto del comportamiento del usuario proporciona casi el 90% del resultado.  S√≠, existe el problema de un arranque en fr√≠o, cuando las cosas de contenido, como la informaci√≥n sobre la imagen, pueden aclarar o mejorar las recomendaciones, pero en la pr√°ctica este efecto es mucho menor de lo que dicen en teor√≠a.  Por lo tanto, no ponemos mucho √©nfasis en las fuentes de informaci√≥n de contenido. </li><li>  Para crear recomendaciones de productos en forma de informaci√≥n de contenido, utilizamos elementos como el precio, la categor√≠a, la descripci√≥n y otras propiedades que la tienda nos pasa.  Estas propiedades son independientes de la esfera y se validan cualitativamente al integrar nuestro servicio.  El valor de la imagen, por el contrario, surge de hecho solo en el segmento de art√≠culos de moda. </li><li>  Mantener el servicio de trabajar con im√°genes, validar su calidad y conformidad con los productos es un proceso bastante complicado y un deber t√©cnico serio en el que no quer√≠a incurrir sin confirmar la necesidad. </li></ul><br>  Sin embargo, decidimos dar una oportunidad a las im√°genes y ver c√≥mo afectar√°n la efectividad de las recomendaciones de construcci√≥n.  Nuestro enfoque no es ideal, seguro que alguien resolver√≠a el problema de manera diferente.  El objetivo de este art√≠culo es presentar nuestro enfoque con una descripci√≥n de los argumentos en cada paso y presentar los resultados al lector. <br><br><h2>  Formaci√≥n del concepto </h2><br>  Comenzamos cruzando los tres componentes de cualquier producto: tecnolog√≠a asequible, recursos disponibles y necesidades del cliente.  El concepto de "mejorar las recomendaciones a trav√©s de la informaci√≥n sobre la imagen de productos relacionados" se ha desarrollado por s√≠ mismo.  La implementaci√≥n "ideal" de este producto se form√≥ como un problema compilado en la imagen de un aspecto seleccionado.  Adem√°s, tales recomendaciones no solo deber√≠an verse bien, sino que tambi√©n deber√≠an funcionar desde el punto de vista de las m√©tricas b√°sicas de comercio electr√≥nico (Conversi√≥n, RPV, AOV) no peor que nuestro algoritmo b√°sico. <br><br>  Look es una imagen elegida por los estilistas, que incluye un conjunto de cosas diferentes que se combinan entre s√≠, por ejemplo, un vestido, chaqueta, bolso, cintur√≥n, etc.  Del lado de nuestros clientes, dicho trabajo generalmente lo realizan personas especialmente designadas cuyo trabajo est√° mal automatizado.  Despu√©s de todo, no todas las redes neuronales pueden tener sentido del gusto. <br><br><img src="https://habrastorage.org/webt/xk/n7/98/xkn798q47nkdwvi_cgowffdl7n4.png" width="400"><br>  <i>Una imagen de ejemplo (look).</i> <br><br>  Inmediatamente hubo restricciones en el uso de la informaci√≥n de la imagen; de hecho, la aplicaci√≥n se encontr√≥ solo en el segmento de la moda. <br><br><h2>  Infraestructura y conjunto de datos </h2><br>  En primer lugar, planteamos un banco de pruebas para experimentos y creaci√≥n de prototipos.  Aqu√≠ todo es GPU + Python + Keras bastante est√°ndar, por lo que no entraremos en detalles.  Encontramos un conjunto de datos de alta calidad que fue dise√±ado para resolver varios problemas a la vez, desde la predicci√≥n de los atributos de la imagen hasta la generaci√≥n de nuevas texturas de ropa.  Lo que fue especialmente importante para nosotros, inclu√≠a fotograf√≠as que constitu√≠an pr√°cticamente una sola mirada.  Adem√°s, el conjunto de datos inclu√≠a fotograf√≠as de modelos de ropa desde diferentes √°ngulos, que intentamos usar en la primera etapa. <br><br><img src="https://habrastorage.org/webt/-5/eh/hb/-5ehhbydvhgpjz5akabwleuofaq.png"><br>  <i>Ejemplo de un conjunto de datos.</i> <br><br><img src="https://habrastorage.org/webt/s_/xh/ia/s_xhia1hvgbeod61q93u1ft0sl0.png"><br>  <i>Ejemplos de im√°genes del mismo modelo de ropa desde diferentes √°ngulos.</i> <br><br><h2>  Primeros pasos </h2><br>  La primera idea de implementar el producto final utilizando el conjunto de datos fue bastante simple: ‚ÄúReduzcamos el problema a la tarea de reconocer la ropa por imagen.  Por lo tanto, al formular recomendaciones, "levantaremos" aquellas recomendaciones que son similares al producto b√°sico ".  En consecuencia, se supon√≠a que deb√≠a encontrar la funci√≥n de "proximidad" de los bienes y, en el camino, resolver el problema de eliminar alternativas en el tema. <br><br>  Debo decir de inmediato que este tipo de problema podr√≠a resolverse usando una red neuronal pre-entrenada convencional, como ResNet-50.  De hecho: eliminamos la √∫ltima capa, obtenemos incrustaciones, bueno, y luego el coseno, como una medida de "proximidad".  Sin embargo, despu√©s de experimentar un poco con este enfoque, decidimos dejarlo principalmente por tres razones. <br><br><ol><li>  No est√° muy claro c√≥mo interpretar correctamente la proximidad resultante.  Lo que se dice coseno = 0.7 en el dominio de las camisetas, donde por regla general todo es muy similar entre s√≠ y lo que es coseno = 0.5 en el dominio de las chaquetas, donde las diferencias son m√°s significativas.  Necesit√°bamos este tipo de interpretaci√≥n para eliminar simult√°neamente productos muy cercanos: alternativas. </li><li>  Este enfoque nos limit√≥ un poco desde el punto de vista de la educaci√≥n adicional para nuestras tareas espec√≠ficas.  Por ejemplo, las caracter√≠sticas importantes que forman una imagen hol√≠stica no siempre son las mismas de un dominio a otro.  En alguna parte, el color y la forma son m√°s importantes, pero en alguna parte el material y su textura.  Adem√°s, quer√≠amos capacitar a la red para cometer menos errores de g√©nero cuando se recomienda a las mujeres para la ropa de los hombres.  Tal error es inmediatamente evidente y debe encontrarse tan raramente como sea posible.  Con el simple uso de redes neuronales pre-entrenadas, parec√≠a que est√°bamos un poco limitados por la incapacidad de proporcionar ejemplos que son bien "similares" en t√©rminos de imagen. </li><li>  El uso de las redes siamesas, que son m√°s adecuadas para estas tareas, parec√≠a ser una opci√≥n m√°s natural y mejor estudiada. </li></ol><br><h2>  Un poco sobre la red neuronal siamesa </h2><br>  Las redes neuronales siamesas se utilizan ampliamente para resolver tareas relacionadas con el reconocimiento facial.  En la entrada, se proporciona una imagen de la persona, en la salida, el nombre de la persona de la base de datos a la que pertenece.  Tal problema se puede resolver directamente, si usa softmax y el n√∫mero de clases igual al n√∫mero de personas reconocibles en la √∫ltima capa de la red neuronal.  Sin embargo, este enfoque tiene varias limitaciones: <br><br><ul><li>  necesitas tener una cantidad suficientemente grande de im√°genes para cada clase, lo cual es pr√°cticamente imposible. </li><li>  una red neuronal de este tipo tendr√° que volverse a entrenar cada vez que se agregue una nueva persona a la base de datos, lo cual es muy inconveniente. </li></ul><br>  Una soluci√≥n l√≥gica en tal situaci√≥n ser√≠a obtener la funci√≥n de "similitud" de las dos fotos para responder en cualquier momento si las dos fotos, suministradas a la entrada de la red neuronal y la referencia de la base de datos, pertenecen a la misma persona y, en consecuencia, resuelven el problema del reconocimiento facial.  Esto es m√°s consistente con el comportamiento de una persona.  Por ejemplo, un guardia mira la cara de una persona y una foto en una placa y responde a la pregunta de si esa persona es una o no.  La red neuronal siamesa implementa un concepto similar. <br><br>  El componente principal de la red neuronal siamesa es la red neuronal troncal, que genera una incrustaci√≥n de im√°genes.  Esta incrustaci√≥n se puede utilizar para determinar el grado de similitud entre las dos im√°genes.  En la arquitectura de la red neuronal siamesa, el componente principal se usa dos veces, cada vez para recibir la incrustaci√≥n de la imagen.  El investigador necesita mostrar los valores de salida 0 o 1, dependiendo de si una o diferentes personas son propietarias de las fotos, y ajustar la red neuronal de la red troncal. <br><br><img src="https://habrastorage.org/webt/4u/fu/od/4ufuodzpu2yt5dkkktpgvogwug4.png"><br>  <i>Un ejemplo de una red neuronal siamesa.</i>  <i>Las incrustaciones de las im√°genes superior e inferior se obtienen de la columna vertebral de la red neuronal.</i>  <i>Imagen tomada del curso "Redes neuronales convolucionales" de Andrey Ng.</i> <br><br><h2>  Soluci√≥n b√°sica </h2><br>  Por lo tanto, despu√©s de algunos experimentos, la primera versi√≥n del algoritmo fue la siguiente: <br><br><ol><li>  Tomamos cualquier red neuronal pre-entrenada como columna vertebral.  Experimentamos con ResNet-50 e InceptionV3.  Seleccionado en funci√≥n del equilibrio del tama√±o de la red y la precisi√≥n de las predicciones.  Nos centramos en los datos presentados en la documentaci√≥n oficial de la secci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Keras</a> "Documentaci√≥n para modelos individuales". </li><li>  Creamos una red siamesa sobre la base y utilizamos la p√©rdida de triplete para el entrenamiento. </li><li>  Como ejemplos positivos, servimos la misma imagen, pero desde un √°ngulo diferente.  Como ejemplo negativo, estamos sirviendo otro producto. </li><li>  Con un modelo entrenado, obtenemos la m√©trica de proximidad para cualquier par de productos de la misma manera que se considera la p√©rdida de triplete. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nt/x4/bp/ntx4bphenliyspt0fgwmmzgsu-e.png"></div><br>  <i>C√≥digo de c√°lculo de p√©rdida de triplete.</i> <br><br>  El acuerdo con Triplet Loss en un proyecto real fue la primera vez, lo que cre√≥ una serie de dificultades.  Al principio, lucharon durante mucho tiempo con el hecho de que las incrustaciones recibidas se redujeron a un punto.  Hubo varias razones: no normalizamos las incrustaciones antes de calcular la p√©rdida;  margen el par√°metro alfa era demasiado peque√±o y los ejemplos demasiado dif√≠ciles.  La normalizaci√≥n y las incorporaciones a√±adidas comenzaron a variar.  El segundo problema inesperadamente se convirti√≥ en Gradient Exploding.  Afortunadamente, Keras hizo posible resolver este problema de manera bastante simple: agregamos clipnorm = 1.0 al optimizador, lo que no permiti√≥ que los gradientes crecieran durante el entrenamiento. <br><br>  El trabajo fue iterativo: capacitamos al modelo, bajamos la p√©rdida, observamos el resultado final y decidimos por expertos en qu√© direcci√≥n √≠bamos.  En alg√∫n momento, qued√≥ claro que de inmediato establecemos ejemplos bastante complejos y que la complejidad no cambia en el proceso de aprendizaje, lo que afecta negativamente el resultado final.  Afortunadamente, el conjunto de datos con el que trabajamos ten√≠a una buena estructura de √°rbol que reflejaba el producto en s√≠, por ejemplo, Hombres -&gt; Pantalones, Hombres -&gt; Su√©teres, etc.  Esto nos permiti√≥ rehacer el generador y comenzamos a dar ejemplos "f√°ciles" para las primeras eras, luego las m√°s complejas y as√≠ sucesivamente.  Los ejemplos m√°s dif√≠ciles son productos de la misma categor√≠a de productos, por ejemplo Pantalones, como negativos. <br><br>  Como resultado, obtuvimos un modelo que difer√≠a en su salida de la metodolog√≠a "ingenua" para usar ResNet-50.  Sin embargo, la calidad de las recomendaciones finales no nos satisfizo completamente.  En primer lugar, hubo un problema con los errores de g√©nero, pero se entendi√≥ c√≥mo se podr√≠a resolver.  Dado que el conjunto de datos dividi√≥ la ropa en hombres y mujeres, fue f√°cil recopilar ejemplos negativos para el entrenamiento.  En segundo lugar, al entrenar en el conjunto de datos el resultado final, verificamos visualmente a nuestros clientes; de inmediato qued√≥ claro que era necesario volver a entrenar sus ejemplos, ya que para algunos el algoritmo funcion√≥ muy mal si los productos no se superpon√≠an bien con lo que se mostr√≥ durante el entrenamiento .  Finalmente, la calidad era a menudo deficiente, porque la imagen del entrenamiento a menudo era ruidosa y conten√≠a, por ejemplo, no solo jeans, sino tambi√©n una camiseta. <br><br><img src="https://habrastorage.org/webt/qn/jk/qd/qnjkqdhwqeu_p__3xvztofsmvny.png"><br>  <i>La imagen de jeans en la que, de hecho, tambi√©n muestra una camiseta y botas.</i> <br><br>  La primera experiencia sirvi√≥ de base para la soluci√≥n posterior, aunque no comenzamos de inmediato a implementar un modelo mejorado. <br><br><img src="https://habrastorage.org/webt/u8/ho/bi/u8hobio7yfpawxdbgyulgy-g5r4.png"><br>  <i>Un ejemplo de recomendaciones basadas en una soluci√≥n b√°sica.</i>  <i>Hay errores de g√©nero, tambi√©n surgen alternativas.</i> <br><br><h2>  Modelo mejorado </h2><br>  Comenzamos entrenando ResNet-50 sobre los datos de nuestro conjunto de datos.  El conjunto de datos contiene informaci√≥n sobre lo que se muestra en la imagen.  Se extrae de la estructura del conjunto de datos Hombres -&gt; Pantalones, Mujeres -&gt; C√°rdigans y m√°s.  Este procedimiento se realiz√≥ por dos razones: en primer lugar, quer√≠an "dirigir" la columna vertebral: una red neuronal al dominio de la ropa;  En segundo lugar, dado que la ropa tambi√©n se divide por g√©nero, esperaban deshacerse del problema de los errores de g√©nero que se encontraron en la primera versi√≥n. <br><br>  En la segunda etapa, tratamos de eliminar simult√°neamente el ruido de las im√°genes de entrada y obtener pares positivos de productos relacionados para capacitaci√≥n adicional.  El conjunto de datos que utilizamos tambi√©n est√° dise√±ado para resolver el problema de detectar objetos en la imagen.  En otras palabras, para cada imagen hay: las coordenadas del rect√°ngulo que describe el objeto y su clase.  Para resolver este tipo de problema, utilizamos un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">proyecto listo para</a> usar.  Este proyecto utiliza la arquitectura de red neuronal RetinaNet utilizando una p√©rdida focal especial.  La esencia de esta p√©rdida es enfocarse m√°s no en el fondo de la imagen, que est√° en casi todas las im√°genes, sino en el objeto que necesita ser detectado.  Como columna vertebral de una red neuronal para el entrenamiento, utilizamos nuestra red pre-entrenada ResNet-50. <br>  Como resultado, se detectan tres clases de objetos en cada imagen del conjunto de datos: "arriba", "abajo" y "vista general".  Despu√©s de definir las clases "superior" e "inferior", simplemente cortamos la imagen en dos im√°genes separadas, que luego se utilizar√°n como un par de ejemplos positivos para calcular la p√©rdida de triplete.  La calidad de detecci√≥n de objetos result√≥ ser bastante alta, la √∫nica queja era que no siempre era posible encontrar una clase en la imagen.  Esto no fue un problema para nosotros, ya que pod√≠amos aumentar f√°cilmente el n√∫mero de im√°genes para las predicciones. <br><br><img src="https://habrastorage.org/webt/re/t2/bl/ret2blikjezyoibdvno8w9f8nic.png"><br>  <i>Un ejemplo de detectar las clases "arriba" y "abajo" y cortar la imagen.</i> <br><br>  Al tener este tipo de divisor de im√°genes, tuvimos la oportunidad de echar un vistazo a Internet y dividirlo en componentes para usar en la capacitaci√≥n.  Para aumentar la muestra de capacitaci√≥n y vencer el problema con una cobertura insuficiente de ejemplos que surgieron durante el desarrollo de la soluci√≥n b√°sica, ampliamos el conjunto de datos debido a las im√°genes "cortadas" de uno de nuestros clientes.  El √∫nico problema era que no distingu√≠amos objetos como "accesorio", "tocado", "zapatos", etc.  Esto cre√≥ algunas limitaciones, pero fue bastante adecuado para probar el concepto.  Despu√©s de recibir resultados positivos, planeamos expandir el modelo a las clases descritas anteriormente. <br><br>  Habiendo recibido un conjunto de datos extendido, utilizamos la metodolog√≠a ya probada para construir la red siamesa a partir de una soluci√≥n b√°sica, aunque hubo varias diferencias.  En primer lugar, como la columna vertebral de la red neuronal, utilizamos la red ResNet-50 ahora capacitada descrita anteriormente.  En segundo lugar, ahora, como ejemplos positivos, hemos presentado pares de arriba a abajo y viceversa, permiti√©ndonos aprender de la red neuronal exactamente la "correspondencia" de la imagen.  Bueno, en realidad una docena de √©pocas m√°s tarde, apareci√≥ un mecanismo que nos dio la oportunidad de evaluar la "conformidad" de los productos con una sola imagen. <br><br><img src="https://habrastorage.org/webt/zt/ey/ic/zteyicg29iuubwu7y8adm8id7xm.png"><br>  <i>Un ejemplo de recomendaciones basadas en el uso de una red neuronal.</i>  <i>Se recomiendan pantalones cortos para el producto b√°sico; se recomiendan camisetas.</i> <br><br>  El resultado final nos agrad√≥: las recomendaciones resultaron ser visualmente de buena calidad y, lo que es especialmente bueno, su construcci√≥n no requiri√≥ ning√∫n historial de interacciones del usuario.  Sin embargo, los problemas persistieron, el principal fue la disponibilidad de alternativas en la extradici√≥n.  Entonces encontr√© extradiciones en las que el "fondo" se recomendaba al "fondo", lo mismo sucedi√≥ con la categor√≠a "superior".  Esto nos hizo pensar y refinar la soluci√≥n para eliminar alternativas. <br><br><h2>  Eliminar alternativas </h2><br>  Para resolver el problema de la disponibilidad de alternativas, la emisi√≥n fue bastante r√°pida.  Los experimentos iniciales con el ResNet-50 "vainilla" ayudaron.  Tal red neuronal dio como bienes "similares" a los que m√°s coincid√≠an en la imagen, de hecho, alternativas.  Es decir, podr√≠a usarse para identificar alternativas. <br><br><img src="https://habrastorage.org/webt/-0/u_/qj/-0u_qj7rrnciudumospo75ff9co.png"><br>  <i>Un ejemplo de recomendaciones basadas en el ResNet-50 "vainilla".</i>  <i>Los bienes son alternativas.</i> <br><br>  Usando esta √∫til propiedad de ResNet-50, comenzamos a filtrar los productos lo m√°s cerca posible de la emisi√≥n, eliminando as√≠ las alternativas.  Tambi√©n hubo desventajas en este enfoque: la misma situaci√≥n incomprensible con la que elegir el umbral para el filtrado.  A veces se filtraron muchos productos, a pesar de que externamente no eran alternativas.  Sin embargo, no nos centramos en este problema y seguimos trabajando m√°s. <br><br><h2>  Preparaci√≥n de pruebas AB </h2><br>  Para la verificaci√≥n final de pr√°cticamente cualquier cambio en los algoritmos, utilizamos ampliamente la herramienta de prueba AB.  Adem√°s, solo tenemos una regla: "no importa cu√°n peque√±a sea la p√©rdida, no importa cu√°n compleja y de m√∫ltiples capas sea la red neuronal, cu√°n hermosas pueden ser las recomendaciones; todo esto no se tiene en cuenta si no hay resultados en la prueba AB".  La l√≥gica es bastante simple: una prueba AB es la m√°s honesta, comprensible para todas las partes (especialmente clientes y empresas) y un m√©todo preciso para medir el resultado.    Retail Rocket     -         (       ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">  A/-   99%  -  ?</a> ¬ª).     -     . <br><br>                -.  ,              <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RecSys 2016</a> .               . ,    ,    ,         ,       .  ,   -   ,   . <br><br>          ,   .           ,       .         ,      .        -      . ,     ,    ,   ,  -    .        :              . <br><br>   -    ,      . -,    ,   ,     ,      . -,  ‚Äî  ,   ,    ,   ,         . ,        . ,     ,  ,    ‚Äú¬ª,   . <br><br>   : <br><br><ul><li>            ‚Äú‚Äù  ‚Äú‚Äù,       , ,  ,   . ,     ,      ,       . </li><li>        ,       .     proof-of-concept    ,        . </li></ul><br>      ,         ,       . ,         ,       . <br><br><h2>  AB- </h2><br>  ,    ,   -    .   ‚Äî      fashion.          .  ,          ,       .    ,    ,        . <br><br>      .      3 .         ,          95%. <br><br><img src="https://habrastorage.org/webt/a1/d2/u3/a1d2u3lfxuxejt-u-0e0is8tfj0.png"><br> <i>  . Related-9 ‚Äî   ‚Äú‚Äù  , Related ‚Äî    .</i> <br><br><img src="https://habrastorage.org/webt/ue/vf/lm/uevflmd-birf3m_bcryiyq1vp5m.png"><br> <i>   . Related-9   ‚Äú‚Äù  .         : Mann-Whitney Test  Bootstrap.       97%.</i> <br><br>            :    .      ,    ,  ,    ‚Äú‚Äù    CTR. ,  ,    CTR   ,      .  -    ,   -       -   ,        -.     ,       . <br><br><img src="https://habrastorage.org/webt/rz/lc/in/rzlcinclsxpuxr8olu3uvdihzcu.png" width="400"><br> <i>  CTR.     .   CTR  Related-9,   ‚Äú‚Äù  , ()   Related ‚Äî   (). CTR     (  ) ‚Äî    95%.</i> <br><br>  ,    ,   ,     ,   .      ,          ,    .      ,       ,        .                    . <br><br><h2>  Conclusiones </h2><br>   ,     ,   .   ,  ,      .                 -  .   ,      ‚Äî    ‚Äî     ,   .  ,            .   ,     ,     ,     Retail Rocket. <br><br>  ,   ,   ,       ,    ¬´ ¬ª.           ,               . ,          . <br><br> <b><i> ,  Retail Rocket</i></b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/441366/">https://habr.com/ru/post/441366/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../441356/index.html">¬øC√≥mo entender el c√≥digo "extranjero" y unirme a un nuevo equipo?</a></li>
<li><a href="../441358/index.html">Lanz√≥ el primer m√≥dulo de aterrizaje lunar comercial Beresheet</a></li>
<li><a href="../441360/index.html">OpenShift - manualidades de sombrero rojo</a></li>
<li><a href="../441362/index.html">Gu√≠a del usuario de Kibana. Visualizaci√≥n. Parte 3</a></li>
<li><a href="../441364/index.html">Programa de conferencias Lua en Mosc√∫ 2019</a></li>
<li><a href="../441368/index.html">¬øC√≥mo se ve la luna invisible de Neptuno?</a></li>
<li><a href="../441370/index.html">Protecci√≥n sin miedo. Seguridad de roscas en √≥xido</a></li>
<li><a href="../441372/index.html">[Viernes] C√≥mo fre√≠r pollo en t√©rminos de f√≠sica</a></li>
<li><a href="../441376/index.html">M√°s all√° de la pureza: qu√© puede y qu√© no puede revertir la membrana de √≥smosis</a></li>
<li><a href="../441378/index.html">Investigadores de Google: para protegerse contra Spectre requiere un cambio en la arquitectura del procesador, los parches de software no ayudar√°n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•Ä ‚úäüèΩ üë®üèø‚Äçüöí ROS: mapa de profundidad en la Raspberry Pi "sangre baja" üçô üëêüèº ‚Ü™Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Si usa ROS cuando crea robots, probablemente sepa que tiene soporte para trabajar con c√°maras est√©reo. Puede construir, por ejemplo, un mapa de profun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ROS: mapa de profundidad en la Raspberry Pi "sangre baja"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431092/"><img src="https://habrastorage.org/webt/jl/ks/vn/jlksvndgnvhxzgvr_jmo19ni580.jpeg" alt="imagen"><br><br>  Si usa ROS cuando crea robots, probablemente sepa que tiene soporte para trabajar con c√°maras est√©reo.  Puede construir, por ejemplo, un mapa de profundidad de la parte visible del espacio o una nube de puntos.  Y me preguntaba qu√© f√°cil ser√≠a usar una c√°mara est√©reo StereoPi basada en frambuesa en ROS.  Anteriormente, ya estaba convencido de que el mapa de profundidad est√° perfectamente construido por OpenCV, pero nunca he tratado con ROS.  Y decid√≠ probarlo.  Quiero hablar sobre mis aventuras para encontrar una soluci√≥n. <br><a name="habracut"></a><br><h3>  1. ¬øHay alguna ROS en la Raspberry Pi? </h3><br>  Al principio, decid√≠ averiguar si era posible construir ROS para Raspberry Pi.  Lo primero que me dijo Google fue una lista de instrucciones para instalar diferentes versiones de ROS en la Raspberry Pi, es decir, esta p√°gina <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">wiki de ROS</a> <br><br>  Bueno, ¬°ya hay algo por donde empezar!  Recuerdo bien cu√°nto tiempo llev√≥ construir OpenCV en Raspberry (aproximadamente ocho horas), as√≠ que decid√≠ buscar im√°genes ya preparadas de tarjetas MicroSD para ahorrar tiempo. <br><br><h3>  2. ¬øHay im√°genes de tarjetas microSD listas para usar con ROS para Raspberry? </h3><br>  Result√≥ que este problema ya ha sido resuelto por varios equipos de desarrollo.  Si no toma compilaciones √∫nicas de entusiastas, entonces se destacaron un par de im√°genes que se actualizan constantemente con el lanzamiento de nuevas versiones del sistema operativo y ROS. <br><br>  La primera opci√≥n es ROS instalada en el sistema operativo Raspbian nativo del equipo de ROSbots, aqu√≠ hay una p√°gina con un enlace de imagen actualizado: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ready-to-use-image-raspbian-stretch-ros-opencv</a> <br><br>  El segundo son las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">im√°genes de Ubiquiti Robotics en ubuntu</a> . <br><br>  Bueno, la segunda pregunta tambi√©n se cerr√≥ lo suficientemente r√°pido.  Es hora de sumergirse m√°s profundo. <br><br><h3>  3. ¬øC√≥mo funciona ROS con la c√°mara Raspberry Pi? </h3><br>  ¬øY qu√© c√°maras est√©reo generalmente son compatibles con ROS?  Mir√© la p√°gina con c√°maras est√©reo, para la cual se declar√≥ la disponibilidad de controladores listos para ROS, esta: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">wiki.ros.org/Sensors</a> <br><br>  Hab√≠a dos secciones: <br>  <i><b>2.3 Sensores 3D (tel√©metros y c√°maras RGB-D)</b></i> <i><br></i>  <i><b>2.5 c√°maras</b></i> <br>  Result√≥ que en la primera secci√≥n, no solo se enumeran las c√°maras est√©reo, sino tambi√©n los sensores TOF y los lidares de escaneo, en general, todo lo que puede proporcionar informaci√≥n en 3D de inmediato.  Y en el segundo ya hay c√°maras est√©reo.  Intentar ver los controladores de varias c√°maras est√©reo no fue un placer para m√≠, ya que insinu√≥ una inmersi√≥n seria en el c√≥digo. <br><br>  Bien, retrocede un paso.  ¬øC√≥mo funciona con una sola c√°mara Raspberry Pi en ROS? <br><br>  Aqu√≠ me esperaban tres sorpresas agradables: <br><br><ul><li>  Resulta que para ROS hay un nodo especial <b><i>raspicam_node</i></b> solo para trabajar con la c√°mara Raspberry Pi </li><li>  Los tipos de nodo se encuentran en el github, el c√≥digo se mantiene activamente y est√° bien documentado: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github.com/UbiquityRobotics/raspicam_node</a> </li><li>  El autor del nodo Rohan Agrawal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">@Rohbotics</a> ) trabaja para una empresa que respalda activamente una de las im√°genes preparadas para Raspberry Pi </li></ul><br>  Mir√© el repositorio de github raspicam_node y mir√© los problemas.  All√≠ encontr√© un problema abierto con el nombre espacioso "modo est√©reo" hace casi siete meses, sin respuestas ni comentarios.  En realidad, en √©l todos los eventos se desarrollaron a√∫n m√°s. <br><br><h3>  4. Hardcore o no? </h3><br>  Para no hacer preguntas de los ni√±os a los autores, decid√≠ mirar el c√≥digo fuente y evaluar qu√© amenaza la incorporaci√≥n del modo est√©reo.  Estaba m√°s interesado en la parte del sistema aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github.com/UbiquityRobotics/raspicam_node/tree/kinetic/src</a> <br>  Bueno, los muchachos escribieron al conductor hundi√©ndose en el nivel MMAL.  Tambi√©n record√© que el c√≥digo fuente de las frambuesas en modo est√©reo tambi√©n est√° abierto (la evoluci√≥n se puede rastrear <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠ en el foro de frambuesas</a> ), y la tarea de escribir un controlador est√©reo completo es solucionable, pero a gran escala.  Al observar la descripci√≥n de los controladores de otras c√°maras, me di cuenta de que era necesario publicar no solo las im√°genes izquierda y derecha, sino tambi√©n dar los par√°metros de ambas c√°maras, aplicar los resultados de calibraci√≥n a cada una y hacer muchas otras cosas.  Esto atrajo experimentos de un mes o dos de largo.  Por lo tanto, decid√≠ paralelizar el enfoque, a saber: escribirle al autor una pregunta sobre el soporte est√©reo y buscar una soluci√≥n m√°s simple pero que funcione. <br><br><h3>  5. Di√°logos con el autor. </h3><br>  En el hilo sobre el modo est√©reo en el github, le hice una pregunta al autor, mencionando que el est√©reo ha sido respaldado por frambuesas desde 2014, y suger√≠, si es necesario, enviarle una placa de depuraci√≥n para experimentos.  Perm√≠teme recordarte que todav√≠a dudaba que en esta distribuci√≥n el est√©reo funcionar√° como en el Raspbian nativo. <br><br>  Rohan respondi√≥ sorprendentemente r√°pido, diciendo que su distribuci√≥n usa un n√∫cleo de frambuesa y que todo deber√≠a funcionar.  Y pidi√≥ que lo revisen en una de sus asambleas. <br><br>  N√∫cleo de frambuesa!  ¬°Hurra!  ¬°Te√≥ricamente, se debe capturar una imagen est√©reo sin bailar con una pandereta! <br><br>  Descargu√© e implement√© su √∫ltima imagen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">usando un enlace de Rohan</a> y ejecut√© un simple script de Python para capturar un par est√©reo.  Funcion√≥! <br><br><img src="https://habrastorage.org/webt/vh/6i/fg/vh6ifg37hbuzr0khcyxnuxpq5fa.jpeg" alt="imagen"><br><br>  Despu√©s de eso, Rohan escribi√≥ que mirar√≠a el c√≥digo del controlador para el modo est√©reo, y escribi√≥ un par de preguntas.  Por ejemplo, nuestro modo est√©reo produce una imagen pegada, y tendr√≠amos que cortarla en dos: izquierda y derecha.  Y la segunda pregunta sobre los par√°metros de calibraci√≥n de cada c√°mara es c√≥mo manejarla. <br><br>  Dije que como primer paso, puedes tomar fotos de las c√°maras de forma independiente.  S√≠, no se sincronizar√°n en el tiempo de captura y la configuraci√≥n (como el balance de brillo, contraste y blanco), pero como primer paso, esto podr√≠a reducirse. <br><br>  Rohan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lanz√≥</a> r√°pidamente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un parche</a> que le permite especificar directamente desde ROS de qu√© c√°mara tomar fotos.  Lo comprob√©: elegir una c√°mara funciona, ya es un excelente resultado. <br><br><h3>  6. Ayuda inesperada </h3><br>  Y luego aparece un comentario del usuario de Wezzoid en el hilo.  Dijo que estaba haciendo un proyecto basado en una c√°mara est√©reo en un Pi Compute 3 usando paneles de frambuesa.  Su robot ambulante de cuatro patas rastre√≥ la posici√≥n del objeto en el espacio, cambi√≥ la posici√≥n de las c√°maras y mantuvo la distancia especificada (el proyecto se publica en hackaday.io <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ). <br><br><img src="https://habrastorage.org/webt/og/sp/iy/ogspiywmjvs67yhodxpbes0pd-8.jpeg" alt="imagen"><br><br>  Y comparti√≥ el c√≥digo en el que tom√≥ la imagen, la cort√≥ por la mitad con python y lo comparti√≥ como nodos de las c√°maras izquierda y derecha. <br>  Python no es un amigo muy r√°pido en estos asuntos, por lo que utiliz√≥ una resoluci√≥n baja de 320x240 y un buen truco de vida.  Si capturamos una imagen est√©reo lado a lado (una c√°mara a la izquierda de la imagen est√©reo, la segunda a la derecha), entonces la pit√≥n deber√≠a cortar cada una de las 240 l√≠neas por la mitad.  Pero si hace una imagen de arriba a abajo (la c√°mara izquierda es la mitad superior del cuadro, la derecha es la parte inferior), entonces la pit√≥n corta la matriz por la mitad en una sola operaci√≥n.  Lo cual fue realizado con √©xito por el usuario Wezzoid. <br>  Adem√°s, public√≥ su c√≥digo de Python en Pastebin, que realiz√≥ esta operaci√≥n.  Aqu√≠ esta: <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo Wezzoid para publicar nodos de dos c√°maras desde un par est√©reo</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env python # picamera stereo ROS node using dual CSI Pi CS3 board # Wes Freeman 2018 # modified from code by Adrian Rosebrock, pyimagesearch.com # and jensenb, https://gist.github.com/jensenb/7303362 from picamera.array import PiRGBArray from picamera import PiCamera import time import rospy from sensor_msgs.msg import CameraInfo, Image import yaml import io import signal # for ctrl-C handling import sys def parse_calibration_yaml(calib_file): with file(calib_file, 'r') as f: params = yaml.load(f) cam_info = CameraInfo() cam_info.height = params['image_height'] cam_info.width = params['image_width'] cam_info.distortion_model = params['distortion_model'] cam_info.K = params['camera_matrix']['data'] cam_info.D = params['distortion_coefficients']['data'] cam_info.R = params['rectification_matrix']['data'] cam_info.P = params['projection_matrix']['data'] return cam_info # cam resolution res_x = 320 #320 # per camera res_y = 240 #240 target_FPS = 15 # initialize the camera print "Init camera..." camera = PiCamera(stereo_mode = 'top-bottom',stereo_decimate=False) camera.resolution = (res_x, res_y*2) # top-bottom stereo camera.framerate = target_FPS # using several camera options can cause instability, hangs after a while camera.exposure_mode = 'antishake' #camera.video_stabilization = True # fussy about res? stream = io.BytesIO() # ---------------------------------------------------------- #setup the publishers print "init publishers" # queue_size should be roughly equal to FPS or that causes lag? left_img_pub = rospy.Publisher('left/image_raw', Image, queue_size=1) right_img_pub = rospy.Publisher('right/image_raw', Image, queue_size=1) left_cam_pub = rospy.Publisher('left/camera_info', CameraInfo, queue_size=1) right_cam_pub = rospy.Publisher('right/camera_info', CameraInfo, queue_size=1) rospy.init_node('stereo_pub') # init messages left_img_msg = Image() left_img_msg.height = res_y left_img_msg.width = res_x left_img_msg.step = res_x*3 # bytes per row: pixels * channels * bytes per channel (1 normally) left_img_msg.encoding = 'rgb8' left_img_msg.header.frame_id = 'stereo_camera' # TF frame right_img_msg = Image() right_img_msg.height = res_y right_img_msg.width = res_x right_img_msg.step = res_x*3 right_img_msg.encoding = 'rgb8' right_img_msg.header.frame_id = 'stereo_camera' imageBytes = res_x*res_y*3 # parse the left and right camera calibration yaml files left_cam_info = parse_calibration_yaml('/home/pi/catkin_ws/src/mmstereocam/camera_info/left.yaml') right_cam_info = parse_calibration_yaml('/home/pi/catkin_ws/src/mmstereocam/camera_info/right.yaml') # --------------------------------------------------------------- # this is supposed to shut down gracefully on CTRL-C but doesn't quite work: def signal_handler(signal, frame): print 'CTRL-C caught' print 'closing camera' camera.close() time.sleep(1) print 'camera closed' sys.exit(0) signal.signal(signal.SIGINT, signal_handler) #----------------------------------------------------------- print "Setup done, entering main loop" framecount=0 frametimer=time.time() toggle = True # capture frames from the camera for frame in camera.capture_continuous(stream, format="rgb", use_video_port=True): framecount +=1 stamp = rospy.Time.now() left_img_msg.header.stamp = stamp right_img_msg.header.stamp = stamp left_cam_info.header.stamp = stamp right_cam_info.header.stamp = stamp left_cam_pub.publish(left_cam_info) right_cam_pub.publish(right_cam_info) frameBytes = stream.getvalue() left_img_msg.data = frameBytes[:imageBytes] right_img_msg.data = frameBytes[imageBytes:] #publish the image pair left_img_pub.publish(left_img_msg) right_img_pub.publish(right_img_msg) # console info if time.time() &gt; frametimer +1.0: if toggle: indicator = ' o' # just so it's obviously alive if values aren't changing else: indicator = ' -' toggle = not toggle print 'approx publish rate:', framecount, 'target FPS:', target_FPS, indicator frametimer=time.time() framecount=0 # clear the stream ready for next frame stream.truncate(0) stream.seek(0)</span></span></code> </pre> <br></div></div><br><h3>  7. Comience a publicar los nodos de las c√°maras izquierda y derecha </h3><br>  Al principio, el c√≥digo maldijo que no hab√≠a acceso a los archivos YML con los par√°metros de la c√°mara.  Utilic√© c√°maras V2 de color frambuesa y record√© que los archivos listos para <i><b>usar</b></i> con resultados de calibraci√≥n para diferentes modelos de c√°maras llegaron al <i><b>raspicam_node</b></i> en el github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github.com/UbiquityRobotics/raspicam_node/tree/kinetic/camera_info</a> <br>  Tom√© uno de ellos, hice dos copias y lo guard√© con los nombres left.yml y right.yml, escribiendo en ellos la resoluci√≥n de la c√°mara del gui√≥n del autor.  Esto es lo que sucedi√≥ con la c√°mara izquierda: <br><br><div class="spoiler">  <b class="spoiler_title">left.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">image_width: 320 image_height: 240 camera_name: left camera_matrix: rows: 3 cols: 3 data: [1276.704618338571, 0, 634.8876509199106, 0, 1274.342831275509, 379.8318028940378, 0, 0, 1] distortion_model: plumb_bob distortion_coefficients: rows: 1 cols: 5 data: [0.1465167016954302, -0.2847343180128725, 0.00134017721235817, -0.004309553450829512, 0] rectification_matrix: rows: 3 cols: 3 data: [1, 0, 0, 0, 1, 0, 0, 0, 1] projection_matrix: rows: 3 cols: 4 data: [1300.127197265625, 0, 630.215390285608, 0, 0, 1300.670166015625, 380.1702884455881, 0, 0, 0, 1, 0]</code> </pre> <br></div></div><br>  A la derecha, el nombre de la c√°mara se reemplaza por right, y el archivo en s√≠ se llama right.yml.  El resto del archivo es id√©ntico. <br><br>  Como no planeaba hacer un proyecto complejo, no repet√≠ las largas rutas del autor con subcarpetas y solo puse los archivos en la ra√≠z de la carpeta de inicio junto al script de Python.  El c√≥digo se inici√≥ correctamente y muestra mensajes de estado en la consola. <br><br><img src="https://habrastorage.org/webt/sz/oi/my/szoimymcugjmfggyfdez98l3kku.jpeg" alt="imagen"><br><br>  Solo quedaba por ver lo que finalmente publicaron nuestras c√°maras izquierda y derecha.  Para hacer esto, lanc√© rqt_image_view.  Los elementos / left / image_raw y / right / image_raw aparecieron en el men√∫ desplegable. Cuando los seleccion√©, vi im√°genes de las c√°maras izquierda y derecha. <br><br><img src="https://habrastorage.org/webt/og/1i/du/og1iduqsqdfjq_j2ijp-fkzfxhm.jpeg" alt="imagen"><br><br>  Bueno, esto ha ganado!  Ahora la parte divertida. <br><br><h3>  8. Observamos el mapa de las profundidades. </h3><br>  Para ver el mapa de profundidad, no se me ocurri√≥ mi propio enfoque y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">revis√© el manual</a> cl√°sico de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ROS para configurar los par√°metros est√©reo</a> . <br>  A partir de ah√≠, descubr√≠ que ser√≠a bueno publicar ambos nodos en un espacio de nombres espec√≠fico, y no en la ra√≠z como lo hizo Wezzoid.  Como resultado, las viejas l√≠neas de publicaci√≥n del formulario <br><br><pre> <code class="python hljs">left_img_pub = rospy.Publisher(<span class="hljs-string"><span class="hljs-string">'left/image_raw'</span></span>, Image, queue_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  comenz√≥ a verse as√≠: <br><br><pre> <code class="python hljs">left_img_pub = rospy.Publisher(<span class="hljs-string"><span class="hljs-string">'stereo/right/image_raw'</span></span>, Image, queue_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Despu√©s de eso, lanzamos el nodo de procesamiento del modo est√©reo stereo_image_proc: <br><br><pre> <code class="bash hljs">ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_ige_proc</code> </pre> <br>  Bueno, tambi√©n queremos ver el resultado, as√≠ que comenzamos el observador: <br><br><pre> <code class="bash hljs">rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color</code> </pre> <br>  Y para configurar los par√°metros del mapa de profundidad, ejecute la utilidad de configuraci√≥n: <br><br><pre> <code class="bash hljs">rosrun rqt_reconfigure rqt_reconfigure</code> </pre> <br>  Como resultado, vemos la imagen al comienzo del art√≠culo.  Aqu√≠ es un poco m√°s grande: <br><br><img src="https://habrastorage.org/webt/qc/oy/s8/qcoys8o4-yrwfxgc7kynjrxhd9m.jpeg" alt="imagen"><br><br>  Todos los archivos que publiqu√© en el github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github.com/realizator/StereoPi-ROS-depth-map-test</a> <br><br><h3>  9. Planes inmediatos </h3><br>  Despu√©s de mi publicaci√≥n del resultado en una discusi√≥n sobre el github, Rohan escribi√≥ "¬°Genial!  Tengo que ir a recoger mi StereoPi ".  Le escribimos por correo, le envi√© una tarifa.  Espero que con el hardware de trabajo en sus manos le sea m√°s f√°cil terminar y depurar un controlador est√©reo completo para ROS y Raspberry. <br><br><h3>  10. Resumen </h3><br>  Se puede obtener un mapa de profundidad de una imagen est√©reo en frambuesas en ROS de varias maneras.  La ruta elegida para la verificaci√≥n r√°pida no es la m√°s √≥ptima en t√©rminos de rendimiento, pero puede usarse para fines de aplicaci√≥n.  La belleza de su simplicidad y la capacidad de comenzar inmediatamente los experimentos. <br><br>  Bueno, por lo gracioso: despu√©s de recibir los resultados, not√© que Wezzoid, quien propuso su soluci√≥n, fue el autor de la pregunta sobre la publicaci√≥n de dos im√°genes est√©reo.  Se pregunt√≥ a s√≠ mismo, decidi√≥. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es431092/">https://habr.com/ru/post/es431092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es431082/index.html">Kotlin: buscando jefe de marketing</a></li>
<li><a href="../es431084/index.html">En cualquier situaci√≥n incomprensible - escriba guiones</a></li>
<li><a href="../es431086/index.html">Todo lo que quer√≠a saber sobre PVS-Studio y no dud√≥ en preguntar</a></li>
<li><a href="../es431088/index.html">La gesti√≥n de archivos se hizo mal - Parte 1: Originalmente de los a√±os 90</a></li>
<li><a href="../es431090/index.html">Un bot VK, un C # y una naranja</a></li>
<li><a href="../es431094/index.html">Solitario Ordenar</a></li>
<li><a href="../es431096/index.html">C√≥mo construir un producto de chat bot</a></li>
<li><a href="../es431098/index.html">Incluso un incendio no es un obst√°culo, o Zimbra Speed ‚Äã‚ÄãRecovery despu√©s de un desastre</a></li>
<li><a href="../es431102/index.html">C√≥mo se muestra la direcci√≥n f√≠sica en cadenas y bancos DRAM</a></li>
<li><a href="../es431104/index.html">C√≥mo en Neoflex desarrollamos la experiencia de DevOps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
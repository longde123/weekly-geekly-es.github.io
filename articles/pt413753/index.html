<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎀 🐢 🏏 Olho no céu: zangão-patrulha com reconhecimento da violência em multidões e locais públicos 👩🏿‍🤝‍👨🏽 ♍️ ♉️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A ilustração à esquerda mostra 14 pontos-chave no corpo humano que o sistema de visão de máquina reconhece: cabeça, pescoço, ombros, cotovelos, pulsos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Olho no céu: zangão-patrulha com reconhecimento da violência em multidões e locais públicos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413753/"><img src="https://habrastorage.org/webt/hb/9o/52/hb9o52ey8msi1rwh-qzeal7h_zo.jpeg"><br>  <i><font color="gray">A ilustração à esquerda mostra 14 pontos-chave no corpo humano que o sistema de visão de máquina reconhece: cabeça, pescoço, ombros, cotovelos, pulsos, quadris, joelhos e tornozelos.</font></i>  <i><font color="gray">No canto superior direito está o drone Parrot AR com um sistema de reconhecimento de violência.</font></i>  <i><font color="gray">No canto inferior direito, os elementos fotográficos individuais do conjunto de dados de treinamento com pontos-chave</font></i> <br><br>  Atualmente, os UAVs são cada vez mais usados ​​por agências de aplicação da lei e agências de inteligência.  Geralmente para espionagem, inteligência, controle de fronteiras etc. A polícia não está usando ativamente drones para patrulhar as ruas da cidade.  Mas aqui existe um enorme potencial.  Os drones de patrulha podem economizar significativamente os salários dos funcionários.  Eles cobrem grandes áreas e enxergam perfeitamente no escuro. <br><br>  Em conexão com o crescimento do crime e a ameaça de terrorismo em muitos países, as autoridades estão interessadas em fortalecer o controle sobre a população civil.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Os drones automáticos com reconhecimento automático da violência</a> são sistemas de nova geração que abrem as portas para sistemas ainda mais autônomos e inteligentes para responder a tumultos de rua e vandalismo. <br><a name="habracut"></a><br>  Anteriormente, os UAVs eram usados ​​principalmente no modo "manual".  Portanto, eles estão sob o controle de um operador que rastreia simultaneamente a imagem da câmera de vídeo.  Mas esse modo limita bastante o uso em <i>massa</i> de drones, pois cada UAV precisa de um operador separado. <br><br>  Os sistemas de visão de máquina removem essa limitação.  Eles permitem enviar centenas e milhares de drones pelas rotas especificadas e o operador presta atenção apenas aos alarmes que são acionados quando certos sinais são reconhecidos.  Tais sistemas já foram desenvolvidos para patrulhamento automático de objetos para detectar incêndios, danos ao oleoduto etc. Em 2010, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foi</a> desenvolvido um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sistema</a> para órgãos policiais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">com a identificação de “objetos abandonados”,</a> ou seja, sacolas e pacotes deixados em locais públicos.  O reconhecimento automático da violência é o próximo passo lógico, permitindo que você use UAVs para patrulhar multidões e locais públicos. <br><br>  Em 2009, foi publicado um artigo científico descrevendo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um sistema de visão por máquina para reconhecer automaticamente crimes</a> em locais públicos usando análise de movimento.  Ela determina com precisão cerca de 85% de ações como pegar uma carteira de um transeunte, sequestrar uma criança etc. <br><br>  Tais sistemas são muito bem-sucedidos na detecção de vários atos criminosos.  Apesar da precisão impressionante (em alguns casos, mais de 90% de precisão), eles têm um escopo muito limitado. <br><br>  Em 2014, os pesquisadores propuseram o primeiro sistema de VANT para reconhecer automaticamente a violência em locais públicos, o primeiro de seu tipo a usar um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelo de peças deformáveis</a> para avaliar a postura de uma pessoa com a identificação de pessoas suspeitas por suas poses.  Esta é uma tarefa de visão de máquina extremamente difícil, pois as fotos e os vídeos do drone podem sofrer alterações na iluminação, sombras, poucos detalhes e desfocagem.  Além disso, as pessoas aparecem em diferentes locais do quadro e em diferentes posições.  O sistema determinou a violência com uma precisão de cerca de 76%, muito mais baixa que a dos sistemas altamente especializados descritos acima. <br><br>  O novo desenvolvimento de cientistas da Universidade de Cambridge (Grã-Bretanha), do Instituto Nacional de Tecnologia (Índia) e do Instituto Indiano de Ciência em Bangalore apresenta um sistema aprimorado para reconhecimento autônomo em tempo real da violência usando a rede de pirâmide de recursos (FPN), uma rede híbrida de aprendizado profundo ScatterNet (ScatterNet Aprendizagem Profunda Híbrida (SHDL) e cálculo da orientação entre os membros da pose calculada usando a máquina de vetores de suporte (SVM).  A operação do pipeline de reconhecimento é mostrada em detalhes na ilustração. <br><br><img src="https://habrastorage.org/webt/ir/cc/cs/ircccszfjsqyb7aiwfrxh_pwh_e.jpeg"><br>  <i><font color="gray">Um transportador que prevê a postura de uma pessoa que pode ser usado para prever a violência em multidões e locais públicos.</font></i>  <i><font color="gray">A estrutura primeiro reconhece pessoas em quadros fotografados por uma câmera drone.</font></i>  <i><font color="gray">Fragmentos de fotografias com imagens de pessoas são inseridos na rede SHDL, onde o ScatterNet opera no front-end para extrair sinais descritos manualmente das imagens de entrada.</font></i>  <i><font color="gray">As características extraídas de três camadas são combinadas e alimentadas com a entrada de quatro camadas convolucionais da rede de regressão que é executada no back-end.</font></i> <br><br>  A precisão média de reconhecer a violência no novo sistema é de 88,8%, incluindo 89% para chutes, 94% para chutes, 82% para tiros, 85% para estrangulamento e 92% para esfaqueamento.  Isso é significativamente maior que o sistema anterior em 2014. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/zYypJPJipYc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  O artigo científico foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publicado</a> em 3 de junho de 2018 no site de pré-impressão arXiv.org e será apresentado nos Workshops IEEE de Visão Computacional e Reconhecimento de Padrões (CVPR). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt413753/">https://habr.com/ru/post/pt413753/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt413743/index.html">Inicie o LAMP e centenas de outros aplicativos da web em apenas alguns cliques</a></li>
<li><a href="../pt413745/index.html">Um sistema de energia sem fio foi desenvolvido para todos os componentes eletrônicos do corpo humano de uma só vez</a></li>
<li><a href="../pt413747/index.html">Passando por NULL</a></li>
<li><a href="../pt413749/index.html">Árvore B + em um projeto real</a></li>
<li><a href="../pt413751/index.html">Ruslan Cheremin e Maxim Gramin - trabalhem com o meio ambiente em jug.msk.ru</a></li>
<li><a href="../pt413757/index.html">Banco de dados em um projeto comercial: o que fazer?</a></li>
<li><a href="../pt413759/index.html">A curiosidade descobriu orgânicos em Marte, com bilhões de anos</a></li>
<li><a href="../pt413761/index.html">Como impedir que o Windows 10 seja reiniciado após atualizações</a></li>
<li><a href="../pt413763/index.html">O que lemos em maio: Revisões do Ivy, lançamento do Nest 5 e outros textos úteis para desenvolvedores Angular</a></li>
<li><a href="../pt413765/index.html">Cadeia de responsabilidade em modelos variáveis ​​C ++</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê• üí™üèº üßñüèº Migrando do Mongo para o Postgres: a experi√™ncia do jornal The Guardian ‚ôãÔ∏è üêñ üíç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O Guardian √© um dos maiores jornais brit√¢nicos, foi fundado em 1821. Por quase 200 anos de exist√™ncia, o arquivo acumulou uma quantia justa. Felizment...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migrando do Mongo para o Postgres: a experi√™ncia do jornal The Guardian</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/436416/"><img src="https://habrastorage.org/webt/4w/zu/h3/4wzuh3ik2zdn_awvt9l2rhd4oia.jpeg" alt="imagem"><br><br>  O Guardian √© um dos maiores jornais brit√¢nicos, foi fundado em 1821.  Por quase 200 anos de exist√™ncia, o arquivo acumulou uma quantia justa.  Felizmente, nem tudo √© armazenado no site - apenas nas √∫ltimas duas d√©cadas.  O banco de dados, que os pr√≥prios brit√¢nicos chamaram de "fonte da verdade" para todo o conte√∫do online, cont√©m cerca de 2,3 milh√µes de elementos.  E, a certa altura, eles perceberam a necessidade de migrar do Mongo para o Postgres SQL - ap√≥s um dia quente de julho de 2015, os procedimentos de failover foram severamente testados.  A migra√ß√£o levou quase 3 anos! .. <br><br>  Traduzimos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> que descreve como foi o processo de migra√ß√£o e quais dificuldades os administradores enfrentaram.  O processo √© longo, mas o resumo √© simples: resumindo-se √† grande tarefa, reconcilie que ser√£o necess√°rios erros.  Mas, no final, tr√™s anos depois, colegas brit√¢nicos conseguiram comemorar o fim da migra√ß√£o.  E durma. <br><a name="habracut"></a><br><h4>  <b>Parte Um: O Come√ßo</b> </h4><br>  No Guardian, a maior parte do conte√∫do, incluindo artigos, blogs, galerias de fotos e v√≠deos, √© produzida em nosso pr√≥prio CMS, Composer.  At√© recentemente, o Composer trabalhava com o Mongo DB da AWS.  Esse banco de dados era essencialmente uma "fonte de verdade" para todo o conte√∫do on-line do Guardian - cerca de 2,3 milh√µes de elementos.  E acabamos de concluir a migra√ß√£o do Mongo para o Postgres SQL. <br><br>  O Composer e seus bancos de dados foram originalmente hospedados na Guardian Cloud, um data center no por√£o de nosso escrit√≥rio perto de Kings Cross, com failover em outros locais de Londres.  Em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dia quente de julho de 2015,</a> nossos procedimentos de failover foram submetidos a um teste bastante severo. <br><br><img src="https://habrastorage.org/webt/ij/nu/wx/ijnuwxcxdtlrnupaxikvcqq7ofe.jpeg" alt="imagem"><br>  <i>Calor: bom para dan√ßar na fonte, desastroso para o data center.</i>  <i>Foto: Sarah Lee / Guardi√£o</i> <br><br>  Desde ent√£o, a migra√ß√£o do Guardian para a AWS se tornou uma quest√£o de vida ou morte.  Para migrar para a nuvem, decidimos comprar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpsManager</a> , software de gerenciamento Mongo DB, e assinamos um contrato de suporte t√©cnico Mongo.  Usamos o OpsManager para gerenciar backups, orquestrar e monitorar nosso cluster de banco de dados. <br><br>  Devido aos requisitos editoriais, precisamos iniciar o cluster de banco de dados e o OpsManager em nossa pr√≥pria infraestrutura na AWS, e n√£o usar a solu√ß√£o gerenciada Mongo.  Tivemos que suar, pois o Mongo n√£o forneceu nenhuma ferramenta para facilitar a configura√ß√£o na AWS: projetamos manualmente toda a infraestrutura e escrevemos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">centenas de scripts Ruby</a> para instalar agentes de monitoramento / automa√ß√£o e orquestrar novas inst√¢ncias de banco de dados.  Como resultado, tivemos que organizar uma equipe de programas educacionais sobre gerenciamento de banco de dados na equipe - o que esper√°vamos que o OpsManager assumisse. <br><br>  Desde a transi√ß√£o para a AWS, tivemos duas falhas significativas devido a problemas no banco de dados, cada uma das quais n√£o permitiu a publica√ß√£o no theguardian.com por pelo menos uma hora.  Nos dois casos, nem a equipe de suporte t√©cnico da OpsManager nem a Mongo puderam nos fornecer assist√™ncia suficiente, e resolvemos o problema por conta pr√≥pria - em um caso, gra√ßas a um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">membro da nossa equipe</a> que conseguiu lidar com a situa√ß√£o por telefone do deserto nos arredores de Abu Dhabi. <br><br>  Cada uma das quest√µes problem√°ticas merece um post separado, mas aqui est√£o os pontos gerais: <br><br><ul><li>  Preste muita aten√ß√£o ao tempo - n√£o bloqueie o acesso ao seu VPC a tal ponto que o NTP pare de funcionar. </li><li>  Criar automaticamente √≠ndices de banco de dados na inicializa√ß√£o do aplicativo √© uma m√° id√©ia. </li><li>  O gerenciamento de banco de dados √© extremamente importante e dif√≠cil - e n√£o queremos fazer isso sozinhos. </li></ul><br>  O OpsManager n√£o cumpriu sua promessa de gerenciamento simples de banco de dados.  Por exemplo, o gerenciamento real do pr√≥prio OpsManager - em particular, a atualiza√ß√£o da vers√£o 1 para a vers√£o 2 do OpsManager - exigiu muito tempo e conhecimento especial sobre a configura√ß√£o do OpsManager.  Ele tamb√©m n√£o cumpriu sua promessa de "atualiza√ß√µes com um clique" devido a altera√ß√µes no esquema de autentica√ß√£o entre diferentes vers√µes do Mongo DB.  Perdemos pelo menos dois meses de engenheiros por ano gerenciando o banco de dados. <br><br>  Todos esses problemas, combinados com a significativa taxa anual que pagamos pelo contrato de suporte e pelo OpsManager, nos for√ßaram a procurar uma op√ß√£o alternativa de banco de dados com as seguintes caracter√≠sticas: <br><br><ul><li>  Esfor√ßo m√≠nimo para gerenciar o banco de dados. </li><li>  Criptografia em repouso. </li><li>  Um caminho de migra√ß√£o aceit√°vel com o Mongo. </li></ul><br>  Como todos os nossos outros servi√ßos executam a AWS, a escolha √≥bvia √© Dynamo, o banco de dados NoSQL da Amazon.  Infelizmente, no momento, o Dynamo n√£o suportava criptografia em repouso.  Depois de esperar cerca de nove meses para que esse recurso fosse adicionado, acabamos abandonando essa ideia, decidindo usar o Postgres no AWS RDS. <br>  "Mas o Postgres n√£o √© um reposit√≥rio de documentos!"  - voc√™ est√° indignado ... Bem, sim, este n√£o √© um reposit√≥rio dock, mas possui tabelas semelhantes √†s colunas JSONB, com suporte para √≠ndices nos campos da ferramenta JSON Blob.  Esper√°vamos que, usando JSONB, pud√©ssemos migrar do Mongo para o Postgres com altera√ß√µes m√≠nimas em nosso modelo de dados.  Al√©m disso, se quis√©ssemos mudar para um modelo mais relacional no futuro, ter√≠amos essa oportunidade.  Outra grande coisa sobre o Postgres √© como ele funcionou: para todas as perguntas que tivemos, na maioria dos casos, a resposta j√° foi dada no Stack Overflow. <br><br>  Em termos de desempenho, t√≠nhamos certeza de que o Postgres poderia faz√™-lo: o Composer √© uma ferramenta exclusiva para gravar conte√∫do (grava no banco de dados toda vez que um jornalista para de imprimir) e, geralmente, o n√∫mero de usu√°rios simult√¢neos n√£o excede v√°rias centenas - o que n√£o requer um sistema super alta pot√™ncia! <br><br><h4>  <b>Parte dois: a migra√ß√£o de conte√∫do de duas d√©cadas passou sem tempo de inatividade</b> </h4><br>  <b>Planejar</b> <br><br>  A maioria das migra√ß√µes de banco de dados implica as mesmas a√ß√µes, e a nossa n√£o foi exce√ß√£o.  Aqui est√° o que fizemos: <br><br><ul><li>  Criou um novo banco de dados. </li><li>  Eles criaram uma maneira de gravar em um novo banco de dados (nova API). </li><li>  Criamos um servidor proxy que envia tr√°fego para o banco de dados antigo e o novo, usando o antigo como principal. </li><li>  Registros movidos do banco de dados antigo para o novo. </li><li>  Eles fizeram do novo banco de dados o principal. </li><li>  Removido o banco de dados antigo. </li></ul><br>  Como o banco de dados para o qual migramos fornecia o funcionamento do nosso CMS, era fundamental que a migra√ß√£o causasse o m√≠nimo de problemas poss√≠vel para nossos jornalistas.  No final, as not√≠cias nunca terminam. <br><br>  <b>Nova API</b> <br><br>  O trabalho na nova API baseada no Postgres come√ßou no final de julho de 2017.  Este foi o come√ßo de nossa jornada.  Mas, para entender como era, precisamos primeiro esclarecer por onde come√ßamos. <br><br>  Nossa arquitetura simplificada do CMS era mais ou menos assim: um banco de dados, uma API e v√°rios aplicativos relacionados a ele (como uma interface do usu√°rio).  A pilha foi constru√≠da e, h√° 4 anos, opera com base no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scala</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scalatra Framework</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Angular.js</a> . <br><br>  Ap√≥s algumas an√°lises, chegamos √† conclus√£o de que, antes de podermos migrar o conte√∫do existente, precisamos de uma maneira de entrar em contato com o novo banco de dados PostgreSQL, mantendo a antiga API operacional.  Afinal, o Mongo DB √© a nossa "fonte da verdade".  Ela nos serviu como uma t√°bua de salva√ß√£o enquanto experiment√°vamos a nova API. <br><br>  Essa √© uma das raz√µes pelas quais construir sobre a API antiga n√£o fazia parte de nossos planos.  A separa√ß√£o de fun√ß√µes na API original era m√≠nima, e os m√©todos espec√≠ficos necess√°rios para trabalhar especificamente com o Mongo DB podiam ser encontrados mesmo no n√≠vel do controlador.  Como resultado, a tarefa de adicionar outro tipo de banco de dados a uma API existente era muito arriscada. <br><br>  Fomos para o outro lado e duplicamos a API antiga.  Assim nasceu o APIV2.  Era uma c√≥pia mais ou menos exata da antiga API relacionada ao Mongo e inclu√≠a os mesmos pontos de extremidade e funcionalidade.  Usamos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">doobie</a> , a camada de recursos JDBC pura para Scala, adicionamos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Docker</a> para executar e testar localmente e aprimoramos o registro de opera√ß√µes e o compartilhamento de responsabilidades.  O APIV2 deveria ser uma vers√£o r√°pida e moderna da API. <br><br>  At√© o final de agosto de 2017, implantamos uma nova API que usava o PostgreSQL como banco de dados.  Mas isso foi apenas o come√ßo.  Existem artigos no Mongo DB que foram criados h√° mais de duas d√©cadas e todos tiveram que migrar para o banco de dados Postgres. <br><br>  <b>A migra√ß√£o</b> <br><br>  Dever√≠amos poder editar qualquer artigo no site, independentemente de quando ele foi publicado, portanto, todos os artigos existem em nosso banco de dados como uma √∫nica "fonte de verdade". <br><br>  Embora todos os artigos estejam na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">API de conte√∫do do Guardian (CAPI)</a> , que atende aos aplicativos e ao site, era extremamente importante migrar sem falhas, pois nosso banco de dados √© a nossa ‚Äúfonte de verdade‚Äù.  Se algo acontecesse com o cluster Elasticsearch CAPI, n√≥s o reindexar√≠amos do banco de dados do Composer. <br>  Portanto, antes de desativar o Mongo, tivemos que garantir que a mesma solicita√ß√£o para a API executada no Postgres e a API executada no Mongo retornasse respostas id√™nticas. <br>  Para fazer isso, precisamos copiar todo o conte√∫do no novo banco de dados do Postgres.  Isso foi feito usando um script que interagiu diretamente com as APIs novas e antigas.  A vantagem desse m√©todo era que as duas APIs j√° forneciam uma interface bem testada para ler e escrever artigos dentro e fora dos bancos de dados, em vez de escrever algo que acessasse diretamente os respectivos bancos de dados. <br><br>  A ordem b√°sica de migra√ß√£o foi a seguinte: <br><br><ul><li>  Obtenha conte√∫do do Mongo. </li><li>  Poste conte√∫do no Postgres. </li><li>  Obtenha conte√∫do do Postgres. </li><li>  Verifique se as respostas s√£o id√™nticas. </li></ul><br>  A migra√ß√£o do banco de dados pode ser considerada bem-sucedida apenas se os usu√°rios finais n√£o perceberem que isso aconteceu e um bom script de migra√ß√£o sempre ser√° a chave para esse sucesso.  Precis√°vamos de um script que pudesse: <br><br><ul><li>  Execute solicita√ß√µes HTTP. </li><li>  Certifique-se de que, ap√≥s migrar parte do conte√∫do, a resposta das duas APIs seja a mesma. </li><li>  Pare quando ocorrer um erro. </li><li>  Crie um log de opera√ß√£o detalhado para diagnosticar problemas. </li><li>  Reinicie ap√≥s um erro do ponto correto. </li></ul><br>  Come√ßamos usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">amonita</a> .  Ele permite que voc√™ escreva scripts na linguagem Scala, que √© o n√∫cleo da nossa equipe.  Foi uma boa oportunidade para experimentar algo que n√£o t√≠nhamos usado antes para ver se seria √∫til para n√≥s.  Embora a amonita nos permitisse usar uma linguagem familiar, encontramos v√°rias defici√™ncias ao trabalhar nela.  Atualmente, a Intellij <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">suporta</a> amonita, mas n√£o o fez durante a migra√ß√£o - e perdemos a conclus√£o autom√°tica e a importa√ß√£o autom√°tica.  Al√©m disso, por um longo per√≠odo de tempo, o script amonita falhou em ser executado. <br>  Por fim, o Amonite n√£o era a ferramenta certa para esse trabalho e, em vez disso, usamos o projeto sbt para fazer a migra√ß√£o.  Isso nos permitiu trabalhar em um idioma em que est√°vamos confiantes, al√©m de executar v√°rias 'migra√ß√µes de teste' antes de iniciar no ambiente de trabalho principal. <br><br>  Inesperado foi o qu√£o √∫til foi verificar a vers√£o da API em execu√ß√£o no Postgres.  Encontramos v√°rios erros dif√≠ceis de encontrar e casos limitantes que n√£o encontramos anteriormente. <br><br>  Avance para janeiro de 2018, quando √© hora de testar a migra√ß√£o completa em nosso ambiente de c√≥digo pr√©-prod. <br><br>  Como a maioria dos nossos sistemas, a √∫nica semelhan√ßa entre CODE e PROD √© a vers√£o do aplicativo que est√° sendo lan√ßada.  A infraestrutura da AWS que suporta o CODE era muito menos poderosa que o PROD, simplesmente porque ela recebe muito menos carga de trabalho. <br><br>  Esper√°vamos que a migra√ß√£o de teste no ambiente CODE nos ajudasse: <br><br><ul><li>  Estime quanto tempo a migra√ß√£o levar√° no ambiente do PROD. </li><li>  Avalie como (se √© que existe) a migra√ß√£o afeta a produtividade. </li></ul><br>  Para obter medi√ß√µes precisas desses indicadores, tivemos que trazer os dois ambientes em completa correspond√™ncia m√∫tua.  Isso incluiu a restaura√ß√£o de um backup do Mongo DB do PROD para o CODE e a atualiza√ß√£o da infraestrutura suportada pela AWS. <br><br>  A migra√ß√£o de pouco mais de 2 milh√µes de itens de dados deveria levar muito mais tempo do que um dia √∫til padr√£o permitiria.  Portanto, executamos o script na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tela</a> para a noite. <br><br>  Para medir o progresso da migra√ß√£o, enviamos consultas estruturadas (usando tokens) para nossa pilha ELK (Elasticsearch, Logstash e Kibana).  A partir da√≠, poder√≠amos criar pain√©is detalhados rastreando o n√∫mero de artigos transferidos com sucesso, o n√∫mero de falhas e o progresso geral.  Al√©m disso, todos os indicadores foram exibidos na tela grande para que toda a equipe pudesse ver os detalhes. <br><br><img src="https://habrastorage.org/webt/wk/zh/uj/wkzhujequqzbqpf65ewnt4zcfbg.png" alt="imagem"><br>  <i>Painel mostrando o andamento da migra√ß√£o: Editorial Tools / Guardian</i> <br><br>  Depois que a migra√ß√£o foi conclu√≠da, verificamos uma correspond√™ncia para cada documento no Postgres e no Mongo. <br><br><h4>  <b>Parte Tr√™s: Proxies e Lan√ßamento no Prod</b> </h4><br>  <b>Proxies</b> <br><br>  Agora que a nova API em execu√ß√£o no Postgres foi lan√ßada, precis√°vamos test√°-la com padr√µes reais de tr√°fego e acesso a dados para garantir sua confiabilidade e estabilidade.  Havia duas maneiras poss√≠veis de fazer isso: atualizar cada cliente que acessa a API do Mongo para acessar as duas APIs;  ou execute um proxy que far√° isso por n√≥s.  Escrevemos proxies no Scala usando o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Akka Streams</a> . <br><br>  O proxy era bastante simples: <br><br><ul><li>  Receba tr√°fego do balanceador de carga. </li><li>  Redirecione o tr√°fego para a API principal e vice-versa. </li><li>  Encaminhe o mesmo tr√°fego de forma ass√≠ncrona para uma API adicional. </li><li>  Calcule as discrep√¢ncias entre as duas respostas e registre-as em um log. </li></ul><br>  Inicialmente, o proxy registrou muitas discrep√¢ncias, incluindo algumas diferen√ßas comportamentais dif√≠ceis de encontrar, mas importantes nas duas APIs que precisavam ser corrigidas. <br><br>  <b>Registro Estruturado</b> <br><br>  No Guardian, registramos usando a pilha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ELK</a> (Elasticsearch, Logstash e Kibana).  O uso do Kibana nos deu a oportunidade de visualizar a revista da maneira mais conveniente para n√≥s.  O Kibana usa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a sintaxe de consulta do Lucene</a> , que √© bastante f√°cil de aprender.  Mas logo percebemos que era imposs√≠vel filtrar ou agrupar os lan√ßamentos cont√°beis manuais na configura√ß√£o atual.  Por exemplo, n√£o conseguimos filtrar os que foram enviados como resultado de solicita√ß√µes GET. <br><br>  Decidimos enviar dados mais estruturados para o Kibana, n√£o apenas mensagens.  Uma entrada de log cont√©m v√°rios campos, por exemplo, o carimbo de data e hora e o nome da pilha ou aplicativo que enviou a solicita√ß√£o.  Adicionar novos campos √© muito f√°cil.  Esses campos estruturados s√£o chamados de marcadores e podem ser implementados usando a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">biblioteca logstash-logback-encoder</a> .  Para cada solicita√ß√£o, extra√≠mos informa√ß√µes √∫teis (por exemplo, rota, m√©todo, c√≥digo de status) e criamos um mapa com informa√ß√µes adicionais necess√°rias para o log.  Aqui est√° um exemplo: <br><br><pre><code class="plaintext hljs">import akka.http.scaladsl.model.HttpRequest import ch.qos.logback.classic.{Logger =&gt; LogbackLogger} import net.logstash.logback.marker.Markers import org.slf4j.{LoggerFactory, Logger =&gt; SLFLogger} import scala.collection.JavaConverters._ object Logging { val rootLogger: LogbackLogger = LoggerFactory.getLogger(SLFLogger.ROOT_LOGGER_NAME).asInstanceOf[LogbackLogger] private def setMarkers(request: HttpRequest) = { val markers = Map( "path" -&gt; request.uri.path.toString(), "method" -&gt; request.method.value ) Markers.appendEntries(markers.asJava) } def infoWithMarkers(message: String, akkaRequest: HttpRequest) = rootLogger.info(setMarkers(akkaRequest), message) }</code> </pre> <br>  Campos adicionais em nossos logs nos permitiram criar pain√©is informativos e adicionar mais contexto √†s discrep√¢ncias, o que nos ajudou a identificar algumas inconsist√™ncias menores entre as duas APIs. <br><br>  <b>Replica√ß√£o de tr√°fego e refatora√ß√£o de proxy</b> <br><br>  Depois de transferir o conte√∫do para o banco de dados CODE, obtivemos uma c√≥pia quase exata do banco de dados PROD.  A principal diferen√ßa era que o CODE n√£o tinha tr√°fego.  Para replicar o tr√°fego real no ambiente CODE, usamos a ferramenta de c√≥digo aberto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GoReplay</a> (a seguir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">denominada</a> gor).  √â muito f√°cil de instalar e flex√≠vel para personalizar de acordo com seus requisitos. <br><br>  Como todo o tr√°fego que chegava √†s nossas APIs era destinado a proxies, fazia sentido instalar o gor em cont√™ineres proxy.  Veja abaixo como carregar o gor no seu cont√™iner e como come√ßar a monitorar o tr√°fego na porta 80 e envi√°-lo para outro servidor. <br><br><pre> <code class="plaintext hljs"> wget https://github.com/buger/goreplay/releases/download/v0.16.0.2/gor_0.16.0_x64.tar.gz tar -xzf gor_0.16.0_x64.tar.gz gor sudo gor --input-raw :80 --output-http http://apiv2.code.co.uk</code> </pre><br>  Por um tempo, tudo funcionou bem, mas logo houve um mau funcionamento quando o proxy ficou indispon√≠vel por v√°rios minutos.  Na an√°lise, descobrimos que todos os tr√™s cont√™ineres proxy eram suspensos periodicamente ao mesmo tempo.  A princ√≠pio, pensamos que o proxy estava travando porque o gor estava usando muitos recursos.  Ap√≥s uma an√°lise mais aprofundada do console da AWS, descobrimos que os cont√™ineres de proxy penduravam regularmente, mas n√£o ao mesmo tempo. <br><br>  Antes de nos aprofundarmos mais no problema, tentamos encontrar uma maneira de executar o gor, mas desta vez sem carga adicional no proxy.  A solu√ß√£o veio da nossa pilha secund√°ria para o Composer.  Essa pilha √© usada apenas em caso de emerg√™ncia e nossa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ferramenta de monitoramento de trabalho</a> a testa constantemente.  Dessa vez, a reprodu√ß√£o do tr√°fego dessa pilha para o CODE em velocidade dupla funcionou sem problemas. <br><br>  Novas descobertas levantaram muitas quest√µes.  O proxy foi criado como uma ferramenta tempor√°ria, portanto, pode n√£o ter sido t√£o cuidadosamente projetado quanto outros aplicativos.  Al√©m disso, ele foi constru√≠do usando o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://doc.akka.io/docs/akka-">Akka Http</a> , com o qual ningu√©m da nossa equipe estava familiarizada.  O c√≥digo estava confuso e cheio de corre√ß√µes r√°pidas.  Decidimos iniciar muitas refatora√ß√µes para melhorar a legibilidade.  Desta vez, usamos geradores for, em vez da crescente l√≥gica aninhada que usamos antes.  E adicionou ainda mais marcadores de log. <br><br>  Esper√°vamos que ser√≠amos capazes de impedir que os cont√™ineres proxy congelassem se entr√°ssemos em detalhes do que estava acontecendo dentro do sistema e simplific√°ssemos a l√≥gica de sua opera√ß√£o.  Mas isso n√£o funcionou.  Depois de duas semanas tentando tornar o proxy mais confi√°vel, nos sentimos presos.  Era necess√°rio tomar uma decis√£o.  Decidimos correr o risco e deixar o proxy como est√°, pois √© melhor dedicar tempo √† migra√ß√£o do que tentar consertar um software que se tornar√° desnecess√°rio em um m√™s.  Pagamos por essa solu√ß√£o com mais duas falhas - quase dois minutos cada -, mas isso tinha que ser feito. <br><br>  Avance para mar√ßo de 2018, quando j√° conclu√≠mos a migra√ß√£o para o CODE sem sacrificar o desempenho da API ou a experi√™ncia do cliente no CMS.  Agora poder√≠amos come√ßar a pensar em anular proxies do CODE. <br><br>  O primeiro passo foi alterar as prioridades da API para que o proxy interagisse primeiro com o Postgres.  Como dissemos acima, isso foi decidido por uma altera√ß√£o nas configura√ß√µes.  No entanto, houve uma dificuldade. <br><br>  O compositor envia mensagens para o fluxo Kinesis ap√≥s atualizar o documento.  Apenas uma API precisava enviar mensagens para evitar duplica√ß√£o.  Para isso, as APIs t√™m um sinalizador na configura√ß√£o: true para a API suportada pelo Mongo e false para o Postgres suportado.  Simplesmente alterar o proxy para interagir primeiro com o Postgres n√£o foi suficiente, pois a mensagem n√£o seria enviada ao fluxo do Kinesis at√© que a solicita√ß√£o chegasse ao Mongo.  J√° faz muito tempo. <br><br>  Para resolver esse problema, criamos pontos de extremidade HTTP para alterar instantaneamente a configura√ß√£o de todas as inst√¢ncias do balanceador de carga em tempo real.  Isso nos permitiu conectar a API principal muito rapidamente, sem a necessidade de editar o arquivo de configura√ß√£o e reimplementar.  Al√©m disso, isso pode ser automatizado, reduzindo a intera√ß√£o humana e a probabilidade de erros. <br><br>  Agora, todas as solicita√ß√µes foram enviadas primeiro ao Postgres e a API2 interagiu com o Kinesis.  As substitui√ß√µes podem se tornar permanentes com altera√ß√µes de configura√ß√£o e reimplementa√ß√£o. <br><br>  A pr√≥xima etapa foi remover completamente o proxy e for√ßar os clientes a acessar exclusivamente a API do Postgres.  Como temos muitos clientes, n√£o foi poss√≠vel atualizar cada um deles individualmente.  Portanto, elevamos essa tarefa ao n√≠vel do DNS.  Ou seja, criamos um CNAME no DNS que primeiro apontava para o proxy ELB e mudava para apontar para a API ELB.  Isso permitiu que uma √∫nica altera√ß√£o fosse feita em vez de atualizar cada cliente API individual. <br><br>  √â hora de mudar o PROD.  Embora tenha sido um pouco assustador, bem, porque este √© o principal ambiente de trabalho.  O processo foi relativamente simples, pois tudo foi decidido alterando as configura√ß√µes.  Al√©m disso, √† medida que um marcador de est√°gio foi adicionado aos logs, tornou-se poss√≠vel re-criar um perfil dos pain√©is constru√≠dos anteriormente, simplesmente atualizando o filtro Kibana. <br><br>  <b>Desativando proxies e Mongo DB</b> <br><br>  Ap√≥s 10 meses e 2,4 milh√µes de artigos migrados, finalmente conseguimos desativar toda a infraestrutura relacionada ao Mongo.  Mas primeiro, tivemos que fazer o que est√°vamos esperando: matar o proxy. <br><br><img src="https://habrastorage.org/webt/6q/g5/ck/6qg5cksqesrnoig3gxnu7kfea-i.png" alt="imagem"><br>  <i>Logs mostrando a desativa√ß√£o do proxy flex√≠vel da API.</i>  <i>Fotografia: Editorial Tools / Guardian</i> <br><br>  Esse pequeno software nos causou tantos problemas que ansiamos por desconect√°-lo em breve!  Tudo o que tivemos que fazer foi atualizar o registro CNAME para apontar diretamente para o balanceador de carga APIV2. <br>  Toda a equipe se reuniu em torno de um computador.  Era necess√°rio pressionar apenas uma tecla.  Todo mundo prendeu a respira√ß√£o!  Sil√™ncio completo ... Clique!  O trabalho est√° feito.  E nada voou!  Todos n√≥s exalamos alegremente. <br><br>  No entanto, a remo√ß√£o da antiga API do Mongo DB foi repleta de mais um teste.  Desesperados para remover o c√≥digo antigo, descobrimos que nossos testes de integra√ß√£o nunca foram ajustados para usar a nova API.  Tudo rapidamente ficou vermelho.  Felizmente, a maioria dos problemas estava relacionada √† configura√ß√£o e os corrigimos facilmente.  Houve v√°rios problemas com as consultas do PostgreSQL que foram detectados pelos testes.  Pensando no que poderia ser feito para evitar esse erro, aprendemos uma li√ß√£o: ao iniciar uma grande tarefa, reconcilie que haver√° erros. <br><br>  Depois disso, tudo funcionou sem problemas.  Desconectamos todas as inst√¢ncias do Mongo do OpsManager e depois as desconectamos.  A √∫nica coisa que faltava fazer era comemorar.  E durma. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt436416/">https://habr.com/ru/post/pt436416/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt436400/index.html">Configure o ambiente de desenvolvimento para aprender HTML, CSS, PHP no Windows</a></li>
<li><a href="../pt436404/index.html">Balanceamento de tr√°fego VoIP tolerante a falhas. Troca de carga entre data centers no hor√°rio de pico</a></li>
<li><a href="../pt436406/index.html">Como se tornar um desenvolvedor de jogos, se voc√™ √© um corretor de im√≥veis</a></li>
<li><a href="../pt436408/index.html">Modelagem num√©rica - a hist√≥ria de um projeto</a></li>
<li><a href="../pt436412/index.html">Visita fotogr√°fica ao novo escrit√≥rio de Boston no Facebook</a></li>
<li><a href="../pt436420/index.html">O maior lix√£o da hist√≥ria: 2,7 bilh√µes de contas, das quais 773 milh√µes s√£o √∫nicas</a></li>
<li><a href="../pt436422/index.html">A imita√ß√£o n√£o pode ser uma estrat√©gia de desenvolvimento de produto.</a></li>
<li><a href="../pt436424/index.html">Pequenas criaturas, grandes feitos: o papel dos cortadores de folhas no efeito estufa dos neotr√≥picos</a></li>
<li><a href="../pt436426/index.html">Pausar o aplicativo se a conex√£o de rede for perdida</a></li>
<li><a href="../pt436428/index.html">Por que torcemos pela programa√ß√£o esportiva</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§µüèΩ üî£ ü•§ Fonctionnement du codec vid√©o. Partie 1. Bases ü§πüèæ üë®‚Äçüíº üç©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Deuxi√®me partie: Fonctionnement du codec vid√©o 

 Toute image raster peut √™tre repr√©sent√©e comme une matrice √† deux dimensions . En ce qui concerne le...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Fonctionnement du codec vid√©o. Partie 1. Bases</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/edison/blog/481418/"><h3>  Deuxi√®me partie: <a href="https://habr.com/ru/company/edison/blog/480430/">Fonctionnement du codec vid√©o</a> </h3><br><hr><br>  Toute <b>image</b> raster peut √™tre repr√©sent√©e comme une <b>matrice √† deux dimensions</b> .  En ce qui concerne les couleurs, l'id√©e peut √™tre d√©velopp√©e en regardant l'image sous la forme d'une <b>matrice tridimensionnelle</b> , dans laquelle des mesures suppl√©mentaires sont utilis√©es pour stocker des donn√©es pour chacune des couleurs. <br><br>  Si nous consid√©rons la couleur finale comme une combinaison de ce qu'on appelle  couleurs primaires (rouge, vert et bleu), dans notre matrice tridimensionnelle, nous d√©terminons trois plans: le premier pour le rouge, le second pour le vert et le dernier pour le bleu. <br><div style="text-align:center;"><img width="746" height="235" src="https://habrastorage.org/webt/gz/rx/7q/gzrx7qp8p_kzdeb2cat-raur3sk.png" alt="Matrice RVB 3D" title="Matrice RVB 3D"></div><br>  Nous appellerons chaque point de cette matrice un pixel (√©l√©ment image).  Chaque pixel contient des informations d'intensit√© (g√©n√©ralement sous la forme d'une valeur num√©rique) de chaque couleur.  Par exemple, un <b>pixel rouge</b> signifie qu'il a 0 vert, 0 bleu et rouge maximum.  <b>Un pixel rose</b> peut √™tre form√© en utilisant une combinaison de trois couleurs.  En utilisant une plage num√©rique de 0 √† 255, le pixel rose est d√©fini comme <b>Rouge = 255</b> , <b>Vert = 192</b> et <b>Bleu = 203</b> . <a name="habracut"></a><blockquote> <a href="https://www.edsd.ru/" title="Logiciel EDISON - d√©veloppement web"><img align="left" width="153" height="75" src="https://habrastorage.org/webt/w0/zl/to/w0zltoxvysbr0yeinstkfvw1wbg.png" alt="Logiciel EDISON - d√©veloppement web"></a> <br clear="right">  Cet article a √©t√© publi√© avec le soutien d'EDISON. <br><br>  Nous d√©veloppons des <a href="https://www.edsd.ru/ru/portfolio/tehnologiya/video">applications de vid√©osurveillance, de streaming vid√©o</a> , ainsi que d' <a href="https://www.edsd.ru/videozapis-v-bolnichnoj-operacionnoj-s-vozmozhnostyu-obsuzhdeniya-na-forume">enregistrement vid√©o en salle d'op√©ration</a> . </blockquote><h3>  Techniques alternatives de codage couleur </h3><br>  Pour repr√©senter les couleurs qui composent l'image, il existe de nombreux autres mod√®les.  Par exemple, vous pouvez utiliser une palette index√©e dans laquelle un seul octet est n√©cessaire pour repr√©senter chaque pixel, au lieu des trois n√©cessaires lors de l'utilisation du mod√®le RVB.  Dans un tel mod√®le, vous pouvez utiliser une matrice 2D au lieu d'une matrice 3D pour repr√©senter chaque couleur.  Cela √©conomise de la m√©moire, mais donne moins de couleurs. <br><br><img width="479" height="120" src="https://habrastorage.org/webt/yx/pp/nb/yxppnbcixbaszve4ixpqzbvsrdy.png" alt="Palette NES" title="Palette nda"><br><br><h2>  RVB </h2><br><br>  Par exemple, regardez cette image ci-dessous.  La premi√®re face est enti√®rement peinte.  Les autres sont les plans rouge, vert et bleu (l'intensit√© des couleurs correspondantes est indiqu√©e en niveaux de gris). <br><br><img src="https://habrastorage.org/webt/n1/_6/uc/n1_6uc9on4ze-fixad_o7ijvl1u.png" alt="Intensit√© du canal RVB" title="Intensit√© du canal RVB"><br><br>  Nous voyons que les nuances de rouge dans l'original seront aux m√™mes endroits o√π les parties les plus brillantes de la deuxi√®me personne sont observ√©es.  Alors que l'apport du bleu ne se voit principalement qu'aux yeux de Mario (le dernier visage) et des √©l√©ments de ses v√™tements.  Remarquez o√π les trois plans de couleur apportent le moins de contribution (les parties les plus sombres des images) - c'est la moustache de Mario. <br><br>  Pour stocker l'intensit√© de chaque couleur, un certain nombre de bits est requis - cette valeur est appel√©e <b>profondeur de bits</b> .  Disons que 8 bits sont d√©pens√©s (sur la base d'une valeur de 0 √† 255) sur un plan de couleur.  Ensuite, nous avons une profondeur de couleur de 24 bits (8 bits * 3 plan R / G / B). <br><br>  Une autre propri√©t√© de l'image est la <b>r√©solution</b> , qui est le nombre de pixels dans une dimension.  Il est souvent appel√© <b>largeur √ó hauteur</b> , comme ci-dessous dans l'exemple d'image 4 par 4. <br><img width="401" height="185" src="https://habrastorage.org/webt/5q/2i/so/5q2isolirmyfjxl-hb7m4hj_7au.png" alt="R√©solution d'image" title="R√©solution d'image"><br><br>  Une autre propri√©t√© que nous traitons lorsque nous travaillons avec des images / vid√©o est le <b>rapport d'aspect</b> , qui d√©crit la relation proportionnelle habituelle entre la largeur et la hauteur d'une image ou d'un pixel. <br><br>  Lorsqu'ils disent qu'un film ou une image mesure 16 x 9, cela se r√©f√®re g√©n√©ralement au <b>rapport d'aspect de l'affichage</b> ( <b>DAR</b> - de <i>Display Aspect Ratio</i> ).  Cependant, il peut parfois y avoir diff√©rentes formes de pixels individuels - dans ce cas, nous parlons du <b>rapport des pixels</b> ( <b>PAR</b> - de <i>Pixel Aspect Ratio</i> ). <br><br><img width="536" height="254" src="https://habrastorage.org/webt/xg/mb/gp/xgmbgpydyzkiraifaxf9ltiqkxq.png" alt="Afficher le rapport hauteur / largeur" title="Afficher le rapport hauteur / largeur"><br><br><img width="725" height="318" src="https://habrastorage.org/webt/sg/ti/eq/sgtieqvisg6eu5oaddpmfxmrxnm.png" alt="rapport hauteur / largeur pixel" title="rapport hauteur / largeur pixel"><br><blockquote>  Note √† l'h√¥tesse: le <b>DVD</b> correspond au <b>DAR 4 par 3</b> <br><br>  Bien que la r√©solution r√©elle du DVD soit de 704x480, il conserve n√©anmoins un rapport d'aspect de 4: 3 puisque le PAR est r√©gl√© √† 10:11 (704x10 / 480x11). </blockquote><br>  Et enfin, nous pouvons d√©finir une <b>vid√©o</b> comme une s√©quence de <b>n</b> images sur une p√©riode de <b>temps</b> , qui peut √™tre consid√©r√©e comme une dimension suppl√©mentaire.  Et <b>n</b> est alors la fr√©quence d'images ou le nombre d'images par seconde ( <b>FPS</b> - √† partir d' <i>images par seconde</i> ). <br><br><img width="710" height="240" src="https://habrastorage.org/webt/67/kd/us/67kdus1r36qphfoi1jqqt9uinpy.png" alt="la vid√©o" title="la vid√©o"><br><br>  Le nombre de bits par seconde requis pour afficher une vid√©o est son <b>d√©bit binaire</b> . <br><blockquote>  bitrate = largeur * hauteur * profondeur de bits * images par seconde </blockquote><br>  Par exemple, pour des vid√©os avec 30 images par seconde, 24 bits par pixel, r√©solution 480x240, 82 944 000 bits par seconde ou 82 944 Mbit / s (30x480x240x24) seraient n√©cessaires - mais c'est le cas si vous n'utilisez aucune des m√©thodes de compression. <br><br>  Si le d√©bit binaire est <i>presque constant</i> , il est alors appel√© <i>d√©bit binaire constant</i> ( <b>CBR</b> - √† partir d' <i>un d√©bit binaire constant</i> ).  Mais il peut √©galement varier, dans ce cas, il est appel√© un <i>d√©bit binaire variable</i> ( <b>VBR</b> - √† partir du <i>d√©bit binaire variable</i> ). <br><br>  Ce graphique montre un VBR limit√© lorsque pas trop de bits sont d√©pens√©s dans le cas d'une trame compl√®tement sombre. <br><br><img src="https://habrastorage.org/webt/5l/sb/v-/5lsbv-4t7iucyksv39yyqgqmggs.png" alt="VBR limit√©" title="VBR limit√©"><br><br>  Initialement, les ing√©nieurs ont d√©velopp√© une m√©thode pour doubler la fr√©quence d'images per√ßue d'un affichage vid√©o sans utiliser de bande passante suppl√©mentaire.  Cette m√©thode est connue sous le nom de <b>vid√©o entrelac√©e</b> ;  en gros, il envoie la moiti√© de l'√©cran dans la premi√®re "trame", et l'autre moiti√© dans la "trame" suivante. <br><br>  Actuellement, la visualisation des sc√®nes est principalement r√©alis√©e √† l'aide de <b>la technologie de balayage progressif</b> .  Il s'agit d'une m√©thode d'affichage, de stockage ou de transmission d'images anim√©es dans laquelle toutes les lignes de chaque image sont dessin√©es s√©quentiellement. <br><br><img width="747" height="299" src="https://habrastorage.org/webt/bp/z5/u8/bpz5u84cyduvkd6izoangniaevs.png" alt="  " title="entrelac√© et progressif"><br><br>  Eh bien!  Nous savons maintenant comment l'image est repr√©sent√©e sous forme num√©rique, comment ses couleurs sont organis√©es, combien de bits par seconde nous d√©pensons pour montrer la vid√©o si la vitesse de transmission est constante (CBR) ou variable (VBR).  Nous connaissons une r√©solution donn√©e en utilisant une fr√©quence d'images donn√©e, nous nous sommes familiaris√©s avec de nombreux autres termes, tels que vid√©o entrelac√©e, PAR et quelques autres. <br><br><h2>  Suppression de la redondance </h2><br>  Il est connu que la vid√©o sans compression ne peut pas √™tre utilis√©e normalement.  La vid√©o horaire avec une r√©solution de 720p et une fr√©quence de 30 images par seconde occuperait 278 Go.  On arrive √† cette valeur en multipliant 1280 x 720 x 24 x 30 x 3600 (largeur, hauteur, bits par pixel, FPS et temps en secondes). <br><br>  L'utilisation <b>d'algorithmes de compression sans perte</b> comme DEFLATE (utilis√© dans PKZIP, Gzip et PNG) ne r√©duira pas suffisamment la bande passante requise.  Vous devez chercher d'autres moyens de compresser la vid√©o. <br><br>  Pour cela, vous pouvez utiliser les fonctionnalit√©s de notre vision.  On distingue une meilleure luminosit√© que les couleurs.  Une vid√©o est un ensemble d'images s√©quentielles qui se r√©p√®tent au fil du temps.  Il existe de petites diff√©rences entre les images adjacentes de la m√™me sc√®ne.  De plus, chaque cadre contient de nombreuses zones qui utilisent la m√™me couleur (ou similaire). <br><br><h2>  Couleur, luminosit√© et nos yeux </h2><br>  Nos yeux sont plus sensibles √† la luminosit√© qu'√† la couleur.  Vous pouvez voir par vous-m√™me en regardant cette photo. <br><br><div style="text-align:center;"><img width="637" height="239" src="https://habrastorage.org/webt/gj/00/kv/gj00kvz32okevvthxqf9_jqi9ng.png" alt="  " title="luminosit√© versus couleur"></div><br><br>  Si vous ne voyez pas que dans la moiti√© gauche de l'image les couleurs des carr√©s <b>A</b> et <b>B</b> sont en fait les m√™mes, alors c'est normal.  Notre cerveau nous fait porter plus d'attention au clair-obscur qu'√† la couleur.  Sur le c√¥t√© droit entre les carr√©s marqu√©s, il y a un cavalier de la m√™me couleur - donc nous (c'est-√†-dire notre cerveau) pouvons facilement d√©terminer qu'en fait, la m√™me couleur est l√†. <blockquote>  Voyons (simplifi√©) comment nos yeux fonctionnent.  L'≈ìil est un organe complexe compos√© de nombreuses parties.  Cependant, nous sommes plus int√©ress√©s par les c√¥nes et les b√¢tons.  L'≈ìil contient environ 120 millions de b√¢tonnets et 6 millions de c√¥nes. <br><br>  Consid√©rez la perception de la couleur et de la luminosit√© comme des fonctions distinctes de certaines parties de l'≈ìil (en fait, tout est un peu plus compliqu√©, mais nous allons simplifier).  Les cellules en b√¢tonnet sont principalement responsables de la luminosit√©, tandis que les cellules en c√¥ne sont responsables de la couleur.  Les c√¥nes sont divis√©s en trois types, selon le pigment contenu: c√¥nes S (bleu), c√¥nes M (vert) et c√¥nes L (rouge). <br><br>  Comme nous avons beaucoup plus de b√¢tonnets (luminosit√©) que de c√¥nes (couleur), nous pouvons conclure que nous sommes plus capables de distinguer les transitions entre l'obscurit√© et la lumi√®re que les couleurs. <br><br><img width="672" height="373" src="https://habrastorage.org/webt/8z/ul/yl/8zulylhy-pkitzl5mubbzdcbswm.jpeg" alt=" " title="maquillage des yeux"><br><br><h2>  Fonctions de sensibilit√© au contraste </h2><br>  Les chercheurs en psychologie exp√©rimentale et dans de nombreux autres domaines ont d√©velopp√© de nombreuses th√©ories de la vision humaine.  Et l'un d'eux est appel√© <b>fonctions de sensibilit√© au contraste</b> .  Ils sont associ√©s √† un √©clairage spatial et temporel.  En bref, il s'agit du nombre de changements n√©cessaires avant que l'observateur ne les voie.  Notez le pluriel du mot ¬´fonction¬ª.  Cela est d√ª au fait que nous pouvons mesurer les fonctions de sensibilit√© pour contraster non seulement avec les images en noir et blanc, mais aussi avec la couleur.  Les r√©sultats de ces exp√©riences montrent que dans la plupart des cas, nos yeux sont plus sensibles √† la luminosit√© qu'√† la couleur. </blockquote>  Puisqu'il est connu que nous sommes plus sensibles √† la luminosit√© de l'image, vous pouvez essayer d'utiliser ce fait. <br><br><h2>  Mod√®le de couleur </h2><br>  Nous avons compris comment travailler avec des images en couleur en utilisant le sch√©ma RVB.  Il existe d'autres mod√®les.  Il existe un mod√®le qui s√©pare la luminance de la couleur et est connu sous le nom de <b>YCbCr</b> .  Soit dit en passant, il existe d'autres mod√®les qui font une s√©paration similaire, mais nous ne consid√©rerons que celui-ci. <br><br>  Dans ce mod√®le de couleur, <b>Y</b> est une repr√©sentation de la luminosit√© et deux canaux de couleur sont utilis√©s: <b>Cb</b> (bleu satur√©) et <b>Cr</b> (rouge satur√©).  YCbCr peut √™tre obtenu √† partir de RGB, ainsi que la transformation inverse est possible.  En utilisant ce mod√®le, nous pouvons cr√©er des images en couleur, comme nous le voyons ci-dessous: <br><br><img src="https://habrastorage.org/webt/_y/ee/3x/_yee3xnjjk7xq1mpw_bvndfsnru.png" alt=" ycbcr" title="exemple ycbcr"><br><br><h2>  Convertir entre YCbCr et RGB </h2><br>  Quelqu'un objectera: comment est-il possible d'obtenir toutes les couleurs si le vert n'est pas utilis√©? <br><br>  Pour r√©pondre √† cette question, convertissez RVB en YCbCr.  Nous utilisons les coefficients adopt√©s dans la <b>norme BT.601</b> , qui a √©t√© recommand√©e par l'unit√© <b>UIT-R</b> .  Cette unit√© d√©finit les normes vid√©o num√©riques.  Par exemple: qu'est-ce que la 4K?  Quelle devrait √™tre la fr√©quence d'images, la r√©solution, le mod√®le de couleur? <br><br>  Tout d'abord, nous calculons la luminosit√©.  Nous utilisons les constantes propos√©es par l'UIT et rempla√ßons les valeurs RVB. <br><br>  <b>Y</b> = 0,299 <b>R</b> + 0,587 <b>G</b> + 0,114 <b>B</b> <br><br>  Apr√®s avoir obtenu la luminosit√©, nous s√©parerons les couleurs bleues et rouges: <br><br>  <b>Cb</b> = 0,564 ( <b>B</b> - <b>Y</b> ) <br><br>  <b>Cr</b> = 0,713 ( <b>R</b> - <b>Y</b> ) <br><br>  Et nous pouvons √©galement reconvertir et m√™me passer au vert avec YCbCr: <br><br>  <b>R</b> = <b>Y</b> + 1,402 <b>Cr</b> <br><br>  <b>B</b> = <b>Y</b> + 1,772 <b>Cb</b> <br><br>  <b>G</b> = <b>Y</b> - 0,344 <b>Cb</b> - 0,714 <b>Cr</b> <br><br>  En r√®gle g√©n√©rale, les √©crans (moniteurs, t√©l√©viseurs, √©crans, etc.) utilisent uniquement le mod√®le RVB.  Mais ce mod√®le peut √™tre organis√© de diff√©rentes mani√®res: <br><br><img width="550" height="550" src="https://habrastorage.org/webt/rq/is/by/rqisbywjfks_tvcpk7liyvyaiqw.jpeg" alt=" " title="g√©om√©trie des pixels"><br><br><h2>  Sous-√©chantillonnage des couleurs </h2><br>  Avec l'image pr√©sent√©e comme une combinaison de luminosit√© et de couleur, nous pouvons utiliser une sensibilit√© plus √©lev√©e du syst√®me visuel humain √† la luminosit√© qu'√† la couleur si nous supprimons s√©lectivement des informations.  Le sous-√©chantillonnage des couleurs est une m√©thode d'encodage d'images utilisant une r√©solution plus faible pour la couleur que pour la luminosit√©. <br><br><div style="text-align:center;"><img width="715" height="361" src="https://habrastorage.org/webt/ce/ee/9_/ceee9_x9vh8b_vpklek7rnhvoz0.png" alt="ycbcr  " title="Autorisations de sous-√©chantillonnage Ycbcr"></div><br><br>  Est-il acceptable de r√©duire la r√©solution des couleurs?!  Il s'av√®re qu'il existe d√©j√† quelques sch√©mas qui d√©crivent comment g√©rer la r√©solution et la fusion <nobr>(couleur finale = Y + Cb + Cr).</nobr> <br><br>  Ces sch√©mas sont connus sous le nom de <b>syst√®mes de sous-√©chantillonnage</b> et sont exprim√©s sous la forme d'un rapport triple - <b>a</b> : <b>x</b> : <b>y</b> , qui d√©termine le nombre d'√©chantillons de signaux de luminance et de diff√©rence de couleur. <br><br>  <b>a</b> - √©chantillonnage horizontal standard (g√©n√©ralement √©gal √† 4) <br>  <b>x</b> - le nombre d'√©chantillons de couleur dans la premi√®re rang√©e de pixels (r√©solution horizontale par rapport √† <b>a</b> ) <br>  <b>y</b> est le nombre de changements dans les √©chantillons de couleurs entre les premi√®re et deuxi√®me rang√©es de pixels. <blockquote>  L'exception est <b>4</b> : <b>1</b> : <b>0</b> , qui fournit un √©chantillon de couleur dans chaque bloc de r√©solution de luminosit√© 4 x 4. </blockquote>  Sch√©mas courants utilis√©s dans les codecs modernes: <br><br><ul><li>  <b>4</b> : <b>4</b> : <b>4</b> (sans sous-√©chantillonnage) </li><li>  <b>4</b> : <b>2</b> : <b>2</b> </li><li>  <b>4</b> : <b>1</b> : <b>1</b> </li><li>  <b>4</b> : <b>2</b> : <b>0</b> </li><li>  <b>4</b> : <b>1</b> : <b>0</b> </li><li>  <b>3</b> : <b>1</b> : <b>1</b> </li></ul><blockquote><h3>  YCbCr 4: 2: 0 - Exemple de fusion </h3><br>  Voici le fragment d'image combin√© utilisant YCbCr 4: 2: 0.  Veuillez noter que nous ne d√©pensons que 12 bits par pixel. <br><br><div style="text-align:center;"><img width="555" height="315" src="https://habrastorage.org/webt/yq/fj/oi/yqfjoiza1glbn0rcj4nl0gfrsrm.png" alt="YCbCr 4:2:0" title="YCbCr 4: 2: 0"></div></blockquote>  Voici √† quoi ressemble la m√™me image encod√©e par les principaux types de sous-√©chantillonnage des couleurs.  La premi√®re ligne est le YCbCr final, la ligne du bas montre la r√©solution des couleurs.  Des r√©sultats tr√®s d√©cents, compte tenu de la faible perte de qualit√©. <br><br><img src="https://habrastorage.org/webt/q5/g_/-f/q5g_-f0w41riagjrnt3msc0a-us.jpeg" alt="  " title="exemples de sous-√©chantillonnage de chrominance"><br><br>  Rappelez-vous, nous avons compt√© 278 Go d'espace de stockage pour un fichier vid√©o d'une heure avec une r√©solution de 720p et 30 images par seconde?  Si nous utilisons YCbCr 4: 2: 0, cette taille sera r√©duite de moiti√© - 139 Go.  Jusqu'√† pr√©sent, c'est encore loin d'un r√©sultat acceptable. <br><br>  Vous pouvez obtenir l'histogramme YCbCr vous-m√™me avec FFmpeg.  Dans cette image, le bleu pr√©vaut sur le rouge, qui est clairement visible sur l'histogramme lui-m√™me. <br><br><img src="https://habrastorage.org/webt/gj/wa/lr/gjwalry6l_oeqssuishxlxtjrae.png"><blockquote><h4>  Couleur, luminosit√©, gamme de couleurs - examen vid√©o </h4><br>  Il est recommand√© de regarder cette superbe vid√©o.  Cela explique ce qu'est la luminosit√©, et en effet, tous les points sont plac√©s au- <i>dessus</i> de la luminosit√© et de la couleur. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Ymt47wXUDEU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></blockquote><h2>  Types de montures </h2><br>  Nous continuons.  Essayons d'√©liminer la redondance dans le temps.  Mais d'abord, d√©finissons une terminologie de base.  Supposons que nous ayons un film avec 30 images par seconde, voici ses 4 premi√®res images: <br><br><img width="64" height="64" src="https://habrastorage.org/webt/iv/6n/5x/iv6n5xrkspmna4ysdwmx-geaavg.png" alt="ball 1" title="balle 1"><img width="64" height="64" src="https://habrastorage.org/webt/yx/pm/jb/yxpmjbgftbludyfwblix9e51mie.png" alt="ball 2" title="boule 2"><img width="64" height="64" src="https://habrastorage.org/webt/gp/wk/no/gpwknos5yniugafyfj-hk_a1pkk.png" alt="ball 3" title="boule 3"><img width="64" height="64" src="https://habrastorage.org/webt/-k/22/81/-k228175bwr2raujpfa-72p7hnm.png" alt="ball 4" title="boule 4"><br><br>  Nous pouvons voir de nombreuses r√©p√©titions dans les cadres: par exemple, un fond bleu qui ne change pas d'un cadre √† l'autre.  Pour r√©soudre ce probl√®me, nous pouvons les classer de mani√®re abstraite en trois types de trames. <br><br><h3>  Cadre <b>I</b> (cadre <b>I</b> ntro) </h3><br>  La trame I (trame de r√©f√©rence, trame cl√©, trame interne) est autonome.  Ind√©pendamment de ce qui doit √™tre visualis√©, le cadre en I est, en fait, une photographie statique.  La premi√®re image est g√©n√©ralement une I-frame, mais nous observerons r√©guli√®rement des I-frames loin des premi√®res images. <br><br><img width="64" height="64" src="https://habrastorage.org/webt/iv/6n/5x/iv6n5xrkspmna4ysdwmx-geaavg.png" alt="ball 1" title="balle 1"><br><br><h3>  Cadre <b>P</b> (cadre <b>P</b> reddit) </h3><br>  L'image P (image pr√©dite) tire parti du fait que presque toujours l'image actuelle peut √™tre lue en utilisant l'image pr√©c√©dente.  Par exemple, dans la deuxi√®me image, le seul changement est la balle avant.  Nous pouvons obtenir l'image 2 en modifiant l√©g√®rement l'image 1, en utilisant uniquement la diff√©rence entre ces images.  Pour construire le cadre 2, reportez-vous au cadre 1 qui le pr√©c√®de. <br><br><img width="64" height="64" src="https://habrastorage.org/webt/iv/6n/5x/iv6n5xrkspmna4ysdwmx-geaavg.png" alt="ball 1" title="balle 1">  ‚Üê <img width="64" height="64" src="https://habrastorage.org/webt/3o/-a/-_/3o-a-_o0jmv5vrg6wu2jmma0xpo.png" alt=" 1" title="balle 1"><br><br><h3>  Trame <b>B</b> (trame <b>B</b> i-pr√©dictive) </h3><br>  Qu'en est-il des liens non seulement vers les images pass√©es, mais aussi vers les images futures, pour une compression encore meilleure?  Il s'agit essentiellement d'une trame B (trame bidirectionnelle). <br><br><img width="64" height="64" src="https://habrastorage.org/webt/iv/6n/5x/iv6n5xrkspmna4ysdwmx-geaavg.png" alt="ball 1" title="balle 1">  ‚Üê <img width="64" height="64" src="https://habrastorage.org/webt/3o/-a/-_/3o-a-_o0jmv5vrg6wu2jmma0xpo.png" alt=" 1" title="balle 1">  ‚Üí <img width="64" height="64" src="https://habrastorage.org/webt/gp/wk/no/gpwknos5yniugafyfj-hk_a1pkk.png" alt="ball 3" title="boule 3"><br><br><h2>  Retrait interm√©diaire </h2><br>  Ces types de trames sont utilis√©s pour fournir la meilleure compression.  Nous verrons comment cela se produit dans la section suivante.  En attendant, on note que l'image I est la plus ¬´ch√®re¬ª en termes de m√©moire, l'image P est beaucoup moins ch√®re, mais l'image B est l'option la plus rentable pour la vid√©o. <br><br><img src="https://habrastorage.org/webt/kb/tq/iv/kbtqivaoykzul7air0x-bi4p0nk.png" alt="  " title="exemple de types de trame"><br><br><h2>  Redondance temporelle (pr√©diction inter-trames) </h2><br>  Voyons quelles opportunit√©s nous avons pour minimiser les r√©p√©titions de temps.  Ce type de redondance peut √™tre r√©solu en utilisant les m√©thodes de pr√©vision mutuelle. <br><br>  Nous allons essayer de d√©penser le moins de bits possible pour encoder une s√©quence de trames 0 et 1. <br><br><img width="489" height="249" src="https://habrastorage.org/webt/_r/or/uu/_roruusxx8nchbiamc6hxqxv7ns.png" alt=" " title="cadres originaux"><br><br>  Nous pouvons <b>soustraire</b> , simplement soustraire l'image 1 de l'image 0. Nous obtenons l'image 1, nous utilisons uniquement la diff√©rence entre celle-ci et l'image pr√©c√©dente, en fait, nous encodons uniquement le reste r√©sultant. <br><br><img width="334" height="330" src="https://habrastorage.org/webt/lz/1q/vm/lz1qvmad3_cjsaulbo4dy-qfwuc.png" alt=" " title="cadres delta"><br><br>  Mais que se passe-t-il si je vous dis qu'il existe une m√©thode encore meilleure qui utilise encore moins de bits?!  Tout d'abord, d√©composons l'image 0 en une grille claire de blocs.  Et puis nous essayons de comparer les blocs de l'image 0 avec l'image 1. En d'autres termes, nous √©valuons le mouvement entre les images. <blockquote>  De Wikipedia - <b>compensation de mouvement de bloc</b> <br><br>  La compensation de mouvement de bloc divise la trame actuelle en blocs disjoints et le vecteur de compensation de mouvement signale l'origine des blocs (une id√©e fausse commune est que la trame <i>pr√©c√©dente</i> est divis√©e en blocs disjoints, et les vecteurs de compensation de mouvement indiquent o√π vont ces blocs. Mais en fait, pas le pr√©c√©dent n'est analys√© le cadre, et le suivant, il s'av√®re non pas o√π les blocs se d√©placent, mais d'o√π ils viennent).  En r√®gle g√©n√©rale, les blocs source se chevauchent dans le cadre source.  Certains algorithmes de compression vid√©o collectent l'image actuelle √† partir de parties non seulement d'une, mais de plusieurs images pr√©c√©demment transmises. </blockquote><img width="489" height="249" src="https://habrastorage.org/webt/mm/0n/r3/mm0nr3fmjnihn1xgvgeip8lnqcy.png" alt=" " title="cadres delta"><br><br>  Dans le processus d'√©valuation, nous voyons que la balle est pass√©e de <nobr>(</nobr> <b>x</b> = 0, <b>y</b> = 25) √† <nobr>(</nobr> <b>x</b> = 6, <b>y</b> = 26), les valeurs de <b>x</b> et <b>y</b> d√©terminent le vecteur de mouvement.  Une autre √©tape que nous pouvons prendre pour enregistrer les bits est de coder uniquement la diff√©rence des vecteurs de mouvement entre la derni√®re position du bloc et celle pr√©dite, de sorte que le vecteur de mouvement final sera <nobr>(x = 6-0 = 6, y = 26-25 = 1).</nobr> <br><br>  Dans une situation r√©elle, cette balle serait divis√©e en <b>n</b> blocs, mais cela ne change pas l'essence de la question. <br><br>  Les objets dans le cadre se d√©placent en trois dimensions, donc lorsque la balle se d√©place, elle peut devenir visuellement plus petite (ou plus si elle se d√©place vers le spectateur).  Il est normal qu'il n'y ait pas de correspondance parfaite entre les blocs.  Voici une vue combin√©e de notre √©valuation et de l'image r√©elle. <br><br><img width="374" height="361" src="https://habrastorage.org/webt/g2/0v/lf/g20vlfrxrjfd2z5jopsrwtjeayu.png" alt=" " title="estimation du mouvement"><br><br>  Mais nous voyons que lorsque nous appliquons l'estimation de mouvement, les donn√©es pour l'encodage sont sensiblement inf√©rieures √† celles de la m√©thode plus simple de calcul du delta entre les images. <br><br><img width="489" height="249" src="https://habrastorage.org/webt/al/yh/um/alyhumga0r2vz1sduqqpbbfwsf0.png" alt="   " title="delta d'estimation de mouvement"><br><br><h2>  √Ä quoi ressemblera la compensation de mouvement r√©elle </h2><br>  Cette technique s'applique imm√©diatement √† tous les blocs.  Souvent, notre balle en mouvement conditionnelle sera divis√©e en plusieurs blocs √† la fois. <br><br><img src="https://habrastorage.org/webt/qd/r9/zi/qdr9zittbih-suwng4vhcktrini.png" alt="    " title="    "><br><br>      ,  <a href="https://jupyter.org/">Jupyter</a> . <br><br>             <a href="https://www.ffmpeg.org/">ffmpeg</a> . <br><br><img width="730" height="434" src="https://habrastorage.org/webt/8p/fz/y4/8pfzy4_x_u8rhx0e-qdwggcfz18.png" alt="  ( )   ffmpeg" title="  ( )   ffmpeg"><br><br>    <a href="https://software.intel.com/en-us/video-pro-analyzer">Intel Video Pro Analyzer</a> ( ,     ,      ). <br><br><img src="https://habrastorage.org/webt/gi/xv/2x/gixv2xsurl-vpyoqppvr_w9qtc4.png" alt="    " title="    "><br><br><h2>   ( ) </h2><br>      ,     . <br><br><img width="550" height="312" src="https://habrastorage.org/webt/cy/rt/wu/cyrtwua6vufuvoommyb-3ggyfu0.png"><br><br>    .          . <br><br><img width="277" height="156" src="https://habrastorage.org/webt/-i/yr/8r/-iyr8rtaba0yxiwgvrp0xzhpghg.png"><br><br>  I-.       ,    .    .      ,  ,     -  . <br><br><img width="278" height="413" src="https://habrastorage.org/webt/pi/2l/bg/pi2lbg2js6klz5_qepjcqtgevqq.png"><br><br> ,       .  ,         . <br><br><img width="246" height="404" src="https://habrastorage.org/webt/wy/qe/zt/wyqezt5qtss2h37wim8itgpgobe.png"><br><br>      .         (  ),      .     ,           . <br><br><img src="https://habrastorage.org/webt/ks/at/av/ksatavivnluz7pgxmawvtgixu1y.png"><br><br>      ,            ffmpeg.           ffmpeg. <br><br><img src="https://habrastorage.org/webt/70/pd/tq/70pdtqqlhlx-atda44tfwrygtna.png" alt="  ()   ffmpeg" title="  ( )   ffmpeg"><br><br>     Intel Video Pro Analyzer (    ,        10 ,       ). <br><br><img src="https://habrastorage.org/webt/_e/3x/f-/_e3xf-wuez64lr6x89oxhozl0a4.png" alt="Analyseur Intel Video Pro intra-pr√©diction" title="Analyseur intelligent Intel Pro"><br><br><hr><br><h3>  : <a href="https://habr.com/ru/company/edison/blog/480430/">  </a> </h3><br><hr><br><br> <a href="https://habr.com/ru/company/edison/blog/485460/"><img align="right" width="404" height="150" src="https://habrastorage.org/webt/2b/9i/gm/2b9igmgpbxunecpetjj6hhqsa9m.png"></a> <br clear="left"><h4>  Lisez aussi le blog <br>  Soci√©t√© EDISON: </h4><br>  <a href="https://habr.com/ru/company/edison/blog/485460/"><b>20 biblioth√®ques pour</b></a> <a href="https://habr.com/ru/company/edison/blog/485460/"><b><br></b></a>  <a href="https://habr.com/ru/company/edison/blog/485460/"><b>application iOS spectaculaire</b></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr481418/">https://habr.com/ru/post/fr481418/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr481394/index.html">Recr√©er dans un nouveau jeu ce que nous aimions pour les anciens</a></li>
<li><a href="../fr481398/index.html">Commandes Linux de base pour les testeurs et plus</a></li>
<li><a href="../fr481402/index.html">Impl√©mentation paresseuse de la travers√©e d'un arbre d'enfants de la classe QObject</a></li>
<li><a href="../fr481406/index.html">Immersion profonde dans l'investissement d'Ilona Mask</a></li>
<li><a href="../fr481416/index.html">Annonce du deuxi√®me Meetup AWS √† Minsk (13/02/2020)</a></li>
<li><a href="../fr481420/index.html">15 meilleures et plus grandes biblioth√®ques d'ic√¥nes</a></li>
<li><a href="../fr481424/index.html">Commandes personnalis√©es en angulaire</a></li>
<li><a href="../fr481426/index.html">Avantages de l'architecture de microservices pour le d√©veloppement de logiciels</a></li>
<li><a href="../fr481428/index.html">Jeu pour les programmeurs FuncBall</a></li>
<li><a href="../fr481430/index.html">Comment restaurer une revue scientifique dans la liste HAC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
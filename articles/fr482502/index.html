<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòî ‚òØÔ∏è üí° 5,8 millions d'IOPS: pourquoi autant? üïç üë®‚Äçüë¶‚Äçüë¶ üßíüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut Habr! Les ensembles de donn√©es pour le Big Data et l'apprentissage automatique connaissent une croissance exponentielle et doivent √™tre trait√©s....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>5,8 millions d'IOPS: pourquoi autant?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/kingston_technology/blog/482502/">  Salut Habr!  Les ensembles de donn√©es pour le Big Data et l'apprentissage automatique connaissent une croissance exponentielle et doivent √™tre trait√©s.  Notre article sur une autre technologie innovante en calcul haute performance (HPC), pr√©sent√©e sur le stand de Kingston au <a href="https://sc19.supercomputing.org/">Supercomputing 2019</a> .  Il s'agit de l'utilisation de syst√®mes de stockage haut de gamme (SHD) dans des serveurs dot√©s de processeurs graphiques (GPU) et de la technologie de bus de stockage GPUDirect.  Gr√¢ce √† l'√©change de donn√©es direct entre le stockage et les GPU, en contournant le CPU, le chargement des donn√©es dans les acc√©l√©rateurs de GPU est acc√©l√©r√© d'un ordre de grandeur, donc les applications Big Data fonctionnent aux performances maximales fournies par le GPU.  √Ä leur tour, les d√©veloppeurs de syst√®mes HPC sont int√©ress√©s par les r√©alisations dans le domaine du stockage avec la vitesse d'entr√©e / sortie la plus √©lev√©e - comme celles publi√©es par Kingston. <br><br><img src="https://habrastorage.org/webt/b8/2i/xn/b82ixn44lhhvlqyxr16byft_s7e.jpeg"><br><a name="habracut"></a><br><h2>  Performances du GPU avant le chargement des donn√©es </h2><br>  Depuis la cr√©ation de CUDA, une architecture informatique parall√®le mat√©rielle et logicielle bas√©e sur GPU pour le d√©veloppement d'applications √† usage g√©n√©ral, en 2007, les capacit√©s mat√©rielles des GPU elles-m√™mes se sont consid√©rablement accrues.  Aujourd'hui, les GPU sont de plus en plus utilis√©s dans le domaine des applications HPC telles que le Big Data, le machine learning et le deep learning. <br><br>  Notez que malgr√© la similitude des termes, les deux derniers sont des t√¢ches algorithmiquement diff√©rentes.  ML enseigne un ordinateur bas√© sur des donn√©es structur√©es, et DL enseigne un ordinateur bas√© sur la r√©ponse d'un r√©seau neuronal.  Un exemple qui aide √† comprendre les diff√©rences est assez simple.  Supposons qu'un ordinateur doit distinguer les photos de chats et de chiens charg√©es du stockage.  Pour ML, vous devez soumettre un ensemble d'images avec de nombreuses balises, chacune d√©finissant une caract√©ristique particuli√®re de l'animal.  Pour DL, il suffit de t√©l√©charger un nombre d'images beaucoup plus important, mais avec une seule √©tiquette "c'est un chat" ou "c'est un chien".  DL est tr√®s similaire √† la fa√ßon dont les jeunes enfants sont enseign√©s - on leur montre simplement des images de chiens et de chats dans les livres et dans la vie (le plus souvent, sans m√™me expliquer la diff√©rence d√©taill√©e), et le cerveau de l'enfant lui-m√™me commence √† d√©terminer le type d'animal apr√®s un certain nombre critique d'images √† comparer ( selon les estimations, on parle de cent ou deux impressions pour tout le temps de la petite enfance).  Les algorithmes DL ne sont pas encore aussi parfaits: pour r√©ussir √† travailler sur la d√©finition d'images d'un r√©seau neuronal, il est n√©cessaire de soumettre et de traiter des millions d'images dans le GPU. <br><br>  R√©sultat de la pr√©face: sur la base du GPU, vous pouvez cr√©er des applications HPC dans le domaine des Big Data, ML et DL, mais il y a un probl√®me - les ensembles de donn√©es sont si importants que le temps n√©cessaire pour charger les donn√©es du syst√®me de stockage vers le GPU commence √† r√©duire les performances globales de l'application.  En d'autres termes, les GPU rapides restent sous-charg√©s en raison de la lenteur d'entr√©e / sortie des donn√©es d'autres sous-syst√®mes.  La diff√©rence de vitesse d'entr√©e / sortie du GPU et du bus vers le CPU / SHD peut √™tre d'un ordre de grandeur. <br><br><h2>  Comment fonctionne la technologie de stockage GPUDirect? </h2><br>  Le processus d'entr√©e / sortie est contr√¥l√© par le CPU, ainsi que le processus de chargement des donn√©es du stockage dans les GPU pour un traitement ult√©rieur.  Cela a d√©clench√© une demande de technologie qui fournirait un acc√®s direct entre les disques GPU et NVMe pour une interaction rapide entre eux.  La premi√®re de ces technologies a √©t√© propos√©e par NVIDIA et l'a appel√©e GPUDirect Storage.  En fait, il s'agit d'une variante de la technologie GPUDirect RDMA (Remote Direct Memory Address) qu'ils ont pr√©c√©demment d√©velopp√©e. <br><br><img src="https://habrastorage.org/webt/dp/ol/hi/dpolhi7l7snwfppuormyzcwmovu.jpeg"><br>  <i>Jensen Huang, PDG de NVIDIA, pr√©sente GPUDirect Storage comme une variante de GPUDirect RDMA au SC-19.</i>  <i>Source: NVIDIA</i> <br><br>  La diff√©rence entre GPUDirect RDMA et GPUDirect Storage r√©side dans les p√©riph√©riques entre lesquels l'adressage est effectu√©.  La technologie GPUDirect RDMA est r√©affect√©e pour d√©placer les donn√©es directement entre la carte d'entr√©e d'interface r√©seau (NIC) et la m√©moire GPU, et le stockage GPUDirect fournit un chemin de transfert de donn√©es direct entre le stockage local ou distant, tel que NVMe ou NVMe via Fabric (NVMe-oF) et la m√©moire GPU. <br><br>  Les deux options, GPUDirect RDMA et GPUDirect Storage, √©vitent les mouvements de donn√©es inutiles √† travers un tampon dans la m√©moire du processeur et permettent au m√©canisme DMA (Direct Memory Access) de transf√©rer des donn√©es depuis une carte r√©seau ou un stockage directement vers ou depuis la m√©moire GPU - le tout sans charge sur la centrale processeur  Pour GPUDirect Storage, l'emplacement de stockage n'a pas d'importance: il peut s'agir d'un disque NVME √† l'int√©rieur d'une unit√© GPU, √† l'int√©rieur d'un rack ou connect√© via un r√©seau en tant que NVMe-oF. <br><br><img src="https://habrastorage.org/webt/or/yh/jo/oryhjovu8dmxuqiecan36inssn8.png"><br>  <i>Sch√©ma d'op√©ration de stockage GPUDirect.</i>  <i>Source: NVIDIA</i> <br><br><h2>  Stockage haut de gamme NVMe requis sur le march√© des applications HPC </h2><br>  Comprenant qu'avec l'av√®nement de GPUDirect Storage, l'int√©r√™t des grands clients sera tourn√© vers l'offre de syst√®mes de stockage avec une vitesse d'entr√©e / sortie correspondant √† la bande passante du GPU, Kingston a montr√© un syst√®me de d√©monstration compos√© de syst√®mes de stockage bas√©s sur des disques NVMe et d'une unit√© avec un GPU au SC-19 qui a analys√© des milliers d'images satellites par seconde.  Nous avons d√©j√† √©crit sur un tel stockage sur la base de 10 disques DC1000M U.2 NVMe <a href="https://habr.com/ru/company/kingston_technology/blog/479052/">dans un rapport de l'exposition des supercalculateurs</a> . <br><br><img src="https://habrastorage.org/webt/ot/x2/ap/otx2apc_kz_v_m2azmy8bnnxjn0.jpeg"><br>  <i>Le stockage bas√© sur 10 disques DC1000M U.2 NVMe compl√®te ad√©quatement le serveur avec des acc√©l√©rateurs graphiques.</i>  <i>Source: Kingston</i> <br><br>  Un tel stockage est effectu√© sous la forme d'une unit√© de rack 1U ou plus et peut √™tre mis √† l'√©chelle en fonction du nombre de disques NVMe DC1000M U.2, chacun ayant une capacit√© de 3,84 √† 7,68 To.  Le DC1000M est le premier mod√®le SSD NVMe au format U.2 de la gamme de disques Kingston pour centres de donn√©es.  Il a une cote d'endurance (DWPD, Drive √©crit par jour), ce qui vous permet d'√©craser les donn√©es √† pleine capacit√© une fois par jour pour une dur√©e de vie du lecteur garantie. <br><br>  Dans le test fio v3.13 sur le syst√®me d'exploitation Ubuntu 18.04.3 LTS, noyau Linux 5.0.0-31-g√©n√©rique, le mod√®le de stockage d'exposition a montr√© une vitesse de lecture soutenue de 5,8 millions d'IOPS avec une bande passante soutenue de 23,8 Gb / s. <br><br>  Ariel Perez, directeur commercial des SSD de Kingston, a d√©crit les nouveaux syst√®mes de stockage comme suit: ¬´Nous sommes pr√™ts √† fournir √† la prochaine g√©n√©ration de serveurs des SSD U.2 NVMe pour r√©soudre de nombreux goulots d'√©tranglement de transfert de donn√©es qui √©taient traditionnellement associ√©s au stockage.  La combinaison de disques SSD NVMe et de notre DRAM Server Premium Premium fait de Kingston l'un des fournisseurs de processeurs de donn√©es de bout en bout les plus complets du secteur. ¬ª <br><br><img src="https://habrastorage.org/webt/bw/ov/7l/bwov7lbdbhgfqvtlaxqn40kqba0.jpeg"><br>  <i>Le test gfio v3.13 a montr√© une bande passante de 23,8 Gb / s pour le stockage de d√©monstration sur les disques NVMe DC1000M U.2.</i>  <i>Source: Kingston</i> <br><br>  √Ä quoi ressemblera un syst√®me typique pour les applications HPC qui utilisent la technologie de stockage GPUDirect ou similaire?  Il s'agit d'une architecture avec s√©paration physique des blocs fonctionnels au sein d'un rack: une ou deux unit√©s pour la RAM, quelques autres pour les n≈ìuds de calcul GPU et CPU, et une ou plusieurs unit√©s pour le stockage. <br><br>  Avec l'annonce de GPUDirect Storage et l'√©mergence possible de technologies similaires chez d'autres fournisseurs de GPU, Kingston √©largit sa demande de syst√®mes de stockage con√ßus pour une utilisation dans le calcul haute performance.  Le marqueur sera la vitesse de lecture des donn√©es du syst√®me de stockage, comparable √† la bande passante des cartes r√©seau 40 ou 100 Gbit √† l'entr√©e d'une unit√© informatique avec un GPU.  Ainsi, les syst√®mes de stockage ultra-rapides, y compris les NVMe externes via Fabric, de l'exotic deviendront courants pour les applications HPC.  En plus des calculs scientifiques et financiers, ils trouveront une application dans de nombreux autres domaines pratiques, tels que les syst√®mes de s√©curit√© au niveau de la m√©galopole Safe City ou les centres de surveillance sur les v√©hicules o√π la reconnaissance et l'identification de la vitesse de millions d'images HD par seconde sont n√©cessaires ¬ª, la niche de march√© du top SHD <br><br>  Des informations suppl√©mentaires sur les produits Kingston sont disponibles sur <a href="https://kings.tn/HabrRaidCompany">le site officiel de l'entreprise</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr482502/">https://habr.com/ru/post/fr482502/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr482492/index.html">D√©gel du perg√©lisol et √©missions de gaz √† effet de serre</a></li>
<li><a href="../fr482494/index.html">Mettre √† jour les r√©sultats de l'enqu√™te</a></li>
<li><a href="../fr482496/index.html">R√©sultats: 9 avanc√©es technologiques majeures de 2019</a></li>
<li><a href="../fr482498/index.html">Histoire de l'√©volution des interfaces en Java</a></li>
<li><a href="../fr482500/index.html">Python ou R: quel est le meilleur choix pour la science des donn√©es?</a></li>
<li><a href="../fr482504/index.html">Publier avec des publications: nos r√©sultats pour 2019</a></li>
<li><a href="../fr482506/index.html">Entr√©e de donn√©es dans STM32F4xx √† partir d'ADC parall√®le via DCMI</a></li>
<li><a href="../fr482508/index.html">2019 sur Habr√© en chiffres: il y a plus de publications, moins les m√™mes, commentez plus activement</a></li>
<li><a href="../fr482512/index.html">Ils sont comme nous: en entrant en Chine, oubliez la mentalit√© asiatique particuli√®re</a></li>
<li><a href="../fr482520/index.html">Calcul des remises maximales possibles dans les projets r√©alis√©s sur commande en fonction de la charge actuelle</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
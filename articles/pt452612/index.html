<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèáüèº üíõ ‚úàÔ∏è Aprendizado de m√°quina de rede neural profunda refor√ßada no tensorflow.js: truques üéÖüèº üíù ü§πüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Treinar redes neurais profundas a partir do zero n√£o √© uma tarefa f√°cil. 

 S√£o necess√°rios muitos dados e tempo para aprender, mas alguns truques pod...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aprendizado de m√°quina de rede neural profunda refor√ßada no tensorflow.js: truques</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452612/">  Treinar redes neurais profundas a partir do zero n√£o √© uma tarefa f√°cil. <br><br>  S√£o necess√°rios muitos dados e tempo para aprender, mas alguns truques podem ajudar a acelerar o processo, sobre o qual falarei em detalhes. <br><br>  Demonstra√ß√£o da passagem de um labirinto simples usando truques.  Dura√ß√£o do treinamento em rede: 1 hora 06 minutos.  Grava√ß√£o acelerada em 8 vezes. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/KbuNjZKidpw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  Para cada tarefa, voc√™ precisa desenvolver seu pr√≥prio conjunto de truques para acelerar o aprendizado em rede.  Vou compartilhar alguns truques que me ajudaram a treinar a rede muito mais rapidamente. <br><br>  Para conhecimento te√≥rico, recomendo mudar para o canal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sim0nsays</a> . <br>  E vou contar sobre meus modestos sucessos no treinamento de redes neurais. <br><br><h2>  Declara√ß√£o do problema </h2><br>  <i>Aproximar a fun√ß√£o de converg√™ncia, minimizando a fun√ß√£o de perda quadr√°tica pela propaga√ß√£o reversa do erro por redes neurais profundas.</i> <br><br>  Eu tive uma escolha estrat√©gica sobre como treinar uma rede neural. <br>  Incentive a conclus√£o bem-sucedida da tarefa ou incentive-a √† medida que se aproxima da conclus√£o da tarefa. <br><br>  Eu escolhi o segundo m√©todo, por dois motivos: <br><br><ul><li>  A probabilidade de que a rede atinja a linha de chegada por conta pr√≥pria √© muito pequena, portanto estar√° fadada a receber muito refor√ßo negativo.  Isso redefinir√° o peso de todos os neur√¥nios e a rede n√£o ser√° capaz de treinamento adicional. <br></li><li>  Redes neurais profundas s√£o poderosas.  N√£o excluo que o primeiro m√©todo teria sido bem-sucedido se eu tivesse um enorme poder de computa√ß√£o e muito tempo para treinamento.  Eu segui o caminho de menor custo desenvolvendo truques. <br></li></ul><br><h2>  Arquitetura de rede neural </h2><br>  A arquitetura est√° sendo desenvolvida experimentalmente, com base na experi√™ncia do arquiteto e na boa sorte. <br><br>  Arquitetura para resolver o problema: <br><br><ul><li>  3 neur√¥nios de entrada - as coordenadas do agente e o valor da c√©lula passada (normalizamos no intervalo de 0 a 1). <br></li><li>  2 camadas ocultas de 256 e 128 neur√¥nios (reduzimos a dimens√£o das camadas em dire√ß√£o √† sa√≠da da rede). <br></li><li>  1 camada descartando neur√¥nios aleat√≥rios para a rede de aprendizagem da sustentabilidade. <br></li><li>  4 neur√¥nios de sa√≠da - a probabilidade de decidir qual lado escolher para o pr√≥ximo passo. <br></li><li>  Fun√ß√£o de ativa√ß√£o do neur√¥nio: sigm√≥ide.  Otimizador: adam. <br></li></ul><br>  sigmoid fornece 4 probabilidades na sa√≠da no intervalo de 0 a 1, escolhendo a m√°xima, obtemos o lado para o pr√≥ximo passo: [jumpTop, jumpRight, jumpBottom, jumpLeft]. <br><br><h2>  Desenvolvimento de arquitetura </h2><br>  A reciclagem ocorre ao usar modelos excessivamente complexos. <br><br>  √â quando a rede lembra os dados de treinamento e, para novos dados que a rede ainda n√£o viu, funcionar√° mal porque a rede n√£o precisou procurar generaliza√ß√µes, pois possu√≠a mem√≥ria suficiente para memorizar. <br><br>  Falta de educa√ß√£o - com modelos insuficientemente complexos.  √â quando a rede possui poucos dados de treinamento para encontrar generaliza√ß√µes. <br><br>  <b>Conclus√£o:</b> quanto mais camadas e neur√¥nios neles, mais dados s√£o necess√°rios para o treinamento. <br><br><h2>  Campo de jogo </h2><br><img src="https://habrastorage.org/webt/3n/we/ck/3nweckh5jsx0-pfebojf_yq3n3k.png"><br><br><h3>  Regras do jogo </h3><br>  0 - Ao entrar nesta c√©lula, o agente √© destru√≠do. <br>  1..44 - C√©lulas cujos valores aumentam a cada etapa. <br>  Quanto mais o agente for, mais recompensa ele receber√°. <br>  45 - Concluir.  Ao mesmo tempo, o treinamento n√£o ocorre, apenas quando todos os agentes s√£o destru√≠dos, e o final √© uma exce√ß√£o que simplesmente usa a rede j√° treinada para a pr√≥xima previs√£o, desde o in√≠cio do labirinto. <br><br><h2>  Descri√ß√£o dos par√¢metros </h2><br>  O agente possui uma "antena" em quatro dire√ß√µes - ele desempenha o papel de intelig√™ncia ambiental e √© uma descri√ß√£o das coordenadas do agente e do valor da c√©lula em que est√°. <br><br>  A descri√ß√£o desempenha o papel de prever a pr√≥xima dire√ß√£o para o movimento do agente.  Ou seja, o agente verifica com anteced√™ncia o que vem a seguir e, consequentemente, com o tempo, a rede aprende a se mover na dire√ß√£o de aumentar o valor da c√©lula e n√£o ir al√©m dos limites do movimento permitido. <br><br>  <b>O objetivo da rede neural:</b> obter mais recompensas. <br>  <b>Objetivo do aprendizado: para</b> incentivar a√ß√µes corretas, quanto mais pr√≥ximo o agente estiver da solu√ß√£o da tarefa, maior ser√° a recompensa pela rede neural. <br><br><h2>  Truques </h2><br>  As primeiras tentativas de aprender sem truques levaram v√°rias horas de treinamento e o resultado estava longe de ser completo.  Aplicando certas t√©cnicas, o resultado foi alcan√ßado em apenas uma hora e seis minutos! <br><br><h3>  Loop de agente </h3><br>  Durante o treinamento, a rede come√ßou a tomar decis√µes, fazer movimentos para a frente e para tr√°s - o problema do "uso".  Ambos os movimentos d√£o √† rede uma recompensa positiva, que interrompeu o processo de explora√ß√£o do labirinto e n√£o permitiu sair do m√≠nimo local. <br><br>  A primeira tentativa de uma solu√ß√£o foi limitar o n√∫mero de movimentos do agente, mas isso n√£o foi o ideal, pois o agente passou muito tempo em um loop antes de se autodestruir.  A melhor solu√ß√£o era destruir o agente se ele fosse para a cela com um valor mais baixo do que aquele em que estava - a proibi√ß√£o de seguir na dire√ß√£o oposta. <br><br><h3>  Pesquisa ou uso </h3><br>  Um truque simples foi usado para explorar os caminhos em torno da posi√ß√£o atual do agente: a cada passo, cinco agentes ser√£o pesquisadores "volunt√°rios".  O curso desses agentes ser√° escolhido aleatoriamente, e n√£o pela previs√£o da rede neural. <br><br>  Assim, temos uma probabilidade maior de que um dos cinco agentes avance al√©m dos outros e ajudar√° no treinamento da rede com melhores resultados. <br><br><h3>  Algoritmo gen√©tico </h3><br>  Cada √©poca, 500 agentes participam no campo de jogo.  As previs√µes para todos os agentes s√£o executadas no modo ass√≠ncrono para todos os agentes de uma s√≥ vez; al√©m disso, os c√°lculos s√£o delegados √† gpu.  Assim, obtemos um uso mais eficiente do poder computacional do computador, o que leva a uma redu√ß√£o no tempo para prever uma rede neural para 500 agentes por vez. <br><br>  A previs√£o funciona mais r√°pido que o treinamento, portanto, a rede tem mais chances de avan√ßar no labirinto com a menor quantidade de tempo e o melhor resultado. <br><br><h3>  Aprendendo o melhor da gera√ß√£o </h3><br>  Ao longo da √©poca, para 500 agentes, os resultados de seu avan√ßo pelo labirinto s√£o preservados.  Quando o √∫ltimo agente √© destru√≠do, os 5 melhores agentes entre 500 s√£o selecionados - que chegaram ao labirinto o mais longe poss√≠vel. <br><br>  Com base nos melhores resultados da √©poca, uma rede neural ser√° treinada. <br><br>  Portanto, reduziremos a quantidade de mem√≥ria usada n√£o salvando e n√£o treinando a rede em agentes que n√£o avan√ßam na rede. <br><br><h2>  Conclus√£o </h2><br>  N√£o sendo especialista neste campo, consegui obter algum sucesso no treinamento da rede neural e voc√™ ter√° sucesso - v√° em frente! <br><br>  Esforce-se para aprender mais r√°pido que os computadores, enquanto fazemos melhor. <br><br><h3>  Materiais </h3><br>  <a href="">Reposit√≥rio com c√≥digo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Iniciar o treinamento do navegador</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A documenta√ß√£o do tensorflow.js</a> , onde voc√™ tamb√©m pode encontrar recursos adicionais para aprender. <br><br><h3>  Livros </h3><br><ul><li>  Aprendizagem profunda.  Imers√£o no mundo das redes neurais <br>  S. Nikolenko, A. Kadurin, E. Arkhangelskaya <br></li><li>  Aprendizado de m√°quina e fluxo de tens√£o <br>  N. Shakla <br></li><li>  Sistemas de auto-aprendizagem <br>  S. I. Nikolenko, A. L. Tulupyev <br></li><li>  Treinamento de refor√ßo <br>  R.S. Sutton, E.G. Barto <br></li><li>  Cart√µes auto-organizados <br>  T. Kohonen <br></li></ul><br><h2>  Obrigado pela aten√ß√£o! </h2></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt452612/">https://habr.com/ru/post/pt452612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt452598/index.html">Gerenciamento de uma equipe de programadores: como e como motiv√°-los corretamente? Parte um</a></li>
<li><a href="../pt452602/index.html">Cisco Hyperflex para sistemas de gerenciamento de banco de dados de alta carga</a></li>
<li><a href="../pt452606/index.html">UDB. O que √© isso? Parte 8. Endere√ßando UDB</a></li>
<li><a href="../pt452608/index.html">Parte 1. QInst: √© melhor perder um dia e depois voar em cinco minutos (instrumentos de escrita s√£o triviais)</a></li>
<li><a href="../pt452610/index.html">Ajuda e pedido para ela. Artigo sobre seguran√ßa da informa√ß√£o para usu√°rios comuns</a></li>
<li><a href="../pt452614/index.html">Como iniciar a programa√ß√£o no Adobe Illustrator. Parte dois</a></li>
<li><a href="../pt452618/index.html">O que foi dito no Google I / O 2019: Android 10, aplicativos AR e muito mais</a></li>
<li><a href="../pt452620/index.html">Derivando um tipo de a√ß√£o usando o Typecript</a></li>
<li><a href="../pt452622/index.html">Introdu√ß√£o √† Gen√¥mica para Programadores</a></li>
<li><a href="../pt452624/index.html">Introdu√ß√£o ao Spring Boot Actuator</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
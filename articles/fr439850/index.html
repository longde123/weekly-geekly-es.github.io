<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñ≤Ô∏è üë®üèº‚Äç‚úàÔ∏è ‚ò¶Ô∏è D√©tection d'√©motions contextuelles dans les conversations textuelles √† l'aide de r√©seaux de neurones ü§¨ üôáüèº üèñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="De nos jours, parler aux agents conversationnels devient une routine quotidienne, et il est crucial pour les syst√®mes de dialogue de g√©n√©rer des r√©pon...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>D√©tection d'√©motions contextuelles dans les conversations textuelles √† l'aide de r√©seaux de neurones</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439850/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  De nos jours, parler aux agents conversationnels devient une routine quotidienne, et il est crucial pour les syst√®mes de dialogue de g√©n√©rer des r√©ponses aussi humaines que possible.  Comme l'un des principaux aspects, une attention particuli√®re devrait √™tre accord√©e √† la fourniture de r√©ponses sensibles aux √©motions aux utilisateurs.  Dans cet article, nous allons d√©crire <b>l'architecture de r√©seau de neurones r√©currente pour la d√©tection des √©motions dans les conversations textuelles</b> , qui a particip√© √† la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">t√¢che 3 d'EmoContext SemEval-2019</a> , c'est-√†-dire un atelier annuel sur l'√©valuation s√©mantique.  L'objectif de la t√¢che est de classer l'√©motion (c'est-√†-dire heureuse, triste, en col√®re et autres) dans un ensemble de donn√©es conversationnelles √† 3 tours. <br><a name="habracut"></a><br>  Le reste de l'article est organis√© comme suit.  La section 1 donne un bref aper√ßu de la t√¢che EmoContext et des donn√©es fournies.  Les sections 2 et 3 se concentrent par cons√©quent sur le pr√©traitement des textes et l'int√©gration des mots.  Dans la section 4, nous avons d√©crit l'architecture du mod√®le LSTM utilis√© dans notre m√©moire.  En conclusion, les performances finales de notre syst√®me et le code source sont pr√©sent√©s.  Le mod√®le est impl√©ment√© en Python √† l'aide de la biblioth√®que Keras. <br><br><h2>  1. Donn√©es de formation </h2><br>  La T√¢che 3 ¬´EmoContext¬ª du SemEval-2019 se concentre sur la d√©tection contextuelle des √©motions dans les conversations textuelles.  Dans EmoContext, √©tant donn√© un √©nonc√© utilisateur textuel avec 2 tours de contexte dans une conversation, nous devons classer si l'√©motion du prochain √©nonc√© utilisateur est ¬´heureuse¬ª, ¬´triste¬ª, ¬´en col√®re¬ª ou ¬´autres¬ª (tableau 1).  Il n'y a que deux participants √† la conversation: une personne anonyme (Tuen-1 et Turn-3) et le chatbot bas√© sur l'IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ruuh</a> (Turn-2).  Pour une description d√©taill√©e, voir ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tableau 1. Exemples montrant l'ensemble de donn√©es EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Utilisateur (Turn-1) </th><th>  Agent conversationnel (Turn-1) </th><th>  Utilisateur (Turn-2) </th><th>  V√©ritable classe </th></tr><tr><td>  Je viens de me qualifier pour le stage Nabard </td><td>  WOOT!  Voil√† d'excellentes nouvelles.  F√©licitations! </td><td>  J'ai commenc√© √† pleurer </td><td>  Heureux </td></tr><tr><td>  Comment osez-vous gifler mon enfant </td><td>  Si vous g√¢tez ma voiture, je vous le ferai aussi </td><td>  Essayez juste de le faire une fois </td><td>  F√¢ch√© </td></tr><tr><td>  J'ai √©t√© bless√© par toi plus </td><td>  Tu ne le pensais pas. </td><td>  dis que tu m'aimes </td><td>  Triste </td></tr><tr><td>  Je ferai la nuit. </td><td>  D'accord.  Tenez-moi au courant. </td><td>  Ne pas donner WhatsApp non. </td><td>  Autres </td></tr></tbody></table></div><br>  Pendant le concours, nous avons eu acc√®s √† 30160 textes √©tiquet√©s par des humains fournis par des organisateurs de t√¢ches, o√π environ 5000 √©chantillons chacun de la classe ¬´en col√®re¬ª, ¬´triste¬ª, ¬´heureux¬ª et 15000 pour la classe ¬´autres¬ª (tableau 2).  Les kits de d√©veloppement et de test, qui √©taient √©galement fournis par les organisateurs, contrairement √† un ensemble de trains, ont une distribution r√©elle, qui est d'environ 4% pour chaque classe √©motionnelle et le reste pour la classe ¬´autres¬ª.  Les donn√©es fournies par Microsoft et peuvent √™tre trouv√©es dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le groupe officiel LinkedIn</a> . <br><br>  <i>Tableau 2. Distribution des √©tiquettes de classe d'√©motion dans les jeux de donn√©es ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Jeu de donn√©es </th><th>  Heureux </th><th>  Triste </th><th>  F√¢ch√© </th><th>  Autres </th><th>  Total </th></tr><tr><td>  Train <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30160 <br></td></tr><tr><td>  Dev <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  √âloign√© <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900k <br></td></tr></tbody></table></div><br>  En plus de ces donn√©es, nous avons collect√© 900k tweets anglais afin de cr√©er un ensemble de donn√©es √©loign√© de 300k tweets pour chaque √©motion.  Pour former l'ensemble de donn√©es distant, nous nous sommes bas√©s sur la strat√©gie de Go et al.  (2009), dans lesquels nous associons simplement les tweets √† la pr√©sence de mots li√©s aux √©motions tels que `` #angry '', `` nannoyed '', '#happy', '#sad,' #surprised ', etc.  La liste des termes de requ√™te √©tait bas√©e sur les termes de requ√™te de SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Duppada et al., 2018</a> ). <br><br>  La mesure de performance cl√© d'EmoContext est un score F1 micro-moyen pour trois classes d'√©motions, √† savoir ¬´triste¬ª, ¬´heureux¬ª et ¬´en col√®re¬ª. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Pr√©traitement des textes </h2><br>  Avant toute √©tape de formation, les textes ont √©t√© pr√©trait√©s par l'outil de texte Ekphrasis (Baziotis et al., 2017).  Cet outil permet d'effectuer la correction orthographique, la normalisation des mots, la segmentation et permet de sp√©cifier quels jetons doivent √™tre omis, normalis√©s ou annot√©s avec des balises sp√©ciales.  Nous avons utilis√© les techniques suivantes pour l'√©tape de pr√©traitement. <br><br><ul><li>  Les URL, les e-mails, la date et l'heure, les noms d'utilisateur, le pourcentage, les devises et les nombres ont √©t√© remplac√©s par les balises correspondantes. </li><li>  Les termes r√©p√©t√©s, censur√©s, allong√©s et en majuscules ont √©t√© annot√©s avec les balises correspondantes. </li><li>  Les mots allong√©s ont √©t√© automatiquement corrig√©s sur la base du corpus de statistiques de mots int√©gr√©. </li><li>  Des hashtags et des d√©compactations (c'est-√†-dire la segmentation des mots) ont √©t√© effectu√©s sur la base d'un corpus de statistiques de mots int√©gr√©. </li><li>  Un dictionnaire cr√©√© manuellement pour remplacer les termes extraits du texte a √©t√© utilis√© afin de r√©duire une vari√©t√© d'√©motions. </li></ul><br>  De plus, Emphasis fournit le tokenizer qui est capable d'identifier la plupart des emojis, √©motic√¥nes et expressions compliqu√©es telles que les mots censur√©s, accentu√©s et allong√©s ainsi que les dates, les heures, les devises et les acronymes. <br><br>  <i>Tableau 3. Exemples de pr√©traitement de texte.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texte original </th><th>  Texte pr√©trait√© </th></tr><tr><td>  JE ME SENS ... Je me brise en millions de morceaux <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; je vous sens &lt;/allcaps&gt;.  &lt;r√©p√©t√©&gt; je me brise en millions de morceaux <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  fatigu√© et tu m'as manqu√© aussi :‚Äë( </td><td>  fatigu√© et tu m'as manqu√© aussi &lt;sad&gt; </td></tr><tr><td>  vous devez vous y connecter: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  vous devriez √©couter &lt;allong√©&gt; √† ceci: &lt;url&gt; </td></tr><tr><td>  Mon appartement s'en occupe.  Mon loyer est d'environ 650 $. </td><td>  mon appartement s'en occupe.  mon loyer est d'environ &lt;argent&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Int√©grations de mots </h2><br>  L'incorporation de mots est devenue une partie essentielle de toute approche d'apprentissage en profondeur pour les syst√®mes de PNL.  Pour d√©terminer les vecteurs les plus appropri√©s pour la t√¢che de d√©tection des √©motions, nous essayons les mod√®les Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pennington et al., 2014</a> ) et FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Joulin et al., 2017</a> ) ainsi que DataStories pr√©-form√©s vecteurs de mots ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Baziotis et al., 2017</a> ).  Le concept cl√© de Word2Vec est de localiser des mots, qui partagent des contextes communs dans le corpus d'apprentissage, √† proximit√© imm√©diate de l'espace vectoriel.  Les mod√®les Word2Vec et Glove apprennent les encodages g√©om√©triques des mots √† partir de leurs informations de co-occurrence, mais essentiellement le premier est un mod√®le pr√©dictif et le dernier est un mod√®le bas√© sur le comptage.  En d'autres termes, alors que Word2Vec essaie de pr√©dire un mot cible (architecture CBOW) ou un contexte (architecture Skip-gram), c'est-√†-dire pour minimiser la fonction de perte, GloVe calcule des vecteurs de mots en r√©duisant la dimensionnalit√© sur la matrice de comptage de cooccurrence.  FastText est tr√®s similaire √† Word2Vec √† l'exception du fait qu'il utilise des n-grammes de caract√®res pour apprendre les vecteurs de mots, il est donc capable de r√©soudre le probl√®me de vocabulaire. <br><br>  Pour toutes les techniques mentionn√©es ci-dessus, nous avons utilis√© les landaus de formation par d√©faut fournis par les auteurs.  Nous formons un mod√®le LSTM simple (dim = 64) bas√© sur chacun de ces plongements et comparons l'efficacit√© en utilisant la validation crois√©e.  Selon le r√©sultat, les int√©grations pr√©-entra√Æn√©es de DataStories ont d√©montr√© le meilleur score F1 moyen. <br><br>  Pour enrichir les incorporations de mots s√©lectionn√©s avec la polarit√© √©motionnelle des mots, nous envisageons d'effectuer une phrase de pr√©-apprentissage √† distance par un r√©glage fin des incorporations sur l'ensemble de donn√©es distant √©tiquet√© automatiquement.  L'importance de l'utilisation de la pr√©-formation a √©t√© d√©montr√©e dans ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deriu et al., 201</a> 7).  Nous utilisons l'ensemble de donn√©es distant pour former le r√©seau LSTM simple √† classer les tweets en col√®re, tristes et heureux.  La couche des plongements a √©t√© gel√©e pour la premi√®re √©poque d'entra√Ænement afin d'√©viter des changements importants dans les poids des plongements, puis elle a √©t√© d√©gel√©e pour les 5 √©poques suivantes.  Apr√®s la phase de formation, les int√©grations affin√©es ont √©t√© enregistr√©es pour les phases de formation ult√©rieures et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rendues publiques</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Architecture du r√©seau neuronal </h2><br>  Un r√©seau neuronal r√©current (RNN) est une famille de r√©seaux neuronaux artificiels sp√©cialis√©s dans le traitement de donn√©es s√©quentielles.  Contrairement aux r√©seaux de neurones traditionnels, les RRN sont con√ßus pour traiter des donn√©es s√©quentielles en partageant leurs poids internes traitant la s√©quence.  √Ä cet effet, le graphe de calcul des RRN comprend des cycles, repr√©sentant l'influence des informations pr√©c√©dentes sur la pr√©sente.  Dans le prolongement des RNN, des r√©seaux de m√©moire √† long terme (LSTM) ont √©t√© introduits en 1997 ( <a href="">Hochreiter et Schmidhuber, 1997</a> ).  Dans les LSTM, les cellules r√©currentes sont connect√©es d'une mani√®re particuli√®re pour √©viter la disparition et l'explosion des probl√®mes de gradient.  Les LSTM traditionnels ne conservent que les informations du pass√© car ils ne traitent la s√©quence que dans une seule direction.  Les LSTM bidirectionnels combinent la sortie de deux couches LSTM cach√©es se d√©pla√ßant dans des directions oppos√©es, o√π l'une avance dans le temps et l'autre recule dans le temps, permettant ainsi de capturer simultan√©ment des informations sur les √©tats pass√©s et futurs ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Schuster et Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figure 1: L'architecture d'une version plus petite de l'architecture propos√©e.</i>  <i>Les unit√©s LSTM pour le premier et le troisi√®me tour ont des poids communs.</i> <br><br>  Un aper√ßu de haut niveau de notre approche est fourni √† la figure 1. L'architecture propos√©e du r√©seau de neurones se compose de l'unit√© d'int√©gration et de deux unit√©s LSTM bidirectionnelles (dim = 64).  L'ancienne unit√© LSTM est destin√©e √† analyser la parole du premier utilisateur (c'est-√†-dire le premier tour et le troisi√®me tour de la conversation), et la derni√®re est destin√©e √† analyser la parole du deuxi√®me utilisateur (c'est-√†-dire le deuxi√®me tour).  Ces deux unit√©s apprennent non seulement la repr√©sentation des fonctionnalit√©s s√©mantiques et des sentiments, mais √©galement la fa√ßon de capturer les fonctionnalit√©s de conversation sp√©cifiques √† l'utilisateur, ce qui permet de classer les √©motions plus pr√©cis√©ment.  √Ä la premi√®re √©tape, chaque √©nonc√© utilisateur est introduit dans une unit√© LSTM bidirectionnelle correspondante en utilisant des incorporations de mots pr√©-entra√Æn√©es.  Ensuite, ces trois cartes d'entit√©s sont concat√©n√©es dans un vecteur d'entit√©s aplati puis transmises √† une couche cach√©e enti√®rement connect√©e (dim = 30), qui analyse les interactions entre les vecteurs obtenus.  Enfin, ces fonctionnalit√©s traversent la couche de sortie avec la fonction d'activation softmax pour pr√©dire une √©tiquette de classe finale.  Pour r√©duire le sur-ajustement, des couches de r√©gularisation avec du bruit gaussien ont √©t√© ajout√©es apr√®s la couche d'int√©gration, des couches de d√©crochage ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Srivastava et al., 2014</a> ) ont √©t√© ajout√©es √† chaque unit√© LSTM (p = 0,2) et avant la couche cach√©e enti√®rement connect√©e (p = 0,1). <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. R√©sultats </h2><br>  Dans le processus de recherche d'une architecture optimale, nous avons exp√©riment√© non seulement le nombre de cellules en couches, les fonctions d'activation et les param√®tres de r√©gularisation mais √©galement l'architecture du r√©seau neuronal.  Les informations d√©taill√©es sur cette phrase peuvent √™tre trouv√©es dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'article original</a> . <br><br>  Le mod√®le d√©crit dans la section pr√©c√©dente a d√©montr√© les meilleurs scores sur l'ensemble de donn√©es de d√©veloppement, il a donc √©t√© utilis√© dans la phase d'√©valuation finale du concours.  Sur l'ensemble de donn√©es de test final, il a obtenu un score F1 micro-moyen de 72,59% pour les classes √©motionnelles, tandis que le score maximum parmi tous les participants √©tait de 79,59%.  Cependant, c'est bien au-dessus de la ligne de base officielle publi√©e par les organisateurs de t√¢ches, qui √©tait de 58,68%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code source du mod√®le et les int√©grations de mots</a> sont disponibles sur GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La version compl√®te de l'article</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le document de description des t√¢ches</a> sont disponibles sur ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'ensemble de donn√©es d'entra√Ænement</a> est situ√© dans le groupe de comp√©tition officiel sur LinkedIn. <br><br>  Citation: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439850/">https://habr.com/ru/post/fr439850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439834/index.html">Pr√©sentation de la technologie IPMI</a></li>
<li><a href="../fr439838/index.html">Arithm√©tique du miel: addition et soustraction par les abeilles</a></li>
<li><a href="../fr439840/index.html">Conf√©rence DUMP-2019: nous vous invitons √† prendre la parole dans les sections Conception, Gestion et Tests</a></li>
<li><a href="../fr439844/index.html">Pourquoi les d√©veloppeurs de Dodo Pizza 250?</a></li>
<li><a href="../fr439848/index.html">Pas un seul VPN. Aide-m√©moire sur la fa√ßon de vous prot√©ger et de prot√©ger vos donn√©es</a></li>
<li><a href="../fr439852/index.html">Version de l'application de contr√¥le √† distance: Aspia 1.1.0</a></li>
<li><a href="../fr439854/index.html">Eh, une, une fois de plus: que faire avec un client CRM apr√®s avoir achet√©</a></li>
<li><a href="../fr439856/index.html">Yandex! Merci pour Uber</a></li>
<li><a href="../fr439858/index.html">Prometheus + Grafana + Node Exporter + Docker dans Azure avec notifications dans Telegram</a></li>
<li><a href="../fr439860/index.html">Ubuntu 18.04 Root sur ZFS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèª‚Äçüî¨ üíÖ üë©üèº‚Äçü§ù‚Äçüë®üèø ¬øC√≥mo acelerar la descompresi√≥n de LZ4 en ClickHouse? üë©üèø‚Äçü§ù‚Äçüë©üèª üôÜüèΩ üåà</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cuando ejecuta consultas en ClickHouse , puede notar que el generador de perfiles a menudo muestra la funci√≥n LZ_decompress_fast cerca de la parte sup...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øC√≥mo acelerar la descompresi√≥n de LZ4 en ClickHouse?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/457612/"> Cuando ejecuta consultas en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ClickHouse</a> , puede notar que el generador de perfiles a menudo muestra la funci√≥n <code>LZ_decompress_fast</code> cerca de la parte superior.  Que esta pasando  Esta pregunta nos hizo preguntarnos c√≥mo elegir el mejor algoritmo de compresi√≥n. <br><br>  ClickHouse almacena datos en forma comprimida.  Al ejecutar consultas, ClickHouse intenta hacer lo menos posible para conservar los recursos de la CPU.  En muchos casos, todos los c√°lculos potencialmente lentos ya est√°n bien optimizados, adem√°s el usuario escribi√≥ una consulta bien pensada.  Entonces todo lo que queda por hacer es realizar la descompresi√≥n. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/302/aba/057302aba5041790af404c2c781c4dd3.png"><br><br>  Entonces, ¬øpor qu√© la descompresi√≥n LZ4 se convierte en un cuello de botella?  LZ4 parece un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">algoritmo extremadamente ligero</a> : la tasa de descompresi√≥n de datos suele ser de 1 a 3 GB / s por n√∫cleo de procesador, dependiendo de los datos.  Esto es mucho m√°s r√°pido que el subsistema de disco t√≠pico.  Adem√°s, utilizamos todos los n√∫cleos de CPU disponibles, y la descompresi√≥n se escala linealmente en todos los n√∫cleos f√≠sicos. <br><a name="habracut"></a><br>  Sin embargo, hay dos puntos a tener en cuenta.  Primero, los datos comprimidos se leen del disco, pero la velocidad de descompresi√≥n se da en t√©rminos de la cantidad de datos sin comprimir.  Si la relaci√≥n de compresi√≥n es lo suficientemente grande, no hay casi nada que leer de los discos.  Pero habr√° muchos datos descomprimidos, y esto naturalmente afecta la utilizaci√≥n de la CPU: en el caso de LZ4, la cantidad de trabajo necesaria para descomprimir datos es casi proporcional al volumen de los datos descomprimidos. <br><br>  En segundo lugar, si los datos se almacenan en cach√©, es posible que no necesite leer datos de los discos.  Puede confiar en el cach√© de p√°gina o usar su propio cach√©.  El almacenamiento en cach√© es m√°s eficiente en bases de datos orientadas a columnas, ya que solo las columnas de uso frecuente permanecen en la memoria cach√©.  Es por eso que LZ4 a menudo parece ser un cuello de botella en t√©rminos de carga de CPU. <br><br>  Esto trae dos preguntas m√°s.  Primero, si la descompresi√≥n nos est√° ralentizando, ¬øvale la pena comprimir los datos para empezar?  Pero esta especulaci√≥n es irrelevante en la pr√°ctica.  Hasta hace poco, la configuraci√≥n de ClickHouse ofrec√≠a solo dos opciones de compresi√≥n de datos: LZ4 y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zstandard</a> .  LZ4 se usa por defecto.  Cambiar a Zstandard hace que la compresi√≥n sea m√°s fuerte y m√°s lenta.  Pero no hab√≠a una opci√≥n para desactivar por completo la compresi√≥n, ya que se supone que LZ4 proporciona una compresi√≥n m√≠nima razonable que siempre se puede usar.  (Por eso me encanta LZ4.) <br><br>  Pero luego apareci√≥ un extra√±o misterioso en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">chat internacional de soporte de ClickHouse</a> que dijo que tiene un subsistema de disco muy r√°pido (con NVMe SSD) y que la descompresi√≥n es lo √∫nico que ralentiza sus consultas, por lo que ser√≠a bueno poder almacenar datos sin compresi√≥n  Respond√≠ que no tenemos esta opci√≥n, pero ser√≠a f√°cil de agregar.  Unos d√≠as m√°s tarde, recibimos una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">solicitud de extracci√≥n</a> implementando el m√©todo de compresi√≥n <code>none</code> .  Le ped√≠ al contribuyente que informara sobre cu√°nto esta opci√≥n ayud√≥ a acelerar las consultas.  La respuesta fue que esta nueva caracter√≠stica result√≥ in√∫til en la pr√°ctica, ya que los datos sin comprimir comenzaron a ocupar demasiado espacio en disco y no cab√≠an en esas unidades NVMe. <br><br>  La segunda pregunta que surge es que si hay un cach√©, ¬øpor qu√© no usarlo para almacenar datos que ya est√°n descomprimidos?  Esta es una posibilidad viable que eliminar√° la necesidad de descompresi√≥n en muchos casos.  ClickHouse tambi√©n tiene un cach√© como este: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el cach√© de bloques descomprimidos</a> .  Pero es una pena desperdiciar mucha RAM en esto.  Por lo tanto, generalmente tiene sentido usar consultas peque√±as y secuenciales que usan datos casi id√©nticos. <br><br>  Nuestra conclusi√≥n es que siempre es preferible almacenar datos en formato comprimido.  Siempre escriba datos en el disco en formato comprimido.  Transmita datos a trav√©s de la red con compresi√≥n tambi√©n.  En mi opini√≥n, la compresi√≥n predeterminada es justificable incluso cuando se transfieren datos dentro de un solo centro de datos en una red de 10 GB sin una suscripci√≥n excesiva, mientras que la transferencia de datos sin comprimir entre centros de datos es simplemente inaceptable. <br><br><h3>  ¬øPor qu√© LZ4? </h3><br>  ¬øPor qu√© elegir LZ4?  ¬øNo podr√≠amos elegir algo a√∫n m√°s ligero?  Te√≥ricamente, podr√≠amos, y este es un buen pensamiento.  Pero veamos la clase de algoritmos a los que pertenece LZ4. <br><br>  En primer lugar, es gen√©rico y no adapta el tipo de datos.  Por ejemplo, si sabe de antemano que tendr√° una serie de enteros, puede usar uno de los algoritmos VarInt y esto usar√° la CPU de manera m√°s efectiva.  En segundo lugar, LZ4 no depende demasiado de los supuestos del modelo de datos.  Supongamos que tiene una serie temporal ordenada de valores de sensores, una matriz de n√∫meros de punto flotante.  Si tiene esto en cuenta, puede calcular deltas entre estos n√∫meros y luego comprimirlos con un algoritmo gen√©rico, lo que dar√° como resultado una relaci√≥n de compresi√≥n m√°s alta. <br><br>  No tendr√° ning√∫n problema al usar LZ4 con cualquier conjunto de bytes o cualquier archivo.  Por supuesto, tiene una especializaci√≥n (m√°s sobre eso m√°s adelante), y en algunos casos su uso no tiene sentido.  Pero si lo llamamos un algoritmo de prop√≥sito general, estaremos bastante cerca de la verdad.  Debemos tener en cuenta que gracias a su dise√±o interno, LZ4 implementa autom√°ticamente el algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RLE</a> como un caso especial. <br><br>  Sin embargo, la pregunta m√°s importante es si LZ4 es el algoritmo m√°s √≥ptimo de esta clase en t√©rminos de velocidad general y fuerza de compresi√≥n.  Los algoritmos √≥ptimos se denominan frontera de Pareto, lo que significa que no hay otro algoritmo que sea definitivamente mejor de una manera y no peor de otras (y tambi√©n en una amplia variedad de conjuntos de datos).  Algunos algoritmos son m√°s r√°pidos pero dan como resultado una relaci√≥n de compresi√≥n m√°s peque√±a, mientras que otros tienen una compresi√≥n m√°s fuerte pero son m√°s lentos para comprimir o descomprimir. <br><br>  Para ser sincero, LZ4 no es realmente la frontera de Pareto: hay algunas opciones disponibles que son solo un poco mejores.  Por ejemplo, mire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LZTURBO</a> de un desarrollador apodado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">powturbo</a> .  No hay dudas sobre la fiabilidad de los resultados, gracias a la comunidad <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">encode.ru</a> (el foro m√°s grande y posiblemente el √∫nico sobre compresi√≥n de datos).  Desafortunadamente, el desarrollador no distribuye el c√≥digo fuente o los binarios;  solo est√°n disponibles para un n√∫mero limitado de personas para la prueba, o por una gran cantidad de dinero (aunque parece que todav√≠a nadie lo ha pagado).  Tambi√©n eche un vistazo a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lizard</a> (anteriormente LZ5) y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Density</a> .  Pueden funcionar un poco mejor que LZ4 cuando selecciona un cierto nivel de compresi√≥n.  Otra opci√≥n realmente interesante es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LZSSE</a> .  Pero termine de leer este art√≠culo antes de echarle un vistazo. <br><br><h3>  Como funciona lz4 </h3><br>  Veamos c√≥mo funciona LZ4 en general.  Esta es una de las implementaciones del algoritmo LZ77.  L y Z representan los nombres de los desarrolladores (Lempel y Ziv), y 77 es para el a√±o 1977 cuando se public√≥ el algoritmo.  Tiene muchas otras implementaciones: QuickLZ, FastLZ, BriefLZ, LZF, LZO y gzip y zip si se utilizan niveles bajos de compresi√≥n. <br><br>  Un bloque de datos comprimido usando LZ4 contiene una secuencia de entradas (comandos o instrucciones) de dos tipos: <br><br><ol><li>  Literales: "Tome los siguientes N bytes tal cual y c√≥pielos en el resultado". </li><li>  Coincidencia: "Tomar N bytes del resultado descomprimido comenzando en el valor de desplazamiento relativo a la posici√≥n actual". </li></ol><br>  Ejemplo.  Antes de la compresi√≥n: <br><br><pre> <code class="plaintext hljs">Hello world Hello</code> </pre> <br>  Despu√©s de la compresi√≥n: <br><br><pre> <code class="plaintext hljs">literals 12 "Hello world " match 5 12</code> </pre> <br>  Si tomamos un bloque comprimido e iteramos el cursor a trav√©s de √©l mientras ejecutamos estos comandos, obtendremos los datos originales sin comprimir como resultado. <br><br>  As√≠ es b√°sicamente c√≥mo se descomprimen los datos.  La idea b√°sica es clara: para realizar la compresi√≥n, el algoritmo codifica una secuencia repetida de bytes usando coincidencias. <br><br>  Algunas caracter√≠sticas tambi√©n son claras.  Este algoritmo orientado a bytes no disecciona bytes individuales;  solo los copia en su totalidad.  As√≠ es como difiere de la codificaci√≥n de entrop√≠a.  Por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">zstd</a> es una combinaci√≥n de LZ77 y codificaci√≥n de entrop√≠a. <br><br>  Tenga en cuenta que el tama√±o del bloque comprimido no debe ser demasiado grande.  El tama√±o se elige para evitar el desperdicio de una gran cantidad de RAM durante la descompresi√≥n, para evitar ralentizar demasiado el acceso aleatorio en el archivo comprimido (que consiste en una gran cantidad de bloques comprimidos) y, a veces, el bloque cabe en un cach√© de la CPU.  Por ejemplo, puede elegir 64 KB para que los b√∫feres para datos comprimidos y sin comprimir quepan en la cach√© L2 con la mitad a√∫n libre. <br><br>  Si necesitamos comprimir un archivo m√°s grande, podemos concatenar los bloques comprimidos.  Esto tambi√©n es conveniente para almacenar datos adicionales (como una suma de verificaci√≥n) con cada bloque comprimido. <br><br>  El desplazamiento m√°ximo para el partido es limitado.  En LZ4, el l√≠mite es de 64 kilobytes.  Esta cantidad se llama ventana deslizante.  Esto significa que las coincidencias se pueden encontrar en una ventana de 64 kilobytes que precede al cursor, que se desliza con el cursor a medida que avanza. <br><br>  Ahora veamos c√≥mo comprimir datos o, en otras palabras, c√≥mo encontrar secuencias coincidentes en un archivo.  Siempre puedes usar un sufijo trie (es genial si realmente has o√≠do hablar de esto).  Hay m√©todos que garantizan que la coincidencia m√°s larga se encuentra en los bytes anteriores despu√©s de la compresi√≥n.  Esto se llama an√°lisis √≥ptimo y proporciona <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">casi</a> la mejor relaci√≥n de compresi√≥n para un bloque comprimido de formato fijo.  Pero hay mejores enfoques, como encontrar una coincidencia lo suficientemente buena que no sea necesariamente la m√°s larga.  La forma m√°s eficiente de encontrarlo es usando una tabla hash. <br><br>  Para hacer esto, iteramos el cursor a trav√©s del bloque de datos original y tomamos algunos bytes despu√©s del cursor (digamos 4 bytes).  Los hash y colocamos el desplazamiento desde el principio del bloque (de donde se tomaron los 4 bytes) en la tabla hash.  El valor 4 se llama "min-match": con esta tabla hash, podemos encontrar coincidencias de al menos 4 bytes. <br><br>  Si miramos la tabla hash y ya tiene un registro coincidente, y el desplazamiento no excede la ventana deslizante, verificamos cu√°ntos bytes m√°s coinciden despu√©s de esos 4 bytes.  Quiz√°s haya muchos m√°s partidos.  Tambi√©n es posible que haya una colisi√≥n en la tabla hash y que nada coincida, pero esto no es gran cosa.  Simplemente puede reemplazar el valor en la tabla hash con uno nuevo.  Las colisiones en la tabla hash simplemente conducir√°n a una relaci√≥n de compresi√≥n m√°s baja, ya que habr√° menos coincidencias.  Por cierto, este tipo de tabla hash (con un tama√±o fijo y sin resoluci√≥n de colisiones) se denomina "tabla de cach√©".  Este nombre tiene sentido porque en caso de colisi√≥n, la tabla de cach√© simplemente olvida la entrada anterior. <br><br><blockquote>  Un desaf√≠o para el lector cuidadoso.  Supongamos que los datos son una matriz de n√∫meros UInt32 en formato little endian que representa una parte de una secuencia de n√∫meros naturales: 0, 1, 2 ... Explique por qu√© estos datos no se comprimen cuando se usa LZ4 (el tama√±o de los datos comprimidos no es m√°s peque√±o en comparaci√≥n con los datos sin comprimir). </blockquote><br><h3>  C√≥mo acelerar todo </h3><br>  Entonces quiero acelerar la descompresi√≥n de LZ4.  Veamos c√≥mo se ve el ciclo de descompresi√≥n.  Aqu√≠ est√° en pseudoc√≥digo: <br><br><pre> <code class="plaintext hljs">while (...) {    read(input_pos, literal_length, match_length);    copy(output_pos, input_pos, literal_length);    output_pos += literal_length;    read(input_pos, match_offset);    copy(output_pos, output_pos - match_offset,        match_length);    output_pos += match_length; }</code> </pre> <br>  El formato LZ4 est√° dise√±ado para que los literales y las coincidencias se alternen en un archivo comprimido.  Obviamente, el literal siempre viene primero (porque no hay un lugar desde el que comenzar una partida desde el principio).  Por lo tanto, sus longitudes est√°n codificadas juntas. <br><br>  En realidad es un poco m√°s complicado que eso.  Se lee un byte del archivo, y luego se divide en dos nibbles (medios bytes) que contienen los n√∫meros codificados del 0 al 15. Si el n√∫mero correspondiente no es 15, se supone que es la longitud del literal y la coincidencia, respectivamente.  Y si es 15, la longitud es mayor y est√° codificada en los siguientes bytes.  Luego se lee el siguiente byte y su valor se agrega a la longitud.  Si es igual a 255, se hace lo mismo con el siguiente byte. <br><br>  Tenga en cuenta que la relaci√≥n de compresi√≥n m√°xima para el formato LZ4 no alcanza 255. Y otra observaci√≥n in√∫til es que si sus datos son muy redundantes, usar LZ4 dos veces mejorar√° la relaci√≥n de compresi√≥n. <br><br>  Cuando leemos la longitud de un literal (y luego la longitud de la coincidencia y el desplazamiento de la coincidencia), basta con copiar dos bloques de memoria para descomprimirlo. <br><br><h3>  C√≥mo copiar un bloque de memoria </h3><br>  Parece que podr√≠a usar la funci√≥n <code>memcpy</code> , que est√° dise√±ada para copiar bloques de memoria.  Pero este no es el enfoque √≥ptimo y no es realmente apropiado. <br><br>  Usar memcpy no es √≥ptimo porque: <br><br><ol><li>  Por lo general, se encuentra en la biblioteca libc (y la biblioteca libc generalmente est√° vinculada din√°micamente, por lo que la llamada a memcpy se realizar√° indirectamente a trav√©s de PLT). </li><li>  El compilador no lo alinea si el argumento de tama√±o es desconocido en el momento de la compilaci√≥n. </li><li>  Hace un gran esfuerzo para procesar correctamente las sobras de un bloque de memoria que no son m√∫ltiplos de la longitud de la m√°quina o el registro. </li></ol><br>  El √∫ltimo punto es el m√°s importante.  Digamos que le pedimos a la funci√≥n memcpy que copie exactamente 5 bytes.  Ser√≠a genial copiar 8 bytes de inmediato, utilizando dos instrucciones movq. <br><br> <code>Hello world <font color="#0fc000">Hello</font> <font color="#ff0000">wo</font> ... <br> ^^^^^ <font color="#ff0000">^^^</font> - src <br> ^^^^^ <font color="#ff0000">^^^</font> - dst</code> <br> <br>  Pero luego copiaremos tres bytes adicionales, por lo que escribiremos fuera de los l√≠mites del b√∫fer.  La funci√≥n <code>memcpy</code> no tiene permiso para hacer esto, ya que podr√≠a sobrescribir algunos datos en nuestro programa y provocar un error de memoria.  Y si escribimos a una direcci√≥n no alineada, estos bytes adicionales podr√≠an aterrizar en una p√°gina no asignada de memoria virtual o en una p√°gina sin acceso de escritura.  Eso nos dar√≠a una falla de segmentaci√≥n (esto es bueno). <br><br>  Pero en nuestro caso, casi siempre podemos escribir bytes adicionales.  Podemos leer bytes adicionales en el b√∫fer de entrada siempre que los bytes adicionales se encuentren completamente dentro de √©l.  En las mismas condiciones, podemos escribir los bytes adicionales en el b√∫fer de salida, porque a√∫n los sobrescribiremos en la pr√≥xima iteraci√≥n. <br><br>  Esta optimizaci√≥n ya est√° en la implementaci√≥n original de LZ4: <br><br><pre> <code class="plaintext hljs">inline void copy8(UInt8 * dst, const UInt8 * src) {    memcpy(dst, src, 8); /// Note that memcpy isn't actually called here. } inline void wildCopy8(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy8(dst, src);        dst += 8;        src += 8;    } while (dst &lt; dst_end); }</code> </pre> <br>  Para aprovechar esta optimizaci√≥n, solo debemos asegurarnos de que estamos lo suficientemente lejos de los l√≠mites del b√∫fer.  Esto no deber√≠a costar nada, porque ya estamos comprobando el desbordamiento del b√∫fer.  Y el procesamiento de los √∫ltimos bytes, los datos "sobrantes", se puede hacer despu√©s del bucle principal. <br><br>  Sin embargo, todav√≠a hay algunos matices.  La copia se produce dos veces en el ciclo: con un literal y una coincidencia.  Sin embargo, cuando se usa la funci√≥n <code>LZ4_decompress_fast</code> (en lugar de <code>LZ4_decompress_safe</code> ), la verificaci√≥n se realiza solo una vez, cuando necesitamos copiar el literal.  La verificaci√≥n no se realiza al copiar la coincidencia, pero la <a href="">especificaci√≥n para el formato LZ4</a> tiene condiciones que le permiten evitarlo: <br><br><blockquote>  Los √∫ltimos 5 bytes son siempre literales. <br>  La √∫ltima coincidencia debe comenzar al menos 12 bytes antes del final del bloque. <br>  En consecuencia, un bloque con menos de 13 bytes no se puede comprimir. </blockquote><br>  Los datos de entrada especialmente seleccionados pueden provocar da√±os en la memoria.  Si utiliza la funci√≥n <code>LZ4_decompress_fast</code> , necesita protecci√≥n contra datos incorrectos.  Como m√≠nimo, debe calcular sumas de verificaci√≥n para los datos comprimidos.  Si necesita protecci√≥n contra hackers, use la funci√≥n <code>LZ4_decompress_safe</code> .  Otras opciones: tomar una funci√≥n hash criptogr√°fica como suma de comprobaci√≥n (aunque es probable que esto destruya el rendimiento);  asignar m√°s memoria para buffers;  asigne memoria para buffers con una llamada <code>mmap</code> separada y cree una p√°gina de protecci√≥n. <br><br>  Cuando veo un c√≥digo que copia 8 bytes de datos, inmediatamente me pregunto por qu√© exactamente 8 bytes.  Puede copiar 16 bytes utilizando registros SSE: <br><br><pre> <code class="plaintext hljs">inline void copy16(UInt8 * dst, const UInt8 * src) { #if __SSE2__    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(dst),        _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(src))); #else    memcpy(dst, src, 16); #endif } inline void wildCopy16(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy16(dst, src);        dst += 16;        src += 16;    } while (dst &lt; dst_end); }</code> </pre> <br>  Lo mismo funciona para copiar 32 bytes para AVX y 64 bytes para AVX-512.  Adem√°s, puede desenrollar el bucle varias veces.  Si alguna vez ha visto c√≥mo se implementa <code>memcpy</code> , este es exactamente el enfoque que se utiliza.  (Por cierto, el compilador no desenrollar√° ni vectorizar√° el bucle en este caso, porque esto requerir√° la inserci√≥n de comprobaciones voluminosas). <br><br>  ¬øPor qu√© la implementaci√≥n original de LZ4 no hizo esto?  Primero, no est√° claro si esto es mejor o peor.  La ganancia resultante depende del tama√±o de los bloques a copiar, por lo que si todos son cortos, crear√≠a trabajo extra para nada.  Y en segundo lugar, arruina las disposiciones en el formato LZ4 que ayudan a evitar una rama innecesaria en el bucle interno. <br><br>  Sin embargo, tendremos en cuenta esta opci√≥n por el momento. <br><br><h3>  Copia dif√≠cil </h3><br>  Volvamos a la pregunta de si siempre es posible copiar datos de esta manera.  Digamos que necesitamos copiar una coincidencia, es decir, tomar un trozo de memoria del b√∫fer de salida que se encuentra en alg√∫n desplazamiento detr√°s del cursor y copiarlo en la posici√≥n del cursor. <br><br>  Imagine un caso simple cuando necesita copiar 5 bytes en un desplazamiento de 12: <br><br> <code><font color="#0fc000">Hello</font> world ........... <br> ^^^^^ - src <br> ^^^^^ - dst <br> <br> Hello world <font color="#0fc000">Hello</font> <font color="#a8a8a8">wo</font> ... <br> ^^^^^ - src <br> ^^^^^ - dst</code> <br> <br>  Pero hay un caso m√°s dif√≠cil, cuando necesitamos copiar un bloque de memoria que es m√°s largo que el desplazamiento.  En otras palabras, incluye algunos datos que a√∫n no se han escrito en el b√∫fer de salida. <br><br>  Copie 10 bytes con un desplazamiento de 3: <br><br> <code><font color="#0fc000">abc</font> ............. <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst <br> <br> abc <font color="#0fc000">abcabcabca</font> ... <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst</code> <br> <br>  Tenemos todos los datos durante el proceso de compresi√≥n, y tal coincidencia bien se puede encontrar.  La funci√≥n <code>memcpy</code> no es adecuada para copiarla, ya que no admite el caso cuando se superponen rangos de bloques de memoria.  La funci√≥n <code>memmove</code> tampoco funcionar√°, porque el bloque de memoria del que deben tomarse los datos a√∫n no se ha inicializado por completo.  Necesitamos copiar de la misma manera que si estuvi√©ramos copiando byte a byte. <br><br><pre> <code class="plaintext hljs">op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; ...</code> </pre> <br>  As√≠ es como funciona: <br><br> <code><font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ............ <br> ^ - src <br> ^ - dst <br> <br> a <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........... <br> ^ - src <br> ^ - dst <br> <br> ab <font color="#0fc000">c</font> ab <font color="#0fc000">c</font> .......... <br> ^ - src <br> ^ - dst <br> <br> abc <font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ......... <br> ^ - src <br> ^ - dst <br> <br> abca <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........ <br> ^ - src <br> ^ - dst</code> <br> <br>  En otras palabras, debemos crear una secuencia repetitiva.  La implementaci√≥n original de LZ4 utiliz√≥ un c√≥digo sorprendentemente extra√±o para hacer esto: <br><br><pre> <code class="plaintext hljs">const unsigned dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4}; const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3}; const int dec64 = dec64table[offset]; op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; match += dec32table[offset]; memcpy(op+4, match, 4); match -= dec64;</code> </pre> <br>  Copia los primeros 4 bytes uno por uno, salta por delante con alg√∫n n√∫mero m√°gico, copia los siguientes 4 bytes por completo y mueve el cursor a una coincidencia utilizando otro n√∫mero m√°gico.  El autor del c√≥digo ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Yan Collet</a> ) de alguna manera se olvid√≥ de dejar un comentario sobre lo que esto significa.  Adem√°s, los nombres de las variables son confusos.  Ambos se denominan dec ... table, pero uno se agrega y el otro se resta.  Adem√°s, uno de ellos no est√° firmado y el otro es int.  Sin embargo, el autor recientemente mejor√≥ este lugar en el c√≥digo. <br><br>  As√≠ es como funciona realmente.  Copiamos los primeros 4 bytes uno a la vez: <br><br> <code>abc <font color="#0fc000">abca</font> ......... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Ahora podemos copiar 4 bytes a la vez: <br><br> <code>abcabca <font color="#0fc000">bcab</font> ..... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Podemos continuar como de costumbre, copiando 8 bytes a la vez: <br><br> <code>abcabcabcab <font color="#0fc000">cabcabca</font> ..... <br> ^^^^^^^^ - src <br> ^^^^^^^^ - dst</code> <br> <br>  Como todos sabemos por experiencia, a veces la mejor manera de entender el c√≥digo es reescribirlo.  Esto es lo que se nos ocurri√≥: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    /// Or if 4 % n is zero, we use n.    /// It gives an equivalent result, but is more CPU friendly for unknown reasons.    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset]; }</code> </pre> <br>  Como se esperaba, esto no cambia el rendimiento en absoluto.  Solo quer√≠a probar la optimizaci√≥n para copiar 16 bytes a la vez. <br><br>  Sin embargo, esto complica el "caso especial" y hace que se llame con m√°s frecuencia (la condici√≥n de <code>offset &lt; 16</code> se realiza al menos tan a menudo como el <code>offset &lt; 8</code> ).  La copia de rangos superpuestos con copia de 16 bytes se ve as√≠ (solo se muestra el principio): <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    static constexpr int shift1[]        = { 0, 1, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[]        = { 0, 0, 0, 1, 0, -1, -2, -3, -4, 4, 4, 4, 4, 4, 4, 4 };    /// 16 % n - 8 % n    static constexpr int shift3[]        = { 0, 0, 0, -1, 0, -2, 2, 1, 8, -1, -2, -3, -4, -5, -6, -7 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset];    memcpy(op + 8, match, 8);    match += shift3[offset]; }</code> </pre> <br>  ¬øSe puede implementar esta funci√≥n de manera m√°s efectiva?  Nos gustar√≠a encontrar una instrucci√≥n SIMD m√°gica para un c√≥digo tan complejo, porque todo lo que queremos hacer es escribir 16 bytes, que consisten completamente en unos pocos bytes de datos de entrada (del 1 al 15).  Entonces solo necesitan repetirse en el orden correcto. <br><br>  Hay una instrucci√≥n como esta llamada <code>pshufb</code> (bytes aleatorios empaquetados) que forma parte de SSSE3 (tres S).  Acepta dos registros de 16 bytes.  Uno de los registros contiene los datos de origen.  El otro tiene el "selector": cada byte contiene un n√∫mero del 0 al 15, seg√∫n el byte del registro fuente del que tomar el resultado.  Si el valor de byte del selector es mayor que 127, el byte correspondiente del resultado se llena con cero. <br><br>  Aqu√≠ hay un ejemplo: <br><br><pre>  xmm0: abc .............
 xmm1: 0120120120120120<font></font>
<font></font>
 pshufb% xmm1,% xmm0<font></font>
<font></font>
 xmm0: abcabcabcabcabca </pre><br>  Cada byte del resultado se llena con el byte seleccionado de los datos de origen: ¬°esto es exactamente lo que necesitamos!  As√≠ es como se ve el c√≥digo en el resultado: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset) { #ifdef __SSSE3__    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =    {        0, 1, 2, 1, 4, 1, 4, 2, 8, 7, 6, 5, 4, 3, 2, 1, /* offset = 0, not used as mask, but for shift amount instead */        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, /* offset = 1 */        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,        0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,        0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,        0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0,    };    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(op),        _mm_shuffle_epi8(            _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(match)),            _mm_load_si128(reinterpret_cast&lt;const __m128i *&gt;(masks) + offset)));    match += masks[offset]; #else    copyOverlap16(op, match, offset); #endif }</code> </pre> <br>  Aqu√≠ <code>_mm_shuffle_epi8</code> es un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">intr√≠nseco</a> , que compila las instrucciones de la CPU <code>pshufb</code> . <br><br>  ¬øPodemos realizar esta operaci√≥n para m√°s bytes a la vez usando instrucciones m√°s recientes?  Despu√©s de todo, SSSE3 es un conjunto de instrucciones muy antiguo que existe desde 2006. AVX2 tiene una instrucci√≥n que hace esto por 32 bytes a la vez, pero por separado para carriles individuales de 16 bytes.  Esto se llama bytes de permuta de vectores, en lugar de bytes aleatorios empaquetados: las palabras son diferentes, pero el significado es el mismo.  AVX-512 VBMI tiene otra instrucci√≥n que funciona para 64 bytes a la vez, pero los procesadores que lo admiten solo han aparecido recientemente.  ARM NEON tiene instrucciones similares llamadas vtbl (b√∫squeda de tabla de vectores), pero solo permiten escribir 8 bytes. <br><br>  Adem√°s, hay una versi√≥n de la instrucci√≥n <code>pshufb</code> con registros MMX de 64 bits para formar 8 bytes.  Es justo para reemplazar la versi√≥n original del c√≥digo.  Sin embargo, decid√≠ usar la opci√≥n de 16 bytes en su lugar (por razones serias). <br><br>  En la conferencia Highload ++ Siberia, un asistente se me acerc√≥ despu√©s de mi presentaci√≥n y mencion√≥ que para el caso de 8 bytes, solo puede usar la multiplicaci√≥n por una constante especialmente seleccionada (tambi√©n necesitar√° un desplazamiento), esto ni siquiera hab√≠a ocurrido a mi antes! <br><br><h3>  C√≥mo eliminar una declaraci√≥n if superflua </h3><br>  Digamos que quiero usar una variante que copia 16 bytes.  ¬øC√≥mo puedo evitar tener que hacer una verificaci√≥n adicional para el desbordamiento del b√∫fer? <br><br>  Decid√≠ que simplemente no har√≠a esta verificaci√≥n.  Los comentarios sobre la funci√≥n dir√°n que el desarrollador debe asignar un bloque de memoria para un n√∫mero espec√≠fico de bytes m√°s de lo necesario, para que podamos leer y escribir basura innecesaria all√≠.  La interfaz de la funci√≥n ser√° m√°s dif√≠cil de usar, pero este es un problema diferente. <br><br>  En realidad, podr√≠a haber consecuencias negativas.  Digamos que los datos que necesitamos descomprimir se formaron a partir de bloques de 65.536 bytes cada uno.  Luego, el usuario nos da un trozo de memoria de 65,536 bytes para los datos descomprimidos.  Pero con la nueva interfaz de funci√≥n, el usuario deber√° asignar un bloque de memoria de 65.551 bytes, por ejemplo.  Entonces, el asignador puede verse obligado a asignar 96 o incluso 128 kilobytes, dependiendo de su implementaci√≥n.  Si el asignador es muy malo, podr√≠a detener repentinamente el almacenamiento en memoria cach√© en "mont√≥n" y comenzar a usar <code>mmap</code> y <code>munmap</code> cada vez para la asignaci√≥n de memoria (o liberar memoria usando <code>madvice</code> ).  Este proceso ser√° extremadamente lento debido a fallas en la p√°gina.  Como resultado, esta peque√±a optimizaci√≥n podr√≠a terminar ralentizando todo. <br><br><h3>  ¬øHay alguna aceleraci√≥n? </h3><br>  Entonces hice una versi√≥n del c√≥digo que usa tres optimizaciones: <br><br><ol><li>  Copiando 16 bytes en lugar de 8. </li><li>  Usando las instrucciones de reproducci√≥n aleatoria para el caso <code>offset &lt; 16</code> . </li><li>  Eliminado un extra si. </li></ol><br>  Comenc√© a probar este c√≥digo en diferentes conjuntos de datos y obtuve resultados inesperados. <br><br>  Ejemplo 1: <br>  Xeon E2650v2, datos del navegador Yandex, columna AppVersion. <br>  Referencia: 1,67 GB / seg. <br>  16 bytes, aleatorio: 2.94 GB / seg (76% m√°s r√°pido). <br><br>  Ejemplo 2 <br>  Xeon E2650v2, datos Yandex Direct, columna ShowsSumPosition. <br>  Referencia: 2,30 GB / seg. <br>  16 bytes, aleatorio: 1.91 GB / seg (20% m√°s lento). <br><br>  Al principio estaba muy feliz, cuando vi que todo se hab√≠a acelerado en un porcentaje tan grande.  Entonces vi que nada era m√°s r√°pido con otros archivos.  Incluso fue un poco m√°s lento para algunos de ellos.  Llegu√© a la conclusi√≥n de que los resultados dependen de la relaci√≥n de compresi√≥n.  Cuanto m√°s comprimido est√© el archivo, mayor ser√° la ventaja de cambiar a 16 bytes.  Esto se siente natural: cuanto mayor es la relaci√≥n de compresi√≥n, mayor es la longitud promedio de los fragmentos para copiar. <br><br>  Para investigar, utilic√© plantillas de C ++ para hacer opciones de c√≥digo para cuatro casos: usando fragmentos de 8 bytes o 16 bytes, y con o sin la instrucci√≥n aleatoria. <br><br><pre> <code class="plaintext hljs">template &lt;size_t copy_amount, bool use_shuffle&gt; void NO_INLINE decompressImpl(    const char * const source,    char * const dest,    size_t dest_size)</code> </pre> <br>  Las variantes completamente diferentes del c√≥digo funcionaron mejor en diferentes archivos, pero cuando se prueba en un escritorio, la versi√≥n con barajado siempre ganaba.  Probar en un escritorio es inconveniente porque tienes que hacer esto: <br><br><pre> <code class="plaintext hljs">sudo echo 'performance' | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor kill -STOP $(pidof firefox) $(pidof chromium)</code> </pre> <br>  Luego fui a uno de los viejos servidores de "desarrollo" (con el procesador Xeon E5645), tom√© a√∫n m√°s conjuntos de datos y obtuve resultados casi opuestos, lo que me confundi√≥ por completo.  Resulta que la elecci√≥n del algoritmo √≥ptimo depende del modelo del procesador, adem√°s de la relaci√≥n de compresi√≥n.  El procesador determina cu√°ndo es mejor usar la instrucci√≥n aleatoria, as√≠ como el umbral de cu√°ndo comenzar a usar la copia de 16 bytes. <br><br>  Por cierto, al realizar pruebas en nuestros servidores, tiene sentido hacer esto: <br><br><pre> <code class="plaintext hljs">sudo kill -STOP $(pidof python) $(pidof perl) $(pgrep -u skynet) $(pidof cqudp-client)</code> </pre> <br>  De lo contrario, los resultados ser√°n inestables.  Tambi√©n ten cuidado con la regulaci√≥n t√©rmica y la limitaci√≥n de potencia. <br><br><h3>  C√≥mo elegir el mejor algoritmo </h3><br>  Entonces tenemos cuatro variantes del algoritmo y necesitamos elegir la mejor para las condiciones.  Podr√≠amos crear un conjunto representativo de datos y hardware, luego realizar pruebas de carga serias y elegir el m√©todo que sea mejor en promedio.  Pero no tenemos un conjunto de datos representativo.  Para las pruebas, utilic√© una muestra de datos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Yandex Metrica</a> , Yandex Direct, Yandex Browser y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vuelos en los Estados Unidos</a> .  Pero esto no es suficiente, porque ClickHouse es utilizado por cientos de empresas en todo el mundo.  Al optimizar en exceso en un conjunto de datos, podr√≠amos causar una ca√≠da en el rendimiento con otros datos y ni siquiera darnos cuenta.  Y si los resultados dependen del modelo del procesador, tendremos que escribir expl√≠citamente las condiciones en el c√≥digo y probarlo en cada modelo (o consultar el manual de referencia sobre las instrucciones de temporizaci√≥n, ¬øqu√© te parece?).  En cualquier caso, esto lleva demasiado tiempo. <br><br>  As√≠ que decid√≠ usar otro m√©todo, que es obvio para los colegas que estudiaron en nuestra Escuela de An√°lisis de Datos: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"bandidos multi-armados"</a> .  El punto es que la variante del algoritmo se elige al azar, y luego usamos estad√≠sticas para elegir progresivamente m√°s a menudo las opciones que funcionan mejor. <br><br>  Tenemos muchos bloques de datos que deben descomprimirse, por lo que necesitamos llamadas a funciones independientes para descomprimir datos.  Podr√≠amos elegir uno de los cuatro algoritmos para cada bloque y medir su tiempo de ejecuci√≥n.  Una operaci√≥n como esta generalmente no cuesta nada en comparaci√≥n con el procesamiento de un bloque de datos, y en ClickHouse un bloque de datos sin comprimir es de al menos 64 KB.  (Lea este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> sobre la medici√≥n del tiempo). <br><br>  Para comprender mejor c√≥mo funciona el algoritmo de "bandidos multi-armados", veamos de d√≥nde viene el nombre.  Esta es una analog√≠a con las m√°quinas tragamonedas en un casino que tienen varias palancas que un jugador puede tirar para obtener una cantidad aleatoria de dinero.  El jugador puede tirar de las palancas varias veces en cualquier orden.  Cada palanca tiene una probabilidad fija de la cantidad correspondiente de dinero entregada, pero el jugador no sabe c√≥mo funciona y solo puede aprenderlo por experiencia en el juego.  Una vez que se dan cuenta, pueden maximizar sus ganancias. <br><br>  Un enfoque para maximizar la recompensa es evaluar la distribuci√≥n de probabilidad para cada palanca en cada paso en funci√≥n de las estad√≠sticas del juego de los pasos anteriores.  Luego, mentalmente "ganamos" una recompensa aleatoria por cada palanca, seg√∫n las distribuciones recibidas.  Finalmente, tiramos de la palanca que tuvo el mejor resultado en nuestro juego mental.  Este enfoque se llama Thompson Sampling. <br><br>  Pero estamos eligiendo un algoritmo de descompresi√≥n.  El resultado es el tiempo de ejecuci√≥n en picosegundos por byte: cuanto menos, mejor.  Consideraremos que el tiempo de ejecuci√≥n es una variable aleatoria y evaluaremos su distribuci√≥n utilizando estad√≠sticas matem√°ticas.  El enfoque bayesiano a menudo se usa para tareas como esta, pero ser√≠a engorroso insertar f√≥rmulas complejas en el c√≥digo C ++.  Podemos usar un enfoque param√©trico y decir que una variable aleatoria pertenece a una familia param√©trica de variables aleatorias, y luego evaluar sus par√°metros. <br><br>  ¬øC√≥mo seleccionamos la familia de variables aleatorias?  Como ejemplo, podr√≠amos suponer que el tiempo de ejecuci√≥n del c√≥digo tiene una distribuci√≥n normal.  Pero esto est√° absolutamente mal.  Primero, el tiempo de ejecuci√≥n no puede ser negativo, y la distribuci√≥n normal toma valores en todas partes en la recta num√©rica.  En segundo lugar, supongo que el tiempo de ejecuci√≥n tendr√° una "cola" pesada en el extremo derecho. <br><br>  Sin embargo, hay factores que podr√≠an hacer que sea una buena idea estimar la distribuci√≥n normal solo para los prop√≥sitos de Thompson Sampling (a pesar de que la distribuci√≥n de la variable objetivo no es necesariamente normal).  La raz√≥n de esto es que es muy f√°cil calcular la expectativa matem√°tica y la varianza, y despu√©s de un n√∫mero suficiente de iteraciones, una distribuci√≥n normal se vuelve bastante estrecha, no muy diferente de las distribuciones que habr√≠amos obtenido usando otros m√©todos.  Si no nos preocupamos demasiado por la tasa de convergencia en los primeros pasos, estos detalles pueden ignorarse. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esto puede parecer un enfoque algo ignorante. </font><font style="vertical-align: inherit;">La experiencia nos ha demostrado que el tiempo promedio para la ejecuci√≥n de la consulta, la carga de la p√°gina del sitio web, etc. es "basura" que no vale la pena calcular. </font><font style="vertical-align: inherit;">Ser√≠a mejor calcular la mediana, que es una </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">estad√≠stica robusta</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Pero esto es un poco m√°s dif√≠cil y, como mostrar√© m√°s adelante, el m√©todo descrito se justifica por razones pr√°cticas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al principio implement√© el c√°lculo de la expectativa matem√°tica y la varianza, pero luego decid√≠ que esto es demasiado bueno y que necesito simplificar el c√≥digo para hacerlo "peor":</font></font><br><br><pre> <code class="plaintext hljs">/// For better convergence, we don't use proper estimate of stddev. /// We want to eventually separate the two algorithms even in cases /// when there is no statistical significant difference between them. double sigma() const {    return mean() / sqrt(adjustedCount()); } double sample(pcg64 &amp; rng) const {    ...    return std::normal_distribution&lt;&gt;(mean(), sigma())(rng); }</code> </pre> <br> I wrote it so that the first few iterations were not taken into account, to eliminate the effect of memory latencies. <br><br> The result is a test program that can select the best algorithm for the input data, with optional modes that use the reference implementation of LZ4 or a specific version of the algorithm. <br><br> So there are six options: <br> ‚Äî Reference (baseline): original LZ4 without our modifications. <br> ‚Äî Variant 0: copy 8 bytes at a time without shuffle. <br> ‚Äî Variant 1: copy 8 bytes at a time with shuffle. <br> ‚Äî Variant 2: copy 16 bytes at a time without shuffle. <br> ‚Äî Variant 3: copy 16 bytes at a time with shuffle. <br> ‚Äî The "bandit" option, which selects the best of the four optimized variants. <br><br><h3> Testing on different CPUs </h3><br> If the result strongly depends on the CPU model, it would be interesting to find out exactly how it is affected. There might be an exceptionally large difference on certain CPUs. <br><br> I prepared a set of datasets from different tables in ClickHouse with real data, for a total of 256 different files each with 100 MB of uncompressed data (the number 256 was coincidental). Then I looked at the CPUs of the servers where I can run benchmarks. I found servers with the following CPUs: <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2650 v2 @ 2.60GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 v4 @ 2.00GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 0 @ 2.20GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5645 @ 2.40GHz <br> ‚Äî Intel Xeon E312xx (Sandy Bridge) <br> ‚Äî AMD Opteron(TM) Processor 6274 <br> ‚Äî AMD Opteron(tm) Processor 6380 <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2683 v4 @ 2.10GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5530 @ 2.40GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5440 @ 2.83GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2667 v2 @ 3.30GHz <br><br> The most interesting part comes next ‚Äî the processors provided by the R&amp;D department: <br> ‚Äî AMD EPYC 7351 16-Core Processor, a new AMD server processor. <br> ‚Äî Cavium ThunderX2, which is AArch64, not x86. For these, my SIMD optimization needed to be reworked a bit. The server has 224 logical and 56 physical cores. <br><br> There are 13 servers in total, and each of them runs the test on 256 files in 6 variants (reference, 0, 1, 2, 3, adaptive). The test is run 10 times, alternating between the options in random order. It outputs 199,680 results that we can compare. <br><br> For example, we can compare different CPUs with each other. But we shouldn't jump to conclusions from these results, because we are only testing the LZ4 decompression algorithm on a single core (this is a very narrow case, so we only get a micro-benchmark). For example, the Cavium has the lowest performance per single core. But I tested ClickHouse on it myself, and it wins out over Xeon E5-2650 v2 on heavy queries due to the greater number of cores, even though it is missing many optimizations that are made in ClickHouse specifically for the x86. <br><br><pre> ‚îå‚îÄcpu‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄref‚îÄ‚î¨‚îÄadapt‚îÄ‚î¨‚îÄ‚îÄmax‚îÄ‚î¨‚îÄbest‚îÄ‚î¨‚îÄadapt_boost‚îÄ‚î¨‚îÄmax_boost‚îÄ‚î¨‚îÄadapt_over_max‚îÄ‚îê<font></font>
‚îÇ E5-2667 v2 @ 3.30GHz ‚îÇ 2.81 ‚îÇ 3.19 ‚îÇ 3.15 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2650 v2 @ 2.60GHz ‚îÇ 2.5 ‚îÇ 2.84 ‚îÇ 2.81 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2683 v4 @ 2.10GHz ‚îÇ 2.26 ‚îÇ 2.63 ‚îÇ 2.59 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.15 ‚îÇ 1.02 ‚îÇ<font></font>
‚îÇ E5-2660 v4 @ 2.00GHz ‚îÇ 2.15 ‚îÇ 2.49 ‚îÇ 2.46 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.14 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD EPYC 7351 ‚îÇ 2.03 ‚îÇ 2.44 ‚îÇ 2.35 ‚îÇ 3 ‚îÇ 1.20 ‚îÇ 1.16 ‚îÇ 1.04 ‚îÇ<font></font>
‚îÇ E5-2660 0 @ 2.20GHz ‚îÇ 2.13 ‚îÇ 2.39 ‚îÇ 2.37 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E312xx (Sandy Bridge) ‚îÇ 1.97 ‚îÇ 2.2 ‚îÇ 2.18 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5530 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.93 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.17 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ E5645 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.92 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ AMD Opteron 6380 ‚îÇ 1.47 ‚îÇ 1.58 ‚îÇ 1.56 ‚îÇ 1 ‚îÇ 1.07 ‚îÇ 1.06 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD Opteron 6274 ‚îÇ 1.15 ‚îÇ 1.35 ‚îÇ 1.35 ‚îÇ 1 ‚îÇ 1.17 ‚îÇ 1.17 ‚îÇ 1 ‚îÇ<font></font>
‚îÇ E5440 @ 2.83GHz ‚îÇ 1.35 ‚îÇ 1.33 ‚îÇ 1.42 ‚îÇ 1 ‚îÇ 0.99 ‚îÇ 1.05 ‚îÇ 0.94 ‚îÇ<font></font>
‚îÇ Cavium ThunderX2 ‚îÇ 0.84 ‚îÇ 0.87 ‚îÇ 0.87 ‚îÇ 0 ‚îÇ 1.04 ‚îÇ 1.04 ‚îÇ 1 ‚îÇ<font></font>
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò </pre><br><ul><li> ref, adapt, max ‚Äî The speed in gigabytes per second (the value that is the reverse of the arithmetic mean of time for all launches on all datasets). </li><li> best ‚Äî The number of the best algorithm among the optimized variants, from 0 to 3. </li><li> adapt_boost ‚Äî The relative advantage of the adaptive algorithm compared to the baseline. </li><li> max_boost ‚Äî The relative advantage of the best of the non-adaptive variants compared to the baseline. </li><li> adapt_over_max ‚Äî The relative advantage of the adaptive algorithm over the best non-adaptive one. </li></ul><br> The results show that we were able to speed up decompression by 12-20% on modern x86 processors. Even on ARM we saw 4% improvement, despite the fact that we didn't optimize much for this architecture. It is also clear that on average for different datasets, the "bandit" algorithm comes out ahead of the pre-selected best variant on all processors (except for very old Intel CPUs). <br><br><h3>  Conclusi√≥n </h3><br> In practice, the usefulness of this work is dubious. Yes, LZ4 decompression was accelerated on average by 12-20%, and on some datasets the performance more than doubled. But in general, this doesn't have much effect on query execution time. It's difficult to find real queries that gain more than a couple percent in speed. <br><br> We decided to use ZStandard level 1 instead of LZ4 on several Yandex Metrica clusters intended for executing long queries, because it is more important to save IO and disk space on cold data. Keep this in mind if you have similar workload. <br><br> We observed the greatest benefits from optimizing decompression in highly compressible data, such as columns with mostly duplicate string values. However, we have developed a separate solution specifically for this scenario that allows us to significantly speed up queries over this kind of data. <br><br> Another point to remember is that optimization of decompression speed is often limited by the format of the compressed data. LZ4 uses a very good format, but Lizard, Density and LZSSE have other formats that can work faster. Perhaps instead of trying to accelerate LZ4, it would be better to just integrate LZSSE into ClickHouse. <br><br> It's unlikely that these optimizations will be implemented in the mainstream LZ4 library: in order to use them, the library interface would have to be modified. In fact, this is often the case with improving algorithms ‚Äî optimizations don't fit into old abstractions and they have to be revised. However, variable names have already been corrected in the original implementation. For instance, inc and dec tables have been <a href="">corrected</a> . In addition, about a month ago, the original implementation accelerated decompression by the same 12-15% by copying 32 bytes instead of 16, as discussed above. We tried the 32-byte option ourselves and the results were not that great, but they were still <a href="">faster</a> . <br><br> If you look at the profile at the beginning of the article, you may notice that we could have removed one extra copying operation from the page cache to userspace (either using <code>mmap</code> , or using <code>O_DIRECT</code> and userspace page cache, but both options are problematic). We also could have slightly improved the checksum calculation (CityHash128 is currently used without CRC32-C, but we could use HighwayHash, FARSH or XXH3). Acceleration of these two operations is useful for weakly compressed data, since they are performed on compressed data. <br><br> In any case, the changes have already been added to master more than a year ago, and the ideas that resulted from this research have been applied in other tasks. You can also watch the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">video</a> from HighLoad++ Siberia, or view the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">presentation</a> (both in Russian). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457612/">https://habr.com/ru/post/457612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457600/index.html">Descripci√≥n general de los auriculares Snom A150, Snom A100M y D</a></li>
<li><a href="../457602/index.html">Investigar el rendimiento de DBMS MS SQL Server Developer 2016 y PostgreSQL 10.5 para 1C</a></li>
<li><a href="../457606/index.html">Alan Kay: ¬øQu√© se puede llamar lo m√°s sorprendente que las computadoras hicieron posible?</a></li>
<li><a href="../457608/index.html">C√≥mo visualizar datos en una historia convincente</a></li>
<li><a href="../457610/index.html">An√°lisis de vulnerabilidades de Evil Parcel</a></li>
<li><a href="../457614/index.html">Secretos de encontrar un trabajo en el extranjero de un cazatalentos en ejercicio</a></li>
<li><a href="../457616/index.html">Mi "¬°Guau, no lo sab√≠a!" momentos con broma</a></li>
<li><a href="../457618/index.html">Ser un desarrollador moderno de pila completa</a></li>
<li><a href="../457622/index.html">Medici√≥n del rendimiento de Qt</a></li>
<li><a href="../457624/index.html">C√≥mo rompimos la vieja choza y construimos un rascacielos en su lugar</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游뱡 游꼔 游꼡 Explorando OpenCV en StereoPi: Mapa de profundidad del video 游녧游 游꿥 游낶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoy queremos compartir una serie de ejemplos en Python para los estudiantes de OpenCV en la Raspberry Pi, a saber, la placa StereoPi de doble c치mara. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Explorando OpenCV en StereoPi: Mapa de profundidad del video</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446872/"><img src="https://habrastorage.org/webt/hb/xt/po/hbxtpox_r6mswlkshq4w3cpovr4.gif"><br><br>  Hoy queremos compartir una serie de ejemplos en Python para los estudiantes de OpenCV en la Raspberry Pi, a saber, la placa StereoPi de doble c치mara.  El c칩digo terminado (m치s la imagen de Raspbian) lo ayudar치 a seguir todos los pasos, comenzando con la captura de una imagen y terminando con la obtenci칩n de un mapa de profundidad del video capturado. <br><a name="habracut"></a><br><h3>  Introductorio </h3><br>  Debo enfatizar de inmediato que estos ejemplos son para una inmersi칩n c칩moda en el tema y no para una soluci칩n de producci칩n.  Si es un usuario avanzado de OpenCV y ha estado tratando con frambuesas, entonces sabe que para un funcionamiento adecuado es recomendable codificar una mordida e incluso usar una GPU de frambuesa.  Al final del art칤culo, tocar칠 los "cuellos de botella" de la soluci칩n de Python y el rendimiento general con m치s detalle. <br><br><h3>  Con que estamos trabajando </h3><br>  Tenemos una configuraci칩n como el hierro: <br><br><img src="https://habrastorage.org/webt/or/pd/9u/orpd9ufeuctr0lbmsk0kfogroao.jpeg"><br><br>  Placa StereoPi a bordo del Raspberry Pi Compute Module 3+.  Las dos c치maras m치s simples est치n conectadas para la versi칩n Raspberry Pi V1 (en el sensor ov5647). <br><br>  Lo que est치 instalado: <br><br><ul><li>  Raspbian Stretch (kernel 4.14.98-v7 +) </li><li>  Python 3.5.3 </li><li>  OpenCV 3.4.4 (precompilado, 'pip' de Python Wheels) </li><li>  Picamera 1.13 </li><li>  StereoVision lib 1.0.3 (https://github.com/erget/StereoVision) </li></ul><br>  El proceso de instalaci칩n de todo el software est치 m치s all치 del alcance de este art칤culo, y solo sugerimos descargar la imagen Raspbian terminada (enlaces al github al final del art칤culo). <br><br><h3>  Paso uno: captura una imagen </h3><br>  Para hacer esto, use el script 1_test.py <br><br>  Abra la consola, vaya de la carpeta de inicio a la carpeta con ejemplos: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> stereopi-tutorial</code> </pre> <br>  Ejecute el script: <br><br><pre> <code class="bash hljs">python 1_test.py</code> </pre> <br>  Despu칠s de comenzar, se muestra una vista previa de nuestra imagen est칠reo en la pantalla.  El proceso se puede interrumpir presionando el bot칩n Q. Esto guardar치 la 칰ltima imagen capturada, que se utilizar치 en uno de los siguientes scripts para configurar el mapa de profundidad. <br><br>  Este script le permite asegurarse de que todo el hardware funciona correctamente, as칤 como obtener la primera imagen para uso futuro. <br><br>  As칤 es como se ve el primer script: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wllLrNUw3SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Paso dos: recolecte im치genes para la calibraci칩n </h3><br>  Si hablamos de un caballo esf칠rico en el vac칤o, entonces para obtener un mapa de profundidad de buena calidad, necesitamos tener dos c치maras absolutamente id칠nticas, cuyos ejes vertical y 칩ptico sean perfectamente paralelos y los ejes horizontales coincidan.  Pero en el mundo real, todas las c치maras son ligeramente diferentes, y no es posible organizarlas perfectamente.  Por lo tanto, se invent칩 un truco de calibraci칩n de software.  Usando dos c치maras del mundo real, se toma una gran cantidad de im치genes de un objeto previamente conocido (tenemos una imagen con un tablero de ajedrez), y luego un algoritmo especial calcula todas las "imperfecciones" e intenta corregir las im치genes para que est칠n cerca del ideal. <br><br>  Este script realiza la primera etapa del trabajo, es decir, ayuda a hacer una serie de fotos para la calibraci칩n. <br><br>  Antes de cada foto, el gui칩n comienza una cuenta regresiva de 5 segundos.  Esta vez, como regla, es suficiente para mover el tablero a una nueva posici칩n, para asegurarse de que en ambas c치maras no se arrastre por los bordes y fije su posici칩n (para que no haya borrosidad en la foto).  Por defecto, el tama침o de la serie se establece en 30 fotos. <br><br>  Lanzamiento <br><br><pre> <code class="bash hljs">python 2_chess_cycle.py</code> </pre> <br>  Proceso: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1XCAlU3k-xs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Como resultado, tenemos una serie de fotos en la carpeta / escenas. <br><br><h3>  Cortamos las im치genes en parejas. </h3><br>  El tercer script 3_pairs_cut.py corta las fotos tomadas en im치genes "izquierda" y "derecha" y las guarda en la carpeta / pares.  De hecho, podr칤amos excluir este script y hacer el corte sobre la marcha, pero es muy 칰til en futuros experimentos.  Por ejemplo, puede guardar segmentos de diferentes series, usar sus scripts para trabajar con estos pares, o incluso copiar las im치genes tomadas en otras c치maras est칠reo como pares. <br><br>  Adem치s, antes de cortar cada imagen, el script muestra su imagen, que a menudo le permite ver fotos fallidas antes del siguiente paso de calibraci칩n y simplemente eliminarlas. <br><br>  Ejecute el script: <br><br><pre> <code class="bash hljs">python 3_pairs_cut.py</code> </pre> <br>  Video corto: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/95DWmPECbDc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  En la imagen final hay un conjunto de fotograf칤as y pares de cortes que utilizamos para nuestros experimentos. <br><br><h3>  Calibraci칩n </h3><br>  El script 4_calibration.py dibuja todos los pares con los tableros de ajedrez y calcula las correcciones necesarias para corregir las im치genes.  El gui칩n hizo un rechazo autom치tico de fotos en las que no se encontr칩 un tablero de ajedrez, por lo que en caso de fotos sin 칠xito el trabajo no se detiene.  Despu칠s de cargar los 30 pares de im치genes, comienza el c치lculo.  Nos lleva aproximadamente un minuto y medio.  Una vez finalizado, el script toma uno de los pares est칠reo y, sobre la base de los par치metros de calibraci칩n calculados, los "corrige" y muestra una imagen rectificada en la pantalla.  En este punto, puede evaluar la calidad de la calibraci칩n. <br><br>  Ejecutar por comando: <br><br><pre> <code class="bash hljs">python 4_calibration.py</code> </pre> <br>  Script de calibraci칩n en el trabajo: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/vtPhu23tKGo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Configuraci칩n del mapa de profundidad </h3><br>  El script 5_dm_tune.py carga la imagen tomada por el primer script y los resultados de la calibraci칩n.  A continuaci칩n, se muestra una interfaz que le permite cambiar la configuraci칩n del mapa de profundidad y ver qu칠 cambios.  Consejo: antes de configurar los par치metros, tome un marco en el que simult치neamente tendr치 objetos a diferentes distancias: cerca (30-40 cent칤metros), a una distancia promedio (metro o dos) y en la distancia.  Esto le permitir치 elegir los par치metros en los que los objetos cercanos ser치n rojos y los objetos distantes ser치n azul oscuro. <br><br>  La imagen contiene un archivo con nuestra configuraci칩n de mapa de profundidad.  Puede cargar nuestra configuraci칩n en un script simplemente haciendo clic en el bot칩n "Cargar configuraci칩n" <br><br>  Lanzamos: <br><br><pre> <code class="bash hljs">python 5_dm_tune.py</code> </pre> <br>  As칤 es como se ve el proceso de configuraci칩n: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Z4j3NrMyeGE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Mapa de profundidad en tiempo real </h3><br>  La 칰ltima secuencia de comandos 6_dm_video.py crea un mapa de profundidad a partir del video utilizando los resultados de secuencias de comandos anteriores (calibraci칩n y configuraci칩n del mapa de profundidad). <br><br>  Lanzamiento <br><br><pre> <code class="bash hljs">python 6_dm_video.py</code> </pre> <br>  En realidad el resultado: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/f29arVstfZA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  춰Esperamos que nuestros guiones sean 칰tiles en sus experimentos! <br><br>  Por si acaso, agregar칠 que todas las secuencias de comandos tienen procesamiento de pulsaci칩n de teclas, y puede interrumpir el trabajo presionando el bot칩n Q. Si se detiene "bruscamente", por ejemplo, Ctrl + C, el proceso de interacci칩n de Python con la c치mara puede romperse y ser치 necesario reiniciar la frambuesa. <br><br><h3>  Para avanzado </h3><br><ul><li>  La primera secuencia de comandos en el proceso muestra el tiempo promedio entre capturas de cuadros y, al finalizar, el FPS promedio.  Esta es una herramienta simple y conveniente para seleccionar dichos par치metros de imagen en los que Python todav칤a no se est치 "ahogando".  Con 칠l, recogimos 1280x480 a 20 FPS, en el que el video se renderiza sin demora. </li><li>  Puede notar que capturamos un par est칠reo en una resoluci칩n de 1280x480 y luego lo escalamos a 640x240. <br><br>  Una pregunta razonable: 쯣or qu칠 todo esto y por qu칠 no tomar inmediatamente la miniatura y no cargar nuestra pit칩n reduci칠ndola? <br><br>  Respuesta: con la captura directa a resoluciones muy bajas, todav칤a hay problemas en el n칰cleo de frambuesa (la imagen se rompe).  Por lo tanto, tomamos una resoluci칩n m치s grande y luego reducimos la imagen.  Aqu칤 usamos un peque침o truco: la imagen no se escala con Python, sino con la ayuda de la GPU, por lo que no hay carga en el n칰cleo del brazo. </li><li>  쯇or qu칠 capturar video en formato BGRA, no BGR? <br>  Utilizamos los recursos de la GPU para reducir el tama침o de la imagen, y el nativo para el m칩dulo de cambio de tama침o es el formato BGRA.  Si usamos BGR en lugar de BGRA, tendremos dos inconvenientes.  El primero es ligeramente m치s bajo que el FPS final (en nuestras pruebas - 20 por ciento).  El segundo es el trabajo constante en la consola "PiCameraAlfaStripping: uso de stripping alfa para convertir a formato no alpha;  puede encontrar el formato alfa equivalente m치s r치pido ".  Buscar en Google llev칩 a la secci칩n de documentaci칩n de Picamera, que describe este truco. </li><li>  쮻칩nde est치 el PiRGBArray? <br><br>  Esto es como la clase nativa de Picamera para trabajar con la c치mara, pero aqu칤 no se usa.  Ya result칩 que en nuestras pruebas, trabajar con una matriz numpy "hecha a mano" es mucho m치s r치pido (aproximadamente una vez y media) que usar PiRGBArray.  Esto no significa que PiRGBArray sea malo, lo m치s probable es que estas sean nuestras manos torcidas. </li><li>  쯈u칠 tan cargado es el porcentaje en el c치lculo del mapa de profundidad? <br>  Respondamos con una imagen: <br><br><img src="https://habrastorage.org/webt/nn/ez/ef/nnezefyxuiuxx7difz1xctii16w.jpeg"><br><br>  Vemos que de los 4 n칰cleos del procesador, de hecho, solo uno est치 cargado, y eso es el 70%.  Y esto a pesar del hecho de que trabajamos con una GUI, y estamos enviando im치genes y mapas de profundidad al usuario.  Esto significa que hay un buen margen de rendimiento, y un ajuste fino de OpenCV con OpenMP y otras ventajas en C, as칤 como un modo de "combate" sin una GUI pueden dar resultados muy interesantes. </li><li>  쮺u치l es el mapa de profundidad de FPS m치ximo obtenido con esta configuraci칩n? <br><br>  El m치ximo alcanzado por nosotros fue de 17 FPS, al capturar 20 cuadros por segundo de la c치mara.  Los m치s "sensibles" en t칠rminos de par치metros de velocidad en la configuraci칩n del mapa de profundidad son MinDisparity y NumOfDisparities.  Esto es l칩gico, ya que determinan el n칰mero de "pasos" realizados dentro del algoritmo por la ventana de b칰squeda para comparar marcos.  El segundo m치s sensible es preFilterCap, que afecta, en particular, la "suavidad" del mapa de profundidad. </li><li>  쯈u칠 pasa con la temperatura del procesador? <br><br>  En Compute Module 3+ Lite (una nueva serie, con una "tapa" de hierro en el proceso) muestra aproximadamente los siguientes resultados: <br><br><img src="https://habrastorage.org/webt/ba/p7/kw/bap7kwdbbhd0y2bmvebpqzimqpa.jpeg"></li><li>  쮺칩mo usar la GPU? <br><br>  Como m칤nimo, se puede utilizar para la andistorizaci칩n y rectificaci칩n de im치genes en tiempo real, porque hay ejemplos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu칤 en WebGL</a> ), Python <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pi3d</a> , as칤 como el proyecto Processing ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ejemplos para frambuesas</a> ). <br><br>  Hay otro desarrollo interesante de Koichi Nakamura, llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">py-videocore</a> .  En nuestra correspondencia con 칠l, expres칩 la idea de que para acelerar StereoBM puede usar su n칰cleo y OpenCV <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">con el soporte de Cuda</a> .  En general, para la optimizaci칩n, un borde intacto, como dicen. </li></ul><br>  Gracias por su atenci칩n, y aqu칤 est치 el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace prometido a la fuente</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/446872/">https://habr.com/ru/post/446872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../446860/index.html">Historia de 3dfx Voodoo1</a></li>
<li><a href="../446862/index.html">Lo que los dise침adores esperan en DUMP-2019: descripci칩n general de la secci칩n de dise침o</a></li>
<li><a href="../446864/index.html">Energ칤a, calor y agua</a></li>
<li><a href="../446866/index.html">Sistemas operativos: tres piezas f치ciles. Parte 2: Abstracci칩n: Proceso (traducci칩n)</a></li>
<li><a href="../446870/index.html">Sistemas de part칤culas: una historia navide침a</a></li>
<li><a href="../446876/index.html">Mosc칰, 18 de abril - QIWI SERVER PARTY 4.0</a></li>
<li><a href="../446880/index.html">Gr치ficos incorrectos: nuestra experiencia</a></li>
<li><a href="../446882/index.html">MIPT recibi칩 el derecho de organizar la Copa Mundial de Programaci칩n ICPC en 2020 en Mosc칰</a></li>
<li><a href="../446884/index.html">Qu칠 leer y ver en ciencia ficci칩n fresca: Marte, cyborgs e IA rebelde</a></li>
<li><a href="../446886/index.html">Los mejores expertos de la Expo 3D: Sunny Wong. Se pueden prevenir m치s de 25 millones de esguinces</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
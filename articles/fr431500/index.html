<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüé® üë©üèø‚Äçüî¨ ü§∏ Bases de donn√©es et Kubernetes (revue et rapport vid√©o) üë©‚Äçüë©‚Äçüëß üí© üàØÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le 8 novembre, dans le hall principal de la conf√©rence HighLoad ++ 2018 , dans le cadre de la section DevOps et op√©rations, un rapport a √©t√© √©tabli in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bases de donn√©es et Kubernetes (revue et rapport vid√©o)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/431500/">  Le 8 novembre, dans le hall principal de la conf√©rence <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HighLoad ++ 2018</a> , dans le cadre de la section DevOps et op√©rations, un rapport a √©t√© √©tabli intitul√© Bases de donn√©es et Kubernetes.  Il parle de la haute disponibilit√© des bases de donn√©es et des approches de tol√©rance aux pannes pour Kubernetes et avec lui, ainsi que des options pratiques pour placer le SGBD dans les clusters Kubernetes et les solutions existantes pour cela (y compris Stolon pour PostgreSQL). <br><br><img src="https://habrastorage.org/webt/oq/mh/kp/oqmhkpy4pxg-olk9yybf_julwvu.jpeg"><br><br>  Par tradition, nous sommes heureux de pr√©senter une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>vid√©o avec un rapport</b></a> (environ une heure, <b>beaucoup plus</b> informatif <b>que l'</b> article) et la principale compression sous forme de texte.  C'est parti! <a name="habracut"></a><br><br><h2>  Th√©orie </h2><br>  Ce rapport est apparu comme une r√©ponse √† l'une des questions les plus populaires que nous avons pos√©es sans rel√¢che ces derni√®res ann√©es √† diff√©rents endroits: commentaires sur Habr ou YouTube, r√©seaux sociaux, etc.  Cela semble simple: "Est-il possible d'ex√©cuter la base de donn√©es dans Kubernetes?", Et si nous r√©pondions g√©n√©ralement "g√©n√©ralement oui, mais ...", alors il n'y avait clairement pas assez d'explications pour ces "en g√©n√©ral" et "mais", mais pour les adapter dans un court message n'a pas r√©ussi. <br><br>  Cependant, pour commencer, je r√©sume le probl√®me de la "base de donn√©es [donn√©es]" √† l'√©tat dans son ensemble.  Un SGBD n'est qu'un cas particulier de d√©cisions avec √©tat, dont une liste plus compl√®te peut √™tre repr√©sent√©e comme suit: <br><br><img src="https://habrastorage.org/webt/px/ps/2_/pxps2_ff80ru5qfth8bduiu_kdw.png"><br><br>  Avant d'examiner des cas sp√©cifiques, je parlerai de trois caract√©ristiques importantes du travail / de l'utilisation de Kubernetes. <br><br><h3>  1. Philosophie de haute disponibilit√© de Kubernetes </h3><br>  Tout le monde conna√Æt l'analogie ¬´animaux de compagnie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vs b√©tail</a> ¬ª et comprend que si Kubernetes est une histoire du monde du troupeau, alors les SGBD classiques ne sont que des animaux de compagnie. <br><br>  Et √† quoi ressemblait l'architecture des ¬´animaux de compagnie¬ª dans la version ¬´traditionnelle¬ª?  Un exemple classique d'installation de MySQL est la r√©plication sur deux serveurs de fer avec une alimentation redondante, un disque, un r√©seau ... et tout le reste (y compris un ing√©nieur et divers outils auxiliaires), qui nous aideront √† √™tre s√ªrs que le processus MySQL n'√©chouera pas, et s'il y a un probl√®me avec l'un des √©l√©ments critiques pour ses composants, la tol√©rance aux pannes sera respect√©e: <br><br><img src="https://habrastorage.org/webt/0m/qg/s3/0mqgs3e3cco1zukmlah1jg2ubjs.png"><br><br>  √Ä quoi ressemblera la m√™me chose dans Kubernetes?  Ici, il y a g√©n√©ralement beaucoup plus de serveurs de fer, ils sont plus simples et ils n'ont pas d'alimentation et de r√©seau redondants (dans le sens o√π la perte d'une machine n'affecte rien) - tout cela est combin√© dans un cluster.  Sa tol√©rance aux pannes est fournie par le logiciel: si quelque chose arrive au n≈ìud, Kubernetes d√©tecte et d√©marre les instances n√©cessaires sur l'autre n≈ìud. <br><br>  Quels sont les m√©canismes de haute disponibilit√© dans les K8? <br><br><img src="https://habrastorage.org/webt/n2/gw/mh/n2gwmhiogm3uzv1m5igrzqpyifq.png"><br><br><ol><li>  Contr√¥leurs  Il en existe de nombreux, mais deux principaux: <code>Deployment</code> (pour les applications sans √©tat) et <code>StatefulSet</code> (pour les applications avec √©tat).  Ils stockent toute la logique des actions entreprises en cas de panne d'un n≈ìud (inaccessibilit√© du pod). </li><li>  <code>PodAntiAffinity</code> - la possibilit√© de sp√©cifier des pods sp√©cifiques afin qu'ils ne se trouvent pas sur le m√™me noeud. </li><li>  <code>PodDisruptionBudgets</code> - limite le nombre d'instances de pod qui peuvent √™tre d√©sactiv√©es en m√™me temps en cas de travail planifi√©. </li></ol><br><h3>  2. Garantie de coh√©rence Kubernetes </h3><br>  Comment fonctionne le sch√©ma de tol√©rance de panne √† ma√Ætre unique familier?  Deux serveurs (ma√Ætre et secours), dont l'un est constamment accessible par l'application, qui √† son tour est utilis√© via l'√©quilibreur de charge.  Que se passe-t-il en cas de probl√®me de r√©seau? <br><br><img src="https://habrastorage.org/webt/6p/1k/ve/6p1kvelnrzyrphtu6sb_agftgaa.gif"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>Split-brain</i></a> classique: l'application commence √† acc√©der aux deux instances du SGBD, dont chacune se consid√®re comme la principale.  Pour √©viter cela, keepalived a √©t√© remplac√© par corosync avec d√©j√† trois instances pour atteindre un quorum lors du vote pour le ma√Ætre.  Cependant, m√™me dans ce cas, il y a des probl√®mes: si une instance de SGBD tomb√©e en panne tente de "se tuer" de toutes les mani√®res possibles (supprimer l'adresse IP, traduire la base de donn√©es en lecture seule ...), alors l'autre partie du cluster ne sait pas ce qui est arriv√© au ma√Ætre - cela pourrait arriver, que ce noeud fonctionne toujours et que les requ√™tes y parviennent, ce qui signifie que nous ne pouvons toujours pas changer d'assistant. <br><br>  Pour r√©soudre cette situation, il existe un m√©canisme pour isoler le n≈ìud afin de prot√©ger l'ensemble du cluster contre un fonctionnement incorrect - ce processus est appel√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>cl√¥ture</i></a> .  L'essence pratique se r√©sume au fait que nous essayons par des moyens externes de "tuer" la voiture tomb√©e.  Les approches peuvent √™tre diff√©rentes: de la mise hors tension de la machine via IPMI et du blocage du port du commutateur √† l'acc√®s √† l'API du fournisseur de cloud, etc.  Et ce n'est qu'apr√®s cette op√©ration que vous pouvez changer d'assistant.  Cela garantit une garantie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>au plus une fois</i></a> qui nous assure la <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">coh√©rence</a></i> . <br><br><img src="https://habrastorage.org/webt/sl/xb/9r/slxb9rwf-lk8mcdaeqiuankz3z8.png"><br><br>  Comment r√©aliser la m√™me chose dans Kubernetes?  Pour ce faire, il existe d√©j√† des contr√¥leurs dont le comportement en cas d'inaccessibilit√© d'un n≈ìud est diff√©rent: <br><br><ol><li>  <code>Deployment</code> : "On m'a dit qu'il devrait y avoir 3 pods, et maintenant il n'y a plus que 2 pods - j'en cr√©erai un nouveau"; </li><li>  <code>StatefulSet</code> : "Pod disparu?"  J'attendrai: soit ce n≈ìud reviendra, soit ils nous diront de le tuer ",  les conteneurs eux-m√™mes (sans action de l'op√©rateur) ne sont pas recr√©√©s.  C'est ainsi que la m√™me garantie au plus une fois est obtenue. </li></ol><br>  Cependant, ici, dans ce dernier cas, une cl√¥ture est n√©cessaire: nous avons besoin d'un m√©canisme qui confirme que ce n≈ìud est d√©finitivement parti.  Le rendre automatique est, d'une part, tr√®s difficile (de nombreuses impl√©mentations sont n√©cessaires), et d'autre part, pire encore, il tue g√©n√©ralement les n≈ìuds lentement (l'acc√®s √† IPMI peut prendre des secondes ou des dizaines de secondes, voire des minutes).  Peu de gens sont satisfaits de l'attente par minute pour passer de la base au nouveau ma√Ætre.  Mais il existe une autre approche qui ne n√©cessite pas de m√©canisme de cl√¥ture ... <br><br>  Je vais commencer sa description en dehors de Kubernetes.  Il utilise un √©quilibreur de charge sp√©cial √† travers lequel les backends acc√®dent au SGBD.  Sa sp√©cificit√© r√©side dans le fait qu'il a la propri√©t√© de la coh√©rence, c'est-√†-dire  protection contre les pannes de r√©seau et le split-brain, car il vous permet de supprimer toutes les connexions au ma√Ætre actuel, d'attendre la synchronisation (r√©plique) sur un autre n≈ìud et de basculer vers celui-ci.  Je n'ai pas trouv√© de terme √©tabli pour cette approche et je l'ai appel√© <i>Switchover coh√©rent</i> . <br><br><img src="https://habrastorage.org/webt/ct/oq/lk/ctoqlkp3efyctjlvsyiheesk2s4.gif"><br><br>  La question principale avec lui est de savoir comment la rendre universelle, en fournissant un support aux fournisseurs de cloud et aux installations priv√©es.  Pour cela, des serveurs proxy sont ajout√©s aux applications.  Chacun d'eux acceptera les demandes de sa candidature (et les transmettra au SGBD), et un quorum sera recueilli de chacun d'eux.  D√®s qu'une partie du cluster √©choue, les mandataires qui ont perdu le quorum suppriment imm√©diatement leurs connexions au SGBD. <br><br><img src="https://habrastorage.org/webt/nj/y0/-t/njy0-tahnwp8uxeyevxot_tlntq.png"><br><br><h3>  3. Stockage de donn√©es et Kubernetes </h3><br>  Le m√©canisme principal est le lecteur r√©seau <i>Network Block Device</i> (aka SAN) dans diverses impl√©mentations pour les options de cloud souhait√©es ou le bare metal.  Cependant, le fait de mettre une base de donn√©es charg√©e (par exemple, MySQL, qui n√©cessite 50 000 IOPS) dans le cloud (AWS EBS) ne fonctionnera pas en raison de la <i>latence</i> . <br><br><img src="https://habrastorage.org/webt/qq/wp/r7/qqwpr7fae-nbek0y2o6ex9lbzsa.png"><br><br>  Kubernetes pour de tels cas a la capacit√© de connecter un disque dur <i>local</i> - <i>Stockage local</i> .  Si une panne se produit (le disque n'est plus disponible dans le pod), nous sommes alors oblig√©s de r√©parer cette machine - similaire au sch√©ma classique en cas de panne d'un serveur fiable. <br><br>  Les deux options ( <i>Network Block Device</i> et <i>Local Storage</i> ) appartiennent √† la cat√©gorie <i>ReadWriteOnce</i> : le stockage ne peut pas √™tre mont√© √† deux endroits (pods) - pour cette mise √† l'√©chelle, vous devrez cr√©er un nouveau disque et le connecter √† un nouveau pod (il existe un m√©canisme K8 int√©gr√© pour cela) , puis remplissez avec les donn√©es n√©cessaires (d√©j√† effectu√©es par nos forces). <br><br>  Si nous avons besoin du mode <i>ReadWriteMany</i> , des impl√©mentations <i>Network File System</i> (ou NAS) sont disponibles: pour le cloud public, ce sont <code>AzureFile</code> et <code>AWSElasticFileSystem</code> , et pour leurs installations CephFS et Glusterfs pour les fans de syst√®mes distribu√©s, ainsi que NFS. <br><br><img src="https://habrastorage.org/webt/eq/y6/gp/eqy6gpf2duz9ljtzc342bj9upg4.png"><br><br><h2>  Pratique </h2><br><h3>  1. Autonome </h3><br>  Cette option concerne le cas o√π rien ne vous emp√™che de d√©marrer le SGBD en mode serveur s√©par√© avec stockage local.  Il n'est pas question de haute disponibilit√© ... bien qu'elle puisse √™tre dans une certaine mesure (c'est-√†-dire suffisante pour cette application) mise en ≈ìuvre au niveau du fer.  Il existe de nombreux cas pour cette application.  Tout d'abord, ce sont toutes sortes d'environnements de d√©veloppement et de d√©veloppement, mais pas seulement: les services secondaires arrivent √©galement ici, leur d√©sactivation pendant 15 minutes n'est pas critique.  Dans Kubernetes, ceci est impl√©ment√© par <code>StatefulSet</code> avec un pod: <br><br><img src="https://habrastorage.org/webt/hl/xk/ha/hlxkhaodepe50imvuobtoilrz6o.png"><br><br>  En g√©n√©ral, c'est une option viable, qui, de mon point de vue, n'a aucun inconv√©nient par rapport √† l'installation d'un SGBD sur une machine virtuelle distincte. <br><br><h3>  2. Paire r√©pliqu√©e avec commutation manuelle </h3><br>  <code>StatefulSet</code> nouveau utilis√©, mais le sch√©ma g√©n√©ral ressemble √† ceci: <br><br><img src="https://habrastorage.org/webt/vq/_i/to/vq_itonyvigrh0uezqek_lwtlt4.png"><br><br>  Si l'un des n≈ìuds plante ( <code>mysql-a-0</code> ), un miracle ne se produit pas, mais nous avons une r√©plique ( <code>mysql-b-0</code> ) vers laquelle nous pouvons commuter le trafic.  Dans ce cas, m√™me avant de commuter le trafic, il est important de ne pas oublier non seulement de supprimer les requ√™tes SGBD du service <code>mysql</code> , mais √©galement de se connecter manuellement au SGBD et de s'assurer que toutes les connexions sont termin√©es (les tuer), et aussi d'aller au deuxi√®me n≈ìud du SGBD et reconfigurer la r√©plique dans la direction oppos√©e. <br><br>  Si vous utilisez actuellement la version classique avec deux serveurs (ma√Ætre + veille) sans <i>basculement</i> automatique, cette solution est l'√©quivalent dans Kubernetes.  Convient pour MySQL, PostgreSQL, Redis et autres produits. <br><br><h3>  3. Mise √† l'√©chelle de la charge de lecture </h3><br>  En fait, ce cas n'est pas avec √©tat, car nous ne parlons que de lecture.  Ici, le serveur SGBD principal est en dehors du sch√©ma consid√©r√©, et dans le cadre de Kubernetes, une "batterie de serveurs esclaves" est cr√©√©e, qui est en lecture seule.  Le m√©canisme g√©n√©ral - l'utilisation de conteneurs init pour remplir les donn√©es du SGBD sur chaque nouveau pod de cette batterie (en utilisant un vidage √† chaud ou l'habituel avec des actions suppl√©mentaires, etc. - d√©pend du SGBD utilis√©).  Pour √™tre s√ªr que chaque instance ne tra√Æne pas trop loin du ma√Ætre, vous pouvez utiliser des tests de vivacit√©. <br><br><img src="https://habrastorage.org/webt/nz/pd/uk/nzpdukumat3zbax7vnkcs5jtsvs.png"><br><br><h3>  4. Client intelligent </h3><br>  Si vous cr√©ez un <code>StatefulSet</code> de trois memcaches, Kubernetes fournit un service sp√©cial qui n'√©quilibrera pas les demandes, mais cr√©era chaque pod pour son propre domaine.  Le client pourra travailler avec eux s'il est lui-m√™me capable de partitionnement et de r√©plication. <br><br>  Vous n'avez pas besoin d'aller loin pour un exemple: voici comment le stockage de session fonctionne en PHP.  Pour chaque demande de session, des demandes sont faites simultan√©ment √† tous les serveurs, apr√®s quoi la r√©ponse la plus pertinente est s√©lectionn√©e parmi eux (de mani√®re similaire √† un enregistrement). <br><br><img src="https://habrastorage.org/webt/t8/iz/26/t8iz261adru0mbdw7cd2o5i3y8o.png"><br><br><h3>  5. Solutions natives cloud </h3><br>  Il existe de nombreuses solutions qui sont initialement ax√©es sur la d√©faillance des n≈ìuds, c'est-√†-dire  eux-m√™mes peuvent effectuer le <i>basculement</i> et la r√©cup√©ration des n≈ìuds, fournir des garanties de <i>coh√©rence</i> .  Ce n'est pas une liste compl√®te d'entre eux, mais seulement une partie d'exemples populaires: <br><br><img src="https://habrastorage.org/webt/9u/ah/qz/9uahqzayfbdsokgyod153jwfjfs.png"><br><br>  Tous sont simplement plac√©s dans <code>StatefulSet</code> , apr√®s quoi les n≈ìuds se retrouvent et forment un cluster.  Les produits eux-m√™mes diff√®rent dans la fa√ßon dont ils mettent en ≈ìuvre trois choses: <br><br><ol><li>  Comment les n≈ìuds apprennent-ils les uns des autres?  Il existe des m√©thodes telles que l'API Kubernetes, les enregistrements DNS, la configuration statique, les n≈ìuds sp√©cialis√©s (semences), la d√©couverte de services tiers ... </li><li>  Comment le client se connecte-t-il?  Gr√¢ce √† un √©quilibreur de charge qui distribue aux h√¥tes, ou le client doit conna√Ætre tous les h√¥tes, et il d√©cidera de la marche √† suivre. </li><li>  Comment s'effectue la mise √† l'√©chelle horizontale?  Pas du tout, complet ou difficile / avec restrictions. </li></ol><br>  Quelles que soient les solutions choisies √† ces probl√®mes, tous ces produits fonctionnent bien avec Kubernetes, car ils ont √©t√© cr√©√©s √† l'origine en tant que ¬´troupeau¬ª <i>(bovins)</i> . <br><br><h3>  6. Stolon PostgreSQL </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Stolon</a> vous permet en fait de transformer PostgreSQL, cr√©√© comme <i>animal</i> de <i>compagnie</i> , en <i>b√©tail</i> .  Comment y parvient-on? <br><br><img src="https://habrastorage.org/webt/g_/z4/pc/g_z4pcehfw6p985duphcgrbukzo.png"><br><br><ul><li>  Tout d'abord, nous avons besoin d'une d√©couverte de service, dans le r√¥le de laquelle peut √™tre <b>etcd</b> (d'autres options sont disponibles) - un cluster d'entre eux est plac√© dans un <code>StatefulSet</code> . </li><li>  Une autre partie de l'infrastructure est <code>StatefulSet</code> avec des instances PostgreSQL.  En plus du SGBD proprement dit, √† c√¥t√© de chaque installation se trouve √©galement un composant appel√© <b>keeper</b> , qui effectue la configuration du SGBD. </li><li>  Un autre composant, <b>sentinelle,</b> est d√©ploy√© en tant que <code>Deployment</code> et surveille la configuration du cluster.  C'est lui qui d√©cide qui sera ma√Ætre et veille, √©crit ces informations sur etcd.  Et le gardien lit les donn√©es de etcd et effectue des actions correspondant √† l'√©tat actuel avec une instance de PostgreSQL. </li><li>  Un autre composant d√©ploy√© dans le <code>Deployment</code> et face aux instances PostgreSQL, le <b>proxy,</b> est une impl√©mentation du mod√®le de <i>basculement coh√©rent</i> d√©j√† mentionn√©.  Ces composants sont connect√©s √† etcd, et si cette connexion est perdue, le proxy tue imm√©diatement les connexions sortantes, car √† partir de ce moment il ne conna√Æt pas le r√¥le de son serveur (est-ce maintenant ma√Ætre ou standby?). </li><li>  Enfin, les instances proxy font face √† l'habituel <code>LoadBalancer</code> Kubernetes. </li></ul><br><h2>  Conclusions </h2><br>  Est-il donc possible de s'installer √† Kubernetes?  Oui, bien s√ªr, c'est possible, dans certains cas ... Et si c'est appropri√©, c'est fait comme √ßa (voir le workflow Stolon) ... <br><br>  Tout le monde sait que la technologie √©volue par vagues.  Au d√©part, tout nouvel appareil peut √™tre tr√®s difficile √† utiliser, mais au fil du temps, tout change: la technologie devient disponible.  O√π allons-nous?  Oui, cela restera ainsi √† l'int√©rieur, mais nous ne saurons pas comment cela fonctionnera.  Kubernetes d√©veloppe activement des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">op√©rateurs</a> .  Jusqu'√† pr√©sent, il n'y en a pas beaucoup et ils ne sont pas si bons, mais il y a un mouvement dans cette direction. <br><br><h2>  Vid√©os et diapositives </h2><br>  Vid√©o de la performance (environ une heure): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BnegHj53pW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Pr√©sentation du rapport: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  PS Nous avons √©galement trouv√© sur le net une tr√®s (!) Courte <a href="">compression textuelle</a> de ce rapport - merci √† Nikolai Volynkin. <br><br><h2>  PPS </h2><br>  Autres reportages sur notre blog: <br><br><ul><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Surveillance et Kubernetes</a> ¬ª;  <i>(Dmitry Stolyarov; 28 mai 2018 √† RootConf)</i> ; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Meilleures pratiques CI / CD avec Kubernetes et GitLab</a> ¬ª;  <i>(Dmitry Stolyarov; 7 novembre 2017 √† HighLoad ++)</i> ; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Notre exp√©rience avec Kubernetes dans les petits projets</a> ¬ª;  <i>(Dmitry Stolyarov; 6 juin 2017 √† RootConf)</i> ; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nous collectons des images Docker pour CI / CD rapidement et facilement avec dapp</a> ¬ª <i>(Dmitry Stolyarov; 8 novembre 2016 sur HighLoad ++)</i> ; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pratiques de livraison continue avec Docker</a> ¬ª <i>(Dmitry Stolyarov; 31 mai 2016 √† RootConf)</i> . </li></ul><br>  Vous pourriez √©galement √™tre int√©ress√© par les publications suivantes: <br><br><ul><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trucs et astuces de Kubernetes: acc√©l√©rer le bootstrap des grandes bases de donn√©es</a> ¬ª; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CockroachDB DBMS Orchestration in Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr431500/">https://habr.com/ru/post/fr431500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr431488/index.html">Modulation sonore</a></li>
<li><a href="../fr431490/index.html">Externe - GUI pour Golang</a></li>
<li><a href="../fr431492/index.html">Analyse du quiz du concours React depuis le stand HeadHunter √† HolyJs 2018</a></li>
<li><a href="../fr431496/index.html">Comment la technologie aide les enseignants des classes sp√©ciales</a></li>
<li><a href="../fr431498/index.html">WebP reprendra bient√¥t le Web, mais ce ne sera pas long</a></li>
<li><a href="../fr431502/index.html">Conf√©rence pour les d√©veloppeurs iOS Kolesa Mobile 3.0. Reportage vid√©o</a></li>
<li><a href="../fr431504/index.html">Phishing - fonctionne. Chronique du vol de l'iPhone XS suivi du vol de donn√©es iCloud</a></li>
<li><a href="../fr431506/index.html">Xcode et d√©bogage avanc√© dans LLDB: Partie 1</a></li>
<li><a href="../fr431508/index.html">Gestion efficace des transactions au printemps</a></li>
<li><a href="../fr431510/index.html">Comment collecter des informations sur le contour. Acheter avec du s√©l√©nium</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
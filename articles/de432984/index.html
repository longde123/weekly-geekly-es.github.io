<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏼‍⚕️ 🚏 📏 Maschinelles Lernen mit Node.js Verwenden der Tensorflow.js-Bibliothek 👩🏻 👩🏽‍🎨 👩🏿‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits, Kollegen! 

 Vielleicht haben sich auch die Fans der Tensorflow-Bibliothek, die dieses Buch bereits in unserer Vorbestellung bemerkt...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Maschinelles Lernen mit Node.js Verwenden der Tensorflow.js-Bibliothek</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/432984/">  Hallo allerseits, Kollegen! <br><br>  Vielleicht haben sich auch die Fans der Tensorflow-Bibliothek, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses Buch bereits</a> in unserer Vorbestellung bemerkt haben, die Möglichkeiten des maschinellen und tiefen Lernens im Browser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">genau angesehen</a> , zumal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Francois Schollet</a> selbst <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> Thema <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht ignorierte</a> .  Wir laden Interessierte ein, wo beschrieben wird, wie die Bibliothek von Tensorflow.js Bilder erkennt. <br><a name="habracut"></a><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow.js</a> ist eine neue Version der beliebten Open Source-Bibliothek, die JavaScript mit umfassenden Lernfunktionen bereichert.  Entwickler können jetzt Modelle mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">übergeordneten Bibliotheks-API</a> definieren, trainieren und ausführen. <br><br>  Dank <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigter Modelle können</a> Entwickler jetzt komplexe Aufgaben wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mustererkennung</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Musikgenerierung</a> oder die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bestimmung menschlicher Positionen in</a> nur wenigen Zeilen JavaScript problemlos lösen. <br><br>  Tensorflow.js begann als Front-End-Bibliothek für die Arbeit in einem Browser, aber dieses Jahr wurde die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">experimentelle Unterstützung für</a> Node.js hinzugefügt.  Daher kann TensorFlow.js auch in JavaScript-Backend-Anwendungen verwendet werden, sodass wir nicht mehr auf Python zurückgreifen müssen. <br><br>  <i>Als ich über diese Bibliothek las, beschloss ich, sie an einer einfachen Aufgabe auszuprobieren ...</i> <br><blockquote>  Verwenden Sie TensorFlow.js zur visuellen Erkennung von Bildern auf Bildern, wenn Sie JavaScript von Node.js verwenden </blockquote>  Leider beschreiben die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentations-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Codebeispiele</a> hauptsächlich die Verwendung dieser Bibliothek im Browser. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projektdienstprogramme</a> , die das Laden und Verwenden von vorab trainierten Modellen zum Zeitpunkt des Schreibens vereinfachen sollten, unterstützten Node.js nicht.  Ich musste viel Zeit damit verbringen, Typoskript-Quellen für diese Bibliothek gut zu lesen. <br><br>  Nach ein paar Tagen des Austauschs habe ich es trotzdem getan!  Hurra! <br><br>  <i>Bevor wir mit einer detaillierten Analyse des Codes fortfahren, wollen wir uns mit anderen Implementierungen der TensorFlow-Bibliothek befassen.</i> <br><br>  <b>Tensorflow</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow</a> ist eine kostenlose Softwarebibliothek für maschinelles Lernen.  Mit TensorFlow können neuronale Netze erstellt und andere Deep-Learning-Algorithmen implementiert werden. <br><br>  Dies ist eine Bibliothek, die im November 2015 von Google veröffentlicht wurde und ursprünglich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in Python geschrieben wurde</a> .  Für das Training und die Bewertung der erstellten Modelle werden Berechnungen auf einer CPU oder GPU verwendet.  Ursprünglich wurde diese Bibliothek für die Arbeit auf Hochleistungsservern mit ressourcenintensiven GPUs erstellt. <br><br>  Dank der jüngsten Aktualisierungen konnte diese Bibliothek optimiert und in Umgebungen mit begrenzten Ressourcen verwendet werden - beispielsweise auf Mobilgeräten und Webbrowsern. <br><br>  <b>TensorFlow Lite</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensorflow Lite</a> , die Lite-Version dieser Bibliothek für mobile Geräte und eingebettete Systeme, wurde im Mai 2017 veröffentlicht.  Zusammen mit diesem wird ein neuer Satz vorgefertigter Tiefenmodelle für Aufgaben im Zusammenhang mit der Mustererkennung bereitgestellt.  Diese Sammlung heißt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MobileNet</a> .  MobileNet-Modelle wurden speziell für den effizienten Betrieb in Umgebungen mit begrenzten Ressourcen wie mobilen Geräten entwickelt. <br><br>  TensorFlow.js <br><br>  Nach Tensorflow Lite wurde TensorFlow.js im März 2018 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">angekündigt</a> .  Diese Version der Bibliothek kann in einem Browser ausgeführt werden und basiert auf einem früheren Projekt namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">deeplearn.js</a> .  WebGL bietet GPU-Zugriff auf die Bibliothek.  Entwickler verwenden die JavaScript-API, um Modelle zu trainieren, zu laden und auszuführen. <br><br>  Später wurde TensorFlow.js erweitert, um mit Node.js zu arbeiten. <code>tfjs-node</code> wird das <code>tfjs-node</code> die <code>tfjs-node</code> verwendet. <br><br>  <b>Importieren Sie vorhandene Modelle in TensorFlow.js</b> <br><br>  Mit der Bibliothek TensorFlow.js können vorgefertigte TensorFlow- und Keras-Modelle ausgeführt werden.  Bevor Sie das Modell ausführen, müssen Sie mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Tool</a> in ein neues Format konvertieren.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auf Github stehen vorab</a> trainierte und transformierte Modelle zum Klassifizieren von Bildern, Definieren von Posen und Erkennen von k-nächsten Nachbarn <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zur Verfügung</a> . <br><br>  <b>Verwenden von TensorFlow.js mit Node.js</b> <br><br>  Installieren Sie die TensorFlow-Bibliotheken <br><br>  TensorFlow.js kann über die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NPM-Registrierung</a> installiert <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . <br><br><ul><li>  <code>@tensorflow/tfjs</code> - <code>@tensorflow/tfjs</code> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow.js</a> </li><li>  <code>@tensorflow/tfjs-node</code> - Erweiterung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow.js Node.js</a> </li><li>  <code>@tensorflow/tfjs-node-gpu</code> - Erweiterung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow.js Node.js mit GPU-Computerunterstützung</a> </li></ul><br><pre> <code class="plaintext hljs">npm install @tensorflow/tfjs @tensorflow/tfjs-node // ... npm install @tensorflow/tfjs @tensorflow/tfjs-node-gpu</code> </pre> <br>  Beide Erweiterungen für Node.js verwenden native Abhängigkeiten, die bei Bedarf kompiliert werden. <br><br>  <b>Laden Sie die TensorFlow-Bibliotheken herunter</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die JavaScript-API</a> für Tensorflow wird aus der Kernbibliothek bereitgestellt.  In Erweiterungsmodulen, die Node.js unterstützen, werden keine Erweiterungs-APIs bereitgestellt. <br><br><pre> <code class="javascript hljs"> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> tf = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'@tensorflow/tfjs'</span></span>) <span class="hljs-comment"><span class="hljs-comment">//   ( CPU) require('@tensorflow/tfjs-node') //    ( GPU) require('@tensorflow/tfjs-node-gpu')</span></span></code> </pre> <br>  <b>Laden Sie TensorFlow Models herunter</b> <br><br>  TensorFlow.js bietet eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NPM-Bibliothek</a> ( <code>tfjs-models</code> ), die das Laden von vorab trainierten und transformierten Modellen zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Klassifizieren von Bildern</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Definieren von Posen</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erkennen von k-nächsten Nachbarn</a> vereinfacht. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Bildklassifizierungsmodell von MobileNet</a> ist ein tiefes neuronales Netzwerk, das darauf trainiert ist, zwischen <a href="">1000 verschiedenen Bildklassen</a> zu unterscheiden. <br><br>  In der README-Datei für das Projekt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">als Beispiel</a> wird der folgende Code zum Laden des Modells verwendet. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mobilenet <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'@tensorflow-models/mobilenet'</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   const model = await mobilenet.load();</span></span></code> </pre> <br>  Eines der ersten Probleme, auf das ich zufällig gestoßen bin, ist, dass dieser Code nicht mit Node.js funktioniert. <br><br><pre> <code class="plaintext hljs">Error: browserHTTPRequest is not supported outside the web browser.</code> </pre> <br>  Nach Prüfung des <a href="">Quellcodes sehen</a> wir, dass die Mobilet-Bibliothek ein Wrapper für die <code>tf.Model</code> Klasse ist.  Beim Aufruf lädt die <code>load()</code> -Methode automatisch die erforderlichen Modelldateien herunter, die sich an einer externen HTTP-Adresse befinden, und instanziiert das TensorFlow-Modell. <br><br>  Die Erweiterung Node.js unterstützte zum Zeitpunkt des Schreibens noch keine HTTP-Anforderungen für das Abrufen dynamischer Modelle.  Alles, was blieb, war das manuelle Laden der Modelle in das Dateisystem. <br><br>  <i>Nachdem ich jedoch den Quellcode der Bibliothek gelesen hatte, fand ich eine Problemumgehung ...</i> <br><br>  <b>Modelle aus dem Dateisystem herunterladen</b> <br><br>  Wenn die MobileNet-Klasse manuell erstellt wird, können Sie die Lademethode des Moduls nicht aufrufen, sondern den automatisch generierten Variablenpfad mit der HTTP-Adresse des Modells neu schreiben und diese Adresse durch den lokalen Pfad im Dateisystem ersetzen.  Wenn danach die <code>load</code> in der Klasseninstanz aufgerufen wird, wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Loader-</a> Klasse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">des Dateisystems ausgelöst</a> .  In diesem Fall lehnen wir die Verwendung eines browserbasierten HTTP-Downloaders ab. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> path = <span class="hljs-string"><span class="hljs-string">"mobilenet/model.json"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mn = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> mobilenet.MobileNet(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); mn.path = <span class="hljs-string"><span class="hljs-string">`file://</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${path}</span></span></span><span class="hljs-string">`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> mn.load()</code> </pre> <br>  Cool, alles funktioniert! <br><br>  Aber woher kommen die Modelldateien? <br><br>  <b>MobileNet-Modelle</b> <br><br>  Modelle für TensorFlow.js bestehen aus zwei Dateitypen: einer im JSON-Format gespeicherten Modellkonfigurationsdatei und im Binärformat gespeicherten Modellgewichten.  Modellgewichte werden häufig in viele Teile fragmentiert, um das Browser-Caching zu optimieren. <br><br>  Nachdem wir den <a href="">automatischen Download-Code</a> für MobileNet-Modelle berücksichtigt haben, sehen wir, dass die Modelle, ihre Konfigurationen und Gewichtsfragmente unter der folgenden Adresse aus dem öffentlichen Container extrahiert werden. <br><br><pre> <code class="plaintext hljs">https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v${version}_${alpha}_${size}/</code> </pre> <br>  Die Vorlagenparameter in der URL beschreiben die <a href="">hier</a> aufgeführten Modellversionen.  Die resultierende Klassifizierungsgenauigkeit wird ebenfalls auf derselben Seite angezeigt. <br><br>  Der Quellcode gibt an, dass nur Modelle von MobileNet v1 mit der <code>tensorflow-models/mobilenet</code> heruntergeladen werden können. <br><br>  Der HTTP-Extraktionscode lädt die Datei <code>model.json</code> vom Speicherort herunter und wählt dann rekursiv alle Fragmente von Modellen mit referenzierten Gewichten aus.  Dies sind Dateien im Format <code>groupX-shard1of1</code> . <br><br>  <b>Manuelles Herunterladen von Modellen</b> <br><br>  Wenn Sie alle Modelldateien im Dateisystem speichern möchten, können Sie Folgendes tun: Extrahieren Sie die Konfigurationsdatei des Modells, analysieren Sie die Syntax aller gewichteten Dateien, auf die in der Konfigurationsdatei verwiesen wird, und laden Sie dann jede gewichtete Datei manuell herunter. <br>  <b>Ich wollte das MobileNet V1-Modul mit einem Alpha-Wert von 1,0 und einem Bild von 224 Pixel verwenden</b> .  Daher erhalte ich die <a href="">folgende URL</a> für die Modellkonfigurationsdatei. <br><br><pre> <code class="plaintext hljs">https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/model.json</code> </pre> <br>  Sobald diese Datei lokal heruntergeladen wurde, können Sie mit dem <code>jq</code> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tool</a> die Namen aller gewichteten Dateien analysieren. <br><br><pre> <code class="javascript hljs">$ cat model.json | jq -r <span class="hljs-string"><span class="hljs-string">".weightsManifest[].paths[0]"</span></span> group1-shard1of1 group2-shard1of1 group3-shard1of1 ...</code> </pre> <br>  Mit dem <code>sed</code> Tool können Sie dem Namen jedes HTTP-Elements eine URL voranstellen, um eine URL für jede Gewichtungsdatei zu generieren. <br><br><pre> <code class="javascript hljs">$ cat model.json | jq -r <span class="hljs-string"><span class="hljs-string">".weightsManifest[].paths[0]"</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/^/https:\/\/storage.googleapis.com\/tfjs-models\/tfjs\/mobilenet_v1_1.0_224\//'</span></span> https:<span class="hljs-comment"><span class="hljs-comment">//storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/group1-shard1of1 https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/group2-shard1of1 https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/group3-shard1of1 ...</span></span></code> </pre><br>  Mit den Befehlen <code>parallel</code> und <code>curl</code> können Sie dann alle diese Dateien in mein lokales Verzeichnis herunterladen. <br><br><pre> <code class="plaintext hljs">cat model.json | jq -r ".weightsManifest[].paths[0]" | sed 's/^/https:\/\/storage.googleapis.com\/tfjs-models\/tfjs\/mobilenet_v1_1.0_224\//' | parallel curl -O</code> </pre> <br>  <b>Bildklassifizierung</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dieser</a> mit TensorFlow.js bereitgestellte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beispielcode</a> zeigt, wie das Ergebnis der Bildklassifizierung zurückgegeben wird. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> img = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'img'</span></span>); <span class="hljs-comment"><span class="hljs-comment">//   const predictions = await model.classify(img);</span></span></code> </pre> <br>  Dies funktioniert in Node.js aufgrund mangelnder DOM-Unterstützung nicht. <br><br>  <a href="">Die</a> <code>classify</code> akzeptiert verschiedene DOM-Elemente ( <code>canvas</code> , <code>video</code> , <code>image</code> ) und extrahiert und konvertiert automatisch die "Bild" <code>tf.Tensor3D</code> aus diesen Elementen in die Klasse <code>tf.Tensor3D</code> , die als Modelleingabe verwendet wird.  Alternativ <code>tf.Tensor3D</code> direkt übertragen werden. <br><br>  <b>Ich habe beschlossen, nicht zu versuchen, ein externes Paket zu verwenden, um ein DOM-Element manuell zu simulieren, habe jedoch festgestellt, dass <code>tf.Tensor3D</code> einfacher manuell zusammenzusetzen ist</b> . <br><br>  <b>Wir erzeugen Tensor3D aus dem Bild</b> <br><br>  Beim Lesen des <a href="">Quellcodes der</a> Methode zum Konvertieren von DOM-Elementen in Tensor3D-Klassen stellen wir fest, dass die folgenden Eingabeparameter zum Generieren der Tensor3D-Klasse verwendet werden. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> values = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Int32Array</span></span>(image.height * image.width * numChannels); <span class="hljs-comment"><span class="hljs-comment">//     ,    const outShape = [image.height, image.width, numChannels]; const input = tf.tensor3d(values, outShape, 'int32');</span></span></code> </pre> <br>  <code>pixels</code> ist ein zweidimensionales Array vom Typ <code>(Int32Array)</code> das eine sequentielle Liste von <code>(Int32Array)</code> für jedes Pixel enthält.  <code>numChannels</code> ist die Anzahl der <code>numChannels</code> pro Pixel. <br><br>  <b>Eingabewerte für JPEG erstellen</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die</a> <code>jpeg-js</code> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bibliothek</a> ist ein JPEG-Encoder / Decoder für Node.js, der in reinem JavaScript geschrieben ist.  Mit dieser Bibliothek können Sie RGB-Werte für jedes Pixel extrahieren. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> pixels = jpeg.decode(buffer, <span class="hljs-literal"><span class="hljs-literal">true</span></span>);</code> </pre> <br>  Als Ergebnis erhalten wir ein Uint8Array mit vier Kanalwerten ( <code>RGBA</code> ) für jedes Pixel ( <code>width * height</code> ).  Das MobileNet-Modell verwendet nur drei Farbkanäle ( <code>RGB</code> ) zur Klassifizierung, der Alphakanal wird ignoriert.  Dieser Code konvertiert ein Vier-Kanal-Array in eine echte Drei-Kanal-Version. <br><br><pre> <code class="javascript hljs"> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> numChannels = <span class="hljs-number"><span class="hljs-number">3</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> numPixels = image.width * image.height; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> values = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Int32Array</span></span>(numPixels * numChannels); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numPixels; i++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> channel = <span class="hljs-number"><span class="hljs-number">0</span></span>; channel &lt; numChannels; ++channel) { values[i * numChannels + channel] = pixels[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + channel]; } }</code> </pre> <br>  <b>Eingabeanforderungen für MobileNet-Modelle</b> <br><br>  Das hier verwendete <a href="">MobileNet-Modell</a> klassifiziert Bilder mit einer Höhe von 224 Pixel und einer Breite.  Eingangstensoren müssen Gleitkommawerte im Bereich von -1 bis 1 für jeden der drei Kanalwerte jedes Pixels enthalten. <br><br>  Eingabewerte für Bilder mit einer anderen Dimension müssen vor der Klassifizierung in die richtige Größe konvertiert werden.  Außerdem liegen die vom JPEG-Decoder erhaltenen Pixelwerte im Bereich von 0 bis 255 und nicht von -1 bis 1. Diese Werte müssen vor der Klassifizierung ebenfalls konvertiert werden. <br><br>  TensorFlow.js verfügt über Bibliotheksmethoden, um diesen Prozess zu vereinfachen. Noch besser ist jedoch, dass es eine <b>spezielle <code>tfjs-models/mobilenet</code> , <a href="">die dieses Problem automatisch löst</a> !</b> <br><br>  Der Entwickler kann Eingabe-Tensor3Ds vom Typ <code>int32</code> sowie verschiedene Dimensionen an die <code>classify</code> , die die Eingabewerte vor der Klassifizierung in das richtige Format übersetzt.  Das heißt, wir haben hier nichts zu tun.  Großartig! <br><br>  <b>Vorhersagen erhalten</b> <br><br>  Die MobileNet-Modelle von Tensorflow lernen, Objekte aus den <a href="">1000 wichtigsten Klassen</a> aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ImageNet-</a> Datensatz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu erkennen</a> .  Geben Sie am Ausgang des Modells Wahrscheinlichkeitswerte an, die die Chancen charakterisieren, diese Objekte im klassifizierten Bild zu finden. <br><br>  <i>Eine vollständige Liste der trainierten Klassen für das verwendete Modell befindet sich in <a href="">dieser Datei</a></i> . <br><br>  Die <code>tfjs-models/mobilenet</code> bietet die <code>classify</code> in der <code>MobileNet</code> Klasse, die das Top-X der wahrscheinlichsten Klassen basierend auf den in der Abbildung gezeigten <code>tfjs-models/mobilenet</code> zurückgibt. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> predictions = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> mn_model.classify(input, <span class="hljs-number"><span class="hljs-number">10</span></span>);</code> </pre> <br>  <code>predictions</code> ist ein Array von X-Klassen und Wahrscheinlichkeiten im folgenden Format. <br><br><pre> <code class="javascript hljs"> { <span class="hljs-attr"><span class="hljs-attr">className</span></span>: <span class="hljs-string"><span class="hljs-string">'panda'</span></span>, <span class="hljs-attr"><span class="hljs-attr">probability</span></span>: <span class="hljs-number"><span class="hljs-number">0.9993536472320557</span></span> }</code> </pre> <br>  <b>Beispiel</b> <br><br>  Wir haben also herausgefunden, wie die TensorFlow.js-Bibliothek und die MobileNet-Modelle in Node.js verwendet werden, und überlegen nun, wie dieses Skript das als Befehlszeilenargument angegebene Bild klassifiziert. <br><br>  <i>Quellcode</i> <br><br>  Speichern Sie diese Skriptdatei und den Paketdeskriptor in lokalen Dateien. <br><br><pre> <code class="javascript hljs">{ <span class="hljs-string"><span class="hljs-string">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"tf-js"</span></span>, <span class="hljs-string"><span class="hljs-string">"version"</span></span>: <span class="hljs-string"><span class="hljs-string">"1.0.0"</span></span>, <span class="hljs-string"><span class="hljs-string">"main"</span></span>: <span class="hljs-string"><span class="hljs-string">"script.js"</span></span>, <span class="hljs-string"><span class="hljs-string">"license"</span></span>: <span class="hljs-string"><span class="hljs-string">"MIT"</span></span>, <span class="hljs-string"><span class="hljs-string">"dependencies"</span></span>: { <span class="hljs-string"><span class="hljs-string">"@tensorflow-models/mobilenet"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.2.2"</span></span>, <span class="hljs-string"><span class="hljs-string">"@tensorflow/tfjs"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.12.3"</span></span>, <span class="hljs-string"><span class="hljs-string">"@tensorflow/tfjs-node"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.1.9"</span></span>, <span class="hljs-string"><span class="hljs-string">"jpeg-js"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.3.4"</span></span> } }</code> </pre> <br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> tf = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'@tensorflow/tfjs'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mobilenet = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'@tensorflow-models/mobilenet'</span></span>); <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'@tensorflow/tfjs-node'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> fs = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> jpeg = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'jpeg-js'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> NUMBER_OF_CHANNELS = <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> readImage = <span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">path</span></span></span><span class="hljs-function"> =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> buf = fs.readFileSync(path) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> pixels = jpeg.decode(buf, <span class="hljs-literal"><span class="hljs-literal">true</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pixels } <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> imageByteArray = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">image, numChannels</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> pixels = image.data <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> numPixels = image.width * image.height; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> values = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Int32Array</span></span>(numPixels * numChannels); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numPixels; i++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> channel = <span class="hljs-number"><span class="hljs-number">0</span></span>; channel &lt; numChannels; ++channel) { values[i * numChannels + channel] = pixels[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + channel]; } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> values } <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> imageToInput = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">image, numChannels</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> values = imageByteArray(image, numChannels) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> outShape = [image.height, image.width, numChannels]; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> input = tf.tensor3d(values, outShape, <span class="hljs-string"><span class="hljs-string">'int32'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> input } <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> loadModel = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> path =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mn = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> mobilenet.MobileNet(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); mn.path = <span class="hljs-string"><span class="hljs-string">`file://</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${path}</span></span></span><span class="hljs-string">`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> mn.load() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mn } <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> classify = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (model, path) =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> image = readImage(path) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> input = imageToInput(image, NUMBER_OF_CHANNELS) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mn_model = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> loadModel(model) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> predictions = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> mn_model.classify(input) <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'classification results:'</span></span>, predictions) } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (process.argv.length !== <span class="hljs-number"><span class="hljs-number">4</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Error</span></span>(<span class="hljs-string"><span class="hljs-string">'incorrect arguments: node script.js &lt;MODEL&gt; &lt;IMAGE_FILE&gt;'</span></span>) classify(process.argv[<span class="hljs-number"><span class="hljs-number">2</span></span>], process.argv[<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br>  <b>Testen</b> <br><br>  Laden Sie die Modelldateien gemäß den obigen Anweisungen in das mobileet-Verzeichnis herunter. <br>  Festlegen von Projektabhängigkeiten mithilfe von NPM <br><br> <code>npm install</code> <br> <br>  Laden Sie die JPEG-Beispieldatei zur Klassifizierung herunter <br><br> <code>wget http://bit.ly/2JYSal9 -O panda.jpg</code> <br> <br><img src="https://habrastorage.org/webt/vt/sm/-2/vtsm-2o5y-t3vhqx5-qaomhxnfw.jpeg"><br><br>  Führen Sie das Skript aus, dessen Argumente die Modelldatei und das Eingabebild sind. <br><br> <code>node script.js mobilenet/model.json panda.jpg</code> <br> <br>  Wenn alles richtig funktioniert hat, sollte die folgende Ausgabe in der Konsole angezeigt werden. <br><br><pre> <code class="javascript hljs"> classification results: [ { <span class="hljs-attr"><span class="hljs-attr">className</span></span>: <span class="hljs-string"><span class="hljs-string">'giant panda, panda, panda bear, coon bear'</span></span>, <span class="hljs-attr"><span class="hljs-attr">probability</span></span>: <span class="hljs-number"><span class="hljs-number">0.9993536472320557</span></span> } ]</code> </pre> <br>  Das Bild ist korrekt als Panda mit einer Wahrscheinlichkeit von 99,93% klassifiziert! <br><br>  <b>Fazit</b> <br><br>  Die TensorFlow.js-Bibliothek eröffnet JavaScript-Entwicklern umfassende Lernmöglichkeiten.  Durch die Verwendung vorgefertigter Modelle mit der Bibliothek TensorFlow.js können Sie auf einfache Weise neue Funktionen in JavaScript-Anwendungen einbauen, um komplexe Probleme des maschinellen Lernens mit minimalem Aufwand und präzisem Code zu lösen. <br><br>  Die TensorFlow.js-Bibliothek wurde ausschließlich für die Arbeit in einem Browser erstellt. Jetzt interagiert sie mit Node.js, obwohl nicht alle Tools und Dienstprogramme diese neue Laufzeit unterstützen.  Nachdem ich einige Tage an der Bibliothek herumgebastelt hatte, lernte ich, sie mit MobileNet-Modellen zur visuellen Erkennung von Bildern aus einer lokalen Datei zu verwenden. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de432984/">https://habr.com/ru/post/de432984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de432972/index.html">Quelle: "Conways Gesetz"</a></li>
<li><a href="../de432976/index.html">Anonymer Weihnachtsmann 2018-2019: Post mit Neujahrsgeschenken</a></li>
<li><a href="../de432978/index.html">John Romero: DOOM Reflexion</a></li>
<li><a href="../de432980/index.html">VMware NSX für die Kleinsten. Teil 1</a></li>
<li><a href="../de432982/index.html">Die kürzeste Einführung in die Compilererstellung</a></li>
<li><a href="../de432986/index.html">C vs Go-Schleifen und einfache Mathematik</a></li>
<li><a href="../de432988/index.html">Achter Webmaster. Lebe auf Habré</a></li>
<li><a href="../de432990/index.html">Edison Sprachaktivierte Holzlampe. Ausgabepreis 5 USD</a></li>
<li><a href="../de432992/index.html">Er setzte seine Kopfhörer auf und starb: Wir haben es mit dem seltsamen Tod eines Schülers in Rimbau zu tun</a></li>
<li><a href="../de432994/index.html">Vivaldi 2.2 - Quantität in Qualität umwandeln</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
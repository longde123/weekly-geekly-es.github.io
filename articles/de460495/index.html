<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏼‍✈️ 🏷️ 🐙 Container-to-Pipeline: CRI-O ist jetzt die Standardeinstellung in OpenShift Container Platform 4 🐶 👩🏾‍🤝‍👨🏻 👨‍👧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mit der Red Hat OpenShift Container Platform 4-Plattform können Sie die Erstellung von Hosts für die Bereitstellung von Containern streamen, einschlie...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Container-to-Pipeline: CRI-O ist jetzt die Standardeinstellung in OpenShift Container Platform 4</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redhatrussia/blog/460495/"> Mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Red Hat OpenShift Container Platform 4-Plattform</a> können Sie die Erstellung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hosts für die Bereitstellung von Containern</a> streamen, einschließlich in der Infrastruktur von Cloud-Dienstanbietern, auf Virtualisierungsplattformen oder in Bare-Metal-Systemen.  Um eine Cloud-Plattform im vollen Sinne zu schaffen, mussten wir alle verwendeten Elemente genau kontrollieren und damit die Zuverlässigkeit eines komplexen Automatisierungsprozesses erhöhen. <br><br><img src="https://habrastorage.org/webt/h5/hn/x9/h5hnx9ulnrjawbfhd2dncjqmxvm.png" width="100%"><br><br>  Die naheliegende Lösung bestand darin, Red Hat Enterprise Linux CoreOS (eine Variante von Red Hat Enterprise Linux) und CRI-O als Standard zu verwenden. <br><a name="habracut"></a><br>  Da das Thema Navigation sehr erfolgreich ist, um Analogien zur Erklärung der Funktionsweise von Kubernetes und Containern zu finden, versuchen wir, am Beispiel der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erfindung</a> von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Brunel für die Herstellung von Rigging-Blöcken</a> über die Geschäftsprobleme zu sprechen, die CoreOS und CRI-O lösen.  Im Jahr 1803 wurde Mark Brunel beauftragt, 100.000 Takelageblöcke für die Bedürfnisse der wachsenden britischen Marine herzustellen.  Ein Hebeblock ist eine Art Rig, mit dem Seile an Segeln befestigt werden.  Bis zum Beginn des 19. Jahrhunderts wurden diese Blöcke von Hand hergestellt, aber Brunel konnte die Produktion automatisieren und begann, standardisierte Blöcke mit Maschinen herzustellen.  Durch die Automatisierung dieses Prozesses waren alle Blöcke nahezu gleich, konnten im Falle eines Ausfalls leicht ausgetauscht und in großen Mengen hergestellt werden. <br><br>  Stellen Sie sich nun vor, Brunel müsste diese Arbeit für 20 verschiedene Schiffsmodelle (Kubernetes-Versionen) und für fünf verschiedene Planeten mit völlig unterschiedlichen Meeresströmungen und -winden (Cloud-Anbieter) ausführen.  Darüber hinaus war es erforderlich, dass sich alle Schiffe (OpenShift-Cluster) unabhängig von den navigierten Planeten aus Sicht der Kapitäne (Betreiber, die den Betrieb der Cluster steuern) identisch verhalten.  In Fortsetzung der Marine-Analogie ist es Schiffskapitänen absolut egal, welche Rigging-Blöcke (CRI-O) auf ihren Schiffen verwendet werden - die Hauptsache für sie ist, dass diese Blöcke stark und zuverlässig sind. <br><br>  OpenShift 4 als Cloud-Plattform steht vor einer sehr ähnlichen geschäftlichen Herausforderung.  Neue Knoten müssen zum Zeitpunkt der Erstellung des Clusters, im Falle eines Fehlers in einem der Knoten oder bei der Skalierung des Clusters erstellt werden.  Beim Erstellen und Initialisieren eines neuen Knotens müssen kritische Hostkomponenten, einschließlich CRI-O, entsprechend konfiguriert werden.  Wie bei jeder anderen Produktion müssen zu Beginn „Rohstoffe“ geliefert werden.  Bei Schiffen fungieren Metall und Holz als Rohstoffe.  Wenn Sie jedoch einen Host für die Bereitstellung von Containern in einem OpenShift 4-Cluster erstellen, müssen an der Eingabe Konfigurationsdateien und API-Server bereitgestellt werden.  Danach bietet OpenShift über den gesamten Lebenszyklus den erforderlichen Automatisierungsgrad, bietet den Endbenutzern den erforderlichen Produkt-Support und zahlt sich somit für Investitionen in die Plattform aus. <br><br>  OpenShift 4 wurde so entwickelt, dass alle wichtigen Anbieter von Cloud Computing, Virtualisierungsplattformen und sogar Bare-Metal-Systemen das System während des gesamten Lebenszyklus der Plattform (für Version 4.X) bequem aktualisieren können.  Dazu müssen Knoten auf Basis austauschbarer Elemente angelegt werden.  Wenn ein Cluster eine neue Version von Kubernetes benötigt, erhält er auch die entsprechende CRI-O-Version unter CoreOS.  Da die CRI-O-Version direkt an Kubernetes gebunden ist, vereinfacht dies alle Permutationen für Tests, Fehlerbehebung oder Support erheblich.  Darüber hinaus reduziert dieser Ansatz die Kosten für Endbenutzer und Red Hat. <br><br>  Dies ist ein grundlegend neuer Blick auf Kubernetes-Cluster, der die Grundlage für die Planung neuer äußerst nützlicher und attraktiver Funktionen bildet.  CRI-O (Open Container-Projekt Container Runtime Interface - Open Container Initiative, abgekürzt CRI-OCI) war die erfolgreichste Wahl für die Massenerstellung von Knoten, die für die Arbeit mit OpenShift erforderlich ist.  CRI-O wird die zuvor verwendete Docker-Engine ersetzen und OpenShift-Benutzern eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wirtschaftliche, stabile, einfache und langweilige</a> - ja, Sie haben es richtig gehört - langweilige Container-Engine bieten, die speziell für die Arbeit mit Kubernetes entwickelt wurde. <br><br><h3>  Die Welt der offenen Container </h3><br>  Die Welt bewegt sich seit langem in Richtung offener Container.  Ob bei Kubernetes oder auf niedrigeren Ebenen, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Entwicklung von Containerstandards</a> führt zu einem Ökosystem der Innovation auf allen Ebenen. <br><br>  Alles begann mit der Gründung der Open Containers Initiative <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im Juni 2015</a> .  In diesem frühen Arbeitsstadium wurden Spezifikationen für das Container- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Image (Image)</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laufzeit erstellt</a> .  Dadurch konnte sichergestellt werden, dass die Tools einen einzigen Standard für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Container-Images</a> und ein einziges Format für die Arbeit mit ihnen verwenden können.  Später wurden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verteilungsspezifikationen</a> hinzugefügt, mit denen Benutzer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Containerbilder</a> problemlos austauschen konnten. <br><br>  Die Kubernetes-Community entwickelte daraufhin einen einzigen steckbaren Schnittstellenstandard namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Container Runtime Interface (CRI)</a> .  Dank dessen konnten Kubernetes-Benutzer neben Docker verschiedene Engines für die Arbeit mit Containern verbinden. <br><br>  Die Ingenieure von Red Hat und Google sahen eine Marktnachfrage nach einer Container-Engine, die Anfragen von Kubelet mithilfe des CRI-Protokolls annehmen konnte, und führten Container ein, die mit den oben genannten OCI-Spezifikationen kompatibel waren.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Es gab also eine OCID</a> .  Aber entschuldigen Sie, weil wir gesagt haben, dass dieses Material CRI-O gewidmet sein wird?  Tatsächlich wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> Projekt erst mit der Veröffentlichung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Version 1.0</a> in CRI-O umbenannt. <br><br>  <b><i>Abb.</i></b>  <b><i>1.</i></b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7-/-n/qb/7--nqbszwtnoy38f-tnbuzdmucm.png"></div><br><br><h3>  Innovation mit CRI-O und CoreOS </h3><br>  Mit dem Start der OpenShift 4-Plattform wurde die in der Standardplattform verwendete <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Container-Engine</a> geändert und Docker durch CRI-O ersetzt, das eine wirtschaftliche, stabile, einfache und langweilige Container-Startumgebung bietet, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sich</a> parallel zu Kubernetes entwickelt.  Dies vereinfacht die Clusterunterstützung und -konfiguration erheblich.  Das Konfigurieren und Verwalten der Container-Engine und des Hosts wird in OpenShift 4 automatisiert. <br><br>  Hör auf, wie ist es? <br><br>  Mit dem Aufkommen von OpenShift 4 ist es jetzt nicht mehr erforderlich, eine Verbindung zu einzelnen Hosts herzustellen und eine Container-Engine zu installieren, Speicher zu konfigurieren, Server für die Suche zu konfigurieren oder ein Netzwerk zu konfigurieren.  Die OpenShift 4-Plattform wurde komplett neu gestaltet, um das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Operator Framework</a> nicht nur in Bezug auf Endbenutzeranwendungen, sondern auch in Bezug auf grundlegende Vorgänge auf Plattformebene wie das Bereitstellen von Images, das Konfigurieren des Systems oder das Installieren von Updates zu verwenden. <br><br>  Kubernetes hat es Benutzern immer ermöglicht, Anwendungen zu verwalten, indem der gewünschte Status ermittelt und mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Controllern</a> sichergestellt wurde, dass der tatsächliche Status dem angegebenen Status so nahe wie möglich kommt.  Dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ansatz unter Verwendung eines bestimmten Zustands und eines tatsächlichen Zustands</a> eröffnet sowohl aus Sicht der Entwicklung als auch aus Sicht der Operationen große Chancen.  Entwickler können den erforderlichen Status ermitteln, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ihn</a> in Form einer YAML- oder JSON-Datei an den Bediener übertragen und anschließend die erforderliche Anwendungsinstanz in der Betriebsumgebung erstellen, während der Betriebsstatus dieser Instanz vollständig dem angegebenen entspricht. <br><br>  OpenShift 4 verwendet Operatoren in der Plattform und bringt dieses neue Paradigma (unter Verwendung des Konzepts von Set und Ist-Status) in die Verwaltung von RHEL CoreOS und CRI-O ein.  Die Aufgaben der Konfiguration und Versionierung des Betriebssystems und der Container-Engine werden mithilfe des sogenannten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Machine Config Operator (MCO)</a> automatisiert.  MCO vereinfacht die Arbeit des Clusteradministrators erheblich und automatisiert im Wesentlichen die letzten Installationsphasen sowie die nachfolgenden Vorgänge nach der Installation (Vorgänge am zweiten Tag).  All dies macht OpenShift 4 zu einer echten Cloud-Plattform.  Wir werden etwas später darauf eingehen. <br><br><h3>  Containerstart </h3><br>  Benutzer hatten die Möglichkeit, die CRI-O-Engine in der OpenShift-Plattform ab Version 3.7 im Status Tech Preview und ab Version 3.9 im Status Allgemein verfügbar (derzeit unterstützt) zu verwenden.  Darüber hinaus nutzt Red Hat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CRI-O</a> seit Version 3.10 in großem Umfang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, um Produktions-Workloads</a> in OpenShift Online <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu starten</a> .  All dies ermöglichte es dem Team, das an CRI-O arbeitete, umfangreiche Erfahrungen beim Massenstart von Containern in großen Kubernetes-Clustern zu sammeln.  Um ein grundlegendes Verständnis der Verwendung von CRI-O durch Kubernetes zu erhalten, sehen wir uns die folgende Abbildung an, die die Funktionsweise der Architektur zeigt. <br><br>  <b><i>Abb.</i></b>  <b><i>2. Funktionsweise von Containern im Kubernetes-Cluster</i></b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1a/zr/kz/1azrkzz-ey6euphpkgqpazncwci.png"></div><br><br>  CRI-O vereinfacht die Erstellung neuer Container-Hosts, indem die gesamte oberste Ebene beim Initialisieren neuer Knoten und beim Freigeben neuer Versionen der OpenShift-Plattform synchronisiert wird.  Ein vollständiges Plattform-Audit ermöglicht Transaktionsaktualisierungen / Rollbacks und verhindert außerdem Deadlocks in Abhängigkeiten zwischen dem Container-Tail-Kernel, der Container-Engine, Kubelets und dem Kubernetes-Master.  Mit der zentralen Verwaltung aller Plattformkomponenten sowie der Versionskontrolle und -verwaltung können Sie jederzeit einen eindeutigen Pfad von Status A zu Status B verfolgen. Dies vereinfacht den Aktualisierungsprozess, verbessert die Sicherheit, verbessert die Leistungsberichte und senkt die Kosten für die Aktualisierung und Installation neuer Versionen. <br><br><h3>  Demonstration der Kraft austauschbarer Elemente </h3><br>  Wie bereits erwähnt, bietet die Verwendung von Machine Config Operator zum Verwalten des Container-Hosts und der Container-Engine in OpenShift 4 einen neuen Automatisierungsgrad, der auf der Kubernetes-Plattform zuvor nicht möglich war.  Um die neuen Funktionen zu demonstrieren, zeigen wir, wie Sie Änderungen an der Datei crio.conf vornehmen können.  Versuchen Sie, sich auf die Ergebnisse zu konzentrieren, um die Terminologie nicht zu verwechseln. <br><br>  Lassen Sie uns zunächst eine sogenannte Container-Laufzeitkonfiguration erstellen - die Container Runtime Config.  Betrachten Sie dies als eine Kubernetes-Ressource, die die Konfiguration für CRI-O darstellt.  In Wirklichkeit handelt es sich hierbei um eine spezielle Version von MachineConfig, bei der es sich um eine Konfiguration handelt, die auf einem RHEL CoreOS-Computer in einem OpenShift-Cluster bereitgestellt wird. <br><br>  Diese benutzerdefinierte Ressource namens ContainerRuntimeConfig wurde erfunden, um Clusteradministratoren die Konfiguration von CRI-O zu erleichtern.  Dies ist ein leistungsstarkes Tool, das abhängig von den Einstellungen von MachineConfigPool nur auf bestimmte Knoten angewendet werden kann.  Betrachten Sie dies als eine Gruppe von Maschinen, die denselben Zweck erfüllen. <br><br>  Beachten Sie die letzten beiden Zeilen, die wir in der Datei /etc/crio/crio.conf ändern werden.  Diese beiden Zeilen sind den Zeilen in der Datei crio.conf sehr ähnlich. Dies sind: <br><br><pre><code class="plaintext hljs">vi ContainerRuntimeConfig.yaml</code> </pre> <br>  Fazit: <br><br><pre> <code class="plaintext hljs">apiVersion: machineconfiguration.openshift.io/v1 kind: ContainerRuntimeConfig metadata: name: set-log-and-pid spec: machineConfigPoolSelector: matchLabels: debug-crio: config-log-and-pid containerRuntimeConfig: pidsLimit: 2048 logLevel: debug</code> </pre><br>  Senden Sie diese Datei nun an den Kubernetes-Cluster und überprüfen Sie, ob sie tatsächlich erstellt wurde.  Bitte beachten Sie, dass der Vorgang wie bei jeder anderen Kubernetes-Ressource ausgeführt wird: <br><br><pre> <code class="plaintext hljs">oc create -f ContainerRuntimeConfig.yaml oc get ContainerRuntimeConfig</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">NAME AGE set-log-and-pid 22h</code> </pre><br>  Nachdem wir ContainerRuntimeConfig erstellt haben, müssen wir einen der MachineConfigPools ändern, damit Kubernetes versteht, dass wir diese Konfiguration auf eine bestimmte Gruppe von Computern im Cluster anwenden möchten.  In diesem Fall ändern wir MachineConfigPool für die Masterknoten: <br><br><pre> <code class="plaintext hljs">oc edit MachineConfigPool/master</code> </pre><br>  Schlussfolgerung (aus Gründen der Klarheit bleibt der Hauptpunkt übrig): <br><br><pre> <code class="plaintext hljs">... metadata: creationTimestamp: 2019-04-10T23:42:28Z generation: 1 labels: debug-crio: config-log-and-pid operator.machineconfiguration.openshift.io/required-for-upgrade: "" ...</code> </pre><br>  Zu diesem Zeitpunkt beginnt MCO mit der Erstellung einer neuen crio.conf-Datei für den Cluster.  In diesem Fall kann eine vollständig fertige Konfigurationsdatei mithilfe der Kubernetes-API angezeigt werden.  Denken Sie daran, ContainerRuntimeConfig ist nur eine spezielle Version von MachineConfig, sodass wir das Ergebnis anhand der Zeilen in MachineConfigs sehen können: <br><br><pre> <code class="plaintext hljs">oc get MachineConfigs | grep rendered</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">rendered-master-c923f24f01a0e38c77a05acfd631910b 4.0.22-201904011459-dirty 2.2.0 16h rendered-master-f722b027a98ac5b8e0b41d71e992f626 4.0.22-201904011459-dirty 2.2.0 4m rendered-worker-9777325797fe7e74c3f2dd11d359bc62 4.0.22-201904011459-dirty 2.2.0 16h</code> </pre><br>  Bitte beachten Sie, dass die resultierende Konfigurationsdatei für die Masterknoten eine neuere Version als die ursprünglichen Konfigurationen war.  Führen Sie den folgenden Befehl aus, um es anzuzeigen.  Nebenbei bemerken wir, dass dies wahrscheinlich eines der besten einzeiligen Skripte in der Geschichte von Kubernetes ist: <br><br><pre> <code class="plaintext hljs">python3 -c "import sys, urllib.parse; print(urllib.parse.unquote(sys.argv[1]))" $(oc get MachineConfig/rendered-master-f722b027a98ac5b8e0b41d71e992f626 -o YAML | grep -B4 crio.conf | grep source | tail -n 1 | cut -d, -f2) | grep pid</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">pids_limit = 2048</code> </pre><br>  Stellen Sie nun sicher, dass die Konfiguration auf alle Masterknoten angewendet wurde.  Zuerst erhalten wir eine Liste der Knoten im Cluster: <br><br><pre> <code class="plaintext hljs">oc get node | grep master Output: ip-10-0-135-153.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1 ip-10-0-154-0.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1 ip-10-0-166-79.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1</code> </pre><br>  Schauen Sie sich nun die installierte Datei an.  Sie werden sehen, dass die Datei mit den neuen PID- und Debug-Anweisungen aktualisiert wurde, die wir in der ContainerRuntimeConfig-Ressource angegeben haben.  Eleganz selbst: <br><br><pre> <code class="plaintext hljs">oc debug node/ip-10-0-135-153.us-east-2.compute.internal — cat /host/etc/crio/crio.conf | egrep 'debug||pid'</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">... pids_limit = 2048 ... log_level = "debug" ...</code> </pre><br>  Alle diese Änderungen im Cluster wurden auch ohne Start von SSH vorgenommen.  Alle Arbeiten wurden durch Kontaktaufnahme mit dem Kuberentes-Masterknoten durchgeführt.  Das heißt, diese neuen Parameter wurden nur auf den Masterknoten konfiguriert.  Gleichzeitig haben sich die Arbeitsknoten nicht geändert, was die Vorteile der Kubernetes-Methodik unter Verwendung der festgelegten und aktuellen Zustände für Hosts von Containern und Container-Engines mit austauschbaren Elementen demonstriert. <br><br>  Das obige Beispiel zeigt die Möglichkeit, Änderungen an einem kleinen OpenShift Container Platform 4-Cluster mit drei Arbeitsknoten oder an einem großen Produktionscluster mit 3000 Knoten vorzunehmen.  In jedem Fall ist der Arbeitsaufwand gleich - und sehr gering - konfigurieren Sie einfach die ContainerRuntimeConfig-Datei und ändern Sie eine Bezeichnung in MachineConfigPool.  Dies ist mit jeder Version der OpenShift Container Platform 4.X-Plattform möglich, die Kubernetes während seines gesamten Lebenszyklus verwendet. <br><br>  Oft entwickeln sich Technologieunternehmen so schnell, dass wir nicht erklären können, warum wir bestimmte Technologien für die Basiskomponenten auswählen.  Container-Engines waren in der Vergangenheit die Komponente, mit der Benutzer direkt interagieren.  Da die Popularität von Containern natürlich mit dem Aufkommen von Containermotoren begann, zeigen Benutzer häufig Interesse an ihnen.  Dies ist ein weiterer Grund, warum sich Red Hat für CRI-O entschieden hat.  Container entwickeln sich weiter, wobei der Schwerpunkt heute auf der Orchestrierung liegt, und wir sind zu dem Schluss gekommen, dass CRI-O die beste Erfahrung bei der Arbeit mit OpenShift 4 bietet. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460495/">https://habr.com/ru/post/de460495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460483/index.html">5 Methoden zum Ausführen eines effektiven Brainstormings</a></li>
<li><a href="../de460485/index.html">Wie ein Online-Turnier das "Ziel nächste Woche" entmutigen kann</a></li>
<li><a href="../de460489/index.html">TOP 11 Fehler bei der Entwicklung von BCP</a></li>
<li><a href="../de460491/index.html">Arduino Temperatur- und Feuchtigkeitssensor mit Senden und Plotten (Teil 1)</a></li>
<li><a href="../de460493/index.html">"Killer Apps" für PC aus den 80ern: VisiCalc und WordStar</a></li>
<li><a href="../de460497/index.html">Intuitive Anwendung von Monte-Carlo-Methoden mit Markov-Ketten</a></li>
<li><a href="../de460499/index.html">Drei Gewinner des Dijkstra-Preises: Wie verliefen Hydra 2019 und SPTDC 2019?</a></li>
<li><a href="../de460501/index.html">Beispiel für die Implementierung einer kontinuierlichen Integration mit BuildBot</a></li>
<li><a href="../de460503/index.html">Drahtlose Konfiguration des Raspberry PI 3 B +</a></li>
<li><a href="../de460505/index.html">Verführen Sie drei Kreuze oder warum Projekte so schwer pünktlich zu beenden sind</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
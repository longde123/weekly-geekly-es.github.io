<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äç‚úàÔ∏è üè∑Ô∏è üêô Container-to-Pipeline: CRI-O ist jetzt die Standardeinstellung in OpenShift Container Platform 4 üê∂ üë©üèæ‚Äçü§ù‚Äçüë®üèª üë®‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mit der Red Hat OpenShift Container Platform 4-Plattform k√∂nnen Sie die Erstellung von Hosts f√ºr die Bereitstellung von Containern streamen, einschlie...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Container-to-Pipeline: CRI-O ist jetzt die Standardeinstellung in OpenShift Container Platform 4</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redhatrussia/blog/460495/"> Mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Red Hat OpenShift Container Platform 4-Plattform</a> k√∂nnen Sie die Erstellung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hosts f√ºr die Bereitstellung von Containern</a> streamen, einschlie√ülich in der Infrastruktur von Cloud-Dienstanbietern, auf Virtualisierungsplattformen oder in Bare-Metal-Systemen.  Um eine Cloud-Plattform im vollen Sinne zu schaffen, mussten wir alle verwendeten Elemente genau kontrollieren und damit die Zuverl√§ssigkeit eines komplexen Automatisierungsprozesses erh√∂hen. <br><br><img src="https://habrastorage.org/webt/h5/hn/x9/h5hnx9ulnrjawbfhd2dncjqmxvm.png" width="100%"><br><br>  Die naheliegende L√∂sung bestand darin, Red Hat Enterprise Linux CoreOS (eine Variante von Red Hat Enterprise Linux) und CRI-O als Standard zu verwenden. <br><a name="habracut"></a><br>  Da das Thema Navigation sehr erfolgreich ist, um Analogien zur Erkl√§rung der Funktionsweise von Kubernetes und Containern zu finden, versuchen wir, am Beispiel der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erfindung</a> von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Brunel f√ºr die Herstellung von Rigging-Bl√∂cken</a> √ºber die Gesch√§ftsprobleme zu sprechen, die CoreOS und CRI-O l√∂sen.  Im Jahr 1803 wurde Mark Brunel beauftragt, 100.000 Takelagebl√∂cke f√ºr die Bed√ºrfnisse der wachsenden britischen Marine herzustellen.  Ein Hebeblock ist eine Art Rig, mit dem Seile an Segeln befestigt werden.  Bis zum Beginn des 19. Jahrhunderts wurden diese Bl√∂cke von Hand hergestellt, aber Brunel konnte die Produktion automatisieren und begann, standardisierte Bl√∂cke mit Maschinen herzustellen.  Durch die Automatisierung dieses Prozesses waren alle Bl√∂cke nahezu gleich, konnten im Falle eines Ausfalls leicht ausgetauscht und in gro√üen Mengen hergestellt werden. <br><br>  Stellen Sie sich nun vor, Brunel m√ºsste diese Arbeit f√ºr 20 verschiedene Schiffsmodelle (Kubernetes-Versionen) und f√ºr f√ºnf verschiedene Planeten mit v√∂llig unterschiedlichen Meeresstr√∂mungen und -winden (Cloud-Anbieter) ausf√ºhren.  Dar√ºber hinaus war es erforderlich, dass sich alle Schiffe (OpenShift-Cluster) unabh√§ngig von den navigierten Planeten aus Sicht der Kapit√§ne (Betreiber, die den Betrieb der Cluster steuern) identisch verhalten.  In Fortsetzung der Marine-Analogie ist es Schiffskapit√§nen absolut egal, welche Rigging-Bl√∂cke (CRI-O) auf ihren Schiffen verwendet werden - die Hauptsache f√ºr sie ist, dass diese Bl√∂cke stark und zuverl√§ssig sind. <br><br>  OpenShift 4 als Cloud-Plattform steht vor einer sehr √§hnlichen gesch√§ftlichen Herausforderung.  Neue Knoten m√ºssen zum Zeitpunkt der Erstellung des Clusters, im Falle eines Fehlers in einem der Knoten oder bei der Skalierung des Clusters erstellt werden.  Beim Erstellen und Initialisieren eines neuen Knotens m√ºssen kritische Hostkomponenten, einschlie√ülich CRI-O, entsprechend konfiguriert werden.  Wie bei jeder anderen Produktion m√ºssen zu Beginn ‚ÄûRohstoffe‚Äú geliefert werden.  Bei Schiffen fungieren Metall und Holz als Rohstoffe.  Wenn Sie jedoch einen Host f√ºr die Bereitstellung von Containern in einem OpenShift 4-Cluster erstellen, m√ºssen an der Eingabe Konfigurationsdateien und API-Server bereitgestellt werden.  Danach bietet OpenShift √ºber den gesamten Lebenszyklus den erforderlichen Automatisierungsgrad, bietet den Endbenutzern den erforderlichen Produkt-Support und zahlt sich somit f√ºr Investitionen in die Plattform aus. <br><br>  OpenShift 4 wurde so entwickelt, dass alle wichtigen Anbieter von Cloud Computing, Virtualisierungsplattformen und sogar Bare-Metal-Systemen das System w√§hrend des gesamten Lebenszyklus der Plattform (f√ºr Version 4.X) bequem aktualisieren k√∂nnen.  Dazu m√ºssen Knoten auf Basis austauschbarer Elemente angelegt werden.  Wenn ein Cluster eine neue Version von Kubernetes ben√∂tigt, erh√§lt er auch die entsprechende CRI-O-Version unter CoreOS.  Da die CRI-O-Version direkt an Kubernetes gebunden ist, vereinfacht dies alle Permutationen f√ºr Tests, Fehlerbehebung oder Support erheblich.  Dar√ºber hinaus reduziert dieser Ansatz die Kosten f√ºr Endbenutzer und Red Hat. <br><br>  Dies ist ein grundlegend neuer Blick auf Kubernetes-Cluster, der die Grundlage f√ºr die Planung neuer √§u√üerst n√ºtzlicher und attraktiver Funktionen bildet.  CRI-O (Open Container-Projekt Container Runtime Interface - Open Container Initiative, abgek√ºrzt CRI-OCI) war die erfolgreichste Wahl f√ºr die Massenerstellung von Knoten, die f√ºr die Arbeit mit OpenShift erforderlich ist.  CRI-O wird die zuvor verwendete Docker-Engine ersetzen und OpenShift-Benutzern eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wirtschaftliche, stabile, einfache und langweilige</a> - ja, Sie haben es richtig geh√∂rt - langweilige Container-Engine bieten, die speziell f√ºr die Arbeit mit Kubernetes entwickelt wurde. <br><br><h3>  Die Welt der offenen Container </h3><br>  Die Welt bewegt sich seit langem in Richtung offener Container.  Ob bei Kubernetes oder auf niedrigeren Ebenen, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Entwicklung von Containerstandards</a> f√ºhrt zu einem √ñkosystem der Innovation auf allen Ebenen. <br><br>  Alles begann mit der Gr√ºndung der Open Containers Initiative <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im Juni 2015</a> .  In diesem fr√ºhen Arbeitsstadium wurden Spezifikationen f√ºr das Container- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Image (Image)</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laufzeit erstellt</a> .  Dadurch konnte sichergestellt werden, dass die Tools einen einzigen Standard f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Container-Images</a> und ein einziges Format f√ºr die Arbeit mit ihnen verwenden k√∂nnen.  Sp√§ter wurden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verteilungsspezifikationen</a> hinzugef√ºgt, mit denen Benutzer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Containerbilder</a> problemlos austauschen konnten. <br><br>  Die Kubernetes-Community entwickelte daraufhin einen einzigen steckbaren Schnittstellenstandard namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Container Runtime Interface (CRI)</a> .  Dank dessen konnten Kubernetes-Benutzer neben Docker verschiedene Engines f√ºr die Arbeit mit Containern verbinden. <br><br>  Die Ingenieure von Red Hat und Google sahen eine Marktnachfrage nach einer Container-Engine, die Anfragen von Kubelet mithilfe des CRI-Protokolls annehmen konnte, und f√ºhrten Container ein, die mit den oben genannten OCI-Spezifikationen kompatibel waren.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Es gab also eine OCID</a> .  Aber entschuldigen Sie, weil wir gesagt haben, dass dieses Material CRI-O gewidmet sein wird?  Tats√§chlich wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> Projekt erst mit der Ver√∂ffentlichung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Version 1.0</a> in CRI-O umbenannt. <br><br>  <b><i>Abb.</i></b>  <b><i>1.</i></b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7-/-n/qb/7--nqbszwtnoy38f-tnbuzdmucm.png"></div><br><br><h3>  Innovation mit CRI-O und CoreOS </h3><br>  Mit dem Start der OpenShift 4-Plattform wurde die in der Standardplattform verwendete <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Container-Engine</a> ge√§ndert und Docker durch CRI-O ersetzt, das eine wirtschaftliche, stabile, einfache und langweilige Container-Startumgebung bietet, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sich</a> parallel zu Kubernetes entwickelt.  Dies vereinfacht die Clusterunterst√ºtzung und -konfiguration erheblich.  Das Konfigurieren und Verwalten der Container-Engine und des Hosts wird in OpenShift 4 automatisiert. <br><br>  H√∂r auf, wie ist es? <br><br>  Mit dem Aufkommen von OpenShift 4 ist es jetzt nicht mehr erforderlich, eine Verbindung zu einzelnen Hosts herzustellen und eine Container-Engine zu installieren, Speicher zu konfigurieren, Server f√ºr die Suche zu konfigurieren oder ein Netzwerk zu konfigurieren.  Die OpenShift 4-Plattform wurde komplett neu gestaltet, um das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Operator Framework</a> nicht nur in Bezug auf Endbenutzeranwendungen, sondern auch in Bezug auf grundlegende Vorg√§nge auf Plattformebene wie das Bereitstellen von Images, das Konfigurieren des Systems oder das Installieren von Updates zu verwenden. <br><br>  Kubernetes hat es Benutzern immer erm√∂glicht, Anwendungen zu verwalten, indem der gew√ºnschte Status ermittelt und mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Controllern</a> sichergestellt wurde, dass der tats√§chliche Status dem angegebenen Status so nahe wie m√∂glich kommt.  Dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ansatz unter Verwendung eines bestimmten Zustands und eines tats√§chlichen Zustands</a> er√∂ffnet sowohl aus Sicht der Entwicklung als auch aus Sicht der Operationen gro√üe Chancen.  Entwickler k√∂nnen den erforderlichen Status ermitteln, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ihn</a> in Form einer YAML- oder JSON-Datei an den Bediener √ºbertragen und anschlie√üend die erforderliche Anwendungsinstanz in der Betriebsumgebung erstellen, w√§hrend der Betriebsstatus dieser Instanz vollst√§ndig dem angegebenen entspricht. <br><br>  OpenShift 4 verwendet Operatoren in der Plattform und bringt dieses neue Paradigma (unter Verwendung des Konzepts von Set und Ist-Status) in die Verwaltung von RHEL CoreOS und CRI-O ein.  Die Aufgaben der Konfiguration und Versionierung des Betriebssystems und der Container-Engine werden mithilfe des sogenannten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Machine Config Operator (MCO)</a> automatisiert.  MCO vereinfacht die Arbeit des Clusteradministrators erheblich und automatisiert im Wesentlichen die letzten Installationsphasen sowie die nachfolgenden Vorg√§nge nach der Installation (Vorg√§nge am zweiten Tag).  All dies macht OpenShift 4 zu einer echten Cloud-Plattform.  Wir werden etwas sp√§ter darauf eingehen. <br><br><h3>  Containerstart </h3><br>  Benutzer hatten die M√∂glichkeit, die CRI-O-Engine in der OpenShift-Plattform ab Version 3.7 im Status Tech Preview und ab Version 3.9 im Status Allgemein verf√ºgbar (derzeit unterst√ºtzt) zu verwenden.  Dar√ºber hinaus nutzt Red Hat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CRI-O</a> seit Version 3.10 in gro√üem Umfang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, um Produktions-Workloads</a> in OpenShift Online <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu starten</a> .  All dies erm√∂glichte es dem Team, das an CRI-O arbeitete, umfangreiche Erfahrungen beim Massenstart von Containern in gro√üen Kubernetes-Clustern zu sammeln.  Um ein grundlegendes Verst√§ndnis der Verwendung von CRI-O durch Kubernetes zu erhalten, sehen wir uns die folgende Abbildung an, die die Funktionsweise der Architektur zeigt. <br><br>  <b><i>Abb.</i></b>  <b><i>2. Funktionsweise von Containern im Kubernetes-Cluster</i></b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1a/zr/kz/1azrkzz-ey6euphpkgqpazncwci.png"></div><br><br>  CRI-O vereinfacht die Erstellung neuer Container-Hosts, indem die gesamte oberste Ebene beim Initialisieren neuer Knoten und beim Freigeben neuer Versionen der OpenShift-Plattform synchronisiert wird.  Ein vollst√§ndiges Plattform-Audit erm√∂glicht Transaktionsaktualisierungen / Rollbacks und verhindert au√üerdem Deadlocks in Abh√§ngigkeiten zwischen dem Container-Tail-Kernel, der Container-Engine, Kubelets und dem Kubernetes-Master.  Mit der zentralen Verwaltung aller Plattformkomponenten sowie der Versionskontrolle und -verwaltung k√∂nnen Sie jederzeit einen eindeutigen Pfad von Status A zu Status B verfolgen. Dies vereinfacht den Aktualisierungsprozess, verbessert die Sicherheit, verbessert die Leistungsberichte und senkt die Kosten f√ºr die Aktualisierung und Installation neuer Versionen. <br><br><h3>  Demonstration der Kraft austauschbarer Elemente </h3><br>  Wie bereits erw√§hnt, bietet die Verwendung von Machine Config Operator zum Verwalten des Container-Hosts und der Container-Engine in OpenShift 4 einen neuen Automatisierungsgrad, der auf der Kubernetes-Plattform zuvor nicht m√∂glich war.  Um die neuen Funktionen zu demonstrieren, zeigen wir, wie Sie √Ñnderungen an der Datei crio.conf vornehmen k√∂nnen.  Versuchen Sie, sich auf die Ergebnisse zu konzentrieren, um die Terminologie nicht zu verwechseln. <br><br>  Lassen Sie uns zun√§chst eine sogenannte Container-Laufzeitkonfiguration erstellen - die Container Runtime Config.  Betrachten Sie dies als eine Kubernetes-Ressource, die die Konfiguration f√ºr CRI-O darstellt.  In Wirklichkeit handelt es sich hierbei um eine spezielle Version von MachineConfig, bei der es sich um eine Konfiguration handelt, die auf einem RHEL CoreOS-Computer in einem OpenShift-Cluster bereitgestellt wird. <br><br>  Diese benutzerdefinierte Ressource namens ContainerRuntimeConfig wurde erfunden, um Clusteradministratoren die Konfiguration von CRI-O zu erleichtern.  Dies ist ein leistungsstarkes Tool, das abh√§ngig von den Einstellungen von MachineConfigPool nur auf bestimmte Knoten angewendet werden kann.  Betrachten Sie dies als eine Gruppe von Maschinen, die denselben Zweck erf√ºllen. <br><br>  Beachten Sie die letzten beiden Zeilen, die wir in der Datei /etc/crio/crio.conf √§ndern werden.  Diese beiden Zeilen sind den Zeilen in der Datei crio.conf sehr √§hnlich. Dies sind: <br><br><pre><code class="plaintext hljs">vi ContainerRuntimeConfig.yaml</code> </pre> <br>  Fazit: <br><br><pre> <code class="plaintext hljs">apiVersion: machineconfiguration.openshift.io/v1 kind: ContainerRuntimeConfig metadata: name: set-log-and-pid spec: machineConfigPoolSelector: matchLabels: debug-crio: config-log-and-pid containerRuntimeConfig: pidsLimit: 2048 logLevel: debug</code> </pre><br>  Senden Sie diese Datei nun an den Kubernetes-Cluster und √ºberpr√ºfen Sie, ob sie tats√§chlich erstellt wurde.  Bitte beachten Sie, dass der Vorgang wie bei jeder anderen Kubernetes-Ressource ausgef√ºhrt wird: <br><br><pre> <code class="plaintext hljs">oc create -f ContainerRuntimeConfig.yaml oc get ContainerRuntimeConfig</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">NAME AGE set-log-and-pid 22h</code> </pre><br>  Nachdem wir ContainerRuntimeConfig erstellt haben, m√ºssen wir einen der MachineConfigPools √§ndern, damit Kubernetes versteht, dass wir diese Konfiguration auf eine bestimmte Gruppe von Computern im Cluster anwenden m√∂chten.  In diesem Fall √§ndern wir MachineConfigPool f√ºr die Masterknoten: <br><br><pre> <code class="plaintext hljs">oc edit MachineConfigPool/master</code> </pre><br>  Schlussfolgerung (aus Gr√ºnden der Klarheit bleibt der Hauptpunkt √ºbrig): <br><br><pre> <code class="plaintext hljs">... metadata: creationTimestamp: 2019-04-10T23:42:28Z generation: 1 labels: debug-crio: config-log-and-pid operator.machineconfiguration.openshift.io/required-for-upgrade: "" ...</code> </pre><br>  Zu diesem Zeitpunkt beginnt MCO mit der Erstellung einer neuen crio.conf-Datei f√ºr den Cluster.  In diesem Fall kann eine vollst√§ndig fertige Konfigurationsdatei mithilfe der Kubernetes-API angezeigt werden.  Denken Sie daran, ContainerRuntimeConfig ist nur eine spezielle Version von MachineConfig, sodass wir das Ergebnis anhand der Zeilen in MachineConfigs sehen k√∂nnen: <br><br><pre> <code class="plaintext hljs">oc get MachineConfigs | grep rendered</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">rendered-master-c923f24f01a0e38c77a05acfd631910b 4.0.22-201904011459-dirty 2.2.0 16h rendered-master-f722b027a98ac5b8e0b41d71e992f626 4.0.22-201904011459-dirty 2.2.0 4m rendered-worker-9777325797fe7e74c3f2dd11d359bc62 4.0.22-201904011459-dirty 2.2.0 16h</code> </pre><br>  Bitte beachten Sie, dass die resultierende Konfigurationsdatei f√ºr die Masterknoten eine neuere Version als die urspr√ºnglichen Konfigurationen war.  F√ºhren Sie den folgenden Befehl aus, um es anzuzeigen.  Nebenbei bemerken wir, dass dies wahrscheinlich eines der besten einzeiligen Skripte in der Geschichte von Kubernetes ist: <br><br><pre> <code class="plaintext hljs">python3 -c "import sys, urllib.parse; print(urllib.parse.unquote(sys.argv[1]))" $(oc get MachineConfig/rendered-master-f722b027a98ac5b8e0b41d71e992f626 -o YAML | grep -B4 crio.conf | grep source | tail -n 1 | cut -d, -f2) | grep pid</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">pids_limit = 2048</code> </pre><br>  Stellen Sie nun sicher, dass die Konfiguration auf alle Masterknoten angewendet wurde.  Zuerst erhalten wir eine Liste der Knoten im Cluster: <br><br><pre> <code class="plaintext hljs">oc get node | grep master Output: ip-10-0-135-153.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1 ip-10-0-154-0.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1 ip-10-0-166-79.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1</code> </pre><br>  Schauen Sie sich nun die installierte Datei an.  Sie werden sehen, dass die Datei mit den neuen PID- und Debug-Anweisungen aktualisiert wurde, die wir in der ContainerRuntimeConfig-Ressource angegeben haben.  Eleganz selbst: <br><br><pre> <code class="plaintext hljs">oc debug node/ip-10-0-135-153.us-east-2.compute.internal ‚Äî cat /host/etc/crio/crio.conf | egrep 'debug||pid'</code> </pre><br>  Fazit: <br><br><pre> <code class="plaintext hljs">... pids_limit = 2048 ... log_level = "debug" ...</code> </pre><br>  Alle diese √Ñnderungen im Cluster wurden auch ohne Start von SSH vorgenommen.  Alle Arbeiten wurden durch Kontaktaufnahme mit dem Kuberentes-Masterknoten durchgef√ºhrt.  Das hei√üt, diese neuen Parameter wurden nur auf den Masterknoten konfiguriert.  Gleichzeitig haben sich die Arbeitsknoten nicht ge√§ndert, was die Vorteile der Kubernetes-Methodik unter Verwendung der festgelegten und aktuellen Zust√§nde f√ºr Hosts von Containern und Container-Engines mit austauschbaren Elementen demonstriert. <br><br>  Das obige Beispiel zeigt die M√∂glichkeit, √Ñnderungen an einem kleinen OpenShift Container Platform 4-Cluster mit drei Arbeitsknoten oder an einem gro√üen Produktionscluster mit 3000 Knoten vorzunehmen.  In jedem Fall ist der Arbeitsaufwand gleich - und sehr gering - konfigurieren Sie einfach die ContainerRuntimeConfig-Datei und √§ndern Sie eine Bezeichnung in MachineConfigPool.  Dies ist mit jeder Version der OpenShift Container Platform 4.X-Plattform m√∂glich, die Kubernetes w√§hrend seines gesamten Lebenszyklus verwendet. <br><br>  Oft entwickeln sich Technologieunternehmen so schnell, dass wir nicht erkl√§ren k√∂nnen, warum wir bestimmte Technologien f√ºr die Basiskomponenten ausw√§hlen.  Container-Engines waren in der Vergangenheit die Komponente, mit der Benutzer direkt interagieren.  Da die Popularit√§t von Containern nat√ºrlich mit dem Aufkommen von Containermotoren begann, zeigen Benutzer h√§ufig Interesse an ihnen.  Dies ist ein weiterer Grund, warum sich Red Hat f√ºr CRI-O entschieden hat.  Container entwickeln sich weiter, wobei der Schwerpunkt heute auf der Orchestrierung liegt, und wir sind zu dem Schluss gekommen, dass CRI-O die beste Erfahrung bei der Arbeit mit OpenShift 4 bietet. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460495/">https://habr.com/ru/post/de460495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460483/index.html">5 Methoden zum Ausf√ºhren eines effektiven Brainstormings</a></li>
<li><a href="../de460485/index.html">Wie ein Online-Turnier das "Ziel n√§chste Woche" entmutigen kann</a></li>
<li><a href="../de460489/index.html">TOP 11 Fehler bei der Entwicklung von BCP</a></li>
<li><a href="../de460491/index.html">Arduino Temperatur- und Feuchtigkeitssensor mit Senden und Plotten (Teil 1)</a></li>
<li><a href="../de460493/index.html">"Killer Apps" f√ºr PC aus den 80ern: VisiCalc und WordStar</a></li>
<li><a href="../de460497/index.html">Intuitive Anwendung von Monte-Carlo-Methoden mit Markov-Ketten</a></li>
<li><a href="../de460499/index.html">Drei Gewinner des Dijkstra-Preises: Wie verliefen Hydra 2019 und SPTDC 2019?</a></li>
<li><a href="../de460501/index.html">Beispiel f√ºr die Implementierung einer kontinuierlichen Integration mit BuildBot</a></li>
<li><a href="../de460503/index.html">Drahtlose Konfiguration des Raspberry PI 3 B +</a></li>
<li><a href="../de460505/index.html">Verf√ºhren Sie drei Kreuze oder warum Projekte so schwer p√ºnktlich zu beenden sind</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
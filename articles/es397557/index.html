<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèΩ ‚úãüèº ‚òëÔ∏è La red neuronal de visi√≥n artificial est√° entrenada en juegos de computadora realistas. ü•£ ü§û üí™üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Disparos del juego de computadora Grand Theft Auto V y marcado sem√°ntico para entrenar una
 
 red neuronal de visi√≥n artificial Las redes neuronales e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La red neuronal de visi√≥n artificial est√° entrenada en juegos de computadora realistas.</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/397557/"><img src="https://habrastorage.org/files/47e/fcc/506/47efcc5062114f4b8ecc13630c9e361e.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Disparos del juego de computadora Grand Theft Auto V y marcado sem√°ntico para entrenar una</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
red neuronal de </font><i><font style="vertical-align: inherit;">visi√≥n artificial</font></i><font style="vertical-align: inherit;"> Las redes neuronales establecen nuevos r√©cords en casi todas las competiciones de visi√≥n por computadora, y tambi√©n se usan cada vez m√°s en otras aplicaciones de inteligencia artificial. Uno de los componentes clave de un rendimiento de red neuronal tan incre√≠ble es la disponibilidad de grandes conjuntos de datos para capacitaci√≥n y evaluaci√≥n. Por ejemplo, el desaf√≠o de reconocimiento visual a gran escala Imagenet (ILSVRC) con m√°s de 1 mill√≥n de im√°genes se utiliza para evaluar las redes neuronales modernas. Pero a juzgar por los √∫ltimos resultados (ResNet muestra el resultado de solo el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3.57% de los errores</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), pronto los investigadores tendr√°n que compilar conjuntos de datos m√°s extensos. Y luego, a√∫n m√°s extenso. Por cierto, anotar esas fotos es mucho trabajo, parte del cual debe hacerse manualmente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Algunos desarrolladores de sistemas de visi√≥n por computadora ofrecen una forma alternativa de entrenar y probar dichos sistemas. En lugar de anotar manualmente las fotos de entrenamiento, usan cuadros sintetizados de juegos de computadora realistas.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este es un enfoque completamente l√≥gico. En los juegos modernos, los gr√°ficos han alcanzado un nivel de realismo tal que las im√°genes sintetizadas son solo ligeramente diferentes de las fotograf√≠as del mundo real. Al mismo tiempo, el motor del juego puede generar una cantidad infinita de tales cuadros, lo que resuelve de manera dram√°tica el problema de recolectar millones de fotos para entrenar y evaluar la red neuronal. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aunque el motor del juego utiliza un n√∫mero finito de texturas, existe una amplia variedad de combinaciones de √°ngulos de visi√≥n, iluminaci√≥n, clima y nivel de detalle, lo que proporciona una variedad suficiente de conjuntos de datos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este a√±o, dos grupos de investigadores comprobaron en la pr√°ctica si es posible usar los fotogramas generados de los juegos de computadora para entrenar redes neuronales de visi√≥n por computadora. Un grupo de investigadores del departamento de inform√°tica de la Universidad de Columbia Brit√°nica (Canad√°) public√≥ un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">art√≠culo cient√≠fico</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para el que recopilaron m√°s de 60,000 cuadros de un juego de computadora con vistas de carretera similares a los </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conjuntos de datos CamVid</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cityscapes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Los investigadores lograron demostrar que la red neuronal despu√©s del entrenamiento en im√°genes sint√©ticas muestra un nivel de error similar al del entrenamiento en fotograf√≠as reales. Adem√°s, el entrenamiento en im√°genes sintetizadas usando fotos reales muestra un resultado a√∫n mejor.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos los 60,000 cuadros fueron tomados en tiempo soleado virtual, a la hora virtual a las 11:00, con una resoluci√≥n de 1024 √ó 768 y la configuraci√≥n m√°xima de gr√°ficos (el nombre del juego no fue revelado debido a las preocupaciones sobre los derechos de autor). Un veh√≠culo no tripulado condujo accidentalmente por las calles de juego, observando las reglas de la carretera. Los marcos fueron filmados una vez por segundo. Cada uno de ellos va acompa√±ado de una segmentaci√≥n sem√°ntica autom√°tica (cielo, peatones, autom√≥viles, √°rboles, fondo: la segmentaci√≥n es absolutamente precisa y tomada del juego), una imagen profunda (imagen de profundidad, mapa con el marcado de objetos), as√≠ como normales a la superficie.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s del conjunto de datos VG b√°sico, los investigadores crearon otro conjunto de datos VG + con mucha informaci√≥n sem√°ntica, no limitada a cinco etiquetas, aqu√≠ la segmentaci√≥n no es precisa. El marcado se realiz√≥ autom√°ticamente utilizando </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SegNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/files/192/934/07c/19293407c01d4ab09be60d46e67c09e5.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tramas marcadas con etiqueta del conjunto VG +</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para comparar la efectividad del entrenamiento de redes neuronales, se prepararon conjuntos de datos CamVid y Cityscapes (cinco etiquetas), as√≠ como CamVid + ‚Äã‚Äãy Cityscapes + con conjuntos de etiquetas extendidas. </font></font><br>
<br>
<img src="https://habrastorage.org/files/d2b/3dd/1e0/d2b3dd1e02e042ebb4ec45ea61c20ba4.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fotos originales de CamVid con anotaciones </font></font></i><br>
<br>
<img src="https://habrastorage.org/files/65f/888/ed1/65f888ed140f4456942204011e0ffd4a.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se </font></font></i><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">utilizaron </font></i><i><font style="vertical-align: inherit;">dos im√°genes aleatorias del conjunto Cityscapes + con anotaciones detalladas.</font></i></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para la clasificaci√≥n sem√°ntica, se </font><font style="vertical-align: inherit;">utiliz√≥ una </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">red neuronal convolucional larga</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> con una arquitectura FCN8 simple en la parte superior de la </font><a href=""><font style="vertical-align: inherit;">red VGG de</font></a><font style="vertical-align: inherit;"> 16 capas </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de Simonyan y Sisserman.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los investigadores realizaron varios experimentos para evaluar la eficiencia de reconocimiento de objetos por una red neuronal que fue entrenada en diferentes conjuntos de datos. En casi todos los casos, una red neuronal entrenada en datos sint√©ticos mostr√≥ un mejor resultado que una red neuronal entrenada en fotograf√≠as reales. Mostr√≥ el mejor resultado incluso al ver fotos reales. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por ejemplo, la tabla muestra el rendimiento de redes neuronales id√©nticas entrenadas en tres conjuntos de datos (fotos reales, datos sint√©ticos del juego, conjuntos mixtos) cuando los objetos se reconocen en fotos reales de los conjuntos CamVid + ‚Äã‚Äãy Cityscapes +. </font></font><br>
<br>
<img src="https://habrastorage.org/files/a64/eac/b8a/a64eacb8a5404f64897af9eed4dab2eb.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como puede ver, cuando entrena una red neuronal, es mejor complementar las im√°genes sint√©ticas de un juego de computadora con fotograf√≠as reales. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Art√≠culo cientifico</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> el 5 de agosto de 2016 en arXiv.org, la segunda versi√≥n es el 15 de agosto ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pdf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s de los investigadores de la Universidad de Columbia Brit√°nica, casi simult√°neamente el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mismo trabajo fue realizado por otro grupo de cient√≠ficos de la Universidad T√©cnica de Darmstadt (Alemania) e Intel Labs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Tomaron 24,966 cuadros del juego de computadora de mundo abierto Grand Theft Auto V. Para el entrenamiento. Los investigadores llegaron al mismo resultado: al usar un conjunto de datos de entrenamiento compuesto por 2/3 de im√°genes sint√©ticas y 1/3 de fotos CamVid, precisi√≥n el reconocimiento es mayor que solo cuando se usan fotos CamVid. </font></font><br>
<br>
<img src="https://habrastorage.org/files/19f/38c/bc3/19f38cbc32c74e2fa2af351b47113b0b.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Precisi√≥n de reconocimiento de varios objetos en fotos del conjunto CamVid cuando se aprende usando m√©todos convencionales y cuando se usan marcos de GTA V (l√≠nea inferior)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al mismo tiempo, la anotaci√≥n semiautom√°tica en un editor especialmente desarrollado reduce significativamente el tiempo requerido para preparar un conjunto de datos para entrenar una red neuronal. Por ejemplo, anotar una foto de CamVid toma 60 minutos, una foto de Cityscapes toma 90 minutos, y la anotaci√≥n semiautom√°tica de cuadros GTA V toma solo 7 segundos, en promedio ( </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">video, demostraci√≥n del editor</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/JGAIfWG2MQQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El trabajo de los investigadores de la Universidad T√©cnica de Darmstadt e Intel Labs se prepar√≥ para la Conferencia Europea sobre Visi√≥n por Computadora </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ECCV'16</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (11-14 de octubre) y se </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">public√≥</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> en el sitio web de la universidad. Los autores presentaron el </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c√≥digo fuente</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para leer etiquetas y </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conjuntos completos de datos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : tanto fotograf√≠as fuente como im√°genes en profundidad con marcado sem√°ntico. Es probable que el c√≥digo fuente del editor para la anotaci√≥n se publique en el futuro.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gracias al progreso en la creaci√≥n de juegos de computadora realistas, los desarrolladores de sistemas de inteligencia artificial tendr√°n a su disposici√≥n una excelente plataforma para aprender sistemas de visi√≥n artificial. </font><font style="vertical-align: inherit;">Estos sistemas se utilizar√°n en veh√≠culos no tripulados y robots. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quiz√°s los juegos de computadora se pueden usar no solo para la visi√≥n artificial, sino tambi√©n para crear patrones naturales de comportamiento en la sociedad. </font><font style="vertical-align: inherit;">Solo con el entrenamiento de IA deber√≠as tener cuidado al elegir un juego.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es397557/">https://habr.com/ru/post/es397557/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es397547/index.html">Byrobot Petrone: los mejores drones (imho) para ense√±ar a los ni√±os. Y para peleas</a></li>
<li><a href="../es397549/index.html">ProDOS 2.4 para Apple II: la primera actualizaci√≥n del sistema operativo para Apple II en 23 a√±os</a></li>
<li><a href="../es397551/index.html">Feliz cumplea√±os, Stanislav Lem</a></li>
<li><a href="../es397553/index.html">¬°Patea AHORA! El futuro est√° m√°s cerca con Kickstarter</a></li>
<li><a href="../es397555/index.html">Hogar inteligente Apple HomeKit. Primeras impresiones</a></li>
<li><a href="../es397559/index.html">Investigadores europeos han creado un nuevo material compuesto con transparencia variable</a></li>
<li><a href="../es397561/index.html">Audio Digest 9: Blogs sobre sonido, m√∫sica y tecnolog√≠a de audio</a></li>
<li><a href="../es397563/index.html">Se demuestra la autenticidad del C√≥digo de Grolier, el cuarto c√≥dice maya sobreviviente.</a></li>
<li><a href="../es397565/index.html">C√≥mo ve Lyft el transporte por carretera en 10 a√±os</a></li>
<li><a href="../es397567/index.html">En Nokia Bell Labs, lograron la transmisi√≥n de datos a una velocidad de 1 Tbit / s por fibra</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
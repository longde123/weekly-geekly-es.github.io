<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçü§ù‚Äçüë®üèª üëåüèΩ ‚úíÔ∏è A loja precisa da experi√™ncia do Stylish Crossell: Retail Rocket em an√°lise de imagens para formar recomenda√ß√µes ü§∑üèº üôåüèª ‚úîÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O interesse na an√°lise de imagens para gerar recomenda√ß√µes est√° aumentando a cada dia. Decidimos descobrir o qu√£o real esse tema de tend√™ncia traz. Fa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A loja precisa da experi√™ncia do Stylish Crossell: Retail Rocket em an√°lise de imagens para formar recomenda√ß√µes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/retailrocket/blog/441366/">  O interesse na an√°lise de imagens para gerar recomenda√ß√µes est√° aumentando a cada dia.  Decidimos descobrir o qu√£o real esse tema de tend√™ncia traz.  Falamos sobre o teste do uso do aprendizado profundo (Deep Learning) para melhorar as recomenda√ß√µes de produtos relacionados. <br><br><img src="https://habrastorage.org/webt/nf/3h/1g/nf3h1gbxcrdaxxge_wmw3mkbvjo.jpeg"><br><br>  Neste artigo, descrevemos a experi√™ncia de aplicar a tecnologia de an√°lise de imagem para melhorar o algoritmo de produtos relacionados.  Voc√™ pode l√™-lo de duas maneiras: aqueles que n√£o est√£o interessados ‚Äã‚Äãnos detalhes t√©cnicos do uso de redes neurais podem pular os cap√≠tulos sobre como criar um conjunto de dados e implementar solu√ß√µes e ir diretamente para os testes AB e seus resultados.  E aqueles que t√™m um entendimento b√°sico de conceitos como casamentos, uma camada de uma rede neural, etc., estar√£o interessados ‚Äã‚Äãem todo o material. <a name="habracut"></a><br><br><h2>  Aprendizado Profundo no Contexto da An√°lise de Imagem </h2><br>  Em nossa pilha de tecnologias, o Deep Learning √© usado com √™xito para resolver alguns problemas.  Durante algum tempo, n√£o ousamos aplic√°-lo no contexto da an√°lise de imagens, mas v√°rias premissas surgiram recentemente que mudaram de id√©ia: <br><br><ul><li>  maior interesse da comunidade na an√°lise de imagens usando m√©todos de aprendizado profundo; </li><li>  foi definido um c√≠rculo de estruturas ‚Äúmaduras‚Äù e redes neurais pr√©-treinadas, a partir das quais se poderia come√ßar de maneira r√°pida e simples; </li><li>  a an√°lise de imagens em sistemas de recomenda√ß√£o tem sido frequentemente usada como um recurso de marketing que garante melhorias "sem precedentes"; </li><li>  as necessidades alimentares come√ßaram a aparecer nesse tipo de pesquisa. </li></ul><br>  No contexto da interse√ß√£o de sistemas de recomenda√ß√£o e an√°lise de imagem, pode haver muitas aplica√ß√µes de aprendizado profundo; no entanto, na primeira etapa, identificamos para n√≥s tr√™s maneiras principais de desenvolver essa √°rea: <br><br><ol><li>  Uma melhoria geral na qualidade das recomenda√ß√µes, por exemplo, produtos relacionados a um vestido, √© mais qualitativamente adequada em cores e estilos. </li><li>  Encontrar mercadorias na base de produtos de uma loja usando uma fotografia (In Shop Retrieval) √© um mecanismo que permite encontrar produtos no banco de dados de uma loja usando uma foto carregada. </li><li>  Determina√ß√£o das propriedades / atributos do produto a partir da foto (marca√ß√£o de atributo), quando atributos significativos s√£o determinados a partir da foto, por exemplo, o tipo de produto - uma camiseta, jaqueta, cal√ßa, etc. </li></ol><br>  A dire√ß√£o mais priorit√°ria e promissora para n√≥s √© a primeira op√ß√£o, e decidimos explor√°-la. <br><br><h3>  Por que voc√™ escolheu um algoritmo para produtos relacionados </h3><br>  Qualquer sistema de recomenda√ß√£o possui dois algoritmos b√°sicos de mercadoria est√°tica: alternativas e produtos relacionados.  E se tudo estiver claro com as alternativas - estes s√£o produtos semelhantes ao modelo original (por exemplo, diferentes tipos de camisas), ent√£o, com produtos relacionados, tudo fica muito mais complicado.  √â importante aqui n√£o cometer erros com a correspond√™ncia entre os produtos b√°sicos e os recomendados, por exemplo, o carregador deve caber no telefone, a cor do vestido nos sapatos, etc;  voc√™ precisa considerar o feedback, por exemplo, n√£o recomenda um telefone ao carregador, apesar do fato de que eles s√£o comprados juntos;  e pense em v√°rias outras nuances que surgem na pr√°tica.  Em grande parte devido √† presen√ßa de v√°rias nuances, nossa escolha recaiu sobre produtos relacionados.  Al√©m disso, somente em produtos relacionados √© poss√≠vel formar uma apar√™ncia completa, se falarmos sobre o segmento da moda. <br><br><blockquote>  Formulamos nosso principal objetivo de pesquisa como "Entendendo se o algoritmo atual para produtos relacionados pode ser significativamente aprimorado usando m√©todos de aprendizado profundo para an√°lise de imagem" </blockquote><br>  Observo que, antes disso, n√£o utiliz√°vamos informa√ß√µes de imagem ao calcular recomenda√ß√µes de produtos, e aqui est√° o porqu√™: <br><br><ul><li>  Durante a exist√™ncia da plataforma Retail Rocket, adquirimos grande experi√™ncia no campo de recomenda√ß√µes de produtos.  E a principal conclus√£o que recebemos durante esse per√≠odo √© que o uso correto do comportamento do usu√°rio fornece quase 90% do resultado.  Sim, h√° o problema de um come√ßo a frio, quando s√£o coisas de conte√∫do, como informa√ß√µes sobre a imagem, que podem esclarecer ou melhorar as recomenda√ß√µes, mas, na pr√°tica, esse efeito √© muito menor do que o que dizem teoricamente.  Portanto, n√£o colocamos muita √™nfase nas fontes de informa√ß√£o de conte√∫do. </li><li>  Para criar recomenda√ß√µes de produtos na forma de informa√ß√µes de conte√∫do, usamos elementos como pre√ßo, categoria, descri√ß√£o e outras propriedades que a loja nos transmite.  Essas propriedades s√£o independentes da esfera e s√£o validadas qualitativamente ao integrar nosso servi√ßo.  O valor da imagem, pelo contr√°rio, surge apenas no segmento de artigos de moda. </li><li>  Manter o servi√ßo de trabalhar com fotos, validar sua qualidade e conformidade com as mercadorias √© um processo bastante complicado e um s√©rio dever t√©cnico que eu n√£o queria incorrer sem a confirma√ß√£o da necessidade. </li></ul><br>  No entanto, decidimos dar uma chance √†s fotos e ver como elas afetar√£o a efic√°cia das recomenda√ß√µes de constru√ß√£o.  Nossa abordagem n√£o √© ideal, com certeza algu√©m resolveria o problema de maneira diferente.  O objetivo deste artigo √© apresentar nossa abordagem com uma descri√ß√£o dos argumentos em cada etapa e apresentar os resultados ao leitor. <br><br><h2>  Forma√ß√£o de conceito </h2><br>  Come√ßamos cruzando os tr√™s componentes de qualquer produto: tecnologia acess√≠vel, recursos dispon√≠veis e necessidades do cliente.  O conceito de "melhorar as recomenda√ß√µes por meio de informa√ß√µes sobre a imagem de produtos relacionados" se desenvolveu por si s√≥.  A implementa√ß√£o "ideal" deste produto foi formada como um problema compilado na imagem de uma apar√™ncia selecionada.  Al√©m disso, essas recomenda√ß√µes n√£o devem apenas parecer √≥timas, mas tamb√©m funcionar do ponto de vista das m√©tricas b√°sicas de com√©rcio eletr√¥nico (Convers√£o, RPV, AOV), n√£o piores que o nosso algoritmo b√°sico. <br><br>  Look √© uma imagem escolhida pelos estilistas, que inclui um conjunto de coisas diferentes que combinam entre si, por exemplo, um vestido, jaqueta, bolsa, cinto, etc.  Do lado de nossos clientes, esse trabalho geralmente √© realizado por pessoas especialmente designadas, cujo trabalho √© mal automatizado.  Afinal, nem toda rede neural pode ter um senso de gosto. <br><br><img src="https://habrastorage.org/webt/xk/n7/98/xkn798q47nkdwvi_cgowffdl7n4.png" width="400"><br>  <i>Uma imagem de exemplo (apar√™ncia).</i> <br><br>  Imediatamente houve restri√ß√µes ao uso das informa√ß√µes da imagem - de fato, a aplica√ß√£o foi encontrada apenas no segmento de moda. <br><br><h2>  Infraestrutura e conjunto de dados </h2><br>  Primeiro, levantamos uma bancada de testes para experimentos e prototipagem.  Tudo √© bastante padr√£o GPU + Python + Keras aqui, por isso n√£o entraremos em detalhes.  Encontramos um conjunto de dados de alta qualidade, projetado para solucionar v√°rios problemas ao mesmo tempo, desde a previs√£o de atributos da imagem at√© a gera√ß√£o de novas texturas de roupas.  O que foi especialmente importante para n√≥s, inclu√≠a fotografias que compunham praticamente um √∫nico olhar.  Al√©m disso, o conjunto de dados incluiu fotografias de modelos de roupas de diferentes √¢ngulos, que tentamos usar no primeiro est√°gio. <br><br><img src="https://habrastorage.org/webt/-5/eh/hb/-5ehhbydvhgpjz5akabwleuofaq.png"><br>  <i>Exemplo de apar√™ncia de um conjunto de dados.</i> <br><br><img src="https://habrastorage.org/webt/s_/xh/ia/s_xhia1hvgbeod61q93u1ft0sl0.png"><br>  <i>Exemplos de imagens do mesmo modelo de roupas de diferentes √¢ngulos.</i> <br><br><h2>  Primeiros passos </h2><br>  A primeira id√©ia de implementar o produto final usando o conjunto de dados foi bastante simples: ‚ÄúVamos reduzir o problema √† tarefa de reconhecer roupas por imagem.  Assim, ao formular recomenda√ß√µes, "elevaremos" as recomenda√ß√µes semelhantes ao produto b√°sico ".  Nesse sentido, deveria encontrar a fun√ß√£o de ‚Äúproximidade‚Äù de mercadorias e, ao longo do caminho, resolver o problema de remover alternativas na quest√£o. <br><br>  Devo dizer imediatamente que esse tipo de problema poderia ser resolvido usando uma rede neural pr√©-treinada convencional, como o ResNet-50.  De fato: removemos a √∫ltima camada, obtemos casamentos, bem, e depois o cosseno, como uma medida de "proximidade".  No entanto, tendo experimentado um pouco essa abordagem, decidimos deix√°-la principalmente por tr√™s raz√µes. <br><br><ol><li>  N√£o est√° muito claro como interpretar corretamente a proximidade resultante.  O que se diz cosseno = 0,7 no dom√≠nio das camisetas, onde, regra geral, tudo √© muito semelhante um ao outro e o que √© cosseno = 0,5 no dom√≠nio das jaquetas, onde as diferen√ßas s√£o mais significativas.  Precis√°vamos desse tipo de interpreta√ß√£o para remover simultaneamente produtos muito pr√≥ximos - alternativas. </li><li>  Essa abordagem nos limitou um pouco do ponto de vista da educa√ß√£o para nossas tarefas espec√≠ficas.  Por exemplo, os recursos importantes que formam uma imagem hol√≠stica nem sempre s√£o os mesmos de dom√≠nio para dom√≠nio.  Em algum lugar, cor e forma s√£o mais importantes, mas em algum lugar o material e sua textura.  Al√©m disso, quer√≠amos treinar a rede para cometer menos erros de g√™nero quando as mulheres s√£o recomendadas para roupas masculinas.  Tal erro √© imediatamente evidente e deve ser encontrado o mais raramente poss√≠vel.  Com o simples uso de redes neurais pr√©-treinadas, parecia que est√°vamos um pouco limitados pela incapacidade de fornecer exemplos bem "semelhantes" em termos de imagem. </li><li>  O uso de redes siamesas, que s√£o mais adequadas para essas tarefas, parecia ser uma op√ß√£o mais natural e bem estudada. </li></ol><br><h2>  Um pouco sobre a rede neural siamesa </h2><br>  As redes neurais siamesas s√£o amplamente usadas na resolu√ß√£o de tarefas relacionadas ao reconhecimento de faces.  Na entrada, uma imagem da pessoa √© fornecida, na sa√≠da, o nome da pessoa do banco de dados ao qual ela pertence.  Esse problema pode ser resolvido diretamente, se voc√™ usar o softmax e o n√∫mero de classes igual ao n√∫mero de pessoas reconhec√≠veis na √∫ltima camada da rede neural.  No entanto, essa abordagem tem v√°rias limita√ß√µes: <br><br><ul><li>  voc√™ precisa ter um n√∫mero suficientemente grande de imagens para cada classe, o que √© praticamente imposs√≠vel. </li><li>  essa rede neural precisar√° ser retreinada toda vez que uma nova pessoa for adicionada ao banco de dados, o que √© muito inconveniente. </li></ul><br>  Uma solu√ß√£o l√≥gica em tal situa√ß√£o seria obter a fun√ß√£o de "similaridade" das duas fotos para responder a qualquer momento se as duas fotos - fornecidas √† entrada da rede neural e √† refer√™ncia do banco de dados - pertencem √† mesma pessoa e, consequentemente, resolvem o problema do reconhecimento de rosto.  Isso √© mais consistente com o comportamento de uma pessoa.  Por exemplo, um guarda olha para o rosto de uma pessoa e uma foto em um crach√° e responde √† pergunta se essa pessoa √© uma ou n√£o.  A rede neural siamesa implementa um conceito semelhante. <br><br>  O principal componente da rede neural siamesa √© a rede neural de backbone, que gera uma incorpora√ß√£o de imagem.  Essa incorpora√ß√£o pode ser usada para determinar o grau de similaridade entre as duas figuras.  Na arquitetura da rede neural siamesa, o componente da espinha dorsal √© usado duas vezes, cada vez para receber a incorpora√ß√£o da imagem.  O pesquisador precisa mostrar os valores de sa√≠da 0 ou 1, dependendo se uma ou v√°rias pessoas s√£o as donas das fotos, e ajustar a rede neural do backbone. <br><br><img src="https://habrastorage.org/webt/4u/fu/od/4ufuodzpu2yt5dkkktpgvogwug4.png"><br>  <i>Um exemplo de uma rede neural siamesa.</i>  <i>Os incorporamentos das imagens superior e inferior s√£o obtidos a partir da espinha dorsal da rede neural.</i>  <i>Imagem tirada do curso "Redes Neurais Convolucionais" de Andrey Ng.</i> <br><br><h2>  Solu√ß√£o b√°sica </h2><br>  Assim, ap√≥s algumas experimenta√ß√µes, a primeira vers√£o do algoritmo foi a seguinte: <br><br><ol><li>  Tomamos qualquer rede neural pr√©-treinada como espinha dorsal.  Experimentamos o ResNet-50 e o InceptionV3.  Selecionado com base no equil√≠brio do tamanho da rede e na precis√£o das previs√µes.  Focamos nos dados apresentados na documenta√ß√£o oficial da se√ß√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Keras</a> "Documenta√ß√£o para modelos individuais". </li><li>  Criamos uma rede siamesa e usamos Triplet Loss para treinamento. </li><li>  Como exemplos positivos, servimos a mesma imagem, mas de um √¢ngulo diferente.  Como exemplo negativo, estamos servindo outro produto. </li><li>  Tendo um modelo treinado, obtemos a m√©trica de proximidade para qualquer par de produtos da mesma maneira que a perda de trig√™meos √© considerada. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nt/x4/bp/ntx4bphenliyspt0fgwmmzgsu-e.png"></div><br>  <i>C√≥digo de c√°lculo de perda tripla.</i> <br><br>  O acordo com a Triplet Loss em um projeto real foi a primeira vez, o que criou v√°rias dificuldades.  A princ√≠pio, eles lutaram por um longo tempo com o fato de que todos os embeddings recebidos chegaram a um ponto.  Havia v√°rias raz√µes: n√£o normalizamos os casamentos antes de calcular a perda;  margem, o par√¢metro alfa era muito pequeno e os exemplos muito dif√≠ceis.  Adicionado normaliza√ß√£o e casamentos come√ßaram a variar.  O segundo problema inesperadamente se tornou Gradient Exploding.  Felizmente, o Keras tornou poss√≠vel resolver esse problema de maneira simples - adicionamos clipnorm = 1.0 ao otimizador, o que n√£o permitia que os gradientes crescessem durante o treinamento. <br><br>  O trabalho foi iterativo: treinamos o modelo, diminu√≠mos a perda, analisamos o resultado final e decidimos habilmente em que dire√ß√£o est√°vamos indo.  Em algum momento, ficou claro que montamos imediatamente exemplos bastante complexos e a complexidade n√£o muda no processo de aprendizado, o que afeta negativamente o resultado final.  Felizmente, o conjunto de dados com o qual trabalhamos tinha uma boa estrutura em √°rvore, que refletia o produto em si, por exemplo, Homens -&gt; Cal√ßas, Homens -&gt; Su√©teres etc.  Isso nos permitiu refazer o gerador e come√ßamos a dar exemplos "f√°ceis" para as primeiras √©pocas, depois para as mais complexas e assim por diante.  Os exemplos mais dif√≠ceis s√£o produtos da mesma categoria de produto, por exemplo, Cal√ßas, como negativos. <br><br>  Como resultado, obtivemos um modelo que diferia em sua produ√ß√£o da metodologia ‚Äúing√™nua‚Äù para usar o ResNet-50.  No entanto, a qualidade das recomenda√ß√µes finais n√£o nos convinha completamente.  Primeiro, havia um problema com os erros de g√™nero, mas havia um entendimento de como isso poderia ser resolvido.  Como o conjunto de dados dividiu as roupas em masculino e feminino, foi f√°cil coletar exemplos negativos para treinamento.  Em segundo lugar, quando treinamos no conjunto de dados o resultado final, verificamos visualmente nossos clientes - ficou imediatamente claro que era necess√°rio treinar novamente seus exemplos, pois para alguns o algoritmo funcionava muito mal se os produtos n√£o se sobrepusessem bem ao que foi mostrado durante o treinamento .  Finalmente, a qualidade era geralmente ruim, porque a imagem do treinamento era frequentemente barulhenta e continha, por exemplo, n√£o apenas jeans, mas tamb√©m uma camiseta. <br><br><img src="https://habrastorage.org/webt/qn/jk/qd/qnjkqdhwqeu_p__3xvztofsmvny.png"><br>  <i>A imagem do jeans na qual de fato tamb√©m mostra uma camiseta e botas.</i> <br><br>  A primeira experi√™ncia serviu de base para a solu√ß√£o subsequente, embora n√£o tenhamos come√ßado imediatamente a implementar um modelo aprimorado. <br><br><img src="https://habrastorage.org/webt/u8/ho/bi/u8hobio7yfpawxdbgyulgy-g5r4.png"><br>  <i>Um exemplo de recomenda√ß√µes baseadas em uma solu√ß√£o b√°sica.</i>  <i>Existem erros de g√™nero, alternativas tamb√©m surgem.</i> <br><br><h2>  Modelo melhorado </h2><br>  Come√ßamos treinando o ResNet-50 nos dados do nosso conjunto de dados.  O conjunto de dados cont√©m informa√ß√µes sobre o que √© mostrado na figura.  √â extra√≠do da estrutura do conjunto de dados Men -&gt; Pants, Women -&gt; Cardigans e mais.  Esse procedimento foi realizado por dois motivos: primeiro, eles queriam "direcionar" o backbone - uma rede neural para o dom√≠nio do vestu√°rio;  segundo, como as roupas tamb√©m s√£o divididas por g√™nero, eles esperavam se livrar do problema dos erros de g√™nero encontrados na primeira vers√£o. <br><br>  No segundo est√°gio, tentamos remover simultaneamente o ru√≠do das imagens de entrada e obter pares positivos de produtos relacionados para treinamento adicional.  O conjunto de dados usado por n√≥s tamb√©m foi projetado para resolver o problema de detec√ß√£o de objetos na imagem.  Em outras palavras, para cada imagem existem: as coordenadas do ret√¢ngulo que descrevem o objeto e sua classe.  Para resolver esse tipo de problema, usamos um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">projeto pronto</a> .  Este projeto usa a arquitetura de rede neural RetinaNet usando uma perda focal especial.  A ess√™ncia dessa perda √© focar mais n√£o no fundo da imagem, que est√° em quase todas as imagens, mas no objeto que precisa ser detectado.  Como espinha dorsal de uma rede neural para treinamento, usamos nossa rede pr√©-treinada ResNet-50. <br>  Como resultado, tr√™s classes de objetos s√£o detectadas em cada imagem do conjunto de dados: "superior", "inferior" e "vis√£o geral".  Depois de definir as classes "superior" e "inferior", simplesmente cortamos a figura em duas figuras separadas, que mais tarde ser√£o usadas como um par de exemplos positivos para o c√°lculo da perda de trig√™meos.  A qualidade de detectar objetos era bastante alta, a √∫nica reclama√ß√£o era que nem sempre era poss√≠vel encontrar uma classe na imagem.  Isso n√£o foi um problema para n√≥s, pois poder√≠amos aumentar facilmente o n√∫mero de imagens para previs√µes. <br><br><img src="https://habrastorage.org/webt/re/t2/bl/ret2blikjezyoibdvno8w9f8nic.png"><br>  <i>Um exemplo de detec√ß√£o das classes ‚Äúsuperior‚Äù e ‚Äúinferior‚Äù e corte da imagem.</i> <br><br>  Com esse tipo de divisor de imagens, tivemos a oportunidade de analisar qualquer aspecto da Internet e dividi-lo em componentes para uso em treinamento.  Para aumentar a amostra de treinamento e derrotar o problema com uma cobertura insuficiente de exemplos que surgiram durante o desenvolvimento da solu√ß√£o b√°sica, expandimos o conjunto de dados devido √†s imagens "cortadas" de um de nossos clientes.    ,        ‚Äú‚Äù, ‚Äú ‚Äù, ‚Äú‚Äù  .    ,      .             . <br><br>   ,           ,     . -,   backbone        ResNet-50,  . -,         -  ,        ‚Äú‚Äù .          ,       ‚Äú‚Äù   . <br><br><img src="https://habrastorage.org/webt/zt/ey/ic/zteyicg29iuubwu7y8adm8id7xm.png"><br> <i> ,      .    ‚Äî ,  .</i> <br><br>    :      ,   ,         .   ,        .       ‚Äú‚Äù  ‚Äú‚Äù,      ‚Äú‚Äù.          . <br><br><h2>   </h2><br>        .     ‚Äú‚Äù ResNet-50.       ‚Äú‚Äù  ,        ‚Äî  .         . <br><br><img src="https://habrastorage.org/webt/-0/u_/qj/-0u_qj7rrnciudumospo75ff9co.png"><br> <i> ,    ‚Äú‚Äù ResNet-50.   .</i> <br><br>     ResNet-50        ,    .      ‚Äî         threshold   .     ,   ,      .             . <br><br><h2>  AB- </h2><br>             -.        : ‚Äú     ,         ,       ‚Äî         -‚Äù.   : - ‚Äî   ,    (   )     .    Retail Rocket     -         (       ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  A/-   99%  -  ?</a> ¬ª).     -     . <br><br>                -.  ,              <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RecSys 2016</a> .               . ,    ,    ,         ,       .  ,   -   ,   . <br><br>          ,   .           ,       .         ,      .        -      . ,     ,    ,   ,  -    .        :              . <br><br>   -    ,      . -,    ,   ,     ,      . -,  ‚Äî  ,   ,    ,   ,         . ,        . ,     ,  ,    ‚Äú¬ª,   . <br><br>   : <br><br><ul><li>            ‚Äú‚Äù  ‚Äú‚Äù,       , ,  ,   . ,     ,      ,       . </li><li>        ,       .     proof-of-concept    ,        . </li></ul><br>      ,         ,       . ,         ,       . <br><br><h2>  AB- </h2><br>  ,    ,   -    .   ‚Äî      fashion.          .  ,          ,       .    ,    ,        . <br><br>      .      3 .         ,          95%. <br><br><img src="https://habrastorage.org/webt/a1/d2/u3/a1d2u3lfxuxejt-u-0e0is8tfj0.png"><br> <i>  . Related-9 ‚Äî   ‚Äú‚Äù  , Related ‚Äî    .</i> <br><br><img src="https://habrastorage.org/webt/ue/vf/lm/uevflmd-birf3m_bcryiyq1vp5m.png"><br> <i>   . Related-9   ‚Äú‚Äù  .         : Mann-Whitney Test  Bootstrap.       97%.</i> <br><br>            :    .      ,    ,  ,    ‚Äú‚Äù    CTR. ,  ,    CTR   ,      .  -    ,   -       -   ,        -.     ,       . <br><br><img src="https://habrastorage.org/webt/rz/lc/in/rzlcinclsxpuxr8olu3uvdihzcu.png" width="400"><br> <i>  CTR.     .   CTR  Related-9,   ‚Äú‚Äù  , ()   Related ‚Äî   (). CTR     (  ) ‚Äî    95%.</i> <br><br>  ,    ,   ,     ,   .      ,          ,    .      ,       ,        .                    . <br><br><h2>  Conclus√µes </h2><br>   ,     ,   .   ,  ,      .                 -  .   ,      ‚Äî    ‚Äî     ,   .  ,            .   ,     ,     ,     Retail Rocket. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como regra geral, ceteris paribus, lan√ßamos algo que √© mais simples e requer menos esfor√ßo de implementa√ß√£o, mesmo que "n√£o esteja na moda". </font><font style="vertical-align: inherit;">O mecanismo para extrair informa√ß√µes de imagens no n√≠vel do produto √© um processo bastante complicado, por isso decidimos deixar a pesquisa nessa dire√ß√£o por um tempo at√© que haja novas informa√ß√µes. </font><font style="vertical-align: inherit;">Por exemplo, a parte do in√≠cio a frio mudar√° significativamente ou outras informa√ß√µes importantes aparecer√£o. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alexander Anokhin, analista, foguete de varejo</font></font></i></b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt441366/">https://habr.com/ru/post/pt441366/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt441356/index.html">Como entender o c√≥digo "estrangeiro" e ingressar em uma nova equipe?</a></li>
<li><a href="../pt441358/index.html">Lan√ßou o primeiro lander lunar comercial da Beresheet</a></li>
<li><a href="../pt441360/index.html">Openshift - artesanato com chap√©u vermelho</a></li>
<li><a href="../pt441362/index.html">Guia do Usu√°rio Kibana. Visualiza√ß√£o. Parte 3</a></li>
<li><a href="../pt441364/index.html">Programa de confer√™ncias Lua em Moscou 2019</a></li>
<li><a href="../pt441368/index.html">Como √© a lua anteriormente invis√≠vel de Netuno?</a></li>
<li><a href="../pt441370/index.html">Prote√ß√£o sem medo. Seguran√ßa da rosca na ferrugem</a></li>
<li><a href="../pt441372/index.html">[Sexta-feira] Como fritar frango em termos de f√≠sica</a></li>
<li><a href="../pt441376/index.html">Al√©m da pureza: o que pode e o que n√£o pode reverter a membrana de osmose</a></li>
<li><a href="../pt441378/index.html">Pesquisadores do Google: para se proteger contra o Spectre requer uma altera√ß√£o na arquitetura do processador, os patches de software n√£o ajudar√£o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
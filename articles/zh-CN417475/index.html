<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍👩‍👦 👈🏽 💄 Glusterfs +纠删码：当您需要大量，便宜且可靠时 👨🏿‍⚕️ 🕑 👼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在俄罗斯几乎没有人拥有Glaster，任何经历都很有趣。 从上一期的讨论来看，我们拥有大型和工业产品，并且需求旺盛。 我谈到了将备份从企业存储迁移到Glusterfs的经验。 

 这还不够硬。 我们没有停下来，而是决定收集更严重的东西。 因此，在这里我们将讨论擦除编码，分片，重新平衡及其限制，压力...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Glusterfs +纠删码：当您需要大量，便宜且可靠时</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/croccloudteam/blog/417475/"> 在俄罗斯几乎没有人拥有Glaster，任何经历都很有趣。 从<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">上一期</a>的讨论来看，我们拥有大型和工业产品，并且需求旺盛。 我谈到了将备份从企业存储迁移到Glusterfs的经验。 <br><br> 这还不够硬。 我们没有停下来，而是决定收集更严重的东西。 因此，在这里我们将讨论擦除编码，分片，重新平衡及其限制，压力测试等问题。 <br><br><img src="https://habrastorage.org/webt/8t/ol/2d/8tol2dsnki7fr_jfcvhxwldsxdk.jpeg"><br><br><ul><li> 更多体积/亚体积理论 </li><li> 热备用 </li><li>  /愈/ he愈/平衡 </li><li> 重新启动3个节点后的结论（从不执行此操作） </li><li> 从不同的虚拟机以不同的速度进行记录以及分片开/关如何影响子卷负载？ </li><li> 光盘离开后重新平衡 </li><li> 快速重新平衡 </li></ul><br><a name="habracut"></a><h3> 你想要什么 </h3><br>  <b>任务很简单：</b>收集便宜但可靠的商店。 尽可能便宜，可靠-以便将我们自己的文件存储在其上进行出售不会感到恐惧。 再见 然后，经过长时间测试并备份到另一个存储系统（也包括客户端存储系统）。 <br><br>  <b>应用程序（顺序IO）</b> ： <br><br>  -备份 <br>  -测试基础架构 <br>  -测试大量媒体文件的存储。 <br> 我们在这里。 <br>  -战斗文件和严格的测试基础架构 <br>  -存储重要数据。 <br><br> 与上次一样，主要要求是Glaster实例之间的网络速度。 首先10G就可以了。 <br><br><h3> 理论：什么是分散体积？ </h3><br> 分散卷基于擦除编码（EC）技术，该技术可有效防止磁盘或服务器故障。 就像RAID 5或RAID 6，但不是。 它以一种方式存储每个砖块的文件的编码片段，使得仅需要存储在其余Briks中的片段的子集即可恢复文件。 在创建卷期间，管理员可以配置不丢失数据访问权而可能不可用的块数。 <br><br><img src="https://habrastorage.org/webt/rt/br/t1/rtbrt12s-0oyc9avxlsp32qzsus.png"><br><br><h3> 什么是子卷？ </h3><br>  GlusterFS术语中的子卷的实质与分布式卷一起体现。 在分布式分散擦除中，编码仅在超低音扬声器的框架中起作用。 并且在这种情况下，例如，使用分布式复制的数据将在低音炮的框架内进行复制。 <br> 它们每个都分布在不同的服务器上，这使它们可以自由丢失或同步输出。 在图中，服务器（物理）标记为绿色，子狼点缀。 它们每个都以磁盘（卷）的形式呈现给应用程序服务器： <br><br><img src="https://habrastorage.org/webt/w-/fp/dj/w-fpdjqguwigusvhtprq_6su3z8.png"><br><br> 可以确定，在6个节点上的分布式分散4 + 2配置看起来非常可靠，我们可以在每个低音炮中丢失任何2台服务器或2个磁盘，同时继续访问数据。 <br><br> 我们可以使用6个旧的DELL PowerEdge R510，它具有12个磁盘插槽和48x2TB 3.5 SATA驱动器。 原则上，如果市场上有一台服务器具有12个磁盘插槽，并且具有多达12 TB的驱动器，那么我们最多可以收集576 TB的可用空间的存储。 但是请不要忘记，即使最大的硬盘尺寸逐年增加，它们的性能仍然保持不变，而重建10-12TB的磁盘可能需要一周的时间。 <br><br><img src="https://habrastorage.org/webt/xo/ud/6f/xoud6fl7sdtknj7vrbn_5fgslpu.png"><br><br>  <b>批量创建：</b> <br> 有关如何准备积木的详细说明，请阅读我<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">以前的文章</a> <br><br><pre><code class="bash hljs">gluster volume create freezer disperse-data 4 redundancy 2 transport tcp \ $(<span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> {0..7} ; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> {sl051s,sl052s,sl053s,sl064s,sl075s,sl078s}:/<span class="hljs-built_in"><span class="hljs-built_in">export</span></span>/brick<span class="hljs-variable"><span class="hljs-variable">$i</span></span>/freezer ; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>)</code> </pre> <br> 我们创建了，但是我们并不急于启动和安装，因为我们仍然必须应用几个重要的参数。 <br><br>  <b>我们得到了：</b> <br><br><img src="https://habrastorage.org/webt/8j/il/e9/8jile9swj-qws3hgdjo3gtht3oo.png"><br><br> 一切看起来都很正常，但有一个警告。 <br><br>  <b>它包括在砖头上记录这样的体积：</b> <br> 文件被逐个放置在半狼中，并且没有均匀地分布在它们之间，因此，我们迟早会遇到文件的大小，而不是整个卷的大小。 我们可以在此存储库中放入的最大文件大小是低音炮的可用大小减去其上已占用的空间。 就我而言，小于8 Tb。 <br><br>  <b>怎么办</b>  <b>怎么样</b> <br> 通过分片或条带化卷可以解决此问题，但是，如实践所示，条带化的效果非常差。 <br><br> 因此，我们将尝试分片。 <br><br>  <b>分片的详细信息</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在这里</a> 。 <br><br>  <b>简而言之，分片是什么</b> ： <br> 放入一个卷中的每个文件将分为多个部分（碎片），这些部分相对均匀地排列在子狼中。 分片的大小由管理员指定，标准值为4 MB。 <br><br>  <b>创建卷之后但在开始之前打开分片</b> ： <br><br><pre> <code class="bash hljs">gluster volume <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> freezer features.shard on</code> </pre> <br>  <b>我们设置分片的大小（这是最佳选择吗？来自oVirt的Dudes建议使用512MB）</b> ： <br><br><pre> <code class="bash hljs">gluster volume <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> freezer features.shard-block-size 512MB</code> </pre> <br> 根据经验，事实证明，使用分散体积4 + 2的砖中碎片的实际大小等于碎片块大小/ 4，在我们的情况下为512M / 4 = 128M。 <br><br> 根据擦除编码逻辑的每个碎片将根据子世界框架中的砖块分解为：4 * 128M + 2 * 128M <br><br>  <b>绘制使用这种配置的gluster幸存的失败案例：</b> <br> 在这种配置下，我们可以承受同一子卷中2个节点或2个任何磁盘的故障。 <br><br> 为了进行测试，我们决定将结果存储放到我们的云下，然后从虚拟机运行。 <br><br> 我们从15个VM中打开顺序记录，然后执行以下操作。 <br><br>  <b>重新启动第一个节点：</b> <br>  17:09 <br> 它看起来不重要（通过ping.timeout参数〜5秒不可用）。 <br><br>  17:19 <br> 全面he愈。 <br> 修复条目的数量仅在增加，这可能是由于对集群的高级别写入。 <br><br>  17:32 <br> 决定关闭来自VM的记录。 <br> 治愈次数开始下降。 <br><br>  17:50 <br> 治愈了。 <br><br>  <b>重新引导2个节点：</b> <br><br>  <i>观察到与第一个节点相同的结果。</i> <br><br>  <b>重新启动3个节点：</b> <br>  <i>挂载点发出传输端点未连接，VM收到ioerror。</i> <i><br></i>  <i>打开节点后，Glaster恢复了自身，没有我们这边的干扰，治疗过程开始了。</i> <br><br> 但是15个虚拟机中有4个无法上升。 我在管理程序上看到错误： <br><br><pre> <code class="bash hljs">2018.04.27 13:21:32.719 ( volumes.py:0029): I: Attaching volume vol-BA3A1BE1 (/GLU/volumes/33/33e3bc8c-b53e-4230-b9be-b120079c0ce1) with attach <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> generic... 2018.04.27 13:21:32.721 ( qmp.py:0166): D: Querying QEMU: __com.redhat_drive_add({<span class="hljs-string"><span class="hljs-string">'file'</span></span>: u<span class="hljs-string"><span class="hljs-string">'/GLU/volumes/33/33e3bc8c-b53e-4230-b9be-b120079c0ce1'</span></span>, <span class="hljs-string"><span class="hljs-string">'iops_rd'</span></span>: 400, <span class="hljs-string"><span class="hljs-string">'media'</span></span>: <span class="hljs-string"><span class="hljs-string">'disk'</span></span>, <span class="hljs-string"><span class="hljs-string">'format'</span></span>: <span class="hljs-string"><span class="hljs-string">'qcow2'</span></span>, <span class="hljs-string"><span class="hljs-string">'cache'</span></span>: <span class="hljs-string"><span class="hljs-string">'none'</span></span>, <span class="hljs-string"><span class="hljs-string">'detect-zeroes'</span></span>: <span class="hljs-string"><span class="hljs-string">'unmap'</span></span>, <span class="hljs-string"><span class="hljs-string">'id'</span></span>: <span class="hljs-string"><span class="hljs-string">'qdev_1k7EzY85TIWm6-gTBorE3Q'</span></span>, <span class="hljs-string"><span class="hljs-string">'iops_wr'</span></span>: 400, <span class="hljs-string"><span class="hljs-string">'discard'</span></span>: <span class="hljs-string"><span class="hljs-string">'unmap'</span></span>})... 2018.04.27 13:21:32.784 ( instance.py:0298): E: Failed to attach volume vol-BA3A1BE1 to the instance: Device <span class="hljs-string"><span class="hljs-string">'qdev_1k7EzY85TIWm6-gTBorE3Q'</span></span> could not be initialized Traceback (most recent call last): File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.7/site-packages/ic/instance.py"</span></span>, line 292, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> emulation_started c2.qemu.volumes.attach(controller.qemu(), device) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.7/site-packages/c2/qemu/volumes.py"</span></span>, line 36, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> attach c2.qemu.query(qemu, drive_meth, drive_args) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.7/site-packages/c2/qemu/_init_.py"</span></span>, line 247, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> query <span class="hljs-built_in"><span class="hljs-built_in">return</span></span> c2.qemu.qmp.query(qemu.pending_messages, qemu.qmp_socket, <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>, args, suppress_logging) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.7/site-packages/c2/qemu/qmp.py"</span></span>, line 194, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> query message[<span class="hljs-string"><span class="hljs-string">"error"</span></span>].get(<span class="hljs-string"><span class="hljs-string">"desc"</span></span>, <span class="hljs-string"><span class="hljs-string">"Unknown error"</span></span>) QmpError: Device <span class="hljs-string"><span class="hljs-string">'qdev_1k7EzY85TIWm6-gTBorE3Q'</span></span> could not be initialized qemu-img: Could not open <span class="hljs-string"><span class="hljs-string">'/GLU/volumes/33/33e3bc8c-b53e-4230-b9be-b120079c0ce1'</span></span>: Could not <span class="hljs-built_in"><span class="hljs-built_in">read</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> determining its format: Input/output error</code> </pre><br>  <b>关闭分片后，硬付清3个节点</b> <br><br><pre> <code class="bash hljs">Transport endpoint is not connected (107) /GLU/volumes/e0/e0bf9a42-8915-48f7-b509-2f6dd3f17549: ERROR: cannot <span class="hljs-built_in"><span class="hljs-built_in">read</span></span> (Input/output error)</code> </pre> <br> 我们还会丢失数据，无法恢复。 <br><br>  <b>轻轻地分片偿还3个节点，会不会有数据损坏？</b> <br> 有，但是更少（巧合？），我丢失了30个驱动器中的3个。 <br><br>  <b>结论：</b> <br><br><ol><li> 这些文件的修复无限期停止，重新平衡无济于事。 我们得出的结论是，当第三个节点关闭时，正在进行活动记录的文件将永远丢失。 </li><li> 在生产环境中，切勿在4 + 2配置中重新加载超过2个节点！ </li><li> 如果您确实要重新引导3个以上的节点，如何不丢失数据？  P在安装点和/或停止音量时停止录制。 </li><li> 节点或积木应尽快更换。 为此，非常需要在每个节点中使用1-2 a的热备用砖，以便快速更换。 还有一个备用节点，带有备用节点，以防发生节点转储。 </li></ol><br><img src="https://habrastorage.org/webt/-m/rj/ti/-mrjtikde2imxdydeka4w-hvjjk.png"><br><br> 测试驱动器更换案例也非常重要 <br><br>  <b>船首驶离（圆盘）：</b> <b><br></b>  <b>17:20</b> <br> 我们敲开一块砖头： <br><br><pre> <code class="bash hljs">/dev/sdh 1.9T 598G 1.3T 33% /<span class="hljs-built_in"><span class="hljs-built_in">export</span></span>/brick6</code> </pre> <br>  <b>17:22</b> <br><pre> <code class="bash hljs">gluster volume replace-brick freezer sl051s:/<span class="hljs-built_in"><span class="hljs-built_in">export</span></span>/brick_spare_1/freezer sl051s:/<span class="hljs-built_in"><span class="hljs-built_in">export</span></span>/brick2/freezer commit force</code> </pre> <br> 您可以在更换积木时看到这样的缩水（来自1个来源的记录）： <br><br><img src="https://habrastorage.org/webt/jk/96/ns/jk96ns2kzhy0radczfpxlfpodso.png"><br><br> 更换过程很长，每个群集的记录级别很小，默认设置为1 TB，大约需要一天的时间才能恢复。 <br><br>  <b>可调治疗参数：</b> <br><br><pre> <code class="bash hljs">gluster volume <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> cluster.background-self-heal-count 20 <span class="hljs-comment"><span class="hljs-comment"># Default Value: 8 # Description: This specifies the number of per client self-heal jobs that can perform parallel heals in the background. gluster volume set cluster.heal-timeout 500 # Default Value: 600 # Description: time interval for checking the need to self-heal in self-heal-daemon gluster volume set cluster.self-heal-window-size 2 # Default Value: 1 # Description: Maximum number blocks per file for which self-heal process would be applied simultaneously. gluster volume set cluster.data-self-heal-algorithm diff # Default Value: (null) # Description: Select between "full", "diff". The "full" algorithm copies the entire file from source to # sink. The "diff" algorithm copies to sink only those blocks whose checksums don't match with those of # source. If no option is configured the option is chosen dynamically as follows: If the file does not exist # on one of the sinks or empty file exists or if the source file size is about the same as page size the # entire file will be read and written ie "full" algo, otherwise "diff" algo is chosen. gluster volume set cluster.self-heal-readdir-size 2KB # Default Value: 1KB # Description: readdirp size for performing entry self-heal</span></span></code> </pre> <br>  <i>选项：disperse.background-heals</i> <i><br></i>  <i>默认值：8</i> <i><br></i>  <i>说明：此选项可用于控制并行愈合的次数</i> <i><br><br></i>  <i>选项：disperse.heal-wait-qlength</i> <i><br></i>  <i>默认值：128</i> <i><br></i>  <i>说明：此选项可用于控制可以等待的治疗次数</i> <i><br><br></i>  <i>选项：disperse.shd-max-threads</i> <i><br></i>  <i>默认值：1</i> <i><br></i>  <i>说明：每个本地砖可以执行SHD并行修复的最大数量。</i>  <i>这样可以大大减少恢复时间，但是如果您没有支持该功能的存储硬件，也可以压垮您的积木。</i> <i><br><br></i>  <i>选项：disperse.shd-wait-qlength</i> <i><br></i>  <i>默认值：1024</i> <i><br></i>  <i>描述：此选项可用于控制每个子卷可以SHD等待的治愈次数</i> <i><br><br></i>  <i>选项：分散.cpu扩展名</i> <i><br></i>  <i>默认值：自动</i> <i><br></i>  <i>说明：强制使用cpu扩展名来加速galois场计算。</i> <i><br><br></i>  <i>选项：分散。自愈窗口大小</i> <i><br></i>  <i>默认值：1</i> <i><br></i>  <i>说明：每个文件可同时应用自我修复过程的最大块数（128KB）。</i> <br><br> 站着： <br><br><pre> <code class="bash hljs">disperse.shd-max-threads: 6 disperse.self-heal-window-size: 4 cluster.self-heal-readdir-size: 2KB cluster.data-self-heal-algorithm: diff cluster.self-heal-window-size: 2 cluster.heal-timeout: 500 cluster.background-self-heal-count: 20 cluster.disperse-self-heal-daemon: <span class="hljs-built_in"><span class="hljs-built_in">enable</span></span> disperse.background-heals: 18</code> </pre> <br> 使用新参数，可在8小时内完成1 TB数据的处理（快3倍！） <br><br>  <b>令人不快的时刻是结果比以前更大了</b> <br><br>  <b>原为：</b> <pre> <code class="bash hljs">Filesystem Size Used Avail Use% Mounted on /dev/sdd 1.9T 645G 1.2T 35% /<span class="hljs-built_in"><span class="hljs-built_in">export</span></span>/brick2</code> </pre> <br>  <b>成为：</b> <pre> <code class="bash hljs">Filesystem Size Used Avail Use% Mounted on /dev/sdj 1.9T 1019G 843G 55% /<span class="hljs-built_in"><span class="hljs-built_in">export</span></span>/hot_spare_brick_0</code> </pre> <br> 有必要了解。 可能事情是使薄磁盘膨胀。 随后更换增加的砖块，尺寸保持不变。 <br><br>  <b>重新平衡：</b> <br>  <i>在扩展（或不迁移数据）卷（分别使用add-brick和remove-brick命令）之后，您需要在服务器之间重新平衡数据。</i>  <i>在非复制卷中，所有块均应准备好以执行替换块操作（启动选项）。</i>  <i>在复制的卷中，副本中的至少一块砖应该向上。</i> <br><br>  <b>调整再平衡：</b> <br><br>  <i>选项：cluster.rebal-throttle</i> <i><br></i>  <i>默认值：正常</i> <i><br></i>  <i>说明：设置重新平衡操作期间节点上允许的最大并行文件迁移数。</i>  <i>默认值为正常，最多允许[[$（处理单位）-4）/ 2），2]个文件到b</i> <i><br></i>  <i>一次迁移。</i>  <i>惰性将一次仅允许迁移一个文件，而积极的将允许最多[[$（处理单位）-4）/ 2），4]</i> <br><br>  <i>选项：cluster.lock-migration</i> <i><br></i>  <i>默认值：关闭</i> <i><br></i>  <i>说明：如果启用此功能，将在重新平衡期间迁移与文件关联的posix锁</i> <br><br>  <i>选项：cluster.weighted-rebalance</i> <i><br></i>  <i>默认值：开</i> <i><br></i>  <i>说明：启用后，文件将以与它们的大小成正比的概率分配给砖块。</i>  <i>否则，所有积木将具有相同的概率（旧版行为）。</i> <br><br>  <b>比较编写，然后读取相同的参数（性能测试的更详细结果-在PM中）：</b> <br><br><pre> <code class="bash hljs">fio --fallocate=keep --ioengine=libaio --direct=1 --buffered=0 --iodepth=1 --bs=64k --name=<span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --rw=write/<span class="hljs-built_in"><span class="hljs-built_in">read</span></span> --filename=/dev/vdb --runtime=6000</code> </pre><br><img src="https://habrastorage.org/webt/fw/up/j0/fwupj0gj9m6vn25bepslaaox01e.png"><br><br><img src="https://habrastorage.org/webt/xi/yf/pd/xiyfpdsecqbfc52fudoz4nwklty.png"><br><br><img src="https://habrastorage.org/webt/nh/xp/es/nhxpestbf-gfjkcwogumbbqabc4.jpeg"><br><br>  <b>如果有意思，请将rsync速度与到达Glaster节点的流量进行比较：</b> <br><br><img src="https://habrastorage.org/webt/6i/cz/ox/6iczoxword1qaauuhkwm3vfkk-q.png"><br><br><img src="https://habrastorage.org/webt/42/ka/eq/42kaeqkdbcuzhq8rwdrqybgkc5u.png"><br><br>  <i>可以看出，大约170 MB / s /流量到110 MB / s /有效负载。</i>  <i>事实证明，这是额外流量的33％，是擦除编码冗余的1/3。</i> <br><br>  <b>在有负载和没有负载的情况下，服务器端的内存消耗不会改变：</b> <br><br><img src="https://habrastorage.org/webt/nz/sz/zc/nzszzcu0eqrck4gpmhvazhm8x7i.png"><br><img src="https://habrastorage.org/webt/nz/sz/zc/nzszzcu0eqrck4gpmhvazhm8x7i.png"><br><br>  <b>群集主机上的负载具有最大的卷负载：</b> <br><br><img src="https://habrastorage.org/webt/vb/u3/3c/vbu33cgi-rmgjn7c2w1guz5ps3c.png"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN417475/">https://habr.com/ru/post/zh-CN417475/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt486156/index.html">Como eu ensinei, e depois escrevi um manual de treinamento em Python</a></li>
<li><a href="../pt486158/index.html">Visualização da tradução automática neural (modelos seq2seq com mecanismo de atenção)</a></li>
<li><a href="../pt486164/index.html">Coronavírus 2019-nCoV. Perguntas frequentes sobre proteção respiratória e desinfecção</a></li>
<li><a href="../pt486174/index.html">Tenho rotatividade zero</a></li>
<li><a href="../zh-CN417473/index.html">使用DRBD9和Proxmox的可信存储（第1部分：NFS）</a></li>
<li><a href="../zh-CN417477/index.html">热桌</a></li>
<li><a href="../zh-CN417479/index.html">在Go中更快地自己动手字符串连接</a></li>
<li><a href="../zh-CN417481/index.html">关于JavaScript ES6中的生成器，以及为什么可以选择研究它们</a></li>
<li><a href="../zh-CN417483/index.html">JS框架比较：React，Vue和Hyperapp</a></li>
<li><a href="../zh-CN417485/index.html">[书签] Linux网络工具的系统管理员备忘单</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¶ğŸ¼ ğŸ¤¦ğŸ» ğŸ¥¦ 63 core dikunci oleh tujuh instruksi ğŸ• ğŸŒ˜ ğŸ‘—</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sepertinya saya memiliki kebiasaan menulis tentang mesin yang kuat , di mana banyak core menganggur karena kunci yang salah. Jadi ... Ya. Lagi tentang...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>63 core dikunci oleh tujuh instruksi</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472552/"> Sepertinya saya memiliki kebiasaan menulis tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mesin yang kuat</a> , di mana banyak core <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menganggur</a> karena kunci yang salah.  Jadi ... Ya.  Lagi tentang itu. <br><br>  Kisah ini sangat mengesankan.  Bahkan, seberapa sering Anda memiliki satu putaran benang selama beberapa detik dalam siklus tujuh perintah, memegang kunci yang menghentikan pekerjaan 63 prosesor lainnya?  Ini luar biasa, dalam arti yang mengerikan. <br><br>  Bertentangan dengan kepercayaan umum, saya sebenarnya tidak memiliki mesin dengan 64 prosesor logis, dan saya belum pernah melihat masalah khusus ini.  Tetapi teman saya menabraknya, <s><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kutu buku ini mengaitkan saya,</a></s> dia meminta bantuan, dan saya memutuskan bahwa masalahnya cukup menarik.  Dia mengirim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jejak ETW</a> dengan informasi yang cukup sehingga pikiran kolektif di Twitter dengan cepat menyelesaikan masalah. <br><a name="habracut"></a><br>  Keluhan teman itu cukup sederhana: dia mengumpulkan bangunan menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ninja</a> .  Biasanya, ninja melakukan pekerjaan yang sangat baik untuk meningkatkan beban, terus mendukung proses n + 2 untuk menghindari downtime.  Tapi di sini penggunaan CPU dalam 17 detik pertama perakitan terlihat seperti ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/708/9d6/808/7089d68083b016688e6ec980981f52a4.png"><br><br>  Jika Anda melihat lebih dekat (lelucon), Anda dapat melihat garis tipis di mana total beban CPU turun dari 100% menjadi 0% dalam beberapa detik.  Hanya dalam setengah detik, beban dikurangi dari 64 menjadi dua atau tiga utas.  Berikut adalah fragmen yang diperbesar dari salah satu jatuh ini - detik ditandai di sepanjang sumbu horizontal: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/14a/f7a/6c3/14af7a6c3dbdb7563fa6e316ad7a21e2.png"><br><br>  Pikiran pertama adalah bahwa ninja tidak dapat dengan cepat membuat proses.  Saya telah melihat ini berkali-kali, biasanya karena intervensi perangkat lunak antivirus.  Tetapi ketika saya mengurutkan grafik pada akhir waktu, saya menemukan bahwa selama crash seperti itu tidak ada proses yang diselesaikan, jadi ninja tidak bisa disalahkan. <br><br>  Tabel <i>Penggunaan CPU (Precise)</i> sangat ideal untuk mengidentifikasi penyebab downtime.  Log semua sakelar konteks disimpan di sana, termasuk catatan akurat dari setiap permulaan aliran, termasuk tempat dan batas waktu. <br><br>  Kuncinya adalah bahwa tidak ada yang salah dengan downtime.  Masalah muncul ketika kita benar-benar ingin utas untuk melakukan pekerjaan, tetapi sebaliknya itu menganggur.  Karena itu, Anda perlu memilih saat-saat downtime tertentu. <br><br>  Saat menganalisis, penting untuk memahami bahwa pengalihan konteks terjadi ketika utas melanjutkan operasi.  Jika kita melihat tempat-tempat itu ketika beban prosesor mulai turun, kita tidak akan menemukan apa pun.  Sebagai gantinya, fokuslah pada saat sistem mulai bekerja kembali.  Fase jejak ini bahkan lebih dramatis.  Sementara penurunan beban CPU membutuhkan waktu setengah detik, proses kebalikan dari satu utas yang digunakan menjadi beban penuh hanya membutuhkan waktu dua belas milidetik!  Grafik di bawah ini cukup diperbesar, namun transisi dari idle ke load hampir merupakan garis vertikal: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d7f/cd4/cc6/d7fcd4cc68e55c5d6c7ff16cc8a5b32d.png"><br><br>  Saya memperbesar menjadi dua belas milidetik dan menemukan 500 switch konteks, analisis yang cermat diperlukan di sini. <br><br>  Tabel saklar konteks memiliki banyak kolom yang telah saya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasikan di sini</a> .  Ketika suatu proses membeku, untuk menemukan alasannya, saya melakukan pengelompokan berdasarkan proses baru, utas baru, tumpukan utas baru, dll. ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dibahas di sini</a> ), tetapi ini tidak bekerja pada ratusan proses yang terhenti.  Jika saya mempelajari salah satu proses yang salah, jelas bahwa itu disiapkan oleh proses sebelumnya, yang disiapkan oleh yang sebelumnya, dan saya akan memindai rantai panjang untuk menemukan tautan pertama yang (mungkin) memegang kunci penting untuk waktu yang lama. <br><br>  Jadi, saya mencoba tata letak kolom yang berbeda dalam program: <br><br><ul><li>  <i>Waktu Switch-In</i> (ketika perpindahan konteks terjadi) <br></li><li>  <i>Proses Mempersiapkan</i> (yang melepaskan kunci setelah menunggu) <br></li><li>  <i>Proses Baru</i> (yang mulai bekerja) <br></li><li>  <i>Waktu Sejak Terakhir</i> (berapa lama proses baru telah menunggu) </li></ul><br>  Ini memberikan daftar sakelar konteks yang disusun berdasarkan waktu dengan catatan siapa yang menyiapkan siapa dan berapa lama proses siap untuk bekerja. <br><br>  Ternyata ini sudah cukup.  Tabel di bawah berbicara sendiri jika Anda tahu cara membacanya.  Beberapa sakelar konteks pertama tidak menarik, karena waktu tunggu untuk proses baru (Waktu Sejak Terakhir) cukup kecil, tetapi pada baris yang disorot (# 4) hal yang menarik dimulai: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0d7/106/72f/0d710672f2cafc1bd7a2953a42ea55dd.png"><br><br>  Baris ini mengatakan bahwa <i>System (4)</i> menyiapkan <i>cl. Exe (3032)</i> , yang menunggu 3,368 detik.  Baris berikutnya mengatakan bahwa dalam waktu kurang dari 0,1 ms, <i>kr. Exe (3032)</i> menyiapkan <i>cl.exe (16232)</i> , yang menunggu 3,367 detik.  Dan sebagainya. <br><br>  Beberapa sakelar konteks, seperti pada baris # 7, tidak termasuk dalam rantai tunggu, tetapi hanya mencerminkan pekerjaan lain dalam sistem, tetapi secara umum rantai tersebut direntangkan ke banyak elemen. <br><br>  Ini berarti bahwa semua proses ini menunggu pelepasan kunci yang sama.  Ketika proses <i>Sistem (4)</i> melepaskan kunci (setelah menahan selama 3.368 detik!), Proses menunggu, pada gilirannya, menangkapnya, melakukan pekerjaan kecil mereka dan meneruskan kunci.  Antrian tunggu memiliki sekitar seratus proses, yang menunjukkan tingkat pengaruh satu kunci. <br><br>  Sebuah studi kecil tentang <i>Ready Thread Stacks</i> menunjukkan bahwa sebagian besar harapan berasal dari <i>KernelBase.dllWriteFile</i> .  Saya meminta WPA untuk menampilkan penelepon fungsi ini, dengan pengelompokan.  Di sana Anda dapat melihat bahwa dalam 12 milidetik dari katarsis ini 174 utas keluar dari <i>WriteFile</i> menunggu, dan mereka menunggu rata-rata 1.184 detik: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c63/a77/73d/c63a7773d08b42f2def485247d57e916.png"><br>  <i><font color="gray">174 utas menunggu WriteFile, waktu tunggu rata-rata 1.184 detik</font></i> <br><br>  Ini adalah kelambatan yang luar biasa, dan pada kenyataannya, bahkan tidak seluruh masalah, karena banyak utas dari fungsi lain, seperti <i>KernelBase.dll! GetQueuedCompletionStatus,</i> mengharapkan rilis kunci yang sama. <br><br><h2>  Apa yang Sistem Lakukan (4) </h2><br>  Pada titik ini, saya tahu bahwa perkembangan build terhenti karena semua proses compiler dan yang lain mengharapkan <i>WriteFile</i> , karena <i>System (4)</i> memegang kunci.  Kolom <i>Id Thread Ready</i> lainnya menunjukkan bahwa thread 3276 melepaskan kunci dalam proses sistem. <br><br>  Selama semua "hang" rakitan, thread 3276 adalah 100% dimuat, jadi jelas bahwa ia melakukan beberapa pekerjaan pada CPU sambil memegang kunci.  Untuk mengetahui di mana waktu CPU dihabiskan, mari kita lihat <i>grafik Penggunaan CPU (Sampel)</i> untuk thread 3276. Data penggunaan CPU secara mengejutkan jelas.  Hampir sepanjang waktu dibutuhkan kerja satu fungsi <i>ntoskrnl.exe! RtlFindNextForwardRunClear</i> (jumlah sampel ditunjukkan dalam kolom dengan angka): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0fc/0ce/2fc/0fc0ce2fc4485818ba45f9504f4c8181.png"><br>  <i><font color="gray">Tumpukan panggilan mengarah ke ntoskrnl.exe! RtlFindNextForwardRunClear</font></i> <br><br>  Melihat tumpukan utas <i>Readying Thread Id</i> mengkonfirmasi bahwa <i>NtfsCheckpointVolume</i> melepaskan kunci setelah 3,368 s: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a43/225/a97/a43225a974de7651a6b51dc04b339364.png"><br>  <i><font color="gray">Panggil Stack dari NtfsCheckpointVolume ke ExReleaseResourceLite</font></i> <br><br>  Pada saat ini, bagi saya sepertinya sudah waktunya untuk menggunakan pengetahuan yang kaya dari pengikut saya di Twitter, jadi saya memposting <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertanyaan ini</a> dan menunjukkan tumpukan panggilan penuh.  Tweet dengan pertanyaan seperti itu bisa sangat efektif jika Anda memberikan informasi yang cukup. <br><br>  Dalam hal ini, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jawaban yang tepat</a> dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Caitlin Gadd</a> datang dengan sangat cepat, bersama dengan banyak saran hebat lainnya.  Dia mematikan fitur pemulihan sistem - dan tiba-tiba bangunannya dua atau tiga kali lebih cepat! <br><br><h2>  Tapi tunggu, lebih jauh lebih baik </h2><br>  Memblokir eksekusi di seluruh sistem selama 3+ detik cukup mengesankan, tetapi situasinya bahkan lebih mengesankan jika Anda menambahkan kolom <i>Alamat</i> ke tabel <i>Penggunaan CPU (Sampel)</i> dan mengurutkannya.  Ini menunjukkan di mana tepatnya di sampel <i>RtlFindNextForwardRunClear</i> dapatkan - dan 99% di antaranya jatuh pada satu instruksi! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aec/1e3/9b6/aec1e39b65cddb3473242514e7cea1a9.png"><br><br>  Saya mengambil file <i>ntoskrnl.exe</i> dan <i>ntkrnlmp.pdb</i> (versi yang sama dengan teman saya) dan menjalankan <code>dumpbin /disasm</code> untuk melihat fungsi yang diminati assembler.  Digit pertama dari alamat berbeda karena kode bergerak saat boot, tetapi empat nilai hex terakhir adalah sama (tidak berubah setelah ASLR): <br><br><pre>  RtlFindNextForwardRunClear:
 ...
 14006464F: 4C 3B C3 cmp r8, rbx
 140064652: 73 0F jae 0000000140064663
 140064654: 41 39 28 cmp dword ptr [r8], ebp
 140064657: 75 0A jne 0000000140064663
 140064659: 49 83 C0 04 tambahkan r8.4
 14006465D: 41 83 C1 20 tambahkan r9d, 20j
 140064661: EB EC jmp 000000014006464F
 ... </pre><br>  Kita melihat bahwa instruksi pada ... 4657 termasuk dalam siklus tujuh instruksi, yang ditemukan dalam sampel lain.  Jumlah sampel tersebut ditunjukkan di sebelah kanan: <br><br><pre>  RtlFindNextForwardRunClear:
 ...
 14006464F: 4C 3B C3 cmp r8, rbx 4
 140064652: 73 0F jae 0000000140064663 41
 140064654: 41 39 28 cmp dword ptr [r8], ebp     
 140064657: 75 0A jne 0000000140064663 7498
 140064659: 49 83 C0 04 tambahkan r8.4 2
 14006465D: 41 83 C1 20 tambahkan r9d, 20h 1
 140064661: EB EC jmp 000000014006464F 1
 ... </pre><br>  Sebagai latihan untuk pembaca, mari kita tinggalkan interpretasi jumlah sampel pada prosesor superscalar dengan pelaksanaan instruksi yang luar biasa, meskipun beberapa ide bagus dapat ditemukan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ini</a> .  Dalam hal ini, kami memiliki AMD Ryzen Threadripper 2990WX 32-core.  Rupanya, fungsi prosesor dari Micro-Up Fusion dengan pelaksanaan lima instruksi pada suatu waktu sebenarnya memungkinkan setiap siklus diselesaikan pada jne, karena instruksi setelah instruksi yang paling mahal masuk ke dalam sebagian besar gangguan dalam pemilihan. <br><br>  Jadi ternyata sebuah mesin dengan 64 prosesor logis berhenti dalam siklus tujuh perintah dalam proses sistem, sambil memegang kunci NTFS yang vital, yang diperbaiki dengan menonaktifkan pemulihan sistem. <br><br><h2>  Coda </h2><br>  Tidak jelas mengapa kode ini berperilaku buruk pada mesin khusus ini.  Saya kira ini terkait dengan distribusi data pada disk 2 TB yang hampir kosong.  Ketika pemulihan sistem dihidupkan kembali, masalahnya juga kembali, tetapi tidak begitu parah.  Mungkin ada semacam patologi untuk disk dengan fragmen besar ruang kosong? <br><br>  Pengikut lain di Twitter menyebutkan bug Volume Shadow Copy dari Windows 7, yang memungkinkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">eksekusi selama O (n ^ 2)</a> .  Kesalahan ini diduga diperbaiki di Windows 8, tetapi mungkin telah dipertahankan dalam beberapa bentuk.  Jejak stack saya dengan jelas menunjukkan bahwa <i>VspUpperFindNextForwardRunClearLimited</i> (menemukan bit yang digunakan di area 16 megabyte ini) memanggil <i>VspUpperFindNextForwardRunClear</i> (mencari bit yang digunakan berikutnya di mana saja, tetapi tidak mengembalikannya jika berada di luar area yang ditentukan).  Tentu saja, ini menyebabkan rasa deja vu.  Seperti yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">baru-baru ini</a> saya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">katakan</a> , O (n ^ 2) adalah titik lemah dari algoritma yang tidak dapat diukur.  Dua faktor bertepatan di sini: kode semacam itu cukup cepat untuk masuk ke produksi, tetapi cukup lambat untuk menghentikan produksi ini. <br><br>  Ada laporan bahwa masalah serupa terjadi dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penghapusan file besar</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">besaran</a> , tetapi penelusuran kami tidak menunjukkan banyak penghapusan, jadi masalahnya, ternyata, bukan itu. <br><br>  Sebagai kesimpulan, saya akan menduplikasi jadwal beban CPU di seluruh sistem dari awal artikel, tetapi kali ini menunjukkan penggunaan CPU oleh proses masalah <i>Sistem</i> (berwarna hijau di bawah).  Dalam gambaran seperti itu, masalahnya sangat jelas.  Proses sistem secara teknis terlihat pada grafik atas, tetapi pada skala ini mudah untuk dilewatkan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4fb/ca1/9ff/4fbca19ffabb57dd7f17d40417eee0ca.png"><br><br>  Meskipun masalah terlihat jelas pada grafik, sebenarnya tidak membuktikan apa-apa.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Seperti yang mereka katakan</a> , korelasi bukanlah hubungan sebab akibat.  Hanya analisis peristiwa pengalihan konteks yang menunjukkan bahwa streaming inilah yang memegang kunci kritis - dan kemudian Anda dapat yakin bahwa kami telah menemukan penyebab sebenarnya, dan bukan hanya korelasi acak. <br><br><h2>  Pertanyaan </h2><br>  Seperti biasa, saya mengakhiri penyelidikan ini dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">panggilan untuk memberi nama thread yang lebih baik</a> .  Proses sistem memiliki lusinan utas, banyak di antaranya memiliki tujuan khusus, dan tidak ada yang memiliki nama.  Utas sistem tersibuk dalam penelusuran ini adalah <i>MiZeroPageThread</i> .  Saya berulang kali terjun ke tumpukannya, dan setiap kali saya ingat itu tidak menarik.  Kompilator VC ++ juga tidak memberi nama utasnya.  Tidak perlu banyak waktu untuk mengubah nama aliran, dan ini sangat berguna.  Berikan saja namanya.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sederhana saja</a> .  Chromium bahkan menyertakan alat untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mencantumkan nama aliran dalam suatu proses</a> . <br><br>  Jika seseorang dari tim NTFS di Microsoft ingin membicarakan topik ini, beri tahu saya, dan saya dapat menghubungkan Anda dengan penulis laporan asli dan memberikan jejak ETW. <br><br><h2>  Referensi </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Utas Twitter</a> asli <br></li><li>  Pengumuman pos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Twitter</a> <br></li><li>  Diskusi di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Hacker News</a> <br></li><li>  Diskusi tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Reddit</a> <br></li><li>  Kemungkinan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Windows / NTFS</a> relevan </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id472552/">https://habr.com/ru/post/id472552/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id472536/index.html">Smart IdReader SDK - menanamkan pengakuan dalam proyek-proyek dalam Python dan PHP</a></li>
<li><a href="../id472540/index.html">Mereka bangun! (n.- kisah, bagian 2, dan yang terakhir)</a></li>
<li><a href="../id472544/index.html">Trik Pemasaran Pornhub: Apa yang Diceritakan Situs Web Paling Menyentuh Dewasa Ini</a></li>
<li><a href="../id472548/index.html">Bagaimana kami pergi ke pasar (dan tidak mencapai sesuatu yang istimewa)</a></li>
<li><a href="../id472550/index.html">Meluncurkan Bisnis TI: Waralaba Teknologi Top 4 tahun 2019</a></li>
<li><a href="../id472556/index.html">Rahasia kebahagiaan karyawan adalah sifat alami di kantor?</a></li>
<li><a href="../id472560/index.html">Pengujian Gestalt: pendekatan baru untuk optimasi milis berdasarkan teori Bayesian dan pembelajaran mesin</a></li>
<li><a href="../id472562/index.html">Tren Keuangan: Perusahaan Besar Membutuhkan Semakin Banyak Profesional TI</a></li>
<li><a href="../id472566/index.html">Neraka pribadi penulis Fraerman, atau Tale of First Love</a></li>
<li><a href="../id472568/index.html">Apache Ignite Zero Deployment: tepatnya Zero?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüîß ‚úäüèø üïå RabbitMQ vs. Kafka: Verwenden von Kafka in ereignisorientierten Anwendungen üë®üèæ‚Äçüíº ‚è∞ üìè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In einem fr√ºheren Artikel haben wir uns die in RabbitMQ verwendeten Muster und Topologien angesehen. In diesem Teil wenden wir uns an Kafka und vergle...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ vs. Kafka: Verwenden von Kafka in ereignisorientierten Anwendungen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/418389/"><p>  In einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fr√ºheren Artikel haben</a> wir uns die in RabbitMQ verwendeten Muster und Topologien angesehen.  In diesem Teil wenden wir uns an Kafka und vergleichen es mit RabbitMQ, um einige Ideen zu ihren Unterschieden zu erhalten.  Es sollte ber√ºcksichtigt werden, dass ereignisorientierte Anwendungsarchitekturen eher verglichen werden als Datenverarbeitungs-Pipelines, obwohl die Grenze zwischen diesen beiden Konzepten in diesem Fall eher verschwommen ist.  Im Allgemeinen ist dies eher ein Spektrum als eine klare Trennung.  Unser Vergleich konzentriert sich lediglich auf den Teil dieses Spektrums, der sich auf ereignisgesteuerte Anwendungen bezieht. </p><br><p><img src="https://habrastorage.org/webt/fu/xp/vw/fuxpvw1pzsm4miouvpbwo7qxq-m.png"></p><a name="habracut"></a><br><p>  Der erste Unterschied besteht darin, dass die von RabbitMQ f√ºr die Arbeit mit Nachrichten mit toten Buchstaben in Kafka verwendeten Mechanismen zum Wiederholen und Schlummern von Nachrichten bedeutungslos sind.  In RabbitMQ sind Nachrichten tempor√§r, werden √ºbertragen und verschwinden.  Daher ist das erneute Hinzuf√ºgen ein absolut realer Anwendungsfall.  Und in Kafka steht das Magazin im Mittelpunkt.  Das L√∂sen von Zustellungsproblemen durch erneutes Senden einer Nachricht an die Warteschlange ist nicht sinnvoll und schadet nur dem Journal.  Einer der Vorteile ist die garantierte klare Verteilung der Nachrichten auf die Partitionen des Journals. Wiederholte Nachrichten verwirren ein gut organisiertes Schema.  In RabbitMQ k√∂nnen Sie bereits Nachrichten an die Warteschlange senden, mit der ein Empf√§nger arbeitet, und auf der Kafka-Plattform gibt es ein Journal f√ºr alle Empf√§nger.  Verz√∂gerungen bei der Zustellung und Probleme bei der Zustellung von Nachrichten schaden dem Betrieb des Journals nicht sehr, aber Kafka enth√§lt keine integrierten Verz√∂gerungsmechanismen. </p><br><p>  Wie Sie Nachrichten auf der Kafka-Plattform erneut √ºbermitteln, wird im Abschnitt √ºber Messaging-Schemata erl√§utert. </p><br><p>  Der zweite gro√üe Unterschied, der sich auf m√∂gliche Messaging-Schemata auswirkt, besteht darin, dass RabbitMQ Nachrichten viel weniger speichert als Kafka.  Wenn eine Nachricht bereits in RabbitMQ an den Empf√§nger √ºbermittelt wurde, wird sie gel√∂scht, ohne eine Spur ihrer Existenz zu hinterlassen.  In Kafka wird jede Nachricht in einem Protokoll gespeichert, bis sie gel√∂scht wird.  Die H√§ufigkeit der Bereinigung h√§ngt von der verf√ºgbaren Datenmenge, dem Speicherplatz ab, den Sie ihnen zuweisen m√∂chten, und den von Ihnen bereitgestellten Messaging-Schemata. Sie k√∂nnen das Zeitfenster verwenden, in dem Nachrichten f√ºr einen bestimmten Zeitraum gespeichert werden: die letzten Tage / Wochen / Monate. </p><br><p>  Auf diese Weise erm√∂glicht Kafka dem Empf√§nger, fr√ºhere Nachrichten erneut anzuzeigen oder zu erfassen.  Es sieht aus wie eine Technologie zum Senden von Nachrichten, obwohl es nicht ganz so funktioniert wie in RabbitMQ. </p><br><p>  Wenn RabbitMQ Nachrichten verschiebt und leistungsstarke Elemente zum Erstellen komplexer Routing-Schemata bereitstellt, speichert Kafka den aktuellen und vorherigen Status des Systems.  Diese Plattform kann als Quelle f√ºr zuverl√§ssige historische Daten verwendet werden, da RabbitMQ dies nicht kann. </p><br><h3>  Beispiel f√ºr ein Messaging-Schema auf der Kafka-Plattform <br></h3><br><p> Das einfachste Beispiel f√ºr die Verwendung von RabbitMQ und Kafka ist die Verbreitung von Informationen gem√§√ü dem Schema ‚ÄûHerausgeber-Abonnent‚Äú.  Ein oder mehrere Herausgeber f√ºgen dem partitionierten Protokoll Nachrichten hinzu, und diese Nachrichten werden vom Abonnenten einer oder mehrerer Abonnentengruppen empfangen. </p><br><p><img src="https://habrastorage.org/webt/rx/lw/56/rxlw56hzrjigugjyiiu01avpxho.png"><br>  <em>Abbildung 1. Mehrere Herausgeber senden Nachrichten an das partitionierte Protokoll, und mehrere Empf√§ngergruppen empfangen sie.</em> </p><br><p>  Wenn Sie nicht n√§her darauf eingehen, wie der Herausgeber Nachrichten an die erforderlichen Abschnitte des Journals sendet und wie Empf√§ngergruppen untereinander koordiniert werden, unterscheidet sich dieses Schema nicht von der in RabbitMQ verwendeten Fanout-Topologie (Forked Exchange). <br>  In einem fr√ºheren Artikel wurden alle RabbitMQ-Messaging-Schemata und -Topologien erl√§utert.  Vielleicht dachten Sie irgendwann: "Ich brauche nicht alle diese Schwierigkeiten, ich m√∂chte nur Nachrichten in der Warteschlange senden und empfangen", und die Tatsache, dass Sie das Magazin auf fr√ºhere Positionen zur√ºckspulen k√∂nnen, sprach √ºber die offensichtlichen Vorteile von Kafka. </p><br><p>  F√ºr Menschen, die an die traditionellen Funktionen von Warteschlangensystemen gew√∂hnt sind, ist die M√∂glichkeit, die Uhr zur√ºckzustellen und das Ereignisprotokoll in die Vergangenheit zur√ºckzuspulen, erstaunlich.  Diese Eigenschaft (verf√ºgbar √ºber das Protokoll anstelle der Warteschlange) ist sehr n√ºtzlich, um Fehler zu beheben.  Ich (der Autor des englischen Artikels) habe vor 4 Jahren als technischer Manager der Server-System-Support-Gruppe angefangen, f√ºr meinen derzeitigen Kunden zu arbeiten.  Wir hatten mehr als 50 Anwendungen, die √ºber MSMQ Echtzeitinformationen zu Gesch√§ftsereignissen erhielten, und das √úbliche war, dass das System einen Fehler in der Anwendung erst am n√§chsten Tag erkannte.  Leider verschwanden die Nachrichten h√§ufig, aber normalerweise konnten wir die Anfangsdaten von einem Drittanbieter-System abrufen und Nachrichten nur an den ‚ÄûAbonnenten‚Äú weiterleiten, der das Problem hatte.  Dazu mussten wir eine Messaging-Infrastruktur f√ºr die Empf√§nger erstellen.  Und wenn wir die Kafka-Plattform h√§tten, w√§re es nicht schwieriger, einen solchen Job zu erledigen, als den Link zum Speicherort der zuletzt empfangenen Nachricht f√ºr die Anwendung zu √§ndern, in der der Fehler aufgetreten ist. </p><br><h3 id="integraciya-dannyh-v-sobytiyno-orientirovannyh-prilozheniyah-i-sistemah">  Datenintegration in ereignisorientierten Anwendungen und Systemen </h3><br><p>  Dieses Schema ist in vielerlei Hinsicht ein Mittel zum Generieren von Ereignissen, obwohl es sich nicht auf eine einzelne Anwendung bezieht.  Es gibt zwei Ebenen der Ereignisgenerierung: Software und System.  Das vorliegende Schema ist mit letzterem verbunden. </p><br><h4 id="programmnyy-uroven-porozhdeniya-sobytiy">  Generierung von Ereignissen auf Programmebene </h4><br><p>  Die Anwendung verwaltet ihren eigenen Status durch eine unver√§nderliche Folge von √Ñnderungsereignissen, die im Ereignisspeicher gespeichert sind.  Um den aktuellen Status der Anwendung zu erhalten, sollten Sie die Ereignisse in der richtigen Reihenfolge abspielen oder kombinieren.  Normalerweise kann in einem solchen Modell <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das CQRS</a> Kafka- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Modell</a> als dieses System verwendet werden. </p><br><h4 id="vzaimodeystvie-mezhdu-prilozheniyami-na-urovne-sistemy">  Interaktion zwischen Anwendungen auf Systemebene. </h4><br><p>  Anwendungen oder Dienste k√∂nnen ihren Status auf eine Weise verwalten, die der Entwickler beispielsweise in einer regul√§ren relationalen Datenbank verwalten m√∂chte. </p><br><p>  Anwendungen ben√∂tigen jedoch h√§ufig Daten √ºber einander. Dies f√ºhrt zu suboptimalen Architekturen, z. B. allgemeinen Datenbanken, Verwischen von Entit√§tsgrenzen oder unbequemen REST-APIs. </p><br><p>  Ich (der Autor des englischen Artikels) habe mir den Podcast ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Software Engineering Daily</a> ‚Äú angeh√∂rt, der ein ereignisorientiertes Szenario f√ºr die Serviceprofile in sozialen Netzwerken beschreibt.  Es gibt eine Reihe verwandter Dienste im System, wie z. B. die Suche, ein System sozialer Diagramme, eine Empfehlungsmaschine usw., die alle √ºber eine √Ñnderung des Status eines Benutzerprofils informiert sein m√ºssen.  Als ich (der Autor des englischen Artikels) als Architekt der Architektur f√ºr ein System im Zusammenhang mit dem Luftverkehr arbeitete, hatten wir zwei gro√üe Softwaresysteme mit einer Vielzahl verwandter kleiner Dienste.  F√ºr den Support sind Bestell- und Flugdaten erforderlich.  Jedes Mal, wenn eine Bestellung erstellt oder ge√§ndert wurde, wenn ein Flug versp√§tet oder storniert wurde, mussten diese Dienste aktiviert werden. </p><br><p>  Es erforderte eine Technik zum Erzeugen von Ereignissen.  Aber zuerst schauen wir uns einige h√§ufige Probleme an, die in gro√üen Softwaresystemen auftreten, und sehen, wie die Generierung von Ereignissen diese l√∂sen kann. </p><br><p>  Ein gro√ües integriertes Unternehmenssystem entwickelt sich normalerweise organisch.  Es werden Migrationen zu neuen Technologien und neuen Architekturen durchgef√ºhrt, die m√∂glicherweise nicht 100% des Systems betreffen.  Die Daten werden an verschiedene Teile der Institution verteilt, Anwendungen legen Datenbanken f√ºr die √∂ffentliche Nutzung offen, damit die Integration so schnell wie m√∂glich erfolgt und niemand mit Sicherheit vorhersagen kann, wie alle Elemente des Systems interagieren werden. </p><br><h4 id="neuporyadochennoe-rasprostranenie-dannyh">  Zuf√§llige Datenverteilung </h4><br><p>  Daten werden an verschiedenen Orten verteilt und an verschiedenen Orten verwaltet. Daher ist es schwer zu verstehen: </p><br><ul><li>  wie sich Daten in Gesch√§ftsprozessen bewegen; </li><li>  wie sich √Ñnderungen in einem Teil des Systems auf andere Teile auswirken k√∂nnen; </li><li>  Was tun mit Datenkonflikten, die aufgrund der Tatsache entstehen, dass sich viele Kopien von Daten langsam verbreiten? </li></ul><br><p>  Wenn es keine klaren Grenzen f√ºr Dom√§nenentit√§ten gibt, sind die √Ñnderungen teuer und riskant, da sie viele Systeme gleichzeitig betreffen. </p><br><h4 id="centralizovannaya-raspredelennaya-baza-dannyh">  Zentralisierte verteilte Datenbank </h4><br><p>  Eine √∂ffentlich ge√∂ffnete Datenbank kann verschiedene Probleme verursachen: </p><br><ul><li>  Es ist nicht f√ºr jede Anwendung einzeln optimiert. H√∂chstwahrscheinlich enth√§lt diese Datenbank einen √ºberm√§√üig vollst√§ndigen Datensatz f√ºr die Anwendung. Au√üerdem ist sie so normalisiert, dass Anwendungen sehr komplexe Abfragen ausf√ºhren m√ºssen, um sie zu empfangen. </li><li>  Mithilfe einer gemeinsamen Datenbank k√∂nnen sich Anwendungen gegenseitig auf die Arbeit auswirken. </li><li>  √Ñnderungen in der logischen Struktur der Datenbank erfordern eine umfassende Koordination und Arbeit an der Datenmigration, und die Entwicklung einzelner Dienste wird f√ºr die Dauer dieses gesamten Prozesses gestoppt. </li><li>  Niemand m√∂chte die Speicherstruktur √§ndern.  Die Ver√§nderungen, auf die alle warten, sind zu schmerzhaft. </li></ul><br><h4 id="ispolzovanie-neudobnogo-rest-api">  Verwenden der unbequemen REST-API </h4><br><p>  Das Abrufen von Daten von anderen Systemen √ºber die REST-API erh√∂ht einerseits die Bequemlichkeit und Isolation, ist jedoch m√∂glicherweise nicht immer erfolgreich.  Jede solche Schnittstelle kann ihren eigenen speziellen Stil und ihre eigenen Konventionen haben.  Das Abrufen der erforderlichen Daten kann viele HTTP-Anforderungen erfordern und recht kompliziert sein. </p><br><p>  Wir bewegen uns immer mehr in Richtung API-Zentrizit√§t, und solche Architekturen bieten viele Vorteile, insbesondere wenn die Dienste selbst au√üerhalb unserer Kontrolle liegen.  Momentan gibt es so viele bequeme M√∂glichkeiten, eine API zu erstellen, dass wir nicht so viel Code schreiben m√ºssen, wie zuvor ben√∂tigt wurde.  Dies ist jedoch nicht das einzige verf√ºgbare Tool, und es gibt Alternativen f√ºr die interne Architektur des Systems. </p><br><h4 id="kafka-kak-hranilische-sobytiy">  Kafka als Event-Repository </h4><br><p>  Wir geben ein Beispiel.  Es gibt ein System, das Reservierungen in einer relationalen Datenbank verwaltet.  Das System nutzt alle Garantien f√ºr Atomizit√§t, Konsistenz, Isolation und Haltbarkeit, die die Datenbank bietet, um ihre Eigenschaften effektiv zu verwalten, und alle sind zufrieden.  Die Aufteilung der Verantwortung in Teams und Anforderungen, die Erzeugung von Ereignissen, Microservices fehlt im Allgemeinen ein traditionell gebauter Monolith.  Es gibt jedoch eine Vielzahl von Support-Services (m√∂glicherweise Microservices) im Zusammenhang mit Reservierungen: Push-Benachrichtigungen, E-Mail-Verteilung, Betrugsbek√§mpfungssystem, Treueprogramm, Abrechnung, Stornierungssystem usw.  Die Liste geht weiter und weiter.  F√ºr alle diese Dienste sind Reservierungsdaten erforderlich, und es gibt viele M√∂glichkeiten, sie zu erhalten.  Diese Dienste selbst erzeugen Daten, die f√ºr andere Anwendungen n√ºtzlich sein k√∂nnen. </p><br><p><img src="https://habrastorage.org/webt/tk/e6/rc/tke6rcvglscapqo_nbx4yk228si.png"><br>  <em>Abbildung 2. Verschiedene Arten der Datenintegration.</em> </p><br><p>  Alternative Architektur basierend auf Kafka.  Jedes Mal, wenn Sie eine neue Reservierung vornehmen oder eine vorherige Reservierung √§ndern, sendet das System vollst√§ndige Daten √ºber den aktuellen Status dieser Reservierung an Kafka.  Durch die Konsolidierung des Journals k√∂nnen Sie die Nachrichten so k√ºrzen, dass nur noch Informationen zum letzten Buchungsstatus darin verbleiben.  In diesem Fall wird die Gr√∂√üe des Journals gesteuert. </p><br><p><img src="https://habrastorage.org/webt/gq/bq/j2/gqbqj2zxxu_zk2sgd-qxrvd17pm.png"><br>  <em>Abbildung 3. Kafka-basierte Datenintegration als Grundlage f√ºr die Ereignisgenerierung</em> </p><br><p>  F√ºr alle Anwendungen, f√ºr die dies erforderlich ist, sind diese Informationen die Quelle der Wahrheit und die einzige Datenquelle.  Pl√∂tzlich wechseln wir von einem integrierten Netzwerk von Abh√§ngigkeiten und Technologien zum Senden und Empfangen von Daten zu / von Kafka-Themen. </p><br><p>  Kafka als Event-Repository: </p><br><ul><li>  Wenn es kein Problem mit dem Speicherplatz gibt, kann Kafka den gesamten Ereignisverlauf speichern, dh eine neue Anwendung kann bereitgestellt werden und alle erforderlichen Informationen aus dem Journal herunterladen.  Aufzeichnungen von Ereignissen, die die Eigenschaften von Objekten vollst√§ndig widerspiegeln, k√∂nnen durch Kompilieren des Protokolls komprimiert werden, wodurch dieser Ansatz f√ºr viele Szenarien gerechtfertigter wird. </li><li>  Was ist, wenn Events in der richtigen Reihenfolge gespielt werden m√ºssen?  Solange die Aufzeichnungen von Ereignissen korrekt verteilt sind, k√∂nnen Sie die Reihenfolge ihrer Wiedergabe festlegen und Filter, Konvertierungswerkzeuge usw. anwenden, sodass die Datenwiedergabe immer mit den erforderlichen Informationen endet.  Abh√§ngig von der M√∂glichkeit der Datenverteilung ist es m√∂glich, deren stark parallelisierte Verarbeitung in der richtigen Reihenfolge sicherzustellen. </li><li>  M√∂glicherweise ist eine √Ñnderung des Datenmodells erforderlich.  Beim Erstellen einer neuen Filter- / Transformationsfunktion muss m√∂glicherweise eine Aufzeichnung aller Ereignisse oder Ereignisse der letzten Woche wiedergegeben werden. </li></ul><br><p>  Nachrichten k√∂nnen nicht nur von Anwendungen Ihres Unternehmens an Kafka gesendet werden, die Nachrichten √ºber alle √Ñnderungen ihrer Eigenschaften (oder die Ergebnisse dieser √Ñnderungen) senden, sondern auch von Diensten von Drittanbietern, die in Ihr System integriert sind.  Dies geschieht auf folgende Weise: </p><br><ul><li>  Regelm√§√üiger Export, Transfer, Import von Daten, die von Drittanbieterdiensten empfangen wurden, und deren Download an Kafka. </li><li>  Herunterladen von Daten von Drittanbieterdiensten in Kafka. </li><li>  Daten aus CSV und anderen Formaten, die von Diensten Dritter hochgeladen wurden, werden auf Kafka hochgeladen. </li></ul><br><p>  Kehren wir zu den Fragen zur√ºck, die wir zuvor betrachtet haben.  Die Kafka-basierte Architektur vereinfacht die Datenverteilung.  Wir wissen, wo die Quelle der Wahrheit liegt, wir wissen, wo sich ihre Datenquellen befinden, und alle Zielanwendungen arbeiten mit Kopien, <strong>die</strong> aus diesen Daten abgeleitet wurden.  Die Daten gehen vom Absender zum Empf√§nger.  Die Quelldaten geh√∂ren nur dem Absender, andere k√∂nnen jedoch mit ihren Projektionen arbeiten.  Sie k√∂nnen sie filtern, transformieren, mit Daten aus anderen Quellen erg√§nzen und in ihren eigenen Datenbanken speichern. </p><br><p><img src="https://habrastorage.org/webt/hw/i7/jw/hwi7jw2n5m5t2hkqb9kx2rqi49c.png"><br>  <em>Abb. 4. Quell- und Ausgabedaten</em> </p><br><p>  Jede Anwendung, die Reservierungs- und Flugdaten ben√∂tigt, erh√§lt diese f√ºr sich, da sie die Abschnitte von Kafka ‚Äûabonniert‚Äú hat, die diese Daten enthalten.  F√ºr diese Anwendung k√∂nnen sie SQL, Cypher, JSON oder eine andere Abfragesprache verwenden.  Eine Anwendung kann dann nach eigenem Ermessen Daten in ihrem System speichern.  Das Datenverteilungsschema kann ge√§ndert werden, ohne den Betrieb anderer Anwendungen zu beeintr√§chtigen. </p><br><p>  Es kann sich die Frage stellen, warum dies alles nicht mit RabbitMQ m√∂glich ist.  Die Antwort ist, dass RabbitMQ verwendet werden kann, um Ereignisse in Echtzeit zu verarbeiten, jedoch nicht als Grundlage f√ºr die Generierung von Ereignissen.  RabbitMQ ist eine Komplettl√∂sung nur f√ºr die Reaktion auf Ereignisse, die gerade stattfinden.  Wenn eine neue Anwendung hinzugef√ºgt wird, die einen eigenen Teil der Reservierungsdaten in einem f√ºr die Aufgaben dieser Anwendung optimierten Format ben√∂tigt, kann RabbitMQ nicht helfen.  Mit RabbitMQ kehren wir zu gemeinsam genutzten Datenbanken oder zur REST-API zur√ºck. </p><br><p>  Zweitens ist die Reihenfolge wichtig, in der Ereignisse verarbeitet werden.  Wenn Sie mit RabbitMQ arbeiten und einen zweiten Empf√§nger zur Warteschlange hinzuf√ºgen, geht die Garantie f√ºr die Einhaltung der Bestellung verloren.  Somit wird die richtige Reihenfolge beim Senden von Nachrichten nur f√ºr einen Empf√§nger eingehalten, aber dies reicht nat√ºrlich nicht aus. </p><br><p>  Im Gegensatz dazu kann Kafka alle Daten bereitstellen, die diese Anwendung ben√∂tigt, um eine eigene Kopie der Daten zu erstellen und die Daten auf dem neuesten Stand zu halten, w√§hrend Kafka die Reihenfolge einh√§lt, in der Nachrichten gesendet werden. </p><br><p>  Nun zur√ºck zu den API-zentrierten Architekturen.  Werden diese Schnittstellen immer die beste Wahl sein?  Wenn Sie den schreibgesch√ºtzten Datenzugriff √∂ffnen m√∂chten, w√ºrde ich eine Architektur bevorzugen, die Ereignisse ausgibt.  Dies verhindert Kaskadierungsfehler und verk√ºrzt die Lebensdauer, die mit einer Zunahme der Anzahl von Abh√§ngigkeiten von anderen Diensten verbunden ist.  Es wird mehr M√∂glichkeiten f√ºr eine kreative und effiziente Organisation von Daten innerhalb von Systemen geben.  Manchmal m√ºssen Sie jedoch Daten sowohl in Ihrem System als auch in einem anderen System synchron √§ndern. In einer solchen Situation sind API-zentrierte Systeme hilfreich.  Viele bevorzugen sie gegen√ºber anderen asynchronen Methoden.  Ich denke, das ist Geschmackssache. </p><br><h3 id="prilozheniya-chuvstvitelnye-k-vysokomu-trafiku-i-poryadku-obrabotki-sobytiy">  Sensible Anwendungen mit hohem Datenverkehr und Ereignisverarbeitung. </h3><br><p>  Vor nicht allzu langer Zeit trat ein Problem mit einem der Empf√§nger von RabbitMQ auf, der Dateien in der Warteschlange von einem Drittanbieter-Dienst erhielt.  Die gesamte Dateigr√∂√üe war gro√ü, und die Anwendung wurde speziell f√ºr den Empfang eines solchen Datenvolumens konfiguriert.  Das Problem war, dass die Daten inkonsistent eingingen, was viele Probleme verursachte. </p><br><p>  Au√üerdem gab es manchmal ein Problem darin, dass manchmal zwei Dateien f√ºr dasselbe Ziel bestimmt waren und sich ihre Ankunftszeit um einige Sekunden unterschied.  Beide haben die Verarbeitung durchlaufen und mussten auf einen Server hochgeladen werden.  Und nachdem die zweite Nachricht auf dem Server aufgezeichnet wurde, √ºberschreibt die erste Nachricht, die darauf folgt, die zweite.  Somit endete alles mit dem Speichern ung√ºltiger Daten.  RabbitMQ hat seine Rolle erf√ºllt und Nachrichten in der richtigen Reihenfolge gesendet, aber trotzdem ist in der Anwendung selbst alles in der falschen Reihenfolge gelandet. </p><br><p>  Dieses Problem wurde gel√∂st, indem der Zeitstempel aus vorhandenen Datens√§tzen gelesen wurde und keine Antwort erfolgte, wenn die Nachricht alt war.  Dar√ºber hinaus wurde w√§hrend des Datenaustauschs konsistentes Hashing angewendet und die Warteschlange wie bei derselben Partitionierung auf der Kafka-Plattform aufgeteilt. </p><br><p>  Als Teil der Partition speichert Kafka Nachrichten in der Reihenfolge, in der sie an sie gesendet wurden.  Die Nachrichtenreihenfolge existiert nur innerhalb der Partition.  Im obigen Beispiel mussten wir mit Kafka die Hash-Funktion auf die ID des Ziels anwenden, um die gew√ºnschte Partition auszuw√§hlen.  Wir mussten eine Reihe von Partitionen erstellen, von denen mehr vorhanden sein sollten, als der Client ben√∂tigte.  Die Reihenfolge der Nachrichtenverarbeitung sollte erreicht worden sein, da jede Partition nur f√ºr einen Empf√§nger bestimmt ist.  Einfach und effektiv. </p><br><p>  Kafka hat im Vergleich zu RabbitMQ einige Vorteile, die mit der Aufteilung von Nachrichten mithilfe von Hashing verbunden sind.  Auf der RabbitMQ-Plattform gibt es nichts, was Empf√§ngerkonflikte in derselben Warteschlange verhindern k√∂nnte, die im Rahmen des Datenaustauschs mithilfe von konsistentem Hashing generiert wird.  RabbitMQ hilft nicht dabei, Empf√§nger zu koordinieren, sodass nur ein Empf√§nger aus der gesamten Warteschlange die Nachricht verwendet.  Kafka bietet all dies durch die Verwendung von Empf√§ngergruppen und eines Koordinatorknotens.  Auf diese Weise k√∂nnen Sie sicherstellen, dass nur ein Empf√§nger in diesem Abschnitt die Nachricht garantiert verwendet und dass die Datenverarbeitungsreihenfolge garantiert ist. </p><br><h3 id="lokalnost-dannyh">  Datenlokalit√§t </h3><br><p>  Kafka verwendet eine Hash-Funktion zum Verteilen von Daten auf Partitionen und bietet Datenlokalit√§t.  Beispielsweise sollten Nachrichten vom Benutzer mit der ID 1001 immer an den Empf√§nger 3 gehen. Da die Ereignisse des Benutzers 1001 immer an den Empf√§nger 3 gehen, kann der Empf√§nger 3 einige Vorg√§nge effektiv ausf√ºhren, die viel schwieriger w√§ren, wenn ein regelm√§√üiger Zugriff auf eine externe Datenbank oder andere Systeme erforderlich w√§re Daten.  Wir k√∂nnen Daten lesen, Aggregationen durchf√ºhren usw.  direkt mit Informationen im Speicher des Empf√§ngers.  Hier beginnen sich ereignisorientierte Anwendungen und Daten-Streaming zu verbinden. </p><br><p>  Wie stellt Kafka die Datenlokalit√§t bereit?  Zun√§chst ist zu beachten, dass Kafka es nicht erlaubt, die Anzahl der Partitionen elastisch zu erh√∂hen und zu verringern.  Erstens k√∂nnen Sie die Anzahl der Partitionen √ºberhaupt nicht reduzieren: Wenn 10 vorhanden sind, k√∂nnen Sie die Anzahl nicht auf 9 reduzieren.  Dies ist jedoch nicht erforderlich.  Jeder Empf√§nger kann entweder eine oder mehrere Partitionen verwenden, daher ist es kaum erforderlich, seine Anzahl zu reduzieren.  Die Erstellung zus√§tzlicher Partitionen in Kafka f√ºhrt zu einer Verz√∂gerung zum Zeitpunkt des Neuausgleichs. Daher versuchen wir, die Anzahl der Partitionen unter Ber√ºcksichtigung der Spitzenlasten zu skalieren. </p><br><p>  Wenn wir jedoch die Anzahl der Partitionen und Empf√§nger noch erh√∂hen m√ºssen, um skalieren zu k√∂nnen, ben√∂tigen wir nur einmalige indirekte Kosten, wenn ein Neuausgleich erforderlich ist.  Es ist zu beachten, dass beim Skalieren alte Daten auf denselben Partitionen verbleiben, auf denen sie sich befanden.  Neue eingehende Nachrichten werden jedoch bereits anders weitergeleitet, und neue Partitionen erhalten neue Nachrichten.  Nachrichten von Benutzer 1001 k√∂nnen jetzt an Empf√§nger 4 gesendet werden (da sich Daten √ºber Benutzer 1001 jetzt in zwei Abschnitten befinden). </p><br><p>  Weiterhin werden wir die √úbermittlungssemantik von √úbermittlungsnachrichten in beiden Systemen vergleichen und vergleichen.  Das Thema Neuausrichtung und Partitionierung verdient einen separaten Artikel, den wir im n√§chsten Teil behandeln werden. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418389/">https://habr.com/ru/post/de418389/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418379/index.html">Bioelektrische Kinderprothese. Teil 2</a></li>
<li><a href="../de418381/index.html">Was ist neu in DevTools in Chrome Version 68?</a></li>
<li><a href="../de418383/index.html">Android-Animationen basierend auf Kotlin und RxJava</a></li>
<li><a href="../de418385/index.html">Wie ich einen Computer f√ºr alte Spiele zusammengebaut habe</a></li>
<li><a href="../de418387/index.html">Physiker Dialog √ºber die Seele</a></li>
<li><a href="../de418391/index.html">OSPF (Teil 1)</a></li>
<li><a href="../de418393/index.html">[Freitag] Wie wir 3D Web ges√§gt haben</a></li>
<li><a href="../de418395/index.html">Elon Musk: Lokale Generatoren elektromagnetischer Felder sch√ºtzen Kolonisten auf dem Mars</a></li>
<li><a href="../de418397/index.html">Freitag Management: Kostenlose Skillbox Webinare</a></li>
<li><a href="../de418399/index.html">Auf der Welle von Selectel FM</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
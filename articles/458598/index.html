<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤙🏽 👐🏾 🈁 Reconocimiento de fuentes de luz en mapas ambientales. 👿 🐼 🍮</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este artículo presenta una implementación de Python del algoritmo para reconocer fuentes de luz en mapas ambientales (LDR o HDR) usando una proyección...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reconocimiento de fuentes de luz en mapas ambientales.</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458598/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a44/e48/451/a44e484510a596be61f83f9c303f25fc.png" alt="imagen"></div><br>  Este artículo presenta una implementación de Python del algoritmo para reconocer fuentes de luz en mapas ambientales (LDR o HDR) usando una proyección equirrectangular.  Sin embargo, después de realizar cambios menores, también se puede usar con imágenes de fondo simples o mapas cúbicos.  Ejemplos de la posible aplicación del algoritmo: programas de trazado de rayos en los que es necesario reconocer fuentes de luz primarias para emitir rayos desde ellos;  en renderizadores rasterizados, se puede usar para proyectar sombras usando un mapa de entorno;  Además, el algoritmo también se puede utilizar en programas de eliminación de reflectores, como AR. <br><br>  El algoritmo consta de los siguientes pasos: <br><br><ol><li>  Disminución de la resolución de la imagen original, por ejemplo, a 1024. </li><li>  Convierta la imagen en brillo (luminancia), si es necesario, con imagen borrosa. </li><li>  Aplicación del método cuasi-Monte Carlo. </li><li>  Transformación de coordenadas esféricas a coordenadas equidistantes. </li><li>  Filtrado de muestras en función del brillo de un vecino. </li><li>  Ordenar muestras en función de su brillo. </li><li>  Filtrado de muestras basado en la métrica euclidiana. </li><li>  Fusionar muestras con el algoritmo de Bresenham. </li><li>  Cálculo de la posición del grupo de iluminación en función de su brillo. </li></ol><br>  Existen muchos algoritmos para reducir la resolución de las imágenes.  El filtrado bilineal es el más rápido o fácil de implementar y, además, es el más adecuado en la mayoría de los casos.  Para convertir el brillo en imágenes LDR y HDR, puede usar la fórmula estándar: <br><br><pre><code class="python hljs">lum = img[:, :, <span class="hljs-number"><span class="hljs-number">0</span></span>] * <span class="hljs-number"><span class="hljs-number">0.2126</span></span> + img[:, :, <span class="hljs-number"><span class="hljs-number">1</span></span>] * <span class="hljs-number"><span class="hljs-number">0.7152</span></span> + img[:, :, <span class="hljs-number"><span class="hljs-number">2</span></span>] * <span class="hljs-number"><span class="hljs-number">0.0722</span></span></code> </pre> <br>  Además, puede aplicar un ligero desenfoque a la imagen de brillo, por ejemplo, 1-2 píxeles para una imagen con una resolución de 1024, para eliminar todos los detalles de alta frecuencia (en particular, causados ​​por una disminución de la resolución). <br><a name="habracut"></a><br><h3>  Proyección Equidistante </h3><br>  La proyección más común en los mapas del entorno es la proyección equidistante <sup>3</sup> .  Mi algoritmo puede funcionar con otras proyecciones, por ejemplo, con mapas panorámicos y cúbicos, sin embargo, en el artículo consideraremos solo una proyección igualmente espaciada.  Primero necesitas normalizar las coordenadas de la imagen: <br><br><pre> <code class="python hljs">pos[<span class="hljs-number"><span class="hljs-number">0</span></span>] = x / width pos[<span class="hljs-number"><span class="hljs-number">1</span></span>] = y / height</code> </pre> <br>  Luego necesitamos convertir desde y hacia coordenadas cartesianas usando coordenadas esféricas, es decir  θ y φ, donde θ = x * 2π, y φ = y * π. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sphereToEquirectangular</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(pos)</span></span></span><span class="hljs-function">:</span></span> invAngles = (<span class="hljs-number"><span class="hljs-number">0.1591</span></span>, <span class="hljs-number"><span class="hljs-number">0.3183</span></span>) xy = (math.atan2(pos[<span class="hljs-number"><span class="hljs-number">1</span></span>], pos[<span class="hljs-number"><span class="hljs-number">0</span></span>]), math.asin(pos[<span class="hljs-number"><span class="hljs-number">2</span></span>])) xy = (xy[<span class="hljs-number"><span class="hljs-number">0</span></span>] * invAngles[<span class="hljs-number"><span class="hljs-number">0</span></span>], xy[<span class="hljs-number"><span class="hljs-number">1</span></span>] * invAngles[<span class="hljs-number"><span class="hljs-number">1</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (xy[<span class="hljs-number"><span class="hljs-number">0</span></span>] + <span class="hljs-number"><span class="hljs-number">0.5</span></span>, xy[<span class="hljs-number"><span class="hljs-number">1</span></span>] + <span class="hljs-number"><span class="hljs-number">0.5</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">equirectangularToSphere</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(pos)</span></span></span><span class="hljs-function">:</span></span> angles = (<span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">0.1591</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">0.3183</span></span>) thetaPhi = (pos[<span class="hljs-number"><span class="hljs-number">0</span></span>] - <span class="hljs-number"><span class="hljs-number">0.5</span></span>, pos[<span class="hljs-number"><span class="hljs-number">1</span></span>] - <span class="hljs-number"><span class="hljs-number">0.5</span></span>) thetaPhi = (thetaPhi[<span class="hljs-number"><span class="hljs-number">0</span></span>] * angles[<span class="hljs-number"><span class="hljs-number">0</span></span>], thetaPhi[<span class="hljs-number"><span class="hljs-number">1</span></span>] * angles[<span class="hljs-number"><span class="hljs-number">1</span></span>]) length = math.cos(thetaPhi[<span class="hljs-number"><span class="hljs-number">1</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (math.cos(thetaPhi[<span class="hljs-number"><span class="hljs-number">0</span></span>]) * length, math.sin(thetaPhi[<span class="hljs-number"><span class="hljs-number">0</span></span>]) * length, math.sin(thetaPhi[<span class="hljs-number"><span class="hljs-number">1</span></span>]))</code> </pre> <br><h3>  Muestreo Hammersley </h3><br>  El siguiente paso será aplicar el método cuasi-Monte Carlo, por ejemplo, el muestreo Hammersley <sup>2</sup> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f9/b07/70f/4f9b0770f72e69ede59e56a25258343d.png"></div><br>  Puede usar otros métodos de muestreo, como Holton <sup>4</sup> , pero Hammersley es más rápido y proporciona una buena distribución de muestras en toda la esfera.  Holton sería una buena opción para muestras de avión si se usa una imagen simple en lugar del mapa del entorno.  Un requisito obligatorio para el muestreo de Hammersley es la inversión de las raíces (fila) de van der Corpute; para más detalles, consulte los enlaces <sup>2</sup> .  Aquí está su implementación rápida: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vdcSequence</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bits)</span></span></span><span class="hljs-function">:</span></span> bits = (bits &lt;&lt; <span class="hljs-number"><span class="hljs-number">16</span></span>) | (bits &gt;&gt; <span class="hljs-number"><span class="hljs-number">16</span></span>) bits = ((bits &amp; <span class="hljs-number"><span class="hljs-number">0x55555555</span></span>) &lt;&lt; <span class="hljs-number"><span class="hljs-number">1</span></span>) | ((bits &amp; <span class="hljs-number"><span class="hljs-number">0xAAAAAAAA</span></span>) &gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span>) bits = ((bits &amp; <span class="hljs-number"><span class="hljs-number">0x33333333</span></span>) &lt;&lt; <span class="hljs-number"><span class="hljs-number">2</span></span>) | ((bits &amp; <span class="hljs-number"><span class="hljs-number">0xCCCCCCCC</span></span>) &gt;&gt; <span class="hljs-number"><span class="hljs-number">2</span></span>) bits = ((bits &amp; <span class="hljs-number"><span class="hljs-number">0x0F0F0F0F</span></span>) &lt;&lt; <span class="hljs-number"><span class="hljs-number">4</span></span>) | ((bits &amp; <span class="hljs-number"><span class="hljs-number">0xF0F0F0F0</span></span>) &gt;&gt; <span class="hljs-number"><span class="hljs-number">4</span></span>) bits = ((bits &amp; <span class="hljs-number"><span class="hljs-number">0x00FF00FF</span></span>) &lt;&lt; <span class="hljs-number"><span class="hljs-number">8</span></span>) | ((bits &amp; <span class="hljs-number"><span class="hljs-number">0xFF00FF00</span></span>) &gt;&gt; <span class="hljs-number"><span class="hljs-number">8</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> float(bits) * <span class="hljs-number"><span class="hljs-number">2.3283064365386963e-10</span></span> <span class="hljs-comment"><span class="hljs-comment"># / 0x100000000 def hammersleySequence(i, N): return (float(i) / float(N), vdcSequence(i))</span></span></code> </pre> <br>  Luego usamos superposición uniforme en la esfera: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sphereSample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(u, v)</span></span></span><span class="hljs-function">:</span></span> PI = <span class="hljs-number"><span class="hljs-number">3.14159265358979</span></span> phi = v * <span class="hljs-number"><span class="hljs-number">2.0</span></span> * PI cosTheta = <span class="hljs-number"><span class="hljs-number">2.0</span></span> * u - <span class="hljs-number"><span class="hljs-number">1.0</span></span> <span class="hljs-comment"><span class="hljs-comment"># map to -1,1 sinTheta = math.sqrt(1.0 - cosTheta * cosTheta); return (math.cos(phi) * sinTheta, math.sin(phi) * sinTheta, cosTheta)</span></span></code> </pre> <br>  Para muestrear Hammersley, utilizamos un número fijo de muestras, dependiendo de la resolución de la imagen, y las convertimos de coordenadas esféricas a cartesianas, y luego a equidistantes: <br><br><pre> <code class="python hljs"> samplesMultiplier = <span class="hljs-number"><span class="hljs-number">0.006</span></span> samples = int(samplesMultiplier * width * height) samplesList = [] <span class="hljs-comment"><span class="hljs-comment"># apply hammersley sampling for i in range(0, samples): xi = hammersleySequence(i, samples) xyz = sphereSample(xi[0], xi[1]) # to cartesian imagePos = sphereToEquirectangular(xyz) luminance = lum[imagePos[0] * width, imagePos[1] * height]</span></span></code> </pre> <br>  Esto nos dará una buena distribución de muestras que serán verificadas por la presencia de fuentes de luz: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/aa8/0a6/470/aa80a64703ef6e38cd0b73f9b02a5852.png"></div><br><h3>  Filtrando fuentes de luz </h3><br>  En el primer paso del filtrado, ignoramos todas las muestras que no exceden el umbral de brillo (para tarjetas HDR, puede ser más alto) y luego clasificamos todas las muestras por su brillo: <br><br><pre> <code class="python hljs"> localSize = int(float(<span class="hljs-number"><span class="hljs-number">12</span></span>) * (width / <span class="hljs-number"><span class="hljs-number">1024.0</span></span>)) + <span class="hljs-number"><span class="hljs-number">1</span></span> samplesList = [] <span class="hljs-comment"><span class="hljs-comment"># apply hammersley sampling for i in range(0, samples): xi = hammersleySequence(i, samples) xyz = sphereSample(xi[0], xi[1]) # to cartesian imagePos = sphereToEquirectangular(xyz) luminance = lum[imagePos [0] * width, imagePos [1] * height] sample = Sample(luminance, imagePos , xyz) luminanceThreshold = 0.8 #do a neighbour search for the maximum luminance nLum = computeNeighborLuminance(lum, width, height, sample.imagePos, localSize) if nLum &gt; luminanceThreshold: samplesList.append(sample) samplesList = sorted(samplesList, key=lambda obj: obj.luminance, reverse=True)</span></span></code> </pre> <br>  La próxima pasada se filtrará según la métrica euclidiana y la distancia umbral entre píxeles (dependiendo de la resolución de la imagen): esta es una estructura de datos espaciales que se puede utilizar para eliminar la complejidad O (N <sup>2</sup> ): <br><br><pre> <code class="python hljs"> euclideanThreshold = int(float(euclideanThresholdPixel) * (width / <span class="hljs-number"><span class="hljs-number">2048.0</span></span>)) <span class="hljs-comment"><span class="hljs-comment"># filter based euclidian distance filteredCount = len(samplesList) localIndices = np.empty(filteredCount); localIndices.fill(-1) for i in range(0, filteredCount): cpos = samplesList[i].pos if localIndices[i] == -1: localIndices[i] = i for j in range(0, filteredCount): if i != j and localIndices[j] == -1 and distance2d(cpos, samplesList[j].pos) &lt; euclideanThreshold: localIndices[j] = i</span></span></code> </pre> <br>  Las muestras resultantes pasan por la etapa de fusión para reducir aún más el número de fuentes de luz: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d39/152/e1e/d39152e1e587c40c3ed29888faf02120.png"></div><br><h3>  Fusionar fuentes de luz </h3><br>  En la última etapa, se realiza la fusión de muestras que pertenecen al mismo grupo de luces.  Para hacer esto, podemos usar el algoritmo de Bresenham y comenzar con las muestras con el brillo más alto, porque ya están ordenadas.  Cuando encontramos una fuente de luz que satisface la prueba de Bresenham, usamos su posición para cambiar la posición de la fuente en función del peso de la ejecución: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># apply bresenham check and compute position of the light clusters lights = [] finalIndices = np.empty(filteredCount); finalIndices.fill(-1) for i in localIndices: sample = samplesList[i] startPos = sample.pos if finalIndices[i] == -1: finalIndices[i] = i light = Light() light.originalPos = np.array(sample.pos) # position of the local maxima light.worldPos = np.array(sample.worldPos) light.pos = np.array(sample.pos) light.luminance = sample.luminance for j in localIndices: if i != j and finalIndices[j] == -1: endPos = samplesList[j].pos if bresenhamCheck(lum, width, height, startPos[0], startPos[1], endPos[0], endPos[1]): finalIndices[j] = i # compute final position of the light source sampleWeight = samplesList[j].luminance / sample.luminance light.pos = light.pos + np.array(endPos) * sampleWeight light.pos = light.pos / (1.0 + sampleWeight) imagePos = light.pos * np.array([1.0 / width, 1.0 / height) light.worldPos = equirectangularToSphere(imagePos) lights.append(light)</span></span></code> </pre> <br>  La función Bresenham busca una línea continua que tenga el mismo brillo.  Si el delta en el píxel actual excede un cierto umbral, la verificación falla: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bresenhamCheck</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(lum, imageSize, x0, y0, x1, y1)</span></span></span><span class="hljs-function">:</span></span> dX = int(x1 - x0) stepX = int((dX &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) - (dX &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>)) dX = abs(dX) &lt;&lt; <span class="hljs-number"><span class="hljs-number">1</span></span> dY = int(y1 - y0) stepY = int((dY &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) - (dY &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>)) dY = abs(dY) &lt;&lt; <span class="hljs-number"><span class="hljs-number">1</span></span> luminanceThreshold = <span class="hljs-number"><span class="hljs-number">0.15</span></span> prevLum = lum[x0][y0] sumLum = <span class="hljs-number"><span class="hljs-number">0.0</span></span> c = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (dX &gt;= dY): <span class="hljs-comment"><span class="hljs-comment"># delta may go below zero delta = int (dY - (dX &gt;&gt; 1)) while (x0 != x1): # reduce delta, while taking into account the corner case of delta == 0 if ((delta &gt; 0) or (delta == 0 and (stepX &gt; 0))): delta -= dX y0 += stepY delta += dY x0 += stepX sumLum = sumLum + min(lum[x0][y0], 1.25) c = c + 1 if(abs(sumLum / c - prevLum) &gt; luminanceThreshold and (sumLum / c) &lt; 1.0): return 0 else: # delta may go below zero delta = int(dX - (dY &gt;&gt; 1)) while (y0 != y1): # reduce delta, while taking into account the corner case of delta == 0 if ((delta &gt; 0) or (delta == 0 and (stepY &gt; 0))): delta -= dY x0 += stepX delta += dX y0 += stepY sumLum = sumLum + min(lum[x0][y0], 1.25) c = c + 1 if(abs(sumLum / c - prevLum) &gt; luminanceThreshold and (sumLum / c) &lt; 1.0): return 0 return 1</span></span></code> </pre> <br>  Cabe señalar que, si es necesario, se pueden realizar mejoras en la prueba de Bresenham, lo que conducirá a una mejor fusión de las muestras, por ejemplo, puede tener en cuenta la transferencia horizontal de las fuentes de luz ubicadas en los bordes de la imagen.  Además, la función se puede ampliar fácilmente para aproximar el área de las fuentes de luz.  Otra mejora: puede agregar un umbral de distancia para no combinar muestras que estén demasiado lejos.  Resultados finales <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/422/4a8/fd9/4224a8fd98cec4203235bb4678ee6826.png"></div><br>  El azul denota los máximos locales de los grupos de luces, el azul denota las posiciones finales de las fuentes de luz y el rojo denota muestras que son parte del mismo grupo de luces y están conectadas por líneas. <br><br>  Otros ejemplos de resultados: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a44/e48/451/a44e484510a596be61f83f9c303f25fc.png"></div><br><hr><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Detección de fuentes de luz en fotografías digitales por Maciej Laskowski</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Puntos Hammersley en el hemisferio por Holger Dammertz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Proyección Equirectangular por Paul Reed</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Muestreo con Hammersley y Halton Points por Tien-Tsin Wong</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458598/">https://habr.com/ru/post/458598/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458582/index.html">El ingeniero de Amazon ha creado un dispositivo de bloqueo de IA que mantiene a los gatos fuera de la calle</a></li>
<li><a href="../458584/index.html">11 de julio, seminario web del Grupo IB "Análisis de malware para principiantes: enfoques básicos"</a></li>
<li><a href="../458590/index.html">Enfoques arquitectónicos en aplicaciones iOS</a></li>
<li><a href="../458594/index.html">No olvide aumentar la posibilidad de una respuesta al cliente utilizando una solicitud repetida en el equilibrio L7</a></li>
<li><a href="../458596/index.html">Petty little joy # 6: OpenAI Gym - juega juegos y controla robots</a></li>
<li><a href="../458600/index.html">¿Qué son las bicicletas eléctricas (revisión grupal en dos partes de cinco modelos de dos fabricantes), parte 1</a></li>
<li><a href="../458602/index.html">Cómo atravesamos el Gran Cortafuegos chino (Parte 1)</a></li>
<li><a href="../458604/index.html">¿Por qué los dos mayores fabricantes de productos electrónicos unieron fuerzas en un nuevo proyecto de GPU?</a></li>
<li><a href="../458606/index.html">Ejecute OpenVPN en Docker en 2 segundos</a></li>
<li><a href="../458608/index.html">Herramientas de desarrollo de Node.js Cola de trabajo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
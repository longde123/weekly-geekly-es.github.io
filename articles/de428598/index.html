<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì† üëπ üç± Tiefe neuronale Netze f√ºr die automatische Anrufbewertung üïµüèø üíö ü§∏üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Anrufbewertung ist ein wesentlicher Bestandteil der Qualit√§tskontrolle f√ºr Call Center. Unternehmen k√∂nnen damit ihren Workflow optimieren, sodass...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tiefe neuronale Netze f√ºr die automatische Anrufbewertung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/428598/">  Die Anrufbewertung ist ein wesentlicher Bestandteil der Qualit√§tskontrolle f√ºr Call Center.  Unternehmen k√∂nnen damit ihren Workflow optimieren, sodass Bediener schneller und effizienter arbeiten und bedeutungslose Routinen vermeiden k√∂nnen. <br><br>  In dem Bewusstsein, dass das Call Center effektiv sein sollte, haben wir an der Automatisierung der Anrufergebnisse gearbeitet.  Als Ergebnis haben wir einen Algorithmus entwickelt, der Anrufe verarbeitet und in zwei Gruppen verteilt: verd√§chtig und neutral.  Alle verd√§chtigen Anrufe wurden sofort an das Qualit√§tsbewertungsteam gesendet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yj/0t/yq/yj0tyqtftcw-e0m_wcxkh_ls7l0.jpeg"></div><br><a name="habracut"></a><br>
<h2>  Wie wir ein tiefes neuronales Netzwerk trainiert haben </h2><br>  F√ºr die Samples haben wir 1700 Audiodateien genommen, auf denen wir das Netzwerk trainiert haben.  Da das Neuron anfangs nicht wusste, was als verd√§chtig und was als neutral anzusehen war, haben wir alle Dateien manuell entsprechend markiert. <br><br>  In neutralen Stichproben haben die Bediener: <br><br><ul><li>  erhoben ihre Stimmen nicht; </li><li>  Stellen Sie den Kunden alle angeforderten Informationen zur Verf√ºgung. </li><li>  reagierte nicht auf Provokationen des Kunden. </li></ul><br>  In verd√§chtigen Mustern haben die Bediener h√§ufig Folgendes getan: <br><br><ul><li>  benutzte obsz√∂ne Sprache; </li><li>  ihre Stimmen erheben oder Kunden anschreien; </li><li>  ging zu der Person; </li><li>  weigerte sich, in Fragen zu beraten. </li></ul><br>  Als der Algorithmus die Verarbeitung der Dateien beendet hatte, markierte er 200 Dateien als ung√ºltig.  Diese Dateien enthielten keine verd√§chtigen oder neutralen Anzeichen.  Wir haben herausgefunden, was in diesen 200 Dateien enthalten ist: <br><br><ul><li>  Der Kunde legte sofort auf, nachdem der Betreiber ihm geantwortet hatte. </li><li>  der Klient sagte nichts, nachdem er beantwortet worden war; </li><li>  Es gab zu viel L√§rm auf der Client- oder Bedienerseite. </li></ul><br>  Beim L√∂schen dieser Dateien haben wir die verbleibenden 1.500 in Schulungs- und Testf√§lle unterteilt.  In Zukunft haben wir diese Datens√§tze zum Trainieren und Testen eines tiefen neuronalen Netzwerks verwendet. <br><br><h2>  Schritt 1: Features extrahieren </h2><br>  Die Extraktion von Merkmalen auf hoher Ebene spielt eine wichtige Rolle beim maschinellen Lernen  Dies wirkt sich direkt auf die Effizienz des Algorithmus aus.  Nachdem wir alle m√∂glichen Quellen analysiert hatten, w√§hlten wir die folgenden Symptome aus: <br><br><h3>  Zeitstatistik </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nulldurchgangsrate</a> : Die Geschwindigkeit, mit der sich das Signal von Plus nach Minus und umgekehrt √§ndert. </li><li>  <b>Mittlere Rahmenenergie</b> : Die Summe der Signale, die quadriert und auf die entsprechende Rahmenl√§nge normiert sind. </li><li>  <b>Subframe-Energieentropie</b> : Die Entropie der normalisierten Subframe-Energie.  Es kann als Ma√ü f√ºr drastische Ver√§nderungen interpretiert werden. </li><li>  <b>Der Durchschnitt / Median / Standardabweichung des Rahmens</b> . </li></ul><br><h3>  Spektralstatistik (mit Frequenzintervallen) </h3><br><ol><li>  Spektralschwerpunkt. </li><li>  Spektralverteilung. </li><li>  Spektrale Entropie. </li><li>  Spektrale Strahlung. </li><li>  Spektrale D√§mpfung. </li></ol><br>  Die Cepstralkoeffizienten der Tonfrequenz und des S√§ttigungsvektors sind abh√§ngig von der L√§nge des Eingangssignals.  Wir k√∂nnten sie gleichzeitig aus der gesamten Datei extrahieren, w√ºrden jedoch die Entwicklung des Merkmals rechtzeitig verpassen.  Da diese Methode nicht zu uns passte, haben wir beschlossen, das Signal in ‚ÄûFenster‚Äú (Zeitbl√∂cke) zu unterteilen. <br><br>  Um die Qualit√§t des Zeichens zu verbessern, haben wir das Signal in St√ºcke zerlegt, die sich teilweise √ºberlappten.  Als n√§chstes extrahierten wir das Tag nacheinander f√ºr jeden Block.  Daher wurde die Attributmatrix f√ºr jede Audiodatei berechnet. <br><br>  Fenstergr√∂√üe - 0,2 s;  Fensterschritt - 0,1 s. <br><br><h2>  Schritt 2: Definieren Sie den Tonfall in separaten S√§tzen </h2><br>  Unser erster Ansatz zur L√∂sung des Problems besteht darin, jede Phrase im Stream separat zu definieren und zu verarbeiten. <br><br>  Zuerst haben wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diarisierung durchgef√ºhrt</a> und alle Phrasen mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LIUM-</a> Bibliothek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">isoliert</a> .  Die Eingabedateien waren von schlechter Qualit√§t, daher haben wir bei der Ausgabe auch Gl√§ttung und adaptive Schwellenwerte f√ºr jede Datei angewendet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ri/8t/me/ri8tmehn045h1dbiztmtq4ixb-o.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/c9/_t/z3c9_tkardcnk9irbxxokxxso44.png"></div><br><h3>  Verarbeitungsunterbrechungen und lange Stille </h3><br>  Als wir die Fristen f√ºr jede Phrase (sowohl f√ºr den Kunden als auch f√ºr den Operator) festgelegt haben, haben wir sie einander √ºberlagert und F√§lle aufgedeckt, in denen beide Personen gleichzeitig sprechen, sowie F√§lle, in denen beide schweigen.  Es blieb nur die Bestimmung des Schwellenwertes.  Wir waren uns einig, dass wenn 3 oder mehr Sekunden die Teilnehmer gleichzeitig sprechen, dies als Unterbrechung angesehen wird.  F√ºr die Stille wurde genau ein Schwellenwert von 3 Sekunden eingestellt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ke/md/dh/kemddhguibgoz6kug0imtvphl84.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ti/_o/dlti_okejnlhqdwlnpihys0d0vi.png"></div><br>  Der Punkt ist, dass jede Phrase ihre eigene L√§nge hat.  Folglich ist die Anzahl der extrahierten Merkmale f√ºr jede Phrase unterschiedlich. <br><br>  Das neuronale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSTM-</a> Netzwerk k√∂nnte dieses Problem l√∂sen.  Netzwerke dieser Art k√∂nnen nicht nur Sequenzen unterschiedlicher L√§nge verarbeiten, sondern auch Feedback enthalten, mit dem Sie Informationen speichern k√∂nnen.  Diese Funktionen sind sehr wichtig, da zuvor gesprochene Phrasen Informationen enthalten, die sich auf die danach gesprochenen Phrasen auswirken. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/s1/fa/sr/s1fasrlj1hby2a67opppjka_n5m.png"></div><br>  Dann haben wir unser LSTM-Netzwerk trainiert, um die Intonation jeder Phrase zu bestimmen. <br><br>  Als Trainingsset haben wir 70 Dateien mit durchschnittlich 30 Phrasen (15 Phrasen f√ºr jede Seite) genommen. <br><br>  Das Hauptziel war es, die Phrasen des Call-Center-Betreibers zu bewerten, sodass wir die Client-Sprache nicht f√ºr Schulungen verwendeten.  Wir haben 750 S√§tze als Trainingsdatensatz und 250 S√§tze als Test verwendet.  Infolgedessen lernte das Neuron, Sprache mit einer Genauigkeit von 72% zu klassifizieren. <br><br>  Letztendlich waren wir jedoch mit der Leistung des LSTM-Netzwerks nicht zufrieden: Die Arbeit damit hat zu lange gedauert, w√§hrend die Ergebnisse alles andere als perfekt sind.  Daher wurde beschlossen, einen anderen Ansatz zu verwenden. <br><br>  Es ist Zeit zu erz√§hlen, wie wir den Ton der Stimme mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">XGBoost</a> plus einer Kombination aus LSTM und XGB bestimmt haben. <br><br><h2>  Bestimmen Sie den Sprachton f√ºr die gesamte Datei </h2><br>  Wir haben Dateien als verd√§chtig markiert, wenn sie mindestens einen Satz enthielten, der gegen die Regeln verstie√ü.  Also haben wir 2500 Dateien markiert. <br><br>  Um Attribute zu extrahieren, haben wir dieselbe Methode und dieselbe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ANN-</a> Architektur verwendet, jedoch mit einem Unterschied: Wir haben die Architektur so skaliert, dass sie den neuen Dimensionen der Attribute entspricht. <br><br>  Bei optimalen Parametern ergab das neuronale Netzwerk eine Genauigkeit von 85%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pu/1f/q3/pu1fq3pnbx828w78lppbfkcdrla.png" width="650"></div><br><h3>  XGBoost </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das XGBoost-Modell</a> erfordert eine feste Anzahl von Attributen f√ºr jede Datei.  Um diese Anforderung zu erf√ºllen, haben wir verschiedene Signale und Parameter erstellt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lh/n0/ec/lhn0ecwl46_pfqmzgq-nelhxagu.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/kl/xh/6vklxhkhif4zlv_haaqhk71pmgy.jpeg"></div><br>  Die folgenden Statistiken wurden verwendet: <br><br><ol><li>  Der Durchschnittswert des Signals. </li><li>  Der Durchschnittswert der ersten 10 Sekunden des Signals. </li><li>  Der Durchschnittswert der letzten 3 Sekunden des Signals. </li><li>  Der Durchschnittswert der lokalen Maxima im Signal. </li><li>  Der Durchschnittswert der lokalen Maxima in den ersten 10 Sekunden des Signals. </li><li>  Der Durchschnittswert der lokalen Maxima in den letzten 3 Sekunden des Signals. </li></ol><br>  Alle Indikatoren wurden f√ºr jedes Signal separat berechnet.  Die Gesamtzahl der Attribute betr√§gt 36, mit Ausnahme der L√§nge des Datensatzes.  Als Ergebnis hatten wir 37 numerische Vorzeichen f√ºr jeden Datensatz. <br><br>  Die Vorhersagegenauigkeit dieses Algorithmus betr√§gt 0,869. <br><br><h3>  Kombination von LSTM und XGB </h3><br>  Um die Klassifikatoren zu kombinieren, haben wir diese beiden Modelle gekreuzt.  Am Ausgang erh√∂hte dies die Genauigkeit um 2%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e9/wi/21/e9wi21ggxfrlo6tj_shuo6b3pve.png"></div><br>  Das hei√üt, wir konnten die Vorhersagegenauigkeit auf 0,9 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ROC</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AUC</a> (Area Under Curve) erh√∂hen. <br><br><h2>  Ergebnis </h2><br>  Wir haben unser tiefes neuronales Netzwerk an 205 Dateien getestet (177 neutral, 28 verd√§chtig).  Das Netzwerk musste jede Datei verarbeiten und entscheiden, zu welcher Gruppe sie geh√∂rt.  Das Folgende sind die Ergebnisse: <br><br><ul><li>  170 neutrale Dateien wurden korrekt identifiziert; </li><li>  7 neutrale Dateien wurden als verd√§chtig identifiziert; </li><li>  13 verd√§chtige Dateien wurden korrekt identifiziert; </li><li>  15 verd√§chtige Dateien wurden als neutral identifiziert. </li></ul><br>  Um den Prozentsatz der korrekten / falschen Ergebnisse abzusch√§tzen, haben wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehlermatrix</a> in Form einer 2x2-Tabelle verwendet. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mh/iu/4g/mhiu4g2975opf6esqhuiflvphsm.jpeg"></div><br><h2>  Suchen Sie eine bestimmte Phrase in einem Gespr√§ch </h2><br>  Wir wollten diesen Ansatz unbedingt ausprobieren, um W√∂rter und Phrasen in Audiodateien zu erkennen.  Ziel war es, Dateien zu finden, in denen der Callcenter-Betreiber den Kunden in den ersten 10 Sekunden des Gespr√§chs nicht pr√§sentiert wurde. <br><br>  Wir haben 200 S√§tze mit einer durchschnittlichen L√§nge von 1,5 Sekunden verwendet, in denen die Betreiber ihren Namen und Firmennamen nennen. <br><br>  Das manuelle Suchen nach solchen Dateien hat lange gedauert, weil  Ich musste mir jede Datei anh√∂ren, um zu √ºberpr√ºfen, ob sie die erforderlichen S√§tze enthielt.  Um das weitere Training zu beschleunigen, haben wir den Datensatz ‚Äûk√ºnstlich‚Äú vergr√∂√üert: Wir haben jede Datei sechsmal zuf√§llig ge√§ndert - Rauschen hinzugef√ºgt, Frequenz und / oder Lautst√§rke ge√§ndert.  Wir haben also einen Datensatz von 1.500 Dateien erhalten. <br><br><h3>  Zusammenfassung </h3><br>  Wir haben die ersten 10 Sekunden der Antwort des Bedieners verwendet, um den Klassifikator zu trainieren, da in diesem Intervall die gew√ºnschte Phrase ausgesprochen wurde.  Jede solche Passage wurde in Fenster unterteilt (Fensterl√§nge 1,5 s, Fensterschritt 1 s) und vom neuronalen Netzwerk als Eingabedatei verarbeitet.  Als Ausgabedatei haben wir die Wahrscheinlichkeit erhalten, jede Phrase im ausgew√§hlten Fenster auszusprechen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cr/md/4-/crmd4-kcd7c-_qfd5h_arxpa6ei.jpeg"></div><br>  Wir haben weitere 300 Dateien durch das Netzwerk geleitet, um herauszufinden, ob die gew√ºnschte Phrase in den ersten 10 Sekunden gesprochen wurde.  F√ºr diese Dateien betrug die Genauigkeit 87%. <br><br><h2>  Wof√ºr ist das alles eigentlich? </h2><br>  Die automatische Anrufbewertung hilft dabei, klare KPIs f√ºr Call Center-Betreiber zu ermitteln, Best Practices hervorzuheben und zu befolgen sowie die Call Center-Leistung zu steigern.  Es ist jedoch anzumerken, dass Spracherkennungssoftware f√ºr ein breiteres Spektrum von Aufgaben verwendet werden kann. <br><br>  Im Folgenden finden Sie einige Beispiele, wie die Spracherkennung Organisationen helfen kann: <br><br><ul><li>  Sammeln und Analysieren von Daten zur Verbesserung der Sprach-UX; </li><li>  Anrufaufzeichnungen analysieren, um Beziehungen und Trends zu identifizieren; </li><li>  Menschen durch Stimme erkennen; </li><li>  Finden und identifizieren Sie Kundenemotionen, um die Benutzerzufriedenheit zu verbessern </li><li>  Steigerung des durchschnittlichen Umsatzes pro Anruf; </li><li>  Abfluss reduzieren; </li><li>  und vieles mehr! </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428598/">https://habr.com/ru/post/de428598/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428582/index.html">Vergessene Geschichte von OOP</a></li>
<li><a href="../de428588/index.html">Zusammenfassung der IT-Ereignisse im November (Teil zwei)</a></li>
<li><a href="../de428590/index.html">Mikrointeraktionen und Mikroaufforderungen in der Schnittstelle</a></li>
<li><a href="../de428592/index.html">Stellen Sie keine "effektiven Manager" mehr ein. Sie sind nicht nur nutzlos, sondern auch sch√§dlich</a></li>
<li><a href="../de428596/index.html">Elon Musk entlie√ü Starlink-Satelliten-Internet-Projektmanager wegen Nichteinhaltung der Fristen</a></li>
<li><a href="../de428600/index.html">SSDs mit Spezialeffekten oder was beim Modden fehlte - √úberpr√ºfung des HyperX FURY RGB-Laufwerks</a></li>
<li><a href="../de428602/index.html">Lernen Sie kontroverse Taktiken, Techniken und allgemeines Wissen (ATT @ CK). Unternehmenstaktik. Teil 4</a></li>
<li><a href="../de428604/index.html">Online Data Science Meisterschaft</a></li>
<li><a href="../de428606/index.html">"Das Verst√§ndnis der Funktionsweise des Systems erm√∂glichte viel Hacking": Roy Beniosef √ºber die Android-Entwicklung</a></li>
<li><a href="../de428608/index.html">Medienbeteiligungen einigten sich mit Yandex auf die Entfernung von Raubkopien</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
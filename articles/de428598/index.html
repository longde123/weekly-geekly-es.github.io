<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📠 👹 🍱 Tiefe neuronale Netze für die automatische Anrufbewertung 🕵🏿 💚 🤸🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Anrufbewertung ist ein wesentlicher Bestandteil der Qualitätskontrolle für Call Center. Unternehmen können damit ihren Workflow optimieren, sodass...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tiefe neuronale Netze für die automatische Anrufbewertung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/428598/">  Die Anrufbewertung ist ein wesentlicher Bestandteil der Qualitätskontrolle für Call Center.  Unternehmen können damit ihren Workflow optimieren, sodass Bediener schneller und effizienter arbeiten und bedeutungslose Routinen vermeiden können. <br><br>  In dem Bewusstsein, dass das Call Center effektiv sein sollte, haben wir an der Automatisierung der Anrufergebnisse gearbeitet.  Als Ergebnis haben wir einen Algorithmus entwickelt, der Anrufe verarbeitet und in zwei Gruppen verteilt: verdächtig und neutral.  Alle verdächtigen Anrufe wurden sofort an das Qualitätsbewertungsteam gesendet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yj/0t/yq/yj0tyqtftcw-e0m_wcxkh_ls7l0.jpeg"></div><br><a name="habracut"></a><br>
<h2>  Wie wir ein tiefes neuronales Netzwerk trainiert haben </h2><br>  Für die Samples haben wir 1700 Audiodateien genommen, auf denen wir das Netzwerk trainiert haben.  Da das Neuron anfangs nicht wusste, was als verdächtig und was als neutral anzusehen war, haben wir alle Dateien manuell entsprechend markiert. <br><br>  In neutralen Stichproben haben die Bediener: <br><br><ul><li>  erhoben ihre Stimmen nicht; </li><li>  Stellen Sie den Kunden alle angeforderten Informationen zur Verfügung. </li><li>  reagierte nicht auf Provokationen des Kunden. </li></ul><br>  In verdächtigen Mustern haben die Bediener häufig Folgendes getan: <br><br><ul><li>  benutzte obszöne Sprache; </li><li>  ihre Stimmen erheben oder Kunden anschreien; </li><li>  ging zu der Person; </li><li>  weigerte sich, in Fragen zu beraten. </li></ul><br>  Als der Algorithmus die Verarbeitung der Dateien beendet hatte, markierte er 200 Dateien als ungültig.  Diese Dateien enthielten keine verdächtigen oder neutralen Anzeichen.  Wir haben herausgefunden, was in diesen 200 Dateien enthalten ist: <br><br><ul><li>  Der Kunde legte sofort auf, nachdem der Betreiber ihm geantwortet hatte. </li><li>  der Klient sagte nichts, nachdem er beantwortet worden war; </li><li>  Es gab zu viel Lärm auf der Client- oder Bedienerseite. </li></ul><br>  Beim Löschen dieser Dateien haben wir die verbleibenden 1.500 in Schulungs- und Testfälle unterteilt.  In Zukunft haben wir diese Datensätze zum Trainieren und Testen eines tiefen neuronalen Netzwerks verwendet. <br><br><h2>  Schritt 1: Features extrahieren </h2><br>  Die Extraktion von Merkmalen auf hoher Ebene spielt eine wichtige Rolle beim maschinellen Lernen  Dies wirkt sich direkt auf die Effizienz des Algorithmus aus.  Nachdem wir alle möglichen Quellen analysiert hatten, wählten wir die folgenden Symptome aus: <br><br><h3>  Zeitstatistik </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nulldurchgangsrate</a> : Die Geschwindigkeit, mit der sich das Signal von Plus nach Minus und umgekehrt ändert. </li><li>  <b>Mittlere Rahmenenergie</b> : Die Summe der Signale, die quadriert und auf die entsprechende Rahmenlänge normiert sind. </li><li>  <b>Subframe-Energieentropie</b> : Die Entropie der normalisierten Subframe-Energie.  Es kann als Maß für drastische Veränderungen interpretiert werden. </li><li>  <b>Der Durchschnitt / Median / Standardabweichung des Rahmens</b> . </li></ul><br><h3>  Spektralstatistik (mit Frequenzintervallen) </h3><br><ol><li>  Spektralschwerpunkt. </li><li>  Spektralverteilung. </li><li>  Spektrale Entropie. </li><li>  Spektrale Strahlung. </li><li>  Spektrale Dämpfung. </li></ol><br>  Die Cepstralkoeffizienten der Tonfrequenz und des Sättigungsvektors sind abhängig von der Länge des Eingangssignals.  Wir könnten sie gleichzeitig aus der gesamten Datei extrahieren, würden jedoch die Entwicklung des Merkmals rechtzeitig verpassen.  Da diese Methode nicht zu uns passte, haben wir beschlossen, das Signal in „Fenster“ (Zeitblöcke) zu unterteilen. <br><br>  Um die Qualität des Zeichens zu verbessern, haben wir das Signal in Stücke zerlegt, die sich teilweise überlappten.  Als nächstes extrahierten wir das Tag nacheinander für jeden Block.  Daher wurde die Attributmatrix für jede Audiodatei berechnet. <br><br>  Fenstergröße - 0,2 s;  Fensterschritt - 0,1 s. <br><br><h2>  Schritt 2: Definieren Sie den Tonfall in separaten Sätzen </h2><br>  Unser erster Ansatz zur Lösung des Problems besteht darin, jede Phrase im Stream separat zu definieren und zu verarbeiten. <br><br>  Zuerst haben wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diarisierung durchgeführt</a> und alle Phrasen mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LIUM-</a> Bibliothek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">isoliert</a> .  Die Eingabedateien waren von schlechter Qualität, daher haben wir bei der Ausgabe auch Glättung und adaptive Schwellenwerte für jede Datei angewendet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ri/8t/me/ri8tmehn045h1dbiztmtq4ixb-o.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/c9/_t/z3c9_tkardcnk9irbxxokxxso44.png"></div><br><h3>  Verarbeitungsunterbrechungen und lange Stille </h3><br>  Als wir die Fristen für jede Phrase (sowohl für den Kunden als auch für den Operator) festgelegt haben, haben wir sie einander überlagert und Fälle aufgedeckt, in denen beide Personen gleichzeitig sprechen, sowie Fälle, in denen beide schweigen.  Es blieb nur die Bestimmung des Schwellenwertes.  Wir waren uns einig, dass wenn 3 oder mehr Sekunden die Teilnehmer gleichzeitig sprechen, dies als Unterbrechung angesehen wird.  Für die Stille wurde genau ein Schwellenwert von 3 Sekunden eingestellt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ke/md/dh/kemddhguibgoz6kug0imtvphl84.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ti/_o/dlti_okejnlhqdwlnpihys0d0vi.png"></div><br>  Der Punkt ist, dass jede Phrase ihre eigene Länge hat.  Folglich ist die Anzahl der extrahierten Merkmale für jede Phrase unterschiedlich. <br><br>  Das neuronale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSTM-</a> Netzwerk könnte dieses Problem lösen.  Netzwerke dieser Art können nicht nur Sequenzen unterschiedlicher Länge verarbeiten, sondern auch Feedback enthalten, mit dem Sie Informationen speichern können.  Diese Funktionen sind sehr wichtig, da zuvor gesprochene Phrasen Informationen enthalten, die sich auf die danach gesprochenen Phrasen auswirken. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/s1/fa/sr/s1fasrlj1hby2a67opppjka_n5m.png"></div><br>  Dann haben wir unser LSTM-Netzwerk trainiert, um die Intonation jeder Phrase zu bestimmen. <br><br>  Als Trainingsset haben wir 70 Dateien mit durchschnittlich 30 Phrasen (15 Phrasen für jede Seite) genommen. <br><br>  Das Hauptziel war es, die Phrasen des Call-Center-Betreibers zu bewerten, sodass wir die Client-Sprache nicht für Schulungen verwendeten.  Wir haben 750 Sätze als Trainingsdatensatz und 250 Sätze als Test verwendet.  Infolgedessen lernte das Neuron, Sprache mit einer Genauigkeit von 72% zu klassifizieren. <br><br>  Letztendlich waren wir jedoch mit der Leistung des LSTM-Netzwerks nicht zufrieden: Die Arbeit damit hat zu lange gedauert, während die Ergebnisse alles andere als perfekt sind.  Daher wurde beschlossen, einen anderen Ansatz zu verwenden. <br><br>  Es ist Zeit zu erzählen, wie wir den Ton der Stimme mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">XGBoost</a> plus einer Kombination aus LSTM und XGB bestimmt haben. <br><br><h2>  Bestimmen Sie den Sprachton für die gesamte Datei </h2><br>  Wir haben Dateien als verdächtig markiert, wenn sie mindestens einen Satz enthielten, der gegen die Regeln verstieß.  Also haben wir 2500 Dateien markiert. <br><br>  Um Attribute zu extrahieren, haben wir dieselbe Methode und dieselbe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ANN-</a> Architektur verwendet, jedoch mit einem Unterschied: Wir haben die Architektur so skaliert, dass sie den neuen Dimensionen der Attribute entspricht. <br><br>  Bei optimalen Parametern ergab das neuronale Netzwerk eine Genauigkeit von 85%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pu/1f/q3/pu1fq3pnbx828w78lppbfkcdrla.png" width="650"></div><br><h3>  XGBoost </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das XGBoost-Modell</a> erfordert eine feste Anzahl von Attributen für jede Datei.  Um diese Anforderung zu erfüllen, haben wir verschiedene Signale und Parameter erstellt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lh/n0/ec/lhn0ecwl46_pfqmzgq-nelhxagu.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/kl/xh/6vklxhkhif4zlv_haaqhk71pmgy.jpeg"></div><br>  Die folgenden Statistiken wurden verwendet: <br><br><ol><li>  Der Durchschnittswert des Signals. </li><li>  Der Durchschnittswert der ersten 10 Sekunden des Signals. </li><li>  Der Durchschnittswert der letzten 3 Sekunden des Signals. </li><li>  Der Durchschnittswert der lokalen Maxima im Signal. </li><li>  Der Durchschnittswert der lokalen Maxima in den ersten 10 Sekunden des Signals. </li><li>  Der Durchschnittswert der lokalen Maxima in den letzten 3 Sekunden des Signals. </li></ol><br>  Alle Indikatoren wurden für jedes Signal separat berechnet.  Die Gesamtzahl der Attribute beträgt 36, mit Ausnahme der Länge des Datensatzes.  Als Ergebnis hatten wir 37 numerische Vorzeichen für jeden Datensatz. <br><br>  Die Vorhersagegenauigkeit dieses Algorithmus beträgt 0,869. <br><br><h3>  Kombination von LSTM und XGB </h3><br>  Um die Klassifikatoren zu kombinieren, haben wir diese beiden Modelle gekreuzt.  Am Ausgang erhöhte dies die Genauigkeit um 2%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e9/wi/21/e9wi21ggxfrlo6tj_shuo6b3pve.png"></div><br>  Das heißt, wir konnten die Vorhersagegenauigkeit auf 0,9 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ROC</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AUC</a> (Area Under Curve) erhöhen. <br><br><h2>  Ergebnis </h2><br>  Wir haben unser tiefes neuronales Netzwerk an 205 Dateien getestet (177 neutral, 28 verdächtig).  Das Netzwerk musste jede Datei verarbeiten und entscheiden, zu welcher Gruppe sie gehört.  Das Folgende sind die Ergebnisse: <br><br><ul><li>  170 neutrale Dateien wurden korrekt identifiziert; </li><li>  7 neutrale Dateien wurden als verdächtig identifiziert; </li><li>  13 verdächtige Dateien wurden korrekt identifiziert; </li><li>  15 verdächtige Dateien wurden als neutral identifiziert. </li></ul><br>  Um den Prozentsatz der korrekten / falschen Ergebnisse abzuschätzen, haben wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehlermatrix</a> in Form einer 2x2-Tabelle verwendet. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mh/iu/4g/mhiu4g2975opf6esqhuiflvphsm.jpeg"></div><br><h2>  Suchen Sie eine bestimmte Phrase in einem Gespräch </h2><br>  Wir wollten diesen Ansatz unbedingt ausprobieren, um Wörter und Phrasen in Audiodateien zu erkennen.  Ziel war es, Dateien zu finden, in denen der Callcenter-Betreiber den Kunden in den ersten 10 Sekunden des Gesprächs nicht präsentiert wurde. <br><br>  Wir haben 200 Sätze mit einer durchschnittlichen Länge von 1,5 Sekunden verwendet, in denen die Betreiber ihren Namen und Firmennamen nennen. <br><br>  Das manuelle Suchen nach solchen Dateien hat lange gedauert, weil  Ich musste mir jede Datei anhören, um zu überprüfen, ob sie die erforderlichen Sätze enthielt.  Um das weitere Training zu beschleunigen, haben wir den Datensatz „künstlich“ vergrößert: Wir haben jede Datei sechsmal zufällig geändert - Rauschen hinzugefügt, Frequenz und / oder Lautstärke geändert.  Wir haben also einen Datensatz von 1.500 Dateien erhalten. <br><br><h3>  Zusammenfassung </h3><br>  Wir haben die ersten 10 Sekunden der Antwort des Bedieners verwendet, um den Klassifikator zu trainieren, da in diesem Intervall die gewünschte Phrase ausgesprochen wurde.  Jede solche Passage wurde in Fenster unterteilt (Fensterlänge 1,5 s, Fensterschritt 1 s) und vom neuronalen Netzwerk als Eingabedatei verarbeitet.  Als Ausgabedatei haben wir die Wahrscheinlichkeit erhalten, jede Phrase im ausgewählten Fenster auszusprechen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cr/md/4-/crmd4-kcd7c-_qfd5h_arxpa6ei.jpeg"></div><br>  Wir haben weitere 300 Dateien durch das Netzwerk geleitet, um herauszufinden, ob die gewünschte Phrase in den ersten 10 Sekunden gesprochen wurde.  Für diese Dateien betrug die Genauigkeit 87%. <br><br><h2>  Wofür ist das alles eigentlich? </h2><br>  Die automatische Anrufbewertung hilft dabei, klare KPIs für Call Center-Betreiber zu ermitteln, Best Practices hervorzuheben und zu befolgen sowie die Call Center-Leistung zu steigern.  Es ist jedoch anzumerken, dass Spracherkennungssoftware für ein breiteres Spektrum von Aufgaben verwendet werden kann. <br><br>  Im Folgenden finden Sie einige Beispiele, wie die Spracherkennung Organisationen helfen kann: <br><br><ul><li>  Sammeln und Analysieren von Daten zur Verbesserung der Sprach-UX; </li><li>  Anrufaufzeichnungen analysieren, um Beziehungen und Trends zu identifizieren; </li><li>  Menschen durch Stimme erkennen; </li><li>  Finden und identifizieren Sie Kundenemotionen, um die Benutzerzufriedenheit zu verbessern </li><li>  Steigerung des durchschnittlichen Umsatzes pro Anruf; </li><li>  Abfluss reduzieren; </li><li>  und vieles mehr! </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428598/">https://habr.com/ru/post/de428598/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428582/index.html">Vergessene Geschichte von OOP</a></li>
<li><a href="../de428588/index.html">Zusammenfassung der IT-Ereignisse im November (Teil zwei)</a></li>
<li><a href="../de428590/index.html">Mikrointeraktionen und Mikroaufforderungen in der Schnittstelle</a></li>
<li><a href="../de428592/index.html">Stellen Sie keine "effektiven Manager" mehr ein. Sie sind nicht nur nutzlos, sondern auch schädlich</a></li>
<li><a href="../de428596/index.html">Elon Musk entließ Starlink-Satelliten-Internet-Projektmanager wegen Nichteinhaltung der Fristen</a></li>
<li><a href="../de428600/index.html">SSDs mit Spezialeffekten oder was beim Modden fehlte - Überprüfung des HyperX FURY RGB-Laufwerks</a></li>
<li><a href="../de428602/index.html">Lernen Sie kontroverse Taktiken, Techniken und allgemeines Wissen (ATT @ CK). Unternehmenstaktik. Teil 4</a></li>
<li><a href="../de428604/index.html">Online Data Science Meisterschaft</a></li>
<li><a href="../de428606/index.html">"Das Verständnis der Funktionsweise des Systems ermöglichte viel Hacking": Roy Beniosef über die Android-Entwicklung</a></li>
<li><a href="../de428608/index.html">Medienbeteiligungen einigten sich mit Yandex auf die Entfernung von Raubkopien</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
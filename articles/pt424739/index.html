<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèè üë©üèª‚Äçü§ù‚Äçüë®üèæ üåÜ Registro de eventos com Kafka üö£üèª üïπÔ∏è üèπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° Habr! 

 Descobrimos as √∫ltimas reservas do livro " Apache Kafka. Processamento de fluxo e an√°lise de dados " e o enviamos √† pr√©-impress√£o. Al√©m d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Registro de eventos com Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Ol√° Habr! <br><br>  Descobrimos as √∫ltimas reservas do livro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Kafka. Processamento de fluxo e an√°lise de dados</a> " e o enviamos √† pr√©-impress√£o.  Al√©m disso, recebemos um contrato para o livro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kafka Streams in Action</a> " e come√ßamos a traduzi-lo literalmente na pr√≥xima semana. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Para mostrar o caso interessante do uso da biblioteca Kafka Streams, decidimos traduzir o artigo sobre o paradigma Event Sourcing em Kafka do pr√≥prio Adam Worski, cujo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> sobre o idioma Scala foi publicado h√° duas semanas.  √â ainda mais interessante que a opini√£o de Adam Worski n√£o seja ineg√°vel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , por exemplo, argumenta-se que esse paradigma definitivamente n√£o √© adequado para Kafka.  Ainda mais memor√°vel, esperamos, temos a impress√£o do artigo. <br><br>  O termo "Event Sourcing" √© traduzido como "Event Logging", tanto em nossa publica√ß√£o de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Arquitetura Limpa, de</a> Robert Martin, quanto neste artigo.  Se algu√©m estiver impressionado com a tradu√ß√£o de "eventos de bombeamento", informe-me. <br><a name="habracut"></a><br>  Criando um sistema que fornece registro de eventos (fonte de eventos), mais cedo ou mais tarde nos deparamos com o problema de persist√™ncia (persist√™ncia) - e aqui temos algumas op√ß√µes.  Em primeiro lugar, existe o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">EventStore</a> , uma implementa√ß√£o madura endurecida em batalha.  Como alternativa, voc√™ pode usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">akka-persistence</a> para aproveitar ao m√°ximo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a</a> escalabilidade <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do Cassandra</a> , al√©m de confiar no desempenho do modelo de ator.  Outra op√ß√£o √© o bom e antigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">banco de dados relacional</a> , em que a abordagem <code>CRUD</code> √© combinada com o uso de eventos e o benef√≠cio m√°ximo √© extra√≠do das transa√ß√µes. <br><br>  Al√©m dessas (e talvez de muitas outras) oportunidades que surgiram gra√ßas a v√°rias coisas implementadas recentemente, hoje ficou bastante simples organizar o registro de eventos em cima de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kafka</a> .  Vamos ver como. <br><br>  <b>O que √© log de eventos?</b> <br><br>  Existem v√°rios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">excelentes</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigos</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">introdut√≥rios</a> sobre esse assunto, portanto vou me limitar √† introdu√ß√£o mais concisa.  Ao registrar eventos, n√£o salvamos o estado ‚Äúatual‚Äù das entidades usadas em nosso sistema, mas o fluxo de eventos relacionados a essas entidades.  Cada <i>evento</i> √© um <b>fato</b> que descreve uma mudan√ßa de estado (j√°!) Que <b>ocorreu</b> com o objeto.  Como voc√™ sabe, os fatos n√£o s√£o discutidos e <b>inalterados</b> . <br><br>  Quando temos um fluxo de tais eventos, o estado atual de uma entidade pode ser esclarecido, minimizando todos os eventos relacionados a ela;  no entanto, lembre-se de que o oposto n√£o √© poss√≠vel - preservando apenas o estado "atual", descartamos muitas informa√ß√µes cronol√≥gicas valiosas. <br><br>  O registro de eventos pode <b>coexistir</b> pacificamente com formas mais tradicionais de armazenamento de estado.  Como regra, o sistema processa v√°rios tipos de entidades (por exemplo: usu√°rios, pedidos, mercadorias, ...) e √© bem poss√≠vel que o registro de eventos seja √∫til apenas para algumas dessas categorias.  √â importante notar que aqui n√£o somos confrontados com a escolha de "tudo ou nada";  trata-se apenas do recurso adicional de gerenciamento de estado em nosso aplicativo. <br><br>  <b>Armazenamento de eventos em Kafka</b> <br><br>  O primeiro problema a ser resolvido: como armazenar eventos em Kafka?  Existem tr√™s estrat√©gias poss√≠veis: <br><br><ul><li>  Armazene todos os eventos para todos os tipos de entidades em um <b>√∫nico t√≥pico</b> (com muitos segmentos) </li><li>  Por t√≥pico por tipo de entidade, ou seja, retiramos todos os eventos relacionados ao usu√°rio em um t√≥pico separado, em um separado - todos relacionados ao produto, etc. </li><li>  Por t√≥pico por ess√™ncia, ou seja, por um t√≥pico separado para cada usu√°rio espec√≠fico e nome de cada produto </li></ul><br>  A terceira estrat√©gia (t√≥pico por ess√™ncia) √© praticamente impratic√°vel.  Se, quando cada novo usu√°rio aparecesse no sistema, ele precisasse iniciar um t√≥pico separado, logo o n√∫mero de t√≥picos se tornaria ilimitado.  Qualquer agrega√ß√£o nesse caso seria muito dif√≠cil, por exemplo, seria dif√≠cil indexar todos os usu√°rios em um mecanismo de pesquisa;  voc√™ n√£o apenas teria que consumir um grande n√∫mero de t√≥picos - mas ainda nem todos eles eram conhecidos antecipadamente. <br><br>  Portanto, resta escolher entre 1 e 2. Ambas as op√ß√µes t√™m suas vantagens e desvantagens.  Ter um √∫nico t√≥pico facilita a <b>visualiza√ß√£o global</b> de todos os eventos.  Por outro lado, destacando o t√≥pico para cada tipo de entidade, voc√™ pode dimensionar e segmentar o fluxo de cada entidade individualmente.  A escolha de uma das duas estrat√©gias depende do caso de uso espec√≠fico. <br><br>  Al√©m disso, voc√™ pode implementar as duas estrat√©gias ao mesmo tempo, se tiver espa√ßo de armazenamento adicional: produza t√≥picos por tipo de entidade a partir de um t√≥pico abrangente. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  No restante do artigo, trabalharemos com apenas um tipo de entidade e com um √∫nico t√≥pico, embora o material apresentado possa ser facilmente extrapolado e aplicado para trabalhar com muitos t√≥picos ou tipos de entidade. <br><br>  (EDIT: como observou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chris Hunt</a> , h√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um excelente artigo de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Martin Kleppman</a> , que examinou em detalhes como distribuir eventos por t√≥pico e segmento). <br><br>  <b>As opera√ß√µes mais simples de armazenamento no paradigma de log de eventos</b> <br><br>  A opera√ß√£o mais simples, que √© l√≥gica esperar de um armazenamento que ofere√ßa suporte ao log de eventos, √© ler o estado "atual" (minimizado) de uma entidade espec√≠fica.  Como regra, cada entidade tem um ou outro <code>id</code> .  Conseq√ºentemente, conhecendo esse <code>id</code> , nosso sistema de armazenamento deve retornar o estado atual do objeto. <br><br>  A verdade, em √∫ltimo recurso, ser√° o log de eventos: o estado atual sempre pode ser deduzido do fluxo de eventos associado a uma entidade espec√≠fica.  Para isso, o mecanismo de banco de dados precisar√° de uma fun√ß√£o pura (sem efeitos colaterais) que aceite o evento e o estado inicial e retorne o estado alterado: <code>Event = &amp;gt State =&amp;gt State</code> .  Na presen√ßa de tal fun√ß√£o e do <b>valor do estado inicial, o</b> estado atual √© uma <b>convolu√ß√£o do</b> fluxo de eventos (a fun√ß√£o de mudan√ßa de estado deve estar <b>limpa</b> para que possa ser aplicada livremente repetidamente aos mesmos eventos). <br><br>  Uma implementa√ß√£o simplificada da opera√ß√£o ‚Äúler estado atual‚Äù no Kafka coleta um fluxo de <b>todos os</b> eventos do t√≥pico, os filtra, deixando apenas eventos com o <code>id</code> fornecido e recolhe usando a fun√ß√£o especificada.  Se houver muitos eventos (e com o tempo o n√∫mero de eventos aumentar apenas), essa opera√ß√£o poder√° ficar lenta e consumir muitos recursos.  Mesmo que seu resultado seja armazenado em cache na mem√≥ria e armazenado no n√≥ de servi√ßo, essas informa√ß√µes ainda precisar√£o ser recriadas periodicamente, por exemplo, devido a falhas no n√≥ ou devido ao bloqueio dos dados do cache. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Portanto, √© necess√°ria uma maneira mais racional.  √â aqui que os kafka-streams e os reposit√≥rios de estados s√£o √∫teis.  Os aplicativos Kafka-streams s√£o executados em um cluster inteiro de n√≥s que consomem certos t√≥picos juntos.  Cada n√≥ recebe uma s√©rie de segmentos de t√≥picos consumidos, assim como o consumidor Kafka comum.  No entanto, o kafka-streams fornece opera√ß√µes de dados de n√≠vel superior que facilitam a cria√ß√£o de fluxos derivados. <br><br>  Uma dessas opera√ß√µes em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">kafka-streams</a> √© a convolu√ß√£o de um fluxo no armazenamento local.  Cada armazenamento local cont√©m dados apenas dos segmentos que s√£o consumidos por um determinado n√≥.  Fora da caixa, duas implementa√ß√µes de armazenamento local est√£o dispon√≠veis: <i>na RAM</i> e com base no <i>RocksDB</i> . <br><br>  Voltando ao t√≥pico do registro de eventos, observamos que √© poss√≠vel reduzir o fluxo de eventos no <b>armazenamento de estado</b> mantendo no n√≥ local o "estado atual" de cada entidade dos segmentos designados ao n√≥.  Se usarmos a implementa√ß√£o do armazenamento de estado com base no RocksDB, quantas entidades podemos rastrear em um √∫nico n√≥ depende apenas da quantidade de espa√ßo em disco. <br><br>  Veja como √© a convolu√ß√£o de eventos no armazenamento local ao usar a API Java (serde significa "serializador / desserializador"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Um exemplo completo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">de processamento de pedidos com base em microsservi√ßos</a> est√° dispon√≠vel no site da Confluent. <br><br>  (EDIT: como observado por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sergei Egorov</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nikita Salnikov</a> no Twitter, para um sistema com log de eventos, voc√™ provavelmente precisar√° alterar as configura√ß√µes padr√£o de armazenamento de dados em Kafka para que nenhum tempo ou tamanho limite funcione e, opcionalmente, opcionalmente , habilite a compacta√ß√£o de dados.) <br><br>  <b>Exibir status atual</b> <br><br>  Criamos um reposit√≥rio de estados no qual est√£o localizados os estados atuais de todas as entidades provenientes de segmentos atribu√≠dos ao n√≥, mas como solicitar esse reposit√≥rio agora?  Se a solicita√ß√£o √© local (ou seja, vem do mesmo n√≥ em que o reposit√≥rio est√° localizado), tudo √© bem simples: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Mas e se quisermos solicitar dados localizados em outro n√≥?  E como descobrir o que √© esse n√≥?  Aqui, outro recurso recentemente introduzido no Kafka √© √∫til: <b>consultas interativas</b> .  Com a ajuda deles, voc√™ pode acessar os metadados Kafka e descobrir qual n√≥ processa o segmento de t√≥pico com o <code>id</code> fornecido (nesse caso, a ferramenta para segmenta√ß√£o de t√≥picos √© usada implicitamente): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  Em seguida, voc√™ precisa redirecionar de alguma forma a solicita√ß√£o para o n√≥ correto.  Observe: a maneira espec√≠fica pela qual a comunica√ß√£o entre sites √© implementada e gerenciada - seja REST, akka-remote ou qualquer outra - n√£o pertence √† √°rea de responsabilidade da kafka-streams.  O Kafka simplesmente fornece acesso ao armazenamento de estado e fornece informa√ß√µes em qual n√≥ o armazenamento de estado est√° localizado para o <code>id</code> fornecido. <br><br>  <b>Recupera√ß√£o de desastre</b> <br><br>  As lojas de estado t√™m uma boa apar√™ncia, mas o que acontece quando um n√≥ falha?  Reconstruir um armazenamento local do estado para um determinado segmento tamb√©m pode ser uma opera√ß√£o cara.  Isso pode provocar atrasos aumentados ou perda de solicita√ß√µes por um longo tempo, pois os kafka-streams precisar√£o ser reequilibrados (ap√≥s adicionar ou remover um n√≥). <br><br>  √â por isso que, por padr√£o, os armazenamentos de estado de longo prazo s√£o registrados: ou seja, todas as altera√ß√µes feitas no reposit√≥rio s√£o gravadas adicionalmente no t√≥pico do registro de altera√ß√µes.  Este t√≥pico est√° compactado (porque para cada <code>id</code> , estamos interessados ‚Äã‚Äãapenas no √∫ltimo registro, sem um hist√≥rico de altera√ß√µes, pois o hist√≥rico √© armazenado nos pr√≥prios eventos) - portanto, √© o menor poss√≠vel.  √â por isso que a recria√ß√£o do armazenamento em outro n√≥ pode ocorrer muito mais rapidamente. <br><br>  No entanto, com o reequil√≠brio nesse caso, atrasos ainda s√£o poss√≠veis.  Para reduzi-los ainda mais, o kafka-streams oferece a capacidade de armazenar v√°rias <b>r√©plicas de backup</b> ( <code>num.standby.replicas</code> ) para cada reposit√≥rio.  Essas r√©plicas aplicam todas as atualiza√ß√µes recuperadas dos t√≥picos com os logs de altera√ß√µes √† medida que ficam dispon√≠veis e est√£o prontas para alternar para o modo principal de armazenamento de estado para um determinado segmento assim que o armazenamento principal atual falhar. <br><br>  <b>Coer√™ncia</b> <br><br>  Com as configura√ß√µes padr√£o, o Kafka fornece pelo menos uma entrega √∫nica.  Ou seja, no caso de uma falha no n√≥, algumas mensagens podem ser entregues v√°rias vezes.  Por exemplo, √© poss√≠vel que um evento espec√≠fico seja aplicado duas vezes ao armazenamento de estado se o sistema travar ap√≥s o armazenamento de estado mudar para o log, mas antes que o deslocamento desse evento espec√≠fico seja executado.  Talvez isso n√£o cause dificuldades: nossa fun√ß√£o de atualiza√ß√£o de estado ( <code>Event = &amp;gt State =&amp;gt State</code> ) normalmente pode lidar com essas situa√ß√µes.  No entanto, pode n√£o ser capaz de lidar: nesse caso, as garantias de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">entrega estritamente √∫nica</a> fornecidas pela Kafka podem ser usadas.  Essas garantias se aplicam apenas ao ler e escrever t√≥picos Kafka, mas √© o que estamos fazendo aqui: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em segundo plano, todas as entradas nos t√≥picos Kafka s√£o reduzidas √† atualiza√ß√£o do log de altera√ß√µes do armazenamento de estados</a> e √† execu√ß√£o de compensa√ß√µes.  Tudo isso pode ser feito <b>na forma de transa√ß√µes</b> . <br><br>  Portanto, se nossa fun√ß√£o de atualizar o estado exigir isso, podemos ativar a sem√¢ntica do processamento de fluxos ‚Äúentrega estritamente √∫nica‚Äù usando uma √∫nica op√ß√£o de configura√ß√£o: <code>processing.guarantee</code> .  Por esse motivo, o desempenho cai, mas nada √© em v√£o. <br><br>  <b>Escuta de evento</b> <br><br>  Agora que abordamos o b√°sico - consultar o "estado atual" e atualiz√°-lo para cada entidade - e quanto a desencadear <b>efeitos colaterais</b> ?  Em algum momento, isso ser√° necess√°rio, por exemplo, para: <br><br><ul><li>  Enviando e-mails de notifica√ß√£o </li><li>  Indexa√ß√£o de entidade do mecanismo de pesquisa </li><li>  Chamando servi√ßos externos via REST (ou SOAP, CORBA, etc.) </li></ul><br>  Todas essas tarefas s√£o, em um grau ou outro, bloqueadas e relacionadas a opera√ß√µes de E / S (isso √© natural para efeitos colaterais), portanto, provavelmente n√£o √© uma boa ideia execut√°-las dentro da estrutura da l√≥gica de atualiza√ß√£o de estado: como resultado, a frequ√™ncia de falhas no loop principal pode aumentar eventos e, em termos de desempenho, haver√° um gargalo. <br><br>  Al√©m disso, uma fun√ß√£o com l√≥gica de atualiza√ß√£o de estado (E <code>Event = &amp;gt State =&amp;gt State</code> ) pode ser executada v√°rias vezes (no caso de falhas ou reinicializa√ß√µes), e na maioria das vezes queremos minimizar o n√∫mero de casos em que os efeitos colaterais de um evento espec√≠fico s√£o executados v√°rias vezes. <br><br>  Felizmente, como trabalhamos com t√≥picos de Kafka, temos uma boa flexibilidade.  No est√°gio de fluxos, onde o armazenamento de estado √© atualizado, os eventos podem ser emitidos inalterados (ou, se necess√°rio, tamb√©m em uma forma modificada), e o fluxo / t√≥pico resultante (no Kafka esses conceitos s√£o equivalentes) pode ser consumido como voc√™ desejar.  Al√©m disso, ele pode ser consumido antes ou depois do est√°gio de atualiza√ß√£o do estado.  Finalmente, podemos controlar como lan√ßamos efeitos colaterais: pelo menos uma vez ou no m√°ximo uma vez.  A primeira op√ß√£o √© fornecida se voc√™ executar o deslocamento do evento-t√≥pico consumido somente depois que todos os efeitos colaterais forem conclu√≠dos com √™xito.  Por outro lado, com o m√°ximo de uma corrida, realizamos mudan√ßas at√© o in√≠cio dos efeitos colaterais. <br><br>  Existem v√°rias op√ß√µes para desencadear efeitos colaterais, eles dependem da situa√ß√£o pr√°tica espec√≠fica.  Antes de tudo, voc√™ pode definir o est√°gio Kafka-streams em que os efeitos colaterais de cada evento s√£o acionados como parte da fun√ß√£o de processamento de fluxo. <br>  A configura√ß√£o de um mecanismo desse tipo √© bastante simples, mas essa solu√ß√£o n√£o √© flex√≠vel quando voc√™ precisa lidar com novas tentativas, controlar compensa√ß√µes e compensar compensa√ß√µes por muitos eventos ao mesmo tempo.  Nesses casos mais complexos, pode ser mais apropriado determinar o processamento usando, digamos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">kafka reativo</a> ou outro mecanismo que consome os t√≥picos Kafka "diretamente". <br><br>  Tamb√©m √© poss√≠vel que um evento <b>ative outros eventos</b> - por exemplo, o evento "pedido" pode acionar os eventos "prepara√ß√£o para expedi√ß√£o" e "notifica√ß√£o ao cliente".  Isso tamb√©m pode ser implementado no est√°gio kafka-streams. <br><br>  Por fim, se quisermos armazenar eventos ou alguns dados extra√≠dos de eventos em um banco de dados ou mecanismo de pesquisa, digamos, no ElasticSearch ou no PostgreSQL, poder√≠amos usar o conector <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kafka Connect</a> , que processar√° para n√≥s todos os detalhes relacionados ao consumo de t√≥picos. <br><br>  <b>Criando vistas e proje√ß√µes</b> <br><br>  Normalmente, os requisitos do sistema n√£o se limitam a consultar e processar apenas fluxos de entidade √∫nica.  Agrega√ß√£o, combina√ß√£o de v√°rios fluxos de eventos tamb√©m deve ser suportada.  Esses fluxos combinados s√£o geralmente chamados de <b>proje√ß√µes</b> e, quando recolhidos, podem ser usados ‚Äã‚Äãpara criar <b>representa√ß√µes de dados</b> .  √â poss√≠vel implement√°-los com o Kafka? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  Mais uma vez sim!  Lembre-se de que, em princ√≠pio, estamos lidando simplesmente com o t√≥pico Kafka, onde nossos eventos s√£o armazenados;  portanto, temos todo o poder do Kafka Consumer / Producer bruto, do combinador kafka-streams e at√© do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">KSQL</a> - tudo isso √© √∫til para definir proje√ß√µes.  Por exemplo, usando kafka-streams, voc√™ pode filtrar um fluxo, exibir, agrupar por chave, agregar em janelas tempor√°rias ou de sess√£o, etc.  no n√≠vel do c√≥digo ou usando o KSQL semelhante ao SQL. <br><br>  Esses fluxos podem ser armazenados e fornecidos para consultas por um longo tempo usando armazenamentos de estado e consultas interativas, assim como fizemos com os fluxos de entidades individuais. <br><br>  <b>O que vem a seguir</b> <br><br>  Para impedir o fluxo infinito de eventos √† medida que o sistema se desenvolve, uma op√ß√£o de compacta√ß√£o, como salvar <b>instant√¢neos do</b> "estado atual", pode ser √∫til.  Assim, podemos nos limitar a armazenar apenas alguns instant√¢neos recentes e os eventos que ocorreram ap√≥s a sua cria√ß√£o. <br><br>  Embora o Kafka n√£o tenha suporte direto para snapshots (e em alguns outros sistemas operando com o princ√≠pio de registrar eventos), voc√™ pode definitivamente adicionar esse tipo de funcionalidade, usando alguns dos mecanismos acima, como fluxos, consumidores, lojas de estado, etc. d. <br><br>  <b>Sum√°rio</b> <br><br>  Embora, inicialmente, o Kafka n√£o tenha sido projetado com um olho no paradigma de registro de eventos, na verdade, √© um mecanismo de dados de streaming com suporte para <b>replica√ß√£o de t√≥picos</b> , segmenta√ß√£o, <b>reposit√≥rios de estados</b> e <b>APIs de streaming</b> , e √© muito flex√≠vel ao mesmo tempo.  Portanto, al√©m do Kafka, voc√™ pode implementar facilmente um sistema de registro de eventos.  Al√©m disso, como no contexto de tudo o que acontece, sempre teremos um t√≥pico Kafka, ganharemos flexibilidade adicional, pois podemos trabalhar com APIs de streaming de alto n√≠vel ou com consumidores de baixo n√≠vel. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt424739/">https://habr.com/ru/post/pt424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt424729/index.html">Por que o compilador transformou meu loop condicional em um infinito?</a></li>
<li><a href="../pt424731/index.html">Hist√≥rico de suporte t√©cnico quente ou Por que o AutoCAD exclui objetos proxy?</a></li>
<li><a href="../pt424733/index.html">P√≠lula azul STM32F103 como PLC</a></li>
<li><a href="../pt424735/index.html">Como isso funciona, e a psicoterapia conversacional funciona de todo</a></li>
<li><a href="../pt424737/index.html">42¬∫ protocolo da vida, o universo e tudo isso: "discurso de despedida"</a></li>
<li><a href="../pt424741/index.html">Pessoal, vamos viver em paz ou sobre o campo Senha ao registrar</a></li>
<li><a href="../pt424745/index.html">A atividade de GosSOPKI aumentou</a></li>
<li><a href="../pt424747/index.html">O lugar onde o som vive</a></li>
<li><a href="../pt424751/index.html">Como o sistema biom√©trico unificado funciona</a></li>
<li><a href="../pt424753/index.html">O que h√° de novo no YouTrack 2018.3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
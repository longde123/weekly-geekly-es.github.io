<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöØ ‚è© üëàüèΩ Wir haben den Tokio-Scheduler zehnmal beschleunigt üé¥ üö† üêç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir bereiten gerade die n√§chste Hauptversion von Tokio vor, eine asynchrone Laufzeitumgebung f√ºr Rust. Am 13. Oktober wurde eine Poolanforderung mit e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir haben den Tokio-Scheduler zehnmal beschleunigt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472242/"> Wir bereiten gerade die n√§chste Hauptversion von Tokio vor, eine asynchrone Laufzeitumgebung f√ºr Rust.  Am 13. Oktober wurde eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Poolanforderung</a> mit einem vollst√§ndig neu geschriebenen Taskplaner zum Zusammenf√ºhren in eine Zweigstelle ausgegeben.  Das Ergebnis sind enorme Leistungsverbesserungen und eine verringerte Latenz.  Einige Tests haben eine zehnfache Beschleunigung festgestellt!  Wie √ºblich spiegeln synthetische Tests nicht den tats√§chlichen Nutzen in der Realit√§t wider.  Daher haben wir auch √ºberpr√ºft, wie sich √Ñnderungen im Scheduler auf reale Aufgaben wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hyper</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tonic</a> auswirken (Spoiler: Das Ergebnis ist wunderbar). <br><br>  Ich bereitete mich auf die Arbeit an einem neuen Planer vor und suchte nach thematischen Ressourcen.  Abgesehen von den tats√§chlichen Implementierungen wurde nichts Besonderes gefunden.  Ich fand auch, dass der Quellcode f√ºr vorhandene Implementierungen schwer zu navigieren ist.  Um dies zu beheben, haben wir versucht, den Tokio-Sheduler so sauber wie m√∂glich zu schreiben.  Ich hoffe, dieser ausf√ºhrliche Artikel √ºber die Implementierung des Schedulers hilft denjenigen, die sich in derselben Position befinden und erfolglos nach Informationen zu diesem Thema suchen. <br><br>  Der Artikel beginnt mit einer allgemeinen √úberpr√ºfung des Designs, einschlie√ülich der Richtlinien zur Auftragserfassung.  Tauchen Sie dann im neuen Tokio-Scheduler in die Details spezifischer Optimierungen ein. <br><a name="habracut"></a><br>  Ber√ºcksichtigte Optimierungen: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neues std :: future Task System</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auswahl des besten Warteschlangenalgorithmus</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Optimieren Sie Nachrichtenvorlagen</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drosselklappenerfassung</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reduzieren Sie die Synchronisation zwischen Threads</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Speicherzuordnung reduzieren</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reduzierte Anzahl atomarer Verbindungen</a> </li></ul><br>  Wie Sie sehen k√∂nnen, lautet das Hauptthema ‚ÄûReduktion‚Äú.  Der schnellste Code ist schlie√ülich sein Mangel! <br><br>  Wir werden auch √ºber das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testen des neuen Schedulers</a> sprechen.  Es ist sehr schwierig, den richtigen parallelen Code ohne Sperren zu schreiben.  Es ist besser, langsam, aber korrekt als schnell zu arbeiten, aber mit St√∂rungen, insbesondere wenn die Fehler die Speichersicherheit betreffen.  Die beste Option sollte jedoch schnell und fehlerfrei funktionieren. Deshalb haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">loom geschrieben</a> , ein Tool zum Testen der Parallelit√§t. <br><br>  Bevor ich mich mit dem Thema befasse, m√∂chte ich mich bedanken bei: <br><br><ul><li> <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@withoutboats</a></b> und andere, die an der <code>async / await</code> Funktion in Rust gearbeitet haben.  Du hast einen tollen Job gemacht.  Dies ist eine Killer-Funktion. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@cramertj</a></b> und andere, die <code>std::task</code> .  Dies ist eine enorme Verbesserung gegen√ºber dem, was es vorher war.  Und toller Code. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Buoyant</a></b> , der Sch√∂pfer von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Linkerd</a> und vor allem mein Arbeitgeber.  Vielen Dank, dass ich so viel Zeit mit diesem Job verbringen durfte.  Wenn sich jemand f√ºr das Service-Mesh interessiert, schauen Sie sich Linkerd an.  In K√ºrze werden alle in diesem Artikel beschriebenen Vorteile enthalten sein. <br></li><li>  <b><a href="">Entscheiden Sie sich</a></b> f√ºr eine so gute Planerimplementierung. </li></ul><br>  Nehmen Sie eine Tasse Kaffee und lehnen Sie sich zur√ºck.  Dies wird ein langer Artikel sein. <br><br><h1>  Wie arbeiten Planer? </h1><br>  Die Aufgabe des Schuppers ist es, die Arbeit zu planen.  Die Anwendung ist in Arbeitseinheiten unterteilt, die wir <i>Aufgaben</i> nennen <i>werden</i> .  Eine Aufgabe gilt als ausf√ºhrbar, wenn sie in ihrer Ausf√ºhrung voranschreiten kann, aber nicht mehr ausgef√ºhrt wird, oder wenn sie f√ºr eine externe Ressource gesperrt ist.  Aufgaben sind insofern unabh√§ngig, als beliebig viele Aufgaben gleichzeitig ausgef√ºhrt werden k√∂nnen.  Der Scheduler ist daf√ºr verantwortlich, Aufgaben in einem laufenden Zustand auszuf√ºhren, bis sie in den Standby-Modus zur√ºckkehren.  Bei der Ausf√ºhrung von Aufgaben wird der Aufgabe Prozessorzeit zugewiesen - eine globale Ressource. <br><br>  Der Artikel beschreibt User Space Scheduler, dh das Arbeiten auf Betriebssystem-Threads (die wiederum von einem Sheduler auf Kernel-Ebene gesteuert werden).  Der Tokio-Scheduler f√ºhrt Rust-Futures aus, die als "asynchrone gr√ºne Threads" betrachtet werden k√∂nnen.  Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gemischtes M: N-Streaming-</a> Muster, bei dem viele Benutzeroberfl√§chenaufgaben auf mehrere Threads des Betriebssystems gemultiplext werden. <br><br>  Es gibt viele verschiedene M√∂glichkeiten, einen Sheduler zu simulieren, jede mit ihren eigenen Vor- und Nachteilen.  Auf der einfachsten Ebene kann der Scheduler als <i>Ausf√ºhrungswarteschlange</i> und als <i>Prozessor</i> modelliert werden, der ihn auseinander zieht.  Ein Prozessor ist ein Code, der in einem Thread ausgef√ºhrt wird.  Im Pseudocode wird Folgendes ausgef√ºhrt: <br><br><pre> <code class="plaintext hljs">while let Some(task) = self.queue.pop() { task.run(); }</code> </pre> <br>  Wenn eine Aufgabe realisierbar wird, wird sie in die Ausf√ºhrungswarteschlange eingef√ºgt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ff6/1f4/18f/ff61f418f73f08c62b5e9eaeacaeb8ed.png"><br><br>  Obwohl Sie ein System entwerfen k√∂nnen, in dem Ressourcen, Aufgaben und ein Prozessor im selben Thread vorhanden sind, bevorzugt Tokio die Verwendung mehrerer Threads.  Wir leben in einer Welt, in der ein Computer viele Prozessoren hat.  Die Entwicklung eines Single-Threaded-Schedulers f√ºhrt zu einer unzureichenden Eisenbeladung.  Wir wollen alle CPUs nutzen.  Es gibt verschiedene M√∂glichkeiten, dies zu tun: <br><br><ul><li>  Eine globale Ausf√ºhrungswarteschlange, viele Prozessoren. <br></li><li>  Viele Prozessoren mit jeweils eigener Ausf√ºhrungswarteschlange. </li></ul><br><h3>  Eine Runde, viele Prozessoren </h3><br>  Dieses Modell verf√ºgt √ºber eine globale Ausf√ºhrungswarteschlange.  Wenn die Aufgaben abgeschlossen sind, werden sie am Ende der Warteschlange platziert.  Es gibt mehrere Prozessoren, die sich jeweils in einem separaten Thread befinden.  Jeder Prozessor √ºbernimmt eine Aufgabe vom Kopf der Warteschlange oder blockiert den Thread, wenn keine Aufgaben verf√ºgbar sind. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/85c/8d0/23d/85c8d023dfeba249bba01234e0e8783a.png"><br><br>  Die Ausf√ºhrungslinie muss von vielen Herstellern und Verbrauchern unterst√ºtzt werden.  Normalerweise wird eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aufdringliche</a> Liste verwendet, in der die Struktur jeder Aufgabe einen Zeiger auf die n√§chste Aufgabe in der Warteschlange enth√§lt (anstatt die Aufgaben in eine verkn√ºpfte Liste zu packen).  Somit kann eine Speicherzuweisung f√ºr Push- und Pop-Operationen vermieden werden.  Sie k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Push-Operation ohne Sperren verwenden</a> , aber um die Verbraucher zu koordinieren, ist der Mutex f√ºr die Pop-Operation erforderlich (es ist technisch m√∂glich, eine Mehrbenutzer-Warteschlange ohne Sperren zu implementieren). <br><br>  In der Praxis ist der Aufwand f√ºr einen ordnungsgem√§√üen Schutz vor Schl√∂ssern jedoch mehr als nur die Verwendung eines Mutex. <br><br>  Dieser Ansatz wird h√§ufig f√ºr einen allgemeinen Thread-Pool verwendet, da er mehrere Vorteile bietet: <br><br><ul><li>  Aufgaben sind ziemlich geplant. <br></li><li>  Relativ einfache Implementierung.  Eine mehr oder weniger Standardwarteschlange ist mit dem oben beschriebenen Prozessorzyklus verbunden. </li></ul><br>  Ein kurzer Hinweis zur fairen (gerechten) Planung.  Das bedeutet, dass die Aufgaben ehrlich ausgef√ºhrt werden: Wer fr√ºher kam, ist derjenige, der fr√ºher gegangen ist.  Allzweckplaner versuchen fair zu sein, aber es gibt Ausnahmen wie die Parallelisierung √ºber Fork-Join, bei denen die Geschwindigkeit der Ergebnisberechnung und nicht die Gerechtigkeit f√ºr jede einzelne Teilaufgabe ein wichtiger Faktor ist. <br><br>  Dieses Modell hat einen Nachteil.  Alle Prozessoren beantragen Aufgaben vom Kopf der Warteschlange aus.  F√ºr Allzweck-Threads ist dies normalerweise kein Problem.  Die Zeit zum Ausf√ºhren einer Aufgabe √ºberschreitet bei weitem die Zeit zum Abrufen aus der Warteschlange.  Wenn Aufgaben √ºber einen l√§ngeren Zeitraum ausgef√ºhrt werden, wird der Wettbewerb in der Warteschlange verringert.  Es wird jedoch erwartet, dass asynchrone Rust-Aufgaben sehr schnell abgeschlossen werden.  In diesem Fall erh√∂hen sich die Gemeinkosten f√ºr den Kampf in der Warteschlange erheblich. <br><br><h3>  Parallelit√§t und mechanische Sympathie </h3><br>  Um maximale Leistung zu erzielen, m√ºssen wir die Hardwarefunktionen optimal nutzen.  Der Begriff ‚Äûmechanische Sympathie‚Äú f√ºr Software wurde zuerst von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Martin Thompson verwendet</a> (dessen Blog nicht mehr aktualisiert, aber immer noch sehr informativ ist). <br><br>  Eine ausf√ºhrliche Er√∂rterung der Implementierung von Parallelit√§t in modernen Ger√§ten w√ºrde den Rahmen dieses Artikels sprengen.  Im Allgemeinen erh√∂ht Eisen die Produktivit√§t nicht aufgrund von Beschleunigung, sondern aufgrund der Einf√ºhrung einer gr√∂√üeren Anzahl von CPU-Kernen (sogar mein Laptop hat sechs!). Jeder Kern kann in winzigen Zeitintervallen gro√üe Rechenmengen ausf√ºhren.  Aktionen wie der Zugriff auf den Cache und den Speicher ben√∂tigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im</a> Vergleich zur Ausf√ºhrungszeit auf der CPU <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">viel mehr Zeit</a> .  Um Anwendungen zu beschleunigen, m√ºssen Sie daher die Anzahl der CPU-Anweisungen f√ºr jeden Speicherzugriff maximieren.  Obwohl der Compiler sehr hilfreich ist, m√ºssen wir noch √ºber Dinge wie Ausrichtung und Speicherzugriffsmuster nachdenken. <br><br>  Separate Threads funktionieren separat sehr √§hnlich wie ein einzelner isolierter Thread, <b>bis</b> mehrere Threads gleichzeitig dieselbe Cache-Zeile √§ndern (gleichzeitige Mutationen) oder eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">konsistente Konsistenz</a> erforderlich ist.  In diesem Fall wird das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CPU-Cache-Koh√§renzprotokoll</a> aktiviert.  Es garantiert die Relevanz des Caches jeder CPU. <br><br>  Die Schlussfolgerung liegt auf der Hand: Vermeiden Sie nach M√∂glichkeit die Synchronisation zwischen Threads, da diese langsam ist. <br><br><h3>  Viele Prozessoren mit jeweils eigener Ausf√ºhrungswarteschlange </h3><br>  Ein weiteres Modell sind mehrere Single-Threaded-Scheduler.  Jeder Prozessor erh√§lt eine eigene Ausf√ºhrungswarteschlange, und Aufgaben werden auf einem bestimmten Prozessor festgelegt.  Dies vermeidet das Synchronisationsproblem vollst√§ndig.  Da das Rust-Aufgabenmodell die F√§higkeit erfordert, eine Aufgabe von einem beliebigen Thread in die Warteschlange zu stellen, sollte es dennoch eine thread-sichere M√∂glichkeit geben, Aufgaben in den Scheduler einzugeben.  Entweder unterst√ºtzt die Ausf√ºhrungswarteschlange jedes Prozessors die thread-sichere Push-Operation (MPSC), oder jeder Prozessor verf√ºgt √ºber <b>zwei</b> Ausf√ºhrungswarteschlangen: unsynchronisiert und thread-sicher. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6d/a3c/35e/c6da3c35e7f6fb28b63fdb3ff6417882.png"><br><br>  Diese Strategie verwendet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Seastar</a> .  Da wir die Synchronisation fast vollst√§ndig vermeiden, bietet diese Strategie eine sehr gute Geschwindigkeit.  Aber sie l√∂st nicht alle Probleme.  Wenn die Arbeitslast nicht vollst√§ndig homogen ist, sind einige Prozessoren unter Last, w√§hrend andere im Leerlauf sind, was zu einer nicht optimalen Ressourcennutzung f√ºhrt.  Dies liegt daran, dass Aufgaben auf einem bestimmten Prozessor festgelegt sind.  Wenn eine Gruppe von Aufgaben in einem Paket auf einem Prozessor geplant ist, erf√ºllt sie im Alleingang die Spitzenlast, auch wenn andere im Leerlauf sind. <br><br>  Die meisten ‚Äûrealen‚Äú Workloads sind nicht homogen.  Daher meiden Allzweckplaner dieses Modell normalerweise. <br><br><h3>  Job Capture Scheduler </h3><br>  Der Scheduler mit Work-Stealing-Schedulern basiert auf dem Sharded-Scheduler-Modell und l√∂st das Problem des unvollst√§ndigen Ladens von Hardwareressourcen.  Jeder Prozessor unterst√ºtzt seine eigene Ausf√ºhrungswarteschlange.  Aufgaben, die ausgef√ºhrt werden, werden in die Ausf√ºhrungswarteschlange des aktuellen Prozessors gestellt und funktionieren darauf.  Wenn der Prozessor jedoch inaktiv ist, √ºberpr√ºft er die Warteschlangen des Schwesterprozessors und versucht, etwas von dort abzurufen.  Der Prozessor wechselt erst in den Ruhemodus, nachdem er keine Arbeit in Peer-to-Peer-Ausf√ºhrungswarteschlangen gefunden hat. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/561/9a9/02c/5619a902c1d95252d20ac7db1273e57f.png"><br><br>  Auf Modellebene ist dies der Ansatz ‚ÄûDas Beste aus zwei Welten‚Äú.  Unter Last arbeiten Prozessoren unabh√§ngig voneinander und vermeiden Overhead-Synchronisation.  In F√§llen, in denen die Last zwischen den Prozessoren ungleichm√§√üig verteilt ist, kann der Scheduler sie neu verteilen.  Aus diesem Grund werden solche Scheduler in <a href="">Go</a> , <a href="">Erlang</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Java</a> und anderen Sprachen verwendet. <br><br>  Der Nachteil ist, dass dieser Ansatz viel komplizierter ist.  Der Warteschlangenalgorithmus muss die Auftragserfassung unterst√ºtzen. F√ºr eine reibungslose Ausf√ºhrung ist eine <b>gewisse</b> Synchronisierung zwischen den Prozessoren erforderlich.  Wenn es nicht korrekt implementiert ist, kann der Overhead f√ºr die Erfassung gr√∂√üer sein als die Verst√§rkung. <br><br>  Stellen Sie sich folgende Situation vor: Prozessor A f√ºhrt derzeit eine Aufgabe aus und hat eine leere Ausf√ºhrungswarteschlange.  Prozessor B ist inaktiv;  Er versucht, eine Aufgabe zu erfassen, schl√§gt jedoch fehl und wechselt in den Schlafmodus.  Dann werden 20 Aufgaben aus der Aufgabe von Prozessor A erzeugt.  Im Idealfall sollte Prozessor B aufwachen und einige davon greifen.  Zu diesem Zweck m√ºssen bestimmte Heuristiken im Scheduler implementiert werden, wobei die Prozessoren den schlafenden Peer-Prozessoren signalisieren, dass neue Aufgaben in ihrer Warteschlange erscheinen.  Dies erfordert nat√ºrlich eine zus√§tzliche Synchronisation, so dass solche Operationen am besten minimiert werden. <br><br>  Zusammenfassend: <br><br><ul><li>  Je weniger Synchronisation, desto besser. <br></li><li>  Die Auftragserfassung ist der optimale Algorithmus f√ºr Allzweckplaner. <br></li><li>  Jeder Prozessor arbeitet unabh√§ngig von den anderen, es ist jedoch eine gewisse Synchronisierung erforderlich, um die Arbeit zu erfassen. </li></ul><br><h1>  Tokio 0.1 Scheduler </h1><br>  Der erste Arbeitsplaner f√ºr Tokio wurde im M√§rz 2018 ver√∂ffentlicht.  Dies war der erste Versuch, der auf einigen Annahmen beruhte, die sich als falsch herausstellten. <br><br>  Erstens schlug der Tokio 0.1-Scheduler vor, Prozessorthreads zu schlie√üen, wenn sie f√ºr eine bestimmte Zeit inaktiv waren.  Der Scheduler wurde urspr√ºnglich als "Allzweck" -System f√ºr den Rust-Thread-Pool erstellt.  Zu diesem Zeitpunkt befand sich die Tokio-Laufzeit noch in einem fr√ºhen Entwicklungsstadium.  Dann ging das Modell davon aus, dass E / A-Aufgaben auf demselben Thread wie der E / A-Selektor ausgef√ºhrt werden (epoll, kqueue, iocp ...).  Weitere Rechenaufgaben k√∂nnten an den Thread-Pool gerichtet werden.  In diesem Zusammenhang wird eine flexible Konfiguration der Anzahl der aktiven Threads angenommen, sodass es sinnvoller ist, inaktive Threads zu deaktivieren.  Im Scheduler mit Joberfassung wurde das Modell jedoch auf die Ausf√ºhrung <i>aller</i> asynchronen Aufgaben umgestellt. In diesem Fall ist es sinnvoll, immer eine kleine Anzahl von Threads im aktiven Zustand zu halten. <br><br>  Zweitens wurde dort eine Zweiwege- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quertr√§gerlinie</a> implementiert.  Diese Implementierung basiert auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bidirektionalen Chase-Lev-Linie</a> und ist aus den unten beschriebenen Gr√ºnden nicht f√ºr die Planung unabh√§ngiger asynchroner Aufgaben geeignet. <br><br>  Drittens erwies sich die Implementierung als zu kompliziert.  Dies liegt zum Teil daran, dass dies mein erster Taskplaner war.  Au√üerdem war ich zu ungeduldig, wenn ich Atomics in Zweigen verwendete, in denen der Mutex gut funktioniert h√§tte.  Eine wichtige Lektion ist, dass sehr oft Mutexe am besten funktionieren. <br><br>  Schlie√ülich gab es viele kleinere M√§ngel bei der anf√§nglichen Implementierung.  In den Anfangsjahren haben sich die Implementierungsdetails des asynchronen Rust-Modells erheblich weiterentwickelt, aber die Bibliotheken haben die API jederzeit stabil gehalten.  Dies f√ºhrte zu einer Anh√§ufung technischer Schulden. <br><br>  Jetzt n√§hert sich Tokio der ersten Hauptversion - und wir k√∂nnen all diese Schulden bezahlen und aus den Erfahrungen lernen, die wir in den Jahren der Entwicklung gesammelt haben.  Dies ist eine aufregende Zeit! <br><br><h1>  Tokio Scheduler der n√§chsten Generation </h1><br>  Jetzt ist es Zeit, sich genauer anzusehen, was sich im neuen Scheduler ge√§ndert hat. <br><br><a name="1"></a><h3>  Neues Aufgabensystem </h3><br>  Zun√§chst ist es wichtig hervorzuheben, was <b>nicht</b> Teil von Tokio ist, aber f√ºr die Verbesserung der Effizienz von entscheidender Bedeutung ist: Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neues Aufgabensystem</a> in <code>std</code> , das urspr√ºnglich von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Taylor Kramer entwickelt wurde</a> .  Dieses System bietet die Hooks, die der Scheduler implementieren muss, um asynchrone Rust-Aufgaben auszuf√ºhren, und das System ist wirklich hervorragend entworfen und implementiert.  Es ist viel leichter und flexibler als die vorherige Iteration. <br><br>  Die <code>Waker</code> Struktur aus den Ressourcen signalisiert, dass eine <i>realisierbare</i> Aufgabe in die Scheduler-Warteschlange gestellt werden sollte.  Im neuen Aufgabensystem ist dies eine Zwei-Zeiger-Struktur, w√§hrend sie zuvor viel gr√∂√üer war.  Das Reduzieren der Gr√∂√üe ist wichtig, um den Aufwand f√ºr das Kopieren des <code>Waker</code> Werts an verschiedenen Stellen zu minimieren. <code>Waker</code> nimmt es weniger Platz in den Strukturen ein, sodass Sie wichtigere Daten in die Cache-Zeile dr√ºcken k√∂nnen.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vtable-</a> Design hat eine Reihe von Optimierungen vorgenommen, die wir sp√§ter diskutieren werden. <br><br><a name="2"></a><h3>  Auswahl des besten Warteschlangenalgorithmus </h3><br>  Die Ausf√ºhrungswarteschlange befindet sich in der Mitte des Schedulers.  Daher ist dies die wichtigste zu behebende Komponente.  Der urspr√ºngliche Tokio-Scheduler verwendete eine Zwei-Wege- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Crossbeam-Warteschlange</a> : eine Single-Source-Implementierung (Produzent) und viele Konsumenten.  Eine Aufgabe wird an einem Ende platziert und Werte werden vom anderen abgerufen.  Meistens "pusht" der Thread die Werte vom Ende der Warteschlange, aber manchmal fangen andere Threads die Arbeit ab und f√ºhren dieselbe Operation aus.  Die Zwei-Wege-Warteschlange wird von einem Array und einer Reihe von Indizes unterst√ºtzt, die Kopf und Schwanz verfolgen.  Wenn die Warteschlange voll ist, f√ºhrt die Einf√ºhrung zu einer Erh√∂hung des Speicherplatzes.  Ein neues, gr√∂√üeres Array wird zugewiesen und die Werte werden in den neuen Speicher verschoben. <br><br>  Die F√§higkeit zu wachsen wird durch Komplexit√§t und Overhead erreicht.  Push / Pop-Operationen sollten dieses Wachstum ber√ºcksichtigen.  Dar√ºber hinaus ist das Freigeben des urspr√ºnglichen Arrays mit zus√§tzlichen Schwierigkeiten verbunden.  In einer Garbage Collection (GC) -Sprache verl√§sst das alte Array den G√ºltigkeitsbereich und wird schlie√ülich vom GC gel√∂scht.  Rust wird jedoch ohne GC geliefert.  Dies bedeutet, dass wir selbst f√ºr die Freigabe des Arrays verantwortlich sind, Threads jedoch gleichzeitig versuchen k√∂nnen, auf den Speicher zuzugreifen.  Um dieses Problem zu l√∂sen, verwendet Crossbeam eine epochenbasierte Rekultivierungsstrategie.  Obwohl es nicht viele Ressourcen erfordert, f√ºgt es dem Hauptpfad (Hot Path) nicht trivialen Overhead hinzu.  Jede Operation sollte nun atomare RMW-Operationen (Lesen-√Ñndern-Schreiben) am Ein- und Ausgang kritischer Abschnitte ausf√ºhren, um anderen Threads zu signalisieren, dass der Speicher verwendet wird und nicht gel√∂scht werden kann. <br><br>  Aufgrund des Overheads f√ºr das Wachstum der Ausf√ºhrungswarteschlange ist es sinnvoll zu denken: Ist die Unterst√ºtzung f√ºr dieses Wachstum wirklich notwendig?  Diese Frage veranlasste mich schlie√ülich, den Planer neu zu schreiben.  Die neue Strategie besteht darin, f√ºr jeden Prozess eine feste Warteschlangengr√∂√üe zu haben.  Wenn die Warteschlange voll ist, wird die Aufgabe nicht mit der lokalen Warteschlange vergr√∂√üert, sondern mit mehreren Verbrauchern und mehreren Produzenten in die globale Warteschlange verschoben.  Prozessoren √ºberpr√ºfen diese globale Warteschlange regelm√§√üig, jedoch mit einer viel geringeren H√§ufigkeit als die lokale. <br><br>  Im Rahmen eines der ersten Experimente haben wir den Quertr√§ger durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mpmc ersetzt</a> .  Dies f√ºhrte aufgrund des Umfangs der Synchronisation f√ºr Push und Pop nicht zu einer signifikanten Verbesserung.  Der Schl√ºssel zur Erfassung der Arbeit besteht darin, dass in den Warteschlangen unter Last fast keine Konkurrenz besteht, da jeder Prozessor nur auf seine eigene Warteschlange zugreift. <br><br>  Zu diesem Zeitpunkt habe ich mich entschlossen, die Go-Quellen sorgf√§ltig zu untersuchen - und festgestellt, dass sie eine feste Warteschlangengr√∂√üe mit einem Hersteller und mehreren Verbrauchern bei minimaler Synchronisation verwenden, was sehr beeindruckend ist.  Um den Algorithmus an den Tokio-Scheduler anzupassen, habe ich einige √Ñnderungen vorgenommen.  Es ist bemerkenswert, dass die Go-Implementierung sequentielle atomare Operationen verwendet (so wie ich es verstehe).  Die Tokio-Version reduziert auch die Anzahl einiger Kopiervorg√§nge in selteneren Codezweigen. <br><br>  Eine Warteschlangenimplementierung ist ein Ringpuffer, der Werte in einem Array speichert.  Der Kopf und das Ende der Warteschlange werden durch atomare Operationen mit ganzzahligen Werten verfolgt. <br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Queue</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// Concurrently updated by many threads. head: AtomicU32, /// Only updated by producer thread but read by many threads. tail: AtomicU32, /// Masks the head / tail position value to obtain the index in the buffer. mask: usize, /// Stores the tasks. buffer: Box&lt;[MaybeUninit&lt;Task&gt;]&gt;, }</span></span></code> </pre> <br>  Die Warteschlange wird von einem einzelnen Thread ausgef√ºhrt: <br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if tail.wrapping_sub(head) &lt; self.buffer.len() as u32 { // Map the position to a slot index. let idx = tail as usize &amp; self.mask; // Don't drop the previous value in `buffer[idx]` because // it is uninitialized memory. self.buffer[idx].as_mut_ptr().write(task); // Make the task available self.tail.store(tail.wrapping_add(1), Release); return; } // The local buffer is full. Push a batch of work to the global // queue. match self.push_overflow(task, head, tail, global) { Ok(_) =&gt; return, // Lost the race, try again Err(v) =&gt; task = v, } }</span></span></code> </pre> <br>  Beachten Sie, dass in dieser <code>push</code> Funktion die einzigen atomaren Operationen das Laden mit <code>Acquire</code> Ordering und das Speichern mit <code>Release</code> Ordering sind.  Es gibt keine RMW-Operationen ( <code>compare_and_swap</code> , <code>fetch_and</code> ...) oder sequentielle Reihenfolge wie zuvor.  Dies ist wichtig, da auf x86-Chips alle Downloads / Speicherungen bereits "atomar" sind.  Auf CPU-Ebene wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diese Funktion daher nicht synchronisiert</a> .  Atomic-Operationen verhindern bestimmte Optimierungen im Compiler, aber das ist alles.  H√∂chstwahrscheinlich k√∂nnte der erste <code>Relaxed</code> mit einer <code>Relaxed</code> Bestellung sicher durchgef√ºhrt werden, aber der Austausch bringt keinen merklichen Aufwand mit sich. <br><br>  Wenn die Warteschlange voll ist, wird <code>push_overflow</code> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diese Funktion verschiebt die H√§lfte der Aufgaben von der lokalen in die globale Warteschlange. Die globale Warteschlange ist eine aufdringliche Liste, die durch einen Mutex gesch√ºtzt ist. Beim Verschieben in die globale Warteschlange werden Aufgaben zuerst miteinander verkn√ºpft, dann wird ein Mutex erstellt und alle Aufgaben werden durch Aktualisieren des Zeigers auf das Ende der globalen Warteschlange eingef√ºgt. Dies spart eine kleine kritische Abschnittsgr√∂√üe. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn Sie mit den Details der Reihenfolge des Atomspeichers vertraut sind, stellen Sie m√∂glicherweise ein potenzielles ‚ÄûProblem‚Äú mit der oben gezeigten Funktion fest </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Die atomare </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ordnungsoperation </font><font style="vertical-align: inherit;">ist </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ziemlich schwach. Es kann veraltete Werte zur√ºckgeben, d. H. Eine parallele Erfassungsoperation kann den Wert bereits erh√∂hen </font></font><code>self.head</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, jedoch im Stream-Cache</font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der alte Wert bleibt erhalten, sodass der Erfassungsvorgang nicht bemerkt wird. Dies ist kein Problem mit der Richtigkeit des Algorithmus. Im Wesentlichen (schnell) </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k√ºmmern wir uns nur darum, ob die lokale Warteschlange voll ist oder nicht. Da nur der aktuelle Thread die Warteschlange verschieben kann, l√§sst eine veraltete Operation </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Warteschlange einfach voller aussehen, als sie tats√§chlich ist. M√∂glicherweise wird f√§lschlicherweise festgestellt, dass die Warteschlange voll ist, und </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dies f√ºhrt zu einer st√§rkeren atomaren Operation. Wenn </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">festgestellt wird, dass die Warteschlange tats√§chlich nicht voll ist, wird w / zur√ºckgegeben </font></font><code>Err</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und der Vorgang </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">erneut gestartet. Dies ist ein weiterer Grund warum</font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verschiebt die H√§lfte der Ausf√ºhrungswarteschlange in die globale Warteschlange. </font><font style="vertical-align: inherit;">Nach dieser Bewegung treten solche Fehlalarme viel seltener auf. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Local </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(vom Prozessor, zu dem die Warteschlange geh√∂rt) wird ebenfalls einfach implementiert:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if head == tail { // queue is empty return None; } // Map the head position to a slot index. let idx = head as usize &amp; self.mask; let task = self.buffer[idx].as_ptr().read(); // Attempt to claim the task read above. let actual = self .head .compare_and_swap(head, head.wrapping_add(1), Release); if actual == head { return Some(task.assume_init()); } }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In dieser Funktion sind ein Atom </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und ein </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Der Hauptaufwand kommt von </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Funktion </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ist √§hnlich </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, aber die </font></font><code>self.tail</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Atomlast muss von √ºbertragen werden. </font><font style="vertical-align: inherit;">In √§hnlicher Weise </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versucht die Operation </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, so zu tun, als w√§re sie die halbe Warteschlange anstelle einer einzelnen Aufgabe. </font><font style="vertical-align: inherit;">Dies hat einen guten Einfluss auf die Leistung, auf die wir sp√§ter noch eingehen werden.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der letzte fehlende Teil ist die Analyse der globalen Warteschlange, die Aufgaben empf√§ngt, die lokale Warteschlangen √ºberlaufen, sowie das √úbertragen von Aufgaben von Nicht-Prozessor-Threads an den Scheduler. </font><font style="vertical-align: inherit;">Wenn der Prozessor unter Last ist, dh sich Aufgaben in der lokalen Warteschlange befinden, versucht der Prozessor, die Aufgaben nach etwa 60 Aufgaben in der lokalen Warteschlange aus der globalen Warteschlange zu ziehen. </font><font style="vertical-align: inherit;">Es √ºberpr√ºft auch die globale Warteschlange, wenn sie sich im unten beschriebenen Status "Suchen" befindet.</font></font><br><br><a name="3"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Optimieren Sie Nachrichtenvorlagen </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tokio-Anwendungen bestehen normalerweise aus vielen kleinen unabh√§ngigen Aufgaben. Sie interagieren miteinander durch Nachrichten. Eine solche Vorlage √§hnelt anderen Sprachen wie Go und Erlang. Angesichts der H√§ufigkeit der Vorlage ist es f√ºr den Planer sinnvoll, sie zu optimieren. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Angenommen, die Aufgaben A und B sind gegeben. Aufgabe A wird jetzt ausgef√ºhrt und sendet eine Nachricht √ºber den √úbertragungskanal an Aufgabe B. Ein Kanal ist eine Ressource, f√ºr die Task B derzeit gesperrt ist. Durch das Senden einer Nachricht wird Task B in einen ausf√ºhrbaren Status versetzt und in die Ausf√ºhrungswarteschlange des aktuellen Prozessors gestellt. Dann leitet der Prozessor die n√§chste Aufgabe aus der Ausf√ºhrungswarteschlange ab, f√ºhrt sie aus und wiederholt diesen Zyklus, bis er Aufgabe B erreicht.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Problem besteht darin, dass zwischen dem Senden einer Nachricht und dem Abschlie√üen von Aufgabe B eine erhebliche Verz√∂gerung auftreten kann. </font><font style="vertical-align: inherit;">Dar√ºber hinaus werden hei√üe Daten, z. B. eine Nachricht, im CPU-Cache gespeichert. Wenn die Aufgabe abgeschlossen ist, werden die entsprechenden Caches wahrscheinlich gel√∂scht. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dieses Problem zu l√∂sen, implementiert der neue Tokio-Scheduler die Optimierung (wie bei den Go- und Kotlin-Schedulern). </font><font style="vertical-align: inherit;">Wenn eine Aufgabe in einen ausf√ºhrbaren Zustand versetzt wird, wird sie nicht am Ende der Warteschlange platziert, sondern in einem speziellen Steckplatz f√ºr die n√§chste Aufgabe gespeichert. </font><font style="vertical-align: inherit;">Der Prozessor √ºberpr√ºft diesen Steckplatz immer, bevor er die Warteschlange √ºberpr√ºft. </font><font style="vertical-align: inherit;">Wenn beim Einf√ºgen in den Steckplatz bereits eine alte Aufgabe vorhanden ist, wird diese aus dem Steckplatz gel√∂scht und an das Ende der Warteschlange verschoben. </font><font style="vertical-align: inherit;">Somit wird die Aufgabe des Sendens einer Nachricht praktisch ohne Verz√∂gerung abgeschlossen.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/12f/e12/a32/12fe12a324d1855a6c62cacd56cb4f70.png"><br><br><a name="4"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Drosselklappenerfassung </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn in einem Joberfassungsplaner die Prozessorausf√ºhrungswarteschlange leer ist, versucht der Prozessor, Aufgaben von Peer-CPUs zu erfassen. Zuerst wird eine zuf√§llige Peer-CPU ausgew√§hlt. Wenn keine Aufgaben daf√ºr gefunden werden, wird die n√§chste durchsucht usw., bis Aufgaben gefunden werden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In der Praxis beenden mehrere Prozessoren h√§ufig die Verarbeitung der Ausf√ºhrungswarteschlange ungef√§hr zur gleichen Zeit. Dies geschieht, wenn ein Jobpaket eintrifft (z. B. wenn</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auf Bereitschaft der Steckdose abgefragt). Prozessoren wachen auf, empfangen Aufgaben, starten sie und erledigen sie. Dies f√ºhrt dazu, dass alle Prozessoren gleichzeitig versuchen, die Aufgaben anderer Personen zu erfassen, dh viele Threads versuchen, auf dieselben Warteschlangen zuzugreifen. Es gibt einen Konflikt. Eine zuf√§llige Auswahl des Startpunkts tr√§gt zur Reduzierung des Wettbewerbs bei, aber die Situation ist immer noch nicht sehr gut. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dieses Problem zu umgehen, begrenzt der neue Scheduler die Anzahl der parallelen Prozessoren, die Erfassungsvorg√§nge ausf√ºhren. Wir nennen den Status des Prozessors, in dem er versucht, die Aufgaben anderer Personen zu erfassen, "Jobsuche" oder kurz "Suche" (dazu sp√§ter mehr). Eine solche Optimierung wird unter Verwendung eines Atomwerts durchgef√ºhrt</font></font><code>int</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, die der Prozessor vor dem Starten der Suche erh√∂ht und beim Verlassen des Suchstatus verringert. </font><font style="vertical-align: inherit;">Maximal die H√§lfte der Gesamtzahl der Prozessoren kann sich im Suchstatus befinden. </font><font style="vertical-align: inherit;">Das hei√üt, die ungef√§hre Grenze ist festgelegt, und dies ist normal. </font><font style="vertical-align: inherit;">Wir brauchen keine feste Begrenzung f√ºr die Anzahl der CPUs in der Suche, sondern nur eine Drosselung. </font><font style="vertical-align: inherit;">Wir opfern die Genauigkeit, um die Effizienz des Algorithmus zu verbessern. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nach dem Eintritt in den Suchstatus versucht der Prozessor, die Arbeit von Peer-CPUs zu erfassen, und √ºberpr√ºft die globale Warteschlange.</font></font><br><br><a name="5"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verringern Sie die Synchronisation zwischen Threads </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein weiterer wichtiger Teil des Schedulers ist die Benachrichtigung von Peer-CPUs √ºber neue Aufgaben. Wenn der "Bruder" schl√§ft, wacht er auf und erfasst Aufgaben. Benachrichtigungen spielen eine weitere wichtige Rolle. Denken Sie daran, dass der Warteschlangenalgorithmus eine schwache atomare Ordnung ( </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">/ </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) verwendet. Aufgrund der atomaren Speicherzuweisung kann nicht garantiert werden, dass ein Peer-Prozessor jemals Aufgaben in der Warteschlange ohne zus√§tzliche Synchronisierung sieht. Daher sind auch Benachrichtigungen daf√ºr verantwortlich. Aus diesem Grund werden Benachrichtigungen teuer. Das Ziel ist es, ihre Anzahl zu minimieren, um keine CPU-Ressourcen zu verwenden, dh der Prozessor hat Aufgaben und der Bruder kann sie nicht stehlen. Eine √ºberm√§√üige Anzahl von Benachrichtigungen f√ºhrt zu </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einem Problem mit der Donnerherde</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der urspr√ºngliche Tokio-Planer verfolgte einen naiven Ansatz bei Benachrichtigungen. Immer wenn eine neue Aufgabe in die Ausf√ºhrungswarteschlange gestellt wurde, erhielt der Prozessor eine Benachrichtigung. Immer wenn die CPU benachrichtigt wurde und die Aufgabe nach dem Aufwachen sah, benachrichtigte sie eine andere CPU. Diese Logik f√ºhrte sehr schnell dazu, dass alle Prozessoren aufwachten und nach Arbeit suchten (was zu einem Konflikt f√ºhrte). Oft fanden die meisten Prozessoren keine Arbeit und schliefen wieder ein.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der neue Scheduler hat dieses Muster erheblich verbessert, √§hnlich wie der Go-Scheduler. Benachrichtigungen werden wie zuvor gesendet, jedoch nur, wenn sich keine CPU im Suchstatus befindet (siehe vorherigen Abschnitt). Wenn der Prozessor eine Benachrichtigung erh√§lt, wechselt er sofort in den Suchstatus. Wenn der Prozessor im Suchstatus neue Aufgaben findet, verl√§sst er zuerst den Suchstatus und benachrichtigt dann den anderen Prozessor. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diese Logik begrenzt die Geschwindigkeit, mit der Prozessoren aufwachen. Wenn ein ganzes Aufgabenpaket sofort geplant ist (zum Beispiel wann</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">abgefragt auf Bereitschaft des Sockets), dann f√ºhrt die erste Aufgabe zu einer Benachrichtigung an den Prozessor. </font><font style="vertical-align: inherit;">Er ist jetzt in einem Suchzustand. </font><font style="vertical-align: inherit;">Die verbleibenden geplanten Aufgaben im Paket benachrichtigen den Prozessor nicht, da sich mindestens eine CPU im Suchstatus befindet. </font><font style="vertical-align: inherit;">Dieser benachrichtigte Prozessor erfasst die H√§lfte der Aufgaben im Stapel und benachrichtigt wiederum den anderen Prozessor. </font><font style="vertical-align: inherit;">Ein dritter Prozessor wacht auf, findet die Aufgaben eines der ersten beiden Prozessoren und erfasst die H√§lfte davon. </font><font style="vertical-align: inherit;">Dies f√ºhrt zu einem reibungslosen Anstieg der Anzahl der funktionierenden CPUs sowie zu einem schnellen Lastausgleich.</font></font><br><br><a name="6"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Speicherzuordnung reduzieren </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der neue Tokio-Scheduler ben√∂tigt nur eine Speicherzuordnung f√ºr jede erzeugte Aufgabe, w√§hrend der alte zwei ben√∂tigt. </font><font style="vertical-align: inherit;">Bisher sah die Aufgabenstruktur ungef√§hr so ‚Äã‚Äãaus:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// All state needed to manage the task state: TaskState, /// The logic to run is represented as a future trait object. future: Box&lt;dyn Future&lt;Output = ()&gt;&gt;, }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Struktur </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wird auch in hervorgehoben </font></font><code>Box</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ich wollte dieses Gelenk schon sehr lange reparieren (ich habe es 2014 zum ersten Mal versucht). Zwei Dinge haben sich seit dem alten Tokio-Planer ge√§ndert. Erstens stabilisiert </font></font><code>std::alloc</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Zweitens hat das zuk√ºnftige Aufgabensystem auf eine explizite </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vtable-Strategie umgestellt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Es waren diese beiden Dinge, die schlie√ülich fehlten, um die ineffiziente doppelte Speicherzuweisung f√ºr jede Aufgabe zu beseitigen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nun wird die Struktur </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in der folgenden Form dargestellt:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span>&lt;T&gt; { header: Header, future: T, trailer: Trailer, }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√ºr Aufgaben notwendig und </font></font><code>Header</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und </font></font><code>Trailer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, aber sie sind zwischen dem ‚Äûhei√üen‚Äú Daten (Kopf) und ‚Äûkalten‚Äú (Schwanz), m. E. etwa zwischen Daten h√§ufig zugegriffen wird </font><font style="vertical-align: inherit;">und solche unterteilt , </font><font style="vertical-align: inherit;">die selten verwendet werden. </font><font style="vertical-align: inherit;">"Hei√üe" Daten werden am Kopf der Struktur platziert und so wenig wie m√∂glich gespeichert. </font><font style="vertical-align: inherit;">Wenn der Prozessor den Taskzeiger dereferenziert, l√§dt er sofort die Cache-Zeile (von 64 bis 128 Byte). </font><font style="vertical-align: inherit;">Wir m√∂chten, dass diese Daten so relevant wie m√∂glich sind.</font></font><br><br><a name="7"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Reduzierte Anzahl atomarer Verbindungen </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die letzte Optimierung, die wir in diesem Artikel diskutieren, besteht darin, die Anzahl der atomaren Verkn√ºpfungen zu reduzieren. Es gibt viele Verweise auf die Struktur der Aufgabe, auch vom Scheduler und von jedem Waker. Die allgemeine Strategie zur Verwaltung dieses Speichers ist das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Z√§hlen atomarer Verbindungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Diese Strategie erfordert jedes Mal, wenn ein Link geklont und ein Link gel√∂scht wird, eine atomare Operation. Wenn der letzte Link den G√ºltigkeitsbereich verl√§sst, wird der Speicher freigegeben. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im alten Tokio-Scheduler enthielten sowohl der Scheduler als auch alle Waker einen Link zu einem Task-Deskriptor, ungef√§hr:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Waker</span></span></span></span> { task: Arc&lt;Task&gt;, } <span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn die Aufgabe aktiviert wird, wird die Verbindung geklont (ein atomares Inkrement tritt auf). </font><font style="vertical-align: inherit;">Dann wird der Link in die Ausf√ºhrungswarteschlange gestellt. </font><font style="vertical-align: inherit;">Wenn der Prozessor die Aufgabe empf√§ngt und ihre Ausf√ºhrung abschlie√üt, verwirft er die Verkn√ºpfung, was zu einer atomaren Reduktion f√ºhrt. </font><font style="vertical-align: inherit;">Diese atomaren Operationen (Inkrementieren und Verringern) summieren sich. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses Problem wurde zuvor von den Entwicklern des Task-Systems identifiziert </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Sie bemerkten, dass beim Anrufen der </font></font><code>Waker::wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">urspr√ºngliche Link zu </font></font><code>waker</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h√§ufig nicht mehr ben√∂tigt wird. </font><font style="vertical-align: inherit;">Auf diese Weise k√∂nnen Sie den Atomic Link-Z√§hler wiederverwenden, wenn Sie eine Aufgabe in die Ausf√ºhrungswarteschlange verschieben. </font><font style="vertical-align: inherit;">Das Task-System enth√§lt </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jetzt zwei API-Aufrufe zum ‚ÄûAufwachen‚Äú:</font></font><br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>wake</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was akzeptiert </font></font><code>self</code> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>wake_by_ref</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was akzeptiert </font></font><code>&amp;self</code> </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine solche API-Konstruktion l√§sst uns sie beim Aufrufen verwenden </font></font><code>wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, um atomare Inkremente zu vermeiden. </font><font style="vertical-align: inherit;">Die Implementierung sieht folgenderma√üen aus:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { task.scheduler.schedule(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake_by_ref</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies vermeidet den Aufwand f√ºr zus√§tzliche Verbindungsz√§hlungen </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nur,</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wenn Sie die Verantwortung f√ºr das Aufwachen √ºbernehmen k√∂nnen. Nach meiner Erfahrung ist es stattdessen fast immer ratsam, mit aufzuwachen </font></font><code>&amp;self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Das Erwachen </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verhindert die Wiederverwendung von Waker (n√ºtzlich in F√§llen, in denen die Ressource viele Werte sendet, d. H. Kan√§le, Sockets, ...). Auch f√ºr den Fall, dass es </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">schwieriger ist, ein thread-sicheres Aufwachen zu implementieren (wir werden die Details f√ºr einen anderen Artikel belassen). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der neue Planer l√∂st das Problem des "Aufwachens </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">", indem er das atomare Inkrement vermeidet </font></font><code>wake_by_ref</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, was es so effektiv wie macht</font></font><code>wake(self)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Zu diesem Zweck verwaltet der Scheduler eine Liste aller Aufgaben, die derzeit aktiv sind (noch nicht abgeschlossen). </font><font style="vertical-align: inherit;">Die Liste stellt den Referenzz√§hler dar, der zum Senden der Aufgabe an die Ausf√ºhrungswarteschlange erforderlich ist. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Komplexit√§t dieser Optimierung liegt in der Tatsache, dass der Scheduler Aufgaben erst dann aus seiner Liste entfernt, wenn er die Garantie erh√§lt, dass die Aufgabe erneut in die Ausf√ºhrungswarteschlange gestellt wird. </font><font style="vertical-align: inherit;">Details zur Implementierung dieses Schemas gehen √ºber den Rahmen dieses Artikels hinaus. Ich empfehle jedoch dringend, dass Sie sich die Quelle ansehen.</font></font><br><br><a name="7"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fettgedruckte (unsichere) Parallelit√§t mit Loom </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist sehr schwierig, den richtigen parallelen Code ohne Sperren zu schreiben. Es ist besser, langsam, aber korrekt als schnell zu arbeiten, aber mit St√∂rungen, insbesondere wenn die Fehler die Speichersicherheit betreffen. Die beste Option sollte jedoch schnell und fehlerfrei funktionieren. Der neue Scheduler hat einige ziemlich aggressive Optimierungen vorgenommen und vermeidet die meisten Typen </font></font><code>std</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aus Gr√ºnden der Spezialisierung. Im Allgemeinen enth√§lt es ziemlich viel unsicheren Code </font></font><code>unsafe</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gibt verschiedene M√∂glichkeiten, parallelen Code zu testen. Eine davon ist, dass Benutzer anstelle von Ihnen testen und debuggen k√∂nnen (eine attraktive Option, das ist sicher). Eine andere M√∂glichkeit besteht darin, Komponententests zu schreiben, die in einer Schleife ausgef√ºhrt werden und einen Fehler abfangen k√∂nnen. Vielleicht sogar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TSAN verwenden</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wenn er einen Fehler findet, kann er nat√ºrlich nicht einfach reproduziert werden, ohne den Testzyklus neu zu starten. Wie lange dauert dieser Zyklus? Zehn Sekunden? Zehn Minuten? Zehn Tage? Zuvor mussten Sie parallelen Code in Rust testen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir fanden diese Situation inakzeptabel. Wenn wir den Code freigeben, m√∂chten wir uns (so weit wie m√∂glich) sicher f√ºhlen, insbesondere bei parallelem Code ohne Sperren. Tokio-Benutzer ben√∂tigen Zuverl√§ssigkeit. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aus diesem Grund haben wir </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Loom</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> entwickelt </font><font style="vertical-align: inherit;">: ein Tool zum Testen der Permutation von parallelem Code. Tests werden wie gewohnt geschrieben, aber</font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie werden viele Male ausgef√ºhrt und alle m√∂glichen Optionen f√ºr die Ausf√ºhrung und das Verhalten neu angeordnet, auf die der Test in einer Streaming-Umgebung sto√üen kann. Au√üerdem wird √ºberpr√ºft, ob der Speicherzugriff korrekt ist, Speicher freigegeben usw. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist als Beispiel der Webmaschinentest f√ºr den neuen Scheduler:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-meta"><span class="hljs-meta">#[test]</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">multi_spawn</span></span></span></span>() { loom::model(|| { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pool = ThreadPool::new(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> c1 = Arc::new(AtomicUsize::new(<span class="hljs-number"><span class="hljs-number">0</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (tx, rx) = oneshot::channel(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> tx1 = Arc::new(Mutex::new(<span class="hljs-literal"><span class="hljs-literal">Some</span></span>(tx))); <span class="hljs-comment"><span class="hljs-comment">// Spawn a task let c2 = c1.clone(); let tx2 = tx1.clone(); pool.spawn(async move { spawn(async move { if 1 == c1.fetch_add(1, Relaxed) { tx1.lock().unwrap().take().unwrap().send(()); } }); }); // Spawn a second task pool.spawn(async move { spawn(async move { if 1 == c2.fetch_add(1, Relaxed) { tx2.lock().unwrap().take().unwrap().send(()); } }); }); rx.recv(); }); }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es sieht ziemlich normal aus, aber ein Teil des Codes in einem Block wird </font></font><code>loom::model</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">viele tausend Mal (m√∂glicherweise Millionen) ausgef√ºhrt, jedes Mal mit einer geringf√ºgigen √Ñnderung des Verhaltens. Jeder Lauf √§ndert die genaue Reihenfolge der Threads. Dar√ºber hinaus versucht loom f√ºr jede atomare Operation alle unterschiedlichen Verhaltensweisen, die im C ++ 11-Speichermodell zul√§ssig sind. Denken Sie daran, dass die Atomlast mit </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eher schwach war und veraltete Werte zur√ºckgeben konnte. Der Test </font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versucht alle m√∂glichen Werte, die geladen werden k√∂nnen. </font></font><br><br> <code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wurde ein unsch√§tzbares Werkzeug bei der Entwicklung eines neuen Planers. Er hat mehr als zehn Fehler entdeckt, die alle Unit-Tests, manuellen Tests und Lasttests bestanden haben.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein anspruchsvoller Leser kann bezweifeln, dass der Webstuhl ‚Äûalle m√∂glichen Permutationen‚Äú √ºberpr√ºft, und er wird Recht haben. Naive Permutationen f√ºhren zu einer kombinatorischen Explosion. Jeder nicht triviale Test wird niemals enden. Dieses Problem wurde viele Jahre lang untersucht und eine Reihe von Algorithmen entwickelt, um eine kombinatorische Explosion zu verhindern. Webstuhl grundlegender Algorithmus basierend auf </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dynamische Reduktion mit teilweise Ordnung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dynamic Teil Ordnung reduction). Dieser Algorithmus eliminiert Permutationen, die zum gleichen Ergebnis f√ºhren. Der Zustandsraum kann jedoch immer noch so gro√ü werden, dass er nicht in angemessener Zeit (mehrere Minuten) verarbeitet wird. Mit Loom k√∂nnen Sie die dynamische Reduzierung durch Teilbestellung weiter einschr√§nken.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im Allgemeinen bin ich dank umfangreicher Tests mit Loom jetzt </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">viel</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sicherer in der Richtigkeit des Schedulers.</font></font><br><br><h1>  Ergebnisse </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben uns also angesehen, was Scheduler sind und wie der neue Tokio-Scheduler einen enormen Leistungsschub erzielt hat ... aber welche Art von Wachstum? </font><font style="vertical-align: inherit;">Da der neue Scheduler nur entwickelt wurde, wurde er in der realen Welt noch nicht vollst√§ndig getestet. </font><font style="vertical-align: inherit;">Folgendes wissen wir. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstens ist der neue Scheduler bei Mikro-Benchmarks viel schneller:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Alter Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Test chained_spawn ... Bank: 2.019.796 ns / iter (+/- 302.168)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test ping_pong ... Bank: 1.279.948 ns / iter (+/- 154.365)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... Bench: 10.283.608 ns / iter (+/- 1.284.275)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test Yield_many ... Bench: 21.450.748 ns / iter (+/- 1.201.337) </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Neuer Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Test chained_spawn ... Bank: 168.854 ns / iter (+/- 8.339)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test ping_pong ... Bank: 562.659 ns / iter (+/- 34.410)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... Bench: 7.320.737 ns / iter (+/- 264.620)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test Yield_many ... Bench: 14.638.563 ns / iter (+/- 1.573.678) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Diese Benchmark umfasst Folgendes: </font></font><br><br><ul><li> <code>chained_spawn</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rekursiv neue Aufgaben erzeugen, d. h. eine Aufgabe erzeugen, die eine andere Aufgabe erzeugt, die auch eine Aufgabe erzeugt, usw. </font></font><br></li><li> <code>ping_pong</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w√§hlt einen Kanal aus </font></font><code>oneshot</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und erzeugt eine Aufgabe, die eine Nachricht auf diesem Kanal sendet. </font><font style="vertical-align: inherit;">Die urspr√ºngliche Aufgabe wartet auf eine Nachricht. </font><font style="vertical-align: inherit;">Dies ist der Test, der der ‚Äûrealen Welt‚Äú am n√§chsten kommt.</font></font><br></li><li> <code>spawn_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √úberpr√ºft die Implementierung von Aufgaben im Scheduler, d. H. Erzeugt Aufgaben von au√üerhalb seines Kontexts. </font></font><br></li><li> <code>yield_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pr√ºft auf unabh√§ngiges Aufwecken von Aufgaben. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Unterschied bei den Benchmarks ist sehr beeindruckend. </font><font style="vertical-align: inherit;">Aber wie wird sich das in der "realen Welt" widerspiegeln? </font><font style="vertical-align: inherit;">Es ist schwer zu sagen, aber ich habe versucht, die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyper-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Benchmarks auszuf√ºhren </font><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist der einfachste Hyper-Server, dessen Leistung gemessen wird mit </font></font><code>wrk -t1 -c50 -d10</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Alter Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ausf√ºhren von 10s test @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 Gewinde und 50 Verbindungen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Thread-Statistiken Durchschn. Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latenz 371,53us 99,05us 1,97 ms 60,53%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Req / Sec 114.61k 8.45k 133.85k 67.00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1139307 Anfragen in 10.00s, 95.61MB gelesen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anfragen / Sek.: 113923.19</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√úbertragung / Sek.: 9,56 MB </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Neuer Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ausf√ºhren von 10s test @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 Gewinde und 50 Verbindungen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Thread-Statistiken Durchschn. Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latenz 275.05us 69.81us 1.09ms 73.57%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Req / Sec 153.17k 10.68k 171.51k 71.00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1522671 Anfragen in 10.00s, 127.79MB gelesen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anfragen / Sek.: 152258.70</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√úbertragung / Sek.: 12,78 MB </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir sehen einen Anstieg der Anfragen pro Sekunde um 34% unmittelbar nach dem Planerwechsel! Als ich das zum ersten Mal sah, war ich sehr gl√ºcklich, weil ich eine Steigerung von maximal 5-10% erwartet hatte. Aber dann war ich traurig, denn dieses Ergebnis zeigte auch, dass der alte Tokio-Scheduler nicht so gut ist. Dann erinnerte ich mich, dass Hyper </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bereits</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºhrend bei </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">TechEmpower-</font></a><font style="vertical-align: inherit;"> Bewertungen ist </font><font style="vertical-align: inherit;">. Es ist interessant zu sehen, wie sich der neue Planer auf die Bewertungen auswirkt. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tonic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , der gRPC-Client und -Server mit dem neuen Scheduler, hat sich um etwa 10% beschleunigt, was ziemlich beeindruckend ist, wenn man bedenkt, dass Tonic noch nicht vollst√§ndig optimiert ist.</font></font><br><br><h1>  Fazit </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich freue mich sehr, dieses Projekt nach einigen Monaten Arbeit endlich abschlie√üen zu k√∂nnen. </font><font style="vertical-align: inherit;">Dies ist eine wesentliche Verbesserung der asynchronen E / A von Rust. </font><font style="vertical-align: inherit;">Ich bin sehr zufrieden mit den Verbesserungen. </font><font style="vertical-align: inherit;">In Tokio-Code gibt es noch viel Raum f√ºr Optimierungen, sodass wir mit der Leistungsverbesserung noch nicht fertig sind. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich hoffe, dass das Material im Artikel f√ºr Kollegen n√ºtzlich ist, die versuchen, ihren Aufgabenplaner zu schreiben.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de472242/">https://habr.com/ru/post/de472242/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de472228/index.html">9 Tricks zum Arbeiten mit Visual Studio-Code</a></li>
<li><a href="../de472230/index.html">Chips f√ºr ML - sprechen Sie √ºber neue Produkte</a></li>
<li><a href="../de472232/index.html">Vom ‚ÄûColor Extender f√ºr ZX-Spectrum‚Äú bis zum ZX-Poly</a></li>
<li><a href="../de472234/index.html">Kryptow√§hrung: Ist es immer noch ein Freeloader oder ein Partner?</a></li>
<li><a href="../de472240/index.html">√úber Gamification. Was ist das, warum und wie geht das? Entwickler-Look</a></li>
<li><a href="../de472246/index.html">Reagieren + IndexDb + Auto-Update = fast AsyncRedux</a></li>
<li><a href="../de472248/index.html">Wie wir das Programmier-IT-Planet-Finale zusammengef√ºhrt haben</a></li>
<li><a href="../de472252/index.html">Digitale Veranstaltungen in Moskau vom 21. bis 28. Oktober</a></li>
<li><a href="../de472254/index.html">Digitale Veranstaltungen in St. Petersburg vom 21. bis 28. Oktober</a></li>
<li><a href="../de472258/index.html">Wie man "lernt zu lernen" - die Achtsamkeit verbessert</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
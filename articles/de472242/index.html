<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚯 ⏩ 👈🏽 Wir haben den Tokio-Scheduler zehnmal beschleunigt 🎴 🚠 🐍</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir bereiten gerade die nächste Hauptversion von Tokio vor, eine asynchrone Laufzeitumgebung für Rust. Am 13. Oktober wurde eine Poolanforderung mit e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir haben den Tokio-Scheduler zehnmal beschleunigt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472242/"> Wir bereiten gerade die nächste Hauptversion von Tokio vor, eine asynchrone Laufzeitumgebung für Rust.  Am 13. Oktober wurde eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Poolanforderung</a> mit einem vollständig neu geschriebenen Taskplaner zum Zusammenführen in eine Zweigstelle ausgegeben.  Das Ergebnis sind enorme Leistungsverbesserungen und eine verringerte Latenz.  Einige Tests haben eine zehnfache Beschleunigung festgestellt!  Wie üblich spiegeln synthetische Tests nicht den tatsächlichen Nutzen in der Realität wider.  Daher haben wir auch überprüft, wie sich Änderungen im Scheduler auf reale Aufgaben wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hyper</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tonic</a> auswirken (Spoiler: Das Ergebnis ist wunderbar). <br><br>  Ich bereitete mich auf die Arbeit an einem neuen Planer vor und suchte nach thematischen Ressourcen.  Abgesehen von den tatsächlichen Implementierungen wurde nichts Besonderes gefunden.  Ich fand auch, dass der Quellcode für vorhandene Implementierungen schwer zu navigieren ist.  Um dies zu beheben, haben wir versucht, den Tokio-Sheduler so sauber wie möglich zu schreiben.  Ich hoffe, dieser ausführliche Artikel über die Implementierung des Schedulers hilft denjenigen, die sich in derselben Position befinden und erfolglos nach Informationen zu diesem Thema suchen. <br><br>  Der Artikel beginnt mit einer allgemeinen Überprüfung des Designs, einschließlich der Richtlinien zur Auftragserfassung.  Tauchen Sie dann im neuen Tokio-Scheduler in die Details spezifischer Optimierungen ein. <br><a name="habracut"></a><br>  Berücksichtigte Optimierungen: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neues std :: future Task System</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auswahl des besten Warteschlangenalgorithmus</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Optimieren Sie Nachrichtenvorlagen</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drosselklappenerfassung</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reduzieren Sie die Synchronisation zwischen Threads</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Speicherzuordnung reduzieren</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reduzierte Anzahl atomarer Verbindungen</a> </li></ul><br>  Wie Sie sehen können, lautet das Hauptthema „Reduktion“.  Der schnellste Code ist schließlich sein Mangel! <br><br>  Wir werden auch über das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testen des neuen Schedulers</a> sprechen.  Es ist sehr schwierig, den richtigen parallelen Code ohne Sperren zu schreiben.  Es ist besser, langsam, aber korrekt als schnell zu arbeiten, aber mit Störungen, insbesondere wenn die Fehler die Speichersicherheit betreffen.  Die beste Option sollte jedoch schnell und fehlerfrei funktionieren. Deshalb haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">loom geschrieben</a> , ein Tool zum Testen der Parallelität. <br><br>  Bevor ich mich mit dem Thema befasse, möchte ich mich bedanken bei: <br><br><ul><li> <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@withoutboats</a></b> und andere, die an der <code>async / await</code> Funktion in Rust gearbeitet haben.  Du hast einen tollen Job gemacht.  Dies ist eine Killer-Funktion. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@cramertj</a></b> und andere, die <code>std::task</code> .  Dies ist eine enorme Verbesserung gegenüber dem, was es vorher war.  Und toller Code. <br></li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Buoyant</a></b> , der Schöpfer von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Linkerd</a> und vor allem mein Arbeitgeber.  Vielen Dank, dass ich so viel Zeit mit diesem Job verbringen durfte.  Wenn sich jemand für das Service-Mesh interessiert, schauen Sie sich Linkerd an.  In Kürze werden alle in diesem Artikel beschriebenen Vorteile enthalten sein. <br></li><li>  <b><a href="">Entscheiden Sie sich</a></b> für eine so gute Planerimplementierung. </li></ul><br>  Nehmen Sie eine Tasse Kaffee und lehnen Sie sich zurück.  Dies wird ein langer Artikel sein. <br><br><h1>  Wie arbeiten Planer? </h1><br>  Die Aufgabe des Schuppers ist es, die Arbeit zu planen.  Die Anwendung ist in Arbeitseinheiten unterteilt, die wir <i>Aufgaben</i> nennen <i>werden</i> .  Eine Aufgabe gilt als ausführbar, wenn sie in ihrer Ausführung voranschreiten kann, aber nicht mehr ausgeführt wird, oder wenn sie für eine externe Ressource gesperrt ist.  Aufgaben sind insofern unabhängig, als beliebig viele Aufgaben gleichzeitig ausgeführt werden können.  Der Scheduler ist dafür verantwortlich, Aufgaben in einem laufenden Zustand auszuführen, bis sie in den Standby-Modus zurückkehren.  Bei der Ausführung von Aufgaben wird der Aufgabe Prozessorzeit zugewiesen - eine globale Ressource. <br><br>  Der Artikel beschreibt User Space Scheduler, dh das Arbeiten auf Betriebssystem-Threads (die wiederum von einem Sheduler auf Kernel-Ebene gesteuert werden).  Der Tokio-Scheduler führt Rust-Futures aus, die als "asynchrone grüne Threads" betrachtet werden können.  Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gemischtes M: N-Streaming-</a> Muster, bei dem viele Benutzeroberflächenaufgaben auf mehrere Threads des Betriebssystems gemultiplext werden. <br><br>  Es gibt viele verschiedene Möglichkeiten, einen Sheduler zu simulieren, jede mit ihren eigenen Vor- und Nachteilen.  Auf der einfachsten Ebene kann der Scheduler als <i>Ausführungswarteschlange</i> und als <i>Prozessor</i> modelliert werden, der ihn auseinander zieht.  Ein Prozessor ist ein Code, der in einem Thread ausgeführt wird.  Im Pseudocode wird Folgendes ausgeführt: <br><br><pre> <code class="plaintext hljs">while let Some(task) = self.queue.pop() { task.run(); }</code> </pre> <br>  Wenn eine Aufgabe realisierbar wird, wird sie in die Ausführungswarteschlange eingefügt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ff6/1f4/18f/ff61f418f73f08c62b5e9eaeacaeb8ed.png"><br><br>  Obwohl Sie ein System entwerfen können, in dem Ressourcen, Aufgaben und ein Prozessor im selben Thread vorhanden sind, bevorzugt Tokio die Verwendung mehrerer Threads.  Wir leben in einer Welt, in der ein Computer viele Prozessoren hat.  Die Entwicklung eines Single-Threaded-Schedulers führt zu einer unzureichenden Eisenbeladung.  Wir wollen alle CPUs nutzen.  Es gibt verschiedene Möglichkeiten, dies zu tun: <br><br><ul><li>  Eine globale Ausführungswarteschlange, viele Prozessoren. <br></li><li>  Viele Prozessoren mit jeweils eigener Ausführungswarteschlange. </li></ul><br><h3>  Eine Runde, viele Prozessoren </h3><br>  Dieses Modell verfügt über eine globale Ausführungswarteschlange.  Wenn die Aufgaben abgeschlossen sind, werden sie am Ende der Warteschlange platziert.  Es gibt mehrere Prozessoren, die sich jeweils in einem separaten Thread befinden.  Jeder Prozessor übernimmt eine Aufgabe vom Kopf der Warteschlange oder blockiert den Thread, wenn keine Aufgaben verfügbar sind. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/85c/8d0/23d/85c8d023dfeba249bba01234e0e8783a.png"><br><br>  Die Ausführungslinie muss von vielen Herstellern und Verbrauchern unterstützt werden.  Normalerweise wird eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aufdringliche</a> Liste verwendet, in der die Struktur jeder Aufgabe einen Zeiger auf die nächste Aufgabe in der Warteschlange enthält (anstatt die Aufgaben in eine verknüpfte Liste zu packen).  Somit kann eine Speicherzuweisung für Push- und Pop-Operationen vermieden werden.  Sie können <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Push-Operation ohne Sperren verwenden</a> , aber um die Verbraucher zu koordinieren, ist der Mutex für die Pop-Operation erforderlich (es ist technisch möglich, eine Mehrbenutzer-Warteschlange ohne Sperren zu implementieren). <br><br>  In der Praxis ist der Aufwand für einen ordnungsgemäßen Schutz vor Schlössern jedoch mehr als nur die Verwendung eines Mutex. <br><br>  Dieser Ansatz wird häufig für einen allgemeinen Thread-Pool verwendet, da er mehrere Vorteile bietet: <br><br><ul><li>  Aufgaben sind ziemlich geplant. <br></li><li>  Relativ einfache Implementierung.  Eine mehr oder weniger Standardwarteschlange ist mit dem oben beschriebenen Prozessorzyklus verbunden. </li></ul><br>  Ein kurzer Hinweis zur fairen (gerechten) Planung.  Das bedeutet, dass die Aufgaben ehrlich ausgeführt werden: Wer früher kam, ist derjenige, der früher gegangen ist.  Allzweckplaner versuchen fair zu sein, aber es gibt Ausnahmen wie die Parallelisierung über Fork-Join, bei denen die Geschwindigkeit der Ergebnisberechnung und nicht die Gerechtigkeit für jede einzelne Teilaufgabe ein wichtiger Faktor ist. <br><br>  Dieses Modell hat einen Nachteil.  Alle Prozessoren beantragen Aufgaben vom Kopf der Warteschlange aus.  Für Allzweck-Threads ist dies normalerweise kein Problem.  Die Zeit zum Ausführen einer Aufgabe überschreitet bei weitem die Zeit zum Abrufen aus der Warteschlange.  Wenn Aufgaben über einen längeren Zeitraum ausgeführt werden, wird der Wettbewerb in der Warteschlange verringert.  Es wird jedoch erwartet, dass asynchrone Rust-Aufgaben sehr schnell abgeschlossen werden.  In diesem Fall erhöhen sich die Gemeinkosten für den Kampf in der Warteschlange erheblich. <br><br><h3>  Parallelität und mechanische Sympathie </h3><br>  Um maximale Leistung zu erzielen, müssen wir die Hardwarefunktionen optimal nutzen.  Der Begriff „mechanische Sympathie“ für Software wurde zuerst von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Martin Thompson verwendet</a> (dessen Blog nicht mehr aktualisiert, aber immer noch sehr informativ ist). <br><br>  Eine ausführliche Erörterung der Implementierung von Parallelität in modernen Geräten würde den Rahmen dieses Artikels sprengen.  Im Allgemeinen erhöht Eisen die Produktivität nicht aufgrund von Beschleunigung, sondern aufgrund der Einführung einer größeren Anzahl von CPU-Kernen (sogar mein Laptop hat sechs!). Jeder Kern kann in winzigen Zeitintervallen große Rechenmengen ausführen.  Aktionen wie der Zugriff auf den Cache und den Speicher benötigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im</a> Vergleich zur Ausführungszeit auf der CPU <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">viel mehr Zeit</a> .  Um Anwendungen zu beschleunigen, müssen Sie daher die Anzahl der CPU-Anweisungen für jeden Speicherzugriff maximieren.  Obwohl der Compiler sehr hilfreich ist, müssen wir noch über Dinge wie Ausrichtung und Speicherzugriffsmuster nachdenken. <br><br>  Separate Threads funktionieren separat sehr ähnlich wie ein einzelner isolierter Thread, <b>bis</b> mehrere Threads gleichzeitig dieselbe Cache-Zeile ändern (gleichzeitige Mutationen) oder eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">konsistente Konsistenz</a> erforderlich ist.  In diesem Fall wird das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CPU-Cache-Kohärenzprotokoll</a> aktiviert.  Es garantiert die Relevanz des Caches jeder CPU. <br><br>  Die Schlussfolgerung liegt auf der Hand: Vermeiden Sie nach Möglichkeit die Synchronisation zwischen Threads, da diese langsam ist. <br><br><h3>  Viele Prozessoren mit jeweils eigener Ausführungswarteschlange </h3><br>  Ein weiteres Modell sind mehrere Single-Threaded-Scheduler.  Jeder Prozessor erhält eine eigene Ausführungswarteschlange, und Aufgaben werden auf einem bestimmten Prozessor festgelegt.  Dies vermeidet das Synchronisationsproblem vollständig.  Da das Rust-Aufgabenmodell die Fähigkeit erfordert, eine Aufgabe von einem beliebigen Thread in die Warteschlange zu stellen, sollte es dennoch eine thread-sichere Möglichkeit geben, Aufgaben in den Scheduler einzugeben.  Entweder unterstützt die Ausführungswarteschlange jedes Prozessors die thread-sichere Push-Operation (MPSC), oder jeder Prozessor verfügt über <b>zwei</b> Ausführungswarteschlangen: unsynchronisiert und thread-sicher. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6d/a3c/35e/c6da3c35e7f6fb28b63fdb3ff6417882.png"><br><br>  Diese Strategie verwendet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Seastar</a> .  Da wir die Synchronisation fast vollständig vermeiden, bietet diese Strategie eine sehr gute Geschwindigkeit.  Aber sie löst nicht alle Probleme.  Wenn die Arbeitslast nicht vollständig homogen ist, sind einige Prozessoren unter Last, während andere im Leerlauf sind, was zu einer nicht optimalen Ressourcennutzung führt.  Dies liegt daran, dass Aufgaben auf einem bestimmten Prozessor festgelegt sind.  Wenn eine Gruppe von Aufgaben in einem Paket auf einem Prozessor geplant ist, erfüllt sie im Alleingang die Spitzenlast, auch wenn andere im Leerlauf sind. <br><br>  Die meisten „realen“ Workloads sind nicht homogen.  Daher meiden Allzweckplaner dieses Modell normalerweise. <br><br><h3>  Job Capture Scheduler </h3><br>  Der Scheduler mit Work-Stealing-Schedulern basiert auf dem Sharded-Scheduler-Modell und löst das Problem des unvollständigen Ladens von Hardwareressourcen.  Jeder Prozessor unterstützt seine eigene Ausführungswarteschlange.  Aufgaben, die ausgeführt werden, werden in die Ausführungswarteschlange des aktuellen Prozessors gestellt und funktionieren darauf.  Wenn der Prozessor jedoch inaktiv ist, überprüft er die Warteschlangen des Schwesterprozessors und versucht, etwas von dort abzurufen.  Der Prozessor wechselt erst in den Ruhemodus, nachdem er keine Arbeit in Peer-to-Peer-Ausführungswarteschlangen gefunden hat. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/561/9a9/02c/5619a902c1d95252d20ac7db1273e57f.png"><br><br>  Auf Modellebene ist dies der Ansatz „Das Beste aus zwei Welten“.  Unter Last arbeiten Prozessoren unabhängig voneinander und vermeiden Overhead-Synchronisation.  In Fällen, in denen die Last zwischen den Prozessoren ungleichmäßig verteilt ist, kann der Scheduler sie neu verteilen.  Aus diesem Grund werden solche Scheduler in <a href="">Go</a> , <a href="">Erlang</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Java</a> und anderen Sprachen verwendet. <br><br>  Der Nachteil ist, dass dieser Ansatz viel komplizierter ist.  Der Warteschlangenalgorithmus muss die Auftragserfassung unterstützen. Für eine reibungslose Ausführung ist eine <b>gewisse</b> Synchronisierung zwischen den Prozessoren erforderlich.  Wenn es nicht korrekt implementiert ist, kann der Overhead für die Erfassung größer sein als die Verstärkung. <br><br>  Stellen Sie sich folgende Situation vor: Prozessor A führt derzeit eine Aufgabe aus und hat eine leere Ausführungswarteschlange.  Prozessor B ist inaktiv;  Er versucht, eine Aufgabe zu erfassen, schlägt jedoch fehl und wechselt in den Schlafmodus.  Dann werden 20 Aufgaben aus der Aufgabe von Prozessor A erzeugt.  Im Idealfall sollte Prozessor B aufwachen und einige davon greifen.  Zu diesem Zweck müssen bestimmte Heuristiken im Scheduler implementiert werden, wobei die Prozessoren den schlafenden Peer-Prozessoren signalisieren, dass neue Aufgaben in ihrer Warteschlange erscheinen.  Dies erfordert natürlich eine zusätzliche Synchronisation, so dass solche Operationen am besten minimiert werden. <br><br>  Zusammenfassend: <br><br><ul><li>  Je weniger Synchronisation, desto besser. <br></li><li>  Die Auftragserfassung ist der optimale Algorithmus für Allzweckplaner. <br></li><li>  Jeder Prozessor arbeitet unabhängig von den anderen, es ist jedoch eine gewisse Synchronisierung erforderlich, um die Arbeit zu erfassen. </li></ul><br><h1>  Tokio 0.1 Scheduler </h1><br>  Der erste Arbeitsplaner für Tokio wurde im März 2018 veröffentlicht.  Dies war der erste Versuch, der auf einigen Annahmen beruhte, die sich als falsch herausstellten. <br><br>  Erstens schlug der Tokio 0.1-Scheduler vor, Prozessorthreads zu schließen, wenn sie für eine bestimmte Zeit inaktiv waren.  Der Scheduler wurde ursprünglich als "Allzweck" -System für den Rust-Thread-Pool erstellt.  Zu diesem Zeitpunkt befand sich die Tokio-Laufzeit noch in einem frühen Entwicklungsstadium.  Dann ging das Modell davon aus, dass E / A-Aufgaben auf demselben Thread wie der E / A-Selektor ausgeführt werden (epoll, kqueue, iocp ...).  Weitere Rechenaufgaben könnten an den Thread-Pool gerichtet werden.  In diesem Zusammenhang wird eine flexible Konfiguration der Anzahl der aktiven Threads angenommen, sodass es sinnvoller ist, inaktive Threads zu deaktivieren.  Im Scheduler mit Joberfassung wurde das Modell jedoch auf die Ausführung <i>aller</i> asynchronen Aufgaben umgestellt. In diesem Fall ist es sinnvoll, immer eine kleine Anzahl von Threads im aktiven Zustand zu halten. <br><br>  Zweitens wurde dort eine Zweiwege- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Querträgerlinie</a> implementiert.  Diese Implementierung basiert auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bidirektionalen Chase-Lev-Linie</a> und ist aus den unten beschriebenen Gründen nicht für die Planung unabhängiger asynchroner Aufgaben geeignet. <br><br>  Drittens erwies sich die Implementierung als zu kompliziert.  Dies liegt zum Teil daran, dass dies mein erster Taskplaner war.  Außerdem war ich zu ungeduldig, wenn ich Atomics in Zweigen verwendete, in denen der Mutex gut funktioniert hätte.  Eine wichtige Lektion ist, dass sehr oft Mutexe am besten funktionieren. <br><br>  Schließlich gab es viele kleinere Mängel bei der anfänglichen Implementierung.  In den Anfangsjahren haben sich die Implementierungsdetails des asynchronen Rust-Modells erheblich weiterentwickelt, aber die Bibliotheken haben die API jederzeit stabil gehalten.  Dies führte zu einer Anhäufung technischer Schulden. <br><br>  Jetzt nähert sich Tokio der ersten Hauptversion - und wir können all diese Schulden bezahlen und aus den Erfahrungen lernen, die wir in den Jahren der Entwicklung gesammelt haben.  Dies ist eine aufregende Zeit! <br><br><h1>  Tokio Scheduler der nächsten Generation </h1><br>  Jetzt ist es Zeit, sich genauer anzusehen, was sich im neuen Scheduler geändert hat. <br><br><a name="1"></a><h3>  Neues Aufgabensystem </h3><br>  Zunächst ist es wichtig hervorzuheben, was <b>nicht</b> Teil von Tokio ist, aber für die Verbesserung der Effizienz von entscheidender Bedeutung ist: Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neues Aufgabensystem</a> in <code>std</code> , das ursprünglich von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Taylor Kramer entwickelt wurde</a> .  Dieses System bietet die Hooks, die der Scheduler implementieren muss, um asynchrone Rust-Aufgaben auszuführen, und das System ist wirklich hervorragend entworfen und implementiert.  Es ist viel leichter und flexibler als die vorherige Iteration. <br><br>  Die <code>Waker</code> Struktur aus den Ressourcen signalisiert, dass eine <i>realisierbare</i> Aufgabe in die Scheduler-Warteschlange gestellt werden sollte.  Im neuen Aufgabensystem ist dies eine Zwei-Zeiger-Struktur, während sie zuvor viel größer war.  Das Reduzieren der Größe ist wichtig, um den Aufwand für das Kopieren des <code>Waker</code> Werts an verschiedenen Stellen zu minimieren. <code>Waker</code> nimmt es weniger Platz in den Strukturen ein, sodass Sie wichtigere Daten in die Cache-Zeile drücken können.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vtable-</a> Design hat eine Reihe von Optimierungen vorgenommen, die wir später diskutieren werden. <br><br><a name="2"></a><h3>  Auswahl des besten Warteschlangenalgorithmus </h3><br>  Die Ausführungswarteschlange befindet sich in der Mitte des Schedulers.  Daher ist dies die wichtigste zu behebende Komponente.  Der ursprüngliche Tokio-Scheduler verwendete eine Zwei-Wege- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Crossbeam-Warteschlange</a> : eine Single-Source-Implementierung (Produzent) und viele Konsumenten.  Eine Aufgabe wird an einem Ende platziert und Werte werden vom anderen abgerufen.  Meistens "pusht" der Thread die Werte vom Ende der Warteschlange, aber manchmal fangen andere Threads die Arbeit ab und führen dieselbe Operation aus.  Die Zwei-Wege-Warteschlange wird von einem Array und einer Reihe von Indizes unterstützt, die Kopf und Schwanz verfolgen.  Wenn die Warteschlange voll ist, führt die Einführung zu einer Erhöhung des Speicherplatzes.  Ein neues, größeres Array wird zugewiesen und die Werte werden in den neuen Speicher verschoben. <br><br>  Die Fähigkeit zu wachsen wird durch Komplexität und Overhead erreicht.  Push / Pop-Operationen sollten dieses Wachstum berücksichtigen.  Darüber hinaus ist das Freigeben des ursprünglichen Arrays mit zusätzlichen Schwierigkeiten verbunden.  In einer Garbage Collection (GC) -Sprache verlässt das alte Array den Gültigkeitsbereich und wird schließlich vom GC gelöscht.  Rust wird jedoch ohne GC geliefert.  Dies bedeutet, dass wir selbst für die Freigabe des Arrays verantwortlich sind, Threads jedoch gleichzeitig versuchen können, auf den Speicher zuzugreifen.  Um dieses Problem zu lösen, verwendet Crossbeam eine epochenbasierte Rekultivierungsstrategie.  Obwohl es nicht viele Ressourcen erfordert, fügt es dem Hauptpfad (Hot Path) nicht trivialen Overhead hinzu.  Jede Operation sollte nun atomare RMW-Operationen (Lesen-Ändern-Schreiben) am Ein- und Ausgang kritischer Abschnitte ausführen, um anderen Threads zu signalisieren, dass der Speicher verwendet wird und nicht gelöscht werden kann. <br><br>  Aufgrund des Overheads für das Wachstum der Ausführungswarteschlange ist es sinnvoll zu denken: Ist die Unterstützung für dieses Wachstum wirklich notwendig?  Diese Frage veranlasste mich schließlich, den Planer neu zu schreiben.  Die neue Strategie besteht darin, für jeden Prozess eine feste Warteschlangengröße zu haben.  Wenn die Warteschlange voll ist, wird die Aufgabe nicht mit der lokalen Warteschlange vergrößert, sondern mit mehreren Verbrauchern und mehreren Produzenten in die globale Warteschlange verschoben.  Prozessoren überprüfen diese globale Warteschlange regelmäßig, jedoch mit einer viel geringeren Häufigkeit als die lokale. <br><br>  Im Rahmen eines der ersten Experimente haben wir den Querträger durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mpmc ersetzt</a> .  Dies führte aufgrund des Umfangs der Synchronisation für Push und Pop nicht zu einer signifikanten Verbesserung.  Der Schlüssel zur Erfassung der Arbeit besteht darin, dass in den Warteschlangen unter Last fast keine Konkurrenz besteht, da jeder Prozessor nur auf seine eigene Warteschlange zugreift. <br><br>  Zu diesem Zeitpunkt habe ich mich entschlossen, die Go-Quellen sorgfältig zu untersuchen - und festgestellt, dass sie eine feste Warteschlangengröße mit einem Hersteller und mehreren Verbrauchern bei minimaler Synchronisation verwenden, was sehr beeindruckend ist.  Um den Algorithmus an den Tokio-Scheduler anzupassen, habe ich einige Änderungen vorgenommen.  Es ist bemerkenswert, dass die Go-Implementierung sequentielle atomare Operationen verwendet (so wie ich es verstehe).  Die Tokio-Version reduziert auch die Anzahl einiger Kopiervorgänge in selteneren Codezweigen. <br><br>  Eine Warteschlangenimplementierung ist ein Ringpuffer, der Werte in einem Array speichert.  Der Kopf und das Ende der Warteschlange werden durch atomare Operationen mit ganzzahligen Werten verfolgt. <br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Queue</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// Concurrently updated by many threads. head: AtomicU32, /// Only updated by producer thread but read by many threads. tail: AtomicU32, /// Masks the head / tail position value to obtain the index in the buffer. mask: usize, /// Stores the tasks. buffer: Box&lt;[MaybeUninit&lt;Task&gt;]&gt;, }</span></span></code> </pre> <br>  Die Warteschlange wird von einem einzelnen Thread ausgeführt: <br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if tail.wrapping_sub(head) &lt; self.buffer.len() as u32 { // Map the position to a slot index. let idx = tail as usize &amp; self.mask; // Don't drop the previous value in `buffer[idx]` because // it is uninitialized memory. self.buffer[idx].as_mut_ptr().write(task); // Make the task available self.tail.store(tail.wrapping_add(1), Release); return; } // The local buffer is full. Push a batch of work to the global // queue. match self.push_overflow(task, head, tail, global) { Ok(_) =&gt; return, // Lost the race, try again Err(v) =&gt; task = v, } }</span></span></code> </pre> <br>  Beachten Sie, dass in dieser <code>push</code> Funktion die einzigen atomaren Operationen das Laden mit <code>Acquire</code> Ordering und das Speichern mit <code>Release</code> Ordering sind.  Es gibt keine RMW-Operationen ( <code>compare_and_swap</code> , <code>fetch_and</code> ...) oder sequentielle Reihenfolge wie zuvor.  Dies ist wichtig, da auf x86-Chips alle Downloads / Speicherungen bereits "atomar" sind.  Auf CPU-Ebene wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diese Funktion daher nicht synchronisiert</a> .  Atomic-Operationen verhindern bestimmte Optimierungen im Compiler, aber das ist alles.  Höchstwahrscheinlich könnte der erste <code>Relaxed</code> mit einer <code>Relaxed</code> Bestellung sicher durchgeführt werden, aber der Austausch bringt keinen merklichen Aufwand mit sich. <br><br>  Wenn die Warteschlange voll ist, wird <code>push_overflow</code> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diese Funktion verschiebt die Hälfte der Aufgaben von der lokalen in die globale Warteschlange. Die globale Warteschlange ist eine aufdringliche Liste, die durch einen Mutex geschützt ist. Beim Verschieben in die globale Warteschlange werden Aufgaben zuerst miteinander verknüpft, dann wird ein Mutex erstellt und alle Aufgaben werden durch Aktualisieren des Zeigers auf das Ende der globalen Warteschlange eingefügt. Dies spart eine kleine kritische Abschnittsgröße. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn Sie mit den Details der Reihenfolge des Atomspeichers vertraut sind, stellen Sie möglicherweise ein potenzielles „Problem“ mit der oben gezeigten Funktion fest </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Die atomare </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ordnungsoperation </font><font style="vertical-align: inherit;">ist </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ziemlich schwach. Es kann veraltete Werte zurückgeben, d. H. Eine parallele Erfassungsoperation kann den Wert bereits erhöhen </font></font><code>self.head</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, jedoch im Stream-Cache</font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der alte Wert bleibt erhalten, sodass der Erfassungsvorgang nicht bemerkt wird. Dies ist kein Problem mit der Richtigkeit des Algorithmus. Im Wesentlichen (schnell) </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kümmern wir uns nur darum, ob die lokale Warteschlange voll ist oder nicht. Da nur der aktuelle Thread die Warteschlange verschieben kann, lässt eine veraltete Operation </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Warteschlange einfach voller aussehen, als sie tatsächlich ist. Möglicherweise wird fälschlicherweise festgestellt, dass die Warteschlange voll ist, und </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dies führt zu einer stärkeren atomaren Operation. Wenn </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">festgestellt wird, dass die Warteschlange tatsächlich nicht voll ist, wird w / zurückgegeben </font></font><code>Err</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und der Vorgang </font></font><code>push</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">erneut gestartet. Dies ist ein weiterer Grund warum</font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verschiebt die Hälfte der Ausführungswarteschlange in die globale Warteschlange. </font><font style="vertical-align: inherit;">Nach dieser Bewegung treten solche Fehlalarme viel seltener auf. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Local </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(vom Prozessor, zu dem die Warteschlange gehört) wird ebenfalls einfach implementiert:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">loop</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> head = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.head.load(Acquire); <span class="hljs-comment"><span class="hljs-comment">// safety: this is the **only** thread that updates this cell. let tail = self.tail.unsync_load(); if head == tail { // queue is empty return None; } // Map the head position to a slot index. let idx = head as usize &amp; self.mask; let task = self.buffer[idx].as_ptr().read(); // Attempt to claim the task read above. let actual = self .head .compare_and_swap(head, head.wrapping_add(1), Release); if actual == head { return Some(task.assume_init()); } }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In dieser Funktion sind ein Atom </font></font><code>load</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und ein </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Der Hauptaufwand kommt von </font></font><code>compare_and_swap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Funktion </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ist ähnlich </font></font><code>pop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, aber die </font></font><code>self.tail</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Atomlast muss von übertragen werden. </font><font style="vertical-align: inherit;">In ähnlicher Weise </font></font><code>push_overflow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versucht die Operation </font></font><code>steal</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, so zu tun, als wäre sie die halbe Warteschlange anstelle einer einzelnen Aufgabe. </font><font style="vertical-align: inherit;">Dies hat einen guten Einfluss auf die Leistung, auf die wir später noch eingehen werden.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der letzte fehlende Teil ist die Analyse der globalen Warteschlange, die Aufgaben empfängt, die lokale Warteschlangen überlaufen, sowie das Übertragen von Aufgaben von Nicht-Prozessor-Threads an den Scheduler. </font><font style="vertical-align: inherit;">Wenn der Prozessor unter Last ist, dh sich Aufgaben in der lokalen Warteschlange befinden, versucht der Prozessor, die Aufgaben nach etwa 60 Aufgaben in der lokalen Warteschlange aus der globalen Warteschlange zu ziehen. </font><font style="vertical-align: inherit;">Es überprüft auch die globale Warteschlange, wenn sie sich im unten beschriebenen Status "Suchen" befindet.</font></font><br><br><a name="3"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Optimieren Sie Nachrichtenvorlagen </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tokio-Anwendungen bestehen normalerweise aus vielen kleinen unabhängigen Aufgaben. Sie interagieren miteinander durch Nachrichten. Eine solche Vorlage ähnelt anderen Sprachen wie Go und Erlang. Angesichts der Häufigkeit der Vorlage ist es für den Planer sinnvoll, sie zu optimieren. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Angenommen, die Aufgaben A und B sind gegeben. Aufgabe A wird jetzt ausgeführt und sendet eine Nachricht über den Übertragungskanal an Aufgabe B. Ein Kanal ist eine Ressource, für die Task B derzeit gesperrt ist. Durch das Senden einer Nachricht wird Task B in einen ausführbaren Status versetzt und in die Ausführungswarteschlange des aktuellen Prozessors gestellt. Dann leitet der Prozessor die nächste Aufgabe aus der Ausführungswarteschlange ab, führt sie aus und wiederholt diesen Zyklus, bis er Aufgabe B erreicht.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Problem besteht darin, dass zwischen dem Senden einer Nachricht und dem Abschließen von Aufgabe B eine erhebliche Verzögerung auftreten kann. </font><font style="vertical-align: inherit;">Darüber hinaus werden heiße Daten, z. B. eine Nachricht, im CPU-Cache gespeichert. Wenn die Aufgabe abgeschlossen ist, werden die entsprechenden Caches wahrscheinlich gelöscht. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dieses Problem zu lösen, implementiert der neue Tokio-Scheduler die Optimierung (wie bei den Go- und Kotlin-Schedulern). </font><font style="vertical-align: inherit;">Wenn eine Aufgabe in einen ausführbaren Zustand versetzt wird, wird sie nicht am Ende der Warteschlange platziert, sondern in einem speziellen Steckplatz für die nächste Aufgabe gespeichert. </font><font style="vertical-align: inherit;">Der Prozessor überprüft diesen Steckplatz immer, bevor er die Warteschlange überprüft. </font><font style="vertical-align: inherit;">Wenn beim Einfügen in den Steckplatz bereits eine alte Aufgabe vorhanden ist, wird diese aus dem Steckplatz gelöscht und an das Ende der Warteschlange verschoben. </font><font style="vertical-align: inherit;">Somit wird die Aufgabe des Sendens einer Nachricht praktisch ohne Verzögerung abgeschlossen.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/12f/e12/a32/12fe12a324d1855a6c62cacd56cb4f70.png"><br><br><a name="4"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Drosselklappenerfassung </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn in einem Joberfassungsplaner die Prozessorausführungswarteschlange leer ist, versucht der Prozessor, Aufgaben von Peer-CPUs zu erfassen. Zuerst wird eine zufällige Peer-CPU ausgewählt. Wenn keine Aufgaben dafür gefunden werden, wird die nächste durchsucht usw., bis Aufgaben gefunden werden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In der Praxis beenden mehrere Prozessoren häufig die Verarbeitung der Ausführungswarteschlange ungefähr zur gleichen Zeit. Dies geschieht, wenn ein Jobpaket eintrifft (z. B. wenn</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auf Bereitschaft der Steckdose abgefragt). Prozessoren wachen auf, empfangen Aufgaben, starten sie und erledigen sie. Dies führt dazu, dass alle Prozessoren gleichzeitig versuchen, die Aufgaben anderer Personen zu erfassen, dh viele Threads versuchen, auf dieselben Warteschlangen zuzugreifen. Es gibt einen Konflikt. Eine zufällige Auswahl des Startpunkts trägt zur Reduzierung des Wettbewerbs bei, aber die Situation ist immer noch nicht sehr gut. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dieses Problem zu umgehen, begrenzt der neue Scheduler die Anzahl der parallelen Prozessoren, die Erfassungsvorgänge ausführen. Wir nennen den Status des Prozessors, in dem er versucht, die Aufgaben anderer Personen zu erfassen, "Jobsuche" oder kurz "Suche" (dazu später mehr). Eine solche Optimierung wird unter Verwendung eines Atomwerts durchgeführt</font></font><code>int</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, die der Prozessor vor dem Starten der Suche erhöht und beim Verlassen des Suchstatus verringert. </font><font style="vertical-align: inherit;">Maximal die Hälfte der Gesamtzahl der Prozessoren kann sich im Suchstatus befinden. </font><font style="vertical-align: inherit;">Das heißt, die ungefähre Grenze ist festgelegt, und dies ist normal. </font><font style="vertical-align: inherit;">Wir brauchen keine feste Begrenzung für die Anzahl der CPUs in der Suche, sondern nur eine Drosselung. </font><font style="vertical-align: inherit;">Wir opfern die Genauigkeit, um die Effizienz des Algorithmus zu verbessern. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nach dem Eintritt in den Suchstatus versucht der Prozessor, die Arbeit von Peer-CPUs zu erfassen, und überprüft die globale Warteschlange.</font></font><br><br><a name="5"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verringern Sie die Synchronisation zwischen Threads </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein weiterer wichtiger Teil des Schedulers ist die Benachrichtigung von Peer-CPUs über neue Aufgaben. Wenn der "Bruder" schläft, wacht er auf und erfasst Aufgaben. Benachrichtigungen spielen eine weitere wichtige Rolle. Denken Sie daran, dass der Warteschlangenalgorithmus eine schwache atomare Ordnung ( </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">/ </font></font><code>Release</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) verwendet. Aufgrund der atomaren Speicherzuweisung kann nicht garantiert werden, dass ein Peer-Prozessor jemals Aufgaben in der Warteschlange ohne zusätzliche Synchronisierung sieht. Daher sind auch Benachrichtigungen dafür verantwortlich. Aus diesem Grund werden Benachrichtigungen teuer. Das Ziel ist es, ihre Anzahl zu minimieren, um keine CPU-Ressourcen zu verwenden, dh der Prozessor hat Aufgaben und der Bruder kann sie nicht stehlen. Eine übermäßige Anzahl von Benachrichtigungen führt zu </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einem Problem mit der Donnerherde</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der ursprüngliche Tokio-Planer verfolgte einen naiven Ansatz bei Benachrichtigungen. Immer wenn eine neue Aufgabe in die Ausführungswarteschlange gestellt wurde, erhielt der Prozessor eine Benachrichtigung. Immer wenn die CPU benachrichtigt wurde und die Aufgabe nach dem Aufwachen sah, benachrichtigte sie eine andere CPU. Diese Logik führte sehr schnell dazu, dass alle Prozessoren aufwachten und nach Arbeit suchten (was zu einem Konflikt führte). Oft fanden die meisten Prozessoren keine Arbeit und schliefen wieder ein.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der neue Scheduler hat dieses Muster erheblich verbessert, ähnlich wie der Go-Scheduler. Benachrichtigungen werden wie zuvor gesendet, jedoch nur, wenn sich keine CPU im Suchstatus befindet (siehe vorherigen Abschnitt). Wenn der Prozessor eine Benachrichtigung erhält, wechselt er sofort in den Suchstatus. Wenn der Prozessor im Suchstatus neue Aufgaben findet, verlässt er zuerst den Suchstatus und benachrichtigt dann den anderen Prozessor. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diese Logik begrenzt die Geschwindigkeit, mit der Prozessoren aufwachen. Wenn ein ganzes Aufgabenpaket sofort geplant ist (zum Beispiel wann</font></font><code>epoll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">abgefragt auf Bereitschaft des Sockets), dann führt die erste Aufgabe zu einer Benachrichtigung an den Prozessor. </font><font style="vertical-align: inherit;">Er ist jetzt in einem Suchzustand. </font><font style="vertical-align: inherit;">Die verbleibenden geplanten Aufgaben im Paket benachrichtigen den Prozessor nicht, da sich mindestens eine CPU im Suchstatus befindet. </font><font style="vertical-align: inherit;">Dieser benachrichtigte Prozessor erfasst die Hälfte der Aufgaben im Stapel und benachrichtigt wiederum den anderen Prozessor. </font><font style="vertical-align: inherit;">Ein dritter Prozessor wacht auf, findet die Aufgaben eines der ersten beiden Prozessoren und erfasst die Hälfte davon. </font><font style="vertical-align: inherit;">Dies führt zu einem reibungslosen Anstieg der Anzahl der funktionierenden CPUs sowie zu einem schnellen Lastausgleich.</font></font><br><br><a name="6"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Speicherzuordnung reduzieren </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der neue Tokio-Scheduler benötigt nur eine Speicherzuordnung für jede erzeugte Aufgabe, während der alte zwei benötigt. </font><font style="vertical-align: inherit;">Bisher sah die Aufgabenstruktur ungefähr so ​​aus:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">/// All state needed to manage the task state: TaskState, /// The logic to run is represented as a future trait object. future: Box&lt;dyn Future&lt;Output = ()&gt;&gt;, }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Struktur </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wird auch in hervorgehoben </font></font><code>Box</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ich wollte dieses Gelenk schon sehr lange reparieren (ich habe es 2014 zum ersten Mal versucht). Zwei Dinge haben sich seit dem alten Tokio-Planer geändert. Erstens stabilisiert </font></font><code>std::alloc</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Zweitens hat das zukünftige Aufgabensystem auf eine explizite </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vtable-Strategie umgestellt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Es waren diese beiden Dinge, die schließlich fehlten, um die ineffiziente doppelte Speicherzuweisung für jede Aufgabe zu beseitigen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nun wird die Struktur </font></font><code>Task</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in der folgenden Form dargestellt:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span></span>&lt;T&gt; { header: Header, future: T, trailer: Trailer, }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Für Aufgaben notwendig und </font></font><code>Header</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und </font></font><code>Trailer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, aber sie sind zwischen dem „heißen“ Daten (Kopf) und „kalten“ (Schwanz), m. E. etwa zwischen Daten häufig zugegriffen wird </font><font style="vertical-align: inherit;">und solche unterteilt , </font><font style="vertical-align: inherit;">die selten verwendet werden. </font><font style="vertical-align: inherit;">"Heiße" Daten werden am Kopf der Struktur platziert und so wenig wie möglich gespeichert. </font><font style="vertical-align: inherit;">Wenn der Prozessor den Taskzeiger dereferenziert, lädt er sofort die Cache-Zeile (von 64 bis 128 Byte). </font><font style="vertical-align: inherit;">Wir möchten, dass diese Daten so relevant wie möglich sind.</font></font><br><br><a name="7"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Reduzierte Anzahl atomarer Verbindungen </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die letzte Optimierung, die wir in diesem Artikel diskutieren, besteht darin, die Anzahl der atomaren Verknüpfungen zu reduzieren. Es gibt viele Verweise auf die Struktur der Aufgabe, auch vom Scheduler und von jedem Waker. Die allgemeine Strategie zur Verwaltung dieses Speichers ist das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zählen atomarer Verbindungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Diese Strategie erfordert jedes Mal, wenn ein Link geklont und ein Link gelöscht wird, eine atomare Operation. Wenn der letzte Link den Gültigkeitsbereich verlässt, wird der Speicher freigegeben. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im alten Tokio-Scheduler enthielten sowohl der Scheduler als auch alle Waker einen Link zu einem Task-Deskriptor, ungefähr:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Waker</span></span></span></span> { task: Arc&lt;Task&gt;, } <span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn die Aufgabe aktiviert wird, wird die Verbindung geklont (ein atomares Inkrement tritt auf). </font><font style="vertical-align: inherit;">Dann wird der Link in die Ausführungswarteschlange gestellt. </font><font style="vertical-align: inherit;">Wenn der Prozessor die Aufgabe empfängt und ihre Ausführung abschließt, verwirft er die Verknüpfung, was zu einer atomaren Reduktion führt. </font><font style="vertical-align: inherit;">Diese atomaren Operationen (Inkrementieren und Verringern) summieren sich. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses Problem wurde zuvor von den Entwicklern des Task-Systems identifiziert </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Sie bemerkten, dass beim Anrufen der </font></font><code>Waker::wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ursprüngliche Link zu </font></font><code>waker</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">häufig nicht mehr benötigt wird. </font><font style="vertical-align: inherit;">Auf diese Weise können Sie den Atomic Link-Zähler wiederverwenden, wenn Sie eine Aufgabe in die Ausführungswarteschlange verschieben. </font><font style="vertical-align: inherit;">Das Task-System enthält </font></font><code>std::future</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jetzt zwei API-Aufrufe zum „Aufwachen“:</font></font><br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>wake</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was akzeptiert </font></font><code>self</code> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><code>wake_by_ref</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was akzeptiert </font></font><code>&amp;self</code> </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine solche API-Konstruktion lässt uns sie beim Aufrufen verwenden </font></font><code>wake</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, um atomare Inkremente zu vermeiden. </font><font style="vertical-align: inherit;">Die Implementierung sieht folgendermaßen aus:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-keyword"><span class="hljs-keyword">impl</span></span> Waker { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake</span></span></span></span>(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { task.scheduler.schedule(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wake_by_ref</span></span></span></span>(&amp;<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> task = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.task.clone(); task.scheduler.schedule(task); } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies vermeidet den Aufwand für zusätzliche Verbindungszählungen </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nur,</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wenn Sie die Verantwortung für das Aufwachen übernehmen können. Nach meiner Erfahrung ist es stattdessen fast immer ratsam, mit aufzuwachen </font></font><code>&amp;self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Das Erwachen </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verhindert die Wiederverwendung von Waker (nützlich in Fällen, in denen die Ressource viele Werte sendet, d. H. Kanäle, Sockets, ...). Auch für den Fall, dass es </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">schwieriger ist, ein thread-sicheres Aufwachen zu implementieren (wir werden die Details für einen anderen Artikel belassen). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der neue Planer löst das Problem des "Aufwachens </font></font><code>self</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">", indem er das atomare Inkrement vermeidet </font></font><code>wake_by_ref</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, was es so effektiv wie macht</font></font><code>wake(self)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Zu diesem Zweck verwaltet der Scheduler eine Liste aller Aufgaben, die derzeit aktiv sind (noch nicht abgeschlossen). </font><font style="vertical-align: inherit;">Die Liste stellt den Referenzzähler dar, der zum Senden der Aufgabe an die Ausführungswarteschlange erforderlich ist. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Komplexität dieser Optimierung liegt in der Tatsache, dass der Scheduler Aufgaben erst dann aus seiner Liste entfernt, wenn er die Garantie erhält, dass die Aufgabe erneut in die Ausführungswarteschlange gestellt wird. </font><font style="vertical-align: inherit;">Details zur Implementierung dieses Schemas gehen über den Rahmen dieses Artikels hinaus. Ich empfehle jedoch dringend, dass Sie sich die Quelle ansehen.</font></font><br><br><a name="7"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fettgedruckte (unsichere) Parallelität mit Loom </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist sehr schwierig, den richtigen parallelen Code ohne Sperren zu schreiben. Es ist besser, langsam, aber korrekt als schnell zu arbeiten, aber mit Störungen, insbesondere wenn die Fehler die Speichersicherheit betreffen. Die beste Option sollte jedoch schnell und fehlerfrei funktionieren. Der neue Scheduler hat einige ziemlich aggressive Optimierungen vorgenommen und vermeidet die meisten Typen </font></font><code>std</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aus Gründen der Spezialisierung. Im Allgemeinen enthält es ziemlich viel unsicheren Code </font></font><code>unsafe</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gibt verschiedene Möglichkeiten, parallelen Code zu testen. Eine davon ist, dass Benutzer anstelle von Ihnen testen und debuggen können (eine attraktive Option, das ist sicher). Eine andere Möglichkeit besteht darin, Komponententests zu schreiben, die in einer Schleife ausgeführt werden und einen Fehler abfangen können. Vielleicht sogar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TSAN verwenden</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wenn er einen Fehler findet, kann er natürlich nicht einfach reproduziert werden, ohne den Testzyklus neu zu starten. Wie lange dauert dieser Zyklus? Zehn Sekunden? Zehn Minuten? Zehn Tage? Zuvor mussten Sie parallelen Code in Rust testen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir fanden diese Situation inakzeptabel. Wenn wir den Code freigeben, möchten wir uns (so weit wie möglich) sicher fühlen, insbesondere bei parallelem Code ohne Sperren. Tokio-Benutzer benötigen Zuverlässigkeit. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aus diesem Grund haben wir </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Loom</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> entwickelt </font><font style="vertical-align: inherit;">: ein Tool zum Testen der Permutation von parallelem Code. Tests werden wie gewohnt geschrieben, aber</font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie werden viele Male ausgeführt und alle möglichen Optionen für die Ausführung und das Verhalten neu angeordnet, auf die der Test in einer Streaming-Umgebung stoßen kann. Außerdem wird überprüft, ob der Speicherzugriff korrekt ist, Speicher freigegeben usw. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist als Beispiel der Webmaschinentest für den neuen Scheduler:</font></font><br><br><pre> <code class="rust hljs"><span class="hljs-meta"><span class="hljs-meta">#[test]</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fn</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">multi_spawn</span></span></span></span>() { loom::model(|| { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pool = ThreadPool::new(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> c1 = Arc::new(AtomicUsize::new(<span class="hljs-number"><span class="hljs-number">0</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (tx, rx) = oneshot::channel(); <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> tx1 = Arc::new(Mutex::new(<span class="hljs-literal"><span class="hljs-literal">Some</span></span>(tx))); <span class="hljs-comment"><span class="hljs-comment">// Spawn a task let c2 = c1.clone(); let tx2 = tx1.clone(); pool.spawn(async move { spawn(async move { if 1 == c1.fetch_add(1, Relaxed) { tx1.lock().unwrap().take().unwrap().send(()); } }); }); // Spawn a second task pool.spawn(async move { spawn(async move { if 1 == c2.fetch_add(1, Relaxed) { tx2.lock().unwrap().take().unwrap().send(()); } }); }); rx.recv(); }); }</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es sieht ziemlich normal aus, aber ein Teil des Codes in einem Block wird </font></font><code>loom::model</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">viele tausend Mal (möglicherweise Millionen) ausgeführt, jedes Mal mit einer geringfügigen Änderung des Verhaltens. Jeder Lauf ändert die genaue Reihenfolge der Threads. Darüber hinaus versucht loom für jede atomare Operation alle unterschiedlichen Verhaltensweisen, die im C ++ 11-Speichermodell zulässig sind. Denken Sie daran, dass die Atomlast mit </font></font><code>Acquire</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eher schwach war und veraltete Werte zurückgeben konnte. Der Test </font></font><code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versucht alle möglichen Werte, die geladen werden können. </font></font><br><br> <code>loom</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wurde ein unschätzbares Werkzeug bei der Entwicklung eines neuen Planers. Er hat mehr als zehn Fehler entdeckt, die alle Unit-Tests, manuellen Tests und Lasttests bestanden haben.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein anspruchsvoller Leser kann bezweifeln, dass der Webstuhl „alle möglichen Permutationen“ überprüft, und er wird Recht haben. Naive Permutationen führen zu einer kombinatorischen Explosion. Jeder nicht triviale Test wird niemals enden. Dieses Problem wurde viele Jahre lang untersucht und eine Reihe von Algorithmen entwickelt, um eine kombinatorische Explosion zu verhindern. Webstuhl grundlegender Algorithmus basierend auf </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dynamische Reduktion mit teilweise Ordnung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dynamic Teil Ordnung reduction). Dieser Algorithmus eliminiert Permutationen, die zum gleichen Ergebnis führen. Der Zustandsraum kann jedoch immer noch so groß werden, dass er nicht in angemessener Zeit (mehrere Minuten) verarbeitet wird. Mit Loom können Sie die dynamische Reduzierung durch Teilbestellung weiter einschränken.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im Allgemeinen bin ich dank umfangreicher Tests mit Loom jetzt </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">viel</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sicherer in der Richtigkeit des Schedulers.</font></font><br><br><h1>  Ergebnisse </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben uns also angesehen, was Scheduler sind und wie der neue Tokio-Scheduler einen enormen Leistungsschub erzielt hat ... aber welche Art von Wachstum? </font><font style="vertical-align: inherit;">Da der neue Scheduler nur entwickelt wurde, wurde er in der realen Welt noch nicht vollständig getestet. </font><font style="vertical-align: inherit;">Folgendes wissen wir. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstens ist der neue Scheduler bei Mikro-Benchmarks viel schneller:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Alter Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Test chained_spawn ... Bank: 2.019.796 ns / iter (+/- 302.168)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test ping_pong ... Bank: 1.279.948 ns / iter (+/- 154.365)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... Bench: 10.283.608 ns / iter (+/- 1.284.275)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test Yield_many ... Bench: 21.450.748 ns / iter (+/- 1.201.337) </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Neuer Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Test chained_spawn ... Bank: 168.854 ns / iter (+/- 8.339)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test ping_pong ... Bank: 562.659 ns / iter (+/- 34.410)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
test spawn_many ... Bench: 7.320.737 ns / iter (+/- 264.620)</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Test Yield_many ... Bench: 14.638.563 ns / iter (+/- 1.573.678) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Diese Benchmark umfasst Folgendes: </font></font><br><br><ul><li> <code>chained_spawn</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rekursiv neue Aufgaben erzeugen, d. h. eine Aufgabe erzeugen, die eine andere Aufgabe erzeugt, die auch eine Aufgabe erzeugt, usw. </font></font><br></li><li> <code>ping_pong</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wählt einen Kanal aus </font></font><code>oneshot</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und erzeugt eine Aufgabe, die eine Nachricht auf diesem Kanal sendet. </font><font style="vertical-align: inherit;">Die ursprüngliche Aufgabe wartet auf eine Nachricht. </font><font style="vertical-align: inherit;">Dies ist der Test, der der „realen Welt“ am nächsten kommt.</font></font><br></li><li> <code>spawn_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Überprüft die Implementierung von Aufgaben im Scheduler, d. H. Erzeugt Aufgaben von außerhalb seines Kontexts. </font></font><br></li><li> <code>yield_many</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> prüft auf unabhängiges Aufwecken von Aufgaben. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Unterschied bei den Benchmarks ist sehr beeindruckend. </font><font style="vertical-align: inherit;">Aber wie wird sich das in der "realen Welt" widerspiegeln? </font><font style="vertical-align: inherit;">Es ist schwer zu sagen, aber ich habe versucht, die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyper-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Benchmarks auszuführen </font><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist der einfachste Hyper-Server, dessen Leistung gemessen wird mit </font></font><code>wrk -t1 -c50 -d10</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Alter Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ausführen von 10s test @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 Gewinde und 50 Verbindungen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Thread-Statistiken Durchschn. Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latenz 371,53us 99,05us 1,97 ms 60,53%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Req / Sec 114.61k 8.45k 133.85k 67.00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1139307 Anfragen in 10.00s, 95.61MB gelesen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anfragen / Sek.: 113923.19</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Übertragung / Sek.: 9,56 MB </font></font></pre><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Neuer Planer </font></font></h4><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ausführen von 10s test @ http://127.0.0.1 {000</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1 Gewinde und 50 Verbindungen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  Thread-Statistiken Durchschn. Stdev Max +/- Stdev</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Latenz 275.05us 69.81us 1.09ms 73.57%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    Req / Sec 153.17k 10.68k 171.51k 71.00%</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
  1522671 Anfragen in 10.00s, 127.79MB gelesen</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anfragen / Sek.: 152258.70</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Übertragung / Sek.: 12,78 MB </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir sehen einen Anstieg der Anfragen pro Sekunde um 34% unmittelbar nach dem Planerwechsel! Als ich das zum ersten Mal sah, war ich sehr glücklich, weil ich eine Steigerung von maximal 5-10% erwartet hatte. Aber dann war ich traurig, denn dieses Ergebnis zeigte auch, dass der alte Tokio-Scheduler nicht so gut ist. Dann erinnerte ich mich, dass Hyper </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bereits</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> führend bei </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">TechEmpower-</font></a><font style="vertical-align: inherit;"> Bewertungen ist </font><font style="vertical-align: inherit;">. Es ist interessant zu sehen, wie sich der neue Planer auf die Bewertungen auswirkt. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tonic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , der gRPC-Client und -Server mit dem neuen Scheduler, hat sich um etwa 10% beschleunigt, was ziemlich beeindruckend ist, wenn man bedenkt, dass Tonic noch nicht vollständig optimiert ist.</font></font><br><br><h1>  Fazit </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich freue mich sehr, dieses Projekt nach einigen Monaten Arbeit endlich abschließen zu können. </font><font style="vertical-align: inherit;">Dies ist eine wesentliche Verbesserung der asynchronen E / A von Rust. </font><font style="vertical-align: inherit;">Ich bin sehr zufrieden mit den Verbesserungen. </font><font style="vertical-align: inherit;">In Tokio-Code gibt es noch viel Raum für Optimierungen, sodass wir mit der Leistungsverbesserung noch nicht fertig sind. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich hoffe, dass das Material im Artikel für Kollegen nützlich ist, die versuchen, ihren Aufgabenplaner zu schreiben.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de472242/">https://habr.com/ru/post/de472242/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de472228/index.html">9 Tricks zum Arbeiten mit Visual Studio-Code</a></li>
<li><a href="../de472230/index.html">Chips für ML - sprechen Sie über neue Produkte</a></li>
<li><a href="../de472232/index.html">Vom „Color Extender für ZX-Spectrum“ bis zum ZX-Poly</a></li>
<li><a href="../de472234/index.html">Kryptowährung: Ist es immer noch ein Freeloader oder ein Partner?</a></li>
<li><a href="../de472240/index.html">Über Gamification. Was ist das, warum und wie geht das? Entwickler-Look</a></li>
<li><a href="../de472246/index.html">Reagieren + IndexDb + Auto-Update = fast AsyncRedux</a></li>
<li><a href="../de472248/index.html">Wie wir das Programmier-IT-Planet-Finale zusammengeführt haben</a></li>
<li><a href="../de472252/index.html">Digitale Veranstaltungen in Moskau vom 21. bis 28. Oktober</a></li>
<li><a href="../de472254/index.html">Digitale Veranstaltungen in St. Petersburg vom 21. bis 28. Oktober</a></li>
<li><a href="../de472258/index.html">Wie man "lernt zu lernen" - die Achtsamkeit verbessert</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ… ğŸ¥¤ ğŸ§œğŸ¿ Basis data dan Kubernet (laporan ulasan dan video) ğŸ¤±ğŸ¾ ğŸ ğŸ™‡ğŸ½</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada 8 November, di aula utama konferensi HighLoad ++ 2018 , dalam kerangka kerja bagian DevOps dan Operasi, sebuah laporan dibuat berjudul Databases ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Basis data dan Kubernet (laporan ulasan dan video)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/431500/">  Pada 8 November, di aula utama konferensi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++ 2018</a> , dalam kerangka kerja bagian DevOps dan Operasi, sebuah laporan dibuat berjudul Databases and Kubernetes.  Ini berbicara tentang ketersediaan tinggi database dan pendekatan toleransi kesalahan untuk Kubernetes dan dengannya, serta pilihan praktis untuk menempatkan DBMS di cluster Kubernetes dan solusi yang ada untuk ini (termasuk Stolon untuk PostgreSQL). <br><br><img src="https://habrastorage.org/webt/oq/mh/kp/oqmhkpy4pxg-olk9yybf_julwvu.jpeg"><br><br>  Secara tradisi, kami senang menyajikan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><b>video dengan laporan</b></a> (sekitar satu jam, <b>jauh lebih</b> informatif <b>daripada</b> artikel) dan penekanan utama dalam bentuk teks.  Ayo pergi! <a name="habracut"></a><br><br><h2>  Teori </h2><br>  Laporan ini muncul sebagai jawaban atas salah satu pertanyaan paling populer yang selama beberapa tahun terakhir kami telah ditanyai tanpa lelah di berbagai tempat: komentar di Habr atau YouTube, jejaring sosial, dll.  Kedengarannya sederhana: "Apakah mungkin untuk menjalankan database di Kubernetes?", Dan jika kita biasanya menjawab "secara umum ya, tapi ...", maka jelas tidak ada cukup penjelasan untuk ini "secara umum" dan "tetapi", tetapi untuk mencocokkannya dalam pesan singkat tidak berhasil. <br><br>  Namun, sebagai permulaan, saya meringkas masalah dari "database [data]" menjadi stateful secara keseluruhan.  DBMS hanya merupakan kasus khusus dari keputusan negara, daftar yang lebih lengkap yang dapat direpresentasikan sebagai berikut: <br><br><img src="https://habrastorage.org/webt/px/ps/2_/pxps2_ff80ru5qfth8bduiu_kdw.png"><br><br>  Sebelum melihat kasus-kasus tertentu, saya akan berbicara tentang tiga fitur penting dari pekerjaan / penggunaan Kubernetes. <br><br><h3>  1. Filosofi Ketersediaan Tinggi Kubernetes </h3><br>  Semua orang tahu analogi "hewan peliharaan dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ternak</a> " dan mengerti bahwa jika Kubernetes adalah cerita dari dunia kawanan, maka DBMS klasik hanyalah hewan peliharaan. <br><br>  Dan seperti apa arsitektur "hewan peliharaan" terlihat dalam versi "tradisional"?  Contoh klasik menginstal MySQL adalah replikasi pada dua server besi dengan daya redundan, disk, jaringan ... dan yang lainnya (termasuk seorang insinyur dan berbagai alat bantu), yang akan membantu kita memastikan bahwa proses MySQL tidak akan gagal, dan jika ada masalah dengan masalah kritis apa pun untuk komponen-komponennya, toleransi kesalahan akan dihormati: <br><br><img src="https://habrastorage.org/webt/0m/qg/s3/0mqgs3e3cco1zukmlah1jg2ubjs.png"><br><br>  Bagaimana tampilan yang sama di Kubernetes?  Di sini, biasanya ada jauh lebih banyak server besi, mereka lebih sederhana dan mereka tidak memiliki daya dan jaringan yang berlebihan (dalam arti bahwa kehilangan satu mesin tidak mempengaruhi apa pun) - semua ini digabungkan menjadi sebuah cluster.  Toleransi kesalahannya disediakan oleh perangkat lunak: jika sesuatu terjadi pada node, Kubernetes mendeteksi dan memulai instance yang diperlukan pada node lain. <br><br>  Apa mekanisme ketersediaan tinggi di K8? <br><br><img src="https://habrastorage.org/webt/n2/gw/mh/n2gwmhiogm3uzv1m5igrzqpyifq.png"><br><br><ol><li>  Pengontrol  Ada banyak, tetapi dua yang utama: <code>Deployment</code> (untuk aplikasi stateless) dan <code>StatefulSet</code> (untuk aplikasi stateful).  Mereka menyimpan semua logika tindakan yang diambil jika terjadi crash node (pod tidak dapat diaksesnya). </li><li>  <code>PodAntiAffinity</code> - kemampuan untuk menentukan pod tertentu sehingga tidak berada pada simpul yang sama. </li><li>  <code>PodDisruptionBudgets</code> - membatasi jumlah instance pod yang dapat dimatikan pada saat yang sama jika ada pekerjaan yang dijadwalkan. </li></ol><br><h3>  2. Jaminan konsistensi Kubernetes </h3><br>  Bagaimana cara kerja skema toleransi kesalahan satu-induk yang sudah dikenal?  Dua server (master dan siaga), salah satunya secara konstan diakses oleh aplikasi, yang pada gilirannya digunakan melalui penyeimbang beban.  Apa yang terjadi jika terjadi masalah jaringan? <br><br><img src="https://habrastorage.org/webt/6p/1k/ve/6p1kvelnrzyrphtu6sb_agftgaa.gif"><br><br>  Klasik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><i>-otak</i></a> : aplikasi mulai mengakses kedua contoh DBMS, masing-masing menganggap dirinya sebagai yang utama.  Untuk menghindari ini, keepalived diganti dengan corosync dengan sudah tiga contoh untuk mencapai kuorum saat memberikan suara untuk master.  Namun, bahkan dalam kasus ini ada masalah: jika turunan DBMS jatuh mencoba untuk "bunuh diri" dengan segala cara yang mungkin (menghapus alamat IP, menerjemahkan database menjadi read-only ...), maka bagian lain dari cluster tidak tahu apa yang terjadi pada master - itu bisa terjadi, bahwa simpul itu benar-benar masih berfungsi dan permintaan sampai ke sana, yang berarti bahwa kita masih tidak bisa mengganti wizard. <br><br>  Untuk mengatasi situasi ini, ada mekanisme untuk mengisolasi node untuk melindungi seluruh cluster dari operasi yang salah - proses ini disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><i>pagar</i></a> .  Esensi praktis bermuara pada kenyataan bahwa kita mencoba dengan beberapa cara eksternal untuk "membunuh" mobil yang jatuh.  Pendekatannya bisa berbeda: dari mematikan mesin melalui IPMI dan memblokir port pada sakelar hingga mengakses API penyedia cloud, dll.  Dan hanya setelah operasi ini Anda dapat beralih wizard.  Ini memastikan jaminan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><i>paling banyak</i></a> yang menjamin <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">konsistensi</a></i> kami. <br><br><img src="https://habrastorage.org/webt/sl/xb/9r/slxb9rwf-lk8mcdaeqiuankz3z8.png"><br><br>  Bagaimana cara mencapai hal yang sama di Kubernetes?  Untuk melakukan ini, ada pengendali yang telah disebutkan, perilaku yang dalam hal node tidak dapat diakses berbeda: <br><br><ol><li>  <code>Deployment</code> : "Saya diberi tahu bahwa seharusnya ada 3 pod, dan sekarang hanya ada 2 pod - saya akan membuat yang baru"; </li><li>  <code>StatefulSet</code> : "Pod pergi?"  Saya akan menunggu: apakah simpul ini akan kembali, atau mereka akan menyuruh kita untuk membunuhnya, "  wadah itu sendiri (tanpa tindakan operator) tidak diciptakan kembali.  Begitulah jaminan yang sama paling banyak sekali dicapai. </li></ol><br>  Namun, di sini, dalam kasus terakhir, pagar diperlukan: kita membutuhkan mekanisme yang mengkonfirmasi bahwa simpul ini sudah tidak ada.  Membuatnya otomatis, pertama, sangat sulit (banyak implementasi yang diperlukan), dan kedua, bahkan lebih buruk, biasanya membunuh node secara lambat (mengakses IPMI dapat mengambil detik atau puluhan detik, atau bahkan beberapa menit).  Hanya sedikit orang yang puas dengan menunggu per menit untuk mengalihkan pangkalan ke master baru.  Tetapi ada pendekatan lain yang tidak memerlukan mekanisme pagar ... <br><br>  Saya akan memulai deskripsinya di luar Kubernetes.  Ia menggunakan penyeimbang beban khusus di mana backend mengakses DBMS.  Spesifisitasnya terletak pada fakta bahwa ia memiliki sifat konsistensi, yaitu  perlindungan terhadap kegagalan jaringan dan split-brain, karena memungkinkan Anda untuk menghapus semua koneksi ke master saat ini, tunggu sinkronisasi (replika) pada node lain dan beralih ke itu.  Saya tidak menemukan istilah yang mapan untuk pendekatan ini dan menyebutnya <i>Konsisten Peralihan</i> . <br><br><img src="https://habrastorage.org/webt/ct/oq/lk/ctoqlkp3efyctjlvsyiheesk2s4.gif"><br><br>  Pertanyaan utama bersamanya adalah bagaimana membuatnya universal, memberikan dukungan untuk penyedia cloud dan instalasi pribadi.  Untuk ini, server proxy ditambahkan ke aplikasi.  Masing-masing dari mereka akan menerima permintaan dari aplikasinya (dan meneruskannya ke DBMS), dan kuorum akan dikumpulkan dari semuanya.  Segera setelah beberapa bagian gugus gagal, proksi yang kehilangan kuorum segera menghapus koneksi mereka ke DBMS. <br><br><img src="https://habrastorage.org/webt/nj/y0/-t/njy0-tahnwp8uxeyevxot_tlntq.png"><br><br><h3>  3. Penyimpanan Data dan Kubernet </h3><br>  Mekanisme utamanya adalah drive jaringan <i>Network Block Device</i> (alias SAN) dalam berbagai implementasi untuk opsi cloud yang diinginkan atau bare metal.  Namun, menempatkan basis data yang dimuat (misalnya, MySQL, yang membutuhkan 50 ribu IOPS) ke cloud (AWS EBS) tidak akan berfungsi karena <i>latensi</i> . <br><br><img src="https://habrastorage.org/webt/qq/wp/r7/qqwpr7fae-nbek0y2o6ex9lbzsa.png"><br><br>  Kubernetes untuk kasus semacam itu memiliki kemampuan untuk menghubungkan hard drive <i>lokal</i> - <i>Penyimpanan Lokal</i> .  Jika terjadi kegagalan (disk tidak lagi tersedia di pod), maka kami terpaksa memperbaiki mesin ini - mirip dengan skema klasik jika terjadi kegagalan satu server yang dapat diandalkan. <br><br>  Kedua opsi ( <i>Perangkat Blok Jaringan</i> dan <i>Penyimpanan Lokal</i> ) milik kategori <i>ReadWriteOnce</i> : penyimpanan tidak dapat dipasang di dua tempat (pod) - untuk penskalaan ini, Anda harus membuat disk baru dan menghubungkannya ke pod baru (ada mekanisme K8 bawaan untuk ini) , dan kemudian isi dengan data yang diperlukan (sudah dilakukan oleh pasukan kami). <br><br>  Jika kita memerlukan mode <i>ReadWriteMany</i> , maka implementasi <i>Network File System</i> (atau NAS) tersedia: untuk cloud publik ini adalah <code>AzureFile</code> dan <code>AWSElasticFileSystem</code> , dan untuk instalasi mereka CephFS dan Glusterfs untuk penggemar sistem terdistribusi, serta NFS. <br><br><img src="https://habrastorage.org/webt/eq/y6/gp/eqy6gpf2duz9ljtzc342bj9upg4.png"><br><br><h2>  Berlatih </h2><br><h3>  1. Standalone </h3><br>  Opsi ini adalah tentang kasus ketika tidak ada yang mencegah Anda memulai DBMS dalam mode server terpisah dengan penyimpanan lokal.  Tidak ada pertanyaan tentang ketersediaan tinggi ... meskipun dapat sampai batas tertentu (mis., Cukup untuk aplikasi ini) diimplementasikan pada tingkat besi.  Ada banyak kasus untuk aplikasi ini.  Pertama-tama, ini semua jenis lingkungan pementasan dan pengembangan, tetapi tidak hanya: layanan sekunder juga jatuh di sini, menonaktifkannya selama 15 menit tidak kritis.  Di Kubernetes, ini diterapkan oleh <code>StatefulSet</code> dengan satu pod: <br><br><img src="https://habrastorage.org/webt/hl/xk/ha/hlxkhaodepe50imvuobtoilrz6o.png"><br><br>  Secara umum, ini adalah opsi yang layak, yang, dari sudut pandang saya, tidak memiliki kekurangan dibandingkan dengan menginstal DBMS pada mesin virtual yang terpisah. <br><br><h3>  2. Pasangan yang direplikasi dengan perpindahan manual </h3><br>  <code>StatefulSet</code> digunakan lagi, tetapi skema umum terlihat seperti ini: <br><br><img src="https://habrastorage.org/webt/vq/_i/to/vq_itonyvigrh0uezqek_lwtlt4.png"><br><br>  Jika salah satu node mogok ( <code>mysql-a-0</code> ), keajaiban tidak terjadi, tetapi kami memiliki replika ( <code>mysql-b-0</code> ) yang dapat digunakan untuk mengalihkan lalu lintas.  Dalam hal ini, bahkan sebelum mengalihkan lalu lintas, penting untuk tidak lupa tidak hanya menghapus permintaan DBMS dari layanan <code>mysql</code> , tetapi juga untuk masuk ke DBMS secara manual dan memastikan bahwa semua koneksi selesai (bunuh), dan juga pergi ke simpul kedua dari DBMS dan konfigurasikan ulang replika dalam arah yang berlawanan. <br><br>  Jika Anda saat ini menggunakan versi klasik dengan dua server (master + standby) tanpa <i>failover</i> otomatis, maka solusi ini setara dengan di Kubernetes.  Cocok untuk MySQL, PostgreSQL, Redis dan produk lainnya. <br><br><h3>  3. Penskalaan beban baca </h3><br>  Faktanya, kasus ini tidak bersifat negara, karena kita hanya berbicara tentang membaca.  Di sini, server DBMS utama berada di luar skema yang dipertimbangkan, dan dalam kerangka Kubernetes, "server server slave" dibuat, yang hanya-baca.  Mekanisme umum - penggunaan wadah init untuk mengisi data DBMS pada setiap pod baru di tambak ini (menggunakan hot dump atau yang biasa dengan tindakan tambahan, dll. - tergantung pada DBMS yang digunakan).  Untuk memastikan bahwa setiap instance tidak ketinggalan terlalu jauh dari master, Anda dapat menggunakan tes liveness. <br><br><img src="https://habrastorage.org/webt/nz/pd/uk/nzpdukumat3zbax7vnkcs5jtsvs.png"><br><br><h3>  4. Klien yang cerdas </h3><br>  Jika Anda membuat <code>StatefulSet</code> dengan tiga memcached, Kubernetes memiliki layanan khusus yang tidak akan menyeimbangkan permintaan, tetapi akan membuat setiap pod untuk domainnya sendiri.  Klien akan dapat bekerja dengan mereka jika dia sendiri mampu sharding dan replikasi. <br><br>  Anda tidak perlu melangkah jauh untuk contoh: ini adalah cara penyimpanan sesi bekerja dalam PHP di luar kotak.  Untuk setiap permintaan sesi, permintaan dilakukan secara bersamaan ke semua server, setelah itu jawaban yang paling relevan dipilih dari mereka (mirip dengan catatan). <br><br><img src="https://habrastorage.org/webt/t8/iz/26/t8iz261adru0mbdw7cd2o5i3y8o.png"><br><br><h3>  5. Solusi Cloud Asli </h3><br>  Ada banyak solusi yang awalnya berfokus pada kegagalan node, yaitu  mereka sendiri dapat melakukan <i>failover</i> dan pemulihan node, memberikan jaminan <i>konsistensi</i> .  Ini bukan daftar lengkap dari mereka, tetapi hanya bagian dari contoh populer: <br><br><img src="https://habrastorage.org/webt/9u/ah/qz/9uahqzayfbdsokgyod153jwfjfs.png"><br><br>  Semuanya ditempatkan di <code>StatefulSet</code> , setelah itu node saling menemukan dan membentuk sebuah cluster.  Produk itu sendiri berbeda dalam bagaimana mereka menerapkan tiga hal: <br><br><ol><li>  Bagaimana simpul belajar tentang satu sama lain?  Ada metode seperti API Kubernetes, catatan DNS, konfigurasi statis, node khusus (seed), penemuan layanan pihak ketiga ... </li><li>  Bagaimana cara klien terhubung?  Melalui load balancer yang mendistribusikan ke host, atau klien perlu tahu tentang semua host, dan ia akan memutuskan bagaimana untuk melanjutkan. </li><li>  Bagaimana penskalaan horizontal dilakukan?  Tidak mungkin, penuh atau sulit / dengan batasan. </li></ol><br>  Terlepas dari solusi yang dipilih untuk masalah ini, semua produk tersebut bekerja dengan baik dengan Kubernetes, karena mereka awalnya diciptakan sebagai " <i>ternak"</i> . <br><br><h3>  6. Stolon PostgreSQL </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Stolon</a> sebenarnya memungkinkan Anda untuk mengubah PostgreSQL, yang dibuat sebagai <i>hewan peliharaan</i> , menjadi <i>ternak</i> .  Bagaimana ini dicapai? <br><br><img src="https://habrastorage.org/webt/g_/z4/pc/g_z4pcehfw6p985duphcgrbukzo.png"><br><br><ul><li>  Pertama, kita membutuhkan penemuan layanan, yang perannya mungkin <b>etcd</b> (opsi lain tersedia) - sekelompok dari mereka ditempatkan di <code>StatefulSet</code> . </li><li>  Bagian lain dari infrastruktur adalah <code>StatefulSet</code> dengan instance PostgreSQL.  Selain DBMS yang tepat, di sebelah setiap instalasi juga ada komponen yang disebut <b>keeper</b> , yang melakukan konfigurasi DBMS. </li><li>  Komponen lain, <b>sentinel,</b> digunakan sebagai <code>Deployment</code> dan memonitor konfigurasi cluster.  Dialah yang memutuskan siapa yang akan menjadi tuan dan siaga, menulis informasi ini ke etcd.  Dan penjaga membaca data dari etcd dan melakukan tindakan yang sesuai dengan status saat ini dengan turunan dari PostgreSQL. </li><li>  Komponen lain yang digunakan dalam <code>Deployment</code> dan menghadapi instance PostgreSQL, <b>proxy,</b> adalah implementasi dari pola <i>Peralihan Konsisten yang</i> telah disebutkan sebelumnya.  Komponen-komponen ini terhubung ke etcd, dan jika koneksi ini hilang, proksi segera membunuh koneksi keluar, karena sejak saat itu ia tidak tahu peran servernya (apakah sekarang master atau standby?). </li><li>  Akhirnya, instance proxy menghadapi <code>LoadBalancer</code> LoadBalancer yang biasa. </li></ul><br><h2>  Kesimpulan </h2><br>  Jadi apakah mungkin untuk berbasis di Kubernet?  Ya, tentu saja, itu mungkin, dalam beberapa kasus ... Dan jika sesuai, itu dilakukan seperti ini (lihat alur kerja Stolon) ... <br><br>  Semua orang tahu bahwa teknologi berkembang dalam gelombang.  Awalnya, setiap perangkat baru bisa sangat sulit digunakan, tetapi seiring waktu, semuanya berubah: teknologi menjadi tersedia.  Kemana kita akan pergi  Ya, itu akan tetap ada di dalam, tetapi kami tidak akan tahu cara kerjanya.  Kubernetes secara aktif mengembangkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">operator</a> .  Sejauh ini tidak ada banyak dari mereka dan mereka tidak begitu baik, tetapi ada gerakan ke arah ini. <br><br><h2>  Video dan slide </h2><br>  Video dari kinerja (sekitar satu jam): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BnegHj53pW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Penyajian laporan: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  PS Kami juga menemukan di internet sangat singkat (!) <a href="">Pemerasan tekstual</a> dari laporan ini - terima kasih untuk itu untuk Nikolai Volynkin. <br><br><h2>  PPS </h2><br>  Laporan lain di blog kami: <br><br><ul><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Monitoring and Kubernetes</a> â€;  <i>(Dmitry Stolyarov; 28 Mei 2018 di RootConf)</i> ; </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Praktik CI / CD Terbaik dengan Kubernetes dan GitLab</a> â€;  <i>(Dmitry Stolyarov; 7 November 2017 di HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengalaman kami dengan Kubernetes dalam proyek-proyek kecil</a> ";  <i>(Dmitry Stolyarov; 6 Juni 2017 di RootConf)</i> ; </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kami mengumpulkan gambar Docker untuk CI / CD dengan cepat dan nyaman dengan dapp</a> â€ <i>(Dmitry Stolyarov; 8 November 2016 di HighLoad ++)</i> ; </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Praktik Pengiriman Berkelanjutan dengan Docker</a> â€ <i>(Dmitry Stolyarov; 31 Mei 2016 di RootConf)</i> . </li></ul><br>  Anda mungkin juga tertarik dengan publikasi berikut: <br><br><ul><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubernetes tips &amp; trik: mempercepat bootstrap dari database besar</a> â€; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Orkestrasi DBMS CockroachDB di Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id431500/">https://habr.com/ru/post/id431500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id431488/index.html">Modulasi suara</a></li>
<li><a href="../id431490/index.html">Eksternal - GUI untuk Golang</a></li>
<li><a href="../id431492/index.html">Bereaksi kuis kontes parsing dari booth HeadHunter di HolyJs 2018</a></li>
<li><a href="../id431496/index.html">Bagaimana teknologi membantu guru kelas khusus</a></li>
<li><a href="../id431498/index.html">WebP akan segera mengambil alih web, tetapi itu tidak akan lama</a></li>
<li><a href="../id431502/index.html">Konferensi untuk pengembang iOS Kolesa Mobile 3.0. Laporan video</a></li>
<li><a href="../id431504/index.html">Phishing - bekerja. Kronik pencurian iPhone XS diikuti oleh pencurian data iCloud</a></li>
<li><a href="../id431506/index.html">Xcode dan Advanced Debugging di LLDB: Bagian 1</a></li>
<li><a href="../id431508/index.html">Manajemen Transaksi yang Efisien di Musim Semi</a></li>
<li><a href="../id431510/index.html">Cara mengumpulkan informasi dari Kontur. Membeli dengan Selenium</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
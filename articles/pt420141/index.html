<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÖüèæ üë∞üèæ üóúÔ∏è No MPP DBMS carregado - peppy Data Lake com ferramentas anal√≠ticas: compartilhe os detalhes da cria√ß√£o üôáüèΩ üåõ üõ∑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todas as organiza√ß√µes que t√™m pelo menos algo a ver com dados, mais cedo ou mais tarde, enfrentam o problema de armazenar bancos de dados relacionais ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>No MPP DBMS carregado - peppy Data Lake com ferramentas anal√≠ticas: compartilhe os detalhes da cria√ß√£o</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/420141/">  Todas as organiza√ß√µes que t√™m pelo menos algo a ver com dados, mais cedo ou mais tarde, enfrentam o problema de armazenar bancos de dados relacionais e n√£o estruturados.  N√£o √© f√°cil encontrar uma abordagem conveniente, eficaz e barata para esse problema ao mesmo tempo.  E para garantir que os cientistas de dados possam trabalhar com sucesso com modelos de aprendizado de m√°quina.  Fizemos isso - e, embora eu tivesse que mexer com isso, o lucro final foi ainda mais do que o esperado.  Discutiremos todos os detalhes abaixo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/755/bd0/32c/755bd032c95a1b46c4f412d65c5a7bf4.png"><br><a name="habracut"></a><br>  Com o tempo, quantidades incr√≠veis de dados corporativos se acumulam em qualquer banco.  Uma quantidade compar√°vel √© armazenada apenas em empresas e telecomunica√ß√µes da Internet.  Isso aconteceu devido aos altos requisitos regulat√≥rios.  Esses dados n√£o ficam ociosos - os diretores das institui√ß√µes financeiras descobriram h√° muito tempo como lucrar com isso. <br><br>  Todos n√≥s come√ßamos com relat√≥rios gerenciais e financeiros.  Com base nesses dados, aprendemos a tomar decis√µes de neg√≥cios.  Muitas vezes, havia a necessidade de obter dados de v√°rios sistemas de informa√ß√£o do banco, para os quais criamos bancos de dados e sistemas de relat√≥rios consolidados.  A partir disso, gradualmente se formou o que agora √© chamado de data warehouse.  Logo, com base nesse armazenamento, nossos outros sistemas come√ßaram a funcionar: <br><br><ul><li>  CRM anal√≠tico, permitindo oferecer ao cliente produtos mais convenientes para ele; <br></li><li>  transportadores de empr√©stimos que ajudam voc√™ a tomar uma decis√£o r√°pida e precisa sobre um empr√©stimo; <br></li><li>  sistemas de fidelidade que calculam pontos de reembolso ou b√¥nus de acordo com a mec√¢nica de complexidade vari√°vel. <br></li></ul><br>  Todas essas tarefas s√£o resolvidas por aplicativos anal√≠ticos que usam modelos de aprendizado de m√°quina.  Quanto mais modelos de informa√ß√µes puderem extrair do reposit√≥rio, mais precisamente eles funcionar√£o.  Sua necessidade de dados est√° crescendo exponencialmente. <br><br>  Sobre essa situa√ß√£o, chegamos a dois ou tr√™s anos atr√°s.  Naquela √©poca, t√≠nhamos um armazenamento baseado no MPP Teradata DBMS usando a ferramenta SAS Data Integration Studio ELT.  Constru√≠mos este armaz√©m desde 2011 em conjunto com a Glowbyte Consulting.  Mais de 15 grandes sistemas banc√°rios foram integrados a ele e, ao mesmo tempo, dados suficientes foram acumulados para a implementa√ß√£o e o desenvolvimento de aplicativos anal√≠ticos.  A prop√≥sito, naquele momento, a quantidade de dados nas camadas principais da loja, devido a muitas tarefas diferentes, come√ßou a crescer de maneira n√£o linear e as an√°lises avan√ßadas de clientes tornaram-se uma das principais dire√ß√µes do desenvolvimento do banco.  Sim, e nossos dados Os cientistas estavam ansiosos para apoi√°-la.  Em geral, para construir a Plataforma de Pesquisa de Dados, as estrelas se formaram como deveriam. <br><br><h2>  Planejando uma solu√ß√£o </h2><br>  Aqui √© necess√°rio explicar: software e servidores industriais s√£o um prazer caro, mesmo para um grande banco.  Nem toda organiza√ß√£o pode se dar ao luxo de armazenar uma grande quantidade de dados nos principais MPP DBMS.  Voc√™ sempre precisa escolher entre pre√ßo e velocidade, confiabilidade e volume. <br><br>  Para aproveitar ao m√°ximo as oportunidades dispon√≠veis, decidimos fazer o seguinte: <br><br><ul><li> A carga do ELT e a parte mais solicitada dos dados hist√≥ricos do CD devem ser deixadas no DBMS Teradata; <br></li><li>  envie a hist√≥ria completa para o Hadoop, que permite armazenar informa√ß√µes muito mais baratas. <br></li></ul><br>  Naquela √©poca, o ecossistema Hadoop tornou-se n√£o apenas elegante, mas tamb√©m suficientemente confi√°vel, conveniente para uso corporativo.  Foi necess√°rio escolher um kit de distribui√ß√£o.  Voc√™ pode criar o seu pr√≥prio ou usar o Apache Hadoop aberto.  Por√©m, entre as solu√ß√µes empresariais baseadas no Hadoop, as distribui√ß√µes prontas de outros fornecedores - Cloudera e Hortonworks - provaram ser mais.  Portanto, tamb√©m decidimos usar uma distribui√ß√£o pronta. <br><br>  Como nossa principal tarefa ainda era armazenar big data estruturado, na pilha do Hadoop, est√°vamos interessados ‚Äã‚Äãem solu√ß√µes o mais pr√≥ximo poss√≠vel dos DBMSs SQL cl√°ssicos.  Os l√≠deres aqui s√£o Impala e Hive.  A Cloudera desenvolve e integra as solu√ß√µes Impala, Hortonworks - Hive. <br><br>  Para um estudo aprofundado, organizamos testes de carga para os dois DBMSs, levando em considera√ß√£o a carga de perfil para n√≥s.  Devo dizer que os mecanismos de processamento de dados no Impala e no Hive s√£o significativamente diferentes - o Hive geralmente apresenta v√°rias op√ß√µes diferentes.  No entanto, a escolha recaiu na Impala - e, consequentemente, na distribui√ß√£o da Cloudera. <br><br><h2>  O que eu gostei sobre o Impala </h2><br><ul><li>  <i>Alta velocidade de execu√ß√£o de consultas anal√≠ticas</i> devido a uma abordagem alternativa em rela√ß√£o ao MapReduce.  Os resultados intermedi√°rios dos c√°lculos n√£o dobram no HDFS, o que acelera significativamente o processamento de dados. <br></li><li>  <i>Trabalho eficiente com armazenamento de dados em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">parquet</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parquet</a> .</i>  Para tarefas anal√≠ticas, as chamadas tabelas amplas com muitas colunas s√£o frequentemente usadas.  Todas as colunas raramente s√£o usadas - a capacidade de aumentar do HDFS apenas as necess√°rias para o trabalho permite economizar RAM e acelerar significativamente a solicita√ß√£o. <br></li><li>  <i>Uma solu√ß√£o elegante com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtros de tempo de execu√ß√£o</a> que incluem filtragem de bloom.</i>  O Hive e o Impala s√£o significativamente limitados no uso de √≠ndices comuns aos DBMSs cl√°ssicos devido √† natureza do sistema de armazenamento de arquivos HDFS.  Portanto, para otimizar a execu√ß√£o da consulta SQL, o mecanismo DBMS deve efetivamente usar o particionamento dispon√≠vel, mesmo quando n√£o for especificado explicitamente nas condi√ß√µes da consulta.  Al√©m disso, ele precisa tentar prever qual quantidade m√≠nima de dados do HDFS precisa ser gerada para garantir o processamento de todas as linhas.  Na Impala, isso funciona muito bem. <br></li><li>  <i>A Impala <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">usa o LLVM</a></i> , um compilador de m√°quina virtual com instru√ß√µes semelhantes a RISC, para gerar o c√≥digo de execu√ß√£o de consulta SQL ideal. <br></li><li>  <i>As interfaces ODBC e JDBC s√£o suportadas.</i>  Isso permite integrar os dados do Impala com ferramentas e aplicativos anal√≠ticos quase que prontos para uso. <br></li><li>  <i>√â poss√≠vel usar o Kudu</i> para contornar algumas das limita√ß√µes do HDFS e, em particular, escrever constru√ß√µes UPDATE e DELETE em consultas SQL. <br></li></ul><br><h2>  Sqoop e o restante da arquitetura </h2><br>  A pr√≥xima ferramenta mais importante na pilha do Hadoop foi o Sqoop para n√≥s.  Ele permite transferir dados entre o DBMS relacional (√© claro que est√°vamos interessados ‚Äã‚Äãno Teradata) e o HDFS em um cluster Hadoop em v√°rios formatos, incluindo o Parquet.  Nos testes, o Sqoop mostrou alta flexibilidade e desempenho, por isso decidimos us√°-lo - em vez de desenvolver nossas pr√≥prias ferramentas para capturar dados atrav√©s do ODBC / JDBC e salvar no HDFS. <br><br>  Para modelos de treinamento e tarefas relacionadas √† Data Science, que s√£o mais convenientes para executar diretamente no cluster Hadoop, usamos o Apache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Spark</a> .  Em seu campo, tornou-se uma solu√ß√£o padr√£o - e h√° uma raz√£o: <br><br><ul><li>  Bibliotecas de aprendizado de m√°quina Spark ML <br></li><li>  suporte para quatro linguagens de programa√ß√£o (Scala, Java, Python, R); <br></li><li>  integra√ß√£o com ferramentas anal√≠ticas; <br></li><li>  O processamento de dados na mem√≥ria oferece excelente desempenho. <br></li></ul><br>  O servidor Oracle Big Data Appliance foi adquirido como uma plataforma de hardware.  Come√ßamos com seis n√≥s em um circuito produtivo com uma CPU de 2x24 n√∫cleos e 256 GB de mem√≥ria cada.  A configura√ß√£o atual cont√©m 18 dos mesmos n√≥s com expans√£o de at√© 512 GB de mem√≥ria. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58f/173/025/58f173025e987a85582e383fd5f4b3d9.png"><br><br>  O diagrama mostra a arquitetura de n√≠vel superior da Data Research Platform e sistemas relacionados.  O link central √© o cluster Hadoop com base na distribui√ß√£o Cloudera (CDH).  √â usado para receber com Sqoop e armazenar dados QCD em HDFS - no formato parquet, permitindo o uso de codecs para compacta√ß√£o, por exemplo, Snappy.  O cluster tamb√©m processa dados: o Impala √© usado para transforma√ß√µes do tipo ELT, Spark - para tarefas de Ci√™ncia de Dados.  O Sentry √© usado para compartilhar o acesso a dados. <br><br>  A Impala possui interfaces para quase todas as ferramentas modernas de an√°lise corporativa.  Al√©m disso, ferramentas arbitr√°rias que suportam interfaces ODBC / JDBC podem ser conectadas como clientes.  Para trabalhar com SQL, consideramos o Hue e o TOAD for Hadoop como os principais clientes. <br><br>  Um subsistema ETL que consiste em ferramentas SAS (Metadata Server, Data Integration Studio) e uma estrutura ETL gravada com base em scripts SAS e shell usando um banco de dados para armazenar metadados de processos ETL s√£o usados ‚Äã‚Äãpara gerenciar todos os fluxos indicados pelas setas no diagrama. .  Guiado pelas regras especificadas nos metadados, o subsistema ETL inicia os processos de processamento de dados no QCD e na Plataforma de Pesquisa de Dados.  Como resultado, temos um sistema completo para monitorar e gerenciar fluxos de dados, independentemente do ambiente utilizado (Teradata, Impala, Spark, etc., se necess√°rio). <br><br><h2>  Atrav√©s do ancinho para as estrelas </h2><br>  Descarregar o QCD parece ser simples.  Na entrada e na sa√≠da, o DBMS relacional recebe e transborda dados pelo Sqoop.  A julgar pela descri√ß√£o acima, tudo correu muito bem conosco, mas, √© claro, n√£o foi sem aventuras, e essa talvez seja a parte mais interessante de todo o projeto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c7/011/2fc/5c70112fc6dae573401cfd4a85733514.png"><br><br>  Com o nosso volume, n√£o poder√≠amos esperar transferir todos os dados inteiramente todos os dias.  Assim, em cada instala√ß√£o de armazenamento, foi necess√°rio aprender a distinguir um incremento confi√°vel, o que nem sempre √© f√°cil quando os dados para datas comerciais hist√≥ricas podem mudar na tabela.  Para resolver esse problema, sistematizamos objetos, dependendo dos m√©todos de carregamento e manuten√ß√£o do hist√≥rico.  Em seguida, para cada tipo, foram determinados o predicado correto para Sqoop e o m√©todo de carregamento no receptor.  E, finalmente, eles escreveram instru√ß√µes para desenvolvedores de novos objetos. <br><br>  O Sqoop √© uma ferramenta de alta qualidade, mas n√£o em todos os casos e combina√ß√µes de sistemas, ele funciona de maneira absolutamente confi√°vel.  Em nossos volumes, o conector para Teradata n√£o funcionou de maneira ideal.  Aproveitamos o c√≥digo-fonte aberto do Sqoop e fizemos altera√ß√µes nas bibliotecas de conectores.  A estabilidade da conex√£o ao mover dados aumentou. <br><br>  Por algum motivo, quando o Sqoop chama Teradata, os predicados n√£o s√£o convertidos corretamente nas condi√ß√µes WHERE.  Por esse motivo, o Sqoop √†s vezes tenta extrair uma tabela enorme e filtr√°-la mais tarde.  Falhamos em corrigir o conector aqui, mas encontramos outra maneira: criar √† for√ßa uma tabela tempor√°ria com um predicado imposto para cada objeto descarregado e pedir ao Sqoop para preench√™-lo em excesso. <br><br>  Todo o MPP, e o Teradata em particular, possuem um recurso relacionado ao armazenamento paralelo de dados e √† execu√ß√£o de instru√ß√µes.  Se esse recurso n√£o for levado em considera√ß√£o, pode ser que todo o trabalho seja ocupado por um n√≥ l√≥gico do cluster, o que tornar√° a execu√ß√£o da consulta muito mais lenta, uma vez em 100-200.  Obviamente, n√£o poder√≠amos permitir isso, portanto, escrevemos um mecanismo especial que usa metadados ETL das tabelas QCD e seleciona o grau ideal de paraleliza√ß√£o das tarefas do Sqoop. <br><br>  O hist√≥rico do armazenamento √© uma quest√£o delicada, especialmente se voc√™ usar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SCD2</a> , enquanto o Impala n√£o suporta UPDATE e DELETE.  Obviamente, queremos que as tabelas hist√≥ricas na Data Research Platform sejam exatamente iguais √†s do Teradata.  Isso pode ser alcan√ßado combinando o incremento de recebimento por meio do Sqoop, destacando chaves de neg√≥cios atualizadas e excluindo parti√ß√µes no Impala.  Para que essa l√≥gica elaborada n√£o precise ser escrita por cada desenvolvedor, compilamos em uma biblioteca especial (no nosso ‚Äúcarregador‚Äù de g√≠ria ETL). <br><br>  Finalmente - uma pergunta com tipos de dados.  O Impala √© bastante livre para convers√£o de tipos, portanto, encontramos algumas dificuldades apenas nos tipos TIMESTAMP e CHAR / VARCHAR.  Para data e hora, decidimos armazenar dados no Impala no formato de texto (STRING) AAAA-MM-DD HH: MM: SS.  Essa abordagem, como se viu, possibilita o uso das fun√ß√µes de transforma√ß√£o de data e hora.  Para dados de string de um determinado comprimento, descobriu-se que o armazenamento no formato STRING no Impala n√£o √© inferior a eles, portanto, tamb√©m o usamos. <br><br>  Normalmente, para organizar o Data Lake, os dados de origem em formatos semiestruturados s√£o copiados para uma √°rea de est√°gio especial no Hadoop e, usando o Hive ou Impala, eles estabelecem um esquema de desserializa√ß√£o desses dados para uso em consultas SQL.  N√≥s seguimos o mesmo caminho.  √â importante observar que nem tudo e nem sempre faz sentido arrastar o data warehouse, pois o desenvolvimento de processos de c√≥pia de arquivos e a instala√ß√£o do esquema s√£o muito mais baratos do que carregar atributos de neg√≥cios no modelo QCD usando processos ETL.  Quando ainda n√£o est√° claro quanto, por quanto tempo e com que frequ√™ncia os dados de origem s√£o necess√°rios, o Data Lake na abordagem descrita √© uma solu√ß√£o simples e barata.  Agora, carregamos regularmente no Data Lake principalmente fontes que geram eventos do usu√°rio: dados de an√°lise de aplicativos, logs e cen√°rios de transi√ß√£o para discagem autom√°tica e secret√°ria eletr√¥nica da Avaya, transa√ß√µes de cart√£o. <br><br><h2>  Kit de ferramentas do analista </h2><br>  N√£o esquecemos outro objetivo de todo o projeto - permitir que os analistas usem toda essa riqueza.  Aqui est√£o os princ√≠pios b√°sicos que nos guiaram aqui: <br><br><ul><li>  Conveni√™ncia da ferramenta em uso e suporte <br></li><li>  Aplicabilidade em tarefas de ci√™ncia de dados <br></li><li>  A possibilidade m√°xima de usar os recursos de computa√ß√£o do cluster Hadoop, em vez de servidores de aplicativos ou o computador do pesquisador <br></li></ul><br>  E aqui est√° o que paramos: <br><br><ul><li>  Python + Anaconda.  O ambiente usado √© o iPython / Jupyter <br></li><li>  R + Brilhante.  O pesquisador trabalha na vers√£o desktop ou web do R Studio, Shiny, usada para desenvolver aplicativos da web aprimorados pelo uso de algoritmos desenvolvidos em R. <br></li><li>  Spark  Para trabalhar com dados, s√£o usadas as interfaces para Python (pyspark) e R, configuradas nos ambientes de desenvolvimento especificados nos par√°grafos anteriores.  Ambas as interfaces permitem usar a biblioteca Spark ML, o que possibilita o treinamento de modelos ML no cluster Hadoop / Spark. <br></li><li>  Os dados do Impala s√£o acess√≠veis atrav√©s do Hue, Spark e de ambientes de desenvolvimento usando a interface ODBC padr√£o e bibliotecas especiais como implyr <br></li></ul><br>  Atualmente, o Data Lake cont√©m cerca de 100 TB de dados do armazenamento de varejo, al√©m de cerca de 50 TB de v√°rias fontes OLTP.  O lago √© atualizado diariamente de forma incremental.  No futuro, aumentaremos a conveni√™ncia do usu√°rio, introduziremos uma carga ELT no Impala, aumentaremos o n√∫mero de fontes carregadas no Data Lake e expandiremos as oportunidades para an√°lises avan√ßadas. <br><br>  Concluindo, gostaria de dar alguns conselhos gerais aos colegas que est√£o apenas come√ßando sua jornada na cria√ß√£o de grandes reposit√≥rios: <br><br><ul><li>  Use as melhores pr√°ticas.  Se n√£o tiv√©ssemos um subsistema ETL, metadados, armazenamento com vers√£o e uma arquitetura compreens√≠vel, n√£o ter√≠amos dominado essa tarefa.  As melhores pr√°ticas se pagam, embora n√£o imediatamente. <br></li><li>  Lembre-se da quantidade de dados.  O big data pode criar dificuldades t√©cnicas em locais muito inesperados. <br></li><li>  Fique atento √†s novas tecnologias.  Novas solu√ß√µes aparecem frequentemente, nem todas s√£o √∫teis, mas √†s vezes gemas reais s√£o encontradas. <br></li><li>  Experimente mais.  N√£o confie apenas nas descri√ß√µes de marketing das solu√ß√µes - tente voc√™ mesmo. <br></li></ul><br>  <i>A prop√≥sito, voc√™ pode ler sobre como nossos analistas usaram o aprendizado de m√°quina e os dados banc√°rios para trabalhar com riscos de cr√©dito em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">post</a> separado.</i> <i><br></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420141/">https://habr.com/ru/post/pt420141/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420129/index.html">Padr√µes ass√≠ncronos de rotina: fora aguardam</a></li>
<li><a href="../pt420131/index.html">M√©todo Probabil√≠stico de Minera√ß√£o de Bitcoin</a></li>
<li><a href="../pt420133/index.html">Modelagem de sistemas din√¢micos: como a lua se move?</a></li>
<li><a href="../pt420135/index.html">Isso tamb√©m √© Toshiba: produtos inesperados da corpora√ß√£o japonesa</a></li>
<li><a href="../pt420139/index.html">Livro ‚ÄúSite Confiabilidade Engenharia. Confiabilidade e confiabilidade como no Google ¬ª</a></li>
<li><a href="../pt420143/index.html">Desempenho do Kotlin no Android</a></li>
<li><a href="../pt420145/index.html">Como √© o dia √∫til dos membros do PC AppsConf</a></li>
<li><a href="../pt420147/index.html">C√≥digo aberto no Clojure</a></li>
<li><a href="../pt420151/index.html">Mais f√°cil do que parece. Cap√≠tulo 12</a></li>
<li><a href="../pt420153/index.html">Impress√£o 3D de pe√ßas complexas feitas de ABS e PLA com muito suporte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
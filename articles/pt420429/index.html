<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíä ü•ã ü•§ USE, RED, PgBouncer, suas configura√ß√µes e monitoramento üåê üßëüèº üë∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Come√ßamos a atualizar o monitoramento do PgBouncer em nosso servi√ßo e decidimos pentear tudo um pouco. Para ajustar tudo, reunimos as mais famosas met...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>USE, RED, PgBouncer, suas configura√ß√µes e monitoramento</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/420429/"><img align="left" width="359" src="https://habrastorage.org/webt/l4/xy/iz/l4xyize9ztzrmf303fot3iylnc8.png" alt="Pgbouncer USE RED"><br><p>  Come√ßamos a atualizar o monitoramento do PgBouncer em nosso servi√ßo e decidimos pentear tudo um pouco.  Para ajustar tudo, reunimos as mais famosas metodologias de monitoramento de desempenho: USE (Utiliza√ß√£o, Satura√ß√£o, Erros), de Brendan Gregg, e RED (Solicita√ß√µes, Erros, Dura√ß√µes), de Tom Wilkie. </p><br><p>  Sob a cena, h√° uma hist√≥ria com gr√°ficos sobre como o pgbouncer funciona, qual configura√ß√£o lida com ele e como usar USE / RED para escolher as m√©tricas corretas para monitor√°-lo. </p><a name="habracut"></a><br><h2 id="snachala-pro-sami-metody">  Primeiro sobre os pr√≥prios m√©todos </h2><br><p>  Embora esses m√©todos sejam bastante conhecidos (sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">eles, ele j√° estava em Habr√©, embora n√£o em grandes detalhes</a> ), n√£o √© que eles sejam difundidos na pr√°tica. </p><br><h3 id="use">  UTILIZA√á√ÉO </h3><br><blockquote>  Para cada recurso, acompanhe o descarte, a satura√ß√£o e os erros. <br>  Brendan gregg </blockquote><p>  Aqui, um <strong>recurso</strong> √© qualquer componente f√≠sico separado - uma CPU, disco, barramento, etc.  Mas n√£o apenas - o desempenho de alguns recursos de software tamb√©m pode ser considerado por esse m√©todo, em particular recursos virtuais, como containers / cgroups com limites, tamb√©m √© conveniente considerar isso. </p><br><p> <strong>U - Descarte</strong> : uma porcentagem do tempo (a partir do intervalo de observa√ß√£o) em que o recurso estava ocupado com um trabalho √∫til.  Como, por exemplo, carregar 90% da CPU ou da utiliza√ß√£o do disco significa que 90% do tempo foi gasto por algo √∫til) ou, para recursos como mem√≥ria, essa √© a porcentagem de mem√≥ria usada. </p><br><p>  De qualquer forma, 100% de reciclagem significa que o recurso n√£o pode ser usado mais do que agora.  E o trabalho ficar√° parado aguardando libera√ß√£o / v√° para a fila ou haver√° erros.  Esses dois cen√°rios s√£o cobertos pelas duas m√©tricas restantes de USE correspondentes: </p><br><p>  <strong>S - Satura√ß√£o</strong> , tamb√©m √© satura√ß√£o: uma medida da quantidade de trabalho "adiado" / em fila. </p><br><p>  <strong>E - Erros</strong> : contamos simplesmente o n√∫mero de falhas.  Erros / falhas afetam o desempenho, mas podem n√£o ser percebidos imediatamente devido √† recupera√ß√£o de opera√ß√µes invertidas ou mecanismos de toler√¢ncia a falhas com dispositivos de backup, etc. </p><br><h3 id="red">  Vermelho </h3><br><p>  Tom Wilkie (agora trabalhando na Grafana Labs) ficou frustrado com a metodologia USE, ou melhor, com sua baixa aplicabilidade em alguns casos e inconsist√™ncia com a pr√°tica.  Como, por exemplo, medir a satura√ß√£o da mem√≥ria?  Ou como medir erros de barramento do sistema na pr√°tica? </p><br><blockquote>  Acontece que o Linux realmente relata contagens de bugs. <br>  T. Wilkie </blockquote><p>  Em resumo, para monitorar o desempenho e o comportamento dos microsservi√ßos, ele prop√¥s outro m√©todo adequado: medir novamente tr√™s indicadores: </p><br><p>  <strong>Taxa R</strong> : O n√∫mero de solicita√ß√µes por segundo. <br>  <strong>E - Erros</strong> : quantas solicita√ß√µes retornaram um erro. <br>  <strong>D - Dura√ß√£o</strong> : tempo necess√°rio para processar a solicita√ß√£o.  √â lat√™ncia, "lat√™ncia" (¬© Sveta Smirnova :), tempo de resposta, etc. </p><br><p>  Em geral, USE √© mais adequado para monitorar recursos e RED para servi√ßos e sua carga de trabalho / carga √∫til. </p><br><h2 id="pgbouncer">  Pgbouncer </h2><br><p>  Sendo um servi√ßo, ao mesmo tempo, possui todos os tipos de limites e recursos internos.  O mesmo pode ser dito sobre o Postgres, que os clientes acessam atrav√©s deste PgBouncer.  Portanto, para o monitoramento completo nessa situa√ß√£o, os dois m√©todos s√£o necess√°rios. </p><br><p>  Para entender como aplicar esses m√©todos a um seguran√ßa, voc√™ precisa entender os detalhes de seu dispositivo.  N√£o basta monitor√°-lo como uma caixa preta - "o processo do pgbouncer est√° ativo" ou "a porta est√° aberta", porque  em caso de problemas, isso n√£o dar√° uma compreens√£o do que exatamente e como ele quebrou e o que fazer. </p><br><p>  O que geralmente tem a apar√™ncia do PgBouncer do ponto de vista do cliente: </p><br><ol><li>  cliente se conecta </li><li>  [o cliente faz uma solicita√ß√£o - recebe uma resposta] x quantas vezes ele precisa </li></ol><br><p>  Aqui, desenhei um diagrama dos estados correspondentes do cliente do ponto de vista do PgBoucer: <br><img src="https://habrastorage.org/webt/zb/mh/ot/zbmhotvidvuxnsbzp04-bqtgqhk.jpeg"></p><br><p> No processo de login, a autoriza√ß√£o pode ocorrer localmente (arquivos, certificados e at√© PAM e hba de novas vers√µes) e remotamente - ou seja,  no pr√≥prio banco de dados ao qual a conex√£o est√° sendo tentada.  Assim, o estado de logon possui um subestado adicional.  Vamos cham√°-lo de <code>Executing</code> para indicar que o <code>auth_query</code> est√° <code>auth_query</code> no banco de dados no momento: <br><img src="https://habrastorage.org/webt/e4/ib/pb/e4ibpbf6ef5q9xcdy2fantydkc4.png"></p><br><p>  Mas essas conex√µes do cliente realmente correspondem √†s conex√µes de back-end / upstream que o PgBouncer abre no pool e mant√©m um n√∫mero limitado.  E eles fornecem essa conex√£o ao cliente apenas durante o tempo - pela dura√ß√£o da sess√£o, transa√ß√£o ou solicita√ß√£o, dependendo do tipo de pool (determinado pela configura√ß√£o <code>pool_mode</code> ).  Na maioria das vezes, o pool de transa√ß√µes √© usado (discutiremos isso mais tarde) - quando a conex√£o √© emitida para o cliente por uma transa√ß√£o e o resto do tempo o cliente n√£o est√° conectado ao servidor.  Assim, o estado "ativo" do cliente nos diz pouco e vamos dividi-lo em substratos: <br><img src="https://habrastorage.org/webt/uv/q4/tj/uvq4tjzbbauunpwzhboxc8s3pgu.png"></p><br><p>  Cada um desses clientes cai em seu pr√≥prio conjunto de conex√µes, que ser√° emitido para uso pela conex√£o real com o Postgres.  Esta √© a principal tarefa do PgBouncer - limitar o n√∫mero de conex√µes com o Postgres. </p><br><p>  Devido √†s conex√µes limitadas do servidor, pode surgir uma situa√ß√£o em que o cliente precisa atender diretamente √† solicita√ß√£o, mas n√£o h√° conex√£o gratuita agora.  Em seguida, o cliente √© colocado na fila e sua conex√£o entra no estado <code>CL_WAITING</code> .  Assim, o diagrama de estados deve ser complementado: <br><img src="https://habrastorage.org/webt/2v/ny/yu/2vnyyuhlqher6cc5q5izwjtu7te.png"><br>  Como isso pode acontecer no caso em que o cliente efetua login apenas e ele precisa executar uma solicita√ß√£o de autoriza√ß√£o, o estado <code>CL_WAITING_LOGIN</code> tamb√©m <code>CL_WAITING_LOGIN</code> . </p><br><p>  Se voc√™ agora olha do lado oposto - do lado das conex√µes do servidor, eles est√£o em tais estados: quando a autoriza√ß√£o ocorre imediatamente ap√≥s a conex√£o - <code>SV_LOGIN</code> , emitida e (possivelmente) usada pelo cliente - <code>SV_ACTIVE</code> ou livremente - <code>SV_IDLE</code> . </p><br><h2 id="use-dlya-pgbouncer">  USE para PgBouncer </h2><br><p>  Assim, chegamos √† utiliza√ß√£o (vers√£o ing√™nua) de um pool espec√≠fico: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Pool</span></span> utiliz =    /  </code> </pre> <br><p>  O PgBouncer possui um banco de dados especial do utilit√°rio pgbouncer, no qual existe um <code>SHOW POOLS</code> que exibe o status atual das conex√µes de cada pool: <br><img src="https://habrastorage.org/webt/xz/_o/eb/xz_oebvf-0yahuvdfzrxx3iass0.png"><br>  Existem 4 conex√µes de clientes abertas e todas elas s√£o <code>cl_active</code> .  Das 5 conex√µes do servidor - 4 <code>sv_active</code> e uma no novo estado <code>sv_used</code> . </p><br><div class="spoiler">  <b class="spoiler_title">O que √© sv_used realmente sobre as diferentes configura√ß√µes do pgbouncer n√£o relacionadas ao monitoramento</b> <div class="spoiler_text"><p>  Portanto, <code>sv_used</code> n√£o significa ‚Äúa conex√£o est√° sendo usada‚Äù, como voc√™ pode pensar, mas ‚Äúa conex√£o foi usada uma vez e n√£o foi usada por um longo tempo‚Äù.  O fato √© que o PgBouncer usa as conex√µes do servidor no modo LIFO por padr√£o - ou seja,  Primeiro, s√£o usadas as conex√µes rec√©m-lan√ßadas, depois as usadas recentemente, etc.  gradualmente se movendo para compostos usados ‚Äã‚Äãh√° muito tempo.  Conseq√ºentemente, as conex√µes do servidor na parte inferior de uma pilha dessas podem ‚Äúficar ruins‚Äù.  E eles devem ser verificados quanto √† disponibilidade antes do uso, o que √© feito usando <code>server_check_query</code> , enquanto est√£o sendo verificados, o estado ser√° <code>sv_tested</code> . </p><br><p>  A documenta√ß√£o diz que o LIFO est√° ativado por padr√£o, como  ent√£o "um pequeno n√∫mero de conex√µes obt√©m a maior carga de trabalho. E isso oferece o melhor desempenho quando h√° um servidor que serve o banco de dados por tr√°s do pgbouncer", ou seja,  como se fosse o caso mais t√≠pico.  Acredito que o aumento potencial de desempenho se deve √†s economias na troca de desempenho entre v√°rios processos de back-end.  Mas n√£o deu certo, porque  Esse detalhe de implementa√ß√£o existe h√°&gt; 12 anos e vai al√©m do hist√≥rico de confirma√ß√£o no github e da profundidade do meu interesse =) </p><br><p>  Portanto, parecia estranho e <code>server_check_delay</code> com as realidades atuais que o valor padr√£o da configura√ß√£o <code>server_check_delay</code> , que determina que o servidor n√£o foi usado por muito tempo e deve ser verificado antes de ser entregue ao cliente, √© de 30 segundos.  Isso apesar do fato de, por padr√£o, tcp_keepalive ser ativado simultaneamente com as configura√ß√µes padr√£o - comece a verificar a conex√£o keep alive com amostras 2 horas ap√≥s sua inatividade. <br>  Acontece que, em uma situa√ß√£o de intermit√™ncia / surto de conex√µes de clientes que desejam fazer algo no servidor, um atraso adicional √© introduzido no <code>server_check_query</code> , que, embora " <code>SELECT 1;</code> ainda pode levar ~ 100 microssegundos, e se <code>server_check_query = ';'</code>  ent√£o voc√™ pode salvar ~ 30 microssegundos =) </p><br><p>  Mas a suposi√ß√£o de que trabalhar em apenas algumas conex√µes = em v√°rios processos "principais" de back-end do postgres ser√° mais eficiente, parece-me duvidoso.  O processo do operador do postgres armazena em cache (meta) informa√ß√µes sobre cada tabela que foi acessada nesta conex√£o.  Se voc√™ tiver um grande n√∫mero de tabelas, esse relcache poder√° crescer muito e consumir muita mem√≥ria, at√© a troca das p√°ginas do processo 0_o.  Para contornar isso, use a configura√ß√£o <code>server_lifetime</code> (o padr√£o √© 1 hora), pela qual a conex√£o do servidor ser√° fechada para rota√ß√£o.  Mas, por outro lado, h√° uma configura√ß√£o <code>server_round_robin</code> que alternar√° o modo de usar conex√µes de LIFO para FIFO, espalhando solicita√ß√µes de clientes em conex√µes de servidor de maneira mais uniforme. </p></div></div><br><p>  <code>SHOW POOLS</code> tomar <code>SHOW POOLS</code> m√©tricas de <code>SHOW POOLS</code> (por algum exportador de prometheus), podemos tra√ßar estes estados: </p><br><p><img src="https://habrastorage.org/webt/i8/8f/-x/i88f-xpwo_2hj7z6iq6qbnatsju.png"></p><br><p>  Mas para chegar ao descarte, voc√™ precisa responder a algumas perguntas: </p><br><ul><li>  Qual √© o tamanho da piscina? </li><li>  Como contar quantos compostos s√£o usados?  Em piadas ou no tempo, em m√©dia ou no pico? </li></ul><br><h3 id="razmer-pula">  Tamanho da piscina </h3><br><p>  Tudo √© complicado aqui, como na vida.  No total, j√° existem cinco limites de configura√ß√µes no pbbouncer! </p><br><ul><li>  <code>pool_size</code> pode ser definido para cada banco de dados.  Um pool separado √© criado para cada par DB / usu√°rio, ou seja,  de qualquer usu√°rio <em>adicional</em> , voc√™ pode criar outros trabalhadores de <code>pool_size</code> backends / Postgres.  Porque  se <code>pool_size</code> n√£o <code>pool_size</code> definido, ele cai em <code>default_pool_size</code> , cujo padr√£o √© 20, ent√£o cada usu√°rio que tem o direito de se conectar ao banco de dados (e trabalha atrav√©s do pgbouncer) pode criar potencialmente 20 processos do Postgres, o que parece n√£o ser muito.  Mas se voc√™ tiver muitos usu√°rios diferentes dos bancos de dados ou dos pr√≥prios bancos de dados, e os conjuntos n√£o forem registrados com um usu√°rio fixo, ou seja,  ser√° criado em tempo real (e exclu√≠do por <code>autodb_idle_timeout</code> ), isso pode ser perigoso =) <br><blockquote>  Pode valer a pena deixar <code>default_pool_size</code> pequeno, apenas para todos os bombeiros. <br></blockquote></li><li>  <code>max_db_connections</code> - apenas necess√°rio para limitar o n√∫mero total de conex√µes com um banco de dados, porque  caso contr√°rio, os clientes que se comportam mal podem criar muitos processos de back-end / postgres.  E por padr√£o aqui - ilimitado ¬Ø_ („ÉÑ) _ / ¬Ø <br><blockquote>  Talvez voc√™ deva alterar as <code>max_db_connections</code> padr√£o, por exemplo, voc√™ pode se concentrar nas <code>max_connections</code> seu Postgres (por padr√£o 100).  Mas se voc√™ tem muitos PgBouncers ... <br></blockquote></li><li>  <code>reserve_pool_size</code> - na verdade, se <code>pool_size</code> usado, o PgBouncer poder√° abrir v√°rias outras conex√µes com a base.  Pelo que entendi, isso √© feito para lidar com um aumento na carga.  Voltaremos a isso. </li><li>  <code>max_user_connections</code> - pelo contr√°rio, √© o limite de conex√µes de um usu√°rio para todos os bancos de dados, ou seja,  relevante se voc√™ tiver v√°rios bancos de dados e eles estiverem sob os mesmos usu√°rios. </li><li>  <code>max_client_conn</code> - quantas conex√µes de cliente o PgBouncer aceitar√° no total.  O padr√£o, como sempre, tem um significado muito estranho - 100. Ou seja,  presume-se que, se mais de 100 clientes travarem repentinamente, eles precisar√£o <code>reset</code> silenciosamente no n√≠vel TCP e <code>reset</code> (bem, nos logs, devo admitir, isso ser√° "sem mais conex√µes permitidas (max_client_conn)"). <br><blockquote>  Pode valer a pena fazer <code>max_client_conn &gt;&gt; SUM ( pool_size' )</code> , por exemplo, 10 vezes mais. <br></blockquote></li></ul><br><p>  Al√©m de <code>SHOW POOLS</code> servi√ßo pseudo-base pgbouncer tamb√©m fornece o <code>SHOW DATABASES</code> , que mostra os limites realmente aplicados a um pool espec√≠fico: <br><img src="https://habrastorage.org/webt/1v/lv/4h/1vlv4hviyhxz1pbh9puc6xxim9o.jpeg"></p><br><h3 id="servernye-soedineniya">  Conex√µes do servidor </h3><br><p>  Mais uma vez - como medir quantos compostos s√£o usados? <br>  Em piadas, em m√©dia / no pico / no tempo? </p><br><p>  Na pr√°tica, √© bastante problem√°tico monitorar o uso de piscinas pelo seguran√ßa com ferramentas difundidas, como  O pr√≥prio pgbouncer fornece apenas uma imagem moment√¢nea e, como muitas vezes n√£o fazem uma pesquisa, ainda existe a possibilidade de uma imagem errada devido √† amostragem.  Aqui est√° um exemplo real de quando, dependendo de quando o exportador trabalhou - no come√ßo do minuto ou no final - a imagem dos compostos abertos e usados ‚Äã‚Äãmuda fundamentalmente: </p><br><p><img src="https://habrastorage.org/webt/i3/ch/qb/i3chqbtvyp3p6nm0bayw62pf3hq.png"></p><br><p>  Aqui todas as mudan√ßas no carregamento / uso das conex√µes s√£o apenas uma fic√ß√£o, um artefato das reinicializa√ß√µes do coletor de estat√≠sticas.  Aqui voc√™ pode ver os gr√°ficos de conex√£o no Postgres durante esse per√≠odo e os descritores de arquivos do seguran√ßa e do PG - sem altera√ß√µes: </p><br><p><img src="https://habrastorage.org/webt/n7/bh/4r/n7bh4r_2h21ypaxhtr7njv2u8xa.png"></p><br><p>  Voltar para a quest√£o do descarte.  Decidimos usar uma abordagem combinada em nosso servi√ßo - mostramos <code>SHOW POOLS</code> uma vez por segundo e, a cada minuto, renderizamos o n√∫mero m√©dio e m√°ximo de conex√µes em cada classe: </p><br><p><img src="https://habrastorage.org/webt/ea/v5/ei/eav5eimcl7fofctvc24oaymzsu4.png"></p><br><p>  E se dividirmos o n√∫mero dessas conex√µes de estado ativo pelo tamanho do pool, obteremos a m√©dia e o pico de utiliza√ß√£o desse pool e podemos alertar se ele est√° pr√≥ximo de 100%. </p><br><p>  Al√©m disso, o PgBouncer possui um comando <code>SHOW STATS</code> que mostrar√° estat√≠sticas de uso para cada banco de dados em proxy: <br><img src="https://habrastorage.org/webt/mo/wz/_q/mowz_qavy_zspkljbvnehbj1bpc.png"><br>  Estamos mais interessados ‚Äã‚Äãna coluna <code>total_query_time</code> - o tempo gasto por todas as conex√µes no processo de execu√ß√£o de consultas no postgres.  E a partir da vers√£o 1.8, h√° tamb√©m a m√©trica <code>total_xact_time</code> - o tempo gasto nas transa√ß√µes.  Com base nessas m√©tricas, podemos construir a utiliza√ß√£o do tempo de conex√£o do servidor; esse indicador n√£o est√° sujeito, ao contr√°rio do calculado a partir dos estados da conex√£o, a problemas de amostragem, porque  estes contadores de <code>total_..._time</code> s√£o cumulativos e n√£o passam nada: </p><br><p><img src="https://habrastorage.org/webt/p3/1l/iv/p31liv1gccpj3rxnxav-nbelck0.png"><br>  Compare <br><img src="https://habrastorage.org/webt/yk/rt/gd/ykrtgdu5s8_pcltl3w3mmcuj4oo.png"><br>  Pode-se observar que a amostragem n√£o mostra todos os momentos de alta utiliza√ß√£o de ~ 100%, e o query_time mostra. </p><br><h3 id="saturation-i-pgbouncer">  Satura√ß√£o e PgBouncer </h3><br><p>  Por que voc√™ precisa monitorar a satura√ß√£o, devido √† alta utiliza√ß√£o, j√° est√° claro que tudo est√° ruim? </p><br><p>  O problema √© que, independentemente de como voc√™ mede a utiliza√ß√£o, mesmo os contadores acumulados n√£o podem mostrar a utiliza√ß√£o local de 100% dos recursos, se ocorrer apenas em intervalos muito curtos.  Por exemplo, voc√™ tem coroas ou outros processos s√≠ncronos que podem come√ßar simultaneamente a fazer consultas ao banco de dados no comando.  Se essas solicita√ß√µes forem curtas, a utiliza√ß√£o, medida na escala de minutos e at√© segundos, poder√° ser baixa, mas, ao mesmo tempo, em algum momento, essas solicita√ß√µes foram for√ßadas a aguardar na fila pela execu√ß√£o.  Isso √© semelhante a uma situa√ß√£o de n√£o uso da CPU de 100% e alta carga m√©dia - como o tempo do processador ainda est√° l√°, mas, no entanto, muitos processos est√£o aguardando na fila pela execu√ß√£o. </p><br><p>  Como essa situa√ß√£o pode ser monitorada - bem, novamente, podemos simplesmente contar o n√∫mero de clientes no estado <code>cl_waiting</code> acordo com <code>SHOW POOLS</code> .  Em uma situa√ß√£o normal, h√° zero e mais de zero significa excesso desse pool: </p><br><p><img src="https://habrastorage.org/webt/q1/tg/tj/q1tgtjcqgrqpavfpkf0kyg31hjq.png"></p><br><p>  Resta o problema de que o <code>SHOW POOLS</code> s√≥ pode ser amostrado e, em uma situa√ß√£o com coroas s√≠ncronas ou algo parecido, podemos simplesmente pular e n√£o ver esses clientes em espera. </p><br><p>  Voc√™ pode usar esse truque, o pr√≥prio pgbouncer pode detectar 100% de uso do pool e abrir o pool de backup.  Duas configura√ß√µes s√£o respons√°veis ‚Äã‚Äãpor isso: <code>reserve_pool_size</code> - por seu tamanho, como eu disse, e <code>reserve_pool_timeout</code> - quantos segundos um cliente deve <code>waiting</code> antes de usar o pool de backup.  Portanto, se vemos no gr√°fico de conex√µes do servidor que o n√∫mero de conex√µes abertas ao Postgres √© maior que pool_size, houve uma satura√ß√£o do pool, assim: <br><img src="https://habrastorage.org/webt/ne/ec/hn/neechnkp9sffd8g3rjov_3jjijm.png"><br>  Obviamente, algo como coroas uma vez por hora faz muitos pedidos e ocupa completamente a piscina.  E mesmo que n√£o vejamos o momento em que <code>active</code> conex√µes <code>active</code> excedam o limite <code>pool_size</code> , o pgbouncer ainda foi for√ßado a abrir conex√µes adicionais. </p><br><p>  Tamb√©m neste gr√°fico, as configura√ß√µes <code>server_idle_timeout</code> funcionam √© claramente vis√≠vel - depois de quanto parar de manter e fechar as conex√µes que n√£o s√£o usadas.  Por padr√£o, s√£o 10 minutos, o que vemos no gr√°fico - ap√≥s os picos <code>active</code> exatamente √†s 5:00, √†s 6:00, etc.  (de acordo com cron <code>0 * * * *</code> ), as conex√µes ficam <code>idle</code> + <code>used</code> mais 10 minutos e fecham. </p><br><p>  Se voc√™ mora na vanguarda do progresso e atualizou o PgBouncer nos √∫ltimos 9 meses, pode encontrar na coluna <code>SHOW STATS</code> <code>total_wait_time</code> , que melhor mostra a satura√ß√£o, porque  cumulativamente considera o tempo gasto pelos clientes em um estado de <code>waiting</code> .  Por exemplo, o <code>waiting</code> aqui - em <code>waiting</code> apareceu √†s 16:30: <br><img src="https://habrastorage.org/webt/ck/-q/qt/ck-qqth3dhvsqsw1zzeuvkjg4wa.png"><br>  E <code>wait_time</code> , que √© compar√°vel e afeta claramente o <code>average query time</code> , pode ser visto das 15:15 √†s quase 19: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  No entanto, o monitoramento do status das conex√µes do cliente ainda √© muito √∫til, porque  ele permite descobrir n√£o apenas o fato de que todas as conex√µes com esse banco de dados foram gastas e os clientes precisam esperar, mas tamb√©m porque o <code>SHOW POOLS</code> dividido em pools separados pelos usu√°rios, e o <code>SHOW STATS</code> n√£o, permite descobrir quais clientes usaram todas as conex√µes para a base especificada - de acordo com a coluna <code>sv_active</code> do pool correspondente.  Ou por m√©trica </p><br><pre> <code class="hljs pgsql">sum_by(<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">database</span></span>, metric(<span class="hljs-type"><span class="hljs-type">name</span></span>="pgbouncer.clients.count", state="active-link")):</code> </pre> <br><p><img src="https://habrastorage.org/webt/k_/0s/lf/k_0slfupzfrdz4npoiz8kbxgpko.png"></p><br><p>  No okmeter, fomos ainda mais longe e adicionamos um detalhamento das conex√µes usadas pelos endere√ßos IP dos clientes que os abriram e usaram.  Isso permite que voc√™ entenda exatamente quais inst√¢ncias de aplicativos se comportam de maneira diferente: <br><img src="https://habrastorage.org/webt/dk/fr/5j/dkfr5j_yvxgmm2f0b5dvru4b9nk.png"><br>  Aqui vemos IPs de kubernetes espec√≠ficos de lares com os quais precisamos lidar. </p><br><h3 id="errors">  Erros </h3><br><p>  N√£o h√° nada de particularmente complicado aqui: o pgbouncer grava logs nos quais relata erros se o limite de conex√µes do cliente for atingido, o tempo limite para se conectar ao servidor, etc.  Ainda n√£o alcan√ßamos os registros do pgbouncer :( </p><br><h2 id="red-dlya-pgbouncer">  RED para PgBouncer </h2><br><p>  Enquanto o USE est√° mais focado no desempenho, no sentido de gargalos, o RED, na minha opini√£o, √© mais sobre as caracter√≠sticas do tr√°fego de entrada e sa√≠da em geral, e n√£o sobre gargalos.  Ou seja, o RED responde √† pergunta - tudo funciona bem e, se n√£o, o USE ajudar√° a entender qual √© o problema. </p><br><h2 id="requests">  Exig√™ncias </h2><br><p>  Parece que tudo √© bastante simples para o banco de dados SQL e para o extrator de proxy / conex√£o nesse banco de dados - os clientes executam instru√ß√µes SQL, que s√£o Solicita√ß√µes.  Em <code>SHOW STATS</code> pegamos <code>total_requests</code> e <code>total_requests</code> sua derivada de tempo </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"pgbouncer.total_requests"</span></span>, database: <span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fa/7u/o2/fa7uo2r8b6_4y6z9e2bounudzmw.png"></p><br><p>  Mas, de fato, existem diferentes modos de puxar, e o mais comum s√£o as transa√ß√µes.  A unidade de trabalho para este modo √© uma transa√ß√£o, n√£o uma consulta.  Assim, a partir da vers√£o 1.8, o Pgbouner j√° fornece duas outras estat√≠sticas - <code>total_query_count</code> , em vez de <code>total_requests</code> e <code>total_xact_count</code> - o n√∫mero de transa√ß√µes conclu√≠das. </p><br><p>  Agora, a carga de trabalho pode ser caracterizada n√£o apenas em termos do n√∫mero de solicita√ß√µes / transa√ß√µes conclu√≠das, mas, por exemplo, voc√™ pode observar o n√∫mero m√©dio de solicita√ß√µes por transa√ß√£o em diferentes bancos de dados, dividindo-se em outro </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_requests"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>)) / rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_xact"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/xd/uh/3w/xduh3wsb-bww1tysfwtdhcw-seg.png"></p><br><p>  Aqui vemos mudan√ßas √≥bvias no perfil de carga, que podem ser o motivo da altera√ß√£o no desempenho.  E se voc√™ analisou apenas a taxa de transa√ß√µes ou solicita√ß√µes, talvez n√£o veja isso. </p><br><h2 id="red-errors">  Erros RED </h2><br><p>  √â claro que RED e USE se cruzam no monitoramento de erros, mas parece-me que os erros no USE s√£o principalmente sobre erros de processamento de solicita√ß√£o devido √† utiliza√ß√£o de 100%, ou seja,  quando o servi√ßo se recusar a aceitar mais trabalho.  E os erros do RED seriam melhores para medir erros precisamente do ponto de vista do cliente, solicita√ß√µes do cliente.  Ou seja, n√£o apenas em uma situa√ß√£o em que o pool no PgBouncer est√° cheio ou outro limite funcionou, mas tamb√©m quando solicita√ß√µes de tempo limite, como "cancelamento de declara√ß√£o devido ao tempo limite da declara√ß√£o", cancelamentos e revers√µes de transa√ß√µes pelo cliente funcionaram, etc. e  n√≠vel superior, mais pr√≥ximo dos tipos de erros da l√≥gica de neg√≥cios. </p><br><h2 id="durations">  Dura√ß√µes </h2><br><p>  Aqui, novamente, <code>SHOW STATS</code> com contadores cumulativos <code>total_xact_time</code> , <code>total_query_time</code> e <code>total_wait_time</code> nos ajudar√£o, dividindo-os pelo n√∫mero de solicita√ß√µes e transa√ß√µes, respectivamente, obtemos o tempo m√©dio de solicita√ß√£o, tempo m√©dio de transa√ß√£o e tempo m√©dio de espera por transa√ß√£o.  Eu j√° mostrei um gr√°fico sobre o primeiro e o terceiro: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  O que mais voc√™ pode esfriar?  O antipadr√£o conhecido no trabalho com o banco de dados e o Postgres, em particular, quando o aplicativo abre uma transa√ß√£o, faz uma solicita√ß√£o e depois come√ßa (por um longo tempo) a processar seus resultados, ou pior ainda - vai para outro servi√ßo / banco de dados e faz solicita√ß√µes l√°.  Todo esse tempo, a transa√ß√£o "trava" no postgres aberto, o servi√ßo retorna e faz mais algumas solicita√ß√µes, atualiza√ß√µes no banco de dados e somente depois fecha a transa√ß√£o.  Para o postgres, isso √© especialmente desagrad√°vel, porque  pg trabalhadores s√£o caros.  Portanto, podemos monitorar quando esse aplicativo est√° <code>idle in transaction</code> no pr√≥prio postgres - de acordo com a coluna <code>state</code> em <code>pg_stat_activity</code> , mas ainda existem os mesmos problemas descritos com a amostragem, porque  <code>pg_stat_activity</code> fornece apenas a imagem atual.  No PgBouncer, podemos subtrair o tempo gasto pelos clientes nas solicita√ß√µes <code>total_query_time</code> do tempo gasto nas transa√ß√µes <code>total_xact_time</code> - este ser√° o tempo dessa inatividade.  Se o resultado ainda estiver dividido por <code>total_xact_time</code> , ele ser√° normalizado: um valor 1 corresponde a uma situa√ß√£o em que os clientes est√£o <code>idle in transaction</code> 100% do tempo.  E com essa normaliza√ß√£o, fica f√°cil entender como tudo √© ruim: </p><br><p><img src="https://habrastorage.org/webt/t9/kn/io/t9knioh2ckzd_photgqvcq543x4.png"></p><br><p>  Al√©m disso, retornando √† Dura√ß√£o, a m√©trica <code>total_xact_time - total_query_time</code> pode ser dividida pelo n√∫mero de transa√ß√µes para ver quanto √© o aplicativo inativo m√©dio por transa√ß√£o. </p><br><hr><br><p>  Na minha opini√£o, os m√©todos USE / RED s√£o mais √∫teis para estruturar quais m√©tricas voc√™ dispara e por qu√™.  Como estamos envolvidos no monitoramento em tempo integral e precisamos monitorar v√°rios componentes da infraestrutura, esses m√©todos nos ajudam a obter as m√©tricas corretas, fazer os cronogramas e acionadores certos para nossos clientes. </p><br><p>  <em>Um bom monitoramento n√£o pode ser feito imediatamente, √© um processo iterativo.</em>  <em>No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">okmeter.io</a> , temos apenas o monitoramento cont√≠nuo (h√° muitas coisas, mas amanh√£ ser√° melhor e mais detalhado :)</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420429/">https://habr.com/ru/post/pt420429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420413/index.html">SQLite e NW.js - instru√ß√µes passo a passo para criar amizades fortes</a></li>
<li><a href="../pt420415/index.html">Tudo o que voc√™ queria saber sobre o teste de adaptadores Wi-Fi, mas tinha medo de perguntar</a></li>
<li><a href="../pt420419/index.html">Corredores para quem gosta de humilha√ß√£o ou como mudamos e modificamos o PixJam</a></li>
<li><a href="../pt420423/index.html">Problemas na interface de travessia de terra</a></li>
<li><a href="../pt420425/index.html">Teoria e pr√°tica do uso do HBase</a></li>
<li><a href="../pt420431/index.html">Marte Guia pr√°tico de terraforma√ß√£o para donas de casa</a></li>
<li><a href="../pt420433/index.html">‚ÄúFormato sexta-feira‚Äù: estradas musicais - o que √© e por que n√£o est√° na R√∫ssia</a></li>
<li><a href="../pt420435/index.html">In√≠cio r√°pido com o ARM Mbed: desenvolvimento de microcontroladores modernos para iniciantes</a></li>
<li><a href="../pt420437/index.html">Uma introdu√ß√£o pr√°tica ao gerenciador de pacotes do Kubernetes - Helm</a></li>
<li><a href="../pt420439/index.html">Resumo da Fintech: os investimentos na fintech chegaram a US $ 57 bilh√µes, a velocidade das transa√ß√µes est√° crescendo e o custo est√° caindo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
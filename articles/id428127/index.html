<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ»â€ğŸ¤â€ğŸ‘¨ğŸ½ ğŸ‘©ğŸ¿â€ğŸ¤â€ğŸ‘¨ğŸ» ğŸ§‘ Cache nginx: semuanya baru - lama terlupakan ğŸ¤ŸğŸ¼ â—¾ï¸ ğŸ“Œ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam kehidupan setiap proyek, saatnya tiba ketika server berhenti untuk memenuhi persyaratan SLA dan secara harfiah mulai tersedak jumlah lalu lintas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cache nginx: semuanya baru - lama terlupakan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428127/">  Dalam kehidupan setiap proyek, saatnya tiba ketika server berhenti untuk memenuhi persyaratan SLA dan secara harfiah mulai tersedak jumlah lalu lintas yang masuk.  Setelah itu, proses panjang untuk menemukan kemacetan, pertanyaan berat, indeks yang salah dibuat, data yang tidak di-cache, atau sebaliknya, terlalu sering memperbarui data dalam cache dan sisi gelap lain dari proyek, dimulai. <br><br>  Tapi apa yang harus dilakukan ketika kode Anda "sempurna", semua permintaan berat ditempatkan di latar belakang, semua yang mungkin di-cache, dan server masih belum mencapai indikator SLA yang kita butuhkan?  Jika memungkinkan, maka tentu saja Anda dapat membeli mobil baru, mendistribusikan beberapa lalu lintas dan melupakan masalah untuk sementara waktu. <br><br>  Tetapi jika Anda merasa bahwa server Anda mampu melakukan lebih, atau ada parameter ajaib yang mempercepat situs sebanyak 100 kali, maka Anda dapat mengingat fitur nginx bawaan yang memungkinkan Anda untuk menembolok respons dari backend.  Mari kita lihat apa itu dan bagaimana hal itu dapat membantu meningkatkan jumlah permintaan yang diproses oleh server. <a name="habracut"></a><br><br>
<h3>  Apa itu cache Nginx dan bagaimana cara kerjanya? </h3><br>  Cache nginx dapat secara signifikan mengurangi jumlah permintaan untuk backend.  Ini dicapai dengan menyimpan respons HTTP untuk waktu tertentu, dan ketika mengakses sumber daya lagi, mengembalikannya dari cache tanpa mem-proxy-kan permintaan backend.  Caching, bahkan untuk waktu yang singkat, akan memberikan peningkatan signifikan pada jumlah permintaan yang diproses oleh server. <br><br>  Sebelum melanjutkan dengan konfigurasi nginx, Anda perlu memastikan bahwa itu dibangun dengan modul â€œngx_http_proxy_moduleâ€, karena kami akan mengonfigurasinya menggunakan modul ini. <br><br>  Untuk kenyamanan, Anda dapat meletakkan konfigurasi dalam file yang terpisah, misalnya, â€œ/etc/nginx/conf.d/cache.confâ€.  Mari kita lihat direktif proxy_cache_path, yang memungkinkan Anda untuk mengonfigurasi pengaturan penyimpanan cache. <br><br><pre><code class="hljs swift">proxy_cache_path /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/nginx/proxy_cache levels=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">2</span></span> keys_zone=proxy_cache:15m max_size=1G;</code> </pre> <br>  "/ Var / lib / nginx / proxy_cache" menentukan jalur penyimpanan cache di server.  Di direktori ini nginx akan menyimpan file-file yang sangat dengan respon dari backend.  Pada saat yang sama, nginx tidak akan secara mandiri membuat direktori untuk cache, Anda harus mengurusnya sendiri. <br><br>  "Levels = 1: 2" - mengatur tingkat sarang direktori dengan cache.  Level Nesting ditunjukkan melalui â€œ:â€, dalam hal ini 2 direktori akan dibuat, total 3 level sarang diperbolehkan.  Untuk setiap tingkat bersarang, nilai dari 1 hingga 2 tersedia, yang menunjukkan cara membuat nama direktori. <br><br>  Poin penting adalah bahwa nama direktori tidak dipilih secara acak, tetapi dibuat berdasarkan nama file.  Nama file, pada gilirannya, adalah hasil dari fungsi md5 dari kunci cache, kita akan melihat kunci cache sedikit kemudian. <br><br>  Mari kita lihat dalam praktik bagaimana path ke file cache dibangun: <br><br><pre> <code class="hljs swift">/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/nginx/proxy_cache/<span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">49</span></span>/07edcfe6974569ab4da6634ad4e5d492</code> </pre> <br>  Parameter â€œKeys_zone = proxy_cache: 15mâ€ menetapkan nama zona dalam memori bersama, tempat semua kunci aktif dan informasi tentangnya disimpan.  Melalui â€œ:â€ menunjukkan ukuran memori yang dialokasikan dalam MB.  Menurut nginx, 1 MB sudah cukup untuk menyimpan 8 ribu kunci. <br><br>  "Max_size = 1G" menentukan ukuran cache maksimum untuk semua halaman di atas yang nginx akan menghapus data yang kurang dibutuhkan. <br><br>  Dimungkinkan juga untuk mengontrol masa pakai data dalam cache, karena ini cukup untuk menentukan parameter "tidak aktif" dari direktif "proxy_cache_path", yang secara default adalah 10 menit.  Jika selama waktu yang ditentukan dalam parameter "tidak aktif" tidak ada panggilan ke data cache, maka data ini dihapus bahkan jika cache belum "masam". <br><br>  Seperti apa cache ini?  Ini sebenarnya adalah file biasa di server, yang isinya ditulis: <br><br>  â€¢ kunci cache; <br>  â€¢ header cache; <br>  â€¢ respons konten dari backend. <br><br>  Jika semuanya jelas dengan header dan respons dari backend, maka ada sejumlah pertanyaan pada "kunci cache".  Bagaimana itu dibangun dan bagaimana bisa dikelola? <br><br>  Untuk menjelaskan templat untuk membuat kunci cache di nginx, ada direktif proxy_cache_key, di mana string ditentukan sebagai parameter.  Sebuah string dapat terdiri dari variabel apa saja yang tersedia di nginx. <br><br>  Sebagai contoh: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_key</span></span> <span class="hljs-variable"><span class="hljs-variable">$request_method</span></span><span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$orig_uri</span></span>:<span class="hljs-variable"><span class="hljs-variable">$cookie_some_cookie</span></span>:<span class="hljs-variable"><span class="hljs-variable">$arg_some_arg</span></span>;</code> </pre> <br>  Simbol ":" antara parameter cookie dan parameter get digunakan untuk mencegah tabrakan antara kunci cache, Anda dapat memilih simbol lain dari pilihan Anda.  Secara default, nginx menggunakan baris berikut untuk menghasilkan kunci: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_key</span></span> <span class="hljs-variable"><span class="hljs-variable">$scheme</span></span><span class="hljs-variable"><span class="hljs-variable">$proxy_host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>;</code> </pre> <br>  Arahan berikut harus diperhatikan yang akan membantu Anda mengelola caching Anda secara lebih fleksibel: <br><br>  <i>proxy_cache_valid</i> - Menentukan waktu caching respons.  Dimungkinkan untuk menunjukkan status spesifik dari respons, misalnya 200, 302, 404, dll., Atau untuk menentukan semuanya sekaligus menggunakan konstruk â€œapa sajaâ€.  Jika hanya waktu caching yang ditentukan, nginx akan default untuk cache hanya 200, 301 dan 302 status. <br><br>  Contoh: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_valid</span></span> <span class="hljs-number"><span class="hljs-number">15m</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_valid</span></span> <span class="hljs-number"><span class="hljs-number">404</span></span> <span class="hljs-number"><span class="hljs-number">15s</span></span>;</code> </pre><br>  Dalam contoh ini, kami menetapkan masa pakai cache menjadi 15 menit untuk status 200, 301, 302 (nginx menggunakannya secara default, karena kami tidak menentukan status tertentu).  Baris berikutnya mengatur waktu caching ke 15 detik, hanya untuk tanggapan dengan status 404. <br><br>  <i>proxy_cache_lock</i> - Arahan ini akan membantu untuk menghindari beberapa lintasan ke backend segera setelah set cache, cukup atur nilai pada posisi "on".  Semua permintaan lain akan menunggu respons dalam cache, atau batas waktu untuk memblokir permintaan ke halaman.  Dengan demikian, semua batas waktu dapat dikonfigurasi. <br><br>  <i>proxy_cache_lock_age</i> - Memungkinkan Anda untuk menetapkan batas waktu untuk tanggapan dari server, setelah itu permintaan berikutnya akan dikirim kepadanya setelah cache telah ditetapkan.  Standarnya adalah 5 detik. <br><br>  <i>proxy_cache_lock_timeout</i> - Menetapkan waktu untuk menunggu kunci, setelah itu permintaan akan dikirim ke backend, tetapi jawabannya tidak akan di-cache.  Standarnya adalah 5 detik. <br><br>  <i>proxy_cache_use_stale</i> - <i>Arahan</i> lain yang berguna yang memungkinkan Anda untuk mengkonfigurasi ketika dimungkinkan untuk menggunakan cache yang usang. <br><br>  Contoh: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_use_stale</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout updating;</code> </pre> <br>  Dalam hal ini, ia akan menggunakan cache yang ketinggalan jaman jika terjadi kesalahan koneksi, mengirim permintaan, membaca respons dari server, melebihi batas tunggu untuk mengirim permintaan, membaca respons dari server, atau jika data dalam cache diperbarui pada saat permintaan. <br><br>  <i>proxy_cache_bypass</i> - Menentukan kondisi di mana nginx tidak akan mengambil respons dari cache, tetapi segera mengarahkan permintaan ke backend.  Jika setidaknya salah satu parameter tidak kosong dan tidak sama dengan "0".  Contoh: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_bypass</span></span> <span class="hljs-variable"><span class="hljs-variable">$cookie_nocache</span></span> <span class="hljs-variable"><span class="hljs-variable">$arg_nocache</span></span>;</code> </pre> <br>  <i>proxy_no_cache</i> - Menetapkan kondisi di mana nginx tidak akan menyimpan respons dari backend ke cache.  Prinsip operasi adalah sama dengan yang ada pada direktif proxy_cache_bypass. <br><br><h3>  Kemungkinan masalah dengan caching halaman </h3><br>  Seperti disebutkan di atas, bersama dengan caching respons HTTP, nginx menyimpan header yang diterima dari backend.  Jika situs Anda menggunakan sesi, maka cookie sesi juga akan di-cache.  Semua pengguna yang mengunjungi halaman yang beruntung Anda cache akan menerima data pribadi Anda yang disimpan dalam sesi. <br><br>  Tantangan berikutnya yang akan Anda hadapi adalah manajemen caching.  Tentu saja, Anda dapat mengatur waktu cache tidak signifikan 2-5 menit dan ini akan cukup dalam kebanyakan kasus.  Tapi ini tidak berlaku di semua situasi, jadi kami akan menemukan kembali sepeda kami.  Sekarang, hal pertama yang pertama. <br><br>  <b>Manajemen Pelestarian Cookie</b> <br><br>  Caching di sisi nginx membebankan beberapa batasan desain.  Misalnya, kita tidak bisa menggunakan sesi pada halaman dalam cache, karena pengguna tidak mencapai backend, batasan lain adalah pengiriman cookie oleh backend.  Karena nginx cache semua header, untuk menghindari menyimpan sesi orang lain di cache, kita perlu melarang pengiriman cookie untuk halaman yang di-cache.  Arahan proxy_ignore_headers akan membantu kami dalam hal ini.  Argumen daftar header yang harus diabaikan dari backend. <br><br>  Contoh: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_ignore_headers</span></span> <span class="hljs-string"><span class="hljs-string">"Set-Cookie"</span></span>;</code> </pre> <br>  Dengan baris ini, kami mengabaikan pemasangan cookie dari server proksi, yaitu, pengguna akan menerima respons tanpa tajuk "Set-Cookies".  Dengan demikian, segala sesuatu yang dicoba dituliskan oleh backend ke cookie akan diabaikan di sisi klien, karena ia bahkan tidak akan tahu bahwa itu dimaksudkan untuk sesuatu.  Pembatasan cookie ini harus dipertimbangkan ketika mengembangkan aplikasi.  Misalnya, untuk meminta otorisasi, Anda dapat mematikan kunci kontak sehingga pengguna menerima cookie sesi. <br><br>  Anda juga harus mempertimbangkan seumur hidup sesi, itu dapat dilihat dalam parameter â€œ <i>session.gc_maxlifetime</i> â€ dari konfigurasi php.ini.  Bayangkan bahwa pengguna masuk ke situs dan mulai melihat feed berita, semua data sudah ada di cache nginx.  Setelah beberapa waktu, pengguna memperhatikan bahwa otorisasi-nya telah hilang dan ia harus melalui proses otorisasi, meskipun selama ini ia berada di situs, menonton berita.  Ini terjadi karena pada semua permintaannya nginx mengembalikan hasil dari cache tanpa mengirim permintaan ke backend.  Oleh karena itu, backend memutuskan bahwa pengguna tidak aktif dan setelah waktu yang ditentukan dalam " <i>session.gc_maxlifetime</i> " menghapus file sesi. <br><br>  Untuk mencegah hal ini terjadi, kami dapat meniru permintaan backend.  Misalnya, melalui ajax mengirim permintaan yang akan dijamin lolos ke backend.  Untuk meneruskan cache nginx ke backend, cukup kirim permintaan POST, Anda juga dapat menggunakan aturan dari direktif â€œproxy_cache_bypassâ€, atau cukup nonaktifkan cache untuk halaman ini.  Permintaan tidak harus memberikan sesuatu kembali, itu bisa berupa file dengan satu baris memulai sesi.  Tujuan dari permintaan semacam itu adalah untuk memperpanjang masa pakai sesi ketika pengguna berada di situs, dan nginx dengan sadar memberikan data yang di-cache ke semua permintaannya. <br><br>  <b>Manajemen siram cache</b> <br><br>  Pertama, Anda perlu menentukan persyaratan, tujuan apa yang ingin kami capai.  Katakanlah situs kami memiliki bagian dengan siaran teks acara olahraga populer.  Saat memuat halaman diberikan dari cache, maka semua pesan baru datang di soket.  Agar pengguna dapat melihat pesan saat ini pada saat saat ini pada saat boot pertama, daripada 15 menit yang lalu, kita harus dapat menghapus cache nginx secara mandiri kapan saja.  Pada saat yang sama, nginx mungkin tidak berada pada mesin yang sama dengan aplikasi.  Juga, salah satu persyaratan untuk reset adalah kemampuan untuk menghapus cache, di beberapa halaman sekaligus. <br><br>  Sebelum Anda mulai menulis solusi Anda, mari kita lihat apa yang ditawarkan nginx di luar kotak.  Untuk mengatur ulang cache, nginx memiliki arahan khusus yang disebut â€œproxy_cache_purgeâ€, yang mencatat kondisi untuk mengatur ulang cache.  Kondisi sebenarnya adalah garis normal, yang, jika tidak kosong dan bukan "0", akan menghapus cache dengan kunci yang dilewati.  Pertimbangkan sebuah contoh kecil. <br><br><pre> <code class="hljs perl">proxy_cache_path /data/nginx/cache keys_zone=cache_zone:<span class="hljs-number"><span class="hljs-number">10</span></span><span class="hljs-keyword"><span class="hljs-keyword">m</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">map</span></span> $request_method $purge_method { PURGE <span class="hljs-number"><span class="hljs-number">1</span></span>; default <span class="hljs-number"><span class="hljs-number">0</span></span>; } server { ... location / { proxy_pass http:<span class="hljs-regexp"><span class="hljs-regexp">//backend</span></span>; proxy_cache cache_zone; proxy_cache_key $uri; proxy_cache_purge $purge_method; } }</code> </pre><br>  <i>Contoh diambil dari situs web nginx resmi.</i> <br><br>  Variabel $ purge_method bertanggung jawab untuk membilas cache, yang merupakan syarat untuk direktif proxy_cache_purge dan diset ke 0 secara default.  Ini berarti bahwa nginx berfungsi dalam mode "normal" (ini menyimpan respons dari backend).  Tetapi jika Anda mengubah metode permintaan menjadi "PURGE", maka alih-alih mem-proxy permintaan backend dengan menyimpan respons, entri cache akan dihapus menggunakan kunci cache yang sesuai.  Dimungkinkan juga untuk menentukan mask penghapusan dengan menentukan "*" di akhir kunci cache.  Jadi, kita tidak perlu tahu lokasi cache pada disk dan prinsip pembentukan kunci, nginx mengambil tanggung jawab ini.  Namun ada juga kelemahan dari pendekatan ini. <br><br><ul><li>  Arahan proxy_cache_purge tersedia sebagai bagian dari langganan komersial. </li><li>  Hanya dimungkinkan untuk menghapus cache secara langsung, atau dengan menggunakan mask form {cache key} â€œ*â€ </li></ul><br>  Karena alamat halaman yang di-cache bisa sangat berbeda, tanpa bagian umum, pendekatan dengan mask â€œ*â€ dan arahan â€œproxy_cache_purgeâ€ tidak cocok untuk kami.  Masih mengingat sedikit teori dan menemukan ide favorit Anda. <br><br>  Kita tahu bahwa cache nginx adalah file biasa di server.  Kami secara independen menentukan direktori untuk menyimpan file cache dalam direktif â€œproxy_cache_pathâ€, kami bahkan menentukan logika pembentukan path ke file dari direktori ini menggunakan â€œlevelâ€.  Satu-satunya hal yang kami lewatkan adalah pembentukan kunci caching yang benar.  Tapi kita juga bisa melihatnya di direktif â€œproxy_cache_keyâ€.  Sekarang yang harus kita lakukan adalah: <br><br><ul><li>  membentuk path lengkap ke halaman, persis seperti yang ditentukan dalam direktif proxy_cache_key; </li><li>  menyandikan string yang dihasilkan di md5; </li><li>  buat direktori bersarang menggunakan aturan dari parameter "level". </li><li>  Dan sekarang kita sudah memiliki path lengkap ke file cache di server.  Sekarang yang tersisa bagi kita adalah menghapus file ini.  Dari bagian pengantar, kita tahu bahwa nginx mungkin tidak terletak di mesin aplikasi, jadi Anda harus memungkinkan untuk menghapus beberapa alamat sekaligus.  Sekali lagi, kami menggambarkan algoritme: </li><li>  Path yang dihasilkan ke file cache kita akan menulis ke file; </li><li>  Mari kita menulis skrip bash sederhana yang kita pasang di mesin dengan aplikasi.  Tugasnya adalah untuk terhubung melalui ssh ke server di mana kita memiliki caching nginx dan menghapus semua file cache yang ditentukan dalam file yang dihasilkan dari langkah 1; </li></ul><br>  Kami beralih dari teori ke praktek, kami akan menulis contoh kecil yang menggambarkan algoritma kerja kami. <br><br>  Langkah 1. Membuat file dengan jalur ke cache. <br><br><pre> <code class="hljs powershell"><span class="hljs-variable"><span class="hljs-variable">$urls</span></span> = [ <span class="hljs-string"><span class="hljs-string">'httpGETdomain.ru/news/111/1:2'</span></span>, <span class="hljs-string"><span class="hljs-string">'httpGETdomain.ru/news/112/3:4'</span></span>, ]; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_nginx_cache_path</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span></span> { <span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span> = md5(<span class="hljs-variable"><span class="hljs-variable">$url</span></span>); <span class="hljs-variable"><span class="hljs-variable">$firstDir</span></span> = substr(<span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span>, <span class="hljs-literal"><span class="hljs-literal">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-variable"><span class="hljs-variable">$secondDir</span></span> = substr(<span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span>, <span class="hljs-literal"><span class="hljs-literal">-3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"/var/lib/nginx/proxy_cache/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$firstDir</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$secondDir</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$nginxHash</span></span></span><span class="hljs-string">"</span></span>; } //        tmp <span class="hljs-variable"><span class="hljs-variable">$filePath</span></span> = tempnam(<span class="hljs-string"><span class="hljs-string">'tmp'</span></span>, <span class="hljs-string"><span class="hljs-string">'nginx_cache_'</span></span>); //      <span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span> = fopen(<span class="hljs-variable"><span class="hljs-variable">$filePath</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-variable"><span class="hljs-variable">$urls</span></span> as <span class="hljs-variable"><span class="hljs-variable">$url</span></span>) { //      <span class="hljs-variable"><span class="hljs-variable">$cachePath</span></span> = to_nginx_cache_path(<span class="hljs-variable"><span class="hljs-variable">$url</span></span>); //       fwrite(<span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span>, <span class="hljs-variable"><span class="hljs-variable">$cachePath</span></span> . PHP_EOL); } //     fclose(<span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span>); //  bash       exec(<span class="hljs-string"><span class="hljs-string">"/usr/local/bin/cache_remover </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$filePath</span></span></span><span class="hljs-string">"</span></span>);</code> </pre><br>  Harap dicatat bahwa variabel $ url berisi url dari halaman yang di-cache, sudah dalam format proxy_cache_key yang ditentukan dalam konfigurasi nginx.  Url bertindak sebagai tag untuk entitas yang ditampilkan di halaman.  Misalnya, Anda bisa membuat tabel biasa di dalam basis data, di mana setiap entitas akan dipetakan ke halaman tertentu di mana ia ditampilkan.  Kemudian, ketika mengubah data apa pun, kita dapat membuat pilihan di atas meja dan menghapus cache dari semua halaman yang kita butuhkan. <br><br>  Langkah 2. Hubungkan ke server cache dan hapus file cache. <br><br><pre> <code class="hljs smalltalk">#      ,      <span class="hljs-type"><span class="hljs-type">FILE_LIST</span></span>=`cat <span class="hljs-string"><span class="hljs-string">$1</span></span> | tr <span class="hljs-comment"><span class="hljs-comment">"\n"</span></span> <span class="hljs-comment"><span class="hljs-comment">" "</span></span>` #   ssh  <span class="hljs-type"><span class="hljs-type">SSH</span></span>=`which ssh` <span class="hljs-type"><span class="hljs-type">USER</span></span>=<span class="hljs-comment"><span class="hljs-comment">"root"</span></span> #         nginx <span class="hljs-type"><span class="hljs-type">HOST</span></span>=<span class="hljs-comment"><span class="hljs-comment">"10.10.1.0"</span></span> #   <span class="hljs-type"><span class="hljs-type">KEY</span></span>=<span class="hljs-comment"><span class="hljs-comment">"/var/keys/id_rsa"</span></span> # <span class="hljs-type"><span class="hljs-type">SSH</span></span> ,          <span class="hljs-string"><span class="hljs-string">$S</span></span>SH -i <span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">KEY</span></span>} <span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">USER</span></span>}@<span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">HOST</span></span>} <span class="hljs-comment"><span class="hljs-comment">"rm -f ${FILE_LIST}"</span></span> #       rm -rf rm -f <span class="hljs-string"><span class="hljs-string">$1</span></span> #  </code> </pre><br>  Contoh di atas hanya untuk panduan, jangan menggunakannya dalam produksi.  Dalam contoh, pemeriksaan parameter input dan pembatasan perintah dihilangkan.  Salah satu masalah yang mungkin Anda temui adalah membatasi panjang argumen ke perintah rm.  Ketika menguji dalam lingkungan dev pada volume kecil, ini dapat dengan mudah dilewatkan, dan dalam produksi Anda mendapatkan kesalahan "rm: Daftar argumen terlalu panjang". <br><br><h3>  Caching Blok Khusus </h3><br>  Mari kita simpulkan apa yang berhasil kita lakukan: <br><br><ul><li>  mengurangi beban di backend; </li><li>  Pelajari cara mengelola caching </li><li>  belajar menyiram cache pada waktu tertentu. </li></ul><br>  Tapi tidak semuanya sebagus kelihatannya pada pandangan pertama.  Sekarang, mungkin, jika tidak setiap pertama, maka tepatnya setiap situs kedua memiliki fungsi registrasi / otorisasi, setelah melewati mana kami ingin menampilkan nama pengguna di suatu tempat di header.  Blokir dengan nama tersebut unik dan harus menampilkan nama pengguna yang kami otorisasi.  Karena nginx menyimpan respons dari backend, dan dalam kasus halaman itu adalah konten html halaman, blok dengan data pribadi juga akan di-cache.  Semua pengunjung ke situs akan melihat nama pengguna pertama yang diteruskan ke backend untuk satu set cache. <br>  Oleh karena itu, backend tidak boleh memberikan blok di mana informasi pribadi berada sehingga informasi ini tidak termasuk dalam cache nginx. <br><br>  Penting untuk mempertimbangkan pemuatan alternatif dari bagian halaman tersebut.  Seperti biasa, ini dapat dilakukan dengan banyak cara, misalnya, setelah memuat halaman, mengirim permintaan ajax, dan menampilkan loader di tempat konten pribadi.  Cara lain yang akan kita pertimbangkan hari ini adalah dengan menggunakan tag ssi.  Pertama mari kita pahami apa itu SSI, dan kemudian bagaimana kita bisa menggunakannya bersamaan dengan cache nginx. <br><br><h3>  Apa itu SSI dan bagaimana cara kerjanya </h3><br>  SSI (Termasuk Sisi-Server, inklusi sisi-server) adalah sekumpulan perintah yang tertanam dalam laman html yang memberi tahu server apa yang harus dilakukan. <br><br>  Berikut adalah daftar perintah (arahan) tersebut: <br><br>  â€¢ if / elif / else / endif - Operator percabangan; <br>  â€¢ echo - Menampilkan nilai variabel; <br>  â€¢ include - Memungkinkan Anda untuk memasukkan konten file lain ke dalam dokumen. <br>  Arahan terakhir akan dibahas.  Arahan include memiliki dua parameter: <br>  â€¢ file - Menentukan jalur ke file di server.  Mengenai direktori saat ini; <br>  â€¢ virtual - Menunjukkan jalur virtual ke dokumen di server. <br><br>  Kami tertarik pada parameter "virtual", karena menentukan path lengkap ke file di server tidak selalu nyaman, atau dalam kasus arsitektur terdistribusi, file di server sama sekali tidak ada.  Arahan contoh: <br><br><pre> <code class="hljs xml"><span class="hljs-comment"><span class="hljs-comment">&lt;!--#include virtual="/user/personal_news/"--&gt;</span></span></code> </pre> <br>  Agar nginx mulai memproses sisipan ssi, Anda perlu mengubah lokasi sebagai berikut: <br><br><pre> <code class="hljs cs">location / { ssi <span class="hljs-keyword"><span class="hljs-keyword">on</span></span>; ... }</code> </pre><br>  Sekarang semua permintaan yang diproses oleh lokasi "/" akan dapat melakukan sisipan ssi. <br><br>  Bagaimana permintaan kami melalui seluruh skema ini? <br><br><ul><li>  klien meminta halaman; </li><li>  Nginx proksi permintaan backend; </li><li>  backend memberi halaman dengan sisipan ssi; </li><li>  hasilnya disimpan dalam cache; </li><li>  Nginx "bertanya" blok yang hilang; </li><li>  Halaman yang dihasilkan dikirim ke klien. </li></ul><br>  Seperti yang Anda lihat dari langkah-langkahnya, konstruksi ssi akan masuk ke cache nginx, yang akan memungkinkan untuk tidak melakukan cache blok pribadi, dan halaman html siap pakai dengan semua sisipan akan dikirim ke klien.  Di sini pemuatan kami berfungsi, nginx secara mandiri meminta blok halaman yang hilang.  Tetapi seperti solusi lainnya, pendekatan ini memiliki pro dan kontra.  Bayangkan bahwa ada beberapa blok pada halaman yang harus ditampilkan secara berbeda tergantung pada pengguna, maka setiap blok tersebut akan diganti dengan insert ssi.  Nginx, seperti yang diharapkan, akan meminta setiap blok seperti itu dari backend, yaitu, satu permintaan dari pengguna akan segera menghasilkan beberapa permintaan untuk backend, yang saya tidak mau sama sekali. <br><br><h3>  Menyingkirkan permintaan backend persisten melalui ssi </h3><br>  Untuk mengatasi masalah ini, modul nginx â€œngx_http_memcached_moduleâ€ akan membantu kami.  Modul ini memungkinkan penerimaan nilai dari server memcached.  Menulis melalui modul tidak akan berfungsi, server aplikasi harus mengurus ini.  Pertimbangkan contoh kecil konfigurasi nginx bersamaan dengan modul: <br><br><pre> <code class="hljs nginx"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> /page { <span class="hljs-attribute"><span class="hljs-attribute">set</span></span> <span class="hljs-variable"><span class="hljs-variable">$memcached_key</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$uri</span></span></span><span class="hljs-string">"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:11211</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">error_page</span></span> <span class="hljs-number"><span class="hljs-number">404</span></span> <span class="hljs-number"><span class="hljs-number">502</span></span> <span class="hljs-number"><span class="hljs-number">504</span></span> = <span class="hljs-variable"><span class="hljs-variable">@fallback</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@fallback</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> http://backend; } }</code> </pre><br>  Dalam variabel $ memcache_key kami menentukan kunci yang nginx akan mencoba untuk mendapatkan data dari memcache.  Parameter untuk menghubungkan ke server memcache diatur dalam direktif memcached_pass.  Koneksi dapat ditentukan dalam beberapa cara: <br><br>  â€¢ nama domain; <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">memcached_pass</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">cache</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.domain</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.ru</span></span>;</code> </pre> <br>  â€¢ Alamat dan port IP; <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> localhost:<span class="hljs-number"><span class="hljs-number">11211</span></span>;</code> </pre> <br>  â€¢ soket unix; <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> unix:/tmp/memcached.socket;</code> </pre> <br>  â€¢ arahan hulu. <br><br><pre> <code class="hljs axapta">upstream cachestream { hash $request_uri consistent; <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">10.10</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>:<span class="hljs-number"><span class="hljs-number">11211</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">10.10</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>:<span class="hljs-number"><span class="hljs-number">11211</span></span>; } location / { ... memcached_pass cachestream; ... }</code> </pre><br>  Jika nginx berhasil mendapatkan respons dari server cache, maka itu memberikannya kepada klien.  Jika tidak ada data dalam cache, permintaan akan dikirim ke backend melalui "@fallback".  Pengaturan kecil ini dari modul memcached di bawah nginx akan membantu kami mengurangi jumlah permintaan lewat untuk backend dari sisipan ssi. <br><br>  Kami berharap artikel ini bermanfaat dan kami dapat menunjukkan salah satu cara untuk mengoptimalkan beban di server, mempertimbangkan prinsip dasar pengaturan caching nginx dan menutup masalah yang muncul saat menggunakannya. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id428127/">https://habr.com/ru/post/id428127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id428117/index.html">Prosesor tensor gratis dari Google di Colaboratory Cloud</a></li>
<li><a href="../id428119/index.html">â€œClass-field-proposalâ€ atau â€œApa yang salah di tc39 commitâ€</a></li>
<li><a href="../id428121/index.html">Stan Drapkin. Perangkap Kriptografi Tingkat Tinggi di .NET</a></li>
<li><a href="../id428123/index.html">Minggu Keamanan 41: Kabar Baik</a></li>
<li><a href="../id428125/index.html">Siapa analitik produk dan mengapa mereka diperlukan dalam sebuah tim?</a></li>
<li><a href="../id428129/index.html">Logika fuzzy sederhana saling menempel â€œdari apa duluâ€ untuk mesin turbin gas</a></li>
<li><a href="../id428131/index.html">Seluruh kebenaran tentang RTOS. Artikel # 17. Grup Bendera Acara: Pengantar dan Layanan Dasar</a></li>
<li><a href="../id428133/index.html">Hasura. GraphQL Kinerja Tinggi untuk Arsitektur SQL Server</a></li>
<li><a href="../id428135/index.html">Cara mengkonfigurasi atau menonaktifkan linting di editor kode bawaan</a></li>
<li><a href="../id428137/index.html">Olimpiade, kontes ide, ceramah tentang manajemen proyek TI dan pemutaran film: 10 acara mendatang di ITMO University</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
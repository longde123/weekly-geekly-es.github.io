<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçº üå∑ ü•¶ Bagaimana saya TIDAK memindai Internet Belarusia üòë üçê üë®üèΩ‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kata Pengantar 
 Artikel ini tidak terlalu mirip dengan yang diterbitkan sebelumnya tentang pemindaian Internet di negara-negara tertentu, karena saya...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana saya TIDAK memindai Internet Belarusia</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446022/"><h2>  Kata Pengantar </h2><br>  Artikel ini tidak terlalu mirip dengan yang diterbitkan sebelumnya tentang pemindaian Internet di negara-negara tertentu, karena saya tidak mengejar tujuan pemindaian massal segmen tertentu dari Internet untuk port terbuka dan keberadaan kerentanan paling populer karena melanggar hukum. <br><br>  Saya agak memiliki minat yang sedikit berbeda - untuk mencoba mengidentifikasi semua situs yang relevan di zona BY domain menggunakan metode yang berbeda, untuk menentukan tumpukan teknologi yang digunakan, melalui layanan seperti Shodan, VirusTotal, dll. Untuk melakukan pengintaian pasif atas IP dan port terbuka dan, dalam lampiran, untuk mengumpulkan sedikit berguna lainnya informasi untuk pembentukan beberapa statistik umum pada tingkat keamanan mengenai situs dan pengguna. <br><a name="habracut"></a><br><h2>  Pendahuluan dan perangkat kami </h2><br>  Rencana di awal sangat sederhana - hubungi registrar lokal Anda untuk daftar domain terdaftar saat ini, kemudian periksa semuanya untuk ketersediaan dan mulai menjelajahi situs yang berfungsi.  Pada kenyataannya, semuanya ternyata jauh lebih rumit - informasi semacam ini alami, tidak ada yang mau memberikan, dengan pengecualian halaman statistik resmi dari nama domain terdaftar aktual di zona BY (sekitar 130 ribu domain).  Jika tidak ada informasi seperti itu, maka Anda harus mengumpulkannya sendiri. <br><br><img src="https://habrastorage.org/webt/yh/pz/4w/yhpz4wvpvleq-f25o5fp5wwt_2u.png"><br><br>  Dalam hal alat, pada kenyataannya, semuanya cukup sederhana - kami melihat ke arah open source, Anda selalu dapat menambahkan sesuatu, menyelesaikan beberapa kruk minimal.  Yang paling populer, alat berikut digunakan: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Whatweb</a> </li><li>  ikal </li><li>  menggali </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">wafw00f</a> </li><li>  API <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pihak</a> Ketiga ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VirusTotal</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Google SafeBrwosing</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Shodan</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Vulners</a> ) </li></ul><br><br><h2>  Mulai dari Kegiatan: Titik Awal </h2><br>  Sebagai pengantar, seperti yang saya katakan sebelumnya, idealnya nama domain cocok, tetapi di mana saya bisa mendapatkannya?  Kita perlu mulai dari sesuatu yang lebih sederhana, dalam hal ini alamat IP cocok untuk kita, tetapi sekali lagi - dengan pencarian terbalik tidak selalu mungkin untuk menangkap semua domain, dan ketika mengumpulkan nama host - itu tidak selalu merupakan domain yang benar.  Pada tahap ini, saya mulai berpikir tentang kemungkinan skenario untuk mengumpulkan informasi semacam ini, lagi - fakta bahwa anggaran kami adalah $ 5 untuk sewa VPS diperhitungkan, semuanya harus gratis. <br><br><h3>  Sumber informasi potensial kami: </h3><br><ul><li>  Alamat IP (situs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ip2lokasi</a> ) </li><li>  Pencarian domain berdasarkan bagian kedua dari alamat email (tetapi di mana mendapatkannya? Mari kita cari tahu sedikit di bawah) </li><li>  Beberapa penyedia pendaftar / hosting dapat memberi kami informasi tersebut dalam bentuk subdomain </li><li>  Subdomain dan kebalikannya berikutnya (Sublist3r dan Aquatone dapat membantu di sini) </li><li>  Masukan bruteforce dan manual (panjang, suram, tetapi mungkin, meskipun saya tidak menggunakan opsi ini) </li></ul><br>  Saya akan berlari sedikit ke depan dan mengatakan bahwa dengan pendekatan ini saya berhasil mengumpulkan sekitar 50 ribu domain dan situs unik, masing-masing (saya tidak berhasil memproses semuanya).  Jika dia terus mengumpulkan informasi secara aktif, maka pastinya dalam waktu kurang dari sebulan kerja konveyor saya akan menguasai seluruh database, atau sebagian besar. <br><br><h3>  Mari kita mulai bisnis </h3><br>  Pada artikel sebelumnya, informasi tentang alamat IP diambil dari situs IP2LOCATION, untuk alasan yang jelas, saya tidak menemukan artikel ini (karena semua tindakan terjadi lebih awal), tetapi juga datang ke sumber ini.  Benar, dalam kasus saya, pendekatannya berbeda - saya memutuskan untuk tidak mengambil database secara lokal untuk diri saya sendiri dan tidak mengambil informasi dari CSV, tetapi memutuskan untuk memantau perubahan secara langsung di situs, secara berkelanjutan dan sebagai basis utama dari mana semua skrip berikutnya akan mengambil tujuan - membuat tabel dengan Alamat IP dalam berbagai format: CIDR, daftar "dari" dan "ke", tanda negara (untuk berjaga-jaga), Nomor AS, Deskripsi AS. <br><br><img src="https://habrastorage.org/webt/mx/s4/wj/mxs4wjpxueytkcd15srf7alswf8.png"><br><br>  Formatnya bukan yang paling optimal, tetapi saya cukup senang dengan demo dan promosi satu kali, dan agar tidak terus mencari informasi tambahan seperti ASN, saya memutuskan untuk mencatatnya sendiri.  Untuk mendapatkan informasi ini, saya beralih ke layanan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">IpToASN</a> , mereka memiliki API yang nyaman (dengan batasan), yang sebenarnya Anda hanya perlu mengintegrasikannya ke dalam diri Anda. <br><br><div class="spoiler">  <b class="spoiler_title">Kode parsing IP</b> <div class="spoiler_text"><pre><code class="php hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ipList</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, <span class="hljs-string"><span class="hljs-string">"https://lite.ip2location.com/belarus-ip-address-ranges"</span></span>); curl_setopt($ch, CURLOPT_HEADER, <span class="hljs-number"><span class="hljs-number">0</span></span>); curl_setopt($ch, CURLOPT_USERAGENT,<span class="hljs-string"><span class="hljs-string">'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.13) Gecko/20080311 Firefox/2.0.0.13'</span></span>); curl_setopt($ch, CURLOPT_RETURNTRANSFER, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); $ipList = curl_exec($ch); curl_close ($ch); preg_match_all(<span class="hljs-string"><span class="hljs-string">"/(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\&lt;\/td\&gt;\s+\&lt;td\&gt;\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})/"</span></span>, $ipList, $matches); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> $matches[<span class="hljs-number"><span class="hljs-number">0</span></span>]; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">iprange2cidr</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">($ipStart, $ipEnd)</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (is_string($ipStart) || is_string($ipEnd)){ $start = ip2long($ipStart); $end = ip2long($ipEnd); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>{ $start = $ipStart; $end = $ipEnd; } $result = <span class="hljs-keyword"><span class="hljs-keyword">array</span></span>(); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>($end &gt;= $start){ $maxSize = <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ($maxSize &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>){ $mask = hexdec(iMask($maxSize - <span class="hljs-number"><span class="hljs-number">1</span></span>)); $maskBase = $start &amp; $mask; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>($maskBase != $start) <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; $maxSize--; } $x = log($end - $start + <span class="hljs-number"><span class="hljs-number">1</span></span>)/log(<span class="hljs-number"><span class="hljs-number">2</span></span>); $maxDiff = floor(<span class="hljs-number"><span class="hljs-number">32</span></span> - floor($x)); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>($maxSize &lt; $maxDiff){ $maxSize = $maxDiff; } $ip = long2ip($start); array_push($result, <span class="hljs-string"><span class="hljs-string">"$ip/$maxSize"</span></span>); $start += pow(<span class="hljs-number"><span class="hljs-number">2</span></span>, (<span class="hljs-number"><span class="hljs-number">32</span></span>-$maxSize)); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> $result; } $getIpList = ipList(); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span>($getIpList <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> $item) { $cidr = iprange2cidr($ip[<span class="hljs-number"><span class="hljs-number">0</span></span>], $ip[<span class="hljs-number"><span class="hljs-number">1</span></span>]); }</code> </pre> <br></div></div><br>  Setelah kami menemukan IP, kami perlu menjalankan seluruh database kami melalui layanan pencarian terbalik, sayangnya, tanpa batasan - ini tidak mungkin, kecuali untuk uang. <br><br>  Dari layanan yang bagus untuk ini dan nyaman untuk digunakan, saya ingin menyebutkan dua: <br><br><ol><li>  VirusTotal - membatasi frekuensi panggilan dari satu kunci API </li><li>  Hackertarget.com (API mereka) - membatasi jumlah klik dari satu IP </li></ol><br>  Melewati batas, opsi berikut diperoleh: <br><br><ul><li>  Dalam kasus pertama, salah satu skenario adalah untuk menahan timeout 15 detik, secara total kita akan memiliki 4 panggilan per menit, yang dapat sangat mempengaruhi kecepatan kita dan dalam situasi ini akan berguna untuk menggunakan 2-3 kunci seperti itu, dan saya akan merekomendasikan menggunakan yang sama untuk proksi dan mengubah agen-pengguna. </li><li>  Dalam kasus kedua, saya menulis sebuah skrip untuk penguraian otomatis dari basis data proxy berdasarkan informasi yang tersedia untuk umum, validasi dan penggunaan selanjutnya (tetapi kemudian saya meninggalkan opsi ini karena VirusTotal juga cukup pada dasarnya) </li></ul><br>  Kami melangkah lebih jauh dan dengan lancar menuju ke alamat email.  Mereka juga dapat menjadi sumber informasi yang berguna, tetapi di mana mengumpulkannya?  Saya tidak perlu mencari solusi untuk waktu yang lama, karena  pengguna memegang sedikit di segmen situs pribadi kami, dan kebanyakan dari mereka adalah organisasi - situs web profil seperti direktori toko online, forum, dan pasar bersyarat yang cocok untuk kami. <br><br>  Misalnya, pemeriksaan cepat terhadap salah satu situs ini menunjukkan bahwa banyak pengguna menambahkan email mereka langsung ke profil publik mereka dan, dengan demikian, bisnis ini dapat diurai dengan hati-hati untuk penggunaan di masa mendatang. <br><br><div class="spoiler">  <b class="spoiler_title">Salah satu pengurai</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env python3 import sys, threading, time, os, urllib, re, requests, pymysql from html.parser import HTMLParser from urllib import request from bs4 import BeautifulSoup # HEADERS CONFIG headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11.9; rv:42.0) Gecko/20200202 Firefox/41.0' } file = open('dat.html', 'w') def parseMails(uid): page = 'https://profile.onliner.by/user/'+str(uid)+'' cookie = {'onl_session': 'YOUR_SESSION_COOOKIE_HERE'} r = requests.get(page, headers = headers, cookies = cookie) data = BeautifulSoup(r.text) userinfo = data.find_all('dl', {'class': 'uprofile-info'}) find_email = [] for item in userinfo: find_email += str(item.find('a')) get_mail = ''.join(find_email) detect_email = re.compile(".+?&gt;(.+@.+?)&lt;/a&gt;").search(get_mail) file.write("&lt;li&gt;('"+detect_email.group(1)+"'),&lt;/li&gt;") for uid in range(1, 10000): t = threading.Thread(target=parseMails, args=(uid,)) t.start() time.sleep(0.3)</span></span></code> </pre><br></div></div><br>  Saya tidak akan membahas detail penguraian setiap situs, di tempat yang lebih nyaman untuk menebak ID pengguna dengan kekerasan, di suatu tempat lebih mudah untuk menguraikan peta situs, mendapatkan informasi tentang halaman perusahaan dari itu dan kemudian mengumpulkan alamat dari mereka.  Setelah mengumpulkan alamat, tetap bagi kami untuk melakukan beberapa operasi sederhana segera menyortirnya berdasarkan zona domain, melestarikan "ekor" dan menjalankannya untuk mengecualikan duplikat dari database yang ada. <br><br>  Pada tahap ini, saya percaya bahwa dengan pembentukan ruang lingkup, kita dapat mengakhiri dan beralih ke kecerdasan.  Kecerdasan, seperti yang telah kita ketahui, dapat terdiri dari dua jenis - aktif dan pasif, dalam kasus kami - pendekatan pasif akan paling relevan.  Tetapi sekali lagi, hanya mengakses situs pada port 80 atau 443 tanpa beban berbahaya dan mengeksploitasi kerentanan adalah tindakan yang sah.  Minat kami adalah respons server terhadap satu permintaan, dalam beberapa kasus mungkin ada dua permintaan (redirect dari http ke https), dalam kasus yang lebih jarang, sebanyak tiga (ketika www digunakan). <br><br><h2>  Kecerdasan </h2><br>  Dengan menggunakan informasi seperti domain, kami dapat mengumpulkan data berikut: <br><br><ul><li>  Catatan DNS (NS, MX, TXT) </li><li>  Header Jawab </li><li>  Identifikasi tumpukan teknologi yang digunakan </li><li>  Pahami protokol apa yang digunakan situs ini. </li><li>  Cobalah untuk mengidentifikasi port terbuka (berdasarkan database Shodan / Censys) tanpa pemindaian langsung </li><li>  Cobalah untuk mengidentifikasi kerentanan berdasarkan korelasi informasi dari Shodan / Censys dengan database Vulners </li><li>  Apakah itu ada di basis data malware Google Safe Browsing </li><li>  Kumpulkan alamat email berdasarkan domain, serta kecocokan yang sudah ditemukan dan periksa oleh Have I Been Pwned, selain itu - menautkan ke jejaring sosial </li><li>  Domain dalam beberapa kasus tidak hanya wajah perusahaan, tetapi juga produk dari aktivitasnya, alamat email untuk pendaftaran layanan, dll., Masing-masing - Anda dapat mencari informasi yang terkait dengan mereka pada sumber daya seperti GitHub, Pastebin, Google Dorks (Google CSE ) </li></ul><br>  Anda selalu dapat melanjutkan dan menggunakan masscan atau nmap, zmap sebagai opsi, mengaturnya terlebih dahulu melalui Tor dengan meluncurkan secara acak atau bahkan dari beberapa kejadian, tetapi kami memiliki tujuan lain dan namanya menyiratkan bahwa saya tidak melakukan pemindaian langsung. <br><br>  Kami mengumpulkan catatan DNS, memeriksa kemungkinan amplifikasi permintaan dan kesalahan konfigurasi seperti AXFR: <br><br><div class="spoiler">  <b class="spoiler_title">Contoh mengumpulkan catatan server NS</b> <div class="spoiler_text"><pre> <code class="bash hljs">dig ns +short <span class="hljs-variable"><span class="hljs-variable">$domain</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/\.$//g'</span></span> | awk <span class="hljs-string"><span class="hljs-string">'{print $1}'</span></span></code> </pre> <br></div></div><br>  Contoh pengumpulan catatan MX (lihat NS, ganti saja 'ns' dengan 'mx' <br><br><div class="spoiler">  <b class="spoiler_title">Periksa AXFR (ada banyak solusi di sini, ini ada kruk lain, tetapi bukan keamanan, yang digunakan untuk melihat output)</b> <div class="spoiler_text"><pre> <code class="php hljs"> $digNs = trim(shell_exec(<span class="hljs-string"><span class="hljs-string">"dig ns +short $domain | sed 's/\.$//g' | awk '{print $1}'"</span></span>)); $ns = explode(<span class="hljs-string"><span class="hljs-string">"\n"</span></span>, $digNs); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span>($ns <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> $target) { $axfr = trim(shell_exec(<span class="hljs-string"><span class="hljs-string">"dig -t axfr $domain @$target | awk '{print $1}' | sed 's/\.$//g'"</span></span>)); $axfr = preg_replace(<span class="hljs-string"><span class="hljs-string">"/\;/"</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, $axfr); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(!<span class="hljs-keyword"><span class="hljs-keyword">empty</span></span>(trim($axfr))) { $axfr = preg_replace(<span class="hljs-string"><span class="hljs-string">"/\;/"</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, $axfr); $res = json_encode(explode(<span class="hljs-string"><span class="hljs-string">"\n"</span></span>, trim($axfr)));</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Periksa Amplifikasi DNS</b> <div class="spoiler_text"><pre> <code class="bash hljs">dig +short test.openresolver.com TXT @<span class="hljs-variable"><span class="hljs-variable">$dns</span></span></code> </pre> <br>  Dalam kasus saya, server NS diambil dari database, jadi pada akhir variabel, di sana Anda dapat mengganti sembarang server.  Mengenai kebenaran hasil dari layanan ini, saya tidak dapat memastikan bahwa semuanya bekerja dengan lancar di sana dan hasilnya selalu valid, tetapi saya berharap bahwa sebagian besar hasilnya nyata. <br></div></div><br>  Jika untuk tujuan apa pun kita perlu menyimpan URL final lengkap ke situs, untuk ini saya menggunakan cURL: <br><br><pre> <code class="bash hljs">curl -I -L <span class="hljs-variable"><span class="hljs-variable">$target</span></span> | awk <span class="hljs-string"><span class="hljs-string">'/Location/{print $2}'</span></span></code> </pre> <br>  Dia sendiri akan melalui seluruh pengalihan dan menampilkan yang terakhir, yaitu  URL situs saat ini.  Dalam kasus saya, itu sangat berguna untuk penggunaan alat selanjutnya seperti WhatWeb. <br><br>  Kenapa kita harus menggunakannya?  Untuk menentukan OS, server web, situs CMS yang digunakan, beberapa tajuk, modul tambahan seperti pustaka / kerangka kerja JS / HTML, serta judul situs yang nantinya dapat Anda coba saring berdasarkan bidang aktivitas yang sama. <br><br>  Pilihan yang sangat nyaman dalam hal ini adalah untuk mengekspor hasil pengoperasian alat dalam format XML untuk analisis selanjutnya dan impor ke dalam basis data jika ada tujuan untuk memproses semuanya nanti. <br><br><pre> <code class="bash hljs">whatweb --no-errors https://www.mywebsite.com --<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>-xml=results.xml</code> </pre> <br>  Untuk saya sendiri, saya membuat JSON sebagai hasil dari output dan sudah memasukkannya ke dalam database. <br><br>  Berbicara tentang tajuk, Anda dapat melakukan hal yang hampir sama dengan CURL biasa dengan mengeksekusi kueri formulir: <br><br><pre> <code class="bash hljs">curl -I https://www.mywebsite.com</code> </pre> <br>  Di tajuk, tangkap informasi tentang CMS dan server web menggunakan ekspresi reguler, misalnya. <br><br>  Selain yang berguna, kami juga dapat menyoroti kemungkinan mengumpulkan informasi tentang port terbuka menggunakan Shodan dan kemudian menggunakan data yang telah diperoleh, melakukan pemeriksaan pada database Vulners menggunakan API mereka (tautan ke layanan diberikan di header).  Tentu saja, mungkin ada masalah dengan keakuratan dalam skenario ini, tetapi ini bukan pemindaian langsung dengan validasi manual, tetapi "juggling" data dari sumber pihak ketiga, tapi setidaknya itu lebih baik daripada tidak sama sekali. <br><br><div class="spoiler">  <b class="spoiler_title">Fungsi PHP untuk Shodan</b> <div class="spoiler_text"><pre> <code class="php hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">shodanHost</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">($host)</span></span></span><span class="hljs-function"> </span></span>{ $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, <span class="hljs-string"><span class="hljs-string">"https://api.shodan.io/shodan/host/"</span></span>.$host.<span class="hljs-string"><span class="hljs-string">"?key=&lt;YOUR_API_KEY&gt;"</span></span>); curl_setopt($ch, CURLOPT_HEADER, <span class="hljs-number"><span class="hljs-number">0</span></span>); curl_setopt($ch, CURLOPT_USERAGENT,<span class="hljs-string"><span class="hljs-string">'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.13) Gecko/20080311 Firefox/2.0.0.13'</span></span>); curl_setopt($ch, CURLOPT_RETURNTRANSFER, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); $shodanResponse = curl_exec($ch); curl_close ($ch); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> json_decode($shodanResponse); }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Contoh dari analisis perbandingan # 1</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/ha/fv/7q/hafv7qlzupcsueqn_qwe_0qyo7y.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Contoh # 2</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/9x/0c/jx/9x0cjxkltuscladnh9rd4nshsga.png"><br></div></div><br>  Ya, karena mereka mulai berbicara tentang API, maka Vulners memiliki batasan dan solusi yang paling optimal adalah dengan menggunakan skrip Python mereka, semuanya akan berfungsi dengan baik tanpa puntiran-puntiran, dalam kasus PHP, saya menemui beberapa kesulitan kecil (sekali lagi, tambahkan. timeout menyelamatkan situasi). <br><br>  Salah satu tes terbaru - kami akan mempelajari informasi tentang firewall yang digunakan dengan skrip seperti "wafw00f".  Saat menguji alat yang luar biasa ini, saya perhatikan satu hal yang menarik: tidak selalu pertama kali menentukan jenis firewall yang digunakan. <br><br>  Untuk melihat jenis firewall apa yang berpotensi dapat dideteksi wafw00f, Anda dapat memasukkan perintah berikut: <br><br><pre> <code class="bash hljs">wafw00f -l</code> </pre> <br>  Untuk menentukan jenis firewall, wafw00f menganalisis header respons server setelah mengirim permintaan standar ke situs, jika upaya ini tidak cukup, menghasilkan permintaan tes sederhana tambahan dengan baik, dan jika ini tidak cukup lagi, metode ketiga beroperasi pada data setelah dua upaya pertama . <br><br>  Karena  untuk statistik, pada kenyataannya, kami tidak memerlukan seluruh jawaban, kami memotong semua kelebihan dengan ekspresi reguler dan hanya meninggalkan nama firewall: <br><br><pre> <code class="php hljs">/is\sbehind\sa\s(.+?)\n/</code> </pre> <br>  Yah, seperti yang saya tulis sebelumnya - selain informasi tentang domain dan situs, informasi tentang alamat email dan jejaring sosial juga diperbarui dalam mode pasif: <br><br><div class="spoiler">  <b class="spoiler_title">Statistik berdasarkan email ditentukan berdasarkan domain</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/f-/lq/fj/f-lqfjqylimkrb3l8ham2yxo8f4.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Contoh penentuan ikatan jejaring sosial ke alamat email</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/an/pw/dq/anpwdqniobeopkdhnyq5pd5ejgk.png"><br></div></div><br>  Cara termudah adalah berurusan dengan validasi alamat di Twitter (2 cara), dengan Facebook (1 cara) dalam hal ini ternyata menjadi sedikit lebih rumit karena sistem yang sedikit lebih rumit untuk menghasilkan sesi pengguna nyata. <br><br><h2>  Mari kita beralih ke statistik kering. </h2><br><h4>  Statistik DNS </h4><br><img src="https://habrastorage.org/webt/uk/md/m1/ukmdm1eoizu6sjvxaf7nld8kdgi.png"><br><br>  <b>Penyedia - berapa banyak situs</b> <br>  ns1.tutby.com: 10899 <br>  ns2.tutby.com: 10899 <br>  ns1.neolocation.com: 4877 <br>  ns2.neolocation.com: 4873 <br>  ns3.neolocation.com: 4572 <br>  ns1.activeby.net: 4231 <br>  ns2.activeby.net: 4229 <br>  u1.hoster.by: 3382 <br>  u2.hoster.by: 3378 <br><br>  DNS unik ditemukan: 2462 <br>  Server MX (surat) unik: 9175 (selain layanan populer, ada cukup banyak administrator yang menggunakan layanan surat mereka sendiri) <br>  Dipengaruhi oleh Transfer Zona DNS: 1011 <br>  Dipengaruhi oleh Penguatan DNS: 531 <br>  Beberapa penggemar CloudFlare: 375 (berdasarkan catatan NS yang digunakan) <br><br><h4>  Statistik CMS </h4><br><img src="https://habrastorage.org/webt/oz/zp/0k/ozzp0kkl6kof-gomjiesmgoju_y.png"><br><br>  <b>CMS - Kuantitas</b> <br>  WordPress: 5118 <br>  Joomla: 2722 <br>  Bitrix: 1757 <br>  Drupal: 898 <br>  OpenCart: 235 <br>  DataLife: 133 <br>  Magento: 32 <br><br><ul><li>  Instalasi WordPress yang berpotensi rentan: 2977 </li><li>  Instalasi yang berpotensi rentan terhadap Joomla: 212 </li><li>  Dengan menggunakan layanan Google SafeBrowsing, dimungkinkan untuk mengidentifikasi situs yang berpotensi berbahaya atau terinfeksi: sekitar 10.000 (pada waktu yang berbeda, seseorang diperbaiki, seseorang tampaknya bangkrut, statistik tidak sepenuhnya objektif) </li><li>  Tentang HTTP dan HTTPS - kurang dari setengah situs volume yang ditemukan menggunakan yang terakhir, tetapi dengan mempertimbangkan fakta bahwa basis data saya tidak lengkap, tetapi hanya 40% dari jumlah total, sangat mungkin bahwa sebagian besar situs dari babak kedua dapat dan berkomunikasi melalui HTTPS . </li></ul><br><h4>  Statistik firewall: </h4><br><img src="https://habrastorage.org/webt/1o/pf/qc/1opfqck9bluf4aa2xvjt2aivaks.png"><br><br>  <b>Firewall - Nomor</b> <br>  ModSecurity: 4354 <br>  Keamanan Aplikasi Web IBM: 126 <br>  Keamanan WP yang lebih baik: 110 <br>  CloudFlare: 104 <br>  Imperva SecureSphere: 45 <br>  Juniper WebApp Secure: 45 <br><br><h4>  Statistik Server Web </h4><br><img src="https://habrastorage.org/webt/k1/ru/ut/k1ruutqumvvmoism9bafmdp8oko.png"><br><br>  <b>Server Web - Nomor</b> <br>  Nginx: 31752 <br>  Apache: 4042 <br>  IIS: 959 <br><br>  Instalasi Nginx yang ketinggalan zaman dan berpotensi rentan: 20966 <br>  Instalasi Apache yang sudah usang dan berpotensi rentan: 995 <br><br>  Terlepas dari kenyataan bahwa hoster.by adalah pemimpin dalam domain dan hosting, misalnya, secara umum, Kontak Terbuka juga dibedakan, tetapi kebenarannya ada pada sejumlah situs pada satu IP: <br><br><img src="https://habrastorage.org/webt/mq/gu/wj/mqguwjm8_1ggvfo_o5vam20tjto.png"><br><br>  <b>IP - Situs</b> <br>  93.84.119.243: 556 <br>  93.125.99.83: 399 <br>  193.232.92.25: 386 <br><br><img src="https://habrastorage.org/webt/h0/us/nk/h0usnka_tsv0yqqa5jb8vd5wy_k.png"><br><br>  Melalui email, statistik terperinci benar-benar memutuskan untuk tidak ditarik, tidak disortir berdasarkan zona domain, melainkan, menarik untuk melihat lokasi pengguna ke vendor tertentu: <br><br><ul><li>  Pada layanan TUT.BY: 38282 </li><li>  Pada layanan Yandex (oleh | ru): 28127 </li><li>  Pada layanan Gmail: 33452 </li><li>  Terikat ke Facebook: 866 </li><li>  Terikat ke Twitter: 652 </li><li>  Ditampilkan dalam kebocoran menurut HIBP: 7844 </li><li>  Kecerdasan pasif membantu mengidentifikasi lebih dari 13 ribu alamat email </li></ul><br>  Seperti yang Anda lihat, gambaran keseluruhan cukup positif, terutama penggunaan aktif nginx dari bagian penyedia hosting.  Mungkin ini sebagian besar karena populer di kalangan pengguna biasa - tipe hosting bersama. <br><br>  Dari kenyataan bahwa saya tidak benar-benar menyukainya - ada cukup banyak penyedia hosting dari tangan tengah yang telah melihat kesalahan seperti AXFR, menggunakan versi lama SSH dan Apache dan beberapa masalah kecil lainnya.  Di sini, tentu saja, lebih banyak cahaya pada situasi dapat ditumpahkan oleh fase aktif, tetapi pada saat ini, berdasarkan undang-undang kami, tampaknya bagi saya itu tidak mungkin, dan saya tidak ingin mendaftar dalam barisan hama untuk hal-hal semacam itu. <br><br>  Gambar email umumnya sangat cerah, jika Anda bisa menyebutnya begitu.  Oh ya, di mana penyedia TUT.BY ditunjukkan - ini berarti menggunakan domain, karena  Layanan ini bekerja atas dasar Yandex. <br><br><h2>  Kesimpulan </h2><br>  Sebagai kesimpulan, saya dapat mengatakan satu hal - bahkan dengan hasil yang tersedia, Anda dapat dengan cepat memahami bahwa ada banyak pekerjaan untuk spesialis yang terlibat dalam pembersihan situs dari virus, pengaturan WAF, dan mengkonfigurasi / menambahkan CMS yang berbeda. <br><br>  Nah, serius, seperti pada dua artikel sebelumnya, kita melihat bahwa masalah ada pada tingkat yang sangat berbeda di semua segmen Internet dan negara, dan beberapa dari mereka bahkan datang dengan studi jarak jauh masalah ini, tanpa menggunakan metode ofensif, dll. e.  menggunakan informasi yang tersedia untuk umum untuk mengumpulkan keterampilan khusus mana yang tidak diperlukan. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id446022/">https://habr.com/ru/post/id446022/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id445992/index.html">Nauchpop minimal: ilusi optik</a></li>
<li><a href="../id445998/index.html">Cara berteman Progress OpenEdge dan Oracle DBMS</a></li>
<li><a href="../id446000/index.html">Apa yang salah dengan Yandex.Music? UX / UI parsing</a></li>
<li><a href="../id446006/index.html">Intel - terdengar baru</a></li>
<li><a href="../id446008/index.html">Alat open source untuk validasi kualitas pencarian berbasis niat</a></li>
<li><a href="../id446024/index.html">Instal dan konfigurasikan simpul Ripple</a></li>
<li><a href="../id446026/index.html">Mengapa SvelteJS bisa dibilang kerangka kerja terbaik untuk pengembang web baru</a></li>
<li><a href="../id446028/index.html">Blok bangunan aplikasi terdistribusi. Nol aproksimasi</a></li>
<li><a href="../id446030/index.html">Startup di bidang bioteknologi anti-penuaan, yang akan relevan pada 2019</a></li>
<li><a href="../id446032/index.html">Zoom video 1080P ke 4K, atau Bagaimana saya belajar untuk tidak khawatir dan menyukai kelas atas menggunakan jaringan saraf</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ§—ğŸ» ğŸ•º ğŸ‘‘ Terjemahan buku Andrew Un, Passion for Machine Learning, Bab 20 - 27 ğŸ–²ï¸ ğŸ¶ ğŸ³</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="bab sebelumnya 
 20 Offset dan Menyebarkan: Dua Sumber Utama Kesalahan 


 komentar penerjemah Sebelum perubahan, bab ini disebut "Sistematis dan Acak...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Terjemahan buku Andrew Un, Passion for Machine Learning, Bab 20 - 27</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420591/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">bab sebelumnya</a> </p><br><h1 id="20-smeschenie-i-razbros-dva-osnovnyh-istochnika-oshibok">  20 Offset dan Menyebarkan: Dua Sumber Utama Kesalahan </h1><br><p>  <em><u>komentar penerjemah</u> Sebelum perubahan, bab ini disebut <strong>"Sistematis dan Acak: Dua Sumber Utama Kesalahan,"</strong> yaitu, saya menggunakan istilah "kesalahan acak" dan "kesalahan sistematis" untuk menerjemahkan bias dan varian.</em>  <em>Namun, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">robot anggota</a> forum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@ Phaker,</a> dalam komentarnya, dengan tepat mencatat bahwa dalam bidang pembelajaran mesin dalam terminologi Rusia untuk istilah-istilah ini konsep "perpindahan" dan "pencar" adalah tetap.</em>  <em>Saya melihat karya K.V.</em>  <em>Vorontsov, yang sepatutnya adalah salah satu otoritas di bidang pembelajaran mesin di Rusia dan sumber daya dari komunitas profesional, dan setuju dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">robot</a> komentar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@ Phaker</a> .</em>  <em>Terlepas dari kenyataan bahwa, dari sudut pandang saya, ada analogi mendalam yang bermakna antara "bias" dan "varians" dalam pelatihan algoritma dan "kesalahan sistematis" dan "kesalahan acak" dari eksperimen fisik, selain itu mereka diekspresikan secara matematis sama Namun demikian, benar untuk menggunakan istilah yang ditetapkan dalam bidang ini.</em>  <em>Oleh karena itu, saya merevisi terjemahan bab ini dan selanjutnya, mengganti "Kesalahan Sistematis dan Acak" dengan "Offset and Scatter" dan saya akan tetap menggunakan pendekatan ini di masa mendatang.</em> </p><a name="habracut"></a><br><p>  Misalkan pelatihan Anda, validasi, dan sampel uji memiliki distribusi yang sama.  Maka Anda perlu mengambil lebih banyak data untuk pelatihan, ini hanya akan meningkatkan kualitas algoritma, apakah ini benar? </p><br><p>  Meskipun mendapatkan lebih banyak data tidak dapat melukai pekerjaan, sayangnya, data baru tidak selalu membantu sebanyak yang Anda harapkan.  Dalam beberapa kasus, pekerjaan untuk mendapatkan data tambahan mungkin merupakan usaha yang sia-sia.  Cara membuat keputusan - dalam hal apa untuk menambahkan data, dan kapan tidak perlu khawatir tentang hal itu. </p><br><p>  Dalam pembelajaran mesin, ada dua sumber utama kesalahan: bias dan pencar (varians).  Memahami apa itu akan membantu Anda memutuskan apakah akan menambah lebih banyak data, itu juga akan membantu Anda memilih taktik untuk meningkatkan kualitas pengklasifikasi. </p><br><p>  Misalkan Anda berharap untuk membangun pengidentifikasi kucing dengan kesalahan 5%.  Saat ini, kesalahan klasifikasi Anda pada sampel pelatihan adalah 15%, pada sampel validasi 16%.  Dalam hal ini, menambahkan data pelatihan tidak mungkin meningkatkan kualitas secara signifikan.  Anda harus berkonsentrasi pada perubahan sistem lainnya.  Bahkan, menambahkan lebih banyak contoh ke set pelatihan Anda hanya akan membuat algoritma Anda lebih sulit untuk mendapatkan hasil yang baik pada set pelatihan tersebut (mengapa ini akan dijelaskan dalam bab-bab berikut). </p><cut></cut><br><p>  Jika persentase kesalahan Anda dalam sampel pelatihan adalah 15% (yang sesuai dengan akurasi 85%), tetapi tujuan Anda adalah persentase kesalahan dalam 5% (akurasi 95%), maka pertama-tama Anda perlu meningkatkan kualitas algoritme Anda dalam sampel pelatihan.  Kualitas algoritma dalam validasi / sampel uji biasanya lebih buruk daripada kualitas kerjanya dalam sampel pelatihan (dalam sampel pelatihan).  Anda perlu memahami bahwa pendekatan-pendekatan yang telah mengarahkan Anda ke akurasi tidak melebihi 85% dalam contoh-contoh yang biasa digunakan oleh algoritma Anda tidak akan memungkinkan Anda untuk mendapatkan akurasi 95% dalam contoh-contoh yang bahkan belum terlihat oleh algoritma ini. </p><cut></cut><br><p>  Misalkan, seperti yang ditunjukkan di atas, tingkat kesalahan algoritma Anda adalah 16% (akurasi 84%) dalam sampel validasi.  Kita harus memecah kesalahan 16% menjadi dua komponen: </p><br><ul><li>  Pertama, proporsi kesalahan algoritma dalam sampel pelatihan.  Dalam contoh ini, ini adalah 15%.  Kami secara informal menyebutnya <strong>bias</strong> . </li><li>  Kedua, seberapa buruk algoritme bekerja pada sampel validasi (atau tes) daripada pada yang pelatihan.  Dalam contoh kami, 1% lebih buruk pada sampel validasi daripada pada sampel pelatihan.  Kami juga akan secara tidak resmi menganggapnya sebagai <strong>varian dari</strong> algoritma. </li></ul><br><p>  <em><u>komentar penulis</u> Dalam statistik, ada definisi yang lebih tepat untuk bias dan pencar (kesalahan sistematis dan acak), tetapi ini seharusnya tidak mengganggu kita.</em>  <em>Secara kasar, kami menganggap bahwa bias adalah kesalahan dalam algoritme Anda dalam set pelatihan Anda ketika Anda memiliki set pelatihan yang sangat besar.</em>  <em>Menyebarkan - ini adalah seberapa buruk algoritma bekerja pada sampel uji dibandingkan dengan yang pelatihan dengan pengaturan parameter yang sama.</em>  <em>Jika Anda menggunakan kesalahan standar, Anda bisa menulis rumus yang menentukan dua kuantitas ini dan membuktikan bahwa kesalahan total sama dengan jumlah bias dan pencar (jumlah kesalahan acak dan sistematis).</em>  <em>Tetapi untuk tujuan kami, meningkatkan algoritma dalam masalah pembelajaran mesin, definisi informal bias dan pencar sudah cukup.</em> </p><br><p>  Beberapa perubahan dalam pelatihan algoritma mempengaruhi komponen pertama dari kesalahan - <strong>bias</strong> dan meningkatkan kinerja algoritma dalam sampel pelatihan.  Beberapa perubahan mempengaruhi komponen kedua - <strong>varians</strong> dan membantu untuk lebih menggeneralisasi algoritma untuk validasi dan menguji sampel.  Untuk memilih perubahan paling efektif yang perlu dilakukan pada sistem, sangat berguna untuk memahami bagaimana masing-masing dari dua komponen kesalahan ini mempengaruhi keseluruhan kesalahan sistem. </p><br><p>  <em><u>Komentar penulis:</u> Ada juga beberapa pendekatan yang secara bersamaan mengurangi perpindahan dan penyebaran, membuat perubahan signifikan pada arsitektur sistem.</em>  <em>Tetapi mereka biasanya lebih sulit ditemukan dan diimplementasikan.</em> </p><br><p>  Untuk memilih perubahan paling efektif yang perlu dilakukan pada sistem, sangat berguna untuk memahami bagaimana masing-masing dari dua komponen kesalahan ini mempengaruhi keseluruhan kesalahan sistem. </p><br><p>  Pengembangan intuisi dalam memahami bagaimana Kontribusi berkontribusi terhadap kesalahan, dan Scatter yang mana, akan membantu Anda secara efektif memilih cara untuk meningkatkan algoritme Anda. </p><cut></cut><br><h1 id="21-primery-klassifikacii-oshibok">  21 Contoh klasifikasi kesalahan </h1><br><p>  Pertimbangkan masalah klasifikasi kucing kami.  Penggolong ideal (misalnya, seseorang) dapat mencapai kualitas yang sangat baik dari tugas ini. </p><br><p>  Misalkan kualitas algoritma kami adalah sebagai berikut: </p><br><ul><li>  Kesalahan dalam sampel pelatihan = 1% </li><li>  Kesalahan dalam sampel validasi = 11% </li></ul><br><p>  Apa masalah dengan pengelompokan ini?  Menerapkan definisi dari bab sebelumnya, kami memperkirakan bias pada 1% dan spread pada 10% (= 11% - 1%).  Dengan demikian, algoritma kami memiliki <strong>penyebaran</strong> besar.  Pengklasifikasi memiliki kesalahan yang sangat rendah dalam sampel pelatihan, tetapi tidak dapat menggeneralisasi hasil pelatihan ke sampel validasi.  Dengan kata lain, kita berhadapan dengan <strong>overfitting</strong> . </p><br><p>  Sekarang pertimbangkan situasi ini: </p><br><ul><li>  Kesalahan dalam sampel pelatihan = 15% </li><li>  Kesalahan dalam sampel validasi = 16% </li></ul><br><p>  Kemudian kami memperkirakan <strong>bias</strong> pada 15% dan <strong>spread</strong> pada 1%.  Klasifikasi ini kurang terlatih dalam sampel pelatihan, sedangkan kesalahannya dalam sampel validasi sedikit lebih besar daripada sampel pelatihan.  Dengan demikian, classifier ini memiliki bias yang besar, tetapi penyebarannya kecil.  Dapat disimpulkan bahwa algoritma ini <strong>kurang tepat</strong> . </p><cut></cut><br><p>  Kami juga mempertimbangkan distribusi kesalahan berikut: </p><br><ul><li>  Kesalahan dalam sampel pelatihan = 15% </li><li>  Kesalahan dalam sampel validasi = 30% </li></ul><br><p>  Dalam hal ini, biasnya 15% dan spreadnya juga 15%.  Pengklasifikasi ini memiliki bias dan penyebaran tinggi: ia tidak bekerja dengan baik dalam sampel pelatihan, memiliki bias tinggi, dan kualitasnya dalam sampel validasi jauh lebih buruk daripada dalam pelatihan, yaitu.  hamburan juga besar.  Kasus ini sulit untuk dijelaskan dalam hal pelatihan ulang / pendidikan rendah, klasifikasi ini dilatih ulang dan kurang berpendidikan. </p><cut></cut><br><p>  Akhirnya, pertimbangkan situasi ini: </p><br><ul><li>  Kesalahan dalam sampel pelatihan = 0,5% </li><li>  Kesalahan dalam sampel validasi = 1% </li></ul><br><p>  Ini adalah penggolong yang hebat, memiliki bias dan pencar yang rendah.  Selamat kepada para insinyur untuk mencapai hasil yang luar biasa! </p><cut></cut><br><h1 id="22-sravnenie-s-optimalnoy-doley-oshibok">  22 Perbandingan dengan tingkat kesalahan optimal </h1><br><p>  Dalam contoh kami untuk pengenalan kucing, bagian kesalahan yang ideal adalah level yang tersedia untuk classifier "optimal" dan level ini mendekati 0%.  Seseorang yang melihat gambar hampir selalu dapat mengenali apakah ada kucing di dalam gambar atau tidak, dan kita dapat berharap bahwa cepat atau lambat mesin akan melakukannya juga. </p><br><p>  Tetapi ada tugas yang lebih kompleks.  Misalnya, bayangkan Anda sedang mengembangkan sistem pengenalan suara, dan menemukan bahwa 14% rekaman audio memiliki begitu banyak suara latar belakang atau suara yang tidak terbaca sehingga bahkan seseorang tidak dapat mengetahui apa yang dikatakan di sana.  Dalam hal ini, bahkan sistem pengenalan ucapan yang paling "optimal" mungkin memiliki kesalahan di wilayah 14%. </p><br><p>  Misalkan dalam tugas pengenalan suara kita, algoritma kita telah mencapai hasil sebagai berikut: </p><br><ul><li>  Kesalahan dalam sampel pelatihan = 15% </li><li>  Kesalahan dalam sampel validasi = 30% </li></ul><cut></cut><br><p>  Kualitas classifier dalam sampel pelatihan sudah mendekati optimal, memiliki tingkat kesalahan 14%.  Jadi, dalam hal ini, kami tidak memiliki banyak peluang untuk mengurangi <strong>bias</strong> (meningkatkan algoritme dalam sampel pelatihan).  Namun, tidak mungkin untuk menggeneralisasi operasi algoritma ini ke sampel validasi, oleh karena itu, ada bidang besar untuk kegiatan pengurangan <strong>sebar</strong> . </p><br><p>  Kasus ini mirip dengan contoh ketiga dari bab sebelumnya, di mana kesalahan dalam sampel pelatihan juga sama dengan 15% dan kesalahan dalam sampel validasi adalah 30%.  Jika tingkat kesalahan optimal adalah sekitar 0%, maka kesalahan dalam sampel pelatihan 15% memberikan banyak ruang untuk bekerja untuk meningkatkan algoritma.  Dengan asumsi ini, upaya untuk mengurangi <strong>bias</strong> dalam algoritma bisa sangat membuahkan hasil.  Tetapi jika proporsi optimal kesalahan klasifikasi tidak boleh lebih rendah dari 14%, maka proporsi kesalahan algoritma yang sama dalam sampel pelatihan (mis., Di wilayah 14-15%) menunjukkan bahwa kemungkinan untuk mengurangi <strong>bias</strong> hampir habis. </p><br><p>  Untuk masalah di mana proporsi optimal kesalahan klasifikasi berbeda secara signifikan dari nol, penataan kesalahan yang lebih rinci dapat diusulkan.  Kami terus mempertimbangkan contoh di atas dengan pengenalan ucapan, kesalahan total 30% dalam sampel validasi dapat didekomposisi menjadi komponen berikut (kesalahan dalam sampel uji dapat dianalisis dengan cara yang sama): </p><cut></cut><br><ul><li>  <strong>Bias optimal (bias tak terhindarkan):</strong> 14%.  Bayangkan, kami memutuskan bahwa bahkan sistem pengenalan ucapan terbaik di dunia, akan memiliki tingkat kesalahan 14%.  Kami akan membicarakan hal ini sebagai bagian "tak terhindarkan" dari offset algoritma pembelajaran. </li><li>  <strong>Bias yang dapat dihindari</strong> : 1%.  Nilai ini dihitung sebagai perbedaan antara proporsi kesalahan dalam sampel pelatihan dan proporsi kesalahan optimal. </li></ul><br><p>  <em><u>komentar penulis:</u> Jika nilai ini ternyata negatif, maka, algoritma Anda pada sampel pelatihan menunjukkan kesalahan yang lebih kecil daripada yang "optimal".</em>  <em>Ini berarti bahwa Anda dilatih ulang di set pelatihan, algoritma Anda mengingat contoh (dan kelas mereka) dari set pelatihan.</em>  <em>Dalam hal ini, Anda harus fokus pada metode untuk mengurangi penyebaran, daripada mengurangi bias lebih lanjut.</em> </p><br><ul><li>  <strong>Varians</strong> : 15%.  Perbedaan antara kesalahan dalam sampel pelatihan dan dalam sampel validasi </li></ul><br><p>  Terkait dengan definisi kami sebelumnya, perpindahan dan perpindahan sekali pakai terkait sebagai berikut: </p><br><p>  Bias <strong>(bias)</strong> = Bias optimal ( <strong>"bias tak terhindarkan"</strong> ) + Bias sekali pakai ( <strong>"bias dihindari"</strong> ) </p><br><p>  <em><u>Catatan penulis</u> : Definisi-definisi ini dipilih untuk lebih menjelaskan bagaimana kualitas algoritma pembelajaran dapat ditingkatkan.</em>  <em>Definisi-definisi ini berbeda dari definisi formal bias dan pencar yang diadopsi dalam statistik.</em>  <em>Secara teknis, apa yang saya definisikan sebagai "Offset" harus disebut "kesalahan yang ada dalam struktur data (tidak dapat diidentifikasi dan dihilangkan)" dan "Hilangkan bias" harus didefinisikan sebagai "Bias algoritma pembelajaran yang melebihi bias optimal" .</em> </p><br><p>  Bias yang dapat dihindari menunjukkan betapa buruknya kualitas algoritme Anda dalam sampel pelatihan dibandingkan kualitas "penggolong optimal". </p><br><p>  Ide dasar varians tetap sama.  Secara teori, kita selalu dapat mengurangi penyebaran menjadi hampir nol dengan melatih sampel pelatihan yang cukup besar.  Dengan demikian, sebaran apapun "dihindari" ketika ada sampel yang cukup besar, sehingga tidak ada yang namanya "penyebaran tidak dapat dihindari" (varians yang tidak dapat dihindari). </p><cut></cut><br><p>  Pertimbangkan contoh lain di mana kesalahan optimal adalah 14% dan kami memiliki: </p><br><ul><li>  Kesalahan dalam sampel pelatihan = 15% </li><li>  Kesalahan dalam sampel validasi = 16% </li></ul><br><p>  Pada bab sebelumnya, kami mengklasifikasikan penggolong dengan indikator seperti penggolong dengan bias tinggi, dalam kondisi saat ini kami mengatakan bahwa "bias yang dapat dihindari" adalah 1%, dan penyebarannya sekitar 1%.  Dengan demikian, algoritma sudah bekerja dengan cukup baik dan hampir tidak ada cadangan untuk meningkatkan kualitas pekerjaannya.  Kualitas algoritma ini hanya 2% di bawah optimal. </p><br><p>  Dari contoh-contoh ini, jelas bahwa mengetahui besarnya kesalahan fatal berguna untuk memutuskan tindakan selanjutnya.  Dalam statistik, <strong>tingkat kesalahan</strong> optimal juga disebut <strong>tingkat kesalahan Bayes</strong> . </p><br><p>  Bagaimana cara mengetahui ukuran tingkat kesalahan optimal?  Untuk tugas-tugas yang diatasi seseorang dengan baik, seperti pengenalan gambar atau decoding klip audio, Anda dapat meminta penilai untuk menandai data, dan kemudian mengukur akurasi markup manusia dalam sampel pelatihan.  Ini akan memberikan perkiraan tingkat kesalahan optimal.  Jika Anda mengerjakan masalah yang sulit bahkan untuk diatasi oleh seseorang (misalnya, untuk memprediksi film mana yang akan direkomendasikan atau iklan mana yang akan ditampilkan kepada pengguna), dalam hal ini agak sulit untuk menilai proporsi kesalahan optimal. </p><br><p>  Dalam bagian Membandingkan Kinerja Tingkat Manusia, bab 33 hingga 35, saya akan membahas secara lebih rinci proses membandingkan kualitas algoritma pembelajaran dengan tingkat kualitas yang dapat dicapai seseorang. </p><cut></cut><br><p>  Dalam bab-bab terakhir, Anda belajar bagaimana mengevaluasi bias dan pencar yang dapat dilepas / tidak dapat dipulihkan dengan menganalisis proporsi kesalahan klasifikasi dalam sampel pelatihan dan validasi.  Bab selanjutnya akan memeriksa bagaimana Anda dapat menggunakan kesimpulan dari analisis tersebut untuk memutuskan apakah akan berkonsentrasi pada metode yang mengurangi bias atau pada metode yang mengurangi penyebaran.  Pendekatan untuk melawan bias sangat berbeda dari pendekatan untuk mengurangi hamburan, sehingga teknik yang harus Anda terapkan dalam proyek Anda untuk meningkatkan kualitas sangat tergantung pada apa yang saat ini menjadi masalah - bias besar atau hamburan besar. </p><cut></cut><br><p>  Baca terus! </p><br><h1 id="23-ustranenie-smescheniya-i-razbrosa">  23 Menghilangkan Offset dan Pencar </h1><br><p>  Berikut ini adalah rumus sederhana untuk menghilangkan bias dan pencar: </p><br><ul><li>  Jika Anda memiliki bias besar yang dapat dihindari, tingkatkan kompleksitas model Anda (misalnya, tambah jaringan saraf Anda dengan menambahkan layer atau (dan) neuron) </li><li>  Jika Anda memiliki penyebaran luas, tambahkan contoh ke set pelatihan Anda. </li></ul><br><p>  Jika Anda memiliki kesempatan untuk meningkatkan ukuran jaringan saraf dan menambahkan data ke set pelatihan tanpa batas, ini akan membantu untuk mencapai hasil yang baik untuk sejumlah besar tugas pembelajaran mesin. </p><br><p>  Dalam praktiknya, meningkatkan ukuran model pada akhirnya akan menyebabkan kesulitan komputasi, karena pelatihan model yang sangat besar lambat.  Anda juga dapat menggunakan batas data yang tersedia untuk pelatihan.  (Bahkan di Internet, jumlah gambar dengan kucing tentu saja!) </p><br><p>  Arsitektur model algoritma yang berbeda, misalnya, arsitektur jaringan saraf yang berbeda, akan memberikan nilai yang berbeda untuk bias dan pencar, dalam kaitannya dengan tugas Anda.  Sebuah poros penelitian pembelajaran mendalam baru-baru ini telah menciptakan sejumlah besar arsitektur model jaringan saraf inovatif.  Jadi, jika Anda menggunakan jaringan saraf, non-fiksi bisa menjadi sumber inspirasi.  Ada juga sejumlah besar implementasi algoritma yang sangat baik dalam sumber terbuka, misalnya pada GitHub.  Namun, hasil dari upaya untuk menggunakan arsitektur baru secara signifikan kurang dapat diprediksi daripada rumus sederhana yang diberikan di atas - menambah ukuran model dan menambahkan data. </p><br><p>  Peningkatan ukuran model biasanya mengurangi bias, tetapi juga dapat menyebabkan peningkatan penyebaran, dan risiko pelatihan ulang juga meningkat.  Namun, masalah pelatihan ulang hanya muncul ketika Anda tidak menggunakan regularisasi.  Jika Anda memasukkan metode regularisasi yang dirancang dengan baik dalam model Anda, Anda biasanya berhasil meningkatkan ukuran model dengan aman tanpa mengizinkan pelatihan ulang. </p><br><p> ,    ,  L2   dropout ( <em><u> </u> :  <strong>Dropout</strong>  , , : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://habr.com/company/wunderfund/blog/330814/</a></em> ),   ,     .     ,          ;    .  , -        â€”   . </p><br><h1 id="24-kompromiss-mezhdu-smescheniem-i-razbrosom"> 24      </h1><br><p>     Â«    Â».   ,      ,  ,        .      Â«Â»    . </p><br><p> ,    â€”    ()   ,       ,    . ,     ,   . </p><br><p>                      (  ).  ,      ,          ,       . </p><br><p> ,            ,       .     ,  ,  ,  ,    . </p><br><p>     ,   ,       .        . </p><br><p>    ,     ,       . </p><br><h1 id="25-podhody-k-umensheniyu-ustranimogo-smescheniya"> 25      </h1><br><p>        ,     : </p><br><ul><li> <strong>  </strong> (,     ):    ,            .   ,     ,  ,     . </li><li> <strong>  ,   ,    </strong> .         ,         (      ).        ,    .        ;    ,     , ,  ,     . </li><li> <strong>    </strong> (L2 , L1 , Dropout):     , ,    . </li><li> <strong>  </strong> (,   )       :      ,     </li></ul><br><p>     : </p><br><ul><li> <strong>    </strong> :     ,        . </li></ul><br><h1 id="26-analiz-oshibok-na-trenirovochnoy-vyborke"> 26      </h1><br><p>        ,        / . </p><br><p>    ,  ,    ,           ,    ,        .   ,      , . .         . </p><br><p> ,        -         .         ,      ,   100 ,       ,        .      ,       : </p><br><div class="scrollable-table"><table><thead><tr><th>   </th><th>    </th><th>     </th><th>     </th><th>  Komentar </th></tr></thead><tbody><tr><td>  1 </td><td>  X </td><td></td><td></td><td>    </td></tr><tr><td>  2 </td><td>  X </td><td></td><td>  X </td><td>   </td></tr><tr><td>  3 </td><td></td><td>  X </td><td>  X </td><td>     </td></tr><tr><td>  4 </td><td>  X </td><td></td><td></td><td>   </td></tr><tr><td> %   - </td><td> 75% </td><td> 25% </td><td>  50% </td><td></td></tr></tbody></table></div><br><p>       ,         ,    .       ,           . </p><br><p>      ,      -,      ,    .       ,    - ,   ,     ,  -     .      ,          ,  . </p><br><h1 id="27-podhody-k-umensheniyu-razbrosa"> 27     </h1><br><p>       ,     : </p><br><ul><li> <strong>     </strong> :         ,     ,                  . </li><li> <strong> </strong> (L1 , L2 , dropout):    ,   . </li><li> <strong>  </strong> (. .    ,       ):    ,   .      ,       . </li><li> <strong>    /  </strong> :       ,     .     (,  1000   900)       .   (  1000   100  10  )     ,      ,        .    ,   ,      ,        ,          ,     ,    ,      . ,     ,      . </li><li> <strong>  () </strong> (    / ). <em>  !</em>       , ,  . ,          .        .                  .       ,        . ,              ,     . </li></ul><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Di sini saya memberikan dua teknik taktis tambahan, mengulangi apa yang dikatakan dalam bab-bab sebelumnya, sehubungan dengan pengurangan bias: </font></font></p><br><ul><li> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ubah tanda yang masuk berdasarkan pemahaman yang diperoleh dari analisis kesalahan</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Katakanlah analisis kesalahan Anda telah mengarah pada gagasan bahwa Anda dapat membuat gejala tambahan yang akan membantu algoritma menyingkirkan beberapa kategori kesalahan. </font><font style="vertical-align: inherit;">Fitur-fitur baru ini akan membantu mengurangi penyebaran dan offset. </font><font style="vertical-align: inherit;">Secara teoritis, penambahan sifat-sifat baru dapat meningkatkan penyebaran; </font><font style="vertical-align: inherit;">tetapi jika ini terjadi, Anda selalu dapat mengambil keuntungan dari regularisasi, yang biasanya meratakan peningkatan penyebaran.</font></font></li><li> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ubah arsitektur model</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (misalnya, arsitektur jaringan saraf) agar lebih cocok untuk tugas Anda: Pendekatan ini dapat mengurangi bias dan pencar.</font></font></li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kelanjutan</font></font></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id420591/">https://habr.com/ru/post/id420591/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id420579/index.html">CPU 24-core, tapi saya tidak bisa mengetikkan email</a></li>
<li><a href="../id420581/index.html">Perkiraan penjualan real estat. Kuliah di Yandex</a></li>
<li><a href="../id420585/index.html">Basis data barcode, unduhan gratis tanpa registrasi (dan kesaksian lainnya)</a></li>
<li><a href="../id420587/index.html">Nah, di mana harus meletakkan mesin ini sekarang?</a></li>
<li><a href="../id420589/index.html">Apa yang harus dicari ketika memilih sistem logging, dan mengapa kami memilih ELK</a></li>
<li><a href="../id420593/index.html">Optimalisasi navigasi web seluler (2 keberhasilan terkini)</a></li>
<li><a href="../id420595/index.html">Pembuatan program secara otomatis, masalah terbalik, dan beberapa solusi terkait</a></li>
<li><a href="../id420597/index.html">Petugas Perlindungan Data - GDPR memperbarui profesi</a></li>
<li><a href="../id420599/index.html">Tiga Belas Hal Yang Terlihat Lama</a></li>
<li><a href="../id420603/index.html">Statistik dari pemilik Tesla Model S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
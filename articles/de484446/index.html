<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôçüèΩ üéÖüèª üéÖüèæ Python 3.5 Implementieren der Parallelit√§t mit asyncio üåâ üí™üèª üôÑ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√úbersetzung von Kapitel 13 Parallelit√§t 
 aus dem Buch 'Expert Python Programming', 
 Zweite Auflage 
 Micha≈Ç Jaworski & Tarek Ziad√©, 2016 
 
 Asynchr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python 3.5 Implementieren der Parallelit√§t mit asyncio</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/484446/">  <i>√úbersetzung von Kapitel 13 Parallelit√§t</i> <i><br></i>  <i>aus dem Buch 'Expert Python Programming',</i> <i><br></i>  <i>Zweite Auflage</i> <i><br></i>  <i>Micha≈Ç Jaworski &amp; Tarek Ziad√©, 2016</i> <i><br></i> <br><h4>  Asynchrone Programmierung </h4><br>  In den letzten Jahren hat die asynchrone Programmierung eine gro√üe Popularit√§t erlangt.  Python 3.5 hat endlich einige Syntaxfunktionen, die die Konzepte asynchroner L√∂sungen unterst√ºtzen.  Dies bedeutet jedoch nicht, dass eine asynchrone Programmierung erst seit Python 3.5 m√∂glich ist.  Viele Bibliotheken und Frameworks wurden bereits viel fr√ºher bereitgestellt, und die meisten stammten aus √§lteren Versionen von Python 2. Es gibt sogar eine alternative Implementierung von Python namens Stackless (siehe Kapitel 1, ‚ÄûDer aktuelle Status von Python‚Äú), die sich auf diesen einzigen Programmieransatz konzentriert.  F√ºr einige L√∂sungen, wie <b>Twisted, Tornado</b> oder <b>Eventlet</b> , gibt es noch aktive Communities, die es wirklich wert sind, kennen zu <b>lernen</b> .  In jedem Fall ist die asynchrone Programmierung seit Python 3.5 so einfach wie nie zuvor.  Daher wird erwartet, dass die integrierten asynchronen Funktionen die meisten alten Tools ersetzen, oder dass externe Projekte allm√§hlich zu einer Art √ºbergeordneten Frameworks werden, die auf integriertem Python basieren. <br><a name="habracut"></a><br>  Wenn Sie versuchen zu erkl√§ren, was asynchrone Programmierung ist, ist es am einfachsten, sich diesen Ansatz als Thread-√§hnlichen Ansatz vorzustellen, jedoch ohne einen System-Scheduler.  Dies bedeutet, dass ein asynchrones Programm gleichzeitig Aufgaben verarbeiten kann, sein Kontext jedoch intern und nicht vom System-Scheduler umgeschaltet wird. <br><br>  Nat√ºrlich verwenden wir keine Threads f√ºr die parallele Verarbeitung von Aufgaben in einem asynchronen Programm.  Die meisten L√∂sungen verwenden unterschiedliche Konzepte und werden je nach Implementierung unterschiedlich aufgerufen.  Einige Beispiele f√ºr Namen, die zur Beschreibung solcher paralleler Programmobjekte verwendet werden, sind: <br><br><ul><li>  <b>Gr√ºne F√§den</b> - Gr√ºne F√§den (Greenlet-, Ereignis- oder Eventlet-Projekte) </li><li>  <b>Coroutinen</b> - Coroutinen (reine asynchrone Programmierung in Python 3.5) </li><li>  <b>Tasklets (Stackless Python)</b> Hierbei handelt es sich im Grunde genommen um dieselben Konzepte, die jedoch h√§ufig auf leicht unterschiedliche Weise implementiert werden. </li></ul><br>  Aus offensichtlichen Gr√ºnden konzentrieren wir uns in diesem Abschnitt nur auf Coroutinen, die ab Version 3.5 von Python unterst√ºtzt werden. <br><br><h4>  Kollaboratives Multitasking und asynchrone E / A </h4><br>  Kollaboratives Multitasking ist der Kern der asynchronen Programmierung.  In diesem Sinne ist Multitasking im Betriebssystem nicht erforderlich, um einen Kontextwechsel (zu einem anderen Prozess oder Thread) auszul√∂sen, sondern jeder Prozess gibt freiwillig die Kontrolle frei, wenn er sich im Standby-Modus befindet, um die gleichzeitige Ausf√ºhrung mehrerer Programme sicherzustellen.  Deshalb nennt man es kollaborativ.  Alle Prozesse m√ºssen zusammenarbeiten, um sicherzustellen, dass Multitasking erfolgreich ist. <br><br>  Das Multitasking-Modell wurde manchmal in Betriebssystemen verwendet, kann aber jetzt kaum noch als L√∂sung auf Systemebene gefunden werden.  Dies liegt daran, dass die Gefahr besteht, dass ein schlecht konzipierter Dienst die Stabilit√§t des gesamten Systems leicht st√∂rt.  Das Planen von Threads und Prozessen mithilfe von Kontextwechseln, die direkt vom Betriebssystem gesteuert werden, ist derzeit der dominierende Ansatz f√ºr die Parallelit√§t auf Systemebene.  Kollaboratives Multitasking ist jedoch immer noch ein hervorragendes Tool f√ºr den gemeinsamen Zugriff auf Anwendungsebene. <br><br>  Apropos gemeinsames Multitasking auf Anwendungsebene: Wir haben es nicht mit Threads oder Prozessen zu tun, die die Kontrolle freigeben m√ºssen, da die gesamte Ausf√ºhrung in einem Prozess und Thread enthalten ist.  Stattdessen haben wir mehrere Aufgaben (Coroutinen, Tasklets und gr√ºne F√§den), die die Kontrolle auf eine einzige Funktion √ºbertragen, die die Koordination der Aufgaben steuert.  Diese Funktion ist normalerweise eine Art Ereignisschleife. <br><br>  Um (aufgrund der Python-Terminologie) Verwirrung zu vermeiden, werden wir jetzt solche parallelen Aufgaben Coroutinen nennen.  Das wichtigste Problem beim kollaborativen Multitasking ist die √úbertragung der Kontrolle.  In den meisten asynchronen Anwendungen wird die Steuerung w√§hrend der E / A-Vorg√§nge an den Scheduler oder die Ereignisschleife √ºbergeben.  Unabh√§ngig davon, ob das Programm Daten aus dem Dateisystem liest oder √ºber einen Socket kommuniziert, ist eine solche E / A-Operation immer mit einer Wartezeit verbunden, wenn der Prozess inaktiv wird.  Die Latenz h√§ngt von einer externen Ressource ab, daher ist dies eine gute Gelegenheit, die Kontrolle √ºber andere Coroutinen freizugeben, bis diese darauf warten m√ºssen, dass sich dieses Vorgehen in etwa so verh√§lt, wie Multithreading in Python implementiert wird.  Wir wissen, dass die GIL Python-Threads serialisiert, sie wird jedoch auch bei jeder E / A-Operation freigegeben.  Der Hauptunterschied besteht darin, dass Threads in Python als Threads auf Systemebene implementiert sind, sodass das Betriebssystem den aktuell ausgef√ºhrten Thread jederzeit entladen und die Steuerung auf einen anderen √ºbertragen kann. <br><br>  Bei der asynchronen Programmierung werden Aufgaben niemals durch die Hauptereignisschleife unterbrochen.  Aus diesem Grund wird dieser Multitasking-Stil auch als Multitasking ohne Priorit√§t bezeichnet. <br><br>  Nat√ºrlich l√§uft jede Python-Anwendung auf einem Betriebssystem, auf dem andere Prozesse um Ressourcen konkurrieren.  Dies bedeutet, dass das Betriebssystem immer das Recht hat, den gesamten Prozess auszulagern und die Kontrolle auf einen anderen zu √ºbertragen.  Wenn unsere asynchrone Anwendung jedoch wieder gestartet wird, wird sie an der Stelle fortgesetzt, an der sie beim Eingreifen des System-Schedulers angehalten wurde.  Aus diesem Grund gelten Koroutinen in diesem Zusammenhang als nicht √ºberf√ºllt. <br><br><h4>  Python asynchrone und warten Schl√ºsselw√∂rter </h4><br>  Die Schl√ºsselw√∂rter <i>async</i> und <i>await</i> sind die Hauptbausteine ‚Äã‚Äãder asynchronen Python-Programmierung. <br><br>  Das vor der <i>def-</i> Anweisung <i>verwendete Schl√ºsselwort async</i> definiert eine neue Coroutine.  Eine Coroutine-Funktion kann unter genau definierten Umst√§nden ausgesetzt und wieder aufgenommen werden.  Die Syntax und das Verhalten sind den Generatoren sehr √§hnlich (siehe Kapitel 2, ‚ÄûSyntaxempfehlungen‚Äú, unter der Klassenebene).  Tats√§chlich sollten Generatoren in √§lteren Versionen von Python verwendet werden, um Coroutinen zu implementieren.  Hier ist eine Beispieldeklaration einer Funktion, die das <i>Schl√ºsselwort async verwendet</i> : <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">async_hello</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"hello, world!"</span></span>)</code> </pre> <br>  Funktionen, die mit dem <i>Schl√ºsselwort async</i> definiert wurden, sind speziell.  Beim Aufruf f√ºhren sie keinen Code im Inneren aus, sondern geben stattdessen ein Coroutine-Objekt zur√ºck: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; async_hello() &lt;coroutine object async_hello at 0x1014129e8&gt;</code></b> </pre><br>  Das Coroutine-Objekt tut nichts, bis seine Ausf√ºhrung in der Ereignisschleife geplant ist.  Das Asyncio-Modul ist verf√ºgbar, um eine grundlegende Implementierung der Ereignisschleife sowie viele andere asynchrone Dienstprogramme bereitzustellen: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; import asyncio &gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; loop = asyncio.get_event_loop() &gt;&gt;&gt; loop.run_until_complete(async_hello()) hello, world! &gt;&gt;&gt; loop.close()</code></b> </pre><br>  Wenn wir nur eine einfache Koroutine erstellen, implementieren wir in unserem Programm nat√ºrlich keine Parallelit√§t.  Um etwas wirklich Paralleles zu sehen, m√ºssen wir mehr Aufgaben erstellen, die von einer Ereignisschleife ausgef√ºhrt werden. <br><br>  Neue Tasks k√∂nnen der Schleife hinzugef√ºgt werden, indem die <i>loop.create_task ()</i> -Methode <i>aufgerufen</i> oder ein anderes Objekt bereitgestellt wird, das auf die <i>Verwendung</i> der <i>asyncio.wait ()</i> -Funktion wartet.  Wir werden den letzteren Ansatz verwenden und versuchen, eine mit der <i>range ()</i> -Funktion erzeugte Folge von Zahlen asynchron zu drucken: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_number</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(number)</span></span></span><span class="hljs-function">:</span></span> print(number) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete( asyncio.wait([ print_number(number) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> number <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>) ]) ) loop.close()</code> </pre><br>  Die Funktion <i>asyncio.wait ()</i> akzeptiert eine Liste von Coroutine-Objekten und kehrt sofort zur√ºck.  Das Ergebnis ist ein Generator, der Objekte erzeugt, die zuk√ºnftige Ergebnisse darstellen (Futures).  Wie der Name schon sagt, wird es verwendet, um auf den Abschluss aller bereitgestellten Coroutinen zu warten.  Der Grund, warum ein Generator anstelle eines Coroutine-Objekts zur√ºckgegeben wird, liegt darin, dass es mit fr√ºheren Versionen von Python abw√§rtskompatibel ist, was sp√§ter erl√§utert wird.  Das Ergebnis der Ausf√ºhrung dieses Skripts kann wie folgt aussehen: <br><br><pre> <b><code class="plaintext hljs">$ python asyncprint.py 0 7 8 3 9 4 1 5 2 6</code></b> </pre><br>  Wie wir sehen k√∂nnen, werden die Zahlen nicht in der Reihenfolge gedruckt, in der wir unsere Koroutinen erstellt haben.  Aber genau das wollten wir erreichen. <br><br>  Das zweite wichtige Schl√ºsselwort, das in Python 3.5 hinzugef√ºgt wurde, wird <i>erwartet</i> .  Es wird verwendet, um auf die Ergebnisse einer Coroutine oder eines zuk√ºnftigen Ereignisses zu warten (wird sp√§ter erl√§utert) und die Kontrolle √ºber die Ausf√ºhrung in der Ereignisschleife freizugeben.  Um besser zu verstehen, wie dies funktioniert, m√ºssen wir ein komplexeres Codebeispiel betrachten. <br><br>  Angenommen, wir m√∂chten zwei Coroutinen erstellen, die einige einfache Aufgaben in einer Schleife ausf√ºhren: <br><br><ul><li>  Warten Sie eine zuf√§llige Anzahl von Sekunden </li><li>  Geben Sie einen als Argument angegebenen Text und die Wartezeit aus.  Beginnen wir mit einer einfachen Implementierung, die einige Parallelit√§tsprobleme aufweist, die wir sp√§ter mit der zus√§tzlichen Verwendung von await verbessern wollen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> time.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) ) <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.wait([waiter(<span class="hljs-string"><span class="hljs-string">"foo"</span></span>), waiter(<span class="hljs-string"><span class="hljs-string">"bar"</span></span>)]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete(main()) loop.close()</code> </pre></li></ul><br>  Bei der Ausf√ºhrung im Terminal (mit dem Befehl time zum Messen der Zeit) sehen Sie Folgendes: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait.py bar waited 0.25 seconds bar waited 0.25 seconds bar waited 0.5 seconds bar waited 0.5 seconds foo waited 0.75 seconds foo waited 0.75 seconds foo waited 0.25 seconds foo waited 0.25 seconds real 0m3.734s user 0m0.153s sys 0m0.028s</code></b> </pre><br><br>  Wie wir sehen k√∂nnen, haben beide Coroutinen ihre Ausf√ºhrung abgeschlossen, jedoch nicht asynchron.  Der Grund daf√ºr ist, dass beide die Funktion <i>time.sleep ()</i> verwenden, die das Steuerelement in der Ereignisschleife sperrt, aber nicht <i>freigibt</i> .  Dies funktioniert in einer Multithread-Installation besser, wir m√∂chten jedoch derzeit keine Streams verwenden.  Wie k√∂nnen wir das beheben? <br><br>  Die Antwort lautet: Verwenden Sie <i>asyncio.sleep ()</i> , eine asynchrone Version von time.sleep (), und erwarten Sie das Ergebnis mit dem Schl√ºsselwort <i>await</i> .  Wir haben diese Anweisung bereits in der ersten Version von <i>main () verwendet</i> , dies diente jedoch nur der besseren √úbersichtlichkeit des Codes.  Dies hat unsere Implementierung eindeutig nicht paralleler gemacht.  Schauen wir uns eine verbesserte Version der waiter () - Coroutine an, die await asyncio.sleep () verwendet: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) )</code> </pre><br><br>  Wenn Sie das aktualisierte Skript ausf√ºhren, werden Sie sehen, wie sich die Ausgabe von zwei Funktionen abwechselt: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait_improved.py bar waited 0.25 seconds foo waited 0.25 seconds bar waited 0.25 seconds foo waited 0.5 seconds foo waited 0.25 seconds bar waited 0.75 seconds foo waited 0.25 seconds bar waited 0.5 seconds real 0m1.953s user 0m0.149s sys 0m0.026s</code></b> </pre><br><br>  Ein zus√§tzlicher Vorteil dieser einfachen Verbesserung ist, dass der Code schneller ausgef√ºhrt wird.  Die Gesamtausf√ºhrungszeit war k√ºrzer als die Summe aller Schlafzeiten, da die Koroutinen nacheinander die Kontrolle √ºbernahmen. <br><br><h4>  Asyncio in fr√ºheren Versionen von Python </h4><br>  Das Asyncio-Modul erschien in Python 3.4.  Dies ist also die einzige Version von Python, die ernsthafte Unterst√ºtzung f√ºr die asynchrone Programmierung vor Python 3.5 bietet.  Leider scheinen diese beiden nachfolgenden Versionen ausreichend zu sein, um Kompatibilit√§tsprobleme aufzuzeigen. <br><br>  Wie auch immer, der asynchrone Programmierkern in Python wurde fr√ºher eingef√ºhrt als die Syntaxelemente, die diese Vorlage unterst√ºtzen.  Besser sp√§t als nie, aber dies f√ºhrte zu einer Situation, in der es zwei Syntaxen f√ºr die Arbeit mit Coroutinen gibt. <br><br>  Ab Python 3.5 k√∂nnen Sie <i>async verwenden</i> und <i>auf</i> <i>Folgendes</i> <i>warten</i> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre><br><br>  In Python 3.4 m√ºssen Sie jedoch zus√§tzlich den Dekorator asyncio.coroutine anwenden und im Coroutine-Text ausgeben: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@asyncio.couroutine def main(): yield from asyncio.sleep(0)</span></span></code> </pre><br><br>  Eine weitere n√ºtzliche Tatsache ist, dass die Ausgabe <i>von statement</i> in Python 3.3 eingef√ºhrt wurde und PyPI einen asynchronen Backport hat.  Dies bedeutet, dass Sie diese Implementierung des kollaborativen Multitasking auch mit Python 3.3 verwenden k√∂nnen. <br><br><h4>  Ein praktisches Beispiel f√ºr asynchrone Programmierung </h4><br>  Wie in diesem Kapitel oft erw√§hnt, ist die asynchrone Programmierung ein hervorragendes Werkzeug f√ºr die Handhabung von E / A.  Es ist an der Zeit, etwas Praktischeres als nur das Drucken von Sequenzen oder das asynchrone Warten zu schaffen. <br><br>  Um die Konsistenz zu gew√§hrleisten, werden wir versuchen, dasselbe Problem zu l√∂sen, das wir mit Hilfe von Multithreading und Multiprocessing gel√∂st haben.  Aus diesem Grund werden wir versuchen, einige Daten √ºber eine Netzwerkverbindung asynchron aus externen Ressourcen zu extrahieren.  Es w√§re gro√üartig, wenn wir das gleiche <i>python-gmaps-</i> Paket wie in den vorherigen Abschnitten verwenden k√∂nnten.  Leider k√∂nnen wir nicht. <br><br>  Der Sch√∂pfer von <i>Python-Gmaps</i> war etwas faul und nahm nur den Namen.  Um die Entwicklung zu vereinfachen, w√§hlte er das Anforderungspaket als seine HTTP-Client-Bibliothek.  Leider unterst√ºtzen Anforderungen keine asynchrone E / A mit <i>Async</i> und <i>warten</i> .  Es gibt einige andere Projekte, die darauf abzielen, eine gewisse Parallelit√§t f√ºr das Abfrageprojekt bereitzustellen, aber sie <i>basieren</i> entweder auf <i>Gevent</i> ( <i>grequests</i> , siehe <i>https://github.com/ kennethreitz / grequests</i> ) oder f√ºhren einen <i>Thread-</i> / Prozesspool aus (query-futures) siehe <i><a href="https://github.com/ross/requests-futures" rel="nofollow">github.com/ross/requests-futures</a></i> ).  Keiner von ihnen l√∂st unser Problem. <br><br><blockquote>  <i>Beruhige dich, bevor ich mich beschuldige, einen unschuldigen Open-Source-Entwickler beschimpft zu haben.</i>  <i>Die Person hinter dem Paket <i>python-gmaps bin</i> ich.</i>  <i>Eine schlechte Wahl der Abh√§ngigkeiten ist eines der Probleme dieses Projekts.</i>  <i>Ich kritisiere mich nur gerne von Zeit zu Zeit √∂ffentlich.</i>  <i>Dies wird eine bittere Lektion f√ºr mich sein, da <i>Python-gmaps</i> in der neuesten Version (0.3.1 zum Zeitpunkt des Schreibens) nicht einfach in Pythons asynchrones I / O integriert werden kann.</i>  <i>In jedem Fall kann sich dies in Zukunft √§ndern, sodass nichts verloren geht.</i> <br></blockquote>  Da wir die Einschr√§nkungen der Bibliothek kennen, die in den vorherigen Beispielen so einfach zu verwenden war, m√ºssen wir etwas erstellen, das diese L√ºcke f√ºllt.  Google MapsAPI ist sehr einfach zu bedienen. Wir werden daher zur Veranschaulichung ein asynchrones Hilfsprogramm entwickeln.  In der Standardbibliothek von Python 3.5 fehlt noch eine Bibliothek, die asynchrone HTTP-Anforderungen so einfach ausf√ºhren kann wie das Aufrufen von <i>urllib.urlopen ()</i> .  Wir m√∂chten definitiv keine vollst√§ndige Protokollunterst√ºtzung von Grund auf erstellen, daher werden wir eine kleine Hilfe aus dem in <i>PyPI</i> verf√ºgbaren <i>aiohttp-</i> Paket verwenden.  Dies ist eine vielversprechende Bibliothek, die sowohl Client- als auch Serverimplementierungen f√ºr asynchrones HTTP hinzuf√ºgt.  Hier ist ein kleines Modul, das auf <i>aiohttp aufbaut</i> und eine <i>Geocode () -</i> <i>Hilfsfunktion</i> erstellt, mit der <i>Geocodierungsanforderungen</i> an den Google Maps-API-Dienst ausgef√ºhrt werden: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> aiohttp session = aiohttp.ClientSession() <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">geocode</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> params = { <span class="hljs-string"><span class="hljs-string">'sensor'</span></span>: <span class="hljs-string"><span class="hljs-string">'false'</span></span>, <span class="hljs-string"><span class="hljs-string">'address'</span></span>: place } <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> session.get( <span class="hljs-string"><span class="hljs-string">'https://maps.googleapis.com/maps/api/geocode/json'</span></span>, params=params ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> response: result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> response.json() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-string"><span class="hljs-string">'results'</span></span>]</code> </pre><br><br>  Nehmen wir an, dass dieser Code in einem Modul mit dem Namen <i>asyncgmaps</i> gespeichert ist, das wir sp√§ter verwenden werden.  Jetzt k√∂nnen wir das Beispiel f√ºr Multithreading und Multiprocessing neu schreiben.  Bisher haben wir den gesamten Vorgang in zwei separate Phasen unterteilt: <br><br><ol><li>  Erf√ºllen Sie alle Anfragen an den externen Dienst parallel mit der Funktion <i>fetch_place ()</i> . </li><li>  <i>Zeigen Sie</i> mit der Funktion <i>present_result ()</i> alle Ergebnisse in einer Schleife an. </li></ol><br>  Da sich kollaboratives Multitasking jedoch grundlegend von der Verwendung mehrerer Prozesse oder Threads unterscheidet, k√∂nnen wir unseren Ansatz leicht √§ndern.  Die meisten Probleme, die bei der Verwendung eines einzelnen Threads pro Element auftreten, sind nicht l√§nger unser Anliegen. <br>  Coroutinen sind nicht pr√§emptiv, daher k√∂nnen wir die Ergebnisse sofort nach Erhalt der HTTP-Antworten problemlos anzeigen.  Dies wird unseren Code vereinfachen und verst√§ndlicher machen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-comment"><span class="hljs-comment"># note: local module introduced earlier from asyncgmaps import geocode, session PLACES = ( 'Reykjavik', 'Vien', 'Zadar', 'Venice', 'Wroc≈Çaw', 'Bolognia', 'Berlin', 'S≈Çubice', 'New York', 'Dehli', ) async def fetch_place(place): return (await geocode(place))[0] async def present_result(result): geocoded = await result print("{:&gt;25s}, {:6.2f}, {:6.2f}".format( geocoded['formatted_address'], geocoded['geometry']['location']['lat'], geocoded['geometry']['location']['lng'], )) async def main(): await asyncio.wait([ present_result(fetch_place(place)) for place in PLACES ]) if __name__ == "__main__": loop = asyncio.get_event_loop() loop.run_until_complete(main()) # aiohttp will raise issue about unclosed # ClientSession so we perform cleanup manually loop.run_until_complete(session.close()) loop.close()</span></span></code> </pre><br><br>  Die asynchrone Programmierung eignet sich hervorragend f√ºr Back-End-Entwickler, die skalierbare Anwendungen erstellen m√∂chten.  In der Praxis ist dies eines der wichtigsten Tools f√ºr die Erstellung von Servern mit hohem Wettbewerbsdruck. <br><br>  Aber die Realit√§t ist traurig.  Viele beliebte Pakete, die sich mit E / A-Problemen befassen, sind nicht f√ºr die Verwendung mit asynchronem Code vorgesehen.  Die Hauptgr√ºnde daf√ºr sind: <br><br><ul><li>  Noch immer wenig Implementierung von Python 3 und einigen seiner erweiterten Funktionen </li><li>  Geringes Verst√§ndnis f√ºr verschiedene Nebenl√§ufigkeitskonzepte bei Anf√§ngern zum Erlernen von Python </li></ul><br>  Dies bedeutet, dass die Migration vorhandener synchroner Multithread-Anwendungen und -Pakete h√§ufig entweder nicht m√∂glich (aufgrund architektonischer Einschr√§nkungen) oder zu teuer ist.  Viele Projekte k√∂nnten von der Implementierung des asynchronen Multitasking-Stils stark profitieren, aber nur wenige werden dies letztendlich tun.  Dies bedeutet, dass Sie von Anfang an Schwierigkeiten haben werden, asynchrone Anwendungen zu erstellen.  In den meisten F√§llen √§hnelt dies dem im Abschnitt ‚ÄûPraktisches Beispiel f√ºr asynchrone Programmierung‚Äú genannten Problem: Inkompatible Schnittstellen und nicht synchrones Blockieren von E / A-Vorg√§ngen.  Nat√ºrlich kann es manchmal vorkommen, dass Sie das Warten aufgeben, wenn eine solche Inkompatibilit√§t auftritt, und nur synchron die erforderlichen Ressourcen abrufen.  Dies verhindert jedoch, dass sich die Coroutine gegenseitig den Code ausf√ºhrt, w√§hrend Sie auf die Ergebnisse warten.  Technisch funktioniert dies, zerst√∂rt aber auch alle Vorteile der asynchronen Programmierung.  Daher ist die Kombination von asynchroner E / A mit synchroner E / A letztendlich keine Option.  Dies ist ein Alles-oder-Nichts-Spiel. <br><br>  Ein weiteres Problem sind langwierige prozessorgebundene Operationen.  Wenn Sie eine E / A-Operation ausf√ºhren, ist es kein Problem, die Steuerung von einer Coroutine freizugeben.  Wenn Sie von einem Dateisystem oder Socket aus schreiben / lesen, werden Sie eventuell warten, sodass ein Aufruf mit wait das Beste ist, was Sie tun k√∂nnen.  Aber was ist, wenn Sie etwas berechnen m√ºssen und wissen, dass es einige Zeit dauern wird?  Nat√ºrlich k√∂nnen Sie das Problem in Teile aufteilen und die Kontrolle jedes Mal abbrechen, wenn Sie die Arbeit ein wenig vorantreiben.  Aber bald werden Sie feststellen, dass dies kein sehr gutes Modell ist.  So etwas kann den Code unordentlich machen und garantiert auch keine guten Ergebnisse. <br><br>  Die zeitliche Bindung sollte in der Verantwortung des Interpreters oder des Betriebssystems liegen. <br><br><h4>  Kombination von asynchronem Code mit asynchronen Zuk√ºnften </h4><br>  Was ist also zu tun, wenn Sie Code haben, der lange synchrone E / A-Vorg√§nge ausf√ºhrt, die Sie nicht umschreiben k√∂nnen oder wollen?  Oder was tun, wenn Sie in einer Anwendung, die haupts√§chlich f√ºr asynchrone E / A konzipiert ist, einige schwere Prozessoroperationen ausf√ºhren m√ºssen?  Nun ... Sie m√ºssen eine Problemumgehung finden.  Und damit meine ich Multithreading oder Multiprocessing. <br><br>  Das h√∂rt sich vielleicht nicht sehr gut an, aber manchmal ist die beste L√∂sung das, wovon wir versucht haben wegzukommen.  Die parallele Verarbeitung von ressourcenintensiven Aufgaben in Python wird aufgrund der Mehrfachverarbeitung immer besser ausgef√ºhrt.  Multithreading kann E / A-Vorg√§nge gleicherma√üen gut (schnell und ohne gro√üe Ressourcen) verarbeiten, da es asynchron ist und wartet, wenn es ordnungsgem√§√ü konfiguriert und sorgf√§ltig behandelt wird. <br><br>  Wenn Sie also manchmal nicht wissen, was zu tun ist, wenn etwas nicht in Ihre asynchrone Anwendung passt, verwenden Sie einen Code, der es in einen separaten Thread oder Prozess stellt.  Sie k√∂nnen so tun, als ob es sich um eine Koroutine handelt, die Steuerung f√ºr die Ereignisschleife freigeben und die Ergebnisse schlie√ülich verarbeiten, wenn sie bereit sind. <br><br>  Gl√ºcklicherweise bietet die Python-Standardbibliothek das <i>concurrent.futures-</i> Modul, das auch in das <i>asyncio-</i> Modul integriert ist.  Zusammen erm√∂glichen diese beiden Module das Planen von Blockierungsfunktionen, die in Threads oder zus√§tzlichen Prozessen ausgef√ºhrt werden, als w√§ren sie asynchrone, nicht blockierende Coroutinen. <br><br><h4>  Executors und Futures </h4><br>  Bevor wir uns mit dem Einbetten von Threads oder Prozessen in eine asynchrone Ereignisschleife befassen, schauen wir uns das <i>concurrent.futures-</i> Modul genauer an, das sp√§ter die Hauptkomponente unserer so genannten Problemumgehung sein wird. <br><br>  Die wichtigsten Klassen im Modul <i>concurrent.futures</i> sind <i>Executor</i> und <i>Future</i> . <br><br>  <i>Executor</i> ist ein Ressourcenpool, der Workitems parallel verarbeiten kann.  Es mag in seinem Zweck den Klassen des Multiprozessor-Moduls - <i>Pool</i> und <i>dummy.Pool</i> - sehr √§hnlich <i>erscheinen</i> , hat aber eine v√∂llig andere Schnittstelle und Semantik.  Dies ist eine Basisklasse, die nicht implementiert werden soll und zwei spezifische Implementierungen aufweist: <br><br><ul><li>  <i>ThreadPoolExecutor</i> : repr√§sentiert einen Thread-Pool </li><li>  <i>ProcessPoolExecutor</i> : repr√§sentiert einen Prozesspool </li></ul><br>  Jeder <i>Executor</i> stellt drei Methoden vor: <br><br><ul><li>  <i>submit (fn, * args, ** kwargs)</i> : <i>Plant</i> die Ausf√ºhrung der Funktion fn im Ressourcenpool und gibt ein Future-Objekt zur√ºck, das die Ausf√ºhrung des aufgerufenen Objekts darstellt </li><li>  <i>map (func, * iterables, timeout = None, chunksize = 1)</i> : Die Funktion <i>func</i> wird bei der Iteration √§hnlich wie bei der <i>Mehrfachverarbeitung</i> ausgef√ºhrt.  <i>Pool.map () -</i> Methode </li><li>  <i>shutdown (wait = True)</i> : Hiermit wird der <i>Executor</i> heruntergefahren und alle seine Ressourcen <i>freigegeben</i> . </li></ul><br>  Die interessanteste Methode ist <i>submit (),</i> da das Future-Objekt zur√ºckgegeben wird.  Es repr√§sentiert die asynchrone Ausf√ºhrung des aufgerufenen und nur indirekt dessen Ergebnis.  Um den tats√§chlichen R√ºckgabewert des versendeten aufgerufenen Objekts <i>abzurufen</i> , m√ºssen Sie die <i>Future.result ()</i> -Methode <i>aufrufen</i> .  Und wenn das aufgerufene Objekt bereits abgeschlossen ist, blockiert die Methode <i>result ()</i> es nicht und gibt einfach die Ausgabe der Funktion zur√ºck.  Ist dies nicht der Fall, blockiert er es, bis das Ergebnis fertig ist.  Stellen Sie es sich als Versprechen eines Ergebnisses vor (es ist eigentlich dasselbe Konzept wie ein Versprechen in JavaScript).  Sie m√ºssen es nicht sofort nach Erhalt entpacken (mithilfe der <i>result () -</i> Methode), aber wenn Sie dies versuchen, wird es garantiert irgendwann etwas zur√ºckgeben: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; def loudy_return(): ... print("processing") ... return 42 ... &gt;&gt;&gt; from concurrent.futures import ThreadPoolExecutor &gt;&gt;&gt; with ThreadPoolExecutor(1) as executor: ... future = executor.submit(loudy_return) ... processing &gt;&gt;&gt; future &lt;Future at 0x33cbf98 state=finished returned int&gt; &gt;&gt;&gt; future.result() 42</code></b> </pre><br><br>  Wenn Sie die <i>Executor.map ()</i> -Methode verwenden m√∂chten, unterscheidet sie sich nicht von der <i>Pool.map ()</i> -Methode der <i>Pool-</i> Klasse des Multiprozessor-Moduls: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> ThreadPoolExecutor(POOL_SIZE) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pool: results = pool.map(fetch_place, PLACES) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> result <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> results: present_result(result)</code> </pre><br><br><h4>  Verwenden von <i>Executor</i> in einer Ereignisschleife </h4><br>  Die von der <i>Executor.submit ()</i> -Methode zur√ºckgegebenen Instanzen der Future-Klasse sind konzeptionell den bei der asynchronen Programmierung verwendeten Coroutinen sehr √§hnlich.  Aus diesem Grund k√∂nnen wir K√ºnstler einsetzen, um eine Mischung aus kollaborativem Multitasking und Multiprocessing oder Multithreading zu erstellen. <br><br>  Der Kern dieser <i>Problemumgehung</i> ist die <i>BaseEventLoop.run_in_executor-Methode (executor, func, * args)</i> der <i>Ereignisschleifenklasse</i> .  Auf diese Weise k√∂nnen Sie die Ausf√ºhrung der func-Funktion in einem durch das executor-Argument dargestellten Prozess oder Thread-Pool planen.  Das Wichtigste an dieser Methode ist, dass sie das neue erwartete Objekt zur√ºckgibt (das Objekt, das mit dem Operator await erwartet werden kann).  Auf diese Weise k√∂nnen Sie eine Blockierungsfunktion ausf√ºhren, die nicht genau wie eine Coroutine ist, und die nicht blockiert, egal wie lange es dauert, bis sie abgeschlossen ist.  Es wird nur die Funktion gestoppt, die Ergebnisse von einem solchen Aufruf erwartet, aber der gesamte Zyklus von Ereignissen wird fortgesetzt. <br><br>  Und eine n√ºtzliche Tatsache ist, dass Sie nicht einmal Ihre eigene Executor-Instanz erstellen m√ºssen.  Wenn Sie <i>None</i> als Argument an <i>executor √ºbergeben</i> , wird die <i>ThreadPoolExecutor-</i> Klasse mit der Standardanzahl von Threads verwendet (f√ºr Python 3.5 ist dies die Anzahl der Prozessoren multipliziert mit 5). <br><br>  Nehmen wir also an, wir wollten den problematischen Teil des python-gmaps-Pakets, der unsere Kopfschmerzen verursacht hat, nicht umschreiben.  Wir k√∂nnen einen blockierenden Aufruf an einen separaten Thread einfach verschieben, indem <i>wir loop.run_in_executor ()</i> aufrufen und dabei die Funktion fetch_place () als erwartete Coroutine belassen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch_place</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> coro = loop.run_in_executor(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, api.geocode, place) result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> coro <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine solche L√∂sung ist schlimmer als eine vollst√§ndig asynchrone Bibliothek, aber Sie wissen, dass zumindest etwas besser ist als nichts. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nachdem wir erkl√§rt hatten, was Parallelit√§t wirklich ist, haben wir Ma√ünahmen ergriffen und eines der typischen Parallelprobleme mithilfe von Multithreading analysiert. Nachdem wir die Hauptm√§ngel unseres Codes identifiziert und korrigiert hatten, wandten wir uns der Mehrfachverarbeitung zu, um zu sehen, wie dies in unserem Fall funktionieren w√ºrde. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Danach stellten wir fest, dass die Verwendung mehrerer Prozesse mit einem Multiprozessor-Modul viel einfacher ist als grundlegende Threads mit Multithreading. Erst danach wurde uns klar, dass wir dank </font><i><font style="vertical-align: inherit;">multiprocessing.dummy</font></i><font style="vertical-align: inherit;"> dieselbe API f√ºr Threads verwenden k√∂nnen</font></font><i><font style="vertical-align: inherit;"></font></i> .  ,          ,     ,       . <br><br>    ,  -   ,       ,    / ,   ,          .  ,   ,    ,   ! <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und das f√ºhrt uns zum endg√ºltigen Abschluss dieses Kapitels. </font><font style="vertical-align: inherit;">Es gibt keine L√∂sung, die allen zusagt. </font><font style="vertical-align: inherit;">Es gibt verschiedene Ans√§tze, die Sie bevorzugen oder bevorzugen. </font><font style="vertical-align: inherit;">Es gibt einige Ans√§tze, die f√ºr diese Problematik besser geeignet sind, aber Sie m√ºssen alle kennen, um erfolgreich zu sein. </font><font style="vertical-align: inherit;">In realistischen Szenarien k√∂nnen Sie das gesamte Arsenal an Werkzeugen und Parallelit√§tsstilen in einer Anwendung verwenden. Dies ist keine Seltenheit. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die vorherige Schlussfolgerung ist eine hervorragende Einf√ºhrung in das Thema des n√§chsten Kapitels, Kapitel 14 ‚ÄûN√ºtzliche Entwurfsmuster‚Äú. </font><font style="vertical-align: inherit;">Da es keine einzige Vorlage gibt, die alle Ihre Probleme l√∂st. </font><font style="vertical-align: inherit;">Sie sollten so viel wie m√∂glich wissen, denn letztendlich werden Sie sie jeden Tag verwenden.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de484446/">https://habr.com/ru/post/de484446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de484436/index.html">Ungrateful Opensource: Der Entwickler des schnellsten Webservers hat sein Repository gel√∂scht - Wichtiges Update</a></li>
<li><a href="../de484438/index.html">Ber√ºhmte Fl√ºssigkeitsgleichungen sind durchgesickert</a></li>
<li><a href="../de484440/index.html">Vollst√§ndige Sicherung mit Standard-Windows-Tools</a></li>
<li><a href="../de484442/index.html">SNMPv3-Beispiel</a></li>
<li><a href="../de484444/index.html">Wie sich die Betriebsbedingungen auf die Batterie auswirken oder wie sich die Geschichte einer wundersamen Auferstehung auswirkt</a></li>
<li><a href="../de484448/index.html">DEFCON-Konferenz 27. Hacken Sie die Polizei. Teil 1</a></li>
<li><a href="../de484454/index.html">Habra Detektiv: Ihr Bild ist verloren</a></li>
<li><a href="../de484456/index.html">ReactJS, serverseitiges Rendering und einige Feinheiten bei der Verarbeitung von Seiten-Metatags</a></li>
<li><a href="../de484458/index.html">Dieser Freiberufler ist kaputt - gib mir den n√§chsten</a></li>
<li><a href="../de484462/index.html">Scraping Github: Suche nach "Geheimnissen", die es zu entwickeln gilt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
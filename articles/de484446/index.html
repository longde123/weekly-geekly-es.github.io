<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙍🏽 🎅🏻 🎅🏾 Python 3.5 Implementieren der Parallelität mit asyncio 🌉 💪🏻 🙄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Übersetzung von Kapitel 13 Parallelität 
 aus dem Buch 'Expert Python Programming', 
 Zweite Auflage 
 Michał Jaworski & Tarek Ziadé, 2016 
 
 Asynchr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python 3.5 Implementieren der Parallelität mit asyncio</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/484446/">  <i>Übersetzung von Kapitel 13 Parallelität</i> <i><br></i>  <i>aus dem Buch 'Expert Python Programming',</i> <i><br></i>  <i>Zweite Auflage</i> <i><br></i>  <i>Michał Jaworski &amp; Tarek Ziadé, 2016</i> <i><br></i> <br><h4>  Asynchrone Programmierung </h4><br>  In den letzten Jahren hat die asynchrone Programmierung eine große Popularität erlangt.  Python 3.5 hat endlich einige Syntaxfunktionen, die die Konzepte asynchroner Lösungen unterstützen.  Dies bedeutet jedoch nicht, dass eine asynchrone Programmierung erst seit Python 3.5 möglich ist.  Viele Bibliotheken und Frameworks wurden bereits viel früher bereitgestellt, und die meisten stammten aus älteren Versionen von Python 2. Es gibt sogar eine alternative Implementierung von Python namens Stackless (siehe Kapitel 1, „Der aktuelle Status von Python“), die sich auf diesen einzigen Programmieransatz konzentriert.  Für einige Lösungen, wie <b>Twisted, Tornado</b> oder <b>Eventlet</b> , gibt es noch aktive Communities, die es wirklich wert sind, kennen zu <b>lernen</b> .  In jedem Fall ist die asynchrone Programmierung seit Python 3.5 so einfach wie nie zuvor.  Daher wird erwartet, dass die integrierten asynchronen Funktionen die meisten alten Tools ersetzen, oder dass externe Projekte allmählich zu einer Art übergeordneten Frameworks werden, die auf integriertem Python basieren. <br><a name="habracut"></a><br>  Wenn Sie versuchen zu erklären, was asynchrone Programmierung ist, ist es am einfachsten, sich diesen Ansatz als Thread-ähnlichen Ansatz vorzustellen, jedoch ohne einen System-Scheduler.  Dies bedeutet, dass ein asynchrones Programm gleichzeitig Aufgaben verarbeiten kann, sein Kontext jedoch intern und nicht vom System-Scheduler umgeschaltet wird. <br><br>  Natürlich verwenden wir keine Threads für die parallele Verarbeitung von Aufgaben in einem asynchronen Programm.  Die meisten Lösungen verwenden unterschiedliche Konzepte und werden je nach Implementierung unterschiedlich aufgerufen.  Einige Beispiele für Namen, die zur Beschreibung solcher paralleler Programmobjekte verwendet werden, sind: <br><br><ul><li>  <b>Grüne Fäden</b> - Grüne Fäden (Greenlet-, Ereignis- oder Eventlet-Projekte) </li><li>  <b>Coroutinen</b> - Coroutinen (reine asynchrone Programmierung in Python 3.5) </li><li>  <b>Tasklets (Stackless Python)</b> Hierbei handelt es sich im Grunde genommen um dieselben Konzepte, die jedoch häufig auf leicht unterschiedliche Weise implementiert werden. </li></ul><br>  Aus offensichtlichen Gründen konzentrieren wir uns in diesem Abschnitt nur auf Coroutinen, die ab Version 3.5 von Python unterstützt werden. <br><br><h4>  Kollaboratives Multitasking und asynchrone E / A </h4><br>  Kollaboratives Multitasking ist der Kern der asynchronen Programmierung.  In diesem Sinne ist Multitasking im Betriebssystem nicht erforderlich, um einen Kontextwechsel (zu einem anderen Prozess oder Thread) auszulösen, sondern jeder Prozess gibt freiwillig die Kontrolle frei, wenn er sich im Standby-Modus befindet, um die gleichzeitige Ausführung mehrerer Programme sicherzustellen.  Deshalb nennt man es kollaborativ.  Alle Prozesse müssen zusammenarbeiten, um sicherzustellen, dass Multitasking erfolgreich ist. <br><br>  Das Multitasking-Modell wurde manchmal in Betriebssystemen verwendet, kann aber jetzt kaum noch als Lösung auf Systemebene gefunden werden.  Dies liegt daran, dass die Gefahr besteht, dass ein schlecht konzipierter Dienst die Stabilität des gesamten Systems leicht stört.  Das Planen von Threads und Prozessen mithilfe von Kontextwechseln, die direkt vom Betriebssystem gesteuert werden, ist derzeit der dominierende Ansatz für die Parallelität auf Systemebene.  Kollaboratives Multitasking ist jedoch immer noch ein hervorragendes Tool für den gemeinsamen Zugriff auf Anwendungsebene. <br><br>  Apropos gemeinsames Multitasking auf Anwendungsebene: Wir haben es nicht mit Threads oder Prozessen zu tun, die die Kontrolle freigeben müssen, da die gesamte Ausführung in einem Prozess und Thread enthalten ist.  Stattdessen haben wir mehrere Aufgaben (Coroutinen, Tasklets und grüne Fäden), die die Kontrolle auf eine einzige Funktion übertragen, die die Koordination der Aufgaben steuert.  Diese Funktion ist normalerweise eine Art Ereignisschleife. <br><br>  Um (aufgrund der Python-Terminologie) Verwirrung zu vermeiden, werden wir jetzt solche parallelen Aufgaben Coroutinen nennen.  Das wichtigste Problem beim kollaborativen Multitasking ist die Übertragung der Kontrolle.  In den meisten asynchronen Anwendungen wird die Steuerung während der E / A-Vorgänge an den Scheduler oder die Ereignisschleife übergeben.  Unabhängig davon, ob das Programm Daten aus dem Dateisystem liest oder über einen Socket kommuniziert, ist eine solche E / A-Operation immer mit einer Wartezeit verbunden, wenn der Prozess inaktiv wird.  Die Latenz hängt von einer externen Ressource ab, daher ist dies eine gute Gelegenheit, die Kontrolle über andere Coroutinen freizugeben, bis diese darauf warten müssen, dass sich dieses Vorgehen in etwa so verhält, wie Multithreading in Python implementiert wird.  Wir wissen, dass die GIL Python-Threads serialisiert, sie wird jedoch auch bei jeder E / A-Operation freigegeben.  Der Hauptunterschied besteht darin, dass Threads in Python als Threads auf Systemebene implementiert sind, sodass das Betriebssystem den aktuell ausgeführten Thread jederzeit entladen und die Steuerung auf einen anderen übertragen kann. <br><br>  Bei der asynchronen Programmierung werden Aufgaben niemals durch die Hauptereignisschleife unterbrochen.  Aus diesem Grund wird dieser Multitasking-Stil auch als Multitasking ohne Priorität bezeichnet. <br><br>  Natürlich läuft jede Python-Anwendung auf einem Betriebssystem, auf dem andere Prozesse um Ressourcen konkurrieren.  Dies bedeutet, dass das Betriebssystem immer das Recht hat, den gesamten Prozess auszulagern und die Kontrolle auf einen anderen zu übertragen.  Wenn unsere asynchrone Anwendung jedoch wieder gestartet wird, wird sie an der Stelle fortgesetzt, an der sie beim Eingreifen des System-Schedulers angehalten wurde.  Aus diesem Grund gelten Koroutinen in diesem Zusammenhang als nicht überfüllt. <br><br><h4>  Python asynchrone und warten Schlüsselwörter </h4><br>  Die Schlüsselwörter <i>async</i> und <i>await</i> sind die Hauptbausteine ​​der asynchronen Python-Programmierung. <br><br>  Das vor der <i>def-</i> Anweisung <i>verwendete Schlüsselwort async</i> definiert eine neue Coroutine.  Eine Coroutine-Funktion kann unter genau definierten Umständen ausgesetzt und wieder aufgenommen werden.  Die Syntax und das Verhalten sind den Generatoren sehr ähnlich (siehe Kapitel 2, „Syntaxempfehlungen“, unter der Klassenebene).  Tatsächlich sollten Generatoren in älteren Versionen von Python verwendet werden, um Coroutinen zu implementieren.  Hier ist eine Beispieldeklaration einer Funktion, die das <i>Schlüsselwort async verwendet</i> : <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">async_hello</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"hello, world!"</span></span>)</code> </pre> <br>  Funktionen, die mit dem <i>Schlüsselwort async</i> definiert wurden, sind speziell.  Beim Aufruf führen sie keinen Code im Inneren aus, sondern geben stattdessen ein Coroutine-Objekt zurück: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; async_hello() &lt;coroutine object async_hello at 0x1014129e8&gt;</code></b> </pre><br>  Das Coroutine-Objekt tut nichts, bis seine Ausführung in der Ereignisschleife geplant ist.  Das Asyncio-Modul ist verfügbar, um eine grundlegende Implementierung der Ereignisschleife sowie viele andere asynchrone Dienstprogramme bereitzustellen: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; import asyncio &gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; loop = asyncio.get_event_loop() &gt;&gt;&gt; loop.run_until_complete(async_hello()) hello, world! &gt;&gt;&gt; loop.close()</code></b> </pre><br>  Wenn wir nur eine einfache Koroutine erstellen, implementieren wir in unserem Programm natürlich keine Parallelität.  Um etwas wirklich Paralleles zu sehen, müssen wir mehr Aufgaben erstellen, die von einer Ereignisschleife ausgeführt werden. <br><br>  Neue Tasks können der Schleife hinzugefügt werden, indem die <i>loop.create_task ()</i> -Methode <i>aufgerufen</i> oder ein anderes Objekt bereitgestellt wird, das auf die <i>Verwendung</i> der <i>asyncio.wait ()</i> -Funktion wartet.  Wir werden den letzteren Ansatz verwenden und versuchen, eine mit der <i>range ()</i> -Funktion erzeugte Folge von Zahlen asynchron zu drucken: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_number</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(number)</span></span></span><span class="hljs-function">:</span></span> print(number) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete( asyncio.wait([ print_number(number) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> number <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>) ]) ) loop.close()</code> </pre><br>  Die Funktion <i>asyncio.wait ()</i> akzeptiert eine Liste von Coroutine-Objekten und kehrt sofort zurück.  Das Ergebnis ist ein Generator, der Objekte erzeugt, die zukünftige Ergebnisse darstellen (Futures).  Wie der Name schon sagt, wird es verwendet, um auf den Abschluss aller bereitgestellten Coroutinen zu warten.  Der Grund, warum ein Generator anstelle eines Coroutine-Objekts zurückgegeben wird, liegt darin, dass es mit früheren Versionen von Python abwärtskompatibel ist, was später erläutert wird.  Das Ergebnis der Ausführung dieses Skripts kann wie folgt aussehen: <br><br><pre> <b><code class="plaintext hljs">$ python asyncprint.py 0 7 8 3 9 4 1 5 2 6</code></b> </pre><br>  Wie wir sehen können, werden die Zahlen nicht in der Reihenfolge gedruckt, in der wir unsere Koroutinen erstellt haben.  Aber genau das wollten wir erreichen. <br><br>  Das zweite wichtige Schlüsselwort, das in Python 3.5 hinzugefügt wurde, wird <i>erwartet</i> .  Es wird verwendet, um auf die Ergebnisse einer Coroutine oder eines zukünftigen Ereignisses zu warten (wird später erläutert) und die Kontrolle über die Ausführung in der Ereignisschleife freizugeben.  Um besser zu verstehen, wie dies funktioniert, müssen wir ein komplexeres Codebeispiel betrachten. <br><br>  Angenommen, wir möchten zwei Coroutinen erstellen, die einige einfache Aufgaben in einer Schleife ausführen: <br><br><ul><li>  Warten Sie eine zufällige Anzahl von Sekunden </li><li>  Geben Sie einen als Argument angegebenen Text und die Wartezeit aus.  Beginnen wir mit einer einfachen Implementierung, die einige Parallelitätsprobleme aufweist, die wir später mit der zusätzlichen Verwendung von await verbessern wollen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> time.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) ) <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.wait([waiter(<span class="hljs-string"><span class="hljs-string">"foo"</span></span>), waiter(<span class="hljs-string"><span class="hljs-string">"bar"</span></span>)]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete(main()) loop.close()</code> </pre></li></ul><br>  Bei der Ausführung im Terminal (mit dem Befehl time zum Messen der Zeit) sehen Sie Folgendes: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait.py bar waited 0.25 seconds bar waited 0.25 seconds bar waited 0.5 seconds bar waited 0.5 seconds foo waited 0.75 seconds foo waited 0.75 seconds foo waited 0.25 seconds foo waited 0.25 seconds real 0m3.734s user 0m0.153s sys 0m0.028s</code></b> </pre><br><br>  Wie wir sehen können, haben beide Coroutinen ihre Ausführung abgeschlossen, jedoch nicht asynchron.  Der Grund dafür ist, dass beide die Funktion <i>time.sleep ()</i> verwenden, die das Steuerelement in der Ereignisschleife sperrt, aber nicht <i>freigibt</i> .  Dies funktioniert in einer Multithread-Installation besser, wir möchten jedoch derzeit keine Streams verwenden.  Wie können wir das beheben? <br><br>  Die Antwort lautet: Verwenden Sie <i>asyncio.sleep ()</i> , eine asynchrone Version von time.sleep (), und erwarten Sie das Ergebnis mit dem Schlüsselwort <i>await</i> .  Wir haben diese Anweisung bereits in der ersten Version von <i>main () verwendet</i> , dies diente jedoch nur der besseren Übersichtlichkeit des Codes.  Dies hat unsere Implementierung eindeutig nicht paralleler gemacht.  Schauen wir uns eine verbesserte Version der waiter () - Coroutine an, die await asyncio.sleep () verwendet: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) )</code> </pre><br><br>  Wenn Sie das aktualisierte Skript ausführen, werden Sie sehen, wie sich die Ausgabe von zwei Funktionen abwechselt: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait_improved.py bar waited 0.25 seconds foo waited 0.25 seconds bar waited 0.25 seconds foo waited 0.5 seconds foo waited 0.25 seconds bar waited 0.75 seconds foo waited 0.25 seconds bar waited 0.5 seconds real 0m1.953s user 0m0.149s sys 0m0.026s</code></b> </pre><br><br>  Ein zusätzlicher Vorteil dieser einfachen Verbesserung ist, dass der Code schneller ausgeführt wird.  Die Gesamtausführungszeit war kürzer als die Summe aller Schlafzeiten, da die Koroutinen nacheinander die Kontrolle übernahmen. <br><br><h4>  Asyncio in früheren Versionen von Python </h4><br>  Das Asyncio-Modul erschien in Python 3.4.  Dies ist also die einzige Version von Python, die ernsthafte Unterstützung für die asynchrone Programmierung vor Python 3.5 bietet.  Leider scheinen diese beiden nachfolgenden Versionen ausreichend zu sein, um Kompatibilitätsprobleme aufzuzeigen. <br><br>  Wie auch immer, der asynchrone Programmierkern in Python wurde früher eingeführt als die Syntaxelemente, die diese Vorlage unterstützen.  Besser spät als nie, aber dies führte zu einer Situation, in der es zwei Syntaxen für die Arbeit mit Coroutinen gibt. <br><br>  Ab Python 3.5 können Sie <i>async verwenden</i> und <i>auf</i> <i>Folgendes</i> <i>warten</i> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre><br><br>  In Python 3.4 müssen Sie jedoch zusätzlich den Dekorator asyncio.coroutine anwenden und im Coroutine-Text ausgeben: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@asyncio.couroutine def main(): yield from asyncio.sleep(0)</span></span></code> </pre><br><br>  Eine weitere nützliche Tatsache ist, dass die Ausgabe <i>von statement</i> in Python 3.3 eingeführt wurde und PyPI einen asynchronen Backport hat.  Dies bedeutet, dass Sie diese Implementierung des kollaborativen Multitasking auch mit Python 3.3 verwenden können. <br><br><h4>  Ein praktisches Beispiel für asynchrone Programmierung </h4><br>  Wie in diesem Kapitel oft erwähnt, ist die asynchrone Programmierung ein hervorragendes Werkzeug für die Handhabung von E / A.  Es ist an der Zeit, etwas Praktischeres als nur das Drucken von Sequenzen oder das asynchrone Warten zu schaffen. <br><br>  Um die Konsistenz zu gewährleisten, werden wir versuchen, dasselbe Problem zu lösen, das wir mit Hilfe von Multithreading und Multiprocessing gelöst haben.  Aus diesem Grund werden wir versuchen, einige Daten über eine Netzwerkverbindung asynchron aus externen Ressourcen zu extrahieren.  Es wäre großartig, wenn wir das gleiche <i>python-gmaps-</i> Paket wie in den vorherigen Abschnitten verwenden könnten.  Leider können wir nicht. <br><br>  Der Schöpfer von <i>Python-Gmaps</i> war etwas faul und nahm nur den Namen.  Um die Entwicklung zu vereinfachen, wählte er das Anforderungspaket als seine HTTP-Client-Bibliothek.  Leider unterstützen Anforderungen keine asynchrone E / A mit <i>Async</i> und <i>warten</i> .  Es gibt einige andere Projekte, die darauf abzielen, eine gewisse Parallelität für das Abfrageprojekt bereitzustellen, aber sie <i>basieren</i> entweder auf <i>Gevent</i> ( <i>grequests</i> , siehe <i>https://github.com/ kennethreitz / grequests</i> ) oder führen einen <i>Thread-</i> / Prozesspool aus (query-futures) siehe <i><a href="https://github.com/ross/requests-futures" rel="nofollow">github.com/ross/requests-futures</a></i> ).  Keiner von ihnen löst unser Problem. <br><br><blockquote>  <i>Beruhige dich, bevor ich mich beschuldige, einen unschuldigen Open-Source-Entwickler beschimpft zu haben.</i>  <i>Die Person hinter dem Paket <i>python-gmaps bin</i> ich.</i>  <i>Eine schlechte Wahl der Abhängigkeiten ist eines der Probleme dieses Projekts.</i>  <i>Ich kritisiere mich nur gerne von Zeit zu Zeit öffentlich.</i>  <i>Dies wird eine bittere Lektion für mich sein, da <i>Python-gmaps</i> in der neuesten Version (0.3.1 zum Zeitpunkt des Schreibens) nicht einfach in Pythons asynchrones I / O integriert werden kann.</i>  <i>In jedem Fall kann sich dies in Zukunft ändern, sodass nichts verloren geht.</i> <br></blockquote>  Da wir die Einschränkungen der Bibliothek kennen, die in den vorherigen Beispielen so einfach zu verwenden war, müssen wir etwas erstellen, das diese Lücke füllt.  Google MapsAPI ist sehr einfach zu bedienen. Wir werden daher zur Veranschaulichung ein asynchrones Hilfsprogramm entwickeln.  In der Standardbibliothek von Python 3.5 fehlt noch eine Bibliothek, die asynchrone HTTP-Anforderungen so einfach ausführen kann wie das Aufrufen von <i>urllib.urlopen ()</i> .  Wir möchten definitiv keine vollständige Protokollunterstützung von Grund auf erstellen, daher werden wir eine kleine Hilfe aus dem in <i>PyPI</i> verfügbaren <i>aiohttp-</i> Paket verwenden.  Dies ist eine vielversprechende Bibliothek, die sowohl Client- als auch Serverimplementierungen für asynchrones HTTP hinzufügt.  Hier ist ein kleines Modul, das auf <i>aiohttp aufbaut</i> und eine <i>Geocode () -</i> <i>Hilfsfunktion</i> erstellt, mit der <i>Geocodierungsanforderungen</i> an den Google Maps-API-Dienst ausgeführt werden: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> aiohttp session = aiohttp.ClientSession() <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">geocode</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> params = { <span class="hljs-string"><span class="hljs-string">'sensor'</span></span>: <span class="hljs-string"><span class="hljs-string">'false'</span></span>, <span class="hljs-string"><span class="hljs-string">'address'</span></span>: place } <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> session.get( <span class="hljs-string"><span class="hljs-string">'https://maps.googleapis.com/maps/api/geocode/json'</span></span>, params=params ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> response: result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> response.json() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-string"><span class="hljs-string">'results'</span></span>]</code> </pre><br><br>  Nehmen wir an, dass dieser Code in einem Modul mit dem Namen <i>asyncgmaps</i> gespeichert ist, das wir später verwenden werden.  Jetzt können wir das Beispiel für Multithreading und Multiprocessing neu schreiben.  Bisher haben wir den gesamten Vorgang in zwei separate Phasen unterteilt: <br><br><ol><li>  Erfüllen Sie alle Anfragen an den externen Dienst parallel mit der Funktion <i>fetch_place ()</i> . </li><li>  <i>Zeigen Sie</i> mit der Funktion <i>present_result ()</i> alle Ergebnisse in einer Schleife an. </li></ol><br>  Da sich kollaboratives Multitasking jedoch grundlegend von der Verwendung mehrerer Prozesse oder Threads unterscheidet, können wir unseren Ansatz leicht ändern.  Die meisten Probleme, die bei der Verwendung eines einzelnen Threads pro Element auftreten, sind nicht länger unser Anliegen. <br>  Coroutinen sind nicht präemptiv, daher können wir die Ergebnisse sofort nach Erhalt der HTTP-Antworten problemlos anzeigen.  Dies wird unseren Code vereinfachen und verständlicher machen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-comment"><span class="hljs-comment"># note: local module introduced earlier from asyncgmaps import geocode, session PLACES = ( 'Reykjavik', 'Vien', 'Zadar', 'Venice', 'Wrocław', 'Bolognia', 'Berlin', 'Słubice', 'New York', 'Dehli', ) async def fetch_place(place): return (await geocode(place))[0] async def present_result(result): geocoded = await result print("{:&gt;25s}, {:6.2f}, {:6.2f}".format( geocoded['formatted_address'], geocoded['geometry']['location']['lat'], geocoded['geometry']['location']['lng'], )) async def main(): await asyncio.wait([ present_result(fetch_place(place)) for place in PLACES ]) if __name__ == "__main__": loop = asyncio.get_event_loop() loop.run_until_complete(main()) # aiohttp will raise issue about unclosed # ClientSession so we perform cleanup manually loop.run_until_complete(session.close()) loop.close()</span></span></code> </pre><br><br>  Die asynchrone Programmierung eignet sich hervorragend für Back-End-Entwickler, die skalierbare Anwendungen erstellen möchten.  In der Praxis ist dies eines der wichtigsten Tools für die Erstellung von Servern mit hohem Wettbewerbsdruck. <br><br>  Aber die Realität ist traurig.  Viele beliebte Pakete, die sich mit E / A-Problemen befassen, sind nicht für die Verwendung mit asynchronem Code vorgesehen.  Die Hauptgründe dafür sind: <br><br><ul><li>  Noch immer wenig Implementierung von Python 3 und einigen seiner erweiterten Funktionen </li><li>  Geringes Verständnis für verschiedene Nebenläufigkeitskonzepte bei Anfängern zum Erlernen von Python </li></ul><br>  Dies bedeutet, dass die Migration vorhandener synchroner Multithread-Anwendungen und -Pakete häufig entweder nicht möglich (aufgrund architektonischer Einschränkungen) oder zu teuer ist.  Viele Projekte könnten von der Implementierung des asynchronen Multitasking-Stils stark profitieren, aber nur wenige werden dies letztendlich tun.  Dies bedeutet, dass Sie von Anfang an Schwierigkeiten haben werden, asynchrone Anwendungen zu erstellen.  In den meisten Fällen ähnelt dies dem im Abschnitt „Praktisches Beispiel für asynchrone Programmierung“ genannten Problem: Inkompatible Schnittstellen und nicht synchrones Blockieren von E / A-Vorgängen.  Natürlich kann es manchmal vorkommen, dass Sie das Warten aufgeben, wenn eine solche Inkompatibilität auftritt, und nur synchron die erforderlichen Ressourcen abrufen.  Dies verhindert jedoch, dass sich die Coroutine gegenseitig den Code ausführt, während Sie auf die Ergebnisse warten.  Technisch funktioniert dies, zerstört aber auch alle Vorteile der asynchronen Programmierung.  Daher ist die Kombination von asynchroner E / A mit synchroner E / A letztendlich keine Option.  Dies ist ein Alles-oder-Nichts-Spiel. <br><br>  Ein weiteres Problem sind langwierige prozessorgebundene Operationen.  Wenn Sie eine E / A-Operation ausführen, ist es kein Problem, die Steuerung von einer Coroutine freizugeben.  Wenn Sie von einem Dateisystem oder Socket aus schreiben / lesen, werden Sie eventuell warten, sodass ein Aufruf mit wait das Beste ist, was Sie tun können.  Aber was ist, wenn Sie etwas berechnen müssen und wissen, dass es einige Zeit dauern wird?  Natürlich können Sie das Problem in Teile aufteilen und die Kontrolle jedes Mal abbrechen, wenn Sie die Arbeit ein wenig vorantreiben.  Aber bald werden Sie feststellen, dass dies kein sehr gutes Modell ist.  So etwas kann den Code unordentlich machen und garantiert auch keine guten Ergebnisse. <br><br>  Die zeitliche Bindung sollte in der Verantwortung des Interpreters oder des Betriebssystems liegen. <br><br><h4>  Kombination von asynchronem Code mit asynchronen Zukünften </h4><br>  Was ist also zu tun, wenn Sie Code haben, der lange synchrone E / A-Vorgänge ausführt, die Sie nicht umschreiben können oder wollen?  Oder was tun, wenn Sie in einer Anwendung, die hauptsächlich für asynchrone E / A konzipiert ist, einige schwere Prozessoroperationen ausführen müssen?  Nun ... Sie müssen eine Problemumgehung finden.  Und damit meine ich Multithreading oder Multiprocessing. <br><br>  Das hört sich vielleicht nicht sehr gut an, aber manchmal ist die beste Lösung das, wovon wir versucht haben wegzukommen.  Die parallele Verarbeitung von ressourcenintensiven Aufgaben in Python wird aufgrund der Mehrfachverarbeitung immer besser ausgeführt.  Multithreading kann E / A-Vorgänge gleichermaßen gut (schnell und ohne große Ressourcen) verarbeiten, da es asynchron ist und wartet, wenn es ordnungsgemäß konfiguriert und sorgfältig behandelt wird. <br><br>  Wenn Sie also manchmal nicht wissen, was zu tun ist, wenn etwas nicht in Ihre asynchrone Anwendung passt, verwenden Sie einen Code, der es in einen separaten Thread oder Prozess stellt.  Sie können so tun, als ob es sich um eine Koroutine handelt, die Steuerung für die Ereignisschleife freigeben und die Ergebnisse schließlich verarbeiten, wenn sie bereit sind. <br><br>  Glücklicherweise bietet die Python-Standardbibliothek das <i>concurrent.futures-</i> Modul, das auch in das <i>asyncio-</i> Modul integriert ist.  Zusammen ermöglichen diese beiden Module das Planen von Blockierungsfunktionen, die in Threads oder zusätzlichen Prozessen ausgeführt werden, als wären sie asynchrone, nicht blockierende Coroutinen. <br><br><h4>  Executors und Futures </h4><br>  Bevor wir uns mit dem Einbetten von Threads oder Prozessen in eine asynchrone Ereignisschleife befassen, schauen wir uns das <i>concurrent.futures-</i> Modul genauer an, das später die Hauptkomponente unserer so genannten Problemumgehung sein wird. <br><br>  Die wichtigsten Klassen im Modul <i>concurrent.futures</i> sind <i>Executor</i> und <i>Future</i> . <br><br>  <i>Executor</i> ist ein Ressourcenpool, der Workitems parallel verarbeiten kann.  Es mag in seinem Zweck den Klassen des Multiprozessor-Moduls - <i>Pool</i> und <i>dummy.Pool</i> - sehr ähnlich <i>erscheinen</i> , hat aber eine völlig andere Schnittstelle und Semantik.  Dies ist eine Basisklasse, die nicht implementiert werden soll und zwei spezifische Implementierungen aufweist: <br><br><ul><li>  <i>ThreadPoolExecutor</i> : repräsentiert einen Thread-Pool </li><li>  <i>ProcessPoolExecutor</i> : repräsentiert einen Prozesspool </li></ul><br>  Jeder <i>Executor</i> stellt drei Methoden vor: <br><br><ul><li>  <i>submit (fn, * args, ** kwargs)</i> : <i>Plant</i> die Ausführung der Funktion fn im Ressourcenpool und gibt ein Future-Objekt zurück, das die Ausführung des aufgerufenen Objekts darstellt </li><li>  <i>map (func, * iterables, timeout = None, chunksize = 1)</i> : Die Funktion <i>func</i> wird bei der Iteration ähnlich wie bei der <i>Mehrfachverarbeitung</i> ausgeführt.  <i>Pool.map () -</i> Methode </li><li>  <i>shutdown (wait = True)</i> : Hiermit wird der <i>Executor</i> heruntergefahren und alle seine Ressourcen <i>freigegeben</i> . </li></ul><br>  Die interessanteste Methode ist <i>submit (),</i> da das Future-Objekt zurückgegeben wird.  Es repräsentiert die asynchrone Ausführung des aufgerufenen und nur indirekt dessen Ergebnis.  Um den tatsächlichen Rückgabewert des versendeten aufgerufenen Objekts <i>abzurufen</i> , müssen Sie die <i>Future.result ()</i> -Methode <i>aufrufen</i> .  Und wenn das aufgerufene Objekt bereits abgeschlossen ist, blockiert die Methode <i>result ()</i> es nicht und gibt einfach die Ausgabe der Funktion zurück.  Ist dies nicht der Fall, blockiert er es, bis das Ergebnis fertig ist.  Stellen Sie es sich als Versprechen eines Ergebnisses vor (es ist eigentlich dasselbe Konzept wie ein Versprechen in JavaScript).  Sie müssen es nicht sofort nach Erhalt entpacken (mithilfe der <i>result () -</i> Methode), aber wenn Sie dies versuchen, wird es garantiert irgendwann etwas zurückgeben: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; def loudy_return(): ... print("processing") ... return 42 ... &gt;&gt;&gt; from concurrent.futures import ThreadPoolExecutor &gt;&gt;&gt; with ThreadPoolExecutor(1) as executor: ... future = executor.submit(loudy_return) ... processing &gt;&gt;&gt; future &lt;Future at 0x33cbf98 state=finished returned int&gt; &gt;&gt;&gt; future.result() 42</code></b> </pre><br><br>  Wenn Sie die <i>Executor.map ()</i> -Methode verwenden möchten, unterscheidet sie sich nicht von der <i>Pool.map ()</i> -Methode der <i>Pool-</i> Klasse des Multiprozessor-Moduls: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> ThreadPoolExecutor(POOL_SIZE) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pool: results = pool.map(fetch_place, PLACES) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> result <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> results: present_result(result)</code> </pre><br><br><h4>  Verwenden von <i>Executor</i> in einer Ereignisschleife </h4><br>  Die von der <i>Executor.submit ()</i> -Methode zurückgegebenen Instanzen der Future-Klasse sind konzeptionell den bei der asynchronen Programmierung verwendeten Coroutinen sehr ähnlich.  Aus diesem Grund können wir Künstler einsetzen, um eine Mischung aus kollaborativem Multitasking und Multiprocessing oder Multithreading zu erstellen. <br><br>  Der Kern dieser <i>Problemumgehung</i> ist die <i>BaseEventLoop.run_in_executor-Methode (executor, func, * args)</i> der <i>Ereignisschleifenklasse</i> .  Auf diese Weise können Sie die Ausführung der func-Funktion in einem durch das executor-Argument dargestellten Prozess oder Thread-Pool planen.  Das Wichtigste an dieser Methode ist, dass sie das neue erwartete Objekt zurückgibt (das Objekt, das mit dem Operator await erwartet werden kann).  Auf diese Weise können Sie eine Blockierungsfunktion ausführen, die nicht genau wie eine Coroutine ist, und die nicht blockiert, egal wie lange es dauert, bis sie abgeschlossen ist.  Es wird nur die Funktion gestoppt, die Ergebnisse von einem solchen Aufruf erwartet, aber der gesamte Zyklus von Ereignissen wird fortgesetzt. <br><br>  Und eine nützliche Tatsache ist, dass Sie nicht einmal Ihre eigene Executor-Instanz erstellen müssen.  Wenn Sie <i>None</i> als Argument an <i>executor übergeben</i> , wird die <i>ThreadPoolExecutor-</i> Klasse mit der Standardanzahl von Threads verwendet (für Python 3.5 ist dies die Anzahl der Prozessoren multipliziert mit 5). <br><br>  Nehmen wir also an, wir wollten den problematischen Teil des python-gmaps-Pakets, der unsere Kopfschmerzen verursacht hat, nicht umschreiben.  Wir können einen blockierenden Aufruf an einen separaten Thread einfach verschieben, indem <i>wir loop.run_in_executor ()</i> aufrufen und dabei die Funktion fetch_place () als erwartete Coroutine belassen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch_place</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> coro = loop.run_in_executor(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, api.geocode, place) result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> coro <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine solche Lösung ist schlimmer als eine vollständig asynchrone Bibliothek, aber Sie wissen, dass zumindest etwas besser ist als nichts. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nachdem wir erklärt hatten, was Parallelität wirklich ist, haben wir Maßnahmen ergriffen und eines der typischen Parallelprobleme mithilfe von Multithreading analysiert. Nachdem wir die Hauptmängel unseres Codes identifiziert und korrigiert hatten, wandten wir uns der Mehrfachverarbeitung zu, um zu sehen, wie dies in unserem Fall funktionieren würde. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Danach stellten wir fest, dass die Verwendung mehrerer Prozesse mit einem Multiprozessor-Modul viel einfacher ist als grundlegende Threads mit Multithreading. Erst danach wurde uns klar, dass wir dank </font><i><font style="vertical-align: inherit;">multiprocessing.dummy</font></i><font style="vertical-align: inherit;"> dieselbe API für Threads verwenden können</font></font><i><font style="vertical-align: inherit;"></font></i> .  ,          ,     ,       . <br><br>    ,  -   ,       ,    / ,   ,          .  ,   ,    ,   ! <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und das führt uns zum endgültigen Abschluss dieses Kapitels. </font><font style="vertical-align: inherit;">Es gibt keine Lösung, die allen zusagt. </font><font style="vertical-align: inherit;">Es gibt verschiedene Ansätze, die Sie bevorzugen oder bevorzugen. </font><font style="vertical-align: inherit;">Es gibt einige Ansätze, die für diese Problematik besser geeignet sind, aber Sie müssen alle kennen, um erfolgreich zu sein. </font><font style="vertical-align: inherit;">In realistischen Szenarien können Sie das gesamte Arsenal an Werkzeugen und Parallelitätsstilen in einer Anwendung verwenden. Dies ist keine Seltenheit. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die vorherige Schlussfolgerung ist eine hervorragende Einführung in das Thema des nächsten Kapitels, Kapitel 14 „Nützliche Entwurfsmuster“. </font><font style="vertical-align: inherit;">Da es keine einzige Vorlage gibt, die alle Ihre Probleme löst. </font><font style="vertical-align: inherit;">Sie sollten so viel wie möglich wissen, denn letztendlich werden Sie sie jeden Tag verwenden.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de484446/">https://habr.com/ru/post/de484446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de484436/index.html">Ungrateful Opensource: Der Entwickler des schnellsten Webservers hat sein Repository gelöscht - Wichtiges Update</a></li>
<li><a href="../de484438/index.html">Berühmte Flüssigkeitsgleichungen sind durchgesickert</a></li>
<li><a href="../de484440/index.html">Vollständige Sicherung mit Standard-Windows-Tools</a></li>
<li><a href="../de484442/index.html">SNMPv3-Beispiel</a></li>
<li><a href="../de484444/index.html">Wie sich die Betriebsbedingungen auf die Batterie auswirken oder wie sich die Geschichte einer wundersamen Auferstehung auswirkt</a></li>
<li><a href="../de484448/index.html">DEFCON-Konferenz 27. Hacken Sie die Polizei. Teil 1</a></li>
<li><a href="../de484454/index.html">Habra Detektiv: Ihr Bild ist verloren</a></li>
<li><a href="../de484456/index.html">ReactJS, serverseitiges Rendering und einige Feinheiten bei der Verarbeitung von Seiten-Metatags</a></li>
<li><a href="../de484458/index.html">Dieser Freiberufler ist kaputt - gib mir den nächsten</a></li>
<li><a href="../de484462/index.html">Scraping Github: Suche nach "Geheimnissen", die es zu entwickeln gilt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
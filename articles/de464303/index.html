<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîØ üçê üê∏ Zeitreihendaten in einem relationalen DBMS. Erweiterungen TimescaleDB und PipelineDB f√ºr PostgreSQL üî± üëãüèø üôÖüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Zeitreihendaten oder Zeitreihen sind Daten, die sich im Laufe der Zeit √§ndern. W√§hrungskurse, Telemetrie von Transportbewegungen, Statistiken des Serv...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Zeitreihendaten in einem relationalen DBMS. Erweiterungen TimescaleDB und PipelineDB f√ºr PostgreSQL</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/464303/">  Zeitreihendaten oder Zeitreihen sind Daten, die sich im Laufe der Zeit √§ndern.  W√§hrungskurse, Telemetrie von Transportbewegungen, Statistiken des Serverzugriffs oder der CPU-Auslastung sind Zeitreihendaten.  Zum Speichern sind spezielle Tools erforderlich - tempor√§re Datenbanken.  Es gibt Dutzende von Tools, zum Beispiel InfluxDB oder ClickHouse.  Aber auch die besten Zeitreihen-Speicherl√∂sungen haben Nachteile.  Alle Zeitreihenspeicher sind auf niedrigem Niveau und nur f√ºr Zeitreihendaten geeignet. Das Ausf√ºhren und Injizieren in den aktuellen Stapel ist teuer und schmerzhaft. <br><br><img src="https://habrastorage.org/webt/sx/9x/bz/sx9xbzv26lix6lh-frspdsopknw.jpeg"><br><br>  Wenn Sie jedoch einen PostgreSQL-Stack haben, k√∂nnen Sie InfluxDB und alle anderen tempor√§ren Datenbanken vergessen.  Installieren Sie zwei Erweiterungen, TimescaleDB und PipelineDB, und speichern, verarbeiten und analysieren Sie Zeitreihendaten direkt im PostgreSQL-√ñkosystem.  Ohne die Einf√ºhrung von L√∂sungen von Drittanbietern, ohne die Nachteile von Zeitspeichern und ohne die Probleme, diese einzuf√ºhren.  Was sind diese Erweiterungen, was sind ihre Vorteile und F√§higkeiten, wird <b>Ivan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Muratov</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">binakot</a> )</b> - dem Leiter der Entwicklungsabteilung in der "First Monitoring Company" - sagen. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3WkNp7mllv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Was sind Zeitreihendaten oder Zeitreihen? </h2><br><blockquote>  Dies sind Daten √ºber den Prozess, die an verschiedenen Punkten in seinem Leben gesammelt werden. </blockquote><br>  Zum Beispiel der Standort des Autos: Geschwindigkeit, Koordinaten, Richtung oder die Verwendung von Ressourcen auf dem Server mit Daten zur Belastung der CPU, verwendetem RAM und freiem Speicherplatz. <br><br>  Zeitreihen haben mehrere Funktionen. <br><br><ul><li>  In einem <b>Befestigungsgurt</b> .  Jeder Zeitreihendatensatz enth√§lt ein Feld mit einem Zeitstempel, in dem der Wert aufgezeichnet wurde. <br></li><li>  <b>Die Eigenschaften des Prozesses, die als Ebenen der Serie bezeichnet werden</b> : Geschwindigkeit, Koordinaten, Lastdaten. <br></li><li>  Fast immer arbeiten sie mit solchen Daten <b>im Nur-Anh√§ngen-Modus</b> .  Dies bedeutet, dass die neuen Daten die alten nicht ersetzen.  Es werden nur veraltete Daten gel√∂scht. <br></li><li>  <b>Eintr√§ge werden nicht getrennt voneinander betrachtet</b> .  Daten werden nur gemeinsam f√ºr Zeitfenster, Intervalle oder Zeitr√§ume verwendet. <br></li></ul><br><h3>  Beliebte Speicherl√∂sungen </h3><br>  Die Grafik, die ich von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">db-engines.com aufgenommen habe,</a> zeigt die Beliebtheit verschiedener Speichermodelle in den letzten zwei Jahren. <br><br><img src="https://habrastorage.org/webt/w2/wf/_u/w2wf_uryfor_djey8enzmrskywo.jpeg"><br><br>  Die f√ºhrende Position nehmen Zeitreihenspeicher ein, zweitens - Graphendatenbanken, dann - Schl√ºsselwert- und relationale Datenbanken.  Die Popularit√§t spezialisierter Repositories ist mit einem intensiven Wachstum bei der Integration von Informationstechnologien verbunden: Big Data, soziale Netzwerke, IoT, √úberwachung der Hochlastinfrastruktur.  Neben n√ºtzlichen Gesch√§ftsdaten beanspruchen auch Protokolle und Metriken eine enorme Menge an Ressourcen. <br><br><h3>  Beliebte Speicherl√∂sungen f√ºr Zeitreihendaten </h3><br>  Die Grafik zeigt spezielle L√∂sungen zum Speichern von Zeitreihendaten.  Die Skala ist logarithmisch. <br><br><img src="https://habrastorage.org/webt/ny/bz/6_/nybz6_-_3ce7t0y7xre1oxkbks8.jpeg"><br><br>  Stabiler Anf√ºhrer InfluxDB.  Jeder, der auf Zeitreihendaten gesto√üen ist, hat von diesem Produkt geh√∂rt.  Die Grafik zeigt jedoch eine Verzehnfachung von TimescaleDB - eine Erweiterung des relationalen DBMS k√§mpft um einen Platz unter der Sonne unter den Produkten, die urspr√ºnglich im Rahmen der Zeitreihen entwickelt wurden. <br><br><blockquote>  PostgreSQL ist nicht nur eine gute Datenbank, sondern auch eine erweiterbare Plattform f√ºr die Entwicklung spezialisierter L√∂sungen. </blockquote><br><h2>  Postgres, Postgis und TimescaleDB </h2><br>  Die First Monitoring Company √ºberwacht die Bewegung von Fahrzeugen mithilfe von Satelliten.  Wir verfolgen 20.000 Fahrzeuge und speichern zwei Jahre lang Bewegungsdaten.  Insgesamt verf√ºgen wir √ºber 10 TB aktuelle Telemetriedaten.  Im Durchschnitt sendet jedes Fahrzeug w√§hrend der Fahrt 5 Telemetrie-Aufzeichnungen pro Minute.  Die Daten werden √ºber Navigationsger√§te an unsere Telematikserver gesendet.  Sie erhalten 500 Navigationspakete pro Sekunde. <br><br>  Vor einiger Zeit haben wir beschlossen, die Infrastruktur global zu aktualisieren und von einem Monolithen auf Microservices umzusteigen.  Wir haben das neue System Waliot genannt und es ist bereits in Produktion - 90% aller Fahrzeuge werden darauf √ºbertragen. <br><br>  In der Infrastruktur hat sich viel ge√§ndert, aber die zentrale Verbindung ist unver√§ndert geblieben - dies ist die PostgreSQL-Datenbank.  Jetzt arbeiten wir an Version 10 und bereiten die Umstellung auf 11 vor. Zus√§tzlich zu PostgreSQL als Hauptspeicher verwenden wir PostGIS f√ºr Geodaten im Stack und TimescaleDB zum Speichern einer gro√üen Anzahl von Zeitreihendaten. <br><br><h3>  Warum PostgreSQL? </h3><br>  Warum versuchen wir, eine relationale Datenbank zum Speichern von Zeitreihen zu verwenden, anstatt <s>ClickHouse-</s> Speziall√∂sungen f√ºr diesen Datentyp?  Vor dem Hintergrund des gesammelten Fachwissens und der Eindr√ºcke der Arbeit mit PostgreSQL m√∂chten wir keine unbekannte L√∂sung als Hauptspeicher verwenden. <br><br><blockquote>  Der Wechsel zu einer neuen L√∂sung ist ein Risiko. </blockquote><br>  Es gibt viele spezielle L√∂sungen zum Speichern und Verarbeiten von Zeitreihendaten.  Dokumentation ist nicht immer genug und eine gro√üe Auswahl an L√∂sungen ist nicht immer gut.  Es scheint, dass die Entwickler jedes neuen Produkts alles von Grund auf neu schreiben m√∂chten, da in der vorherigen L√∂sung etwas nicht angenehm war.  Um zu verstehen, was genau nicht gefallen hat, m√ºssen Sie nach Informationen suchen, analysieren und vergleichen.  Eine Vielzahl von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tops</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bewertungen</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vergleichen sind</a> eher be√§ngstigend als motivierend, etwas auszuprobieren.  Sie m√ºssen viel Zeit aufwenden, um alle L√∂sungen selbst auszuprobieren.  Wir k√∂nnen es uns nicht leisten, mehrere Monate lang nur eine L√∂sung anzupassen.  Dies ist eine schwierige Aufgabe, und die aufgewendete Zeit wird sich nie auszahlen.  Aus diesem Grund haben wir Erweiterungen f√ºr PostgreSQL ausgew√§hlt. <br><br>  W√§hrend der Entwicklungsphase der Waliot-Infrastruktur betrachteten wir InfluxDB als das Haupt-Telemetrie-Repository.  Aber als ich auf TimescaleDB stie√ü und Tests daran durchf√ºhrte, gab es keine Fragen zur Auswahl.  Mit PostgreSQL mit der Erweiterung TimescaleDB k√∂nnen Sie andere Erweiterungen im selben PostGIS- oder PipelineDB-Speicher verwenden.  Wir m√ºssen keine Daten abrufen, transformieren, Analysen durchf√ºhren und √ºber das Netzwerk √ºbertragen.  Alles liegt auf einem Server oder in einem Clustersystem - Daten m√ºssen nicht gezogen werden.  Alle Berechnungen werden auf derselben Ebene durchgef√ºhrt. <br><br>  K√ºrzlich ver√∂ffentlichte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nikolay Samokhvalov</a> , der Autor des Postgresmen-Kontos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Link</a> zu einem interessanten Artikel √ºber die Verwendung von SQL f√ºr die Streaming-Datenverarbeitung.  F√ºnf von sechs Autoren des Artikels sind an der Entwicklung verschiedener Apache-Produkte beteiligt und arbeiten mit der Stream-Verarbeitung.  Daher werden in dem Artikel Apache Spark, Apache Flink, Apache Beam, Apache Calcite und KSQL von Confluent erw√§hnt. <br><br>  Aber nicht der Artikel selbst ist interessant, sondern das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Thema in den Hacker News</a> , in dem es diskutiert wird.  Der Autor des Themas schreibt, dass er basierend auf dem Artikel fast alle Ideen basierend auf PostgreSQL 11 implementiert hat. Er verwendete CitusDB-Erweiterungen f√ºr horizontale Skalierung und Sharding, PipelineDB f√ºr Stream-Computing und materialisierte Ansichten, TimescaleDB f√ºr die Speicherung von Zeitreihendaten und Schnitte.  Er verwendet auch mehrere Foreign Data Wrapper. <br><br><blockquote>  Eine verr√ºckte Mischung aus PostgreSQL und seinen Erweiterungen best√§tigt erneut, dass PostgreSQL nicht nur ein DBMS ist, sondern eine Plattform. </blockquote><br>  Und wann der steckbare Speicher geliefert wird ... Ugh! <br><br>  Ironischerweise fanden wir bei der Erforschung der L√∂sungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Outflux</a> , die Entwicklung des TimescaleDB-Teams, die am 1. April ver√∂ffentlicht wurde.  Was glaubst du, macht sie?  Dies ist ein Dienstprogramm f√ºr die Migration von InfluxDB zu TimescaleDB in einem Befehl ... <br><br><h3>  Postgres Hype! </h3><br>  Untersch√§tzen Sie nicht die Macht des Hype!  Wir scherzen oft, dass ‚ÄûEntwicklung von Hype getrieben wird‚Äú, weil dies unsere Wahrnehmung von Tuning- und Infrastrukturkomponenten beeinflusst.  Bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++</a> diskutieren wir viel √ºber PostgreSQL, ClickHouse, Tarantool - das sind Hype-Entwicklungen.  Sagen Sie nur nicht, dass dies keine Auswirkungen auf Ihre Vorlieben und die Auswahl der L√∂sungen f√ºr die Infrastruktur hat ... Nat√ºrlich ist dies nicht der Hauptfaktor, aber gibt es irgendwelche Auswirkungen? <br><br>  Ich arbeite seit 5 Jahren mit PostgreSQL.  Ich mag diese L√∂sung.  Er l√∂st fast alle meine Aufgaben mit einem Knall.  Jedes Mal, wenn mit dieser Basis etwas schief ging, waren meine krummen H√§nde schuld.  Daher war die Wahl vorbestimmt. <br><br><h2>  TimescaleDB VS PipelineDB </h2><br>  Fahren wir mit den Erweiterungen TimescaleDB und PipelineDB fort.  Was sagen ihre Sch√∂pfer √ºber Erweiterungen? <br><br>  <b>TimescaleDB ist eine</b> Open-Source- <b>Zeitreihendatenbank</b> , die f√ºr schnelles Einf√ºgen und komplexe Abfragen optimiert ist. <br><br>  <b>PipelineDB</b> ist eine leistungsstarke Erweiterung, mit der fortlaufende SQL-Abfragen <b>f√ºr Zeitreihendaten ausgef√ºhrt werden k√∂nnen</b> . <br><br>  Sie arbeiten nicht nur mit Zeitreihendaten, sondern haben auch eine √§hnliche Geschichte.  Timescale wurde 2015 und Pipeline 2013 gegr√ºndet. Die ersten Arbeitsversionen erschienen 2017 bzw. 2015.  Es dauerte zwei Jahre, bis die Teams die Mindestfunktionalit√§t freigegeben hatten.  Die Produktionsfreigaben beider Erweiterungen erfolgten im vergangenen Oktober mit einem Unterschied von einer Woche.  Anscheinend in Eile nacheinander. <br><br>  GitHub hat eine Reihe von Sternen und Gabeln, die wie √ºblich kein einziges Commit sind.  So funktioniert Open Source, es gibt nichts zu tun.  Aber es gibt viele Sterne, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TimescaleDB hat</a> mehr als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PipelineDB</a> und sogar mehr als PostgreSQL selbst. <br><br>  Erweiterungen scheinen √§hnlich zu sein, aber sie positionieren sich anders. <br><br>  <b>TimescaleDB</b> behauptet, Millionen von Datens√§tzen pro Sekunde eingef√ºgt und Hunderte von Milliarden Zeilen und Dutzende Terabyte Daten gespeichert zu haben.  Die Erweiterung ist schneller als InfluxDB, Cassandra, MongoDB oder Vanilla PostgreSQL.  Unterst√ºtzt Streaming-Replikations- und Sicherungstools.  TimescaleDB ist eine Erweiterung, keine Abzweigung von PostgreSQL. <br><br>  <b>PipelineDB</b> speichert nur das Ergebnis von Streaming-Berechnungen, ohne dass Rohdaten f√ºr ihre Berechnungen gespeichert werden m√ºssen.  Die Erweiterung kann kontinuierlich √ºber Echtzeitdatenstr√∂me aggregiert und mit herk√∂mmlichen Tabellen f√ºr Berechnungen im Kontext einer Dom√§nendom√§ne kombiniert werden.  PipelineDB ist eine Erweiterung, keine Abzweigung, aber urspr√ºnglich war es eine Abzweigung. <br><br><h2>  Timescaledb </h2><br>  Nun im Detail zu den Erweiterungen.  Beginnen wir mit TimescaleDB.  Ich arbeite seit fast 2 Jahren mit ihm.  Zog es vor der Release-Version in die Produktion.  Schauen wir uns Beispiele f√ºr die Anwendung an. <br><br>  <b>Speicher f√ºr Infrastrukturmetriken</b> .  Wir haben Docker-Container-Ressourcenverbrauchsmetriken, Metrik-Festschreibungszeit, Container-ID und Ressourcenverbrauchsfelder, z. B. freien Speicher.  Wir m√ºssen Statistiken f√ºr alle Container mit einer durchschnittlichen Anzahl von freien Speicherfenstern f√ºr 10 Sekunden anzeigen.  Die angezeigte Abfrage l√∂st dieses Problem, und TimescaleDB kann als Repository f√ºr Infrastrukturmetriken verwendet werden. <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'10 seconds'</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">time</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span>, container_id, <span class="hljs-keyword"><span class="hljs-keyword">avg</span></span>(free_mem) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> metrics <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-built_in"><span class="hljs-built_in">time</span></span> &lt; <span class="hljs-keyword"><span class="hljs-keyword">now</span></span>() - <span class="hljs-built_in"><span class="hljs-built_in">interval</span></span> <span class="hljs-string"><span class="hljs-string">'10 minutes'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span>, container_id <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span>, container_id;</code> </pre> <br><pre> <code class="plaintext hljs">period | container_id | avg -----------------------+--------------+--- 2019-06-24 12:01:00+00 | 16 | 72202 2019-06-24 12:01:00+00 | 73 | 837725 2019-06-24 12:01:00+00 | 96 | 412237 2019-06-24 12:00:50+00 | 16 | 1173393 2019-06-24 12:00:50+00 | 73 | 90104 2019-06-24 12:00:50+00 | 96 | 784596</code> </pre> <br>  <b>F√ºr Berechnungen</b> .  Wir m√ºssen die Anzahl der Lastwagen, die Krasnodar verlassen haben, und ihre Gesamttonnage in Tagen berechnen. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'1 day'</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">time</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> trucks_exiting, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(weight) / <span class="hljs-number"><span class="hljs-number">1000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> tonnage <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> vehicles <span class="hljs-keyword"><span class="hljs-keyword">INNER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> cities <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> cities.name = <span class="hljs-string"><span class="hljs-string">'Krasnodar'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> ST_Within(last_location, ST_Polygon(cities.geom, <span class="hljs-number"><span class="hljs-number">4326</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> ST_Within(current_location, ST_Polygon(cities.geom, <span class="hljs-number"><span class="hljs-number">4326</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span>;</code> </pre> <br>  Es verwendet auch Funktionen aus der PostGIS-Erweiterung, um den Transport zu berechnen, der die Stadt verlassen hat, anstatt sich nur darin zu bewegen. <br><br>  <b>W√§hrungskurs√ºberwachung</b> .  Das dritte Beispiel betrifft Kryptow√§hrungen.  Mit der Anfrage k√∂nnen Sie anzeigen, wie sich der Preis von Ethereum im Vergleich zu Bitcoin und dem US-Dollar in den letzten 2 Wochen pro Tag ver√§ndert hat. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'14 days'</span></span>, c.time) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">last</span></span>(c.closing_price, c.time) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> closing_price_btc, <span class="hljs-keyword"><span class="hljs-keyword">last</span></span>(c.closing_price, c.time) * <span class="hljs-keyword"><span class="hljs-keyword">last</span></span>(b.closing_price, c.time) filter (<span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> b.currency_code = <span class="hljs-string"><span class="hljs-string">'USD'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> closing_price_usd <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> crypto_prices c <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> btc_prices b <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> time_bucket(<span class="hljs-string"><span class="hljs-string">'1 day'</span></span>, c.time) = time_bucket(<span class="hljs-string"><span class="hljs-string">'1 day'</span></span>, b.time) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> c.currency_code = <span class="hljs-string"><span class="hljs-string">'ETH'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">period</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span>;</code> </pre> <br>  Dies ist alles klar und bequem f√ºr uns SQL. <br><br><h3>  Was ist so cool an TimescaleDB? </h3><br>  Warum nicht die integrierten Tabellenpartitionierungstools verwenden?  Und warum sich die M√ºhe machen, Tische zu brechen?  Die offensichtliche Antwort ist die <b>Einf√ºgegeschwindigkeit in solche Datenbanken</b> .  Die Grafik zeigt die tats√§chlichen Messungen der Einf√ºgungsrate der Anzahl der Zeilen pro Sekunde zwischen der regul√§ren Vanilletabelle PostgreSQL 10 ohne Schnitt und der Hypertabelle TimescaleDB. <br><br><img src="https://habrastorage.org/webt/gq/ln/xd/gqlnxdxeupbqkf_i-wdeihs0zlq.jpeg"><br><br>  Dieser Benchmark schreibt 1 Milliarde Zeilen auf einen Computer und simuliert ein Szenario zum Sammeln von Metriken aus der Infrastruktur.  Der Datensatz enth√§lt die Zeit, die Kennung der Infrastrukturkomponente und 10 Metriken.  Der Benchmark wurde auf Azure VM mit 8 Kernen und 28 Gigabyte RAM sowie Netzwerk-SSD-Laufwerken ausgef√ºhrt.  Das Einf√ºgen wurde in Chargen von 10 Tausend Datens√§tzen durchgef√ºhrt. <br><br>  Woher kommt eine solche Verschlechterung der PostgreSQL-Leistung?  Denn beim Einf√ºgen m√ºssen Sie auch die Tabellenindizes aktualisieren.  Wenn sie nicht in den Cache passen, beginnen wir, Festplatten zu laden.  Die Partitionierung l√∂st dieses Problem, wenn die Indizes des Abschnitts, in den wir die Daten einf√ºgen, im RAM abgelegt werden. <br><br>  Schauen wir uns die folgende Tabelle an.  Dies vergleicht das in PostgreSQL 10 integrierte deklarative Partitionierungssystem und die TimescaleDB-Hypertabelle.  Auf der horizontalen Achse die Anzahl der Abschnitte. <br><br><img src="https://habrastorage.org/webt/kd/dz/xd/kddzxdttzspi9peoiriem7sipms.jpeg"><br><br>  In TimescaleDB ist die Verschlechterung mit zunehmenden Abschnitten vernachl√§ssigbar.  Erweiterungsentwickler behaupten, dass sie mit 10.000 Abschnitten in einer einzelnen PostgreSQL-Instanz gut zurechtkommen. <br><br>  In PostgreSQL verschlechtert sich die native Implementierung nach 3.000 erheblich. Im Allgemeinen ist die deklarative Partitionierung in PostgreSQL ein gro√üer Fortschritt, funktioniert jedoch nur f√ºr Tabellen mit weniger Last.  Zum Beispiel f√ºr Waren, K√§ufer und andere Domain-Einheiten, die nicht so intensiv in das System eintreten wie Metriken. <br><br>  In 11 und 12 Versionen von PostgreSQL wird die native Partitionierungsunterst√ºtzung angezeigt, und Sie k√∂nnen versuchen, Vergleichstests f√ºr Zeitreihendaten mit neuen Versionen durchzuf√ºhren.  Aber es scheint mir, dass TimescaleDB immer noch besser ist.  Alle Benchmarks von TimescaleDB finden Sie auf ihrem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> und probieren Sie es aus. <br><br><h3>  Hauptmerkmale </h3><br>  Ich hoffe, Sie haben bereits Interesse an der Erweiterung.  Lassen Sie uns die Hauptfunktionen von TimescaleDB durchgehen, um dieses Gef√ºhl zu festigen. <br><br>  <b>Partitionierung durch Hypertabellen</b> .  TimescaleDB verwendet den Begriff "hypertable" f√ºr Tabellen, auf die die Funktion create_hypertable () angewendet wurde.  Danach wird die Tabelle zum √ºbergeordneten Element f√ºr alle geerbten Abschnitte - Chunks.  Die √ºbergeordnete Tabelle selbst enth√§lt keine Daten, ist jedoch ein Einstiegspunkt f√ºr alle Abfragen und eine Vorlage, wenn automatisch neue Abschnitte erstellt werden.  Alle Abschnitte werden nicht im Hauptschema Ihrer Daten gespeichert, sondern in einem speziellen Schema.  Dies ist praktisch, da im Datenschema nicht Tausende dieser Abschnitte angezeigt werden. <br><br>  <b>Die Erweiterung ist in den Scheduler und den Query Executor integriert</b> .  Durch spezielle Hooks in PostgreSQL versteht TimescaleDB, wann es auf eine Hypertabelle zugreift.  TimescaleDB analysiert die Abfrage und leitet die Abfragen nur an die erforderlichen Abschnitte weiter, basierend auf den im SQL-Aufruf selbst angegebenen Bedingungen.  Auf diese Weise k√∂nnen Sie die Arbeit w√§hrend der Extraktion einer erheblichen Datenmenge mit Abschnitten parallelisieren. <br><br>  <b>Durch die Erweiterung werden SQL keine Einschr√§nkungen auferlegt</b> .  Sie k√∂nnen Gewerkschaften, Aggregate, Fensterfunktionen, CTEs und zus√§tzliche Indizes frei verwenden.  Wenn Sie die Liste der Einschr√§nkungen f√ºr das integrierte Partitionierungssystem gesehen haben, sollte dies Ihnen gefallen. <br><br>  <b>Zus√§tzliche n√ºtzliche Funktionen</b> f√ºr Zeitreihendaten: <br><br><ul><li>  "Time_bucket" - "date_trun" einer gesunden Person; <br></li><li>  Histogramme - Ausf√ºllen der fehlenden Intervalle durch Interpolation oder den letzten bekannten Wert; <br></li><li>  Hintergrundarbeiter - Dienste, mit denen Sie Hintergrundvorg√§nge ausf√ºhren k√∂nnen: Bereinigen alter Abschnitte, Neuorganisation. <br></li></ul><br>  <b>Mit TimescaleDB k√∂nnen Sie im leistungsstarken PostgreSQL-√ñkosystem bleiben</b> .  Diese Erweiterung unterbricht PostgreSQL nicht, daher funktionieren alle Hochverf√ºgbarkeitsl√∂sungen, Sicherungssysteme und √úberwachungstools weiterhin.  TimescaleDB ist mit Grafana, Periscope, Prometheus, Telegraf, Zabbix, Kubernetes, Kafka, Seeq und JackDB befreundet. <br><br>  <b>Grafana</b> unterst√ºtzt TimescaleDB bereits nativ als Datenquelle.  Grafana versteht sofort, dass PostscreSQL √ºber TimescaleDB verf√ºgt.  Der Abfrage-Generator in Grafana in Dashboards versteht zus√§tzliche TimescaleDB-Funktionen wie "time_bucket", "first", "last".  Mit diesen Zeitreihenfunktionen k√∂nnen Sie Diagramme direkt aus der relationalen Datenbank ohne gigantische Abfragen erstellen. <br><br>  <b>Prometheus verf√ºgt √ºber</b> einen Adapter, mit dem Sie Daten zusammenf√ºhren und TimescaleDB als zuverl√§ssiges Data Warehouse verwenden k√∂nnen.  Verwenden Sie einen Adapter, um Daten jahrelang nicht in Prometheus zu speichern. <br><br>  Es gibt auch ein <b>Telegraf-Plugin</b> .  Mit der L√∂sung k√∂nnen Sie Prometheus vollst√§ndig entfernen.  Infrastrukturdaten werden sofort an TimescaleDB √ºbertragen und durch Telegraf gelesen. <br><br><h3>  Lizenzen und Neuigkeiten </h3><br>  Vor nicht allzu langer Zeit hat das Unternehmen auf ein neues Lizenzmodell umgestellt.  Der gr√∂√üte Teil des Codes ist unter Apache 2.0 lizenziert.  Ein kleiner Teil kann kostenlos verwendet werden, ist jedoch unter TSL lizenziert. <br><br>  Es gibt eine Enterprise-Version mit einer kommerziellen Lizenz.  Keine Sorge, nicht alle Extras in der Enterprise-Version.  Grunds√§tzlich gibt es Automatisierungen wie das automatische Entfernen veralteter Brocken, die durch ein einfaches "Cron" und √§hnliche Dinge erfolgen k√∂nnen. <br><br>  Jetzt arbeitet das Unternehmen aktiv an einer Clusterl√∂sung.  Vielleicht f√§llt es in die Enterprise-Version.  Es gibt auch eine Cloud-Version f√ºr Startups, die den Markteintritt schaffen m√∂chten, bevor den Anlegern das Geld ausgeht. <br><br>  Aus den Nachrichten: <br><br><ul><li>  eine Million Downloads in den letzten anderthalb Jahren; <br></li><li>  Investition von 31 Millionen US-Dollar; <br></li><li>  Aktive Zusammenarbeit mit MS Azure in Bezug auf IoT-L√∂sungen. <br></li></ul><br><h3>  Zusammenfassend </h3><br><blockquote>  TimescaleDB dient zum Speichern von Zeitreihendaten.  Dies ist ein leistungsstarkes Partitionierungssystem mit minimalen Einschr√§nkungen im Vergleich zu nativen in PostgreSQL. </blockquote><br>  Leider hat die Erweiterung noch keine Multinode-Version.  Wenn Sie einen Multimaster oder Shard m√∂chten, m√ºssen Sie beispielsweise mit CitusDB herumspielen.  Wenn Sie eine logische Replikation w√ºnschen, tut dies weh.  Aber es tut ihr immer weh. <br><br><h2>  Pipelinedb </h2><br>  Lassen Sie uns nun √ºber die zweite Erweiterung sprechen.  Leider konnten wir es im Kampf nicht richtig testen.  Jetzt durchl√§uft es die Phase der Anpassung in unserem System.  Es stimmt, es gibt ein Problem, √ºber das ich n√§her am Ende sprechen werde. <br><br>  Wie im vorherigen Fall beginnen wir mit realen Beispielen.  Es ist einfacher, die Vorteile der Erweiterung und die Motivation zu verstehen, sie zu verwenden. <br><br>  <b>Statistiksammlung</b> .  Stellen Sie sich vor, wir sammeln Statistiken √ºber Besuche auf unserer Website.  Wir ben√∂tigen eine Analyse der beliebtesten Seiten, die Anzahl der eindeutigen Benutzer und eine Vorstellung von Ressourcenverz√∂gerungen.  All dies sollte in Echtzeit aktualisiert werden.  Wir m√∂chten jedoch nicht jedes Mal die Datentabelle ber√ºhren und eine Abfrage erstellen oder die Ansicht oben auf der Tabelle aktualisieren. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> CONTINUOUS <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">url</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> total_count, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> cookie::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques, <span class="hljs-keyword"><span class="hljs-keyword">percentile_cont</span></span>(<span class="hljs-number"><span class="hljs-number">0.99</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">WITHIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> latency::<span class="hljs-built_in"><span class="hljs-built_in">integer</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> p99_latency <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> page_views <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">url</span></span>;</code> </pre> <br><pre> <code class="plaintext hljs">url | total_count | uniques | p99_latency -----------+-------------+---------+------------ some/url/0 | 633 | 51 | 178 some/url/1 | 688 | 37 | 139 some/url/2 | 508 | 88 | 121 some/url/3 | 848 | 36 | 59 some/url/4 | 126 | 64 | 159</code> </pre> <br>  Die Streaming-Verarbeitung und die PipelineDB-Erweiterung helfen dabei.  Die Erweiterung f√ºgt die Abstraktion CONTINUES VIEW hinzu.  In der russischen Version mag dies wie eine ‚Äûkontinuierliche Pr√§sentation‚Äú klingen.  Diese Ansicht wird automatisch aktualisiert, wenn sie mit den Aufzeichnungen der Besuche in die Tabelle eingef√ºgt wird, und zwar nur auf der Grundlage neuer Daten, ohne dass das bereits zuvor aufgezeichnete Lesen erfolgt. <br><br>  <b>Datenstrom</b> .  PipelineDB ist nicht nur auf den neuen Ansichtstyp beschr√§nkt.  Angenommen, wir f√ºhren A / B-Tests durch und sammeln Echtzeitanalysen zur Effektivit√§t einer neuen Gesch√§ftsl√∂sung.  Wir m√∂chten die Daten jedoch nicht selbst auf Benutzeraktionen speichern.  Wir sind nur am Ergebnis interessiert - welche Gruppe hat die meisten Conversions. <br><br>  Um die direkte Speicherung von Rohdaten f√ºr das Streaming-Computing zu vermeiden, ben√∂tigen wir eine Abstraktion wie <b>Streams - Data Stream</b> .  PipelineDB f√ºhrt diese Funktion ein.  Sie k√∂nnen Streams wie normale Tabellen erstellen.  Unter der Haube wird es "FOREIGN TABLE" sein, basierend auf der ZeroMQ-Warteschlange, die die Erweiterung von uns unmerklich verwendet.  Daten werden in die interne ZeroMQ-Warteschlange eingegeben und l√∂sen eine Aktualisierung der fortlaufenden Ansicht aus. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> STREAM ab_event_stream ( <span class="hljs-keyword"><span class="hljs-keyword">name</span></span> <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>, ab_group <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>, event_type <span class="hljs-built_in"><span class="hljs-built_in">varchar</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>), cookie <span class="hljs-built_in"><span class="hljs-built_in">varchar</span></span>(<span class="hljs-number"><span class="hljs-number">32</span></span>) ); <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> CONTINUOUS <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> ab_test_monitor <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, ab_group, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> WHENevent_type = <span class="hljs-string"><span class="hljs-string">'v'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ELSE</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> view_count, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> WHENevent_type = <span class="hljs-string"><span class="hljs-string">'c'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ELSE</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> conversion_count, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> cookie) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ab_event_stream <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, ab_group;</code> </pre> <br>  Dann erstellen wir "CONTINUOUS VIEW" basierend auf Daten aus einem zuvor erstellten Stream.  Wenn die Daten im Stream ankommen, wird die Ansicht basierend auf diesen Daten aktualisiert.  Danach werden die Daten einfach verworfen, nirgendwo gespeichert und belegen keinen Speicherplatz.  Auf diese Weise k√∂nnen Sie Analysen f√ºr eine nahezu unbegrenzte Datenmenge erstellen, diese in den PipelineDB-Datenstrom laden und das Berechnungsergebnis aus einer kontinuierlichen Ansicht lesen. <br><br>  <b>Stream Computing</b>  Nachdem wir den Datenstrom und die kontinuierliche Ansicht erstellt haben, k√∂nnen wir mit Stream Computing arbeiten.  Es sieht so aus. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> ab_event_stream (<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, ab_group, event_type, cookie) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">round</span></span>(random() * <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">round</span></span>(random() * <span class="hljs-number"><span class="hljs-number">4</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> ab_group, (<span class="hljs-keyword"><span class="hljs-keyword">CASE</span></span> WHENrandom() &gt; <span class="hljs-number"><span class="hljs-number">0.4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">THEN</span></span> <span class="hljs-string"><span class="hljs-string">'v'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ELSE</span></span> <span class="hljs-string"><span class="hljs-string">'c'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> event_type, <span class="hljs-keyword"><span class="hljs-keyword">md5</span></span>(random()::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> cookie <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">100000</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ab_group, uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ab_test_monitor; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ab_group, view_count * <span class="hljs-number"><span class="hljs-number">100</span></span> / (conversion_count + view_count) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> conversion_rate <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ab_test_monitor;</code> </pre> <br>  Das erste "SELECT" gibt die Gruppe "ab" und die Anzahl der eindeutigen Besucher an.  Die zweite - gibt das Verh√§ltnis zwischen den Gruppen an - Umwandlung.  Das ist alles A / B-Testen bei f√ºnf SQL-Aufrufen in einer relationalen Datenbank. <br><br>  Die Ansicht wird dynamisch aktualisiert.  Sie k√∂nnen nicht auf die Verarbeitung des gesamten Datenarrays warten, sondern bereits verarbeitete Zwischenergebnisse lesen.  Ansichten werden wie normales PostgreSQL gelesen.  Sie k√∂nnen eine Ansicht auch mit Tabellen oder sogar anderen Ansichten kombinieren.  Es gibt keine Einschr√§nkungen. <br><br><h3>  Topologie </h3><br>  Kafka empf√§ngt Telemetrie, das Thema in Kafka sendet diese Daten an PostgreSQL und wir aggregieren sie weiter.  Zum Beispiel kombinieren wir mit einer gew√∂hnlichen Tabelle und leiten die Daten in den Stream um.  Ferner provoziert er die Aktualisierung der entsprechenden fortlaufenden Pr√§sentation, aus der die Datenbankclients bereits die fertigen Daten lesen k√∂nnen. <br><br><img src="https://habrastorage.org/webt/0e/4p/zb/0e4pzbehsh35td5tdiillcaq82m.jpeg"><br><br>  <i>Ein Beispiel f√ºr die Topologie von PipelineDB-Komponenten in PostgreSQL.</i>  <i>Die Strecke ist einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pr√§sentation von</a> Derek Nelson entlehnt.</i> <br><br>  Neben Streams und Ansichten bietet die Erweiterung auch eine Abstraktion von "Transform" - Konvertern oder Mutatoren.  Diese Ansicht zielte jedoch darauf ab, den eingehenden Datenstrom in eine modifizierte Ausgabe umzuwandeln.  Mit diesen Mutatoren k√∂nnen Sie die Darstellung der Daten √§ndern oder filtern.  Vom Mutator f√§llt alles in die Ansicht CONTINUOUS VIEW.  Wir stellen bereits gesch√§ftliche Anfragen.  Jeder, der mit funktionaler Programmierung vertraut ist, sollte die Idee verstehen. <br><br>  In PipelineDB k√∂nnen wir einen Ausl√∂ser an unsere Ansichten h√§ngen und Aktionen ausf√ºhren, z. B. "Warnung".  Bei all diesen Berechnungen speichern wir die Rohdaten niemals selbst, auf deren Grundlage wir sie alle berechnen.  Dies k√∂nnen Terabyte sein, die wir nacheinander auf einen Server mit einer 100-Gigabyte-Festplatte hochladen.  Schlie√ülich interessiert uns nur das Ergebnis von Berechnungen. <br><br><h3>  Hauptmerkmale </h3><br>  Die PipelineDB-Erweiterung ist schwieriger zu erlernen als TimescaleDB.  In TimescaleDB erstellen wir eine Tabelle, teilen ihr mit, dass sie eine Hypertabelle ist, und genie√üen das Leben mit mehreren zus√§tzlichen Funktionen, die die Erweiterung bietet. <br><br>  <b>PipelineDB l√∂st das Problem des Streaming Computing in relationalen Datenbanken</b> .  Die Aufgabe der Streaming-Datenverarbeitung ist hinsichtlich Integration und Verwendung komplizierter als die Partitionierung.  Allerdings hat nicht jeder riesige Datenmengen und Milliarden von Zeilen.  Warum die Infrastruktur komplizieren, wenn es PipelineDB gibt?  Die Erweiterung bietet eigene Implementierungen von Darstellungen, Streams, Konvertern und Aggregaten f√ºr die Stream-Verarbeitung.  Es ist auch <b>in den Abfrageplaner integriert und der Abfrage-Executor</b> erm√∂glicht die Implementierung des Konzepts des Stream Computing in einer relationalen Datenbank. <br><br>  Wie bei TimescaleDB gelten f√ºr die PipelineDB-Erweiterung <b>in PostgreSQL keine SQL-Einschr√§nkungen</b> .  Es gibt verschiedene Funktionen, z. B. k√∂nnen Sie nicht zwei Streams kombinieren, dies ist jedoch nicht erforderlich. <br><br>  <b>Unterst√ºtzung f√ºr probabilistische Datenstrukturen und Algorithmen</b> .  Die Erweiterung verwendet den Bloom-Filter f√ºr SELECT DISTINCT, HyperLogLog f√ºr COUNT (DISTINCT) und T-Digest f√ºr Percentile_count () direkt in SQL.  Dies verbessert die Produktivit√§t. <br><br>  <b>√ñkosystem</b>  Mit der Erweiterung k√∂nnen Sie mit den √ºblichen Hochverf√ºgbarkeitsl√∂sungen, √úberwachungstools und allem anderen, was in PostgreSQL bekannt ist, arbeiten. <br><br>  Aufgrund der Besonderheiten des Streaming Computing verf√ºgt PipelineDB √ºber <b>Integrationen mit Apache Kafka</b> und mit Amazon Kinesis, einem Echtzeit-Analysedienst.  Da PipelineDB keine Abzweigung mehr ist, sondern eine Erweiterung, sollte die Integration mit dem Rest des Zoos ebenfalls sofort m√∂glich sein.  Ein Muss, aber wir leben nicht in einer idealen Welt, und alles ist eine √úberpr√ºfung wert. <br><br><h3>  Lizenzen und Neuigkeiten </h3><br>  Der gesamte Code ist unter Apache 2.0 lizenziert.  Es gibt ein kostenpflichtiges Abonnement f√ºr die Unterst√ºtzung verschiedener Schie√übuden sowie eine Cluster-Version mit einer kommerziellen Lizenz.  Basierend auf PipelineDB bietet das Unternehmen einen Stride-Analysedienst an. <br><br>  Bevor ich √ºber die Erweiterung sprach, sagte ich, dass es ein "aber" gibt.  Es ist Zeit, √ºber ihn zu sprechen.  Am 1. Mai 2019 gab das PipelineDB-Team bekannt, dass es nun Teil von Confluent ist.  Dies ist das Unternehmen, das KSQL entwickelt - eine Engine zum Streamen von Daten in Kafka mit SQL-Syntax.  Jetzt arbeitet dort Victor Gamov, Mitbegr√ºnder des Podcasts Debriefing. <br><br>  Was folgt daraus?  PipelineDB ist in Version 1.0.0 eingefroren.  Neben der Behebung kritischer Fehler ist nichts geplant.  Aufgrund der √úbernahme erwarten wir die Uber-Integration von Kafka in PostgreSQL.  Vielleicht ist es Confluent, das auf steckbarem Speicher basiert und etwas Cooles bewirkt. <br><br>  Was zu tun ist?  Gehen Sie zu TimescaleDB.  In der neuesten Version haben sie ihre "CONTINUOUS VIEW" mit Blackjack gemacht.  Nat√ºrlich ist die Funktionalit√§t jetzt nicht mehr so ‚Äã‚Äãcool wie in PipelineDB, aber es ist eine Frage der Zeit. <br><br><h3>  Zusammenfassend </h3><br><blockquote>  PipelineDB wurde f√ºr die Hochleistungs-Streaming-Datenverarbeitung entwickelt.  Sie k√∂nnen Berechnungen f√ºr gro√üe Datenmengen durchf√ºhren, ohne die Daten selbst speichern zu m√ºssen. </blockquote><br>  Wenn wir mit PipelineDB einen Datenstrom in einem Stream an PostgreSQL senden, betrachten wir ihn als virtuell.  Wir speichern keine Daten, sondern aggregieren, berechnen und verwerfen.  Sie k√∂nnen einen 200-Gigabyte-Server erstellen und Terabyte an Daten √ºber Streams austreiben.  Wir werden das Ergebnis erhalten, aber die Daten selbst werden verworfen. <br><br>  Wenn Ihnen aus irgendeinem Grund die "CONTINUOUS VIEW" von TimescaleDB nicht ausreicht, versuchen Sie es mit PipelineDB.  Dies ist ein Open Source-Projekt unter der Apache-Lizenz.  Es wird nirgendwo hingehen, obwohl es nicht mehr aktiv entwickelt wird.  Aber die Dinge k√∂nnen sich √§ndern, Confluent hat noch nicht √ºber Expansionspl√§ne geschrieben. <br><br><h2>  Verwenden von TimescaleDB und PipelineDB </h2><br>  Mit PostgreSQL und zwei Erweiterungen k√∂nnen <b>wir gro√üe Arrays von Zeitreihendaten speichern und verarbeiten</b> .  Sie k√∂nnen an viele Anwendungen denken.  Schauen wir uns ein Beispiel aus meinem Themenbereich an - Fahrzeug√ºberwachung. <br><br><img src="https://habrastorage.org/webt/mx/_k/ru/mx_krumolcfgrlfrraktizshhem.jpeg"><br><br>  Navigationsger√§te senden kontinuierlich Telemetrie-Aufzeichnungen an unsere Server.  Sie analysieren verschiedene Text- und Bin√§rprotokolle in einem gemeinsamen Format und senden in einem speziellen Thema Daten an Kafka.  Von dort gelangen sie durch die Integration mit PipelineDB in den Telemetriedatenstrom in PostgreSQL.  Dieser Stream aktualisiert die Ansicht f√ºr den aktuellen Status von Fahrzeugen und die gesamte Flottenanalyse und provoziert auf der Grundlage des Ausl√∂sers die Aufzeichnung von Telemetriedatens√§tzen in der TimescaleDB-Hypertabelle. <br><br>  Mit Erweiterungen haben wir drei Vorteile. <br><br><ul><li>  Echtzeitanalyse. <br></li><li>  Speicherzeitreihendaten. <br></li><li>  Verringerung des Volumens der gespeicherten Telemetrie.  Mit dem PipelineDB-Mutator aggregieren wir Daten beispielsweise um eine Minute und berechnen Durchschnittswerte. <br></li></ul><br>  Grafana bietet integrierte Unterst√ºtzung f√ºr TimescaleDB-Funktionen.  Daher ist es m√∂glich, Diagramme nach Gesch√§ftsmetriken direkt von der Box bis zu den Spuren auf der Karte nach Koordinaten zu erstellen.  Die Analytikabteilung wird sich freuen. <br><br>  Um alles selbst zu "ber√ºhren", schauen Sie sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Demo auf GitHub an</a> und f√ºhren Sie das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker-Image aus</a> - innerhalb der Assembly aus den neuesten PostgreSQL-, TimescaleDB- und PipelineDB-Versionen. <br><br><h2>  Insgesamt </h2><br>  Mit PostgreSQL k√∂nnen Sie verschiedene Erweiterungen kombinieren und eigene Datentypen und Funktionen hinzuf√ºgen, um bestimmte Probleme zu l√∂sen.  In unserem Fall deckt die Verwendung der Erweiterungen TimescaleDB und PostGIS den Bedarf f√ºr die Speicherung von Zeitreihendaten und Geodatenberechnungen fast vollst√§ndig ab.  Mit der PipelineDB-Erweiterung k√∂nnen wir kontinuierliche Berechnungen f√ºr verschiedene Analysen und Statistiken durchf√ºhren. Durch die Verwendung von JSONB-Spalten k√∂nnen wir schwach strukturierte Daten in einer relationalen Datenbank speichern.  Open Source-L√∂sungen reichen mit dem Kopf aus - wir verwenden keine kommerziellen L√∂sungen. <br><br>  Diese Erweiterungen stellen praktisch keine Einschr√§nkungen f√ºr das √ñkosystem rund um PostgreSQL dar, wie z. B. Hochverf√ºgbarkeitsl√∂sungen, Sicherungssysteme, √úberwachungs- und Protokollanalysetools.  Wir brauchen MongoDB nicht, wenn es JSONB-Spalten gibt, und wir brauchen InfluxDB nicht, wenn es TimescaleDB gibt. <br><br><blockquote>  Magst du die Geschichte von Ivan und m√∂chtest etwas √Ñhnliches teilen?  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bewerben Sie sich</a> vor dem 7. September bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++</a> in Moskau.  Das Programm f√ºllt sich allm√§hlich.  Neben Datenbankf√§llen wird √ºber Architektur, Optimierung und nat√ºrlich hohe Lasten berichtet.    ,    ! </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de464303/">https://habr.com/ru/post/de464303/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de464289/index.html">Wie schreibe ich Go-Pakete</a></li>
<li><a href="../de464291/index.html">Die 10 einflussreichsten Programmiersprachen der letzten 50 Jahre und ihre Sch√∂pfer</a></li>
<li><a href="../de464293/index.html">Ersetzen Haken in React Redux?</a></li>
<li><a href="../de464295/index.html">Beispiele f√ºr die Verwendung einiger neuer JavaScript-Funktionen</a></li>
<li><a href="../de464299/index.html">0, 0, 1, 0, 2, 0, 2, 2, 1, 6, 0, 5, 0, 2, 6, 5, 4, 0, 5, 3, 0, 3, 2, 9, 0, 4, 9, 3, 6, 14, 0, 6, 3, 5, 15, 0, 5, 3, 5 ...</a></li>
<li><a href="../de464305/index.html">Klein, ja. Unboxing des Firecracker mikrovirtuell</a></li>
<li><a href="../de464307/index.html">Integrationstests von Microservices auf Scala</a></li>
<li><a href="../de464309/index.html">DIY Ruftaste. Raspberry Pi, MajorDoMo, Freeswitch und Linphonec</a></li>
<li><a href="../de464315/index.html">Der Film, in dem es Erde gab. Yandex-Forschung und eine kurze Geschichte der Suche nach Bedeutung</a></li>
<li><a href="../de464317/index.html">Konbanwa-Projekt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
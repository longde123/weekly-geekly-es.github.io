<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¥üèæ üë®üèΩ‚Äçü§ù‚Äçüë®üèª üßïüèø [Case Locomizer] So beschleunigen Sie die Berechnung einer Heatmap in zweieinhalb Jahren um das 20.000-fache ü§∑üèø üë®üèæ‚Äçüé§ üíπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel ist eine Fortsetzung der Case Locomizer-Reihe, siehe auch 



- Welches Wissen kann tats√§chlich aus einem anonymisierten Datensatz mit ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>[Case Locomizer] So beschleunigen Sie die Berechnung einer Heatmap in zweieinhalb Jahren um das 20.000-fache</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485988/"><blockquote>  Dieser Artikel ist eine Fortsetzung der Case Locomizer-Reihe, siehe auch <br><br><ul><li>  <a href="https://habr.com/ru/post/485484">Welches Wissen kann tats√§chlich aus einem anonymisierten Datensatz mit Benutzerkoordinaten extrahiert werden?</a> </li><li> Open One Ring - ein Toolkit zur flexiblen Konfiguration komplexer Datenverarbeitungsprozesse auf Spark in the Cloud (in K√ºrze verf√ºgbar!) </li></ul></blockquote><br>  Guten Tag. <br><br><img src="https://habrastorage.org/webt/fj/uo/jz/fjuojzz4hen-a54ybf62phjmlvk.png" alt="FDC: TC, EMR, IDEA" title="FDC: TC, EMR, IDEA"><br><br>  Wissen Sie, was eine Obduktion ist?  Dies ist eine Geschichte dar√ºber, wie wir zu einem solchen Leben gekommen sind. <br><br>  Ich bin mir nicht sicher, aber ich lese verdammt gerne Geschichten √ºber den Prozess der Entwicklung von hochspezialisierter oder einfacher Software.  Kollegen haben vielleicht eine interessante Idee, mit der sie arbeiten k√∂nnen, und es ist immer wieder neugierig zu verfolgen, was mit dem Programm vom Prototyp bis zum ausgereiften Produkt passiert ist, das in einem unbekannten Fachgebiet etwas Magie aus√ºbt. <br><br>  Dar√ºber hinaus ist es unwahrscheinlich, dass jemand eine Ahnung davon bekommt, was es ist und warum und f√ºr welche Aufgaben es n√ºtzlich sein kann, wenn ich nur einen Link zu einem Repository mit einer solchen Software lege.  Auch wenn ich drei Dutzend Seiten mit Anleitungen f√ºr den Einstieg aus dem Englischen √ºbersetze.  Trotzdem ist das <a href="https://spark.apache.org/">Spark-</a> Framework nicht nur ein weiteres Handwerk auf dem Winkel, es muss verstanden werden, <s>dass die</s> Autoren <s>geraucht haben,</s> warum es so geschrieben wurde und nicht anders. <br><br>  Dieser Artikel ist eine historische Einf√ºhrung in One Ring.  Es gibt keinen Code und die Geschichte ist popul√§rer als wissenschaftlich.  Aber nur √ºber die Entwicklung und √ºber nichts anderes als zweieinhalb Jahre Entwicklung. <br><a name="habracut"></a><br>  Beim letzten Mal habe ich ausf√ºhrlich genug √ºber die Schwierigkeiten beim Extrahieren von Daten aus anonymisierten Datens√§tzen in der Mittelspur gesprochen und am Ende nicht schwache Intrigen entdeckt.  Lassen wir die L√∂sung ein letztes Mal, und wir werden heute √ºber den langen und schwierigen Weg zur Perfektion unseres Hauptwerkzeugs sprechen: <br><br><ul><li>  Big Data ist gro√ü </li><li>  Unser Fall ist nicht Standard </li><li>  Prototyp in C # und PostGIS </li><li>  Erste Ann√§herung an Hadoop MapReduce </li><li>  Das Aufkommen von CI und Spark </li><li>  Dritte Ann√§herung bei GeoSpark </li><li>  Japanische Analysten und Migration von Azure nach AWS </li><li>  Asche Nazg Durbatuluk, Asche Nazg Gimbatul, Asche Nazg Trakatuluk, Ag Burzum Ishi Krimpatul !! </li><li>  Optimierung und Geokatarsis mit Uber H3 </li><li>  Ganz in Wei√ü </li></ul><br><h3>  Big Data ist gro√ü </h3><br>  Bei Big Data geht es nicht um Gr√∂√üe. <br><br>  In einem monatlichen Datensatz in der Region Greater London kann es Dutzende oder sogar Hunderte Millionen Datens√§tze geben, aber das ist nicht viel.  Eine einzelne Iteration von Anfang bis Ende h√§ngt von der Geschwindigkeit des linearen Lesens von der Platte ab.  Wenn es sich bei dem Laufwerk um eine SSD handelt, dauert es einige Sekunden. <br><br>  (Ich erinnere Sie daran, dass es sich bei dem fraglichen Datensatz um eine Reihe von CSV-Dateien mit einer Reihe von Feldern handelt, die f√ºr den Anbieter spezifisch sind. Die Gruppierung von Datens√§tzen mit den Koordinaten anonymer Benutzer in einer Datei erfolgt entlang der Grenzen des Verwaltungsgebiets des Landes, der Pr√§fektur oder der Stadt. Die Dateien selbst werden auf erstellt Das ausgew√§hlte Datum, t√§glich oder <a href="https://habr.com/ru/post/485484">monatlich. Weitere</a> Details sind im vorherigen Teil beschrieben. <a href="https://habr.com/ru/post/485484">F√ºhren Sie es diagonal aus,</a> wenn nicht gen√ºgend Kontext vorhanden ist.) <br><br>  Unser Prozess ist mehrstufig.  Anf√§ngliche Heuristiken zur Anreicherung von Rohdaten, die nur in einem einzigen Iterationsmodus ausgef√ºhrt werden, sind schnell, und Sie k√∂nnen sie zumindest in Python, zumindest in C ++ und sogar in PHP schreiben.  Selbst auf einer schwachen Maschine ist die Verarbeitung schnell. <br><br>  Befindet sich das Dataset irgendwo in der Cloud, ist es, sofern sich der Handler in derselben Cloud befindet, kein besonderes Problem, dorthin zu gelangen, zu gehen und das Ergebnis daneben zu speichern.  Dar√ºber hinaus ist die Datei in der Regel bereits vorhanden, da Datenanbieter das Archiv mit gro√üer Freude selbst in Ihren Cloud-Speicher hochladen, wodurch Sie einen Download-Link erhalten.  Es bleibt nur die Bereitstellung der virtuellen Maschine, und alle Bibliotheken f√ºr den Zugriff auf das Repository werden vom Hersteller sorgf√§ltig darauf gespeichert. Alle Zugriffsschl√ºssel sind registriert. Nehmen Sie einfach die API in die Hand und verwenden Sie sie.  Es wird auch schnell gehen. <br><br>  Nun, mit den ersten Schritten ist alles klar.  Sie nahmen die Datei, durchliefen sie mehrmals und setzten die verarbeitete Version zur√ºck.  Aber was passiert, wenn die nachfolgenden Schritte unseres Algorithmus einige etwas komplexere Berechnungen f√ºr jeden Datensatz erfordern? <br><br>  Nehmen Sie so etwas wie die Bestimmung der Entfernung zwischen einem Koordinatenpaar.  Es gibt eine extrem schnelle <a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine-</a> Methode (‚ÄûHaversinuses‚Äú gem√§√ü der Version der Halle), die auf kurze Distanz eine akzeptable Genauigkeit liefert und es erlaubt, das <abbr title="World Geodetic System '84, jetzt Standard-Geoid">WGS84-</abbr> Geoid nicht zu nehmen, dessen Berechnung viel langsamer abl√§uft. <br><br>  An sich kostet eine solche Berechnung nicht so viel, wenn sie einmalig ist.  Und selbst wenn es Dutzende von Millionen von ihnen gibt, ist dies im Prinzip Unsinn. <br><br>  Und jetzt nehmen wir den Fall von unserem patentierten Algorithmus, bei dem wir die Entfernung von jedem Signal zu jedem POI aus der ausgew√§hlten Kategorie berechnen und diejenigen verwerfen m√ºssen, die weiter als einen halben Kilometer entfernt sind (eine solche Entfernung, die leicht zu gehen ist). <br><br>  In der Region Greater London fallen ungef√§hr eine Million Einrichtungen in die Ziel- <abbr title="Punkt des Interesses">POIs</abbr> der Kategorie Stores and Outlets.  Und wie gesagt, im monatlichen Datensatz kommen Dutzende von Hunderten von Millionen Datens√§tzen f√ºr ihn.  Und so bekommen wir ... <br><br><h2>  1.000.000 POIs √ó N ,.000.000 Signale = N ,.000.000.000.000 Entfernungen. </h2><br>  Oh, komm schon.  Verr√ºckte Billionen von Entfernungsberechnungen und Vergleichen von Schwellenkonstanten. <br><br>  Die klassische Situation mit dem <abbr title="Ein Set, dessen Elemente alle m√∂glichen geordneten Elementpaare des Originalsets sind">kartesischen Produkt</abbr> .  Zwei nicht sehr leistungsstarke Sets ergeben leicht N √ó 10 <sup>12</sup> Zwischenergebnisse, und dies ist nur ein Monat in einer Region!  Aus einer solchen Menge wird bereits Qualit√§t.  Nicht nur die Gr√∂√üe des Zwischenergebnisses ist bereits ein ernstes Problem, da es nicht vollst√§ndig in den Speicher passt und sofort am Empfangsort verarbeitet werden muss, sondern auch der Rechenaufwand, der erforderlich ist, um es zu erhalten, nimmt zu viel Computerzeit in Anspruch.  Und wenn f√ºr einen Datensatz unter Ber√ºcksichtigung aller Verz√∂gerungen bei der √úbertragung √ºber das Netzwerk und anderer Gemeinkosten nur 100 Nanosekunden aufgewendet werden, sind Millionen von Sekunden Tage und Wochen von Berechnungen in einem Datenstrom. <br><br>  Oder, wenn wir zum Beispiel ein Segment aus der allgemeinen Bev√∂lkerung herauswerfen m√ºssen, die Bedingung "die Interessen von Benutzern, die in einem bestimmten Gebiet leben, nicht ber√ºcksichtigen", dann m√ºssen wir die device_id jedes Datensatzes des angereicherten Datensatzes der gesamten Region mit einem Satz vergleichen, in dem Hunderttausende Datens√§tze mit enthalten sind ausgeschlossen device_id Bewohner dieses Gebiets.  Und dies sind in vielerlei Hinsicht Zeichenfolgenvergleiche, nicht so schnell wie f√ºr zwei Zoll.  Wieder gibt es eine verr√ºckte Anzahl von Nullen bei der Bewertung einer einfachen Operation, und wir haben sie f√ºr einen vollst√§ndigen Satz von Heuristiken f√ºr ein durchschnittliches Projekt mit einem Dutzend oder sogar mehr. <br><blockquote>  Big Data sind Daten, die aufgrund ihrer Gr√∂√üe aufgrund der Unangemessenheit oder Unpraktikabilit√§t der direkten Verarbeitung spezielle algorithmische Techniken erfordern. </blockquote><br>  ... auch wenn das Endergebnis der Berechnung in einem Bildschirm der Excel-Tabelle zusammenf√§llt. <br><br>  Sie k√∂nnen versuchen, den "naiven" Handler anhand der Anzahl der verf√ºgbaren virtuellen Prozessoren auf der Maschine, auf der die Berechnung ausgef√ºhrt wird, zu parallelisieren.  Sie k√∂nnen den Datensatz in Teile teilen und die Berechnung der Strasssteine ‚Äã‚Äãauf einem Dutzend virtueller Maschinen in der Cloud ausf√ºhren.  All dies f√ºhrt jedoch nicht zu einem qualitativ hervorragenden Ergebnis.  Die Skalierung "in der Breite" f√ºhrt ab einer bestimmten Breite zu <a href="https://ru.wikipedia.org/wiki/%25D0%2597%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25BD_%25D1%2583%25D0%25B1%25D1%258B%25D0%25B2%25D0%25B0%25D1%258E%25D1%2589%25D0%25B5%25D0%25B9_%25D0%25B4%25D0%25BE%25D1%2585%25D0%25BE%25D0%25B4%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25B8">abnehmenden Ertr√§gen</a> .  Und das Problem der Synchronisierung und Partitionierung wird mit Sicherheit auftauchen, und die Verwaltung einer ganzen Flotte virtueller Maschinen wird Zeit und Geld kosten.  Es ist teuer, sie die ganze Zeit eingeschaltet zu halten, und das Starten und Stoppen bei Bedarf ist arbeitsintensiv. <br><br>  Daher werden f√ºr Big Data spezielle Softwaresysteme aus dem Hadoop-√ñkosystem verwendet, die bereits √ºber Skalensteuerungen verf√ºgen, sowie spezielle Algorithmen, die es dem Mammut erm√∂glichen, in kleinen Portionen zu essen, ohne die astronomische Menge von Zwischendaten zu verschlucken, und die das Leben eines Big-Data-Entwicklers erheblich vereinfachen.  Sie k√∂nnen Hadoop jedoch nicht einfach verwenden.  Zuerst m√ºssen Sie einen Plan erstellen. <br><br>  Besonders wenn ... <br><br><h3>  Unser Fall ist nicht Standard </h3><br>  Wenn Sie sich fragen, wie die an der Analyse gro√üer Datenmengen beteiligten Stellen ihre Prozesse aufbauen, stellt sich heraus, dass in der Weltpraxis zwei Hauptans√§tze verwendet werden. <br><br><h4>  Ansatz Nummer 1.  Data Lake </h4><br>  F√ºr Daten, die sich im Laufe der Zeit ansammeln und f√ºr immer relevant bleiben, ist eine spezielle Art der Speicherung vorgesehen, der sogenannte " <a href="https://habr.com/ru/post/485180/">Data Lake</a> ". <br><br>  Die Architektur solcher Repositories ist f√ºr den schnellen Direktzugriff optimiert.  Viele der gesammelten Datens√§tze werden in ein spezielles Format √ºbersetzt, mit dem Sie schnell mehrere Kriterien und Segmente nach Spaltens√§tzen ausw√§hlen k√∂nnen.  Im Gegensatz zu herk√∂mmlichen relationalen und dokumentenorientierten Datenbanken wird die Spaltenspeicherung in Data Lakes verwendet.  Normalerweise sind sie endg√ºltig, das hei√üt, das Format der Container mit den Daten ist so, dass sich nach dem F√ºllen und Indizieren der Daten im selben Datensatz nie mehr √§ndert.  Zum Beispiel Parkettdateien, die nicht modifiziert werden m√ºssen. <br><br>  Danach dr√§ngen sich eine Menge Datensatanisten oder Datenanalysten, und in Spezialsoftware (‚ÄûLaptops‚Äú wie Jupyter) werden Statistiken, Indikatoren usw. gesammelt.  online.  Diese Statistiken werden irgendwo nach au√üen aus dem See geladen oder einfach in Form derselben endg√ºltigen Dateien f√ºr die nachfolgende Aggregation addiert. <br><br><h4>  Ansatz Nummer 2.  Daten-Streaming </h4><br>  F√ºr Daten, die in Echtzeit eingehen und schnell verarbeitet werden m√ºssen (dh Daten-Streaming), sind Datenbusse oder Nachrichtenwarteschlangen vorgesehen. <br><br>  In einer Infrastruktur mit einem Datenbus gibt es an einem Ende Generatoren und am anderen Ende Verbraucher, und die Datenstr√∂me selbst setzen sich aus Ereignissen zusammen. <br><br>  Generatoren werden generiert, und Verbraucher analysieren Ereignisse in Echtzeit oder nahezu in Echtzeit, wobei sie einige Endergebnisse ansammeln, die wiederum Ereignisse generieren k√∂nnen, die die n√§chste Gruppe von Aggregatoren √ºber denselben Bus verbraucht, und so weiter, bis das Endergebnis erhalten wird. im Endergebnisspeicher gefaltet. <br><br>  Es wird von Apache Kafka und schnellem Speicher wie Aerospike angetrieben. <br><br><h4>  Unser Fall </h4><br>  Unser Fall passt jedoch nicht in diese beiden Ans√§tze. <br><br>  Erstens macht es f√ºr uns keinen Sinn, einen Datensee zu f√ºhren, da der Datensatz selten l√§nger als ein Jahr dauert (Benutzerspuren f√ºr 2016 im Jahr 2019 werden von niemandem mehr ben√∂tigt) und jedes Mal, wenn Kunden einen v√∂llig unvorhersehbaren Teil aller gesammelten Daten ben√∂tigen.  Aufgrund der Tatsache, dass f√ºr jedes Bev√∂lkerungssegment und jede Kategorie eine eigene Vorlage erstellt wird, sind wir weiterhin gezwungen, nur das erforderliche Teil zu nehmen, und das Zusammenf√ºhren zu einem gemeinsamen See macht wenig Sinn.  Es ist einfacher, jeden Monatsdatensatz in seiner urspr√ºnglichen Form zu halten - CSV-Dateien in einem eigenen Verzeichnis.  Der Pfad zur Datei wird abgerufen ... / provider / country / region / subregion / year / month / dataset-Dateien, und eine Teilmenge wird einfach √ºber die Dateinamenmaske ausgew√§hlt, z. B. ... / Tamoco / UK / Greater_London / * / 2019 / {6, 7,8} / *. Csv. <br><br>  Zweitens ist die Art der Datens√§tze diskret und kein Streaming.  Nat√ºrlich k√∂nnte man einige Indikatoren direkt beim Hochladen in den Netzwerkspeicher berechnen, aber die fertigen W√§rmekarten f√ºr die Moskauer Region und die Nachbarregion der Moskauer Region stimmen nicht mit der fertigen W√§rmekarte der kombinierten Region Moskau und Region √ºberein ( aufgrund der Tatsache, dass zu viele in der Region leben und in Moskau arbeiten, und wir immer noch nicht im Voraus wissen, welche Region wir brauchen werden.  Vielleicht weder Moskau noch die Region Moskau, sondern nur eine Stadt 17.  Es ist sehr teuer, Heuristiken zu fahren und Indikatoren f√ºr alle Datens√§tze zu berechnen. <br><br>  Daher m√ºssen wir schnell eine Teilmenge der akkumulierten Datens√§tze ausw√§hlen, schnell eine f√ºr die Stromversorgung geeignete Computerfarm bereitstellen, schnell einen eindeutigen, aber standardisierten Berechnungsprozess ausf√ºhren, das Ergebnis ausspucken und ... vielleicht nie wieder zu einer Teilmenge oder einer Farm dieser Gr√∂√üe zur√ºckkehren , nicht an die Vorlage.  Und wir k√∂nnen absolut keinen gut abgestimmten Leistungscluster auf unserer eigenen Hardware halten, der die Anforderungen aller unserer Projekte vom kleinsten bis zum schwierigsten abdeckt, da sie zu unterschiedlich sind. <br><br>  Ich denke nicht, dass wir so einzigartig sind.  In Gespr√§chen mit Kollegen taucht regelm√§√üig die Notwendigkeit auf, √§hnliche <abbr title="Babah!, Gro√üer Knall, Blitz, Maschinengewehrknall usw.">Burst-</abbr> F√§lle zu instrumentieren, aber hier baut jeder den Prozess auf seine eigene Weise auf.  In der Regel werden L√∂sungen f√ºr nicht standardisierte F√§lle von den seitlichen Ans√§tzen Nr. 1 oder Nr. 2 an den vorhandenen F√∂rderer angeh√§ngt.  unser prozess besteht ausschlie√ülich aus privaten projekten, wir haben alle aufgaben wie "burst". <br><br>  Nun gut.  F√ºr zwei Jahre und einen Cent konnten wir ein Tool-Kit entwickeln, um meine Arbeit so weit wie m√∂glich zu automatisieren, und genau dies werde ich im dritten Teil meiner Geschichte f√ºr den allgemeinen Gebrauch vorstellen.  Sprechen wir in der Zwischenzeit √ºber die Evolution und all die Fehler und Probleme, die wir korrigieren und l√∂sen, die wir durch Erfahrung zu einem nachhaltigen Prozess gebracht haben. <br><br><h3>  Prototyp in C # und PostGIS </h3><br>  Alles begann vor ein paar Jahren.  Zwei sehr kluge Typen namens <a href="https://www.forbes.ru/tehnologii/336439-na-kletochnom-urovne-kak-zarabatyvat-na-sinteze-marketinga-i-biologii">Alexei Polyakov und Alexei Polyakov</a> - lachen Sie nicht, sie sind eigentlich Namensvetter, aber aus verschiedenen Teilen der Welt - Biologe und Vermarkter - beschlossen, die Methode aus der Dissertation √ºber das kollektive Verhalten von Zellpopulationen in Zellkulturen anzuwenden, die experimentell an M√§usen getestet wurde , Werbung und Marketing. <br><br>  Es hat bei Menschen funktioniert. <br><br>  Und dann kam das Locomizer-Projekt zustande.  Ich sage "Projekt", weil es wie ein Startup mit einer <abbr title="Ltd., nur in London">GmbH ist</abbr> , Vertr√§ge abzuschlie√üen, aber nicht ganz.  Unsere Teammitglieder sind √ºber die ganze Welt verstreut, arbeiten an verschiedenen Orten und in verschiedenen B√ºros als Freiberufler oder Outsourcer (und nicht alle in Vollzeit) und wir verwenden unsere Algorithmen f√ºr sehr unterschiedliche Kunden mit unterschiedlichen Interaktionsmodellen, wenn wir Auftr√§ge erhalten oder finden.  Es gibt Abonnements, aber mehr private einmalige Aufgaben. <br><br>  Aber das ist gerade jetzt.  Und vor ein paar Jahren war alles noch chaotischer.  Wer die erste Software-Implementierung zur Berechnung der Geschwindigkeit geschrieben hat, wei√ü ich generell nicht.  (Wenn Sie diese unbekannten Helden pl√∂tzlich kennen, gr√º√üen Sie sie.) Am Ende meines letzten <a href="https://habr.com/ru/post/437610/">Artikels</a> √ºber die Karriere eines Programmierers in einer bestimmten Stadt schrieb ich w√∂rtlich Folgendes: ‚ÄûIch bin gekommen, um mit dem Ort zu sprechen, an dem ich jetzt arbeite, und PM hat von Anfang an darauf hingewiesen Das Projekt ist h√∂llisch.  Nichts  Auch hier, GIS, basieren nur Berechnungen auf MapReduce (und ich m√∂chte es auf Spark), Karten auf ArcGIS, und all dies dreht sich in Wolken, die sich niemand ausdenken kann.  Meiner Meinung nach eine gro√üartige Option! ‚Äú- in diesem Moment war es bereits so, und ich kann die allererste Stufe der <a href="https://habr.com/ru/users/mitra_kun/" class="user_link">Codeentwicklung</a> eines Projekts nur aus den Memoiren von <a href="https://habr.com/ru/users/mitra_kun/" class="user_link">mitra_kun wiederherstellen</a> , die selbst ein Jahr zuvor f√ºr das Projekt erschienen sind. <br><br>  Die rudiment√§ren Heuristiken f√ºr die Verarbeitung von Rohdatens√§tzen wurden in PHP, Python und C ++ geschrieben, und die Hauptberechnung der Geschwindigkeit f√ºr die Heatmap wurde von einem Programm in C # durchgef√ºhrt. <br><br><img src="https://habrastorage.org/webt/ni/yp/qc/niypqcxxu3ugnbt1mx16ecnuhds.png" alt="Das ganze Projekt in C #" title="Das ganze Projekt in C #" align="right"><br><br>  Sie hat so gearbeitet: <br><br><ol><li>  Zuerst lesen wir den String direkt aus der Dataset-Datei in das Array. </li><li>  F√ºhren Sie es f√ºr sie aus, bauen Sie eine Hash-Tabelle auf polzakz. </li><li>  Die POI-Basis ist eine Literal-Tabelle in einer PostgreSQL-Datenbank mit PostGIS-Feldern vom Typ GEOMETRY. Um den Abstand zwischen jedem Benutzersignal und jedem POI zu berechnen, wird die Funktion ST_DISTANCE durch einen kleinen <a href="https://postgis.net/docs/ST_Distance.html">Speicher gezogen</a> und das Ergebnis f√ºr jeden Benutzer in eine Hash-Tabelle mit einem Schl√ºssel eingef√ºgt. </li><li>  Dann foreachen wir auf dem Tisch mit der Akkumulation des Ergebnisses der Zinsbewertung f√ºr jeden Schl√ºssel im Array. </li><li>  Gruppieren Sie noch einmal f√ºr jede Kategorie. </li><li>  Nach dem Ende der Berechnung, die nur ein paar Stunden bis eine Woche dauert, wird das Ergebnis zur CSV-Datei hinzugef√ºgt ... </li><li>  ... und dann noch manuell verarbeitet, auf der Karte <a href="https://desktop.arcgis.com/ru/">eingeblendet</a> und in <a href="https://desktop.arcgis.com/ru/">ArcGIS</a> visualisiert. </li></ol><br>  Es ist klar, dass das maximal verarbeitete Volumen durch den auf dem Computer verf√ºgbaren Speicher begrenzt ist und die Geschwindigkeit einzelner Abfragen an die Datenbank einen bestimmten Alarm ausl√∂st. <br><br><h3>  Erste Ann√§herung an Hadoop MapReduce </h3><br>  Am lokalen Prototyp wurde etwas berechnet, die Angemessenheit der angewandten Methoden zur Erstellung von Datens√§tzen und Geb√§ude-Heatmaps getestet und die Frage aufgeworfen, wie die Arbeit in Betrieb genommen werden soll.  Nun, es ist wichtig, den Sonnenuntergang nicht manuell zu bew√§ltigen, sondern die F√§higkeiten einer Plattform zu nutzen, die vorzugsweise von Industriewalen geschrieben wird, und zumindest auf das Minimum zu skalieren. <br><br>  Wie gesagt, die Standardplattform f√ºr die Verarbeitung gro√üer Datenmengen ist das Hadoop-√ñkosystem.  Eine gro√üe Anzahl heterogener Bibliotheken, darunter ein verteiltes Dateisystem, Planer f√ºr die Parallelisierung von Aufgaben, relativ bequeme Abstraktionen √ºber Kartenreduzierung, Engines f√ºr die Ausf√ºhrung von Abfragen und sogar eine gro√üe Menge an Material f√ºr die Datenanalyse.  Und all diese Software-Infrastruktur ist in Form von integrierten Paketen in den Clouds von verschiedenen Anbietern verf√ºgbar und wird automatisiert, aber dazu sp√§ter mehr. <br><br>  Ok Google, suche nach Hadoop.  Meine Vorg√§nger nahmen den Prototyp und schrieben die Hauptberechnung von C # auf Java um, wobei sie buchst√§blich alle foreach durch den entsprechenden Hadup-Mapper und -Reducer ersetzten und alle Schritte zur Aufbereitung und Anreicherung von Datens√§tzen in separaten Dienstprogrammen in Skriptsprachen unternahmen, um sich mit dem Aufkommen von different schneller zu entwickeln Kundenalgorithmen begannen sich aktiv zu entwickeln.  Separat haben wir im Fr√ºhjahr mit dem Schreiben eines Backends f√ºr die Web-Benutzeroberfl√§che begonnen (nicht die beste L√∂sung, wenn keine Java-Entwicklungserfahrung vorhanden ist, es sollte besser in PHP geschrieben werden), mit einem Frontend f√ºr Node.js mit Kartenintegration von ArcGIS. <br><br><img src="https://habrastorage.org/webt/oq/i3/ye/oqi3yehxn8ybmjbh0j1g0f4sqj4.png" alt="Ein kleiner Teil eines Java-Projekts" title="Ein kleiner Teil eines Java-Projekts" align="left"><br><br>  Sie haben f√ºr diesen Fall den "gro√üen Cluster" von Hadoop auf f√ºnf virtuellen Maschinen in Microsoft Azure ausgel√∂st.  Warum Azure?  Erstens gibt es f√ºr Startups in den ersten Jahren einen gro√üen Rabatt.  Zweitens wurde ArcGIS Desktop f√ºr Windows zur Visualisierung von Karten bereits in dieser Cloud bereitgestellt. <br><br>  Der Hadoop-Cluster wurde manuell bereitgestellt und nicht √ºber den entsprechenden Azure HDInsight-Dienst, der schwer zu konfigurieren war.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf jedem der Cluster-Rechner haben sie Postgre + PostGIS ausgel√∂st (eine eher zweifelhafte Entscheidung, da MR und die Basis beginnen, um den Prozessor zu konkurrieren), um keine Entfernungen zu einem separaten Server anzustreben. Wir haben ein kleines Skript erstellt, das Repliken der POI-Datenbank auf die Knoten des Clusters verteilt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Projekt war noch ein Prototyp, nur etwas weiter fortgeschritten. PostGIS wurde immer noch verwendet, weil Geofencing auftauchte und die Jungs noch nicht wussten, wie es mit minimalem Arbeitsaufwand implementiert werden k√∂nnte. Es f√ºhlte sich an, als sei alles furchtbar langsam, und die Anzahl der Schritte, die manuell ausgef√ºhrt werden mussten, √ºberstieg ein Dutzendeinhalb.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In diesem Moment interessierte mich der Vorschlag einer in unserer kleinen, aber sehr IT-orientierten Stadt wenig bekannten Firma (in Ischewsk gibt es mehr als sieben Dutzend B√ºros mit Entwicklungsmitarbeitern, in denen etwa dreitausend Programmierer arbeiten), ein B√ºro mit dem absolut generischen Namen ‚ÄûRussische Informationstechnologien‚Äú pl√∂tzlich, ohne Grund, brauchte es Senior Java Developer mit umfassender Erfahrung in der Bereitstellung und Automatisierung und h√∂rte zumindest vom Ohr √ºber Big Data und die Clouds. Nun, als ich etwas √ºber Wolken und Big Data h√∂rte. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was alles andere angeht, ich habe mehr als genug Erfahrung :( Deshalb habe ich als erstes gesagt, dass ich den Code und den Status der Prozesse laut und oft in den besten Traditionen von Artemy Lebedev gesehen habe. Ich werde es nicht wiederholen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nun, wenn der Code und die Prozesse von verst√§ndlicher Qualit√§t sind, dann haben sie definitiv einen Optimierungsplatz. F√ºr den Anfang k√∂nnen Sie Anforderungen mindestens einzeln an PostGIS senden, jedoch stapelweise mit jeweils ca. 5000 Punkten. Datenbanken sind in der Regel gut f√ºr die Aufl√∂sung kartesischer Produkte optimiert. Es ist erledigt, der Speicher mit dem Aufruf ST_DISTANCE wurde so umgeschrieben, dass sofort ein gro√ües Array f√ºr ein Paket von Punkten zur√ºckgegeben wurde, und die Berechnung wurde sofort von Grund auf um das 40-fache beschleunigt, da nun nicht mehr so ‚Äã‚Äãoft eine Verbindung zur Datenbank und zu so vielen Indizes hergestellt werden musste auf Geometrie in der Tabelle mit POI begann mit gro√üem Sinn zu arbeiten.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Richtig, ein b√∂ser esoterischer Fehler hat sich direkt in die Berechnung eingeschlichen, da der Prototyp nicht vollst√§ndig korrekt von C # nach Java portiert wurde. Die Jungs haben den Punkt einer wichtigen Variablen verpasst, und die formale TK auf dem Prototyp hat sie √ºberhaupt nicht erreicht, irgendwo auf dem Weg verloren. Dann haben wir alle Algorithmen aus fragmentarischen Beschreibungen wiederhergestellt, aber das war schon sehr viel sp√§ter. Dieser Fehler hat das Berechnungsergebnis insgesamt jedoch nicht beeintr√§chtigt, sondern lediglich den Kontrast der W√§rmekarte verringert.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit MapReduce erhalten Sie jedoch nicht viel Leistung, da der Mapper Daten aus HDFS liest und zur√ºckschreibt und der n√§chste Reduzierer in der Kette dasselbe tut und so weiter, bis alle Schritte abgeschlossen sind. </font><font style="vertical-align: inherit;">Es ist auch sehr unpraktisch, einen mehrstufigen Prozess zu verwalten, insbesondere wenn der Algorithmus aufgrund von Einstellungen Verzweigungen aufweist. </font><font style="vertical-align: inherit;">Der gesamte Algorithmus ist ein Hardcode, und wenn Sie die Schritte irgendwie neu anordnen m√∂chten, m√ºssen Sie sie mit Ihrem eigenen Launcher in separate Module verschieben und eine Art Logik nach au√üen packen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Abrufen von PostGIS aus der Berechnung heraus, selbst wenn Sie die Datenbank auf jedem Knoten des Clusters duplizieren, ist immer noch eine sehr schmerzhafte Idee.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das Aufkommen von CI und Spark </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Automatisiere es! - mein zweites gro√ües </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Punkt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rofessionalny Interesse nach enterprayznogo </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rogrammirovaniya auf einer Kr√∂te ... Und nein. Zweitens - es ist </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> itstsa, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> asta und </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> udingi, dann lassen Sie </font><font style="vertical-align: inherit;">es eine dritte sein - ist </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Stop - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Prozesse und deren Automatisierung. (I wie shef- </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ovar wie alles an haben , </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Hashtag # </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> echenki.)</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Handarbeit birgt zu viele Gefahren. Menschen sind unzuverl√§ssig und machen h√§ufig Fehler, auch wenn sie das Gleiche tun. Daher ist es viel effizienter, den gesamten Projektfluss zu formalisieren und ein Skript zu schreiben, das nicht fehlschl√§gt, wenn das Dienstprogramm zum Kopieren des Datensatzes aus dem Langzeitspeicher in den Online-Speicher aufgerufen wird, und die Reihenfolge der Schritte nicht zu vertauschen. als weiter den Rechen laufen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rake Walking war nur das schwerwiegendste Problem, das zuerst gel√∂st werden musste. Zuerst habe ich mich in einer separaten kleinen virtuellen </font></font><a href="https://www.jetbrains.com/teamcity/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">teamCity bereitgestellt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Richten Sie die Assembly mit dem Durchlauf aller Tests so ein, dass das √ºberpr√ºfte Artefakt immer zur Hand ist und nicht manuell auf den Cluster geworfen werden muss. Der zweite Schritt bestand darin, einen Wrapper zu schreiben, um eine MR-Task mit dem angegebenen Datensatz und Parametersatz im Cluster direkt aus demselben TC zu starten. Dabei wurden die urspr√ºnglichen Datens√§tze automatisch in den Cluster kopiert und die Ergebnisse der Berechnung im Ergebnisspeicher gespeichert. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und der dritte Schritt, der viel Zeit in Anspruch nahm, bestand darin, die Bereitstellung des Clusters selbst zu automatisieren, seine Parameter zu optimieren und die Berechnung f√ºr ein in Azure Blob Storage integriertes Dataset zu starten. Pl√∂tzlich gab es Projekte, bei denen ein statischer Cluster von f√ºnf virtuellen Maschinen √ºbersehen wurde und / oder deren Datens√§tze nicht mit einem Speicherauszug alter Dateien auf HDFS gemischt werden sollten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Azure HDInsight ist eigentlich</font></font><a href="https://www.cloudera.com/downloads/hortonworks-sandbox/hdp.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hortonworks HDP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Earth Rest in Peace), und einige seiner Einstellungen werden in der API vorgenommen, und einige k√∂nnen nur √ºber </font><abbr title="Web-Benutzeroberfl√§che zu konfigurieren, gruselig wie jedes Unternehmen Web-Benutzeroberfl√§che"><font style="vertical-align: inherit;">Ambari</font></abbr><font style="vertical-align: inherit;"> registriert werden</font></font><abbr title="Web-Benutzeroberfl√§che zu konfigurieren, gruselig wie jedes Unternehmen Web-Benutzeroberfl√§che"><font style="vertical-align: inherit;"></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Das Bereitstellen eines Clusters kann je nach Auslastung der Cloud bis zu einer Stunde dauern, und der Optimierungszyklus, dh das √úberpr√ºfen der Auswirkungen einer Reihe von Einstellungen auf die Leistung unseres Codes, kann einen ganzen Tag dauern. </font><font style="vertical-align: inherit;">Die lokale Version von HDP Sandbox in der virtuellen Maschine ben√∂tigt 11 GB RAM und stellt eine enorme Belastung f√ºr das Festplattensubsystem dar. Daher ist auch das lokale Debuggen √§u√üerst unangenehm und die Einstellungen unterscheiden sich geringf√ºgig von der Cloud-Version. </font><font style="vertical-align: inherit;">Ich habe viel Zeit f√ºr Experimente aufgewendet, aber zumindest habe ich herausgefunden, wie das alles funktioniert und was zu tun ist, wenn die Berechnung beim n√§chsten OOM pl√∂tzlich in der Mitte h√§ngt, weil es auch ziemlich unangenehm ist, die Protokolle manuell zu analysieren.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">W√§hrend ich mich mit HDP besch√§ftigte, begann ein anderer Programmierer, die unterschiedlichen Phasen der Vorbereitung von Datens√§tzen auf Apache Spark zu vereinheitlichen. Spark l√∂ste das Problem des st√§ndigen Schreibens / Lesens von Zwischendaten, die zwischen den Schritten einer Berechnung auftreten, und wurde im Allgemeinen unter Ber√ºcksichtigung aller schlechten Stellen von MR entwickelt und kann dies um ein Vielfaches sofort tun. Und Spark's fauler </font></font><abbr title="Resilient Distributed Dataset, eine Datenstruktur mit hervorragenden Eigenschaften, auf denen Spark aufbaut"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RDD</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ist eine sehr praktische Sache. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gleichzeitig erstellte ich ein Skript f√ºr Azure-Vorlagen in PowerShell, um den Edge-Knoten f√ºr PostGIS zu konfigurieren - eine separate Thick-Nose-Instanz im Cluster mit einer Reihe von Kernen und Arbeitsspeicher, um Anforderungen zu beschleunigen dann in HDFS auf dem Cluster geladen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So lernte die Skriptbindung, die urspr√ºnglich davon ausgegangen war, dass sie sowohl interaktiv als auch im Batch-Modus auf TC als separater Build funktionieren w√ºrde, nach und nach, eine beliebige Kombination von Schritten auf MR, Spark und anderen Softwarepaketen auszuf√ºhren, die wir nicht aus der HDInsight-Suite, sondern verwendeten noch mit rudiment√§rer Parametrisierung. Das √úbertragen der Build-Parameter auf ein benachbartes Repository mit einer Reihe von INI-Dateien (f√ºr jede Plattformkomponente und f√ºr jeden Prozessschritt) und das Verwalten von Prozessvorlagen in den Zweigen dieses Repositorys erwies sich jedoch als eine so praktische Praxis, dass wir sie immer noch verwenden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schon Fortschritte. Mit der Automatisierung einer manuellen Routine wurde die Vorbereitungszeit f√ºr die Berechnung um das Vierfache reduziert, ganz zu schweigen von menschlichen Fehlern, die viel geringer wurden. Es ist aber noch nicht der Zeitpunkt der Berechnung.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dritte Ann√§herung bei GeoSpark </font></font></h3><br>  Es dauerte ungef√§hr sechs Monate.  Zu diesem Zeitpunkt hatte sich allm√§hlich eine Reihe von debuggten und getesteten Heuristiken angesammelt, bereits mit separaten Anwendungen auf Spark und ohne Skripte, und es wurden einige typische Prozessvorlagen entwickelt.  Jetzt war es notwendig, sie zu optimieren. <br><br>  Der zweite Programmierer, der weder in einem Team noch in einem Unternehmen Erfahrung hatte, handelte mit seinen Modulen ganz unkompliziert - nachdem er die √úbertragung einer Heuristik an Spark abgeschlossen hatte, kopierte er einfach das gesamte Projekt und begann, den alten Algorithmus durch den neuen zu ersetzen.  Infolgedessen stellten acht solcher parallelen Module, von denen jedes einen √§hnlichen, aber leicht unterschiedlichen Parametersatz, eine ausgezeichnete Aufrufsemantik und eine Menge doppelter Dienstcodes aufwies, ein weiteres Problem dar.  Je mehr Code vorhanden ist, desto mehr Zeit wird f√ºr die Unterst√ºtzung aufgewendet, insbesondere, wenn die Entwicklung in dieser Zeit nicht aufh√∂rt.  Durch das st√§ndige Kopieren und Einf√ºgen sammelten sich unbenutzte Parameter und andere Abf√§lle an. <br><br>  Nachdem ich mit dem Brennproblem der Automatisierung fertig war und mich mit der Konfiguration von Clustern befasst hatte, konnte ich jetzt bereits die Datenaufbereitungsmodule und die Heuristik aufnehmen.  Zun√§chst habe ich den gesamten sich wiederholenden Code in ein separates Commons-Projekt √ºbernommen, das als <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules">Git-Submodul eingesteckt wurde</a> , und in den Berechnungsmodulen wurde es um ein Vielfaches weniger chaotisch.  Ich habe eine Vorlage f√ºr eine typische Heuristik zusammengestellt, aus der bereits ein neues Projekt hervorgegangen ist, ohne dass Code-Teile ersetzt werden m√ºssen und ohne unn√∂tigen Schmutz in der Geschichte der Festschreibungen.  Die Entwicklung begann schneller zu werden. <br><br>  Das n√§chste gro√üe Problem, das besiegt werden musste, war die Logik der Berechnung der kartesischen Produkt √ó POI-Signale. <br><br>  Nur die Stapelverarbeitung √ºbertr√§gt sie in die Datenbank, verringert jedoch nicht die Anzahl der Vorg√§nge, selbst wenn die Datenbank Indizes und die Abfrageoptimierung effektiv verwendet.  Es w√§re logisch, den Abstand f√ºr diejenigen Paare nicht zu ber√ºcksichtigen, bei denen er offensichtlich den von uns ben√∂tigten Schwellenwert √ºberschreitet.  Aber wie kann man Paare mit einem Abstand verwerfen, der gr√∂√üer als der Schwellenwert ist, ohne diesen Abstand zu berechnen? <br><br>  Antwort: <abbr title="Bez√ºglich der Aufteilung von RDD in Teile in Funken, warum es nicht aufh√∂rt, ein einzelnes Ganzes zu sein, sondern in Teilen verarbeitet werden kann">Partitionieren Sie</abbr> sowohl Signale als auch POIs in einem geometrischen Raster. <br><br>  Dar√ºber hinaus besteht die Heatmap bereits aus einem Gitter von Polygonen.  Und wenn Sie die Zellengr√∂√üe dieses Gitters richtig ausw√§hlen, k√∂nnen wir uns f√ºr jeden POI des ausgew√§hlten Polygons durchaus darauf beschr√§nken, die Abst√§nde zu den Signalen zu berechnen, die in dasselbe Polygon fallen, seine Nachbarzellen und das ist alles.  Der Rest kann weggeworfen werden, er wird sicherlich au√üerhalb der relevanten Grenzen liegen. <br><br>  Spark hat bereits ein fertiges Tool f√ºr die Arbeit mit Gittern - <abbr title="Ich gebe keinen Link. Die Qualit√§t dieses Projekts ist mir zu deprimierend :(">GeoSpark</abbr> .  Der zweite Programmierer fing an, es zu verwenden, und die vorl√§ufige Operation "Ziehen des Datensatzes auf das Raster" erschien.  Aber es wurde nicht viel besser, ein ernstes Problem wurde durch ein anderes ernstes Problem ersetzt. <br><br>  Dies war nun das Problem der "Long Tail" -Nutzer, bei denen die Anzahl der Signale in Millionenh√∂he liegt.  Es gibt nicht viele von ihnen, aber wenn sie sich in der Innenstadt ansammeln, wo der POI hoch ist, und sie sich dort ansammeln, wie es das Gl√ºck wollte, dann wird es immer noch eine geben, egal wie Sie sich in der Geometrie unterteilen (zumindest <a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi</a> , zumindest <a href="https://en.wikipedia.org/wiki/Quadtree">Quadtree</a> ) Polygone, bei denen die Anzahl der Vergleiche einen angemessenen Betrag √ºberschreitet.  Sie m√ºssen aber auch benachbarte Polygone √ºberpr√ºfen, bei denen die Dichte so hoch ist. <br><br>  Und wenn 99% der Partitionen mit schwach ges√§ttigten Polygonen schnell funktionieren, h√§ngt 1% der Spark-Workstations mit Zellen hoher Dichte weiterhin am Sieg, frisst das Ged√§chtnis wie bewusstlos und verdirbt alle Himbeeren.  Spark versucht, alles im Auge zu behalten. Wenn die Gr√∂√üe der Partitionen in RDD stark schwankt, l√§uft die gesamte Optimierung des Speicherverbrauchs den Bach runter, da dies f√ºr die gr√∂√üten Partitionen erforderlich ist. <br><br>  Es stellte sich heraus, dass 99% der Berechnung Hunderte Male mit geometrischer Partitionierung beschleunigt wurden und 1% des langen Schwanzes die gesamte Optimierung auf fast nichts reduzierte. <br><br>  Im Allgemeinen hat der √úbergang zu GeoSpark zu einer Verf√ºnffachung gef√ºhrt, allerdings nur bei der Gr√∂√üe von Executoren, die sehr speichereffizient waren - und dementsprechend auch bei Clustern mit teuren virtuellen Maschinen.  Kurz gesagt, die geometrische Unterteilung f√ºr Geodaten mit hoher Dichte erwies sich als Sackgasse. <br><br>  Und dann war da noch das Gl√ºck in der Person des analytischen Schreibtisches einer der gr√∂√üten japanischen Telekommunikationsunternehmen.  Ein kleines Tochterunternehmen, das auf Geolokalisierungsdaten basiert, die vom Hauptunternehmen gesammelt wurden. <br><br><h3>  Japanische Analysten und Migration von Azure nach AWS </h3><br>  Die Japaner haben eine interessante Mentalit√§t.  Sie selbst haben es nicht eilig, aber wenn ihnen nur ein Gaijin in den Finger bei√üt, werden beide H√§nde abgeschnitten.  Geben Sie niemals die genauen Daten f√ºr Japaner an!  Und wenn Sie anrufen, dann nehmen Sie mindestens die dreifache Menge.  Es wird ungeheuer lang und schwierig sein, die Aufgaben zu koordinieren, und nicht nur die ber√ºhmte japanische Akribie wird st√∂ren, sondern auch der Unterschied im Denken.  M√∂glicherweise bleibt einfach keine Zeit mehr, um die endg√ºltige Version des TOR zu implementieren. <br><br>  Das Projekt zur Integration mit der "Tochter" der japanischen Telekom h√§tte unser Projekt beinahe zum Erliegen gebracht.  Die Aussichten waren gro√üartig, ein exklusiver Datenanbieter f√ºr den verr√ºckten japanischen Werbemarkt zu werden, und das Gesch√§ft ist ein bisschen ... √§h, ich kann ohne Kommentar auskommen. <br><br>  Erstens kein Azure.  Nur AWS, nur Hardcore. <br><br>  Zweitens sollte die Front an ihre Bed√ºrfnisse angepasst werden, die sich im Laufe des Projekts st√§ndig √§nderten.  Marketingfachleute aus diesem B√ºro wollten st√§ndig etwas, das sie selbst nicht genau kannten und das sie nicht wirklich artikulieren konnten, und es musste zehnmal pro Phase wiederholt werden, um die Berechnungslogik f√ºr die n√§chsten neuen Indikatoren im Handumdrehen zu √§ndern. <br><br> <a href=""><img src="https://habrastorage.org/webt/3n/oy/y1/3noyy1wt6pjuqik6ukzfnmcmy9a.png" alt="Ich entschuldige mich f√ºr die Qualit√§t, einen Screenshot aus dem Fehlerbericht gibt es nicht mehr" title="Ich entschuldige mich f√ºr die Qualit√§t, einen Screenshot aus dem Fehlerbericht gibt es nicht mehr"></a> <br><br>  Irgendwann bin ich ein bisschen durchgedreht und habe eine Reihe von ‚Äûelementaren Operationen‚Äú durchgef√ºhrt - ungef√§hr 15 primitive Aktionen auf RDD mit dem Aufrufen grundlegender Methoden wie Joins, Mapping, Ablegen von Standardwerten, Summieren von Spaltenwerten - und anderen derart kleinen Operationen - zu schnell √Ñndern Sie die Logik der Berechnungskette, als ob es sich um eine Reihe von SQL-Anweisungen handeln w√ºrde. <br><br>  (In unserem Fall ist regul√§res Spark-SQL nicht anwendbar, da weder eine strenge Typisierung noch eine strenge Reihe von Feldern vorhanden sind. Sie k√∂nnen dem Datensatz jederzeit beliebig viele zus√§tzliche Felder hinzuf√ºgen, die sich w√§hrend des Prozessablaufs √§ndern Es ist zu schwierig, Metadaten unter sich st√§ndig √§ndernden Bedingungen zu verschreiben.) <br><br>  Die √ºbergeordnete Aufgabe bestand darin, eine beliebige Region Japans auszuw√§hlen und eine Heatmap f√ºr einen beliebigen Zeitraum unter Verwendung einer beliebigen Gruppe von Kategorien mit einer Vielzahl von Indikatoren f√ºr die Deponie zu erstellen.  Welche Art von Indikatoren, wie man sie z√§hlt - der Kunde selbst hat das nicht wirklich verstanden. <br><br>  Der (dh kleine) Testdatensatz mit Benutzersignalen f√ºr 2016-2017, an dem wir die Technologie ausarbeiten mussten, umfasst 5 Terabyte Daten, 14.000.000.000 Datens√§tze.  Allein in Tokio gibt es mehrere Millionen POIs und in der Region Hokkaido 1.600.000 Zellen. <br><br>  Und die Karten f√ºr alle zweitausend Kategorien f√ºr jede der 47 japanischen Perfektionen sollten als "on the fly" betrachtet werden, da sie als Cloud-Service verkauft werden sollten. <br><br>  Eine gro√üartige Aufgabe, um das Gehirn zu brechen.  Irgendwo drei oder vier Gr√∂√üenordnungen h√∂her als unsere damaligen F√§higkeiten in Bezug auf "Berechnungsgeschwindigkeit" und "Datenvolumen". <br><br>  Nachdem wir traurig geworden waren, beschlossen wir dennoch, f√ºr jede Region (den Shinto-G√∂ttern sei Dank, die Japaner mussten die Regionen nicht vereinen) und f√ºr einen Monat eine Vorberechnung vorzunehmen, damit die Heatmap nach zuvor erstellten Scores erstellt wurde.  Nicht in Echtzeit, sondern ein paar Minuten oder zehn Minuten (f√ºr das Zentrum von Tokio).  Die Vorberechnung dauerte mehrere Monate mit Clustern von 25 der leistungsst√§rksten virtuellen Maschinen, die in der AWS-Region Tokio verf√ºgbar sind. <br><br>  Um jedoch in AWS ausgef√ºhrt zu werden, mussten Sie zuerst die Automatisierung unter der AWS-API neu schreiben.  Und verschiedene Clouds bieten zwar nach au√üen hin √§hnliche Dienste an, sind jedoch intern v√∂llig unterschiedlich.  Es ist gut, dass zu diesem Zeitpunkt PowerShell bereits die Release Candidate-Version 6 erreicht hat und Azur-Bindungsskripte f√ºr die Bereitstellung des Clusters und die Ausf√ºhrung der Berechnung unter Linux TeamCity portiert und k√ºhn ausgef√ºhrt werden k√∂nnen (da die Bereitstellung von Servern unter Windows in AWS eine Idee ist )  Genauer gesagt, portieren Sie nicht, sondern √∂ffnen Sie ein vorhandenes Skript auf einem Monitor und schreiben Sie die parallele Implementierung f√ºr eine andere Cloud auf dem zweiten. <br><br>  Au√üerdem ist AWS viel √§lter und daher archaischer als Azure. Au√üerdem ist die Architektur viel √§lter, und die Konfiguration der niedrigeren Infrastrukturebene erfordert viel mehr manuelle Arbeit.  Und die lokale Auktion f√ºr den Verkauf von Computer-Ressourcen bereitet Kopfzerbrechen, wenn Sie m√∂glicherweise nicht die richtige Gr√∂√üe f√ºr Autos zum gew√ºnschten Preis haben und der Kunde kein Budget f√ºr die vollst√§ndige Preisberechnung zuweist. <br><br>  Aber das Hadoop-√ñkosystem selbst in der Amazonas-Inkarnation - EMR - kommt Vanille n√§her und die Arbeit damit ist einfacher als mit HDInsight.  Nun, zumindest mit etwas stellte sich heraus, dass es einfacher war. <br><br>  Aber nicht mit s3.  Hier kam √Ñrger raus, wo sie nicht gewartet haben.  S3 hat undokumentierte Grenzen.  Zum Beispiel kann es in einem Bucket nicht mehr als ~ 11.000.000 Objekte geben, weil sie irgendwo in den Tiefen der API die Schl√ºssel in lexikografischer Reihenfolge f√ºr jede (jede!) Anfrage sortieren und der daf√ºr zugewiesene Puffer einfach keine Sortierung zul√§sst mehr Zeilen, besonders wenn sie lang sind.  Um die Berechnung zu beschleunigen, haben wir am Ende keine Partitionen zusammengef√ºhrt, und irgendwann stie√üen wir auf dieses Limit, wonach der Prozess einfach gestoppt wurde. <br><br>  Nach Ansicht des Verstandes muss das Zusammenf√ºhren durchgef√ºhrt werden, und es gibt sogar ein Tool - das Dienstprogramm s3-dist-cp, dessen Verwendung jedoch separate Kopfschmerzen verursacht.  Die Raubtiere f√ºr Au√üerirdische haben das Dienstprogramm mit Sicherheit geschrieben, es verh√§lt sich so intuitiv.  Und es hat einen schwerwiegenden Fehler: Unter der zusammengef√ºhrten Datei ben√∂tigen Sie so viel Speicherplatz auf HDFS, wie alle Originaldateien ben√∂tigen.  Das Zusammenf√ºhren von Zehntausenden von Partitionsdateien mit einer Gr√∂√üe von Hunderten von Bytes bis Zehntausenden von Megabytes, verteilt auf einen Cluster von 25 Computern, wird sehr lange dauern. <br><br>  Bereits mit einer Million Objekten im Bucket beginnt S3, still und leise Anfragen an ihn zu richten.  Und unter m√∂glichen Konsistenzbedingungen ist dies im Allgemeinen eine Katastrophe - Funken, ohne auf das n√§chste Pult zu warten, kann die vereinbarte Anzahl von Malen fallen.  Es gibt eine L√∂sung: Verwenden Sie das EMRFS-eigene Amazon-Add-On, das jedoch zus√§tzlich zu DynamoDB funktioniert. Dies ist eine sehr teure Sache.  Und mit eigenen Grenzen f√ºr die Anzahl der Anfragen pro Sekunde. <br><br>  Kurz gesagt, wir haben uns aus Zeitgr√ºnden entschlossen, auf das statische Schema zur√ºckzugreifen - einen permanenten Cluster auf Instanzen mit einer relativ geringen Gr√∂√üe bereitzustellen (wenn auch teuer, aber billiger als DynamoDB), alle Terabyte des urspr√ºnglichen und berechneten Datensatzes in HDFS zusammenzuf√ºhren und die Karten lokal zu lesen. <br><br>  Der n√§chste Wendepunkt war jedoch die japanische Forderung, vom erzeugten hexagonalen Gitter auf <abbr title="Ich werde keinen Link mehr geben, Sie werden keine Informationen zu diesem Raster auf Japanisch finden, und kein einziger Online-√úbersetzer kann dieses Dokument normal verarbeiten. Unser Tokio Alexei Polyakov ist Japaner, er konnte irgendwie √ºbersetzen">Japan Mesh umzusteigen</abbr> - die Standardmethode f√ºr die geografische Unterteilung mit rechteckigen Zellen, die nur von den Koordinaten des Punkts abh√§ngen.  Eine sehr gute Sache, da Sie damit den rechenintensiven Schritt ‚ÄûSignale auf das Gitter ziehen‚Äú aufgeben k√∂nnen. <br><br>  Der Nachteil ist, dass das Japan Mesh-Netz nur f√ºr Japan und die Inselgebiete gilt, von denen es historisch behauptet, dass sie es sind, nicht jedoch f√ºr den Rest der Welt.  Aber zumindest f√ºr die Japaner wurde es m√∂glich, den langsamen GeoSpark aufzugeben und die Signale ohne Bezug auf die √§u√üere Geometrie gleichm√§√üig zu verteilen.  Und mit dem Weggang des "langen Schwanzes" beschleunigte sich die Rechnung sofort noch einmal um 10 Uhr. <br><br>  Es ist bedauerlich, dass dies geschah, nachdem wir alle die Sechsecke herausgefunden hatten und viel Geld und Zeit umsonst ausgegeben hatten.  Ein Cluster mit Terabytes vorbereiteter Datens√§tze musste einfach weggeworfen werden. <br><br>  Und auf jeden Fall baten die Japaner noch mitten in der Arbeit darum, die gesamte Infrastruktur von einem AWS-Konto auf ein anderes zu √ºbertragen.  Und als ob Sie sich nicht um die ganze Arbeit k√ºmmern, die Sie am Setup erledigt haben.  Nun, ich konnte zum Zeitpunkt des √úbergangs ein Skript f√ºr die CloudFormation-Vorlage erstellen, sodass die Migration mehr oder weniger reibungslos verlief. <br><br>  Als letzte Kirsche auf dem Kuchen entschieden die Japaner schlie√ülich, dass die Front nicht aufgibt, und sie zogen die Berechnungen auf Wunsch ihrer Kunden manuell durch. Wir danken ihnen f√ºr die Algorithmen (zum ersten Mal haben wir sie alle detailliert dokumentiert - und einige gefunden Fehler) und vorerst.  Nun ... viel Gl√ºck und bis sp√§ter. <br><br>  Brrr  Ich erinnere mich mit Entsetzen und Schaudern an dieses Projekt. <br><br><h3>  Asche Nazg Durbatuluk, Asche Nazg Gimbatul, Asche Nazg Trakatuluk, Ag Burzum Ishi Krimpatul !! </h3><br>  Neben der Dokumentation aller Algorithmen gab es auch allgemeine Verbesserungen. <br><br>  Wir haben einen Studenten in Java Junior kennengelernt und er hat eine Reihe von geografischen Bibliotheken studiert, wodurch er es endlich geschafft hat, die richtige auszuw√§hlen und aus der PostGIS-Umgebung zu werfen. <br><br>  Fr√ºhere Versuche blieben aufgrund mangelnder Genauigkeit erfolglos.  Im Umkreis von drei Kilometern machen die Haversins bereits einen merklichen Fehler f√ºr uns, und die meisten Bibliotheken, die wir von Anfang an zu entnehmen versuchten, waren in den Breitengraden n√∂rdlich von St. Petersburg mies, wodurch L√∂cher oder doppelte √úberlappungen im Raster auftraten.  Und wir Finnen sind Stammkunden, daher ist es wichtig, dass alles in ihren Breitengraden korrekt funktioniert. <br><br>  Bis wir herausfanden, dass wir eine Bibliothek mit einem normalen Geoid ben√∂tigen (vorzugsweise das gleiche wie in PostGIS, WGS84), stimmten die Ergebnisse nicht mit den erwarteten Ergebnissen √ºberein.  Nach dem Wechsel zu GeographicLib wurde der Engpass in Form von Postgre-Verbindungen beseitigt und die letzte Stufe der Berechnung der Geschwindigkeit um das 40-fache beschleunigt.  Golovnyak ging mit der zus√§tzlichen Konfiguration einer separaten RDS-Instanz unter der Basis und dem Hochladen eines Dumps mit POI davon aus, der zu den √ºblichen Datens√§tzen in S3 verschoben wurde.  Vereinigung! <br><br>  Zur gleichen Zeit hat derselbe Sch√ºler genau den Fehler entdeckt und behoben, der dazu f√ºhrte, dass die Karten blasser aussahen, als sie tats√§chlich waren.  Wenn es eine zeitlich unbegrenzte Aufgabe gibt, beneide ich die Sch√ºler. <br><br>  Ein weiterer wichtiger Punkt.  Einmal, zum x-ten Mal, habe ich mir Bindungsskripte angesehen, die ein Spark-Modul nach dem anderen aufrufen, aber mit was f√ºr einem Teufel schlie√üen wir sie kurz? <br><br>  Warum sollten Zwischenergebnisse jedes Mal in S3 oder HDFS gespeichert werden, wenn die endg√ºltige RDD des vorherigen Moduls einfach zum Eingang des n√§chsten Moduls in der Kette umgeleitet werden kann?  Gesagt, getan, MetaRunner wurde in ein paar Stunden geschrieben.  Das Vorhandensein von Commons half dabei sehr, da die Module zu diesem Zeitpunkt ziemlich standardisiert waren, zumal die Parameter der einzelnen Module bereits in derselben task.ini lagen und die Schl√ºsselpr√§fixe ihren Namen entsprachen. <br>  Ihre Aufmerksamkeit wird mit einem Blockdiagramm einer Karte (der letzte Schritt vor der Ausgabe an die Front, aber nicht die endg√ºltige Version), geschrieben √ºber elementare Operationen, dargestellt: <br><br> <a href=""><img src="https://habrastorage.org/webt/al/ke/4h/alke4hk9txojjq8j8lwauoihvqs.png" alt="Flussdiagramm des Heatmap-Vorbereitungsprozesses" title="Flussdiagramm des heatmap-vorbereitungsprozesses"></a> <br><br>  Wenn Sie 24 zwischenzeitliche Aufrufe von HDFS loswerden, wird diese Berechnung speziell um das 50-fache beschleunigt. <br><br>  Was ist jedoch, wenn Sie der Prozessvorlage eine variable Unterst√ºtzung hinzuf√ºgen, damit Sie die Datei "tasks.ini" nicht jedes Mal neu generieren m√ºssen, wenn Sie die Parameter im Eigenschaftenspeicher √§ndern? <br><br>  - Ash Nazg!  Schrie ich.  Die Kollegen sahen sich ratlos an.  Ein Typ hat wegen dieser Japaner ein Dach, aber na ja, das passiert. <br>  "Ash nazg ... burzum-ishi krimpatul", knurrte ich (es hat nicht sehr gut geklappt) und ging zu PM, um die Zusammenf√ºhrung aller 15 (die Anzahl der Heuristiken und Hilfsprogramme nahm allm√§hlich zu) der Berechnungsmodule zu einem einzigen Speicher zu besprechen. <br><br>  Wenn wir die Module miteinander kurzschlie√üen, dann schuften wir nicht mehr mit der Auskleidung aller einzelnen JARs im Klassenpfad des Funkens herum und lassen das gesamte Paket der patentierten Locomizer-Logik (und unserer Hilfsoperationen) zu einem fetten JAR zusammenbauen.  Gleichzeitig und lokal kann jetzt ohne Cluster ausgef√ºhrt werden.  Und was wichtig ist, die Logik zum Parsen von tasks.ini kann von PowerShell-Bindungen in Java-Code √ºbertragen werden, wo die Variablensubstitution viel einfacher ist. <br><br>  Kollegen, die √ºber den Vorschlag nachdenken, das Projekt "Der Ring der Allmacht" zu nennen - ein Ring -, aber ein wenig gesundes Pathos wird niemals schaden. <br><br>  Nachdem ich den Moment der n√§chsten Runde der endlosen Koordination von TK an der Front genutzt hatte, sammelte ich alle Module auf einem Haufen.  Maven ist ein erweitertes Tool zum Aufl√∂sen von Abh√§ngigkeiten in einem Projekt mit mehreren Modulen. Daher war es m√∂glich, die letzten Teile des duplizierten Codes zu bereinigen, Versionen aller Bibliotheken zu vereinheitlichen und Erstellungsoptionen f√ºr lokale und Cloud-Umgebungen zu erstellen.  Dar√ºber hinaus bleibt jedes Modul in einem eigenen Teilprojekt, und der Autor kann ganz unabh√§ngig daran arbeiten, ohne den Rest zu st√∂ren. <br><br>  √úbrigens betrachte ich einen solchen Ansatz mit der Kristallisation von Abstraktionen und der Konstruktion einer Architektur aus einer bestehenden Menge homogener Entit√§ten mehr als den Versuch, eine abstrakte Ebene im Voraus zu entwerfen und in bestimmte Aufgaben umzusetzen.  Ohne etablierte Praktiken und Nutzungsmuster ist es nutzlos, eine Architektur zu entwerfen - alle F√§lle k√∂nnen nicht im Voraus vorhergesehen werden, und die Optionen f√ºr das Verhalten der Benutzer des Systems k√∂nnen sich radikal von den Ideen des Designers unterscheiden. <br><br>  Mit der einheitlichen Logik der Verarbeitung der Parameter konnte ein eindeutiges einheitliches Objektmodell f√ºr die Modulkonfiguration erstellt und die G√ºltigkeit und Konsistenz der Konfigurationen der Module untereinander innerhalb desselben Prozesses normal √ºberpr√ºft werden.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies ist besonders wichtig bei Datens√§tzen im CSV-Format - die Kontrolle der Anzahl und Reihenfolge der Felder in jedem RDD-Datensatz sowie die Richtigkeit der √úbertragung des Datensatzes selbst von der Ausgabe eines Moduls zur Eingabe mehrerer nachfolgender liegt vollst√§ndig auf der aufrufenden Seite. </font><font style="vertical-align: inherit;">Und wenn es einen Kontrollpunkt gibt, kann das schon gut gemacht werden.</font></font><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum gehen wir nicht h√∂her und arbeiten mit RDD und nicht mit Datenrahmen? </font><font style="vertical-align: inherit;">Aus dem gleichen Grund, dass wir kein Spark-SQL verwenden. </font><font style="vertical-align: inherit;">Dar√ºber hinaus ist die Implementierung von Spark die letzte, letzte Stufe des Codes, der mit Whitepaper beginnt, vollst√§ndig in Python debuggt und erst dann in wenigen Schritten auf die produktivste Version optimiert wird. </font><font style="vertical-align: inherit;">Und je n√§her an den Primitiven der Basisbibliothek, desto schneller wird der Code normalerweise ausgef√ºhrt.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">... wenn die H√§nde des Entwicklers aus seinen Schultern wachsen und sein Kopf hell ist. Theoretisch. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es stellt sich heraus, dass es unter unseren Bedingungen viel einfacher ist, die Zeile der urspr√ºnglichen CSV-Datei in Form eines kompakten nativen Hadoup-Texts (unter der Haube handelt es sich nur um ein Array von Bytes) zu verschieben und nur die Spalten zu beschreiben, die der aktuelle Vorgang kennt, und zwar nur f√ºr diesen. Entsprechend den Ergebnissen von Experimenten ergeben Datenrahmen einen gr√∂√üeren Overhead f√ºr den Speicherverbrauch als die Notwendigkeit, CSV am Eingang jeder Operation zu analysieren und am Ausgang wieder in Text zu komprimieren. Gut und doch - es ist wichtig, dass wir die M√∂glichkeit behalten, zwischengeschaltete RDDs nach jedem Schritt manuell zu partitionieren, da sich neue Datasets aus dem Speicher mit ihnen vermischen k√∂nnen (dies ist im Diagramm deutlich sichtbar), sodass Sie immer noch eine Ebene tiefer gehen m√ºssen, egal, wie Sie auf der Ebene bleiben m√∂chten Logik-Whitepaper.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aber im "Low-Level" -Code in Java gibt es auch Pluspunkte. Wenn Sie beispielsweise die Betriebsparameter (sowie die erwarteten und generierten RDDs) in den Metadaten beschreiben, k√∂nnen Sie automatisch sowohl Dokumentation als auch ein Konfigurationsbeispiel daf√ºr generieren und diese nicht mehr manuell schreiben. Und die Docks werden nach jedem Build immer relevant sein. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Konfigurationsdatei tasks.ini selbst wurde aus einem heterogenen Satz von Parametern f√ºr jedes Modul sofort zu einem Programm in einer Art deklarativer Programmiersprache. Nicht sehr sch√∂n, aber intern logisch und relativ lesbar. Das Aufr√ºsten auf echtes DSL mit eigener Syntax ist kein Problem, aber ich habe es nicht als unn√∂tig angesehen. Wenig sp√§ter f√ºgte er JSON jedoch mit einem visuellen Editor eine Ansicht f√ºr die zuk√ºnftige Front hinzu.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein kurzgeschlossener Prozess erhielt durchschnittlich drei- bis f√ºnfmal schneller als eine Kette von Einzelaufrufen zu Spark-Jobs. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nicht hundert Mal, denn jetzt k√∂nnen im Rahmen desselben Spark-Jobs Schritte von Aufgaben unterschiedlicher Komplexit√§t und Datens√§ttigung gemischt werden. Infolgedessen hat die Feinabstimmung der Clusterparameter f√ºr jeden der Teile eines mehrstufigen Prozesses keine praktische Bedeutung mehr. Allm√§hlich und f√ºr eine solche Option wurden einige allgemeine Muster gefunden, die es erm√∂glichten, Voreinstellungen f√ºr die Clustergr√∂√üe nur auf der Grundlage der Gr√∂√üe des urspr√ºnglichen Datensatzes und der Gesamtzahl der Schritte in der Verarbeitungsprozessvorlage auszuw√§hlen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um diese Phase zusammenzufassen: Am Ende unserer Arbeit mit den Japanern hatten wir bereits einige Tools entwickelt:</font></font><br><br><ul><li>          ,           , </li><li> ,    ,             DSL  , </li><li>   ,    ‚Äî   , </li><li>      AWS,           . </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aber was nicht geklappt hat, war die Front. </font><font style="vertical-align: inherit;">Die alte Web-Benutzeroberfl√§che von Locomizer ist hoffnungslos veraltet. Wir haben es nie geschafft, die neuen Japaner in einen vern√ºnftigen Zustand zu versetzen, bevor sie ihn vollst√§ndig aufgegeben haben. </font><font style="vertical-align: inherit;">Ja, und der Backend-Code dieser Benutzeroberfl√§che selbst, der in einer dunklen Oktobernacht mit meinem linken hinteren Fu√ü geschrieben wurde, konnte ich allein wegen des gro√üen Volumens nicht bis zum Ende k√§mmen.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Optimierung und Geokatarsis mit Uber H3 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nach dem Ausatmen kehrten wir zu privaten Projekten zur√ºck. Die Stimmung nach den Japanern war ehrlich gesagt, das ganze Team war sehr mittelm√§√üig. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aber ich habe mich endlich der Notwendigkeit entledigt, ein Back-up an der Front mit seinen Bogomersssky, holm, holm, spring zu unterhalten. (Dies ist meine pers√∂nliche Meinung. EE gef√§llt mir nicht ein bisschen weniger, da es weniger Autogie und implizite Standardeinstellungen hat. Es spielt also keine Rolle, was f√ºr ein schrecklicher Mist es ist, RESTs zu schreiben.) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gab eine Zeit, in jedes Modul mit einer Sucht zu schauen.</font></font><br><blockquote>     ‚Äî        ,       .            ,    ,    ,       .   -      .       ‚Äî            .       ,         ‚Äî    . </blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nicht, dass ich mir den Code meiner Kollegen unaufmerksam angesehen h√§tte. Nur jeder ist mit der ihm √ºbertragenen Aufgabe besch√§ftigt, und w√§hrend sie von ihm mit dem gew√ºnschten Ergebnis ausgef√ºhrt wird, darf der Entwickler bei seiner Arbeit nicht gest√∂rt werden. Wenn der Algorithmus korrekt funktioniert und dies durch Tests best√§tigt wird, ist alles in Ordnung. Je nach Arbeitsgeschwindigkeit wird - es ist akzeptabel oder anders - die Entscheidung vom Ministerpr√§sidenten getroffen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich greife erst ein, wenn ich ein hohes Risiko f√ºr weitere Unterst√ºtzung bei der Entscheidung des Entwicklers bei der Implementierung einer neuen Aufgabe erkenne. Und die alten und h√§sslichen Module, die unter Zar Gorokh von jemandem geschrieben wurden, der das Projekt schon lange verlassen hat, aber f√ºr das Gesch√§ft notwendig ist, werden auf einem brauchbaren Niveau gehalten, so wie es ist, und egal, wie sehr es nach ihnen riecht. Es klingt zynisch, aber ich bin ein Pragmatiker, kein Idealist. Das Ergebnis der Arbeit ist mir wichtiger als die Sch√∂nheit des Codes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aber manchmal ist es notwendig, die technischen Schulden zu begleichen, damit er das Projekt nicht unter seinem eigenen Gewicht begr√§bt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spark ist eine Bibliothek auf sehr hohem Niveau. Es erm√∂glicht Ihnen, Operationen an RDD auf viele verschiedene Arten durchzuf√ºhren, die zum gleichen Ergebnis f√ºhren, und jede Methode kann mehrere Teile mit einigen ausgezeichneten Optionen enthalten. Sie m√ºssen die Beschreibung der einzelnen Elemente sorgf√§ltig lesen und im Zweifelsfall in die Quelle klettern, um zu verstehen, welches in welchem ‚Äã‚ÄãFall optimal ist. Das Ergebnis ist das gleiche, aber der Unterschied in der Geschwindigkeit seiner Berechnung kann mehrere Male sein. Wenn die Logik einer Heuristik in Spark hundert Codezeilen entfaltet, m√ºssen Sie besonders vorsichtig sein, um die am besten geeigneten Methoden zum Transformieren der Daten zu verwenden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hochsprachen - sie sind so, dass Sie abstrakt denken.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gleichzeitig sollte sich der Entwickler des niedrigen Niveaus bewusst sein, egal wie sehr er in hohe Abstraktionen aufsteigt. Beispielsweise wird jedes Lambda, das an die .map () -Methode √ºbergeben wird, in der der Speicher f√ºr ein fett gedrucktes Objekt zugeordnet ist, f√ºr jeden Datensatz erneut aufgerufen und das gleiche Objekt neu zugeordnet, und keine der vorhandenen JVMs mag fett gedruckte wiederholte Zuordnungen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und wenn Sie √ºber die Unterst√ºtzung von Code nachdenken, w√§re es sch√∂n, Teile des Algorithmus zu haben, die durch interne Logik verbunden sind, aber gleichzeitig f√ºr einige Parameterwerte vollst√§ndig vom Rest des Codes isoliert sind, insbesondere wenn sich diese Teile am Anfang oder Ende des Algorithmus befinden. Sie k√∂nnen in der Regel in einem separaten Arbeitsgang entnommen werden, gleichzeitig werden Tests mit vollst√§ndiger Abdeckung aller F√§lle k√ºrzer.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fr√ºher war es verfr√ºht, sich mit Optimierung zu befassen, aber jetzt ist es soweit, und f√ºr ein paar Monate bin ich mit meinem Kopf in den Darm von Computermodulen eingetaucht, deren Profiling-Code √ºber zwei Jahre von meinen Kollegen geschrieben wurde. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Als ich dort getaucht bin, hatte One Ring 29 Operationen (einige Module enthalten mehr als eine). Als es herauskam - 43, und jedes schneller als das Original, von ein paar Prozent bis zehnmal. Wertvoller ist jedoch, dass die Vorg√§nge, die zuvor mit Daten zu Partitionen mit 10.000 Elementen unterdr√ºckt wurden, jetzt problemlos auf Teilen in einer Million Datens√§tzen verarbeitet werden k√∂nnen. An einigen Stellen musste ich auf die Flexibilit√§t und Lesbarkeit des Codes verzichten, an einigen Stellen kostete es einen einfachen Ersatz von .map () durch .mapPartition (), aber der Code st√ºrzte nicht mehr ab.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gab nur einen Engpass - Geofencing in einer beliebigen Region. Es war immer noch eine seltsame Hybridl√∂sung mit einem externen Netz. Es war m√∂glich, Japan Mesh f√ºr Japan zu verwenden, aber f√ºr den Rest der Welt war es erforderlich, nach einer geeigneten Variante eines dynamischen Gitters zu suchen, die nur von den Koordinaten des Punkts abh√§ngt und bequem zu verwenden ist. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine solche Option wurde gefunden - </font></font><a href="https://uber.github.io/h3/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uber H3</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Soweit ich wei√ü, ist der sechseckige Baum mit dem Namen H3 verschl√ºsselt - und dies ist ein geografisches Raster mit gro√üartigen Funktionen. Es ist √ºber den gesamten Koordinatenbereich stabil, unglaublich schnell (der native Code wird genannt), gibt Zellen mit einheitlicher Gr√∂√üe ohne L√ºcken auf dem gesamten Land und erm√∂glicht es Ihnen, eine Reihe verschiedener Optionen zum Abdecken von Polygonen, Punkten und Pfaden zu erstellen. Au√üerdem hat eine hexagonale Gitterzelle eine minimale Anzahl von Nachbarn, und die n√§chste Ebene umfasst sieben Zellen der vorherigen, die genau √ºber der Mitte der zugrunde liegenden Zelle liegen. Dies ist praktisch, wenn Sie Karten zusammenfassen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit dem √úbergang zu H3 scheint sich das Puzzle vollst√§ndig entwickelt zu haben.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn wir uns mit dem vergleichen, was es zu Beginn vor 2,5 Jahren war, dann kamen wir von den Wochen, die f√ºr eine ungl√ºckliche W√§rmekarte auf einem Datensatz verbracht wurden, zu ein paar Millionen Signalen zu den Minuten, die f√ºr Dutzende Karten mit Datens√§tzen ausgegeben wurden, deren Gr√∂√üe Der Datenanalyst schenkt nicht viel Aufmerksamkeit (Sie m√ºssen meckern, wenn er die Voreinstellung f√ºr die Clustergr√∂√üe zu hoch einstellt, wenn das Schreiben des Ergebnisses in S3 l√§nger dauert als die Berechnung selbst). Und er schaut sich TC nicht mehr selbst an, sondern verstopft nur die Parametermatrix irgendwo zu Hause und zieht die erforderliche Anzahl an erforderlichen Builds mit der Python.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√ºgen Sie eine neue Operation hinzu - Sie m√ºssen nur die Operationsklasse korrekt implementieren (Sie k√∂nnen auch die Scala verwenden, wenn Sie m√∂chten), sie mit Metadaten einschlie√üen, sie in Ihre Konfiguration aufnehmen und One Ring wird dann herausfinden, ob Sie die neue Heuristik oder die Verarbeitung in der Kette korrekt aufrufen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nun, alles funktioniert sowohl lokal als auch in AWS. </font><font style="vertical-align: inherit;">Es wird auch in einer anderen Cloud sein, wenn es S3 unterst√ºtzt, und Spark kann dort √ºber </font></font><abbr title="REST-Launcher f√ºr Spark"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Livy abgerufen werden</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - und wir haben alle anderen externen Abh√§ngigkeiten beseitigt.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ganz in Wei√ü </font></font></h3><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Gandalf?!</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wir haben aber immer noch keine Front, um flexible Prozesse in Gang zu setzen. Und die Vorlagen solcher Prozesse selbst m√ºssen auf altmodische Weise geschrieben werden - von Hand in VSCode, aber ich wollte eine Maus in einem Editor sein, der Visio √§hnelt. So etwas in der Art: </font><font style="vertical-align: inherit;">Ich habe im Rahmen von One Ring sogar einen kleinen REST-Service erstellt, der alles enth√§lt, was Sie zum Schreiben eines solchen Editors ben√∂tigen. Das letzte Mal, als ich an der Front gearbeitet habe, war das vor etwa 10 Jahren und nicht in den Kursen der aktuellen Trends. Es ist nicht f√ºr JSF, dass ich es niete, es wird nicht einmal Retro sein, sondern schon eine Art Nekro. Es w√§re sch√∂n, daraus ein statisches SPA f√ºr etwas Modernes zu machen. Nur ich habe keine Ahnung was. </font><font style="vertical-align: inherit;">Mein </font><s><font style="vertical-align: inherit;">egoistisches</font></s><font style="vertical-align: inherit;"> pers√∂nliches Interesse, </font><a href="https://github.com/PastorGL/OneRing"><font style="vertical-align: inherit;">One Ring-</font></a><font style="vertical-align: inherit;"> Code zu enth√ºllen</font></font><br><br> <a href=""><img src="https://habrastorage.org/webt/g2/su/hr/g2suhrumf4-lmrwasnribe2zokc.png" alt="Mocap-Oberfl√§che zum Bearbeiten eines Prozesses" title="Mocap-Oberfl√§che zum Bearbeiten eines Prozesses"></a> <br><br><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><s><font style="vertical-align: inherit;"></font></s><font style="vertical-align: inherit;"></font><a href="https://github.com/PastorGL/OneRing"><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Ich beende das Repository mit Inhalten, aber Sie k√∂nnen es jetzt ansehen.) Ich hoffe, es ist klar. </font><font style="vertical-align: inherit;">Und wenn es jemanden gibt, der mutig genug ist, </font></font><a href="https://github.com/PastorGL/OneRing/issues/1"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">diese Aufgabe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> anzugehen </font><font style="vertical-align: inherit;">, schreibe ich eine vern√ºnftige technische Aufgabe mit Spezifikationen.</font></font><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im Allgemeinen m√∂chten wir, das Data Engineer-Team, das fertige Tool jedoch nicht in unserem Schrank aufbewahren. </font><font style="vertical-align: inherit;">Wir sind sicher: Es wird nicht nur uns n√ºtzen. </font><font style="vertical-align: inherit;">Und das nicht nur f√ºr die Bed√ºrfnisse von GIS, sondern generell f√ºr jede Burst-Verarbeitung von Datens√§tzen mit parametrierbaren Verarbeitungsschritten.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im letzten Artikel (oder in einigen Artikeln dauert etwas zu lange) werde ich Ihnen erkl√§ren, wie Sie One Ring f√ºr Ihre Forschungsaufgaben erstellen, ausf√ºhren, erweitern und verwenden. </font></font><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">* Der One Ring OSS-Quellcode enth√§lt keine propriet√§ren heuristischen Locomizer-Algorithmen. </font><font style="vertical-align: inherit;">Das Repository wird jedoch Schnittstellen und Beschreibungen enthalten, anhand derer die freien Implementierungen dieser Heuristiken mithilfe der Reinraummethode neu erstellt werden k√∂nnen, ohne dass ich dazu aufgefordert werde, den Code einzugeben.</font></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Danksagung </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">... an Kollegen Gregory </font></font><a href="https://github.com/pomadchin"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pomadchin</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr sachliche Kommentare zum Thema und </font></font><a href="https://habr.com/ru/users/sshikov/" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sshikov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr eine unabh√§ngige Bewertung der Lesbarkeit des Textes sowie an Anton </font></font><a href="https://habr.com/ru/users/dartov/" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dartov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Zadorozhny f√ºr ein unerwartetes Feedback zum vorherigen Artikel in der Serie.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de485988/">https://habr.com/ru/post/de485988/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de485968/index.html">Und wieder Bypass-Schl√∂sser. RouterOS + BGP + OSPF</a></li>
<li><a href="../de485970/index.html">K√ºrzlich 30 Top-Interviews: Entwicklung, Design, Sciencepop und Lebensstil</a></li>
<li><a href="../de485972/index.html">Regressionsanalysemethoden in Data Science</a></li>
<li><a href="../de485974/index.html">Raspberry Pi und SIM7600E 4G HAT Modem</a></li>
<li><a href="../de485986/index.html">Top 5 Lokalisierungstrends im Jahr 2020</a></li>
<li><a href="../de485990/index.html">Automatisierung t√∂tet?</a></li>
<li><a href="../de485996/index.html">Elastic APM in der App</a></li>
<li><a href="../de485998/index.html">LyX: Allgemeine Bemerkungen. Teil 2</a></li>
<li><a href="../de486000/index.html">ADSM3. IPAM / DCIM-Systeme</a></li>
<li><a href="../de486006/index.html">Speichern Sie den Chat-Status auf dem Stapel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
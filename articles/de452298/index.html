<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚òÑÔ∏è üë©üèæ ü§¶üèø Optimierung der Speicherbereinigung in einem hoch geladenen .NET-Dienst üóΩ üë¥ üè≥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="T√§glich arbeiten Zehntausende von Mitarbeitern aus mehreren tausend Organisationen auf der ganzen Welt bei Pyrus. Wir betrachten die Reaktionsf√§higkei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimierung der Speicherbereinigung in einem hoch geladenen .NET-Dienst</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452298/">  T√§glich arbeiten Zehntausende von Mitarbeitern aus mehreren tausend Organisationen auf der ganzen Welt bei Pyrus.  Wir betrachten die Reaktionsf√§higkeit des Dienstes (die Geschwindigkeit der Bearbeitung von Anfragen) als einen wichtigen Wettbewerbsvorteil, da dies die Benutzererfahrung direkt beeinflusst.  Die Schl√ºsselmetrik f√ºr uns ist der ‚ÄûProzentsatz langsamer Abfragen‚Äú.  Bei der Untersuchung des Verhaltens haben wir festgestellt, dass auf den Anwendungsservern einmal pro Minute Pausen von etwa 1000 ms L√§nge auftreten.  In diesen Intervallen antwortet der Server nicht und es entsteht eine Warteschlange mit mehreren Dutzend Anforderungen.  Die Suche nach den Ursachen und die Beseitigung von Engp√§ssen, die durch die Speicherbereinigung in der Anwendung verursacht werden, werden in diesem Artikel erl√§utert. <br><br><img src="https://habrastorage.org/webt/fu/1s/j9/fu1sj9ixpj4nc633ikhwblbhlfs.jpeg"><br><a name="habracut"></a><br>  Moderne Programmiersprachen k√∂nnen in zwei Gruppen unterteilt werden.  In Sprachen wie C / C ++ oder Rust wird die manuelle Speicherverwaltung verwendet, sodass Programmierer mehr Zeit damit verbringen, Code zu schreiben, die Lebensdauer von Objekten zu verwalten und dann zu debuggen.  Gleichzeitig sind Fehler aufgrund unsachgem√§√üer Speichernutzung einige der am schwierigsten zu debuggenden Fehler, sodass die modernste Entwicklung in Sprachen mit automatischer Speicherverwaltung durchgef√ºhrt wird.  Dazu geh√∂ren beispielsweise Java, C #, Python, Ruby, Go, PHP, JavaScript usw.  Programmierer sparen Entwicklungszeit, aber Sie m√ºssen f√ºr die zus√§tzliche Ausf√ºhrungszeit bezahlen, die das Programm regelm√§√üig f√ºr die Speicherbereinigung ben√∂tigt. Dadurch wird Speicherplatz frei, der von Objekten belegt wird, zu denen im Programm keine Links mehr vorhanden sind.  In kleinen Programmen ist diese Zeit vernachl√§ssigbar, aber mit zunehmender Anzahl von Objekten und der Intensit√§t ihrer Erstellung leistet die Speicherbereinigung einen sp√ºrbaren Beitrag zur Gesamtausf√ºhrungszeit des Programms. <br><br>  Pyrus-Webserver werden auf der .NET-Plattform ausgef√ºhrt, die die automatische Speicherverwaltung verwendet.  Die meisten M√ºllsammlungen sind "Stop the World", d. H.  Zum Zeitpunkt ihrer Arbeit stoppen sie alle Threads der Anwendung.  Nicht blockierende (Hintergrund-) Assemblys stoppen tats√§chlich auch alle Threads, jedoch f√ºr einen sehr kurzen Zeitraum.  W√§hrend der Thread-Blockierung verarbeitet der Server keine Anforderungen, vorhandene Anforderungen frieren ein, neue werden zur Warteschlange hinzugef√ºgt.  Infolgedessen werden Anforderungen, die zum Zeitpunkt der Speicherbereinigung verarbeitet wurden, direkt verlangsamt, und Anforderungen werden aufgrund der angesammelten Warteschlangen unmittelbar nach Abschluss der Speicherbereinigung langsamer verarbeitet.  Dies verschlechtert die Metrik "Prozentsatz langsamer Abfragen". <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ausger√ºstet</a> mit dem k√ºrzlich ver√∂ffentlichten Buch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konrad Kokosa: Pro .NET Memory Management</a> (dar√ºber, wie wir sein erstes Exemplar in zwei Tagen nach Russland gebracht haben, k√∂nnen Sie einen separaten Beitrag schreiben), das sich ausschlie√ülich dem Thema Speicherverwaltung in .NET widmet, haben wir begonnen, das Problem zu untersuchen. <br><br><h2>  Messung </h2><br>  Zum Profilieren des Pyrus-Webservers haben wir das PerfView-Dienstprogramm ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/Microsoft/perfview</a> ) verwendet, das f√ºr die Profilerstellung von .NET-Anwendungen gesch√§rft wurde.  Das Dienstprogramm basiert auf der ETW-Engine (Event Tracing for Windows) und hat nur minimale Auswirkungen auf die Leistung der Profilanwendung, sodass sie auf einem Kampfserver verwendet werden kann.  Dar√ºber hinaus h√§ngt die Auswirkung auf die Leistung davon ab, welche Arten von Ereignissen und welche Informationen wir sammeln.  Wir sammeln nichts - die Anwendung funktioniert wie gewohnt.  Au√üerdem erfordert PerfView weder eine Neukompilierung noch einen Neustart der Anwendung. <br><br>  F√ºhren Sie den PerfView-Trace mit dem Parameter / GCCollectOnly aus (Trace-Zeit 1,5 Stunden).  In diesem Modus werden nur Speicherbereinigungsereignisse erfasst und die Leistung wird nur minimal beeintr√§chtigt.  Schauen wir uns den Speichergruppen- / GCStats-Ablaufverfolgungsbericht und darin eine Zusammenfassung der Garbage Collector-Ereignisse an: <br><br><img src="https://habrastorage.org/webt/v4/ia/cd/v4iacdyso10-0toycwyijfm0zbm.png"><br><br>  Hier sehen wir mehrere interessante Indikatoren gleichzeitig: <br><ul><li>  Die durchschnittliche Erstellungspausenzeit in der 2. Generation betr√§gt 700 Millisekunden, und die maximale Pause betr√§gt etwa eine Sekunde.  Diese Abbildung zeigt den Zeitpunkt, zu dem alle Threads in der .NET-Anwendung beendet werden. Insbesondere wird diese Pause allen verarbeiteten Anforderungen hinzugef√ºgt. <br></li><li>  Die Anzahl der Baugruppen der 2. Generation ist vergleichbar mit der 1. Generation und liegt geringf√ºgig unter der Anzahl der Baugruppen der 0. Generation. <br></li><li>  In der Spalte Induziert sind 53 Baugruppen der 2. Generation aufgef√ºhrt.  Die induzierte Assemblierung ist das Ergebnis eines expliziten Aufrufs von GC.Collect ().  In unserem Code haben wir keinen einzigen Aufruf dieser Methode gefunden, was bedeutet, dass einige der von unserer Anwendung verwendeten Bibliotheken schuld sind. <br></li></ul><br>  Lassen Sie uns die Beobachtung √ºber die Anzahl der Speicherbereinigungen erkl√§ren.  Die Idee, Objekte durch ihre Lebensdauer zu teilen, basiert auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Generationshypothese</a> : Ein erheblicher Teil der erstellten Objekte stirbt schnell und die meisten anderen leben lange (mit anderen Worten, wenige Objekte mit einer ‚Äûdurchschnittlichen‚Äú Lebensdauer).  In diesem Modus ist der .NET-Garbage Collector inhaftiert, und in diesem Modus sollten die Assemblys der zweiten Generation viel kleiner sein als die der 0. Generation.  Das hei√üt, f√ºr den optimalen Betrieb des Garbage Collectors m√ºssen wir die Arbeit unserer Anwendung auf die Generationshypothese abstimmen.  Formulieren wir die Regel wie folgt: Objekte m√ºssen entweder schnell sterben, ohne f√ºr die √§ltere Generation zu √ºberleben, oder danach leben und f√ºr immer dort leben.  Diese Regel gilt auch f√ºr andere Plattformen, die eine automatische Speicherverwaltung mit Generationstrennung verwenden, z. B. Java. <br><br>  Die f√ºr uns interessanten Daten k√∂nnen aus einer anderen Tabelle im GCStats-Bericht extrahiert werden: <br><br><img src="https://habrastorage.org/webt/m5/7y/je/m57yjedgbkwfpbiwmjkvnbhgl4o.png"><br><br>  In einigen F√§llen versucht eine Anwendung, ein gro√ües Objekt zu erstellen (in .NET Framework werden Objekte mit einer Gr√∂√üe von&gt; 85.000 Byte im LOH - Heap f√ºr gro√üe Objekte erstellt) und muss auf den Abschluss der Assembly der 2. Generation warten, die parallel im Hintergrund stattfindet.  Diese Pausen des Allokators sind nicht so kritisch wie die Pausen des Garbage Collector, da sie nur einen Thread betreffen.  Zuvor haben wir .NET Framework Version 4.6.1 verwendet. In Version 4.7.1 hat Microsoft den Garbage Collector fertiggestellt. Jetzt k√∂nnen Sie w√§hrend der Hintergrundgenerierung der 2. Generation Speicher im Heap f√ºr gro√üe Objekte zuweisen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://docs.microsoft.com / ru-ru / dotnet / framework / whats-new / # gemeinsame Sprache-Laufzeit-clr</a> <br>  Aus diesem Grund haben wir zu diesem Zeitpunkt ein Upgrade auf die neueste Version 4.7.2 durchgef√ºhrt. <br><br><h2>  Builds der 2. Generation </h2><br>  Warum haben wir so viele Builds der √§lteren Generation?  Die erste Annahme ist, dass wir einen Speicherverlust haben.  Um diese Hypothese zu testen, werfen wir einen Blick auf die Gr√∂√üe der zweiten Generation (wir haben die √úberwachung der entsprechenden Leistungsindikatoren in Zabbix eingerichtet).  Aus den Diagrammen der Gr√∂√üe der 2. Generation f√ºr 2 Pyrus-Server ist ersichtlich, dass ihre Gr√∂√üe zuerst zunimmt (haupts√§chlich aufgrund des F√ºllens von Caches), sich dann aber stabilisiert (gro√üe Fehler im Diagramm - regelm√§√üiger Neustart des Webdienstes zur Aktualisierung der Version): <br><br><img src="https://habrastorage.org/webt/gg/lc/ce/gglcce4tssnhzgcjfhesec9rcja.png"><br><br>  Dies bedeutet, dass keine merklichen Speicherverluste auftreten, dh eine gro√üe Anzahl von Baugruppen der 2. Generation tritt aus einem anderen Grund auf.  Die n√§chste Hypothese ist, dass es viel Speicherverkehr gibt, d. H. Viele Objekte fallen in die 2. Generation und viele Objekte sterben dort ab.  PerfView verf√ºgt √ºber einen / GCOnly-Modus, um solche Objekte zu finden.  Beachten Sie in den Ablaufverfolgungsberichten die Stapel "Gen 2-Objekttod (Grobabtastung)", die eine Auswahl von Objekten enthalten, die in der 2. Generation sterben, sowie Aufrufstapel der Orte, an denen diese Objekte erstellt wurden.  Hier sehen wir folgende Ergebnisse: <br><br><img src="https://habrastorage.org/webt/h7/r2/d0/h7r2d0htyxsnaqrr_ekn_ybilti.png"><br><br>  Nachdem wir die Zeile ge√∂ffnet haben, sehen wir im Inneren einen Aufrufstapel der Stellen im Code, die Objekte erstellen, die der 2. Generation gerecht werden.  Unter ihnen: <br><ul><li>  System.Byte [] Wenn Sie nach innen schauen, werden Sie feststellen, dass mehr als die H√§lfte Puffer f√ºr die Serialisierung in JSON sind: <br></li></ul><br><img src="https://habrastorage.org/webt/la/up/6v/laup6v0mho5e1tbwjfkfmsgdhog.png"><br><br><ul><li>  Slot [System.Int32] [] (dies ist Teil der HashSet-Implementierung), System.Int32 [] usw.  Dies ist unser Code, der Client-Caches berechnet - die Verzeichnisse, Formulare, Listen, Freunde usw., die dieser Benutzer sieht und die in seinem Browser oder seiner mobilen Anwendung zwischengespeichert werden: <br></li></ul><br><img src="https://habrastorage.org/webt/dx/et/jy/dxetjyvj2ande72qrod6leza6i8.png"><br><br><img src="https://habrastorage.org/webt/v6/k6/r-/v6k6r-wq0qeof0edb6h5jvct-he.png"><br><br>  Interessanterweise sind die Puffer f√ºr JSON und f√ºr die Berechnung von Client-Caches alle tempor√§re Objekte, die auf derselben Anforderung leben.  Warum werden sie der 2. Generation gerecht?  Beachten Sie, dass alle diese Objekte Arrays von ziemlich gro√üer Gr√∂√üe sind.  Bei einer Gr√∂√üe&gt; 85000 Byte wird der Speicher f√ºr sie im Large Object Heap zugewiesen, der nur zusammen mit der 2. Generation gesammelt wird. <br><br>  √ñffnen Sie zur √úberpr√ºfung den Abschnitt 'GC Heap Alloc Ignore Free (Coarse Sampling) -Stapel' in den perfview / GCOnly-Ergebnissen.  Dort sehen wir die LargeObject-Zeile, in der PerfView die Erstellung gro√üer Objekte gruppiert, und im Inneren sehen wir dieselben Arrays, die wir in der vorherigen Analyse gesehen haben.  Wir erkennen die Hauptursache f√ºr die Probleme mit dem Garbage Collector an: Wir erstellen viele tempor√§re gro√üe Objekte. <br><br><img src="https://habrastorage.org/webt/sy/kr/lk/sykrlkgbmvl9jyny5hl1_ftg4ee.png"><br><br><img src="https://habrastorage.org/webt/f9/6q/mp/f96qmplnj4devma1buedg6fpo8q.png"><br><br><h2>  √Ñnderungen im Pyrus-System </h2><br>  Basierend auf den Messergebnissen haben wir die Hauptbereiche weiterer Arbeiten identifiziert: den Kampf gegen gro√üe Objekte bei der Berechnung von Client-Caches und die Serialisierung in JSON.  Es gibt verschiedene L√∂sungen f√ºr dieses Problem: <br><ul><li>  Am einfachsten ist es, keine gro√üen Objekte zu erstellen.  Wenn beispielsweise der gro√üe Puffer B in sequentiellen Datentransformationen A-&gt; B-&gt; C verwendet wird, k√∂nnen diese Transformationen manchmal kombiniert werden, indem sie in A-&gt; C umgewandelt werden und das Erstellen von Objekt B entf√§llt. Diese Option ist nicht immer anwendbar, aber sie ist anwendbar das einfachste und effektivste. <br></li><li>  Pool von Objekten.  Anstatt st√§ndig neue Objekte zu erstellen und sie wegzuwerfen und den Garbage Collector zu laden, k√∂nnen wir eine Sammlung freier Objekte speichern.  Im einfachsten Fall, wenn wir ein neues Objekt ben√∂tigen, nehmen wir es aus dem Pool oder erstellen ein neues, wenn der Pool leer ist.  Wenn wir das Objekt nicht mehr ben√∂tigen, geben wir es an den Pool zur√ºck.  Ein gutes Beispiel ist ArrayPool in .NET Core, das auch in .NET Framework als Teil des System.Buffers Nuget-Pakets verf√ºgbar ist. <br></li><li>  Verwenden Sie kleine statt gro√üe Objekte. <br></li></ul><br>  Betrachten wir beide F√§lle gro√üer Objekte getrennt - das Berechnen von Client-Caches und das Serialisieren in JSON. <br><br><h2>  Client-Cache-Berechnung </h2><br>  Der Pyrus-Webclient und mobile Anwendungen speichern die dem Benutzer zur Verf√ºgung stehenden Daten (Projekte, Formulare, Benutzer usw.) zwischen. Das Caching wird verwendet, um die Arbeit zu beschleunigen. Es ist auch f√ºr die Arbeit im Offline-Modus erforderlich.  Caches werden auf dem Server berechnet und an den Client √ºbertragen.  Sie sind f√ºr jeden Benutzer individuell, da sie von ihren Zugriffsrechten abh√§ngen, und werden h√§ufig aktualisiert, beispielsweise wenn die Verzeichnisse ge√§ndert werden, auf die er Zugriff hat. <br><br>  Daher werden regelm√§√üig viele Client-Cache-Berechnungen auf dem Server durchgef√ºhrt und viele tempor√§re kurzlebige Objekte erstellt.  Wenn der Benutzer eine gro√üe Organisation ist, kann er auf viele Objekte zugreifen. Die Client-Caches f√ºr ihn sind gro√ü.  Aus diesem Grund haben wir die Zuweisung von Speicher f√ºr gro√üe tempor√§re Arrays im Heap f√ºr gro√üe Objekte gesehen. <br><br>  Lassen Sie uns die vorgeschlagenen Optionen analysieren, um die Erstellung gro√üer Objekte zu vermeiden: <br><ul><li>  Vollst√§ndige Entsorgung gro√üer Gegenst√§nde.  Dieser Ansatz ist nicht anwendbar, da Datenaufbereitungsalgorithmen unter anderem das Sortieren und Vereinigen von Mengen verwenden und tempor√§re Puffer erfordern. <br></li><li>  Verwenden eines Pools von Objekten.  Dieser Ansatz hat Schwierigkeiten: <br><ul><li>  Die Vielfalt der verwendeten Sammlungen und die Arten der darin enthaltenen Elemente: HashSet, List und Array werden verwendet (die beiden letzteren k√∂nnen kombiniert werden).  Int32, Int64 sowie alle Arten von Datenklassen werden in Sammlungen gespeichert.  F√ºr jeden verwendeten Typ ben√∂tigen Sie einen eigenen Pool, in dem auch Sammlungen unterschiedlicher Gr√∂√üe gespeichert werden. <br></li><li>  Schwierige Lebensdauer von Sammlungen.  Um die Vorteile des Pools nutzen zu k√∂nnen, m√ºssen die darin enthaltenen Objekte nach der Verwendung zur√ºckgegeben werden.  Dies kann erfolgen, wenn das Objekt in einer Methode verwendet wird.  In unserem Fall ist die Situation jedoch komplizierter, da viele gro√üe Objekte zwischen Methoden wechseln, in Datenstrukturen eingef√ºgt, auf andere Strukturen √ºbertragen werden usw. <br></li><li>  Implementierung.  Es gibt ArrayPool von Microsoft, aber wir brauchen noch List und HashSet.  Wir haben keine geeignete Bibliothek gefunden, daher m√ºssten wir die Klassen selbst implementieren. </li></ul></li><li>  Verwendung kleiner Gegenst√§nde.  Ein gro√ües Array kann in mehrere kleine Teile unterteilt werden, von denen ich den Heap f√ºr gro√üe Objekte nicht lade, sondern in der 0. Generation erstelle und dann in der 1. und 2. Generation den Standardpfad entlang gehe.  Wir hoffen, dass sie nicht der 2. gerecht werden, sondern in der 0. oder im Extremfall in der 1. Generation vom M√ºllsammler abgeholt werden.  Der Vorteil dieses Ansatzes besteht darin, dass die √Ñnderungen am vorhandenen Code minimal sind.  Schwierigkeiten: <br><ul><li>  Implementierung.  Wir haben keine geeigneten Bibliotheken gefunden, daher m√ºssten wir die Klassen selbst schreiben.  Der Mangel an Bibliotheken ist verst√§ndlich, da das Szenario ‚ÄûSammlungen, die den Heap f√ºr gro√üe Objekte nicht laden‚Äú ein sehr enger Bereich ist. </li></ul></li></ul><br>  Wir haben uns entschlossen, den dritten Weg zu gehen und <strike>unser Fahrrad</strike> zu <strike>erfinden</strike> , um List und HashSet zu schreiben, ohne den Heap f√ºr gro√üe Objekte zu laden. <br><br><h2>  St√ºckliste </h2><br>  Unsere ChunkedList &lt;T&gt; implementiert Standardschnittstellen, einschlie√ülich IList &lt;T&gt;, f√ºr die nur minimale √Ñnderungen am vorhandenen Code erforderlich sind.  Ja, und die von uns verwendete Newtonsoft.Json-Bibliothek kann sie automatisch serialisieren, da sie IEnumerable &lt;T&gt; implementiert: <br><br><pre><code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">sealed</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ChunkedList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; : <span class="hljs-title"><span class="hljs-title">IList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>, <span class="hljs-title"><span class="hljs-title">IList</span></span>, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>, <span class="hljs-title"><span class="hljs-title">IReadOnlyList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IReadOnlyCollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; {</code> </pre> <br>  Die Standardliste &lt;T&gt; enth√§lt die folgenden Felder: Array f√ºr Elemente und Anzahl der gef√ºllten Elemente.  In ChunkedList &lt;T&gt; gibt es ein Array von Arrays von Elementen, die Anzahl der vollst√§ndig gef√ºllten Arrays und die Anzahl der Elemente im letzten Array.  Jedes der Arrays von Elementen mit weniger als 85.000 Bytes: <br><br><img src="https://habrastorage.org/webt/72/zj/js/72zjjs9q6lcfud-l7nq8cy5prdi.png"><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> T[][] chunks; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunk; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunkSize;</code> </pre> <br>  Da die ChunkedList &lt;T&gt; ziemlich kompliziert ist, haben wir detaillierte Tests dazu geschrieben.  Jede Operation muss in mindestens zwei Modi getestet werden: in "klein", wenn die gesamte Liste in ein St√ºck mit einer Gr√∂√üe von bis zu 85.000 Byte passt, und in "gro√ü", wenn sie aus mehr als einem St√ºck besteht.  Dar√ºber hinaus sind die Methoden f√ºr Methoden, die die Gr√∂√üe √§ndern (z. B. Hinzuf√ºgen), noch gr√∂√üer: "klein" -&gt; "klein", "klein" -&gt; "gro√ü", "gro√ü" -&gt; "gro√ü", "gro√ü" -&gt; " klein. "  Hier gibt es einige verwirrende Grenzf√§lle, die Unit-Tests gut machen. <br><br>  Die Situation wird durch die Tatsache vereinfacht, dass einige der Methoden der IList-Schnittstelle nicht verwendet werden und weggelassen werden k√∂nnen (z. B. Einf√ºgen, Entfernen).  Ihre Implementierung und Pr√ºfung w√§re ziemlich aufw√§ndig.  Dar√ºber hinaus wird das Schreiben von Komponententests durch die Tatsache vereinfacht, dass wir keine neuen Funktionen entwickeln m√ºssen. ChunkedList &lt;T&gt; sollte sich genauso verhalten wie List &lt;T&gt;.  Das hei√üt, alle Tests sind wie folgt organisiert: Erstellen Sie eine Liste &lt;T&gt; und eine ChunkedList &lt;T&gt;, f√ºhren Sie dieselben Vorg√§nge f√ºr sie aus und vergleichen Sie die Ergebnisse. <br><br>  Wir haben die Leistung mithilfe der BenchmarkDotNet-Bibliothek gemessen, um sicherzustellen, dass wir unseren Code beim Wechsel von List &lt;T&gt; zu ChunkedList &lt;T&gt; nicht wesentlich verlangsamen.  Testen wir zum Beispiel das Hinzuf√ºgen von Elementen zur Liste: <br><br><pre> <code class="cs hljs">[<span class="hljs-meta"><span class="hljs-meta">Benchmark</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedList&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedList</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> list = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedList&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N; i++) list.Add(i); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list; }</code> </pre> <br>  Und der gleiche Test mit List &lt;T&gt; zum Vergleich.  Ergebnisse beim Hinzuf√ºgen von 500 Elementen (alles passt in ein Array): <br><div class="scrollable-table"><table><tbody><tr><td>  Methode </td><td>  Mittelwert </td><td>  Fehler </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Zugewiesener Speicher / Op </td></tr><tr><td>  Standardliste </td><td>  1.415 uns </td><td>  0,0149 us </td><td>  0,0140 us </td><td>  0,6847 </td><td>  0,0095 </td><td>  - - </td><td>  4,21 KB </td></tr><tr><td>  Chunkedlist </td><td>  3.728 uns </td><td>  0,0238 us </td><td>  0,0222 us </td><td>  0,6943 </td><td>  0,0076 </td><td>  - - </td><td>  4,28 KB </td></tr></tbody></table></div><br>  Ergebnisse beim Hinzuf√ºgen von 50.000 Elementen (aufgeteilt in mehrere Arrays): <br><div class="scrollable-table"><table><tbody><tr><td>  Methode </td><td>  Mittelwert </td><td>  Fehler </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Zugewiesener Speicher / Op </td></tr><tr><td>  Standardliste </td><td>  146,273 uns </td><td>  3.1466 uns </td><td>  4.8053 uns </td><td>  124.7559 </td><td>  124.7559 </td><td>  124.7559 </td><td>  513,23 KB </td></tr><tr><td>  Chunkedlist </td><td>  287.687 uns </td><td>  1.4630 uns </td><td>  1.2969 uns </td><td>  41.5039 </td><td>  20.5078 </td><td>  - - </td><td>  256,75 KB </td></tr></tbody></table></div><br><div class="spoiler">  <b class="spoiler_title">Detaillierte Beschreibung der Spalten in den Ergebnissen</b> <div class="spoiler_text"><pre> <code class="cs hljs">BenchmarkDotNet=v0<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">.4</span></span>, OS=Windows <span class="hljs-number"><span class="hljs-number">10.0</span></span><span class="hljs-number"><span class="hljs-number">.17763</span></span><span class="hljs-number"><span class="hljs-number">.379</span></span> (<span class="hljs-number"><span class="hljs-number">1809</span></span>/October2018Update/Redstone5) Intel Core i7<span class="hljs-number"><span class="hljs-number">-8700</span></span>K CPU <span class="hljs-number"><span class="hljs-number">3.70</span></span>GHz (Coffee Lake), <span class="hljs-number"><span class="hljs-number">1</span></span> CPU, <span class="hljs-number"><span class="hljs-number">12</span></span> logical and <span class="hljs-number"><span class="hljs-number">6</span></span> physical cores [Host] : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> DefaultJob : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> <span class="hljs-comment"><span class="hljs-comment">// * Hints * Outliers ListAdd.StandardList: Default -&gt; 2 outliers were removed ListAdd.ChunkedList: Default -&gt; 1 outlier was removed // * Legends * Mean : Arithmetic mean of all measurements Error : Half of 99.9% confidence interval StdDev : Standard deviation of all measurements Gen 0/1k Op : GC Generation 0 collects per 1k Operations Gen 1/1k Op : GC Generation 1 collects per 1k Operations Gen 2/1k Op : GC Generation 2 collects per 1k Operations Allocated Memory/Op : Allocated memory per single operation (managed only, inclusive, 1KB = 1024B) 1 us : 1 Microsecond (0.000001 sec)</span></span></code> </pre> <br></div></div><br>  Wenn Sie sich die Spalte "Mittelwert" ansehen, in der die durchschnittliche Testausf√ºhrungszeit angezeigt wird, sehen Sie, dass unsere Implementierung nur 2 bis 2,5 Mal langsamer als der Standard ist.  Wenn man bedenkt, dass Operationen mit Listen im realen Code nur einen kleinen Teil aller ausgef√ºhrten Aktionen ausmachen, wird dieser Unterschied unbedeutend.  Die Spalte 'Gen 2 / 1k op' (die Anzahl der Baugruppen der 2. Generation f√ºr 1000 Testl√§ufe) zeigt jedoch, dass wir das Ziel erreicht haben: Mit einer gro√üen Anzahl von Elementen erzeugt ChunkedList in der 2. Generation keinen M√ºll, was unsere Aufgabe war. <br><br><h2>  St√ºcksatz </h2><br>  In √§hnlicher Weise implementiert ChunkedHashSet &lt;T&gt; die ISet &lt;T&gt; -Schnittstelle.  Beim Schreiben des ChunkedHashSet &lt;T&gt; haben wir die bereits in der ChunkedList implementierte kleine Chunk-Logik wiederverwendet.  Zu diesem Zweck haben wir eine vorgefertigte Implementierung von HashSet &lt;T&gt; aus der .NET-Referenzquelle √ºbernommen, die unter der MIT-Lizenz verf√ºgbar ist, und Arrays durch ChunkedLists ersetzt. <br><br>  In Unit-Tests verwenden wir denselben Trick wie f√ºr Listen: Wir vergleichen das Verhalten von ChunkedHashSet &lt;T&gt; mit dem Referenz-HashSet &lt;T&gt;. <br><br>  Zum Schluss Leistungstests.  Die Hauptoperation, die wir verwenden, ist die Vereinigung von Mengen, weshalb wir sie testen: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedHashSet&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedHashSet</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params">[][] source</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedHashSet&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> arr <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> source) <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>.UnionWith(arr); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; }</code> </pre> <br>  Und genau der gleiche Test f√ºr das Standard-HashSet.  Erster Test f√ºr kleine Sets: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  Methode </td><td>  Mittelwert </td><td>  Fehler </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Zugewiesener Speicher / Op </td></tr><tr><td>  StandardHashSet </td><td>  30.16 uns </td><td>  0,1046 uns </td><td>  0,0979 us </td><td>  9.3079 </td><td>  1,6785 </td><td>  - - </td><td>  57,41 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  73,54 uns </td><td>  0,5919 us </td><td>  0,5247 us </td><td>  9,5215 </td><td>  1,5869 </td><td>  - - </td><td>  58,84 KB </td></tr></tbody></table></div><br>  Der zweite Test f√ºr gro√üe Mengen, der ein Problem mit einer Reihe gro√üer Objekte verursachte: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">30000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">60000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">30000</span></span>, <span class="hljs-number"><span class="hljs-number">100000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  Methode </td><td>  Mittelwert </td><td>  Fehler </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Zugewiesener Speicher / Op </td></tr><tr><td>  StandardHashSet </td><td>  3.031,30 uns </td><td>  32.0797 uns </td><td>  28.4378 uns </td><td>  699,2188 </td><td>  667,9688 </td><td>  664.0625 </td><td>  4718,23 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  7.189,66 uns </td><td>  25.6319 uns </td><td>  23.9761 uns </td><td>  539.0625 </td><td>  265,6250 </td><td>  7.8125 </td><td>  3280,71 KB </td></tr></tbody></table></div><br>  Die Ergebnisse √§hneln den Auflistungen.  ChunkedHashSet ist 2-2,5-mal langsamer, l√§dt aber gleichzeitig bei gro√üen Sets die 2. Generation um 2 Gr√∂√üenordnungen weniger. <br><br><h2>  Serialisierung in JSON </h2><br>  Der Pyrus-Webserver bietet mehrere APIs, die unterschiedliche Serialisierungen verwenden.  Wir haben die Erstellung gro√üer Objekte in der von Bots verwendeten API und dem Synchronisierungsdienstprogramm (im Folgenden als √∂ffentliche API bezeichnet) entdeckt.  Beachten Sie, dass die API grunds√§tzlich eine eigene Serialisierung verwendet, die von diesem Problem nicht betroffen ist.  Wir haben dar√ºber im Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://habr.com/en/post/227595/</a> im Abschnitt "2.  Sie wissen nicht, wo der Engpass Ihrer Anwendung liegt. "  Das hei√üt, die Haupt-API funktioniert bereits gut, und das Problem trat in der √∂ffentlichen API auf, als die Anzahl der Anforderungen und die Datenmenge in den Antworten zunahmen. <br><br>  Lassen Sie uns die √∂ffentliche API optimieren.  Am Beispiel der Haupt-API wissen wir, dass Sie im Streaming-Modus eine Antwort an den Benutzer zur√ºckgeben k√∂nnen.  Das hei√üt, Sie m√ºssen keine Zwischenpuffer erstellen, die die gesamte Antwort enthalten, sondern die Antwort sofort in den Stream schreiben. <br><br>  Bei n√§herer Betrachtung haben wir festgestellt, dass wir beim Serialisieren der Antwort einen tempor√§ren Puffer f√ºr das Zwischenergebnis erstellen ('content' ist ein Array von Bytes, die JSON in UTF-8-Codierung enthalten): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] content; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MemoryStream(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> writer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(writer, result); writer.Flush(); content = ms.ToArray(); }</code> </pre> <br>  Mal sehen, wo Inhalte verwendet werden.  Aus historischen Gr√ºnden basiert die √∂ffentliche API auf WCF, f√ºr das XML das Standard-Anforderungs- und Antwortformat ist.  In unserem Fall enth√§lt die XML-Antwort ein einzelnes 'Bin√§r'-Element, in das in Base64 codiertes JSON geschrieben ist: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">RawBodyWriter</span></span> : <span class="hljs-title"><span class="hljs-title">BodyWriter</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] _content; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RawBodyWriter</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] content</span></span></span><span class="hljs-function">) : </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">base</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-literal"><span class="hljs-function"><span class="hljs-params"><span class="hljs-literal">true</span></span></span></span></span><span class="hljs-function">)</span></span> { _content = content; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); writer.WriteBase64(_content, <span class="hljs-number"><span class="hljs-number">0</span></span>, _content.Length); writer.WriteEndElement(); } }</code> </pre> <br>  Beachten Sie, dass hier kein tempor√§rer Puffer ben√∂tigt wird.  JSON kann sofort in den von WCF bereitgestellten XmlWriter-Puffer geschrieben und im laufenden Betrieb in Base64 codiert werden.  Wir werden also den ersten Weg gehen und die Speicherzuweisung loswerden: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); Stream stream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Base64Writer(writer); Var sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(stream, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> jsonWriter = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(jsonWriter, _result); jsonWriter.Flush(); } writer.WriteEndElement(); }</code> </pre> <br>  Hier ist Base64Writer ein einfacher Wrapper √ºber XmlWriter, der die Stream-Schnittstelle implementiert, die als Base64 in XmlWriter schreibt.  Gleichzeitig reicht es aus, von der gesamten Schnittstelle aus nur eine Write-Methode zu implementieren, die in StreamWriter aufgerufen wird: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Base64Writer</span></span> : <span class="hljs-title"><span class="hljs-title">Stream</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> XmlWriter _writer; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Base64Writer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlWriter writer</span></span></span><span class="hljs-function">)</span></span> { _writer = writer; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] buffer, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count</span></span></span><span class="hljs-function">)</span></span> { _writer.WriteBase64(buffer, offset, count); } &lt;...&gt; }</code> </pre> <br><h2>  Induzierte gc </h2><br>  Versuchen wir, mit mysteri√∂sen M√ºllsammlungen umzugehen.  Wir haben unseren Code zehnmal auf GC.Collect-Aufrufe √ºberpr√ºft, dies ist jedoch fehlgeschlagen.  Ich habe es geschafft, diese Ereignisse in PerfView abzufangen, aber der Aufrufstapel ist nicht sehr bezeichnend (DotNETRuntime / GC / Triggered-Ereignis): <br><br><img src="https://habrastorage.org/webt/ye/j0/qg/yej0qglbieyx_tg05hdgutajhmc.png"><br><br>  Es gibt einen kleinen Hinweis: RecycleLimitMonitor.RaiseRecycleLimitEvent vor der induzierten Garbage Collection aufrufen.  Verfolgen wir den Aufrufstapel der RaiseRecycleLimitEvent-Methode: <br><br><pre> <code class="cs hljs">RecycleLimitMonitor.RaiseRecycleLimitEvent(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.AlertProxyMonitors(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.CollectInfrequently(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.PBytesMonitorThread(...)</code> </pre> <br>  Die Namen der Methoden stimmen mit ihren Funktionen √ºberein: <br><ul><li>  Im Konstruktor von RecycleLimitMonitor.RecycleLimitMonitorSingleton wird ein Timer erstellt, der PBytesMonitorThread in einem bestimmten Intervall aufruft. <br></li><li>  PBytesMonitorThread sammelt Statistiken zur Speichernutzung und ruft unter bestimmten Umst√§nden CollectInfrequently auf. <br></li><li>  CollectInfrequently ruft AlertProxyMonitors auf, ruft als Ergebnis einen Bool ab und ruft GC.Collect () auf, wenn es wahr wird.  Er √ºberwacht auch die Zeit, die seit dem letzten Anruf beim Garbage Collector vergangen ist, und ruft sie nicht zu oft auf. <br></li><li>  AlertProxyMonitors geht die Liste der ausgef√ºhrten IIS-Webanwendungen durch, l√∂st f√ºr jede das entsprechende RecycleLimitMonitor-Objekt aus und ruft RaiseRecycleLimitEvent auf. <br></li><li>  RaiseRecycleLimitEvent l√∂st die IObserver-Liste &lt;RecycleLimitInfo&gt; aus.  Die Handler erhalten als Parameter RecycleLimitInfo, in dem sie das RequestGC-Flag setzen k√∂nnen, das h√§ufig zu CollectInfre zur√ºckkehrt und eine induzierte Garbage Collection verursacht. <br></li></ul><br><br>  Weitere Untersuchungen zeigen, dass IObserver &lt;RecycleLimitInfo&gt; -Handler in der RecycleLimitMonitor.Subscribe () -Methode hinzugef√ºgt werden, die in der AspNetMemoryMonitor.Subscribe () -Methode aufgerufen wird.  Au√üerdem ist der Standard-IObserver-Handler &lt;RecycleLimitInfo&gt; (die RecycleLimitObserver-Klasse) in der AspNetMemoryMonitor-Klasse h√§ngen, die ASP.NET-Caches bereinigt und manchmal nach Garbage Collection fragt. <br><br>  Das R√§tsel der induzierten GC ist fast gel√∂st.  Es bleibt die Frage, warum diese Garbage Collection aufgerufen wird.  RecycleLimitMonitor √ºberwacht die Verwendung des IIS-Speichers (genauer gesagt die Anzahl der privaten Bytes). Wenn sich die Verwendung einer bestimmten Grenze n√§hert, beginnt ein ziemlich verwirrender Algorithmus, um das RaiseRecycleLimitEvent-Ereignis auszul√∂sen.  Der Wert von AspNetMemoryMonitor.ProcessPrivateBytesLimit wird als Speicherlimit verwendet und enth√§lt wiederum die folgende Logik: <br><ul><li>  Wenn der Anwendungspool in IIS auf "Private Memory Limit (KB)" eingestellt ist, wird der Wert in Kilobyte von dort √ºbernommen <br></li><li>  Andernfalls werden bei 64-Bit-Systemen 60% des physischen Speichers belegt (bei 32-Bit-Systemen ist die Logik komplizierter). <br></li></ul><br>  Das Ergebnis der Untersuchung lautet: ASP.NET n√§hert sich seinem Speicherlimit und ruft regelm√§√üig die Garbage Collection auf.  Das 'Private Memory Limit (KB)' wurde nicht festgelegt, daher war ASP.NET auf 60% des physischen Speichers beschr√§nkt.  Das Problem wurde durch die Tatsache maskiert, dass auf dem Task-Manager-Server viel freier Speicher angezeigt wurde und es anscheinend fehlte.  Wir haben den Wert f√ºr "Private Memory Limit (KB)" in den Anwendungspooleinstellungen in IIS auf 80% des physischen Speichers erh√∂ht.  Dies ermutigt ASP.NET, mehr verf√ºgbaren Speicher zu verwenden.  Wir haben auch die √úberwachung des Leistungsindikators '.NET CLR Memory / # Induced GC' hinzugef√ºgt, um das n√§chste Mal nicht zu verpassen, wenn ASP.NET entscheidet, dass es sich der Grenze der Speichernutzung n√§hert. <br><br><h2>  Wiederholte Messungen </h2><br>  Mal sehen, was nach all diesen √Ñnderungen mit der Garbage Collection passiert ist.  Beginnen wir mit perfview / GCCollectOnly (Trace-Zeit - 1 Stunde), GCStats-Bericht: <br><br><img src="https://habrastorage.org/webt/8b/l3/fn/8bl3fnxpuymka28coyzbo0r5ak4.png"><br><br>  Es ist ersichtlich, dass die Baugruppen der 2. Generation jetzt 2 Gr√∂√üenordnungen kleiner sind als die 0. und 1 ..  Auch die Zeit dieser Baugruppen nahm ab.  Induzierte Baugruppen werden nicht mehr beobachtet.  Schauen wir uns die Liste der Baugruppen der 2. Generation an: <br><br><img src="https://habrastorage.org/webt/mx/oy/tv/mxoytvprkypunnhwtao6o6fboai.png"><br><br>  Die Spalte Gen zeigt, dass alle Baugruppen der 2. Generation zum Hintergrund geworden sind ('2B' bedeutet 2. Generation, Hintergrund).  Das hei√üt, der gr√∂√üte Teil der Arbeit wird parallel zur Ausf√ºhrung der Anwendung ausgef√ºhrt, und alle Threads werden f√ºr kurze Zeit blockiert (Spalte 'MSec anhalten').  Schauen wir uns die Pausen beim Erstellen gro√üer Objekte an: <br><br><img src="https://habrastorage.org/webt/qp/04/hp/qp04hpcq35buinfnfjn5uuudnyg.png"><br><br>  Es ist ersichtlich, dass die Anzahl solcher Pausen beim Erstellen gro√üer Objekte erheblich gesunken ist. <br><br><h2>  Zusammenfassung </h2><br>  Dank der im Artikel beschriebenen √Ñnderungen konnte die Anzahl und Dauer der Baugruppen der 2. Generation deutlich reduziert werden.  Es gelang mir, die Ursache f√ºr die induzierten Baugruppen zu finden und sie loszuwerden.  Die Anzahl der Baugruppen der 0. und 1. Generation nahm zu, ihre durchschnittliche Dauer nahm jedoch ab (von ~ 200 ms auf ~ 60 ms).  Die maximale Montagedauer der 0. und 1. Generation hat sich verringert, jedoch nicht so deutlich.  Baugruppen der 2. Generation wurden schneller, lange Pausen bis zu 1000 ms sind komplett weg. <br><br>  Die Schl√ºsselmetrik ‚ÄûProzentsatz langsamer Abfragen‚Äú verringerte sich nach allen √Ñnderungen um 40%. <br><br>  Dank unserer Arbeit haben wir erkannt, welche Leistungsindikatoren erforderlich sind, um die Situation mit Speicher- und Speicherbereinigung zu bewerten, und sie zur kontinuierlichen √úberwachung zu Zabbix hinzugef√ºgt.  Hier ist eine Liste der wichtigsten, auf die wir achten und deren Grund wir herausfinden (z. B. ein erh√∂hter Fluss von Anforderungen, eine gro√üe Menge √ºbertragener Daten, ein Fehler in der Anwendung): <br><div class="scrollable-table"><table><tbody><tr><td>  Leistungsindikator </td><td>  Beschreibung </td><td>  Wann man aufpasst </td></tr><tr><td>  \ Process (*) \ Private Bytes </td><td>  Die f√ºr die Anwendung zugewiesene Speichermenge </td><td rowspan="3">  Die Werte √ºberschreiten den Schwellenwert bei weitem.  Als Schwellenwert k√∂nnen Sie den Median f√ºr 2 Wochen aus den maximalen Tageswerten ableiten. </td></tr><tr><td>  \ .NET CLR-Speicher (*) \ # Gen 2-Sammlungen </td><td>  Die Speichermenge in der √§lteren Generation </td></tr><tr><td>  \ .NET CLR-Speicher (*) \ Heap-Gr√∂√üe f√ºr gro√üe Objekte </td><td>  Die Speichermenge f√ºr gro√üe Objekte </td></tr><tr><td>  \ .NET CLR-Speicher (*) \% Zeit in GC </td><td>  Der Prozentsatz der Zeit, die f√ºr das Sammeln von M√ºll aufgewendet wurde </td><td>  Der Wert betr√§gt mehr als 5%. </td></tr><tr><td>  \ .NET CLR-Speicher (*) \ # Induzierte GC </td><td>  Anzahl der induzierten Baugruppen </td><td>  Wert ist gr√∂√üer als 0. </td></tr></tbody></table></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de452298/">https://habr.com/ru/post/de452298/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de452284/index.html">Klassifizierung der Landbedeckung mittels Eo-Learn. Teil 1</a></li>
<li><a href="../de452288/index.html">Situation: US-Mobilfunkbetreiber, denen illegaler Handel mit Geodaten von Abonnenten vorgeworfen wird</a></li>
<li><a href="../de452290/index.html">Was Hacker vermissen, wenn sie an PHDays eine Bank brechen</a></li>
<li><a href="../de452294/index.html">Webinar "Mitarbeiter - Hintert√ºr: Moderne Techniken des Social Engineering"</a></li>
<li><a href="../de452296/index.html">Positive Hack Days 9: Competitive Intelligence Contest 18. Mai</a></li>
<li><a href="../de452302/index.html">Vorl√§ufiges Programm f√ºr PyConRu-2019: zwei Python Core-Entwickler, Sprecher von Anaconda, Intel, JetBrains, Yandex</a></li>
<li><a href="../de452304/index.html">OpenAI AI lernte Gedichte, Artikel und Nachrichten zu schreiben</a></li>
<li><a href="../de452306/index.html">Wohin geht Fintech, wie z√§hlt man die Einheits√∂konomie und warum entwickelt man einheimisches Unternehmertum? Mitap Yandex.Money</a></li>
<li><a href="../de452310/index.html">Einrichten von Netzwerkvertriebskan√§len f√ºr DO-RA-Ger√§te</a></li>
<li><a href="../de452312/index.html">Die britische Telekommunikation zahlt den Abonnenten eine Entsch√§digung f√ºr Verbindungsabbr√ºche</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧝🏽 🍓 🔖 Memoria de hogar dedicada e intervención OOM Killer 🕟 🧜🏿 😶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola de nuevo La traducción del siguiente artículo se preparó específicamente para los estudiantes del curso de la Plataforma de Infraestructura basad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Memoria de hogar dedicada e intervención OOM Killer</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/456002/">  Hola de nuevo  La traducción del siguiente artículo se preparó específicamente para los estudiantes del curso de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Plataforma de Infraestructura basada en Kubernetes</a> , que comienza este mes. <br><br><img src="https://habrastorage.org/webt/uv/io/fj/uviofjoh-y_arqntutialytzgcs.png"><br><br>  En los últimos días, algunos de mis pods se bloquearon constantemente, dejando un registro en el registro del sistema operativo que OOM Killer destruyó el proceso del contenedor.  Decidí averiguar por qué está sucediendo esto. <a name="habracut"></a><br><br><h2>  Configuración de límite de memoria de hogar y memoria de grupo c </h2><br>  Probemos en la distribución de K3s.  Creamos bajo con un límite de memoria característico de 123 MiB (123 Mi). <br><br><pre><code class="go hljs">kubectl run --restart=Never --rm -it --image=ubuntu --limits=<span class="hljs-string"><span class="hljs-string">'memory=123Mi'</span></span> -- sh If you don<span class="hljs-string"><span class="hljs-string">'t see a command prompt, try pressing enter. root@sh:/#</span></span></code> </pre> <br>  En otra consola, descubra el <code>uid</code> hogar. <br><br><pre> <code class="go hljs">kubectl get pods sh -o yaml | grep uid uid: bc001ffa<span class="hljs-number"><span class="hljs-number">-68f</span></span>c<span class="hljs-number"><span class="hljs-number">-11e9</span></span><span class="hljs-number"><span class="hljs-number">-92d</span></span>7<span class="hljs-number"><span class="hljs-number">-5</span></span>ef9efd9374c</code> </pre> <br>  En el servidor donde se está ejecutando, descubrimos los parámetros de <code>cgroup</code> especificando el <code>uid</code> pod deseado. <br><br><pre> <code class="go hljs">cd /sys/fs/cgroup/memory/kubepods/burstable/podbc001ffa<span class="hljs-number"><span class="hljs-number">-68f</span></span>c<span class="hljs-number"><span class="hljs-number">-11e9</span></span><span class="hljs-number"><span class="hljs-number">-92d</span></span>7<span class="hljs-number"><span class="hljs-number">-5</span></span>ef9efd9374c cat memory.limit_in_bytes <span class="hljs-number"><span class="hljs-number">128974848</span></span></code> </pre> <br>  128974848 es exactamente 123 MiB (123 * 1024 * 1024).  La situación se está aclarando.  Resulta que en Kubernetes, el límite de memoria se establece a través de cgroup.  Tan pronto como crezca más del límite de memoria asignado, cgroup inicia la destrucción del proceso del contenedor. <br><br><h2>  Prueba de esfuerzo </h2><br>  Instalemos utilidades para probar el hogar mediante una sesión de consola de comandos abierta. <br><br><pre> <code class="go hljs">root@sh:/# apt update; apt install -y stress</code> </pre> <br>  Al mismo tiempo, rastrearemos las entradas de syslog con el <code>dmesg -Tw</code> . <br><br>  Primero, ejecute la utilidad de prueba de esfuerzo, asignando 100 MB de memoria.  El proceso comenzó con éxito. <br><br><pre> <code class="go hljs">root@sh:/# stress --vm <span class="hljs-number"><span class="hljs-number">1</span></span> --vm-bytes <span class="hljs-number"><span class="hljs-number">100</span></span>M &amp; [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">271</span></span> root@sh:/# stress: info: [<span class="hljs-number"><span class="hljs-number">271</span></span>] dispatching hogs: <span class="hljs-number"><span class="hljs-number">0</span></span> cpu, <span class="hljs-number"><span class="hljs-number">0</span></span> io, <span class="hljs-number"><span class="hljs-number">1</span></span> vm, <span class="hljs-number"><span class="hljs-number">0</span></span> hdd</code> </pre> <br>  Ahora realizaremos la segunda prueba de esfuerzo. <br><br><pre> <code class="go hljs">root@sh:/# stress --vm <span class="hljs-number"><span class="hljs-number">1</span></span> --vm-bytes <span class="hljs-number"><span class="hljs-number">50</span></span>M stress: info: [<span class="hljs-number"><span class="hljs-number">273</span></span>] dispatching hogs: <span class="hljs-number"><span class="hljs-number">0</span></span> cpu, <span class="hljs-number"><span class="hljs-number">0</span></span> io, <span class="hljs-number"><span class="hljs-number">1</span></span> vm, <span class="hljs-number"><span class="hljs-number">0</span></span> hdd stress: FAIL: [<span class="hljs-number"><span class="hljs-number">271</span></span>] (<span class="hljs-number"><span class="hljs-number">415</span></span>) &lt;-- worker <span class="hljs-number"><span class="hljs-number">272</span></span> got signal <span class="hljs-number"><span class="hljs-number">9</span></span> stress: WARN: [<span class="hljs-number"><span class="hljs-number">271</span></span>] (<span class="hljs-number"><span class="hljs-number">417</span></span>) now reaping child worker processes stress: FAIL: [<span class="hljs-number"><span class="hljs-number">271</span></span>] (<span class="hljs-number"><span class="hljs-number">451</span></span>) failed run completed in <span class="hljs-number"><span class="hljs-number">7s</span></span></code> </pre> <br>  El lanzamiento condujo a la destrucción instantánea del proceso de la primera prueba de esfuerzo (PID 271) en la señal 9. <br><br>  Mientras tanto, aparecieron las siguientes entradas en el registro del sistema: <br><br> <code>[Sat Apr 27 22:56:09 2019] stress invoked oom-killer: gfp_mask=0x14000c0(GFP_KERNEL), nodemask=(null), order=0, oom_score_adj=939 <br> [Sat Apr 27 22:56:09 2019] stress cpuset=a2ed67c63e828da3849bf9f506ae2b36b4dac5b402a57f2981c9bdc07b23e672 mems_allowed=0 <br> [Sat Apr 27 22:56:09 2019] CPU: 0 PID: 32332 Comm: stress Not tainted 4.15.0-46-generic #49-Ubuntu <br> [Sat Apr 27 22:56:09 2019] Hardware name: BHYVE, BIOS 1.00 03/14/2014 <br> [Sat Apr 27 22:56:09 2019] Call Trace: <br> [Sat Apr 27 22:56:09 2019] dump_stack+0x63/0x8b <br> [Sat Apr 27 22:56:09 2019] dump_header+0x71/0x285 <br> [Sat Apr 27 22:56:09 2019] oom_kill_process+0x220/0x440 <br> [Sat Apr 27 22:56:09 2019] out_of_memory+0x2d1/0x4f0 <br> [Sat Apr 27 22:56:09 2019] mem_cgroup_out_of_memory+0x4b/0x80 <br> [Sat Apr 27 22:56:09 2019] mem_cgroup_oom_synchronize+0x2e8/0x320 <br> [Sat Apr 27 22:56:09 2019] ? mem_cgroup_css_online+0x40/0x40 <br> [Sat Apr 27 22:56:09 2019] pagefault_out_of_memory+0x36/0x7b <br> [Sat Apr 27 22:56:09 2019] mm_fault_error+0x90/0x180 <br> [Sat Apr 27 22:56:09 2019] __do_page_fault+0x4a5/0x4d0 <br> [Sat Apr 27 22:56:09 2019] do_page_fault+0x2e/0xe0 <br> [Sat Apr 27 22:56:09 2019] ? page_fault+0x2f/0x50 <br> [Sat Apr 27 22:56:09 2019] page_fault+0x45/0x50 <br> [Sat Apr 27 22:56:09 2019] RIP: 0033:0x558182259cf0 <br> [Sat Apr 27 22:56:09 2019] RSP: 002b:00007fff01a47940 EFLAGS: 00010206 <br> [Sat Apr 27 22:56:09 2019] RAX: 00007fdc18cdf010 RBX: 00007fdc1763a010 RCX: 00007fdc1763a010 <br> [Sat Apr 27 22:56:09 2019] RDX: 00000000016a5000 RSI: 0000000003201000 RDI: 0000000000000000 <br> [Sat Apr 27 22:56:09 2019] RBP: 0000000003200000 R08: 00000000ffffffff R09: 0000000000000000 <br> [Sat Apr 27 22:56:09 2019] R10: 0000000000000022 R11: 0000000000000246 R12: ffffffffffffffff <br> [Sat Apr 27 22:56:09 2019] R13: 0000000000000002 R14: fffffffffffff000 R15: 0000000000001000 <br> [Sat Apr 27 22:56:09 2019] Task in /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c/a2ed67c63e828da3849bf9f506ae2b36b4dac5b402a57f2981c9bdc07b23e672 killed as a result of limit of /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c <br> [Sat Apr 27 22:56:09 2019] memory: usage 125952kB, limit 125952kB, failcnt 3632 <br> [Sat Apr 27 22:56:09 2019] memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0 <br> [Sat Apr 27 22:56:09 2019] kmem: usage 2352kB, limit 9007199254740988kB, failcnt 0 <br> [Sat Apr 27 22:56:09 2019] Memory cgroup stats for /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c: cache:0KB rss:0KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:0KB inactive_file:0KB active_file:0KB unevictable:0KB <br> [Sat Apr 27 22:56:09 2019] Memory cgroup stats for /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c/79fae7c2724ea1b19caa343fed8da3ea84bbe5eb370e5af8a6a94a090d9e4ac2: cache:0KB rss:48KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:48KB inactive_file:0KB active_file:0KB unevictable:0KB <br> [Sat Apr 27 22:56:09 2019] Memory cgroup stats for /kubepods/burstable/podbc001ffa-68fc-11e9-92d7-5ef9efd9374c/a2ed67c63e828da3849bf9f506ae2b36b4dac5b402a57f2981c9bdc07b23e672: cache:0KB rss:123552KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:123548KB inactive_file:0KB active_file:0KB unevictable:0KB <br> [Sat Apr 27 22:56:09 2019] [ pid ] uid tgid total_vm rss pgtables_bytes swapents oom_score_adj name <br> [Sat Apr 27 22:56:09 2019] [25160] 0 25160 256 1 28672 0 -998 pause <br> [Sat Apr 27 22:56:09 2019] [25218] 0 25218 4627 872 77824 0 939 bash <br> [Sat Apr 27 22:56:09 2019] [32307] 0 32307 2060 275 57344 0 939 stress <br> [Sat Apr 27 22:56:09 2019] [32308] 0 32308 27661 24953 253952 0 939 stress <br> [Sat Apr 27 22:56:09 2019] [32331] 0 32331 2060 304 53248 0 939 stress <br> [Sat Apr 27 22:56:09 2019] [32332] 0 32332 14861 5829 102400 0 939 stress <br> [Sat Apr 27 22:56:09 2019] Memory cgroup out of memory: Kill process 32308 (stress) score 1718 or sacrifice child <br> [Sat Apr 27 22:56:09 2019] Killed process 32308 (stress) total-vm:110644kB, anon-rss:99620kB, file-rss:192kB, shmem-rss:0kB <br> [Sat Apr 27 22:56:09 2019] oom_reaper: reaped process 32308 (stress), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB</code> <br> <br>  El proceso con PID 32308 en el host se destruyó debido a falta de memoria (OOM).  Pero lo más interesante está oculto al final de las entradas del diario: <br><br><img src="https://habrastorage.org/webt/fz/dn/pb/fzdnpbniemrgqc8qvmkxvttose0.png"><br><br>  Aquí están los procesos de este hogar que están marcados como candidatos para la destrucción por el componente OOM Killer.  El proceso de <code>pause</code> base, que almacena los espacios de nombres de la red, recibió una calificación de <code>-998</code> de <code>-998</code> , lo que significa que no se garantiza que el proceso sea destruido.  Los procesos restantes en el contenedor recibieron una puntuación <code>oom_score_adj</code> de <code>939</code> .  Puede verificar este valor utilizando la fórmula de la documentación de Kubernetes a continuación: <br><br><pre> <code class="go hljs">min(max(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span> - (<span class="hljs-number"><span class="hljs-number">1000</span></span> * memoryRequestBytes) / machineMemoryCapacityBytes), <span class="hljs-number"><span class="hljs-number">999</span></span>)</code> </pre> <br>  Descubrimos la cantidad de memoria disponible para el nodo: <br><br><pre> <code class="go hljs">kubectl describe nodes k3s | grep Allocatable -A <span class="hljs-number"><span class="hljs-number">5</span></span> Allocatable: cpu: <span class="hljs-number"><span class="hljs-number">1</span></span> ephemeral-storage: <span class="hljs-number"><span class="hljs-number">49255941901</span></span> hugepages<span class="hljs-number"><span class="hljs-number">-1</span></span>Gi: <span class="hljs-number"><span class="hljs-number">0</span></span> hugepages<span class="hljs-number"><span class="hljs-number">-2</span></span>Mi: <span class="hljs-number"><span class="hljs-number">0</span></span> memory: <span class="hljs-number"><span class="hljs-number">2041888</span></span>Ki</code> </pre> <br>  Si no se especifica el tamaño de memoria solicitado, de forma predeterminada será igual al límite.  Sustituyendo los valores, obtenemos el siguiente valor <code>oom_score_adj</code> : <code>1000–123*1024/2041888=938.32</code> , que está muy cerca del valor <code>939</code> especificado en el registro del sistema.  (No sé cómo OOM Killer obtiene el valor exacto de 939). <br><br>  Por lo tanto, todos los procesos en el contenedor tienen el mismo valor oom_score_adj.  El componente OOM Killer calcula el valor OOM en función del uso de memoria y ajusta el resultado en función de la puntuación oom_score_adj.  Y, en última instancia, destruye el proceso de la primera prueba de esfuerzo, que consumió la mayor parte de la memoria, 100 MB, que corresponde a la estimación oom_score = 1718. <br><br><h2>  Conclusión </h2><br>  Kubernetes controla el límite de memoria del hogar a través de los componentes cgroup y OOM Killer.  Es necesario acordar cuidadosamente las condiciones del sistema operativo OOM y los hogares OOM. <br><br>  ¿Cómo te gusta el material?  Todos los que quieran aprender más sobre el curso están invitados a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">seminario</a> web <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gratuito</a> el 17 de junio, donde estudiaremos las capacidades de Kubernetes para organizar prácticas de entrega continua (CI / CD) y enfoques para un equipo pequeño con varias aplicaciones, así como para una gran organización con una gran cantidad de sistemas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/456002/">https://habr.com/ru/post/456002/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455986/index.html">¿Por qué un técnico de TI debe sacar un cerebro?</a></li>
<li><a href="../455988/index.html">Las estructuras de datos del estado de Blockchain de plasma efectivo</a></li>
<li><a href="../455990/index.html">CTT en soluciones de servidor: ¿cómo se ve?</a></li>
<li><a href="../455996/index.html">Transformación digital de la publicidad en la red minorista. Siguiendo los pasos de Video Analytics en Retail</a></li>
<li><a href="../456000/index.html">Crear un juego Tic-Tac-Toe con TypeScript, React y Mocha</a></li>
<li><a href="../456004/index.html">Te invitamos a una reunión de desarrollo front-end en servicios muy cargados</a></li>
<li><a href="../456006/index.html">Aumente sus ingresos utilizando compras en la aplicación</a></li>
<li><a href="../456008/index.html">Desarrollo de programas para el procesador central Redd sobre el ejemplo de acceso a FPGA</a></li>
<li><a href="../456010/index.html">Cómo Java 10 cambia la forma en que usas clases internas anónimas</a></li>
<li><a href="../456014/index.html">Sobre la localización de productos. Parte 2: ¿cómo se forma el precio?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
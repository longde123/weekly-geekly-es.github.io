<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëºüèø üìö üë£ Zabbix, series de tiempo y TimescaleDB üïü ü§∏üèº üòå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cada sistema de monitoreo enfrenta tres tipos de problemas de rendimiento. 

 En primer lugar, un buen sistema de monitoreo deber√≠a recibir, procesar ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Zabbix, series de tiempo y TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/zabbix/blog/458530/"> Cada sistema de monitoreo enfrenta tres tipos de problemas de rendimiento. <br><br>  En primer lugar, un buen sistema de monitoreo deber√≠a recibir, procesar y registrar r√°pidamente los datos provenientes del exterior.  La cuenta va a microsegundos.  Por casualidad, esto puede parecer poco obvio, pero cuando el sistema se vuelve lo suficientemente grande, todas estas fracciones de segundos se resumen, convirti√©ndose en demoras claramente notables. <br><br><img src="https://habrastorage.org/webt/s6/fy/mx/s6fymxoyf5_f9n0hwidv8q6qsh4.png" alt="imagen"><br><a name="habracut"></a><br>  La segunda tarea es proporcionar un acceso conveniente a grandes conjuntos de m√©tricas recopiladas previamente (en otras palabras, a datos hist√≥ricos).  Los datos hist√≥ricos se utilizan en una amplia variedad de contextos.  Por ejemplo, se generan informes y gr√°ficos a partir de ellos, se crean controles agregados sobre ellos, los desencadenantes dependen de ellos.  Si hay retrasos en el acceso al historial, esto afecta inmediatamente la velocidad de todo el sistema en su conjunto. <br><br>  En tercer lugar, los datos hist√≥ricos ocupan mucho espacio.  Incluso las configuraciones de monitoreo relativamente modestas adquieren r√°pidamente un historial s√≥lido.  Pero casi nadie quiere tener a mano el historial de carga del procesador de cinco a√±os de antig√ºedad, por lo que el sistema de monitoreo deber√≠a poder no solo grabar bien, sino tambi√©n borrar bien el historial (en Zabbix este proceso se llama "limpieza").  La eliminaci√≥n de datos antiguos no tiene que ser tan eficiente como la recopilaci√≥n y el an√°lisis de datos nuevos, pero las operaciones de eliminaci√≥n intensivas se basan en recursos valiosos de DBMS y pueden ralentizar las operaciones m√°s cr√≠ticas. <br><br>  Los dos primeros problemas se resuelven mediante el almacenamiento en cach√©.  Zabbix admite varias cach√©s especializadas para acelerar las operaciones de lectura y escritura de datos.  Los mecanismos DBMS en s√≠ mismos no son adecuados aqu√≠, porque  incluso el algoritmo de almacenamiento en cach√© de prop√≥sito general m√°s avanzado no sabr√° qu√© estructuras de datos requieren acceso instant√°neo en un momento dado. <br><br><h4>  Monitoreo y datos de series temporales </h4><br>  Todo est√° bien siempre que los datos est√©n en la memoria del servidor Zabbix.  Pero la memoria no es infinita y en alg√∫n momento los datos deben escribirse (o leerse) en la base de datos.  Y si el rendimiento de la base de datos est√° muy por detr√°s de la velocidad de recopilaci√≥n de m√©tricas, incluso los algoritmos de almacenamiento en cach√© especiales m√°s avanzados no ayudar√°n durante mucho tiempo. <br><br>  El tercer problema tambi√©n se reduce al rendimiento de la base de datos.  Para resolverlo, debe elegir una estrategia de eliminaci√≥n confiable que no interfiera con otras operaciones de la base de datos.  Por defecto, Zabbix elimina datos hist√≥ricos en lotes de varios miles de registros por hora.  Puede configurar per√≠odos de mantenimiento m√°s largos o paquetes de mayor tama√±o si la velocidad de la recopilaci√≥n de datos y el lugar en la base de datos lo permiten.  Pero con una gran cantidad de m√©tricas y / o una alta frecuencia de recopilaci√≥n, la configuraci√≥n adecuada de limpieza puede ser una tarea desalentadora, ya que un programa de eliminaci√≥n de datos puede no mantenerse al ritmo de la grabaci√≥n de nuevos. <br><br>  Resumiendo, el sistema de monitoreo resuelve problemas de rendimiento en tres direcciones: recolectando datos nuevos y escribi√©ndolos en la base de datos usando consultas SQL INSERT, accediendo a datos usando consultas SELECT y eliminando datos usando DELETE.  Veamos c√≥mo se ejecuta una consulta SQL t√≠pica: <br><br><ul><li>  El DBMS analiza la consulta y verifica si hay errores de sintaxis.  Si la solicitud es sint√°cticamente correcta, el motor construye un √°rbol de sintaxis para su posterior procesamiento. </li><li>  El planificador de consultas analiza el √°rbol de sintaxis y calcula las diversas formas (rutas) para ejecutar la solicitud. </li><li>  El planificador calcula la forma m√°s barata.  En el proceso, tiene en cuenta muchas cosas: qu√© tan grandes son las tablas, si es necesario ordenar los resultados, si hay √≠ndices aplicables a la consulta, etc. </li><li>  Cuando se encuentra la ruta √≥ptima, el motor ejecuta la consulta accediendo a los bloques de datos deseados (usando √≠ndices o escaneo secuencial), aplica los criterios de clasificaci√≥n y filtrado, recopila el resultado y lo devuelve al cliente. </li><li>  Para insertar, modificar y eliminar consultas, el motor tambi√©n debe actualizar los √≠ndices para las tablas correspondientes.  Para tablas grandes, esta operaci√≥n puede llevar m√°s tiempo que trabajar con los datos en s√≠. </li><li>  Lo m√°s probable es que el DBMS tambi√©n actualice las estad√≠sticas internas del uso de datos para llamadas posteriores al programador de consultas. </li></ul><br>  En general, hay mucho trabajo.  La mayor√≠a de los DBMS proporcionan una gran cantidad de configuraciones para la optimizaci√≥n de consultas, pero generalmente se centran en algunos flujos de trabajo promedio en los que la inserci√≥n y eliminaci√≥n de registros ocurre aproximadamente con la misma frecuencia que el cambio. <br><br>  Sin embargo, como se mencion√≥ anteriormente, para los sistemas de monitoreo, las operaciones m√°s t√≠picas son agregar y eliminar peri√≥dicamente en modo por lotes.  El cambio de datos agregados anteriormente casi nunca ocurre, y el acceso a los datos implica el uso de funciones agregadas.  Adem√°s, generalmente los valores de las m√©tricas agregadas se ordenan por tiempo.  Tales datos se conocen com√∫nmente como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">series de tiempo</a> : <br><br><blockquote>  La serie temporal es una serie de puntos de datos indexados (o listados o graffiti) en un orden temporal. </blockquote><br><br>  Desde el punto de vista de la base de datos, las series temporales tienen las siguientes propiedades: <br><br><ul><li>  Las series de tiempo pueden ubicarse en un disco como una secuencia de bloques ordenados por tiempo. </li><li>  Las tablas de series de tiempo se pueden indexar utilizando una columna de tiempo. </li><li>  La mayor√≠a de las consultas SQL SELECT usar√°n las cl√°usulas WHERE, GROUP BY u ORDER BY en una columna que indica el tiempo. </li><li>  Por lo general, los datos de series temporales tienen una "fecha de vencimiento" despu√©s de la cual se pueden eliminar. </li></ul><br>  Obviamente, las bases de datos SQL tradicionales no son adecuadas para almacenar dichos datos, ya que las optimizaciones de uso general no tienen en cuenta estas cualidades.  Por lo tanto, en los √∫ltimos a√±os, han aparecido bastantes DBMS nuevos orientados al tiempo, como, por ejemplo, InfluxDB.  Pero todos los DBMS populares para series temporales tienen un inconveniente significativo: la falta de soporte SQL completo.  Adem√°s, la mayor√≠a de ellos ni siquiera son CRUD (Crear, Leer, Actualizar, Eliminar). <br><br>  ¬øPuede Zabbix usar estos DBMS de alguna manera?  Uno de los enfoques posibles es transferir datos hist√≥ricos para el almacenamiento a una base de datos externa especializada en las series de tiempo.  Dado que la arquitectura Zabbix admite backends externos para almacenar datos hist√≥ricos (por ejemplo, el soporte Elasticsearch se implementa en Zabbix), a primera vista, esta opci√≥n parece muy razonable.  Pero si admiti√©ramos uno o varios DBMS para series temporales como servidores externos, los usuarios tendr√≠an que tener en cuenta los siguientes puntos: <br><br><ul><li>  Otro sistema que necesita ser explorado, configurado y mantenido.  Otro lugar para realizar un seguimiento de la configuraci√≥n, el espacio en disco, las pol√≠ticas de almacenamiento, el rendimiento, etc. </li><li>  Reducci√≥n de la tolerancia a fallas del sistema de monitoreo, como  aparece un nuevo enlace en la cadena de componentes relacionados. </li></ul><br>  Para algunos usuarios, los beneficios del almacenamiento dedicado dedicado para datos hist√≥ricos pueden ser mayores que las molestias de tener que preocuparse por otro sistema.  Pero para muchos, esta es una complicaci√≥n innecesaria.  Tambi√©n vale la pena recordar que, dado que la mayor√≠a de estas soluciones especializadas tienen sus propias API, la complejidad de la capa universal para trabajar con bases de datos Zabbix aumentar√° notablemente.  Y, idealmente, preferimos crear nuevas funciones, en lugar de luchar contra otras API. <br><br>  Surge la pregunta: ¬øhay alguna forma de aprovechar el DBMS para series temporales, pero sin perder la flexibilidad y las ventajas de SQL?  Naturalmente, no existe una respuesta universal, pero una soluci√≥n espec√≠fica se acerc√≥ mucho a la respuesta: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TimescaleDB</a> . <br><br><h4>  ¬øQu√© es TimescaleDB? </h4><br>  TimescaleDB (TSDB) es una extensi√≥n de PostgreSQL que optimiza el trabajo con series temporales en una base de datos PostgreSQL (PG) normal.  Aunque, como se mencion√≥ anteriormente, no hay escasez de soluciones de series temporales bien escalables en el mercado, una caracter√≠stica √∫nica de TimescaleDB es su capacidad para funcionar bien con series temporales sin sacrificar la compatibilidad y los beneficios de las bases de datos relacionales CRUD tradicionales.  En la pr√°ctica, esto significa que obtenemos lo mejor de ambos mundos.  La base de datos sabe qu√© tablas deben considerarse como series de tiempo (y aplica todas las optimizaciones necesarias), pero puede trabajar con ellas de la misma manera que con las tablas normales.  ¬°Adem√°s, no se requiere que las aplicaciones sepan que TSDB controla los datos! <br><br>  Para marcar una tabla como una tabla de series de tiempo (en TSDB esto se llama hipertable), simplemente llame al procedimiento create_ hypertable () TSDB.  Bajo el cap√≥, TSDB divide esta tabla en los llamados fragmentos (el t√©rmino en ingl√©s es fragmentado) de acuerdo con las condiciones especificadas.  Los fragmentos se pueden representar como secciones controladas autom√°ticamente de una tabla.  Cada fragmento tiene un rango de tiempo correspondiente.  Para cada fragmento, TSDB tambi√©n establece √≠ndices especiales para que trabajar con un rango de datos no afecte el acceso a otros. <br><br><img src="https://habrastorage.org/webt/qu/d0/9s/qud09swu7nrhn2e6d6thqhfbgjw.png" alt="imagen"><br><br><oembed>  Imagen Hipertable de timescaledb.com </oembed><br>  Cuando la aplicaci√≥n agrega un nuevo valor para la serie temporal, la extensi√≥n dirige este valor al fragmento deseado.  Si el rango para el tiempo del nuevo valor no est√° definido, TSDB crear√° un nuevo fragmento, le asignar√° el rango deseado e insertar√° el valor all√≠.  Si una aplicaci√≥n solicita datos de un hipertable, antes de ejecutar la solicitud, la extensi√≥n verifica qu√© fragmentos est√°n asociados con esta solicitud. <br><br>  Pero eso no es todo.  TSDB complementa el robusto y probado ecosistema PostgreSQL con una gran cantidad de cambios de rendimiento y escalabilidad.  Estos incluyen la adici√≥n r√°pida de nuevos registros, consultas r√°pidas y eliminaciones por lotes pr√°cticamente gratuitas. <br><br>  Como se se√±al√≥ anteriormente, para controlar el tama√±o de la base de datos y cumplir con las pol√≠ticas de retenci√≥n (es decir, no almacenar datos por m√°s tiempo del necesario), una buena soluci√≥n de monitoreo deber√≠a eliminar efectivamente una gran cantidad de datos hist√≥ricos.  Con TSDB, podemos eliminar la historia deseada simplemente eliminando ciertos fragmentos del hipertable.  En este caso, la aplicaci√≥n no necesita rastrear fragmentos por nombre o cualquier otro enlace, TSDB eliminar√° todos los fragmentos necesarios de acuerdo con la condici√≥n de tiempo especificada. <br><br><h4>  Particionamiento TimescaleDB y PostgreSQL </h4><br>  A primera vista, puede parecer que TSDB es un buen envoltorio alrededor de la partici√≥n est√°ndar de tablas PG ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">partici√≥n declarativa</a> , como se llama oficialmente en PG10).  De hecho, para almacenar datos hist√≥ricos, puede usar la partici√≥n est√°ndar PG10.  Pero si nos fijamos bien, los fragmentos de la secci√≥n TSDB y PG10 est√°n lejos de ser conceptos id√©nticos. <br><br>  Para comenzar, la configuraci√≥n de la partici√≥n en PG requiere una comprensi√≥n m√°s profunda de los detalles, lo que la aplicaci√≥n misma o el DBMS deber√≠an hacer de una buena manera.  Primero, debe planificar su jerarqu√≠a de secciones y decidir si usar particiones anidadas.  En segundo lugar, debe crear un esquema de nomenclatura de secci√≥n y, de alguna manera, transferirlo a los scripts para crear el esquema.  Lo m√°s probable es que el esquema de nomenclatura incluya la fecha y / o la hora, y dichos nombres deber√°n automatizarse de alguna manera. <br><br>  A continuaci√≥n, debe pensar en c√≥mo eliminar los datos caducados.  En TSDB, simplemente puede llamar al comando drop_chunks (), que determina los fragmentos que se eliminar√°n durante un per√≠odo de tiempo determinado.  En PG10, si necesita eliminar un cierto rango de valores de las secciones PG est√°ndar, tendr√° que calcular la lista de nombres de secci√≥n para este rango usted mismo.  Si el esquema de partici√≥n seleccionado involucra secciones anidadas, esto complica a√∫n m√°s la eliminaci√≥n. <br><br>  Otro problema que debe abordarse es qu√© hacer con los datos que van m√°s all√° de los rangos de tiempo actuales.  Por ejemplo, los datos pueden provenir de un futuro para el que a√∫n no se han creado secciones.  O del pasado para secciones ya eliminadas.  Por defecto en PG10, agregar un registro de este tipo no funcionar√° y simplemente perderemos los datos.  En PG11, puede definir una secci√≥n predeterminada para dichos datos, pero esto solo enmascara temporalmente el problema y no lo resuelve. <br><br>  Por supuesto, todos los problemas anteriores se pueden resolver de una forma u otra.  Puedes colgar la base con disparadores, cron-jabs y rociar generosamente con scripts.  Ser√° feo, pero funcional.  No hay duda de que las secciones de PG son mejores que las tablas monol√≠ticas gigantes, pero lo que definitivamente no se resuelve a trav√©s de scripts y desencadenantes son las mejoras de series temporales que PG no tiene. <br><br>  Es decir  En comparaci√≥n con las secciones PG, las hipertables TSDB se distinguen favorablemente no solo por salvar los nervios de los administradores de bases de datos, sino tambi√©n por optimizar tanto el acceso a los datos como agregar nuevos.  Por ejemplo, los fragmentos en TSDB son siempre una matriz unidimensional.  Esto simplifica la gesti√≥n de fragmentos y acelera las inserciones y selecciones.  Para agregar nuevos datos, TSDB usa su propio algoritmo de enrutamiento en el fragmento deseado, que, a diferencia del PG est√°ndar, no abre de inmediato todas las secciones.  Con una gran cantidad de secciones, la diferencia en el rendimiento puede variar significativamente.  Los detalles t√©cnicos sobre la diferencia entre la partici√≥n est√°ndar en PG y TSDB se pueden encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este art√≠culo</a> . <br><br><h4>  Zabbix y TimescaleDB </h4><br>  De todas las opciones, TimescaleDB parece ser la opci√≥n m√°s segura para Zabbix y sus usuarios: <br><br><ul><li>  TSDB est√° dise√±ado como una extensi√≥n PostgreSQL, y no como un sistema independiente.  Por lo tanto, no requiere hardware adicional, m√°quinas virtuales ni ning√∫n otro cambio en la infraestructura.  Los usuarios pueden continuar usando sus herramientas elegidas para PostgreSQL. </li><li>  TSDB le permite guardar casi todo el c√≥digo para trabajar con la base de datos en Zabbix sin cambios. </li><li>  TSDB mejora significativamente el rendimiento del historiador y ama de llaves. </li><li>  Umbral de entrada bajo: los conceptos b√°sicos de TSDB son simples y directos. </li><li>  La f√°cil instalaci√≥n y configuraci√≥n de la extensi√≥n en s√≠ y de Zabbix ser√° de gran ayuda para los usuarios de sistemas peque√±os y medianos. </li></ul><br>  Veamos qu√© hay que hacer para iniciar TSDB con un Zabbix reci√©n instalado.  Despu√©s de instalar Zabbix y ejecutar los scripts de creaci√≥n de bases de datos PostgreSQL, debe descargar e instalar TSDB en la plataforma deseada.  Consulte las instrucciones de instalaci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  Despu√©s de instalar la extensi√≥n, debe habilitarla para la base de Zabbix y luego ejecutar el script timecaledb.sql que viene con Zabbix.  Se encuentra en la base de datos / postgresql / timecaledb.sql si la instalaci√≥n es desde el origen, o en /usr/share/zabbix/database/timecaledb.sql.gz si la instalaci√≥n es desde paquetes.  Eso es todo!  Ahora puede iniciar el servidor Zabbix y funcionar√° con TSDB. <br><br>  El script timescaledb.sql es trivial.  Todo lo que hace es convertir las tablas hist√≥ricas normales de Zabbix en hipertables TSDB y cambiar la configuraci√≥n predeterminada: establece los par√°metros Anular per√≠odo de historial de elementos y Anular per√≠odo de tendencia de elementos.  Ahora (versi√≥n 4.2) las siguientes tablas de Zabbix funcionan bajo el control de TSDB: history, history_uint, history_str, history_log, history_text, trends y trends_uint.  Se puede utilizar el mismo script para migrar estas tablas (tenga en cuenta que el par√°metro migrate_data est√° establecido en verdadero).  Debe tenerse en cuenta que la migraci√≥n de datos es un proceso muy largo y puede llevar varias horas. <br><br>  El par√°metro chunk_time_interval =&gt; 86400 tambi√©n puede requerir cambios antes de ejecutar timecaledb.sql. Chunk_time_interval es el intervalo que limita el tiempo de los valores que caen en este fragmento.  Por ejemplo, si establece el intervalo chunk_time_interval en 3 horas, los datos para todo el d√≠a se distribuir√°n en 8 fragmentos, con el primer fragmento No. 1 cubriendo las primeras 3 horas (0: 00-2: 59), el segundo fragmento No. 2 - las segundas 3 horas ( 3: 00-5: 59), etc.  El √∫ltimo fragmento No. 8 contendr√° valores con un tiempo de 21: 00-23: 59.  86400 segundos (1 d√≠a) es el valor predeterminado promedio, pero los usuarios de sistemas cargados pueden querer reducirlo. <br><br>  Para estimar aproximadamente los requisitos de memoria, es importante comprender cu√°nto espacio puede ocupar una pieza en promedio.  El principio general es que el sistema debe tener suficiente memoria para organizar al menos un fragmento de cada hipertable.  En este caso, por supuesto, la suma de los tama√±os de los fragmentos no solo debe caber en la memoria con un margen, sino que tambi√©n debe ser menor que el valor del par√°metro shared_buffers de postgresql.conf.  Puede encontrar m√°s informaci√≥n sobre este tema en la documentaci√≥n de TimescaleDB. <br><br>  Por ejemplo, si tiene un sistema que recopila principalmente m√©tricas enteras y decide dividir la tabla history_uint en fragmentos de 2 horas y dividir el resto de las tablas en fragmentos de un d√≠a, entonces necesita cambiar esta fila en timecaledb.sql: <br><br><pre><code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_uint'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">7200</span></span>, migrate_data =&gt; <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>);</code> </pre> <br>  Despu√©s de que se haya acumulado una cierta cantidad de datos hist√≥ricos, puede verificar los tama√±os de fragmento para la tabla history_uint llamando a chunk_relation_size (): <br><br><pre> <code class="plaintext hljs">zabbix=&gt; SELECT chunk_table,total_bytes FROM chunk_relation_size('history_uint');              chunk_table               | total_bytes -----------------------------------------+------------- _timescaledb_internal._hyper_2_6_chunk  |    13287424 _timescaledb_internal._hyper_2_7_chunk  |    13172736 _timescaledb_internal._hyper_2_8_chunk  |    13344768 _timescaledb_internal._hyper_2_9_chunk  |    13434880 _timescaledb_internal._hyper_2_10_chunk |    13230080 _timescaledb_internal._hyper_2_11_chunk |    13189120</code> </pre> <br>  Esta llamada se puede repetir para encontrar los tama√±os de fragmento para todas las hipertables.  Si, por ejemplo, se descubri√≥ que el tama√±o del fragmento de history_uint es de 13 MB, los fragmentos para otras tablas de historial, digamos 20 MB y para las tablas de tendencias de 10 MB, entonces el requisito de memoria total es 13 + 4 x 20 + 2 x 10 = 113 MB.  Tambi√©n debemos dejar espacio desde shared_buffers para almacenar otros datos, digamos 20%.  Luego, el valor de shared_buffers debe establecerse en 113MB / 0.8 = ~ 140MB. <br><br>  Para un ajuste m√°s fino de TSDB, recientemente apareci√≥ la utilidad timecaledb-tune.  Analiza postgresql.conf, lo correlaciona con la configuraci√≥n del sistema (memoria y procesador), y luego da recomendaciones sobre la configuraci√≥n de par√°metros de memoria, par√°metros para procesamiento paralelo, WAL.  La utilidad cambia el archivo postgresql.conf, pero puede ejecutarlo con el par√°metro -dry-run y verificar los cambios propuestos. <br><br>  Nos detendremos en los par√°metros de Zabbix. Anular per√≠odo de historial de art√≠culo y Per√≠odo de tendencia de art√≠culo de anulaci√≥n (disponible en Administraci√≥n -&gt; General -&gt; Mantenimiento).  Se necesitan para eliminar datos hist√≥ricos como fragmentos enteros de hipertables TSDB, no registros. <br><br>  El hecho es que Zabbix le permite establecer el per√≠odo de limpieza para cada elemento de datos (m√©trica) individualmente.  Sin embargo, esta flexibilidad se logra escaneando la lista de elementos y calculando per√≠odos individuales en cada iteraci√≥n de la limpieza.  Si el sistema tiene per√≠odos de limpieza individuales para elementos individuales, entonces el sistema obviamente no puede tener un √∫nico punto de corte para todas las m√©tricas juntas y Zabbix no podr√° dar el comando correcto para eliminar los fragmentos necesarios.  Por lo tanto, al desactivar el historial de anulaci√≥n para las m√©tricas, Zabbix perder√° la capacidad de eliminar el historial r√°pidamente llamando al procedimiento drop_chunks () para las tablas history_ * y, en consecuencia, al desactivar las tendencias de anulaci√≥n se perder√° la misma funci√≥n para las tablas de tendencias_ *. <br><br>  En otras palabras, para aprovechar al m√°ximo el nuevo sistema de limpieza, debe hacer que ambas opciones sean globales.  En este caso, el proceso de limpieza no leer√° la configuraci√≥n de los elementos de datos. <br><br><h4>  Rendimiento con TimescaleDB </h4><br>  Es hora de verificar si todo lo anterior realmente funciona en la pr√°ctica.  Nuestro banco de pruebas es Zabbix 4.2rc1 con PostgreSQL 10.7 y TimescaleDB 1.2.1 para Debian 9. La m√°quina de prueba es un Intel Xeon de 10 n√∫cleos con 16 GB de RAM y 60 GB de espacio de almacenamiento en el SSD.  Seg√∫n los est√°ndares actuales, esta es una configuraci√≥n muy modesta, pero nuestro objetivo es descubrir qu√© tan efectiva es la TSDB en la vida real.  En configuraciones con un presupuesto ilimitado, simplemente puede insertar 128-256 GB de RAM y colocar la mayor√≠a (si no toda) de la base de datos en la memoria. <br><br>  Nuestra configuraci√≥n de prueba consta de 32 agentes Zabbix activos que transfieren datos directamente al servidor Zabbix.  Cada agente sirve 10,000 art√≠culos.  El cach√© hist√≥rico de Zabbix est√° configurado en 256 MB, y shared_buffers PG est√° configurado en 2 GB.  Esta configuraci√≥n proporciona una carga suficiente en la base de datos, pero al mismo tiempo no crea una carga grande en los procesos del servidor Zabbix.  Para reducir el n√∫mero de partes m√≥viles entre las fuentes de datos y la base de datos, no utilizamos el Proxy Zabbix. <br><br>  Aqu√≠ est√° el primer resultado obtenido del sistema PG est√°ndar: <br><br><img src="https://habrastorage.org/webt/hm/wj/rp/hmwjrp03sittv-f7ay9swag5z5y.png" alt="imagen"><br><br>  El resultado de TSDB es completamente diferente: <br><br><img src="https://habrastorage.org/webt/0-/75/r-/0-75r-lgjnjbwty1wnoniq7az4k.png" alt="imagen"><br><br>  El siguiente gr√°fico combina ambos resultados.  El trabajo comienza con valores NVPS bastante altos en 170-200K, porque  Lleva alg√∫n tiempo llenar el cach√© del historial antes de que comience la sincronizaci√≥n con la base de datos. <br><br><img src="https://habrastorage.org/webt/qm/ro/p9/qmrop9da6tqvsdlbmaoe00jixxy.png" alt="imagen"><br><br>  Cuando la tabla de historial est√° vac√≠a, la velocidad de escritura en TSDB es comparable a la velocidad de escritura en PG, e incluso con un peque√±o margen de este √∫ltimo.  Tan pronto como el n√∫mero de registros en la historia alcanza 50-60 millones, el rendimiento de PG cae a 110K NVPS, pero, lo que es m√°s desagradable, contin√∫a cambiando inversamente con el n√∫mero de registros acumulados en la tabla hist√≥rica.  Al mismo tiempo, TSDB mantiene una velocidad estable de 130K NVPS durante toda la prueba de 0 a 300 millones de registros. <br><br>  En total, en nuestro ejemplo, la diferencia en el rendimiento promedio es bastante significativa (130K versus 90K sin tener en cuenta el pico inicial).  Tambi√©n se ve que la tasa de inserci√≥n en PG est√°ndar var√≠a en un amplio rango.  Por lo tanto, si un flujo de trabajo requiere almacenar decenas o cientos de millones de registros en la historia, pero no hay recursos para estrategias de almacenamiento en cach√© muy agresivas, entonces TSDB es un fuerte candidato para reemplazar el PG est√°ndar. <br><br>  La ventaja de TSDB ya es obvia para este sistema relativamente modesto, pero lo m√°s probable es que la diferencia sea a√∫n m√°s notable en grandes conjuntos de datos hist√≥ricos.  Por otro lado, esta prueba no es en modo alguno una generalizaci√≥n de todos los escenarios posibles de trabajar con Zabbix.  Naturalmente, hay muchos factores que influyen en los resultados, como las configuraciones de hardware, la configuraci√≥n del sistema operativo, la configuraci√≥n del servidor Zabbix y la carga adicional de otros servicios que se ejecutan en segundo plano.  Es decir, su kilometraje puede variar. <br><br><h4>  Conclusi√≥n </h4><br>  TimescaleDB es una tecnolog√≠a muy prometedora.  Ya ha sido operado con √©xito en entornos de producci√≥n serios.  TSDB funciona bien con Zabbix y ofrece ventajas significativas sobre la base de datos PostgreSQL est√°ndar. <br><br>  ¬øTiene TSDB alguna falla o raz√≥n para posponer su uso?  Desde un punto de vista t√©cnico, no vemos ning√∫n argumento en contra.  Pero debe tenerse en cuenta que la tecnolog√≠a a√∫n es nueva, con un ciclo de lanzamiento inestable y una estrategia poco clara para el desarrollo de la funcionalidad.  En particular, se lanzan nuevas versiones con cambios significativos cada mes o dos.  Algunas funciones pueden eliminarse, como, por ejemplo, sucedi√≥ con fragmentaci√≥n adaptativa.  Por separado, como otro factor de incertidumbre, vale la pena mencionar la pol√≠tica de licencias.  Es muy confuso ya que hay tres niveles de licencia.  El kernel TSDB est√° hecho bajo la licencia Apache, algunas funciones se lanzan bajo su propia licencia Timescale, pero tambi√©n hay una versi√≥n cerrada de Enterprise. <br><br>  Si usa Zabbix con PostgreSQL, entonces no hay raz√≥n al menos para no probar TimescaleDB.  Quiz√°s esto te sorprenda gratamente :) Solo ten en cuenta que el soporte para TimescaleDB en Zabbix sigue siendo experimental, por un tiempo, mientras recopilamos rese√±as de usuarios y ganamos experiencia. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458530/">https://habr.com/ru/post/458530/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458514/index.html">La violaci√≥n de GDPR se castiga m√°s activamente: nuevas multas y el impacto de las regulaciones fuera de la UE</a></li>
<li><a href="../458516/index.html">Obtenga un registro de trabajo de Jira</a></li>
<li><a href="../458518/index.html">Python consume mucha memoria o ¬øc√≥mo reducir el tama√±o de los objetos?</a></li>
<li><a href="../458520/index.html">El libro "C√≥digo de alto rendimiento en la plataforma .NET. 2da edicion</a></li>
<li><a href="../458524/index.html">VC nube de palabras en la rodilla</a></li>
<li><a href="../458532/index.html">Pioneros de las nuevas tecnolog√≠as: Vadim Artsev cont√≥ c√≥mo dej√≥ de ser ciego</a></li>
<li><a href="../458536/index.html">Python + Pyside2 o simplemente "Calculadora"</a></li>
<li><a href="../458546/index.html">D√≠a de la automatizaci√≥n, o c√≥mo construimos la capa de autotest.</a></li>
<li><a href="../458548/index.html">Cree su propia biblioteca de estilos de Spring Data Repository con Dynamic Proxy y Spring IoC</a></li>
<li><a href="../458550/index.html">Biblioteca de s√≠mbolos GOST para DipTrace</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游높游 游닄 游녺 Zabbix, series de tiempo y TimescaleDB 游 游뱢游낖 游땗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cada sistema de monitoreo enfrenta tres tipos de problemas de rendimiento. 

 En primer lugar, un buen sistema de monitoreo deber칤a recibir, procesar ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Zabbix, series de tiempo y TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/zabbix/blog/458530/"> Cada sistema de monitoreo enfrenta tres tipos de problemas de rendimiento. <br><br>  En primer lugar, un buen sistema de monitoreo deber칤a recibir, procesar y registrar r치pidamente los datos provenientes del exterior.  La cuenta va a microsegundos.  Por casualidad, esto puede parecer poco obvio, pero cuando el sistema se vuelve lo suficientemente grande, todas estas fracciones de segundos se resumen, convirti칠ndose en demoras claramente notables. <br><br><img src="https://habrastorage.org/webt/s6/fy/mx/s6fymxoyf5_f9n0hwidv8q6qsh4.png" alt="imagen"><br><a name="habracut"></a><br>  La segunda tarea es proporcionar un acceso conveniente a grandes conjuntos de m칠tricas recopiladas previamente (en otras palabras, a datos hist칩ricos).  Los datos hist칩ricos se utilizan en una amplia variedad de contextos.  Por ejemplo, se generan informes y gr치ficos a partir de ellos, se crean controles agregados sobre ellos, los desencadenantes dependen de ellos.  Si hay retrasos en el acceso al historial, esto afecta inmediatamente la velocidad de todo el sistema en su conjunto. <br><br>  En tercer lugar, los datos hist칩ricos ocupan mucho espacio.  Incluso las configuraciones de monitoreo relativamente modestas adquieren r치pidamente un historial s칩lido.  Pero casi nadie quiere tener a mano el historial de carga del procesador de cinco a침os de antig칲edad, por lo que el sistema de monitoreo deber칤a poder no solo grabar bien, sino tambi칠n borrar bien el historial (en Zabbix este proceso se llama "limpieza").  La eliminaci칩n de datos antiguos no tiene que ser tan eficiente como la recopilaci칩n y el an치lisis de datos nuevos, pero las operaciones de eliminaci칩n intensivas se basan en recursos valiosos de DBMS y pueden ralentizar las operaciones m치s cr칤ticas. <br><br>  Los dos primeros problemas se resuelven mediante el almacenamiento en cach칠.  Zabbix admite varias cach칠s especializadas para acelerar las operaciones de lectura y escritura de datos.  Los mecanismos DBMS en s칤 mismos no son adecuados aqu칤, porque  incluso el algoritmo de almacenamiento en cach칠 de prop칩sito general m치s avanzado no sabr치 qu칠 estructuras de datos requieren acceso instant치neo en un momento dado. <br><br><h4>  Monitoreo y datos de series temporales </h4><br>  Todo est치 bien siempre que los datos est칠n en la memoria del servidor Zabbix.  Pero la memoria no es infinita y en alg칰n momento los datos deben escribirse (o leerse) en la base de datos.  Y si el rendimiento de la base de datos est치 muy por detr치s de la velocidad de recopilaci칩n de m칠tricas, incluso los algoritmos de almacenamiento en cach칠 especiales m치s avanzados no ayudar치n durante mucho tiempo. <br><br>  El tercer problema tambi칠n se reduce al rendimiento de la base de datos.  Para resolverlo, debe elegir una estrategia de eliminaci칩n confiable que no interfiera con otras operaciones de la base de datos.  Por defecto, Zabbix elimina datos hist칩ricos en lotes de varios miles de registros por hora.  Puede configurar per칤odos de mantenimiento m치s largos o paquetes de mayor tama침o si la velocidad de la recopilaci칩n de datos y el lugar en la base de datos lo permiten.  Pero con una gran cantidad de m칠tricas y / o una alta frecuencia de recopilaci칩n, la configuraci칩n adecuada de limpieza puede ser una tarea desalentadora, ya que un programa de eliminaci칩n de datos puede no mantenerse al ritmo de la grabaci칩n de nuevos. <br><br>  Resumiendo, el sistema de monitoreo resuelve problemas de rendimiento en tres direcciones: recolectando datos nuevos y escribi칠ndolos en la base de datos usando consultas SQL INSERT, accediendo a datos usando consultas SELECT y eliminando datos usando DELETE.  Veamos c칩mo se ejecuta una consulta SQL t칤pica: <br><br><ul><li>  El DBMS analiza la consulta y verifica si hay errores de sintaxis.  Si la solicitud es sint치cticamente correcta, el motor construye un 치rbol de sintaxis para su posterior procesamiento. </li><li>  El planificador de consultas analiza el 치rbol de sintaxis y calcula las diversas formas (rutas) para ejecutar la solicitud. </li><li>  El planificador calcula la forma m치s barata.  En el proceso, tiene en cuenta muchas cosas: qu칠 tan grandes son las tablas, si es necesario ordenar los resultados, si hay 칤ndices aplicables a la consulta, etc. </li><li>  Cuando se encuentra la ruta 칩ptima, el motor ejecuta la consulta accediendo a los bloques de datos deseados (usando 칤ndices o escaneo secuencial), aplica los criterios de clasificaci칩n y filtrado, recopila el resultado y lo devuelve al cliente. </li><li>  Para insertar, modificar y eliminar consultas, el motor tambi칠n debe actualizar los 칤ndices para las tablas correspondientes.  Para tablas grandes, esta operaci칩n puede llevar m치s tiempo que trabajar con los datos en s칤. </li><li>  Lo m치s probable es que el DBMS tambi칠n actualice las estad칤sticas internas del uso de datos para llamadas posteriores al programador de consultas. </li></ul><br>  En general, hay mucho trabajo.  La mayor칤a de los DBMS proporcionan una gran cantidad de configuraciones para la optimizaci칩n de consultas, pero generalmente se centran en algunos flujos de trabajo promedio en los que la inserci칩n y eliminaci칩n de registros ocurre aproximadamente con la misma frecuencia que el cambio. <br><br>  Sin embargo, como se mencion칩 anteriormente, para los sistemas de monitoreo, las operaciones m치s t칤picas son agregar y eliminar peri칩dicamente en modo por lotes.  El cambio de datos agregados anteriormente casi nunca ocurre, y el acceso a los datos implica el uso de funciones agregadas.  Adem치s, generalmente los valores de las m칠tricas agregadas se ordenan por tiempo.  Tales datos se conocen com칰nmente como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">series de tiempo</a> : <br><br><blockquote>  La serie temporal es una serie de puntos de datos indexados (o listados o graffiti) en un orden temporal. </blockquote><br><br>  Desde el punto de vista de la base de datos, las series temporales tienen las siguientes propiedades: <br><br><ul><li>  Las series de tiempo pueden ubicarse en un disco como una secuencia de bloques ordenados por tiempo. </li><li>  Las tablas de series de tiempo se pueden indexar utilizando una columna de tiempo. </li><li>  La mayor칤a de las consultas SQL SELECT usar치n las cl치usulas WHERE, GROUP BY u ORDER BY en una columna que indica el tiempo. </li><li>  Por lo general, los datos de series temporales tienen una "fecha de vencimiento" despu칠s de la cual se pueden eliminar. </li></ul><br>  Obviamente, las bases de datos SQL tradicionales no son adecuadas para almacenar dichos datos, ya que las optimizaciones de uso general no tienen en cuenta estas cualidades.  Por lo tanto, en los 칰ltimos a침os, han aparecido bastantes DBMS nuevos orientados al tiempo, como, por ejemplo, InfluxDB.  Pero todos los DBMS populares para series temporales tienen un inconveniente significativo: la falta de soporte SQL completo.  Adem치s, la mayor칤a de ellos ni siquiera son CRUD (Crear, Leer, Actualizar, Eliminar). <br><br>  쯇uede Zabbix usar estos DBMS de alguna manera?  Uno de los enfoques posibles es transferir datos hist칩ricos para el almacenamiento a una base de datos externa especializada en las series de tiempo.  Dado que la arquitectura Zabbix admite backends externos para almacenar datos hist칩ricos (por ejemplo, el soporte Elasticsearch se implementa en Zabbix), a primera vista, esta opci칩n parece muy razonable.  Pero si admiti칠ramos uno o varios DBMS para series temporales como servidores externos, los usuarios tendr칤an que tener en cuenta los siguientes puntos: <br><br><ul><li>  Otro sistema que necesita ser explorado, configurado y mantenido.  Otro lugar para realizar un seguimiento de la configuraci칩n, el espacio en disco, las pol칤ticas de almacenamiento, el rendimiento, etc. </li><li>  Reducci칩n de la tolerancia a fallas del sistema de monitoreo, como  aparece un nuevo enlace en la cadena de componentes relacionados. </li></ul><br>  Para algunos usuarios, los beneficios del almacenamiento dedicado dedicado para datos hist칩ricos pueden ser mayores que las molestias de tener que preocuparse por otro sistema.  Pero para muchos, esta es una complicaci칩n innecesaria.  Tambi칠n vale la pena recordar que, dado que la mayor칤a de estas soluciones especializadas tienen sus propias API, la complejidad de la capa universal para trabajar con bases de datos Zabbix aumentar치 notablemente.  Y, idealmente, preferimos crear nuevas funciones, en lugar de luchar contra otras API. <br><br>  Surge la pregunta: 쯛ay alguna forma de aprovechar el DBMS para series temporales, pero sin perder la flexibilidad y las ventajas de SQL?  Naturalmente, no existe una respuesta universal, pero una soluci칩n espec칤fica se acerc칩 mucho a la respuesta: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TimescaleDB</a> . <br><br><h4>  쯈u칠 es TimescaleDB? </h4><br>  TimescaleDB (TSDB) es una extensi칩n de PostgreSQL que optimiza el trabajo con series temporales en una base de datos PostgreSQL (PG) normal.  Aunque, como se mencion칩 anteriormente, no hay escasez de soluciones de series temporales bien escalables en el mercado, una caracter칤stica 칰nica de TimescaleDB es su capacidad para funcionar bien con series temporales sin sacrificar la compatibilidad y los beneficios de las bases de datos relacionales CRUD tradicionales.  En la pr치ctica, esto significa que obtenemos lo mejor de ambos mundos.  La base de datos sabe qu칠 tablas deben considerarse como series de tiempo (y aplica todas las optimizaciones necesarias), pero puede trabajar con ellas de la misma manera que con las tablas normales.  춰Adem치s, no se requiere que las aplicaciones sepan que TSDB controla los datos! <br><br>  Para marcar una tabla como una tabla de series de tiempo (en TSDB esto se llama hipertable), simplemente llame al procedimiento create_ hypertable () TSDB.  Bajo el cap칩, TSDB divide esta tabla en los llamados fragmentos (el t칠rmino en ingl칠s es fragmentado) de acuerdo con las condiciones especificadas.  Los fragmentos se pueden representar como secciones controladas autom치ticamente de una tabla.  Cada fragmento tiene un rango de tiempo correspondiente.  Para cada fragmento, TSDB tambi칠n establece 칤ndices especiales para que trabajar con un rango de datos no afecte el acceso a otros. <br><br><img src="https://habrastorage.org/webt/qu/d0/9s/qud09swu7nrhn2e6d6thqhfbgjw.png" alt="imagen"><br><br><oembed>  Imagen Hipertable de timescaledb.com </oembed><br>  Cuando la aplicaci칩n agrega un nuevo valor para la serie temporal, la extensi칩n dirige este valor al fragmento deseado.  Si el rango para el tiempo del nuevo valor no est치 definido, TSDB crear치 un nuevo fragmento, le asignar치 el rango deseado e insertar치 el valor all칤.  Si una aplicaci칩n solicita datos de un hipertable, antes de ejecutar la solicitud, la extensi칩n verifica qu칠 fragmentos est치n asociados con esta solicitud. <br><br>  Pero eso no es todo.  TSDB complementa el robusto y probado ecosistema PostgreSQL con una gran cantidad de cambios de rendimiento y escalabilidad.  Estos incluyen la adici칩n r치pida de nuevos registros, consultas r치pidas y eliminaciones por lotes pr치cticamente gratuitas. <br><br>  Como se se침al칩 anteriormente, para controlar el tama침o de la base de datos y cumplir con las pol칤ticas de retenci칩n (es decir, no almacenar datos por m치s tiempo del necesario), una buena soluci칩n de monitoreo deber칤a eliminar efectivamente una gran cantidad de datos hist칩ricos.  Con TSDB, podemos eliminar la historia deseada simplemente eliminando ciertos fragmentos del hipertable.  En este caso, la aplicaci칩n no necesita rastrear fragmentos por nombre o cualquier otro enlace, TSDB eliminar치 todos los fragmentos necesarios de acuerdo con la condici칩n de tiempo especificada. <br><br><h4>  Particionamiento TimescaleDB y PostgreSQL </h4><br>  A primera vista, puede parecer que TSDB es un buen envoltorio alrededor de la partici칩n est치ndar de tablas PG ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">partici칩n declarativa</a> , como se llama oficialmente en PG10).  De hecho, para almacenar datos hist칩ricos, puede usar la partici칩n est치ndar PG10.  Pero si nos fijamos bien, los fragmentos de la secci칩n TSDB y PG10 est치n lejos de ser conceptos id칠nticos. <br><br>  Para comenzar, la configuraci칩n de la partici칩n en PG requiere una comprensi칩n m치s profunda de los detalles, lo que la aplicaci칩n misma o el DBMS deber칤an hacer de una buena manera.  Primero, debe planificar su jerarqu칤a de secciones y decidir si usar particiones anidadas.  En segundo lugar, debe crear un esquema de nomenclatura de secci칩n y, de alguna manera, transferirlo a los scripts para crear el esquema.  Lo m치s probable es que el esquema de nomenclatura incluya la fecha y / o la hora, y dichos nombres deber치n automatizarse de alguna manera. <br><br>  A continuaci칩n, debe pensar en c칩mo eliminar los datos caducados.  En TSDB, simplemente puede llamar al comando drop_chunks (), que determina los fragmentos que se eliminar치n durante un per칤odo de tiempo determinado.  En PG10, si necesita eliminar un cierto rango de valores de las secciones PG est치ndar, tendr치 que calcular la lista de nombres de secci칩n para este rango usted mismo.  Si el esquema de partici칩n seleccionado involucra secciones anidadas, esto complica a칰n m치s la eliminaci칩n. <br><br>  Otro problema que debe abordarse es qu칠 hacer con los datos que van m치s all치 de los rangos de tiempo actuales.  Por ejemplo, los datos pueden provenir de un futuro para el que a칰n no se han creado secciones.  O del pasado para secciones ya eliminadas.  Por defecto en PG10, agregar un registro de este tipo no funcionar치 y simplemente perderemos los datos.  En PG11, puede definir una secci칩n predeterminada para dichos datos, pero esto solo enmascara temporalmente el problema y no lo resuelve. <br><br>  Por supuesto, todos los problemas anteriores se pueden resolver de una forma u otra.  Puedes colgar la base con disparadores, cron-jabs y rociar generosamente con scripts.  Ser치 feo, pero funcional.  No hay duda de que las secciones de PG son mejores que las tablas monol칤ticas gigantes, pero lo que definitivamente no se resuelve a trav칠s de scripts y desencadenantes son las mejoras de series temporales que PG no tiene. <br><br>  Es decir  En comparaci칩n con las secciones PG, las hipertables TSDB se distinguen favorablemente no solo por salvar los nervios de los administradores de bases de datos, sino tambi칠n por optimizar tanto el acceso a los datos como agregar nuevos.  Por ejemplo, los fragmentos en TSDB son siempre una matriz unidimensional.  Esto simplifica la gesti칩n de fragmentos y acelera las inserciones y selecciones.  Para agregar nuevos datos, TSDB usa su propio algoritmo de enrutamiento en el fragmento deseado, que, a diferencia del PG est치ndar, no abre de inmediato todas las secciones.  Con una gran cantidad de secciones, la diferencia en el rendimiento puede variar significativamente.  Los detalles t칠cnicos sobre la diferencia entre la partici칩n est치ndar en PG y TSDB se pueden encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este art칤culo</a> . <br><br><h4>  Zabbix y TimescaleDB </h4><br>  De todas las opciones, TimescaleDB parece ser la opci칩n m치s segura para Zabbix y sus usuarios: <br><br><ul><li>  TSDB est치 dise침ado como una extensi칩n PostgreSQL, y no como un sistema independiente.  Por lo tanto, no requiere hardware adicional, m치quinas virtuales ni ning칰n otro cambio en la infraestructura.  Los usuarios pueden continuar usando sus herramientas elegidas para PostgreSQL. </li><li>  TSDB le permite guardar casi todo el c칩digo para trabajar con la base de datos en Zabbix sin cambios. </li><li>  TSDB mejora significativamente el rendimiento del historiador y ama de llaves. </li><li>  Umbral de entrada bajo: los conceptos b치sicos de TSDB son simples y directos. </li><li>  La f치cil instalaci칩n y configuraci칩n de la extensi칩n en s칤 y de Zabbix ser치 de gran ayuda para los usuarios de sistemas peque침os y medianos. </li></ul><br>  Veamos qu칠 hay que hacer para iniciar TSDB con un Zabbix reci칠n instalado.  Despu칠s de instalar Zabbix y ejecutar los scripts de creaci칩n de bases de datos PostgreSQL, debe descargar e instalar TSDB en la plataforma deseada.  Consulte las instrucciones de instalaci칩n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu칤</a> .  Despu칠s de instalar la extensi칩n, debe habilitarla para la base de Zabbix y luego ejecutar el script timecaledb.sql que viene con Zabbix.  Se encuentra en la base de datos / postgresql / timecaledb.sql si la instalaci칩n es desde el origen, o en /usr/share/zabbix/database/timecaledb.sql.gz si la instalaci칩n es desde paquetes.  Eso es todo!  Ahora puede iniciar el servidor Zabbix y funcionar치 con TSDB. <br><br>  El script timescaledb.sql es trivial.  Todo lo que hace es convertir las tablas hist칩ricas normales de Zabbix en hipertables TSDB y cambiar la configuraci칩n predeterminada: establece los par치metros Anular per칤odo de historial de elementos y Anular per칤odo de tendencia de elementos.  Ahora (versi칩n 4.2) las siguientes tablas de Zabbix funcionan bajo el control de TSDB: history, history_uint, history_str, history_log, history_text, trends y trends_uint.  Se puede utilizar el mismo script para migrar estas tablas (tenga en cuenta que el par치metro migrate_data est치 establecido en verdadero).  Debe tenerse en cuenta que la migraci칩n de datos es un proceso muy largo y puede llevar varias horas. <br><br>  El par치metro chunk_time_interval =&gt; 86400 tambi칠n puede requerir cambios antes de ejecutar timecaledb.sql. Chunk_time_interval es el intervalo que limita el tiempo de los valores que caen en este fragmento.  Por ejemplo, si establece el intervalo chunk_time_interval en 3 horas, los datos para todo el d칤a se distribuir치n en 8 fragmentos, con el primer fragmento No. 1 cubriendo las primeras 3 horas (0: 00-2: 59), el segundo fragmento No. 2 - las segundas 3 horas ( 3: 00-5: 59), etc.  El 칰ltimo fragmento No. 8 contendr치 valores con un tiempo de 21: 00-23: 59.  86400 segundos (1 d칤a) es el valor predeterminado promedio, pero los usuarios de sistemas cargados pueden querer reducirlo. <br><br>  Para estimar aproximadamente los requisitos de memoria, es importante comprender cu치nto espacio puede ocupar una pieza en promedio.  El principio general es que el sistema debe tener suficiente memoria para organizar al menos un fragmento de cada hipertable.  En este caso, por supuesto, la suma de los tama침os de los fragmentos no solo debe caber en la memoria con un margen, sino que tambi칠n debe ser menor que el valor del par치metro shared_buffers de postgresql.conf.  Puede encontrar m치s informaci칩n sobre este tema en la documentaci칩n de TimescaleDB. <br><br>  Por ejemplo, si tiene un sistema que recopila principalmente m칠tricas enteras y decide dividir la tabla history_uint en fragmentos de 2 horas y dividir el resto de las tablas en fragmentos de un d칤a, entonces necesita cambiar esta fila en timecaledb.sql: <br><br><pre><code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_uint'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">7200</span></span>, migrate_data =&gt; <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>);</code> </pre> <br>  Despu칠s de que se haya acumulado una cierta cantidad de datos hist칩ricos, puede verificar los tama침os de fragmento para la tabla history_uint llamando a chunk_relation_size (): <br><br><pre> <code class="plaintext hljs">zabbix=&gt; SELECT chunk_table,total_bytes FROM chunk_relation_size('history_uint');              chunk_table               | total_bytes -----------------------------------------+------------- _timescaledb_internal._hyper_2_6_chunk  |    13287424 _timescaledb_internal._hyper_2_7_chunk  |    13172736 _timescaledb_internal._hyper_2_8_chunk  |    13344768 _timescaledb_internal._hyper_2_9_chunk  |    13434880 _timescaledb_internal._hyper_2_10_chunk |    13230080 _timescaledb_internal._hyper_2_11_chunk |    13189120</code> </pre> <br>  Esta llamada se puede repetir para encontrar los tama침os de fragmento para todas las hipertables.  Si, por ejemplo, se descubri칩 que el tama침o del fragmento de history_uint es de 13 MB, los fragmentos para otras tablas de historial, digamos 20 MB y para las tablas de tendencias de 10 MB, entonces el requisito de memoria total es 13 + 4 x 20 + 2 x 10 = 113 MB.  Tambi칠n debemos dejar espacio desde shared_buffers para almacenar otros datos, digamos 20%.  Luego, el valor de shared_buffers debe establecerse en 113MB / 0.8 = ~ 140MB. <br><br>  Para un ajuste m치s fino de TSDB, recientemente apareci칩 la utilidad timecaledb-tune.  Analiza postgresql.conf, lo correlaciona con la configuraci칩n del sistema (memoria y procesador), y luego da recomendaciones sobre la configuraci칩n de par치metros de memoria, par치metros para procesamiento paralelo, WAL.  La utilidad cambia el archivo postgresql.conf, pero puede ejecutarlo con el par치metro -dry-run y verificar los cambios propuestos. <br><br>  Nos detendremos en los par치metros de Zabbix. Anular per칤odo de historial de art칤culo y Per칤odo de tendencia de art칤culo de anulaci칩n (disponible en Administraci칩n -&gt; General -&gt; Mantenimiento).  Se necesitan para eliminar datos hist칩ricos como fragmentos enteros de hipertables TSDB, no registros. <br><br>  El hecho es que Zabbix le permite establecer el per칤odo de limpieza para cada elemento de datos (m칠trica) individualmente.  Sin embargo, esta flexibilidad se logra escaneando la lista de elementos y calculando per칤odos individuales en cada iteraci칩n de la limpieza.  Si el sistema tiene per칤odos de limpieza individuales para elementos individuales, entonces el sistema obviamente no puede tener un 칰nico punto de corte para todas las m칠tricas juntas y Zabbix no podr치 dar el comando correcto para eliminar los fragmentos necesarios.  Por lo tanto, al desactivar el historial de anulaci칩n para las m칠tricas, Zabbix perder치 la capacidad de eliminar el historial r치pidamente llamando al procedimiento drop_chunks () para las tablas history_ * y, en consecuencia, al desactivar las tendencias de anulaci칩n se perder치 la misma funci칩n para las tablas de tendencias_ *. <br><br>  En otras palabras, para aprovechar al m치ximo el nuevo sistema de limpieza, debe hacer que ambas opciones sean globales.  En este caso, el proceso de limpieza no leer치 la configuraci칩n de los elementos de datos. <br><br><h4>  Rendimiento con TimescaleDB </h4><br>  Es hora de verificar si todo lo anterior realmente funciona en la pr치ctica.  Nuestro banco de pruebas es Zabbix 4.2rc1 con PostgreSQL 10.7 y TimescaleDB 1.2.1 para Debian 9. La m치quina de prueba es un Intel Xeon de 10 n칰cleos con 16 GB de RAM y 60 GB de espacio de almacenamiento en el SSD.  Seg칰n los est치ndares actuales, esta es una configuraci칩n muy modesta, pero nuestro objetivo es descubrir qu칠 tan efectiva es la TSDB en la vida real.  En configuraciones con un presupuesto ilimitado, simplemente puede insertar 128-256 GB de RAM y colocar la mayor칤a (si no toda) de la base de datos en la memoria. <br><br>  Nuestra configuraci칩n de prueba consta de 32 agentes Zabbix activos que transfieren datos directamente al servidor Zabbix.  Cada agente sirve 10,000 art칤culos.  El cach칠 hist칩rico de Zabbix est치 configurado en 256 MB, y shared_buffers PG est치 configurado en 2 GB.  Esta configuraci칩n proporciona una carga suficiente en la base de datos, pero al mismo tiempo no crea una carga grande en los procesos del servidor Zabbix.  Para reducir el n칰mero de partes m칩viles entre las fuentes de datos y la base de datos, no utilizamos el Proxy Zabbix. <br><br>  Aqu칤 est치 el primer resultado obtenido del sistema PG est치ndar: <br><br><img src="https://habrastorage.org/webt/hm/wj/rp/hmwjrp03sittv-f7ay9swag5z5y.png" alt="imagen"><br><br>  El resultado de TSDB es completamente diferente: <br><br><img src="https://habrastorage.org/webt/0-/75/r-/0-75r-lgjnjbwty1wnoniq7az4k.png" alt="imagen"><br><br>  El siguiente gr치fico combina ambos resultados.  El trabajo comienza con valores NVPS bastante altos en 170-200K, porque  Lleva alg칰n tiempo llenar el cach칠 del historial antes de que comience la sincronizaci칩n con la base de datos. <br><br><img src="https://habrastorage.org/webt/qm/ro/p9/qmrop9da6tqvsdlbmaoe00jixxy.png" alt="imagen"><br><br>  Cuando la tabla de historial est치 vac칤a, la velocidad de escritura en TSDB es comparable a la velocidad de escritura en PG, e incluso con un peque침o margen de este 칰ltimo.  Tan pronto como el n칰mero de registros en la historia alcanza 50-60 millones, el rendimiento de PG cae a 110K NVPS, pero, lo que es m치s desagradable, contin칰a cambiando inversamente con el n칰mero de registros acumulados en la tabla hist칩rica.  Al mismo tiempo, TSDB mantiene una velocidad estable de 130K NVPS durante toda la prueba de 0 a 300 millones de registros. <br><br>  En total, en nuestro ejemplo, la diferencia en el rendimiento promedio es bastante significativa (130K versus 90K sin tener en cuenta el pico inicial).  Tambi칠n se ve que la tasa de inserci칩n en PG est치ndar var칤a en un amplio rango.  Por lo tanto, si un flujo de trabajo requiere almacenar decenas o cientos de millones de registros en la historia, pero no hay recursos para estrategias de almacenamiento en cach칠 muy agresivas, entonces TSDB es un fuerte candidato para reemplazar el PG est치ndar. <br><br>  La ventaja de TSDB ya es obvia para este sistema relativamente modesto, pero lo m치s probable es que la diferencia sea a칰n m치s notable en grandes conjuntos de datos hist칩ricos.  Por otro lado, esta prueba no es en modo alguno una generalizaci칩n de todos los escenarios posibles de trabajar con Zabbix.  Naturalmente, hay muchos factores que influyen en los resultados, como las configuraciones de hardware, la configuraci칩n del sistema operativo, la configuraci칩n del servidor Zabbix y la carga adicional de otros servicios que se ejecutan en segundo plano.  Es decir, su kilometraje puede variar. <br><br><h4>  Conclusi칩n </h4><br>  TimescaleDB es una tecnolog칤a muy prometedora.  Ya ha sido operado con 칠xito en entornos de producci칩n serios.  TSDB funciona bien con Zabbix y ofrece ventajas significativas sobre la base de datos PostgreSQL est치ndar. <br><br>  쯊iene TSDB alguna falla o raz칩n para posponer su uso?  Desde un punto de vista t칠cnico, no vemos ning칰n argumento en contra.  Pero debe tenerse en cuenta que la tecnolog칤a a칰n es nueva, con un ciclo de lanzamiento inestable y una estrategia poco clara para el desarrollo de la funcionalidad.  En particular, se lanzan nuevas versiones con cambios significativos cada mes o dos.  Algunas funciones pueden eliminarse, como, por ejemplo, sucedi칩 con fragmentaci칩n adaptativa.  Por separado, como otro factor de incertidumbre, vale la pena mencionar la pol칤tica de licencias.  Es muy confuso ya que hay tres niveles de licencia.  El kernel TSDB est치 hecho bajo la licencia Apache, algunas funciones se lanzan bajo su propia licencia Timescale, pero tambi칠n hay una versi칩n cerrada de Enterprise. <br><br>  Si usa Zabbix con PostgreSQL, entonces no hay raz칩n al menos para no probar TimescaleDB.  Quiz치s esto te sorprenda gratamente :) Solo ten en cuenta que el soporte para TimescaleDB en Zabbix sigue siendo experimental, por un tiempo, mientras recopilamos rese침as de usuarios y ganamos experiencia. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458530/">https://habr.com/ru/post/458530/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458514/index.html">La violaci칩n de GDPR se castiga m치s activamente: nuevas multas y el impacto de las regulaciones fuera de la UE</a></li>
<li><a href="../458516/index.html">Obtenga un registro de trabajo de Jira</a></li>
<li><a href="../458518/index.html">Python consume mucha memoria o 쯖칩mo reducir el tama침o de los objetos?</a></li>
<li><a href="../458520/index.html">El libro "C칩digo de alto rendimiento en la plataforma .NET. 2da edicion</a></li>
<li><a href="../458524/index.html">VC nube de palabras en la rodilla</a></li>
<li><a href="../458532/index.html">Pioneros de las nuevas tecnolog칤as: Vadim Artsev cont칩 c칩mo dej칩 de ser ciego</a></li>
<li><a href="../458536/index.html">Python + Pyside2 o simplemente "Calculadora"</a></li>
<li><a href="../458546/index.html">D칤a de la automatizaci칩n, o c칩mo construimos la capa de autotest.</a></li>
<li><a href="../458548/index.html">Cree su propia biblioteca de estilos de Spring Data Repository con Dynamic Proxy y Spring IoC</a></li>
<li><a href="../458550/index.html">Biblioteca de s칤mbolos GOST para DipTrace</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
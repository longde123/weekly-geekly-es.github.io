<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍🔬 👩🏾‍💻 🤘🏿 So machen Sie einen Bot, der aus einem Foto ein Comic-Buch macht: Schritt-für-Schritt-Anleitung für Dummies 👩‍🚒 🧝🏻 🤾🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Erster Teil, ergänzt. 
  Cotans, hallo. 
 Ich bin Sasha und ich gönne mir Neuronen. 

 Auf Wunsch der Arbeiter sammelte ich endlich meine Gedanken und...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So machen Sie einen Bot, der aus einem Foto ein Comic-Buch macht: Schritt-für-Schritt-Anleitung für Dummies</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479218/">  <i>Erster Teil, ergänzt.</i> <i><br></i> <blockquote>  Cotans, hallo. <br>  Ich bin Sasha und ich gönne mir Neuronen. <br><br>  Auf Wunsch der Arbeiter sammelte ich endlich meine Gedanken und beschloss, eine Reihe von kurzen und fast schrittweisen Anweisungen zu unterbrechen. <br><br>  Anweisungen, wie Sie Ihr neuronales Netzwerk von Grund auf trainieren und bereitstellen und sich gleichzeitig mit dem Telegramm-Bot anfreunden. <br><br>  Anleitung für Dummies wie mich. </blockquote>  Heute werden wir die Architektur unseres neuronalen Netzwerks auswählen, testen und unseren ersten Trainingsdatensatz sammeln. <br><br><h2>  Wahl der Architektur </h2><br>  Nach dem relativ erfolgreichen Start des <a href="https://t.me/selfie2animebot" rel="nofollow">selfie2anime-</a> Bots (unter Verwendung des vorgefertigten <a href="https://github.com/taki0112/UGATIT" rel="nofollow">UGATIT-</a> Modells) wollte ich dasselbe tun, aber <a href="https://github.com/taki0112/UGATIT" rel="nofollow">meines</a> .  Zum Beispiel ein Modell, das Ihre Fotos in Comics verwandelt. <br><br>  Hier sind einige Beispiele aus meinem <a href="https://t.me/photo2comicsbot" rel="nofollow">photo2comicsbot</a> , und wir werden etwas Ähnliches tun. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/7h/yh/sk/7hyhskjvb1hhlhfyiytr5afcl4q.png"><br><img src="https://habrastorage.org/webt/5c/qd/av/5cqdavi7b-i_fna2ienr4_5hrmu.png"><br><img src="https://habrastorage.org/webt/ej/vy/tn/ejvytnyo92bdr-jmitilezpt60k.png"><br><br>  Da das <a href="https://github.com/taki0112/UGATIT" rel="nofollow">UGATIT-</a> Modell für meine Grafikkarte zu schwer war, machte ich auf eine ältere, aber weniger unersättliche Analogie aufmerksam - <a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" rel="nofollow">CycleGAN</a> <br><br>  In dieser Implementierung gibt es mehrere Modellarchitekturen und eine komfortable visuelle Darstellung des Lernprozesses im Browser. <br><br>  CycleGAN erfordert wie <a href="https://github.com/lengstrom/fast-style-transfer" rel="nofollow">Architekturen zum Übertragen von Stilen</a> über ein einzelnes Bild keine gepaarten Bilder für das Training.  Dies ist wichtig, da wir sonst alle Fotos selbst in Comics neu zeichnen müssten, um ein Trainingsset zu erstellen. <br><br>  Die Aufgabe, die wir für unseren Algorithmus festlegen, besteht aus zwei Teilen. <br>  Am Ausgang sollten wir ein Bild bekommen, das: <br><br>  a) ähnlich einem Comic <br>  b) ähnlich dem Originalbild <br><br>  Punkt "a" kann mit der üblichen GAN implementiert werden, wobei der geschulte Kritiker für "Comicähnlichkeit" verantwortlich sein wird. <br><br><div class="spoiler">  <b class="spoiler_title">Mehr zu GAN</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/-g/j-/hq/-gj-hqvnumsgc7k1xuaau7d8tfe.jpeg"><br><br>  Das GAN (Generative Adversarial Network) ist ein Paar von zwei neuronalen Netzwerken: Generator und Critic. <br>  Der Generator wandelt die Eingabe beispielsweise von einem Foto in ein Comic-Buch um, und der Kritiker vergleicht das resultierende "falsche" Ergebnis mit einem echten Comic-Buch.  Der Generator hat die Aufgabe, die Kritiker auszutricksen und umgekehrt. <br><br>  Während des Lernprozesses lernt der Generator, Comics zu erstellen, die den realen Comics immer ähnlicher werden, und der Kritiker lernt, sie besser voneinander zu unterscheiden. <br></div></div><br>  Der zweite Teil ist etwas komplizierter.  Wenn wir Bilder gepaart hätten, bei denen es Fotos in Satz „A“ und in Satz „B“ geben würde, die aber in Comics neu gezeichnet werden (das ist, was wir vom Modell erhalten möchten), könnten wir Nur um das vom Generator erzeugte Ergebnis mit dem gepaarten Bild aus Satz „B“ unseres Trainingssatzes zu vergleichen. <br><br>  In unserem Fall sind die Mengen "A" und "B" in keiner Weise miteinander verbunden.  In Set "A" - zufällige Fotos, in Set "B" - zufällige Comics. <br><br>  Es ist sinnlos, einen gefälschten Comic mit einem zufälligen Comic aus der Menge „B“ zu vergleichen, da dies zumindest die Funktion des Kritikers dupliziert, ganz zu schweigen von dem unvorhersehbaren Ergebnis. <br><br>  Hier hilft die CycleGAN-Architektur. <br><br>  Kurz gesagt, dies ist ein GAN-Paar, bei dem das erste Bild von Kategorie "A" (zum Beispiel ein Foto) in Kategorie "B" (zum Beispiel ein Comic) und das zweite zurück von Kategorie "B" in Kategorie "A" konvertiert wird. <br><br><img src="https://habrastorage.org/webt/jl/0d/eg/jl0deg09yccaa8sez0djtsti4fo.jpeg"><br><br>  Die Modelle werden sowohl auf der Grundlage des Vergleichs des Originalfotos mit dem wiederhergestellten (als Ergebnis des Zyklus „A“ - „B“ - „A“, „Foto-Comic-Foto“) als auch auf der Grundlage der Daten der Kritiker wie bei einer regulären GAN trainiert. <br><br>  Dies ermöglicht es, beide Teile unserer Aufgabe zu erfüllen: ein Comic-Buch zu erstellen, das sich nicht von anderen Comics unterscheidet und gleichzeitig dem Originalfoto ähnelt. <br><br><h2>  Modellinstallation und -überprüfung </h2><br>  Um unseren Listplan umzusetzen, brauchen wir: <br><br><ul><li>  CUDA-fähige Grafikkarte mit 8 GB RAM </li><li>  Linux-Betriebssystem </li><li>  Miniconda / Anaconda mit Python 3.5+ </li></ul><br>  Grafikkarten mit weniger als 8 GB RAM können auch funktionieren, wenn Sie mit den Einstellungen zaubern.  Es wird auch unter Windows funktionieren, aber langsamer hatte ich einen Unterschied von mindestens 1,5-2 mal. <br><br>  <i>Wenn Sie keine GPU mit CUDA-Unterstützung haben oder zu faul sind, um alles einzurichten, können Sie immer Google Colab verwenden.</i>  <i>Wenn es eine ausreichende Anzahl von Personen gibt, die dies möchten, fülle ich das Lernprogramm aus und erkläre, wie die folgenden Schritte in einer Google-Cloud ausgeführt werden.</i> <br><br>  <a href="https://docs.conda.io/en/latest/miniconda.html" rel="nofollow">Miniconda kann hier genommen werden</a> <br>  <a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html" rel="nofollow">Installationsanleitung</a> <br><br>  Erstellen Sie nach der Installation von Anaconda / Miniconda (im Folgenden als conda bezeichnet) eine neue Umgebung für unsere Experimente und aktivieren Sie diese: <br><br>  <i>(Windows-Benutzer müssen Anaconda Prompt zuerst über das Startmenü starten.)</i> <br><br><pre><code class="bash hljs">conda create --name cyclegan conda activate cyclegan</code> </pre> <br>  Jetzt werden alle Pakete in der aktiven Umgebung installiert, ohne den Rest der Umgebung zu beeinträchtigen.  Dies ist praktisch, wenn Sie bestimmte Kombinationen von Versionen verschiedener Pakete benötigen, z. B. wenn Sie den alten Code einer anderen Person verwenden und veraltete Pakete installieren müssen, ohne Ihr Leben und Ihre Hauptarbeitsumgebung zu beeinträchtigen. <br><br>  Folgen Sie dann einfach den README.MD-Anweisungen der Distribution: <br><br>  Speichern Sie die CycleGAN-Distribution: <br><br>  <i>(oder einfach das Archiv von GitHub herunterladen)</i> <br><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> pytorch-CycleGAN-and-pix2pix</code> </pre> <br>  Installieren Sie die erforderlichen Pakete: <br><br><pre> <code class="bash hljs">conda install numpy pyyaml mkl mkl-include setuptools cmake cffi typing conda install pytorch torchvision -c pytorch conda install visdom dominate -c conda-forge</code> </pre> <br>  Laden Sie den fertigen Datensatz und das entsprechende Modell herunter: <br><br><pre> <code class="bash hljs">bash ./datasets/download_cyclegan_dataset.sh horse2zebra bash ./scripts/download_cyclegan_model.sh horse2zebra</code> </pre> <br>  Achten Sie darauf, welche Fotos im heruntergeladenen Datensatz enthalten sind. <br><br>  Wenn Sie die Skriptdateien aus dem vorherigen Absatz öffnen, können Sie feststellen, dass andere vorgefertigte Datensätze und Modelle für diese vorhanden sind. <br><br>  Testen Sie abschließend das Modell anhand des heruntergeladenen Datensatzes: <br><br><pre> <code class="bash hljs">python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --no_dropout</code> </pre><br>  Die Ergebnisse werden im Ordner / results / horse2zebra_pretrained / gespeichert <br><br><h2>  Trainingsset erstellen </h2><br>  Ein ebenso wichtiger Schritt nach der Auswahl der Architektur des zukünftigen Modells (und der Suche nach einer fertigen Implementierung auf github) ist die Kompilierung eines Datensatzes oder eines Datensatzes, auf dem wir unser Modell trainieren und testen werden. <br><blockquote>  Fast alles hängt davon ab, welche Daten wir verwenden.  Zum Beispiel wurde <a href="https://github.com/taki0112/UGATIT" rel="nofollow">UGATIT</a> für den <a href="https://t.me/selfie2animebot" rel="nofollow">selfie2anime-</a> Bot auf weibliche Selfies und weibliche Gesichter von Anime trainiert.  Daher benimmt sie sich auf männlichen Fotos zumindest lustig und ersetzt brutale bärtige Männer durch kleine Mädchen mit hohem Kragen.  Auf dem Foto hat dein bescheidener Diener erfahren, dass er sich einen Anime ansieht. <br><br><img src="https://habrastorage.org/webt/iz/b1/yl/izb1yltkkhenla6oo5ajvbqrujg.jpeg"><br><br>  Wie Sie bereits verstanden haben, lohnt es sich, die Fotos / Comics auszuwählen, die Sie am Eingang verwenden möchten, und am Ausgang zu erhalten.  Planen Sie Selfies zu verarbeiten? Fügen Sie Selfies und Nahaufnahmen von Gesichtern aus Comics, Fotos von Gebäuden hinzu? Fügen Sie Fotos von Gebäuden und Seiten aus Comics mit Gebäuden hinzu. <br></blockquote>  Als Beispielfotos habe ich <a href="" rel="nofollow">DIV2K</a> und <a href="" rel="nofollow">Urban100 verwendet</a> , die mit Fotos von Google-Stars gewürzt wurden, um die Vielfalt zu verbessern. <br><br>  Ich nahm Comics aus dem Marvel-Universum, der gesamten Seite, und warf Anzeigen und Ankündigungen aus, bei denen das Bild nicht wie ein Comic aussieht.  Ich kann den Link aus offensichtlichen Gründen nicht anhängen, aber auf Anfrage von Marvel Comics können Sie gescannte Optionen auf Ihren Lieblingsseiten mit Comics leicht finden, wenn Sie wissen, was ich meine. <br><br>  Es ist wichtig, auf die Zeichnung zu achten, sie unterscheidet sich in verschiedenen Serien und in der Farbgebung. <br><br><img src="https://habrastorage.org/webt/qn/na/7e/qnna7eye4d7reejujjdafcv682a.png"><br><br>  Ich hatte eine Menge Deadpool und Spiderman, so dass die Haut sehr rot wird. <br><br>  Eine unvollständige Liste anderer öffentlicher Datensätze finden Sie <a href="http://datasets.visionbib.com/info-index.html" rel="nofollow">hier</a> . <br><br>  Die Ordnerstruktur in unserem Datensatz sollte wie folgt aussehen: <br><br>  selfie2comics <br>  ├── trainA <br>  ├── trainB <br>  ├── testA <br>  └── testB <br><br>  trainA - unsere Fotos (ca. 1000 Stück) <br>  testA - einige Fotos für Modelltests (30 Stück reichen aus) <br>  trainB - unsere Comics (ca. 1000 Stück) <br>  testB - comics für tests (30 stück) <br><br>  Es wird empfohlen, den Datensatz möglichst auf einer SSD abzulegen. <br><br>  Das ist alles für heute, in der nächsten Ausgabe werden wir damit beginnen, das Modell zu trainieren und die ersten Ergebnisse zu erzielen! <br><br>  Stellen Sie sicher, dass Sie schreiben, wenn bei Ihnen ein Fehler aufgetreten ist. Dies wird dazu beitragen, die Führung zu verbessern und das Leiden der nachfolgenden Leser zu lindern. <br><br>  Wenn Sie bereits versucht haben, das Modell zu trainieren, teilen Sie die Ergebnisse in den Kommentaren mit.  Bis bald <br><br>  <a href="https://habr.com/ru/post/483168/">⇨ Nächster Teil</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479218/">https://habr.com/ru/post/de479218/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479200/index.html">Fraktale Bildkomprimierung</a></li>
<li><a href="../de479202/index.html">C ++ und numerische Methoden: Ungefähre Newton-Cotes-Integration</a></li>
<li><a href="../de479210/index.html">Was passiert mit Einkäufen in ausländischen Online-Shops ab dem 1. Januar 2020?</a></li>
<li><a href="../de479214/index.html">Eine Auswahl an bevorstehenden kostenlosen Events für Entwickler in Moskau # 2</a></li>
<li><a href="../de479216/index.html">Zweiter Wind Pandora DXL 3000 oder wie ich meine eigene Telemetrie verschraubt habe</a></li>
<li><a href="../de479220/index.html">Nano-Neuron - 7 einfache JavaScript-Funktionen, die zeigen, wie die Maschine "lernen" kann</a></li>
<li><a href="../de479222/index.html">Die Zusammenstellung interessanter Materialien für den mobilen Entwickler # 325 (vom 2. bis 8. Dezember)</a></li>
<li><a href="../de479226/index.html">Habr-Analyse: Was Anwender bei Habr als Geschenk bestellen</a></li>
<li><a href="../de479230/index.html">Dokumentieren Sie Ihre Express-API mit Swagger-Annotationen</a></li>
<li><a href="../de479232/index.html">MQ JMS-Anwendungsentwicklung auf Spring Boot</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
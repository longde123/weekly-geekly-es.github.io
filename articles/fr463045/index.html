<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛄 🆖 👆 Détectez automatiquement les émotions dans les conversations textuelles à l'aide de réseaux de neurones 🤞🏾 👋🏽 👨🏾‍🔧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'une des tâches principales des systèmes de dialogue est non seulement de fournir les informations dont l'utilisateur a besoin, mais aussi de générer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Détectez automatiquement les émotions dans les conversations textuelles à l'aide de réseaux de neurones</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  L'une des tâches principales des systèmes de dialogue est non seulement de fournir les informations dont l'utilisateur a besoin, mais aussi de générer autant de réponses humaines que possible.  Et la reconnaissance des émotions de l’interlocuteur n’est plus seulement une caractéristique intéressante, c’est une nécessité vitale.  Dans cet article, nous nous pencherons sur l' <b>architecture d'un réseau neuronal récurrent pour déterminer les émotions dans les conversations textuelles</b> , qui a participé au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SemEval-2019 Tâche 3 «EmoContext»</a> , le concours annuel en linguistique informatique.  La tâche consistait à classer les émotions («heureux», «triste», «en colère» et «autres») dans une conversation de trois remarques, à laquelle un robot de discussion et une personne ont participé. <br><br>  Dans la première partie de l'article, nous examinerons l'ensemble des tâches dans EmoContext et les données fournies par les organisateurs.  Dans les deuxième et troisième parties, nous analysons le traitement préliminaire du texte et les modes de représentation vectorielle des mots.  Dans la quatrième partie, nous décrivons l'architecture LSTM que nous avons utilisée dans la compétition.  Le code est écrit en Python à l'aide de la bibliothèque Keras. <br><a name="habracut"></a><br><h2>  1. Données d'entraînement </h2><br>  Le titre «EmoContext» du SemEval-2019 était dédié à la définition des émotions dans les conversations textuelles, en tenant compte du contexte de la correspondance.  Le contexte dans ce cas est plusieurs remarques consécutives des participants au dialogue.  Il y a deux participants à la conversation: un utilisateur anonyme (il possède la première et la troisième réplique) et un robot de discussion <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ruuh</a> (il possède la deuxième réplique).  Sur la base de trois répliques, il est nécessaire de déterminer l'émotion ressentie par l'utilisateur lors de la rédaction d'une réponse au chatbot (tableau 1).  Au total, le balisage de l'ensemble de données contenait quatre émotions: «heureux», «triste», «en colère» ou «autres» (tableau 1).  Une description détaillée est présentée ici: ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tableau 1. Exemples de l'ensemble de données EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Utilisateur (étape 1) </th><th>  Robot interactif (étape 1) </th><th>  Utilisateur (étape 2) </th><th>  Véritable classe </th></tr><tr><td>  Je viens de me qualifier pour le stage Nabard </td><td>  WOOT!  Voilà d'excellentes nouvelles.  Félicitations! </td><td>  J'ai commencé à pleurer </td><td>  Le bonheur </td></tr><tr><td>  Comment osez-vous gifler mon enfant </td><td>  Si vous gâtez ma voiture, je vous le ferai aussi </td><td>  Essayez juste de le faire une fois </td><td>  La colère </td></tr><tr><td>  J'ai été blessé par toi plus </td><td>  Tu ne le pensais pas. </td><td>  dis que tu m'aimes </td><td>  La tristesse </td></tr><tr><td>  Je ferai la nuit. </td><td>  D'accord.  Tenez-moi au courant. </td><td>  Ne pas donner WhatsApp non. </td><td>  Autre </td></tr></tbody></table></div><br>  Pendant le concours, les organisateurs ont fourni plusieurs ensembles de données.  Le jeu de données de formation (Train) comprenait 30 160 textes marqués manuellement.  Dans ces textes, il y avait environ 5 000 objets appartenant aux classes «heureux», «triste» et «en colère», ainsi que 15 000 textes de la classe «autres» (tableau 2). <br><br>  Les organisateurs ont également fourni des ensembles de données pour le développement (Dev) et les tests (Test), dans lesquels, contrairement au jeu de données de formation, la distribution par classe d'émotions correspondait à la vie réelle: environ 4% pour chacune des classes «heureux», «triste» et « en colère ", et le reste est la classe" autres ".  Données fournies par Microsoft, vous pouvez les télécharger dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">groupe officiel sur LinkedIn</a> . <br><br>  <i>Tableau 2. Distribution des étiquettes de classe d'émotion dans l'ensemble de données ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datacet </th><th>  Le bonheur </th><th> La tristesse </th><th>  La colère </th><th>  Autre </th><th>  Total </th></tr><tr><td>  La formation <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30 160 <br></td></tr><tr><td>  Développer <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  À distance <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900 mille <br></td></tr></tbody></table></div><br>  En plus de ces données, nous avons collecté 900 000 messages en anglais sur Twitter pour créer un ensemble de données Distant (300 000 tweets pour chaque émotion).  Lors de sa création, nous avons suivi la stratégie de Go et al.  (2009), dans le cadre desquels les messages étaient simplement associés à la présence de mots liés aux émotions, tels que #angry, #annoyed, #happy, #sad, #surprised, etc.  La liste des termes est basée sur les termes de SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Duppada et al., 2018</a> ). <br><br>  La principale mesure de qualité dans le concours EmoContext est la mesure F1 moyenne pour les trois classes d'émotions, c'est-à-dire pour les classes «heureux», «triste» et «en colère». <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Prétraitement du texte </h2><br>  Avant la formation, nous avons prétraité les textes à l'aide de l'outil Ekphrasis (Baziotis et al., 2017).  Il permet de corriger l'orthographe, de normaliser les mots, de segmenter et également de déterminer quels jetons doivent être supprimés, normalisés ou annotés à l'aide de balises spéciales.  Au stade du prétraitement, nous avons fait ce qui suit: <br><br><ul><li>  Les URL et le courrier, la date et l'heure, les surnoms, les pourcentages, les devises et les nombres ont été remplacés par des balises correspondantes. </li><li>  Des termes majuscules répétés, censurés et allongés accompagnés d'étiquettes appropriées. </li><li>  Les mots allongés ont été automatiquement corrigés. </li></ul><br>  De plus, Emphasis contient un tokenizer qui peut identifier la plupart des emojis, émoticônes et expressions complexes, ainsi que les dates, heures, devises et acronymes. <br><br>  <i>Tableau 3. Exemples de prétraitement de texte.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texte source </th><th>  Texte prétraité </th></tr><tr><td>  JE ME SENS ... Je me brise en millions de morceaux <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; je vous sens &lt;/allcaps&gt;.  &lt;répété&gt; je me brise en millions de morceaux <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  fatigué et tu m'as manqué aussi :‑( </td><td>  fatigué et tu m'as manqué aussi &lt;sad&gt; </td></tr><tr><td>  vous devez vous y connecter: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  vous devriez écouter &lt;allongé&gt; à ceci: &lt;url&gt; </td></tr><tr><td>  Mon appartement s'en occupe.  Mon loyer est d'environ 650 $. </td><td>  mon appartement s'en occupe.  mon loyer est d'environ &lt;argent&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^・^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑c'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‑':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‑["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Représentation vectorielle des mots </h2><br>  La représentation vectorielle est devenue une partie intégrante de la plupart des approches de la création de systèmes PNL utilisant l'apprentissage en profondeur.  Pour déterminer les modèles de cartographie vectorielle les plus appropriés, nous avons essayé Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pennington et al., 2014</a> ) et FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Joulin et al., 2017</a> ), ainsi que des vecteurs DataStories pré-formés ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Baziotis et al. ., 2017</a> ).  Word2Vec trouve des relations entre les mots en supposant que les mots sémantiquement liés se trouvent dans des contextes similaires.  Word2Vec essaie de prédire le mot cible (architecture CBOW) ou le contexte (architecture Skip-Gram), c'est-à-dire minimiser la fonction de perte, et GloVe calcule des vecteurs de mots, réduisant la dimension de la matrice d'adjacence.  La logique de FastText est similaire à la logique de Word2Vec, sauf qu'elle utilise des n-grammes symboliques pour créer des vecteurs de mots et, par conséquent, elle peut résoudre le problème des mots inconnus. <br><br>  Pour tous les modèles mentionnés, nous utilisons les paramètres de formation par défaut fournis par les auteurs.  Nous avons formé un modèle LSTM simple (dim = 64) basé sur chacune de ces représentations vectorielles et comparé l'efficacité de la classification en utilisant la validation croisée.  Le meilleur résultat dans les mesures F1 a été montré par des vecteurs DataStories pré-formés. <br><br>  Pour enrichir l'affichage vectoriel sélectionné avec la coloration émotionnelle des mots, nous avons décidé d'affiner les vecteurs à l'aide du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jeu de données</a> Distant automatiquement étiqueté ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deriu et al., 2017</a> ).  Nous avons utilisé l'ensemble de données Distant pour former un réseau LSTM simple afin de classer les messages «diaboliques», «tristes» et «heureux».  La couche d'intégration a été gelée lors de la première itération de l'entraînement afin d'éviter de forts changements dans les poids des vecteurs, et pour les cinq prochaines itérations, la couche a été décongelée.  Après l'entraînement, les vecteurs «retardés» ont été enregistrés pour une utilisation ultérieure dans le réseau neuronal, ainsi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">que partagés</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Architecture du réseau neuronal </h2><br>  Les réseaux de neurones récurrents (RNN) sont une famille de réseaux de neurones qui se spécialisent dans le traitement d'une série d'événements.  Contrairement aux réseaux de neurones traditionnels, les RNN sont conçus pour fonctionner avec des séquences utilisant des équilibres internes.  Pour cela, le graphe de calcul RNN contient des cycles qui reflètent l'influence des informations précédentes de la séquence d'événements sur l'actuel.  Les réseaux de neurones LSTM (Long Short-Term Memory) ont été introduits comme une extension de RNN en 1997 ( <a href="">Hochreiter et Schmidhuber, 1997</a> ).  Les cellules de récurrence LSTM sont connectées pour éviter les problèmes d'éclatement et de fondu.  Les LSTM traditionnels ne conservent que les informations passées car ils traitent la séquence dans une seule direction.  Les LSTM bidirectionnels fonctionnant dans les deux directions combinent la sortie de deux couches LSTM cachées qui transmettent des informations dans des directions opposées - l'une au cours du temps et l'autre contre - recevant ainsi simultanément des données des états passés et futurs ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Schuster et Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figure 1: Version réduite de l'architecture.</i>  <i>Le module LSTM utilise les mêmes poids pour les première et troisième étapes.</i> <br><br>  Une représentation simplifiée de l'approche décrite est illustrée à la figure 1. L'architecture du réseau neuronal se compose d'une couche d'intégration et de deux modules LTSM bidirectionnels (dim = 64).  Le premier module LTSM analyse les mots du premier utilisateur (c'est-à-dire les première et troisième répliques de la conversation), et le deuxième module analyse les mots du deuxième utilisateur (deuxième réplique).  À la première étape, les mots de chaque utilisateur utilisant des représentations vectorielles pré-entraînées sont introduits dans le module LTSM bidirectionnel correspondant.  Ensuite, les trois cartes d'entités résultantes sont combinées en un vecteur d'entités plat, puis transférées vers une couche cachée entièrement connectée (dim = 30), qui analyse les interactions entre les entités extraites.  Enfin, ces caractéristiques sont traitées dans la couche de sortie à l'aide de la fonction d'activation softmax pour déterminer l'étiquette de classe finale.  Pour réduire le surajustement, après les couches de la représentation vectorielle, des couches de régularisation avec bruit gaussien ont été ajoutées et des couches de décrochage ont été ajoutées à chaque module LTSM (p = 0,2) et à une couche entièrement connectée cachée (p = 0,1) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Srivastava et al., 2014</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Résultats </h2><br>  Dans la recherche de l'architecture optimale, nous avons expérimenté non seulement le nombre de neurones dans les couches, les fonctions d'activation et les paramètres de régularisation, mais aussi l'architecture du réseau neuronal lui-même.  Ceci est décrit plus en détail dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">œuvre originale</a> . <br><br>  L'architecture décrite dans la section précédente a montré les meilleurs résultats lors de la formation sur le jeu de données Train et la validation sur le jeu de données Dev, elle a donc été utilisée dans la phase finale de la compétition.  Lors du dernier ensemble de données de test, le modèle a montré une mesure F1 micro-moyenne de 72,59%, et le résultat maximum atteint parmi tous les participants était de 79,59%.  Néanmoins, notre résultat était bien supérieur à la valeur de référence de 58,68% fixée par les organisateurs. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code source du modèle et de la représentation vectorielle des mots</a> est disponible sur GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La version complète de l'article</a> et le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travail avec la description de la tâche se</a> trouvent sur le site Web d'ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'ensemble de données de formation</a> peut être téléchargé à partir du groupe officiel LinkedIn. <br><br>  Citant: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr463045/">https://habr.com/ru/post/fr463045/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr463031/index.html">Vivez et apprenez. Partie 3. Formation continue ou âge de l'éternel étudiant</a></li>
<li><a href="../fr463035/index.html">Nouvelles du monde d'OpenStreetMap n ° 471 (07.23.2019-29.07.2019)</a></li>
<li><a href="../fr463037/index.html">Vous cherchez de l'inspiration, ou comment vous sortir de F</a></li>
<li><a href="../fr463039/index.html">Aspirateur manucure bricolage</a></li>
<li><a href="../fr463041/index.html">Défini ou non défini? Nuances de création de tableaux en JavaScript</a></li>
<li><a href="../fr463055/index.html">À propos des administrateurs, des devops, de la confusion sans fin et de la transformation DevOps au sein de l'entreprise</a></li>
<li><a href="../fr463057/index.html">Yii Framework 2 Droits personnalisés</a></li>
<li><a href="../fr463059/index.html">Trois vies en informatique et pas seulement</a></li>
<li><a href="../fr463061/index.html">Règles de préparation des mises en page dans Figma</a></li>
<li><a href="../fr463063/index.html">Nous traitons les interfaces dans Go</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
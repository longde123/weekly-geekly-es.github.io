<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõÑ üÜñ üëÜ D√©tectez automatiquement les √©motions dans les conversations textuelles √† l'aide de r√©seaux de neurones ü§ûüèæ üëãüèΩ üë®üèæ‚Äçüîß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'une des t√¢ches principales des syst√®mes de dialogue est non seulement de fournir les informations dont l'utilisateur a besoin, mais aussi de g√©n√©rer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>D√©tectez automatiquement les √©motions dans les conversations textuelles √† l'aide de r√©seaux de neurones</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  L'une des t√¢ches principales des syst√®mes de dialogue est non seulement de fournir les informations dont l'utilisateur a besoin, mais aussi de g√©n√©rer autant de r√©ponses humaines que possible.  Et la reconnaissance des √©motions de l‚Äôinterlocuteur n‚Äôest plus seulement une caract√©ristique int√©ressante, c‚Äôest une n√©cessit√© vitale.  Dans cet article, nous nous pencherons sur l' <b>architecture d'un r√©seau neuronal r√©current pour d√©terminer les √©motions dans les conversations textuelles</b> , qui a particip√© au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SemEval-2019 T√¢che 3 ¬´EmoContext¬ª</a> , le concours annuel en linguistique informatique.  La t√¢che consistait √† classer les √©motions (¬´heureux¬ª, ¬´triste¬ª, ¬´en col√®re¬ª et ¬´autres¬ª) dans une conversation de trois remarques, √† laquelle un robot de discussion et une personne ont particip√©. <br><br>  Dans la premi√®re partie de l'article, nous examinerons l'ensemble des t√¢ches dans EmoContext et les donn√©es fournies par les organisateurs.  Dans les deuxi√®me et troisi√®me parties, nous analysons le traitement pr√©liminaire du texte et les modes de repr√©sentation vectorielle des mots.  Dans la quatri√®me partie, nous d√©crivons l'architecture LSTM que nous avons utilis√©e dans la comp√©tition.  Le code est √©crit en Python √† l'aide de la biblioth√®que Keras. <br><a name="habracut"></a><br><h2>  1. Donn√©es d'entra√Ænement </h2><br>  Le titre ¬´EmoContext¬ª du SemEval-2019 √©tait d√©di√© √† la d√©finition des √©motions dans les conversations textuelles, en tenant compte du contexte de la correspondance.  Le contexte dans ce cas est plusieurs remarques cons√©cutives des participants au dialogue.  Il y a deux participants √† la conversation: un utilisateur anonyme (il poss√®de la premi√®re et la troisi√®me r√©plique) et un robot de discussion <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ruuh</a> (il poss√®de la deuxi√®me r√©plique).  Sur la base de trois r√©pliques, il est n√©cessaire de d√©terminer l'√©motion ressentie par l'utilisateur lors de la r√©daction d'une r√©ponse au chatbot (tableau 1).  Au total, le balisage de l'ensemble de donn√©es contenait quatre √©motions: ¬´heureux¬ª, ¬´triste¬ª, ¬´en col√®re¬ª ou ¬´autres¬ª (tableau 1).  Une description d√©taill√©e est pr√©sent√©e ici: ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tableau 1. Exemples de l'ensemble de donn√©es EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Utilisateur (√©tape 1) </th><th>  Robot interactif (√©tape 1) </th><th>  Utilisateur (√©tape 2) </th><th>  V√©ritable classe </th></tr><tr><td>  Je viens de me qualifier pour le stage Nabard </td><td>  WOOT!  Voil√† d'excellentes nouvelles.  F√©licitations! </td><td>  J'ai commenc√© √† pleurer </td><td>  Le bonheur </td></tr><tr><td>  Comment osez-vous gifler mon enfant </td><td>  Si vous g√¢tez ma voiture, je vous le ferai aussi </td><td>  Essayez juste de le faire une fois </td><td>  La col√®re </td></tr><tr><td>  J'ai √©t√© bless√© par toi plus </td><td>  Tu ne le pensais pas. </td><td>  dis que tu m'aimes </td><td>  La tristesse </td></tr><tr><td>  Je ferai la nuit. </td><td>  D'accord.  Tenez-moi au courant. </td><td>  Ne pas donner WhatsApp non. </td><td>  Autre </td></tr></tbody></table></div><br>  Pendant le concours, les organisateurs ont fourni plusieurs ensembles de donn√©es.  Le jeu de donn√©es de formation (Train) comprenait 30 160 textes marqu√©s manuellement.  Dans ces textes, il y avait environ 5 000 objets appartenant aux classes ¬´heureux¬ª, ¬´triste¬ª et ¬´en col√®re¬ª, ainsi que 15 000 textes de la classe ¬´autres¬ª (tableau 2). <br><br>  Les organisateurs ont √©galement fourni des ensembles de donn√©es pour le d√©veloppement (Dev) et les tests (Test), dans lesquels, contrairement au jeu de donn√©es de formation, la distribution par classe d'√©motions correspondait √† la vie r√©elle: environ 4% pour chacune des classes ¬´heureux¬ª, ¬´triste¬ª et ¬´ en col√®re ", et le reste est la classe" autres ".  Donn√©es fournies par Microsoft, vous pouvez les t√©l√©charger dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">groupe officiel sur LinkedIn</a> . <br><br>  <i>Tableau 2. Distribution des √©tiquettes de classe d'√©motion dans l'ensemble de donn√©es ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datacet </th><th>  Le bonheur </th><th> La tristesse </th><th>  La col√®re </th><th>  Autre </th><th>  Total </th></tr><tr><td>  La formation <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30 160 <br></td></tr><tr><td>  D√©velopper <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  √Ä distance <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900 mille <br></td></tr></tbody></table></div><br>  En plus de ces donn√©es, nous avons collect√© 900 000 messages en anglais sur Twitter pour cr√©er un ensemble de donn√©es Distant (300 000 tweets pour chaque √©motion).  Lors de sa cr√©ation, nous avons suivi la strat√©gie de Go et al.  (2009), dans le cadre desquels les messages √©taient simplement associ√©s √† la pr√©sence de mots li√©s aux √©motions, tels que #angry, #annoyed, #happy, #sad, #surprised, etc.  La liste des termes est bas√©e sur les termes de SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Duppada et al., 2018</a> ). <br><br>  La principale mesure de qualit√© dans le concours EmoContext est la mesure F1 moyenne pour les trois classes d'√©motions, c'est-√†-dire pour les classes ¬´heureux¬ª, ¬´triste¬ª et ¬´en col√®re¬ª. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Pr√©traitement du texte </h2><br>  Avant la formation, nous avons pr√©trait√© les textes √† l'aide de l'outil Ekphrasis (Baziotis et al., 2017).  Il permet de corriger l'orthographe, de normaliser les mots, de segmenter et √©galement de d√©terminer quels jetons doivent √™tre supprim√©s, normalis√©s ou annot√©s √† l'aide de balises sp√©ciales.  Au stade du pr√©traitement, nous avons fait ce qui suit: <br><br><ul><li>  Les URL et le courrier, la date et l'heure, les surnoms, les pourcentages, les devises et les nombres ont √©t√© remplac√©s par des balises correspondantes. </li><li>  Des termes majuscules r√©p√©t√©s, censur√©s et allong√©s accompagn√©s d'√©tiquettes appropri√©es. </li><li>  Les mots allong√©s ont √©t√© automatiquement corrig√©s. </li></ul><br>  De plus, Emphasis contient un tokenizer qui peut identifier la plupart des emojis, √©motic√¥nes et expressions complexes, ainsi que les dates, heures, devises et acronymes. <br><br>  <i>Tableau 3. Exemples de pr√©traitement de texte.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texte source </th><th>  Texte pr√©trait√© </th></tr><tr><td>  JE ME SENS ... Je me brise en millions de morceaux <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; je vous sens &lt;/allcaps&gt;.  &lt;r√©p√©t√©&gt; je me brise en millions de morceaux <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  fatigu√© et tu m'as manqu√© aussi :‚Äë( </td><td>  fatigu√© et tu m'as manqu√© aussi &lt;sad&gt; </td></tr><tr><td>  vous devez vous y connecter: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  vous devriez √©couter &lt;allong√©&gt; √† ceci: &lt;url&gt; </td></tr><tr><td>  Mon appartement s'en occupe.  Mon loyer est d'environ 650 $. </td><td>  mon appartement s'en occupe.  mon loyer est d'environ &lt;argent&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Repr√©sentation vectorielle des mots </h2><br>  La repr√©sentation vectorielle est devenue une partie int√©grante de la plupart des approches de la cr√©ation de syst√®mes PNL utilisant l'apprentissage en profondeur.  Pour d√©terminer les mod√®les de cartographie vectorielle les plus appropri√©s, nous avons essay√© Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pennington et al., 2014</a> ) et FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Joulin et al., 2017</a> ), ainsi que des vecteurs DataStories pr√©-form√©s ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Baziotis et al. ., 2017</a> ).  Word2Vec trouve des relations entre les mots en supposant que les mots s√©mantiquement li√©s se trouvent dans des contextes similaires.  Word2Vec essaie de pr√©dire le mot cible (architecture CBOW) ou le contexte (architecture Skip-Gram), c'est-√†-dire minimiser la fonction de perte, et GloVe calcule des vecteurs de mots, r√©duisant la dimension de la matrice d'adjacence.  La logique de FastText est similaire √† la logique de Word2Vec, sauf qu'elle utilise des n-grammes symboliques pour cr√©er des vecteurs de mots et, par cons√©quent, elle peut r√©soudre le probl√®me des mots inconnus. <br><br>  Pour tous les mod√®les mentionn√©s, nous utilisons les param√®tres de formation par d√©faut fournis par les auteurs.  Nous avons form√© un mod√®le LSTM simple (dim = 64) bas√© sur chacune de ces repr√©sentations vectorielles et compar√© l'efficacit√© de la classification en utilisant la validation crois√©e.  Le meilleur r√©sultat dans les mesures F1 a √©t√© montr√© par des vecteurs DataStories pr√©-form√©s. <br><br>  Pour enrichir l'affichage vectoriel s√©lectionn√© avec la coloration √©motionnelle des mots, nous avons d√©cid√© d'affiner les vecteurs √† l'aide du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jeu de donn√©es</a> Distant automatiquement √©tiquet√© ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deriu et al., 2017</a> ).  Nous avons utilis√© l'ensemble de donn√©es Distant pour former un r√©seau LSTM simple afin de classer les messages ¬´diaboliques¬ª, ¬´tristes¬ª et ¬´heureux¬ª.  La couche d'int√©gration a √©t√© gel√©e lors de la premi√®re it√©ration de l'entra√Ænement afin d'√©viter de forts changements dans les poids des vecteurs, et pour les cinq prochaines it√©rations, la couche a √©t√© d√©congel√©e.  Apr√®s l'entra√Ænement, les vecteurs ¬´retard√©s¬ª ont √©t√© enregistr√©s pour une utilisation ult√©rieure dans le r√©seau neuronal, ainsi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">que partag√©s</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Architecture du r√©seau neuronal </h2><br>  Les r√©seaux de neurones r√©currents (RNN) sont une famille de r√©seaux de neurones qui se sp√©cialisent dans le traitement d'une s√©rie d'√©v√©nements.  Contrairement aux r√©seaux de neurones traditionnels, les RNN sont con√ßus pour fonctionner avec des s√©quences utilisant des √©quilibres internes.  Pour cela, le graphe de calcul RNN contient des cycles qui refl√®tent l'influence des informations pr√©c√©dentes de la s√©quence d'√©v√©nements sur l'actuel.  Les r√©seaux de neurones LSTM (Long Short-Term Memory) ont √©t√© introduits comme une extension de RNN en 1997 ( <a href="">Hochreiter et Schmidhuber, 1997</a> ).  Les cellules de r√©currence LSTM sont connect√©es pour √©viter les probl√®mes d'√©clatement et de fondu.  Les LSTM traditionnels ne conservent que les informations pass√©es car ils traitent la s√©quence dans une seule direction.  Les LSTM bidirectionnels fonctionnant dans les deux directions combinent la sortie de deux couches LSTM cach√©es qui transmettent des informations dans des directions oppos√©es - l'une au cours du temps et l'autre contre - recevant ainsi simultan√©ment des donn√©es des √©tats pass√©s et futurs ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Schuster et Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figure 1: Version r√©duite de l'architecture.</i>  <i>Le module LSTM utilise les m√™mes poids pour les premi√®re et troisi√®me √©tapes.</i> <br><br>  Une repr√©sentation simplifi√©e de l'approche d√©crite est illustr√©e √† la figure 1. L'architecture du r√©seau neuronal se compose d'une couche d'int√©gration et de deux modules LTSM bidirectionnels (dim = 64).  Le premier module LTSM analyse les mots du premier utilisateur (c'est-√†-dire les premi√®re et troisi√®me r√©pliques de la conversation), et le deuxi√®me module analyse les mots du deuxi√®me utilisateur (deuxi√®me r√©plique).  √Ä la premi√®re √©tape, les mots de chaque utilisateur utilisant des repr√©sentations vectorielles pr√©-entra√Æn√©es sont introduits dans le module LTSM bidirectionnel correspondant.  Ensuite, les trois cartes d'entit√©s r√©sultantes sont combin√©es en un vecteur d'entit√©s plat, puis transf√©r√©es vers une couche cach√©e enti√®rement connect√©e (dim = 30), qui analyse les interactions entre les entit√©s extraites.  Enfin, ces caract√©ristiques sont trait√©es dans la couche de sortie √† l'aide de la fonction d'activation softmax pour d√©terminer l'√©tiquette de classe finale.  Pour r√©duire le surajustement, apr√®s les couches de la repr√©sentation vectorielle, des couches de r√©gularisation avec bruit gaussien ont √©t√© ajout√©es et des couches de d√©crochage ont √©t√© ajout√©es √† chaque module LTSM (p = 0,2) et √† une couche enti√®rement connect√©e cach√©e (p = 0,1) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Srivastava et al., 2014</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. R√©sultats </h2><br>  Dans la recherche de l'architecture optimale, nous avons exp√©riment√© non seulement le nombre de neurones dans les couches, les fonctions d'activation et les param√®tres de r√©gularisation, mais aussi l'architecture du r√©seau neuronal lui-m√™me.  Ceci est d√©crit plus en d√©tail dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">≈ìuvre originale</a> . <br><br>  L'architecture d√©crite dans la section pr√©c√©dente a montr√© les meilleurs r√©sultats lors de la formation sur le jeu de donn√©es Train et la validation sur le jeu de donn√©es Dev, elle a donc √©t√© utilis√©e dans la phase finale de la comp√©tition.  Lors du dernier ensemble de donn√©es de test, le mod√®le a montr√© une mesure F1 micro-moyenne de 72,59%, et le r√©sultat maximum atteint parmi tous les participants √©tait de 79,59%.  N√©anmoins, notre r√©sultat √©tait bien sup√©rieur √† la valeur de r√©f√©rence de 58,68% fix√©e par les organisateurs. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code source du mod√®le et de la repr√©sentation vectorielle des mots</a> est disponible sur GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La version compl√®te de l'article</a> et le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travail avec la description de la t√¢che se</a> trouvent sur le site Web d'ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'ensemble de donn√©es de formation</a> peut √™tre t√©l√©charg√© √† partir du groupe officiel LinkedIn. <br><br>  Citant: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr463045/">https://habr.com/ru/post/fr463045/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr463031/index.html">Vivez et apprenez. Partie 3. Formation continue ou √¢ge de l'√©ternel √©tudiant</a></li>
<li><a href="../fr463035/index.html">Nouvelles du monde d'OpenStreetMap n ¬∞ 471 (07.23.2019-29.07.2019)</a></li>
<li><a href="../fr463037/index.html">Vous cherchez de l'inspiration, ou comment vous sortir de F</a></li>
<li><a href="../fr463039/index.html">Aspirateur manucure bricolage</a></li>
<li><a href="../fr463041/index.html">D√©fini ou non d√©fini? Nuances de cr√©ation de tableaux en JavaScript</a></li>
<li><a href="../fr463055/index.html">√Ä propos des administrateurs, des devops, de la confusion sans fin et de la transformation DevOps au sein de l'entreprise</a></li>
<li><a href="../fr463057/index.html">Yii Framework 2 Droits personnalis√©s</a></li>
<li><a href="../fr463059/index.html">Trois vies en informatique et pas seulement</a></li>
<li><a href="../fr463061/index.html">R√®gles de pr√©paration des mises en page dans Figma</a></li>
<li><a href="../fr463063/index.html">Nous traitons les interfaces dans Go</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
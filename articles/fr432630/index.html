<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçü§ù‚Äçüë®üèΩ üê° üàµ Tout ce que vous vouliez savoir sur le traitement des requ√™tes, mais vous avez h√©sit√© √† demander üòù ü§∑üèø ü§ú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Qu'est-ce qu'un service r√©seau? Il s'agit d'un programme qui accepte les demandes entrantes sur le r√©seau et les traite, renvoyant √©ventuellement des ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tout ce que vous vouliez savoir sur le traitement des requ√™tes, mais vous avez h√©sit√© √† demander</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/432630/"><p>  Qu'est-ce qu'un service r√©seau?  Il s'agit d'un programme qui accepte les demandes entrantes sur le r√©seau et les traite, renvoyant √©ventuellement des r√©ponses. </p><br><p>  Il existe de nombreux aspects dans lesquels les services r√©seau diff√®rent les uns des autres.  Dans cet article, je me concentre sur la fa√ßon de g√©rer les demandes entrantes. </p><br><p>  Le choix d'une m√©thode de traitement des demandes a des cons√©quences consid√©rables.  Comment faire un service de chat avec 100 000 connexions simultan√©es?  Quelle approche adopter pour extraire des donn√©es d'un flux de fichiers mal structur√©s?  Un mauvais choix entra√Ænera une perte de temps et d'√©nergie. </p><br><p>  L'article aborde des approches telles qu'un pool de processus / threads, le traitement orient√© √©v√©nement, le mod√®le moiti√© sync / moiti√© async et bien d'autres.  De nombreux exemples sont donn√©s, les avantages et les inconv√©nients des approches, leurs caract√©ristiques et leurs applications sont pris en compte. </p><a name="habracut"></a><br><h2 id="vvedenie">  Pr√©sentation </h2><br><p>  Le sujet des m√©thodes de traitement des requ√™tes n'est pas nouveau, voir, par exemple: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deux</a> .  Cependant, la plupart des articles ne le consid√®rent que partiellement.  Cet article est destin√© √† combler les lacunes et √† fournir une pr√©sentation coh√©rente du probl√®me. </p><br><p>  Les approches suivantes seront envisag√©es: </p><br><ul><li>  traitement s√©quentiel </li><li>  processus de demande </li><li>  flux de demande </li><li>  pool de processus / thread </li><li>  traitement √©v√©nementiel (configuration du r√©acteur) </li><li>  mod√®le moiti√© sync / moiti√© asynchrone </li><li>  traitement de convoyeur </li></ul><br><p>  Il est √† noter qu'un service qui traite des requ√™tes n'est pas n√©cessairement un service r√©seau.  Il peut s'agir d'un service qui re√ßoit de nouvelles t√¢ches de la base de donn√©es ou de la file d'attente des t√¢ches.  Dans cet article, les services r√©seau sont destin√©s, mais vous devez comprendre que les approches consid√©r√©es ont une port√©e plus large. </p><br><h3 id="tldr">  TL; DR </h3><br><p>  √Ä la fin de l'article est une liste avec une br√®ve description de chaque approche. </p><br><h2 id="posledovatelnaya-obrabotka">  Traitement s√©quentiel </h2><br><p>  Une application se compose d'un seul thread dans un seul processus.  Toutes les demandes ne sont trait√©es que s√©quentiellement.  Il n'y a pas de parall√©lisme.  Si plusieurs demandes arrivent au service en m√™me temps, l'une d'elles est trait√©e, les autres sont mises en file d'attente. </p><br><p>  De plus, cette approche est facile √† mettre en ≈ìuvre.  Il n'y a pas de verrous et de concurrence pour les ressources.  L'inconv√©nient √©vident est l'incapacit√© √† √©voluer avec un grand nombre de clients. </p><br><h2 id="process-na-zapros">  Processus de demande </h2><br><p>  Une application se compose d'un processus principal qui accepte les demandes et les flux de travail entrants.  Pour chaque nouvelle demande, le processus principal cr√©e un flux de travail qui traite la demande.  La mise √† l'√©chelle par le nombre de demandes est simple: chaque demande obtient son propre processus. </p><br><p>  Il n'y a rien de compliqu√© dans cette architecture, mais elle a <del>  les probl√®mes </del>  <strong>limitations</strong> : </p><br><ul><li>  Le processus consomme beaucoup de ressources. <br>  Essayez de cr√©er 10 000 connexions simultan√©es au SGBDR PostgreSQL et regardez le r√©sultat. </li><li>  Les processus n'ont pas de m√©moire partag√©e (par d√©faut).  Si vous avez besoin d'acc√©der √† des donn√©es partag√©es ou √† un cache partag√©, vous devrez mapper la m√©moire partag√©e (appeler linux mmap, munmap) ou utiliser un stockage externe (memcahed, redis) </li></ul><br><p>  Ces probl√®mes ne s'arr√™tent en aucun cas.  Ce qui suit montrera comment ils sont g√©r√©s dans le SGBDR PostgeSQL. </p><br><p>  <strong>Avantages de</strong> cette architecture: </p><br><ul><li>  La chute de l'un des processus n'affectera pas les autres.  Par exemple, une erreur de traitement de cas rare ne supprimera pas la demande enti√®re, seule la demande trait√©e souffrira </li><li>  Diff√©renciation des droits d'acc√®s au niveau du syst√®me d'exploitation.  √âtant donn√© que le processus est l'essence m√™me du syst√®me d'exploitation, vous pouvez utiliser ses m√©canismes standard pour d√©limiter les droits d'acc√®s aux ressources du syst√®me d'exploitation. </li><li>  Vous pouvez modifier le processus en cours √† la vol√©e.  Par exemple, si un script distinct est utilis√© pour traiter une demande, puis pour remplacer l'algorithme de traitement, il suffit de changer le script.  Un exemple sera consid√©r√© ci-dessous. </li><li>  Machines multic≈ìurs efficacement utilis√©es </li></ul><br><p>  <strong>Exemples:</strong> </p><br><ul><li>  Le SGBDR PostgreSQL cr√©e un nouveau processus pour chaque nouvelle connexion.  La m√©moire partag√©e est utilis√©e pour travailler avec des donn√©es g√©n√©rales.  PostgreSQL peut g√©rer la consommation √©lev√©e de ressources des processus de diff√©rentes mani√®res.  S'il y a peu de clients (un stand d√©di√© aux analystes), alors ce probl√®me n'existe pas.  S'il existe une seule application qui acc√®de √† la base de donn√©es, vous pouvez cr√©er un pool de connexions √† la base de donn√©es au niveau de l'application.  S'il existe de nombreuses applications, vous pouvez utiliser pgbouncer </li><li>  sshd √©coute les requ√™tes entrantes sur le port 22 et fork √† chaque connexion.  Chaque connexion ssh est un fork du d√©mon sshd qui re√ßoit et ex√©cute les commandes utilisateur en s√©quence.  Gr√¢ce √† cette architecture, les ressources de l'OS lui-m√™me sont utilis√©es pour diff√©rencier les droits d'acc√®s </li><li>  Un exemple de notre propre pratique.  Il existe un flux de fichiers non structur√©s √† partir desquels vous devez obtenir des m√©tadonn√©es.  Le processus de service principal r√©partit les fichiers entre les processus de gestionnaire.  Chaque processus de gestionnaire est un script qui prend un chemin de fichier comme param√®tre.  Le traitement des fichiers se produit dans un processus distinct.Par cons√©quent, en raison d'une erreur de traitement, l'ensemble du service ne se bloque pas.  Pour mettre √† jour l'algorithme de traitement, il suffit de changer les scripts de traitement sans arr√™ter le service. </li></ul><br><p>  En g√©n√©ral, je dois dire que cette approche a ses avantages, qui d√©terminent sa port√©e, mais l'√©volutivit√© est tr√®s limit√©e. </p><br><h2 id="potok-na-zapros">  Flux de demande </h2><br><p>  Cette approche ressemble beaucoup √† la pr√©c√©dente.  La diff√©rence est que les threads sont utilis√©s √† la place des processus.  Cela vous permet d'utiliser la m√©moire partag√©e pr√™te √† l'emploi.  Cependant, les autres avantages de l'approche pr√©c√©dente ne peuvent plus √™tre utilis√©s, tandis que la consommation de ressources sera √©galement √©lev√©e. </p><br><p>  <strong>Avantages:</strong> </p><br><ul><li>  M√©moire partag√©e pr√™te √† l'emploi </li><li>  Facilit√© de mise en ≈ìuvre </li><li>  Utilisation efficace des processeurs multic≈ìurs </li></ul><br><p>  <strong>Inconv√©nients:</strong> </p><br><ul><li>  Un flux consomme beaucoup de ressources.  Sur les syst√®mes d'exploitation de type Unix, un thread consomme presque autant de ressources qu'un processus </li></ul><br><p>  Un exemple d'utilisation est MySQL.  Mais il convient de noter que MySQL utilise une approche mixte, donc cet exemple sera discut√© dans la section suivante. </p><br><h2 id="pul-processovpotokov">  Pool de processus / threads </h2><br><p>  Les flux (processus) cr√©ent co√ªteux et longs.  Afin de ne pas gaspiller les ressources, vous pouvez utiliser le m√™me thread √† plusieurs reprises.  Ayant en outre limit√© le nombre maximum de threads, nous obtenons un pool de threads (processus).  Maintenant, le thread principal accepte les demandes entrantes et les place dans une file d'attente.  Les workflows prennent les demandes de la file d'attente et les traitent.  Cette approche peut √™tre consid√©r√©e comme la mise √† l'√©chelle naturelle du traitement s√©quentiel des demandes: chaque thread de travail ne peut traiter les flux que s√©quentiellement, leur mise en commun vous permet de traiter les demandes en parall√®le.  Si chaque flux peut g√©rer 1000 rps, alors 5 flux g√©reront la charge pr√®s de 5000 rps (sous r√©serve d'une concurrence minimale pour les ressources partag√©es). </p><br><p>  Le pool peut √™tre cr√©√© √† l'avance au d√©but de la prestation ou form√© progressivement.  L'utilisation d'un pool de threads est plus courante car  vous permet d'appliquer la m√©moire partag√©e. </p><br><p>  La taille du pool de threads ne doit pas √™tre limit√©e.  Un service peut utiliser des threads libres du pool et, s'il n'y en a pas, cr√©er un nouveau thread.  Apr√®s avoir trait√© la demande, le thread rejoint le pool et attend la prochaine demande.  Cette option est une combinaison d'une approche de thread sur demande et d'un pool de threads.  Un exemple sera donn√© ci-dessous. </p><br><p>  <strong>Avantages:</strong> </p><br><ul><li>  l'utilisation de nombreux c≈ìurs de CPU </li><li>  r√©duction des co√ªts de cr√©ation d'un thread / processus </li></ul><br><p>  <strong>Inconv√©nients:</strong> </p><br><ul><li>  √âvolutivit√© limit√©e du nombre de clients simultan√©s.  L'utilisation du pool nous permet de r√©utiliser le m√™me thread plusieurs fois sans co√ªts de ressources suppl√©mentaires, cependant, cela ne r√©sout pas le probl√®me fondamental d'un grand nombre de ressources consomm√©es par le thread / processus.  La cr√©ation d'un service de chat capable de supporter 100 000 connexions simultan√©es √† l'aide de cette approche √©chouera. </li><li>  L'√©volutivit√© est limit√©e par les ressources partag√©es, par exemple, si les threads utilisent la m√©moire partag√©e en ajustant l'acc√®s √† celle-ci √† l'aide de s√©maphores / mutex.  Il s'agit d'une limitation de toutes les approches qui utilisent des ressources partag√©es. </li></ul><br><p>  <strong>Exemples:</strong> </p><br><ol><li>  Application Python fonctionnant avec uWSGI et nginx.  Le processus uWSGI principal re√ßoit les demandes entrantes de nginx et les r√©partit entre les processus Python de l'interpr√©teur qui traitent les demandes.  L'application peut √™tre √©crite sur n'importe quel framework compatible uWSGI - Django, Flask, etc. </li><li>  MySQL utilise un pool de threads: chaque nouvelle connexion est trait√©e par l'un des threads libres du pool.  S'il n'y a pas de threads libres, MySQL cr√©e un nouveau thread.  La taille du pool de threads libres et le nombre maximum de threads (connexions) sont limit√©s par les param√®tres. </li></ol><br><p>  C'est peut-√™tre l'une des approches les plus courantes pour cr√©er des services r√©seau, sinon la plus courante.  Il vous permet de bien √©voluer, atteignant de grands rps.  La principale limitation de l'approche est le nombre de connexions r√©seau trait√©es simultan√©ment.  En fait, cette approche ne fonctionne bien que si les demandes sont courtes ou peu de clients. </p><br><h2 id="sobytiyno-orientirovannaya-obrabotka-reactor-pattern">  Traitement orient√© √©v√©nement (mod√®le de r√©acteur) </h2><br><p>  Deux paradigmes - synchrone et asynchrone - sont des concurrents √©ternels l'un de l'autre.  Jusqu'√† pr√©sent, seules les approches synchrones ont √©t√© discut√©es, mais il serait faux d'ignorer l'approche asynchrone.  Le traitement de demande orient√© √©v√©nement ou r√©actif est une approche dans laquelle chaque op√©ration d'E / S est effectu√©e de mani√®re asynchrone, et √† la fin de l'op√©ration, un gestionnaire est appel√©.  En r√®gle g√©n√©rale, le traitement de chaque demande consiste en de nombreux appels asynchrones suivis de l'ex√©cution de gestionnaires.  √Ä tout moment, une application √† un seul thread ex√©cute le code d'un seul gestionnaire, mais l'ex√©cution des gestionnaires de diverses demandes alterne entre elles, ce qui vous permet de traiter simultan√©ment (pseudo-parall√®le) de nombreuses demandes parall√®les. </p><br><p>  Une discussion compl√®te de cette approche d√©passe le cadre de cet article.  Pour un regard plus profond, vous pouvez recommander <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reactor (Reactor)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Quel est le secret de la vitesse NodeJS?</a>  , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√Ä l'int√©rieur de NGINX</a> .  Ici, nous nous limitons √† consid√©rer les avantages et les inconv√©nients de cette approche. </p><br><p>  <strong>Avantages:</strong> </p><br><ul><li>  Mise √† l'√©chelle efficace par rps et le nombre de connexions simultan√©es.  Un service r√©actif peut traiter simultan√©ment un grand nombre de connexions (des dizaines de milliers) si la plupart des connexions attendent la fin des E / S </li></ul><br><p>  <strong>Inconv√©nients:</strong> </p><br><ul><li>  La complexit√© du d√©veloppement.  La programmation en style asynchrone est plus difficile qu'en mode synchrone.  La logique du traitement des requ√™tes est plus complexe, le d√©bogage est √©galement plus difficile que dans le code synchrone. </li><li>  Erreurs conduisant √† bloquer l'ensemble du service.  Si la langue ou le runtime n'est pas con√ßu √† l'origine pour le traitement asynchrone, une seule op√©ration synchrone peut bloquer l'ensemble du service, annulant la possibilit√© de mise √† l'√©chelle. </li><li>  Difficile de faire √©voluer les c≈ìurs de processeur.  Cette approche suppose un seul thread dans un seul processus, vous ne pouvez donc pas utiliser plusieurs c≈ìurs de processeur en m√™me temps.  Il convient de noter qu'il existe des moyens de contourner cette limitation. </li><li>  Corollaire du paragraphe pr√©c√©dent: cette approche ne s'adapte pas bien aux requ√™tes n√©cessitant un processeur.  Le nombre de rps pour cette approche est inversement proportionnel au nombre d'op√©rations CPU requises pour traiter chaque requ√™te.  Exiger des demandes de CPU annule les avantages de cette approche. </li></ul><br><p>  <strong>Exemples:</strong> </p><br><ol><li>  Node.js utilise le mod√®le de r√©acteur pr√™t √† l'emploi.  Pour plus de d√©tails, voir Quel est le secret de la vitesse NodeJS? </li><li>  nginx: les processus de travail de nginx utilisent le mod√®le de r√©acteur pour traiter les demandes en parall√®le.  Voir Inside NGINX pour plus de d√©tails. </li><li>  Programme C / C ++ qui utilise directement les outils OS (epoll sur linux, IOCP sur windows, kqueue sur FreeBSD), ou utilise le framework (libev, libevent, libuv, etc.). </li></ol><br><h2 id="half-synchalf-async">  Mi-sync / mi-async </h2><br><p>  Le nom est tir√© de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">POSA: Patterns for Concurrent and Networked Objects</a> .  Dans l'original, ce mod√®le est interpr√©t√© de mani√®re tr√®s large, mais pour les besoins de cet article, je comprendrai ce mod√®le un peu plus √©troitement.  Half sync / half async est une approche de traitement des demandes qui utilise un flux de contr√¥le l√©ger (fil vert) pour chaque demande.  Un programme se compose d'un ou de plusieurs threads au niveau du syst√®me d'exploitation, cependant, le syst√®me d'ex√©cution du programme prend en charge les threads verts que le syst√®me d'exploitation ne voit pas et ne peut pas contr√¥ler. </p><br><p>  Quelques <strong>exemples</strong> pour rendre la consid√©ration plus pr√©cise: </p><br><ol><li>  Service en langue Go.  Le langage Go prend en charge de nombreux threads d'ex√©cution l√©gers - goroutine.  Le programme utilise un ou plusieurs threads du syst√®me d'exploitation, mais le programmeur fonctionne avec des goroutines, qui sont r√©parties de mani√®re transparente entre les threads du syst√®me d'exploitation afin d'utiliser des processeurs multic≈ìurs. </li><li>  Service Python avec biblioth√®que gevent.  La biblioth√®que gevent permet au programmeur d'utiliser des fils verts au niveau de la biblioth√®que.  L'ensemble du programme est ex√©cut√© dans un seul thread OS. </li></ol><br><p>  En substance, cette approche est con√ßue pour combiner les hautes performances de l'approche asynchrone avec la simplicit√© de programmation de code synchrone. </p><br><p>  En utilisant cette approche, malgr√© l'illusion de synchronisme, le programme fonctionnera de mani√®re asynchrone: le syst√®me d'ex√©cution du programme contr√¥lera la boucle d'√©v√©nements, et chaque op√©ration "synchrone" sera en fait asynchrone.  Lorsqu'une telle op√©ration est appel√©e, le syst√®me d'ex√©cution appelle l'op√©ration asynchrone √† l'aide des outils du syst√®me d'exploitation et enregistre le gestionnaire de la fin de l'op√©ration.  Une fois l'op√©ration asynchrone termin√©e, le syst√®me d'ex√©cution appellera le gestionnaire pr√©c√©demment enregistr√©, qui continuera √† ex√©cuter le programme au point d'invocation de l'op√©ration "synchrone". </p><br><p>  Par cons√©quent, l'approche moiti√© sync / moiti√© asynchrone contient √† la fois certains avantages et certains inconv√©nients de l'approche asynchrone.  Le volume de l'article ne nous permet pas d'approfondir cette approche.  Pour les personnes int√©ress√©es, je vous conseille de lire le chapitre du m√™me nom dans le livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">POSA: Patterns for Concurrent and Networked Objects</a> . </p><br><p>  L'approche moiti√© sync / moiti√© async elle-m√™me introduit une nouvelle entit√© ¬´green stream¬ª - un flux de contr√¥le l√©ger au niveau du syst√®me d'ex√©cution du programme ou de la biblioth√®que.  Que faire avec les fils verts est le choix du programmeur.  Il peut utiliser un pool de fils verts, il peut cr√©er un nouveau fil vert pour chaque nouvelle demande.  La diff√©rence par rapport aux threads / processus OS est que les threads verts sont beaucoup moins chers: ils consomment beaucoup moins de RAM et sont cr√©√©s beaucoup plus rapidement.  Cela vous permet de cr√©er un grand nombre de fils verts, par exemple, des centaines de milliers dans la langue Go.  Une telle quantit√© justifie l'utilisation de l'approche verte de flux sur demande. </p><br><p>  <strong>Avantages:</strong> </p><br><ul><li>  Il √©volue bien en rps et le nombre de connexions simultan√©es </li><li>  Le code est plus facile √† √©crire et √† d√©boguer que l'approche asynchrone </li></ul><br><p>  <strong>Inconv√©nients:</strong> </p><br><ul><li>  √âtant donn√© que l'ex√©cution des op√©rations est en fait asynchrone, des erreurs de programmation sont possibles lorsqu'une seule op√©ration synchrone bloque l'ensemble du processus.  Cela se ressent surtout dans les langages o√π cette approche est impl√©ment√©e au moyen d'une biblioth√®que, par exemple Python. </li><li>  L'opacit√© du programme.  Lors de l'utilisation de threads ou de processus OS, l'algorithme d'ex√©cution du programme est clair: chaque thread / processus effectue des op√©rations dans l'ordre dans lequel elles sont √©crites dans le code.  En utilisant l'approche moiti√© sync / moiti√© asynchrone, les op√©rations qui sont √©crites s√©quentiellement dans le code peuvent alterner de mani√®re impr√©visible avec des op√©rations qui traitent des demandes simultan√©es. </li><li>  Ne convient pas aux syst√®mes en temps r√©el.  Le traitement asynchrone des demandes complique consid√©rablement la fourniture de garanties pour le temps de traitement de chaque demande individuelle.  Ceci est une cons√©quence du paragraphe pr√©c√©dent. </li></ul><br><p>  Selon l'impl√©mentation, cette approche √©volue bien sur les c≈ìurs de processeur (Golang) ou ne se modifie pas du tout (Python). <br>  Cette approche, ainsi qu'asynchrone, vous permet de g√©rer un grand nombre de connexions simultan√©es.  Mais la programmation d'un service en utilisant cette approche est plus facile, car  le code est √©crit dans un style synchrone. </p><br><h2 id="konveyernaya-obrabotka">  Traitement des convoyeurs </h2><br><p>  Comme son nom l'indique, dans cette approche, les demandes sont trait√©es par pipeline.  Le processus de traitement consiste en plusieurs threads OS dispos√©s en cha√Æne.  Chaque thread est un maillon de la cha√Æne, il effectue un certain sous-ensemble des op√©rations n√©cessaires pour traiter la demande.  Chaque demande passe s√©quentiellement √† travers tous les maillons de la cha√Æne, et diff√©rents maillons √† chaque instant traitent diff√©rentes demandes. </p><br><p>  <strong>Avantages:</strong> </p><br><ul><li>  Cette approche √©volue bien en rps.  Plus il y a de maillons dans la cha√Æne, plus les requ√™tes sont trait√©es par seconde. </li><li>  L'utilisation de plusieurs threads vous permet de bien √©voluer sur les c≈ìurs de processeur. </li></ul><br><p>  <strong>Inconv√©nients:</strong> </p><br><ul><li>  Toutes les cat√©gories de requ√™tes ne conviennent pas √† cette approche.  Par exemple, l'organisation de longs sondages √† l'aide de cette approche sera difficile et peu pratique. </li><li>  La complexit√© de l'impl√©mentation et du d√©bogage.  Battre le traitement s√©quentiel afin que la productivit√© soit √©lev√©e peut √™tre difficile.  Le d√©bogage d'un programme dans lequel chaque requ√™te est trait√©e s√©quentiellement dans plusieurs threads parall√®les est plus difficile que le traitement s√©quentiel. </li></ul><br><p>  <strong>Exemples:</strong> </p><br><ol><li>  Un exemple int√©ressant de traitement des convoyeurs a √©t√© d√©crit dans le rapport highload 2018 L' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©volution de l'architecture du syst√®me de n√©gociation et de compensation de la Bourse de Moscou</a> </li></ol><br><p>  Le pipeline est largement utilis√©, mais le plus souvent, les liens sont des composants individuels dans des processus ind√©pendants qui √©changent des messages, par exemple via une file d'attente de messages ou une base de donn√©es. </p><br><h2 id="rezyume">  R√©sum√© </h2><br><p>  Un bref r√©sum√© des approches envisag√©es: </p><br><ul><li>  Traitement synchrone. <br>  Une approche simple, mais tr√®s limit√©e en termes d'√©volutivit√©, aussi bien en RPS qu'en nombre de connexions simultan√©es.  Il ne permet pas l'utilisation de plusieurs c≈ìurs de processeur en m√™me temps. </li><li>  Un nouveau processus pour chaque demande. <br>     .         ,      .             .       ( ,     ). </li><li>     . <br>   ,     ,      .       ,      . </li><li>  /. <br>            /.        .    rps    .        .      . </li><li> -  (reactor ). <br>    rps    .   -   ,     .      CPU    </li><li> Half sync/half async. <br>    rps    .         CPU (Golang)     (Python).      ,   ()  .        reactor ,      ,    reactor . </li><li>  . <br>    ,     .       (, long polling   ). </li></ul><br><p>     ,        . </p><br><p>   :    ?    ,        ? </p><br><h3 id="ssylki">  Les r√©f√©rences </h3><br><ol><li>  Articles li√©s: <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">     </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">     : </a> </li></ul></li><li> - : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reactor ()</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">    NodeJS?</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Inside NGINX</a> </li></ul></li><li>       : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache vs Nginx:  </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">       Node.js  PHP</a> </li></ul></li><li> Half sync/half async: <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Half-Sync/Half-Async (Java Design Patterns)</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">POSA: Patterns for Concurrent and Networked Objects</a> </li></ul></li><li>  : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Green threads ()</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Green Vs Native Threads</a> </li></ul></li><li>  : <br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  -   </a> </li></ul></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr432630/">https://habr.com/ru/post/fr432630/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr432620/index.html">Cours MIT "S√©curit√© des syst√®mes informatiques". Conf√©rence 20: S√©curit√© des t√©l√©phones portables, partie 3</a></li>
<li><a href="../fr432622/index.html">Besoin de plus de flous diff√©rents</a></li>
<li><a href="../fr432624/index.html">Apprenez les tactiques, techniques et connaissances communes contradictoires (ATT @ CK). Tactiques d'entreprise. Partie 5</a></li>
<li><a href="../fr432626/index.html">Fa√ßons d'interagir avec le syst√®me: des bandes perfor√©es aux neurointerfaces</a></li>
<li><a href="../fr432628/index.html">@Pythonetc novembre 2018</a></li>
<li><a href="../fr432632/index.html">L'histoire de Lenny, le troll de t√©l√©phone spam pr√©f√©r√© d'Internet Troll</a></li>
<li><a href="../fr432634/index.html">Pr√©sentation de cinq biblioth√®ques de d√©veloppement Web HTTP</a></li>
<li><a href="../fr432636/index.html">Tutoriel React Partie 1: Pr√©sentation du cours, React, ReactDOM et JSX Raisons de la popularit√©</a></li>
<li><a href="../fr432638/index.html">Nouveaut√©s d'Upsource 2018.2</a></li>
<li><a href="../fr432640/index.html">Version Rust 1.31 et Rust 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
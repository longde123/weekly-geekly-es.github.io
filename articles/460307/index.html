<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§© üåÄ ü§´ Experiencia de modelado del equipo de Computer Vision Mail.ru üíÇüèº ‚ôøÔ∏è üåè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mi nombre es Eduard Tyantov, lidero el equipo de Computer Vision en Mail.ru Group. A lo largo de varios a√±os de nuestra existencia, nuestro equipo ha ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experiencia de modelado del equipo de Computer Vision Mail.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/460307/"><img src="https://habrastorage.org/webt/zz/gc/py/zzgcpycxxdaz-0a657wzkvjlvos.jpeg"><br><br>  Mi nombre es Eduard Tyantov, lidero el equipo de Computer Vision en Mail.ru Group.  A lo largo de varios a√±os de nuestra existencia, nuestro equipo ha resuelto docenas de problemas de visi√≥n por computadora, y hoy les contar√© qu√© m√©todos usamos para crear con √©xito modelos de aprendizaje autom√°tico que funcionan en una amplia gama de tareas.  Compartir√© trucos que pueden acelerar el modelo en todas las etapas: establecer una tarea, preparar datos, capacitaci√≥n e implementaci√≥n en producci√≥n. <br><a name="habracut"></a><br><h2>  Computer Vision en Mail.ru </h2><br>  Para empezar, qu√© es Computer Vision en Mail.ru y qu√© proyectos hacemos.  Brindamos soluciones en nuestros productos, como Mail, Mail.ru Cloud (una aplicaci√≥n para almacenar fotos y videos), Vision (soluciones B2B basadas en visi√≥n por computadora) y otras.  Dar√© algunos ejemplos. <br><br>  La nube (este es nuestro primer y principal cliente) tiene 60 mil millones de fotos.  Desarrollamos varias caracter√≠sticas basadas en el aprendizaje autom√°tico para su procesamiento inteligente, por ejemplo, reconocimiento facial y visitas tur√≠sticas ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hay una publicaci√≥n separada sobre esto</a> ).  Todas las fotos de los usuarios se ejecutan a trav√©s de modelos de reconocimiento, lo que le permite organizar una b√∫squeda y agrupaci√≥n por personas, etiquetas, ciudades y pa√≠ses visitados, etc. <br><br><img src="https://habrastorage.org/webt/dc/ls/ug/dclsugao8xumevprode0ift5dxq.jpeg"><img src="https://habrastorage.org/webt/zr/bo/rd/zrbordgq4zygrzpzvmsg5x0nt6i.jpeg"><br><br>  Para Mail, hicimos OCR: reconocimiento de texto de una imagen.  Hoy te contar√© un poco m√°s sobre √©l. <br><br>  Para los productos B2B, reconocemos y contamos a las personas en las colas.  Por ejemplo, hay una cola para el remonte y debe calcular cu√°ntas personas hay en √©l.  Para empezar, para probar la tecnolog√≠a y jugar, implementamos un prototipo en el comedor de la oficina.  Hay varios mostradores de efectivo y, en consecuencia, varias colas, y nosotros, usando varias c√°maras (una para cada una de las colas), usando el modelo, calculamos cu√°ntas personas hay en las colas y cu√°ntos minutos quedan aproximadamente en cada una de ellas.  De esta manera podemos equilibrar mejor las l√≠neas en el comedor. <br><br><img src="https://habrastorage.org/webt/yr/yq/hb/yryqhbu5zqhxm_fozg-4ygkz6i4.jpeg"><br><br><h2>  Declaraci√≥n del problema. </h2><br>  Comencemos con la parte cr√≠tica de cualquier tarea: su formulaci√≥n.  Casi cualquier desarrollo de ML lleva al menos un mes (esto es mejor cuando sabes qu√© hacer), y en la mayor√≠a de los casos varios meses.  Si la tarea es incorrecta o inexacta, al final del trabajo hay una gran posibilidad de escuchar del gerente de producto algo en el esp√≠ritu: ‚ÄúTodo est√° mal.  Esto no es bueno  Quer√≠a algo m√°s ".  Para evitar que esto suceda, debe seguir algunos pasos.  ¬øQu√© tienen de especial los productos basados ‚Äã‚Äãen ML?  A diferencia de la tarea de desarrollar un sitio, la tarea de aprendizaje autom√°tico no se puede formalizar solo con texto.  Adem√°s, como regla general, a una persona no preparada le parece que todo ya es obvio, y simplemente se requiere que haga todo "bellamente".  Pero, ¬øqu√© peque√±os detalles hay? Es posible que el administrador de tareas ni siquiera lo sepa, nunca haya pensado en ellos y no piense hasta que vea el producto final y diga: "¬øQu√© has hecho? <br><br><h2>  Los problemas </h2><br>  Comprendamos con ejemplos qu√© problemas pueden ser.  Supongamos que tiene una tarea de reconocimiento facial.  Lo recibe, se regocija y llama a su madre: "¬°Hurra, una tarea interesante!"  Pero, ¬øes posible romper directamente y comenzar a hacerlo?  Si hace esto, al final puede esperar sorpresas: <br><br><ul><li>  Hay diferentes nacionalidades.  Por ejemplo, no hab√≠a asi√°ticos ni nadie m√°s en el conjunto de datos.  Su modelo, en consecuencia, no sabe c√≥mo reconocerlos en absoluto, y el producto lo necesita.  O viceversa, pas√≥ tres meses adicionales en la revisi√≥n, y el producto solo tendr√° cauc√°sicos, y esto no fue necesario. <br></li><li>  Hay ni√±os  Para los padres sin hijos como yo, todos los ni√±os est√°n en una sola cara.  Estoy totalmente de acuerdo con el modelo, cuando ella env√≠a a todos los ni√±os a un grupo: ¬°no est√° claro c√≥mo difieren la mayor√≠a de los ni√±os!  ;) Pero las personas que tienen hijos tienen una opini√≥n completamente diferente.  Por lo general, tambi√©n son tus l√≠deres.  O todav√≠a hay errores divertidos de reconocimiento cuando la cabeza del ni√±o se compara con √©xito con el codo o la cabeza de un hombre calvo (historia real). <br></li><li>  Qu√© hacer con los personajes pintados generalmente no est√° claro.  ¬øNecesito reconocerlos o no? <br></li></ul><br>  Tales aspectos de la tarea son muy importantes para identificar al principio.  Por lo tanto, debe trabajar y comunicarse con el gerente desde el principio "sobre los datos".  No se pueden aceptar explicaciones orales.  Es necesario mirar los datos.  Es deseable a partir de la misma distribuci√≥n en la que funcionar√° el modelo. <br><br>  Idealmente, en el proceso de esta discusi√≥n, se obtendr√°n algunos conjuntos de datos de prueba en los que finalmente puede ejecutar el modelo y verificar si funciona como el administrador quer√≠a.  Es aconsejable entregar parte del conjunto de datos de prueba al administrador mismo, para que no tenga acceso a √©l.  Como puedes volver a entrenar f√°cilmente en este conjunto de prueba, ¬°eres un desarrollador de ML! <br><br>  Establecer una tarea en ML es un trabajo constante entre un gerente de producto y un especialista en ML.  Incluso si al principio establece bien la tarea, a medida que el modelo se desarrolle, aparecer√°n m√°s y m√°s problemas nuevos, nuevas caracter√≠sticas que aprender√° sobre sus datos.  Todo esto debe discutirse constantemente con el gerente.  Los buenos gerentes siempre transmiten a sus equipos de ML que deben asumir la responsabilidad y ayudar al gerente a establecer tareas. <br><br>  Por qu√©  El aprendizaje autom√°tico es un √°rea bastante nueva.  Los gerentes no tienen (o tienen poca) experiencia en la gesti√≥n de tales tareas.  ¬øCon qu√© frecuencia las personas aprenden a resolver nuevos problemas?  Sobre los errores.  Si no desea que su proyecto favorito se convierta en un error, debe involucrarse y asumir la responsabilidad, ense√±ar al gerente de producto a establecer la tarea correctamente, desarrollar listas de verificaci√≥n y pol√≠ticas;  Todo esto ayuda mucho.  Cada vez que salgo (o alguien de mis colegas me saca) cuando llega una nueva tarea interesante, y corremos para hacerlo.  Todo lo que acabo de contarte, lo olvido yo mismo.  Por lo tanto, es importante tener alg√∫n tipo de lista de verificaci√≥n para comprobarlo usted mismo. <br><br><h2>  Datos </h2><br>  Los datos son s√∫per importantes en ML.  Para el aprendizaje profundo, cuantos m√°s datos alimentes a los modelos, mejor.  El gr√°fico azul muestra que, por lo general, los modelos de aprendizaje profundo mejoran enormemente cuando se agregan datos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1x/wf/bb/1xwfbbc7-os0p9wjc8y_2iiyn10.jpeg"></div><br>  Y los algoritmos "antiguos" (cl√°sicos) desde alg√∫n punto ya no pueden mejorar. <br><br>  Por lo general, los conjuntos de datos de ML est√°n sucios  Fueron marcados por personas que siempre mienten.  Los evaluadores a menudo son desatentos y cometen muchos errores.  Utilizamos esta t√©cnica: tomamos los datos que tenemos, entrenamos el modelo en ellos y luego, con la ayuda de este modelo, borramos los datos y repetimos el ciclo nuevamente. <br><br>  Echemos un vistazo m√°s de cerca al ejemplo del mismo reconocimiento facial.  Digamos que descargamos avatares de usuario de VKontakte.  Por ejemplo, tenemos un perfil de usuario con 4 avatares.  Detectamos rostros que est√°n en las 4 im√°genes y ejecutamos el modelo de reconocimiento de rostros.  Entonces obtenemos incrustaciones de personas, con la ayuda de las cuales pueden "pegar" personas similares en grupos (grupo).  A continuaci√≥n, seleccionamos el grupo m√°s grande, suponiendo que los avatares del usuario contengan principalmente su cara.  En consecuencia, podemos limpiar todas las otras caras (que son ruido) de esta manera.  Despu√©s de eso, podemos repetir el ciclo nuevamente: en los datos limpiados, entrene el modelo y √∫selo para limpiar los datos.  Puedes repetir varias veces. <br><br>  Casi siempre para tales agrupamientos usamos algoritmos CLink.  Este es un algoritmo de agrupamiento jer√°rquico en el que es muy conveniente establecer un valor umbral para "pegar" objetos similares (esto es exactamente lo que se requiere para la limpieza).  CLink genera grupos esf√©ricos.  Esto es importante, ya que a menudo aprendemos el espacio m√©trico de estas incrustaciones.  El algoritmo tiene una complejidad de O (n <sup>2</sup> ), que, en principio, es de aprox. <br><br>  A veces, los datos son tan dif√≠ciles de obtener o marcar que no queda nada por hacer tan pronto como comience a generarlos.  El enfoque generativo le permite producir una gran cantidad de datos.  Pero para esto necesitas programar algo.  El ejemplo m√°s simple es OCR, reconocimiento de texto en im√°genes.  El marcado del texto para esta tarea es extremadamente costoso y ruidoso: debe resaltar cada l√≠nea y cada palabra, firmar el texto, etc.  Los asesores (personas de marcado) ocupar√°n cien p√°ginas de texto durante un tiempo extremadamente largo, y se necesita mucho m√°s para la capacitaci√≥n.  Obviamente, de alguna manera puede generar el texto y de alguna manera "moverlo" para que el modelo aprenda de √©l. <br><br>  Hemos descubierto por nosotros mismos que el mejor y m√°s conveniente juego de herramientas para esta tarea es una combinaci√≥n de PIL, OpenCV y Numpy.  Tienen todo para trabajar con texto.  Puede complicar la imagen con texto de cualquier manera para que la red no se vuelva a entrenar con ejemplos simples. <br><br><img src="https://habrastorage.org/webt/cv/zd/ib/cvzdibgjrtt_qnyro4u8-zcgdgw.png"><br><br>  A veces necesitamos algunos objetos del mundo real.  Por ejemplo, productos en los estantes de las tiendas.  Una de estas im√°genes se genera autom√°ticamente.  ¬øPiensas izquierda o derecha? <br><br><img src="https://habrastorage.org/webt/os/py/gi/ospygi-cu95vtgblk8ekol86qak.jpeg"><br><br>  De hecho, ambos se generan.  Si no observa los peque√±os detalles, no notar√° diferencias con la realidad.  Hacemos esto usando Blender (an√°logo de 3dmax). <br><br><img src="https://habrastorage.org/webt/wq/7i/hd/wq7ihd3zrqp0fevkbdylp96hm0m.jpeg"><br><br>  La principal ventaja importante es que es de c√≥digo abierto.  Tiene una excelente API de Python, que le permite colocar objetos directamente en el c√≥digo, configurar y aleatorizar el proceso y finalmente obtener un conjunto de datos diverso. <br><br>  Para el renderizado, se utiliza el trazado de rayos.  Este es un procedimiento bastante costoso, pero produce un resultado con excelente calidad.  La pregunta m√°s importante: ¬ød√≥nde obtener modelos para objetos?  Como regla, deben comprarse.  Pero si eres un estudiante pobre y quieres experimentar con algo, siempre hay torrentes.  Est√° claro que para la producci√≥n necesita comprar u ordenar modelos renderizados de alguien. <br><br>  Eso es todo acerca de los datos.  Pasemos al aprendizaje. <br><br><h2>  Aprendizaje m√©trico </h2><br>  El objetivo del aprendizaje m√©trico es capacitar a la red para que traduzca objetos similares en regiones similares en el espacio m√©trico incrustado.  Volver√© a dar un ejemplo con las vistas, lo cual es inusual porque en esencia es una tarea de clasificaci√≥n, pero para decenas de miles de clases.  Parecer√≠a, ¬øpor qu√© aqu√≠ el aprendizaje m√©trico, que, como regla, es apropiado en tareas como el reconocimiento facial?  Tratemos de resolverlo. <br><br>  Si usa p√©rdidas est√°ndar cuando entrena un problema de clasificaci√≥n, por ejemplo, Softmax, entonces las clases en el espacio m√©trico est√°n bien separadas, pero en el espacio de inserci√≥n, los puntos de diferentes clases pueden estar cerca uno del otro ... <br><br><img src="https://habrastorage.org/webt/od/fl/aq/odflaq4hgygf8vvrnftdrdeinh8.jpeg"><br><br>  Esto crea posibles errores durante la generalizaci√≥n, ya que  Una ligera diferencia en los datos de origen puede cambiar el resultado de la clasificaci√≥n.  Realmente nos gustar√≠a que los puntos sean m√°s compactos.  Para esto, se utilizan varias t√©cnicas de aprendizaje m√©trico.  Por ejemplo, la p√©rdida del centro, cuya idea es extremadamente simple: simplemente juntamos puntos al centro de aprendizaje de cada clase, que eventualmente se vuelven m√°s compactos. <br><br><img src="https://habrastorage.org/webt/am/pf/nw/ampfnwjhkn4idpxob_tjpvg3sey.jpeg"><br><br>  La p√©rdida central se programa literalmente en 10 l√≠neas en Python, funciona muy r√°pidamente y, lo m√°s importante, mejora la calidad de la clasificaci√≥n, porque  La compacidad conduce a una mejor capacidad de generalizaci√≥n. <br><br><h2>  Softmax angular </h2><br>  Probamos muchos m√©todos diferentes de aprendizaje m√©trico y llegamos a la conclusi√≥n de que Angular Softmax produce los mejores resultados.  Entre la comunidad de investigaci√≥n, tambi√©n se le considera estado de la t√©cnica. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ks/gx/ap/ksgxapfkweb9invhas0g2dz2w2s.jpeg"></div><br>  Veamos un ejemplo de reconocimiento facial.  Aqu√≠ tenemos dos personas.  Si usa el Softmax est√°ndar, se dibujar√° un plano divisorio entre ellos, basado en dos vectores de peso.  Si hacemos la norma de incrustaci√≥n 1, entonces los puntos se ubicar√°n en el c√≠rculo, es decir  en la esfera en el caso n-dimensional (imagen a la derecha). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/by/zf/a9/byzfa9okk0cry7vcx6vg4n3dsd8.jpeg"></div><br>  Entonces puede ver que el √°ngulo entre ellos ya es responsable de la separaci√≥n de clases, y puede optimizarse.  Pero eso no es suficiente.  Si solo optimizamos el √°ngulo, la tarea no cambiar√° de hecho, porque  simplemente lo reformulamos en otros t√©rminos.  Recuerdo que nuestro objetivo es hacer que los grupos sean m√°s compactos. <br><br>  Es necesario de alguna manera exigir un √°ngulo mayor entre las clases, para complicar la tarea de la red neuronal.  Por ejemplo, de tal manera que ella piensa que el √°ngulo entre los puntos de una clase es mayor que en la realidad, por lo que trata de comprimirlos cada vez m√°s.  Esto se logra al introducir el par√°metro m, que controla la diferencia en los cosenos de los √°ngulos. <br><br><img src="https://habrastorage.org/webt/lx/fk/xc/lxfkxcrdodlg-wpoasqxcws3gao.jpeg"><br><br>  Hay varias opciones para Angular Softmax.  Todos juegan con el hecho de que multiplican por m este √°ngulo o suman, o multiplican y suman.  Estado del arte - ArcFace. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/_i/zw/ye_izwbkvqmr0-fxpxahc2uty6e.gif"></div><br>  De hecho, este es bastante f√°cil de integrar en la clasificaci√≥n de la tuber√≠a. <br><br><img src="https://habrastorage.org/webt/05/gi/vt/05givtsihtduioo9co9f0jzj5hk.jpeg"><br><br>  Veamos el ejemplo de Jack Nicholson.  Corremos su foto a trav√©s de la cuadr√≠cula en el proceso de aprendizaje.  Nos incrustamos, corremos a trav√©s de la capa lineal para la clasificaci√≥n y obtenemos puntajes en la salida, que reflejan el grado de pertenencia a la clase.  En este caso, la fotograf√≠a de Nicholson tiene una velocidad de 20, la m√°s grande.  Adem√°s, de acuerdo con la f√≥rmula de ArcFace, reducimos la velocidad de 20 a 13 (solo para la clase de verdad), lo que complica la tarea para la red neuronal.  Luego hacemos todo como de costumbre: Softmax + Cross Entropy. <br><br>  En total, la capa lineal habitual se reemplaza por la capa ArcFace, que no est√° escrita en 10, sino en 20 l√≠neas, pero proporciona excelentes resultados y un m√≠nimo de sobrecarga para la implementaci√≥n.  Como resultado, ArcFace es mejor que la mayor√≠a de los otros m√©todos para la mayor√≠a de las tareas.  Se integra perfectamente con las tareas de clasificaci√≥n y mejora la calidad. <br><br><h2>  Transferencia de aprendizaje </h2><br>  La segunda cosa de la que quer√≠a hablar es el aprendizaje de transferencia: usar una red pre-entrenada en una tarea similar para volver a capacitarse en una nueva tarea.  Por lo tanto, el conocimiento se transfiere de una tarea a otra. <br><br>  Hicimos nuestra b√∫squeda en im√°genes.  La esencia de la tarea es producir sem√°nticamente similares a partir de la base de datos en la imagen (consulta). <br><br><img src="https://habrastorage.org/webt/hp/m-/x2/hpm-x27etg2zdagi9wupvgjdqtm.jpeg"><br><br>  Es l√≥gico tomar una red que ya ha estudiado en una gran cantidad de im√°genes, en conjuntos de datos ImageNet u OpenImages, en los que hay millones de im√°genes, y entrenar en nuestros datos. <br><br><img src="https://habrastorage.org/webt/fn/hq/c-/fnhqc-efmzfkuqmwocx_zy4wp1a.jpeg"><br><br>  Recopilamos datos para esta tarea en funci√≥n de la similitud de las im√°genes y los clics de los usuarios y obtuvimos 200k clases.  Despu√©s de entrenar con ArFace, obtuvimos el siguiente resultado. <br><br><img src="https://habrastorage.org/webt/da/gu/dd/daguddqmsfbsvj9rdrix-slta4u.jpeg"><br><br>  En la imagen de arriba, vemos que para el pel√≠cano solicitado, los gorriones tambi√©n se metieron en el problema.  Es decir  la incrustaci√≥n result√≥ sem√°nticamente cierta: es un p√°jaro, pero racialmente infiel.  Lo m√°s molesto es que el modelo original con el que nos volvimos a entrenar conoc√≠a estas clases y las distingu√≠a perfectamente.  Aqu√≠ vemos el efecto que es com√∫n a todas las redes neuronales, llamado olvido catastr√≥fico.  Es decir, durante el reciclaje, la red olvida la tarea anterior, a veces incluso por completo.  Esto es exactamente lo que impide en esta tarea lograr una mejor calidad. <br><br><h2>  Destilaci√≥n de conocimiento </h2><br>  Esto se trata utilizando una t√©cnica llamada destilaci√≥n de conocimiento, cuando una red ense√±a a otra y "le transfiere su conocimiento".  C√≥mo se ve (canal de entrenamiento completo en la imagen a continuaci√≥n). <br><br><img src="https://habrastorage.org/webt/-j/bx/kc/-jbxkco1joxnxva7ec8luts-hii.jpeg"><br><br>  Ya tenemos una tuber√≠a de clasificaci√≥n familiar con Arcface.  Recordemos que tenemos una red con la que estamos fingiendo.  Lo congelamos y simplemente calculamos sus incrustaciones en todas las fotos en las que aprendemos nuestra red, y obtenemos las clases de las clases de OpenImages: pel√≠canos, gorriones, autos, personas, etc. OpenImages, que produce puntuaciones similares.  Con BCE, hacemos que la red produzca una distribuci√≥n similar de estos puntajes.  Por lo tanto, por un lado, estamos aprendiendo una nueva tarea (en la parte superior de la imagen), pero tambi√©n hacemos que la red no olvide sus ra√≠ces (en la parte inferior): recuerde las clases que sol√≠a conocer.  Si equilibras correctamente los gradientes en una proporci√≥n condicional de 50/50, esto dejar√° a todos los pel√≠canos en la parte superior y arrojar√° todos los gorriones desde all√≠. <br><br><img src="https://habrastorage.org/webt/vx/kf/ha/vxkfhatx6n6heozx_xpbhgg_zuq.jpeg"><br><br>  Cuando aplicamos esto, obtuvimos un porcentaje completo en el mAP.  Esto es bastante <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo </th><th>  mAP </th></tr><tr><td>  Arcface </td><td>  92,8 </td></tr><tr><td>  + Conocimiento destilado </td><td>  93,8 (+ 1%) </td></tr></tbody></table></div><br>  Entonces, si su red olvida la tarea anterior, entonces trate usando la destilaci√≥n de conocimiento, esto funciona bien. <br><br><h2>  Cabezas adicionales </h2><br>  La idea b√°sica es muy simple.  De nuevo en el ejemplo del reconocimiento facial.  Tenemos un conjunto de personas en el conjunto de datos.  Pero tambi√©n a menudo en los conjuntos de datos hay otras caracter√≠sticas de la cara.  Por ejemplo, qu√© edad, qu√© color de ojos, etc.  Todo esto se puede agregar como un complemento m√°s.  se√±al: ense√±e a los jefes individuales a predecir estos datos.  Por lo tanto, nuestra red recibe una se√±al m√°s diversa y, como resultado, puede ser mejor aprender la tarea principal. <br><br><img src="https://habrastorage.org/webt/43/to/rp/43torpgdsj-cce3akz2pfe3me9a.jpeg"><br><br>  Otro ejemplo: detecci√≥n de colas. <br><br><img src="https://habrastorage.org/webt/im/cj/tk/imcjtk4jdpqwcphgrzjldnckfgq.jpeg"><br><br>  A menudo, en conjuntos de datos con personas, adem√°s del cuerpo, hay una marca separada de la posici√≥n de la cabeza, que, obviamente, se puede usar.  Por lo tanto, agregamos a la red la predicci√≥n del cuadro delimitador de la persona y la predicci√≥n del cuadro delimitador de la cabeza, y obtuvimos un aumento del 0,5% en precisi√≥n (mAP), que es decente.  Y lo m√°s importante: gratis en t√©rminos de rendimiento, porque  en producci√≥n, el cabezal adicional se "desconecta". <br><br><img src="https://habrastorage.org/webt/gl/4y/5l/gl4y5lhjiikvdewhfntr7bdhkwu.jpeg"><br><br><h2>  OCR </h2><br>  Un caso m√°s complejo e interesante es el OCR, ya mencionado anteriormente.  La tuber√≠a est√°ndar es as√≠. <br><br><img src="https://habrastorage.org/webt/i8/nj/dd/i8njddzf7z3ux8wcawjqmjvkyri.jpeg"><br><br>  Que haya un cartel con un ping√ºino, el texto est√° escrito en √©l.  Usando el modelo de detecci√≥n, destacamos este texto.  Adem√°s, alimentamos este texto a la entrada del modelo de reconocimiento, que produce el texto reconocido.  Digamos que nuestra red est√° mal y en lugar de "i" en la palabra ping√ºinos predice "l".  Este es realmente un problema muy com√∫n en OCR cuando la red confunde caracteres similares.  La pregunta es c√≥mo evitar esto: ¬øtraducir ping√ºinos en ping√ºinos?  Cuando una persona mira este ejemplo, es obvio para √©l que esto es un error, porque  √©l tiene conocimiento de la estructura del lenguaje.  Por lo tanto, el conocimiento sobre la distribuci√≥n de caracteres y palabras en el idioma debe estar integrado en el modelo. <br><br>  Usamos una cosa llamada BPE (codificaci√≥n de par de bytes) para esto.  Este es un algoritmo de compresi√≥n que generalmente se invent√≥ en los a√±os 90, no para el aprendizaje autom√°tico, pero ahora es muy popular y se utiliza en el aprendizaje profundo.  El significado del algoritmo es que las subsecuencias que ocurren con frecuencia en el texto se reemplazan con nuevos caracteres.  Supongamos que tenemos la cadena "aaabdaaabac" y queremos obtener un BPE.  Encontramos que el par de caracteres "aa" es el m√°s frecuente en nuestra palabra.  Lo reemplazamos con un nuevo car√°cter "Z", obtenemos la cadena "ZabdZabac".  Repetimos la iteraci√≥n: vemos que ab es la subsecuencia m√°s frecuente, reempl√°cela con "Y", obtenemos la cadena "ZYdZYac".  Ahora "ZY" es la subsecuencia m√°s frecuente, la reemplazamos con "X", obtenemos "XdXac".  Por lo tanto, codificamos algunas dependencias estad√≠sticas en la distribuci√≥n del texto.  Si nos encontramos con una palabra en la que hay subsecuencias muy "extra√±as" (raras para el cuerpo docente), entonces esta palabra es sospechosa. <br><br> <code>aaabdaaabac <br> ZabdZabac Z=aa <br> <font color="#fa7566">ZY</font> d <font color="#fa7566">ZY</font> ac Y=ab <br> <font color="#fa7566">X</font> d <font color="#fa7566">X</font> ac X=ZY</code> <br> <br>  C√≥mo todo encaja en el reconocimiento. <br><br><img src="https://habrastorage.org/webt/zq/fm/1v/zqfm1vzn2szxicl-txouuvguwj0.jpeg"><br><br>  Destacamos la palabra "ping√ºino", la enviamos a la red neuronal convolucional, que produjo incrustaci√≥n espacial (un vector de longitud fija, por ejemplo 512).  Este vector codifica informaci√≥n de s√≠mbolo espacial.  A continuaci√≥n, usamos una red de recurrencia (UPD: de hecho, ya usamos el modelo Transformer), proporciona algunos estados ocultos (barras verdes), en cada uno de los cuales se cose la distribuci√≥n de probabilidad, que, seg√∫n el modelo, el s√≠mbolo se representa en una posici√≥n espec√≠fica.  Luego, usando CTC-Loss, desenrollamos estos estados y obtenemos nuestra predicci√≥n para toda la palabra, pero con un error: L en lugar de i. <br><br><img src="https://habrastorage.org/webt/jc/p4/6k/jcp46k4rb7hz_b18kbbsbgm_aac.jpeg"><br><br>  Ahora integrando BPE en la tuber√≠a.  Queremos alejarnos de la predicci√≥n de caracteres individuales a palabras, por lo que nos separamos de los estados en los que se cose la informaci√≥n sobre los caracteres y establecemos otra red recursiva en ellos;  ella predice BPE.  En el caso del error descrito anteriormente, se obtienen 3 BPE: "peng", "ul", "ns".  Esto difiere significativamente de la secuencia correcta para la palabra ping√ºinos, es decir, pen, gu, ins.  Si observa esto desde el punto de vista del entrenamiento de modelos, entonces, en una predicci√≥n de car√°cter por palabra, la red cometi√≥ un error en solo una de cada ocho letras (error del 12.5%);  y en t√©rminos de BPE, estaba 100% equivocada al predecir los 3 BPE incorrectamente.  Esta es una se√±al mucho m√°s grande para la red de que algo sali√≥ mal y necesita corregir su comportamiento.  Cuando implementamos esto, pudimos corregir errores de este tipo y redujimos la tasa de error de Word en un 0.25%, eso es mucho.  Esta cabeza extra se elimina cuando se hace inferencia, cumpliendo su papel en el entrenamiento. <br><br><h2>  FP16 </h2><br>  Lo √∫ltimo que quer√≠a decir sobre el entrenamiento fue FP16.  Sucedi√≥ hist√≥ricamente que las redes se entrenaron en la GPU con precisi√≥n de unidad, es decir, FP32.  Pero esto es redundante, especialmente para la inferencia, donde la precisi√≥n media (FP16) es suficiente sin p√©rdida de calidad.  Sin embargo, este no es el caso con el entrenamiento. <br><br><img src="https://habrastorage.org/webt/ax/wj/ts/axwjtss6t1hmatnqwhd34s6uztq.jpeg"><br><br>  Si observamos la distribuci√≥n de gradientes, informaci√≥n que actualiza nuestros pesos al propagar errores, veremos que hay un enorme pico en cero.  Y en general, muchos valores est√°n cerca de cero.  Si solo transferimos todos los pesos al FP16, resulta que cortamos el lado izquierdo en la regi√≥n de cero (desde la l√≠nea roja). <br><br><img src="https://habrastorage.org/webt/sv/th/2_/svth2_7cdnkfckg5qvvebpv-bwo.jpeg"><br><br>  Es decir, restableceremos una gran cantidad de gradientes.  Y la parte correcta, en el rango de trabajo FP16, no se utiliza en absoluto.  Como resultado, si entrena la frente en FP16, es probable que el proceso se disperse (el gr√°fico gris en la imagen a continuaci√≥n). <br><br><img src="https://habrastorage.org/webt/nq/n_/20/nqn_20y7f_4auaqespf7pxakuoo.jpeg"><br><br>  Si entrenas usando la t√©cnica de precisi√≥n mixta, el resultado es casi id√©ntico al FP32.  La precisi√≥n mixta implementa dos trucos. <br><br>  Primero: simplemente multiplicamos la p√©rdida por una constante, por ejemplo, 128. Por lo tanto, escalamos todos los gradientes y movemos sus valores de cero al rango de trabajo FP16.  Segundo: almacenamos la versi√≥n maestra de la balanza FP32, que se usa solo para actualizar, y en las operaciones de computaci√≥n de redes de paso hacia adelante y hacia atr√°s, solo se usa FP16. <br><br>  Usamos Pytorch para entrenar redes.  NVIDIA realiz√≥ un ensamblaje especial con el llamado APEX, que implementa la l√≥gica descrita anteriormente.  √âl tiene dos modos.  El primero es la precisi√≥n mixta autom√°tica.  Vea el c√≥digo a continuaci√≥n para ver lo f√°cil que es usarlo. <br><br><img src="https://habrastorage.org/webt/fu/nb/8o/funb8omqcc4yrglue2tlsn9bx14.jpeg"><br><br>  Literalmente, se agregan dos l√≠neas al c√≥digo de capacitaci√≥n que envuelven la p√©rdida y el procedimiento de inicializaci√≥n del modelo y los optimizadores.  ¬øQu√© hace AMP?  √âl mono patch'it todas las funciones.  ¬øQu√© est√° pasando exactamente?  Por ejemplo, √©l ve que hay una funci√≥n de convoluci√≥n, y ella recibe una ganancia de FP16.  Luego lo reemplaza con el suyo, que primero se convierte en FP16, y luego realiza una operaci√≥n de convoluci√≥n.  Entonces AMP lo hace para todas las funciones que se pueden usar en la red.  Para algunos, no lo hace.  No habr√° aceleraci√≥n.  Para la mayor√≠a de las tareas, este m√©todo es adecuado. <br><br>  Segunda opci√≥n: optimizador FP16 para fan√°ticos de control completo.  Adecuado si usted mismo desea especificar qu√© capas estar√°n en FP16 y cu√°les en FP32.  Pero tiene una serie de limitaciones y dificultades.  No comienza con una media patada (al menos tuvimos que sudar para comenzar).  Tambi√©n FP_optimizer funciona solo con Adam, e incluso solo con ese Adam, que est√° en APEX (s√≠, tienen su propio Adam en el repositorio, que tiene una interfaz completamente diferente a Paytorch). <br><br>  Hicimos una comparaci√≥n al aprender sobre las tarjetas Tesla T4. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/go/6c/rqgo6cvrixdwnueh4rczvoooj3m.jpeg"></div><br><br>  En Inference, tenemos la aceleraci√≥n esperada dos veces.  En el entrenamiento, vemos que el marco Apex proporciona una aceleraci√≥n del 20% con FP16 relativamente simple.  Como resultado, tenemos un entrenamiento que es dos veces m√°s r√°pido y consume 2 veces menos memoria, y la calidad del entrenamiento no se ve afectada de ninguna manera.  Freebie <br><br><h2>  Inferencia </h2><br>  Porque  Como usamos PyTorch, la pregunta es con urgencia c√≥mo implementarlo en producci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/6u/vr/qj6uvrpjh44wmvkktkvdoxpfwow.jpeg"></div><br>  Hay 3 opciones sobre c√≥mo hacerlo (y todas las que usamos). <br><br><ul><li>  ONNX -&gt; Caffe2 </li><li>  ONNX -&gt; TensorRT </li><li>  Y m√°s recientemente Pytorch C ++ </li></ul><br>  Veamos cada uno de ellos. <br><br><h2>  ONNX y Caffe2 </h2><br>  ONNX apareci√≥ hace 1,5 a√±os.  Este es un marco especial para convertir modelos entre diferentes marcos.  Y Caffe2 es un marco adyacente a Pytorch, los cuales se est√°n desarrollando en Facebook.  Hist√≥ricamente, Pytorch se est√° desarrollando mucho m√°s r√°pido que Caffe2.  Caffe2 va a la zaga de Pytorch en caracter√≠sticas, por lo que no todos los modelos que entrenaste en Pytorch se pueden convertir a Caffe2.  A menudo tienes que volver a aprender con otras capas.  Por ejemplo, en Caffe2 no existe una operaci√≥n est√°ndar como el muestreo ascendente con la interpolaci√≥n de vecino m√°s cercano.  Como resultado, llegamos a la conclusi√≥n de que para cada modelo obtuvimos una imagen acoplable especial, en la que clavamos las versiones del marco con clavos para evitar discrepancias durante sus futuras actualizaciones, de modo que cuando una de las versiones se actualiza nuevamente, no perdamos tiempo en su compatibilidad .  Todo esto no es muy conveniente y alarga el proceso de implementaci√≥n. <br><br><h2>  Tensor rt </h2><br>  Tambi√©n est√° Tensor RT, un marco NVIDIA que optimiza la arquitectura de red para acelerar la inferencia.  Hicimos nuestras mediciones (en el mapa Tesla T4). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ls/fn/q0/lsfnq0otllhgjqy1gh2lhwufbom.jpeg"></div><br>  Si observa los gr√°ficos, puede ver que la transici√≥n de FP32 a FP16 proporciona una aceleraci√≥n 2x ‚Äã‚Äãen Pytorch, y TensorRT al mismo tiempo proporciona 4x.  Una diferencia muy significativa.  Lo probamos en Tesla T4, que tiene n√∫cleos tensoriales que utilizan muy bien los c√°lculos de FP16, lo que obviamente es excelente en TensorRT.  Por lo tanto, si hay un modelo altamente cargado que se ejecuta en docenas de tarjetas gr√°ficas, entonces todos son motivadores para probar Tensor RT. <br><br>  Sin embargo, cuando se trabaja con TensorRT hay incluso m√°s dolor que en Caffe2: las capas son a√∫n menos compatibles.  Desafortunadamente, cada vez que usamos este marco, tenemos que sufrir un poco para convertir el modelo.  Pero para modelos muy cargados, tienes que hacer esto.  ;) Observo que en los mapas sin n√∫cleos tensoriales no se observa un aumento tan masivo. <br><br><h2>  Pytorch C ++ </h2><br>  Y el √∫ltimo es Pytorch C ++.  Hace seis meses, los desarrolladores de Pytorch se dieron cuenta del dolor de las personas que usan su marco y lanzaron el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tutorial de TorchScript</a> , que le permite rastrear y serializar el modelo de Python en un gr√°fico est√°tico sin gestos innecesarios (JIT).  Fue lanzado en diciembre de 2018, de inmediato comenzamos a usarlo, inmediatamente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">detectamos</a> algunos errores de rendimiento y esperamos varios meses para que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Chintala lo reparara</a> .  Pero ahora es una tecnolog√≠a bastante estable, y la estamos utilizando activamente para todos los modelos.  Lo √∫nico es la falta de documentaci√≥n, que se complementa activamente.  Por supuesto, siempre puedes mirar archivos * .h, pero para las personas que no conocen las ventajas, es dif√≠cil.  Pero luego hay un trabajo realmente id√©ntico con Python.  En C ++, el c√≥digo j se ejecuta en un int√©rprete m√≠nimo de Python, que pr√°cticamente garantiza la identidad de C ++ con Python. <br><br><h2>  Conclusiones </h2><br><ul><li>  La declaraci√≥n del problema es s√∫per importante.  Debe comunicarse con los gerentes de producto sobre los datos.  Antes de comenzar a realizar la tarea, es recomendable tener un conjunto de pruebas listo para usar en el que medimos las m√©tricas finales antes de la etapa de implementaci√≥n. <br></li><li>  Limpiamos los datos nosotros mismos con la ayuda de la agrupaci√≥n.  Obtenemos el modelo en los datos de origen, limpiamos los datos utilizando el cl√∫ster CLink y repetimos el proceso hasta la convergencia. <br></li><li>  Aprendizaje m√©trico: incluso la clasificaci√≥n ayuda.  Estado del arte: ArcFace, que es f√°cil de integrar en el proceso de aprendizaje. <br></li><li>  Si transfiere el aprendizaje de una red previamente capacitada, para que la red no olvide la tarea anterior, utilice la destilaci√≥n de conocimiento. <br></li><li>  Tambi√©n es √∫til usar varios cabezales de red que utilizar√°n diferentes se√±ales de los datos para mejorar la tarea principal. <br></li><li>  Para FP16, debe usar los ensamblajes Apex de NVIDIA, Pytorch. <br></li><li>  Y, por inferencia, es conveniente usar Pytorch C ++. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/460307/">https://habr.com/ru/post/460307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../460291/index.html">Problemas de procesamiento por lotes de solicitudes y sus soluciones (parte 1)</a></li>
<li><a href="../460295/index.html">¬øQu√© significa inseguro en Rust?</a></li>
<li><a href="../460297/index.html">WeakRef - propuesta para agregar al est√°ndar ECMAScript</a></li>
<li><a href="../460301/index.html">L√°mparas LED de alta potencia de nueva generaci√≥n.</a></li>
<li><a href="../460305/index.html">AERODISCO Motor: catastr√≥fico. Parte 2. Metrocluster</a></li>
<li><a href="../460311/index.html">Hora de una nueva teor√≠a del dinero.</a></li>
<li><a href="../460313/index.html">¬øLas diferentes canciones de √©xito tienen algo en com√∫n?</a></li>
<li><a href="../460319/index.html">Caza de inspectores espaciales</a></li>
<li><a href="../460321/index.html">Galer√≠a de los mejores cuadernos ML y Data Science</a></li>
<li><a href="../460329/index.html">No el FEDOR, pero el Skybot F-850 volar√° a la ISS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
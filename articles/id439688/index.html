<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👶🏾 💃🏾 👩🏿‍🤝‍👨🏼 Ikhtisar solusi AI & ML pada 2018 dan perkiraan untuk 2019: Bagian 1 - NLP, Computer Vision ⛹️ 👩‍🏭 👨‍🔬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya! Saya mempersembahkan untuk Anda terjemahan artikel Vidhya Analytics dengan ikhtisar acara AI / ML pada tren 2018 dan 2019. Bahannya cuk...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ikhtisar solusi AI & ML pada 2018 dan perkiraan untuk 2019: Bagian 1 - NLP, Computer Vision</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439688/"><blockquote> Halo semuanya!  Saya mempersembahkan untuk Anda terjemahan artikel <i>Vidhya Analytics</i> dengan ikhtisar acara AI / ML pada tren 2018 dan 2019.  Bahannya cukup besar, sehingga dibagi menjadi 2 bagian.  Saya harap artikel ini akan menarik minat tidak hanya spesialis spesialis, tetapi juga mereka yang tertarik dengan topik AI.  Selamat membaca! <br><br><div class="spoiler">  <b class="spoiler_title">Navigasi artikel</b> <div class="spoiler_text">  <b>Bagian 1</b> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pemrosesan Bahasa Alami (NLP)</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">NLP Trends untuk 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Visi komputer</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tren dalam visi mesin untuk 2019</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 2</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Alat dan perpustakaan</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tren AutoML untuk 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pembelajaran Penguatan</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tren Pembelajaran Penguatan untuk 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AI untuk anak laki-laki yang baik - gerakan menuju AI "etis"</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tren etis dalam AI untuk 2019</a> <br></div></div></blockquote><br><h2>  Pendahuluan </h2><br>  Beberapa tahun terakhir untuk penggemar AI dan profesional pembelajaran mesin telah berlalu dalam mengejar mimpi.  Teknologi ini telah berhenti menjadi ceruk, telah menjadi arus utama dan sudah mempengaruhi kehidupan jutaan orang saat ini.  Kementerian AI dibuat di berbagai negara [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lebih detail di sini</a> - kira-kira.  per.] dan anggaran dialokasikan untuk mengikuti lomba ini. <br><br>  Hal yang sama berlaku untuk para profesional ilmu data.  Beberapa tahun yang lalu, Anda bisa merasa nyaman mengetahui beberapa alat dan trik, tetapi kali ini telah berlalu.  Jumlah peristiwa terkini dalam ilmu data dan jumlah pengetahuan yang diperlukan untuk mengikuti perkembangan di bidang ini luar biasa. <br><br>  Saya memutuskan untuk mengambil langkah mundur dan melihat perkembangan di beberapa bidang utama di bidang kecerdasan buatan dari sudut pandang para pakar ilmu data.  Berjerawat apa yang telah terjadi?  Apa yang terjadi pada 2018 dan apa yang diharapkan pada 2019?  Baca artikel ini untuk mendapat jawaban! <a name="habracut"></a><br><br>  NB Seperti dalam ramalan apa pun, di bawah ini adalah kesimpulan pribadi saya yang didasarkan pada upaya untuk menggabungkan setiap fragmen ke dalam keseluruhan gambar.  Jika sudut pandang Anda berbeda dari saya, saya akan senang mengetahui pendapat Anda tentang apa lagi yang mungkin berubah dalam ilmu data pada tahun 2019. <br><br>  Area yang akan kita bahas dalam artikel ini adalah: <br><br>  - Proses Bahasa Alami (NLP) <br>  - Visi komputer <br>  - Alat dan perpustakaan <br>  - Pembelajaran Penguatan <br>  - Masalah etika dalam AI <br><br><a name="NLP"></a><h2>  Pemrosesan Bahasa Alami (NLP) </h2><br>  Memaksa mesin untuk menguraikan kata dan kalimat selalu tampak seperti mimpi pipa.  Ada banyak nuansa dan fitur dalam bahasa yang terkadang sulit dipahami bahkan untuk orang-orang, tetapi 2018 adalah titik balik nyata bagi NLP. <br><br>  Kami menyaksikan satu terobosan luar biasa: ULMFiT, ELMO, OpenAl Transformer, Google BERT, dan ini bukan daftar lengkap.  Aplikasi pembelajaran transfer yang berhasil (seni menerapkan model pra-terlatih untuk data) telah membuka pintu bagi NLP dalam berbagai tugas. <br><blockquote>  Transfer pembelajaran - memungkinkan Anda untuk mengadaptasi model / sistem yang sudah dilatih sebelumnya untuk tugas spesifik Anda menggunakan jumlah data yang relatif kecil. </blockquote>  Mari kita lihat beberapa perkembangan penting ini secara lebih rinci. <br><br><h3>  ULMFiT </h3><br>  Dikembangkan oleh Sebastian Ruder dan Jeremy Howard (fast.ai), ULMFiT adalah kerangka kerja pertama yang menerima pembelajaran transfer tahun ini.  Untuk yang belum tahu, singkatan ULMFiT adalah singkatan dari “Universal Language Model Fine-Tuning”.  Jeremy dan Sebastian secara sah menambahkan kata "universal" ke ULMFiT - kerangka kerja ini dapat diterapkan untuk hampir semua tugas NLP! <br><br>  Hal terbaik tentang ULMFiT adalah Anda tidak perlu melatih model dari awal!  Para peneliti telah melakukan yang paling sulit bagi Anda - ambil dan terapkan dalam proyek Anda.  ULMFiT mengungguli metode lain dalam enam tugas klasifikasi teks. <br><br>  Anda dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">membaca</a> tutorial oleh Pratek Joshi [Pateek Joshi - kira-kira.  trans.] tentang cara mulai menggunakan ULMFiT untuk tugas klasifikasi teks apa pun. <br><br><h3>  ELMo </h3><br>  Coba tebak apa arti singkatan ELMo?  Akronim untuk Embeddings dari Model Bahasa [lampiran dari model bahasa - kira-kira.  trans.].  Dan ELMo menarik perhatian komunitas ML setelah rilis. <br><br>  ELMo menggunakan model bahasa untuk menerima lampiran untuk setiap kata, dan juga memperhitungkan konteks di mana kata tersebut cocok dengan kalimat atau paragraf.  Konteks adalah aspek kritis NLP, di mana sebagian besar pengembang sebelumnya gagal.  ELMo menggunakan LSTM dua arah untuk membuat lampiran. <br><blockquote>  Memori jangka pendek (LSTM) adalah jenis arsitektur jaringan saraf berulang yang diusulkan pada tahun 1997 oleh Sepp Hochreiter dan Jürgen Schmidhuber.  Seperti kebanyakan jaringan saraf berulang, jaringan LSTM bersifat universal dalam arti bahwa, dengan jumlah elemen jaringan yang cukup, dapat melakukan perhitungan apa pun yang dapat dilakukan oleh komputer biasa, yang membutuhkan matriks bobot yang sesuai yang dapat dianggap sebagai program.  Tidak seperti jaringan saraf berulang tradisional, jaringan LSTM sangat cocok untuk pelatihan tentang masalah mengklasifikasikan, memproses, dan memprediksi deret waktu dalam kasus-kasus di mana peristiwa-peristiwa penting dipisahkan oleh jeda waktu dengan durasi dan batas yang tidak terbatas. <br><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sumber.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Wikipedia</a> </blockquote>  Seperti ULMFiT, ELMo secara signifikan meningkatkan produktivitas dalam menyelesaikan sejumlah besar tugas NLP, seperti menganalisis suasana teks atau menjawab pertanyaan. <br><br><h3>  BERT dari Google </h3><br>  Cukup banyak ahli mencatat bahwa rilis BERT menandai awal era baru di NLP.  Mengikuti ULMFiT dan ELMo, BERT memimpin, menunjukkan kinerja tinggi.  Seperti yang dinyatakan oleh pengumuman aslinya: "BERT secara konseptual sederhana dan kuat secara empiris." <br><br>  BERT telah menunjukkan hasil luar biasa dalam 11 tugas NLP!  Lihat hasil dalam tes SQuAD: <br><br><img src="https://habrastorage.org/webt/rf/6n/cz/rf6nczjjvbcz1cg4nxfeo-lm7ou.png"><br><br>  Mau mencobanya?  Anda dapat menggunakan implementasi ulang di PyTorch, atau kode TensorFlow dari Google dan mencoba mengulang hasilnya di mesin Anda. <br><br><h3>  Facebook PyText </h3><br>  Bagaimana Facebook bisa menjauh dari balapan ini?  Perusahaan ini menawarkan kerangka kerja NLP open-source miliknya yang disebut PyText.  Menurut sebuah penelitian yang diterbitkan oleh Facebook, PyText meningkatkan keakuratan model percakapan sebesar 10% dan mengurangi waktu pelatihan. <br><br>  PyText sebenarnya di belakang beberapa produk Facebook sendiri, seperti Messenger.  Jadi bekerja dengannya akan menambah poin bagus untuk portofolio Anda dan pengetahuan yang tak ternilai yang pasti akan Anda dapatkan. <br><br>  Anda dapat mencobanya sendiri, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">unduh kode dari GitHub</a> . <br><br><h3>  Google duplex </h3><br>  Sulit dipercaya bahwa Anda belum pernah mendengar tentang Google Duplex.  Berikut ini adalah demo yang telah lama dimuat dalam berita utama: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NO0-5MuJvew" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Karena ini adalah produk Google, ada sedikit kemungkinan bahwa cepat atau lambat kode akan dipublikasikan kepada semua orang.  Tentu saja, demonstrasi ini menimbulkan banyak pertanyaan: dari masalah etika hingga privasi, tetapi kita akan membicarakannya nanti.  Untuk saat ini, nikmati saja sejauh mana kami telah mencapai ML dalam beberapa tahun terakhir. <br><br><a name="NLPtrends"></a><h2>  Tren NLP 2019 </h2><br>  Siapa yang lebih baik dari Sebastian Ruder sendiri yang bisa memberikan gambaran tentang ke mana NLP menuju 2019?  Berikut ini adalah temuannya: <br><blockquote><ol><li>  Penggunaan model investasi bahasa pra-terlatih akan semakin meluas;  model canggih tanpa dukungan akan sangat jarang. </li><li>  Tampilan pra-terlatih akan muncul yang dapat menyandikan informasi khusus yang melengkapi lampiran model bahasa.  Kami akan dapat mengelompokkan berbagai jenis presentasi pra-terlatih tergantung pada persyaratan tugas. </li><li>  Lebih banyak pekerjaan akan muncul di bidang aplikasi multibahasa dan model multibahasa.  Secara khusus, dengan bergantung pada penyisipan kata dalam bahasa antarbahasa, kita akan melihat kemunculan representasi antar bahasa dalam pra-terlatih. </li></ol></blockquote><a name="cv"></a><h2>  Visi komputer </h2><br><img src="https://habrastorage.org/webt/pu/aj/_c/puaj_c89feaiultos4yynrcj7x4.jpeg"><br><br>  Saat ini, visi komputer adalah bidang yang paling populer di bidang pembelajaran yang mendalam.  Tampaknya buah pertama dari teknologi telah diperoleh dan kami berada pada tahap pengembangan aktif.  Terlepas dari apakah ini gambar atau video, kami melihat munculnya banyak kerangka kerja dan perpustakaan yang dengan mudah memecahkan masalah penglihatan komputer. <br><br>  Berikut adalah daftar solusi terbaik yang dapat dilihat tahun ini. <br><br><h3>  BigGANs Out </h3><br>  Ian Goodfellow merancang GAN pada tahun 2014, dan konsep ini melahirkan berbagai macam aplikasi.  Tahun demi tahun, kami mengamati bagaimana konsep asli diselesaikan untuk digunakan pada kasus nyata.  Tapi satu hal tetap tidak berubah sampai tahun ini - gambar yang dihasilkan komputer terlalu mudah dibedakan.  Inkonsistensi tertentu selalu muncul dalam bingkai, yang membuat perbedaannya sangat jelas. <br><br>  Dalam beberapa bulan terakhir, pergeseran telah muncul ke arah ini, dan, dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penciptaan BigGAN</a> , masalah seperti itu dapat diselesaikan sekali dan untuk semua.  Lihatlah gambar yang dihasilkan oleh metode ini: <br><br><img src="https://habrastorage.org/webt/mo/w7/ow/mow7owldedw4r1jtwex6wbfwwje.png"><br><br>  Tanpa mikroskop, sulit untuk mengatakan apa yang salah dengan gambar-gambar ini.  Tentu saja, semua orang akan memutuskan sendiri, tetapi tidak ada keraguan bahwa GAN mengubah cara kita memandang gambar digital (dan video). <br><br>  Untuk referensi: model ini pertama kali dilatih pada dataset ImageNet, dan kemudian pada JFT-300M untuk menunjukkan bahwa model ini ditransfer dengan baik dari satu dataset ke yang lain.  Berikut ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ke halaman</a> dari milis GAN yang menjelaskan cara memvisualisasikan dan memahami GAN. <br><br><h3>  Model Fast.ai dilatih di ImageNet dalam 18 menit </h3><br>  Ini adalah implementasi yang sangat keren.  Ada kepercayaan luas bahwa, untuk melakukan tugas-tugas pembelajaran yang mendalam, Anda akan membutuhkan terabyte data dan sumber daya komputasi yang besar.  Hal yang sama berlaku untuk melatih model dari awal pada data ImageNet.  Sebagian besar dari kita berpikir dengan cara yang sama sebelum beberapa orang berpuasa. <br><br>  Model mereka memberikan akurasi 93% dengan 18 menit mengesankan.  Perangkat keras yang mereka gunakan, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dijelaskan</a> secara rinci <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di blog mereka</a> , terdiri dari 16 instance cloud AWS publik, masing-masing dengan 8 GPU NVIDIA V100.  Mereka membangun sebuah algoritma menggunakan perpustakaan fast.ai dan PyTorch. <br><br>  Total biaya perakitan hanya $ 40!  Jeremy menggambarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pendekatan dan metode mereka</a> secara lebih rinci di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Ini adalah kemenangan bersama! <br><br><h3>  vid2vid dari NVIDIA </h3><br>  Selama 5 tahun terakhir, pemrosesan gambar telah membuat langkah besar, tetapi bagaimana dengan video?  Metode untuk mengkonversi dari bingkai statis ke yang dinamis ternyata sedikit lebih rumit dari yang diharapkan.  Bisakah Anda mengambil urutan frame dari video dan memprediksi apa yang akan terjadi di frame berikutnya?  Studi semacam itu telah dilakukan sebelumnya, tetapi publikasi tidak jelas. <br><br><img src="https://habrastorage.org/webt/hz/ox/hj/hzoxhjbehlnlzl8ivc-bgiz0vh0.png"><br><br>  NVIDIA memutuskan untuk membuat keputusannya untuk publik awal tahun ini [2018 - kira-kira.  per.], yang secara positif dievaluasi oleh masyarakat.  Tujuan vid2vid adalah untuk memperoleh fungsi tampilan dari video input yang diberikan untuk membuat video output yang mentransmisikan konten video input dengan akurasi luar biasa. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/S1OwOd-war8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Anda dapat mencoba implementasinya di PyTorch, bawa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ke GitHub di sini</a> . <br><br><a name="cvtrends"></a><h2>  Tren Visi Mesin untuk 2019 </h2><br>  Seperti yang saya sebutkan sebelumnya, pada 2019 kita lebih cenderung melihat perkembangan tren 2018, daripada terobosan baru: mobil self-driving, algoritma pengenalan wajah, realitas virtual dan banyak lagi.  Bisakah Anda tidak setuju dengan saya jika Anda memiliki sudut pandang atau penambahan yang berbeda, berbagi dengan kami, apa lagi yang bisa kami harapkan di tahun 2019? <br><br>  Masalah drone, sambil menunggu persetujuan politisi dan pemerintah, akhirnya mungkin mendapatkan lampu hijau di Amerika Serikat (India jauh tertinggal dalam hal ini).  Secara pribadi, saya ingin lebih banyak penelitian dilakukan dalam skenario dunia nyata.  Konferensi seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CVPR</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ICML memberikan</a> cakupan yang baik dari pencapaian terbaru di bidang ini, tetapi seberapa dekat proyek dengan kenyataan tidak terlalu jelas. <br><br>  "Menjawab pertanyaan visual" dan "sistem dialog visual" akhirnya mungkin muncul dengan debut yang telah lama ditunggu-tunggu.  Sistem ini tidak memiliki kemampuan untuk menggeneralisasi, tetapi diharapkan bahwa kita akan segera melihat pendekatan multimodal yang terintegrasi. <br><br><img src="https://habrastorage.org/webt/s5/bn/uy/s5bnuydmsc8hf37vm26icbmwrgc.jpeg"><br><br>  Latihan mandiri datang ke permukaan tahun ini.  Saya bertaruh bahwa tahun depan ia akan menemukan aplikasi dalam jumlah studi yang jauh lebih besar.  Ini adalah arah yang sangat keren: tanda ditentukan langsung dari input data, daripada membuang waktu secara manual menandai gambar.  Mari jaga agar jari kita saling bersilang! <br><br><h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Baca selengkapnya: Bagian 2 - Alat dan Perpustakaan, AutoML, Pembelajaran Penguatan, Etika dalam AI</a> </h4></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id439688/">https://habr.com/ru/post/id439688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id439676/index.html">Bereaksi Integrasi Asli dan C ++ untuk iOS dan Android</a></li>
<li><a href="../id439678/index.html">Kirim ke Tantangan F # Terapan</a></li>
<li><a href="../id439680/index.html">Sekitar 50% orang Rusia bersedia menjual data pribadi mereka</a></li>
<li><a href="../id439682/index.html">Pelatihan Cisco 200-125 CCNA v3.0. Cisco Certified Network Specialist (CCNA). Hari 4. Perangkat Gateway</a></li>
<li><a href="../id439684/index.html">Terapkan untuk Tantangan F # Terapan</a></li>
<li><a href="../id439690/index.html">Perbandingan kinerja mesin virtual dari 6 platform cloud: Selectel, MCS, I. Cloud, Google Cloud, AWS dan Azure</a></li>
<li><a href="../id439692/index.html">AT&T dituntut karena mengubah ikon jaringan dari 4G ke 5G E</a></li>
<li><a href="../id439694/index.html">Jaringan pintar responsif terhadap perubahan suhu tubuh</a></li>
<li><a href="../id439696/index.html">Di puncak gelombang, atau "Saya ingin arus utama" - tetapi apakah itu layak?</a></li>
<li><a href="../id439698/index.html">Pengantar pemrograman: penembak 3D sederhana dari awal selama akhir pekan, bagian 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
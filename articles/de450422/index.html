<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍶 💕 🙋 Die Einschränkungen von Bilderkennungsalgorithmen 🏅 ⛏️ 🕺🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nein, es geht nicht um Bilderkennungsalgorithmen, sondern um die Einschränkungen ihrer Verwendung, insbesondere beim Erstellen von KI. 

 Meiner Meinu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Einschränkungen von Bilderkennungsalgorithmen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450422/"><img src="https://habrastorage.org/webt/wv/6j/k6/wv6jk6e24vdagqflmeorpmhjg-0.jpeg"><br><br>  Nein, es geht nicht um Bilderkennungsalgorithmen, sondern um die Einschränkungen ihrer Verwendung, insbesondere beim Erstellen von KI. <br><br>  Meiner Meinung nach ist die Erkennung visueller Bilder durch eine Person und ein Computersystem sehr unterschiedlich - so sehr, dass es wenig gemeinsam hat.  Wenn eine Person „Ich sehe“ sagt, denkt sie tatsächlich mehr als sie sieht, was nicht über ein Computersystem gesagt werden kann, das mit Geräten zur Bilderkennung ausgestattet ist. <br><br>  Ich weiß, dass die Idee nicht neu ist, aber ich schlage noch einmal vor, ihre Gültigkeit am Beispiel eines Roboters sicherzustellen, der behauptet, Intelligenz zu besitzen.  Die Testfrage lautet: Welche Art von Roboter sollte die umliegende Welt sehen, um vollständig wie eine Person zu werden? <br><a name="habracut"></a><br>  Natürlich muss der Roboter Objekte erkennen.  Oh ja, die Algorithmen kommen damit zurecht - durch Training an den Originalproben, wie ich es verstehe.  Aber das ist katastrophal klein! <br><br>  <b>I.</b> <br>  Erstens besteht jedes Objekt der umgebenden Welt aus vielen Objekten und ist wiederum eine Teilmenge anderer Objekte.  Ich nenne diese Eigenschaft Verschachtelung.  Was aber, wenn ein Subjekt einfach keinen Namen hat und sich nicht auf der Basis der Originalproben befindet, die zum Erlernen des Algorithmus verwendet wurden - was sollte der Roboter in diesem Fall erkennen? <br><br>  Die Wolke, die ich gerade im Fenster beobachte, hat keine benannten Teile, obwohl sie offensichtlich aus Kanten und einer Mitte besteht.  Es gibt jedoch keine speziellen Begriffe für die Kanten und die Mitte der Wolke, die nicht geprägt sind.  Um ein unbenanntes Objekt anzuzeigen, habe ich eine verbale Formulierung ("Wolke" - Objekttyp, "Wolkenkante" - verbale Formulierung) verwendet, die nicht in den Funktionen des Bilderkennungsalgorithmus enthalten ist. <br><br>  Es stellt sich heraus, dass ein Algorithmus ohne logischen Block wenig nützlich ist.  Wenn der Algorithmus einen Teil des gesamten Objekts erkennt, kann er nicht immer herausfinden - dementsprechend kann der Roboter nicht sagen, was es ist. <br><br>  <b>II.</b> <br>  Zweitens wird die Liste der Objekte, aus denen die Welt besteht, nicht geschlossen, sondern ständig aktualisiert. <br><br>  Eine Person hat die Fähigkeit, Objekte der Realität zu konstruieren und neu entdeckten Objekten, beispielsweise Tierarten, Namen zuzuweisen.  Er wird ein Pferd mit einem menschlichen Kopf und Torso einen Zentauren nennen, aber dafür wird zunächst verstanden, dass die Kreatur einen menschlichen Kopf und Torso hat und alles andere pferdeartig ist, wodurch das Objekt als neues erkannt wird.  Das macht das menschliche Gehirn.  Und wenn keine Eingabedaten vorliegen, bestimmt der Algorithmus eine solche Kreatur entweder als Person oder als Pferd: Ohne die Arbeit mit Typmerkmalen kann er ihre Kombination nicht ermitteln. <br><br>  Damit ein Roboter wie ein Mensch wird, muss er in der Lage sein, neue Objekttypen für ihn zu definieren und diesen Typen Namen zuzuweisen.  In den Beschreibungen des neuen Typs sollten Merkmale bekannter Typen erscheinen.  Und wenn der Roboter nicht weiß wie, warum um alles in der Welt brauchen wir ihn so schön? <br><br>  Nehmen wir an, wir schicken einen Aufklärungsroboter zum Mars.  Ein Roboter sieht etwas Ungewöhnliches, kann aber ein Objekt ausschließlich in irdischen Begriffen identifizieren, die ihm bekannt sind.  Was wird dies den Menschen geben, die verbale Nachrichten hören, die vom Roboter kommen?  Manchmal gibt es natürlich etwas (wenn Erdobjekte auf dem Mars gefunden werden) und in anderen Fällen nichts (wenn die Marsobjekte den Erdobjekten nicht ähnlich sind). <br><br>  Das Bild ist eine andere Sache: Eine Person selbst kann alles sehen, richtig bewerten und benennen.  Nur durch keinen vorab trainierten Bilderkennungsalgorithmus, sondern durch Ihr schlauer konstruiertes menschliches Gehirn. <br><br>  <b>III.</b> <br>  Drittens gibt es ein Problem bei der Individualisierung von Objekten. <br><br>  Die Welt besteht aus bestimmten Objekten.  Eigentlich können Sie nur bestimmte Objekte sehen.  In einigen Fällen müssen sie jedoch verbal individualisiert werden, wobei entweder persönliche Namen verwendet werden ("Vasya Petrov") oder eine einfache Angabe eines bestimmten Objekts, ausgesprochen oder impliziert ("diese Tabelle").  Was ich Objekttypen („Personen“, „Tabellen“) nenne, sind nur Sammelnamen von Objekten, die bestimmte gemeinsame Merkmale aufweisen. <br><br>  Bilderkennungsalgorithmen können, wenn sie an den Originalproben trainiert werden, sowohl individualisierte als auch nicht individualisierte Objekte erkennen - das ist gut.  Gesichtserkennung an überfüllten Orten und so weiter.  Das Schlimme ist, dass solche Algorithmen nicht verstehen, welche Objekte als individualistisch erkannt werden sollten und welche absolut nicht wert sind. <br><br>  Der Roboter als Besitzer der KI sollte gelegentlich in Nachrichten wie: <br>  <i>- Oh, und ich habe diese alte Frau vor einer Woche gesehen!</i> <br><br>  Es lohnt sich jedoch nicht, solche Nachbildungen von Grashalmen zu missbrauchen, zumal begründete Befürchtungen bestehen, dass die Rechenleistung für eine solche Aufgabe ausreicht. <br><br>  Mir ist nicht klar, wo die feine Linie zwischen einer individualisierten alten Frau und unzähligen Grashalmen gezogen wird, die von nicht weniger als einer alten Frau individualisiert werden, aber unter dem Gesichtspunkt der Individualisierung für eine Person nicht von Interesse sind.  Was ist das erkannte Bild in diesem Sinne?  Fast nichts - der Beginn einer schwierigen bis schmerzhaften Wahrnehmung der umgebenden Realität. <br><br>  <b>IV.</b> <br>  Viertens die Dynamik von Objekten, die durch ihre gegenseitige räumliche Anordnung bestimmt wird.  Das ist etwas, sage ich dir! <br><br>  Ich sitze in einem tiefen Sessel vor dem Kamin und versuche jetzt aufzustehen. <br>  <i>"Was siehst du, Roboter?"</i> <br><br>  Aus unserer alltäglichen Sicht sieht der Roboter mich von einem Stuhl aufstehen.  Was soll er antworten?  Wahrscheinlich wäre die relevante Antwort: <br>  <i>"Ich sehe dich von deinem Stuhl aufstehen."</i> <br><br>  Dazu muss der Roboter wissen, wer ich bin, was ein Stuhl ist und was es bedeutet, sich zu erheben ... <br><br>  Der Bilderkennungsalgorithmus kann mich und den Stuhl nach entsprechenden Einstellungen erkennen. Durch Vergleichen der Rahmen können wir dann feststellen, dass ich mich gegenseitig vom Stuhl entferne. Aber was bedeutet es, sich zu erheben?  Wie geschieht „Erhebung“ in der physischen Realität? <br><br>  Wenn ich schon aufgestanden bin und weggegangen bin, ist alles ganz einfach.  Nachdem ich mich vom Stuhl entfernt hatte, änderten alle Objekte im Büro nicht die räumliche Position relativ zueinander, mit Ausnahme von mir, der ursprünglich auf dem Stuhl saß und nach einiger Zeit vom Stuhl entfernt war.  Es ist zulässig zu schließen, dass ich den Stuhl verlassen habe. <br><br>  Wenn ich noch vom Stuhl aufstehe, ist alles etwas komplizierter.  Ich bin immer noch neben dem Stuhl, aber die relative räumliche Position der Körperteile hat sich geändert: <br><br><ul><li>  anfangs befanden sich Tibia und Rumpf in aufrechter Position und der Oberschenkel in horizontaler Position (ich saß), </li><li>  Im nächsten Moment befanden sich alle Körperteile in aufrechter Position (ich stand auf). </li></ul><br>  Beobachten Sie mein Verhalten als Person, er wird sofort zu dem Schluss kommen, dass ich von einem Stuhl aufstehe.  Für einen Menschen ist dies weniger eine logische Schlussfolgerung als eine visuelle Wahrnehmung: Er wird mich buchstäblich von meinem Stuhl aufstehen sehen, obwohl er tatsächlich eine Veränderung der relativen Position von Teilen meines Körpers sehen wird.  In Wirklichkeit ist es jedoch eine logische Schlussfolgerung, die jemand dem Roboter erklären muss, oder der Roboter muss diese logische Schlussfolgerung selbst herausarbeiten. <br><br>  Beide sind gleich schwierig: <br><br><ul><li>  In die anfängliche Wissensbasis einzugeben, dass das Aufstehen eine sequentielle Änderung der gegenseitigen räumlichen Position bestimmter Körperteile ist, ist irgendwie nicht inspirierend. </li><li>  Es ist nicht weniger dumm zu hoffen, dass der Roboter als künstliches denkendes Wesen selbst schnell erraten wird, dass die oben beschriebene Änderung der gegenseitigen räumlichen Position bestimmter Körperteile als Stehen bezeichnet wird.  Beim Menschen dauert dieser Prozess Jahre. Wie viel braucht ein Roboter? </li></ul><br>  Und was haben die Bilderkennungsalgorithmen damit zu tun?  Sie werden niemals feststellen können, dass ich von einem Stuhl aufstehe. <br><br>  <b>V. V.</b> <br>  "Aufstehen" ist ein abstraktes Konzept, das durch eine Änderung der Eigenschaften materieller Objekte bestimmt wird, in diesem Fall durch eine Änderung ihrer gegenseitigen räumlichen Position.  Im allgemeinen Fall gilt dies für alle abstrakten Konzepte, da abstrakte Konzepte selbst nicht in der materiellen Welt existieren, sondern vollständig von materiellen Objekten abhängig sind.  Obwohl wir sie oft als persönlich beobachtet wahrnehmen. <br><br>  Den Kiefer nach rechts oder links bewegen, ohne den Mund zu öffnen - wie heißt diese Aktion?  Aber auf keinen Fall.  Zweifellos aus dem Grund, dass eine solche Bewegung für eine Person im Allgemeinen untypisch ist.  Mit den besprochenen Algorithmen wird der Roboter etwas sehen, aber worum geht es?  In der Basis der anfänglichen Proben fehlt der gewünschte Name, und es ist schwierig, die aufgezeichnete Aktion des Roboters zu benennen.  Und um unbenannten Aktionen sowie anderen abstrakten Konzepten detaillierte verbale Formulierungen zu geben, werden Bilderkennungsalgorithmen nicht trainiert. <br><br>  Tatsächlich haben wir ein Duplikat des ersten Absatzes, nicht nur in Bezug auf Objekte, sondern auch in Bezug auf abstrakte Konzepte.  Der Rest der vorherigen und nächsten Absätze kann jedoch auch mit abstrakten Konzepten verknüpft werden. Ich achte nur darauf, die Komplexität bei der Arbeit mit Abstraktionen zu erhöhen. <br><br>  <b>VI.</b> <br>  Sechstens ein Kausalzusammenhang. <br><br>  Stellen Sie sich vor, Sie beobachten einen Pickup, der von der Straße fliegt und einen Zaun abreißt.  Der Grund, warum der Zaun abgerissen wird, ist die Aufnahmebewegung, und die Aufnahmebewegung führt wiederum zum Abriss des Zauns. <br><br>  <i>- Ich habe es mit eigenen Augen gesehen!</i> <br>  Dies ist die Antwort auf die Frage, ob Sie gesehen haben, was passiert ist oder daran gedacht haben.  Und was hast du eigentlich gesehen? <br><br>  Einige Punkte in einer solchen Dynamik: <br><br><ul><li>  Ein Pickup fuhr von der Straße ab </li><li>  Pickup kam nahe an den Zaun, </li><li>  Der Zaun hat Form und Lage geändert. </li></ul><br>  Aufgrund der visuellen Wahrnehmung muss der Roboter erkennen, dass sich die Zäune im Normalfall nicht in Form und Position ändern. Hier geschah dies durch Kontakt mit dem Pickup.  Die Subjektursache und die Subjektwirkung müssen miteinander in Kontakt stehen, sonst fehlt in ihrer Beziehung die Kausalität. <br><br>  Obwohl wir hier in eine logische Falle geraten, weil andere Objekte mit der Subjekt-Konsequenz in Kontakt treten können, nicht nur mit dem Subjekt-Grund. <br><br>  Angenommen, zum Zeitpunkt der Abholung schlagen Sie die Dohle auf dem Zaun.  Ein Pickup und eine Dohle hatten gleichzeitig Kontakt mit dem Zaun: Wie kann man feststellen, bei welchem ​​Kontakt der Zaun abgerissen wurde? <br><br>  Wahrscheinlich mit Wiederholbarkeit: <br><br><ul><li>  Wenn in jedem Fall, wenn eine Dohle auf dem Zaun sitzt, der Zaun abgerissen wird, ist die Dohle schuld; </li><li>  Wenn in jedem Fall ein Pickup gegen den Zaun stößt, ist der Pickup schuld. </li></ul><br>  Die Schlussfolgerung, dass der Zaun durch einen Pickup abgerissen wurde, ist also nicht gerade eine Beobachtung, sondern das Ergebnis einer Analyse, die auf der Beobachtung von Objekten in Kontakt basiert. <br><br>  Andererseits kann die Wirkung in einer Entfernung ausgeführt werden, beispielsweise die Wirkung eines Magneten auf ein Eisenobjekt.  Wie vermutet der Roboter, dass ein Nagel, der sich einem Nagel nähert, den Nagel in Richtung des Magneten stürzt?  Das visuelle Bild ist nicht so: <br><br><ul><li>  Der Magnet nähert sich, hat aber keinen Kontakt mit dem Nagel. </li><li>  Gleichzeitig stürzt der Nagel von sich aus zum Magneten und kommt mit ihm in Kontakt. </li></ul><br>  Wie Sie sehen, ist es sehr schwierig, Ursache-Wirkungs-Beziehungen zu verfolgen, selbst wenn der Zeuge mit eiserner Überzeugung erklärt, dass er sie mit eigenen Augen gesehen hat.  Bilderkennungsalgorithmen sind hier machtlos. <br><br>  <b>VII.</b> <br>  Siebtens und zuletzt ist dies die Wahl der visuellen Wahrnehmungsziele. <br><br>  Das umgebende visuelle Bild kann aus Hunderten und Tausenden von ineinander verschachtelten Objekten bestehen, von denen viele ihre räumliche Position und andere Eigenschaften ständig ändern.  Natürlich muss der Roboter nicht jeden Grashalm auf dem Feld wahrnehmen, wie jedes Gesicht auf einer Stadtstraße: Sie müssen nur das Wichtige wahrnehmen, abhängig von den ausgeführten Aufgaben. <br><br>  Offensichtlich funktioniert es nicht, den Bilderkennungsalgorithmus an die Wahrnehmung einiger Objekte anzupassen und andere zu ignorieren, da möglicherweise nicht im Voraus bekannt ist, worauf zu achten ist und was zu ignorieren ist, zumal sich die aktuellen Ziele auf dem Weg ändern können.  Eine Situation kann entstehen, wenn Sie zuerst viele tausend ineinander verschachtelte Objekte wahrnehmen müssen - buchstäblich jedes von ihnen -, um zu analysieren und erst dann ein Urteil abzugeben, welche Objekte für die Lösung des aktuellen Problems wesentlich sind und welche nicht von Interesse sind.  So nimmt der Mensch die Welt um sich herum wahr: Er sieht nur das Wichtige und achtet nicht auf uninteressante Hintergrundereignisse.  Wie er Erfolg hat, ist ein Geheimnis. <br><br>  Und der Roboter, der sogar mit den modernsten und genialsten Bilderkennungsalgorithmen ausgestattet ist? .. Wenn er während eines Angriffs von Mars-Außerirdischen einen Bericht mit Wetterberichten startet und mit einer Beschreibung der vor ihm ausgebreiteten neuen Landschaft fortfährt, hat er möglicherweise keine Zeit, den Angriff selbst zu melden. <br><br>  <b>Schlussfolgerungen</b> <br><br><ol><li>  Die einfache Erkennung visueller Bilder ersetzt nicht das menschliche Auge. </li><li>  Bilderkennungsalgorithmen sind ein Hilfswerkzeug mit einem sehr engen Anwendungsbereich. </li><li>  Damit ein Roboter nicht nur denken kann, sondern es zumindest menschlich sieht, sind Algorithmen nicht nur für die Mustererkennung erforderlich, sondern auch für dasselbe vollwertige und dennoch unerreichbare menschliche Denken. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450422/">https://habr.com/ru/post/de450422/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450398/index.html">Die furchtlosesten Gifte</a></li>
<li><a href="../de450410/index.html">Terraformer - Infrastruktur zum Codieren</a></li>
<li><a href="../de450416/index.html">Wie Shareware-VPN-Anbieter Ihre Daten verkaufen</a></li>
<li><a href="../de450418/index.html">Die Kunst, organische 3D-Modelle zu erstellen: Subdermale Shader</a></li>
<li><a href="../de450420/index.html">Warum Data Science-Teams Universal brauchen, keine Spezialisten</a></li>
<li><a href="../de450426/index.html">2011 gegen AM4. Dinosaurier gegen Säugetiere</a></li>
<li><a href="../de450428/index.html">Indexer in C # unter der Haube: Indizierung besser als Dow Jones</a></li>
<li><a href="../de450430/index.html">Was ist ein Staubangriff?</a></li>
<li><a href="../de450432/index.html">Nun, wo ist sie?</a></li>
<li><a href="../de450436/index.html">Was ist ein Coding Bootcamp?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
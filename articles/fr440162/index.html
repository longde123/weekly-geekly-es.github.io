<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤶 ❔ 🕴🏻 Un exemple de réseau neuronal simple en C / C ++ 👨‍👩‍👦‍👦 👩🏽‍🎓 🐿️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour à tous. 

 J'ai décidé de partager une solution simple et volumineuse à mon avis d'un réseau de neurones en C ++. 

 Pourquoi ces informations...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Un exemple de réseau neuronal simple en C / C ++</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440162/">  Bonjour à tous. <br><br>  J'ai décidé de partager une solution simple et volumineuse à mon avis d'un réseau de neurones en C ++. <br><br>  <b>Pourquoi ces informations devraient-elles être intéressantes?</b> <br><br>  <b>Réponse:</b> J'ai essayé de programmer le travail du perceptron multicouche dans un ensemble minimal, afin qu'il puisse être configuré comme j'aime en quelques lignes de code, et la mise en œuvre des algorithmes de base pour travailler sur «C» vous permettra de transférer facilement des langues orientées vers «C» (dans et à tout autre) <b><u>sans utiliser de bibliothèques tierces!</u></b> <br><br><h4>  Veuillez jeter un coup d'œil à ce qui en est sorti </h4><br>  Je ne vais pas vous parler de l' <b>objectif des réseaux de neurones</b> , j'espère que vous n'avez pas été banni de <b>Google</b> et que vous pourrez trouver les informations qui vous intéressent (objectif, capacités, applications, etc.). <br><br>  Vous trouverez le <b>code source</b> à la fin de l'article, mais pour l'instant, dans l'ordre. <br><br><h3>  Commençons l'analyse </h3><br><h4>  1) Architecture et détails techniques </h4><br>  - <b>Perceptron multicouche</b> avec la possibilité de configurer n'importe quel nombre de couches avec une largeur donnée.  Ci-dessous est présenté <br><br><div class="spoiler">  <b class="spoiler_title">exemple de configuration</b> <div class="spoiler_text">  <b>myNeuero.cpp</b> <br><br><pre><code class="cpp hljs">inputNeurons = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   outputNeurons =2; //   nlCount = 4; //  (    3,      1 list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); //  INPUTS/OUTPUTS    list[1].setIO(20,6); // -//- list[2].setIO(6,3); // -//- list[3].setIO(3,2); // -//-  </span></span></code> </pre> <br></div></div><br>  Notez que le réglage de la largeur de l'entrée et de la sortie pour chaque couche est effectué selon une certaine règle - l'entrée de la couche actuelle = la sortie de la précédente.  Une exception est la couche d'entrée. <br><br>  Ainsi, vous avez la possibilité de configurer n'importe quelle configuration manuellement ou selon une règle donnée avant de compiler ou après la compilation pour lire les données des fichiers source. <a name="habracut"></a><br><br>  - mise en place du mécanisme de <b>rétro-propagation des erreurs</b> avec possibilité de régler la vitesse d'apprentissage <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> learnRate 0.1</span></span></code> </pre> <br>  - installation des <b>poids initiaux</b> <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5))</span></span></code> </pre> <br>  <b>Remarque</b> : s'il y a plus de trois couches (nlCount&gt; 4), alors pow (out, -0.5) doit être augmenté de sorte que lorsque le signal passe directement, son énergie ne se réduit pas à 0. Exemple pow (out, -0.2) <br><br>  - la <b>base du code en C.</b> Les algorithmes de base et le stockage des coefficients de pondération sont implémentés comme une structure en C, tout le reste est la coquille de la fonction appelante de cette structure, c'est aussi le reflet de l'une des couches prises séparément <br><br><div class="spoiler">  <b class="spoiler_title">Structure de couche</b> <div class="spoiler_text">  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">nnLay</span></span></span><span class="hljs-class">{</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> in; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> out; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>** matrix; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* hidden; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* errors; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getInCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> in;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> **</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matrix;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">updMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *enteredVal)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setIO</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inputs, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outputs)</span></span></span><span class="hljs-function"> </span></span>{ in=inputs; out=outputs; hidden = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); matrix = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>**) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((in+<span class="hljs-number"><span class="hljs-number">1</span></span>)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { matrix[inp] = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(out*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> outp =<span class="hljs-number"><span class="hljs-number">0</span></span>; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">makeHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *inputs)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; out; hid++) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> tmpS = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> hidden; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcOutError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcHidError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> **outWeights,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inS, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outS)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((inS)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; inS; hid++) { errors[hid] = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getErrors</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> errors; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoida</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-number"><span class="hljs-number">1.0</span></span> / (<span class="hljs-number"><span class="hljs-number">1.0</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-val))); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoidasDerivate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (val * (<span class="hljs-number"><span class="hljs-number">1.0</span></span> - val)); }; };</code> </pre><br></div></div><br><h4>  2) Application </h4><br>  Le test du projet avec l'ensemble mnist a réussi, nous avons réussi à obtenir une probabilité de reconnaissance conditionnelle de l'écriture manuscrite de 0,9795 (nlCount = 4, learnRate = 0,03 et plusieurs époques).  Le but principal du test était de tester les performances du réseau de neurones, avec lequel il s'est adapté. <br><br>  Ci-dessous, nous considérons les travaux sur la <b>"tâche conditionnelle"</b> . <br><br>  <b>Données sources:</b> <br><br>  -2 vecteurs d'entrée aléatoires de 100 valeurs <br>  réseau de neurones avec génération aléatoire de poids <br>  -2 objectifs fixés <br><br>  <b>Le code</b> dans la fonction main () <br><br><pre> <code class="cpp hljs">{ <span class="hljs-comment"><span class="hljs-comment">//!!!________    qDebug()   std::cout  std::cerr myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- /!  2    qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- //  2   float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- //    bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); //  int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } //   (   ) qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); }</span></span></code> </pre> <br>  <b>Le résultat du réseau neuronal</b> <br><br><img src="https://habrastorage.org/webt/gt/oe/vc/gtoevca428fe3i7wmvkkupaayq0.png" alt="image"><br><br><h3>  <b>Résumé</b> </h3><br>  Comme vous pouvez le voir, appeler la fonction de requête (entrées) avant l'entraînement pour chacun des vecteurs ne nous permet pas de juger de leurs différences.  En outre, en appelant la fonction train (entrée, cible), pour la formation dans le but d'arranger les coefficients de poids de sorte que le réseau neuronal puisse ensuite distinguer les vecteurs d'entrée. <br><br>  Après avoir terminé la formation, nous observons que la tentative de mappage du vecteur «abc» à «tar1» et «cba» à «tar2» a échoué. <br><br>  <b>Vous avez la possibilité, en utilisant le code source, de tester indépendamment les performances et d'expérimenter la configuration!</b> <br><br>  PS: ce code a été écrit depuis QtCreator, j'espère que vous pourrez facilement remplacer la sortie, laissez vos commentaires et commentaires. <br><br>  PPS: si quelqu'un est intéressé par une analyse détaillée du travail d'écriture de struct nnLay {}, il y aura un nouveau message. <br><br>  PPPS: J'espère que quelqu'un pourra utiliser le code orienté «C» pour le portage vers d'autres outils. <br><br><div class="spoiler">  <b class="spoiler_title">Code source</b> <div class="spoiler_text">  <b>main.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCoreApplication&gt; #include &lt;QDebug&gt; #include &lt;QTime&gt; #include "myneuro.h" int main(int argc, char *argv[]) { QCoreApplication a(argc, argv); myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); qDebug()&lt;&lt;"_______________THE____END_______________"; return a.exec(); }</span></span></span></span></code> </pre><br>  <b>myNeuro.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"myneuro.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QDebug&gt; myNeuro::myNeuro() { //-------- inputNeurons = 100; outputNeurons =2; nlCount = 4; list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); list[1].setIO(20,6); list[2].setIO(6,3); list[3].setIO(3,2); //----------------- // inputNeurons = 100; // outputNeurons =2; // nlCount = 2; // list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); // inputs = (float*) malloc((inputNeurons)*sizeof(float)); // targets = (float*) malloc((outputNeurons)*sizeof(float)); // list[0].setIO(100,10); // list[1].setIO(10,2); } void myNeuro::feedForwarding(bool ok) { list[0].makeHidden(inputs); for (int i =1; i&lt;nlCount; i++) list[i].makeHidden(list[i-1].getHidden()); if (!ok) { qDebug()&lt;&lt;"Feed Forward: "; for(int out =0; out &lt; outputNeurons; out++) { qDebug()&lt;&lt;list[nlCount-1].hidden[out]; } return; } else { // printArray(list[3].getErrors(),list[3].getOutCount()); backPropagate(); } } void myNeuro::backPropagate() { //-------------------------------ERRORS-----CALC--------- list[nlCount-1].calcOutError(targets); for (int i =nlCount-2; i&gt;=0; i--) list[i].calcHidError(list[i+1].getErrors(),list[i+1].getMatrix(), list[i+1].getInCount(),list[i+1].getOutCount()); //-------------------------------UPD-----WEIGHT--------- for (int i =nlCount-1; i&gt;0; i--) list[i].updMatrix(list[i-1].getHidden()); list[0].updMatrix(inputs); } void myNeuro::train(float *in, float *targ) { inputs = in; targets = targ; feedForwarding(true); } void myNeuro::query(float *in) { inputs=in; feedForwarding(false); } void myNeuro::printArray(float *arr, int s) { qDebug()&lt;&lt;"__"; for(int inp =0; inp &lt; s; inp++) { qDebug()&lt;&lt;arr[inp]; } }</span></span></span></span></code> </pre> <br>  <b>myNeuro.h</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifndef</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;math.h&gt; #include &lt;QtGlobal&gt; #include &lt;QDebug&gt; #define learnRate 0.1 #define randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5)) class myNeuro { public: myNeuro(); struct nnLay{ int in; int out; float** matrix; float* hidden; float* errors; int getInCount(){return in;} int getOutCount(){return out;} float **getMatrix(){return matrix;} void updMatrix(float *enteredVal) { for(int ou =0; ou &lt; out; ou++) { for(int hid =0; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; void setIO(int inputs, int outputs) { in=inputs; out=outputs; hidden = (float*) malloc((out)*sizeof(float)); matrix = (float**) malloc((in+1)*sizeof(float)); for(int inp =0; inp &lt; in+1; inp++) { matrix[inp] = (float*) malloc(out*sizeof(float)); } for(int inp =0; inp &lt; in+1; inp++) { for(int outp =0; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } void makeHidden(float *inputs) { for(int hid =0; hid &lt; out; hid++) { float tmpS = 0.0; for(int inp =0; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; float* getHidden() { return hidden; }; void calcOutError(float *targets) { errors = (float*) malloc((out)*sizeof(float)); for(int ou =0; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; void calcHidError(float *targets,float **outWeights,int inS, int outS) { errors = (float*) malloc((inS)*sizeof(float)); for(int hid =0; hid &lt; inS; hid++) { errors[hid] = 0.0; for(int ou =0; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; float* getErrors() { return errors; }; float sigmoida(float val) { return (1.0 / (1.0 + exp(-val))); } float sigmoidasDerivate(float val) { return (val * (1.0 - val)); }; }; void feedForwarding(bool ok); void backPropagate(); void train(float *in, float *targ); void query(float *in); void printArray(float *arr,int s); private: struct nnLay *list; int inputNeurons; int outputNeurons; int nlCount; float *inputs; float *targets; }; #endif // MYNEURO_H</span></span></span></span></code> </pre> <br></div></div><br><br><h3>  <b>UPD:</b> </h3>  Les sources de vérification sur mnist sont par <div class="spoiler">  <b class="spoiler_title">le lien</b> <div class="spoiler_text">  1) Projet <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github.com/mamkin-itshnik/simple-neuro-network</a> " <br>  Il y a aussi une description graphique du travail.  En bref, lors de l'interrogation du réseau avec des données de test, vous obtenez la valeur de chacun des neurones de sortie (10 neurones correspondent à des nombres de 0 à 9).  Pour prendre une décision sur le chiffre représenté, vous devez connaître l'indice du neurone maximum.  Digit = index + 1 (n'oubliez pas d'où les numéros des tableaux sont numérotés)) <br>  2) MNIST <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Www.kaggle.com/oddrationale/mnist-in-csv</a> " (si vous avez besoin d'utiliser un ensemble de données plus petit, limitez simplement le compteur while lors de la lecture du fichier CSV du PS: il y a un exemple pour git) <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440162/">https://habr.com/ru/post/fr440162/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440148/index.html">Réalité virtuelle - la vie parallèle avec ses courants</a></li>
<li><a href="../fr440152/index.html">Lehmann Linear DIY ou comment cloner un Allemand pur-sang avec un bon résultat</a></li>
<li><a href="../fr440154/index.html">Comment Spore a été créé: entretiens avec les développeurs</a></li>
<li><a href="../fr440156/index.html">Comment organiser le développement distribué, si cela n'est pas possible</a></li>
<li><a href="../fr440158/index.html">Statistiques de ventes de véhicules électriques et hybrides rechargeables en 2018 (aux États-Unis et dans le monde)</a></li>
<li><a href="../fr440164/index.html">La monétisation des données des utilisateurs deviendra-t-elle une tendance en 2019?</a></li>
<li><a href="../fr440166/index.html">Compression du pointeur Java</a></li>
<li><a href="../fr440168/index.html">Reportages vidéo de FunTech ML-meetup</a></li>
<li><a href="../fr440170/index.html">Analyse des incidents liés aux cyberattaques sur les projets de blockchain</a></li>
<li><a href="../fr440172/index.html">CQRS: le principe du «diviser pour mieux régner» au service d'un programmeur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
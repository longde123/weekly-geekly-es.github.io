<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∂ ‚ùî üï¥üèª Un exemple de r√©seau neuronal simple en C / C ++ üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ üë©üèΩ‚Äçüéì üêøÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous. 

 J'ai d√©cid√© de partager une solution simple et volumineuse √† mon avis d'un r√©seau de neurones en C ++. 

 Pourquoi ces informations...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Un exemple de r√©seau neuronal simple en C / C ++</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440162/">  Bonjour √† tous. <br><br>  J'ai d√©cid√© de partager une solution simple et volumineuse √† mon avis d'un r√©seau de neurones en C ++. <br><br>  <b>Pourquoi ces informations devraient-elles √™tre int√©ressantes?</b> <br><br>  <b>R√©ponse:</b> J'ai essay√© de programmer le travail du perceptron multicouche dans un ensemble minimal, afin qu'il puisse √™tre configur√© comme j'aime en quelques lignes de code, et la mise en ≈ìuvre des algorithmes de base pour travailler sur ¬´C¬ª vous permettra de transf√©rer facilement des langues orient√©es vers ¬´C¬ª (dans et √† tout autre) <b><u>sans utiliser de biblioth√®ques tierces!</u></b> <br><br><h4>  Veuillez jeter un coup d'≈ìil √† ce qui en est sorti </h4><br>  Je ne vais pas vous parler de l' <b>objectif des r√©seaux de neurones</b> , j'esp√®re que vous n'avez pas √©t√© banni de <b>Google</b> et que vous pourrez trouver les informations qui vous int√©ressent (objectif, capacit√©s, applications, etc.). <br><br>  Vous trouverez le <b>code source</b> √† la fin de l'article, mais pour l'instant, dans l'ordre. <br><br><h3>  Commen√ßons l'analyse </h3><br><h4>  1) Architecture et d√©tails techniques </h4><br>  - <b>Perceptron multicouche</b> avec la possibilit√© de configurer n'importe quel nombre de couches avec une largeur donn√©e.  Ci-dessous est pr√©sent√© <br><br><div class="spoiler">  <b class="spoiler_title">exemple de configuration</b> <div class="spoiler_text">  <b>myNeuero.cpp</b> <br><br><pre><code class="cpp hljs">inputNeurons = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   outputNeurons =2; //   nlCount = 4; //  (    3,      1 list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); //  INPUTS/OUTPUTS    list[1].setIO(20,6); // -//- list[2].setIO(6,3); // -//- list[3].setIO(3,2); // -//-  </span></span></code> </pre> <br></div></div><br>  Notez que le r√©glage de la largeur de l'entr√©e et de la sortie pour chaque couche est effectu√© selon une certaine r√®gle - l'entr√©e de la couche actuelle = la sortie de la pr√©c√©dente.  Une exception est la couche d'entr√©e. <br><br>  Ainsi, vous avez la possibilit√© de configurer n'importe quelle configuration manuellement ou selon une r√®gle donn√©e avant de compiler ou apr√®s la compilation pour lire les donn√©es des fichiers source. <a name="habracut"></a><br><br>  - mise en place du m√©canisme de <b>r√©tro-propagation des erreurs</b> avec possibilit√© de r√©gler la vitesse d'apprentissage <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> learnRate 0.1</span></span></code> </pre> <br>  - installation des <b>poids initiaux</b> <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5))</span></span></code> </pre> <br>  <b>Remarque</b> : s'il y a plus de trois couches (nlCount&gt; 4), alors pow (out, -0.5) doit √™tre augment√© de sorte que lorsque le signal passe directement, son √©nergie ne se r√©duit pas √† 0. Exemple pow (out, -0.2) <br><br>  - la <b>base du code en C.</b> Les algorithmes de base et le stockage des coefficients de pond√©ration sont impl√©ment√©s comme une structure en C, tout le reste est la coquille de la fonction appelante de cette structure, c'est aussi le reflet de l'une des couches prises s√©par√©ment <br><br><div class="spoiler">  <b class="spoiler_title">Structure de couche</b> <div class="spoiler_text">  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">nnLay</span></span></span><span class="hljs-class">{</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> in; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> out; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>** matrix; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* hidden; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* errors; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getInCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> in;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> **</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matrix;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">updMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *enteredVal)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setIO</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inputs, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outputs)</span></span></span><span class="hljs-function"> </span></span>{ in=inputs; out=outputs; hidden = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); matrix = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>**) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((in+<span class="hljs-number"><span class="hljs-number">1</span></span>)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { matrix[inp] = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(out*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> outp =<span class="hljs-number"><span class="hljs-number">0</span></span>; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">makeHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *inputs)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; out; hid++) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> tmpS = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> hidden; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcOutError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcHidError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> **outWeights,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inS, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outS)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((inS)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; inS; hid++) { errors[hid] = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getErrors</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> errors; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoida</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-number"><span class="hljs-number">1.0</span></span> / (<span class="hljs-number"><span class="hljs-number">1.0</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-val))); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoidasDerivate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (val * (<span class="hljs-number"><span class="hljs-number">1.0</span></span> - val)); }; };</code> </pre><br></div></div><br><h4>  2) Application </h4><br>  Le test du projet avec l'ensemble mnist a r√©ussi, nous avons r√©ussi √† obtenir une probabilit√© de reconnaissance conditionnelle de l'√©criture manuscrite de 0,9795 (nlCount = 4, learnRate = 0,03 et plusieurs √©poques).  Le but principal du test √©tait de tester les performances du r√©seau de neurones, avec lequel il s'est adapt√©. <br><br>  Ci-dessous, nous consid√©rons les travaux sur la <b>"t√¢che conditionnelle"</b> . <br><br>  <b>Donn√©es sources:</b> <br><br>  -2 vecteurs d'entr√©e al√©atoires de 100 valeurs <br>  r√©seau de neurones avec g√©n√©ration al√©atoire de poids <br>  -2 objectifs fix√©s <br><br>  <b>Le code</b> dans la fonction main () <br><br><pre> <code class="cpp hljs">{ <span class="hljs-comment"><span class="hljs-comment">//!!!________    qDebug()   std::cout  std::cerr myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- /!  2    qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- //  2   float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- //    bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); //  int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } //   (   ) qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); }</span></span></code> </pre> <br>  <b>Le r√©sultat du r√©seau neuronal</b> <br><br><img src="https://habrastorage.org/webt/gt/oe/vc/gtoevca428fe3i7wmvkkupaayq0.png" alt="image"><br><br><h3>  <b>R√©sum√©</b> </h3><br>  Comme vous pouvez le voir, appeler la fonction de requ√™te (entr√©es) avant l'entra√Ænement pour chacun des vecteurs ne nous permet pas de juger de leurs diff√©rences.  En outre, en appelant la fonction train (entr√©e, cible), pour la formation dans le but d'arranger les coefficients de poids de sorte que le r√©seau neuronal puisse ensuite distinguer les vecteurs d'entr√©e. <br><br>  Apr√®s avoir termin√© la formation, nous observons que la tentative de mappage du vecteur ¬´abc¬ª √† ¬´tar1¬ª et ¬´cba¬ª √† ¬´tar2¬ª a √©chou√©. <br><br>  <b>Vous avez la possibilit√©, en utilisant le code source, de tester ind√©pendamment les performances et d'exp√©rimenter la configuration!</b> <br><br>  PS: ce code a √©t√© √©crit depuis QtCreator, j'esp√®re que vous pourrez facilement remplacer la sortie, laissez vos commentaires et commentaires. <br><br>  PPS: si quelqu'un est int√©ress√© par une analyse d√©taill√©e du travail d'√©criture de struct nnLay {}, il y aura un nouveau message. <br><br>  PPPS: J'esp√®re que quelqu'un pourra utiliser le code orient√© ¬´C¬ª pour le portage vers d'autres outils. <br><br><div class="spoiler">  <b class="spoiler_title">Code source</b> <div class="spoiler_text">  <b>main.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCoreApplication&gt; #include &lt;QDebug&gt; #include &lt;QTime&gt; #include "myneuro.h" int main(int argc, char *argv[]) { QCoreApplication a(argc, argv); myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); qDebug()&lt;&lt;"_______________THE____END_______________"; return a.exec(); }</span></span></span></span></code> </pre><br>  <b>myNeuro.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"myneuro.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QDebug&gt; myNeuro::myNeuro() { //-------- inputNeurons = 100; outputNeurons =2; nlCount = 4; list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); list[1].setIO(20,6); list[2].setIO(6,3); list[3].setIO(3,2); //----------------- // inputNeurons = 100; // outputNeurons =2; // nlCount = 2; // list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); // inputs = (float*) malloc((inputNeurons)*sizeof(float)); // targets = (float*) malloc((outputNeurons)*sizeof(float)); // list[0].setIO(100,10); // list[1].setIO(10,2); } void myNeuro::feedForwarding(bool ok) { list[0].makeHidden(inputs); for (int i =1; i&lt;nlCount; i++) list[i].makeHidden(list[i-1].getHidden()); if (!ok) { qDebug()&lt;&lt;"Feed Forward: "; for(int out =0; out &lt; outputNeurons; out++) { qDebug()&lt;&lt;list[nlCount-1].hidden[out]; } return; } else { // printArray(list[3].getErrors(),list[3].getOutCount()); backPropagate(); } } void myNeuro::backPropagate() { //-------------------------------ERRORS-----CALC--------- list[nlCount-1].calcOutError(targets); for (int i =nlCount-2; i&gt;=0; i--) list[i].calcHidError(list[i+1].getErrors(),list[i+1].getMatrix(), list[i+1].getInCount(),list[i+1].getOutCount()); //-------------------------------UPD-----WEIGHT--------- for (int i =nlCount-1; i&gt;0; i--) list[i].updMatrix(list[i-1].getHidden()); list[0].updMatrix(inputs); } void myNeuro::train(float *in, float *targ) { inputs = in; targets = targ; feedForwarding(true); } void myNeuro::query(float *in) { inputs=in; feedForwarding(false); } void myNeuro::printArray(float *arr, int s) { qDebug()&lt;&lt;"__"; for(int inp =0; inp &lt; s; inp++) { qDebug()&lt;&lt;arr[inp]; } }</span></span></span></span></code> </pre> <br>  <b>myNeuro.h</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifndef</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;math.h&gt; #include &lt;QtGlobal&gt; #include &lt;QDebug&gt; #define learnRate 0.1 #define randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5)) class myNeuro { public: myNeuro(); struct nnLay{ int in; int out; float** matrix; float* hidden; float* errors; int getInCount(){return in;} int getOutCount(){return out;} float **getMatrix(){return matrix;} void updMatrix(float *enteredVal) { for(int ou =0; ou &lt; out; ou++) { for(int hid =0; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; void setIO(int inputs, int outputs) { in=inputs; out=outputs; hidden = (float*) malloc((out)*sizeof(float)); matrix = (float**) malloc((in+1)*sizeof(float)); for(int inp =0; inp &lt; in+1; inp++) { matrix[inp] = (float*) malloc(out*sizeof(float)); } for(int inp =0; inp &lt; in+1; inp++) { for(int outp =0; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } void makeHidden(float *inputs) { for(int hid =0; hid &lt; out; hid++) { float tmpS = 0.0; for(int inp =0; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; float* getHidden() { return hidden; }; void calcOutError(float *targets) { errors = (float*) malloc((out)*sizeof(float)); for(int ou =0; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; void calcHidError(float *targets,float **outWeights,int inS, int outS) { errors = (float*) malloc((inS)*sizeof(float)); for(int hid =0; hid &lt; inS; hid++) { errors[hid] = 0.0; for(int ou =0; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; float* getErrors() { return errors; }; float sigmoida(float val) { return (1.0 / (1.0 + exp(-val))); } float sigmoidasDerivate(float val) { return (val * (1.0 - val)); }; }; void feedForwarding(bool ok); void backPropagate(); void train(float *in, float *targ); void query(float *in); void printArray(float *arr,int s); private: struct nnLay *list; int inputNeurons; int outputNeurons; int nlCount; float *inputs; float *targets; }; #endif // MYNEURO_H</span></span></span></span></code> </pre> <br></div></div><br><br><h3>  <b>UPD:</b> </h3>  Les sources de v√©rification sur mnist sont par <div class="spoiler">  <b class="spoiler_title">le lien</b> <div class="spoiler_text">  1) Projet <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github.com/mamkin-itshnik/simple-neuro-network</a> " <br>  Il y a aussi une description graphique du travail.  En bref, lors de l'interrogation du r√©seau avec des donn√©es de test, vous obtenez la valeur de chacun des neurones de sortie (10 neurones correspondent √† des nombres de 0 √† 9).  Pour prendre une d√©cision sur le chiffre repr√©sent√©, vous devez conna√Ætre l'indice du neurone maximum.  Digit = index + 1 (n'oubliez pas d'o√π les num√©ros des tableaux sont num√©rot√©s)) <br>  2) MNIST <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Www.kaggle.com/oddrationale/mnist-in-csv</a> " (si vous avez besoin d'utiliser un ensemble de donn√©es plus petit, limitez simplement le compteur while lors de la lecture du fichier CSV du PS: il y a un exemple pour git) <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440162/">https://habr.com/ru/post/fr440162/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440148/index.html">R√©alit√© virtuelle - la vie parall√®le avec ses courants</a></li>
<li><a href="../fr440152/index.html">Lehmann Linear DIY ou comment cloner un Allemand pur-sang avec un bon r√©sultat</a></li>
<li><a href="../fr440154/index.html">Comment Spore a √©t√© cr√©√©: entretiens avec les d√©veloppeurs</a></li>
<li><a href="../fr440156/index.html">Comment organiser le d√©veloppement distribu√©, si cela n'est pas possible</a></li>
<li><a href="../fr440158/index.html">Statistiques de ventes de v√©hicules √©lectriques et hybrides rechargeables en 2018 (aux √âtats-Unis et dans le monde)</a></li>
<li><a href="../fr440164/index.html">La mon√©tisation des donn√©es des utilisateurs deviendra-t-elle une tendance en 2019?</a></li>
<li><a href="../fr440166/index.html">Compression du pointeur Java</a></li>
<li><a href="../fr440168/index.html">Reportages vid√©o de FunTech ML-meetup</a></li>
<li><a href="../fr440170/index.html">Analyse des incidents li√©s aux cyberattaques sur les projets de blockchain</a></li>
<li><a href="../fr440172/index.html">CQRS: le principe du ¬´diviser pour mieux r√©gner¬ª au service d'un programmeur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
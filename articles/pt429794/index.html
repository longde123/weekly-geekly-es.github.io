<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôäÔ∏è üóø üé± Google fala sobre o crescimento exponencial da IA ‚Äã‚Äãmudando a pr√≥pria natureza da computa√ß√£o üëâ üêò ‚ú¥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clif Young, programador do Google, explica como o desenvolvimento explosivo dos algoritmos de aprendizado profundo coincide com o fracasso da Lei de M...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Google fala sobre o crescimento exponencial da IA ‚Äã‚Äãmudando a pr√≥pria natureza da computa√ß√£o</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429794/"><h3>  Clif Young, programador do Google, explica como o desenvolvimento explosivo dos algoritmos de aprendizado profundo coincide com o fracasso da Lei de Moore, que trabalha h√° d√©cadas na regra de ouro para o progresso dos chips de computador e for√ßa o desenvolvimento de esquemas computacionais fundamentalmente novos. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f16/257/7ce/f162577cea1b28010ec340bfff65f307.jpg"><br><br>  O desenvolvimento explosivo da IA ‚Äã‚Äãe dos algoritmos de aprendizado de m√°quina est√° mudando a pr√≥pria natureza da computa√ß√£o - como dizem em uma das maiores empresas que praticam IA - no Google.  O programador do Google Cliff Young falou na abertura da confer√™ncia de microprocessadores de outono organizada pelo Linley Group, um popular simp√≥sio de chips de computador hospedado pela vener√°vel empresa de semicondutores. <br><br>  Young disse que o uso da IA ‚Äã‚Äãentrou na "fase exponencial" no exato momento em que a Lei de Moore, regra geral para o progresso de chips de computador por d√©cadas, foi completamente inibida. <br><a name="habracut"></a><br>  "Os tempos est√£o muito nervosos", disse ele, pensativo.  "O CMOS digital est√° diminuindo a velocidade, estamos vendo problemas com o processo de 10 nm na Intel, estamos vendo com 7nm na GlobalFoundries e, simultaneamente com o desenvolvimento de aprendizado profundo, uma demanda econ√¥mica est√° surgindo".  O CMOS, uma estrutura complementar de √≥xido de metal-semicondutor, √© o material mais comum usado para fabricar chips de computador. <br><br>  Enquanto os chips cl√°ssicos mal conseguem aumentar a efici√™ncia e a produtividade, os pedidos dos pesquisadores de IA est√£o crescendo, disse Young.  Ele forneceu algumas estat√≠sticas: o n√∫mero de artigos cient√≠ficos sobre aprendizado de m√°quina armazenados no site de pr√©-impress√£o arXiv, mantido pela Universidade de Cornell, dobra a cada 18 meses.  E o n√∫mero de projetos internos com foco em IA no Google, ele disse, tamb√©m dobra a cada 18 meses.  A necessidade do n√∫mero de opera√ß√µes de ponto flutuante necess√°rias para processar as redes neurais usadas no aprendizado de m√°quina est√° crescendo ainda mais rapidamente - ela dobra a cada tr√™s meses e meio. <br><br>  Todo esse crescimento em consultas computacionais est√° sendo combinado com a "super lei de Moore", disse Young, e ele chamou de "um pouco assustador" e "um pouco perigoso" e "algo com que se preocupar". <br><br>  "De onde veio todo esse crescimento exponencial", no campo da IA, ele perguntou.  ‚ÄúEm particular, o ponto principal √© que o aprendizado profundo simplesmente funciona.  Na minha carreira, h√° muito tempo ignoro o aprendizado de m√°quina ‚Äù, disse ele.  "N√£o era √≥bvio que essas coisas poderiam decolar". <br><br>  Mas ent√£o come√ßaram a surgir inova√ß√µes, como o reconhecimento de padr√µes, e ficou claro que o aprendizado profundo "√© incrivelmente eficaz", disse ele.  ‚ÄúNos √∫ltimos cinco anos, fomos a empresa que colocou a IA em primeiro lugar e refizemos a maioria dos neg√≥cios com base na IA‚Äù, da pesquisa √† publicidade e muito mais. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a72/3ff/1e9/a723ff1e9203c6ee395dc5cd8d8bd296.jpg"><br><br>  A equipe do projeto Google Brain, um dos principais projetos de pesquisa em IA, precisa de "m√°quinas gigantes", disse Young.  Por exemplo, as redes neurais √†s vezes s√£o medidas pelo n√∫mero de "pesos" que s√£o usados ‚Äã‚Äãnelas, ou seja, as vari√°veis ‚Äã‚Äãaplicadas √† rede neural e afetam a maneira como processam os dados. <br><br>  E se as redes neurais comuns podem conter centenas de milhares ou mesmo milh√µes de pesos que precisam ser calculados, os pesquisadores do Google exigem "m√°quinas com peso de tera", ou seja, computadores que podem calcular trilh√µes de pesos.  Porque "toda vez que dobramos o tamanho da rede neural, melhoramos sua precis√£o".  A regra do desenvolvimento da IA ‚Äã‚Äã√© aumentar cada vez mais. <br><br>  Em resposta a pedidos do Google, eles est√£o desenvolvendo sua pr√≥pria linha de chips para o MO, a Unidade de Processamento de Tensores.  TPU e similares s√£o necess√°rios porque as CPUs tradicionais e os chips gr√°ficos da GPU n√£o conseguem lidar com a carga. <br><br>  "N√≥s nos contivemos por um longo tempo e dissemos que a Intel e a Nvidia s√£o muito boas na cria√ß√£o de sistemas de alto desempenho", disse Young.  "Mas cruzamos essa linha h√° cinco anos." <br><br>  O TPU ap√≥s a primeira apari√ß√£o em p√∫blico em 2017 causou alvoro√ßo ao afirmar que, em termos de velocidade, supera os chips comuns.  O Google j√° est√° trabalhando na TPU de terceira gera√ß√£o, usando-a em seus projetos e oferecendo recursos de computador sob demanda atrav√©s do servi√ßo Google Cloud. <br><br>  A empresa continua a fabricar TPUs cada vez maiores.  Em sua configura√ß√£o "legada", 1024 TPUs s√£o conectadas em conjunto a um novo tipo de supercomputador, e o Google planeja continuar a expandir esse sistema, de acordo com Young. <br><br>  "Estamos construindo multicomputadores gigantes com capacidade para dezenas de petabytes", disse ele.  "Estamos avan√ßando incansavelmente em v√°rias dire√ß√µes ao mesmo tempo, e as opera√ß√µes em escala de terabytes continuam a crescer".  Tais projetos levantam todos os problemas associados ao desenvolvimento de supercomputadores. <br><br>  Por exemplo, os engenheiros do Google adotaram os truques usados ‚Äã‚Äãno lend√°rio supercomputador Cray.  Eles combinaram o gigantesco "m√≥dulo de multiplica√ß√£o de matrizes", a parte do chip que carrega a carga principal da computa√ß√£o para redes neurais, com o "m√≥dulo de uso geral vetorial" e o "m√≥dulo de uso geral escalar", como foi feito em Cray.  "A combina√ß√£o de m√≥dulos escalares e vetoriais permitiu que o Cray superasse todos em termos de desempenho", disse ele. <br><br>  O Google desenvolveu seus pr√≥prios projetos aritm√©ticos inovadores para chips de programa√ß√£o.  Uma certa maneira de representar n√∫meros reais chamados bfloat16 fornece maior efici√™ncia ao processar n√∫meros em redes neurais.  No discurso coloquial, √© chamado de "flutua√ß√£o cerebral". <br><br>  O TPU usa os chips de mem√≥ria mais r√°pidos, a mem√≥ria de alta largura de banda ou HBM [mem√≥ria de alta largura de banda].  Ele disse que a demanda por grandes quantidades de mem√≥ria no treinamento de redes neurais est√° crescendo rapidamente. <br><br>  ‚ÄúA mem√≥ria √© usada mais intensamente durante o treinamento.  As pessoas falam sobre centenas de milh√µes de pesos, mas h√° problemas no processamento da ativa√ß√£o de "vari√°veis ‚Äã‚Äãde uma rede neural". <br><br>  O Google tamb√©m ajusta a maneira como as redes neurais s√£o programadas para ajudar a tirar o m√°ximo proveito do ferro.  ‚ÄúEstamos trabalhando em dados de modelo e paralelismo‚Äù em projetos como ‚ÄúMesh TensorFlow‚Äù - uma adapta√ß√£o da plataforma de software TensorFlow ‚Äúcombinando dados e paralelismo na escala do pod‚Äù. <br><br>  Young n√£o divulgou alguns detalhes t√©cnicos.  Ele observou que a empresa n√£o falou sobre conex√µes internas, sobre como os dados se movem ao longo do chip - ele simplesmente observou que "nossos conectores s√£o gigantescos".  Ele se recusou a expandir esse t√≥pico, o que causou risos na plat√©ia. <br><br>  Young apontou √°reas de computa√ß√£o ainda mais interessantes que em breve poder√£o chegar at√© n√≥s.  Por exemplo, ele sugeriu que c√°lculos usando chips anal√≥gicos, circuitos que processam dados de entrada na forma de valores cont√≠nuos, em vez de zeros e uns, podem desempenhar um papel importante.  "Talvez nos voltemos para o campo anal√≥gico, na f√≠sica h√° muitas coisas interessantes relacionadas aos computadores anal√≥gicos e √† mem√≥ria NVM". <br><br>  Ele tamb√©m expressou esperan√ßa no sucesso das startups de chips apresentadas na confer√™ncia: ‚ÄúExistem algumas startups muito legais aqui, e precisamos que elas funcionem, porque as possibilidades do CMOS digital n√£o s√£o ilimitadas;  Quero que todos esses investimentos sejam acionados. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt429794/">https://habr.com/ru/post/pt429794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt429782/index.html">A hist√≥ria de como aceleramos os testes 12 vezes</a></li>
<li><a href="../pt429786/index.html">Fast Sin and Cos no ASM incorporado para Delphi</a></li>
<li><a href="../pt429788/index.html">Outro motivo pelo qual os cont√™ineres do Docker ficam mais lentos</a></li>
<li><a href="../pt429790/index.html">Julia e o movimento de uma part√≠cula carregada em um campo eletromagn√©tico</a></li>
<li><a href="../pt429792/index.html">A intelig√™ncia artificial baseada na f√≠sica pode inferir as leis dos universos imagin√°rios</a></li>
<li><a href="../pt429796/index.html">Como o DeviceLock DLP impede vazamentos de dados confidenciais no GitHub</a></li>
<li><a href="../pt429798/index.html">Vendas de ve√≠culos el√©tricos plug-in nos Estados Unidos (com gr√°ficos): outubro de 2018</a></li>
<li><a href="../pt429800/index.html">Pacote Symfony para exportar estat√≠sticas no formato Prometheus</a></li>
<li><a href="../pt429804/index.html">Prote√ß√£o amig√°vel de um recurso da Web contra ataques de for√ßa bruta</a></li>
<li><a href="../pt429808/index.html">Roscosmos pode perder o maior pedido devido ao FSB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
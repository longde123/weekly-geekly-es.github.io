<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😡 🏩 🔱 Straßenerkennung durch semantische Segmentierung 👩🏽‍✈️ 🍏 🚶🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In der vorherigen Serie habe ich ein Experiment mit der autonomen Bewegung meines Heimtanks durchgeführt . Die Straße wurde unter Verwendung eines Far...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Straßenerkennung durch semantische Segmentierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452088/">  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherigen Serie habe</a> ich ein Experiment mit der autonomen Bewegung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">meines Heimtanks durchgeführt</a> .  Die Straße wurde unter Verwendung eines Farbfilters erkannt, und die resultierende Maske ging zum Eingang eines speziell trainierten neuronalen Klassifikator-Netzwerks, das sich für rechts, links oder gerade entschied. <br><br>  Der Schwachpunkt war das Erkennen der Fahrbahn selbst aufgrund der Variabilität der Farbtöne, weshalb das entscheidende neuronale Netzwerk zu seltsamen Ergebnissen führte.  In den Kommentaren zu diesem Artikel wurde empfohlen, auf die semantische Segmentierung zu achten.  Das Thema erwies sich als vielversprechend und die Verwendung segmentierter neuronaler Netze brachte seine Vor- und Nachteile mit sich, wo es ohne sie wäre. <br><br>  Aber das Wichtigste zuerst und ein bisschen Ausrüstung. <br><a name="habracut"></a><br><h2>  Segmentierung </h2><br>  Bei der Segmentierung werden einige Teile eines Bildes hervorgehoben.  Die einfachste und offensichtlichste Art der Segmentierung ist die Farbe.  Mit dieser Methode ist es jedoch unmöglich zu verstehen, was und wo auf dem Bild dargestellt ist. <br><br>  Hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">guter Artikel</a> , der primitive Ansätze beschreibt. <br><br><h3>  Semantische Segmentierung </h3><br>  Semantische Segmentierung - Aufteilen eines Bildes in Objekte mit Bestimmung der Typen dieser Objekte. <br><br>  Es sieht ungefähr so ​​aus: <br><br><img src="https://habrastorage.org/webt/at/m4/zl/atm4zleo88k-gaaek75alwzrt_8.png"><br><br>  Die Ergebnisse sind sehr beeindruckend. Mal sehen, was es wert ist, in das wirkliche Leben übersetzt zu werden. <br><br><h4>  U-net </h4><br>  Das bekannteste neuronale Netz, ursprünglich für die Medizin entwickelt. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Primärquelle</a> <br><br>  Die Leute erkannten schnell, dass der Ansatz für alle Gelegenheiten verwendet werden kann. <br><br>  Es gibt viele Artikel im Internet, wie man Daten aufbereitet und U-Net-Netzwerke trainiert: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeiten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zwei</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drei</a> </li></ul><br>  Ich fand jedoch kein fertiges U-Net-Netzwerk, das ich schnell nutzen und experimentieren konnte. <br><br><h4>  E-Net </h4><br>  Ein jüngeres und weniger bekanntes Netzwerk.  Entwickelt nur zum Erkennen von Stadtstraßen. <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Originaldokument</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Einführungsartikel</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lernanleitung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Toller Artikel zur Verwendung</a> </li></ul><br><h4>  Daten </h4><br>  Die beliebtesten Datensätze für die Straßensegmentierung (sie lehrten ursprünglich E-Net): <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CityScapes - deutsche und schweizerische Städte</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CamVid - Cambridge Straßen in England</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SUN - Princeton-Datensatz für verschiedene Arten von Szenen</a> </li></ul><br>  Auf denselben Datensätzen wird U-net jetzt trainiert. <br><br><h4>  Implementierungsauswahl </h4><br>  Die Flut neuer Informationen zur Segmentierung war ziemlich überwältigend.  Instinktiv wollte ich etwas Einfacheres verstehen.  Ich hatte nicht das Gefühl, die Architektur von Netzwerken zu verstehen und Zeit mit Lernen zu verbringen.  In dem Artikel von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PyImageSearch gab es</a> jedoch ein vorgefertigtes und geschultes neuronales Netzwerk in einem mit OpenCV-DNN kompatiblen Format. <br><br>  Also wurde die Wahl zum geringsten Widerstand getroffen. <br><br>  Die Verwendung ist sehr einfach: <br>  (Am besorgniserregendsten ist, dass das Netzwerk auf 1024 x 512 Bilder trainiert ist - dies ist zum einen mehr als die Kamera bei Raspberry ausgibt, und zum anderen ist die erforderliche Leistung für die Verarbeitung dieser Datenmenge etwas verwirrend. Infolgedessen ist das Hauptproblem genau das.) <br><br>  Wir lesen das neuronale Netzwerk aus den Dateien (in einem das Modell selbst, in den anderen Klassennamen in den dritten Farben). <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_segment_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: classes = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(PiConf.SEGMENT_CLASSES) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: classes = f.read().strip().split(<span class="hljs-string"><span class="hljs-string">"\n"</span></span>) colors = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(PiConf.SEGMENT_COLORS) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: colors= f.read().strip().split(<span class="hljs-string"><span class="hljs-string">"\n"</span></span>) colors = [np.array(c.split(<span class="hljs-string"><span class="hljs-string">","</span></span>)).astype(<span class="hljs-string"><span class="hljs-string">"int"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> colors] colors = np.array(colors, dtype=<span class="hljs-string"><span class="hljs-string">"uint8"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"[INFO] loading model..."</span></span>) net = cv2.dnn.readNet(PiConf.SEGMENT_MODEL) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> net, classes, colors <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> Exception <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> e: logging.exception(<span class="hljs-string"><span class="hljs-string">"Cannot load segment model"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span></code> </pre> <br>  Wir segmentieren das Bild und markieren gleichzeitig Segmente über dem Originalbild <br>  (In meinem Fall sind alle Klassen außer der Straße unsichtbar). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">segment_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image_path, seg_net, seg_classes, seg_colors)</span></span></span><span class="hljs-function">:</span></span> image0 = cv2.imread(image_path) image = cv2.resize(image0, (<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span>),interpolation=cv2.INTER_NEAREST) blob = cv2.dnn.blobFromImage(image, <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">255.0</span></span>, (<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span>), <span class="hljs-number"><span class="hljs-number">0</span></span>, swapRB=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, crop=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) seg_net.setInput(blob) start = time.time() output = seg_net.forward() end = time.time() print(<span class="hljs-string"><span class="hljs-string">"[INFO] inference took {:.4f} seconds"</span></span>.format(end - start)) (numClasses, height, width) = output.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] classMap = np.argmax(output[<span class="hljs-number"><span class="hljs-number">0</span></span>], axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) mask = seg_colors[classMap] mask = cv2.resize(mask, (image0.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], image0.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]),interpolation=cv2.INTER_NEAREST) classMap = cv2.resize(classMap, (image0.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], image0.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), interpolation=cv2.INTER_NEAREST) gmask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY) gmask = cv2.resize(gmask, (<span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>), interpolation=cv2.INTER_NEAREST) gmask = gmask[<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">32</span></span>:<span class="hljs-number"><span class="hljs-number">96</span></span>] output = ((<span class="hljs-number"><span class="hljs-number">0.6</span></span> * image0) + (<span class="hljs-number"><span class="hljs-number">0.4</span></span> * mask)).astype(<span class="hljs-string"><span class="hljs-string">"uint8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> output, gmask</code> </pre><br><h4>  Überprüfen Sie </h4><br>  Wir machen fertige Bilder aus dem Tank und setzen ein segmentiertes neuronales Netzwerk darauf. <br><br><h5>  1 </h5><br><img src="https://habrastorage.org/webt/2h/vs/vh/2hvsvhc9ntkfulrphsvaylzz8je.jpeg"><br><br>  Nur die linke Seite des Bürgersteigs wird als teuer erkannt. <br><br>  Wir komprimieren das Bild und nehmen daraus eine Mittengröße von 64x64: <br>  (Diese Größe wird vom neuronalen Netzwerk erwartet, das beschließt, die Richtung zu ändern.) <br><br><img src="https://habrastorage.org/webt/rv/yp/za/rvypza_qrlmnobm-jjafbqgxu4y.jpeg"><br><br>  Das neuronale Netzwerk der Richtung (in der Tat - der Klassifikator) befiehlt, nach links zu nehmen.  Nicht sehr korrekt, aber erträglich. <br><br><h5>  2 </h5><br><img src="https://habrastorage.org/webt/rb/kc/5o/rbkc5okogbebc5vns4whjzrfsuw.jpeg"><br><br>  Eine ähnliche Situation ist wiederum die untere rechte Ecke verloren (es gibt auch Asphalt nass). <br>  Der größte Teil der Straße wird jedoch noch erkannt. <br><br><img src="https://habrastorage.org/webt/fc/5m/4e/fc5m4es-4sc2jortt28xescg2nq.jpeg"><br><br>  Der Klassifikator bietet an, geradeaus zu fahren. <br><br><h5>  3 </h5><br>  Die Situation, als sich der Roboter mitten auf dem Bürgersteig befand. <br><br><img src="https://habrastorage.org/webt/mb/db/he/mbdbheuq0b-sytqwps5qnepuxi4.jpeg"><br><br>  Die Straße ist fast perfekt erkannt. <br><br><img src="https://habrastorage.org/webt/ac/at/bl/acatblunbshunktslu31uongwoe.jpeg"><br><br>  Der Klassifikator befiehlt, nach rechts zu nehmen (um beim nächsten Mal den Straßenrand zu finden). <br><br><h4>  Anwendung </h4><br>  Nachdem ich ein wenig über die Tank-Firmware gezaubert hatte, ersetzte ich den Farbstraßendetektor durch ein segmentierendes neuronales Netzwerk. <br><br>  Als all dies auf dem Raspberry Pi gestartet wurde, war das erste, was herauskam, eine deprimierende Leistung. <br>  Es dauert 6 Sekunden, um ein Bild zu segmentieren - während dieser Zeit schafft es der Panzer, mit einem kräftigen Trab durch alle Kurven zu rutschen. <br><br>  In realen Tests geschah dies - trotz der nahezu perfekten Erkennung des Bürgersteigs und der korrekten Befehle des neuronalen Kontrollnetzwerks - während der Zeit, in der das Bild verarbeitet wurde, gelang es dem Panzer, zur Seite zu gehen. <br><br><img src="https://habrastorage.org/webt/ck/3_/gs/ck3_gstzycmsirkih6oxyd6rpdi.png"><br><br>  Im Allgemeinen können Bilder dieser Größe auf Raspberry nicht verdaut werden. <br>  Es scheint, dass Sie noch ein spezielles neuronales Netzwerk trainieren müssen. <br><br><h4>  Referenzen </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farbbasierte Bürgersteigerkennung und OpenCV</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quellcode der Tank-Firmware mit Segmentierung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Am besten angewandter Artikel zum Thema Segmentierung mit einem fertigen neuronalen Netz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Trainingshandbuch für neuronale Netze zur Segmentierung</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de452088/">https://habr.com/ru/post/de452088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de452074/index.html">Das erste Spiel über die Einheit oder was ich sechs Monate gebraucht habe</a></li>
<li><a href="../de452076/index.html">UC-Browser brechen</a></li>
<li><a href="../de452078/index.html">Kubernetes Reservierung: Es besteht</a></li>
<li><a href="../de452082/index.html">Flexibler Ablauf von In-App-Updates: Beschleunigen Sie den App-Update-Prozess unter Android</a></li>
<li><a href="../de452086/index.html">Was ist in meinem Pixel für Sie: Erstellen von Nanopixeln mit Plasmon-Metaoberflächen</a></li>
<li><a href="../de452090/index.html">Erstellen eines prozeduralen Puzzle-Generators</a></li>
<li><a href="../de452092/index.html">In-App-Updates: Beschleunigen von Android-Anwendungsupdates</a></li>
<li><a href="../de452094/index.html">.NET: Tools zum Arbeiten mit Multithreading und Asynchronität. Teil 1</a></li>
<li><a href="../de452098/index.html">Protokolle des Frontend-Entwicklers Habr: Refactor und Reflex</a></li>
<li><a href="../de452102/index.html">Fotospiel für Drohnenliebhaber: kurz über AirSelfie 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
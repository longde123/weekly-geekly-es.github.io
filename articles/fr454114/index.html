<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏾‍🤝‍👨🏼 🕺🏿 👨‍🎨 Expérience avec Starwind VSAN et EMC ScaleIO (VxFlexOS) + aide-mémoire pour le stockage mini-entreprise (1 partie) 🖱️ 😭 👍🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parfois, il devient nécessaire d'organiser un stockage à tolérance de pannes de petits volumes de stockage jusqu'à 20 To, mais avec des fonctionnalité...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Expérience avec Starwind VSAN et EMC ScaleIO (VxFlexOS) + aide-mémoire pour le stockage mini-entreprise (1 partie)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454114/"> Parfois, il devient nécessaire d'organiser un stockage à tolérance de pannes de petits volumes de stockage jusqu'à 20 To, mais avec des fonctionnalités d'entreprise - All-Flash, cache SSD, MPIO, HA (Activ-Activ) et tout cela à un prix abordable.  Les solutions matérielles prêtes à l'emploi avec ces fonctions partent de centaines de téraoctets et de prix de 8 signes ou plus en roubles.  Avoir un petit budget de 6-7 caractères dans la rivière.  et la nécessité d'un stockage petit et rapide (mais fiable), depuis 2009, deux versions de systèmes de stockage ont été testées et mises en service commercial (La chose courante avec ces systèmes est qu'ils sont des systèmes très fiables sans point de défaillance unique + vous pouvez les toucher avant l'achat ou «s'en passer» (GRATUIT)). <br><br>  Les personnes intéressées par cette expérience seront décrites ci-dessous: <br><br><ol><li>  Expérience du logiciel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">StarWind Virtual SAN (VSAN)</a> . </li><li>  Comment faire du stockage pour petites entreprises. </li><li>  Historique d'overclocking IOPS (pratique). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Aide-mémoire</a> pour le déploiement et l'exploitation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">systèmes</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">stockage EMC ScaleIO (VxFlexOS)</a> (en l'absence de support technique par les spécialistes de «NOT Linux-gourou») 1 partie. </li></ol><a name="habracut"></a><br><h2>  1. Expérience d'exploitation du logiciel StarWind Virtual SAN (VSAN) </h2><br>  <b>StarWind Virtual SAN (VSAN)</b> - dans la solution Activ-Activ (réplication synchrone sur 3 serveurs), en fonctionnement de 2009 à 2016 dans différentes éditions (Starwind ISCSI SAN HA-3) basée sur des serveurs avec des matrices RAID matérielles. <br><br>  <i>Avantages</i> : <br><br><ul><li>  Facile et rapide, même pas installé par un professionnel; </li><li>  MPIO sur Ethernet iSCSI; </li><li>  HA (Activ-Activ); </li><li>  Sur les nouveaux serveurs (sous garantie) (avec de nouveaux disques), vous pouvez oublier de conserver le stockage pendant plusieurs années (les utilisateurs ne remarqueront même pas la panne de deux serveurs sur trois); </li><li>  Volumes de cache RAM et SSD; </li><li>  Rapide Synchronisation rapide pour les pannes de réseau mineures. </li></ul><br>  <i>Inconvénients</i> : <br><br><ul><li>  Auparavant, il n'y avait qu'une version pour la plate-forme Windows; </li><li>  Avec un fonctionnement à long terme (plus de 3 ans) - il est difficile de trouver un disque pour remplacer un disque défectueux (hors production) pour réparer une matrice RAID (avec des disques hétérogènes, des pannes de matrice peuvent se produire); </li><li>  Une augmentation du nombre d'interfaces réseau et des emplacements PCI qu'elles occupent (en plus pour la synchronisation, les cartes réseau, les commutateurs); </li><li>  Lors de l'utilisation de LSFS - «journing file system», arrêt prolongé du système, qui peut être préjudiciable lorsque l'onduleur est déclenché lorsque l'alimentation est coupée; </li><li>  Une très longue période de synchronisation complète avec un grand volume. </li></ul><br>  <i>Peut-être des problèmes déjà résolus</i> (survenus précédemment pendant le fonctionnement dans notre centre de données): <br><br><ul><li>  Lorsque la matrice RAID s'effondre, le serveur reste visible via le canal de synchronisation et de données, mais le disque du serveur Windows est hors réseau, le journal Starwind est gonflé et la mémoire du serveur est consommée, à la suite du gel du serveur.  Traitement possible: affectation d'un fichier de contrôle et suppression des messages non critiques des paramètres du journal. </li><li>  Si le commutateur ou les interfaces réseau échouent, un choix ambigu du serveur hôte (parfois c'est arrivé, le système ne peut pas comprendre avec qui se synchroniser). </li></ul><br>  <i>Actualités utiles</i> (non encore testées): <br>  StarWind Virtual SAN pour vSphere (solution hyperconvergée), vous permet d'intégrer la virtualisation Vmware dans un cluster sans liaison avec les serveurs Windows (basés sur des machines virtuelles Linux). <br><br>  <i><b>Résumé</b></i> : Une solution tolérante aux pannes s'il existe un programme de remplacement de serveur matériel normal à la fin de la garantie et un support technique StarWindSoftWare est disponible. <br><br><h2>  <b>2. Comment faire du stockage pour petites entreprises</b> </h2><br>  <b>Énoncé du problème:</b> <br><br>  Créez un réseau de stockage de données à faible volume de sécurité avec un total de 4 To-20 To, avec un fonctionnement garanti à moyen terme sans coûts financiers supplémentaires importants. <br><br><ul><li>  Le système doit être tolérant aux pannes (transférer calmement la défaillance d'au moins un commutateur, un serveur, des disques et des cartes réseau dans le serveur). </li><li>  Utiliser au maximum toutes les ressources du parc matériel disponible de serveurs (serveurs et commutateurs de 3 à 10 ans). </li><li>  Assurer le fonctionnement des volumes de différents niveaux: All-Flash et cache HDD + SSD. </li></ul><br>  <b>Données sources:</b> <br><br><ul><li>  budget limité; </li><li>  équipement de production il y a 3 à 10 ans; </li><li>  Spécialistes - Pas Linux-Guru. </li></ul><br>  <b>Calcul des caractéristiques</b> <br><br>  Pour éviter les goulots d'étranglement des performances lors de l'utilisation de disques SSD, qui seront coupés par rapport à quelque chose de la chaîne matérielle: cartes réseau, contrôleur RAID (HBA), module d'extension (panier), disques. <br><br>  Il est nécessaire au moment de la création de fournir, en fonction de leurs caractéristiques requises, une certaine configuration d'équipement. <br><br>  Vous pouvez bien sûr exécuter une configuration avec SSD de cache SAS HDD sur les réseaux 1 Gbit / s et les contrôleurs 3G, mais le résultat sera 3-7 fois pire que sur les réseaux RAID 6 Gbit et 10 Gbit / s (vérifié par des tests). <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les instructions de réglage VxFlexOS</a> décrivent des instructions simples pour calculer la bande passante nécessaire, basées sur les classements SSD -450 Mo / C et HDD -100 Mo / C, pour l'enregistrement séquentiel (par exemple, lorsque le serveur est rééquilibré et reconstruit). <br><br><img src="https://habrastorage.org/webt/ia/-h/kl/ia-hklgcn0f0i_t6126vqpondoi.jpeg"><br>  Par exemple: <br><br><ul><li>  (Cache SSD + 3 HDD), nous obtenons ((450 * 1) + (3 * 100)) * 8/1000 = 6 Go </li><li>  (TOUS SSD FLASH) + (Cache SSD + 3 HDD) ((450 * 2) + (3 * 100)) * 8/1000 = 9,6 Go </li></ul><br>  Pour déterminer la bande passante réseau par IOPS (charge standard sur les serveurs de base de données et les serveurs virtuels chargés), il existe un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tableau indicatif de StariWindSoftware</a> <br><br><img src="https://habrastorage.org/webt/uc/xm/qf/ucxmqfcjkdfvg2qyfzyuofsso6e.jpeg"><br>  <b>Configuration finale</b> : <br><br><ul><li>  Logiciel de stockage, qui peut ne pas combiner des disques en matrices RAID, mais les transférer vers le stockage sous forme de disques séparés (afin qu'il n'y ait aucun problème à remplacer les disques après un certain laps de temps où ils échouent, mais simplement les sélectionner par capacité); </li><li>  Serveurs de génération de processeurs e55xx-x56xx et supérieurs, bus pci-express v 2.0 et supérieurs, contrôleurs Raid (HBA) 6G-12G avec mémoire, paniers d'extension pour 6-16 disques; </li><li>  Commutateurs SMB 10G couche 2 (JUMBO FRAME, LACP). </li></ul><br>  <b>Méthode de solution</b> <br><br>  Aucune option budgétaire pour un «stockage matériel de petite entreprise» n'a été trouvée pour le petit volume avec les exigences ci-dessus. <br><br>  Nous nous sommes arrêtés sur des solutions logicielles qui vous permettent de profiter du stockage d'entreprise, avec la possibilité d'utiliser des serveurs existants, qui dans ce cas ont le droit de mourir de vieillesse sans compromettre le stockage. <br><br><ul><li>  Ceph - pas assez de spécialistes Linux; </li><li>  EMC ScaleIO - pour quelques années de support technique - vous pouvez vous en tirer avec le personnel existant. </li><li>  (il s'est avéré que les connaissances sous Linux peuvent être minimes, plus sur cela plus tard dans la feuille de triche). </li></ul><br><h2>  3. Historique de l'overclocking IOPS (pratique budgétaire) </h2><br>  Pour accélérer les opérations de lecture et d'écriture dans les systèmes de stockage, les périphériques SSD suivants ont été utilisés: <br><br>  3.1.  Contrôleurs avec fonctionnalités de mise en cache SSD. <br><br>  En 2010, des contrôleurs RAID avec des fonctions de mise en cache SSD Adaptec 5445 avec un disque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MaxIQ</a> sont apparus (pour un résultat tangible, vous devez avoir au moins 10% du disque MaxIQ du volume du volume mis en cache), le résultat est mais insignifiant * testé sur soi-même; <br>  Plus tard, il y avait des contrôleurs qui peuvent utiliser un disque SSD arbitraire pour la mise en cache, à la fois la série Adaptec Q et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSI CacheCade</a> (mais les licences y sont distinctes); <br><br>  3.2.  Mise en cache logicielle à l'aide de disques, tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Intel DC S3700</a> , qui est vu par le contrôleur et l'expandeur des serveurs de marque HP, IBM, FUJI (la plupart des serveurs les reconnaissent avec succès, coûteux pour All-Flash, mais pour 10% sur le cache SSD, il est tolérable de ne pas les publier sous partenaires d'IBM, HP, FUJI et juste Intel).  * Mais maintenant, il existe des options compatibles moins chères (voir paragraphe 3.5.); <br><br>  3.3.  La mise en cache logicielle à l'aide de l'adaptateur PCIe-M.2, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Synology M.2 M2D18 SSD</a> , est vérifiée, elle fonctionne sur des serveurs ordinaires (pas seulement dans Synology), elle est utile lorsque le contrôleur RAID et le panier refusent de voir les SSD que le fabricant n'a pas indiqués dans les compatibles (n HP D2700)?  *; <br><br>  3.4.  Disques hybrides <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Seagate EXOS</a>  600 Go Seagate Exos 10E2400 (ST600MM0099) {SAS 12 Gb / s, 10000 tr / min, 256 Mo, 2,5 "}, * vérifié reconnu par les serveurs HP, IBM, FUJI (alternative aux versions 3.1.-3.3.); <br><br>  3.5.  Disques SSD avec une grande ressource et un prix comparable avec SAS de classe entreprise, <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Crucial Micron 5200 MAX</a> MTFDDAK480TDN-1AT1ZABYY, * vérifié reconnu par les serveurs HP, IBM, FUJI <br>  (une alternative au remplacement des disques durs par ceux compatibles avec la clause 3.4 et compatibles avec les anciens serveurs SAS: disque dur SAS2.5 "600 Go AL14SEB060N TOSHIBA *, <br>  C10K1800 0B31229 HGST, ST600MM0099 SEAGATE).  Permet à un budget de passer des volumes HDD + SSD aux volumes 100% Flash.; <br><br><h2>  4. Aide-mémoire pour le déploiement et le fonctionnement du stockage EMC ScaleIO (VxFlexOS) 1 partie </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Stockage EMC ScaleIO (VxFlexOS)</a> <br><br>  Après avoir testé la solution avant l'achat, je suis arrivé à la conclusion que pour le fonctionnement normal du système, plus de 3 nœuds sont nécessaires (le basculement est instable à 3), par exemple, prenez une configuration de 8 serveurs (il survivra à l'échec consécutif de 4 serveurs sans perdre de volumes). <br><br>  <i>Partie matériel</i> : <br><br>  FUJI CX2550M1 (E5-2xxx) - 3 pièces.  (Client SDC et serveur SDS du cluster principal de virtualisation du serveur VmWare VSphere + ScaleIO); <br>  Serveurs de génération +5 HP G6 (G7) ou IBM M3 (e55xx-x56xx) - serveurs ScaleIO SDS; <br>  + 2 commutateurs NetGear XS712T-100NES <br><br>  En exécutant le stockage en mode RFCache, j'ai pu overclocker à 44KIops en utilisant Iometer <br><br><img src="https://habrastorage.org/webt/ro/vg/19/rovg1982umabe29n5vqa6_9erpi.jpeg"><br><br>  Configuration de stockage: <br><br>  Capacité brute de 12 To (licence minimale au moment où elle était encore vendue en tant que logiciel) <br><br><img src="https://habrastorage.org/webt/vw/os/4e/vwos4eljcmjyrnk8drmccc9vsoa.jpeg"><br><br>  8 serveurs SDS 28 disques <br><br><img src="https://habrastorage.org/webt/gd/-y/5j/gd-y5j3wve2zmum8vexmkbwhmu8.jpeg"><br><br>  Lire le cache RAM 14 Go <br><br><img src="https://habrastorage.org/webt/uo/-j/ck/uo-jck7jbbvfdbjvap9emzkzjvu.jpeg"><br><br>  Lire Flash cashe 1,27 To (RFCashe) <br><br><img src="https://habrastorage.org/webt/2x/y2/km/2xy2kmosvvldbniqfv6sr_6hykw.jpeg"><br><br>  Dans la version intermédiaire, où seuls 3 serveurs 2x10Gb ont des cartes réseau, dans les 2 x1Gb restants. <br><br><img src="https://habrastorage.org/webt/vh/k8/xc/vhk8xcff6fqdhzp2347gmgtksuu.jpeg"><br>  On voit clairement que même avec une mise en cache SSD à 1 Go au lieu de 10 Go, il y a une perte de bande passante SDS trois fois ou plus, avec des supports identiques. <br><br>  Sans mise en cache, si vous considérez selon ces <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"standards"</a> alors avec 28 disques durs, <br>  on obtient 28X140 = 3920 IOPS, soit  pour obtenir 44 000 IOPS, il vous faudrait 11 fois plus de disques.  Il est économiquement plus rentable pour les petits volumes, non pour augmenter le nombre de disques mais pour le cache SSD. <br><br>  A la question de savoir pourquoi de telles vitesses avec un petit volume, je répondrai tout de suite! <br><br>  Il existe de telles petites organisations (comme la nôtre) dans lesquelles il existe un grand nombre de documents électroniques qui sont traités dans le logiciel pendant une longue période (chaque registre contrôle d'envoyer le logiciel jusqu'à 1 heure, même dans ce stockage overclocké).  Toutes les autres options ont déjà été appliquées précédemment (augmentation sur RM-RAM, CPU i5, SSD, 1Gb-NET).  Même l'utilisation de bundles SSD + SAS uniquement sur le stockage (sans ALL-Flash jusqu'à présent) a permis d'utiliser la plupart des ressources des serveurs de virtualisation, le transfert de machines virtuelles chargées vers ScaleIO - a doublé la charge sur les processeurs FUJI CX400M1 (stockage précédemment retenu). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr454114/">https://habr.com/ru/post/fr454114/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr454100/index.html">Problèmes de code courants dans les microservices</a></li>
<li><a href="../fr454102/index.html">Utiliser un oracle aléatoire sur l'exemple d'une loterie</a></li>
<li><a href="../fr454104/index.html">Services cloud pour jouer sur des PC faibles, pertinents en 2019</a></li>
<li><a href="../fr454110/index.html">Développement d'une boutique en ligne pour préserver la nature du Kamtchatka</a></li>
<li><a href="../fr454112/index.html">Duke Nukem Level Design History (avec Levelord Sketches)</a></li>
<li><a href="../fr454124/index.html">Le livre "Apprendre à coder en JavaScript"</a></li>
<li><a href="../fr454126/index.html">Des accidents quotidiens à la stabilité: Informatica avec 10 yeux d'administrateur</a></li>
<li><a href="../fr454128/index.html">Comment faire deux applications à partir d'une seule. Expérience Tinkoff Junior</a></li>
<li><a href="../fr454130/index.html">C-V2X avec prise en charge des réseaux 5G NR: un nouveau paradigme pour l'échange de données entre véhicules</a></li>
<li><a href="../fr454132/index.html">Surveillance vidéo sur Orange Pi Zero - pas cher et pas du tout en colère</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
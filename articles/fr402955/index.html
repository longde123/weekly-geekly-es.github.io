<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú≥Ô∏è üë©üèº‚Äçüé§ üë®‚Äçüë©‚Äçüëß L'ASIC sp√©cialis√© de Google pour l'apprentissage automatique est dix fois plus rapide que le GPU üôåüèæ üèª üç≤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a quatre ans, Google a r√©alis√© le r√©el potentiel de l'utilisation des r√©seaux de neurones dans ses applications. Puis elle a commenc√© √† les intro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>L'ASIC sp√©cialis√© de Google pour l'apprentissage automatique est dix fois plus rapide que le GPU</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/402955/"><img src="https://habrastorage.org/files/265/7b9/cb4/2657b9cb49834f6ebc249ddcb70c9136.jpg"><br><br>  Il y a quatre ans, Google a r√©alis√© le r√©el potentiel de l'utilisation des r√©seaux de neurones dans ses applications.  Puis elle a commenc√© √† les introduire partout - dans la traduction de texte, la recherche vocale avec reconnaissance vocale, etc. Mais il est imm√©diatement devenu clair que l'utilisation des r√©seaux de neurones augmente consid√©rablement la charge sur les serveurs Google.  En gros, si tout le monde effectuait une recherche vocale sur Android (ou dictait du texte avec reconnaissance vocale) pendant seulement trois minutes par jour, alors Google devrait doubler le nombre de centres de donn√©es (!) Juste pour que les r√©seaux de neurones traitent une telle quantit√© de trafic vocal. <br><br>  Il fallait faire quelque chose - et Google a trouv√© une solution.  En 2015, elle a d√©velopp√© sa propre architecture mat√©rielle pour l'apprentissage automatique (Tensor Processing Unit, TPU), qui est jusqu'√† 70 fois plus rapide que les GPU et CPU traditionnels en termes de performances et jusqu'√† 196 fois plus en termes de nombre de calculs par watt.  Les GPU / CPU traditionnels font r√©f√©rence aux processeurs √† usage g√©n√©ral Xeon E5 v3 (Haswell) et Nvidia Tesla K80 GPU. <br><a name="habracut"></a><br>  L'architecture TPU a √©t√© d√©crite pour la premi√®re fois cette semaine dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article scientifique (pdf)</a> qui sera pr√©sent√© lors du 44e Symposium international sur les architectures informatiques (ISCA), le 26 juin 2017 √† Toronto.  Un des principaux auteurs de plus de 70 auteurs de ce travail scientifique, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un ing√©nieur exceptionnel Norman</a> Jouppi, connu comme l'un des cr√©ateurs du processeur MIPS, dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une interview</a> avec <i>The Next Platform, a</i> expliqu√© dans ses propres mots les caract√©ristiques de l'architecture TPU unique, qui est en fait un ASIC sp√©cialis√©, c'est-√†-dire circuit int√©gr√© √† usage sp√©cial. <br><br>  Contrairement aux FPGA conventionnels ou aux ASIC hautement sp√©cialis√©s, les modules TPU sont programm√©s de la m√™me mani√®re qu'un GPU ou un CPU; ce n'est pas un √©quipement √† courte port√©e pour un seul r√©seau de neurones.  Norman Yuppy dit que TPU prend en charge les instructions CISC pour diff√©rents types de r√©seaux de neurones: r√©seaux de neurones convolutionnels, mod√®les LSTM et grands mod√®les enti√®rement connect√©s.  Pour qu'elle reste toujours programmable, n'utilise la matrice qu'en tant que primitive, et non pas des primitives vectorielles ou scalaires. <br><br>  Google souligne que tandis que d'autres d√©veloppeurs optimisent leurs micropuces pour les r√©seaux de neurones convolutionnels, ces r√©seaux de neurones ne fournissent que 5% de la charge dans les centres de donn√©es Google.  La majorit√© des applications Google utilisent les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">perceptrons multicouches Rumelhart</a> , il √©tait donc tr√®s important de cr√©er une architecture plus universelle qui n'√©tait pas ¬´aff√ªt√©e¬ª uniquement pour les r√©seaux de neurones convolutifs. <br><br><img src="https://habrastorage.org/files/99f/df0/d93/99fdf0d93e494088a3f1fd86791e0b23.png"><br>  <i>L'un des √©l√©ments de l'architecture est le moteur de flux de donn√©es systolique, un tableau de 256 √ó 256, qui re√ßoit l'activation (poids) des neurones de gauche, puis tout se d√©place pas √† pas, multipli√© par les poids dans la cellule.</i>  <i>Il s'av√®re que la matrice systolique effectue 65 536 calculs par cycle.</i>  <i>Cette architecture est id√©ale pour les r√©seaux de neurones.</i> <br><br>  Selon Yuppy, l'architecture des TPU ressemble plus √† un coprocesseur FPU qu'√† un GPU ordinaire, bien que de nombreuses matrices de multiplication ne stockent aucun programme en elles-m√™mes, elles ex√©cutent simplement les instructions re√ßues de l'h√¥te. <br><br><img src="https://habrastorage.org/files/9ba/2a1/2d1/9ba2a12d11204b74888b70e29ecdf876.png"><br>  <i>Toute l'architecture TPU √† l'exception de la m√©moire DDR3.</i>  <i>Les instructions sont envoy√©es de l'h√¥te (√† gauche) √† la file d'attente.</i>  <i>Ensuite, la logique de contr√¥le, en fonction de l'instruction, peut ex√©cuter chacun d'eux √† plusieurs reprises</i> <br><br>  On ne sait pas encore √† quel point cette architecture est √©volutive.  Yuppy dit que dans un syst√®me avec ce type d'h√¥te, il y aura toujours une sorte de goulot d'√©tranglement. <br><br><img src="https://habrastorage.org/files/6c0/87d/3c7/6c087d3c75b744628a716e65a6f0ae5e.png"><br><br>  Par rapport aux processeurs et GPU conventionnels, l'architecture des machines de Google les d√©cuple.  Par exemple, un processeur Haswell Xeon E5-2699 v3 avec 18 c≈ìurs √† une fr√©quence d'horloge de 2,3 GHz avec une virgule flottante 64 bits effectue 1,3 t√©ra-op√©rations par seconde (TOPS) et affiche un taux de transfert de donn√©es de 51 Go / s.  Dans ce cas, la puce elle-m√™me consomme 145 watts, et l'ensemble du syst√®me avec 256 Go de m√©moire - 455 watts. <br><br>  √Ä titre de comparaison, le TPU sur les op√©rations 8 bits avec 256 Go de m√©moire externe et 32 ‚Äã‚ÄãGo de m√©moire interne d√©montre la vitesse d'√©change avec la m√©moire de 34 Go / s, mais en m√™me temps la carte effectue 92 TOPS, soit environ 71 fois plus que le processeur Haswell.  La consommation d'√©nergie du serveur sur TPU est de 384 watts. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/fbb/21b/e41/fbb21be41722273b1e79febcd8b6f9ab.jpg"><br><br>  Le graphique suivant compare les performances relatives par watt d'un serveur avec un GPU (colonne bleue), un serveur sur TPU (rouge) par rapport √† un serveur sur le CPU.  Il compare √©galement les performances relatives par watt du serveur avec le TPU par rapport au serveur sur le GPU (orange) et la version am√©lior√©e de TPU par rapport au serveur sur le CPU (vert) et au serveur sur le GPU (violet). <br><br><img src="https://habrastorage.org/files/d85/52a/445/d8552a4455ed436c9daca5bdba5c1c2e.png"><br><br>  Il convient de noter que Google a effectu√© des comparaisons dans les tests d'applications sur TensorFlow avec l'ancienne version relative de Haswell Xeon, tandis que dans la nouvelle version de Broadwell Xeon E5 v4, le nombre d'instructions par cycle a augment√© de 5% en raison d'am√©liorations architecturales, et dans la version de Skylake Xeon E5 v5 , qui est pr√©vu en √©t√©, le nombre d'instructions par cycle pourrait encore augmenter de 9 √† 10%.  Et avec l'augmentation du nombre de c≈ìurs de 18 √† 28 dans Skylake, les performances globales des processeurs Intel dans les tests Google peuvent s'am√©liorer de 80%.  Mais m√™me ainsi, il y aura une √©norme diff√©rence de performances avec le TPU.  Dans la version du test avec virgule flottante 32 bits, la diff√©rence entre les TPU et les CPU est r√©duite √† environ 3,5 fois.  Mais la plupart des mod√®les quantifient parfaitement √† 8 bits. <br><br>  Google a r√©fl√©chi √† la fa√ßon d'utiliser le GPU, le FPGA et l'ASIC dans ses centres de donn√©es depuis 2006, mais ne les a pas trouv√©s avant la derni√®re fois o√π il a introduit l'apprentissage automatique pour un certain nombre de t√¢ches pratiques, et la charge sur ces r√©seaux de neurones a commenc√© √† augmenter avec des milliards de demandes d'utilisateurs.  D√©sormais, la soci√©t√© n'a d'autre choix que de s'√©loigner des processeurs traditionnels. <br><br>  La soci√©t√© ne pr√©voit pas de vendre ses processeurs √† quiconque, mais esp√®re que le travail scientifique avec les ASIC de 2015 permettra √† d'autres d'am√©liorer l'architecture et de cr√©er des versions am√©lior√©es d'ASIC qui "√©l√®veront la barre encore plus haut".  Google lui-m√™me travaille probablement d√©j√† sur une nouvelle version d'ASIC. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr402955/">https://habr.com/ru/post/fr402955/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr402941/index.html">Pebble Smartwatch lib√®re la synchronisation avec le cloud</a></li>
<li><a href="../fr402943/index.html">Un monde sans pensions</a></li>
<li><a href="../fr402947/index.html">Jeff Bezos consacre 1 milliard de dollars par an au d√©veloppement de Blue Origin</a></li>
<li><a href="../fr402951/index.html">ONYX BOOX MAX Carta Review: A4 sans compromis</a></li>
<li><a href="../fr402953/index.html">A invent√© un syst√®me pour encaisser de l'argent √† partir de cartes de cr√©dit via des pr√™teurs sur gages</a></li>
<li><a href="../fr402957/index.html">La m√©moire RAM √† trois bits a √©t√© imprim√©e sur une imprimante √† jet d'encre</a></li>
<li><a href="../fr402961/index.html">"Encore une fois la m√™me chose": comment se forme une playlist sur les radios</a></li>
<li><a href="../fr402963/index.html">Si vous vous tenez sur l'escalator du m√©tro sur deux rang√©es, son d√©bit augmente de 31%</a></li>
<li><a href="../fr402965/index.html">Geek Keykeeper, Part II: SmartPoket pour les grosses cl√©s que nous avons fabriqu√©es gr√¢ce √† vous</a></li>
<li><a href="../fr402967/index.html">Un peu plus de l√©vitation pour un geek: des gadgets capables de rester en l'air</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
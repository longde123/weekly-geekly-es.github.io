<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶í üë¥üèΩ üò∞ Carro de montanha: resolvendo o desafio cl√°ssico com treinamento de refor√ßo ü•à ‚ôíÔ∏è üßü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como regra, modifica√ß√µes em algoritmos que dependem dos recursos espec√≠ficos de uma tarefa espec√≠fica s√£o consideradas menos valiosas, pois s√£o dif√≠ce...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Carro de montanha: resolvendo o desafio cl√°ssico com treinamento de refor√ßo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hsespb/blog/444428/">  Como regra, modifica√ß√µes em algoritmos que dependem dos recursos espec√≠ficos de uma tarefa espec√≠fica s√£o consideradas menos valiosas, pois s√£o dif√≠ceis de generalizar para uma classe mais ampla de problemas.  No entanto, isso n√£o significa que essas modifica√ß√µes n√£o sejam necess√°rias.  Al√©m disso, muitas vezes eles podem melhorar significativamente o resultado, mesmo para problemas cl√°ssicos simples, o que √© muito importante na aplica√ß√£o pr√°tica de algoritmos.  Como exemplo, neste post, vou resolver o problema do Mountain Car com treinamento de refor√ßo e mostrar que, usando o conhecimento de como a tarefa √© organizada, ela pode ser resolvida muito mais rapidamente. <br><br><img src="https://habrastorage.org/webt/xy/ju/ai/xyjuaivxj9j2c5hp2o-2x3cem2y.png"><br><a name="habracut"></a><br><h2>  Sobre mim </h2><br>  Meu nome √© Oleg Svidchenko, agora estou estudando na Escola de Ci√™ncias F√≠sicas, Matem√°ticas e da Computa√ß√£o do HSE de S√£o Petersburgo, antes de estudar na Universidade de S√£o Petersburgo por tr√™s anos.  Tamb√©m trabalho na JetBrains Research como pesquisador.  Antes de entrar na universidade, estudei no SSC da Universidade Estadual de Moscou e me tornei o vencedor da Olimp√≠ada de toda a R√∫ssia de crian√ßas em idade escolar em ci√™ncia da computa√ß√£o, como parte da equipe de Moscou. <br><br><h2>  Do que precisamos? </h2><br>  Se voc√™ estiver interessado em experimentar o treinamento de refor√ßo, o desafio do Mountain Car √© √≥timo para isso.  Hoje, precisamos do Python com as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bibliotecas</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gym</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PyTorch</a> instaladas, al√©m do conhecimento b√°sico de redes neurais. <br><br><h2>  Descri√ß√£o da tarefa </h2><br>  Em um mundo bidimensional, um carro precisa subir do buraco entre duas colinas at√© o topo da colina direita.  √â complicado pelo fato de ela n√£o ter for√ßa de motor suficiente para superar a for√ßa da gravidade e entrar na primeira tentativa.  Somos convidados a treinar um agente (no nosso caso, uma rede neural), que pode, controlando-a, subir a ladeira direita o mais r√°pido poss√≠vel. <br><br>  O controle da m√°quina √© realizado atrav√©s da intera√ß√£o com o ambiente.  √â dividido em epis√≥dios independentes, e cada epis√≥dio √© realizado passo a passo.  Em cada etapa, o agente recebe estados e ambiente <i>r</i> do ambiente em resposta √† a√ß√£o <i>a</i> .  Al√©m disso, √†s vezes o m√©dium tamb√©m pode relatar que o epis√≥dio terminou.  Nesse problema, <i>s</i> √© um par de n√∫meros, o primeiro deles √© a posi√ß√£o do carro na curva (uma coordenada √© suficiente, j√° que n√£o podemos nos afastar da superf√≠cie) e o segundo √© a velocidade na superf√≠cie (com um sinal).  A recompensa <i>r</i> √© um n√∫mero sempre igual a -1 para esta tarefa.  Dessa forma, incentivamos o agente a concluir o epis√≥dio o mais r√°pido poss√≠vel.  Existem apenas tr√™s a√ß√µes poss√≠veis: empurre o carro para a esquerda, n√£o fa√ßa nada e empurre o carro para a direita.  Essas a√ß√µes correspondem a n√∫meros de 0 a 2. O epis√≥dio pode terminar se o carro chegar ao topo da colina √† direita ou se o agente der 200 passos. <br><br><h2>  Pouco de teoria </h2><br>  Em Habr√© j√° havia um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo sobre DQN</a> no qual o autor descreveu bastante bem toda a teoria necess√°ria.  No entanto, para facilitar a leitura, repetirei aqui de forma mais formal. <br><br>  A tarefa de aprendizado por refor√ßo √© definida por um conjunto de espa√ßo de estado S, espa√ßo de a√ß√£o A, coeficiente <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.197ex" height="1.817ex" viewBox="0 -520.7 2668 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-67" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="730" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6D" x="1260" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="2138" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ gama </script>  , as fun√ß√µes de transi√ß√£o T e as fun√ß√µes de recompensa R. Em geral, a fun√ß√£o de transi√ß√£o e a fun√ß√£o de recompensa podem ser vari√°veis ‚Äã‚Äãaleat√≥rias, mas agora consideraremos uma vers√£o mais simples na qual elas s√£o definidas de forma exclusiva.  O objetivo √© maximizar as recompensas cumulativas. <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>T</mi></mrow></msubsup><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&amp;#xA0;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><msup><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.635ex" height="3.021ex" viewBox="0 -883.9 9315.2 1300.8" role="img" focusable="false" style="vertical-align: -0.969ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-75" x="719" y="0"></use><g transform="translate(1292,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-54" x="1242" y="488"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-3D" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-30" x="1140" y="0"></use></g></g><g transform="translate(3430,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="638" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-63" x="4487" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-64" x="4921" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="5444" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="5930" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-67" x="6541" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="7022" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6D" x="7551" y="0"></use><g transform="translate(8430,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="748" y="513"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>T</mi></mrow></msubsup><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi></mrow></msub><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><msup><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-2"> \ sum_ {t = 0} ^ {T} r_ {t} \ cdot \ gama ^ {t} </script>  , em que t √© o n√∫mero da etapa no meio e T √© o n√∫mero de etapas no epis√≥dio. <br><br>  Para resolver esse problema, definimos a fun√ß√£o de valor V do estado s como o valor da recompensa cumulativa m√°xima, desde que comecemos no estado s.  Conhecendo essa fun√ß√£o, podemos resolver o problema simplesmente passando a cada passo es com o valor m√°ximo poss√≠vel.  No entanto, nem tudo √© t√£o simples: na maioria dos casos, n√£o sabemos que a√ß√£o nos levar√° ao estado desejado.  Portanto, adicionamos a a√ß√£o a como o segundo par√¢metro da fun√ß√£o.  A fun√ß√£o resultante √© chamada fun√ß√£o Q.  Ele mostra qual recompensa cumulativa m√°xima poss√≠vel podemos obter executando a a√ß√£o a no estado s.  Mas j√° podemos usar essa fun√ß√£o para resolver o problema: estando no estado s, simplesmente escolhemos um tal que Q (s, a) seja m√°ximo. <br><br>  Na pr√°tica, n√£o conhecemos a fun√ß√£o Q real, mas podemos aproxim√°-la por v√°rios m√©todos.  Uma dessas t√©cnicas √© a Deep Q Network (DQN).  Sua id√©ia √© que, para cada uma das a√ß√µes, aproximamos a fun√ß√£o Q usando uma rede neural. <br><br><h2>  O meio ambiente </h2><br>  Agora vamos praticar.  Primeiro, precisamos aprender como emular o ambiente MountainCar.  A biblioteca da academia, que fornece um grande n√∫mero de ambientes de aprendizado de refor√ßo padr√£o, nos ajudar√° a lidar com essa tarefa.  Para criar um ambiente, precisamos chamar o m√©todo make no m√≥dulo de academia, passando o nome do ambiente desejado como par√¢metro: <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gym env = gym.make(<span class="hljs-string"><span class="hljs-string">"MountainCar-v0"</span></span>)</code> </pre> <br>  Documenta√ß√£o detalhada pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , e uma descri√ß√£o do ambiente pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br>  Vamos considerar com mais detalhes o que podemos fazer com o ambiente que criamos: <br><br><ul><li>  <code>env.reset()</code> - finaliza o epis√≥dio atual e inicia um novo.  Retorna o estado inicial. </li><li>  <code>env.step(action)</code> - executa a a√ß√£o especificada.  Retorna um novo estado, uma recompensa, se o epis√≥dio terminou e informa√ß√µes adicionais que podem ser usadas para depura√ß√£o. </li><li>  <code>env.seed(seed)</code> - define a semente aleat√≥ria.  Depende de como os estados iniciais ser√£o gerados durante env.reset (). </li><li>  <code>env.render()</code> - exibe o estado atual do ambiente. </li></ul><br><h2>  Percebemos o DQN </h2><br>  DQN √© um algoritmo que usa uma rede neural para avaliar uma fun√ß√£o Q.  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo original, o</a> DeepMind definiu a arquitetura padr√£o para os jogos da Atari usando redes neurais convolucionais.  Ao contr√°rio desses jogos, o Mountain Car n√£o usa a imagem como um estado, portanto, teremos que determinar a arquitetura por conta pr√≥pria. <br><br>  Tomemos, por exemplo, uma arquitetura com duas camadas ocultas de 32 neur√¥nios em cada uma.  Ap√≥s cada camada oculta, usaremos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ReLU</a> como uma fun√ß√£o de ativa√ß√£o.  Dois n√∫meros que descrevem o estado s√£o alimentados na entrada da rede neural e, na sa√≠da, obtemos uma estimativa da fun√ß√£o Q. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ae/jl/mk/aejlmktkosv-jpbne9hqi96enxw.png" alt="Arquitetura de rede neural"></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn model = nn.Sequential( nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) ) target_model = copy.deepcopy(model) <span class="hljs-comment"><span class="hljs-comment">#    def init_weights(layer): if type(layer) == nn.Linear: nn.init.xavier_normal(layer.weight) model.apply(init_weights)</span></span></code> </pre><br>  Como treinamos a rede neural na GPU, precisamos carregar nossa rede l√°: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     CPU,  ‚Äúcuda‚Äù    ‚Äúcpu‚Äù device = torch.device("cuda") model.to(device) target_model.to(device)</span></span></code> </pre><br>  A vari√°vel do dispositivo ser√° global, pois tamb√©m precisaremos carregar os dados. <br><br>  Tamb√©m precisamos definir um otimizador que atualize os pesos do modelo usando a descida do gradiente.  Sim, existem muitos mais de um. <br><br><pre> <code class="python hljs">optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number"><span class="hljs-number">0.00003</span></span>)</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Todos juntos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch device = torch.device(<span class="hljs-string"><span class="hljs-string">"cuda"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_new_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = nn.Sequential( nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) ) target_model = copy.deepcopy(model) <span class="hljs-comment"><span class="hljs-comment">#    def init_weights(layer): if type(layer) == nn.Linear: nn.init.xavier_normal(layer.weight) model.apply(init_weights) #   ,     (GPU  CPU) model.to(device) target_model.to(device) #  ,        optimizer = optim.Adam(model.parameters(), lr=0.00003) return model, target_model, optimizer</span></span></code> </pre><br></div></div><br>  Agora declaramos uma fun√ß√£o que considerar√° a fun√ß√£o de erro, o gradiente ao longo dela e aplicar√° a descida.  Mas antes disso, voc√™ precisa baixar os dados do lote para a GPU: <br><br><pre> <code class="python hljs">state, action, reward, next_state, done = batch <span class="hljs-comment"><span class="hljs-comment">#       state = torch.tensor(state).to(device).float() next_state = torch.tensor(next_state).to(device).float() reward = torch.tensor(reward).to(device).float() action = torch.tensor(action).to(device) done = torch.tensor(done).to(device)</span></span></code> </pre><br>  Em seguida, precisamos calcular os valores reais da fun√ß√£o Q; no entanto, como n√£o os conhecemos, iremos avali√°-los atrav√©s dos valores para o seguinte estado: <br><br><pre> <code class="python hljs">target_q = torch.zeros(reward.size()[<span class="hljs-number"><span class="hljs-number">0</span></span>]).float().to(device) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): <span class="hljs-comment"><span class="hljs-comment">#     Q-function    target_q = target_model(next_state).max(1)[0].view(-1) target_q[done] = 0 target_q = reward + target_q * gamma</span></span></code> </pre><br>  E a previs√£o atual: <br><br><pre> <code class="python hljs">q = model(state).gather(<span class="hljs-number"><span class="hljs-number">1</span></span>, action.unsqueeze(<span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre><br>  Usando target_q e q, calculamos a fun√ß√£o de perda e atualizamos o modelo: <br><br><pre> <code class="python hljs">loss = F.smooth_l1_loss(q, target_q.unsqueeze(<span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-comment"><span class="hljs-comment">#      optimizer.zero_grad() #     loss.backward() #   . ,       for param in model.parameters(): param.grad.data.clamp_(-1, 1) #    optimizer.step()</span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Todos juntos</b> <div class="spoiler_text"><pre> <code class="python hljs">gamma = <span class="hljs-number"><span class="hljs-number">0.99</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(batch, model, target_model, optimizer)</span></span></span><span class="hljs-function">:</span></span> state, action, reward, next_state, done = batch <span class="hljs-comment"><span class="hljs-comment">#       state = torch.tensor(state).to(device).float() next_state = torch.tensor(next_state).to(device).float() reward = torch.tensor(reward).to(device).float() action = torch.tensor(action).to(device) done = torch.tensor(done).to(device) #  ,       target_q = torch.zeros(reward.size()[0]).float().to(device) with torch.no_grad(): #     Q-function    target_q = target_model(next_state).max(1)[0].view(-1) target_q[done] = 0 target_q = reward + target_q * gamma #   q = model(state).gather(1, action.unsqueeze(1)) loss = F.smooth_l1_loss(q, target_q.unsqueeze(1)) #      optimizer.zero_grad() #     loss.backward() #   . ,       for param in model.parameters(): param.grad.data.clamp_(-1, 1) #    optimizer.step()</span></span></code> </pre><br></div></div><br>  Como o modelo considera apenas a fun√ß√£o Q e n√£o executa a√ß√µes, precisamos determinar a fun√ß√£o que decidir√° quais a√ß√µes o agente executar√°.  Como algoritmo de tomada de decis√£o, tomamos <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ varepsilon </script>  pol√≠tica grega.  A ideia dela √© que o agente geralmente execute a√ß√µes com avidez, escolhendo o m√°ximo da fun√ß√£o Q, mas com probabilidade <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ varepsilon </script>  ele far√° uma a√ß√£o aleat√≥ria.  A√ß√µes aleat√≥rias s√£o necess√°rias para que o algoritmo possa examinar as a√ß√µes que ele n√£o executaria guiadas apenas por uma pol√≠tica gananciosa - esse processo √© chamado de explora√ß√£o. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">select_action</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(state, epsilon, model)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> random.random() &lt; epsilon: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model(torch.tensor(state).to(device).float().unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>))[<span class="hljs-number"><span class="hljs-number">0</span></span>].max(<span class="hljs-number"><span class="hljs-number">0</span></span>)[<span class="hljs-number"><span class="hljs-number">1</span></span>].view(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>).item()</code> </pre><br>  Como usamos lotes para treinar a rede neural, precisamos de um buffer no qual armazenaremos a experi√™ncia de interagir com o ambiente e de onde escolheremos os lotes: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Memory</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, capacity)</span></span></span><span class="hljs-function">:</span></span> self.capacity = capacity self.memory = [] self.position = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">push</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(self.memory) &lt; self.capacity: self.memory.append(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) self.memory[self.position] = element self.position = (self.position + <span class="hljs-number"><span class="hljs-number">1</span></span>) % self.capacity <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, batch_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list(zip(*random.sample(self.memory, batch_size))) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__len__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(self.memory)</code> </pre><br><h2>  Decis√£o ing√™nua </h2><br>  Primeiro, declare as constantes que usaremos no processo de aprendizado e crie um modelo: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  model   target model target_update = 1000 #  ,      batch_size = 128 #   max_steps = 100001 #  exploration max_epsilon = 0.5 min_epsilon = 0.1 #    memory = Memory(5000) model, target_model, optimizer = create_new_model()</span></span></code> </pre><br>  Apesar de ser l√≥gico dividir o processo de intera√ß√£o em epis√≥dios, para descrever o processo de aprendizado, √© mais conveniente dividi-lo em etapas separadas, pois queremos fazer uma etapa de gradiente descendente ap√≥s cada etapa do ambiente. <br><br>  Vamos falar mais detalhadamente sobre como uma etapa do aprendizado se parece aqui.  Assumimos que agora estamos dando um passo com o n√∫mero do passo de max_steps steps e o estado atual do estado.  Ent√£o, fazendo a a√ß√£o com <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-5"> \ varepsilon </script>  pol√≠ticas -greedy ficariam assim: <br><br><pre> <code class="python hljs">epsilon = max_epsilon - (max_epsilon - min_epsilon)* step / max_steps action = select_action(state, epsilon, model) new_state, reward, done, _ = env.step(action)</code> </pre><br>  Adicione imediatamente a experi√™ncia adquirida √† mem√≥ria e inicie um novo epis√≥dio se o atual terminar: <br><br><pre> <code class="python hljs">memory.push((state, action, reward, new_state, done)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> done: state = env.reset() done = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: state = new_state</code> </pre><br>  E daremos o passo da descida do gradiente (se, √© claro, j√° podemos coletar pelo menos um lote): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> step &gt; batch_size: fit(memory.sample(batch_size), model, target_model, optimizer)</code> </pre><br>  Agora resta atualizar o target_model: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> step % target_update == <span class="hljs-number"><span class="hljs-number">0</span></span>: target_model = copy.deepcopy(model)</code> </pre><br>  No entanto, tamb√©m gostar√≠amos de seguir o processo de aprendizado.  Para fazer isso, reproduziremos um epis√≥dio adicional ap√≥s cada atualiza√ß√£o do target_model com epsilon = 0, armazenando o pr√™mio total no buffer rewards_by_target_updates: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> step % target_update == <span class="hljs-number"><span class="hljs-number">0</span></span>: target_model = copy.deepcopy(model) state = env.reset() total_reward = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> done: action = select_action(state, <span class="hljs-number"><span class="hljs-number">0</span></span>, target_model) state, reward, done, _ = env.step(action) total_reward += reward done = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> state = env.reset() rewards_by_target_updates.append(total_reward)</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Todos juntos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  model   target model target_update = 1000 #  ,      batch_size = 128 #   max_steps = 100001 #  exploration max_epsilon = 0.5 min_epsilon = 0.1 def fit(): #    memory = Memory(5000) model, target_model, optimizer = create_new_model() for step in range(max_steps): #    epsilon = max_epsilon - (max_epsilon - min_epsilon)* step / max_steps action = select_action(state, epsilon, model) new_state, reward, done, _ = env.step(action) #  ,  ,   memory.push((state, action, reward, new_state, done)) if done: state = env.reset() done = False else: state = new_state #  if step &gt; batch_size: fit(memory.sample(batch_size), model, target_model, optimizer) if step % target_update == 0: target_model = copy.deepcopy(model) #Exploitation state = env.reset() total_reward = 0 while not done: action = select_action(state, 0, target_model) state, reward, done, _ = env.step(action) total_reward += reward done = False state = env.reset() rewards_by_target_updates.append(total_reward) return rewards_by_target_updates</span></span></code> </pre><br></div></div><br>  Execute este c√≥digo e obtenha algo como este gr√°fico: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e35/952/b37/e35952b375fc831ec4bd405303440509.png" alt="Gr√°fico de linha de base na forma de uma linha reta y = -200"><br><br><h2>  O que deu errado? </h2><br>  Isso √© um bug?  Esse √© o algoritmo errado?  Esses par√¢metros s√£o ruins?  Na verdade n√£o.  De fato, o problema est√° na tarefa, nomeadamente na fun√ß√£o da recompensa.  Vamos olhar mais de perto.  A cada passo, nosso agente recebe uma recompensa de -1, e isso acontece at√© o final do epis√≥dio.  Essa recompensa motiva o agente a concluir o epis√≥dio o mais r√°pido poss√≠vel, mas, ao mesmo tempo, n√£o diz a ele como faz√™-lo.  Por esse motivo, a √∫nica maneira de aprender a resolver um problema em uma formula√ß√£o desse tipo para um agente √© resolv√™-lo v√°rias vezes usando a explora√ß√£o. <br><br>  Obviamente, algu√©m poderia tentar usar algoritmos mais complexos para estudar o ambiente em vez do nosso <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ varepsilon </script>  pol√≠ticas de alta qualidade.  No entanto, primeiro, devido √† sua aplica√ß√£o, nosso modelo se tornar√° mais complexo, o que gostar√≠amos de evitar e, segundo, n√£o o fato de que eles funcionar√£o bem o suficiente para esta tarefa.  Em vez disso, podemos eliminar a fonte do problema modificando a tarefa em si, ou seja, alterando a fun√ß√£o de recompensa, ou seja,  aplicando o que √© chamado de modelagem de recompensa. <br><br><h2>  Acelerando a converg√™ncia </h2><br>  Nosso conhecimento intuitivo nos diz que, para subir a colina, voc√™ precisa acelerar.  Quanto maior a velocidade, mais pr√≥ximo o agente de resolver o problema.  Voc√™ pode contar a ele sobre isso, por exemplo, adicionando um m√≥dulo de velocidade com um certo coeficiente √† recompensa: <pre>  modified_reward = recompensa + 10 * abs (novo_estado [1]) </pre><br><br>  Assim, uma linha na fun√ß√£o se ajusta <pre>  memory.push ((estado, a√ß√£o, recompensa, new_state, done)) </pre>  deve ser substitu√≠do por <pre>  memory.push ((estado, a√ß√£o, recompensa_modificada, novo_estado, conclu√≠do)) </pre>  Agora, vejamos o novo gr√°fico (ele apresenta o pr√™mio <b>original</b> sem modifica√ß√µes): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c19/3c2/925/c193c2925d13ba1977cf525697cba1c2.png" alt="Gr√°fico de linha de base versus RS"><br>  <i>Aqui RS √© a abrevia√ß√£o de Reward Shaping.</i> <br><br><h2>  √â bom fazer isso? </h2><br>  O progresso √© √≥bvio: nosso agente aprendeu claramente a subir a colina, pois o pr√™mio come√ßou a diferir de -200.  Resta apenas uma pergunta: se alterar a fun√ß√£o da recompensa, tamb√©m alteramos a tarefa, a solu√ß√£o para o novo problema que achamos √© boa para o antigo problema? <br><br>  Para come√ßar, entendemos o que ‚Äúbondade‚Äù significa no nosso caso.  Resolvendo o problema, estamos tentando encontrar a pol√≠tica ideal - uma que maximize a recompensa total pelo epis√≥dio.  Nesse caso, podemos substituir a palavra "bom" pela palavra "ideal", porque estamos procurando por ela.  Tamb√©m esperamos otimista que, mais cedo ou mais tarde, nosso DQN encontre a solu√ß√£o ideal para o problema modificado e n√£o fique preso no m√°ximo local.  Portanto, a quest√£o pode ser reformulada da seguinte maneira: se alterar a fun√ß√£o da recompensa, tamb√©m alteramos o problema, a solu√ß√£o ideal para o novo problema que achamos √© ideal para o problema antigo? <br><br>  Como se v√™, n√£o podemos fornecer essa garantia no caso geral.  A resposta depende de como exatamente mudamos a fun√ß√£o da recompensa, como ela foi organizada anteriormente e como o pr√≥prio ambiente √© organizado.  Felizmente, h√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> cujos autores investigaram como a altera√ß√£o da fun√ß√£o da recompensa afeta a otimiza√ß√£o da solu√ß√£o encontrada. <br><br>  Primeiro, eles encontraram toda uma classe de altera√ß√µes "seguras", baseadas no m√©todo potencial: <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>R</mi><mo>&amp;#x2032;</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mtext>&amp;#xA0;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><mi>a</mi><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&amp;#xA0;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>o</mi><mi>v</mi><mi>o</mi><msub><mtext>&amp;#xA0;</mtext><mi>e</mi></msub><mi>s</mi><mi>t</mi><mi>a</mi><mi>d</mi><mi>o</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy=&quot;false&quot;>(</mo><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>d</mi><mi>o</mi><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="58.809ex" height="2.66ex" viewBox="0 -832 25320.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-2032" x="1074" y="513"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-3D" x="1332" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-52" x="2388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-2B" x="3370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-28" x="4370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-67" x="5010" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="5490" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6D" x="6020" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6D" x="6898" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="7777" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-63" x="8556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-64" x="8990" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="9513" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="9999" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-50" x="10610" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-68" x="11362" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="11938" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-28" x="12284" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6E" x="12673" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="13274" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-76" x="13759" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="14245" y="0"></use><g transform="translate(14730,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-65" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="15410" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="15880" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="16241" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-64" x="16771" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="17294" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-29" x="17780" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-2212" x="18391" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-50" x="19642" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-68" x="20394" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="20970" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-28" x="21316" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-65" x="21705" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="22172" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-74" x="22641" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="23003" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-64" x="23532" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-6F" x="24056" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-29" x="24541" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-29" x="24931" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mo>‚Ä≤</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mo stretchy="false">(</mo><mtext>&nbsp;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><mi>a</mi><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy="false">(</mo><mi>n</mi><mi>o</mi><mi>v</mi><mi>o</mi><msub><mtext>&nbsp;</mtext><mi>e</mi></msub><mi>s</mi><mi>t</mi><mi>a</mi><mi>d</mi><mi>o</mi><mo stretchy="false">)</mo><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy="false">(</mo><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>d</mi><mi>o</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-7"> R '= R + (\ gamma \ cdot \ Phi (novo \ _estado) - \ Phi (estado)) </script>  onde <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>P</mi><mi>h</mi><mi>i</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.468ex" height="2.057ex" viewBox="0 -780.1 1923.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-50" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-68" x="1001" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-69" x="1578" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>P</mi><mi>h</mi><mi>i</mi></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ Phi </script>  - potencial, que depende apenas do estado.  Para tais fun√ß√µes, os autores conseguiram provar que se a solu√ß√£o para o novo problema √© √≥tima, ent√£o para o antigo problema ela tamb√©m √© √≥tima. <br><br>  Em segundo lugar, os autores mostraram que, para qualquer outro <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>R</mi><mo>&amp;#x2032;</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mi>F</mi><mo stretchy=&quot;false&quot;>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.056ex" height="2.66ex" viewBox="0 -832 7343.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-2032" x="1074" y="513"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-3D" x="1332" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-52" x="2388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-2B" x="3370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-46" x="4370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-28" x="5120" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-73" x="5509" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-2C" x="5979" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMATHI-61" x="6424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhjFYiKRXb8U663iizq0XNBT5oL1xQ#MJMAIN-29" x="6953" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mo>‚Ä≤</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mi>F</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-9"> R '= R + F (s, a) </script>  existe esse problema, a fun√ß√£o de recompensa R e a solu√ß√£o ideal para o problema alterado, que essa solu√ß√£o n√£o √© ideal para o problema original.  Isso significa que n√£o podemos garantir a qualidade da solu√ß√£o encontrada, se usarmos uma altera√ß√£o que n√£o seja baseada no m√©todo potencial. <br><br>  Assim, o uso de fun√ß√µes potenciais para modificar a fun√ß√£o de recompensa pode alterar apenas a taxa de converg√™ncia do algoritmo, mas n√£o afeta a solu√ß√£o final. <br><br><h2>  Acelere a converg√™ncia corretamente </h2><br>  Agora que sabemos como alterar a recompensa com seguran√ßa, vamos tentar modificar a tarefa novamente, usando o m√©todo potencial em vez de heur√≠sticas ing√™nuas: <pre>  modified_reward = recompensa + 300 * (gama * abs (novo_estado [1]) - abs (estado [1])) </pre><br>  Vejamos a programa√ß√£o do pr√™mio original: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ba/a60/5dc/6baa605dc8dd5ad8e7bf154e5dde3c74.png" alt="Gr√°fico comparando linha de base, RS e RS com pre√ßos"><br><br>  Como se viu, al√©m de ter garantias te√≥ricas, a modifica√ß√£o da recompensa com a ajuda de fun√ß√µes potenciais tamb√©m melhorou significativamente o resultado, especialmente nos est√°gios iniciais.  Obviamente, h√° uma chance de que seria poss√≠vel selecionar hiperpar√¢metros √≥timos (semente aleat√≥ria, gama e outros coeficientes) para treinar o agente, mas a forma de recompensa, no entanto, aumenta significativamente a taxa de converg√™ncia do modelo. <br><br><h2>  Posf√°cio </h2><br>  Obrigado por ler at√© o fim!  Espero que voc√™ tenha gostado dessa pequena excurs√£o orientada √† pr√°tica para o aprendizado refor√ßado.  Est√° claro que o Mountain Car √© uma tarefa de "brinquedo", no entanto, como pudemos observar, ensinar um agente a resolver at√© uma tarefa aparentemente t√£o simples do ponto de vista humano pode ser dif√≠cil. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt444428/">https://habr.com/ru/post/pt444428/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt444418/index.html">Milh√µes de bin√°rios depois. Como o Linux foi fortalecido</a></li>
<li><a href="../pt444420/index.html">Como andar de duas rodas para trabalhar</a></li>
<li><a href="../pt444422/index.html">Como era em 2018: impress√£o industrial FDM na Top 3D Expo</a></li>
<li><a href="../pt444424/index.html">AMD Radeon VII: chip de √∫ltima gera√ß√£o (parte 2)</a></li>
<li><a href="../pt444426/index.html">Lyft e Uber fazem abertura de capital p√∫blica. Por que investir na Lyft?</a></li>
<li><a href="../pt444430/index.html">An√°lise: como realmente usar o Present Perfect em ingl√™s</a></li>
<li><a href="../pt444432/index.html">Aplica√ß√£o de Linux e software de c√≥digo aberto em nossa institui√ß√£o educacional: ser ou n√£o ser?</a></li>
<li><a href="../pt444434/index.html">Chegou a hora do Java 12! Revis√£o dos PECs quentes</a></li>
<li><a href="../pt444436/index.html">O que √© um botnet Mirai e como posso proteger meus dispositivos?</a></li>
<li><a href="../pt444438/index.html">Uma breve hist√≥ria do c√≥digo aberto - como o software livre lutou com propriet√°rios</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
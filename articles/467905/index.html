<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïë üßëüèø‚Äçü§ù‚Äçüßëüèø üë¨ C√≥mo hicimos un reconocimiento hist√≥rico en Cloud Mail.ru y por qu√© üë©üèæ‚Äçüéì üßôüèΩ üöµüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Con la llegada de los tel√©fonos m√≥viles con c√°maras de alta calidad, comenzamos a tomar m√°s y m√°s fotos y videos de momentos brillantes y memorables e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo hicimos un reconocimiento hist√≥rico en Cloud Mail.ru y por qu√©</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/467905/"><img src="https://habrastorage.org/webt/vz/bg/ov/vzbgovf2e5gessaexiyl0rnhvay.jpeg"><br><br>  Con la llegada de los tel√©fonos m√≥viles con c√°maras de alta calidad, comenzamos a tomar m√°s y m√°s fotos y videos de momentos brillantes y memorables en nuestras vidas.  Muchos de nosotros tenemos archivos de fotos que se extienden por d√©cadas y comprenden miles de im√°genes, lo que hace que sea cada vez m√°s dif√≠cil navegar por ellas.  Solo recuerde cu√°nto tiempo tard√≥ en encontrar una imagen de inter√©s hace solo unos a√±os. <br><br>  Uno de los objetivos de Mail.ru Cloud es proporcionar los medios m√°s √∫tiles para acceder y buscar sus propios archivos de fotos y videos.  Para este prop√≥sito, nosotros en Mail.ru Computer Vision Team hemos creado e implementado sistemas para el procesamiento inteligente de im√°genes: b√∫squeda por objeto, por escena, por cara, etc.  Otra tecnolog√≠a espectacular es el reconocimiento hist√≥rico.  Hoy les voy a contar c√≥mo hicimos esto realidad usando Deep Learning. <br><a name="habracut"></a><br>  Imagina la situaci√≥n: regresas de tus vacaciones con un mont√≥n de fotos.  Hablando con tus amigos, se te pide que muestres una imagen de un lugar que valga la pena ver, como palacio, castillo, pir√°mide, templo, lago, cascada, monta√±a, etc.  Te apresuras a desplazarte por la carpeta de tu galer√≠a tratando de encontrar una que sea realmente buena.  Lo m√°s probable es que se pierda entre cientos de im√°genes, y usted dice que lo mostrar√° m√°s tarde. <br><br>  Resolvemos este problema agrupando las fotos de los usuarios en √°lbumes.  Esto le permitir√° encontrar las im√°genes que necesita con solo unos pocos clics.  Ahora tenemos √°lbumes compilados por cara, por objeto y por escena, y tambi√©n por hito. <br><br>  Las fotos con puntos de referencia son esenciales porque a menudo capturan lo m√°s destacado de nuestras vidas (viajes, por ejemplo).  Estas pueden ser im√°genes con alguna arquitectura o desierto en el fondo.  Es por eso que buscamos localizar tales im√°genes y ponerlas a disposici√≥n de los usuarios. <br><br><h2>  Peculiaridades del reconocimiento hist√≥rico </h2><br>  Aqu√≠ hay un matiz: uno no solo ense√±a un modelo y hace que reconozca los puntos de referencia de inmediato, hay una serie de desaf√≠os. <br><br>  Primero, no podemos decir claramente qu√© es realmente un "hito".  No podemos decir por qu√© un edificio es un hito, mientras que otro al lado no lo es.  No es un concepto formalizado, lo que hace que sea m√°s complicado establecer la tarea de reconocimiento. <br><br>  En segundo lugar, los puntos de referencia son incre√≠blemente diversos.  Estos pueden ser edificios de valor hist√≥rico o cultural, como un templo, palacio o castillo.  Alternativamente, estos pueden ser todo tipo de monumentos.  O caracter√≠sticas naturales: lagos, ca√±ones, cascadas, etc.  Adem√°s, hay un modelo √∫nico que deber√≠a poder encontrar todos esos puntos de referencia. <br><br>  Tercero, las im√°genes con puntos de referencia son extremadamente pocas.  Seg√∫n nuestras estimaciones, representan solo del 1 al 3 por ciento de las fotos de los usuarios.  Es por eso que no podemos permitirnos cometer errores en el reconocimiento porque si le mostramos a alguien una fotograf√≠a sin un hito, ser√° bastante obvio y causar√° una reacci√≥n adversa.  O, por el contrario, imagine que muestra una foto con un lugar de inter√©s en Nueva York a una persona que nunca ha estado en los Estados Unidos.  Por lo tanto, el modelo de reconocimiento debe tener una FPR baja (tasa de falsos positivos). <br><br>  Cuarto, alrededor del 50% de los usuarios o incluso m√°s suelen deshabilitar el almacenamiento de datos geogr√°ficos.  Necesitamos tener esto en cuenta y usar solo la imagen en s√≠ para identificar la ubicaci√≥n.  Hoy en d√≠a, la mayor√≠a de los servicios capaces de manejar puntos de referencia de alguna manera usan geodatos de propiedades de imagen.  Sin embargo, nuestros requisitos iniciales fueron m√°s estrictos. <br><br>  Ahora d√©jame mostrarte algunos ejemplos. <br><br>  Aqu√≠ hay tres objetos parecidos, tres catedrales g√≥ticas en Francia.  A la izquierda est√° la catedral de Amiens, la del medio es la catedral de Reims y Notre-Dame de Paris a la derecha. <br><br><img src="https://habrastorage.org/webt/bh/4f/ej/bh4fejtind2ngdha-cgxdgkqf9g.jpeg"><br><br>  Incluso un humano necesita algo de tiempo para mirar de cerca y ver que se trata de catedrales diferentes, pero el motor deber√≠a ser capaz de hacer lo mismo, e incluso m√°s r√°pido que un humano. <br><br>  Aqu√≠ hay otro desaf√≠o: las tres fotos aqu√≠ muestran la toma de Notre-Dame de Paris desde diferentes √°ngulos.  Las fotos son bastante diferentes, pero a√∫n deben reconocerse y recuperarse. <br><br><img src="https://habrastorage.org/webt/vx/de/wr/vxdewr0j1vdlm8knfq2_z_6n95u.jpeg"><br><br>  Las caracter√≠sticas naturales son completamente diferentes de la arquitectura.  A la izquierda est√° Cesarea en Israel, a la derecha est√° Englischer Garten en Munich. <br><br><img src="https://habrastorage.org/webt/y6/6o/mb/y66ombyco0nzwj3ghhjumufaiz4.jpeg"><br><br>  Estas fotos le dan al modelo muy pocas pistas para adivinar. <br><br><h2>  Nuestro metodo </h2><br>  Nuestro m√©todo se basa completamente en redes neuronales convolucionales profundas.  La estrategia de capacitaci√≥n que elegimos fue el llamado aprendizaje curricular, que significa aprender en varios pasos.  Para lograr una mayor eficiencia con y sin datos geogr√°ficos disponibles, hicimos una inferencia espec√≠fica.  D√©jame contarte sobre cada paso con m√°s detalle. <br><br><h2>  Conjunto de datos </h2><br>  Los datos son el combustible del aprendizaje autom√°tico.  En primer lugar, tuvimos que reunir un conjunto de datos para ense√±ar el modelo. <br><br>  Dividimos el mundo en 4 regiones, cada una de las cuales se usa en un paso espec√≠fico del proceso de aprendizaje.  Luego, seleccionamos pa√≠ses en cada regi√≥n, seleccionamos una lista de ciudades para cada pa√≠s y recopilamos un banco de fotos.  A continuaci√≥n hay algunos ejemplos. <br><br><img src="https://habrastorage.org/webt/cm/al/en/cmalenos8kpuchcb7ridv6m5rge.jpeg"><br><br>  Primero, intentamos que nuestro modelo aprendiera de la base de datos obtenida.  Los resultados fueron pobres.  Nuestro an√°lisis mostr√≥ que los datos estaban sucios.  Hab√≠a demasiado ruido interfiriendo con el reconocimiento de cada punto de referencia.  ¬øQu√© √≠bamos a hacer?  Ser√≠a costoso, engorroso y no demasiado sabio revisar manualmente la mayor parte de los datos.  Por lo tanto, dise√±amos un proceso para la limpieza autom√°tica de la base de datos donde el manejo manual se usa solo en un paso: seleccionamos de 3 a 5 fotograf√≠as de referencia para cada punto de referencia que definitivamente mostraban el objeto deseado en un √°ngulo m√°s o menos adecuado.  Funciona lo suficientemente r√°pido porque la cantidad de dichos datos de referencia es peque√±a en comparaci√≥n con toda la base de datos.  Luego se realiza una limpieza autom√°tica basada en redes neuronales convolucionales profundas. <br><br>  M√°s adelante, voy a utilizar el t√©rmino "incrustaci√≥n" con el que me refiero a lo siguiente.  Tenemos una red neuronal convolucional.  Lo entrenamos para clasificar objetos, luego cortamos la √∫ltima capa de clasificaci√≥n, seleccionamos algunas im√°genes, las analizamos por la red y obtuvimos un vector num√©rico en la salida.  Esto es lo que llamar√© incrustaci√≥n. <br><br>  Como dije antes, organizamos nuestro proceso de aprendizaje en varios pasos correspondientes a partes de nuestra base de datos.  Entonces, primero, tomamos la red neuronal del paso anterior o la red de inicializaci√≥n. <br><br>  Tenemos fotos de referencia de un hito, las procesamos por la red y obtenemos varias incrustaciones.  Ahora podemos proceder a la limpieza de datos.  Tomamos todas las im√°genes del conjunto de datos para el punto de referencia y tambi√©n procesamos cada una por la red.  Obtenemos algunas incrustaciones y determinamos la distancia a las incrustaciones de referencia para cada una.  Luego, determinamos la distancia promedio y, si excede alg√∫n umbral que es un par√°metro del algoritmo, tratamos el objeto como un no hito.  Si la distancia promedio es menor que el umbral, conservamos la fotograf√≠a. <br><br><img src="https://habrastorage.org/webt/cl/s7/xu/cls7xusqgmt6mmx5uoyksvkvg4s.jpeg"><br><br>  Como resultado, ten√≠amos una base de datos que conten√≠a m√°s de 11 mil puntos de referencia de m√°s de 500 ciudades en 70 pa√≠ses, m√°s de 2.3 millones de fotos.  Recuerde que la mayor parte de las fotograf√≠as no tiene puntos de referencia.  Necesitamos dec√≠rselo a nuestros modelos de alguna manera.  Por esta raz√≥n, agregamos 900 mil fotos sin puntos de referencia a nuestra base de datos y capacitamos a nuestro modelo con el conjunto de datos resultante. <br><br>  Introdujimos una prueba fuera de l√≠nea para medir la calidad del aprendizaje.  Dado que los puntos de referencia ocurren solo en 1 a 3% de todas las fotos, compilamos manualmente un conjunto de 290 im√°genes que mostraban un punto de referencia.  Esas fotos eran bastante diversas y complejas, con una gran cantidad de objetos tomados desde diferentes √°ngulos para hacer la prueba lo m√°s dif√≠cil posible para el modelo.  Siguiendo el mismo patr√≥n, seleccionamos 11 mil fotograf√≠as sin puntos de referencia, tambi√©n bastante complicadas, e intentamos encontrar objetos que se parecieran mucho a los puntos de referencia en nuestra base de datos. <br><br>  Para evaluar la calidad del aprendizaje, medimos la precisi√≥n de nuestro modelo utilizando fotos con y sin puntos de referencia.  Estas son nuestras dos m√©tricas principales. <br><br><h2>  Enfoques existentes </h2><br>  Hay relativamente poca informaci√≥n sobre el reconocimiento de puntos de referencia en la literatura.  La mayor√≠a de las soluciones se basan en caracter√≠sticas locales.  La idea principal es que tenemos una imagen de consulta y una imagen de la base de datos.  Las caracter√≠sticas locales (puntos clave) se encuentran y luego se combinan.  Si el n√∫mero de coincidencias es lo suficientemente grande, concluimos que hemos encontrado un punto de referencia. <br><br>  Actualmente, el mejor m√©todo es DELF (caracter√≠sticas locales profundas) que ofrece Google, que combina caracter√≠sticas locales que coinciden con el aprendizaje profundo.  Al tener una imagen de entrada procesada por la red convolucional, obtenemos algunas caracter√≠sticas DELF. <br><br><img src="https://habrastorage.org/webt/i9/-5/g-/i9-5g-dj0fkjpxlgnjpwaadwyec.jpeg"><br><br>  ¬øC√≥mo funciona el reconocimiento de puntos de referencia?  Tenemos un banco de fotos y una imagen de entrada, y queremos saber si muestra un hito o no.  Al ejecutar la red DELF de todas las fotos, se pueden obtener las caracter√≠sticas correspondientes para la base de datos y la imagen de entrada.  Luego realizamos una b√∫squeda por el m√©todo de vecino m√°s cercano y obtenemos im√°genes candidatas con caracter√≠sticas en la salida.  Utilizamos la verificaci√≥n geom√©trica para que coincida con las caracter√≠sticas: si tiene √©xito, concluimos que la imagen muestra un hito. <br><br><h2>  Red neuronal convolucional </h2><br>  La capacitaci√≥n previa es crucial para el aprendizaje profundo.  Entonces utilizamos una base de datos de escenas para entrenar previamente nuestra red neuronal.  ¬øPor qu√© de esta manera?  Una escena es un objeto m√∫ltiple que comprende una gran cantidad de otros objetos.  Landmark es una instancia de una escena.  Al entrenar previamente el modelo con dicha base de datos, podemos darle una idea de algunas caracter√≠sticas de bajo nivel que luego se pueden generalizar para un reconocimiento exitoso de puntos de referencia. <br><br>  Utilizamos una red neuronal de la familia de redes residuales como modelo.  La diferencia cr√≠tica de tales redes es que usan un bloque residual que incluye una conexi√≥n de salto que permite que una se√±al salte sobre capas con pesos y pase libremente.  Dicha arquitectura permite entrenar redes profundas con un alto nivel de calidad y controlar el efecto de gradiente de fuga, que es esencial para el entrenamiento. <br><br>  Nuestro modelo es Wide ResNet-50-2, una versi√≥n de ResNet-50 donde el n√∫mero de convoluciones en el bloque de cuello de botella interno se duplica. <br><br><img src="https://habrastorage.org/webt/s0/mg/ra/s0mgravn9tobelwyraas7v-umfi.jpeg"><br><br>  La red funciona muy bien.  Lo probamos con nuestra base de datos de escenas, y aqu√≠ est√°n los resultados: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo <br></th><th>  Top 1 err <br></th><th>  Top 5 err <br></th></tr><tr><td>  ResNet-50 <br></td><td>  46,1% <br></td><td>  15,7% <br></td></tr><tr><td>  ResNet-200 <br></td><td>  42,6% <br></td><td>  12,9% <br></td></tr><tr><td>  SE-ResNext-101 <br></td><td>  42% <br></td><td>  12,1% <br></td></tr><tr><td>  WRN-50-2 (¬°r√°pido!) <br></td><td>  41,8% <br></td><td>  11,8% <br></td></tr></tbody></table></div><br>  Wide ResNet funcion√≥ casi el doble de r√°pido que ResNet-200.  Despu√©s de todo, la velocidad de funcionamiento es crucial para la producci√≥n.  Dadas todas estas consideraciones, elegimos Wide ResNet-50-2 como nuestra red neuronal principal. <br><br><h2>  Entrenamiento </h2><br>  Necesitamos una funci√≥n de p√©rdida para entrenar nuestra red.  Decidimos utilizar un enfoque de aprendizaje m√©trico para elegirlo: se entrena una red neuronal para que los elementos de la misma clase se agrupen en un grupo, mientras que los grupos para diferentes clases se deben separar tanto como sea posible.  Para los puntos de referencia, utilizamos la p√©rdida de centro que arrastra elementos de una clase hacia alg√∫n centro.  Una caracter√≠stica importante de este enfoque es que no requiere muestreo negativo, lo que se convierte en algo bastante dif√≠cil de hacer en √©pocas posteriores. <br><br><img src="https://habrastorage.org/webt/ix/xd/if/ixxdifizq_hbvfbz6vloiqc_ppk.jpeg"><br><br>  Recuerde que tenemos n clases de puntos de referencia y una clase m√°s de "no puntos de referencia" para los que no se utiliza la p√©rdida de centro.  Implicamos que un punto de referencia es uno y el mismo objeto, y tiene estructura, por lo que tiene sentido determinar su centro.  En cuanto a la no referencia, puede referirse a lo que sea, por lo que no tiene sentido determinar el centro. <br><br>  Luego juntamos todo esto, y existe nuestro modelo de capacitaci√≥n.  Se compone de tres partes principales: <br><br><ul><li>  Amplia red neuronal convolucional ResNet 50-2 pre-entrenada con una base de datos de escenas; </li><li>  Parte de incrustaci√≥n que comprende una capa totalmente conectada y una capa de norma Batch </li><li>  Clasificador que es una capa totalmente conectada, seguida de un par compuesto por p√©rdida Softmax y p√©rdida central. </li></ul><br><img src="https://habrastorage.org/webt/pt/k0/g_/ptk0g_0cyy3qgfw0wp8d4zqfd3k.jpeg"><br><br>  Como recordar√°, nuestra base de datos est√° dividida en 4 partes por regi√≥n.  Utilizamos estas 4 partes en un paradigma de aprendizaje curricular.  Tenemos un conjunto de datos actual y, en cada etapa del aprendizaje, agregamos otra parte del mundo para obtener un nuevo conjunto de datos para capacitaci√≥n. <br><br>  El modelo consta de tres partes, y utilizamos una tasa de aprendizaje espec√≠fica para cada una en el proceso de capacitaci√≥n.  Esto es necesario para que la red pueda aprender puntos de referencia de una nueva parte del conjunto de datos que hemos agregado y recordar datos ya aprendidos.  Muchos experimentos demostraron que este enfoque es el m√°s eficiente. <br><br>  Entonces, hemos entrenado nuestro modelo.  Ahora tenemos que darnos cuenta de c√≥mo funciona.  Usemos el mapa de activaci√≥n de clase para encontrar la parte de la imagen a la que nuestra red neuronal reacciona m√°s f√°cilmente.  La siguiente imagen muestra im√°genes de entrada en la primera fila, y las mismas im√°genes superpuestas con el mapa de activaci√≥n de clase de la red que hemos entrenado en el paso anterior se muestran en la segunda fila. <br><br><img src="https://habrastorage.org/webt/_e/p6/x0/_ep6x0-7sjfjfkrmyyrxfhlunsq.jpeg"><br><br>  El mapa de calor muestra qu√© partes de la imagen son m√°s atendidas por la red.  Como se muestra en el mapa de activaci√≥n de clase, nuestra red neuronal ha aprendido el concepto de punto de referencia con √©xito. <br><br><h2>  Inferencia </h2><br>  Ahora necesitamos usar este conocimiento de alguna manera para hacer las cosas.  Como hemos utilizado la p√©rdida de centro para el entrenamiento, en el caso de inferencia, parece ser bastante l√≥gico determinar los centroides para puntos de referencia tambi√©n. <br><br>  Para hacer esto, tomamos una parte de las im√°genes del conjunto de entrenamiento para alg√∫n hito, por ejemplo, el Jinete de Bronce en San Petersburgo.  Luego los tenemos procesados ‚Äã‚Äãpor la red, obtener incrustaciones, promediar y derivar un centroide. <br><br><img src="https://habrastorage.org/webt/zy/di/6f/zydi6frte3yxetvtnnkwak2t9y4.jpeg"><br><br>  Sin embargo, aqu√≠ hay una pregunta: ¬øcu√°ntos centroides por punto de referencia tiene sentido derivar?  Inicialmente, parec√≠a ser claro y l√≥gico decir: un centroide.  No exactamente, como result√≥.  Inicialmente decidimos hacer un solo centroide tambi√©n, y el resultado no fue malo.  Entonces, ¬øpor qu√© varios centroides? <br><br>  Primero, los datos que tenemos no son tan limpios.  Aunque hemos limpiado el conjunto de datos, eliminamos solo los datos de desperdicio obvios.  Sin embargo, todav√≠a podr√≠a haber im√°genes que obviamente no se desperdician sino que afectan negativamente el resultado. <br><br>  Por ejemplo, tengo una clase hist√≥rica en el Palacio de Invierno en San Petersburgo.  Quiero derivar un centroide para ello.  Sin embargo, su conjunto de datos incluye algunas fotos con la Plaza del Palacio y el arco de la Sede General, porque estos objetos est√°n cerca uno del otro.  Si se determina el centroide para todas las im√°genes, el resultado no ser√° tan estable.  Lo que tenemos que hacer es agrupar de alguna manera sus incrustaciones derivadas de la red neuronal, tomar solo el centroide que trata con el Palacio de Invierno y promediar usando los datos resultantes. <br><br><img src="https://habrastorage.org/webt/do/2n/lz/do2nlzvg9awjggqsodeuxn9hz3o.jpeg"><br><br>  En segundo lugar, las fotograf√≠as podr√≠an haber sido tomadas desde diferentes √°ngulos. <br><br>  Aqu√≠ hay un ejemplo de tal comportamiento ilustrado con el Campanario de Brujas.  Se han derivado dos centroides para ello.  En la fila superior de la imagen, est√°n las fotos que est√°n m√°s cerca del primer centroide, y en la segunda fila, las que est√°n m√°s cerca del segundo centroide. <br><br><img src="https://habrastorage.org/webt/34/uo/n5/34uon5ifrysj8l9xlh3wwykzw6o.jpeg"><br><br>  El primer centroide trata con m√°s fotograf√≠as "grandiosas" que fueron tomadas en el mercado de Brujas a corta distancia.  El segundo centroide trata con fotograf√≠as tomadas desde la distancia en calles particulares. <br><br>  Como resultado, al derivar varios centroides por clase de punto de referencia, podemos reflexionar sobre la inferencia de diferentes √°ngulos de c√°mara para ese punto de referencia. <br><br>  Entonces, ¬øc√≥mo obtenemos esos conjuntos para derivar los centroides?  Aplicamos la agrupaci√≥n jer√°rquica (enlace completo) a los conjuntos de datos para cada punto de referencia.  Lo usamos para encontrar grupos v√°lidos de los cuales se derivar√°n los centroides.  Por agrupaciones v√°lidas nos referimos a aquellas que comprenden al menos 50 fotograf√≠as como resultado de la agrupaci√≥n.  Los otros grupos son rechazados.  Como resultado, obtuvimos alrededor del 20% de los puntos de referencia con m√°s de un centroide. <br><br>  Ahora a inferencia.  Se obtiene en dos pasos: en primer lugar, alimentamos la imagen de entrada a nuestra red neuronal convolucional y obtenemos la incrustaci√≥n, y luego hacemos coincidir la incrustaci√≥n con los centroides usando el producto punto.  Si las im√°genes tienen datos geogr√°ficos, restringimos la b√∫squeda a los centroides, que se refieren a puntos de referencia ubicados dentro de un cuadrado de 1x1 km desde la ubicaci√≥n de la imagen.  Esto permite una b√∫squeda m√°s precisa y un umbral m√°s bajo para la coincidencia posterior.  Si la distancia resultante excede el umbral, que es un par√°metro del algoritmo, entonces concluimos que una foto tiene un punto de referencia con el valor m√°ximo del producto de puntos.  Si es menor, entonces es una foto no hist√≥rica. <br><br><img src="https://habrastorage.org/webt/mi/pl/os/miplosde7vmgj1ty5qlsjzabc2u.png"><br><br>  Supongamos que una foto tiene un hito.  Si tenemos datos geogr√°ficos, los usamos y derivamos una respuesta.  Si los datos geogr√°ficos no est√°n disponibles, ejecutamos una verificaci√≥n adicional.  Cuando est√°bamos limpiando el conjunto de datos, creamos un conjunto de im√°genes de referencia para cada clase.  Podemos determinar las incrustaciones para ellos y luego obtener una distancia promedio desde ellos hasta la incrustaci√≥n de la imagen de consulta.  Si excede alg√∫n umbral, se pasa la verificaci√≥n y traemos metadatos y obtenemos un resultado.  Es importante tener en cuenta que podemos ejecutar este procedimiento para varios puntos de referencia que se han encontrado en una imagen. <br><br><img src="https://habrastorage.org/webt/rw/kd/ht/rwkdhtwi78ko9fohfgj2dex-lro.png"><br><br><h2>  Resultados de pruebas </h2><br>  Comparamos nuestro modelo con DELF, para lo cual tomamos par√°metros con los que mostrar√≠a el mejor rendimiento en nuestra prueba.  Los resultados son casi id√©nticos. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo <br></th><th>  Punto de referencia <br></th><th>  No hito <br></th></tr><tr><td>  Nuestro modelo <br></td><td>  80% <br></td><td>  99% <br></td></tr><tr><td>  Delf <br></td><td>  80,1% <br></td><td>  99% <br></td></tr></tbody></table></div><br>  Luego clasificamos los puntos de referencia en dos tipos: frecuentes (m√°s de 100 fotograf√≠as en la base de datos), que representaron el 87% de todos los puntos de referencia en la prueba, y raros.  Nuestro modelo funciona bien con los frecuentes: 85.3% de precisi√≥n.  Con puntos de referencia raros, tuvimos un 46%, que tampoco estuvo nada mal, lo que significa que nuestro enfoque funcion√≥ bastante bien incluso con pocos datos. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Tipo <br></th><th>  Precisi√≥n <br></th><th>  Parte del n√∫mero total <br></th></tr><tr><td>  Frecuente <br></td><td>  85,3% <br></td><td>  87% <br></td></tr><tr><td>  Raro <br></td><td>  46% <br></td><td>  13% <br></td></tr></tbody></table></div><br>  Luego realizamos una prueba A / B con fotos de los usuarios.  Como resultado, la tasa de conversi√≥n de compra de espacio en la nube aument√≥ en un 10%, la tasa de conversi√≥n de desinstalaci√≥n de aplicaciones m√≥viles se redujo en un 3% y la cantidad de vistas de √°lbumes aument√≥ en un 13%. <br><br>  Comparemos nuestra velocidad con la de DELF.  Con GPU, DELF requiere 7 ejecuciones de red porque usa 7 escalas de imagen, mientras que nuestro enfoque usa solo 1. Con CPU, DELF usa una b√∫squeda m√°s larga por el m√©todo del vecino m√°s cercano y una verificaci√≥n geom√©trica muy larga.  Al final, nuestro m√©todo fue 15 veces m√°s r√°pido con la CPU.  Nuestro enfoque muestra una mayor velocidad en ambos casos, que es crucial para la producci√≥n. <br><br><h2>  Resultados: recuerdos de vacaciones </h2><br>  Al comienzo de este art√≠culo, mencion√© una soluci√≥n para desplazarse y encontrar im√°genes de referencia deseadas.  Aqui esta <br><br><img src="https://habrastorage.org/webt/ps/x_/7x/psx_7x8ptraq4s_tjodrfhi3g6o.jpeg"><br><br>  Esta es mi nube donde todas las fotos se clasifican en √°lbumes.  Hay √°lbumes "Personas", "Objetos" y "Atracciones".  En el √°lbum Atracciones, los puntos de referencia se clasifican en √°lbumes agrupados por ciudad.  Un clic en Dresdner Zwinger abre un √°lbum con fotos de este hito solamente. <br><br><img src="https://habrastorage.org/webt/sf/qa/bz/sfqabzwvyehdtq9nv4ko85rbnnu.jpeg" width="400"><br><br>  Una caracter√≠stica √∫til: puede irse de vacaciones, tomar algunas fotos y almacenarlas en su nube.  M√°s tarde, cuando desee subirlos a Instagram o compartirlos con amigos y familiares, no tendr√° que buscar y elegir demasiado tiempo: las fotos deseadas estar√°n disponibles con solo unos pocos clics. <br><br><h2>  Conclusiones </h2><br>  Perm√≠tame recordarle las caracter√≠sticas clave de nuestra soluci√≥n. <br><br><ol><li>  Limpieza de bases de datos semiautom√°tica.  Se requiere un poco de trabajo manual para el mapeo inicial, y luego la red neuronal har√° el resto.  Esto permite limpiar nuevos datos r√°pidamente y usarlos para volver a entrenar el modelo. </li><li>  Utilizamos redes neuronales convolucionales profundas y aprendizaje m√©trico profundo que nos permite aprender la estructura en las clases de manera eficiente. </li><li>  Hemos utilizado el aprendizaje curricular, es decir, la capacitaci√≥n en partes, como paradigma de capacitaci√≥n.  Este enfoque nos ha sido muy √∫til.  Utilizamos varios centroides en la inferencia, que permiten utilizar datos m√°s limpios y encontrar diferentes vistas de puntos de referencia. </li></ol><br>  Puede parecer que el reconocimiento de objetos es una tarea trivial.  Sin embargo, al explorar las necesidades de los usuarios en la vida real, encontramos nuevos desaf√≠os como el reconocimiento de puntos de referencia.  Esta t√©cnica permite decirle a las personas algo nuevo sobre el mundo utilizando redes neuronales.  ¬°Es muy alentador y motivador! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/467905/">https://habr.com/ru/post/467905/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../467891/index.html">Preguntas frecuentes sobre la firma en la nube [electr√≥nica]</a></li>
<li><a href="../467893/index.html">Solo otro contenedor Qt para gRPC y protobuf</a></li>
<li><a href="../467895/index.html">¬øQu√© patrones encuentran las redes neuronales?</a></li>
<li><a href="../467897/index.html">Herramientas de prueba autom√°tica, integraci√≥n Yandex Mapkit 3, dise√±o atractivo y enfoque de interfaz de usuario impulsada por el servidor: anuncio de mitap de Android</a></li>
<li><a href="../467903/index.html">Las 20 mejores funciones de navegaci√≥n en IntelliJ IDEA. Parte 1</a></li>
<li><a href="../467907/index.html">Pros y contras de la subcontrataci√≥n</a></li>
<li><a href="../467913/index.html">C√≥mo mejorar el "mineral bastardo", o la nueva interfaz para el panel solar</a></li>
<li><a href="../467915/index.html">Monitoreo de postgres dentro de Openshift</a></li>
<li><a href="../467917/index.html">Plantillas de gesti√≥n</a></li>
<li><a href="../467919/index.html">Problemas de procesamiento por lotes de solicitudes y sus soluciones (parte 2)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå≠ üç∫ üë∞üèº TensorFlow en Apache Ignite üöª üöú üåÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos sabemos c√≥mo comienza la patria, y el aprendizaje profundo comienza con los datos. Sin ellos, es imposible entrenar un modelo, evaluarlo y, de h...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TensorFlow en Apache Ignite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/gridgain/blog/440060/">  Todos sabemos c√≥mo comienza la patria, y el aprendizaje profundo comienza con los datos.  Sin ellos, es imposible entrenar un modelo, evaluarlo y, de hecho, usarlo.  Comprometidos en la investigaci√≥n, aumentando el √≠ndice de Hirsch con art√≠culos sobre nuevas arquitecturas de redes neuronales y experimentando, confiamos en las fuentes de datos locales m√°s simples;  usualmente archivos en varios formatos.  Esto funciona, pero ser√≠a bueno recordar un sistema de combate que contiene terabytes de datos que cambian constantemente.  Y esto significa que necesita simplificar y acelerar la transferencia de datos en la producci√≥n, as√≠ como poder trabajar con big data.  Aqu√≠ es donde entra Apache Ignite. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Ignite</a> es una base de datos distribuida centrada en la memoria, as√≠ como una plataforma para el almacenamiento en cach√© y el procesamiento de operaciones relacionadas con transacciones, an√°lisis y cargas de flujo.  El sistema es capaz de moler petabytes de datos a la velocidad de la RAM.  El art√≠culo se centrar√° en la integraci√≥n entre Apache Ignite y TensorFlow, que le permite utilizar Apache Ignite como fuente de datos para entrenar la red neuronal y la inferencia, as√≠ como un dep√≥sito de modelos entrenados y un sistema de gesti√≥n de cl√∫ster para el aprendizaje distribuido. <br><a name="habracut"></a><br><h2>  Fuente de datos de RAM distribuida </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Ignite le</a> permite almacenar y procesar tantos datos como necesite en un cl√∫ster distribuido.  Para aprovechar este Apache Ignite al entrenar redes neuronales en TensorFlow, use <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ignite Dataset</a> . <br><br>  Nota: Apache Ignite no es solo uno de los enlaces en la tuber√≠a ETL entre una base de datos o un almac√©n de datos y TensorFlow.  Apache Ignite en s√≠ mismo es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HTAP</a> (un sistema h√≠brido para el procesamiento de datos transaccionales / anal√≠ticos).  Al elegir Apache Ignite y TensorFlow, obtiene un √∫nico sistema para el procesamiento transaccional y anal√≠tico, y al mismo tiempo, la capacidad de utilizar datos operativos e hist√≥ricos para entrenar la red neuronal y la inferencia. <br><br>  Los siguientes puntos de referencia demuestran que Apache Ignite es muy adecuado para escenarios en los que los datos se almacenan en un solo host.  Dicho sistema le permite lograr un rendimiento de m√°s de 850 Mb / s, si el almac√©n de datos y el cliente se encuentran en el mismo nodo.  Si el almacenamiento est√° en un host remoto, el rendimiento es de aproximadamente 800 Mb / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b75/eb5/d7f/b75eb5d7fbefd87abba6928b773a5677.png" alt="imagen"><br><br>  El gr√°fico muestra el ancho de banda para Ignite Dataset para un solo nodo Apache Ignite local.  Estos resultados se obtuvieron en un procesador Xeon E5-2609 v4 1.7GHz de 2x con 16GB de RAM y en una red con un ancho de banda de 10GB / s (cada registro tiene un tama√±o de 1MB, tama√±o de p√°gina - 20MB). <br><br>  Otro punto de referencia demuestra c√≥mo funciona Ignite Dataset con un cl√∫ster Apache Ignite distribuido.  Es esta configuraci√≥n la que se selecciona de manera predeterminada cuando se usa Apache Ignite como un sistema HTAP y le permite lograr un ancho de banda para un solo cliente que exceda 1 GB / s en un cl√∫ster con un ancho de banda de 10 Gb / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83f/802/972/83f802972875545a415c88dc6ca64fbd.png" alt="imagen"><br><br>  El gr√°fico muestra el rendimiento del conjunto de datos Ignite para un cl√∫ster Apache Ignite distribuido con un n√∫mero diferente de nodos (de 1 a 9).  Estos resultados se obtuvieron en un procesador Xeon E5-2609 v4 1.7GHz de 2x con 16GB de RAM y en una red con un ancho de banda de 10GB / s (cada registro tiene un tama√±o de 1MB, tama√±o de p√°gina - 20MB). <br><br>  Se prob√≥ el siguiente escenario: el cach√© Apache Ignite (con un n√∫mero variable de particiones en el primer conjunto de pruebas y con 2048 particiones en el segundo) se llena con 10K l√≠neas de 1 MB cada una, despu√©s de lo cual el cliente TensorFlow lee los datos utilizando Ignite Dataset.  El cl√∫ster fue construido a partir de m√°quinas con 2x Xeon E5-2609 v4 1.7 GHz, 16 GB de memoria y conectado a trav√©s de una red que funciona a una velocidad de 10 GB / s.  En cada nodo, Apache Ignite trabaj√≥ en la <a href="">configuraci√≥n est√°ndar</a> . <br><br>  Apache Ignite es f√°cil de usar como una base de datos cl√°sica con interfaz SQL y al mismo tiempo como fuente de datos para TensorFlow. <br><br><pre><code class="bash hljs">$ apache-ignite/bin/ignite.sh $ apache-ignite/bin/sqlline.sh -u <span class="hljs-string"><span class="hljs-string">"jdbc:ignite:thin://localhost:10800/"</span></span></code> </pre> <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> KITTEN_CACHE (<span class="hljs-keyword"><span class="hljs-keyword">ID</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LONG</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NAME</span></span> <span class="hljs-built_in"><span class="hljs-built_in">VARCHAR</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'WARM KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'SOFT KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">'LITTLE BALL OF FUR'</span></span>);</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"SQL_PUBLIC_KITTEN_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">{'key': <span class="hljs-number"><span class="hljs-number">1</span></span>, 'val': {'NAME': b'WARM KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">2</span></span>, 'val': {'NAME': b'SOFT KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">3</span></span>, 'val': {'NAME': b'LITTLE BALL OF FUR'}}</code> </pre> <br><h2>  Objetos estructurados </h2><br>  Apache Ignite le permite almacenar objetos de cualquier tipo que se pueden construir en cualquier jerarqu√≠a.  Puede trabajar con √©l a trav√©s de Ignite Dataset. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): print(element)</code> </pre> <br><pre> <code class="json hljs">{ 'key': 'kitten.png', 'val': { 'metadata': { 'file_name': b'kitten.png', 'label': b'little ball of fur', 'width': <span class="hljs-number"><span class="hljs-number">800</span></span>, 'height': <span class="hljs-number"><span class="hljs-number">600</span></span> }, 'pixels': [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>] } }</code> </pre> <br>  El entrenamiento de la red neuronal y otros c√°lculos requieren un procesamiento previo, que se puede hacer como parte de la tuber√≠a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tf.data</a> si usa Ignite Dataset. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>).map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> obj: obj[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><h2>  Entrenamiento distribuido </h2><br>  TensorFlow es un marco de aprendizaje autom√°tico que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">admite</a> el aprendizaje distribuido de redes neuronales, la inferencia y otros sistemas inform√°ticos.  Como saben, el entrenamiento de la red neuronal se basa en el c√°lculo de gradientes de la funci√≥n de p√©rdida.  En el caso de la capacitaci√≥n distribuida, podemos calcular estos gradientes en cada partici√≥n y luego agregarlos.  Es este m√©todo el que le permite calcular gradientes para nodos individuales en los que se almacenan los datos, resumirlos y, finalmente, actualizar los par√°metros del modelo.  Y, dado que eliminamos la transmisi√≥n de datos de muestra de entrenamiento entre nodos, la red no se convierte en el "cuello de botella" del sistema. <br><br>  Apache Ignite utiliza particionamiento horizontal (fragmentaci√≥n) para almacenar datos en un cl√∫ster distribuido.  Al crear el cach√© Apache Ignite (o una tabla, en t√©rminos de SQL), puede especificar el n√∫mero de particiones entre las que se distribuir√°n los datos.  Por ejemplo, si un cl√∫ster Apache Ignite consta de 100 m√°quinas, y creamos un cach√© con 1000 particiones, cada m√°quina ser√° responsable de aproximadamente 10 particiones con datos. <br><br>  Ignite Dataset le permite utilizar estos dos aspectos para el entrenamiento distribuido de redes neuronales.  Ignite Dataset es el nodo del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gr√°fico de c√≥mputo</a> que forma la base de la arquitectura TensorFlow.  Y, como cualquier nodo en un gr√°fico, puede ejecutarse en un nodo remoto en el cl√∫ster.  Dicho nodo remoto puede anular los par√°metros de Ignite Dataset (por ejemplo, <code>host</code> , <code>port</code> o <code>part</code> ), configurando las variables de entorno apropiadas para el flujo de trabajo (por ejemplo, <code>IGNITE_DATASET_HOST</code> , <code>IGNITE_DATASET_PORT</code> o <code>IGNITE_DATASET_PART</code> ).  Usando tal anulaci√≥n, puede asignar una partici√≥n espec√≠fica a cada nodo del cl√∫ster.  Luego, un nodo es responsable de una partici√≥n y, al mismo tiempo, el usuario recibe una √∫nica fachada de trabajo con el conjunto de datos. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       . gradients = [] for i in range(5): with tf.device("/job:WORKER/task:%d" % i): device_iterator = tf.compat.v1.data.make_one_shot_iterator(dataset) device_next_obj = device_iterator.get_next() gradient = compute_gradient(device_next_obj) gradients.append(gradient) #      result_gradient = tf.reduce_sum(gradients) with tf.Session("grpc://localhost:10000") as sess: print(sess.run(result_gradient))</span></span></code> </pre> <br>  Apache Ignite tambi√©n permite el aprendizaje distribuido utilizando la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API de estimador de</a> alto nivel TensorFlow.  Esta funcionalidad se basa en el llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modo cliente independiente de</a> aprendizaje distribuido en TensorFlow, donde Apache Ignite act√∫a como fuente de datos y sistema de gesti√≥n de cl√∫ster.  El pr√≥ximo art√≠culo estar√° completamente dedicado a este tema. <br><br><h2>  Almacenamiento de puntos de control de aprendizaje </h2><br>  Adem√°s de las capacidades de la base de datos, Apache Ignite tambi√©n tiene un sistema de archivos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IGFS</a> distribuido.  Funcionalmente, se asemeja al sistema de archivos Hadoop HDFS, pero solo en RAM.  Junto con sus propias API, el sistema de archivos IGFS implementa la API Hadoop FileSystem y puede conectarse de forma transparente a Hadoop o Spark implementados.  La biblioteca TensorFlow en Apache Ignite proporciona integraci√≥n entre IGFS y TensorFlow.  La integraci√≥n se basa en el complemento del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sistema de archivos</a> propio de TensorFlow y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API IGFS nativa de</a> Apache Ignite.  Hay varios escenarios para su uso, por ejemplo: <br><br><ul><li>  Los puntos de control de estado se almacenan en IGFS para confiabilidad y tolerancia a fallas. </li><li>  Los procesos de aprendizaje interact√∫an con TensorBoard escribiendo archivos de eventos en un directorio monitoreado por TensorBoard.  IGFS asegura que tales comunicaciones est√©n operativas incluso cuando TensorBoard se est√© ejecutando en otro proceso o en otra m√°quina. </li></ul><br>  Dicha funcionalidad apareci√≥ en el lanzamiento de TensorFlow 1.13.0.rc0, y tambi√©n formar√° parte de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tensorflow / io</a> en el lanzamiento de TensorFlow 2.0. <br><br><h2>  Conexi√≥n SSL </h2><br>  Apache Ignite le permite proteger los canales de datos mediante <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SSL</a> y autenticaci√≥n.  Ignite Dataset admite conexiones SSL con y sin autenticaci√≥n.  Consulte la documentaci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Ignite SSL / TLS</a> para obtener m√°s detalles. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>, certfile=<span class="hljs-string"><span class="hljs-string">"client.pem"</span></span>, cert_password=<span class="hljs-string"><span class="hljs-string">"password"</span></span>, username=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>, password=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>)</code> </pre> <br><h2>  Soporte de Windows </h2><br>  Ignite Dataset es totalmente compatible con Windows.  Se puede usar como parte de TensorFlow en una estaci√≥n de trabajo de Windows, as√≠ como en sistemas Linux / MacOS. <br><br><h2>  Pru√©balo t√∫ mismo </h2><br>  Los siguientes ejemplos lo ayudar√°n a comenzar con el m√≥dulo. <br><br><h4>  Encender conjunto de datos </h4><br>  La forma m√°s f√°cil de comenzar con Ignite Dataset es iniciar el contenedor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Docker</a> con Apache Ignite y descargar datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MNIST</a> , y luego trabajar con √©l usando Ignite Dataset.  Dicho contenedor est√° disponible en el Docker Hub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dmitrievanthony / ignite-with-mnist</a> .  Necesita ejecutar el contenedor en su m√°quina: <br><br><pre> <code class="bash hljs">docker run -it -p 10800:10800 dmitrievanthony/ignite-with-mnist</code> </pre> <br>  Despu√©s de eso, puede trabajar con √©l de la siguiente manera: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/521/e43/417/521e43417bf05c913bdbcb6de66020e5.png" alt="imagen"><br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"MNIST_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, img <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(dataset.take(<span class="hljs-number"><span class="hljs-number">5</span></span>)): plt.subplot(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">'figure.figsize'</span></span>] = (<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) plt.imshow(img[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>].numpy().reshape([<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>])) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>)</code> </pre> <br></div></div><br><h4>  IGFS </h4><br>  El soporte de TensorFlow IGFS apareci√≥ en la versi√≥n TensorFlow 1.13.0rc0 y tambi√©n formar√° parte de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">versi√≥n tensorflow / io</a> en TensorFlow 2.0.  Para probar IGFS con TensorFlow, la forma m√°s f√°cil de iniciar el contenedor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Docker</a> es con Apache Ignite + IGFS, y luego trabajar con √©l usando TensorFlow <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tf.gfile</a> .  Dicho contenedor est√° disponible en Docker Hub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dmitrievanthony / ignite-with-igfs</a> .  Este contenedor se puede ejecutar en su m√°quina: <br><br><pre> <code class="bash hljs">docker run -it -p 10500:10500 dmitrievanthony/ignite-with-igfs</code> </pre> <br>  Entonces puedes trabajar as√≠: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.ignite.python.ops.igfs_ops <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> w: w.write(<span class="hljs-string"><span class="hljs-string">"Hello, world!"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> r: print(r.read())</code> </pre> <br><pre> <code class="json hljs">Hello, world!</code> </pre> <br><h2>  Limitaciones </h2><br>  Actualmente, cuando se trabaja con Ignite Dataset, se supone que todos los objetos en el cach√© tienen la misma estructura (objetos homog√©neos), y que el cach√© contiene al menos un objeto necesario para recuperar el esquema.  Otra limitaci√≥n concierne a los objetos estructurados: Ignite Dataset no admite UUID, mapas y matrices de objetos, que pueden ser parte de un objeto.  Eliminar estas restricciones, as√≠ como estabilizar y sincronizar las versiones de TensorFlow y Apache Ignite, es una de las tareas del desarrollo continuo. <br><br><h2>  Versi√≥n esperada de TensorFlow 2.0 </h2><br>  Los pr√≥ximos cambios a TensorFlow 2.0 resaltar√°n estas caracter√≠sticas en el m√≥dulo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tensorflow / io</a> .  Despu√©s de lo cual, trabajar con ellos se puede construir de manera m√°s flexible.  Los ejemplos cambiar√°n un poco, y esto se reflejar√° en el gihab y en la documentaci√≥n. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440060/">https://habr.com/ru/post/440060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440048/index.html">M√©tricas favoritas: 5 indicadores que todo equipo de ventas debe seguir</a></li>
<li><a href="../440050/index.html">Proxies DNS de bricolaje en Node.JS</a></li>
<li><a href="../440052/index.html">An√°lisis est√°tico de BIOS / UEFI o c√≥mo obtener un gr√°fico de dependencia</a></li>
<li><a href="../440054/index.html">Transfiera el servicio web a Yandex.Cloud con AWS</a></li>
<li><a href="../440058/index.html">Problemas de Internet e Informe de disponibilidad 2018‚Äì2019</a></li>
<li><a href="../440062/index.html">Planificaci√≥n con mucho gusto. C√≥mo configuramos procesos sin gerentes</a></li>
<li><a href="../440064/index.html">Centros de datos para elegir: Londres, Mosc√∫, Z√∫rich, San Petersburgo</a></li>
<li><a href="../440066/index.html">Extensiones VSCode para facilitar el desarrollo de JavaScript y Vue</a></li>
<li><a href="../440070/index.html">Julia, pendiente descendente y m√©todo simplex</a></li>
<li><a href="../440072/index.html">Demostraci√≥n de AresDB: herramienta de an√°lisis en tiempo real de c√≥digo abierto basada en GPU de Uber</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌭 🍺 👰🏼 TensorFlow en Apache Ignite 🚻 🚜 🌁</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos sabemos cómo comienza la patria, y el aprendizaje profundo comienza con los datos. Sin ellos, es imposible entrenar un modelo, evaluarlo y, de h...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TensorFlow en Apache Ignite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/gridgain/blog/440060/">  Todos sabemos cómo comienza la patria, y el aprendizaje profundo comienza con los datos.  Sin ellos, es imposible entrenar un modelo, evaluarlo y, de hecho, usarlo.  Comprometidos en la investigación, aumentando el índice de Hirsch con artículos sobre nuevas arquitecturas de redes neuronales y experimentando, confiamos en las fuentes de datos locales más simples;  usualmente archivos en varios formatos.  Esto funciona, pero sería bueno recordar un sistema de combate que contiene terabytes de datos que cambian constantemente.  Y esto significa que necesita simplificar y acelerar la transferencia de datos en la producción, así como poder trabajar con big data.  Aquí es donde entra Apache Ignite. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Ignite</a> es una base de datos distribuida centrada en la memoria, así como una plataforma para el almacenamiento en caché y el procesamiento de operaciones relacionadas con transacciones, análisis y cargas de flujo.  El sistema es capaz de moler petabytes de datos a la velocidad de la RAM.  El artículo se centrará en la integración entre Apache Ignite y TensorFlow, que le permite utilizar Apache Ignite como fuente de datos para entrenar la red neuronal y la inferencia, así como un depósito de modelos entrenados y un sistema de gestión de clúster para el aprendizaje distribuido. <br><a name="habracut"></a><br><h2>  Fuente de datos de RAM distribuida </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Ignite le</a> permite almacenar y procesar tantos datos como necesite en un clúster distribuido.  Para aprovechar este Apache Ignite al entrenar redes neuronales en TensorFlow, use <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ignite Dataset</a> . <br><br>  Nota: Apache Ignite no es solo uno de los enlaces en la tubería ETL entre una base de datos o un almacén de datos y TensorFlow.  Apache Ignite en sí mismo es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HTAP</a> (un sistema híbrido para el procesamiento de datos transaccionales / analíticos).  Al elegir Apache Ignite y TensorFlow, obtiene un único sistema para el procesamiento transaccional y analítico, y al mismo tiempo, la capacidad de utilizar datos operativos e históricos para entrenar la red neuronal y la inferencia. <br><br>  Los siguientes puntos de referencia demuestran que Apache Ignite es muy adecuado para escenarios en los que los datos se almacenan en un solo host.  Dicho sistema le permite lograr un rendimiento de más de 850 Mb / s, si el almacén de datos y el cliente se encuentran en el mismo nodo.  Si el almacenamiento está en un host remoto, el rendimiento es de aproximadamente 800 Mb / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b75/eb5/d7f/b75eb5d7fbefd87abba6928b773a5677.png" alt="imagen"><br><br>  El gráfico muestra el ancho de banda para Ignite Dataset para un solo nodo Apache Ignite local.  Estos resultados se obtuvieron en un procesador Xeon E5-2609 v4 1.7GHz de 2x con 16GB de RAM y en una red con un ancho de banda de 10GB / s (cada registro tiene un tamaño de 1MB, tamaño de página - 20MB). <br><br>  Otro punto de referencia demuestra cómo funciona Ignite Dataset con un clúster Apache Ignite distribuido.  Es esta configuración la que se selecciona de manera predeterminada cuando se usa Apache Ignite como un sistema HTAP y le permite lograr un ancho de banda para un solo cliente que exceda 1 GB / s en un clúster con un ancho de banda de 10 Gb / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83f/802/972/83f802972875545a415c88dc6ca64fbd.png" alt="imagen"><br><br>  El gráfico muestra el rendimiento del conjunto de datos Ignite para un clúster Apache Ignite distribuido con un número diferente de nodos (de 1 a 9).  Estos resultados se obtuvieron en un procesador Xeon E5-2609 v4 1.7GHz de 2x con 16GB de RAM y en una red con un ancho de banda de 10GB / s (cada registro tiene un tamaño de 1MB, tamaño de página - 20MB). <br><br>  Se probó el siguiente escenario: el caché Apache Ignite (con un número variable de particiones en el primer conjunto de pruebas y con 2048 particiones en el segundo) se llena con 10K líneas de 1 MB cada una, después de lo cual el cliente TensorFlow lee los datos utilizando Ignite Dataset.  El clúster fue construido a partir de máquinas con 2x Xeon E5-2609 v4 1.7 GHz, 16 GB de memoria y conectado a través de una red que funciona a una velocidad de 10 GB / s.  En cada nodo, Apache Ignite trabajó en la <a href="">configuración estándar</a> . <br><br>  Apache Ignite es fácil de usar como una base de datos clásica con interfaz SQL y al mismo tiempo como fuente de datos para TensorFlow. <br><br><pre><code class="bash hljs">$ apache-ignite/bin/ignite.sh $ apache-ignite/bin/sqlline.sh -u <span class="hljs-string"><span class="hljs-string">"jdbc:ignite:thin://localhost:10800/"</span></span></code> </pre> <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> KITTEN_CACHE (<span class="hljs-keyword"><span class="hljs-keyword">ID</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LONG</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NAME</span></span> <span class="hljs-built_in"><span class="hljs-built_in">VARCHAR</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'WARM KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'SOFT KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">'LITTLE BALL OF FUR'</span></span>);</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"SQL_PUBLIC_KITTEN_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">{'key': <span class="hljs-number"><span class="hljs-number">1</span></span>, 'val': {'NAME': b'WARM KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">2</span></span>, 'val': {'NAME': b'SOFT KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">3</span></span>, 'val': {'NAME': b'LITTLE BALL OF FUR'}}</code> </pre> <br><h2>  Objetos estructurados </h2><br>  Apache Ignite le permite almacenar objetos de cualquier tipo que se pueden construir en cualquier jerarquía.  Puede trabajar con él a través de Ignite Dataset. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): print(element)</code> </pre> <br><pre> <code class="json hljs">{ 'key': 'kitten.png', 'val': { 'metadata': { 'file_name': b'kitten.png', 'label': b'little ball of fur', 'width': <span class="hljs-number"><span class="hljs-number">800</span></span>, 'height': <span class="hljs-number"><span class="hljs-number">600</span></span> }, 'pixels': [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>] } }</code> </pre> <br>  El entrenamiento de la red neuronal y otros cálculos requieren un procesamiento previo, que se puede hacer como parte de la tubería <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tf.data</a> si usa Ignite Dataset. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>).map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> obj: obj[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><h2>  Entrenamiento distribuido </h2><br>  TensorFlow es un marco de aprendizaje automático que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">admite</a> el aprendizaje distribuido de redes neuronales, la inferencia y otros sistemas informáticos.  Como saben, el entrenamiento de la red neuronal se basa en el cálculo de gradientes de la función de pérdida.  En el caso de la capacitación distribuida, podemos calcular estos gradientes en cada partición y luego agregarlos.  Es este método el que le permite calcular gradientes para nodos individuales en los que se almacenan los datos, resumirlos y, finalmente, actualizar los parámetros del modelo.  Y, dado que eliminamos la transmisión de datos de muestra de entrenamiento entre nodos, la red no se convierte en el "cuello de botella" del sistema. <br><br>  Apache Ignite utiliza particionamiento horizontal (fragmentación) para almacenar datos en un clúster distribuido.  Al crear el caché Apache Ignite (o una tabla, en términos de SQL), puede especificar el número de particiones entre las que se distribuirán los datos.  Por ejemplo, si un clúster Apache Ignite consta de 100 máquinas, y creamos un caché con 1000 particiones, cada máquina será responsable de aproximadamente 10 particiones con datos. <br><br>  Ignite Dataset le permite utilizar estos dos aspectos para el entrenamiento distribuido de redes neuronales.  Ignite Dataset es el nodo del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gráfico de cómputo</a> que forma la base de la arquitectura TensorFlow.  Y, como cualquier nodo en un gráfico, puede ejecutarse en un nodo remoto en el clúster.  Dicho nodo remoto puede anular los parámetros de Ignite Dataset (por ejemplo, <code>host</code> , <code>port</code> o <code>part</code> ), configurando las variables de entorno apropiadas para el flujo de trabajo (por ejemplo, <code>IGNITE_DATASET_HOST</code> , <code>IGNITE_DATASET_PORT</code> o <code>IGNITE_DATASET_PART</code> ).  Usando tal anulación, puede asignar una partición específica a cada nodo del clúster.  Luego, un nodo es responsable de una partición y, al mismo tiempo, el usuario recibe una única fachada de trabajo con el conjunto de datos. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       . gradients = [] for i in range(5): with tf.device("/job:WORKER/task:%d" % i): device_iterator = tf.compat.v1.data.make_one_shot_iterator(dataset) device_next_obj = device_iterator.get_next() gradient = compute_gradient(device_next_obj) gradients.append(gradient) #      result_gradient = tf.reduce_sum(gradients) with tf.Session("grpc://localhost:10000") as sess: print(sess.run(result_gradient))</span></span></code> </pre> <br>  Apache Ignite también permite el aprendizaje distribuido utilizando la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API de estimador de</a> alto nivel TensorFlow.  Esta funcionalidad se basa en el llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modo cliente independiente de</a> aprendizaje distribuido en TensorFlow, donde Apache Ignite actúa como fuente de datos y sistema de gestión de clúster.  El próximo artículo estará completamente dedicado a este tema. <br><br><h2>  Almacenamiento de puntos de control de aprendizaje </h2><br>  Además de las capacidades de la base de datos, Apache Ignite también tiene un sistema de archivos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IGFS</a> distribuido.  Funcionalmente, se asemeja al sistema de archivos Hadoop HDFS, pero solo en RAM.  Junto con sus propias API, el sistema de archivos IGFS implementa la API Hadoop FileSystem y puede conectarse de forma transparente a Hadoop o Spark implementados.  La biblioteca TensorFlow en Apache Ignite proporciona integración entre IGFS y TensorFlow.  La integración se basa en el complemento del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sistema de archivos</a> propio de TensorFlow y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API IGFS nativa de</a> Apache Ignite.  Hay varios escenarios para su uso, por ejemplo: <br><br><ul><li>  Los puntos de control de estado se almacenan en IGFS para confiabilidad y tolerancia a fallas. </li><li>  Los procesos de aprendizaje interactúan con TensorBoard escribiendo archivos de eventos en un directorio monitoreado por TensorBoard.  IGFS asegura que tales comunicaciones estén operativas incluso cuando TensorBoard se esté ejecutando en otro proceso o en otra máquina. </li></ul><br>  Dicha funcionalidad apareció en el lanzamiento de TensorFlow 1.13.0.rc0, y también formará parte de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tensorflow / io</a> en el lanzamiento de TensorFlow 2.0. <br><br><h2>  Conexión SSL </h2><br>  Apache Ignite le permite proteger los canales de datos mediante <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SSL</a> y autenticación.  Ignite Dataset admite conexiones SSL con y sin autenticación.  Consulte la documentación de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Ignite SSL / TLS</a> para obtener más detalles. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>, certfile=<span class="hljs-string"><span class="hljs-string">"client.pem"</span></span>, cert_password=<span class="hljs-string"><span class="hljs-string">"password"</span></span>, username=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>, password=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>)</code> </pre> <br><h2>  Soporte de Windows </h2><br>  Ignite Dataset es totalmente compatible con Windows.  Se puede usar como parte de TensorFlow en una estación de trabajo de Windows, así como en sistemas Linux / MacOS. <br><br><h2>  Pruébalo tú mismo </h2><br>  Los siguientes ejemplos lo ayudarán a comenzar con el módulo. <br><br><h4>  Encender conjunto de datos </h4><br>  La forma más fácil de comenzar con Ignite Dataset es iniciar el contenedor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Docker</a> con Apache Ignite y descargar datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MNIST</a> , y luego trabajar con él usando Ignite Dataset.  Dicho contenedor está disponible en el Docker Hub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dmitrievanthony / ignite-with-mnist</a> .  Necesita ejecutar el contenedor en su máquina: <br><br><pre> <code class="bash hljs">docker run -it -p 10800:10800 dmitrievanthony/ignite-with-mnist</code> </pre> <br>  Después de eso, puede trabajar con él de la siguiente manera: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/521/e43/417/521e43417bf05c913bdbcb6de66020e5.png" alt="imagen"><br><br><div class="spoiler">  <b class="spoiler_title">Código</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"MNIST_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, img <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(dataset.take(<span class="hljs-number"><span class="hljs-number">5</span></span>)): plt.subplot(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">'figure.figsize'</span></span>] = (<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) plt.imshow(img[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>].numpy().reshape([<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>])) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>)</code> </pre> <br></div></div><br><h4>  IGFS </h4><br>  El soporte de TensorFlow IGFS apareció en la versión TensorFlow 1.13.0rc0 y también formará parte de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">versión tensorflow / io</a> en TensorFlow 2.0.  Para probar IGFS con TensorFlow, la forma más fácil de iniciar el contenedor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Docker</a> es con Apache Ignite + IGFS, y luego trabajar con él usando TensorFlow <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tf.gfile</a> .  Dicho contenedor está disponible en Docker Hub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dmitrievanthony / ignite-with-igfs</a> .  Este contenedor se puede ejecutar en su máquina: <br><br><pre> <code class="bash hljs">docker run -it -p 10500:10500 dmitrievanthony/ignite-with-igfs</code> </pre> <br>  Entonces puedes trabajar así: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.ignite.python.ops.igfs_ops <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> w: w.write(<span class="hljs-string"><span class="hljs-string">"Hello, world!"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> r: print(r.read())</code> </pre> <br><pre> <code class="json hljs">Hello, world!</code> </pre> <br><h2>  Limitaciones </h2><br>  Actualmente, cuando se trabaja con Ignite Dataset, se supone que todos los objetos en el caché tienen la misma estructura (objetos homogéneos), y que el caché contiene al menos un objeto necesario para recuperar el esquema.  Otra limitación concierne a los objetos estructurados: Ignite Dataset no admite UUID, mapas y matrices de objetos, que pueden ser parte de un objeto.  Eliminar estas restricciones, así como estabilizar y sincronizar las versiones de TensorFlow y Apache Ignite, es una de las tareas del desarrollo continuo. <br><br><h2>  Versión esperada de TensorFlow 2.0 </h2><br>  Los próximos cambios a TensorFlow 2.0 resaltarán estas características en el módulo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tensorflow / io</a> .  Después de lo cual, trabajar con ellos se puede construir de manera más flexible.  Los ejemplos cambiarán un poco, y esto se reflejará en el gihab y en la documentación. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440060/">https://habr.com/ru/post/440060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440048/index.html">Métricas favoritas: 5 indicadores que todo equipo de ventas debe seguir</a></li>
<li><a href="../440050/index.html">Proxies DNS de bricolaje en Node.JS</a></li>
<li><a href="../440052/index.html">Análisis estático de BIOS / UEFI o cómo obtener un gráfico de dependencia</a></li>
<li><a href="../440054/index.html">Transfiera el servicio web a Yandex.Cloud con AWS</a></li>
<li><a href="../440058/index.html">Problemas de Internet e Informe de disponibilidad 2018–2019</a></li>
<li><a href="../440062/index.html">Planificación con mucho gusto. Cómo configuramos procesos sin gerentes</a></li>
<li><a href="../440064/index.html">Centros de datos para elegir: Londres, Moscú, Zúrich, San Petersburgo</a></li>
<li><a href="../440066/index.html">Extensiones VSCode para facilitar el desarrollo de JavaScript y Vue</a></li>
<li><a href="../440070/index.html">Julia, pendiente descendente y método simplex</a></li>
<li><a href="../440072/index.html">Demostración de AresDB: herramienta de análisis en tiempo real de código abierto basada en GPU de Uber</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
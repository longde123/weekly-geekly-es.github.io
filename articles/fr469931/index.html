<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕹️ 👨‍🚒 😛 Qu'est-ce qu'un facteur de vitesse d'apprentissage et comment améliore-t-il les caractéristiques d'apprentissage en profondeur? 👷🏻 🥂 🏦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article est ma tentative d'exprimer mon point de vue sur les aspects suivants: 



1. Qu'est-ce qu'un facteur de vitesse d'apprentissage et quelle...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Qu'est-ce qu'un facteur de vitesse d'apprentissage et comment améliore-t-il les caractéristiques d'apprentissage en profondeur?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469931/">  Cet article est ma tentative d'exprimer mon point de vue sur les aspects suivants: <br><br><ol><li>  Qu'est-ce qu'un facteur de vitesse d'apprentissage et quelle est sa valeur? </li><li>  Comment choisir ce coefficient lors de la formation des modèles? </li><li>  Pourquoi est-il nécessaire de modifier le coefficient de la vitesse d'apprentissage lors de la formation des modèles? </li><li>  Que faire d'un facteur de vitesse d'apprentissage lors de l'utilisation d'un modèle pré-formé? </li></ol><br>  La plupart de ce message est basé sur des documents préparés par <i>fast.ai</i> : [1], [2], [5] and [3] - représentant une version concise de leur travail destiné à la compréhension la plus rapide de l'essence de la question.  Pour vous familiariser avec les détails, il est recommandé de cliquer sur les liens ci-dessous. <br><a name="habracut"></a><br><h3>  <b>Qu'est-ce qu'un facteur de vitesse d'apprentissage?</b> </h3><br>  Le coefficient de vitesse d'apprentissage est un hyperparamètre qui détermine l'ordre dans lequel nous ajusterons nos échelles en tenant compte de la fonction de perte en descente de gradient.  Plus la valeur est basse, plus nous nous déplaçons lentement le long de la pente.  Bien que lorsque nous utilisons un faible coefficient de vitesse d'apprentissage, nous pouvons obtenir un effet positif dans le sens où nous ne manquons pas un seul minimum local, cela peut également signifier que nous devrons consacrer beaucoup de temps à la convergence, surtout si nous sommes dans la région du plateau. <br><br>  La relation est illustrée par la formule suivante <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mo>&amp;#x2022;</mo><mi>n</mi><mi>o</mi><mi>u</mi><mi>v</mi><mi>e</mi><mi>a</mi><msub><mi>u</mi><mi>p</mi></msub><mi>o</mi><mi>i</mi><mi>d</mi><mi>s</mi><mo>=</mo><mi>p</mi><mi>o</mi><mi>i</mi><mi>d</mi><msub><mi>s</mi><mi>e</mi></msub><mi>x</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>t</mi><mo>&amp;#x2212;</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>a</mi></msub><mi>p</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>s</mi><mi>a</mi><mi>g</mi><mi>e</mi></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="57.901ex" height="2.66ex" viewBox="0 -780.1 24929.3 1145.2" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMAIN-2219" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6E" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6F" x="1101" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-75" x="1586" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-76" x="2159" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-65" x="2644" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-61" x="3111" y="0"></use><g transform="translate(3640,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-75" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-70" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6F" x="4669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-69" x="5154" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-64" x="5500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-73" x="6023" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMAIN-3D" x="6770" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-70" x="7827" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6F" x="8330" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-69" x="8816" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-64" x="9161" y="0"></use><g transform="translate(9685,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-65" x="663" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-78" x="10584" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-69" x="11156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-73" x="11502" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-74" x="11971" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-61" x="12333" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6E" x="12862" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-74" x="13463" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMAIN-2212" x="14047" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-67" x="15047" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-72" x="15528" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-61" x="15979" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-64" x="16509" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-69" x="17032" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-65" x="17378" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6E" x="17844" y="0"></use><g transform="translate(18445,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-61" x="511" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-70" x="19281" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-70" x="19784" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-72" x="20288" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-65" x="20739" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-6E" x="21206" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-74" x="21806" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-69" x="22168" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-73" x="22513" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-73" x="22983" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-61" x="23452" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-67" x="23982" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhh4N1hY7WBzWfDcbNMSWcaGLivRlA#MJMATHI-65" x="24462" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mo>•</mo><mi>n</mi><mi>o</mi><mi>u</mi><mi>v</mi><mi>e</mi><mi>a</mi><msub><mi>u</mi><mi>p</mi></msub><mi>o</mi><mi>i</mi><mi>d</mi><mi>s</mi><mo>=</mo><mi>p</mi><mi>o</mi><mi>i</mi><mi>d</mi><msub><mi>s</mi><mi>e</mi></msub><mi>x</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>t</mi><mo>−</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>a</mi></msub><mi>p</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>s</mi><mi>a</mi><mi>g</mi><mi>e</mi></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> • nouveau_poids = poids_existant - gradient_apprentissage </script></p><br><img src="https://habrastorage.org/webt/dn/j1/nj/dnj1njm2womrahwlbv_dzs25xqs.jpeg"><br>  <b>Descente en pente avec des facteurs de vitesse d'apprentissage petits (haut) et grands (bas).</b>  <b>Source: Cours d'apprentissage automatique d'Andrew Ng sur Coursera</b> <b><br></b> <br>  Le plus souvent, le facteur de vitesse d'apprentissage est fixé arbitrairement par l'utilisateur.  Dans le meilleur des cas, pour une compréhension intuitive de la valeur la plus appropriée pour déterminer le coefficient de vitesse d'apprentissage, il peut s'appuyer sur des expériences précédentes (ou un autre type de matériel de formation). <br><br>  Essentiellement, il est assez difficile de choisir la bonne valeur.  Le diagramme ci-dessous illustre divers scénarios pouvant survenir lorsque l'utilisateur ajuste indépendamment le taux de vitesse d'apprentissage. <br><br><img src="https://habrastorage.org/webt/qm/uh/qd/qmuhqdtbcagnnzltgnfy53wuxxi.jpeg"><br>  <b>L'influence de divers facteurs de taux d'apprentissage sur la convergence.</b>  <b>(Crédit Img: cs231n)</b> <b><br></b> <br>  De plus, le facteur de vitesse d'apprentissage affecte la rapidité avec laquelle notre modèle atteint un minimum local (aka obtiendra la meilleure précision).  Ainsi, le bon choix dès le début garantit moins de perte de temps pour la formation du modèle.  Moins de temps de formation, moins d'argent est dépensé en puissance de calcul GPU dans le cloud. <br><br><h4>  Existe-t-il un moyen plus pratique de déterminer le taux de coefficient d'apprentissage? <br></h4><br>  Au paragraphe 3.3.  « <i>Coefficients de taux d'apprentissage cycliques pour les réseaux de neurones</i> » Leslie Smith a défendu le point suivant: l'efficacité de la vitesse d'apprentissage peut être estimée en entraînant le modèle avec une vitesse d'apprentissage initialement réglée faible, qui augmente ensuite (linéairement ou exponentiellement) à chaque itération. <br><br><img src="https://habrastorage.org/webt/j9/zu/yi/j9zuyi5do_thph6ylxtaxetvm7q.jpeg"><br>  <b>Le facteur de vitesse d'apprentissage augmente après chaque mini-package.</b> <b><br></b> <br>  En fixant les valeurs des indicateurs à chaque itération, nous verrons qu'à mesure que la vitesse d'apprentissage augmente, un point sera (atteint) auquel la valeur de la fonction de perte cessera de diminuer et commencera à augmenter.  Dans la pratique, notre vitesse d'apprentissage devrait idéalement se situer quelque part à gauche du point inférieur du graphique (comme indiqué dans le graphique ci-dessous).  Dans ce cas (la valeur sera) de 0,001 à 0,01. <br><br><img src="https://habrastorage.org/webt/tq/sw/m7/tqswm7bda8qr9zed3h9s3fafbj4.jpeg"><br><br><h4>  Ce qui précède semble utile.  Comment commencer à l'utiliser? </h4><br>  À l'heure actuelle, il existe une fonction prête à l' <i>emploi</i> dans le package <i>fast.ia</i> développé par Jeremy Howard, c'est une sorte d'abstraction / add-on au-dessus de la bibliothèque pytorch (similaire à la façon dont cela est fait dans le cas de Keras et Tensorflow). <br><br>  Il suffit de saisir la commande suivante pour commencer la recherche du coefficient optimal de vitesse d'apprentissage avant (de démarrer) l'entraînement du réseau neuronal. <br><br><pre><code class="python hljs">learn.lr_find() learn.sched.plot_lr()</code> </pre> <br><br><h3>  <b>Améliorer le modèle</b> </h3><br>  Nous avons donc parlé du coefficient de vitesse d'apprentissage, de sa valeur et de la manière d'atteindre sa valeur optimale avant de commencer à former le modèle lui-même. <br>  Nous allons maintenant nous concentrer sur la façon dont le facteur de vitesse d'apprentissage peut être utilisé pour les modèles de réglage. <br><br><h4>  Sagesse conventionnelle </h4><br>  Habituellement, lorsque l'utilisateur définit son coefficient de vitesse d'apprentissage et commence à entraîner le modèle, il doit attendre que le coefficient de vitesse d'apprentissage commence à chuter et que le modèle atteigne la valeur optimale. <br><br>  Cependant, à partir du moment où le gradient atteint un plateau, il devient plus difficile d'améliorer les valeurs de la fonction de perte lors de l'apprentissage du modèle.  Dans [3], Dauphin exprime l'opinion que la difficulté de minimiser la fonction de perte provient du point de selle, et non du minimum local. <br><br><img src="https://habrastorage.org/webt/-t/jm/uw/-tjmuwg7a8etbhsc36cw97flhh8.png"><br>  <b>Un point de selle à la surface des erreurs.</b>  <b>Un point de selle est un point du domaine de définition d'une fonction qui est stationnaire pour une fonction donnée, mais qui n'est pas son extremum local</b> .  (ImgCredit: safaribooksonline) <br><br><h4>  Alors, comment éviter cela? </h4><br>  Je propose d'envisager plusieurs options.  L'un d'eux, général, en utilisant la citation de [1], <br><blockquote>  ... au lieu d'utiliser une valeur fixe pour le coefficient de vitesse d'apprentissage et de la diminuer au fil du temps, si l'entraînement ne lisse plus notre perte, nous allons changer le coefficient de vitesse d'apprentissage à chaque itération selon une fonction cyclique f.  Chaque boucle a - en termes de nombre d'itérations - une longueur fixe.  Cette méthode permet au coefficient de vitesse d'apprentissage de varier entre des valeurs limites raisonnables.  Cela aide vraiment, car, coincé dans les points de selle, en augmentant le coefficient de vitesse d'apprentissage, nous obtenons une intersection plus rapide du plateau des points de selle </blockquote><br>  Dans [2], Leslie propose la «méthode du triangle», dans laquelle le coefficient de vitesse d'apprentissage est révisé après chacune de plusieurs itérations. <br><br><img src="https://habrastorage.org/webt/j4/_w/ga/j4_wga1vdfg3qmiovtzdbtrmb4e.jpeg"><br><br><img src="https://habrastorage.org/webt/pn/tu/f5/pntuf5w2svpsbk9nsiyme8iqf98.jpeg"><br>  <b>«La méthode des triangles» et «la méthode des triangles-2» sont des méthodes de test cyclique des coefficients de taux d'apprentissage, proposées par Leslie N. Smith.</b>  <b>Dans le graphique supérieur, le minimum et le maximum Ir sont maintenus égaux.</b> <br><br>  Une autre méthode, non moins populaire et appelée «descente de gradient stochastique avec réinitialisation à chaud», a été proposée par Lonchilov &amp; Hutter [6].  Cette méthode, qui repose sur l'utilisation de la fonction cosinus comme fonction cyclique, redémarre le coefficient de la vitesse d'apprentissage au point maximum de chaque cycle.  L'apparition du bit «Hot» est due au fait que lorsque le coefficient de taux d'apprentissage est redémarré, il part non pas du niveau zéro, mais des paramètres auxquels le modèle a atteint l'étape précédente. <br><br>  Étant donné que cette méthode a des variations, le graphique ci-dessous montre l'une des méthodes de son application, où chaque cycle est lié au même intervalle de temps. <br><br><img src="https://habrastorage.org/webt/kb/8o/pe/kb8opexd3ppx8ynj2bj7dtaphzg.jpeg"><br>  <b>SGDR - graphique, coefficient du taux d'apprentissage vs.</b>  <b>itérations</b> <b><br></b> <br>  Ainsi, nous obtenons un moyen de raccourcir la durée de la formation en sautant simplement de temps en temps sur les «pics» (comme indiqué ci-dessous). <br><br><img src="https://habrastorage.org/webt/85/cn/-b/85cn-blk82myspio7d5pxfwfeqk.png"><br>  <b>Comparaison des coefficients de taux d'apprentissage fixes et cycliques</b> (crédit img: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arxiv.org/abs/1704.00109</a> <br>  En plus de gagner du temps, cette méthode, selon les études, améliore la précision de la classification sans réglage et pour moins d'itérations. <br><br><h3>  Transfert de taux d'apprentissage dans Transfert d'apprentissage </h3><br>  Au cours de <i>fast.ai, l'</i> accent est mis sur la gestion d'un modèle pré-formé pour résoudre les problèmes d'intelligence artificielle.  Par exemple, lors de la résolution de problèmes de classification d'images, les étudiants sont formés à l'utilisation de modèles pré-formés tels que VGG et Resnet50 et à les lier à l'échantillon de données d'image à prévoir. <br>  Afin de résumer la façon dont le modèle est construit dans le programme <i>fast.ai</i> (à ne pas confondre avec <i>le package fast. Ai</i> - le package du programme), <i>voici</i> les étapes que nous prendrons dans une situation ordinaire: <br><br><ol><li>  Activer l'augmentation des données et le précalcul = True </li><li>  Utilisez Ir_find () pour trouver le coefficient de taux d'apprentissage le plus élevé, où la perte continue de s'améliorer clairement. </li><li>  Entraînez la dernière couche d'activations pré-calculées pour l'ère 1-2. </li><li>  Entraînez la dernière couche avec un gain de données (c'est-à-dire, calculer = faux) pendant 1-2 époques avec le cycle _len 1. </li><li>  Décongeler toutes les couches. </li><li>  Placez les couches précédentes à un facteur de vitesse d'apprentissage qui est 3x-10x en dessous de la couche supérieure suivante </li><li>  Réutiliser Ir_find () </li><li>  Former un réseau complet avec le cycle _mult = 2 = 2 jusqu'à ce qu'il commence à se recycler. </li></ol><br>  Vous remarquerez peut-être que les étapes deux, cinq et sept (ci-dessus) sont liées au taux de facteur d'apprentissage.  Dans une partie antérieure de notre article, nous avons souligné le point des deuxièmes étapes mentionnées - où nous avons abordé la façon d'obtenir le meilleur coefficient de vitesse d'apprentissage avant de commencer à entraîner le modèle. <br><br>  Dans le paragraphe suivant, nous avons expliqué comment vous pouvez réduire le temps de formation à l'aide de SGDR et, en redémarrant périodiquement le facteur de vitesse d'apprentissage, améliorer la précision afin d'éviter les zones où le gradient est proche de zéro. <br>  Dans la dernière section, nous aborderons le concept d'apprentissage différencié et expliquerons comment il est utilisé pour déterminer le coefficient de vitesse d'apprentissage lorsqu'un modèle formé est associé à un modèle pré-formé ... <br><br><h3>  Qu'est-ce que l'apprentissage différentiel </h3><br>  Il s'agit d'une méthode dans laquelle divers facteurs de vitesse d'entraînement sont définis sur le réseau pendant l'entraînement.  Il offre une alternative à la façon dont les utilisateurs ajustent généralement les facteurs de vitesse d'apprentissage - à savoir, en utilisant le même facteur de vitesse d'apprentissage via le réseau pendant la formation. <br><br><img src="https://habrastorage.org/webt/xb/aw/-e/xbaw-e9-pehhvaeylpidgeykwwo.png"><br>  <b>La raison pour laquelle j'aime Twitter est une réponse directe de la personne elle-même.</b> <b><br></b>  (Au moment de la rédaction de cet article, Jeremy a publié un article avec Sebastian Ruder, qui a plongé encore plus profondément dans ce sujet. Donc, je crois, le coefficient différentiel de la vitesse d'apprentissage a maintenant un autre nom - réglage exact discriminatoire :) <br><br>  Pour illustrer le concept plus clairement, nous pouvons nous référer au diagramme ci-dessous, dans lequel le modèle pré-formé est «divisé» en 3 groupes, où chacun est ajusté avec une valeur croissante du coefficient de vitesse d'apprentissage. <br><br><img src="https://habrastorage.org/webt/cv/3l/ax/cv3laxkfy-60oz9ftqnhotviqss.jpeg"><br>  <b>Exemple CNN avec coefficient de taux d'apprentissage différencié</b> .  Crédit d'image de [3] <br><br>  Cette méthode de configuration est basée sur la compréhension suivante: les premières couches contiennent généralement de très petits détails des données, telles que les lignes et les angles - à partir desquels nous n'essaierons pas de changer beaucoup et d'essayer d'enregistrer les informations qu'elles contiennent.  En général, il n'est pas vraiment nécessaire de changer leur poids en un grand nombre. <br><br>  Au contraire, pour les couches suivantes - telles que celles de l'image peintes en vert, où nous obtenons des signes détaillés des données, comme le blanc des yeux, ou de la bouche, ou du nez - la nécessité de les sauvegarder disparaît. <br><br><h4>  Comment cela se compare-t-il avec d'autres méthodes de réglage fin? </h4><br>  Dans [9], il a été prouvé qu'un réglage fin de l'ensemble du modèle serait trop coûteux, car les utilisateurs peuvent obtenir plus de 100 couches.  Le plus souvent, les gens ont recours à l'optimisation du modèle une couche à la fois. <br><br>  Cependant, c'est la raison d'un certain nombre d'exigences, les soi-disant  interférant concurrence, et nécessite plusieurs entrées à travers un ensemble de données, ce qui conduit à la sur-formation de petits ensembles. <br><br>  Nous avons également montré que les méthodes présentées dans [9] sont capables à la fois d'améliorer la précision et de réduire le nombre d'erreurs dans diverses tâches liées à la classification NRL. <br><br><img src="https://habrastorage.org/webt/by/no/yr/bynoyrrrl8edulvd8udbo8hv-uk.png"><br>  <b>Résultats tirés de la source [9]</b> <br><br>  Références: <br>  [1] Améliorer notre façon de travailler avec le taux d'apprentissage. <br>  [2] La technique du taux d'apprentissage cyclique. <br>  [3] Transférer l'apprentissage en utilisant des taux d'apprentissage différentiels. <br>  [4] Leslie N. Smith.  Taux d'apprentissage cycliques pour la formation des réseaux de neurones. <br>  [5] Estimation d'un taux d'apprentissage optimal pour un réseau neuronal profond <br>  [6] Descente de gradient stochastique avec redémarrage à chaud <br>  [7] Optimisation des points forts du Deep Learning en 2017 <br>  [8] Leçon 1 Notebook, fast.ai Part 1 V2 <br>  [9] Modèles de langue affinés pour la classification des textes </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr469931/">https://habr.com/ru/post/fr469931/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr469919/index.html">Vérification du code Telegram Open Network par l'analyseur PVS-Studio</a></li>
<li><a href="../fr469921/index.html">[Cas] Surveillance de la qualité de l'air dans un village de chalets</a></li>
<li><a href="../fr469923/index.html">Vulnérabilité inattendue dans les produits Apple. Totalement inattendu</a></li>
<li><a href="../fr469925/index.html">«F # n'est pas plus difficile à maîtriser qu'Entity Framework ou WPF»: Entretien avec Scott Vlashin</a></li>
<li><a href="../fr469927/index.html">10 commandements du développeur</a></li>
<li><a href="../fr469935/index.html">Cours "Fondamentaux d'un travail efficace avec les technologies Wolfram": plus de 13 heures de cours vidéo, théorie et problèmes</a></li>
<li><a href="../fr469939/index.html">Routeur CNC domestique comme alternative à une imprimante 3D, quatrième partie. Concepts généraux de traitement</a></li>
<li><a href="../fr469941/index.html">Nématodes extrêmes du lac Mono: nagez dans l'arsenic et survivez</a></li>
<li><a href="../fr469945/index.html">Est-il important que les ordinateurs et les gens voient le monde différemment?</a></li>
<li><a href="../fr469947/index.html">De minuscules images Docker qui croyaient en elles-mêmes *</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
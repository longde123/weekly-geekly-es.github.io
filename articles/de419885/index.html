<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèè üóΩ üë∏üèø √úbersetzung von Andrew Un's Buch, Leidenschaft f√ºr maschinelles Lernen, Kapitel 15-19 üë®üèΩ‚Äçüåæ üö∫ üíø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="vorherige Kapitel 
 15. Gleichzeitige Bewertung mehrerer Ideen w√§hrend der Fehleranalyse 


 Ihr Team hat einige Ideen, wie Sie die Katzenidentifikati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úbersetzung von Andrew Un's Buch, Leidenschaft f√ºr maschinelles Lernen, Kapitel 15-19</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/419885/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherige Kapitel</a> </p><br><h1 id="15-odnovremennaya-ocenka-neskolkih-idey-vo-vremya-analiza-oshibok">  15. Gleichzeitige Bewertung mehrerer Ideen w√§hrend der Fehleranalyse </h1><br><p>  Ihr Team hat einige Ideen, wie Sie die Katzenidentifikation in Ihrer Anwendung verbessern k√∂nnen: </p><br><ul><li>  L√∂sen Sie das Problem, dass Ihr Algorithmus Katzen Katzen zuweist </li><li>  L√∂sen Sie das Problem mit der Tatsache, dass Ihr Algorithmus gro√üe Wildkatzen (L√∂wen, Panther usw.) als Hauskatzen erkennt </li><li>  Verbessern Sie die Systemleistung bei unscharfen Bildern </li><li>  ... </li></ul><br><p>  Sie k√∂nnen all diese Ideen gleichzeitig sch√§tzen.  Normalerweise erstelle ich eine spezielle Tabelle und f√ºlle sie f√ºr ungef√§hr 100 F√§lle falscher Klassifizierung der Validierungsprobe (dev) aus.  Ich mache auch kurze Kommentare, die mir helfen k√∂nnen, mich an bestimmte Beispiele in der Folgezeit zu erinnern.  Schauen wir uns zur Veranschaulichung dieses Prozesses eine Pivot-Tabelle an, die Sie aus einer kleinen Reihe von Beispielen Ihres Validierungsbeispiels (dev) erstellen k√∂nnen </p><a name="habracut"></a><br><table><thead><tr><th>  Bild </th><th>  Hunde </th><th>  Gro√ükatzen </th><th>  Fuzzy </th><th>  Kommentare </th></tr></thead><tbody><tr><td>  1 </td><td>  x </td><td></td><td></td><td>  Ungew√∂hnlicher Pitbull </td></tr><tr><td>  2 </td><td></td><td></td><td></td><td></td></tr><tr><td>  3 </td><td></td><td>  x </td><td>  x </td><td>  Leo  Foto im Zoo an einem regnerischen Tag aufgenommen </td></tr><tr><td>  4 </td><td></td><td>  x </td><td></td><td>  Panther hinter einem Baum </td></tr><tr><td>  <strong>Anteil (%)</strong> </td><td>  <strong>25%</strong> </td><td>  <strong>50%</strong> </td><td>  <strong>50%</strong> </td><td></td></tr></tbody></table><br><p>  Bild 3 in der Tabelle gilt f√ºr Gro√ükatzen und Fuzzy-Katzen.  Aufgrund der Tatsache, dass wir ein Bild mehreren Fehlerkategorien zuordnen k√∂nnen, sind die Gesamtprozents√§tze in der unteren Zeile nicht auf 100% beschr√§nkt. </p><br><p>  Trotz der Tatsache, dass Sie zu Beginn der Arbeit eine bestimmte Reihe von Kategorien f√ºr Fehler (Hunde, Gro√ükatzen, Fuzzy-Bilder) erstellen k√∂nnen, w√§hrend Sie diesen Kategorien manuell Klassifizierungsfehler zuweisen, k√∂nnen Sie neue Fehlertypen hinzuf√ºgen.  Angenommen, Sie haben sich ein Dutzend Bilder angesehen und festgestellt, dass der Klassifizierer bei farbcodierten Instagram-Bildern viele Fehler gemacht hat.  Sie k√∂nnen die Tabelle wiederholen, die Spalte "Instagram" hinzuf√ºgen und Fehler basierend auf dieser Kategorie neu klassifizieren.  Wenn Sie die Beispiele, bei denen der Algorithmus falsch ist, manuell untersuchen und sich fragen, wie Sie als Person das Bild korrekt markieren konnten, k√∂nnen Sie neue Fehlerkategorien erkennen und sich m√∂glicherweise inspirieren lassen, neue L√∂sungen zu finden. </p><br><p>  Die n√ºtzlichsten Fehlerkategorien sind diejenigen, f√ºr die Sie eine Idee zur Verbesserung des Systems haben.  Das Hinzuf√ºgen der Kategorie "Instagram" ist beispielsweise am n√ºtzlichsten, wenn Sie eine Idee haben, wie Sie Filter entfernen und das Originalbild wiederherstellen k√∂nnen.  Sie sollten sich jedoch nicht nur auf die Fehlerkategorien beschr√§nken, f√ºr die Sie ein Rezept zur Beseitigung dieser Fehler haben.  Ziel des Fehleranalyseprozesses ist es, Ihre Intuition bei der Auswahl der vielversprechendsten Schwerpunkte zu entwickeln. </p><br><p>  Die Fehleranalyse ist ein iterativer Prozess.  Machen Sie sich keine Sorgen, wenn Sie es starten, ohne eine einzige Kategorie erstellt zu haben.  Nachdem Sie einige Bilder angezeigt haben, haben Sie verschiedene Ideen zur Kategorisierung von Fehlern.  Nachdem Sie mehrere Bilder manuell kategorisiert haben, m√∂chten Sie m√∂glicherweise neue Kategorien hinzuf√ºgen und Klassifizierungsfehler im Lichte neu hinzugef√ºgter Kategorien usw. √ºberpr√ºfen. </p><br><p>  Angenommen, Sie haben eine Fehleranalyse von 100 falsch klassifizierten Validierungsbeispielen durchgef√ºhrt und Folgendes erhalten: </p><br><table><thead><tr><th>  Bild </th><th>  Hunde </th><th>  Gro√ükatzen </th><th>  Fuzzy </th><th>  Kommentare </th></tr></thead><tbody><tr><td>  1 </td><td>  X. </td><td></td><td></td><td>  Ungew√∂hnlicher Pitbull </td></tr><tr><td>  2 </td><td></td><td></td><td>  X. </td><td></td></tr><tr><td>  3 </td><td></td><td>  X. </td><td>  X. </td><td>  Leo  Foto im Zoo an einem regnerischen Tag aufgenommen </td></tr><tr><td>  4 </td><td></td><td>  X. </td><td></td><td>  Panther hinter einem Baum </td></tr><tr><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td></tr><tr><td>  <strong>Anteil (%)</strong> </td><td>  <strong>8%</strong> </td><td>  <strong>43%</strong> </td><td>  <strong>61%</strong> </td><td></td></tr></tbody></table><br><p>  Jetzt wissen Sie, dass die Arbeit an einem Projekt zur Beseitigung der fehlerhaften Einstufung von Hunden als Katzen bestenfalls 8% der Fehler beseitigt.  Wenn Sie an Big Cats oder Fuzzy Images arbeiten, k√∂nnen Sie eine erheblich gr√∂√üere Anzahl von Fehlern beseitigen.  Daher k√∂nnen Sie eine dieser beiden Kategorien ausw√§hlen und sich auf sie konzentrieren.  Wenn Ihr Team √ºber gen√ºgend Mitarbeiter verf√ºgt, um gleichzeitig in mehreren Bereichen zu arbeiten, k√∂nnen Sie mehrere Ingenieure bitten, sich mit Gro√ükatzen zu befassen, und den Rest der Bem√ºhungen auf unscharfe Bilder konzentrieren. </p><br><p>  Die Fehleranalyse bietet keine strenge mathematische Formel, die Ihnen sagt, welcher Aufgabe Sie die h√∂chste Priorit√§t zuweisen m√ºssen.  Sie m√ºssen auch den Fortschritt korrelieren, der bei der Arbeit an den verschiedenen Fehlerkategorien erzielt wurde, und den Aufwand, der f√ºr diese Arbeit aufgewendet werden muss. </p><br><h1 id="16-ochistka-validacionnoy-i-testovoy-vyborok-ot-nepravilno-markirovannyh-primerov">  16. L√∂schen von Validierungs- und Testproben aus falsch gekennzeichneten Beispielen </h1><br><p>  Bei der Analyse von Fehlern stellen Sie m√∂glicherweise fest, dass einige Beispiele in Ihrem Validierungsbeispiel falsch gekennzeichnet sind (der falschen Klasse zugeordnet).  Wenn ich "falsch beschriftet" sage, meine ich, dass die Bilder bereits falsch klassifiziert wurden, als sie von einer Person markiert wurden, bevor der Algorithmus dies erkannte.  Das hei√üt, beim Markieren des Beispiels (x, y) f√ºr y wurde der falsche Wert angegeben.  Angenommen, einige Bilder, in denen keine Katzen vorhanden sind, werden f√§lschlicherweise als Katzen enthaltend gekennzeichnet und umgekehrt.  Wenn Sie den Verdacht haben, dass der Prozentsatz der falsch gekennzeichneten Beispiele signifikant ist, f√ºgen Sie die entsprechende Kategorie hinzu, um die falsch gekennzeichneten Beispiele zu verfolgen: </p><br><table><thead><tr><th>  Bild </th><th>  Hunde </th><th>  Gro√ükatzen </th><th>  Fuzzy </th><th>  Markup-Fehler </th><th>  Kommentare </th></tr></thead><tbody><tr><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td></tr><tr><td>  98 </td><td></td><td></td><td></td><td>  X. </td><td>  Irrt√ºmlicherweise als Katze im Hintergrund bezeichnet </td></tr><tr><td>  99 </td><td></td><td>  X. </td><td></td><td></td><td></td></tr><tr><td>  100 </td><td></td><td></td><td></td><td>  X. </td><td>  Gemalte Katze (nicht echt) </td></tr><tr><td>  <strong>Anteil (%)</strong> </td><td>  <strong>8%</strong> </td><td>  <strong>43%</strong> </td><td>  <strong>61%</strong> </td><td>  <strong>6%</strong> </td><td></td></tr></tbody></table><br><p>  M√ºssen Sie falsch markierte Daten in Ihrem Validierungsmuster korrigieren?  Ich m√∂chte Sie daran erinnern, dass die Aufgabe der Verwendung eines Validierungsmusters darin besteht, Ihnen bei der schnellen Bewertung von Algorithmen zu helfen, damit Sie entscheiden k√∂nnen, ob Algorithmus A besser als B ist. Wenn der Anteil eines falsch gekennzeichneten Validierungsmusters Sie daran hindert, ein solches Urteil zu f√§llen, ist es sinnvoll, Zeit zu verbringen Korrektur von Fehlern bei der Kennzeichnung der Validierungsprobe. </p><br><p>  Stellen Sie sich zum Beispiel vor, dass die Genauigkeit Ihres Klassifikators wie folgt ist: </p><br><ul><li>  Die Gesamtgenauigkeit der Validierungsprobe ............. ..90% (10% Gesamtfehler) </li><li>  Fehler im Zusammenhang mit Markup-Fehlern ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ ..0.6% (6% des Gesamtfehlers in der Validierungsstichprobe) </li><li>  Fehler aus anderen Gr√ºnden .............. 9,4% (94% des Gesamtfehlers in der Validierungsstichprobe) </li></ul><br><p>  Hier ist ein Fehler von 0,6% aufgrund einer falschen Kennzeichnung m√∂glicherweise nicht signifikant genug in Bezug auf einen Fehler von 9,4%, den Sie verbessern k√∂nnten.  Die manuelle Korrektur der Markup-Fehler des Validierungsmusters ist nicht √ºberfl√ºssig, ihre Korrektur ist jedoch nicht kritisch, da es keine Rolle spielt, ob der tats√§chliche Gesamtfehler Ihres Systems 9,4% oder 10% betr√§gt </p><br><p>  Angenommen, Sie verbessern Ihren Katzenklassifikator und haben die folgenden Genauigkeitsmetriken erreicht: </p><br><ul><li>  Die Gesamtgenauigkeit der Validierungsprobe ............. ..98% (2% Gesamtfehler) </li><li>  Fehler im Zusammenhang mit Markup-Fehlern ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ ..0.6% (30% des Gesamtfehlers in der Validierungsstichprobe) </li><li>  Fehler aus anderen Gr√ºnden .............. 1,4% (70% des Gesamtfehlers in der Validierungsstichprobe) </li></ul><br><p>  30% Ihres Fehlers sind auf eine falsche Kennzeichnung der Bilder des Validierungsmusters zur√ºckzuf√ºhren. Dieser Anteil tr√§gt wesentlich zum Gesamtfehler bei der Beurteilung der Genauigkeit Ihres Systems bei.  In diesem Fall lohnt es sich, die Kennzeichnung der Validierungsprobe zu verbessern.  Wenn Sie falsch beschriftete Beispiele entfernen, k√∂nnen Sie herausfinden, wo Ihre Klassifizierungsfehler n√§her bei 1,4% oder 2% liegen.  Es gibt einen signifikanten relativen Unterschied zwischen 1,4 und 2. </p><br><p>  Es ist nicht ungew√∂hnlich, dass falsch beschriftete Bilder eines Validierungs- oder Testmusters Ihre Aufmerksamkeit erst dann auf sich ziehen, wenn sich Ihr System so stark verbessert hat, dass die mit falschen Beispielen verbundene Fehlerrate im Verh√§ltnis zum Gesamtfehler in diesen Beispielen zunimmt. </p><br><p>  Im n√§chsten Kapitel wird erl√§utert, wie Sie Fehlerkategorien wie Hunde, Gro√ükatzen und Fuzzy verbessern k√∂nnen, w√§hrend Sie an der Verbesserung von Algorithmen arbeiten.  In diesem Kapitel haben Sie gelernt, dass Sie den mit der Kategorie ‚ÄûLayoutfehler‚Äú verbundenen Fehler reduzieren und die Qualit√§t verbessern k√∂nnen, indem Sie das Datenmarkup verbessern. </p><br><p>  Unabh√§ngig davon, welchen Ansatz Sie zum Markieren des Validierungsmusters verwenden, vergessen Sie nicht, ihn auf das Layout des Testmusters anzuwenden, damit Ihre Validierungs- und Testmuster dieselbe Verteilung aufweisen.  Wenn Sie denselben Ansatz f√ºr Validierungs- und Testmuster anwenden, vermeiden Sie das in Kapitel 6 beschriebene Problem, wenn Ihr Team die Qualit√§t des Algorithmus in der Validierungsprobe optimiert und sp√§ter feststellt, dass diese Qualit√§t auf der Grundlage einer anderen als der Validierungstestprobe bewertet wurde. </p><br><p>  Wenn Sie Ihr Markup verbessern m√∂chten, sollten Sie dies √ºberpr√ºfen.  √úberpr√ºfen Sie sowohl das Markup von Beispielen, die Ihr System falsch klassifiziert hat, als auch das Markup von Beispielen, die korrekt klassifiziert wurden.  Es ist m√∂glich, dass sowohl das anf√§ngliche Markup als auch Ihr Lernalgorithmus im selben Beispiel falsch waren.  Wenn Sie nur das Markup der Beispiele korrigieren, bei denen Ihr System einen Fehler in der Klassifizierung gemacht hat, k√∂nnen Sie einen systematischen Fehler in Ihre Bewertung einbringen.  Wenn Sie 1000 Beispiele f√ºr Validierungsmuster nehmen und Ihr Klassifikator eine Genauigkeit von 98,0% aufweist, ist es einfacher, 20 falsch klassifizierte Beispiele als 980 korrekt klassifizierte Beispiele zu √ºberpr√ºfen.  Aufgrund der Tatsache, dass es in der Praxis einfacher ist, nur falsch klassifizierte Beispiele zu √ºberpr√ºfen, kann sich in einigen F√§llen ein systematischer Fehler in die Validierungsmuster einschleichen.  Ein solcher Fehler ist zul√§ssig, wenn Sie nur an der Entwicklung von Anwendungen interessiert sind. Es ist jedoch ein Problem, wenn Sie Ihr Ergebnis in einem wissenschaftlichen Forschungsartikel verwenden m√∂chten oder Messungen der Genauigkeit des Algorithmus an einer Testprobe ben√∂tigen, die v√∂llig frei von systematischen Fehlern ist. </p><br><h1 id="17-esli-u-vas-bolshaya-validacionnaya-vyborka-razdelite-ee-na-dve-podvyborki-i-rassmatrivayte-tolko-odnu-iz-nih">  17. Wenn Sie eine gro√üe Validierungsstichprobe haben, teilen Sie diese in zwei Teilstichproben auf und betrachten Sie nur eine davon. </h1><br><p>  Angenommen, Sie haben eine gro√üe Validierungsstichprobe, die aus 5000 Beispielen besteht, bei denen die Fehlerrate 20% betr√§gt.  Daher klassifiziert Ihr Algorithmus etwa 1000 Validierungsbilder nicht korrekt.  Die manuelle Bewertung von 1000 Bildern wird lange dauern, daher entscheiden wir uns m√∂glicherweise, nicht alle f√ºr Fehleranalysezwecke zu verwenden. </p><br><p>  In diesem Fall w√ºrde ich die Validierungsstichprobe definitiv in zwei Teilstichproben aufteilen, von denen Sie eine beobachten werden und die andere nicht.  Es ist wahrscheinlich, dass Sie den Teil, den Sie manuell analysieren, neu trainieren.  Sie k√∂nnen den Teil, den Sie nicht f√ºr die manuelle Analyse verwenden, zum Konfigurieren von Modellparametern verwenden. </p><br><p><img src="https://habrastorage.org/webt/jq/gx/j2/jqgxj2xgwe2rtxbu5-3d06cvi2m.png" alt="Auge"></p><br><p>  Lassen Sie uns unser oben beschriebenes Beispiel fortsetzen, in dem der Algorithmus 1000 Beispiele von 5000, die die Validierungsstichprobe bilden, falsch klassifiziert hat.  Stellen Sie sich vor, Sie m√∂chten 100 Fehler f√ºr die Analyse verwenden (10% aller Fehler in der Validierungsstichprobe).  Wir m√ºssen zuf√§llig 10% der Beispiele aus der Validierungsstichprobe ausw√§hlen und daraus das ‚Äû <strong>Eyeball Dev Set</strong> ‚Äú ( <strong>Eyeball Dev Set</strong> ) zusammenstellen. Wir haben sie benannt, damit wir uns immer daran erinnern, dass wir diese Beispiele mit unseren eigenen Augen studieren. </p><br><p>  <em><u>Anmerkung</u> des <u>√úbersetzers:</u> Aus meiner Sicht klingt die Definition der ‚ÄûAugapfelauswahl‚Äú √ºberhaupt nicht harmonisch (insbesondere aus Sicht der russischen Sprache).</em>  <em>Aber bei allem Respekt vor Andrew (und unter Ber√ºcksichtigung, dass ich mir nichts Besseres ausgedacht habe) werde ich diese Definition verlassen</em> </p><br><p>  (F√ºr ein Spracherkennungsprojekt, in dem Sie Audioclips anh√∂ren, verwenden Sie m√∂glicherweise stattdessen etwas wie ‚ÄûValidierungsbeispiel f√ºr Ohren‚Äú.)  Somit besteht die Validierungsprobe des Augapfels aus 500 Beispielen, in denen ungef√§hr 100 falsch klassifiziert sein sollten.  Das zweite Teilbeispiel des Validierungsbeispiels, das wir als <strong>Blackbox-Entwickler-Set bezeichnen</strong> , besteht aus 4.500 Beispielen.  Mit der ‚ÄûBlack Box-Unterabtastung‚Äú k√∂nnen Sie die Qualit√§t der Klassifizierer automatisch bewerten und ihren Fehleranteil messen.  Sie k√∂nnen dieses Teilbeispiel auch verwenden, um zwischen Algorithmen zu w√§hlen oder Hyperparameter zu konfigurieren.  Sie sollten jedoch vermeiden, Beispiele f√ºr dieses Teilbeispiel mit eigenen Augen zu betrachten.  Wir verwenden den Begriff ‚ÄûBlack Box‚Äú, weil wir eine Teilstichprobe ihrer Komponente als ‚ÄûBlack Box‚Äú verwenden. <br>  <em><u>ca.</u></em>  <em><u>√úbersetzer</u> : d. h. das Objekt, dessen Struktur wir nicht kennen</em> <br>  die Qualit√§t der Klassifikatoren zu bewerten. </p><br><p><img src="https://habrastorage.org/webt/vn/eq/m_/vneqm_5_1tuyfjdqprt86-valpu.png" alt="Bild"></p><br><p>  Warum trennen wir die Validierungsstichprobe explizit in die Unterprobe ‚ÄûAugapfel‚Äú und die Teilstichprobe ‚ÄûBlack Box‚Äú? <br>  Da Sie irgendwann die Beispiele in der ‚ÄûAugapfel-Unterabtastung‚Äú zunehmend sp√ºren (verstehen), steigt die Wahrscheinlichkeit, dass Sie diese Unterabtastung erneut trainieren.  Um die Umschulung zu steuern, verwenden wir das ‚ÄûBlack Box Subsampling‚Äú.  Wenn Sie feststellen, dass die Qualit√§t der Algorithmen im Eyeball-Sample erheblich schneller w√§chst als die Qualit√§t im Black-Box-Sample, haben Sie anscheinend den Eyeball umgeschult.  In diesem Fall m√ºssen Sie m√∂glicherweise die vorhandene Teilmenge des Augapfels verwerfen und eine neue erstellen, indem Sie weitere Beispiele aus der Black Box in den Augapfel verschieben oder einen neuen Teil der markierten Daten √ºbernehmen. </p><br><p>  Wenn Sie also die Validierungsstichprobe in ‚ÄûAugapfel-Teilstichprobe‚Äú und ‚ÄûBlack-Box-Teilstichprobe‚Äú unterteilen, k√∂nnen Sie den Moment sehen, in dem Sie durch die manuelle Fehleranalyse die Augapfel-Teilstichprobe erneut trainieren. </p><br><h1 id="18-naskolko-bolshimi-dolzhny-byt-vyborka-glaznogo-yabloka-i-vyborka-chernogo-yaschika">  18 Wie gro√ü sollten die Augapfelprobe und die Black-Box-Probe sein? </h1><br><p>  Ihre Augapfelprobe sollte gro√ü genug sein, damit Sie die Hauptkategorien von Klassifizierungsfehlern f√ºr Ihren Algorithmus finden k√∂nnen.  Wenn Sie an einer Aufgabe arbeiten, die eine Person erledigen kann (z. B. das Erkennen von Katzen in Bildern), k√∂nnen Sie die folgenden ziemlich groben Empfehlungen geben: </p><br><ul><li>  Ein Validierungsmuster des Augapfels, das 10 Fehler Ihres Klassifikators enth√§lt, wird als sehr klein angesehen.  Mit nur 10 Fehlern ist es sehr schwierig, die Auswirkungen verschiedener Fehlerkategorien auf die Qualit√§t des Klassifikators genau zu bewerten.  Wenn Sie jedoch nur sehr wenige Daten haben und es keine M√∂glichkeit gibt, der Augapfelprobe weitere Beispiele hinzuzuf√ºgen, ist dies immer noch besser als nichts und hilft auf jeden Fall bei der Priorisierung der Arbeit am Projekt. </li><li>  Wenn Ihr Klassifikator bei einer Probe des Augapfels etwa 20 Mal falsch ist, k√∂nnen Sie die Hauptfehlerquellen grob absch√§tzen. </li><li>  Mit ungef√§hr 50 Fehlern erhalten Sie eine gute Vorstellung von den Hauptfehlerquellen Ihres Klassifikators. </li><li>  Wenn Sie ungef√§hr 100 Fehler haben, erhalten Sie ein sehr gutes Verst√§ndnis daf√ºr, woher die Hauptfehler stammen.  Ich habe Leute getroffen, die manuell noch mehr Fehler analysiert haben, manchmal bis zu 500. Warum nicht, wenn Sie genug Daten haben. </li></ul><br><p>  Angenommen, die Fehlerrate Ihres Klassifikators betr√§gt 5%.  Um mit Sicherheit ungef√§hr 100 falsch gekennzeichnete Beispiele in der Augapfelprobe zu erhalten, sollte diese Probe ungef√§hr 2000 Beispiele enthalten (da 0,05 * 2000 = 100).  Je kleiner die Fehlerrate Ihres Klassifikators ist, desto gr√∂√üer ist die Stichprobe des Augapfels, um eine ausreichend gro√üe Stichprobe von Fehlern f√ºr die Analyse zu erhalten. </p><br><p>  Wenn Sie an einer Aufgabe arbeiten, bei der es selbst f√ºr Menschen schwierig ist, Beispiele korrekt zu klassifizieren, sind √úbungen zur √úberpr√ºfung der Validierungsprobe des Augapfels nicht besonders n√ºtzlich, da schwer zu verstehen ist, warum der Algorithmus das Beispiel nicht korrekt klassifizieren konnte.  In diesem Fall k√∂nnen Sie die Einstellung f√ºr die Augapfelabtastung √ºberspringen.  Wir werden Empfehlungen f√ºr solche Projekte in den folgenden Kapiteln diskutieren. </p><br><p>  Und was ist mit dem ‚ÄûBlack Box Sampling‚Äú?  Wir haben bereits erw√§hnt, dass das Validierungsmuster im allgemeinen Fall 1000 - 10000 Beispiele enth√§lt.  Um diese Aussage zu erg√§nzen, liefert eine Black-Box-Validierungsstichprobe von 1.000 bis 10.000 Beispielen normalerweise (h√§ufig) gen√ºgend Daten, um Hyperparameter zu konfigurieren und zwischen Modellen zu w√§hlen. Wenn Sie jedoch mehr Daten zur Auswahl einer Black-Box verwenden, wird dies nicht schlechter.  Eine Black-Box-Auswahl von 100 Beispielen reicht sicherlich nicht aus, ist aber dennoch n√ºtzlich (besser als nichts). </p><br><p>  Wenn Sie eine kleine Validierungsprobe haben, sind m√∂glicherweise nicht gen√ºgend Daten vorhanden, um sie in Augapfel- und Black-Box-Proben zu unterteilen, sodass beide gro√ü genug sind und den oben beschriebenen Zwecken dienen k√∂nnen.  In diesem Fall m√ºssen Sie m√∂glicherweise Ihre gesamte Validierungsprobe als Augapfelprobe verwenden. <br>  Das hei√üt, Sie werden alle Daten aus dem Validierungsmuster manuell untersuchen. </p><br><p>  Ich glaube, dass die Auswahl des Augapfels wichtiger ist als die Auswahl der Black Box (vorausgesetzt, Sie arbeiten an einem Problem, bei dem die Leute gut darin sind, Klassen zu definieren und Beispiele manuell zu √ºberpr√ºfen, k√∂nnen Sie sich ein Bild von Ihren Daten machen).  Wenn Sie nur eine Auswahl des Augapfels zur Verf√ºgung haben, k√∂nnen Sie an der Analyse von Fehlern, der Auswahl von Modellen und der Einstellung von Hyperparametern arbeiten, indem Sie nur diesen verwenden.  Der Nachteil, nur mit der Auswahl des Augapfels zu arbeiten, besteht darin, dass in diesem Fall das Risiko einer Umschulung des Modells in der Validierungsstichprobe zunimmt. </p><br><p>  Wenn Sie √ºber gen√ºgend Daten verf√ºgen, h√§ngt die Stichprobengr√∂√üe des Augapfels haupts√§chlich davon ab, wie viel Zeit Sie f√ºr die manuelle Datenanalyse verwenden k√∂nnen.  Zum Beispiel habe ich selten jemanden getroffen, der mehr als 1000 Fehler manuell analysiert hat. </p><br><h1 id="19-vyvody-bazovyy-analiz-oshibok">  19 Schlussfolgerungen: Grundlegende Fehleranalyse </h1><br><ul><li>     ,   ,      ,         </li><li>         .         ,    ‚Äî     .    ,                 . </li><li>   ,    100    ,       ,          .         ,   . </li><li>          ,         ,     .          ,      ,                   . </li><li>          ,           .    ,   1000-10000      . </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wenn Ihre Validierungsprobe nicht gro√ü genug ist, um sie in eine Augapfelprobe und eine Black-Box-Probe aufzuteilen, verwenden Sie einfach die Augapfelvalidierungsprobe, um Fehler manuell zu analysieren, Modelle auszuw√§hlen und Hyperparameter zu konfigurieren. </font></font></li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortsetzung</font></font></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de419885/">https://habr.com/ru/post/de419885/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de419873/index.html">Testen nur mit √∂ffentlichen Methoden ist schlecht</a></li>
<li><a href="../de419875/index.html">Noch einmal √ºber Verz√∂gerungen im Quellcode des FPGA-Projekts oder eine einfache Frage f√ºr ein Interview f√ºr einen FPGA-Entwicklerjob</a></li>
<li><a href="../de419877/index.html">Wie wir wieder ‚ÄûSmart Home‚Äú erfunden haben</a></li>
<li><a href="../de419879/index.html">PWA ist einfach. Hallo Joomla</a></li>
<li><a href="../de419883/index.html">Holen Sie sich den Unterschied zwischen Bin√§rdateien mit vcdiff</a></li>
<li><a href="../de419893/index.html">So f√ºhren Sie Benutzersuchen auf Github mit VanillaJS durch</a></li>
<li><a href="../de419895/index.html">Mit der neuen Engine k√∂nnen Mikrosatelliten "erwachsene" Aufgaben ausf√ºhren</a></li>
<li><a href="../de419897/index.html">"Machine Sound": Synthesizer basierend auf neuronalen Netzen</a></li>
<li><a href="../de419899/index.html">Internet im Land: Wie spart man?</a></li>
<li><a href="../de419901/index.html">Ist eine sofortige √úbertragung von Informationen m√∂glich? Quantenverschr√§nkte Teilchenexperimente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
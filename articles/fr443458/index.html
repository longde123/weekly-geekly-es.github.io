<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍💼 ⚜️ 🕡 6 bugs système divertissants dans le fonctionnement de Kubernetes [et leur solution] 🤱🏼 🏁 🐿️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Au fil des années d'exploitation de Kubernetes en production, nous avons accumulé de nombreuses histoires intéressantes, car les bogues dans divers co...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>6 bugs système divertissants dans le fonctionnement de Kubernetes [et leur solution]</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/443458/"><img src="https://habrastorage.org/webt/7o/mz/o2/7omzo2vcqpqijlxsewel9gyhcsq.png"><br><br>  Au fil des années d'exploitation de Kubernetes en production, nous avons accumulé de nombreuses histoires intéressantes, car les bogues dans divers composants du système ont entraîné des conséquences désagréables et / ou incompréhensibles qui affectent le fonctionnement des conteneurs et des pods.  Dans cet article, nous avons sélectionné quelques-unes des plus fréquentes ou intéressantes.  Même si vous n'êtes jamais assez chanceux pour rencontrer de telles situations, lire à propos de ces brefs détectives - d'autant plus, de première main - est toujours amusant, n'est-ce pas? <a name="habracut"></a><br><br><h2>  Historique 1. Docker supercronique et glacial </h2><br>  Sur l'un des clusters, nous recevions périodiquement un Docker «gelé», qui interférait avec le fonctionnement normal du cluster.  Dans le même temps, ce qui suit a été observé dans les journaux Docker <br><br><pre><code class="plaintext hljs">level=error msg="containerd: start init process" error="exit status 2: \"runtime/cgo: pthread_create failed: No space left on device SIGABRT: abort PC=0x7f31b811a428 m=0 goroutine 0 [idle]: goroutine 1 [running]: runtime.systemstack_switch() /usr/local/go/src/runtime/asm_amd64.s:252 fp=0xc420026768 sp=0xc420026760 runtime.main() /usr/local/go/src/runtime/proc.go:127 +0x6c fp=0xc4200267c0 sp=0xc420026768 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc4200267c8 sp=0xc4200267c0 goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 …</code> </pre> <br>  Dans cette erreur, le message nous intéresse le plus: <code>pthread_create failed: No space left on device</code> .  Une étude rapide de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation a</a> expliqué que Docker ne pouvait pas bifurquer le processus, ce qui provoquait un «gel» périodique. <br><br>  Dans le suivi de ce qui se passe, l'image suivante correspond: <br><br><img src="https://habrastorage.org/webt/7r/cq/gv/7rcqgvafvtlmis1kl7maxyz5jgk.png"><br><br>  Une situation similaire est observée sur d'autres nœuds: <br><br><img src="https://habrastorage.org/webt/lj/mw/-h/ljmw-hrrlyukwgmigltivjwyxig.png"><br><br><img src="https://habrastorage.org/webt/ap/tw/5u/aptw5ufxl-9woo5zszegfg1nqvc.png"><br><br>  Sur les mêmes nœuds, nous voyons: <br><br><pre> <code class="bash hljs">root@kube-node-1 ~ <span class="hljs-comment"><span class="hljs-comment"># ps auxfww | grep curl -c 19782 root@kube-node-1 ~ # ps auxfww | grep curl | head root 16688 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 17398 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16852 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 9473 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 4664 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 30571 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 24113 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16475 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 7176 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 1090 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt;</span></span></code> </pre> <br>  Il s'est avéré que ce comportement est une conséquence du travail du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pod</a> avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">supercronic</a> (l'utilitaire sur Go que nous utilisons pour exécuter des tâches cron dans les pods): <br><br><pre> <code class="plaintext hljs"> \_ docker-containerd-shim 833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 /var/run/docker/libcontainerd/833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 docker-runc | \_ /usr/local/bin/supercronic -json /crontabs/cron | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true | | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true -no-pidfile | \_ [newrelic-daemon] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; …</code> </pre> <br>  Le problème est le suivant: lorsqu'une tâche démarre en supercronic, le processus généré par elle <b>ne peut pas se terminer correctement</b> , se transformant en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">zombie</a> . <br><br>  <i><b>Remarque</b> : pour être plus précis, les processus sont générés par des tâches cron, cependant, le supercronic n'est pas un système init et ne peut pas «adopter» les processus que ses enfants ont engendrés.</i>  <i>Lorsque des signaux SIGHUP ou SIGTERM se produisent, ils ne sont pas transmis aux processus générés, à la suite de quoi les processus enfants ne se terminent pas, restant dans le statut zombie.</i>  <i>Vous pouvez en savoir plus sur tout cela, par exemple, dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un tel article</a> .</i> <br><br>  Il existe deux façons de résoudre les problèmes: <br><br><ol><li>  Solution de contournement temporaire: augmentez le nombre de PID dans le système à un moment donné: <br><br><pre> <code class="plaintext hljs"> /proc/sys/kernel/pid_max (since Linux 2.5.34) This file specifies the value at which PIDs wrap around (ie, the value in this file is one greater than the maximum PID). PIDs greater than this value are not allo‐ cated; thus, the value in this file also acts as a system-wide limit on the total number of processes and threads. The default value for this file, 32768, results in the same range of PIDs as on earlier kernels</code> </pre> </li><li>  Ou, faites le lancement de tâches en supercronic pas directement, mais avec l'aide du même <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tini</a> , qui est capable de terminer correctement les processus et de ne pas générer de zombie. </li></ol><br><h2>  Historique 2. "Zombies" lors de la suppression de cgroup </h2><br>  Kubelet a commencé à consommer beaucoup de CPU: <br><br><img src="https://habrastorage.org/webt/ns/lh/mp/nslhmpwfnmennya-btg5icbkh8e.png"><br><br>  Personne n'aime cela, alors nous nous sommes armés de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">perf</a> et avons commencé à régler le problème.  Les résultats de l'enquête sont les suivants: <br><br><ul><li>  Kubelet passe plus d'un tiers du temps CPU à extraire les données de la mémoire de tous les groupes de contrôle: <br><br><img src="https://habrastorage.org/webt/yf/u7/qv/yfu7qvvcnryl5iknz4zosagh0is.png"></li><li>  Dans la liste de diffusion des développeurs du noyau, vous pouvez trouver une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">discussion sur le problème</a> .  En bref, l'essentiel est que <b>différents fichiers tmpfs et autres choses similaires ne sont pas complètement supprimés du système</b> lorsque cgroup est supprimé - le soi-disant <b>zombie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">memcg</a></b> reste.  Tôt ou tard, ils seront néanmoins supprimés du cache de pages, cependant, la mémoire sur le serveur est volumineuse et le noyau ne voit pas l'intérêt de perdre du temps à les supprimer.  Par conséquent, ils continuent de s'accumuler.  Pourquoi cela se produit-il même?  Il s'agit d'un serveur avec des tâches cron qui crée constamment de nouvelles tâches et avec elles de nouveaux pods.  Ainsi, de nouveaux groupes de contrôle sont créés pour les conteneurs qu'ils contiennent, qui seront bientôt supprimés. </li><li>  Pourquoi cAdvisor dans Kubelet passe autant de temps?  Ceci est facilement visible par l'exécution la plus simple du <code>time cat /sys/fs/cgroup/memory/memory.stat</code> .  Si l'opération prend 0,01 seconde sur une machine saine, puis 1,2 seconde sur un cron02 problématique.  Le fait est que cAdvisor, qui lit très lentement les données des sysfs, essaie également de prendre en compte la mémoire utilisée dans les groupes de zombies. </li><li>  Pour supprimer de force les zombies, nous avons essayé de vider les caches, comme recommandé dans LKML: <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>  <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code> , mais le noyau s'est avéré plus compliqué et a bloqué la machine. </li></ul><br>  Que faire?  Le problème est résolu ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">commit</a> , et la description, voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le message de sortie</a> ) en mettant à jour le noyau Linux vers la version 4.16. <br><br><h2>  Historique 3. Systemd et sa monture </h2><br>  Encore une fois, kubelet consomme trop de ressources sur certains nœuds, mais cette fois, c'est déjà de la mémoire: <br><br><img src="https://habrastorage.org/webt/ud/l3/vl/udl3vlr9r5c6hzxoamdmnzvvm5m.png"><br><br>  Il s'est avéré qu'il y avait un problème dans le systemd utilisé dans Ubuntu 16.04, et cela se produit lors du contrôle des montages qui sont créés pour connecter les sous- <code>subPath</code> depuis ConfigMaps ou secrets.  Une fois le pod terminé, le <b>service systemd et son montage de service restent</b> sur le système.  Au fil du temps, ils accumulent une énorme quantité.  Il y a même des problèmes sur ce sujet: <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kops # 5916</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kubernetes # 57345</a> . </li></ol><br>  ... dans le dernier, se référer à PR dans systemd: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="># 7811</a> (le problème dans systemd est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="># 7798</a> ). <br><br>  Le problème n'est plus dans Ubuntu 18.04, mais si vous souhaitez continuer à utiliser Ubuntu 16.04, notre solution de contournement sur ce sujet peut être utile. <br><br>  Nous avons donc créé le DaemonSet suivant: <br><br><pre> <code class="plaintext hljs">--- apiVersion: extensions/v1beta1 kind: DaemonSet metadata: labels: app: systemd-slices-cleaner name: systemd-slices-cleaner namespace: kube-system spec: updateStrategy: type: RollingUpdate selector: matchLabels: app: systemd-slices-cleaner template: metadata: labels: app: systemd-slices-cleaner spec: containers: - command: - /usr/local/bin/supercronic - -json - /app/crontab Image: private-registry.org/systemd-slices-cleaner/systemd-slices-cleaner:v0.1.0 imagePullPolicy: Always name: systemd-slices-cleaner resources: {} securityContext: privileged: true volumeMounts: - name: systemd mountPath: /run/systemd/private - name: docker mountPath: /run/docker.sock - name: systemd-etc mountPath: /etc/systemd - name: systemd-run mountPath: /run/systemd/system/ - name: lsb-release mountPath: /etc/lsb-release-host imagePullSecrets: - name: antiopa-registry priorityClassName: cluster-low tolerations: - operator: Exists volumes: - name: systemd hostPath: path: /run/systemd/private - name: docker hostPath: path: /run/docker.sock - name: systemd-etc hostPath: path: /etc/systemd - name: systemd-run hostPath: path: /run/systemd/system/ - name: lsb-release hostPath: path: /etc/lsb-release</code> </pre> <br>  ... et il utilise le script suivant: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash # we will work only on xenial hostrelease="/etc/lsb-release-host" test -f ${hostrelease} &amp;&amp; grep xenial ${hostrelease} &gt; /dev/null || exit 0 # sleeping max 30 minutes to dispense load on kube-nodes sleep $((RANDOM % 1800)) stoppedCount=0 # counting actual subpath units in systemd countBefore=$(systemctl list-units | grep subpath | grep "run-" | wc -l) # let's go check each unit for unit in $(systemctl list-units | grep subpath | grep "run-" | awk '{print $1}'); do # finding description file for unit (to find out docker container, who born this unit) DropFile=$(systemctl status ${unit} | grep Drop | awk -F': ' '{print $2}') # reading uuid for docker container from description file DockerContainerId=$(cat ${DropFile}/50-Description.conf | awk '{print $5}' | cut -d/ -f6) # checking container status (running or not) checkFlag=$(docker ps | grep -c ${DockerContainerId}) # if container not running, we will stop unit if [[ ${checkFlag} -eq 0 ]]; then echo "Stopping unit ${unit}" # stoping unit in action systemctl stop $unit # just counter for logs ((stoppedCount++)) # logging current progress echo "Stopped ${stoppedCount} systemd units out of ${countBefore}" fi done</span></span></code> </pre> <br>  ... et ça commence toutes les 5 minutes avec le supercronic déjà mentionné.  Son Dockerfile ressemble à ceci: <br><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 COPY rootfs / WORKDIR /app RUN apt-get update &amp;&amp; \ apt-get upgrade -y &amp;&amp; \ apt-get install -y gnupg curl apt-transport-https software-properties-common wget RUN add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable" &amp;&amp; \ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y docker-ce=17.03.0* RUN wget https://github.com/aptible/supercronic/releases/download/v0.1.6/supercronic-linux-amd64 -O \ /usr/local/bin/supercronic &amp;&amp; chmod +x /usr/local/bin/supercronic ENTRYPOINT ["/bin/bash", "-c", "/usr/local/bin/supercronic -json /app/crontab"]</code> </pre> <br><h2>  Historique 4. Compétition dans la planification des modules </h2><br>  Il a été noté que: si un pod est placé sur notre nœud et que son image est pompée pendant très longtemps, alors l'autre pod qui est "arrivé" au même nœud <b>ne commence</b> tout simplement <b>pas à tirer l'image du nouveau pod</b> .  Au lieu de cela, il attend que l'image du pod précédent soit tirée.  En conséquence, un pod qui a déjà été planifié et dont l'image pourrait être téléchargée en une minute se retrouvera longtemps dans l'état <code>containerCreating</code> . <br><br>  Dans les événements, il y aura quelque chose comme ça: <br><br><pre> <code class="plaintext hljs">Normal Pulling 8m kubelet, ip-10-241-44-128.ap-northeast-1.compute.internal pulling image "registry.example.com/infra/openvpn/openvpn:master"</code> </pre> <br>  Il s'avère qu'une <b>seule image du registre lent peut bloquer le déploiement</b> sur le nœud. <br><br>  Malheureusement, il n'y a pas tant de façons de sortir de la situation: <br><br><ol><li>  Essayez d'utiliser votre Docker Registry directement dans le cluster ou directement avec le cluster (par exemple, GitLab Registry, Nexus, etc.); </li><li>  Utilisez des utilitaires comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kraken</a> . </li></ol><br><h2>  Historique 5. Nœuds suspendus avec mémoire insuffisante </h2><br>  Pendant le fonctionnement de diverses applications, nous avons également reçu une situation où le nœud cesse complètement d'être accessible: SSH ne répond pas, tous les démons de surveillance tombent, puis rien (ou presque rien) n'est anormal dans les journaux. <br><br>  Je vais vous dire dans les images sur l'exemple d'un nœud où MongoDB a fonctionné. <br><br>  Voici à quoi ressemble au sommet <b>avant le</b> crash: <br><br><img src="https://habrastorage.org/webt/l5/ef/az/l5efazbhjmzsuxdv6puz1tlvbzs.png"><br><br>  Et donc - <b>après l'</b> accident: <br><br><img src="https://habrastorage.org/webt/wx/mh/q7/wxmhq71060dhvxsxk-dh8m--pas.png"><br><br>  Dans la surveillance aussi, il y a un saut brusque dans lequel le nœud cesse d'être accessible: <br><br><img src="https://habrastorage.org/webt/tp/fm/wf/tpfmwftsui_eoz91ojyy5rzektc.png"><br><br>  Ainsi, les captures d'écran montrent que: <br><br><ol><li>  La RAM sur la machine est proche de la fin; </li><li>  On observe une forte augmentation de la consommation de RAM, après quoi l'accès à l'ensemble de la machine est fortement désactivé; </li><li>  Une grosse tâche arrive chez Mongo, qui oblige le processus SGBD à utiliser plus de mémoire et à lire activement à partir du disque. </li></ol><br>  Il s'avère que si Linux manque de mémoire libre (une pression de mémoire se produit) et qu'il n'y a pas d'échange, puis <b>avant que</b> le tueur OOM n'arrive, un équilibre peut se produire entre le lancement de pages dans le cache de pages et leur réécriture sur le disque.  Ceci est fait par kswapd, qui libère courageusement autant de pages de mémoire que possible pour une distribution ultérieure. <br><br>  Malheureusement, avec une grande charge d'E / S, couplée à une petite quantité de mémoire libre, <b>kswapd devient le goulot d'étranglement de tout le système</b> , car <b>tous les</b> défauts de page des pages de mémoire du système lui sont liés.  Cela peut durer très longtemps si les processus ne veulent plus utiliser de mémoire, mais sont fixés au bord même de l'abîme OOM-killer. <br><br>  La question logique est: pourquoi le tueur OOM arrive si tard?  Dans l'itération OOM actuelle, killer est extrêmement stupide: il ne tuera le processus que lorsque la tentative d'allocation d'une page mémoire échoue, c'est-à-dire  si l'erreur de page échoue.  Cela ne se produit pas pendant longtemps, car kswapd libère courageusement des pages de mémoire en vidant le cache de pages (toutes les E / S de disque du système, en fait) sur disque.  Plus en détail, avec une description des étapes nécessaires pour éliminer de tels problèmes dans le noyau, vous pouvez lire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Ce comportement <a href="">devrait s'améliorer</a> avec le noyau Linux 4.6+. <br><br><h2>  Histoire 6. Les pods sont en attente </h2><br>  Dans certains clusters, dans lesquels il y a vraiment beaucoup de pods, nous avons commencé à remarquer que la plupart d'entre eux étaient suspendus dans l'état <code>Pending</code> depuis très longtemps, bien que les conteneurs Docker eux-mêmes soient déjà en cours d'exécution sur les nœuds et que vous puissiez travailler manuellement avec eux. <br><br>  Il n'y a rien de mal à <code>describe</code> : <br><br><pre> <code class="plaintext hljs"> Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 1m default-scheduler Successfully assigned sphinx-0 to ss-dev-kub07 Normal SuccessfulAttachVolume 1m attachdetach-controller AttachVolume.Attach succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "sphinx-config" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "default-token-fzcsf" Normal SuccessfulMountVolume 49s (x2 over 51s) kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx-exporter/sphinx-indexer:v1" already present on machine Normal Created 43s kubelet, ss-dev-kub07 Created container Normal Started 43s kubelet, ss-dev-kub07 Started container Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx/sphinx:v1" already present on machine Normal Created 42s kubelet, ss-dev-kub07 Created container Normal Started 42s kubelet, ss-dev-kub07 Started container</code> </pre> <br>  Après avoir fouillé, nous avons fait l'hypothèse que kubelet n'a tout simplement pas le temps d'envoyer au serveur API toutes les informations sur l'état des pods, les échantillons de vivacité / préparation. <br><br>  Et après avoir étudié l'aide, nous avons trouvé les paramètres suivants: <br><br><pre> <code class="plaintext hljs">--kube-api-qps - QPS to use while talking with kubernetes apiserver (default 5) --kube-api-burst - Burst to use while talking with kubernetes apiserver (default 10) --event-qps - If &gt; 0, limit event creations per second to this value. If 0, unlimited. (default 5) --event-burst - Maximum size of a bursty event records, temporarily allows event records to burst to this number, while still not exceeding event-qps. Only used if --event-qps &gt; 0 (default 10) --registry-qps - If &gt; 0, limit registry pull QPS to this value. --registry-burst - Maximum size of bursty pulls, temporarily allows pulls to burst to this number, while still not exceeding registry-qps. Only used if --registry-qps &gt; 0 (default 10)</code> </pre> <br>  Comme vous pouvez le voir, les <b>valeurs par défaut sont assez petites</b> , et à 90% elles couvrent tous les besoins ... Cependant, dans notre cas ce n'était pas suffisant.  Par conséquent, nous définissons ces valeurs: <br><br><pre> <code class="plaintext hljs">--event-qps=30 --event-burst=40 --kube-api-burst=40 --kube-api-qps=30 --registry-qps=30 --registry-burst=40</code> </pre> <br><br>  ... et redémarré les kubelets, après quoi ils ont vu l'image suivante sur les graphiques d'accès au serveur API: <br><br><img src="https://habrastorage.org/webt/nq/-i/oq/nq-ioqoyt6_qudmacm5dwfe8hnk.png"><br><br>  ... et oui, tout a commencé à voler! <br><br><h2>  PS </h2><br>  Pour l'aide à la collecte des bugs et à la préparation de l'article, j'exprime ma profonde gratitude aux nombreux ingénieurs de notre entreprise, et en particulier à Andrei Klimentyev (collègue de notre équipe R&amp;D) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">zuzzas</a> ). <br><br><h2>  PPS </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Plugin Kubectl-debug pour le débogage dans les pods Kubernetes</a> »; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Surveillance et Kubernetes (revue et rapport vidéo)</a> »; </li><li>  Cycle de trucs et astuces Kubernetes: <ul><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transfert des ressources travaillant dans un cluster vers la gestion de Helm 2</a> »; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sur l'allocation des nœuds et la charge sur l'application web</a> »; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Accès aux sites de développement</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Accélérer le bootstrap des grandes bases de données.</a> " </li></ul></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr443458/">https://habr.com/ru/post/fr443458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr443438/index.html">7 extensions Firefox utiles pour apprendre l'anglais</a></li>
<li><a href="../fr443440/index.html">Module PHP pour travailler avec des données hiérarchiques dans InterSystems IRIS</a></li>
<li><a href="../fr443450/index.html">Pourquoi les pauvres ne peuvent pas être en bonne santé</a></li>
<li><a href="../fr443452/index.html">L'armée russe créera son propre Internet fermé</a></li>
<li><a href="../fr443456/index.html">Nous vous invitons à Yandex NLP pendant une semaine</a></li>
<li><a href="../fr443460/index.html">11 réponses sur Yandex.Directory</a></li>
<li><a href="../fr443462/index.html">Piratage de caméras: vecteurs d'attaque, outils de recherche de vulnérabilités et anti-tracking</a></li>
<li><a href="../fr443464/index.html">Guide complet pour changer d'expressions dans Java 12</a></li>
<li><a href="../fr443466/index.html">Roi du développement</a></li>
<li><a href="../fr443468/index.html">Quels outils de surveillance de réseau sont devenus des leaders dans la version de Gartner</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
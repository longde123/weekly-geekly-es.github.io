<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéø üçç üëçüèΩ 6 bug sistem yang menghibur dalam pengoperasian Kubernetes [dan solusinya] üòò üçò üåä</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Selama bertahun-tahun mengoperasikan Kubernet dalam produksi, kami telah mengumpulkan banyak cerita menarik, karena bug di berbagai komponen sistem me...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>6 bug sistem yang menghibur dalam pengoperasian Kubernetes [dan solusinya]</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/443458/"><img src="https://habrastorage.org/webt/7o/mz/o2/7omzo2vcqpqijlxsewel9gyhcsq.png"><br><br>  Selama bertahun-tahun mengoperasikan Kubernet dalam produksi, kami telah mengumpulkan banyak cerita menarik, karena bug di berbagai komponen sistem menyebabkan konsekuensi yang tidak menyenangkan dan / atau tidak dapat dipahami yang mempengaruhi pengoperasian wadah dan polong.  Dalam artikel ini, kami telah memilih beberapa yang paling sering atau menarik.  Bahkan jika Anda tidak pernah cukup beruntung untuk menghadapi situasi seperti itu, membaca tentang detektif sesingkat itu - terlebih lagi, secara langsung - selalu menghibur, bukankah begitu? .. <a name="habracut"></a><br><br><h2>  Sejarah 1. Supercronic dan pembekuan Docker </h2><br>  Di salah satu cluster, kami secara berkala menerima Docker "beku", yang mengganggu fungsi normal cluster.  Pada saat yang sama, berikut ini diamati dalam log Docker <br><br><pre><code class="plaintext hljs">level=error msg="containerd: start init process" error="exit status 2: \"runtime/cgo: pthread_create failed: No space left on device SIGABRT: abort PC=0x7f31b811a428 m=0 goroutine 0 [idle]: goroutine 1 [running]: runtime.systemstack_switch() /usr/local/go/src/runtime/asm_amd64.s:252 fp=0xc420026768 sp=0xc420026760 runtime.main() /usr/local/go/src/runtime/proc.go:127 +0x6c fp=0xc4200267c0 sp=0xc420026768 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc4200267c8 sp=0xc4200267c0 goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 ‚Ä¶</code> </pre> <br>  Dalam kesalahan ini, kami paling tertarik pada pesan: <code>pthread_create failed: No space left on device</code> .  Sebuah studi cepat dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi</a> menjelaskan bahwa Docker tidak dapat melakukan proses percabangan, yang menyebabkannya ‚Äúmembeku‚Äù secara berkala. <br><br>  Dalam memantau apa yang terjadi, gambar berikut ini bersesuaian: <br><br><img src="https://habrastorage.org/webt/7r/cq/gv/7rcqgvafvtlmis1kl7maxyz5jgk.png"><br><br>  Situasi serupa diamati pada node lain: <br><br><img src="https://habrastorage.org/webt/lj/mw/-h/ljmw-hrrlyukwgmigltivjwyxig.png"><br><br><img src="https://habrastorage.org/webt/ap/tw/5u/aptw5ufxl-9woo5zszegfg1nqvc.png"><br><br>  Pada node yang sama kita lihat: <br><br><pre> <code class="bash hljs">root@kube-node-1 ~ <span class="hljs-comment"><span class="hljs-comment"># ps auxfww | grep curl -c 19782 root@kube-node-1 ~ # ps auxfww | grep curl | head root 16688 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 17398 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16852 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 9473 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 4664 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 30571 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 24113 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16475 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 7176 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 1090 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt;</span></span></code> </pre> <br>  Ternyata perilaku ini merupakan konsekuensi dari pekerjaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pod</a> dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">supercronic</a> (utilitas on Go yang kami gunakan untuk menjalankan tugas cron di pod): <br><br><pre> <code class="plaintext hljs"> \_ docker-containerd-shim 833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 /var/run/docker/libcontainerd/833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 docker-runc | \_ /usr/local/bin/supercronic -json /crontabs/cron | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true | | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true -no-pidfile | \_ [newrelic-daemon] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; ‚Ä¶</code> </pre> <br>  Masalahnya adalah ini: ketika tugas dimulai dalam supercronic, proses yang dihasilkannya tidak <b>dapat diselesaikan dengan benar</b> , berubah menjadi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">zombie</a> . <br><br>  <i><b>Catatan</b> : Untuk lebih tepatnya, proses dihasilkan oleh tugas cron, namun, supercronic bukanlah sistem init dan tidak dapat "mengadopsi" proses yang ditimbulkan oleh anak-anaknya.</i>  <i>Ketika sinyal SIGHUP atau SIGTERM terjadi, mereka tidak ditransmisikan ke proses melahirkan, sebagai akibatnya proses anak tidak berakhir, tetap dalam status zombie.</i>  <i>Anda dapat membaca lebih lanjut tentang semua ini, misalnya, dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel seperti itu</a> .</i> <br><br>  Ada beberapa cara untuk menyelesaikan masalah: <br><br><ol><li>  Sebagai solusi sementara - tingkatkan jumlah PID dalam sistem pada satu titik waktu: <br><br><pre> <code class="plaintext hljs"> /proc/sys/kernel/pid_max (since Linux 2.5.34) This file specifies the value at which PIDs wrap around (ie, the value in this file is one greater than the maximum PID). PIDs greater than this value are not allo‚Äê cated; thus, the value in this file also acts as a system-wide limit on the total number of processes and threads. The default value for this file, 32768, results in the same range of PIDs as on earlier kernels</code> </pre> </li><li>  Atau, melakukan peluncuran tugas dalam supercronic tidak secara langsung, tetapi dengan bantuan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tini yang</a> sama, yang mampu menghentikan proses dengan benar dan tidak menghasilkan zombie. </li></ol><br><h2>  Riwayat 2. "Zombies" saat menghapus cgroup </h2><br>  Kubelet mulai mengkonsumsi banyak CPU: <br><br><img src="https://habrastorage.org/webt/ns/lh/mp/nslhmpwfnmennya-btg5icbkh8e.png"><br><br>  Tidak ada yang suka ini, jadi kami mempersenjatai diri dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perf</a> dan mulai menangani masalahnya.  Hasil investigasi adalah sebagai berikut: <br><br><ul><li>  Kubelet menghabiskan lebih dari sepertiga waktu CPU untuk menarik data memori dari semua grup: <br><br><img src="https://habrastorage.org/webt/yf/u7/qv/yfu7qvvcnryl5iknz4zosagh0is.png"></li><li>  Di milis pengembang kernel Anda dapat menemukan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diskusi tentang masalah tersebut</a> .  Singkatnya, intinya adalah bahwa <b>file tmpfs</b> yang <b>berbeda dan hal-hal serupa lainnya tidak sepenuhnya dihapus dari sistem</b> ketika cgroup dihapus - <b>zombie yang</b> disebut <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memcg</a></b> tetap ada.  Cepat atau lambat, mereka tetap akan dihapus dari cache halaman, namun, memori di server besar dan kernel tidak melihat titik membuang-buang waktu menghapusnya.  Karena itu, mereka terus menumpuk.  Mengapa ini bahkan terjadi?  Ini adalah server dengan pekerjaan cron yang terus-menerus menciptakan pekerjaan baru, dan dengan mereka pod baru.  Dengan demikian, cgroup baru dibuat untuk wadah di dalamnya, yang akan segera dihapus. </li><li>  Mengapa cAdvisor di kubelet menghabiskan banyak waktu?  Ini mudah dilihat dengan eksekusi <code>time cat /sys/fs/cgroup/memory/memory.stat</code> .  Jika operasi memakan waktu 0,01 detik pada mesin yang sehat, maka 1,2 detik pada cron02 yang bermasalah.  Masalahnya adalah bahwa cAdvisor, yang membaca data dari sysfs dengan sangat lambat, mencoba untuk memperhitungkan memori yang digunakan dalam cgroup zombie juga. </li><li>  Untuk menghapus zombie dengan paksa, kami mencoba menghapus cache, seperti yang direkomendasikan di LKML: <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>  <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code> , tetapi kernel ternyata lebih rumit dan menggantung mesin. </li></ul><br>  Apa yang harus dilakukan  Masalahnya sudah diperbaiki ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">komit</a> , dan keterangannya, lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pesan rilis</a> ) dengan memperbarui kernel Linux ke versi 4.16. <br><br><h2>  Sejarah 3. Systemd dan mount-nya </h2><br>  Sekali lagi, kubelet mengkonsumsi terlalu banyak sumber daya pada beberapa node, tetapi kali ini sudah memori: <br><br><img src="https://habrastorage.org/webt/ud/l3/vl/udl3vlr9r5c6hzxoamdmnzvvm5m.png"><br><br>  Ternyata ada masalah dalam systemd yang digunakan di Ubuntu 16.04, dan itu terjadi ketika mengendalikan mount yang dibuat untuk menghubungkan <code>subPath</code> dari ConfigMaps atau rahasia.  Setelah pod selesai, <b>layanan systemd dan layanan mountnya tetap berada</b> di sistem.  Seiring waktu, mereka mengumpulkan jumlah yang sangat besar.  Bahkan ada masalah pada topik ini: <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kops # 5916</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kubernetes # 57345</a> . </li></ol><br>  ... yang terakhir merujuk ke PR di systemd: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="># 7811</a> (masalah di systemd adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="># 7798</a> ). <br><br>  Masalahnya tidak lagi di Ubuntu 18.04, tetapi jika Anda ingin terus menggunakan Ubuntu 16.04, solusi kami tentang topik ini mungkin berguna. <br><br>  Jadi, kami membuat DaemonSet berikut: <br><br><pre> <code class="plaintext hljs">--- apiVersion: extensions/v1beta1 kind: DaemonSet metadata: labels: app: systemd-slices-cleaner name: systemd-slices-cleaner namespace: kube-system spec: updateStrategy: type: RollingUpdate selector: matchLabels: app: systemd-slices-cleaner template: metadata: labels: app: systemd-slices-cleaner spec: containers: - command: - /usr/local/bin/supercronic - -json - /app/crontab Image: private-registry.org/systemd-slices-cleaner/systemd-slices-cleaner:v0.1.0 imagePullPolicy: Always name: systemd-slices-cleaner resources: {} securityContext: privileged: true volumeMounts: - name: systemd mountPath: /run/systemd/private - name: docker mountPath: /run/docker.sock - name: systemd-etc mountPath: /etc/systemd - name: systemd-run mountPath: /run/systemd/system/ - name: lsb-release mountPath: /etc/lsb-release-host imagePullSecrets: - name: antiopa-registry priorityClassName: cluster-low tolerations: - operator: Exists volumes: - name: systemd hostPath: path: /run/systemd/private - name: docker hostPath: path: /run/docker.sock - name: systemd-etc hostPath: path: /etc/systemd - name: systemd-run hostPath: path: /run/systemd/system/ - name: lsb-release hostPath: path: /etc/lsb-release</code> </pre> <br>  ... dan menggunakan skrip berikut: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash # we will work only on xenial hostrelease="/etc/lsb-release-host" test -f ${hostrelease} &amp;&amp; grep xenial ${hostrelease} &gt; /dev/null || exit 0 # sleeping max 30 minutes to dispense load on kube-nodes sleep $((RANDOM % 1800)) stoppedCount=0 # counting actual subpath units in systemd countBefore=$(systemctl list-units | grep subpath | grep "run-" | wc -l) # let's go check each unit for unit in $(systemctl list-units | grep subpath | grep "run-" | awk '{print $1}'); do # finding description file for unit (to find out docker container, who born this unit) DropFile=$(systemctl status ${unit} | grep Drop | awk -F': ' '{print $2}') # reading uuid for docker container from description file DockerContainerId=$(cat ${DropFile}/50-Description.conf | awk '{print $5}' | cut -d/ -f6) # checking container status (running or not) checkFlag=$(docker ps | grep -c ${DockerContainerId}) # if container not running, we will stop unit if [[ ${checkFlag} -eq 0 ]]; then echo "Stopping unit ${unit}" # stoping unit in action systemctl stop $unit # just counter for logs ((stoppedCount++)) # logging current progress echo "Stopped ${stoppedCount} systemd units out of ${countBefore}" fi done</span></span></code> </pre> <br>  ... dan itu dimulai setiap 5 menit dengan supercronic yang telah disebutkan.  Dockerfile-nya terlihat seperti ini: <br><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 COPY rootfs / WORKDIR /app RUN apt-get update &amp;&amp; \ apt-get upgrade -y &amp;&amp; \ apt-get install -y gnupg curl apt-transport-https software-properties-common wget RUN add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable" &amp;&amp; \ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y docker-ce=17.03.0* RUN wget https://github.com/aptible/supercronic/releases/download/v0.1.6/supercronic-linux-amd64 -O \ /usr/local/bin/supercronic &amp;&amp; chmod +x /usr/local/bin/supercronic ENTRYPOINT ["/bin/bash", "-c", "/usr/local/bin/supercronic -json /app/crontab"]</code> </pre> <br><h2>  Sejarah 4. Persaingan dalam polong perencanaan </h2><br>  Tercatat bahwa: jika sebuah pod ditempatkan pada node kami dan gambarnya dipompa untuk waktu yang sangat lama, maka pod lainnya yang "masuk" ke node yang sama <b>tidak akan mulai menarik gambar pod baru</b> .  Sebaliknya, ia menunggu gambar pod sebelumnya ditarik.  Akibatnya, pod yang telah direncanakan dan yang gambarnya dapat diunduh hanya dalam satu menit akan berakhir dalam status <code>containerCreating</code> untuk waktu yang lama. <br><br>  Dalam acara, akan ada sesuatu seperti ini: <br><br><pre> <code class="plaintext hljs">Normal Pulling 8m kubelet, ip-10-241-44-128.ap-northeast-1.compute.internal pulling image "registry.example.com/infra/openvpn/openvpn:master"</code> </pre> <br>  Ternyata <b>satu gambar dari registri lambat dapat memblokir penyebaran</b> ke node. <br><br>  Sayangnya, tidak banyak jalan keluar dari situasi ini: <br><br><ol><li>  Cobalah untuk menggunakan Docker Registry Anda secara langsung di cluster atau langsung dengan cluster (misalnya, GitLab Registry, Nexus, dll.); </li><li>  Gunakan utilitas seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kraken</a> . </li></ol><br><h2>  Sejarah 5. Menggantung node dengan kehabisan memori </h2><br>  Selama pengoperasian berbagai aplikasi, kami juga menerima situasi di mana node benar-benar tidak dapat diakses: SSH tidak merespons, semua daemon pemantauan jatuh, dan kemudian tidak ada (atau hampir tidak ada) yang abnormal dalam log. <br><br>  Saya akan memberi tahu Anda dalam gambar pada contoh satu simpul di mana MongoDB berfungsi. <br><br>  Beginilah tampilan puncak <b>sebelum</b> kecelakaan: <br><br><img src="https://habrastorage.org/webt/l5/ef/az/l5efazbhjmzsuxdv6puz1tlvbzs.png"><br><br>  Jadi - <b>setelah</b> kecelakaan: <br><br><img src="https://habrastorage.org/webt/wx/mh/q7/wxmhq71060dhvxsxk-dh8m--pas.png"><br><br>  Dalam pemantauan, juga, ada lompatan tajam di mana node tidak lagi dapat diakses: <br><br><img src="https://habrastorage.org/webt/tp/fm/wf/tpfmwftsui_eoz91ojyy5rzektc.png"><br><br>  Jadi, tangkapan layar menunjukkan bahwa: <br><br><ol><li>  RAM pada mesin mendekati akhir; </li><li>  Lonjakan tajam dalam konsumsi RAM diamati, setelah itu akses ke seluruh mesin dinonaktifkan secara tajam; </li><li>  Sebuah tugas besar tiba di Mongo, yang memaksa proses DBMS menggunakan lebih banyak memori dan secara aktif membaca dari disk. </li></ol><br>  Ternyata jika Linux kehabisan memori bebas (tekanan memori terjadi) dan tidak ada swap, maka <b>sebelum</b> pembunuh OOM tiba, keseimbangan dapat terjadi antara membuang halaman di cache halaman dan menulisnya kembali ke disk.  Ini dilakukan oleh kswapd, yang dengan berani membebaskan sebanyak mungkin halaman memori untuk distribusi nanti. <br><br>  Sayangnya, dengan beban I / O yang besar, ditambah dengan sejumlah kecil memori bebas, <b>kswapd menjadi penghambat seluruh sistem</b> , karena <b>semua</b> kesalahan halaman dari halaman memori dalam sistem terkait dengannya.  Ini dapat berlangsung untuk waktu yang sangat lama jika proses tidak ingin menggunakan memori lagi, tetapi tetap di tepi jurang pembunuh OOM. <br><br>  Pertanyaan logisnya adalah: mengapa pembunuh OOM datang sangat terlambat?  Dalam iterasi OOM saat ini, killer sangat bodoh: itu akan membunuh proses hanya ketika upaya untuk mengalokasikan halaman memori gagal, mis.  jika kesalahan halaman gagal.  Ini tidak terjadi untuk waktu yang lama, karena kswapd dengan berani membebaskan halaman memori dengan membilas cache halaman (semua disk I / O dalam sistem, pada kenyataannya) kembali ke disk.  Secara lebih rinci, dengan deskripsi langkah-langkah yang diperlukan untuk menghilangkan masalah seperti itu di kernel, Anda dapat membaca di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . <br><br>  Perilaku ini <a href="">harus ditingkatkan</a> dengan kernel Linux 4.6+. <br><br><h2>  Story 6. Pods Pending </h2><br>  Dalam beberapa kelompok, di mana terdapat banyak polong, kami mulai memperhatikan bahwa kebanyakan dari mereka tergantung dalam status <code>Pending</code> untuk waktu yang sangat lama, meskipun wadah Docker sendiri sudah berjalan di node dan Anda dapat secara manual bekerja dengannya. <br><br>  Tidak ada yang salah dengan <code>describe</code> : <br><br><pre> <code class="plaintext hljs"> Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 1m default-scheduler Successfully assigned sphinx-0 to ss-dev-kub07 Normal SuccessfulAttachVolume 1m attachdetach-controller AttachVolume.Attach succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "sphinx-config" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "default-token-fzcsf" Normal SuccessfulMountVolume 49s (x2 over 51s) kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx-exporter/sphinx-indexer:v1" already present on machine Normal Created 43s kubelet, ss-dev-kub07 Created container Normal Started 43s kubelet, ss-dev-kub07 Started container Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx/sphinx:v1" already present on machine Normal Created 42s kubelet, ss-dev-kub07 Created container Normal Started 42s kubelet, ss-dev-kub07 Started container</code> </pre> <br>  Setelah menggali sekitar, kami membuat asumsi bahwa kubelet tidak punya waktu untuk mengirim server API semua informasi tentang keadaan pod, sampel liness / readiness. <br><br>  Dan setelah mempelajari bantuan, kami menemukan parameter berikut: <br><br><pre> <code class="plaintext hljs">--kube-api-qps - QPS to use while talking with kubernetes apiserver (default 5) --kube-api-burst - Burst to use while talking with kubernetes apiserver (default 10) --event-qps - If &gt; 0, limit event creations per second to this value. If 0, unlimited. (default 5) --event-burst - Maximum size of a bursty event records, temporarily allows event records to burst to this number, while still not exceeding event-qps. Only used if --event-qps &gt; 0 (default 10) --registry-qps - If &gt; 0, limit registry pull QPS to this value. --registry-burst - Maximum size of bursty pulls, temporarily allows pulls to burst to this number, while still not exceeding registry-qps. Only used if --registry-qps &gt; 0 (default 10)</code> </pre> <br>  Seperti yang Anda lihat, nilai <b>standarnya cukup kecil</b> , dan dalam 90% mereka memenuhi semua kebutuhan ... Namun, dalam kasus kami ini tidak cukup.  Oleh karena itu, kami menetapkan nilai-nilai ini: <br><br><pre> <code class="plaintext hljs">--event-qps=30 --event-burst=40 --kube-api-burst=40 --kube-api-qps=30 --registry-qps=30 --registry-burst=40</code> </pre> <br><br>  ... dan me-restart kubelet, setelah itu mereka melihat gambar berikut pada grafik mengakses server API: <br><br><img src="https://habrastorage.org/webt/nq/-i/oq/nq-ioqoyt6_qudmacm5dwfe8hnk.png"><br><br>  ... dan ya, semuanya mulai terbang! <br><br><h2>  PS </h2><br>  Untuk bantuan dalam mengumpulkan bug dan menyiapkan artikel, saya mengucapkan terima kasih yang mendalam kepada banyak insinyur perusahaan kami, dan khususnya kepada Andrei Klimentyev (kolega dari tim R&amp;D kami) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">zuzzas</a> ). <br><br><h2>  PPS </h2><br>  Baca juga di blog kami: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubectl-debug plugin untuk debugging di pod Kubernetes</a> ‚Äù; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Monitoring dan Kubernetes (review dan laporan video)</a> "; </li><li>  Siklus kiat &amp; trik Kubernetes: <ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Transfer sumber daya yang bekerja di sebuah cluster ke manajemen Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tentang alokasi node dan beban pada aplikasi web</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Akses ke situs dev</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mempercepat bootstrap dari database besar.</a> " </li></ul></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id443458/">https://habr.com/ru/post/id443458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id443438/index.html">7 ekstensi Firefox yang berguna untuk belajar bahasa Inggris</a></li>
<li><a href="../id443440/index.html">Modul PHP untuk bekerja dengan data hierarkis di InterSystems IRIS</a></li>
<li><a href="../id443450/index.html">Mengapa orang miskin tidak bisa sehat</a></li>
<li><a href="../id443452/index.html">Militer Rusia akan membuat Internet tertutup mereka sendiri</a></li>
<li><a href="../id443456/index.html">Kami mengundang Anda ke Yandex NLP selama seminggu</a></li>
<li><a href="../id443460/index.html">11 jawaban tentang Yandex.Directory</a></li>
<li><a href="../id443462/index.html">Kamera peretasan: vektor serangan, alat pencarian kerentanan dan anti-pelacakan</a></li>
<li><a href="../id443464/index.html">Panduan Lengkap untuk Mengganti Ekspresi di Jawa 12</a></li>
<li><a href="../id443466/index.html">Raja pembangunan</a></li>
<li><a href="../id443468/index.html">Alat pemantauan jaringan apa yang telah menjadi pemimpin dalam versi Gartner</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
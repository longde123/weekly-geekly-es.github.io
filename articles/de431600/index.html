<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍🔬 🤜 💣 Erhöhen Sie IDS / NMS: Mikrotik und Suricata mit einem Webinterface 🈹 👨🏿‍🏫 🏂🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anscheinend habe ich ein solches Karma: Egal, wie ich die Implementierung eines Dienstes auf Open Source durchführe, ich werde auf jeden Fall eine Rei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erhöhen Sie IDS / NMS: Mikrotik und Suricata mit einem Webinterface</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431600/">  Anscheinend habe ich ein solches Karma: Egal, wie ich die Implementierung eines Dienstes auf Open Source durchführe, ich werde auf jeden Fall eine Reihe von Handbüchern finden, von denen jedes für sich in meinem speziellen Fall nicht funktioniert, die vorgefertigte Lösung nicht startet oder gefällt, was sonst noch passiert -Niemals Verdaulichkeit, und am Ende muss man selbst zum Ergebnis durchbrechen. <br><br>  Dieses Mal waren alle Handbücher auf ELK5 oder älter, aber ich wollte die Software der vorherigen Versionen nicht wirklich installieren.  Ich wollte die Software mit den vielversprechendsten Support-Perioden nehmen: vorzugsweise die neueste aus dem Stall. <br><br>  Um die perfekte Leistung wiederholen zu können, ohne in Zukunft alle Qualen zu wiederholen, müssen Sie daher Schritt-für-Schritt-Spickzettel schreiben, die ich mit Ihnen teile. <br><br>  Also heute Mikrotik (RouterOS), Suricata 4.1, Elasticsearch + Filebeat + Kibana 6.5. <br><a name="habracut"></a><br><h3>  Anstatt mitzumachen </h3><br>  Bedingungen: <br><br><ul><li>  Mikrotik auf i386 in einer virtuellen Maschine auf Host A. Alle Schnittstellen auf Mikrotik sind über VLANs verteilt, der Host verfügt über eine physische Netzwerkschnittstelle. </li><li>  Kostenlose Ressourcen für IDS / IPS / NMS auf Host B mit einer einzigen physischen Netzwerkschnittstelle. </li><li>  20-Megabyte-Kanal aus. </li><li>  Der Wunsch, Analysen über den Datenverkehr zu erhalten, der über die externe Schnittstelle des Mikrotik geleitet wird. </li><li>  Das Budget in den Meerrettich Rubel und FIG Kopeken. </li><li>  Eine gewisse Menge an Freizeit von Ärger. </li></ul><br>  Ich werde hier nicht darüber sprechen, was IDS / IPS / NMS ist, warum es benötigt wird und was es passiert.  Jeder weiß das ohne mich, und wer es nicht weiß, wird googeln. <br><br>  Ich werde auch meine Wahl zwischen Snort und Suricata nicht für letztere rechtfertigen.  Das ist Geschmackssache. <br><br>  Aber erklären Sie oberflächlich, wie es funktioniert: <br><br>  Suricata erhält irgendwie Verkehr.  Es gibt drei Möglichkeiten: a) Weiterleiten im Inline-Modus, b) Empfangen einer Kopie des Datenverkehrs vom Switch-Port und c) Analysieren von Speicherauszügen mit Datenverkehr.  Suricata analysiert den empfangenen Verkehr und liefert basierend auf der Analyse Daten darüber, was dort in diesem Verkehr gefunden wurde. <br><br>  Suricata kann Daten in JSON ausgeben.  Dementsprechend können strukturierte Daten einem System zur Verarbeitung, Systematisierung, Analyse und Visualisierung zugeführt werden. <br>  Für die Analyse und Visualisierung von Daten ist der ELK-Stack meines Wissens perfekt, ohne auf diesem Gebiet spezialisiert zu sein.  Der ELK-Stack bestand ursprünglich aus Elasticsearch, Logstash, Kibana.  Jetzt wurde Beat hinzugefügt (eine Familie von Schnittstellenprogrammen, die als Vermittler zwischen der Datenquelle und Logstash oder Elasticsearch fungieren).  Mit Blick auf die Zukunft werde ich sagen, dass es keinen Logstash gab, da Beat Daten perfekt direkt an Elasticsearch weiterleitet und Elasticsearch sie perfekt isst.  Elasticsearch überträgt die gebissenen Daten an Kibana, das Webinterface für den gesamten ELK-Stack.  Kibana verwendet die von Filebeat an ihn übergebenen Vorlagen und bietet dem Benutzer eine Datenvisualisierung, die sogenannten Dashboards.  In Anbetracht der Tatsache, dass Elasticsearch, Logstash, Beat und Kibana die Früchte der Arbeit eines Herstellers sind, ist diese gesamte Farm gut miteinander verbunden und der Verknüpfungsprozess ist gut dokumentiert (natürlich nach Open-Source-Standards). <br><br>  Auf der Grundlage des Vorstehenden kann die Aufgabe daher wie folgt beschrieben werden: Eine Kopie des Datenverkehrs vom Router-Port abrufen, an Suricata übertragen, Daten im JSON-Format von Suricata empfangen, an Filebeat übertragen, so dass sie wiederum an Elasticsearch und übertragen werden half Kibana bei der Erstellung ihrer visuellen Darstellung. <br><br><h3>  Mikrotik RouterOS </h3><br>  Wenn ich eine Mikrotik-Router-Hardware hätte, wäre das Problem der Portspiegelung (Portspiegelung) überhaupt nicht.  Alles würde entschieden, indem die Spiegelung des Datenverkehrs über die externe Schnittstelle zu einem beliebigen freien Port von Mikrotik selbst ermöglicht wird.  Wenn auf Mikrotik kein freier Port vorhanden ist, können Sie die Portspiegelung auf dem Switch aktivieren.  In meinem Fall hatte Mikrotik jedoch überhaupt keine physischen Ports, und der Port auf dem Switch empfing Datenverkehr vom gesamten Host, auf dem sich neben Mikrotik mehrere weitere virtuelle Maschinen befanden. <br><br>  Und dann sagte ich noch einmal mental: „Danke, Mikrotik!“.  Vielen Dank für den in RouterOS integrierten Sniffer.  Traditionell verzichten wir auf Screenshots, nur auf Konsolenbefehle. <br><br>  Öffnen Sie das Terminal in WinBox und schalten Sie den Sniffer ein: <br><br> <code>/tool sniffer set filter-interface=if-out filter-stream=yes streaming-enabled=yes streaming-server=192.168.1.253 <br> /tool sniffer start</code> <br> <br>  Geben Sie anstelle von <i>if-out den</i> Namen der Schnittstelle an, von der aus Sie den Datenverkehr abfangen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">möchten</a> , und anstelle von <i>192.168.1.253</i> die IP-Adresse des Computers, an den abgefangener Datenverkehr über das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TZSP-</a> Protokoll <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gesendet wird</a> . <br><br>  Mit Mikrotik'om allen. <br><br><h3>  Suricata </h3><br>  Im Allgemeinen bin ich nicht sehr Linux-orientiert, daher mag ich vor allem Pop-Distributionen.  Na ja, vielleicht mag ich den asketischeren Debian.  Also habe ich damit angefangen.  Nun, und natürlich wollte ich aufgrund von Nicht-Linux-Headness auch Binärdateien aus dem Repository installieren.  Die Montage ist für mich immer faul.  Also, wenn es möglich sein wird, Debian zu wählen, - <u>wählen Sie nicht</u> .  Ich kann mich jetzt nicht erinnern, an welchem ​​Ort ich die ganze Farm unter Debian installiert habe, aber er war es.  Und die ganze nachfolgende Geschichte über die Installation von allem unter Ubunta. <br><br>  Eine virtuelle 4-Kern-Maschine mit 4 GB RAM wurde erstellt, <a href="">Ubuntu Server 18.04.1 LTS (x64) wurde</a> heruntergeladen und darauf installiert <br><br><blockquote>  <b>Vereinbarung</b> : Alle weiteren Aktionen werden im Auftrag des Superusers ausgeführt. Melden Sie sich also entweder als root an oder fügen Sie jedem Befehl <i>sudo hinzu</i> . </blockquote><br>  Da ich in jeder Phase Schnappschüsse gemacht und dann wiederholt darauf zurückgegriffen habe, habe ich am Ende viele Störungen mit einer nicht synchronen Zeit in einer virtuellen Maschine in Echtzeit festgestellt. <br>  Daher stellen wir sofort die richtige Zeitzone und NTP-Synchronisation ein: <br><br> <code>systemctl start systemd-timesyncd <br> systemctl status systemd-timesyncd <br> dpkg-reconfigure tzdata</code> <br> <br>  <i><b>Fügen</b></i> Sie die <i>Universums-</i> Repositorys zu <i><b>/etc/apt/sources.list</b></i> hinzu, um sicherzustellen, dass bei der Installation von Suricata keine Abhängigkeitsprobleme <i><b>auftreten</b></i> : <br><br> <code>nano /etc/apt/sources.list</code> <br> <blockquote>  ... <br>  deb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">archive.ubuntu.com/ubuntu</a> bionisches Hauptuniversum <br>  deb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">archive.ubuntu.com/ubuntu</a> bionic-security Hauptuniversum <br>  deb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">archive.ubuntu.com/ubuntu</a> bionic-updates Hauptuniversum </blockquote><br>  Wir fügen auch das Repository hinzu, in dem wir Suricata erhalten: <br> <code>add-apt-repository ppa:oisf/suricata-stable</code> <br> <br>  Aktualisieren der Paketdatenbank: <br> <code>apt-get update</code> <br> <br>  Suricata installieren: <br> <code>apt-get install -y suricata</code> <br> <br>  Der nächste Schritt besteht darin, die Regeln für Suricata und deren Aktualisierung festzulegen: <br> <code>apt-get install -y python-pip <br> pip install pyyaml <br> pip install https://github.com/OISF/suricata-update/archive/master.zip</code> <br> <br>  Wir starten das Update von <i>suricata-update selbst</i> : <br> <code>pip install --pre --upgrade suricata-update</code> <br> <br>  Wenn wir ohne zusätzliche Konfiguration ausgeführt werden, erhalten wir den Regelsatz "Emerging Threats Open": <br> <code>suricata-update</code> <br> <br>  Gehen Sie wie folgt vor, um die Liste der Quellen anzuzeigen: <br> <code>suricata-update list-sources</code> <br> <br>  Aktualisieren von Regelquellen: <br> <code>suricata-update update-sources</code> <br> <br>  Mal sehen, was dort in den Quellen aktualisiert wurde, wieder ausführen: <br> <code>suricata-update list-sources</code> <br> <br>  Wir enthalten alle kostenlosen Quellen: <br> <code>suricata-update enable-source ptresearch/attackdetection <br> suricata-update enable-source oisf/trafficid <br> suricata-update enable-source sslbl/ssl-fp-blacklist</code> <br> <br>  Und wieder aktualisieren wir die Regeln: <br> <code>suricata-update</code> <br> <br>  Suricata ist installiert. <br><br>  Jetzt müssen Sie Verkehr bekommen. <br><br><h3>  Trafr </h3><br>  Trafr ist eine von Mikrotik geschriebene Anwendung zur Konvertierung von TZSP-Verkehr in pcap.  Die Anwendung ist 32-Bit. Um sie zu starten, müssen Sie die Unterstützung für 32-Bit-Anwendungen in 64-Bit-Ubunta aktivieren: <br><br> <code>dpkg --add-architecture i386 <br> apt-get update &amp;&amp; apt-get install -y libc6:i386</code> <br> <br>  <i><b>Trafr</b></i> herunterladen und entpacken: <br><br> <code>wget http://www.mikrotik.com/download/trafr.tgz <br> tar xzf trafr.tgz</code> <br> <br>  Überprüfen Sie, ob der Verkehr abgefangen wird: <br><br> <code>./trafr -s</code> <br> <br>  Nach einem solchen Start brach die symbolische Ausgabe im Grafikmodus in der Konsole der virtuellen Maschine, ich musste neu starten.  Es gab keine Probleme bei der Remoteverbindung über ssh mit PuTTY. <br><br>  Wenn Sie ein unregelmäßiges Flackern auf dem Bildschirm sehen, kommt der Verkehr an und <i><b>trafr</b></i> fängt ihn auf.  Wenn ja, übertragen Sie <i><b>trafr</b></i> in einen ständigen Wohnsitz und leiten Sie ihn mit der Übertragung des gefangenen Verkehrs durch die Pipeline sofort nach Suricata: <br><br> <code>mv trafr /usr/local/bin/ <br> /usr/local/bin/trafr -s | suricata -c /etc/suricata/suricata.yaml -r /dev/stdin <br></code> <br><br>  Jetzt überprüfen wir, ob der Verkehr in Suricata ankommt. Dazu machen wir im benachbarten Terminal Folgendes: <br><br> <code>tail -f /var/log/suricata/fast.log</code> <br> <br>  Sie sollten eine intelligente Schriftrolle eines aussagekräftigen Textes sehen - ein Protokoll über den Empfang von Erdmännchenverkehr. <br><br>  Es wird auch nicht schaden, sicherzustellen, dass der Suricata-Verkehr nicht nur empfängt, sondern auch analysiert: <br><br> <code>tail -f /var/log/suricata/eve.json</code> <br> <br>  Dies ist genau die Ausgabe von Ereignissen aus Suricata im JSON-Format, die wir an Filebeat weiterleiten. <br><br><h3>  Elasticsearch + Filebeat + Kibana 6.5 </h3><br>  Wir installieren den PGP-Schlüssel, der zur Verwendung des Elastic-Repositorys erforderlich ist, und installieren die erforderlichen Abhängigkeiten: <br><br> <code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - <br> echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list <br> apt-get update &amp;&amp; apt-get install -y openjdk-8-jre apt-transport-https wget nginx</code> <br> <br>  Bitte beachten Sie, dass Java Version 8 ist. Alles über 8 wird nicht unterstützt.  Wenn Sie es früher geschafft haben, ein neueres Java zu installieren, brechen Sie es ab und setzen Sie 8. <br><br>  Wir stellen sicher, dass Java so installiert ist, wie es sollte: <br><br> <code>java -version</code> <br> <br>  Wir erhalten ungefähr die folgende Schlussfolgerung: <br><blockquote>  Java-Version "1.8.0_191" <br>  Java (TM) SE-Laufzeitumgebung (Build 1.8.0_191-b12) <br>  Java HotSpot (TM) 64-Bit-Server-VM (Build 25.191-b12, gemischter Modus) </blockquote><br>  Erstellen Sie einen Benutzer und ein Passwort, um auf Kibana zuzugreifen.  Wählen Sie anstelle von <i>admin</i> etwas, das Sie bevorzugen: <br><br> <code>echo "admin:`openssl passwd -apr1`" | sudo tee -a /etc/nginx/htpasswd.users</code> <br> <br>  Da sich der ELK auf localhost dreht, konfigurieren Sie den Reverse-Proxy in nginx: <br><br> <code>nano /etc/nginx/sites-available/kibana</code> <br> <blockquote>  Server { <br>  höre 80; <br><br>  Servername suricata.server; <br><br>  auth_basic "Eingeschränkter Zugriff"; <br>  auth_basic_user_file /etc/nginx/htpasswd.users; <br><br>  Ort / { <br>  proxy_pass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">localhost</a> : 5601; <br>  proxy_http_version 1.1; <br>  proxy_set_header Upgrade $ http_upgrade; <br>  proxy_set_header Verbindung 'Upgrade'; <br>  proxy_set_header Host $ host; <br>  proxy_cache_bypass $ http_upgrade; <br>  }} <br>  }} </blockquote><br> <code>rm /etc/nginx/sites-enabled/default <br> ln -s /etc/nginx/sites-available/kibana /etc/nginx/sites-enabled/kibana <br></code> <br><br>  Starten Sie nginx neu: <br><br> <code>systemctl restart nginx</code> <br> <br>  Wir setzen Elasticsearch: <br><br> <code>apt-get install -y elasticsearch</code> <br> <br>  Aktivieren Sie beim Laden des Betriebssystems die automatische Ausführung: <br><br> <code>systemctl daemon-reload <br> systemctl enable elasticsearch.service</code> <br> <br>  Wir starten: <br><br> <code>systemctl start elasticsearch.service</code> <br> <br>  Überprüfen Sie, ob es gestiegen ist: <br><br> <code>curl -X GET "localhost:9200/"</code> <br> <br>  Abhängig von der Leistung Ihrer Hardware kann das Starten von ES einige Zeit dauern.  Wenn die <i>Verbindung abgelehnt wird</i> , wiederholen Sie einfach die Anfrage und warten Sie, bis wir Folgendes erhalten: <br><blockquote>  { <br>  "Name": "lcZuxxm", <br>  "Clustername": "elasticsearch", <br>  "Cluster_uuid": "kmJHqJnlQe2Rk7F-CRi4EA", <br>  "Version": { <br>  "Nummer": "6.5.1", <br>  "Build_flavor": "default", <br>  "Build_type": "deb", <br>  "Build_hash": "8c58350", <br>  "Build_date": "2018-11-16T02: 22: 42.182257Z", <br>  "Build_snapshot": false, <br>  "Lucene_version": "7.5.0", <br>  "Minimum_wire_compatibility_version": "5.6.0", <br>  "Minimum_index_compatibility_version": "5.0.0" <br>  }, <br>  Slogan: Sie wissen, für die Suche <br>  }} </blockquote><br>  Wir setzen Kibana: <br><br> <code>apt-get install -y kibana</code> <br> <br>  Aktivieren Sie beim Laden des Betriebssystems die automatische Ausführung: <br><br> <code>systemctl daemon-reload <br> systemctl enable kibana.service</code> <br> <br>  Wir starten: <br><br> <code>systemctl start kibana.service</code> <br> <br>  Jetzt können Sie zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">192.168.1.253</a> gehen (natürlich ist die IP-Adresse diejenige, die Ihrem Computer mit einem Erdmännchen zugewiesen wurde).  Das Kibana-Deckblatt sollte geöffnet werden. <br><br>  Wir setzen Filebeat: <br><br> <code>apt-get install -y filebeat</code> <br> <br>  Aktivieren Sie beim Laden des Betriebssystems die automatische Ausführung: <br><br> <code>systemctl daemon-reload <br> systemctl enable filebeat</code> <br> <br>  Wir aktivieren das Suricata-Modul, das Teil des Filebeat-Modulsatzes ist: <br><br> <code>filebeat modules enable suricata</code> <br> <br>  Installieren Sie Plugins für Suricata in Elasticsearch: <br><br> <code><s>/usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip <br> /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-user-agent</s></code> <br>  <b>Siehe UPD 22. Mai 2019.</b> <br><br>  Elasticsearch neu starten: <br><br> <code>systemctl restart elasticsearch.service</code> <br> <br>  Wir führen die Erstkonfiguration von Filebeat durch und laden gleichzeitig Vorlagen in Kibana: <br><br> <code>filebeat setup -e</code> <br> <br>  Wir überprüfen, ob <i>Filebeat</i> /var/log/suricata/eve.json gefunden <i>hat</i> und verarbeitet. Führen Sie dazu Filebeat im Datenausgabemodus mit der <i>Veröffentlichungsmarkierung aus</i> : <br><br> <code>filebeat -e -d "publish"</code> <br> <br>  Die json-formatierte Ausgabe von Filebeat selbst wird zuerst ausgeführt, dann eine einfache Textausgabe der Protokolle und erst nach einer Weile die Ausgabe von Suricata. Warten Sie also und stellen Sie sicher, dass alles funktioniert.  Brechen Sie danach Filebeat ab und kehren Sie zu bash zurück. <br><br>  Aktivieren Sie beim Laden des Betriebssystems die automatische Ausführung: <br><br> <code>systemctl daemon-reload <br> systemctl enable filebeat.service</code> <br> <br>  Führen Sie Filebeat aus: <br><br> <code>systemctl start filebeat.service</code> <br> <br>  Gehen Sie zu Kibana, wählen Sie Dashboard aus dem Menü links und wählen Sie <i><b>filebeat- *</b></i> index.  Wählen Sie erneut Dashboard aus, wählen Sie <b>[Suricata] Alert Overview</b> aus der Liste aus und erhalten Sie Folgendes: <br><br><img src="https://habrastorage.org/webt/tb/5v/st/tb5vsthdvuyveyetcbba1p_asts.png" alt="Bild"><br><br><h3>  Optional </h3><br>  Vergessen Sie nicht, sich zu drehen, und egal wie groß die Festplatte ist, Suricata wird sie sehr schnell bewerten: <br><br> <code>nano /etc/logrotate.d/suricata</code> <br> <blockquote>  /var/log/suricata/*.log /var/log/suricata/*.json <br>  { <br>  wöchentlich <br>  drehen 3 <br>  Missingok <br>  Nocompress <br>  erstellen <br>  Sharedscripts <br>  postrotate <br>  / bin / kill -HUP `cat /var/run/suricata.pid 2&gt; / dev / null` 2&gt; / dev / null ||  wahr <br>  Endschrift <br>  }} <br></blockquote><br>  Darüber hinaus gab es Gerüchte, dass jemand, der regelmäßig in Mikrotik schnüffelt und den Status " <i>Laufen" hat</i> , den Verkehr einstellt.  Dann schreiben wir ein Skript, um den Sniffer neu zu starten und gemäß dem Zeitplan auszuführen: <br><br> <code>/tool sniffer stop <br> :delay 30s <br> /tool sniffer start</code> <br> <br><h3>  Fazit </h3><br>  Ehrlich gesagt bin ich mit der Stabilität des obigen Bündels nicht ganz zufrieden.  Nämlich: Es lohnt sich neu zu starten und Wunder beginnen.  Einmal hörte alles außer ein paar auf, meine Regeln zu verarbeiten.  Ich musste alles neu installieren.  Beim zweiten Mal hat Elasticsearch im Allgemeinen den Empfang von Daten von Filebeat eingestellt und musste vor dem Neustart auf den Status-Snapshot zurückgesetzt werden. <br><br>  Ich habe diese Probleme noch nicht gelöst. <br><br>  Darüber hinaus ist geplant, IPS basierend auf den IP-Adressen der von Suricata identifizierten Bösewichte zu implementieren, die an Mikrotik übertragen wurden. <br><br>  <b>UPD</b> : Instabilitätsvorwürfe werden fallen gelassen.  Meine Schlussfolgerung zur Beendigung der Regelverarbeitung war falsch.  Tatsächlich ist der Grund für die Leere im Dashboard nach dem Neustart die Tatsache, dass Filebeat und Elasticsearch eine sehr bemerkenswerte Zeit benötigen, um die Multi-Gigabyte-JSON-Datei aus dem Erdmännchen zu analysieren.  Wenn Sie das Dashboard mit Ereignissen für einen Zeitraum öffnen, der das <i>Erstellungsdatum der</i> Datei <i>eve.json</i> enthält, können Sie sehen, wie die Spalten des Diagramms während der Verarbeitung der Datei wachsen.  Zusammen mit den verarbeiteten Ereignissen werden Warnungen im entsprechenden Dashboard angezeigt.  Außerdem hat der Sniffer in RouterOS auf x86 nie gehangen. <br><br>  <b>UPD 22. Mai 2019</b> : Ab Version Elasticsearch 6.7 wurden die Plugins ingest-geoip und ingest-user-agent in Module konvertiert.  Dementsprechend wird der Artikel mit ihrer Installation übersprungen. <br><br>  Außerdem wird beim Upgrade ein Elasticsearch-Startfehler angezeigt.  In den Protokollen wird ein Fehler angezeigt: <br><br><blockquote>  erwartete Datenbank [GeoLite2-ASN.mmdb] existiert nicht in [/ etc / elasticsearch / ingest-geoip] </blockquote><br>  Um die Leistung wiederherzustellen, führen wir Folgendes aus: <br><br> <code>/usr/share/elasticsearch/bin/elasticsearch-plugin remove --purge ingest-geoip <br></code> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431600/">https://habr.com/ru/post/de431600/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431586/index.html">So gehen Sie schneller mit Fehlern in der JVM um</a></li>
<li><a href="../de431588/index.html">Selbstständiges Gesetz. Informationen zur Prüfung</a></li>
<li><a href="../de431590/index.html">Die Modernisierung veralteter britischer Windparks wird die Energieerzeugung um 171% steigern</a></li>
<li><a href="../de431596/index.html">Testen der Veeam-Sicherungs- und Replikationslast</a></li>
<li><a href="../de431598/index.html">Wir bringen eine öffentliche virtuelle QEMU-Maschine ohne Netzwerkkarte ins Internet und versuchen, sie abzubauen</a></li>
<li><a href="../de431602/index.html">Russische Entwickler präsentierten in London ein virtuelles Rehabilitationssystem</a></li>
<li><a href="../de431604/index.html">Lokalisierung in Go mit Basispaketen</a></li>
<li><a href="../de431608/index.html">Das US-Unternehmen DriveSavers ist das weltweit erste Unternehmen, das einen iPhone-Hacking-Service für Einzelpersonen anbietet</a></li>
<li><a href="../de431610/index.html">Projektmanager Lifehacks</a></li>
<li><a href="../de431612/index.html">Spieluhr und Drehgeber auf FPGA-Karte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé≥ üà∑Ô∏è üë®‚Äçüé® Reinigen, markieren: Wie wir Chatbot beigebracht haben, um Kundenprobleme zu unterscheiden üò£ üçÖ üôåüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anton Chaynikov, Entwickler von Data Science, Redmadrobot 
 Hallo Habr! Heute werde ich √ºber die Schwierigkeiten auf dem Weg zum Chatbot sprechen, die...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reinigen, markieren: Wie wir Chatbot beigebracht haben, um Kundenprobleme zu unterscheiden</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/436072/"><p><img src="https://habrastorage.org/webt/k4/rl/pc/k4rlpcs5lwl2dsvt97pez6qhfgw.png"></p><br><p><img src="https://habrastorage.org/webt/mp/4c/kh/mp4ckhvyt2k9kydafhv3vxa0its.png" align="left">  <strong>Anton Chaynikov, Entwickler von Data Science, Redmadrobot</strong> <br>  <em>Hallo Habr!</em>  <em>Heute werde ich √ºber die Schwierigkeiten auf dem Weg zum Chatbot sprechen, die die Arbeit der Chat-Betreiber der Versicherungsgesellschaft erleichtern.</em>  <em>Genauer gesagt, wie wir dem Bot beigebracht haben, Anforderungen durch maschinelles Lernen voneinander zu unterscheiden.</em>  <em>Mit welchen Modellen wurde experimentiert und mit welchen wurden die Ergebnisse erzielt?</em>  <em>Wie haben vier Ans√§tze zur Bereinigung und Anreicherung von Daten von anst√§ndiger Qualit√§t und f√ºnf Versuche zur Bereinigung von Daten von Qualit√§t "unanst√§ndig".</em> <a name="habracut"></a></p><br><h3 id="zadacha">  Herausforderung </h3><br><p>  Der Chat der Versicherungsgesellschaft erh√§lt t√§glich +100500 Kundenanrufe.  Die meisten Fragen sind einfach und wiederholen sich, aber die Bediener sind nicht einfacher, und die Kunden m√ºssen noch f√ºnf bis zehn Minuten warten.  Wie kann die Servicequalit√§t verbessert und die Arbeitskosten optimiert werden, damit die Bediener weniger Routine haben und die Benutzer ein angenehmeres Gef√ºhl haben, wenn sie ihre Probleme schnell l√∂sen? </p><br><p>  Und wir machen einen Chatbot.  Lassen Sie ihn Benutzernachrichten lesen, Anweisungen f√ºr einfache F√§lle geben und Standardfragen f√ºr komplexe F√§lle stellen, um die Informationen zu erhalten, die der Bediener ben√∂tigt.  Ein Live-Operator verf√ºgt √ºber einen Skriptbaum - ein Skript (oder Flussdiagramm), das angibt, welche Fragen Benutzer m√∂glicherweise stellen und wie sie darauf antworten sollen.  Wir w√ºrden dieses Schema in einen Chatbot einf√ºgen, aber es ist schlecht - der Chatbot versteht es nicht menschlich und wei√ü nicht, wie er die Frage des Benutzers mit dem Skriptzweig in Beziehung setzen soll. </p><br><p>  Also werden wir ihn mit Hilfe des guten alten maschinellen Lernens unterrichten.  Sie k√∂nnen jedoch nicht nur ein von Benutzern generiertes Datenelement verwenden, um ihm ein anst√§ndiges Qualit√§tsmodell beizubringen.  Dazu m√ºssen Sie mit der Architektur des Modells und den Daten experimentieren, um sie zu bereinigen und manchmal erneut zu sammeln. </p><br><p>  <strong>Wie man einen Bot unterrichtet:</strong> </p><br><ul><li>  Ber√ºcksichtigen Sie die Modelloptionen: Wie werden die Gr√∂√üe des Datensatzes, die Details der Vektorisierung der Texte, die Verringerung der Dimension, der Klassifikator und die endg√ºltige Genauigkeit kombiniert? </li><li>  Lassen Sie uns anst√§ndige Daten bereinigen: Wir werden Klassen finden, die sicher weggeworfen werden k√∂nnen;  Wir werden herausfinden, warum die letzten sechs Monate des Aufschlags besser sind als die vorherigen drei.  bestimmen, wo das Modell liegt und wo das Markup;  Finden Sie heraus, wie Tippfehler n√ºtzlich sein k√∂nnen. </li><li>  Wir werden die "unanst√§ndigen" Daten bereinigen: Wir werden herausfinden, in welchen F√§llen Clustering n√ºtzlich und nutzlos ist, da Benutzer und Bediener sprechen, wenn es Zeit ist, das Leiden zu beenden und Markups zu sammeln. </li></ul><br><h3 id="faktura">  Textur </h3><br><p>  Wir hatten zwei Kunden - Versicherungsunternehmen mit Online-Chats - und Chatbot-Schulungsprojekte (wir werden sie nicht nennen, das ist nicht wichtig) mit stark unterschiedlicher Datenqualit√§t.  Nun, wenn die H√§lfte der Probleme des zweiten Projekts durch Manipulationen des ersten gel√∂st werden k√∂nnte.  Details sind unten. </p><br><p>  Aus technischer Sicht besteht unsere Aufgabe darin, Texte zu klassifizieren.  Dies erfolgt in zwei Schritten: Zuerst werden die Texte vektorisiert (unter Verwendung von tf-idf, doc2vec usw.), dann wird das Klassifizierungsmodell anhand der erhaltenen Vektoren (und Klassen) trainiert - Zufallswald, SVM, neuronales Netzwerk usw.  und so weiter. </p><br><p>  Woher kommen die Daten: </p><br><ul><li>  SQL-Upload-Chat-Verlauf.  Relevante Upload-Felder: Nachrichtentext;  Autor (Kunde oder Betreiber);  Gruppieren von Nachrichten in Dialoge;  Zeitstempel;  Kundenkontaktkategorie (Fragen zur obligatorischen Kfz-Haftpflichtversicherung, zur Rumpfversicherung, zur freiwilligen Krankenversicherung; Fragen zur Website; Fragen zu Treueprogrammen; Fragen zu sich √§ndernden Versicherungsbedingungen usw.). </li><li>  Ein Baum von Skripten oder Sequenzen von Fragen und Antworten von Betreibern an Kunden mit unterschiedlichen Anforderungen. </li></ul><br><p>  Ohne Validierung nat√ºrlich nirgendwo.  Alle Modelle wurden auf 70% der Daten trainiert und gem√§√ü den Ergebnissen auf den restlichen 30% bewertet. </p><br><p>  Qualit√§tsmetriken f√ºr die von uns verwendeten Modelle: </p><br><ul><li>  Im Training: Logloss f√ºr Differenzierbarkeit; </li><li>  Beim Schreiben von Berichten: Klassifizierungsgenauigkeit an einem Testmuster zur Vereinfachung und Klarheit (auch f√ºr den Kunden); </li><li>  Bei der Wahl der Richtung f√ºr weitere Aktionen: die Intuition eines Datenwissenschaftlers, der die Ergebnisse aufmerksam betrachtet. </li></ul><br><h3 id="eksperimenty-s-modelyami">  Modellexperimente </h3><br><p>  Es ist selten, wenn die Aufgabe sofort klar macht, welches Modell die besten Ergebnisse liefert.  Also hier: ohne Experimente nirgendwo. </p><br><p>  Wir werden Vektorisierungsoptionen ausprobieren: </p><br><ul><li>  tf-idf in einzelnen Worten; </li><li>  tf-idf auf Dreifachzeichen (im Folgenden: 3 Gramm); </li><li>  tf-idf auf 2-, 3-, 4-, 5-Gramm getrennt; </li><li>  tf-idf auf 2-, 3-, 4-, 5-Gramm zusammengenommen; </li><li>  Alle oben genannten + Reduzierung der W√∂rter im Quelltext auf ein W√∂rterbuchformular; </li><li>  Alle oben genannten + Verringerung der Dimension durch die abgeschnittene SVD-Methode; </li><li>  Mit der Anzahl der Messungen: 10, 30, 100, 300; </li><li>  doc2vec, geschult auf den Textk√∂rper der Aufgabe. </li></ul><br><p>  Die Klassifizierungsoptionen vor diesem Hintergrund sehen eher schlecht aus: SVM, XGBoost, LSTM, zuf√§llige W√§lder, naive Bayes, zuf√§llige W√§lder zus√§tzlich zu SVM- und XGB-Vorhersagen. </p><br><p>  Und obwohl wir die Reproduzierbarkeit der Ergebnisse an drei unabh√§ngig zusammengestellten Datens√§tzen und deren Fragmenten √ºberpr√ºft haben, k√∂nnen wir nur f√ºr die breite Anwendbarkeit b√ºrgen. </p><br><p>  <strong>Die Ergebnisse der Experimente:</strong> </p><br><ul><li>  In der Kette "Vorverarbeitung-Vektorisierung-Senkung der Dimensionsklassifizierung" ist der Effekt der Auswahl bei jedem Schritt nahezu unabh√§ngig von den anderen Schritten.  Was sehr praktisch ist, Sie k√∂nnen nicht mit jeder neuen Idee ein Dutzend Optionen durchgehen und bei jedem Schritt die bekannteste Option verwenden. </li><li>  tf-idf in Worten verliert auf 3 Gramm (Genauigkeit 0,72 vs 0,78).  2-, 4-, 5-Gramm verlieren gegen 3-Gramm (0,75‚Äì0,76 gegen√ºber 0,78).  {2; 5} -Gramme √ºbertreffen insgesamt 3-Gramm deutlich.  Angesichts des starken Anstiegs des erforderlichen Speichers haben wir beschlossen, das Training mit einer Genauigkeit von 0,4% zu vernachl√§ssigen. </li><li>  Im Vergleich zu tf-idf aller Sorten war doc2vec hilflos (Genauigkeit 0,4 und darunter).  Es w√ºrde sich lohnen, ihn nicht im Korps von der Aufgabe aus zu trainieren (~ 250.000 Texte), sondern in einem viel gr√∂√üeren (2,5‚Äì25 Millionen Texte), aber bisher haben Ihre H√§nde leider nicht erreicht. </li><li>  Abgeschnittene SVD hat nicht geholfen.  Die Genauigkeit nimmt mit zunehmender Messung monoton zu und erreicht ohne TSVD problemlos eine Genauigkeit. </li><li>  Unter den Klassifikatoren gewinnt XGBoost sp√ºrbar (+ 5‚Äì10%).  Die engsten Konkurrenten sind SVM und zuf√§llige W√§lder.  Naive Bayes ist nicht einmal ein Konkurrent zu zuf√§lligen W√§ldern. </li><li>  Der Erfolg von LSTM h√§ngt stark von der Gr√∂√üe des Datensatzes ab: Bei einer Stichprobe von 100.000 Objekten kann es mit XGB konkurrieren.  Auf einer Stichprobe von 6000 - in der Verz√∂gerung zusammen mit Bayes. </li><li>  Eine zuf√§llige Gesamtstruktur √ºber SVM und XGB stimmt entweder immer mit XGB √ºberein oder irrt sich mehr.  Das ist sehr traurig, wir hofften, dass SVM in den Daten zumindest einige Muster findet, die XGB nicht zur Verf√ºgung stehen, aber leider. </li><li>  XGBoost ist mit Stabilit√§t kompliziert.  Zum Beispiel reduzierte das Upgrade von Version 0.72 auf 0.80 unerkl√§rlicherweise die Genauigkeit trainierter Modelle um 5‚Äì10%.  Und noch etwas: XGBoost unterst√ºtzt das √Ñndern von Trainingsparametern w√§hrend des Trainings und die Kompatibilit√§t mit der Standard-Scikit-Learn-API, jedoch streng separat.  Sie k√∂nnen nicht beides zusammen machen.  Musste es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">reparieren.</a> </li><li>  Wenn Sie W√∂rter in ein W√∂rterbuchformular einf√ºgen, verbessert dies die Qualit√§t ein wenig in Kombination mit tf-idf in W√∂rtern, ist jedoch in allen anderen F√§llen nutzlos.  Am Ende haben wir es ausgeschaltet, um Zeit zu sparen. </li></ul><br><h3 id="opyt-1-chistka-dannyh-ili-chto-delat-s-razmetkoy">  Erfahrung 1. Datenbereinigung oder was mit Markup zu tun ist </h3><br><p>  Chat-Betreiber sind nur Menschen.  Bei der Definition der Kategorien von Benutzerabfragen sind diese h√§ufig falsch und interpretieren die Grenzen zwischen den Kategorien unterschiedlich.  Daher m√ºssen die Quelldaten r√ºcksichtslos und intensiv bereinigt werden. </p><br><p>  Unsere Daten zum Modelltraining zum ersten Projekt: </p><br><ul><li>  Eine Geschichte von Online-Chat-Nachrichten √ºber mehrere Jahre.  Dies sind 250.000 Beitr√§ge in 60.000 Gespr√§chen.  Am Ende des Dialogs w√§hlte der Bediener die Kategorie aus, zu der der Anruf des Benutzers geh√∂rt.  Es gibt ungef√§hr 50 Kategorien in diesem Datensatz. </li><li>  Skriptbaum.  In unserem Fall hatten die Operatoren keine Arbeitsskripte. </li></ul><br><p>  Was genau die Daten schlecht sind, haben wir als Hypothesen formuliert, dann √ºberpr√ºft und wenn m√∂glich korrigiert.  Folgendes ist passiert: </p><br><p>  <strong>Der erste Ansatz.</strong>  Von der gesamten riesigen Liste der Klassen k√∂nnen Sie sicher 5-10 verlassen. <br>  Wir verwerfen kleine Klassen (&lt;1% der Stichprobe): wenig Daten + geringe Auswirkung.  Wir vereinen schwer zu unterscheidende Klassen, auf die Operatoren immer noch genauso reagieren.  Zum Beispiel: <br>  'dms' + 'wie man einen Termin mit einem Arzt vereinbart' + 'Frage zum Ausf√ºllen des Programms' <br>  'Stornierung' + 'Stornierungsstatus' + 'Stornierung der bezahlten Police' <br>  "Erneuerungsfrage" + "Wie kann die Richtlinie erneuert werden?" </p><br><p>  Als n√§chstes werfen wir Klassen wie "andere", "andere" und dergleichen aus: F√ºr einen Chatbot sind sie nutzlos (ohnehin an den Operator weitergeleitet) und beeintr√§chtigen gleichzeitig die Genauigkeit erheblich, da 20% der Anforderungen (30, 50, 90) von Operatoren klassifiziert werden und hier.  Jetzt werfen wir die Klasse aus, mit der der Chatbot (noch) nicht arbeiten kann. </p><br><p>  Ergebnis: in einem Fall Wachstum von einer Genauigkeit von 0,40 auf 0,69, in einem anderen Fall von 0,66 auf 0,77. </p><br><p>  <strong>Der zweite Ansatz.</strong>  Zu Beginn des Chats verstehen die Bediener selbst nur schlecht, wie eine Klasse f√ºr den Benutzer ausgew√§hlt werden soll, sodass die Daten viel ‚ÄûRauschen‚Äú und Fehler enthalten. </p><br><p>  Experiment: Wir nehmen nur die letzten zwei (drei, sechs, ...) Monate der Dialoge und trainieren das Modell weiter <br>  sie. </p><br><p>  Ergebnis: In einem bemerkenswerten Fall stieg die Genauigkeit von 0,40 auf 0,60, in einem anderen von 0,69 auf 0,78. </p><br><p>  <strong>Der dritte Ansatz.</strong>  Manchmal bedeutet eine Genauigkeit von 0,70 nicht, dass das Modell in 30% der F√§lle falsch ist, sondern dass in 30% der F√§lle das Markup l√ºgt und das Modell es sehr vern√ºnftig korrigiert. </p><br><p>  Durch Metriken wie Genauigkeit oder Protokollverlust kann diese Hypothese nicht √ºberpr√ºft werden.  F√ºr die Zwecke des Experiments haben wir uns auf den Blick eines Datenwissenschaftlers beschr√§nkt. Im Idealfall m√ºssen Sie den Datensatz jedoch qualitativ neu anordnen, ohne die Kreuzvalidierung zu vergessen. </p><br><p>  Um mit solchen Proben zu arbeiten, haben wir den Prozess der "iterativen Anreicherung" entwickelt: </p><br><ol><li>  Teilen Sie den Datensatz in 3-4 Fragmente auf. </li><li>  Trainiere das Modell auf dem ersten Fragment. </li><li>  Sagen Sie die Klassen der Sekunde anhand des trainierten Modells voraus. </li><li>  Schauen Sie sich die vorhergesagten Klassen und den Vertrauensgrad des Modells genau an und w√§hlen Sie den Grenzwert des Vertrauens. </li><li>  Entfernen Sie Texte (Objekte), die mit Sicherheit unterhalb der Grenze vorhergesagt wurden, aus dem zweiten Fragment und trainieren Sie das Modell darauf. </li><li>  Wiederholen, bis die Fragmente m√ºde werden oder ausgehen. </li></ol><br><p>  Einerseits sind die Ergebnisse ausgezeichnet: Das erste Iterationsmodell hat eine Genauigkeit von 70%, das zweite - 95%, das dritte - 99 +%.  Ein genauer Blick auf die Ergebnisse von Vorhersagen best√§tigt diese Genauigkeit vollst√§ndig. </p><br><p>  Wie kann man andererseits systematisch √ºberpr√ºfen, ob nachfolgende Modelle die Fehler fr√ºherer Modelle nicht lernen?  Es besteht die Idee, den Prozess an einem manuell ‚Äûverrauschten‚Äú Datensatz mit qualitativ hochwertigem Anfangsmarkup wie MNIST zu testen.  Aber leider gab es nicht genug Zeit daf√ºr.  Und ohne √úberpr√ºfung haben wir es nicht gewagt, eine iterative Anreicherung und die daraus resultierenden Modelle in der Produktion einzuf√ºhren. </p><br><p>  <strong>Der vierte Ansatz.</strong>  Der Datensatz kann erweitert werden - und dadurch die Genauigkeit erh√∂hen und die Umschulung reduzieren, wodurch vorhandene Texte um viele Tippfehler erweitert werden. <br>  Tippfehler sind Tippfehler - Verdoppeln eines Buchstabens, √úberspringen eines Buchstabens, Anordnen benachbarter Buchstaben an bestimmten Stellen, Ersetzen eines Buchstabens durch einen benachbarten Buchstaben auf der Tastatur. </p><br><p>  Experiment: Der Anteil der p Buchstaben, in denen ein Tippfehler auftritt: 2%, 4%, 6%, 8%, 10%, 12%.  Datensatzerh√∂hung: In der Regel bis zu 60.000 Replikate.  Abh√§ngig von der Anfangsgr√∂√üe (nach Filtern) bedeutete dies eine 3- bis 30-fache Erh√∂hung. </p><br><p>  Ergebnis: h√§ngt vom Datensatz ab.  Bei einem kleinen Datensatz (~ 300 Replikate) ergeben 4‚Äì6% der Tippfehler eine stabile und signifikante Erh√∂hung der Genauigkeit (0,40 ‚Üí 0,60).  Bei gro√üen Datenmengen ist alles schlechter.  Bei einem Anteil von Tippfehlern von 8% oder mehr werden die Texte zu Unsinn und die Genauigkeit nimmt ab.  Bei einer Fehlerrate von 2 bis 8% schwankt die Genauigkeit im Bereich von wenigen Prozent, √ºberschreitet die Genauigkeit ohne Tippfehler sehr selten, und es scheint, dass die Trainingszeit nicht mehrmals verl√§ngert werden muss. </p><br><p>  Als Ergebnis erhalten wir ein Modell, das 5 Anrufklassen mit einer Genauigkeit von 0,86 unterscheidet.  Wir koordinieren mit dem Kunden die Texte der Fragen und Antworten f√ºr jede der f√ºnf Gabeln, befestigen die Texte am Chatbot und senden sie an die Qualit√§tssicherung. </p><br><h3 id="opyt-2-po-koleno-v-dannyh-ili-chto-delat-bez-razmetki">  Erfahrung 2. Knietief in den Daten oder was ohne Markup zu tun ist </h3><br><p>  Nachdem wir beim ersten Projekt gute Ergebnisse erzielt hatten, n√§herten wir uns dem zweiten mit Zuversicht.  Aber zum Gl√ºck haben wir nicht vergessen, wie man √ºberrascht wird. </p><br><p>  Was wir getroffen haben: </p><br><ul><li>  Ein Skriptbaum mit f√ºnf Zweigen, der vor etwa einem Jahr mit dem Kunden vereinbart wurde. </li><li>  Eine getaggte Stichprobe von 500 Nachrichten und 11 Klassen unbekannter Herkunft. </li><li>  Getaggt von Chat-Betreibern aus 220.000 Nachrichten, 21.000 Konversationen und 50 anderen Klassen. </li><li>  Das an der ersten Stichprobe trainierte SVM-Modell mit einer Genauigkeit von 0,69, das vom vorherigen Team von Datenwissenschaftlern geerbt wurde.  Warum SVM, die Geschichte schweigt. </li></ul><br><p>  Zun√§chst betrachten wir die Klassen: im Skriptbaum, im Beispiel des SVM-Modells, im Hauptbeispiel.  Und hier ist was wir sehen: </p><br><ul><li>  Klassen des SVM-Modells entsprechen in etwa den Zweigen von Skripten, aber in keiner Weise Klassen aus einer gro√üen Stichprobe. </li><li>  Der Skriptbaum wurde vor einem Jahr √ºber Gesch√§ftsprozesse geschrieben und ist fast veraltet.  Das SVM-Modell ist damit veraltet. </li><li>  Die beiden gr√∂√üten Klassen in der gro√üen Stichprobe sind Umsatz (50%) und Sonstige (45%). </li><li>  Von den f√ºnf n√§chstgr√∂√üeren Klassen sind drei so allgemein wie der Vertrieb. </li><li>  Die verbleibenden 45 Klassen enthalten jeweils weniger als 30 Dialoge.  Das hei√üt,  Wir haben keinen Skriptbaum, es gibt keine Klassenliste und kein Markup. </li></ul><br><p>  Was ist in solchen F√§llen zu tun?  Wir krempelten die √Ñrmel hoch und gingen alleine, um Klassen und Markups aus den Daten zu erhalten. </p><br><p>  <strong>Der erste Versuch.</strong>  Versuchen wir, Benutzerfragen zu gruppieren, d. H.  Die ersten Nachrichten im Dialog, au√üer Gr√º√üe. </p><br><p>  Wir pr√ºfen.  Wir vektorisieren Repliken, indem wir 3 Gramm z√§hlen.  Wir reduzieren die Dimension auf die ersten zehn TSVD-Messungen.  Wir clustern durch agglomeratives Clustering mit dem euklidischen Abstand und der Ziel-Ward-Funktion.  Verringern Sie die Abmessung erneut mit t-SNE (bis zu zwei Messungen, damit Sie die Ergebnisse mit Ihren Augen betrachten k√∂nnen).  Wir zeichnen Replikationspunkte auf der Ebene und malen in den Farben der Cluster. </p><br><p>  Ergebnis: Angst und Entsetzen.  Bei gesunden Clustern k√∂nnen wir davon ausgehen, dass es keine gibt: </p><br><img src="https://habrastorage.org/webt/cl/rm/-s/clrm-sda0crxfeyq8ynskurotkk.png"><br><p>  Fast nicht - es gibt eine, links orange, weil alle darin enthaltenen Nachrichten das 3-Gramm-Zeichen ‚Äû@‚Äú enthalten.  Diese 3 Gramm sind ein Vorverarbeitungsartefakt.  Irgendwo beim Filtern von Satzzeichen wurde ‚Äû@‚Äú nicht nur nicht herausgefiltert, sondern auch mit Leerzeichen √ºberwachsen.  Aber das Artefakt ist n√ºtzlich.  Dieser Cluster umfasst Benutzer, die zuerst ihre E-Mail schreiben.  Leider ist nur durch die Verf√ºgbarkeit von E-Mails v√∂llig unklar, was die Anfrage des Benutzers ist.  Wir gehen weiter. </p><br><p>  <strong>Der zweite Versuch.</strong>  Was ist, wenn Betreiber h√§ufig mit mehr oder weniger Standardlinks antworten? <br>  Wir pr√ºfen.  Wir extrahieren linkartige Teilzeichenfolgen aus Operator-Nachrichten, bearbeiten die Links leicht, unterscheiden sich in der Schreibweise, haben aber die gleiche Bedeutung (http / https, / search? City =% city%) und ber√ºcksichtigen Linkh√§ufigkeiten. </p><br><p>  Ergebnis: vielversprechend.  Erstens antworten Betreiber nur auf einen kleinen Teil der Anfragen (&lt;10%) mit Links.  Zweitens gibt es selbst nach einmaliger manueller Reinigung und Filterung von Links mehr als drei√üig.  Drittens gibt es im Verhalten von Benutzern, die den Dialog mit einem Link beenden, keine besondere √Ñhnlichkeit. </p><br><p>  <strong>Der dritte Versuch.</strong>  Lassen Sie uns nach den Standardantworten der Operatoren suchen - was ist, wenn sie Indikatoren f√ºr eine Klassifizierung von Nachrichten sind? </p><br><p>  Wir pr√ºfen.  In jedem Dialog nehmen wir die letzte Replik des Operators (abgesehen von den Abschiedsfeiern: ‚ÄûIch kann etwas anderem helfen‚Äú usw.) und ber√ºcksichtigen die H√§ufigkeit der eindeutigen Replikate. </p><br><p>  Ergebnis: vielversprechend, aber unpraktisch.  50% der Antworten des Bedieners sind eindeutig, weitere 10‚Äì20% werden zweimal gefunden, die restlichen 30‚Äì40% werden von einer relativ kleinen Anzahl beliebter Vorlagen abgedeckt.  Relativ klein - ungef√§hr dreihundert.  Ein genauer Blick auf diese Vorlagen zeigt, dass viele von ihnen in Bezug auf die Bedeutung Varianten derselben Antwort sind - sie unterscheiden sich durch einen Buchstaben, wo durch ein Wort, wo durch einen Absatz.  Ich m√∂chte diese bedeutungsnahen Antworten gruppieren. </p><br><p>  <strong>Der vierte Versuch.</strong>  Clustering der neuesten Replikate von Anweisungen.  Diese sind viel besser gruppiert: </p><br><img src="https://habrastorage.org/webt/cb/to/xh/cbtoxhphxhmfo-94bpelgw1dalq.png"><br><p>  Damit k√∂nnen Sie bereits arbeiten. </p><br><p>  Wir gruppieren und zeichnen Replikate in der Ebene, wie im ersten Versuch, bestimmen die am klarsten getrennten Cluster manuell, entfernen sie aus dem Datensatz und gruppieren sie erneut.  Nachdem Sie etwa die H√§lfte des Datensatzes getrennt haben, enden klare Cluster, und wir beginnen zu √ºberlegen, welche Klassen ihnen zugewiesen werden sollen.  Wir streuen Cluster nach den urspr√ºnglichen f√ºnf Klassen - die Stichprobe ist ‚Äûverzerrt‚Äú, und drei der f√ºnf urspr√ºnglichen Klassen erhalten keinen einzigen Cluster.  Schade.  Wir verteilen Cluster in f√ºnf Klassen, die wir zuf√§llig bestimmen: "Anrufen", "Kommen", "Warten Sie einen Tag auf eine Antwort", "Probleme mit Captcha", "Andere".  Der Versatz ist geringer, aber die Genauigkeit betr√§gt nur 0,4‚Äì0,5.  Wieder schlecht.  Weisen Sie jedem der √ºber 30 Cluster eine eigene Klasse zu.  Die Stichprobe ist erneut verzerrt und die Genauigkeit betr√§gt erneut 0,5, obwohl etwa f√ºnf ausgew√§hlte Klassen eine anst√§ndige Genauigkeit und Vollst√§ndigkeit aufweisen (0,8 und h√∂her).  Das Ergebnis ist aber immer noch nicht beeindruckend. </p><br><p>  <strong>Der f√ºnfte Versuch.</strong>  Wir brauchen alle Vor- und Nachteile des Clustering.  Wir rufen das vollst√§ndige Cluster-Dendrogramm anstelle der oberen drei√üig Cluster ab.  Wir speichern es in einem Format, das f√ºr Kundenanalysten zug√§nglich ist, und helfen ihnen beim Markup - wir skizzieren die Liste der Klassen. </p><br><p>  F√ºr jede Nachricht berechnen wir eine Kette von Clustern, die jede Nachricht enth√§lt, beginnend mit der Wurzel.  Wir erstellen eine Tabelle mit Spalten: Text, ID des ersten Clusters in der Kette, ID des zweiten Clusters in der Kette, ..., ID des Clusters, der dem Text entspricht.  Wir speichern die Tabelle in csv / xls.       . </p><br><p>         .     ~10000   . ,   ,      .    ‚Äî 4000   10000  ,      -.   6000       : </p><br><ul><li> Baseline:    ‚Äî  0.66. </li><li>  ,     .   0.73. </li><li>   ¬´¬ª ‚Äî    0.79. </li></ul><br><p>  ,     .  ,    ,         .   ,                   .    ,      .  . </p><br><h3 id="vyvody-ili-chto-pokazal-opyt"> ,    : </h3><br><ul><li>     (, ,   .)   . </li><li> XGBoost -  ,       - ,   . </li><li>  ‚Äî     ,       . </li><li>   ‚Äî  ,   . </li><li>        .        . </li></ul><br><p> To be concluded. <cut></cut></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de436072/">https://habr.com/ru/post/de436072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de436062/index.html">Schiedsverfahren f√ºr Anf√§nger, Teil 1</a></li>
<li><a href="../de436064/index.html">K√ºnstliche Intelligenz f√ºr alle</a></li>
<li><a href="../de436066/index.html">Mathematik der Apokalypse: Spieltheorie und die karibische Atomkrise</a></li>
<li><a href="../de436068/index.html">C ++ Russland Konferenz 2019</a></li>
<li><a href="../de436070/index.html">Wie man mit flockigen Tests in der OpenSource-Community umgeht</a></li>
<li><a href="../de436076/index.html">Kauri Hanipot Angriffsanalyse</a></li>
<li><a href="../de436080/index.html">Sicherheitswoche 03: 2019 - Jahr der Privatsph√§re</a></li>
<li><a href="../de436082/index.html">Wie UEBA zur Verbesserung der Cybersicherheit beitr√§gt</a></li>
<li><a href="../de436086/index.html">√úbersicht √ºber Update 4 f√ºr Veeam Cloud Connect</a></li>
<li><a href="../de436088/index.html">Der grafische Editor von GANpaint zeichnet Objekte und demonstriert GAN-Funktionen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
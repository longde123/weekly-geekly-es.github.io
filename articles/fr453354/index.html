<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïò ‚öìÔ∏è üï∫üèæ Classification de la couverture terrestre √† l'aide de l'eo-learn. 3e partie üëâüèæ üññüèª üö¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lorsque vous avez besoin de meilleurs r√©sultats que satisfaisants 


 Partie 1 
 2e partie 





 La transition de la zone de l'hiver √† l'√©t√© est comp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Classification de la couverture terrestre √† l'aide de l'eo-learn. 3e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/453354/"><p>  Lorsque vous avez besoin de meilleurs r√©sultats que satisfaisants </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2e partie</a> </p><br><p><img src="https://habrastorage.org/webt/c0/ls/b2/c0lsb2it_c9qwggm74kdk3uglw4.png"></p><br><p> <em>La transition de la zone de l'hiver √† l'√©t√© est compos√©e d'images Sentinel-2.</em>  <em>Vous pouvez remarquer quelques diff√©rences dans les types de couverture dans la neige, qui ont √©t√© d√©crites dans un article pr√©c√©dent.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Pr√©face </h2><br><p> Les deux derni√®res semaines ont √©t√© tr√®s difficiles.  Nous avons publi√© les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premi√®re</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deuxi√®me</a> parties de nos articles sur la classification de la couverture sur l'ensemble du pays en utilisant le cadre <code>eo-learn</code> .  <code>eo-learn</code> est une biblioth√®que open source pour cr√©er une couche entre la r√©ception et le traitement d'images satellites et l'apprentissage automatique.  Dans les articles pr√©c√©dents des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemples,</a> nous n'avons indiqu√© qu'un petit sous-ensemble des donn√©es et montr√© les r√©sultats uniquement sur un petit pourcentage de l'ensemble de la zone d'int√©r√™t (AOI - zone d'int√©r√™t).  Je sais que cela semble au moins pas tr√®s impressionnant, et peut-√™tre tr√®s grossier de notre part.  Pendant tout ce temps, vous avez √©t√© tourment√© par des questions sur la fa√ßon dont vous pouvez utiliser ces connaissances et les transf√©rer au niveau <em>suivant</em> . </p><br><p>  Ne vous inqui√©tez pas, c'est √† cela que sert le troisi√®me article de cette s√©rie!  Prenez une tasse de caf√© et asseyez-vous ... </p><br><h2 id="all-our-data-are-belong-to-you">  Toutes nos donn√©es vous appartiennent! </h2><br><p>  √ätes-vous d√©j√† assis?  Peut-√™tre laisser le caf√© sur la table pendant une seconde, car maintenant vous entendrez les meilleures nouvelles pour aujourd'hui ... <br>  Chez Sinergise, nous avons d√©cid√© de publier l'ensemble complet de donn√©es pour la Slov√©nie pour 2017.  Gratuitement.  Vous pouvez acc√©der librement √† 200 Go de donn√©es sous la forme de ~ 300 fragments d'EOPatch, chacun d'environ 1000x1000, dans une r√©solution de 10m!  Vous pouvez en savoir plus sur le format EOPatch dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dernier article</a> sur l' <code>eo-learn</code> , mais en fait c'est un conteneur pour les donn√©es <em>g√©o-temporelles</em> EO (Observation de la Terre) et non-EO: par exemple, les images satellites, les masques, les cartes, etc. </p><br><p><img src="https://habrastorage.org/webt/dc/nt/gy/dcntgywsu4la7pdpwegv5m6eskc.png"><br>  <em>Structure EOPatch</em> ) </p><br><p>  Nous n'avons pas pirat√© lorsque nous avons t√©l√©charg√© ces donn√©es.  Chaque EOPatch contient des images Sentinel-2 L1C, leur masque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">s2cloudless</a> correspondant et la carte officielle de la couverture terrestre au format raster! </p><br><p>  Les donn√©es sont stock√©es sur AWS S3 √†: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://eo-learn.sentinel-hub.com/</a> </p><br><p>  La d√©s√©rialisation d'un objet EOPatch est assez simple: </p><br><pre> <code class="python hljs">EOPatch.load(<span class="hljs-string"><span class="hljs-string">'path_to_eopatches/eopatch-0x6/'</span></span>)</code> </pre> <br><p>  Par cons√©quent, vous obtenez un objet de la structure suivante: </p><br><pre> <code class="python hljs">EOPatch( data: { BANDS: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>), dtype=float32) } mask: { CLM: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) IS_DATA: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) IS_VALID: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=bool) } mask_timeless: { LULC: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) VALID_COUNT: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=int64) } meta_info: { maxcc: <span class="hljs-number"><span class="hljs-number">0.8</span></span> service_type: <span class="hljs-string"><span class="hljs-string">'wcs'</span></span> size_x: <span class="hljs-string"><span class="hljs-string">'10m'</span></span> size_y: <span class="hljs-string"><span class="hljs-string">'10m'</span></span> time_difference: datetime.timedelta(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">86399</span></span>) time_interval: (datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>), datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)) } bbox: BBox(((<span class="hljs-number"><span class="hljs-number">370230.5261411405</span></span>, <span class="hljs-number"><span class="hljs-number">5085303.344972428</span></span>), (<span class="hljs-number"><span class="hljs-number">380225.31836121203</span></span>, <span class="hljs-number"><span class="hljs-number">5095400.767924464</span></span>)), crs=EPSG:<span class="hljs-number"><span class="hljs-number">32633</span></span>) timestamp: [datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>), ..., datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)], length=<span class="hljs-number"><span class="hljs-number">80</span></span> )</code> </pre> <br><p>  L'acc√®s aux diff√©rents attributs EOPatch est le suivant: </p><br><pre> <code class="python hljs">eopatch.timestamp eopatch.mask[<span class="hljs-string"><span class="hljs-string">'LULC'</span></span>] eopatch.data[<span class="hljs-string"><span class="hljs-string">'CLM'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] eopatch.data[<span class="hljs-string"><span class="hljs-string">'BANDS'</span></span>][<span class="hljs-number"><span class="hljs-number">5</span></span>][..., [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]]</code> </pre> <br><h3 id="eoexecute-order-66">  EOExecute Order 66 </h3><br><p>  G√©nial, les donn√©es se chargent.  Pendant que nous attendons l'ach√®vement de ce processus, examinons les capacit√©s d'une classe qui n'a pas encore √©t√© discut√©e dans ces articles - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>EOExecutor</code></a> .  Ce module est engag√© dans l'ex√©cution et la surveillance du pipeline et permet d'utiliser le multi-threading sans efforts inutiles.  Plus de recherches sur Stack Overflow pour savoir comment parall√©liser correctement le pipeline ou comment faire fonctionner la barre de progression dans ce mode - nous avons d√©j√† tout fait pour vous! </p><br><p>  En outre, il g√®re les erreurs qui se produisent et peut g√©n√©rer un bref r√©sum√© du processus d'ex√©cution.  Ce dernier est le moment le plus important pour √™tre s√ªr de la r√©p√©tabilit√© de vos r√©sultats √† l'avenir, afin que l'utilisateur n'ait pas √† passer un temps de travail pr√©cieux √† rechercher les param√®tres qu'il a utilis√©s jeudi dernier √† 9h apr√®s une nuit enti√®re de r√©jouissances (ne m√©langez pas alcool et programmation √ßa vaut le coup!).  Cette classe est √©galement capable de g√©n√©rer un joli graphique de d√©pendance pour le pipeline, que vous pouvez montrer √† votre patron! </p><br><p><img src="https://habrastorage.org/webt/_o/x7/0q/_ox70q41_uiebqp7opyqbeu0nx0.png"><br>  <em>Graphique de d√©pendance de pipeline g√©n√©r√© par <code>eo-learn</code></em> </p><br><h3 id="eksperimenty-s-mashinnym-obucheniem">  Exp√©riences d'apprentissage automatique </h3><br><p>  Comme promis, cet article est principalement destin√© √† √©tudier diff√©rents mod√®les avec <code>eo-learn</code> utilisant les donn√©es que nous avons fournies.  Ci-dessous, nous avons pr√©par√© deux exp√©riences o√π nous √©tudions l'effet des nuages ‚Äã‚Äãet diff√©rents algorithmes de r√©√©chantillonnage pendant l'interpolation temporelle sur le r√©sultat final.  Apr√®s tout cela, nous commencerons √† travailler avec les r√©seaux de convolution (CNN) et comparerons les r√©sultats de deux approches - l'analyse pixel par pixel de l'arbre de d√©cision et l'apprentissage en profondeur √† l'aide de r√©seaux de neurones convolutionnels. </p><br><p>  Malheureusement, on ne peut pas donner une r√©ponse sans ambigu√Øt√© quant aux d√©cisions √† prendre lors des exp√©riences.  Vous pouvez √©tudier le sujet plus en profondeur et faire des hypoth√®ses afin de d√©cider si le jeu en vaut la chandelle, mais en fin de compte, le travail se r√©sumera √† des essais et des erreurs. </p><br><h3 id="igraem-s-oblakami">  Jouez avec les nuages </h3><br><p>  Les nuages ‚Äã‚Äãsont une √©norme douleur dans le monde de l'OE, en particulier en ce qui concerne les algorithmes d'apprentissage automatique, o√π vous souhaitez les d√©terminer et les supprimer de l'ensemble de donn√©es pour une interpolation bas√©e sur des valeurs manquantes.  Mais quel est le b√©n√©fice de cette proc√©dure?  Est-ce que √ßa vaut le coup?  Ru√üwurm et K√∂rner, dans leur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article Classification multi-temporelle de la couverture terrestre avec encodeurs r√©currents s√©quentiels, ont</a> m√™me montr√© que pour l'apprentissage en profondeur, le processus de filtrage des nuages ‚Äã‚Äãest probablement absolument sans importance, car le classificateur lui-m√™me est capable de d√©tecter les nuages ‚Äã‚Äãet de les ignorer. </p><br><p><img src="https://habrastorage.org/webt/gz/c8/zs/gzc8zsp0nrdjtgbewqqysxulaiu.png"><br>  Activation de la couche d'entr√©e (en haut) et de la couche de modulation (en bas) dans la s√©quence d'images d'un fragment sp√©cifique pour un r√©seau neuronal.  Vous remarquerez peut-√™tre que ce fragment de r√©seau a appris √† cr√©er des masques cloud et √† filtrer les r√©sultats obtenus.  (Page 9 sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.researchgate.net/publication/322975904_Multi-Temporal_Land_Cover_Classification_with_Sequential_Recurrent_Encoders</a> ) </p><br><p>  Nous rappelons bri√®vement la structure de l'√©tape de filtrage des donn√©es (pour plus de d√©tails, voir [article pr√©c√©dent] ()).  Apr√®s avoir pris des instantan√©s Sentinel-2, nous commen√ßons √† filtrer les instantan√©s cloud.  Toutes les images dans lesquelles le nombre de pixels non nuageux ne d√©passe pas 80% sont soumises au filtrage (les valeurs de seuil peuvent diff√©rer selon les zones d'int√©r√™t).  Apr√®s cela, pour obtenir des valeurs de pixels sur des jours arbitraires, des masques de nuage sont utilis√©s afin de ne pas prendre en compte ces donn√©es. </p><br><p>  Au total, quatre comportements sont possibles: </p><br><ol><li>  <strong>avec</strong> filtre d'image, <strong>donn√© des</strong> masques de nuages </li><li>  <strong>pas de</strong> filtre d'instantan√©, <strong>compte tenu des</strong> masques de cloud </li><li>  <strong>avec</strong> filtre d'image, √† l'exclusion des masques de nuage </li><li>  <strong>sans</strong> filtre d'image, √† l'exclusion des masques de nuage </li></ol><br><p><img src="https://habrastorage.org/webt/rd/3i/ne/rd3ineypd8f0akhs41yve8mtgso.png"><br>  <em>Affichage visuel de la pile d'images du satellite Sentinel-2.</em>  <em>Les pixels transparents √† gauche signifient des pixels manquants en raison de la couverture nuageuse.</em>  <em>La pile centrale affiche les valeurs des pixels apr√®s avoir filtr√© les images et les interpoler avec un masque de nuage (cas 4), et la pile de droite montre le r√©sultat de l'interpolation dans le cas sans filtrer les images et sans masques de nuage (1).</em>  <em>(Notez la piste - apparemment, l'article contient une faute de frappe, et c'√©tait le contraire - cas 1 au centre et 4 √† droite).</em> </p><br><p>  Dans le dernier article, nous avons d√©j√† effectu√© une variation du cas 1 et montr√© les r√©sultats, nous allons donc les utiliser pour la comparaison.  Pr√©parer d'autres convoyeurs et former le mod√®le semble √™tre une t√¢che simple - il vous suffit de vous assurer que nous comparons les valeurs correctes.  Pour ce faire, il suffit de prendre le m√™me ensemble de pixels pour entra√Æner et valider le mod√®le. </p><br><p>  Les r√©sultats sont pr√©sent√©s dans le tableau ci-dessous.  Vous pouvez voir qu'en g√©n√©ral, l'influence des nuages ‚Äã‚Äãsur le r√©sultat du mod√®le est assez faible!  Cela peut √™tre d√ª au fait que la carte de r√©f√©rence est de tr√®s bonne qualit√© et que le mod√®le est capable d'ignorer la plupart des images.  Dans tous les cas, ce comportement ne peut √™tre garanti pour aucun AOI, alors prenez le temps de jeter cette √©tape hors de vos mod√®les! </p><br><div class="scrollable-table"><table><thead><tr><th>  Mod√®le </th><th>  Pr√©cision [%] </th><th>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">F_1</a> [%] </th></tr></thead><tbody><tr><td>  Pas de filtres, pas de masque </td><td>  92,8 </td><td>  92,6 </td></tr><tr><td>  Pas de filtres, avec masque </td><td>  94,2 </td><td>  93,9 </td></tr><tr><td>  Avec filtre, sans masque </td><td>  94,0 </td><td>  93,8 </td></tr><tr><td>  Avec filtre, avec masque </td><td>  94,4 </td><td>  94,1 </td></tr></tbody></table></div><br><h3 id="vliyanie-raznyh-podhodov-k-resemplingu">  L'impact des diff√©rentes approches de r√©√©chantillonnage </h3><br><p>  Le choix des options de r√©√©chantillonnage temporel n'est pas √©vident.  D'une part, nous avons besoin d'un tableau d√©taill√© d'images qui montrent bien les d√©tails des images source - nous voulons inclure le nombre d'images le plus proche possible des donn√©es source.  D'un autre c√¥t√©, nous sommes limit√©s par les ressources informatiques.  La r√©duction de l'√©tape de r√©√©chantillonnage double le nombre de trames apr√®s interpolation et augmente ainsi le nombre d'attributs utilis√©s dans la formation.  Une telle am√©lioration vaut-elle le co√ªt des ressources?  C'est ce que nous devons d√©couvrir. </p><br><p>  Pour cette exp√©rience, nous utiliserons la variante 1 de l'√©tape pr√©c√©dente.  Apr√®s interpolation, nous r√©√©chantillonnons avec les variations suivantes: </p><br><ol><li>  R√©√©chantillonnage uniforme avec un intervalle de 16 jours </li><li>  R√©√©chantillonnage uniforme avec un intervalle de 8 jours </li><li>  Le choix des "meilleures" dates, le nombre co√Øncide avec le cas 2. </li></ol><br><p>  L'√©chantillon dans le cas 3 est bas√© sur le plus grand nombre de dates communes pour tous les EOPatch dans la zone d'int√©r√™t s√©lectionn√©e <br><img src="https://habrastorage.org/webt/xg/qa/9w/xgqa9w17-oe4dbtxca22yejwhzo.png"><br>  <em>Le graphique montre le nombre de fragments EOPatch qui contiennent des donn√©es pour chaque jour de 2017 (bleu).</em>  <em>Les lignes rouges indiquent les dates optimales pour le r√©√©chantillonnage, qui sont bas√©es sur les dates des images Sentinel-2 pour l'AOI 2017 donn√©.</em> </p><br><p>  En regardant le tableau ci-dessous, vous pouvez voir que les r√©sultats ne sont pas tr√®s impressionnants, comme par le pass√©.  Pour les cas 2 et 3, le temps pass√© double, mais la diff√©rence avec l'approche initiale est inf√©rieure √† 1%.  Ces am√©liorations sont trop discr√®tes pour une utilisation pratique, nous pouvons donc consid√©rer l'intervalle de 16 jours adapt√© √† la t√¢che. </p><br><div class="scrollable-table"><table><thead><tr><th>  Mod√®le </th><th>  Pr√©cision [%] </th><th>  F_1 [%] </th></tr></thead><tbody><tr><td>  Uniform√©ment tous les 16 jours </td><td>  94,4 </td><td>  94,1 </td></tr><tr><td>  Uniform√©ment tous les 8 jours </td><td>  94,5 </td><td>  94,3 </td></tr><tr><td>  Choisir les meilleures dates </td><td>  94,6 </td><td>  94,4 </td></tr></tbody></table></div><br><p>  <em>R√©sultats de la pr√©cision globale et de la F1 pond√©r√©e pour diff√©rents pipelines avec un changement dans l'approche du r√©√©chantillonnage.</em> </p><br><h2 id="glubokoe-obuchenie-ispolzuem-svyortochnuyu-neyronnuyu-set-cnn">  Deep Learning: Utilisation du r√©seau neuronal convolutif (CNN) </h2><br><p>  L'apprentissage en profondeur est devenu l'approche standard pour de nombreuses t√¢ches, telles que la vision par ordinateur, le traitement de texte en langage naturel et le traitement du signal.  Cela est d√ª √† leur capacit√© √† extraire des mod√®les √† partir d'entr√©es multidimensionnelles complexes.  Les approches classiques d'apprentissage automatique (comme les arbres de d√©cision) ont √©t√© utilis√©es dans de nombreuses t√¢ches de g√©odonn√©es temporelles.  Les r√©seaux convolutifs, d'autre part, ont √©t√© utilis√©s pour analyser la corr√©lation spatiale entre les images adjacentes.  Fondamentalement, leur utilisation se limitait √† travailler avec des images uniques. </p><br><p>  Nous voulions √©tudier l'architecture des mod√®les d'apprentissage profond et essayer d'en choisir une capable d'analyser √† la fois les aspects spatiaux et temporels des donn√©es satellitaires. </p><br><p>  Pour ce faire, nous avons utilis√© Netvork temporel enti√®rement convolutionnel, TFCN, ou plut√¥t l'expansion temporelle vers U-Net, impl√©ment√©e dans TensorFlow.  Plus pr√©cis√©ment, l'architecture utilise des corr√©lations spatio-temporelles pour am√©liorer le r√©sultat.  Un avantage suppl√©mentaire est que la structure du r√©seau vous permet de mieux repr√©senter les relations spatiales √† diff√©rentes √©chelles gr√¢ce au processus de codage / d√©codage dans U-net.  Comme dans les mod√®les classiques, en sortie, nous obtenons une matrice bidimensionnelle d'√©tiquettes, que nous comparerons avec la v√©rit√©. </p><br><p><img src="https://habrastorage.org/webt/p0/jl/mg/p0jlmgxi9euwvodwonx4zrmezsw.png"></p><br><p>  Nous avons utilis√© le mod√®le entra√Æn√© pour pr√©dire les marques sur l'ensemble de test, et les valeurs obtenues ont √©t√© v√©rifi√©es avec la v√©rit√©.  Dans l'ensemble, la pr√©cision √©tait de 84,4% et F1 √©tait de 85,4%. </p><br><p><img src="https://habrastorage.org/webt/ol/z2/zj/olz2zjp3waghaak9hnirzcwa258.png"></p><br><p>  <em>Comparaison de diff√©rentes pr√©dictions pour notre t√¢che.</em>  <em>Image visuelle (en haut √† gauche), vraie carte de r√©f√©rence (en haut √† droite), pr√©diction du mod√®le LightGBM (en bas √† gauche) et pr√©diction U-net (en bas √† droite)</em> </p><br><p>  Ces r√©sultats ne montrent que le travail initial sur ce prototype, qui n'est pas hautement optimis√© pour la t√¢che en cours.  Malgr√© cela, les r√©sultats concordent avec certaines statistiques obtenues dans la r√©gion.  Pour lib√©rer le potentiel d'un r√©seau neuronal, il est n√©cessaire d'optimiser l'architecture (ensemble d'attributs, la profondeur du r√©seau, le nombre de circonvolutions), ainsi que de d√©finir des hyper param√®tres (vitesse d'apprentissage, nombre d'√©poques, pond√©ration de classe).  Nous nous attendons √† approfondir ce sujet (ha ha) encore plus, et pr√©voyons de distribuer notre code lorsqu'il sera sous une forme acceptable. </p><br><h3 id="drugie-eksperimenty">  D'autres exp√©riences </h3><br><p>  Vous pouvez trouver de <em>nombreuses</em> fa√ßons d'am√©liorer vos r√©sultats actuels, mais nous ne pouvons ni les trier ni les essayer tous.  C'est √† ce moment que vous apparaissez sur la sc√®ne!  Montrez ce que vous pouvez faire avec cet ensemble de donn√©es et aidez-nous √† am√©liorer les r√©sultats! </p><br><p>  Par exemple, un de nos coll√®gues dans un proche avenir sera engag√© dans la classification de la couverture bas√©e sur la pile temporelle d'images <em>individuelles √† l'</em> aide de r√©seaux de convolution.  L'id√©e est que certaines surfaces, par exemple artificielles, peuvent √™tre distingu√©es sans caract√©ristiques temporelles - assez spatiales.  Nous serons heureux d'√©crire un article s√©par√© lorsque ce travail aboutira √† des r√©sultats! </p><br><h3 id="ot-perevodchika">  Du traducteur </h3><br><p>  Malheureusement, la partie suivante de cette s√©rie d'articles n'est pas sortie, ce qui signifie que les auteurs n'ont pas montr√© d'exemples de code source avec la construction de U-Net.  Comme alternative, je peux vous proposer les sources suivantes: </p><br><ol><li>  <em>U-Net: R√©seaux convolutionnels pour la segmentation d'images biom√©dicales - Olaf Ronneberger, Philipp Fischer, Thomas Brox</em> est l'un des articles de base sur l'architecture U-Net qui n'implique pas de donn√©es temporelles. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://eo-learn.readthedocs.io/en/latest/examples/land-cover-map/SI_LULC_pipeline.html</a> - La page de documentation eo-learn, o√π se trouve (√©ventuellement) une version plus r√©cente des pipelines de 1.2 parties. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/divamgupta/image-segmentation-keras</a> - Un r√©f√©rentiel avec plusieurs r√©seaux impl√©ment√©s √† l'aide de keras.  J'ai quelques questions sur les impl√©mentations (elles sont l√©g√®rement diff√©rentes de celles d√©crites dans les articles originaux), mais en g√©n√©ral, les solutions sont facilement adaptables √† des fins personnelles et fonctionnent assez bien. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr453354/">https://habr.com/ru/post/fr453354/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr453342/index.html">Mythes sur les employ√©s distants que nous nous sommes d√©truits</a></li>
<li><a href="../fr453346/index.html">Technologies de stockage et de protection des donn√©es - le troisi√®me jour de VMware EMPOWER 2019</a></li>
<li><a href="../fr453348/index.html">√Ä l'int√©rieur d'Asyncio</a></li>
<li><a href="../fr453350/index.html">Diffusion ouverte du hall principal du RIT ++ 2019</a></li>
<li><a href="../fr453352/index.html">Comment les drones d√©livrent des m√©dicaments essentiels au Ghana</a></li>
<li><a href="../fr453356/index.html">Tendances actuelles et recommandations sur l'agglom√©ration des grandes institutions financi√®res</a></li>
<li><a href="../fr453360/index.html">Ville sans embouteillage</a></li>
<li><a href="../fr453362/index.html">HabraConf # 1 - Vers l'arri√®re pour le backend</a></li>
<li><a href="../fr453364/index.html">Une histoire de d√©ploiement qui a tout affect√©</a></li>
<li><a href="../fr453366/index.html">Comment utiliser les virgules en anglais: 15 r√®gles et exemples d'erreur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📇 👩‍🍳 🤳🏾 Überprüfung von Einzelhandelsfotos mit Computer Vision 💍 👨‍👧‍👧 🤗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eintrag 
 Im Rahmen des Kreditprogramms kooperiert die Bank mit vielen Einzelhandelsgeschäften. 
 Eines der Schlüsselelemente eines Kreditantrags ist ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Überprüfung von Einzelhandelsfotos mit Computer Vision</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/tinkoff/blog/432056/"><h2>  Eintrag </h2><br>  Im Rahmen des Kreditprogramms kooperiert die Bank mit vielen Einzelhandelsgeschäften. <br>  Eines der Schlüsselelemente eines Kreditantrags ist ein Foto des Kreditnehmers - ein Vertreter des Partnergeschäfts fotografiert den Käufer;  Ein solches Foto fällt in die „Personalakte“ des Kunden und wird in Zukunft als eine Möglichkeit verwendet, seine Anwesenheit zum Zeitpunkt der Beantragung eines Darlehens zu bestätigen. <br><br>  Leider besteht immer die Gefahr eines unehrlichen Verhaltens eines Agenten, der möglicherweise ungenaue Fotos an die Bank überträgt - beispielsweise Kundenbilder aus sozialen Netzwerken oder Pässen. <br><br>  In der Regel lösen Banken dieses Problem, indem sie überprüfen, ob die Mitarbeiter des Fotobüros Fotos betrachten und versuchen, ungenaue Bilder zu identifizieren. <br>  Wir wollten versuchen, den Prozess zu automatisieren und das Problem mithilfe neuronaler Netze zu lösen. <br><a name="habracut"></a><br><h2>  Aufgabenformalisierung </h2><br>  Wir haben nur Fotos untersucht, auf denen sich Menschen befinden.  Gesichtslose Bilder können mit der geöffneten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dlib-</a> Bibliothek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">abgeschnitten</a> werden. <br><br>  Zur Verdeutlichung geben wir Beispiele für Fotos (Bankangestellte sind abgebildet): <br><br><img src="https://habrastorage.org/webt/qj/c1/al/qjc1alaw2gwuqpnrmqmjj6qj1xk.jpeg" alt="Bild"><br>  <i>Abb. 1. Fotos vom Point of Sale</i> <br><br><img src="https://habrastorage.org/webt/rk/gm/xj/rkgmxjwzo50jn32bwysbu8xkxqo.png" alt="Bild"><br>  <i>Abb. 2. Fotos aus sozialen Netzwerken</i> <br><br><img src="https://habrastorage.org/webt/je/24/6a/je246aabvz08pqfnd9jticzlaqc.png" alt="Bild"><br>  <i>Abb. 3. Passfoto</i> <br><br>  Also mussten wir ein Modell schreiben, das den Hintergrund des Fotos analysiert.  Das Ergebnis ihrer Arbeit war es, die Wahrscheinlichkeit zu bestimmen, mit der das Foto an einer der Verkaufsstellen unserer Partner aufgenommen wurde.  Wir haben drei Möglichkeiten zur Lösung dieses Problems identifiziert: Segmentierung, Vergleich mit anderen Fotos am selben Verkaufsort, Klassifizierung.  Lassen Sie uns jeden von ihnen genauer betrachten. <br><br><h3>  A) Segmentierung </h3><br>  Das erste, was mir in den Sinn kam, war, dieses Problem zu lösen, indem das Bild segmentiert und Bereiche mit dem Hintergrund von Partnergeschäften identifiziert wurden. <br><br>  Nachteile: <br><br><ul><li>  Die Vorbereitung der Trainingsmuster dauert zu lange. </li><li>  Ein auf diesem Modell basierender Dienst funktioniert nicht schnell. </li></ul><br>  Es wurde beschlossen, zu dieser Methode nur zurückzukehren, wenn alternative Optionen aufgegeben wurden.  Spoiler: ist nicht zurückgekehrt. <br><br><h3>  B) Vergleich mit anderen Fotos an derselben Verkaufsstelle </h3><br>  Zusammen mit dem Foto erhalten wir Informationen darüber, in welchem ​​Einzelhandelsgeschäft es hergestellt wurde.  Das heißt, wir haben Gruppen von Bildern, die an denselben Verkaufsstellen aufgenommen wurden.  Die Gesamtzahl der Fotos in jeder Gruppe variiert zwischen einigen Einheiten und mehreren Tausend. <br><br>  Eine andere Idee kam auf: ein Modell zu bauen, das zwei Fotos vergleicht und die Wahrscheinlichkeit vorhersagt, dass sie an einer Verkaufsstelle aufgenommen wurden.  Dann können wir das neu empfangene Foto mit den vorhandenen Fotos im selben Geschäft vergleichen.  Wenn sich herausstellt, dass sie ihnen ähnlich sind, ist das Bild definitiv zuverlässig.  Wenn das Bild aus dem Bild herausgeschlagen wird, senden wir es zusätzlich zur manuellen Überprüfung. <br><br>  Nachteile: <br><br><ul><li>  Unausgeglichene Probenahme. </li><li>  Der Service wird lange funktionieren, wenn am Point of Sale viele Fotos vorhanden sind. </li><li>  Wenn eine neue Verkaufsstelle angezeigt wird, müssen Sie das Modell neu trainieren. </li></ul><br>  Trotz der Nachteile haben wir das Modell aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel unter</a> Verwendung der Blöcke der neuronalen Netze VGG-16 und ResNet-50 implementiert.  Und ... sie haben in beiden Fällen einen Prozentsatz korrekter Antworten erhalten, der nicht viel höher als 50% ist :( <br><br><h3>  B) Klassifizierung! </h3><br>  Die verlockendste Idee war es, einen einfachen Klassifikator zu erstellen, der die Fotos in drei Gruppen unterteilt: Fotos von Verkaufsstellen, Pässen und sozialen Netzwerken.  Es bleibt nur zu überprüfen, ob dieser Ansatz funktioniert.  Nehmen Sie sich auch etwas Zeit, um die Daten für das Training vorzubereiten. <br><br><h4>  Datenaufbereitung </h4><br>  Im Datensatz von Bildern aus sozialen Netzwerken, die die Dlib-Bibliothek verwenden, wurden nur diejenigen Fotos ausgewählt, die Personen enthalten. <br><br>  Passfotos mussten anders geschnitten werden, so dass nur das Gesicht übrig blieb.  Auch hier kam Dlib zur Rettung.  Das Prinzip der Arbeit stellte sich folgendermaßen heraus: Mit Hilfe der Bibliothek wurden die Koordinaten des Gesichts ermittelt -&gt; das Passfoto abgeschnitten und das Gesicht verlassen. <br><br>  In jeder der 3 Klassen blieben 40.000 Fotos.  Vergessen Sie nicht <a href="">die Datenerweiterung</a> <br><br><h4>  Modell </h4><br>  Gebrauchtes ResNet-50.  Sie lösten das Problem als Mehrklassenklassifizierungsproblem mit disjunkten Klassen.  Das heißt, es wurde angenommen, dass ein Foto nur einer Klasse angehören kann. <br><br><pre><code class="python hljs">model = keras.applications.resnet50.ResNet50() model.layers.pop() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model.layers: layer.trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> last = model.layers[<span class="hljs-number"><span class="hljs-number">-1</span></span>].output x = Dense(<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"softmax"</span></span>)(last) resnet50_1 = Model(model.input, x) resnet50_1.compile(optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">0.00001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[ <span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h4>  Ergebnisse </h4><br>  In der Testprobe blieben 24.000 Bilder übrig, d. H. 20%.  Die Fehlermatrix war wie folgt: <br><br><img src="https://habrastorage.org/webt/f3/tj/yo/f3tjyoolgulbx3prlydnbbptf0i.png" alt="Bild"><br>  soziales Netz - soziale Netzwerke; <br>  Reisepass - Reisepässe; <br>  pos-credit - Verkaufsstellen, Partner, die Kredite vergeben. <br><br>  Der Gesamtfehleranteil beträgt 1,6% für Fotos von Verkaufsstellen - 1,2%.  Die meisten der falsch definierten Bilder sind Bilder, die zwei Klassen gleichzeitig ähnlich sind.  Zum Beispiel wurden fast alle falsch definierten Fotos aus der Pos-Credit-Klasse aus erfolglosen Winkeln aufgenommen (an der weißen Wand ist nur das Gesicht sichtbar).  Daher ähnelten sie auch den Fotos aus der Klasse der sozialen Netze.  Solche Fotografien hatten eine geringe maximale Wahrscheinlichkeit. <br>  Wir haben einen Schwellenwert für die maximale Wahrscheinlichkeit hinzugefügt.  Wenn der Endwert höher ist - wir vertrauen dem Klassifikator, niedriger - senden wir das Bild zur manuellen Überprüfung. <br><br>  Als Ergebnis das Ergebnis des Dienstes für die Fotografie <br><br><img src="https://habrastorage.org/webt/gx/b8/2y/gxb82yxdld7qdjsibuaccnjcqxs.jpeg" alt="Bild"><br><br>  sieht so aus: <br><br><img src="https://habrastorage.org/webt/iw/kb/iz/iwkbizeyoq-vnvruacwqpf36nv0.png" alt="Bild"><br><br><h2>  Zusammenfassung </h2><br>  Anhand eines einfachen Modells haben wir gelernt, wie wir automatisch feststellen können, dass ein Foto an einer der Verkaufsstellen unserer Partner aufgenommen wurde.  Dies ermöglichte es uns, einen Teil des umfangreichen Prozesses zur Genehmigung eines Kreditantrags zu automatisieren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de432056/">https://habr.com/ru/post/de432056/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de432046/index.html">Grail Telecom Data Cup Wettbewerb. Das heißeste zu kommen</a></li>
<li><a href="../de432048/index.html">Warum sollte sich jemand die Mühe machen, gefragte Sprachen zu lernen? Eine Fallstudie der F # Community</a></li>
<li><a href="../de432050/index.html">Willkommen beim Waves Blockchain Hackathon</a></li>
<li><a href="../de432052/index.html">"Sie sind ein cooler Entwickler, fragen Sie nach mehr Geld" - wir werden den Managern sagen, wie die Welt funktioniert</a></li>
<li><a href="../de432054/index.html">Was BeOS und HaikuOS einzigartig macht</a></li>
<li><a href="../de432058/index.html">Was ist neu in AppCode 2018.3?</a></li>
<li><a href="../de432060/index.html">Die besten Möglichkeiten, sich englische Wörter zu merken</a></li>
<li><a href="../de432062/index.html">KI-Entwicklung am Beispiel des Dicey Dungeons-Spiels</a></li>
<li><a href="../de432064/index.html">Wie man den "Hasen" entkommt. UV-Anweisung</a></li>
<li><a href="../de432068/index.html">So erleichtern Sie das Englischlernen: 5 nützliche Dienste</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
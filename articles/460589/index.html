<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí£ üîñ üçπ Escribir una red neuronal simple usando matem√°ticas y Numpy üë®üèæ‚Äç‚öñÔ∏è üë©üèæ‚Äçü§ù‚Äçüë®üèª üç∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øPor qu√© el pr√≥ximo art√≠culo sobre c√≥mo escribir redes neuronales desde cero? Por desgracia, no pude encontrar art√≠culos donde la teor√≠a y el c√≥digo s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Escribir una red neuronal simple usando matem√°ticas y Numpy</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460589/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/5_/h5/0t/5_h50teeaqngyx0ccp8cqjqfumm.jpeg" width="350"></div><br>  ¬øPor qu√© el pr√≥ximo art√≠culo sobre c√≥mo escribir redes neuronales desde cero?  Por desgracia, no pude encontrar art√≠culos donde la teor√≠a y el c√≥digo se describieran desde cero a un modelo totalmente funcional.  Inmediatamente advierto que habr√° muchas matem√°ticas.  Supongo que el lector est√° familiarizado con los conceptos b√°sicos de √°lgebra lineal, derivadas parciales y, al menos parcialmente, con la teor√≠a de la probabilidad, as√≠ como con Python y Numpy.  Nos ocuparemos de una red neuronal totalmente conectada y MNIST. <br><a name="habracut"></a><br><h2>  Matem√°ticas  Parte 1 (simple) </h2><br>  ¬øQu√© es una capa totalmente conectada (capa FC)?  Por lo general, dicen algo como "Una capa completamente conectada es una capa, cada neurona de la cual est√° conectada a todas las neuronas de la capa anterior".  Simplemente no est√° claro qu√© son las neuronas, c√≥mo est√°n conectadas, especialmente en el c√≥digo.  Ahora intentar√© analizar esto con un ejemplo.  Que haya una capa de 100 neuronas.  S√© que a√∫n no he explicado de qu√© se trata, pero imaginemos que hay 100 neuronas y tienen una entrada a donde se env√≠an los datos, y una salida desde donde dan los datos.  Y una imagen en blanco y negro de 28x28 p√≠xeles se alimenta a la entrada, solo 784 valores, si la estira en un vector.  Una imagen se puede llamar una capa de entrada.  Luego, para que cada una de las 100 neuronas se conecte con cada "neurona" o, si lo desea, el valor de la capa anterior (es decir, la imagen), es necesario que cada una de las 100 neuronas acepte 784 valores de la imagen original.  Por ejemplo, para cada una de las 100 neuronas ser√° suficiente multiplicar 784 valores de la imagen por unos 784 n√∫meros y sumarlos, como resultado, sale un n√∫mero.  Es decir, esta es una neurona: <br><p><math> </math> $$ display $$ \ text {Neuron output} = \ text {some number} _ {1} \ cdot \ text {picture value} _1 ~ + \\ + ~ ... ~ + ~ \ text {some- ese n√∫mero} _ {784} \ cdot \ text {valor de imagen} _ {784} $$ display $$ </p><br>  Luego resulta que cada neurona tiene 784 n√∫meros, y todos estos n√∫meros: (n√∫mero de neuronas en esta capa) x (n√∫mero de neuronas en la capa anterior) = <math> </math> $ en l√≠nea $ 100 \ times784 $ en l√≠nea $   = 78,400 d√≠gitos.  Estos n√∫meros se denominan com√∫nmente pesos de capa.  Cada neurona dar√° su n√∫mero y como resultado obtenemos un vector de 100 dimensiones, y de hecho podemos escribir que este vector de 100 dimensiones se obtiene multiplicando el vector de 784 dimensiones (nuestra imagen original) por una matriz de peso de tama√±o <math> </math> $ en l√≠nea $ 100 \ times784 $ en l√≠nea $   : <br><p><math> </math> $$ display $$ \ boldsymbol {x} ^ {100} = W_ {100 \ times784} \ cdot \ boldsymbol {x} ^ {784} $$ display $$ </p><br><br>  Adem√°s, los 100 n√∫meros resultantes se transmiten a la funci√≥n de activaci√≥n, alguna funci√≥n no lineal, que afecta a cada n√∫mero por separado.  Por ejemplo, sigmoide, tangente hiperb√≥lica, ReLU y otros.  La funci√≥n de activaci√≥n es necesariamente no lineal; de lo contrario, la red neuronal solo aprender√° transformaciones simples. <br><br><img src="https://habrastorage.org/webt/0j/rl/ba/0jrlbaqv0486mryhqj32u8et0cw.png"><br><br>  Luego, los datos resultantes se env√≠an nuevamente a una capa totalmente conectada, pero con un n√∫mero diferente de neuronas, y nuevamente a la funci√≥n de activaci√≥n.  Esto pasa varias veces.  La √∫ltima capa de la red es la capa que produce la respuesta.  En este caso, la respuesta es informaci√≥n sobre el n√∫mero en la imagen. <br><br><img src="https://habrastorage.org/webt/9f/73/q-/9f73q-feve3kb5k9u5fxvmz4kxk.png"><br><br>  Durante el entrenamiento de la red, es necesario que sepamos qu√© figura se muestra en la imagen.  Es decir, que el conjunto de datos est√° marcado.  Entonces puede usar otro elemento: la funci√≥n de error.  Ella mira la respuesta de la red neuronal y la compara con la respuesta real.  Gracias a esto, la red neuronal est√° aprendiendo. <br><br><h2>  Declaraci√≥n general del problema. </h2><br>  El conjunto de datos completo es un tensor grande (llamaremos tensor a una matriz de datos multidimensional) <math> </math> $ en l√≠nea $ \ boldsymbol {X} = \ left [\ boldsymbol {x} _1, \ boldsymbol {x} _2, \ ldots, \ boldsymbol {x} _n \ right] $ inline $   donde <math> </math> $ en l√≠nea $ \ boldsymbol {x} _i $ en l√≠nea $   - i-√©simo objeto, por ejemplo, una imagen, que tambi√©n es un tensor.  Para cada objeto hay <math> </math> $ en l√≠nea $ y_i $ en l√≠nea $   - la respuesta correcta en el i-√©simo objeto.  En este caso, una red neuronal se puede representar como una funci√≥n que toma un objeto como entrada y le da alguna respuesta: <br><p><math> </math> $$ display $$ F (\ boldsymbol {x} _i) = \ hat {y} _i $$ display $$ </p><br>  Ahora echemos un vistazo m√°s de cerca a la funci√≥n <math> </math> $ en l√≠nea $ F (\ boldsymbol {x} _i) $ en l√≠nea $   .  Dado que la red neuronal consta de capas, cada capa individual es una funci√≥n.  Y eso significa <br><p><math> </math> $$ display $$ F (\ boldsymbol {x} _i) = f_k (f_ {k-1} (\ ldots (f_1 (\ boldsymbol {x} _i)))) = \ hat {y} _i $$ display $ $ $ </p><br>  Es decir, en la primera funci√≥n, la primera capa, se presenta una imagen en forma de alg√∫n tensor.  Funci√≥n <math> </math> $ en l√≠nea $ f_1 $ en l√≠nea $   da alguna respuesta, tambi√©n un tensor, pero de una dimensi√≥n diferente.  Este tensor se llamar√° representaci√≥n interna.  Ahora esta representaci√≥n interna se alimenta a la entrada de la funci√≥n <math> </math> $ en l√≠nea $ f_2 $ en l√≠nea $   , que da su representaci√≥n interna.  Y as√≠ sucesivamente, hasta que la funci√≥n <math> </math> $ en l√≠nea $ f_k $ en l√≠nea $   - √∫ltima capa - no dar√° una respuesta <math> </math> $ en l√≠nea $ \ hat {y} _i $ en l√≠nea $   . <br><br>  Ahora, la tarea es capacitar a la red: hacer que la respuesta de la red coincida con la respuesta correcta.  Primero debes medir qu√© tan equivocada est√° la red neuronal.  Medir esto es una funci√≥n de error. <math> </math> $ en l√≠nea $ L (\ hat {y} _i, y_i) $ en l√≠nea $   .  E imponemos restricciones: <br><br>  1) <math> </math> $ en l√≠nea $ \ hat {y} _i \ xrightarrow {} y_i \ Rightarrow L (\ hat {y} _i, y_i) \ xrightarrow {} 0 $ en l√≠nea $ <br>  2) <math> </math> $ en l√≠nea $ \ existe ~ dL (\ hat {y} _i, y_i) $ en l√≠nea $ <br>  3) <math> </math> $ en l√≠nea $ L (\ hat {y} _i, y_i) \ geq 0 $ en l√≠nea $ <br><br>  La restricci√≥n 2 se impone a todas las funciones de las capas. <math> </math> $ en l√≠nea $ f_j $ en l√≠nea $   - Que todos sean diferenciables. <br><br>  Adem√°s, de hecho (no mencion√© esto) algunas de estas funciones dependen de los par√°metros (los pesos de la red neuronal) <math> </math> $ en l√≠nea $ f_j (\ boldsymbol {x} _i | \ boldsymbol {\ omega} _j) $ en l√≠nea $   .  Y toda la idea es levantar esos pesos para que <math> </math> $ en l√≠nea $ \ hat {y} _i $ en l√≠nea $   coincidi√≥ con <math> </math> $ en l√≠nea $ y_i $ en l√≠nea $   en todos los objetos de un conjunto de datos.  Observo que no todas las funciones tienen pesos. <br><br>  Entonces, ¬ød√≥nde nos detuvimos?  Todas las funciones de la red neuronal son diferenciables, la funci√≥n de error tambi√©n es diferenciable.  Recuerde una de las propiedades del gradiente: muestre la direcci√≥n de crecimiento de la funci√≥n.  Usamos esto, restricciones 1 y 3, el hecho de que <br><p><math> </math> $$ display $$ L (F (\ boldsymbol {x} _i)) = L (f_k (f_ {k-1} (\ ldots (f_1 (\ boldsymbol {x} _i)))))) L (\ hat {y} _i) $$ display $$ </p><br>  y el hecho de que puedo considerar derivadas parciales y derivadas de una funci√≥n compleja.  Ahora hay todo lo que necesitas para calcular <br><p><math> </math> $$ display $$ \ frac {\ partial L (F (\ boldsymbol {x} _i))} {\ partial \ boldsymbol {\ omega_j}} $$ display $$ </p><br>  para cualquier i y j.  Esta derivada parcial muestra la direcci√≥n en la que cambiar <math> </math> $ en l√≠nea $ \ boldsymbol {\ omega_j} $ en l√≠nea $   para ampliar <math> </math> $ en l√≠nea $ L $ en l√≠nea $   .  Para reducir necesitas dar un paso al costado <math> </math> $ en l√≠nea $ - \ frac {\ parcial L (F (\ boldsymbol {x} _i))} {\ partial \ boldsymbol {\ omega_j}} $ en l√≠nea $   nada complicado <br><br>  Entonces, el proceso de capacitaci√≥n de la red se construye de la siguiente manera: varias veces en un ciclo pasamos por todo el conjunto de datos (esto se llama era), para cada objeto del conjunto de datos que consideramos <math> </math> $ en l√≠nea $ L (\ hat {y} _i, y_i) $ en l√≠nea $   (esto se llama avance) y considere la derivada parcial <math> </math> $ en l√≠nea $ \ parcial L $ en l√≠nea $   para todos los pesos <math> </math> $ en l√≠nea $ \ boldsymbol {\ omega_j} $ en l√≠nea $   , luego actualice los pesos (esto se denomina paso hacia atr√°s). <br><br>  Observo que a√∫n no he introducido ninguna funci√≥n y capa espec√≠fica.  Si en esta etapa no est√° claro qu√© hacer con todo esto, propongo continuar leyendo: habr√° m√°s matem√°ticas, pero ahora ir√° con ejemplos. <br><br><h2>  Matem√°ticas  Parte 2 (dif√≠cil) </h2><br><h3>  Funci√≥n de error </h3><br>  Comenzar√© desde el final y derivar√© la funci√≥n de error para el problema de clasificaci√≥n.  Para el problema de regresi√≥n, la derivaci√≥n de la funci√≥n de error se describe bien en el libro "Aprendizaje profundo".  Inmersi√≥n en el mundo de las redes neuronales ". <br><br>  Para simplificar, hay una red neuronal (NN) que separa las fotos de gatos de las fotos de perros, y hay un conjunto de fotos de gatos y perros para las cuales hay una respuesta correcta <math> </math> $ inline $ y_ {true} $ inline $   . <br><p><math> </math> $$ display $$ NN (imagen | \ Omega) = y_ {pred} $$ display $$ </p><br>  Todo lo que har√© a continuaci√≥n es muy similar al m√©todo de m√°xima verosimilitud.  Por lo tanto, la tarea principal es encontrar la funci√≥n de probabilidad.  Si omitimos los detalles, entonces dicha funci√≥n que compara la predicci√≥n de la red neuronal y la respuesta correcta, y si coinciden, da un gran valor, si no, viceversa.  La probabilidad de una respuesta correcta viene a la mente con los par√°metros dados: <br><p><math> </math> $$ display $$ p (y_ {pred} = y_ {true} | \ Omega) $$ display $$ </p><br>  Y ahora haremos una finta que, al parecer, no se sigue de ninguna parte.  Deje que la red neuronal d√© una respuesta en forma de un vector bidimensional, cuya suma de los valores es 1. El primer elemento de este vector puede llamarse una medida de confianza de que el gato est√° en la foto, y el segundo elemento la medida de confianza de que el perro est√° en la foto.  ¬°S√≠, es casi una probabilidad! <br><p><math> </math> $$ display $$ NN (imagen | \ Omega) = \ left [\ begin {matrix} p_0 \\ p_1 \\\ end {matrix} \ right] $$ display $$ </p><br>  Ahora la funci√≥n de probabilidad se puede reescribir como: <br><p><math> </math> $$ display $$ p (y_ {pred} = y_ {true} | \ Omega) = p_ \ Omega (y_ {pred}) ^ t_ {0} * (1 - p_ \ Omega (y_ {pred})) ^ t_ {1} = \\ p_0 ^ {t_0} * p_1 ^ {t_1} $$ display $$ </p><br>  Donde <math> </math> $ en l√≠nea $ t_0, t_1 $ en l√≠nea $   etiquetas de la clase correcta, por ejemplo, si <math> </math> $ inline $ y_ {true} = cat $ inline $   entonces <math> </math> $ en l√≠nea $ t_0 == 1, t_1 == 0 $ en l√≠nea $   si <math> </math> $ en l√≠nea $ y_ {verdadero} = perro $ en l√≠nea $   entonces <math> </math> $ en l√≠nea $ t_0 == 0, t_1 == 1 $ en l√≠nea $   .  Por lo tanto, siempre se considera la probabilidad de una clase que deber√≠a haber sido predicha por una red neuronal (pero no necesariamente predicha por ella).  Ahora esto se puede generalizar a cualquier n√∫mero de clases (por ejemplo, m clases): <br><p><math> </math> $$ display $$ p (y_ {pred} = y_ {true} | \ Omega) = \ prod_0 ^ m p_i ^ {t_i} $$ display $$ </p><br>  Sin embargo, en cualquier conjunto de datos hay muchos objetos (por ejemplo, N objetos).  Quiero que la red neuronal d√© la respuesta correcta en cada uno o la mayor√≠a de los objetos.  Y para esto, debe multiplicar los resultados de la f√≥rmula anterior para cada objeto del conjunto de datos. <br><p><math> </math> $$ display $$ MaximumLikelyhood = \ prod_ {j = 0} ^ N \ prod_ {i = 0} ^ m p_ {i, j} ^ {t_ {i, j}} $$ display $$ </p><br>  Para obtener buenos resultados, esta funci√≥n necesita ser maximizada.  Pero, en primer lugar, es m√°s dif√≠cil de minimizar, porque tenemos un descenso de gradiente estoc√°stico y todos los bollos para ello, solo asigna un signo menos, y en segundo lugar, es dif√≠cil trabajar con un trabajo enorme: es el logaritmo. <br><p><math> </math> $$ display $$ CrossEntropyLoss = - \ sum \ limits_ {j = 0} ^ {N} \ sum \ limits_ {i = 0} ^ {m} t_ {i, j} \ cdot \ log (p_ {i, j }) $$ display $$ </p><br>  Genial  El resultado fue entrop√≠a cruzada o, en el caso binario, logloss.  Esta funci√≥n es f√°cil de contar e incluso m√°s f√°cil de diferenciar: <br><p><math> </math> $$ display $$ \ frac {\ partial CrossEntropyLoss} {\ partial p_j} = - \ frac {\ boldsymbol {t_j}} {\ boldsymbol {p_ {j}}} $$ display $$ </p><br>  Necesita diferenciar para el algoritmo de retropropagaci√≥n.  Observo que la funci√≥n de error no cambia la dimensi√≥n del vector.  Si, como en el caso de MNIST, la salida es un vector de respuestas de 10 dimensiones, entonces al calcular la derivada, obtenemos un vector de derivadas de 10 dimensiones.  Otra cosa interesante es que solo un elemento de la derivada no ser√° cero, en el cual <math> </math> $ en l√≠nea $ t_ {i, j} \ neq 0 $ en l√≠nea $   , es decir, con la respuesta correcta.  Y cuanto menor sea la probabilidad de una respuesta correcta predicha por una red neuronal en un objeto dado, mayor ser√° la funci√≥n de error. <br><br><h3>  Caracter√≠sticas de activaci√≥n </h3><br>  En la salida de cada capa completamente conectada de una red neuronal, debe estar presente una funci√≥n de activaci√≥n no lineal.  Sin ella, es imposible entrenar una red neuronal significativa.  Mirando hacia el futuro, una capa completamente conectada de una red neuronal es simplemente una multiplicaci√≥n de los datos de entrada por una matriz de peso.  En √°lgebra lineal, esto se llama un mapa lineal, una funci√≥n lineal.  La combinaci√≥n de funciones lineales es tambi√©n una funci√≥n lineal.  Pero esto significa que dicha funci√≥n solo puede aproximar funciones lineales.  Por desgracia, no es por eso que se necesitan redes neuronales. <br><br><h4>  Softmax </h4><br>  Por lo general, esta funci√≥n se usa en la √∫ltima capa de la red, ya que convierte el vector de la √∫ltima capa en un vector de "probabilidades": cada elemento del vector se encuentra entre 0 y 1 y su suma es 1. No cambia la dimensi√≥n del vector. <br><p><math> </math> $$ display $$ Softmax_i = \ frac {e ^ {x_i}} {\ sum \ limits_ {j} e ^ {x_j}} $$ display $$ </p><br>  Ahora pasemos a la b√∫squeda derivada.  Desde <math> </math> $ en l√≠nea $ \ boldsymbol {x} $ en l√≠nea $   Es un vector, y todos sus elementos siempre est√°n presentes en el denominador, luego, al tomar la derivada, obtenemos el jacobiano: <br><p><math> </math> $$ display $$ J_ {Softmax} = \ begin {cases} x_i - x_i \ cdot x_j, i = j \\ - x_i \ cdot x_j, i \ neq j \ end {cases} $$ display $$ </p><br>  Ahora sobre la propagaci√≥n hacia atr√°s.  El vector de derivados proviene de la capa anterior (por lo general, esta es una funci√≥n de error) <math> </math> $ en l√≠nea $ \ boldsymbol {dz} $ en l√≠nea $   .  En caso <math> </math> $ en l√≠nea $ \ boldsymbol {dz} $ en l√≠nea $   vino de una funci√≥n de error en mnist, <math> </math> $ en l√≠nea $ \ boldsymbol {dz} $ en l√≠nea $   - Vector de 10 dimensiones.  Entonces el jacobiano tiene una dimensi√≥n de 10x10.  Para obtener <math> </math> $ en l√≠nea $ \ boldsymbol {dz_ {new}} $ en l√≠nea $   , que va m√°s all√° de la capa anterior (no olvide que vamos desde el final hasta el comienzo de la red cuando el error se propaga), necesitamos multiplicar <math> </math> $ en l√≠nea $ \ boldsymbol {dz} $ en l√≠nea $   en <math> </math> $ en l√≠nea $ J_ {Softmax} $ en l√≠nea $   (fila por columna): <br><p><math> </math> $$ display $$ dz_ {new} = \ boldsymbol {dz} \ times J_ {Softmax} $$ display $$ </p><br>  En la salida, obtenemos un vector de derivadas de 10 dimensiones. <math> </math> $ en l√≠nea $ \ boldsymbol {dz_ {new}} $ en l√≠nea $   . <br><br><h4>  Relu </h4><br><p><math> </math> $$ display $$ ReLU (x) = \ begin {cases} x, x&gt; 0 \\ 0, x &lt;0 \ end {cases} $$ display $$ </p><br>  ReLU comenz√≥ a usarse de forma masiva despu√©s de 2011, cuando se public√≥ el art√≠culo "Redes neuronales de rectificador profundo disperso".  Sin embargo, dicha funci√≥n se conoc√≠a anteriormente.  El concepto de "poder de activaci√≥n" es aplicable a ReLU (para m√°s detalles, vea el libro "Aprendizaje profundo. Inmersi√≥n en el mundo de las redes neuronales").  Pero la caracter√≠stica principal que hace que ReLU sea m√°s atractivo que otras funciones de activaci√≥n es su c√°lculo derivado simple: <br><p><math> </math> $$ display $$ d (ReLU (x)) = \ begin {cases} 1, x&gt; 0 \\ 0, x &lt;0 \ end {cases} $$ display $$ </p><br>  Por lo tanto, ReLU es computacionalmente m√°s eficiente que otras funciones de activaci√≥n (sigmoide, tangente hiperb√≥lica, etc.). <br><br><h3>  Capa completamente conectada </h3><br>  Ahora es el momento de discutir una capa totalmente conectada.  El m√°s importante de todos los dem√°s, porque es en esta capa donde se ubican todos los pesos, que deben ajustarse para que la red neuronal funcione bien.  Una capa completamente conectada es simplemente una matriz de peso: <br><p><math> </math> $$ display $$ W = | w_ {i, j} | $$ display $$ </p><br>  Se obtiene una nueva representaci√≥n interna cuando la matriz de peso se multiplica por la columna de entrada: <br><p><math> </math> $$ display $$ \ boldsymbol {x} _ {new} = W \ cdot \ boldsymbol {x} $$ display $$ </p><br>  Donde <math> </math> $ en l√≠nea $ \ boldsymbol {x} $ en l√≠nea $   tiene tama√±o <math> </math> $ inline $ input \ _shape $ inline $   y <math> </math> $ en l√≠nea $ x_ {nuevo} $ en l√≠nea $   - <math> </math> $ inline $ output \ _shape $ inline $   .  Por ejemplo <math> </math> $ en l√≠nea $ \ boldsymbol {x} $ en l√≠nea $   - vector de 784 dimensiones, y <math> </math> $ en l√≠nea $ \ boldsymbol {x} _ {nuevo} $ en l√≠nea $   Es un vector de 100 dimensiones, entonces la matriz W tiene un tama√±o de 100x784.  Resulta que en esta capa es 100x784 = 78,400 pesos. <br><br>  Con la propagaci√≥n hacia atr√°s del error, uno necesita tomar la derivada con respecto a cada peso de esta matriz.  Simplifique el problema y tome solo la derivada con respecto a <math> </math> $ en l√≠nea $ w_ {1,1} $ en l√≠nea $   .  Al multiplicar la matriz y el vector, el primer elemento del nuevo vector <math> </math> $ en l√≠nea $ \ boldsymbol {x} _ {nuevo} $ en l√≠nea $   es igual a <math> </math> $ en l√≠nea $ x_ {nuevo ~ 1} = w_ {1,1} \ cdot x_1 + ... + w_ {1.784} \ cdot x_ {784} $ en l√≠nea $   y la derivada <math> </math> $ en l√≠nea $ x_ {nuevo ~ 1} $ en l√≠nea $   por <math> </math> $ en l√≠nea $ w_ {1,1} $ en l√≠nea $   ser√° simple <math> </math> $ en l√≠nea $ x_1 $ en l√≠nea $   , solo necesita tomar la derivada de la cantidad anterior.  Del mismo modo sucede para todos los dem√°s pesos.  Pero este no es un algoritmo de propagaci√≥n de error, siempre y cuando sea solo una matriz de derivados.  Debe recordar que de la siguiente capa a esta (el error va de principio a fin) viene un vector de gradiente de 100 dimensiones <math> </math> $ en l√≠nea $ d \ boldsymbol {z} $ en l√≠nea $   .  Primer elemento de este vector <math> </math> $ en l√≠nea $ dz_1 $ en l√≠nea $   se multiplicar√° por todos los elementos de la matriz de derivados que "participaron" en la creaci√≥n <math> </math> $ en l√≠nea $ x_ {nuevo ~ 1} $ en l√≠nea $   , es decir, en <math> </math> $ en l√≠nea $ x_1, x_2, ..., x_ {784} $ en l√≠nea $   .  Del mismo modo, el resto de los elementos.  Si traduces esto al lenguaje de √°lgebra lineal, entonces est√° escrito as√≠: <br><p><math> </math> $$ display $$ \ frac {\ partial L} {\ partial W} = (d \ boldsymbol {z}, ~ dW) = \ left (\ begin {matrix} dz_ {1} \ cdot \ boldsymbol {x} \ \ ... \\ dz_ {100} \ cdot \ boldsymbol {x} \ end {matrix} \ right) _ {100} $$ display $$ </p><br>  La salida es una matriz de 100x784. <br><img src="https://habrastorage.org/webt/1m/8_/hl/1m8_hljpr28gm3dikkgpsk4zss8.png"><br><br>  Ahora necesita comprender qu√© transferir a la capa anterior.  Para esto y para una mejor comprensi√≥n de lo que sucedi√≥ ahora, quiero escribir lo que sucedi√≥ al tomar derivados en esta capa en un lenguaje ligeramente diferente, para alejarme de los detalles de "lo que se multiplica por" a las funciones (nuevamente). <br><br>  Cuando quer√≠a ajustar los pesos, quer√≠a tomar la derivada de la funci√≥n de error para estos pesos: <math> </math> $ en l√≠nea $ \ frac {\ partial L} {\ partial W} $ en l√≠nea $   .  Se mostr√≥ arriba c√≥mo tomar derivados de funciones de error y funciones de activaci√≥n.  Por lo tanto, podemos considerar tal caso (en <math> </math> $ en l√≠nea $ d \ boldsymbol {z} $ en l√≠nea $   todas las derivadas de la funci√≥n de error y las funciones de activaci√≥n ya est√°n sentadas): <br><p><math> </math> $$ display $$ \ frac {\ partial L} {\ partial W} = d \ boldsymbol {z} \ cdot \ frac {\ partial \ boldsymbol {x} _ {new} (W)} {\ partial W} $ $ display $$ </p><br>  Esto se puede hacer, porque puedes considerar <math> </math> $ en l√≠nea $ \ boldsymbol {x} _ {nuevo} $ en l√≠nea $   en funci√≥n de W: <math> </math> $ en l√≠nea $ \ boldsymbol {x} _ {new} = W \ cdot \ boldsymbol {x} $ en l√≠nea $   . <br>  Puede sustituir esto en la f√≥rmula anterior: <br><br><p><math> </math> $$ display $$ \ frac {\ partial L} {\ partial W} = d \ boldsymbol {z} \ cdot \ frac {\ partial W \ cdot \ boldsymbol {x}} {\ partial W} = d \ boldsymbol { z} \ cdot E \ cdot \ boldsymbol {x} $$ display $$ </p><br>  Donde E es una matriz que consta de unidades (NO una matriz de unidades). <br><br>  Ahora, cuando necesite tomar la derivada de la capa anterior (incluso para simplificar los c√°lculos, tambi√©n ser√° una capa completamente conectada, pero en el caso general no cambia nada), entonces debe considerar <math> </math> $ en l√≠nea $ \ boldsymbol {x} $ en l√≠nea $   en funci√≥n de la capa anterior <math> </math> $ en l√≠nea $ \ boldsymbol {x} (W_ {old}) $ en l√≠nea $   : <br><p><math> </math> $$ display $$ \ begin {reunido} \ frac {\ partial L} {\ partial W_ {old}} = d \ boldsymbol {z} \ cdot \ frac {\ partial \ boldsymbol {x} _ {new} (W )} {\ partial W_ {old}} = d \ boldsymbol {z} \ cdot \ frac {\ partial W \ cdot \ boldsymbol {x} (W_ {old})} {\ partial W_ {old}} = \\ = d \ boldsymbol {z} \ cdot \ frac {\ partial W \ cdot W_ {old} \ cdot \ boldsymbol {x} _ {old}} {\ partial W_ {old}} = d \ boldsymbol {z} \ cdot W \ cdot E \ cdot \ boldsymbol {x} _ {old} = \\ = d \ boldsymbol {z} _ {new} \ cdot E \ cdot \ boldsymbol {x} _ {old} \ end {reunido} $$ mostrar $$ </p><br>  Exactamente <math> </math> $ en l√≠nea $ d \ boldsymbol {z} _ {new} = d \ boldsymbol {z} \ cdot W $ en l√≠nea $   y necesitas enviar a la capa anterior. <br><br><h2>  C√≥digo </h2><br><blockquote>  Este art√≠culo est√° dirigido principalmente a explicar las matem√°ticas de las redes neuronales.  Dedicar√© muy poco tiempo al c√≥digo. </blockquote><br>  Este es un ejemplo de implementaci√≥n de la funci√≥n de error: <br><br><pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CrossEntropy</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, y_true, y_hat)</span></span></span><span class="hljs-function">:</span></span> self.y_hat = y_hat self.y_true = y_true self.loss = -np.sum(self.y_true * np.log(y_hat)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.loss <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> dz = -self.y_true / self.y_hat <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dz</code> </pre> <br>  La clase tiene m√©todos para el pase directo e inverso.  En el momento del pase directo, la instancia de clase almacena los datos dentro de la capa y, en el momento del pase de retorno, los usa para calcular el gradiente.  Las capas restantes se construyen de la misma manera.  Gracias a esto, es posible escribir un neural completamente conectado en este estilo: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MnistNet</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.d1_layer = Dense(<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>) self.a1_layer = ReLu() self.drop1_layer = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>) self.d2_layer = Dense(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>) self.a2_layer = ReLu() self.drop2_layer = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>) self.d3_layer = Dense(<span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) self.a3_layer = Softmax() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, train=True)</span></span></span><span class="hljs-function">:</span></span> ... <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, dz, learning_rate=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.01</span></span></span></span><span class="hljs-function"><span class="hljs-params">, mini_batch=True, update=False, len_mini_batch=None)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre><br>  El c√≥digo completo se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br>  Tambi√©n aconsejo estudiar este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo sobre Habr√©</a> . <br><br><h2>  Conclusi√≥n </h2><br>  Espero haber podido explicar y demostrar que las redes neuronales est√°n detr√°s de una matem√°tica bastante simple y que esto no da miedo en absoluto.  Sin embargo, para una comprensi√≥n m√°s profunda, vale la pena intentar escribir su propia "bicicleta".  Correcciones y sugerencias est√°n felices de leer en los comentarios. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/460589/">https://habr.com/ru/post/460589/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../460567/index.html">React Native: crea una lista arrastrable y deslizable</a></li>
<li><a href="../460569/index.html">Software de escritura con la funcionalidad de las utilidades cliente-servidor Windows, parte 01</a></li>
<li><a href="../460573/index.html">Google afirma que "reCAPTCHA" no abusa de los datos del usuario. ¬øVale la pena creerlo?</a></li>
<li><a href="../460577/index.html">Larga vida al rey: cruel mundo de la jerarqu√≠a en una jaur√≠a de perros callejeros</a></li>
<li><a href="../460587/index.html">M√≥dulo inal√°mbrico para sensor capacitivo de humedad del suelo en nRF52832</a></li>
<li><a href="../460591/index.html">Obtenci√≥n de root en un enrutador Tenda Nova MW6</a></li>
<li><a href="../460593/index.html">"Universal" en el equipo de desarrollo: ¬øbeneficio o da√±o?</a></li>
<li><a href="../460597/index.html">C√≥mo diagnosticar problemas de integraci√≥n de SDK. La experiencia del equipo de desarrollo de Yandex Mobile Ads SDK</a></li>
<li><a href="../460599/index.html">Noticias del mundo de OpenStreetMap No. 468 (07/02/2019 - 08/07/2019)</a></li>
<li><a href="../460603/index.html">V2G. Los autos el√©ctricos ayudar√°n a equilibrar la producci√≥n y el consumo de electricidad.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
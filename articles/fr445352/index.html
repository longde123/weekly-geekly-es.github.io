<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ûüèø üëêüèø üé® Spark Structured Streaming Applications sur Kubernetes. D√©couvrez FASTEN RUS üçä ‚ö∞Ô∏è üë©‚Äçüë©‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Aujourd'hui, je vais vous dire comment nous avons r√©ussi √† r√©soudre le probl√®me du portage d' applications de streaming structur√© Spark vers Kubernete...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark Structured Streaming Applications sur Kubernetes. D√©couvrez FASTEN RUS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445352/">  Aujourd'hui, je vais vous dire comment nous avons r√©ussi √† r√©soudre le probl√®me du portage d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">applications de streaming structur√© Spark</a> vers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes</a> (K8s) et √† mettre en ≈ìuvre le streaming CI. <br><a name="habracut"></a><br><h4>  <i><b>Comment tout a commenc√©?</b></i> </h4><br>  Le streaming est un √©l√©ment cl√© de la plateforme FASTEN RUS BI.  Les donn√©es en temps r√©el sont utilis√©es par l'√©quipe d'analyse des dates pour cr√©er des rapports op√©rationnels. <br><br>  Les applications de streaming sont impl√©ment√©es √† l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Spark Structured Streaming</a> .  Ce cadre fournit une API de transformation de donn√©es pratique qui r√©pond √† nos besoins en termes de rapidit√© d'am√©liorations. <br><br>  Les flux eux-m√™mes ont augment√© sur le cluster <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AWS EMR</a> .  Ainsi, lors de la g√©n√©ration d'un nouveau flux vers le cluster, un script ssh a √©t√© pr√©sent√© pour soumettre des travaux Spark, apr√®s quoi l'application a √©t√© lanc√©e.  Et au d√©but, tout semblait nous convenir.  Mais avec le nombre croissant de flux, le besoin de streaming CI est devenu de plus en plus √©vident, ce qui augmenterait l'autonomie de la commande d'analyse de date lors du lancement d'applications pour fournir des donn√©es sur de nouvelles entit√©s. <br><br>  Et maintenant, nous allons voir comment nous avons r√©ussi √† r√©soudre ce probl√®me en portant le streaming sur Kubernetes. <br><br><h4>  <i><b>Pourquoi Kubernetes?</b></i> </h4><br>  Kubernetes, en tant que gestionnaire de ressources, r√©pondait le mieux √† nos besoins.  Il s'agit d'un d√©ploiement sans temps d'arr√™t et d'une large gamme d'outils d'impl√©mentation CI sur Kubernetes, y compris Helm.  De plus, notre √©quipe avait une expertise suffisante dans la mise en ≈ìuvre des pipelines CI sur les K8.  Par cons√©quent, le choix √©tait √©vident. <br><br><h4>  <i><b>Comment le mod√®le de gestion des applications Spark bas√© sur Kubernetes est-il organis√©?</b></i> </h4><br><img src="https://habrastorage.org/webt/ms/rz/fv/msrzfvb4_7eqjzokg2cuvplcerm.png"><br><br>  Le client ex√©cute spark-submit sur les K8.  Un module de pilote d'application est cr√©√©.  Kubernetes Scheduler lie un pod √† un n≈ìud de cluster.  Ensuite, le pilote envoie une demande de cr√©ation de pods pour ex√©cuter les ex√©cutifs, les pods sont cr√©√©s et attach√©s aux n≈ìuds du cluster.  Apr√®s cela, un ensemble standard d'op√©rations est effectu√© avec la conversion ult√©rieure du code d'application en DAG, la d√©composition en √©tapes, la d√©composition en t√¢ches et leur ex√©cution sur des ex√©cutables. <br><br>  Ce mod√®le fonctionne assez bien lors du d√©marrage manuel des applications Spark.  Cependant, l'approche de lancement de spark-submit en dehors du cluster ne nous convenait pas en termes d'impl√©mentation de CI.  Il √©tait n√©cessaire de trouver une solution qui permettrait √† Spark de s'ex√©cuter (effectuer la soumission d'√©tincelles) directement sur les n≈ìuds du cluster.  Et ici, le mod√®le Kubernetes Operator r√©pondait pleinement √† nos exigences. <br><br><h4>  <i><b>Op√©rateur Kubernetes en tant que mod√®le de gestion du cycle de vie des applications Spark</b></i> </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes Operator</a> est un concept de gestion des applications d'√©tat dans Kubernetes, propos√© par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CoreOS</a> , qui implique l'automatisation des t√¢ches op√©rationnelles, telles que le d√©ploiement d'applications, le red√©marrage des applications en cas de fichiers, la mise √† jour de la configuration des applications.  L'un des principaux mod√®les d'op√©rateur Kubernetes est CRD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CustomResourceDefinitions</a> ), qui implique l'ajout de ressources personnalis√©es au cluster K8s, qui, √† son tour, vous permet de travailler avec ces ressources comme avec les objets Kubernetes natifs. <br><br>  L'op√©rateur est un d√©mon qui vit dans le pod du cluster et r√©pond √† la cr√©ation / modification de l'√©tat d'une ressource personnalis√©e. <br><br>  Consid√©rez ce concept pour la gestion du cycle de vie des applications Spark. <br><br><img src="https://habrastorage.org/webt/an/ei/gt/aneigtq-0jc8fhtryimgh3orfaw.png"><br><br>  L'utilisateur ex√©cute la commande kubectl apply -f spark-application.yaml, o√π spark-application.yaml est la sp√©cification de l'application Spark.  L'op√©rateur re√ßoit l'objet d'application Spark et ex√©cute spark-submit. <br><br>  Comme nous pouvons le voir, le mod√®le Kubernetes Operator implique de g√©rer le cycle de vie d'une application Spark directement dans le cluster Kubernetes, ce qui √©tait un argument s√©rieux en faveur de ce mod√®le dans le cadre de la r√©solution de nos probl√®mes. <br><br>  En tant qu'op√©rateur Kubernetes pour la gestion des applications de streaming, il a √©t√© d√©cid√© d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">spark-on-k8s-operator</a> .  Cet op√©rateur offre une API assez pratique, ainsi qu'une flexibilit√© dans la configuration de la politique de red√©marrage pour les applications Spark (ce qui est assez important dans le contexte de la prise en charge des applications de streaming). <br><br><h4>  <i><b>Impl√©mentation CI</b></i> </h4><br>  Pour impl√©menter le streaming CI, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitLab CI / CD a √©t√© utilis√©</a> .  Le d√©ploiement des applications Spark sur les K8 a √©t√© r√©alis√© √† l'aide des outils <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Helm</a> . <br><br>  Le pipeline lui-m√™me comprend 2 √©tapes: <br><br><ul><li>  test - la v√©rification de la syntaxe est effectu√©e, ainsi que le rendu des mod√®les Helm; </li><li>  deploy - d√©ploiement d'applications de streaming vers les environnements de test (dev) et de produit (prod). </li></ul><br>  Examinons ces √©tapes plus en d√©tail. <br><br>  Au stade du test, le mod√®le de <a href="">barre d'</a> application Spark (CRD - <a href="">SparkApplication</a> ) est <a href="">rendu</a> avec des valeurs sp√©cifiques √† l'environnement. <br><br>  Les sections cl√©s du mod√®le Helm sont les suivantes: <br><ol><li>  √©tincelle: <br><ul><li>  version - Version Apache Spark </li><li>  image - Image Docker utilis√©e </li></ul></li><li>  nodeSelector - contient une liste (cl√© ‚Üí valeur) correspondant aux √©tiquettes des foyers. </li><li>  Tol√©rances - indique la liste des tol√©rances de l'application Spark. </li><li>  mainClass - Classe d'application Spark </li><li>  applicationFile - chemin local o√π se trouve le bocal d'application Spark </li><li>  restartPolicy - Strat√©gie de red√©marrage de l'application Spark <br><ul><li>  Jamais - l'application Spark termin√©e ne red√©marre pas </li><li>  Toujours - l'application Spark termin√©e red√©marre quelle que soit la raison de l'arr√™t. </li><li>  OnFailure - L'application Spark ne red√©marre qu'en cas de fichier </li></ul></li><li>  maxSubmissionRetries - nombre maximal de soumissions d'une application Spark </li><li>  pilote / ex√©cuteur: <br><ul><li>  cores - le nombre de noyaux allou√©s au pilote / ex√©cuteur </li><li>  instances (utilis√©es uniquement pour la configuration des cadres) - le nombre de cadres </li><li>  memory - la quantit√© de m√©moire allou√©e au processus pilote / ex√©cuteur </li><li>  memoryOverhead - la quantit√© de m√©moire hors segment allou√©e au pilote / ex√©cuteur </li></ul></li><li>  flux: <br><ul><li>  name - nom de l'application de streaming </li><li>  arguments - arguments pour l'application de streaming </li></ul></li><li>  sink - le chemin vers les jeux de donn√©es Data Lake sur S3 </li></ol><br>  Apr√®s avoir rendu le mod√®le, les applications sont d√©ploy√©es dans l'environnement de test de d√©veloppement √† l'aide de Helm. <br><br>  √âlaboration du pipeline CI. <br><br><img src="https://habrastorage.org/webt/ah/za/br/ahzabrhmjpduar2y7ug3xzn90lu.png"><br><br>  Ensuite, nous lan√ßons le travail deploy-prod - lancement d'applications en production. <br><br>  Nous sommes convaincus de la r√©ussite de l'emploi. <br><br><img src="https://habrastorage.org/webt/md/-h/0e/md-h0e0u3mwccnncq7t2qqzaf5i.png"><br><br>  Comme nous pouvons le voir ci-dessous, les applications sont en cours d'ex√©cution, les pods sont √† l'√©tat RUNNING. <br><br><img src="https://habrastorage.org/webt/ce/4i/cc/ce4iccuv7vkzintbor0tyjtae88.png"><br><br><h4>  <i><b>Conclusion</b></i> </h4><br>  Le portage d'applications de streaming structur√© Spark sur K8 et l'impl√©mentation ult√©rieure de CI nous ont permis d'automatiser le lancement de flux pour la livraison de donn√©es √† de nouvelles entit√©s.  Pour augmenter le flux suivant, il suffit de pr√©parer une demande de fusion avec une description de la configuration de l'application Spark dans le fichier de valeurs yaml et lorsque le travail deploy-prod d√©marre, la livraison des donn√©es √† Data Lake (S3) sera lanc√©e.  Cette solution garantissait l'autonomie de la commande d'analyse de date lors de l'ex√©cution de t√¢ches li√©es √† l'ajout de nouvelles entit√©s au r√©f√©rentiel.  De plus, le portage de la diffusion en continu sur K8 et, en particulier, la gestion des applications Spark √† l'aide de l'op√©rateur spark-on-k8s de Kubernetes Operator a consid√©rablement augment√© la r√©silience de la diffusion.  Mais plus √† ce sujet dans le prochain article. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445352/">https://habr.com/ru/post/fr445352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445340/index.html">Augmentez la s√©curit√© du r√©seau en utilisant un analyseur cloud</a></li>
<li><a href="../fr445344/index.html">Plateforme de communications unifi√©es OpenVox</a></li>
<li><a href="../fr445346/index.html">Comment √©crire une mauvaise API</a></li>
<li><a href="../fr445348/index.html">SNA Hackathon 2019: Simplify Architecture - Simplify Features</a></li>
<li><a href="../fr445350/index.html">Sonata - Serveur d'approvisionnement SIP</a></li>
<li><a href="../fr445354/index.html">Trouver des objets en images</a></li>
<li><a href="../fr445356/index.html">Aper√ßu de la section mobile √† DUMP-2019: maximum appliqu√© et utile dans le travail quotidien</a></li>
<li><a href="../fr445358/index.html">Organisation du syst√®me d'√©v√©nements dans Unity - √† travers les yeux d'un game designer</a></li>
<li><a href="../fr445360/index.html">5 t√¢ches typiques pour les interviews JavaScript: analyse et solutions</a></li>
<li><a href="../fr445362/index.html">Le livre "Distributed Systems. Mod√®les de conception</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
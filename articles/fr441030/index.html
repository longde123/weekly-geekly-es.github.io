<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏹 👩🏾‍🌾 🤲🏼 Détection des attaques Web avec un autoencodeur Seq2Seq 🈲 👲🏾 🧑🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La détection des attaques fait partie de la sécurité des informations depuis des décennies. Les premières implémentations connues du système de détect...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Détection des attaques Web avec un autoencodeur Seq2Seq</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pt/blog/441030/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/5ad/baf/742/5adbaf742fa07b485b70886943da8036.png" alt="image"></a> <br><br>  La détection des attaques fait partie de la sécurité des informations depuis des décennies.  Les premières implémentations connues du système de détection d'intrusion (IDS) remontent au début des années 80. <br><br>  De nos jours, il existe toute une industrie de détection d'attaque.  Il existe un certain nombre de types de produits - tels que les solutions IDS, IPS, WAF et pare-feu - dont la plupart offrent une détection d'attaque basée sur des règles.  L'idée d'utiliser une sorte de détection d'anomalies statistiques pour identifier les attaques en production ne semble pas aussi réaliste qu'auparavant.  Mais cette hypothèse est-elle justifiée? <a name="habracut"></a><br><br><h2>  Détection d'anomalies dans les applications Web </h2><br>  Les premiers pare-feu conçus pour détecter les attaques d'applications Web sont apparus sur le marché au début des années 1990.  Les techniques d'attaque et les mécanismes de protection ont évolué considérablement depuis lors, les attaquants se précipitant pour prendre une longueur d'avance. <br><br>  La plupart des pare-feu d'applications Web (WAF) actuels tentent de détecter les attaques de manière similaire, avec un moteur basé sur des règles intégré dans un proxy inverse d'un certain type.  L'exemple le plus important est mod_security, un module WAF pour le serveur Web Apache, qui a été créé en 2002. La détection basée sur des règles présente certains inconvénients: par exemple, elle ne parvient pas à détecter de nouvelles attaques (zéro jour), même si ces mêmes attaques pourrait facilement être détecté par un expert humain.  Ce fait n'est pas surprenant, car le cerveau humain fonctionne très différemment d'un ensemble d'expressions régulières. <br><br>  Du point de vue d'un WAF, les attaques peuvent être divisées en attaques séquentielles (séries temporelles) et celles consistant en une seule requête ou réponse HTTP.  Nos recherches se sont concentrées sur la détection de ce dernier type d'attaques, notamment: <br><br><ul><li>  Injection SQL </li><li>  Scriptage intersite </li><li>  Injection d'entité externe XML </li><li>  Traversée de chemin </li><li>  OS commandant </li><li>  Injection d'objets </li></ul><br>  Mais d'abord, posons-nous la question: comment un humain le ferait-il? <br><br><h2>  Que ferait un humain en voyant une seule demande </h2><br>  Jetez un œil à un exemple de requête HTTP régulière vers une application: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/112/aa6/d1d/112aa6d1d1cc3798f89a7b39fd0aad4c.png" alt="image"><br><br>  Si vous deviez détecter des demandes malveillantes envoyées à une application, il est fort probable que vous souhaitiez observer les demandes bénignes pendant un certain temps.  Après avoir examiné les demandes d'un certain nombre de points de terminaison d'exécution d'application, vous auriez une idée générale de la structure des demandes sécurisées et de leur contenu. <br><br>  Maintenant, vous êtes présenté avec la demande suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/28b/be1/487/28bbe1487cb08fc21fee85bdc1f259b5.png" alt="image"><br><br>  Vous avez immédiatement l'impression que quelque chose ne va pas.  Il faut un peu plus de temps pour comprendre exactement quoi, et dès que vous localisez la partie exacte de la demande qui est anormale, vous pouvez commencer à réfléchir au type d'attaque dont il s'agit.  Essentiellement, notre objectif est de faire en sorte que notre IA de détection d'attaque aborde le problème d'une manière qui ressemble à ce raisonnement humain. <br><br>  Pour compliquer notre tâche, un certain trafic, même s'il peut sembler malveillant à première vue, peut en fait être normal pour un site Web particulier. <br><br>  Par exemple, examinons la demande suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7c3/11e/a25/7c311ea25d363c43c6559429f1bf8991.png" alt="image"><br><br>  Est-ce une anomalie?  En fait, cette demande est bénigne: il s'agit d'une demande typique liée à la publication de bogues sur le traqueur de bogues Jira. <br><br>  Voyons maintenant un autre cas: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b03/57c/884/b0357c884e2b3c3dd19a8733da973a62.png" alt="image"><br><br>  Au début, la demande ressemble à une inscription d'utilisateur typique sur un site Web propulsé par le CMS Joomla.  Cependant, l'opération demandée est «user.register» au lieu du «registration.register» normal.  L'ancienne option est obsolète et contient une vulnérabilité permettant à quiconque de s'inscrire en tant qu'administrateur. <br><br>  Cet exploit est connu sous le nom de «Joomla &lt;3.6.4 Account Creation / Privilege Escalation» (CVE-2016-8869, CVE-2016-8870). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/45b/a08/994/45ba089942a993c3e4d32fd5f8f744a6.png" alt="image"><br><br><h2>  Comment nous avons commencé </h2><br>  Nous avons d'abord examiné les recherches précédentes, car de nombreuses tentatives pour créer différents algorithmes statistiques ou d'apprentissage automatique pour détecter les attaques ont été faites au fil des décennies.  L'une des approches les plus fréquentes consiste à résoudre la tâche d'affectation à une classe («requête bénigne», «injection SQL», «XSS», «CSRF», etc.).  Bien que l'on puisse atteindre une précision décente avec la classification pour un ensemble de données donné, cette approche ne résout pas certains problèmes très importants: <br><br><ol><li>  <b>Le choix de l'ensemble de classe</b> .  Et si votre modèle pendant l'apprentissage est présenté avec trois classes («bénigne», «SQLi», «XSS») mais en production, il rencontre une attaque CSRF ou même une toute nouvelle technique d'attaque? </li><li>  <b>Le sens de ces classes</b> .  Supposons que vous deviez protéger 10 clients, chacun d'eux exécutant des applications Web complètement différentes.  Pour la plupart d'entre eux, vous n'auriez aucune idée de ce à quoi ressemble une seule attaque «Injection SQL» contre leur application.  Cela signifie que vous devrez en quelque sorte construire artificiellement vos ensembles de données d'apprentissage - ce qui est une mauvaise idée, car vous finirez par apprendre à partir de données avec une distribution complètement différente de vos données réelles. </li><li>  <b>Interprétabilité des résultats de votre modèle</b> .  Très bien, le modèle a donc créé le label «Injection SQL» - et maintenant?  Vous et surtout votre client, qui est le premier à voir l'alerte et qui n'est généralement pas un expert en attaques Web, devez deviner quelle partie de la demande le modèle considère comme malveillante. </li></ol><br>  Gardant cela à l'esprit, nous avons décidé d'essayer la classification de toute façon. <br><br>  Comme le protocole HTTP est basé sur du texte, il était évident que nous devions jeter un œil aux classificateurs de texte modernes.  L'un des exemples bien connus est l'analyse des sentiments de l'ensemble de données de revue de films IMDB.  Certaines solutions utilisent des réseaux de neurones récurrents (RNN) pour classer ces revues.  Nous avons décidé d'utiliser un modèle de classification RNN similaire avec quelques légères différences.  Par exemple, les RNN de classification en langage naturel utilisent des incorporations de mots, mais il n'est pas clair quels mots il y a dans un langage non naturel comme HTTP.  C'est pourquoi nous avons décidé d'utiliser des incorporations de caractères dans notre modèle. <br><br>  Les intégrations prêtes à l'emploi ne sont pas pertinentes pour résoudre le problème, c'est pourquoi nous avons utilisé des mappages simples de caractères avec des codes numériques avec plusieurs marqueurs internes tels que <b>GO</b> et <b>EOS</b> . <br>  Après avoir terminé le développement et les tests du modèle, tous les problèmes prédits plus tôt se sont produits, mais au moins notre équipe est passée d'une réflexion au ralenti à quelque chose de productif. <br><br><h2>  Comment nous avons procédé </h2><br>  À partir de là, nous avons décidé d'essayer de rendre les résultats de notre modèle plus interprétables.  À un moment donné, nous sommes tombés sur le mécanisme de «l'attention» et avons commencé à l'intégrer dans notre modèle.  Et cela a donné des résultats prometteurs: finalement, tout s'est réuni et nous avons obtenu des résultats interprétables par l'homme.  Maintenant, notre modèle a commencé à produire non seulement les étiquettes mais aussi les coefficients d'attention pour chaque caractère de l'entrée. <br><br>  Si cela pouvait être visualisé, par exemple, dans une interface Web, nous pourrions colorer l'endroit exact où une attaque «Injection SQL» a été trouvée.  C'est un résultat prometteur, mais les autres problèmes restent en suspens. <br><br>  Nous avons commencé à voir que nous pouvions bénéficier en allant dans le sens du mécanisme d'attention et en s'éloignant de la classification.  Après avoir lu de nombreuses recherches connexes (par exemple, «L'attention est tout ce dont vous avez besoin», Word2Vec et les architectures codeur-décodeur) sur les modèles de séquence et en expérimentant nos données, nous avons pu créer un modèle de détection d'anomalies qui fonctionnerait dans plus ou moins de la même manière qu'un expert humain. <br><br><h2>  Codeurs automatiques </h2><br>  À un moment donné, il est devenu clair qu'un encodeur automatique séquence à séquence convenait le mieux à notre objectif. <br>  Un modèle de séquence à séquence se compose de deux modèles de mémoire multicouche à long terme (LSTM): un codeur et un décodeur.  Le codeur mappe la séquence d'entrée à un vecteur de dimensionnalité fixe.  Le décodeur décode le vecteur cible à l'aide de cette sortie du codeur. <br><br>  Un encodeur automatique est donc un modèle de séquence à séquence qui définit ses valeurs cibles égales à ses valeurs d'entrée.  L'idée est d'apprendre au réseau à recréer ce qu'il a vu, ou, en d'autres termes, à rapprocher une fonction d'identité.  Si l'autoencodeur formé reçoit un échantillon anormal, il est susceptible de le recréer avec un degré d'erreur élevé car il n'a jamais vu un tel échantillon auparavant. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2b/d99/fb1/b2bd99fb15aff53c214892c8d8a36642.png" alt="image"><br><br><h2>  Le code </h2><br>  Notre solution est composée de plusieurs parties: initialisation du modèle, formation, prédiction et validation. <br>  La plupart du code situé dans le référentiel est explicite, nous nous concentrerons uniquement sur les parties importantes. <br><br>  Le modèle est initialisé en tant qu'instance de la classe Seq2Seq, qui a les arguments de constructeur suivants: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b5/183/1f3/0b51831f349befe5753636bda5da404c.png" alt="image"><br><br>  Après cela, les couches de l'encodeur automatique sont initialisées.  Tout d'abord, l'encodeur: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ba/0e0/f7e/5ba0e0f7e354312048f8c3945436af16.png" alt="image"><br><br>  Et puis le décodeur: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fd4/c9c/d5e/fd4c9cd5ef2e4fca445e18dc9d25ff29.png" alt="image"><br><br>  Puisque nous essayons de résoudre la détection d'anomalies, les cibles et les entrées sont les mêmes.  Ainsi, notre feed_dict ressemble à ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e6/7e3/04a/6e67e304a01caa06d4f366327a1d5ef3.png" alt="image"><br><br>  Après chaque époque, le meilleur modèle est enregistré en tant que point de contrôle, qui peut ensuite être chargé pour faire des prédictions.  À des fins de test, une application Web en direct a été configurée et protégée par le modèle afin qu'il soit possible de tester si les attaques réelles ont réussi ou non. <br><br>  Inspirés par le mécanisme d'attention, nous avons essayé de l'appliquer à l'autoencodeur mais nous avons remarqué que les probabilités produites par la dernière couche fonctionnent mieux pour marquer les parties anormales d'une demande. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/56d/748/22e/56d74822e5ee1a376db9d8c79b71769b.png" alt="image"><br><br>  Au stade des tests avec nos échantillons, nous avons obtenu de très bons résultats: la précision et le rappel étaient proches de 0,99.  Et la courbe ROC était d'environ 1. Certainement une belle vue! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/be8/eb4/21f/be8eb421f44d245b553dd71846157aff.png" alt="image"><br><br><h2>  Les résultats </h2><br>  Notre modèle d'autoencodeur Seq2Seq décrit s'est révélé capable de détecter des anomalies dans les requêtes HTTP avec une grande précision. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ad/baf/742/5adbaf742fa07b485b70886943da8036.png" alt="image"><br><br>  Ce modèle agit comme un humain: il n'apprend que les requêtes utilisateur «normales» envoyées à une application web.  Il détecte les anomalies dans les demandes et met en évidence la place exacte dans la demande considérée comme anormale.  Nous avons évalué ce modèle contre les attaques sur l'application de test et les résultats semblent prometteurs.  Par exemple, la capture d'écran précédente montre comment notre modèle a détecté une injection SQL répartie sur deux paramètres de formulaire Web.  Ces injections SQL sont fragmentées, car la charge utile d'attaque est fournie dans plusieurs paramètres HTTP.  Les WAF classiques basés sur des règles ne détectent pas correctement les tentatives d'injection SQL fragmentées car ils inspectent généralement chaque paramètre séparément. <br><br>  Le code du modèle et les données de train / test ont été publiés sous forme de cahier Jupyter afin que chacun puisse reproduire nos résultats et suggérer des améliorations. <br><br><h2>  Conclusion </h2><br>  Nous pensons que notre tâche était assez simple: trouver un moyen de détecter les attaques avec un minimum d'effort.  D'une part, nous avons cherché à éviter de trop compliquer la solution et à créer un moyen de détecter les attaques qui, comme par magie, apprennent à décider par elles-mêmes ce qui est bon et ce qui est mauvais.  En même temps, nous voulions éviter les problèmes avec le facteur humain lorsqu'un expert (faillible) décide ce qui indique une attaque et ce qui ne l’est pas.  Et donc globalement, l'autoencodeur avec l'architecture Seq2Seq semble résoudre très bien notre problème de détection des anomalies. <br><br>  Nous voulions également résoudre le problème de l'interprétabilité des données.  Lors de l'utilisation d'architectures de réseaux neuronaux complexes, il est très difficile d'expliquer un résultat particulier.  Lorsqu'une série entière de transformations est appliquée, l'identification des données les plus importantes derrière une décision devient presque impossible.  Cependant, après avoir repensé l'approche de l'interprétation des données par le modèle, nous avons pu obtenir des probabilités pour chaque caractère de la dernière couche. <br><br>  Il est important de noter que cette approche n'est pas une version prête pour la production.  Nous ne pouvons pas divulguer les détails de la façon dont cette approche pourrait être mise en œuvre dans un produit réel.  Mais nous vous avertirons qu'il n'est pas possible de simplement prendre ce travail et de le "brancher".  Nous faisons cette mise en garde car après la publication sur GitHub, nous avons commencé à voir certains utilisateurs qui tentaient simplement d'implémenter notre solution actuelle en gros dans leurs propres projets, avec des résultats infructueux (et sans surprise). <br><br>  La preuve de concept est disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> (github.com). <br><br>  Auteurs: Alexandra Murzina ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">murzina_a</a> ), Irina Stepanyuk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub</a> ), Fedor Sakharov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub</a> ), Arseny Reutov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">Raz0r</a> ) <br><br><h3>  Lectures complémentaires </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comprendre les réseaux LSTM</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Réseaux de neurones récurrents augmentés et attention</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'attention est tout ce dont vous avez besoin</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'attention est tout ce dont vous avez besoin (annoté)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tutoriel de traduction automatique de neurones (seq2seq)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Codeurs automatiques</a> </li><li>  <a href="">Apprentissage de séquence en séquence avec les réseaux de neurones</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Construire des encodeurs automatiques à Keras</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441030/">https://habr.com/ru/post/fr441030/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441020/index.html">Comment VTB est venu à une seule connaissance</a></li>
<li><a href="../fr441022/index.html">Erreurs courantes des passagers des chemins de fer et des compagnies aériennes</a></li>
<li><a href="../fr441024/index.html">Nous écrivons un robot pour un ou deux 1.0</a></li>
<li><a href="../fr441026/index.html">VMware NSX pour les plus petits. Partie 2. Configuration du pare-feu et du NAT</a></li>
<li><a href="../fr441028/index.html">Comment les chercheurs découvrent les bases de données ouvertes MongoDB et Elasticsearch</a></li>
<li><a href="../fr441032/index.html">KeeBee Créer son propre clavier USB à partir de zéro</a></li>
<li><a href="../fr441034/index.html">6 points de croissance de conversion ou comment augmenter la confiance en utilisant un téléphone sur le site</a></li>
<li><a href="../fr441036/index.html">Comment donner et recevoir des commentaires si vous êtes moineau-sociophobus</a></li>
<li><a href="../fr441040/index.html">Génération d'icônes multi-plateformes multi-marques avec Sketch et un script Node.js - Partie # 1</a></li>
<li><a href="../fr441042/index.html">Génération d'icônes multi-plateformes multi-marques avec Sketch et un script Node.js - Partie # 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
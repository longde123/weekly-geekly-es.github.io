<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöµ üçÅ üîù Optimiser la distribution en rack des serveurs üå´Ô∏è üëçüèø üßòüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans l'un des chats, on m'a pos√© une question: 

 - Et il y a quelque chose √† lire, comment emballer correctement les serveurs dans des racks? 

 J'ai...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimiser la distribution en rack des serveurs</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/474112/"> Dans l'un des chats, on m'a pos√© une question: <br><br>  - Et il y a quelque chose √† lire, comment emballer correctement les serveurs dans des racks? <br><br>  J'ai r√©alis√© que je ne connaissais pas un tel texte, alors j'ai √©crit le mien. <br><br>  Premi√®rement, ce texte concerne les serveurs physiques dans les centres de donn√©es physiques (DC).  Deuxi√®mement, nous pensons qu'il y a beaucoup de serveurs: des centaines ou des milliers, pour un plus petit nombre ce texte n'a pas de sens.  Troisi√®mement, nous pensons que nous avons trois limiteurs: l'espace physique dans les racks, l'alimentation du rack et laisser les racks se tenir en rang√©es, afin que nous puissions utiliser un commutateur ToR pour connecter les serveurs dans les racks voisins. <br><a name="habracut"></a><br>  La r√©ponse √† la question d√©pend grandement du param√®tre que nous optimisons et de ce que nous pouvons varier afin d'obtenir le meilleur r√©sultat.  Par exemple, il suffit de prendre un minimum d'espace pour en laisser plus pour une croissance future.  Ou peut-√™tre que nous avons la libert√© de choisir la hauteur des racks, la puissance par rack, les prises dans la PDU, le nombre de racks dans un groupe de commutateurs (un commutateur pour 1, 2 ou 3 racks), la longueur des fils et le travail de traction (cela est critique √† la fin des rang√©es: avec 10 racks d'affil√©e et 3 racks sur l'interrupteur, vous devrez tirer les fils dans une autre rang√©e ou sous-utiliser les ports de l'interrupteur), etc., etc.  Histoires distinctes: s√©lection du serveur et s√©lection DC, nous supposons qu'elles sont s√©lectionn√©es. <br><br>  Il serait int√©ressant de comprendre certaines nuances et d√©tails, en particulier la consommation moyenne / maximale des serveurs et la fa√ßon dont nous sommes aliment√©s en √©lectricit√©.  Donc, si nous avons une alimentation russe de 230 V et une phase par rack, une machine de 32 A peut contenir environ 7 kW.  Supposons que nous payons nominalement 6 kW par rack.  Si un fournisseur mesure notre consommation uniquement pour une s√©rie de 10 racks, et non pour chaque rack, et si la machine est √† une coupure conventionnelle de 7 kW, alors techniquement, nous pouvons engloutir 6,9 kW dans un rack s√©par√©, dans un autre 5,1 kW et tout ira bien - pas punissable. <br><br>  G√©n√©ralement, notre objectif principal est de minimiser les co√ªts.  Le meilleur crit√®re de mesure est la r√©duction du TCO (co√ªt total de possession).  Il se compose des pi√®ces suivantes: <br><br><ul><li>  CAPEX: acquisition d'infrastructure DC, de serveurs, de mat√©riel r√©seau et de c√¢blage </li><li>  OPEX: location DC, √©lectricit√© consomm√©e, maintenance.  OPEX d√©pend de la dur√©e de vie.  Il est raisonnable de supposer qu'il est √©gal √† 3 ans. </li></ul><br><img src="https://habrastorage.org/webt/ub/ur/zi/uburzia_hkzpiosfd3k6i2agrwq.jpeg"><br><br>  Selon la taille des pi√®ces individuelles dans la tarte enti√®re, nous devons optimiser la plus ch√®re et laisser le reste utiliser toutes les ressources restantes aussi efficacement que possible. <br><br>  Supposons que nous ayons un DC existant, il y a une hauteur de rack d'unit√©s H (par exemple, H = 47), de l'√©lectricit√© vers le rack P du <sub>rack</sub> (P <sub>rack</sub> = 6 kW), et nous avons d√©cid√© d'utiliser des serveurs √† deux unit√©s h = 2U.  Nous retirons 2 √† 4 unit√©s du rack aux commutateurs, panneaux de brassage et organisateurs.  C'est-√†-dire  physiquement, nous avons S <sub>h</sub> = arrondi ((H-2..4) / h) serveurs dans notre rack (c'est-√†-dire S <sub>h</sub> = arrondi ((47-4) / 2) = 21 serveurs par rack).  N'oubliez pas que c'est S <sub>h</sub> . <br><br>  Dans le cas simple, tous les serveurs du rack sont identiques.  Au total, si nous martelons le rack avec des serveurs, alors sur chaque serveur nous pouvons d√©penser en moyenne la puissance P <sub>serv</sub> = P <sub>rack</sub> / S <sub>h</sub> (P <sub>serv</sub> = 6000 W / 21 = 287 W).  Par souci de simplicit√©, nous ignorons ici la consommation des commutateurs. <br><br>  Nous faisons un pas de c√¥t√© et d√©terminons quelle est la consommation maximale du serveur P <sub>max</sub> .  Si c'est tr√®s simple, tr√®s inefficace et compl√®tement s√ªr, alors nous lisons ce qui est √©crit sur l'alimentation du serveur - c'est tout. <br><br>  Si c'est plus compliqu√©, plus efficace, alors nous prenons le TDP (package de conception thermique) de tous les composants et r√©sumons (ce n'est pas tr√®s vrai, mais cela peut √™tre le cas). <br><br>  Habituellement, nous ne connaissons pas les composants TDP (sauf pour le CPU), nous adoptons donc l'approche la plus correcte, mais aussi la plus difficile (nous avons besoin d'un laboratoire) - nous prenons un serveur exp√©rimental de la configuration requise et le chargeons, par exemple, avec Linpack (CPU et m√©moire) et fio (disques) mesurer la consommation.  Si vous le prenez au s√©rieux, vous devez √©galement cr√©er l'environnement le plus chaud dans le couloir froid pendant les tests, car cela affectera √† la fois la consommation du ventilateur et la consommation du processeur.  Nous obtenons la consommation maximale d'un serveur sp√©cifique avec une configuration sp√©cifique dans ces conditions sp√©cifiques sous cette charge sp√©cifique.  Nous voulons simplement dire que le nouveau firmware du syst√®me, une autre version du logiciel, d'autres conditions peuvent affecter le r√©sultat. <br><br>  Au total, nous revenons √† P <sub>serv</sub> et comment le comparer avec P <sub>max</sub> .  Il s'agit de comprendre comment fonctionnent les services et √† quel point vos nerfs sont forts chez votre technicien. <br><br>  Si vous ne le risquez pas du tout, nous pensons que tous les serveurs peuvent imm√©diatement commencer √† consommer leur maximum.  En m√™me temps, une entr√©e vers le DC peut √™tre form√©e.  Infra dans ces conditions devrait fournir un service, donc P <sub>serv</sub> ‚â° P <sub>max</sub> .  Il s'agit d'une approche o√π la fiabilit√© est absolument cruciale. <br><br>  Si le technicien pense non seulement √† une s√©curit√© parfaite, mais aussi √† l'argent de l'entreprise et est assez courageux, alors nous pouvons d√©cider <br><br><ul><li>  nous commen√ßons √† g√©rer nos fournisseurs, en particulier, nous interdisons la maintenance planifi√©e au moment de la charge de pointe pr√©vue pour minimiser la baisse d'une entr√©e; </li><li>  et / ou notre architecture vous permet de perdre le rack / ligne / DC, et les services continuent de fonctionner; </li><li>  et / ou nous r√©partissons bien la charge horizontalement sur les racks, de sorte que nos services n'atteindront jamais la consommation maximale dans un seul rack tous ensemble. </li></ul><br>  Il est tr√®s utile ici non seulement de deviner, mais de surveiller la consommation et de savoir comment les serveurs consomment r√©ellement de l'√©lectricit√© dans des conditions normales et de pointe.  Par cons√©quent, apr√®s quelques analyses, le techdir comprime tout ce qu'il poss√®de et dit: ¬´nous acceptons volontairement que la moyenne maximale r√©alisable de la consommation maximale de serveur par rack est ** tellement ** inf√©rieure √† la consommation maximale¬ª, conditionnellement P <sub>serv</sub> = 0,8 * P <sub>max</sub> . <br><br>  Et puis pas 16 serveurs avec P <sub>max</sub> = 375W, mais 20 serveurs avec P <sub>serv</sub> = 375W \ * 0.8 = 300W, montez dans un rack 6kW.  C'est-√†-dire  25% de serveurs en plus.  Il s'agit d'une tr√®s grande √©conomie - apr√®s tout, nous avons imm√©diatement besoin de 25% de racks en moins (nous √©conomisons √©galement sur les PDU, les commutateurs et les c√¢bles).  Un s√©rieux inconv√©nient d'une telle d√©cision - il est n√©cessaire de surveiller en permanence que nos hypoth√®ses sont toujours vraies.  Que la nouvelle version du firmware ne change pas de mani√®re significative le fonctionnement des ventilateurs et la consommation, que le d√©veloppement d'une nouvelle version n'a soudainement pas commenc√© √† utiliser le serveur beaucoup plus efficacement (lire, nous avons eu plus de charge et plus de consommation sur le serveur).  Apr√®s tout, nos hypoth√®ses et conclusions initiales deviennent imm√©diatement incorrectes.  C'est un risque qui doit √™tre pris de mani√®re responsable (ou √©vit√© puis pay√© pour des racks √©videmment sous-charg√©s). <br><br>  Une note importante - vous devriez essayer de distribuer les serveurs de diff√©rents services sur des racks horizontalement, si possible.  Ceci est n√©cessaire pour que les histoires ne se produisent pas lorsqu'un lot de serveurs pour un service arrive, les racks sont bouch√©s verticalement avec lui pour augmenter la "densit√©" (car c'est plus facile).  En r√©alit√©, il s'av√®re qu'un rack est rempli des m√™mes serveurs √† faible charge d'un service, et que l'autre est √©galement √† forte charge.  La probabilit√© d'une chute de la seconde est beaucoup plus √©lev√©e, car  le profil de charge est le m√™me et tous les serveurs r√©unis dans ce rack commencent √† consommer la m√™me quantit√© en raison d'une charge accrue. <br><br>  Revenons √† la distribution des serveurs dans les racks.  Nous avons examin√© les limitations physiques de l'espace rack et des limitations d'alimentation, et jetons maintenant un ≈ìil au r√©seau.  Vous pouvez utiliser des commutateurs sur les ports N 24/32/48 (par exemple, nous avons des commutateurs ToR √† 48 ports).  Heureusement, il n'y a pas beaucoup d'options si vous ne pensez pas aux c√¢bles de d√©rivation.  Nous consid√©rons les sc√©narios lorsque nous avons un commutateur par rack, un commutateur vers deux ou trois racks dans le groupe R <sub>net</sub> .  Il me semble que plus de trois racks du groupe, c'est d√©j√† trop, car  le probl√®me du c√¢blage entre les racks devient beaucoup plus important. <br><br>  Ainsi, pour chaque sc√©nario de r√©seau (1, 2 ou 3 racks dans un groupe) nous r√©partissons le serveur en racks: <br><br>  <sub>Rack</sub> S = min (S <sub>h</sub> , rounddown (P <sub>rack</sub> / P <sub>serv</sub> ), rounddown (N / R <sub>net</sub> )) <br><br>  Ainsi, pour l'option avec 2 racks du groupe: <br><br>  <sub>Rack</sub> S <sup>2</sup> = min (21, arrondi (6000/300), arrondi (48/2)) = min (21, 20, 24) = 20 serveurs par rack. <br><br>  De m√™me, nous consid√©rons les options restantes: <br><br>  <sub>Rack</sub> S <sup>1</sup> = 20 <br>  <sub>Rack</sub> S <sup>3</sup> = 16 <br><br>  Et nous y sommes presque.  Nous comptons le nombre de racks pour la distribution de tous nos serveurs S (soit 1000): <br><br>  R = arrondi (S / ( <sub>rack</sub> S * R <sub>net</sub> )) * R <sub>net</sub> <br><br>  R <sub>1</sub> = arrondi (1000 / (20 * 1)) * 1 = 50 * 1 = 50 racks <br><br>  R <sub>2</sub> = arrondi (1000 / (20 * 2)) * 2 = 25 * 2 = 50 racks <br><br>  R <sub>3</sub> = arrondi (1000 / (16 * 3)) * 3 = 21 * 3 = 63 racks <br><br>  Ensuite, nous consid√©rons le TCO pour chaque option en fonction du nombre de racks, du nombre requis de commutateurs, du c√¢blage, etc.  Nous choisissons l'option o√π le TCO est moindre.  Profit! <br><br>  Notez que bien que le nombre requis de racks pour les options 1 et 2 soit le m√™me, leur prix sera diff√©rent, car  le nombre de commutateurs pour la deuxi√®me option est deux fois moins √©lev√© et la longueur des c√¢bles requis est plus longue. <br><br>  PS S'il y a une possibilit√© de jouer la puissance sur un rack et une hauteur de rack, la variabilit√© augmente.  Mais le processus peut √™tre r√©duit √† ce qui pr√©c√®de, il suffit de trier les options.  Oui, il y aura plus de combinaisons, mais toujours un nombre tr√®s limit√© - la puissance du rack pour le calcul peut √™tre augment√©e par incr√©ments de 1 kW, les racks typiques sont d'un nombre limit√© de tailles: 42U, 45U, 47U, 48U, 52U.  Et ici, l'analyse What-If d'Excel en mode Table de donn√©es peut aider √† calculer.  Nous regardons les plaques re√ßues et s√©lectionnons le minimum. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474112/">https://habr.com/ru/post/fr474112/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474092/index.html">Section backend de DUMP Kazan: architecture d'application cloud, microservices sortants, DDD et plus</a></li>
<li><a href="../fr474094/index.html">√âditeur de diagramme - sur l'amiti√© entre Vue.js et MxGraph</a></li>
<li><a href="../fr474096/index.html">Langages de programmation populaires 2019 des utilisateurs de hh.ru</a></li>
<li><a href="../fr474104/index.html">Un moyen universel de personnaliser l'apparence d'une application WinForms (en utilisant l'exemple de FAQ.Net)</a></li>
<li><a href="../fr474106/index.html">Outils de r√©solution des d√©pendances S√©mantique</a></li>
<li><a href="../fr474114/index.html">Nous vous invitons √† GDG DevFest Moscou 2019 - une conf√©rence informelle sur les TI</a></li>
<li><a href="../fr474116/index.html">Comment vous n'avez pas besoin de r√©diger votre consentement au traitement des donn√©es personnelles</a></li>
<li><a href="../fr474118/index.html">Le livre "inDriver: de Yakutsk √† la Silicon Valley. L'histoire de la cr√©ation d'une entreprise technologique mondiale "</a></li>
<li><a href="../fr474122/index.html">De la th√©orie √† la pratique: comment la blockchain est utilis√©e en aviation</a></li>
<li><a href="../fr474124/index.html">Nous avons besoin d'un autre 1C-Bitrix, partie 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
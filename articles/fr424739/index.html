<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌃 🐳 🍑 Journalisation des événements avec Kafka ⬇️ 🐈 🤶🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! 

 Nous avons découvert les dernières réserves du livre " Apache Kafka. Stream Processing and Data Analysis " et l'avons envoyé au prép...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Journalisation des événements avec Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Bonjour, Habr! <br><br>  Nous avons découvert les dernières réserves du livre " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Kafka. Stream Processing and Data Analysis</a> " et l'avons envoyé au prépresse.  De plus, nous avons reçu un contrat pour le livre " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kafka Streams in Action</a> " et commençons à le traduire littéralement la semaine prochaine. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Pour montrer le cas intéressant de l'utilisation de la bibliothèque Kafka Streams, nous avons décidé de traduire l'article sur le paradigme Event Sourcing en Kafka du très Adam Worski, dont l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> sur la langue Scala a été publié il y a deux semaines.  Il est encore plus intéressant de noter que l’avis d’Adam Worski n’est pas indéniable: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , par exemple, on soutient que ce paradigme ne convient certainement pas à Kafka.  D'autant plus mémorable, nous l'espérons, que nous avons l'impression de l'article. <br><br>  Le terme «Event Sourcing» est traduit par «Event Logging» à la fois dans notre publication de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Clean Architecture de</a> Robert Martin et dans cet article.  Si quelqu'un est impressionné par la traduction des "événements de pompage" - faites-le moi savoir. <br><a name="habracut"></a><br>  Création d'un système qui fournit l'enregistrement des événements (sourcing d'événements), tôt ou tard, nous sommes confrontés au problème de la persistance (persistance) - et ici, nous avons quelques options.  Il y a tout d'abord <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">EventStore</a> , une implémentation mature endurcie au combat.  Alternativement, vous pouvez utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">akka-persistence</a> pour tirer pleinement parti de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'</a> évolutivité de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cassandra</a> , ainsi que compter sur les performances du modèle d'acteur.  Une autre option est la bonne vieille <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">base de données relationnelle</a> , où l'approche <code>CRUD</code> est combinée avec l'utilisation d'événements et le maximum d'avantages est évincé des transactions. <br><br>  En plus de ces opportunités (et peut-être de nombreuses autres) qui se sont présentées grâce à plusieurs choses récemment mises en œuvre, il est devenu assez simple aujourd'hui d'organiser l'enregistrement d'événements au-dessus de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kafka</a> .  Voyons comment. <br><br>  <b>Qu'est-ce que la journalisation des événements?</b> <br><br>  Il existe un certain nombre d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">excellents</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles d'</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">introduction</a> à ce sujet, je me limiterai donc à l'introduction la plus concise.  Lors de l'enregistrement des événements, nous ne sauvegardons pas l'état «actuel» des entités utilisées dans notre système, mais le flux d'événements liés à ces entités.  Chaque <i>événement</i> est un <b>fait</b> qui décrit un changement d'état (déjà!) Qui s'est <b>produit</b> avec l'objet.  Comme vous le savez, les faits ne sont pas discutés et <b>inchangés</b> . <br><br>  Lorsque nous avons un flux de tels événements, l'état actuel d'une entité peut être clarifié en minimisant tous les événements qui lui sont liés;  cependant, gardez à l'esprit que l'inverse n'est pas possible - en ne conservant que l'état "actuel", nous rejetons de nombreuses informations chronologiques précieuses. <br><br>  La journalisation des événements peut <b>coexister</b> pacifiquement avec des méthodes plus traditionnelles de stockage de l'état.  En règle générale, le système traite un certain nombre de types d'entités (par exemple: utilisateurs, commandes, marchandises, ...) et il est fort possible que l'enregistrement d'événements ne soit utile que pour certaines de ces catégories.  Il est important de noter qu'ici nous ne sommes pas confrontés au choix du «tout ou rien»;  il s'agit simplement de la fonction de gestion d'état supplémentaire dans notre application. <br><br>  <b>Stockage d'événements à Kafka</b> <br><br>  Le premier problème à résoudre: comment stocker les événements à Kafka?  Il existe trois stratégies possibles: <br><br><ul><li>  Stockez tous les événements pour tous les types d'entités dans un <b>seul sujet</b> (avec de nombreux segments) </li><li>  Par sujet par type d'entité, c'est-à-dire que nous supprimons tous les événements liés à l'utilisateur dans un sujet distinct, dans un sujet distinct - tous liés au produit, etc. </li><li>  Par sujet par essence, c'est-à-dire par un sujet distinct pour chaque utilisateur spécifique et chaque nom de produit </li></ul><br>  La troisième stratégie (sujet par essence) est pratiquement impraticable.  Si, lorsque chaque nouvel utilisateur apparaissait dans le système, il devait démarrer un sujet distinct, le nombre de sujets deviendrait bientôt illimité.  Toute agrégation dans ce cas serait très difficile, par exemple, il serait difficile d'indexer tous les utilisateurs dans un moteur de recherche;  non seulement vous auriez à consommer un grand nombre de sujets - mais tous n'étaient pas connus à l'avance. <br><br>  Il reste donc à choisir entre 1 et 2. Les deux options ont leurs avantages et leurs inconvénients.  Le fait d'avoir un seul sujet facilite <b>la visualisation globale</b> de tous les événements.  D'un autre côté, en mettant en surbrillance le sujet pour chaque type d'entité, vous pouvez mettre à l'échelle et segmenter le flux de chaque entité individuellement.  Le choix de l'une des deux stratégies dépend du cas d'utilisation spécifique. <br><br>  De plus, vous pouvez implémenter les deux stratégies à la fois, si vous disposez d'un espace de stockage supplémentaire: produire des rubriques par type d'entité à partir d'une rubrique complète. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  Dans le reste de l'article, nous travaillerons avec un seul type d'entité et avec un seul sujet, bien que le matériel présenté puisse être facilement extrapolé et appliqué pour fonctionner avec de nombreux sujets ou types d'entité. <br><br>  (EDIT: comme l'a noté <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chris Hunt</a> , il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un excellent article de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Martin Kleppman</a> , qui a examiné en détail comment répartir les événements par sujet et segment). <br><br>  <b>Les opérations de stockage les plus simples dans le paradigme de la journalisation des événements</b> <br><br>  L'opération la plus simple, logique à attendre d'un magasin qui prend en charge la journalisation des événements, consiste à lire l'état "actuel" (minimisé) d'une entité particulière.  En règle générale, chaque entité a un ou un autre <code>id</code> .  Par conséquent, connaissant cet <code>id</code> , notre système de stockage doit retourner l'état actuel de l'objet. <br><br>  La vérité en dernier ressort sera le journal des événements: l'état actuel peut toujours être déduit du flux d'événements associés à une entité particulière.  Pour cela, le moteur de base de données aura besoin d'une fonction pure (sans effets secondaires) qui accepte l'événement et l'état initial et renvoie l'état modifié: <code>Event = &amp;gt State =&amp;gt State</code> .  En présence d'une telle fonction et de la <b>valeur de l'état initial, l'</b> état actuel est une <b>convolution du</b> flux d'événements (la fonction de changement d'état doit être <b>propre</b> afin qu'elle puisse être librement appliquée à plusieurs reprises aux mêmes événements.) <br><br>  Une implémentation simplifiée de l'opération «lire l'état actuel» dans Kafka collecte un flux de <b>tous les</b> événements du sujet, les filtre, ne laissant que les événements avec l' <code>id</code> donné et s'effondre à l'aide de la fonction spécifiée.  S'il y a beaucoup d'événements (et au fil du temps le nombre d'événements ne fait qu'augmenter), cette opération peut devenir lente et consommer beaucoup de ressources.  Même si son résultat sera mis en cache dans la mémoire et stocké sur le nœud de service, ces informations devront toujours être recréées périodiquement, par exemple, en raison de défaillances de nœud ou en raison de l'éviction des données de cache. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Par conséquent, un moyen plus rationnel est nécessaire.  C'est là que les kafka-streams et les dépôts d'état sont utiles.  Les applications Kafka-streams s'exécutent sur tout un cluster de nœuds qui consomment certains sujets ensemble.  Chaque nœud se voit attribuer une série de segments de sujet consommés, tout comme avec le consommateur Kafka habituel.  Cependant, kafka-streams fournit des opérations de données de niveau supérieur qui facilitent la création de flux dérivés. <br><br>  Une telle opération dans les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">flux kafka</a> est la convolution d'un flux dans le stockage local.  Chaque stockage local contient des données provenant uniquement des segments consommés par un nœud donné.  <i>Prêt</i> à l' <i>emploi</i> , deux implémentations de stockage local sont disponibles: <i>en RAM</i> et basées sur <i>RocksDB</i> . <br><br>  Revenant au sujet de l'enregistrement des événements, nous notons qu'il est possible de réduire le flux d'événements dans <b>le magasin d'état en</b> maintenant sur le nœud local «l'état actuel» de chaque entité à partir des segments affectés au nœud.  Si nous utilisons l'implémentation du magasin d'état basé sur RocksDB, le nombre d'entités que nous pouvons suivre sur un seul nœud dépend uniquement de la quantité d'espace disque. <br><br>  Voici à quoi ressemble la convolution des événements dans le stockage local lors de l'utilisation de l'API Java (serde signifie "sérialiseur / désérialiseur"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Un exemple complet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">de traitement des commandes basé sur des microservices</a> est disponible sur le site Internet de Confluent. <br><br>  (EDIT: comme indiqué par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sergei Egorov</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nikita Salnikov</a> sur Twitter, pour un système avec journalisation des événements, vous devez probablement modifier les paramètres de stockage de données par défaut dans Kafka afin qu'aucune limite de temps ou de taille ne fonctionne, et aussi, éventuellement, , activez la compression des données.) <br><br>  <b>Afficher l'état actuel</b> <br><br>  Nous avons créé un référentiel d'états où se trouvent les états actuels de toutes les entités provenant des segments affectés au nœud, mais comment demander ce référentiel maintenant?  Si la demande est locale (c'est-à-dire qu'elle provient du même noeud où se trouve le référentiel), alors tout est assez simple: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Mais que se passe-t-il si nous voulons demander des données situées sur un autre nœud?  Et comment savoir ce qu'est ce nœud?  Ici, une autre fonctionnalité récemment introduite dans Kafka est très pratique: <b>les requêtes interactives</b> .  Avec leur aide, vous pouvez accéder aux métadonnées Kafka et découvrir quel nœud traite le segment de rubrique avec l' <code>id</code> donné (dans ce cas, l'outil de segmentation de rubrique est implicitement utilisé): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  Ensuite, vous devez rediriger la demande vers le nœud correct.  Veuillez noter: la manière spécifique dont la communication intersite est mise en œuvre et gérée - que ce soit REST, akka-remote ou autre - n'appartient pas à la zone de responsabilité de kafka-streams.  Kafka fournit simplement un accès au magasin d'état et fournit des informations sur le nœud où se trouve le magasin d'état pour l' <code>id</code> donné. <br><br>  <b>Reprise après sinistre</b> <br><br>  Les magasins d'état sont beaux, mais que se passe-t-il lorsqu'un nœud tombe en panne?  La reconstruction d'un magasin d'état local pour un segment donné peut également être une opération coûteuse.  Cela peut provoquer une augmentation des retards ou une perte de demandes pendant une longue période, car les flux kafka devront être rééquilibrés (après l'ajout ou la suppression d'un nœud). <br><br>  C'est pourquoi, par défaut, les magasins d'état à long terme sont enregistrés: c'est-à-dire que toutes les modifications apportées au magasin sont également écrites dans le journal des modifications.  Cette rubrique est compressée (car pour chaque <code>id</code> nous ne sommes intéressés que par le dernier enregistrement, sans historique des modifications, car l'historique est stocké dans les événements eux-mêmes) - par conséquent, il est aussi petit que possible.  C'est pourquoi la recréation du stockage sur un autre nœud peut se produire beaucoup plus rapidement. <br><br>  Cependant, avec le rééquilibrage dans ce cas, des retards sont encore possibles.  Pour les réduire davantage, kafka-streams offre la possibilité de contenir plusieurs <b>réplicas de sauvegarde</b> ( <code>num.standby.replicas</code> ) pour chaque référentiel.  Ces répliques appliquent toutes les mises à jour récupérées à partir des rubriques avec les journaux des modifications à mesure qu'elles deviennent disponibles et sont prêtes à basculer vers le mode de magasin d'état principal pour un segment donné dès que le magasin principal actuel échoue. <br><br>  <b>Cohérence</b> <br><br>  Avec les paramètres par défaut, Kafka fournit au moins une livraison unique.  Autrement dit, en cas de défaillance d'un nœud, certains messages peuvent être remis plusieurs fois.  Par exemple, il est possible qu'un événement particulier soit appliqué deux fois au magasin d'état si le système se bloque après que le magasin d'état a été modifié dans le journal, mais avant que le décalage de cet événement particulier n'ait été effectué.  Cela ne posera peut-être aucune difficulté: notre fonction de mise à jour d'état ( <code>Event = &amp;gt State =&amp;gt State</code> ) peut tout à fait normalement faire face à de telles situations.  Cependant, il peut ne pas être en mesure de faire face: dans ce cas, les garanties de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">livraison strictement ponctuelle</a> fournies par Kafka peuvent être utilisées.  Ces garanties s'appliquent uniquement lors de la lecture et de l'écriture des rubriques Kafka, mais c'est ce que nous faisons ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">en arrière-plan, toutes les entrées des rubriques Kafka sont réduites à la mise à jour du journal des modifications du magasin d'état</a> et à l'exécution de décalages.  Tout cela peut se faire <b>sous forme de transactions</b> . <br><br>  Par conséquent, si notre fonction de mise à jour de l'état l'exige, nous pouvons activer la sémantique du traitement de flux «livraison strictement ponctuelle» en utilisant la seule option de configuration: <code>processing.guarantee</code> .  Pour cette raison, les performances chutent, mais rien ne vient en vain. <br><br>  <b>Écoute de l'événement</b> <br><br>  Maintenant que nous avons couvert les bases - interroger «l'état actuel» et le mettre à jour pour chaque entité - qu'en est-il du déclenchement <b>des effets secondaires</b> ?  À un moment donné, cela deviendra nécessaire, par exemple, pour: <br><br><ul><li>  Envoi d'e-mails de notification </li><li>  Indexation des entités des moteurs de recherche </li><li>  Appel de services externes via REST (ou SOAP, CORBA, etc.) </li></ul><br>  Toutes ces tâches sont, à un degré ou à un autre, bloquantes et liées aux opérations d'E / S (ce qui est naturel pour les effets secondaires), donc ce n'est probablement pas une bonne idée de les exécuter dans le cadre de la logique de mise à jour de l'état: en conséquence, la fréquence des échecs dans la boucle principale peut augmenter événements, et en termes de performances, il y aura un goulot d'étranglement. <br><br>  De plus, une fonction avec une logique de mise à jour d'état (E <code>Event = &amp;gt State =&amp;gt State</code> ) peut être exécutée plusieurs fois (en cas d'échecs ou de redémarrages), et le plus souvent, nous voulons minimiser le nombre de cas dans lesquels les effets secondaires d'un événement particulier sont exécutés plusieurs fois. <br><br>  Heureusement, puisque nous travaillons avec des sujets Kafka, nous avons une assez grande flexibilité.  Au stade des flux, lorsque le magasin d'état est mis à jour, les événements peuvent être émis sous forme inchangée (ou, si nécessaire, également sous une forme modifiée), et le flux / sujet résultant (dans Kafka ces concepts sont équivalents) peut être consommé comme vous le souhaitez.  De plus, il peut être consommé avant ou après l'étape de mise à jour de l'état.  Enfin, nous pouvons contrôler la façon dont nous lançons les effets secondaires: au moins une fois ou au maximum une fois.  La première option est fournie si vous n'effectuez le décalage de l'événement-sujet consommé qu'après que tous les effets secondaires se sont correctement déroulés.  Inversement, avec un maximum d'un run, nous effectuons des changements jusqu'à ce que des effets secondaires se déclenchent. <br><br>  Il existe plusieurs options pour déclencher des effets secondaires, elles dépendent de la situation pratique spécifique.  Tout d'abord, vous pouvez définir l'étape des flux Kafka où les effets secondaires de chaque événement sont déclenchés dans le cadre de la fonction de traitement des flux. <br>  La mise en place d'un tel mécanisme est assez simple, mais cette solution n'est pas flexible lorsque vous devez gérer des tentatives, contrôler les décalages et concurrencer les compensations pour de nombreux événements à la fois.  Dans ces cas plus complexes, il peut être plus approprié de déterminer le traitement en utilisant, disons, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">réactif-kafka</a> ou un autre mécanisme qui consomme les sujets de Kafka "directement". <br><br>  Il est également possible qu'un événement <b>déclenche d'autres événements</b> - par exemple, l'événement «commande» peut déclencher les événements «préparation pour l'expédition» et «notification client».  Cela peut également être mis en œuvre au stade des flux kafka. <br><br>  Enfin, si nous voulions stocker des événements ou des données extraites d'événements dans une base de données ou un moteur de recherche, par exemple, dans ElasticSearch ou PostgreSQL, nous pourrions utiliser le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">connecteur Kafka Connect</a> , qui traitera pour nous tous les détails liés à la consommation de sujets. <br><br>  <b>Création de vues et de projections</b> <br><br>  En règle générale, la configuration système requise ne se limite pas à interroger et à traiter uniquement des flux d'entité unique.  L'agrégation et la combinaison de plusieurs flux d'événements doivent également être prises en charge.  Ces flux combinés sont souvent appelés <b>projections</b> , et lorsqu'ils sont réduits, ils peuvent être utilisés pour créer des <b>représentations de données</b> .  Est-il possible de les implémenter avec Kafka? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  Encore une fois, oui!  N'oubliez pas qu'en principe, nous traitons simplement du sujet Kafka, où nos événements sont stockés;  par conséquent, nous avons toute la puissance du consommateur / producteur Kafka brut, du combineur kafka-streams et même de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">KSQL</a> - tout cela nous est utile pour définir les projections.  Par exemple, en utilisant kafka-streams, vous pouvez filtrer un flux, l'afficher, le grouper par clé, l'agréger dans des fenêtres temporaires ou de session, etc.  soit au niveau du code, soit en utilisant KSQL de type SQL. <br><br>  De tels flux peuvent être stockés et fournis pour des requêtes pendant une longue période à l'aide de magasins d'état et de requêtes interactives, tout comme nous l'avons fait avec des flux d'entités individuelles. <br><br>  <b>Et ensuite</b> <br><br>  Pour éviter le flux infini d'événements au fur et à mesure que le système se développe, une option de compression telle que la sauvegarde des <b>instantanés de</b> «l'état actuel» peut être utile.  Ainsi, nous pouvons nous limiter à ne stocker que quelques instantanés récents et les événements survenus après leur création. <br><br>  Bien que Kafka ne prenne pas directement en charge les instantanés (et dans certains autres systèmes fonctionnant sur le principe de l'enregistrement des événements, c'est le cas), vous pouvez certainement ajouter ce type de fonctionnalité vous-même, en utilisant certains des mécanismes ci-dessus, tels que les flux, les consommateurs, les magasins d'État, etc. d. <br><br>  <b>Résumé</b> <br><br>  Bien que, au départ, Kafka n'ait pas été conçu avec un œil sur le paradigme d'enregistrement des événements, il s'agit en fait d'un moteur de données en streaming avec prise en charge de la <b>réplication de sujets</b> , de la segmentation, <b>des référentiels d'état</b> et <b>des API de streaming</b> , et il est très flexible en même temps.  Par conséquent, en plus de Kafka, vous pouvez facilement implémenter un système d'enregistrement d'événements.  De plus, comme dans le contexte de tout ce qui se passe, nous aurons toujours un sujet Kafka, nous gagnerons en flexibilité supplémentaire, car nous pouvons travailler avec des API de streaming de haut niveau ou des consommateurs de bas niveau. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424739/">https://habr.com/ru/post/fr424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424729/index.html">Pourquoi le compilateur a-t-il transformé ma boucle conditionnelle en infini?</a></li>
<li><a href="../fr424731/index.html">Historique du support technique à chaud, ou Pourquoi AutoCAD supprime-t-il les objets proxy?</a></li>
<li><a href="../fr424733/index.html">Pilule bleue STM32F103 comme PLC</a></li>
<li><a href="../fr424735/index.html">Comment ça marche, et la psychothérapie conversationnelle fonctionne-t-elle du tout</a></li>
<li><a href="../fr424737/index.html">42ème protocole de vie, l'univers et tout ça: "discours d'adieu"</a></li>
<li><a href="../fr424741/index.html">Les gars, vivons en paix ou sur le champ Mot de passe lors de l'inscription</a></li>
<li><a href="../fr424745/index.html">L'activité de GosSOPKI a augmenté</a></li>
<li><a href="../fr424747/index.html">L'endroit où vit le son</a></li>
<li><a href="../fr424751/index.html">Fonctionnement du système biométrique unifié</a></li>
<li><a href="../fr424753/index.html">Nouveautés de YouTrack 2018.3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
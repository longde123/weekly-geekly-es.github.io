<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåÉ üê≥ üçë Journalisation des √©v√©nements avec Kafka ‚¨áÔ∏è üêà ü§∂üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! 

 Nous avons d√©couvert les derni√®res r√©serves du livre " Apache Kafka. Stream Processing and Data Analysis " et l'avons envoy√© au pr√©p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Journalisation des √©v√©nements avec Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Bonjour, Habr! <br><br>  Nous avons d√©couvert les derni√®res r√©serves du livre " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Kafka. Stream Processing and Data Analysis</a> " et l'avons envoy√© au pr√©presse.  De plus, nous avons re√ßu un contrat pour le livre " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kafka Streams in Action</a> " et commen√ßons √† le traduire litt√©ralement la semaine prochaine. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Pour montrer le cas int√©ressant de l'utilisation de la biblioth√®que Kafka Streams, nous avons d√©cid√© de traduire l'article sur le paradigme Event Sourcing en Kafka du tr√®s Adam Worski, dont l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> sur la langue Scala a √©t√© publi√© il y a deux semaines.  Il est encore plus int√©ressant de noter que l‚Äôavis d‚ÄôAdam Worski n‚Äôest pas ind√©niable: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , par exemple, on soutient que ce paradigme ne convient certainement pas √† Kafka.  D'autant plus m√©morable, nous l'esp√©rons, que nous avons l'impression de l'article. <br><br>  Le terme ¬´Event Sourcing¬ª est traduit par ¬´Event Logging¬ª √† la fois dans notre publication de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Clean Architecture de</a> Robert Martin et dans cet article.  Si quelqu'un est impressionn√© par la traduction des "√©v√©nements de pompage" - faites-le moi savoir. <br><a name="habracut"></a><br>  Cr√©ation d'un syst√®me qui fournit l'enregistrement des √©v√©nements (sourcing d'√©v√©nements), t√¥t ou tard, nous sommes confront√©s au probl√®me de la persistance (persistance) - et ici, nous avons quelques options.  Il y a tout d'abord <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">EventStore</a> , une impl√©mentation mature endurcie au combat.  Alternativement, vous pouvez utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">akka-persistence</a> pour tirer pleinement parti de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'</a> √©volutivit√© de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cassandra</a> , ainsi que compter sur les performances du mod√®le d'acteur.  Une autre option est la bonne vieille <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">base de donn√©es relationnelle</a> , o√π l'approche <code>CRUD</code> est combin√©e avec l'utilisation d'√©v√©nements et le maximum d'avantages est √©vinc√© des transactions. <br><br>  En plus de ces opportunit√©s (et peut-√™tre de nombreuses autres) qui se sont pr√©sent√©es gr√¢ce √† plusieurs choses r√©cemment mises en ≈ìuvre, il est devenu assez simple aujourd'hui d'organiser l'enregistrement d'√©v√©nements au-dessus de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kafka</a> .  Voyons comment. <br><br>  <b>Qu'est-ce que la journalisation des √©v√©nements?</b> <br><br>  Il existe un certain nombre d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">excellents</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles d'</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">introduction</a> √† ce sujet, je me limiterai donc √† l'introduction la plus concise.  Lors de l'enregistrement des √©v√©nements, nous ne sauvegardons pas l'√©tat ¬´actuel¬ª des entit√©s utilis√©es dans notre syst√®me, mais le flux d'√©v√©nements li√©s √† ces entit√©s.  Chaque <i>√©v√©nement</i> est un <b>fait</b> qui d√©crit un changement d'√©tat (d√©j√†!) Qui s'est <b>produit</b> avec l'objet.  Comme vous le savez, les faits ne sont pas discut√©s et <b>inchang√©s</b> . <br><br>  Lorsque nous avons un flux de tels √©v√©nements, l'√©tat actuel d'une entit√© peut √™tre clarifi√© en minimisant tous les √©v√©nements qui lui sont li√©s;  cependant, gardez √† l'esprit que l'inverse n'est pas possible - en ne conservant que l'√©tat "actuel", nous rejetons de nombreuses informations chronologiques pr√©cieuses. <br><br>  La journalisation des √©v√©nements peut <b>coexister</b> pacifiquement avec des m√©thodes plus traditionnelles de stockage de l'√©tat.  En r√®gle g√©n√©rale, le syst√®me traite un certain nombre de types d'entit√©s (par exemple: utilisateurs, commandes, marchandises, ...) et il est fort possible que l'enregistrement d'√©v√©nements ne soit utile que pour certaines de ces cat√©gories.  Il est important de noter qu'ici nous ne sommes pas confront√©s au choix du ¬´tout ou rien¬ª;  il s'agit simplement de la fonction de gestion d'√©tat suppl√©mentaire dans notre application. <br><br>  <b>Stockage d'√©v√©nements √† Kafka</b> <br><br>  Le premier probl√®me √† r√©soudre: comment stocker les √©v√©nements √† Kafka?  Il existe trois strat√©gies possibles: <br><br><ul><li>  Stockez tous les √©v√©nements pour tous les types d'entit√©s dans un <b>seul sujet</b> (avec de nombreux segments) </li><li>  Par sujet par type d'entit√©, c'est-√†-dire que nous supprimons tous les √©v√©nements li√©s √† l'utilisateur dans un sujet distinct, dans un sujet distinct - tous li√©s au produit, etc. </li><li>  Par sujet par essence, c'est-√†-dire par un sujet distinct pour chaque utilisateur sp√©cifique et chaque nom de produit </li></ul><br>  La troisi√®me strat√©gie (sujet par essence) est pratiquement impraticable.  Si, lorsque chaque nouvel utilisateur apparaissait dans le syst√®me, il devait d√©marrer un sujet distinct, le nombre de sujets deviendrait bient√¥t illimit√©.  Toute agr√©gation dans ce cas serait tr√®s difficile, par exemple, il serait difficile d'indexer tous les utilisateurs dans un moteur de recherche;  non seulement vous auriez √† consommer un grand nombre de sujets - mais tous n'√©taient pas connus √† l'avance. <br><br>  Il reste donc √† choisir entre 1 et 2. Les deux options ont leurs avantages et leurs inconv√©nients.  Le fait d'avoir un seul sujet facilite <b>la visualisation globale</b> de tous les √©v√©nements.  D'un autre c√¥t√©, en mettant en surbrillance le sujet pour chaque type d'entit√©, vous pouvez mettre √† l'√©chelle et segmenter le flux de chaque entit√© individuellement.  Le choix de l'une des deux strat√©gies d√©pend du cas d'utilisation sp√©cifique. <br><br>  De plus, vous pouvez impl√©menter les deux strat√©gies √† la fois, si vous disposez d'un espace de stockage suppl√©mentaire: produire des rubriques par type d'entit√© √† partir d'une rubrique compl√®te. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  Dans le reste de l'article, nous travaillerons avec un seul type d'entit√© et avec un seul sujet, bien que le mat√©riel pr√©sent√© puisse √™tre facilement extrapol√© et appliqu√© pour fonctionner avec de nombreux sujets ou types d'entit√©. <br><br>  (EDIT: comme l'a not√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chris Hunt</a> , il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un excellent article de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Martin Kleppman</a> , qui a examin√© en d√©tail comment r√©partir les √©v√©nements par sujet et segment). <br><br>  <b>Les op√©rations de stockage les plus simples dans le paradigme de la journalisation des √©v√©nements</b> <br><br>  L'op√©ration la plus simple, logique √† attendre d'un magasin qui prend en charge la journalisation des √©v√©nements, consiste √† lire l'√©tat "actuel" (minimis√©) d'une entit√© particuli√®re.  En r√®gle g√©n√©rale, chaque entit√© a un ou un autre <code>id</code> .  Par cons√©quent, connaissant cet <code>id</code> , notre syst√®me de stockage doit retourner l'√©tat actuel de l'objet. <br><br>  La v√©rit√© en dernier ressort sera le journal des √©v√©nements: l'√©tat actuel peut toujours √™tre d√©duit du flux d'√©v√©nements associ√©s √† une entit√© particuli√®re.  Pour cela, le moteur de base de donn√©es aura besoin d'une fonction pure (sans effets secondaires) qui accepte l'√©v√©nement et l'√©tat initial et renvoie l'√©tat modifi√©: <code>Event = &amp;gt State =&amp;gt State</code> .  En pr√©sence d'une telle fonction et de la <b>valeur de l'√©tat initial, l'</b> √©tat actuel est une <b>convolution du</b> flux d'√©v√©nements (la fonction de changement d'√©tat doit √™tre <b>propre</b> afin qu'elle puisse √™tre librement appliqu√©e √† plusieurs reprises aux m√™mes √©v√©nements.) <br><br>  Une impl√©mentation simplifi√©e de l'op√©ration ¬´lire l'√©tat actuel¬ª dans Kafka collecte un flux de <b>tous les</b> √©v√©nements du sujet, les filtre, ne laissant que les √©v√©nements avec l' <code>id</code> donn√© et s'effondre √† l'aide de la fonction sp√©cifi√©e.  S'il y a beaucoup d'√©v√©nements (et au fil du temps le nombre d'√©v√©nements ne fait qu'augmenter), cette op√©ration peut devenir lente et consommer beaucoup de ressources.  M√™me si son r√©sultat sera mis en cache dans la m√©moire et stock√© sur le n≈ìud de service, ces informations devront toujours √™tre recr√©√©es p√©riodiquement, par exemple, en raison de d√©faillances de n≈ìud ou en raison de l'√©viction des donn√©es de cache. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Par cons√©quent, un moyen plus rationnel est n√©cessaire.  C'est l√† que les kafka-streams et les d√©p√¥ts d'√©tat sont utiles.  Les applications Kafka-streams s'ex√©cutent sur tout un cluster de n≈ìuds qui consomment certains sujets ensemble.  Chaque n≈ìud se voit attribuer une s√©rie de segments de sujet consomm√©s, tout comme avec le consommateur Kafka habituel.  Cependant, kafka-streams fournit des op√©rations de donn√©es de niveau sup√©rieur qui facilitent la cr√©ation de flux d√©riv√©s. <br><br>  Une telle op√©ration dans les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">flux kafka</a> est la convolution d'un flux dans le stockage local.  Chaque stockage local contient des donn√©es provenant uniquement des segments consomm√©s par un n≈ìud donn√©.  <i>Pr√™t</i> √† l' <i>emploi</i> , deux impl√©mentations de stockage local sont disponibles: <i>en RAM</i> et bas√©es sur <i>RocksDB</i> . <br><br>  Revenant au sujet de l'enregistrement des √©v√©nements, nous notons qu'il est possible de r√©duire le flux d'√©v√©nements dans <b>le magasin d'√©tat en</b> maintenant sur le n≈ìud local ¬´l'√©tat actuel¬ª de chaque entit√© √† partir des segments affect√©s au n≈ìud.  Si nous utilisons l'impl√©mentation du magasin d'√©tat bas√© sur RocksDB, le nombre d'entit√©s que nous pouvons suivre sur un seul n≈ìud d√©pend uniquement de la quantit√© d'espace disque. <br><br>  Voici √† quoi ressemble la convolution des √©v√©nements dans le stockage local lors de l'utilisation de l'API Java (serde signifie "s√©rialiseur / d√©s√©rialiseur"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Un exemple complet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">de traitement des commandes bas√© sur des microservices</a> est disponible sur le site Internet de Confluent. <br><br>  (EDIT: comme indiqu√© par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sergei Egorov</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nikita Salnikov</a> sur Twitter, pour un syst√®me avec journalisation des √©v√©nements, vous devez probablement modifier les param√®tres de stockage de donn√©es par d√©faut dans Kafka afin qu'aucune limite de temps ou de taille ne fonctionne, et aussi, √©ventuellement, , activez la compression des donn√©es.) <br><br>  <b>Afficher l'√©tat actuel</b> <br><br>  Nous avons cr√©√© un r√©f√©rentiel d'√©tats o√π se trouvent les √©tats actuels de toutes les entit√©s provenant des segments affect√©s au n≈ìud, mais comment demander ce r√©f√©rentiel maintenant?  Si la demande est locale (c'est-√†-dire qu'elle provient du m√™me noeud o√π se trouve le r√©f√©rentiel), alors tout est assez simple: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Mais que se passe-t-il si nous voulons demander des donn√©es situ√©es sur un autre n≈ìud?  Et comment savoir ce qu'est ce n≈ìud?  Ici, une autre fonctionnalit√© r√©cemment introduite dans Kafka est tr√®s pratique: <b>les requ√™tes interactives</b> .  Avec leur aide, vous pouvez acc√©der aux m√©tadonn√©es Kafka et d√©couvrir quel n≈ìud traite le segment de rubrique avec l' <code>id</code> donn√© (dans ce cas, l'outil de segmentation de rubrique est implicitement utilis√©): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  Ensuite, vous devez rediriger la demande vers le n≈ìud correct.  Veuillez noter: la mani√®re sp√©cifique dont la communication intersite est mise en ≈ìuvre et g√©r√©e - que ce soit REST, akka-remote ou autre - n'appartient pas √† la zone de responsabilit√© de kafka-streams.  Kafka fournit simplement un acc√®s au magasin d'√©tat et fournit des informations sur le n≈ìud o√π se trouve le magasin d'√©tat pour l' <code>id</code> donn√©. <br><br>  <b>Reprise apr√®s sinistre</b> <br><br>  Les magasins d'√©tat sont beaux, mais que se passe-t-il lorsqu'un n≈ìud tombe en panne?  La reconstruction d'un magasin d'√©tat local pour un segment donn√© peut √©galement √™tre une op√©ration co√ªteuse.  Cela peut provoquer une augmentation des retards ou une perte de demandes pendant une longue p√©riode, car les flux kafka devront √™tre r√©√©quilibr√©s (apr√®s l'ajout ou la suppression d'un n≈ìud). <br><br>  C'est pourquoi, par d√©faut, les magasins d'√©tat √† long terme sont enregistr√©s: c'est-√†-dire que toutes les modifications apport√©es au magasin sont √©galement √©crites dans le journal des modifications.  Cette rubrique est compress√©e (car pour chaque <code>id</code> nous ne sommes int√©ress√©s que par le dernier enregistrement, sans historique des modifications, car l'historique est stock√© dans les √©v√©nements eux-m√™mes) - par cons√©quent, il est aussi petit que possible.  C'est pourquoi la recr√©ation du stockage sur un autre n≈ìud peut se produire beaucoup plus rapidement. <br><br>  Cependant, avec le r√©√©quilibrage dans ce cas, des retards sont encore possibles.  Pour les r√©duire davantage, kafka-streams offre la possibilit√© de contenir plusieurs <b>r√©plicas de sauvegarde</b> ( <code>num.standby.replicas</code> ) pour chaque r√©f√©rentiel.  Ces r√©pliques appliquent toutes les mises √† jour r√©cup√©r√©es √† partir des rubriques avec les journaux des modifications √† mesure qu'elles deviennent disponibles et sont pr√™tes √† basculer vers le mode de magasin d'√©tat principal pour un segment donn√© d√®s que le magasin principal actuel √©choue. <br><br>  <b>Coh√©rence</b> <br><br>  Avec les param√®tres par d√©faut, Kafka fournit au moins une livraison unique.  Autrement dit, en cas de d√©faillance d'un n≈ìud, certains messages peuvent √™tre remis plusieurs fois.  Par exemple, il est possible qu'un √©v√©nement particulier soit appliqu√© deux fois au magasin d'√©tat si le syst√®me se bloque apr√®s que le magasin d'√©tat a √©t√© modifi√© dans le journal, mais avant que le d√©calage de cet √©v√©nement particulier n'ait √©t√© effectu√©.  Cela ne posera peut-√™tre aucune difficult√©: notre fonction de mise √† jour d'√©tat ( <code>Event = &amp;gt State =&amp;gt State</code> ) peut tout √† fait normalement faire face √† de telles situations.  Cependant, il peut ne pas √™tre en mesure de faire face: dans ce cas, les garanties de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">livraison strictement ponctuelle</a> fournies par Kafka peuvent √™tre utilis√©es.  Ces garanties s'appliquent uniquement lors de la lecture et de l'√©criture des rubriques Kafka, mais c'est ce que nous faisons ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">en arri√®re-plan, toutes les entr√©es des rubriques Kafka sont r√©duites √† la mise √† jour du journal des modifications du magasin d'√©tat</a> et √† l'ex√©cution de d√©calages.  Tout cela peut se faire <b>sous forme de transactions</b> . <br><br>  Par cons√©quent, si notre fonction de mise √† jour de l'√©tat l'exige, nous pouvons activer la s√©mantique du traitement de flux ¬´livraison strictement ponctuelle¬ª en utilisant la seule option de configuration: <code>processing.guarantee</code> .  Pour cette raison, les performances chutent, mais rien ne vient en vain. <br><br>  <b>√âcoute de l'√©v√©nement</b> <br><br>  Maintenant que nous avons couvert les bases - interroger ¬´l'√©tat actuel¬ª et le mettre √† jour pour chaque entit√© - qu'en est-il du d√©clenchement <b>des effets secondaires</b> ?  √Ä un moment donn√©, cela deviendra n√©cessaire, par exemple, pour: <br><br><ul><li>  Envoi d'e-mails de notification </li><li>  Indexation des entit√©s des moteurs de recherche </li><li>  Appel de services externes via REST (ou SOAP, CORBA, etc.) </li></ul><br>  Toutes ces t√¢ches sont, √† un degr√© ou √† un autre, bloquantes et li√©es aux op√©rations d'E / S (ce qui est naturel pour les effets secondaires), donc ce n'est probablement pas une bonne id√©e de les ex√©cuter dans le cadre de la logique de mise √† jour de l'√©tat: en cons√©quence, la fr√©quence des √©checs dans la boucle principale peut augmenter √©v√©nements, et en termes de performances, il y aura un goulot d'√©tranglement. <br><br>  De plus, une fonction avec une logique de mise √† jour d'√©tat (E <code>Event = &amp;gt State =&amp;gt State</code> ) peut √™tre ex√©cut√©e plusieurs fois (en cas d'√©checs ou de red√©marrages), et le plus souvent, nous voulons minimiser le nombre de cas dans lesquels les effets secondaires d'un √©v√©nement particulier sont ex√©cut√©s plusieurs fois. <br><br>  Heureusement, puisque nous travaillons avec des sujets Kafka, nous avons une assez grande flexibilit√©.  Au stade des flux, lorsque le magasin d'√©tat est mis √† jour, les √©v√©nements peuvent √™tre √©mis sous forme inchang√©e (ou, si n√©cessaire, √©galement sous une forme modifi√©e), et le flux / sujet r√©sultant (dans Kafka ces concepts sont √©quivalents) peut √™tre consomm√© comme vous le souhaitez.  De plus, il peut √™tre consomm√© avant ou apr√®s l'√©tape de mise √† jour de l'√©tat.  Enfin, nous pouvons contr√¥ler la fa√ßon dont nous lan√ßons les effets secondaires: au moins une fois ou au maximum une fois.  La premi√®re option est fournie si vous n'effectuez le d√©calage de l'√©v√©nement-sujet consomm√© qu'apr√®s que tous les effets secondaires se sont correctement d√©roul√©s.  Inversement, avec un maximum d'un run, nous effectuons des changements jusqu'√† ce que des effets secondaires se d√©clenchent. <br><br>  Il existe plusieurs options pour d√©clencher des effets secondaires, elles d√©pendent de la situation pratique sp√©cifique.  Tout d'abord, vous pouvez d√©finir l'√©tape des flux Kafka o√π les effets secondaires de chaque √©v√©nement sont d√©clench√©s dans le cadre de la fonction de traitement des flux. <br>  La mise en place d'un tel m√©canisme est assez simple, mais cette solution n'est pas flexible lorsque vous devez g√©rer des tentatives, contr√¥ler les d√©calages et concurrencer les compensations pour de nombreux √©v√©nements √† la fois.  Dans ces cas plus complexes, il peut √™tre plus appropri√© de d√©terminer le traitement en utilisant, disons, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©actif-kafka</a> ou un autre m√©canisme qui consomme les sujets de Kafka "directement". <br><br>  Il est √©galement possible qu'un √©v√©nement <b>d√©clenche d'autres √©v√©nements</b> - par exemple, l'√©v√©nement ¬´commande¬ª peut d√©clencher les √©v√©nements ¬´pr√©paration pour l'exp√©dition¬ª et ¬´notification client¬ª.  Cela peut √©galement √™tre mis en ≈ìuvre au stade des flux kafka. <br><br>  Enfin, si nous voulions stocker des √©v√©nements ou des donn√©es extraites d'√©v√©nements dans une base de donn√©es ou un moteur de recherche, par exemple, dans ElasticSearch ou PostgreSQL, nous pourrions utiliser le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">connecteur Kafka Connect</a> , qui traitera pour nous tous les d√©tails li√©s √† la consommation de sujets. <br><br>  <b>Cr√©ation de vues et de projections</b> <br><br>  En r√®gle g√©n√©rale, la configuration syst√®me requise ne se limite pas √† interroger et √† traiter uniquement des flux d'entit√© unique.  L'agr√©gation et la combinaison de plusieurs flux d'√©v√©nements doivent √©galement √™tre prises en charge.  Ces flux combin√©s sont souvent appel√©s <b>projections</b> , et lorsqu'ils sont r√©duits, ils peuvent √™tre utilis√©s pour cr√©er des <b>repr√©sentations de donn√©es</b> .  Est-il possible de les impl√©menter avec Kafka? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  Encore une fois, oui!  N'oubliez pas qu'en principe, nous traitons simplement du sujet Kafka, o√π nos √©v√©nements sont stock√©s;  par cons√©quent, nous avons toute la puissance du consommateur / producteur Kafka brut, du combineur kafka-streams et m√™me de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">KSQL</a> - tout cela nous est utile pour d√©finir les projections.  Par exemple, en utilisant kafka-streams, vous pouvez filtrer un flux, l'afficher, le grouper par cl√©, l'agr√©ger dans des fen√™tres temporaires ou de session, etc.  soit au niveau du code, soit en utilisant KSQL de type SQL. <br><br>  De tels flux peuvent √™tre stock√©s et fournis pour des requ√™tes pendant une longue p√©riode √† l'aide de magasins d'√©tat et de requ√™tes interactives, tout comme nous l'avons fait avec des flux d'entit√©s individuelles. <br><br>  <b>Et ensuite</b> <br><br>  Pour √©viter le flux infini d'√©v√©nements au fur et √† mesure que le syst√®me se d√©veloppe, une option de compression telle que la sauvegarde des <b>instantan√©s de</b> ¬´l'√©tat actuel¬ª peut √™tre utile.  Ainsi, nous pouvons nous limiter √† ne stocker que quelques instantan√©s r√©cents et les √©v√©nements survenus apr√®s leur cr√©ation. <br><br>  Bien que Kafka ne prenne pas directement en charge les instantan√©s (et dans certains autres syst√®mes fonctionnant sur le principe de l'enregistrement des √©v√©nements, c'est le cas), vous pouvez certainement ajouter ce type de fonctionnalit√© vous-m√™me, en utilisant certains des m√©canismes ci-dessus, tels que les flux, les consommateurs, les magasins d'√âtat, etc. d. <br><br>  <b>R√©sum√©</b> <br><br>  Bien que, au d√©part, Kafka n'ait pas √©t√© con√ßu avec un ≈ìil sur le paradigme d'enregistrement des √©v√©nements, il s'agit en fait d'un moteur de donn√©es en streaming avec prise en charge de la <b>r√©plication de sujets</b> , de la segmentation, <b>des r√©f√©rentiels d'√©tat</b> et <b>des API de streaming</b> , et il est tr√®s flexible en m√™me temps.  Par cons√©quent, en plus de Kafka, vous pouvez facilement impl√©menter un syst√®me d'enregistrement d'√©v√©nements.  De plus, comme dans le contexte de tout ce qui se passe, nous aurons toujours un sujet Kafka, nous gagnerons en flexibilit√© suppl√©mentaire, car nous pouvons travailler avec des API de streaming de haut niveau ou des consommateurs de bas niveau. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424739/">https://habr.com/ru/post/fr424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424729/index.html">Pourquoi le compilateur a-t-il transform√© ma boucle conditionnelle en infini?</a></li>
<li><a href="../fr424731/index.html">Historique du support technique √† chaud, ou Pourquoi AutoCAD supprime-t-il les objets proxy?</a></li>
<li><a href="../fr424733/index.html">Pilule bleue STM32F103 comme PLC</a></li>
<li><a href="../fr424735/index.html">Comment √ßa marche, et la psychoth√©rapie conversationnelle fonctionne-t-elle du tout</a></li>
<li><a href="../fr424737/index.html">42√®me protocole de vie, l'univers et tout √ßa: "discours d'adieu"</a></li>
<li><a href="../fr424741/index.html">Les gars, vivons en paix ou sur le champ Mot de passe lors de l'inscription</a></li>
<li><a href="../fr424745/index.html">L'activit√© de GosSOPKI a augment√©</a></li>
<li><a href="../fr424747/index.html">L'endroit o√π vit le son</a></li>
<li><a href="../fr424751/index.html">Fonctionnement du syst√®me biom√©trique unifi√©</a></li>
<li><a href="../fr424753/index.html">Nouveaut√©s de YouTrack 2018.3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
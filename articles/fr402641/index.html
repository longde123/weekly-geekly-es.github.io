<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äç‚úàÔ∏è üßëüèΩ‚Äçü§ù‚Äçüßëüèª üïï A quoi ressemblent les r√©seaux de neurones profonds et pourquoi ils n√©cessitent autant de m√©moire üë©üèæ‚Äçü§ù‚Äçüë®üèª üë®üèΩ‚Äçüåæ üßû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Aujourd'hui, le graphique est l'un des moyens les plus acceptables pour d√©crire les mod√®les cr√©√©s dans le syst√®me d'apprentissage automatique. Ces gra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A quoi ressemblent les r√©seaux de neurones profonds et pourquoi ils n√©cessitent autant de m√©moire</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/402641/"><img src="https://habrastorage.org/getpro/geektimes/post_images/802/6f4/eab/8026f4eab4ee028d6894159b00421c56.jpg" alt="image"><br><br>  Aujourd'hui, le graphique est l'un des moyens les plus acceptables pour d√©crire les mod√®les cr√©√©s dans le syst√®me d'apprentissage automatique.  Ces graphiques de calcul sont compos√©s de sommets de neurones reli√©s par des bords de synapse qui d√©crivent les connexions entre les sommets. <br><br>  Contrairement √† un processeur graphique central ou vectoriel scalaire, IPU - un nouveau type de processeur con√ßu pour l'apprentissage automatique, vous permet de construire de tels graphiques.  Un ordinateur con√ßu pour la gestion des graphes est une machine id√©ale pour les mod√®les de graphes informatiques cr√©√©s dans le cadre de l'apprentissage automatique. <br><br>  L'une des fa√ßons les plus simples de d√©crire le fonctionnement de l'intelligence artificielle est de la visualiser.  L'√©quipe de d√©veloppement de Graphcore a cr√©√© une collection de ces images affich√©es sur l'UIP.  La base √©tait le logiciel Poplar, qui visualise le travail de l'intelligence artificielle.  Les chercheurs de cette entreprise ont √©galement d√©couvert pourquoi les r√©seaux profonds n√©cessitent autant de m√©moire et quelles solutions existent. <a name="habracut"></a><br><br>  Poplar inclut un compilateur graphique qui a √©t√© cr√©√© √† partir de z√©ro pour traduire les op√©rations standard utilis√©es dans le cadre de l'apprentissage automatique en code d'application hautement optimis√© pour les IPU.  Il vous permet de rassembler ces graphiques ensemble sur le m√™me principe que les POPNN sont assembl√©s.  La biblioth√®que contient un ensemble de diff√©rents types de sommets pour les primitives g√©n√©ralis√©es. <br><br>  Les graphiques sont le paradigme sur lequel tous les logiciels sont bas√©s.  Dans Poplar, les graphiques vous permettent de d√©finir le processus de calcul, o√π les sommets effectuent des op√©rations et les ar√™tes d√©crivent la relation entre eux.  Par exemple, si vous souhaitez ajouter deux nombres ensemble, vous pouvez d√©finir un sommet avec deux entr√©es (les nombres que vous souhaitez ajouter), quelques calculs (la fonction d'ajouter deux nombres) et la sortie (r√©sultat). <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/708/107/2ad/7081072ad3e33d401cabae1f3914bccb.jpg" alt="image"><br><br>  Habituellement, les op√©rations de sommet sont beaucoup plus compliqu√©es que dans l'exemple d√©crit ci-dessus.  Ils sont souvent d√©finis par de petits programmes appel√©s codelets (noms de code).  L'abstraction graphique est int√©ressante car elle ne fait aucune hypoth√®se sur la structure des calculs et d√©compose le calcul en composants que le processeur IPU peut utiliser pour fonctionner. <br><br>  Poplar utilise cette abstraction simple pour construire de tr√®s grands graphiques qui sont repr√©sent√©s sous forme d'images.  La g√©n√©ration programmatique du graphique signifie que nous pouvons l'adapter aux calculs sp√©cifiques n√©cessaires pour assurer l'utilisation la plus efficace des ressources de l'UIP. <br><br>  Le compilateur traduit les op√©rations standard utilis√©es dans les syst√®mes d'apprentissage automatique en un code d'application hautement optimis√© pour les IPU.  Un compilateur de graphiques cr√©e une image interm√©diaire d'un graphique de calcul qui est d√©ploy√© sur un ou plusieurs p√©riph√©riques IPU.  Le compilateur peut afficher ce graphe de calcul, donc une application √©crite au niveau de la structure du r√©seau neuronal affiche une image du graphe de calcul qui s'ex√©cute sur l'UIP. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/45a/eb2/4b8/45aeb24b80e244c6c16c6fc584d99678.jpg" alt="image"><br>  <i>Graphique d'apprentissage complet AlexNet en avant et en arri√®re</i> <br><br>  Le compilateur graphique Poplar a transform√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la</a> description <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'AlexNet</a> en un graphe de calcul de 18,7 millions de sommets et 115,8 millions d'ar√™tes.  Le clustering clairement visible est le r√©sultat d'une forte connexion entre les processus dans chaque couche du r√©seau avec une connexion plus facile entre les niveaux. <br><br>  Un autre exemple est un r√©seau simple avec une connectivit√© compl√®te, form√© au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MNIST</a> - un simple ensemble de donn√©es pour la vision par ordinateur, une sorte de ¬´Bonjour, monde¬ª dans l'apprentissage automatique.  Un r√©seau simple pour explorer cet ensemble de donn√©es permet de comprendre les graphiques contr√¥l√©s par les applications Poplar.  En int√©grant des biblioth√®ques de graphes √† des environnements tels que TensorFlow, la soci√©t√© fournit l'un des moyens les plus simples d'utiliser les IPU dans les applications d'apprentissage automatique. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/f07/3bd/4e3/f073bd4e334225380ae51b16fb2e94b6.jpg" alt="image"><br><br>  Une fois le graphique construit √† l'aide du compilateur, il doit √™tre ex√©cut√©.  Cela est possible en utilisant le moteur graphique.  En utilisant ResNet-50 comme exemple, son fonctionnement est d√©montr√©. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/5d7/cb1/ce5/5d7cb1ce55a80f2b8e4ebefe38681710.jpg" alt="image"><br>  <i>Count ResNet-50</i> <br><br>  L'architecture ResNet-50 vous permet de cr√©er des r√©seaux profonds √† partir de partitions r√©p√©titives.  Le processeur n'a besoin de d√©terminer ces partitions qu'une seule fois et de les rappeler.  Par exemple, un cluster de niveau conv4 est ex√©cut√© six fois, mais une seule fois appliqu√© au graphique.  L'image montre √©galement la vari√©t√© des formes des couches convolutives, car chacune d'elles a un graphique construit conform√©ment √† la forme naturelle de calcul. <br><br>  Le moteur cr√©e et contr√¥le l'ex√©cution d'un mod√®le d'apprentissage automatique √† l'aide d'un graphique cr√©√© par le compilateur.  Une fois d√©ploy√©, Graph Engine surveille et r√©pond aux IPU ou aux p√©riph√©riques utilis√©s par les applications. <br><br>  L'image ResNet-50 montre l'ensemble du mod√®le.  √Ä ce niveau, il est difficile de faire la distinction entre les sommets individuels, il est donc int√©ressant de regarder des images agrandies.  Voici quelques exemples de sections √† l'int√©rieur des couches d'un r√©seau neuronal. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/dbf/166/408/dbf166408a0b1626a4bd720e1be1dbe9.jpg" alt="image"><br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/d69/9c1/fb6/d699c1fb6f2e43b9f4d03b405c543186.jpg" alt="image"><br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/802/6f4/eab/8026f4eab4ee028d6894159b00421c56.jpg" alt="image"><br><br><h3>  Pourquoi les r√©seaux profonds ont-ils besoin de tant de m√©moire? </h3><br>  De grandes quantit√©s de m√©moire occup√©e sont l'un des plus gros probl√®mes des r√©seaux de neurones profonds.  Les chercheurs tentent de g√©rer la bande passante limit√©e des p√©riph√©riques DRAM, qui devrait √™tre utilis√©e par les syst√®mes modernes pour stocker un grand nombre de poids et d'activations dans un r√©seau neuronal profond. <br><br>  Les architectures ont √©t√© d√©velopp√©es √† l'aide de puces de processeur con√ßues pour le traitement s√©quentiel et l'optimisation de la DRAM pour la m√©moire haute densit√©.  L'interface entre les deux appareils est un goulot d'√©tranglement qui introduit des limitations de bande passante et ajoute une surcharge importante √† la consommation d'√©nergie. <br><br>  Bien que nous n'ayons toujours pas une image compl√®te du cerveau humain et de son fonctionnement, il est g√©n√©ralement clair qu'il n'y a pas de grande installation de stockage s√©par√©e pour la m√©moire.  On pense que la fonction de la m√©moire √† long terme et √† court terme dans le cerveau humain est int√©gr√©e dans la structure des neurones + synapses.  M√™me des organismes simples comme les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vers</a> avec une structure neuronale du cerveau, compos√©e d'un peu plus de 300 neurones, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ont un</a> certain degr√© de fonction de m√©moire. <br><br>  Construire de la m√©moire dans des processeurs conventionnels est un moyen de contourner les goulots d'√©tranglement de la m√©moire en ouvrant une bande passante √©norme avec une consommation d'√©nergie beaucoup moins √©lev√©e.  N√©anmoins, la m√©moire sur une puce est une chose co√ªteuse qui n'est pas con√ßue pour de tr√®s grandes quantit√©s de m√©moire, qui sont connect√©es aux processeurs centraux et graphiques actuellement utilis√©s pour la pr√©paration et le d√©ploiement de r√©seaux de neurones profonds. <br><br>  Par cons√©quent, il est utile d'examiner comment la m√©moire est utilis√©e aujourd'hui dans les unit√©s centrales de traitement et les syst√®mes d'apprentissage en profondeur sur les acc√©l√©rateurs graphiques et de se demander: pourquoi ont-ils besoin de si grands dispositifs de stockage de m√©moire alors que le cerveau humain fonctionne bien sans eux? <br><br>  Les r√©seaux de neurones ont besoin de m√©moire pour stocker les donn√©es d'entr√©e, les param√®tres de poids et les fonctions d'activation, car l'entr√©e est distribu√©e √† travers le r√©seau.  En formation, l'activation en entr√©e doit √™tre conserv√©e jusqu'√† ce qu'elle puisse √™tre utilis√©e pour calculer les erreurs des gradients en sortie. <br><br>  Par exemple, un r√©seau ResNet √† 50 couches a environ 26 millions de param√®tres de pond√©ration et calcule 16 millions d'activations directes.  Si vous utilisez un nombre √† virgule flottante 32 bits pour stocker chaque poids et activation, cela n√©cessitera environ 168 Mo d'espace.  En utilisant une valeur de pr√©cision inf√©rieure pour stocker ces √©chelles et activations, nous pourrions diviser par deux, voire quadrupler, cette exigence de stockage. <br><br>  Un grave probl√®me de m√©moire provient du fait que les GPU s'appuient sur des donn√©es repr√©sent√©es comme des vecteurs denses.  Par cons√©quent, ils peuvent utiliser un seul flux d'instructions (SIMD) pour obtenir un calcul haute densit√©.  Le processeur central utilise des blocs vectoriels similaires pour un calcul haute performance. <br><br>  Dans les GPU, la synapse a une largeur de 1024 bits, ils utilisent donc des donn√©es √† virgule flottante 32 bits, donc ils les d√©composent souvent en mini-lot parall√®le de 32 √©chantillons pour cr√©er des vecteurs de donn√©es 1024 bits.  Cette approche de l'organisation du parall√©lisme vectoriel augmente le nombre d'activations de 32 fois et le besoin de stockage local d'une capacit√© sup√©rieure √† 2 Go. <br><br>  Les GPU et autres machines con√ßues pour l'alg√®bre matricielle sont √©galement soumis √† une charge m√©moire due aux poids ou aux activations du r√©seau neuronal.  Les GPU ne peuvent pas effectuer efficacement de petites convolutions utilis√©es dans les r√©seaux de neurones profonds.  Par cons√©quent, une transformation appel√©e ¬´r√©trogradation¬ª est utilis√©e pour convertir ces convolutions en multiplications matrice-matrice (GEMM), que les acc√©l√©rateurs graphiques peuvent g√©rer efficacement. <br><br>  De la m√©moire suppl√©mentaire est √©galement requise pour stocker les donn√©es d'entr√©e, les valeurs de temps et les instructions de programme.  La mesure de l'utilisation de la m√©moire lors de la formation de ResNet-50 sur un GPU hautes performances a montr√© qu'il n√©cessite plus de 7,5 Go de DRAM locale. <br><br>  Peut-√™tre que quelqu'un d√©cidera qu'une pr√©cision moindre peut r√©duire la quantit√© de m√©moire n√©cessaire, mais ce n'est pas le cas.  Lorsque vous passez les valeurs des donn√©es √† la moiti√© de la pr√©cision des pond√©rations et des activations, vous ne remplissez que la moiti√© de la largeur vectorielle du SIMD, en d√©pensant la moiti√© des ressources informatiques disponibles.  Pour compenser cela, lorsque vous passez de la pr√©cision totale √† la demi-pr√©cision sur le GPU, vous devrez doubler la taille du mini-lot pour provoquer un parall√©lisme de donn√©es suffisant pour utiliser tous les calculs disponibles.  Ainsi, la transition vers des √©chelles de pr√©cision et des activations plus faibles sur le GPU n√©cessite toujours plus de 7,5 Go de m√©moire dynamique en acc√®s libre. <br><br>  Avec autant de donn√©es √† stocker, il est tout simplement impossible de tout int√©grer dans le GPU.  Sur chaque couche du r√©seau neuronal convolutif, il est n√©cessaire de sauvegarder l'√©tat de la DRAM externe, de charger la couche de r√©seau suivante puis de charger les donn√©es dans le syst√®me.  En cons√©quence, l'interface de m√©moire externe, d√©j√† limit√©e par la bande passante m√©moire, souffre de la charge suppl√©mentaire de recharger constamment la balance, ainsi que de sauvegarder et de r√©cup√©rer les fonctions d'activation.  Cela ralentit consid√©rablement le temps d'entra√Ænement et augmente consid√©rablement la consommation d'√©nergie. <br><br>  Il existe plusieurs solutions √† ce probl√®me.  Tout d'abord, des op√©rations telles que les fonctions d'activation peuvent √™tre effectu√©es ¬´sur place¬ª, ce qui vous permet d'√©craser l'entr√©e directement sur la sortie.  Ainsi, la m√©moire existante peut √™tre r√©utilis√©e.  Deuxi√®mement, l'opportunit√© de r√©utilisation de la m√©moire peut √™tre obtenue en analysant la d√©pendance des donn√©es entre les op√©rations sur le r√©seau et la r√©partition de la m√™me m√©moire pour les op√©rations qui ne l'utilisent pas √† ce moment. <br><br>  La deuxi√®me approche est particuli√®rement efficace lorsque l'ensemble du r√©seau neuronal peut √™tre analys√© au stade de la compilation afin de cr√©er une m√©moire allou√©e fixe, car les co√ªts de gestion de la m√©moire sont r√©duits √† presque z√©ro.  Il s'est av√©r√© qu'une combinaison de ces m√©thodes r√©duit l'utilisation de la m√©moire du r√©seau neuronal de deux √† trois fois. <br>  Une troisi√®me approche significative a √©t√© r√©cemment d√©couverte par l'√©quipe Baidu Deep Speech.  Ils ont appliqu√© diverses m√©thodes d'√©conomie de m√©moire pour obtenir une r√©duction de 16 fois de la consommation de m√©moire par les fonctions d'activation, ce qui leur a permis de former des r√©seaux avec 100 couches.  Auparavant, avec la m√™me quantit√© de m√©moire, ils pouvaient former des r√©seaux √† neuf couches. <br><br>  La combinaison de la m√©moire et des ressources de traitement dans un seul appareil a un potentiel important pour augmenter la productivit√© et l'efficacit√© des r√©seaux de neurones convolutifs, ainsi que d'autres formes d'apprentissage automatique.  Vous pouvez faire un compromis entre la m√©moire et les ressources informatiques afin d'√©quilibrer les capacit√©s et les performances du syst√®me. <br><br>  Les r√©seaux de neurones et les mod√®les de connaissances dans d'autres m√©thodes d'apprentissage automatique peuvent √™tre consid√©r√©s comme des graphiques math√©matiques.  Dans ces graphiques, une √©norme quantit√© de parall√©lisme est concentr√©e.  Un processeur parall√®le con√ßu pour utiliser la concurrence dans les graphiques ne repose pas sur un mini-lot et peut r√©duire consid√©rablement la quantit√© de stockage local requise. <br><br>  Les r√©sultats de la recherche moderne ont montr√© que toutes ces m√©thodes peuvent am√©liorer consid√©rablement les performances des r√©seaux de neurones.  Les graphiques modernes et les unit√©s centrales de traitement ont une m√©moire interne tr√®s limit√©e, seulement quelques m√©gaoctets au total.  De nouvelles architectures de processeur sp√©cialement con√ßues pour l'apprentissage automatique offrent un √©quilibre entre la m√©moire et l'informatique sur puce, offrant une augmentation significative des performances et de l'efficacit√© par rapport aux unit√©s centrales de traitement modernes et aux acc√©l√©rateurs graphiques. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr402641/">https://habr.com/ru/post/fr402641/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr402629/index.html">Mes petits relais: l'ordinateur Brainfuck est magique</a></li>
<li><a href="../fr402631/index.html">Quel moniteur de fr√©quence cardiaque choisir pour la nouvelle saison: des solutions de compromis entre trois et quatre mille roubles</a></li>
<li><a href="../fr402633/index.html">Le conte de Battlefield 1 en Full HD sur les graphismes int√©gr√©s dans le processeur et l'assemblage de la console pour "imp√©rissable"</a></li>
<li><a href="../fr402637/index.html">Un √©tudiant de 17 ans corrige une erreur de la NASA</a></li>
<li><a href="../fr402639/index.html">Peter Watts √† propos de SOMA</a></li>
<li><a href="../fr402643/index.html">"Monde mince." Chapitre 10</a></li>
<li><a href="../fr402645/index.html">En utilisant le programme ServoStudio 12 et la carte Arduino, vous pouvez cr√©er votre propre robot sans √©crire une seule ligne de code</a></li>
<li><a href="../fr402649/index.html">Les plus pr√©cis au monde: les cardiofr√©quencem√®tres Valencell pour Jabra, Suunto, Atlas, Sony et autres</a></li>
<li><a href="../fr402651/index.html">Implant en poly√©thyl√®ne de tr√®s haut poids mol√©culaire ayant remplac√© le tissu osseux ou le polym√®re de fer</a></li>
<li><a href="../fr402653/index.html">Les motos ont des probl√®mes avec les cyclistes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
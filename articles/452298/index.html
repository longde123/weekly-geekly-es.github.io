<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÑ ü¶ï üì† Optimizaci√≥n de la recolecci√≥n de basura en un servicio .NET altamente cargado üöµüèº üë©‚Äçüëß üà≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos los d√≠as, decenas de miles de empleados de varios miles de organizaciones de todo el mundo trabajan en Pyrus. Consideramos que la capacidad de r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimizaci√≥n de la recolecci√≥n de basura en un servicio .NET altamente cargado</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452298/">  Todos los d√≠as, decenas de miles de empleados de varios miles de organizaciones de todo el mundo trabajan en Pyrus.  Consideramos que la capacidad de respuesta del servicio (la velocidad de procesamiento de solicitudes) es una ventaja competitiva importante, ya que afecta directamente la experiencia del usuario.  La m√©trica clave para nosotros es el "porcentaje de consultas lentas".  Al estudiar su comportamiento, notamos que una vez por minuto en los servidores de aplicaciones hay pausas de aproximadamente 1000 ms de longitud.  En estos intervalos, el servidor no responde y surge una cola de varias docenas de solicitudes.  En este art√≠culo se analizar√° la b√∫squeda de las causas y la eliminaci√≥n de los cuellos de botella causados ‚Äã‚Äãpor la recolecci√≥n de basura en la aplicaci√≥n. <br><br><img src="https://habrastorage.org/webt/fu/1s/j9/fu1sj9ixpj4nc633ikhwblbhlfs.jpeg"><br><a name="habracut"></a><br>  Los lenguajes de programaci√≥n modernos se pueden dividir en dos grupos.  En lenguajes como C / C ++ o Rust, se usa la administraci√≥n manual de memoria, por lo que los programadores pasan m√°s tiempo escribiendo c√≥digo, administrando la vida √∫til de los objetos y luego depurando.  Al mismo tiempo, los errores debidos al uso incorrecto de la memoria son algunos de los m√°s dif√≠ciles de depurar, por lo que el desarrollo m√°s moderno se lleva a cabo en idiomas con administraci√≥n autom√°tica de memoria.  Estos incluyen, por ejemplo, Java, C #, Python, Ruby, Go, PHP, JavaScript, etc.  Los programadores ahorran tiempo de desarrollo, pero debe pagar el tiempo de ejecuci√≥n adicional que el programa dedica regularmente a la recolecci√≥n de basura, liberando memoria ocupada por objetos para los que no quedan enlaces en el programa.  En programas peque√±os, este tiempo es insignificante, pero a medida que aumenta el n√∫mero de objetos y la intensidad de su creaci√≥n, la recolecci√≥n de basura comienza a hacer una contribuci√≥n notable al tiempo total de ejecuci√≥n del programa. <br><br>  Los servidores web de Pyrus se ejecutan en la plataforma .NET, que utiliza la administraci√≥n autom√°tica de memoria.  La mayor√≠a de las recolecciones de basura son 'detener el mundo', es decir  en el momento de su trabajo, detienen todos los hilos de la aplicaci√≥n.  Los ensamblajes sin bloqueo (en segundo plano) tambi√©n detienen todos los subprocesos, pero durante un per√≠odo de tiempo muy corto.  Durante el bloqueo de subprocesos, el servidor no procesa las solicitudes, las solicitudes existentes se bloquean, se agregan otras nuevas a la cola.  Como resultado, las solicitudes que se procesaron en el momento de la recolecci√≥n de basura se ralentizan directamente, y las solicitudes se procesan m√°s lentamente inmediatamente despu√©s de que se completa la recolecci√≥n de basura debido a las colas acumuladas.  Esto empeora la m√©trica "porcentaje de consultas lentas". <br><br>  Armado con el libro recientemente publicado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Konrad Kokosa: Pro .NET Memory Management</a> (sobre c√≥mo trajimos su primera copia a Rusia en 2 d√≠as, puede escribir una publicaci√≥n por separado), completamente dedicado al tema de la administraci√≥n de memoria en .NET, comenzamos a estudiar el problema. <br><br><h2>  Medida </h2><br>  Para perfilar el servidor web Pyrus, utilizamos la utilidad PerfView ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/Microsoft/perfview</a> ), mejorada para perfilar aplicaciones .NET.  La utilidad se basa en el motor de Rastreo de eventos para Windows (ETW) y tiene un impacto m√≠nimo en el rendimiento de la aplicaci√≥n perfilada, lo que permite su uso en un servidor de combate.  Adem√°s, el impacto en el rendimiento depende de qu√© tipos de eventos y qu√© informaci√≥n recopilamos.  No recopilamos nada: la aplicaci√≥n funciona como de costumbre.  Adem√°s, PerfView no requiere recompilaci√≥n ni reinicio de la aplicaci√≥n. <br><br>  Ejecute la traza PerfView con el par√°metro / GCCollectOnly (tiempo de traza 1,5 horas).  En este modo, solo recolecta eventos de recolecci√≥n de basura y tiene un impacto m√≠nimo en el rendimiento.  Veamos el informe de seguimiento Grupo de memoria / GCStats, y en √©l un resumen de los eventos del recolector de basura: <br><br><img src="https://habrastorage.org/webt/v4/ia/cd/v4iacdyso10-0toycwyijfm0zbm.png"><br><br>  Aqu√≠ vemos varios indicadores interesantes a la vez: <br><ul><li>  El tiempo de pausa de construcci√≥n promedio en la segunda generaci√≥n es de 700 milisegundos, y la pausa m√°xima es de aproximadamente un segundo.  Esta figura muestra el momento en que todos los subprocesos de la aplicaci√≥n .NET se detienen, en particular, esta pausa se agregar√° a todas las solicitudes procesadas. <br></li><li>  El n√∫mero de ensamblajes de la 2da generaci√≥n es comparable al de la 1ra generaci√≥n y es ligeramente menor que el n√∫mero de ensamblajes de la 0a generaci√≥n. <br></li><li>  La columna Inducida enumera 53 ensamblajes en la 2da generaci√≥n.  El ensamblaje inducido es el resultado de una llamada expl√≠cita a GC.Collect ().  En nuestro c√≥digo, no encontramos una sola llamada a este m√©todo, lo que significa que algunas de las bibliotecas utilizadas por nuestra aplicaci√≥n tienen la culpa. <br></li></ul><br>  Expliquemos la observaci√≥n sobre el n√∫mero de recolecciones de basura.  La idea de dividir los objetos por su tiempo de vida se basa en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hip√≥tesis generacional</a> : una parte significativa de los objetos creados muere r√°pidamente, y la mayor√≠a del resto vive mucho tiempo (en otras palabras, pocos objetos que tienen un tiempo de vida "promedio").  Es bajo este modo que el recolector de basura .NET est√° encarcelado, y en este modo los ensambles de segunda generaci√≥n deben ser mucho m√°s peque√±os que la generaci√≥n 0.  Es decir, para el funcionamiento √≥ptimo del recolector de basura, debemos adaptar el trabajo de nuestra aplicaci√≥n a la hip√≥tesis generacional.  Formulemos la regla de la siguiente manera: los objetos deben morir r√°pidamente, sin sobrevivir a la generaci√≥n anterior, o vivir de acuerdo con ellos y vivir all√≠ para siempre.  Esta regla tambi√©n se aplica a otras plataformas que usan administraci√≥n autom√°tica de memoria con separaci√≥n generacional, como Java. <br><br>  Los datos que nos interesan se pueden extraer de otra tabla en el informe de GCStats: <br><br><img src="https://habrastorage.org/webt/m5/7y/je/m57yjedgbkwfpbiwmjkvnbhgl4o.png"><br><br>  Estos son algunos casos en los que una aplicaci√≥n intenta crear un objeto grande (en .NET Framework se crean objetos&gt; 85,000 bytes de tama√±o en el LOH - Mont√≥n de objetos grandes), y tiene que esperar la finalizaci√≥n del ensamblado de segunda generaci√≥n, que tiene lugar en paralelo en segundo plano.  Estas pausas del asignador no son tan cr√≠ticas como las pausas del recolector de basura, ya que afectan solo un hilo.  Antes de eso, utilizamos la versi√≥n de .NET Framework 4.6.1, y en la versi√≥n 4.7.1 Microsoft finaliz√≥ el recolector de basura, ahora le permite asignar memoria en el Mont√≥n de objetos grandes durante la compilaci√≥n en segundo plano de la segunda generaci√≥n: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://docs.microsoft.com / ru-ru / dotnet / framework / whats-new / # common-language-runtime-clr</a> <br>  Por lo tanto, hemos actualizado a la √∫ltima versi√≥n 4.7.2 en ese momento. <br><br><h2>  Construcciones de segunda generaci√≥n </h2><br>  ¬øPor qu√© tenemos tantas versiones de la generaci√≥n anterior?  La primera suposici√≥n es que tenemos una p√©rdida de memoria.  Para probar esta hip√≥tesis, echemos un vistazo al tama√±o de la segunda generaci√≥n (configuramos el monitoreo de los contadores de rendimiento correspondientes en Zabbix).  A partir de los gr√°ficos del tama√±o de segunda generaci√≥n para 2 servidores Pyrus, se puede ver que su tama√±o crece primero (principalmente debido al llenado de cach√©s), pero luego se estabiliza (grandes fallas en el gr√°fico - reinicio regular del servicio web para actualizar la versi√≥n): <br><br><img src="https://habrastorage.org/webt/gg/lc/ce/gglcce4tssnhzgcjfhesec9rcja.png"><br><br>  Esto significa que no hay p√©rdidas de memoria notables, es decir, se produce un gran n√∫mero de ensamblajes de segunda generaci√≥n por otra raz√≥n.  La siguiente hip√≥tesis es que hay mucho tr√°fico de memoria, es decir, muchos objetos caen en la segunda generaci√≥n y muchos objetos mueren all√≠.  PerfView tiene un modo / GCOnly para encontrar dichos objetos.  De los informes de seguimiento, prestemos atenci√≥n a las 'Pilas de muertes de objetos gen 2 (muestreo grueso)', que contiene una selecci√≥n de objetos que mueren en la segunda generaci√≥n, junto con pilas de llamadas de los lugares donde se crearon estos objetos.  Aqu√≠ vemos los siguientes resultados: <br><br><img src="https://habrastorage.org/webt/h7/r2/d0/h7r2d0htyxsnaqrr_ekn_ybilti.png"><br><br>  Una vez abierta la l√≠nea, en el interior vemos una pila de llamadas de esos lugares en el c√≥digo que crean objetos que est√°n a la altura de la segunda generaci√≥n.  Entre ellos est√°n: <br><ul><li>  System.Byte [] Si miras dentro, veremos que m√°s de la mitad son memorias intermedias para la serializaci√≥n en JSON: <br></li></ul><br><img src="https://habrastorage.org/webt/la/up/6v/laup6v0mho5e1tbwjfkfmsgdhog.png"><br><br><ul><li>  Ranura [System.Int32] [] (esto es parte de la implementaci√≥n de HashSet), System.Int32 [], etc.  Este es nuestro c√≥digo que calcula los cach√©s del cliente: los directorios, formularios, listas, amigos, etc. que este usuario ve y que se almacenan en cach√© en su navegador o aplicaci√≥n m√≥vil: <br></li></ul><br><img src="https://habrastorage.org/webt/dx/et/jy/dxetjyvj2ande72qrod6leza6i8.png"><br><br><img src="https://habrastorage.org/webt/v6/k6/r-/v6k6r-wq0qeof0edb6h5jvct-he.png"><br><br>  Curiosamente, las memorias intermedias para JSON y para el almacenamiento en cach√© de clientes son todos objetos temporales que viven en la misma solicitud.  ¬øPor qu√© viven hasta la 2da generaci√≥n?  Tenga en cuenta que todos estos objetos son matrices de un tama√±o bastante grande.  Y en un tama√±o&gt; 85000 bytes, la memoria para ellos se asigna en el Mont√≥n de objetos grandes, que solo se recopila junto con la segunda generaci√≥n. <br><br>  Para verificar, abra la secci√≥n 'Pilas de GC Heap Alloc Ignore Free (Coarse Sampling)' en los resultados de perfview / GCOnly.  All√≠ vemos la l√≠nea LargeObject, en la que PerfView agrupa la creaci√≥n de objetos grandes, y en el interior vemos las mismas matrices que vimos en el an√°lisis anterior.  Reconocemos la causa ra√≠z de los problemas con el recolector de basura: creamos muchos objetos grandes temporales. <br><br><img src="https://habrastorage.org/webt/sy/kr/lk/sykrlkgbmvl9jyny5hl1_ftg4ee.png"><br><br><img src="https://habrastorage.org/webt/f9/6q/mp/f96qmplnj4devma1buedg6fpo8q.png"><br><br><h2>  Cambios en el sistema Pyrus </h2><br>  En funci√≥n de los resultados de la medici√≥n, identificamos las principales √°reas de trabajo adicional: la lucha contra los objetos grandes al calcular las memorias cach√© del cliente y la serializaci√≥n en JSON.  Hay varias soluciones a este problema: <br><ul><li>  Lo m√°s simple es no crear objetos grandes.  Por ejemplo, si se usa el b√∫fer grande B en las transformaciones de datos secuenciales A-&gt; B-&gt; C, entonces a veces estas transformaciones se pueden combinar convirti√©ndolas en A-&gt; C y eliminando la creaci√≥n del objeto B. Esta opci√≥n no siempre es aplicable, pero El m√°s simple y m√°s efectivo. <br></li><li>  Piscina de objetos.  En lugar de crear constantemente nuevos objetos y tirarlos, cargando el recolector de basura, podemos almacenar una colecci√≥n de objetos gratuitos.  En el caso m√°s simple, cuando necesitamos un nuevo objeto, lo tomamos del grupo o creamos uno nuevo si el grupo est√° vac√≠o.  Cuando ya no necesitamos el objeto, lo devolvemos al grupo.  Un buen ejemplo es ArrayPool en .NET Core, que tambi√©n est√° disponible en .NET Framework como parte del paquete System.Buffers Nuget. <br></li><li>  Use objetos peque√±os en lugar de grandes. <br></li></ul><br>  Consideremos por separado ambos casos de objetos grandes: computar cach√©s de clientes y serializar en JSON. <br><br><h2>  C√°lculo de cach√© del cliente </h2><br>  El cliente web de Pyrus y las aplicaciones m√≥viles almacenan en cach√© los datos disponibles para el usuario (proyectos, formularios, usuarios, etc.) El almacenamiento en cach√© se usa para acelerar el trabajo, tambi√©n es necesario para trabajar en modo fuera de l√≠nea.  Las cach√©s se calculan en el servidor y se transfieren al cliente.  Son individuales para cada usuario, ya que dependen de sus derechos de acceso, y a menudo se actualizan, por ejemplo, al cambiar los directorios a los que tiene acceso. <br><br>  Por lo tanto, muchos de los c√°lculos de cach√© del cliente se realizan regularmente en el servidor y se crean muchos objetos temporales de corta duraci√≥n.  Si el usuario es una organizaci√≥n grande, puede obtener acceso a muchos objetos, respectivamente, las memorias cach√© del cliente para √©l ser√°n grandes.  Es por eso que vimos la asignaci√≥n de memoria para grandes matrices temporales en el mont√≥n de objetos grandes. <br><br>  Analicemos las opciones propuestas para deshacerse de la creaci√≥n de objetos grandes: <br><ul><li>  Eliminaci√≥n completa de objetos grandes.  Este enfoque no es aplicable, ya que los algoritmos de preparaci√≥n de datos utilizan, entre otras cosas, la clasificaci√≥n y la uni√≥n de conjuntos, y requieren memorias intermedias temporales. <br></li><li>  Usando un grupo de objetos.  Este enfoque tiene dificultades: <br><ul><li>  La variedad de colecciones utilizadas y los tipos de elementos en ellas: se utilizan HashSet, List y Array (las √∫ltimas 2 se pueden combinar).  Int32, Int64, as√≠ como todo tipo de clases de datos se almacenan en colecciones.  Para cada tipo utilizado, necesitar√° su propio grupo, que tambi√©n almacenar√° colecciones de diferentes tama√±os. <br></li><li>  Dif√≠cil tiempo de vida de las colecciones.  Para obtener beneficios del grupo, los objetos que contenga deber√°n devolverse despu√©s de su uso.  Esto se puede hacer si el objeto se usa en un m√©todo.  Pero en nuestro caso la situaci√≥n es m√°s complicada, ya que muchos objetos grandes viajan entre m√©todos, se colocan en estructuras de datos, se transfieren a otras estructuras, etc. <br></li><li>  Implementaci√≥n  Hay ArrayPool de Microsoft, pero a√∫n necesitamos List y HashSet.  No encontramos ninguna biblioteca adecuada, por lo que tendr√≠amos que implementar las clases nosotros mismos. </li></ul></li><li>  Uso de objetos peque√±os.  Una matriz grande se puede dividir en varias piezas peque√±as, que no cargar√© el mont√≥n de objetos grandes, sino que se crear√°n en la generaci√≥n 0 y luego seguir√°n el camino est√°ndar en la 1ra y 2da.  Esperamos que no est√©n a la altura de la 2da, sino que sean recolectados por el recolector de basura en la 0, o en casos extremos en la 1ra generaci√≥n.  La ventaja de este enfoque es que los cambios en el c√≥digo existente son m√≠nimos.  Dificultades: <br><ul><li>  Implementaci√≥n  No encontramos ninguna biblioteca adecuada, por lo que tendr√≠amos que escribir las clases nosotros mismos.  La falta de bibliotecas es comprensible, ya que el escenario "colecciones que no cargan el mont√≥n de objetos grandes" es un √°mbito muy limitado. </li></ul></li></ul><br>  Decidimos seguir el tercer camino e <strike>inventar nuestra bicicleta</strike> para escribir List y HashSet, sin cargar el mont√≥n de objetos grandes. <br><br><h2>  Lista de piezas </h2><br>  Nuestra ChunkedList &lt;T&gt; implementa interfaces est√°ndar, incluida IList &lt;T&gt;, que requiere cambios m√≠nimos en el c√≥digo existente.  S√≠, y la biblioteca Newtonsoft.Json que utilizamos es capaz de serializarlo autom√°ticamente, ya que implementa IEnumerable &lt;T&gt;: <br><br><pre><code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">sealed</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ChunkedList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; : <span class="hljs-title"><span class="hljs-title">IList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>, <span class="hljs-title"><span class="hljs-title">IList</span></span>, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>, <span class="hljs-title"><span class="hljs-title">IReadOnlyList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IReadOnlyCollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; {</code> </pre> <br>  La lista est√°ndar &lt;T&gt; tiene los siguientes campos: matriz de elementos y el n√∫mero de elementos rellenos.  En ChunkedList &lt;T&gt; hay una matriz de matrices de elementos, la cantidad de matrices completamente llenas, la cantidad de elementos en la √∫ltima matriz.  Cada una de las matrices de elementos con menos de 85,000 bytes: <br><br><img src="https://habrastorage.org/webt/72/zj/js/72zjjs9q6lcfud-l7nq8cy5prdi.png"><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> T[][] chunks; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunk; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunkSize;</code> </pre> <br>  Como la ChunkedList &lt;T&gt; es bastante complicada, escribimos pruebas detalladas sobre ella.  Cualquier operaci√≥n debe probarse en al menos 2 modos: en "peque√±o" cuando la lista completa cabe en una sola pieza de hasta 85,000 bytes de tama√±o, y "grande" cuando consiste en m√°s de una pieza.  Adem√°s, para los m√©todos que cambian el tama√±o (por ejemplo, Agregar), los escenarios son a√∫n mayores: "peque√±o" -&gt; "peque√±o", "peque√±o" -&gt; "grande", "grande" -&gt; "grande", "grande" -&gt; peque√±o ".  Aqu√≠ hay bastantes casos confusos de l√≠mites que las pruebas unitarias funcionan bien. <br><br>  La situaci√≥n se simplifica por el hecho de que algunos de los m√©todos de la interfaz IList no se utilizan y pueden omitirse (como Insertar, Eliminar).  Su implementaci√≥n y pruebas ser√≠an bastante costosas.  Adem√°s, la escritura de pruebas unitarias se simplifica por el hecho de que no necesitamos crear una nueva funcionalidad, ChunkedList &lt;T&gt; deber√≠a comportarse igual que List &lt;T&gt;.  Es decir, todas las pruebas se organizan de la siguiente manera: cree una Lista &lt;T&gt; y ChunkedList &lt;T&gt;, realice las mismas operaciones en ellas y compare los resultados. <br><br>  Medimos el rendimiento utilizando la biblioteca BenchmarkDotNet para asegurarnos de que no ralentizamos mucho nuestro c√≥digo al cambiar de List &lt;T&gt; a ChunkedList &lt;T&gt;.  Probemos, por ejemplo, agregando elementos a la lista: <br><br><pre> <code class="cs hljs">[<span class="hljs-meta"><span class="hljs-meta">Benchmark</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedList&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedList</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> list = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedList&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N; i++) list.Add(i); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list; }</code> </pre> <br>  Y la misma prueba usando List &lt;T&gt; para comparar.  Resultados al agregar 500 elementos (todo cabe en una matriz): <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Media </td><td>  Error </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Memoria asignada / Op </td></tr><tr><td>  Lista est√°ndar </td><td>  1.415 nosotros </td><td>  0.0149 nosotros </td><td>  0.0140 us </td><td>  0,6847 </td><td>  0.0095 </td><td>  - </td><td>  4.21 KB </td></tr><tr><td>  Lista de trozos </td><td>  3.728 nosotros </td><td>  0.0238 nosotros </td><td>  0.0222 us </td><td>  0,6943 </td><td>  0.0076 </td><td>  - </td><td>  4.28 KB </td></tr></tbody></table></div><br>  Resultados al agregar 50,000 elementos (divididos en varias matrices): <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Media </td><td>  Error </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Memoria asignada / Op </td></tr><tr><td>  Lista est√°ndar </td><td>  146,273 nosotros </td><td>  3.1466 nosotros </td><td>  4.8053 nosotros </td><td>  124,7559 </td><td>  124,7559 </td><td>  124,7559 </td><td>  513,23 KB </td></tr><tr><td>  Lista de trozos </td><td>  287.687 nosotros </td><td>  1.4630 nosotros </td><td>  1.2969 nosotros </td><td>  41.5039 </td><td>  20.5078 </td><td>  - </td><td>  256,75 KB </td></tr></tbody></table></div><br><div class="spoiler">  <b class="spoiler_title">Descripci√≥n detallada de las columnas en los resultados.</b> <div class="spoiler_text"><pre> <code class="cs hljs">BenchmarkDotNet=v0<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">.4</span></span>, OS=Windows <span class="hljs-number"><span class="hljs-number">10.0</span></span><span class="hljs-number"><span class="hljs-number">.17763</span></span><span class="hljs-number"><span class="hljs-number">.379</span></span> (<span class="hljs-number"><span class="hljs-number">1809</span></span>/October2018Update/Redstone5) Intel Core i7<span class="hljs-number"><span class="hljs-number">-8700</span></span>K CPU <span class="hljs-number"><span class="hljs-number">3.70</span></span>GHz (Coffee Lake), <span class="hljs-number"><span class="hljs-number">1</span></span> CPU, <span class="hljs-number"><span class="hljs-number">12</span></span> logical and <span class="hljs-number"><span class="hljs-number">6</span></span> physical cores [Host] : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> DefaultJob : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> <span class="hljs-comment"><span class="hljs-comment">// * Hints * Outliers ListAdd.StandardList: Default -&gt; 2 outliers were removed ListAdd.ChunkedList: Default -&gt; 1 outlier was removed // * Legends * Mean : Arithmetic mean of all measurements Error : Half of 99.9% confidence interval StdDev : Standard deviation of all measurements Gen 0/1k Op : GC Generation 0 collects per 1k Operations Gen 1/1k Op : GC Generation 1 collects per 1k Operations Gen 2/1k Op : GC Generation 2 collects per 1k Operations Allocated Memory/Op : Allocated memory per single operation (managed only, inclusive, 1KB = 1024B) 1 us : 1 Microsecond (0.000001 sec)</span></span></code> </pre> <br></div></div><br>  Si observa la columna 'Media', que muestra el tiempo promedio de ejecuci√≥n de la prueba, puede ver que nuestra implementaci√≥n es solo 2-2.5 veces m√°s lenta que el est√°ndar.  Teniendo en cuenta que en el c√≥digo real, las operaciones con listas son solo una peque√±a parte de todas las acciones realizadas, esta diferencia se vuelve insignificante.  Pero la columna 'Gen 2 / 1k op' (el n√∫mero de ensamblajes de la segunda generaci√≥n para 1000 pruebas) muestra que hemos logrado el objetivo: con una gran cantidad de elementos, ChunkedList no crea basura en la segunda generaci√≥n, que era nuestra tarea. <br><br><h2>  Conjunto de piezas </h2><br>  Del mismo modo, ChunkedHashSet &lt;T&gt; implementa la interfaz ISet &lt;T&gt;.  Al escribir el ChunkedHashSet &lt;T&gt;, reutilizamos la peque√±a l√≥gica de fragmentos ya implementada en la ChunkedList.  Para hacer esto, tomamos una implementaci√≥n lista para usar de HashSet &lt;T&gt; de la Fuente de referencia de .NET, disponible bajo la licencia MIT, y reemplazamos los arreglos con ChunkedLists. <br><br>  En las pruebas unitarias, tambi√©n usamos el mismo truco que para las listas: compararemos el comportamiento de ChunkedHashSet &lt;T&gt; con la referencia HashSet &lt;T&gt;. <br><br>  Finalmente, pruebas de rendimiento.  La operaci√≥n principal que utilizamos es la uni√≥n de conjuntos, por lo que lo estamos probando: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedHashSet&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedHashSet</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params">[][] source</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedHashSet&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> arr <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> source) <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>.UnionWith(arr); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; }</code> </pre> <br>  Y exactamente la misma prueba para el HashSet est√°ndar.  Primera prueba para juegos peque√±os: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Media </td><td>  Error </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Memoria asignada / Op </td></tr><tr><td>  StandardHashSet </td><td>  30,16 nosotros </td><td>  0.1046 nosotros </td><td>  0.0979 nosotros </td><td>  9.3079 </td><td>  1.6785 </td><td>  - </td><td>  57,41 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  73.54 nosotros </td><td>  0.5919 nosotros </td><td>  0.5247 us </td><td>  9.5215 </td><td>  1.5869 </td><td>  - </td><td>  58.84 KB </td></tr></tbody></table></div><br>  La segunda prueba para conjuntos grandes que caus√≥ un problema con un mont√≥n de objetos grandes: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">30000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">60000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">30000</span></span>, <span class="hljs-number"><span class="hljs-number">100000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Media </td><td>  Error </td><td>  Stddev </td><td>  Gen 0 / 1k Op </td><td>  Gen 1 / 1k Op </td><td>  Gen 2 / 1k Op </td><td>  Memoria asignada / Op </td></tr><tr><td>  StandardHashSet </td><td>  3,031.30 us </td><td>  32.0797 nosotros </td><td>  28.4378 nosotros </td><td>  699.2188 </td><td>  667.9688 </td><td>  664.0625 </td><td>  4718.23 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  7.189,66 nosotros </td><td>  25.6319 nosotros </td><td>  23.9761 nosotros </td><td>  539.0625 </td><td>  265,6250 </td><td>  7.8125 </td><td>  3280.71 KB </td></tr></tbody></table></div><br>  Los resultados son similares a los listados.  ChunkedHashSet es m√°s lento 2-2.5 veces, pero al mismo tiempo en conjuntos grandes, carga la segunda generaci√≥n 2 √≥rdenes de magnitud menos. <br><br><h2>  Serializaci√≥n en JSON </h2><br>  El servidor web Pyrus proporciona varias API que utilizan diferentes serializaciones.  Descubrimos la creaci√≥n de objetos grandes en la API utilizada por los bots y la utilidad de sincronizaci√≥n (en adelante, la API p√∫blica).  Tenga en cuenta que, b√°sicamente, la API utiliza su propia serializaci√≥n, que no se ve afectada por este problema.  Escribimos sobre esto en el art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://habr.com/en/post/227595/</a> , en la secci√≥n "2.  No sabes d√≥nde est√° el cuello de botella de tu aplicaci√≥n ".  Es decir, la API principal ya est√° funcionando bien, y el problema apareci√≥ en la API p√∫blica a medida que crec√≠a la cantidad de solicitudes y la cantidad de datos en las respuestas. <br><br>  Optimicemos la API p√∫blica.  Usando el ejemplo de la API principal, sabemos que puede devolver una respuesta al usuario en modo de transmisi√≥n.  Es decir, no es necesario crear memorias intermedias intermedias que contengan la respuesta completa, sino escribir la respuesta inmediatamente en la secuencia. <br><br>  Tras una inspecci√≥n m√°s cercana, descubrimos que en el proceso de serializaci√≥n de la respuesta, creamos un b√∫fer temporal para el resultado intermedio ('contenido' es una matriz de bytes que contiene JSON en la codificaci√≥n UTF-8): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] content; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MemoryStream(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> writer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(writer, result); writer.Flush(); content = ms.ToArray(); }</code> </pre> <br>  Veamos d√≥nde se usa el contenido.  Por razones hist√≥ricas, la API p√∫blica se basa en WCF, para el cual XML es el formato est√°ndar de solicitud y respuesta.  En nuestro caso, la respuesta XML tiene un √∫nico elemento 'Binario', dentro del cual se escribe JSON codificado en Base64: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">RawBodyWriter</span></span> : <span class="hljs-title"><span class="hljs-title">BodyWriter</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] _content; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RawBodyWriter</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] content</span></span></span><span class="hljs-function">) : </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">base</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-literal"><span class="hljs-function"><span class="hljs-params"><span class="hljs-literal">true</span></span></span></span></span><span class="hljs-function">)</span></span> { _content = content; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); writer.WriteBase64(_content, <span class="hljs-number"><span class="hljs-number">0</span></span>, _content.Length); writer.WriteEndElement(); } }</code> </pre> <br>  Tenga en cuenta que aqu√≠ no se necesita un b√∫fer temporal.  JSON se puede escribir inmediatamente en el b√∫fer XmlWriter que nos proporciona WCF, codific√°ndolo en Base64 sobre la marcha.  Por lo tanto, iremos por el primer camino, eliminando la asignaci√≥n de memoria: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); Stream stream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Base64Writer(writer); Var sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(stream, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> jsonWriter = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(jsonWriter, _result); jsonWriter.Flush(); } writer.WriteEndElement(); }</code> </pre> <br>  Aqu√≠ Base64Writer es un contenedor simple sobre XmlWriter que implementa la interfaz Stream, que escribe en XmlWriter como Base64.  Al mismo tiempo, desde toda la interfaz, es suficiente implementar solo un m√©todo de escritura, que se llama en StreamWriter: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Base64Writer</span></span> : <span class="hljs-title"><span class="hljs-title">Stream</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> XmlWriter _writer; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Base64Writer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlWriter writer</span></span></span><span class="hljs-function">)</span></span> { _writer = writer; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] buffer, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count</span></span></span><span class="hljs-function">)</span></span> { _writer.WriteBase64(buffer, offset, count); } &lt;...&gt; }</code> </pre> <br><h2>  Gc inducido </h2><br>  Tratemos de lidiar con misteriosas recolecciones de basura inducidas.  Volvimos a verificar nuestro c√≥digo 10 veces para las llamadas de GC.Collect, pero esto fall√≥.  Logr√© capturar estos eventos en PerfView, pero la pila de llamadas no es muy indicativa (DotNETRuntime / GC / Triggered event): <br><br><img src="https://habrastorage.org/webt/ye/j0/qg/yej0qglbieyx_tg05hdgutajhmc.png"><br><br>  Hay una peque√±a pista: llamar a RecycleLimitMonitor.RaiseRecycleLimitEvent antes de la recolecci√≥n de basura inducida.  Rastreemos la pila de llamadas al m√©todo RaiseRecycleLimitEvent: <br><br><pre> <code class="cs hljs">RecycleLimitMonitor.RaiseRecycleLimitEvent(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.AlertProxyMonitors(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.CollectInfrequently(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.PBytesMonitorThread(...)</code> </pre> <br>  Los nombres de los m√©todos son consistentes con sus funciones: <br><ul><li>  En el constructor de RecycleLimitMonitor.RecycleLimitMonitorSingleton, se crea un temporizador que llama a PBytesMonitorThread en un intervalo determinado. <br></li><li>  PBytesMonitorThread recopila estad√≠sticas sobre el uso de la memoria y, en algunas condiciones, llama a CollectInfrerecuentemente. <br></li><li>  CollectInfreually llama a AlertProxyMonitors, obtiene un bool como resultado y llama a GC.Collect () si se vuelve verdadero.  Tambi√©n supervisa el tiempo transcurrido desde la √∫ltima llamada al recolector de basura, y no lo llama con demasiada frecuencia. <br></li><li>  AlertProxyMonitors revisa la lista de aplicaciones web IIS en ejecuci√≥n, para cada una levanta el objeto RecycleLimitMonitor correspondiente y llama a RaiseRecycleLimitEvent. <br></li><li>  RaiseRecycleLimitEvent plantea la lista IObserver &lt;RecycleLimitInfo&gt;.  Los manejadores reciben como par√°metro RecycleLimitInfo, en el que pueden establecer el indicador RequestGC, que vuelve a CollectInfrecasionalmente, provocando una recolecci√≥n de basura inducida. <br></li></ul><br><br>  Una investigaci√≥n adicional revela que los controladores IObserver &lt;RecycleLimitInfo&gt; se agregan en el m√©todo RecycleLimitMonitor.Subscribe (), que se llama en el m√©todo AspNetMemoryMonitor.Subscribe ().  Adem√°s, el controlador predeterminado IObserver &lt;RecycleLimitInfo&gt; (la clase RecycleLimitObserver) se cuelga en la clase AspNetMemoryMonitor, que limpia los cach√©s ASP.NET y, a veces, solicita la recolecci√≥n de basura. <br><br>  El enigma del GC inducido est√° casi resuelto.  Queda por descubrir la pregunta de por qu√© se llama esta recolecci√≥n de basura.  RecycleLimitMonitor monitorea el uso de la memoria IIS (m√°s precisamente, el n√∫mero de bytes privados), y cuando su uso se acerca a un cierto l√≠mite, comienza con un algoritmo bastante confuso para generar el evento RaiseRecycleLimitEvent.  El valor de AspNetMemoryMonitor.ProcessPrivateBytesLimit se utiliza como l√≠mite de memoria y, a su vez, contiene la siguiente l√≥gica: <br><ul><li>  Si el grupo de aplicaciones en IIS se establece en 'L√≠mite de memoria privada (KB)', entonces el valor en kilobytes se toma de all√≠ <br></li><li>  De lo contrario, para sistemas de 64 bits, se toma el 60% de la memoria f√≠sica (para sistemas de 32 bits, la l√≥gica es m√°s complicada). <br></li></ul><br>  La conclusi√≥n de la investigaci√≥n es la siguiente: ASP.NET se est√° acercando a su l√≠mite de memoria y comienza a llamar regularmente a la recolecci√≥n de basura.  El 'L√≠mite de memoria privada (KB)' no estaba configurado, por lo que ASP.NET estaba limitado al 60% de la memoria f√≠sica.  El problema estaba enmascarado por el hecho de que en el servidor del Administrador de tareas mostraba mucha memoria libre y parec√≠a que faltaba.  Hemos aumentado el valor del 'L√≠mite de memoria privada (KB)' en la configuraci√≥n del grupo de aplicaciones en IIS al 80% de la memoria f√≠sica.  Esto alienta a ASP.NET a usar m√°s memoria disponible.  Tambi√©n agregamos la supervisi√≥n del contador de rendimiento '.NET CLR Memory / # Induced GC' para no perderse la pr√≥xima vez que ASP.NET decida que se est√° acercando al l√≠mite de uso de memoria. <br><br><h2>  Mediciones repetidas </h2><br>  Veamos qu√© sucedi√≥ con la recolecci√≥n de basura despu√©s de todos estos cambios.  Comencemos con perfview / GCCollectOnly (tiempo de rastreo - 1 hora), informe GCStats: <br><br><img src="https://habrastorage.org/webt/8b/l3/fn/8bl3fnxpuymka28coyzbo0r5ak4.png"><br><br>  Se puede ver que las asambleas de la segunda generaci√≥n ahora son 2 √≥rdenes de magnitud m√°s peque√±as que la 0 y la 1ra.  Adem√°s, el tiempo de estas asambleas disminuy√≥.  Los ensamblajes inducidos ya no se observan.  Veamos la lista de ensamblajes de la 2da generaci√≥n: <br><br><img src="https://habrastorage.org/webt/mx/oy/tv/mxoytvprkypunnhwtao6o6fboai.png"><br><br>  La columna Gen muestra que todos los ensamblajes de la segunda generaci√≥n se han convertido en segundo plano ('2B' significa segunda generaci√≥n, segundo plano).  Es decir, la mayor parte del trabajo se realiza en paralelo con la ejecuci√≥n de la aplicaci√≥n, y todos los subprocesos se bloquean por un corto tiempo (columna 'Pausar MSec').  Veamos las pausas al crear objetos grandes: <br><br><img src="https://habrastorage.org/webt/qp/04/hp/qp04hpcq35buinfnfjn5uuudnyg.png"><br><br>  Se puede ver que el n√∫mero de tales pausas al crear objetos grandes disminuy√≥ significativamente. <br><br><h2>  Resumen </h2><br>  Gracias a los cambios descritos en el art√≠culo, fue posible reducir significativamente el n√∫mero y la duraci√≥n de los ensamblajes de la segunda generaci√≥n.  Logr√© encontrar la causa de las asambleas inducidas y deshacerme de ellas.  El n√∫mero de ensamblajes de la generaci√≥n 0 y 1 aument√≥, pero su duraci√≥n promedio disminuy√≥ (de ~ 200 ms a ~ 60 ms).  La duraci√≥n m√°xima de ensamblaje de la generaci√≥n 0 y 1 ha disminuido, pero no tan notablemente.  Los ensambles de segunda generaci√≥n se hicieron m√°s r√°pidos, las pausas largas de hasta 1000 ms desaparecieron por completo. <br><br>  En cuanto a la m√©trica clave: "porcentaje de consultas lentas", disminuy√≥ en un 40% despu√©s de todos los cambios. <br><br>  Gracias a nuestro trabajo, nos dimos cuenta de qu√© contadores de rendimiento son necesarios para evaluar la situaci√≥n con la memoria y la recolecci√≥n de basura, y los agregamos a Zabbix para un monitoreo continuo.  Aqu√≠ hay una lista de los m√°s importantes a los que prestamos atenci√≥n y descubrimos el motivo (por ejemplo, un mayor flujo de solicitudes, una gran cantidad de datos transmitidos, un error en la aplicaci√≥n): <br><div class="scrollable-table"><table><tbody><tr><td>  Contador de rendimiento </td><td>  Descripci√≥n </td><td>  Cuando prestar atenci√≥n </td></tr><tr><td>  \ Proceso (*) \ Bytes privados </td><td>  La cantidad de memoria asignada para la aplicaci√≥n. </td><td rowspan="3">  Los valores superan con creces el umbral.  Como umbral, puede tomar la mediana durante 2 semanas a partir de los valores diarios m√°ximos. </td></tr><tr><td>  \ .NET CLR Memory (*) \ # Gen 2 Collections </td><td>  La cantidad de memoria en la generaci√≥n anterior. </td></tr><tr><td>  \ .NET CLR Memory (*) \ Tama√±o de almacenamiento din√°mico de objetos grandes </td><td>  La cantidad de memoria para objetos grandes. </td></tr><tr><td>  \ .NET CLR Memory (*) \% Tiempo en GC </td><td>  El porcentaje de tiempo dedicado a recolectar basura </td><td>  El valor es m√°s del 5%. </td></tr><tr><td>  \ .NET CLR Memory (*) \ # GC inducido </td><td>  N√∫mero de conjuntos inducidos </td><td>  El valor es mayor que 0. </td></tr></tbody></table></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/452298/">https://habr.com/ru/post/452298/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../452284/index.html">Clasificaci√≥n de la cobertura del suelo utilizando eo-learn. Parte 1</a></li>
<li><a href="../452288/index.html">Situaci√≥n: operadores m√≥viles estadounidenses acusados ‚Äã‚Äãde comercio ilegal de geodatos de suscriptores</a></li>
<li><a href="../452290/index.html">Lo que los hackers extra√±an cuando quiebran un banco en PHDays</a></li>
<li><a href="../452294/index.html">Seminario web "Empleado - puerta trasera: t√©cnicas modernas de ingenier√≠a social"</a></li>
<li><a href="../452296/index.html">Hack Positivo D√≠as 9: Concurso de inteligencia competitiva 18 de mayo</a></li>
<li><a href="../452302/index.html">Programa preliminar PyConRu-2019: dos desarrolladores de Python Core, altavoces de Anaconda, Intel, JetBrains, Yandex</a></li>
<li><a href="../452304/index.html">OpenAI AI aprendi√≥ a escribir poemas, art√≠culos y noticias</a></li>
<li><a href="../452306/index.html">Hacia d√≥nde va la tecnolog√≠a financiera, c√≥mo contar la econom√≠a de la unidad y por qu√© desarrollar el emprendimiento interno. Mitap Yandex.Dinero</a></li>
<li><a href="../452310/index.html">Configuraci√≥n de canales de venta de red para gadgets DO-RA</a></li>
<li><a href="../452312/index.html">Las telecomunicaciones brit√°nicas pagar√°n una compensaci√≥n a los suscriptores por desconexiones</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
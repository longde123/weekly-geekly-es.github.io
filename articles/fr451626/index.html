<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏾‍🎓 🔃 👿 Apprendre sans professeur: un étudiant curieux 🏅 🧑🏾‍🤝‍🧑🏾 ♏️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Au cours de la dernière décennie, le machine learning a progressé sans précédent dans des domaines aussi divers que la reconnaissance des formes, les ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprendre sans professeur: un étudiant curieux</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451626/"> Au cours de la dernière décennie, le machine learning a progressé sans précédent dans des domaines aussi divers que la reconnaissance des formes, les robots et les jeux complexes comme le go.  Ces succès ont été principalement obtenus grâce à la formation de réseaux de neurones profonds avec l'un des deux paradigmes - l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage avec un enseignant</a> et l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage avec renforcement</a> .  Les deux paradigmes nécessitent le développement de signaux d'entraînement humain, qui sont ensuite transmis à l'ordinateur.  Dans le cas d'une formation avec un enseignant, ce sont des «objectifs» (par exemple, la signature correcte sous l'image);  dans le cas des renforts, ce sont des «récompenses» pour un comportement réussi (score élevé dans le jeu d'Atari).  Par conséquent, les limites de l'apprentissage sont déterminées par les gens. <br><br>  Et si certains scientifiques pensent qu'un programme de formation suffisamment étendu - par exemple, la capacité de mener à bien un large éventail de tâches - devrait être suffisant pour générer une intelligence à usage général, alors d'autres pensent que la vraie intelligence nécessitera des stratégies d'apprentissage plus indépendantes.  Considérez, par exemple, le processus d'enseignement d'un bébé.  Sa grand-mère peut s'asseoir avec lui et lui montrer patiemment des exemples de canards (servant de signal pédagogique lors de l'apprentissage avec un professeur) ou le récompenser par des applaudissements pour avoir résolu un puzzle avec des cubes (comme dans l'apprentissage renforcé).  Cependant, la plupart du temps, le bébé explore naïvement le monde et comprend l'environnement par la curiosité, le jeu et l'observation.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apprendre sans professeur</a> est un paradigme conçu pour créer une intelligence autonome en récompensant les agents (programmes informatiques) pour étudier les données qu'ils observent, quelles que soient les tâches spécifiques.  En d'autres termes, l'agent est formé pour apprendre. <br><a name="habracut"></a><br>  La principale motivation de l'apprentissage sans enseignant est que si les données transmises aux algorithmes d'apprentissage ont une structure interne extrêmement riche (images, vidéos, texte), les objectifs et les récompenses de la formation sont généralement très secs (l'étiquette «chien» pour cette espèce, ou unité / zéro, indiquant le succès ou l'échec du jeu).  Cela suggère que l'essentiel de ce que l'algorithme étudie devrait consister à comprendre les données elles-mêmes et non à appliquer cette compréhension à la solution de certains problèmes. <br><br><h2>  Décodage des éléments de vision </h2><br>  2012 a été une année marquante pour l'apprentissage en profondeur lorsqu'AlexNet (du nom de l'architecte principal Alex Krizhevsky) a osé concurrencer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le concours de classification ImageNet</a> .  Sa capacité à reconnaître les images n'avait pas d'analogues, mais ce qui se passait sous le capot était encore plus surprenant.  Après avoir analysé les actions d'AlexNet, les scientifiques ont découvert qu'il interprète les images grâce à la construction de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">représentations internes</a> de plus en plus complexes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des</a> données d'entrée.  Les caractéristiques de bas niveau, par exemple, les textures et les visages, sont représentées par des couches inférieures, puis à partir de celles-ci sur des couches supérieures, les concepts d'un niveau supérieur sont combinés, tels que les roues ou les chiens. <br><br>  Cela est étonnamment similaire à la façon dont notre cerveau traite les informations - les visages et les textures simples dans les principales zones liées aux sens sont assemblés en objets complexes comme les visages dans les zones supérieures du cerveau.  Ainsi, une scène complexe peut être assemblée à partir de primitives visuelles, de la même manière que le sens provient des mots individuels qui composent une phrase.  Sans installation directe, les couches AlexNet ont révélé un «dictionnaire» visuel fondamental adapté à la résolution du problème.  D'une certaine manière, le réseau a appris à jouer ce que Ludwig Wittgenstein a appelé le « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jeu de langage</a> », qui passe pas à pas des pixels aux étiquettes d'images. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e0/495/f64/0e0495f644806cd55f03b9c51e8c5059.png"><br>  <i>Dictionnaire visuel du réseau neuronal convolutif.</i>  <i>Pour chaque couche, des images sont créées qui maximisent l'activation de certains neurones.</i>  <i>Ensuite, la réaction de ces neurones à d'autres images peut être interprétée comme la présence ou l'absence de «mots» visuels: textures, étagères, visages de chiens, oiseaux.</i> <br><br><h2>  Formation de transfert </h2><br>  Du point de vue de l'intelligence à usage général, la chose la plus intéressante dans le dictionnaire AlexNet est qu'il peut être réutilisé ou transféré à d'autres tâches visuelles, par exemple, pour reconnaître non seulement des objets individuels, mais aussi des scènes entières.  Le transfert dans un monde en constante évolution est absolument nécessaire, et les gens le font très bien: nous sommes en mesure d'adapter rapidement les compétences et la compréhension acquises par l'expérience (modèle mondial) à toute situation actuelle.  Par exemple, un pianiste de formation classique apprendra facilement à jouer du jazz.  Les agents artificiels qui forment l'image interne correcte du monde devraient probablement avoir les mêmes capacités. <br><br>  Cependant, les représentations obtenues par des classificateurs tels que AlexNet ont leurs limites.  En particulier, étant donné que le réseau est formé pour étiqueter une classe (chien, chat, voiture, volcan) le reste des informations - quelle que soit leur utilité pour d'autres tâches - il ignorera.  Par exemple, les représentations peuvent ne pas capturer l'arrière-plan des images si les étiquettes se réfèrent uniquement aux objets au premier plan.  Une solution possible consiste à donner des signaux d'entraînement plus complets, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des descriptions détaillées des images</a> : pas seulement un «chien», mais «Corgi attrape le frisbee dans un parc ensoleillé».  Cependant, de telles étiquettes sont difficiles à apposer, surtout à grande échelle, et elles peuvent ne pas être encore suffisantes pour percevoir toutes les informations nécessaires à la réalisation de la tâche.  La prémisse de base de l'apprentissage sans enseignant est que la meilleure façon d'apprendre des représentations facilement portables est d'essayer d'apprendre tout ce qui est possible sur les données. <br><br>  Si le concept de transfert à travers la formation des représentations vous semble trop abstrait, imaginez un enfant qui a appris à dessiner des gens dans le style «bâton, bâton, concombre».  Il a trouvé une représentation de l'apparence d'une personne, qui est à la fois très compacte et bien adaptée.  En complétant chaque figure avec certaines fonctionnalités, il peut créer des portraits de tous ses camarades de classe: des lunettes pour son meilleur ami, un t-shirt rouge préféré à son camarade de classe.  Et il a développé cette compétence non pas pour accomplir une tâche spécifique ou recevoir une récompense, mais en réponse à un besoin fondamental de refléter le monde qui l'entoure. <br><br><h2>  Apprendre par la créativité: modèles génératifs </h2><br>  Le but le plus simple de l'apprentissage sans enseignant est peut-être de former l'algorithme pour créer ses propres exemples de données.  T.N.  les modèles génératifs devraient non seulement reproduire les données sur lesquelles ils ont été formés (c'est juste un «souvenir» inintéressant), mais créer un modèle de la classe dont les données ont été tirées.  Pas une photographie spécifique d'un cheval ou d'un arc-en-ciel, mais un ensemble de photographies de chevaux et d'arcs-en-ciel;  pas une déclaration spécifique d'un locuteur particulier, mais la distribution générale des déclarations verbales.  Le principe de base des modèles génératifs est que la possibilité de créer un exemple convaincant des données est la preuve la plus forte qu'elles sont comprises: comme l'a dit Richard Feynman, «ce que je ne peux pas créer, je ne le comprends pas». <br><br>  Jusqu'à présent, le modèle génératif le plus réussi pour les images reste le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Generative-Competitive Network</a> (GSS), dans lequel deux réseaux - le générateur et le discriminateur - entrent dans le concours de reconnaissance, semblable à celui d'un faux spécialiste et d'un détective.  Le générateur produit des images, essayant de faire croire au discriminateur leur réalité;  le discriminateur est récompensé pour avoir détecté des contrefaçons.  Les images générées sont d'abord obtenues de manière aléatoire et bâclée, puis améliorées sur de nombreuses approches, et l'interaction dynamique des réseaux conduit à l'apparition d'images de plus en plus réalistes, qui dans de nombreux cas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ne peuvent être distinguées</a> des vraies photos.  GSS peut également fournir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des paysages détaillés</a> basés sur des croquis approximatifs des utilisateurs. <br><br>  Un simple coup d'œil sur les images ci-dessous sera suffisant pour s'assurer que le réseau a appris à représenter bon nombre des caractéristiques clés des photographies sur lesquelles il a été formé - la structure du corps animal, la texture de l'herbe et les détails du jeu de lumière et d'ombre (même en réfléchissant une bulle de savon).  Une étude attentive révèle de petites anomalies, telles qu'une jambe supplémentaire chez un chien blanc et un étrange angle droit dans les jets d'une des fontaines.  Bien que les créateurs de modèles génératifs tentent de se débarrasser de ces imperfections, le fait que nous puissions les voir parle de l'un des avantages de la reconstruction de données aussi familières que les images: en étudiant des échantillons, les chercheurs peuvent comprendre ce que le modèle a appris et ce qui ne l'a pas encore été. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a9c/6b1/bdd/a9c6b1bdd0e76da554429897796de392.png"><br><br><h2>  Création par prédiction </h2><br>  Une autre famille de réseaux remarquable dans une classe sans enseignant est constituée par les modèles autorégressifs, dans lesquels les données sont divisées en petits morceaux, chacun prédisant à son tour le modèle.  De tels modèles peuvent être utilisés pour générer des données comme suit: premièrement, le réseau devine ce qui se passe, ils alimentent cette conjecture à son entrée, et il devine à nouveau.  L'exemple le plus célèbre est le modèle de langue, où chaque mot suivant est prédit en fonction des précédents: ce modèle fonctionne avec des prédictions de texte qui apparaissent dans diverses applications et lors de l'envoi d'un e-mail.  Les développements récents dans la modélisation de langage vous permettent de créer des passages étonnamment raisonnables - par exemple, empruntés à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenAI GPT-2</a> : <br><blockquote>  <b>Indice sur le système (écrit par l'homme)</b> <br><br>  Les scientifiques ont fait une découverte choquante en découvrant un troupeau de licornes vivant dans la vallée des Andes éloignée et jusque-là inexplorée.  Encore plus surprenant pour les chercheurs, les licornes parlaient un excellent anglais. <br><br>  <b>Texte complété par le modèle (après 10 tentatives)</b> <br><br>  Les scientifiques ont appelé la population "licornes ovides" en raison de leurs cornes distinctives.  Ces licornes à quatre cornes blanc argenté étaient auparavant inconnues de la science.  Et enfin, après deux siècles, le mystère de ce qui a donné naissance à cet étrange phénomène est résolu. <br><br>  Le Dr Jorge Perez, biologiste évolutionniste à l'Université de Lapaz et plusieurs de ses associés ont étudié les Andes lorsqu'ils ont découvert une petite vallée où il n'y avait pas d'autres animaux et personnes.  Perez a remarqué quelque chose dans la vallée qui ressemblait à une fontaine naturelle, entourée de deux pics rocheux et de neige argentée. <br><br>  Puis Perez et les autres sont allés plus loin dans cette vallée.  "Lorsque nous sommes arrivés à l'un des sommets, l'eau semblait bleue et il y avait peu de cristaux à sa surface", a déclaré Perez. <br><br>  Perez et ses amis ont été étonnés de voir un troupeau de licornes.  Ces créatures pouvaient être vues depuis les airs, ne se rapprochant pas trop d'eux pour les voir - elles étaient si proches qu'elles pouvaient toucher leurs cornes. </blockquote>  Une différence intéressante est la description des licornes comme «à quatre cornes»: il est amusant d'étudier les limites de la compréhension du réseau. <br><br>  En contrôlant la séquence d'entrée utilisée pour affiner les prédictions, vous pouvez utiliser des modèles autorégressifs pour traduire une séquence en une autre.  Cette <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">démonstration</a> utilise un modèle autorégressif conditionnel pour traduire le texte en un aspect manuscrit réaliste.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">WaveNet</a> convertit le texte en parole naturelle et est maintenant utilisé pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">générer de la voix pour Google Assistant</a> .  Des progrès similaires dans le réglage et la génération autorégressive peuvent être utilisés pour les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">traductions</a> d'une langue à une autre. <br><br>  Les modèles autorégressifs étudient les données, essayant de prédire chaque partie dans un certain ordre.  Vous pouvez créer une classe de réseaux plus généralisée avec un apprentissage sans professeur, en faisant des prédictions sur n'importe quelle partie des données sur la base d'une autre.  Par exemple, cela peut signifier que nous supprimons un mot de la phrase et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">essayons de le prédire en fonction du reste du texte</a> .  En enseignant un système à travers une interrogation sur lui d'une multitude de prédictions locales, nous le forçons à étudier l'ensemble des données. <br><br>  L'un des problèmes des modèles génératifs est la possibilité de leur utilisation malveillante.  La manipulation de preuves sous la forme de photographies, de vidéos et d'enregistrements audio est possible depuis longtemps, mais les modèles génératifs peuvent grandement faciliter l'édition de ces documents avec une intention malveillante.  Nous avons déjà vu une démonstration de la soi-disant  deepfake - par exemple, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fausse vidéo avec Obama</a> .  Il est gratifiant de voir qu'il y a de sérieuses tentatives pour relever ces défis - par exemple, l'utilisation de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">techniques statistiques</a> pour détecter les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">matériaux synthétiques</a> et confirmer les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">matériaux</a> authentiques, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">familiariser le public avec ce qui se passe</a> , et des discussions sur la limitation de la disponibilité de modèles génératifs formés.  En outre, les modèles génératifs eux-mêmes peuvent être utilisés pour détecter les matériaux fabriqués et les données anormales - par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">détecter les faux discours</a> ou détecter les paiements anormaux pour protéger les utilisateurs contre les fraudeurs.  Les chercheurs doivent travailler sur des modèles génératifs pour mieux les comprendre et réduire les risques à l'avenir. <br><br><h2>  Réinventer l'intelligence </h2><br>  Les modèles génératifs eux-mêmes sont très intéressants, mais chez DeepMind nous les traitons comme une étape sur la voie de l'intelligence à usage général.  Donner à un agent la capacité de générer des données, c'est comment lui donner de l'imagination et, par conséquent, la capacité de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">planifier et de raisonner</a> sur l'avenir.  Nos études montrent que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">formation à la prédiction de</a> divers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aspects de l’environnement,</a> même sans tâche particulière de génération de données, enrichit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le modèle mondial de l’</a> agent et, par conséquent, améliore sa capacité à résoudre des problèmes. <br><br>  Ces résultats chevauchent notre compréhension intuitive de l'esprit humain.  Notre capacité à étudier le monde sans supervision particulière est l'une des propriétés fondamentales de l'intelligence.  Lors d'un voyage d'entraînement, nous pouvons regarder indifféremment par la fenêtre, toucher le velours de coton dans les sièges, considérer les passagers voyageant avec nous.  Nous n'avons pas d'objectif dans ces études: nous pouvons difficilement échapper à notre esprit de la collecte d'informations, et notre cerveau travaille sans relâche pour comprendre le monde qui nous entoure et notre place dans celui-ci. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451626/">https://habr.com/ru/post/fr451626/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451614/index.html">«Ce dont nous discutons en Russie est également pertinent en Occident»: entretien avec Denis Neklyudov</a></li>
<li><a href="../fr451618/index.html">CampusInsight: de la surveillance de l'infrastructure à l'analyse de l'expérience utilisateur</a></li>
<li><a href="../fr451620/index.html">Autorisation automatique sur la carte Strava Heatmap</a></li>
<li><a href="../fr451622/index.html">À propos du comptage de bits, des types non signés dans Kotlin et des situations où il est justifié d'enregistrer des correspondances</a></li>
<li><a href="../fr451624/index.html">Sur la façon dont Harry Potter façonne l'éducation russe, bien sûr, pas là où vous en avez besoin</a></li>
<li><a href="../fr451628/index.html">Top Revue 3D Expo en avril 2019</a></li>
<li><a href="../fr451630/index.html">Surveillance continue - automatisation des contrôles de qualité des logiciels dans CI / CD Pipeline</a></li>
<li><a href="../fr451634/index.html">Comment nous sommes analysés dans les magasins et les restaurants</a></li>
<li><a href="../fr451636/index.html">Cinq ans d'esclavage</a></li>
<li><a href="../fr451638/index.html">Animation dans les applications mobiles: tester Lottie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
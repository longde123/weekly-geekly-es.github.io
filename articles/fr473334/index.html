<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö£üèª üë∂üèΩ üôÜüèø Cat Ghonim: Comment faire en sorte que les chats ne se soulagent pas sur la pelouse √† la maison? üíë üë®üèæ üë®üèª‚Äçüíª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y avait Robert Bond, un programmeur californien de 65 ans. Et il avait une femme jardini√®re qui aimait beaucoup sa pelouse propre. Mais c'est la Ca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cat Ghonim: Comment faire en sorte que les chats ne se soulagent pas sur la pelouse √† la maison?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/473334/"> Il y avait Robert Bond, un programmeur californien de 65 ans.  Et il avait une femme jardini√®re qui aimait beaucoup sa pelouse propre.  Mais c'est la Californie, il n'y a pas de cl√¥tures de deux m√®tres avec un syst√®me de protection pour les chats.  Les chats voisins marchent sur la pelouse et la merde! <br><br><img src="https://habrastorage.org/webt/ee/li/u5/eeliu5qcoz1urdayl5mvncwbjzo.jpeg"><br><br>  Le probl√®me devait √™tre r√©solu.  Comment Robert a-t-il d√©cid√© cela?  Il a achet√© du fer √† son ordinateur, y a connect√© une cam√©ra de surveillance ext√©rieure, puis a fait quelque chose d'inhabituel.Il a t√©l√©charg√© le logiciel gratuit Open Source disponible - un r√©seau de neurones, et a commenc√© √† l'entra√Æner √† reconna√Ætre les chats dans l'image de la cam√©ra.  Et la t√¢che au d√©but semble insignifiante, car si vous apprenez quelque chose et que c'est facile, c'est pour les chats, parce que les chats sont jonch√©s d'Internet, il y en a des dizaines de millions.  Si tout √©tait si simple, mais que les choses sont pires, dans la vraie vie, les chats vont faire la merde surtout la nuit.  Il n'y a pratiquement pas de photos de chats nocturnes faisant pipi sur la pelouse sur Internet.  Et certains chats parviennent m√™me √† boire dans le syst√®me d'irrigation pendant le travail, mais le jettent quand m√™me. <br><br><img src="https://habrastorage.org/webt/0i/uw/_p/0iuw_pgxfmlmkw_w-ztq2t_hbls.jpeg"><a name="habracut"></a><br><br>  Ci-dessous, nous fournissons une description du projet de l'auteur, la version anglaise peut √™tre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">trouv√©e ici</a> . <br><br>  Ce projet √©tait motiv√© par deux choses: le d√©sir d'en savoir plus sur les logiciels de r√©seau neuronal et le d√©sir d'encourager les chats voisins √† sortir ailleurs que sur ma pelouse. <br><br>  Le projet ne comprend que trois composants mat√©riels: la carte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nvidia Jetson TX1</a> , la cam√©ra IP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Foscam FI9800P</a> et le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">photon √† particules</a> connect√© au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">relais</a> .  La cam√©ra est mont√©e sur le c√¥t√© de la maison sur le c√¥t√© de la pelouse.  Elle contacte le point d'acc√®s WI-FI, suivie de Jetson.  Le photon √† particules et les relais sont install√©s dans l'unit√© de contr√¥le de mon syst√®me d'irrigation et connect√©s √† un point d'acc√®s WI-FI dans la cuisine. <br><br>  Dans le processus, la cam√©ra est configur√©e pour surveiller les changements dans la cour.  Lorsque quelque chose change, la cam√©ra transmet un ensemble de 7 images √† Jetson, une par seconde.  Le service propuls√© par Jetson suit les images entrantes, les transf√©rant vers le r√©seau neuronal d'entra√Ænement en profondeur de Caffe.  Si le r√©seau d√©tecte un chat, Jetson envoie un signal au serveur Particle Photon dans le cloud, qui envoie un message √† Photon.  Photon r√©pond en allumant les gicleurs pendant deux minutes. <br><br>  Ici, le chat est entr√© dans le cadre, allumant l'appareil photo: <br><br><img src="https://habrastorage.org/webt/db/yb/o6/dbybo6fzxy4rfhhqpcuqkr0q02q.jpeg"><br><br>  Apr√®s quelques secondes, le chat est entr√© au milieu de la cour, rallumant la cam√©ra et actionnant les arroseurs du syst√®me d'irrigation: <br><br><img src="https://habrastorage.org/webt/oy/44/b2/oy44b223ivw14to9lca8bxwfbhc.jpeg"><br><br><h3>  Installation de la cam√©ra </h3><br>  Il n'y avait rien d'inhabituel √† installer une cam√©ra.  La seule connexion permanente est une connexion filaire de 12 volts qui passe √† travers un petit trou sous le rebord.  J'ai mont√© la cam√©ra sur une bo√Æte en bois pour capturer la cour avant avec une pelouse.  Un tas de fils sont connect√©s √† la cam√©ra, que j'ai cach√© dans une bo√Æte. <br><br>  Suivez les instructions de Foscam pour l'associer √† l'AP de Jetson (voir ci-dessous).  Dans ma configuration, Jetson est √† 10.42.0.1.  J'ai attribu√© une adresse IP fixe de 10.42.0.11 √† la cam√©ra afin qu'elle soit facile √† trouver.  Une fois cela fait, connectez l'ordinateur portable Windows √† la cam√©ra et configurez le param√®tre ¬´Avertissement¬ª pour activer le changement.  Configurez le t√©l√©chargement de 7 images via FTP par avertissement (alerte).  Donnez-lui ensuite l'ID utilisateur et le mot de passe sur Jetson.  Mon appareil photo envoie des images 640 x 360 par FTP √† son r√©pertoire personnel. <br><br>  Ci-dessous, vous pouvez voir les param√®tres qui ont √©t√© s√©lectionn√©s pour la configuration de la cam√©ra. <br><br><img src="https://habrastorage.org/webt/zu/mn/uq/zumnuqz05cz7nq1mvf_jsid-xi0.jpeg"><br><br><h3>  Configuration du photon de particules </h3><br>  Photon √©tait facile √† installer.  Je l'ai mis dans l'unit√© de contr√¥le de l'irrigation. <br><br><img src="https://habrastorage.org/webt/vr/v4/hg/vrv4hg7qfnd1cctippafwmihbp4.jpeg"><br><br>  La bo√Æte noire sur la gauche avec la LED bleue est un convertisseur 24 V AC (5 V) √† 5 V DC achet√© sur eBay.  Vous pouvez voir le relais blanc sur la carte relais et le connecteur bleu √† l'avant.  Le photon lui-m√™me est √† droite.  Les deux sont coll√©s sur un morceau de carton pour les maintenir ensemble. <br><br>  La sortie 5 V du convertisseur est connect√©e au connecteur VIN de photons de particules.  La carte relais est principalement analogique: elle poss√®de un transistor NPN √† collecteur ouvert avec une entr√©e nominale de 3,3 V √† la base du transistor et un relais 3 V.  Le contr√¥leur de photons ne pouvait pas fournir suffisamment de courant pour contr√¥ler le relais, j'ai donc connect√© le collecteur de l'entr√©e du transistor √† 5 V via une r√©sistance avec une r√©sistance de 15 Ohms et une puissance de 1/2 W, limitant le courant.  Les contacts de relais sont connect√©s au ventilateur d'eau en parall√®le avec le circuit de commande normal. <br><br>  Voici le sch√©ma de connexion: <br><br>  Convertisseur 24VAC 24VAC &lt;---&gt; Bo√Ætier de commande 24VAC OUT <br>  Convertisseur 24VAC + 5V &lt;---&gt; Photon VIN, r√©sistance √† la carte relais + 3,3V <br>  Convertisseur 24VAC GND &lt;---&gt; Photon GND, Relais GND <br>  Photon D0 &lt;---&gt; Entr√©e de signal de la carte relais <br>  Relais COM &lt;---&gt; Bo√Ætier de commande 24VAC OUT <br>  Relais NO &lt;---&gt; Vanne d'eau de cour avant <br><br><h3>  Installer Jetson </h3><br>  Les seuls composants mat√©riels ajout√©s √† Jetson sont un SSD SATA et un petit concentrateur USB Belkin.  Le concentrateur poss√®de deux touches sans fil qui connectent un clavier et une souris. <br><br>  Le SSD est apparu sans probl√®me.  Je l'ai reformat√© en EXT4 et l'ai install√© sous / caffe.  Je recommande fortement de supprimer tout le code de votre projet, les r√©f√©rentiels git et les donn√©es d'application de votre carte SD interne Jetson, car il est souvent plus facile d'effacer votre syst√®me lors de la mise √† niveau de Jetpack. <br><br><img src="https://habrastorage.org/webt/8d/u9/j6/8du9j6xa2inpeyxcvjkneoeuxre.jpeg"><br><br>  La configuration d'un point d'acc√®s sans fil √©tait assez simple (vrai!) Si vous avez suivi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce guide</a> .  Utilisez simplement le menu Ubuntu comme indiqu√© et assurez-vous d'ajouter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce param√®tre de configuration</a> . <br><br>  J'ai install√© vsftpd en tant que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">serveur FTP</a> .  La configuration est largement d'origine.  Je n'ai pas activ√© le FTP anonyme.  J'ai donn√© √† la cam√©ra un nom d'utilisateur et un mot de passe qui ne sont plus utilis√©s pour rien. <br><br>  J'ai install√© Caffe en utilisant la recette <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">JetsonHacks</a> .  Je crois qu'il n'y a plus de probl√®me LMDB_MAP_SIZE dans les versions actuelles, alors essayez de le construire avant d'apporter des modifications.  Vous devriez √™tre en mesure d'ex√©cuter les tests et la d√©mo de synchronisation mentionn√©s dans le script shell JetsonHacks.  J'utilise actuellement Cuda 7.0, mais je ne suis pas s√ªr que ce soit significatif √† ce stade.  Utilisez CDNN, il √©conomise une quantit√© importante de m√©moire dans ces petits syst√®mes.  Une fois qu'il est construit, ajoutez le r√©pertoire de construction √† la variable PATH afin que les scripts puissent trouver Caffe.  Ajoutez √©galement le r√©pertoire lib de Caffe Python √† votre PYTHONPATH. <br><br><pre><code class="plaintext hljs">~ $ echo $PATH /home/rgb/bin:/caffe/drive_rc/src:/caffe/drive_rc/std_caffe/caffe/build/tools:/usr/local/cuda-7.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin ~ $ echo $PYTHONPATH /caffe/drive_rc/std_caffe/caffe/python: ~ $ echo $LD_LIBRARY_PATH /usr/local/cuda-7.0/lib:/usr/local/lib</code> </pre> <br>  J'utilise l'option de r√©seau enti√®rement convolutionnel pour la segmentation s√©mantique (FCN).  Voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Berkeley Model Zoo</a> , <a href="">github</a> . <br><br>  J'ai essay√© plusieurs autres r√©seaux et j'ai finalement opt√© pour FCN.  En savoir plus sur le processus de s√©lection dans le prochain article.  Le Fcn32s fonctionne bien sur TX1 - il prend un peu plus de 1 Go de m√©moire, s'ex√©cute en environ 10 secondes et segmente une image 640x360 en environ un tiers de seconde.  Il existe un bon ensemble de scripts dans le r√©f√©rentiel github actuel, et le param√®tre est ind√©pendant de la taille de l'image - il redimensionne le r√©seau pour s'adapter √† ce que vous y jetez. <br><br>  Pour l'essayer, vous devrez d√©ployer les mod√®les Caffe d√©j√† form√©s.  Cela prend quelques minutes: la taille du fichier fcn32s-heavy-pascal.caffemodel d√©passe 500 Mo. <br><br><pre> <code class="plaintext hljs">$ cd voc-fcn32s $ wget `cat caffemodel-url`</code> </pre><br>  Modifiez infer.py en modifiant le chemin d'acc√®s dans la commande Image.open () par le fichier .jpg correspondant.  Modifiez la ligne "net" pour qu'elle pointe vers le mod√®le qui vient d'√™tre charg√©: <br><br><pre> <code class="plaintext hljs"> -net = caffe.Net('fcn8s/deploy.prototxt', 'fcn8s/fcn8s-heavy-40k.caffemodel', caffe.TEST) +net = caffe.Net('voc-fcn32s/deploy.prototxt', 'voc-fcn32s/fcn32s-heavy-pascal.caffemodel', caffe.TEST)</code> </pre><br>  Vous aurez besoin du fichier voc-fcn32s / deploy.prototxt.  Il est facilement g√©n√©r√© √† partir de voc-fcn32s / train.prototxt.  Regardez les changements entre voc-fcn8s / train.prototxt et voc-fcn8s / deploy.prototxt pour voir comment faire, ou vous pouvez l'obtenir √† partir de mon r√©f√©rentiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chasing-cats</a> sur github.  Vous devriez maintenant pouvoir ex√©cuter. <br><br><pre> <code class="plaintext hljs"> $ python infer.py</code> </pre><br>  Mon r√©f√©rentiel comprend plusieurs versions de infer.py, plusieurs utilitaires Python qui connaissent les fichiers segment√©s, le code Photon et les scripts de gestion et les scripts d'exploitation que j'utilise pour d√©marrer et surveiller le syst√®me.  En savoir plus sur le logiciel ci-dessous. <br><br><h3>  S√©lection du r√©seau </h3><br>  Les r√©seaux de neurones pour la reconnaissance d'images sont g√©n√©ralement form√©s pour reconna√Ætre un ensemble d'objets.  Supposons que nous donnons √† chaque objet un index de un √† n.  Le r√©seau de classification r√©pond √† la question "Quels objets dans cette image?"  renvoyer un tableau de z√©ro √† n-1, o√π chaque entr√©e de tableau a une valeur de z√©ro √† un.  Z√©ro signifie que l'objet n'est pas dans l'image.  Une valeur non nulle signifie qu'elle peut √™tre l√† avec une probabilit√© croissante lorsque la valeur approche de l'unit√©.  Voici un chat et un homme dans un tableau de 5 √©l√©ments: <br><br><img src="https://habrastorage.org/webt/oa/ww/ff/oawwffcoudbw13p25vfa44guxna.png"><br><br>  Un r√©seau segment√© segmente les pixels de l'image des zones occup√©es par des objets de notre liste.  Elle r√©pond √† la question en renvoyant un tableau avec un enregistrement correspondant √† chaque pixel de l'image.  Chaque enregistrement a une valeur de z√©ro s'il s'agit d'un pixel d'arri√®re-plan ou une valeur de un √† n pour n objets diff√©rents qu'il peut reconna√Ætre.  Cet exemple fictif peut √™tre le pied d'une personne: <br><br><img src="https://habrastorage.org/webt/ud/l6/tw/udl6twr0wz9obfkxqbx3njhrsms.png"><br><br>  Ce projet fait partie d'un projet plus vaste visant √† contr√¥ler une voiture radiocommand√©e √† l'aide d'un ordinateur.  L'id√©e est d'utiliser un r√©seau de neurones pour d√©terminer la position (position et orientation tridimensionnelles globales) d'une voiture pour lui transmettre des commandes de navigation.  La cam√©ra est fixe et la pelouse est g√©n√©ralement plate.  Je peux utiliser un peu le d√©clencheur pour changer la position 3D afin que le r√©seau neuronal puisse trouver les pixels et l'orientation de l'√©cran.  Le r√¥le du chat dans tout cela est le ¬´but recherch√©¬ª. <br><br>  J'ai commenc√© par penser principalement √† la voiture, car je ne savais pas comment √ßa allait se passer, en supposant que reconna√Ætre un chat avec un r√©seau pr√©-form√© serait trivial.  Apr√®s beaucoup de travail, que je ne d√©crirai pas en d√©tail dans cet article, j'ai d√©cid√© que vous pouvez d√©terminer l'orientation de la voiture avec un degr√© de fiabilit√© assez √©lev√©.  Voici un plan d'entra√Ænement √† un angle de 292,5 degr√©s: <br><br><img src="https://habrastorage.org/webt/7m/kz/hv/7mkzhvtay1em-qvcuomfxjuvdy4.jpeg"><br><br>  La plupart de ces travaux ont √©t√© r√©alis√©s avec le r√©seau de classification, le mod√®le Caffe bvlc_reference_caffenet.  Par cons√©quent, j'ai d√©cid√© de laisser la t√¢che de r√©seau de segmentation d√©terminer la position de la machine sur l'√©cran. <br><br>  Le premier r√©seau que j'ai utilis√© est Faster R-CNN [1].  Il renvoie des bo√Ætes englobantes pour les objets de l'image, pas les pixels.  Mais le r√©seau sur Jetson √©tait trop lent pour cette application.  L'id√©e d'une bo√Æte englobante √©tait tr√®s attrayante, j'ai donc √©galement examin√© le r√©seau ax√© sur la conduite [2].  Elle √©tait √©galement trop lente.  FCN [3] √©tait le r√©seau de segmentation le plus rapide que j'ai essay√©.  ¬´FCN¬ª signifie ¬´r√©seau enti√®rement convolutionnel¬ª, r√©seau enti√®rement convolutionnel, car il ne n√©cessite plus de taille d'image particuli√®re pour √™tre entr√© et se compose uniquement de convolutions / regroupements.  Passer uniquement aux couches convolutives conduit √† une acc√©l√©ration significative, classant mes images d'environ 1/3 de seconde sur Jetson.  FCN comprend un bon ensemble de scripts Python pour la formation et le d√©ploiement facile.  Les scripts Python redimensionnent le r√©seau pour s'adapter √† n'importe quelle taille de l'image entrante, ce qui facilite le traitement de l'image principale.  J'ai eu un gagnant! <br><br>  La version FCN GitHub propose plusieurs options.  J'ai d'abord essay√© le voc-fcn32s.  Cela a parfaitement fonctionn√©.  Voc-fcn32s a √©t√© pr√©-form√© dans 20 classes vocales standard.  Comme c'est trop simple, j'ai essay√© pascalcontext-fcn32s.  Il a √©t√© form√© dans 59 classes, y compris l'herbe et les arbres, donc j'ai pens√© que √ßa devrait √™tre mieux.  Mais il s'est av√©r√© que pas toujours - les images de sortie avaient beaucoup plus de jeux de pixels, et la segmentation des chats et des personnes superpos√©es √† l'herbe et aux buissons n'√©tait pas si pr√©cise.  La segmentation √† partir de siftflow √©tait encore plus complexe, donc je suis rapidement revenu aux options voc. <br><br>  Choisir des r√©seaux vocaux signifie toujours trois choses √† consid√©rer: voc-fcn32s, voc-fcn16s et voc-fcn8s.  Ils diff√®rent par le ¬´pas¬ª de la segmentation de la sortie.  L'√©tape 32 est l'√©tape principale du r√©seau: l'image 640x360 est r√©duite √† un r√©seau 20x11 au moment o√π les couches convolutionnelles sont termin√©es.  Cette segmentation brute ¬´d√©convolue¬ª ensuite √† 640x360, comme d√©crit dans [3].  Les √©tapes 16 et 8 sont r√©alis√©es en ajoutant plus de logique au r√©seau pour une meilleure segmentation.  Je n'ai m√™me pas essay√© - la segmentation sur 32 segments est la premi√®re que j'ai essay√©e et elle est venue, et je m'en suis tenue parce que la segmentation semble assez bonne pour ce projet, et la formation, comme d√©crit, semble plus compliqu√©e pour les deux autres r√©seaux. <br><br><h3>  La formation </h3><br>  La premi√®re chose que j'ai remarqu√©e lorsque j'ai allum√© et d√©marr√© le syst√®me √©tait que seulement environ 30% des chats √©taient reconnus par le r√©seau.  J'ai trouv√© deux raisons √† cela.  Premi√®rement, les chats viennent souvent la nuit, donc la cam√©ra les voit √† la lumi√®re infrarouge.  Cela peut √™tre facilement r√©solu - il suffit d'ajouter quelques images infrarouges segment√©es de chats pour la formation.  Le deuxi√®me probl√®me que j'ai d√©couvert apr√®s avoir examin√© plusieurs centaines de photos de chats dans le kit de formation est que la plupart des photographies appartiennent √† la vari√©t√© ¬´regardez mon joli chat¬ª.  Ce sont des images frontales d'un chat au niveau de l'≈ìil d'un chat.  Soit le chat est allong√© sur le dos, soit allong√© sur les genoux de son propri√©taire.  Ils ne ressemblent pas √† des chats errant dans ma cour.  Encore une fois, il peut √™tre facilement corrig√© avec certaines images diurnes segment√©es. <br><br><img src="https://habrastorage.org/webt/oz/yh/us/ozyhuswgxhoqy0tndmzvqer_lko.jpeg"><br><br>  Comment segmenter un objet dans une image d'entra√Ænement?  Mon approche consiste √† soustraire l'image d'arri√®re-plan puis √† traiter les pixels de premier plan pour indiquer de suivre l'objet.  En pratique, cela fonctionne plut√¥t bien, car dans mes archives de la cam√©ra, il y a g√©n√©ralement une image qui a √©t√© prise quelques secondes avant l'image segment√©e.  Mais il y a des artefacts qui doivent √™tre nettoy√©s, et la segmentation a souvent besoin d'√™tre clarifi√©e, j'ai donc √©crit un utilitaire de pr√©paration grossi√®re pour l'√©dition des segments d'image, src / extract_fg.cpp.  Voir la note en haut du fichier source pour l'utilisation.  C'est un peu maladroit et a de petites erreurs de v√©rification et a besoin d'√™tre raffin√©, mais cela fonctionne assez bien pour la t√¢che. <br><br>  Maintenant que nous avons des images pour la formation, voyons comment proc√©der.  J'ai clon√© voc-fcn32s dans le r√©pertoire rgb_voc_fcn32s.  Tous les noms de fichiers feront r√©f√©rence √† ce r√©pertoire jusqu'√† la fin de cette le√ßon. <br><br><pre> <code class="plaintext hljs"> $ cp -r voc-fcn32s rgb_voc_fcn32s</code> </pre><br>  Code sur mon github, y compris un exemple de fichier de formation dans data / rgb_voc.  Les principaux changements sont indiqu√©s ci-dessous. <br><br><h3>  Format de fichier de formation </h3><br>  La couche de donn√©es distribu√©es attend des images cod√©es en dur et des r√©pertoires de segmentation.  Le fichier de formation a une ligne par fichier;  puis la couche de donn√©es obtient les noms des fichiers image et des segments, en ajoutant des noms de r√©pertoire cod√©s en dur.  Cela n'a pas fonctionn√© pour moi, car j'ai plusieurs classes de donn√©es d'entra√Ænement.  Mes donn√©es d'entra√Ænement ont un ensemble de lignes, chacune contenant une image et une segmentation pour cette image. <br><br><pre> <code class="plaintext hljs"> $ head data/rgb_voc/train.txt /caffe/drive_rc/images/negs/MDAlarm_20160620-083644.jpg /caffe/drive_rc/images/empty_seg.png /caffe/drive_rc/images/yardp.fg/0128.jpg /caffe/drive_rc/images/yardp.seg/0128.png /caffe/drive_rc/images/negs/MDAlarm_20160619-174354.jpg /caffe/drive_rc/images/empty_seg.png /caffe/drive_rc/images/yardp.fg/0025.jpg /caffe/drive_rc/images/yardp.seg/0025.png /caffe/drive_rc/images/yardp.fg/0074.jpg /caffe/drive_rc/images/yardp.seg/0074.png /caffe/drive_rc/images/yard.fg/0048.jpg /caffe/drive_rc/images/yard.seg/0048.png /caffe/drive_rc/images/yard.fg/0226.jpg /caffe/drive_rc/images/yard.seg/0226.png</code> </pre><br>  J'ai remplac√© voc_layers.py par rgb_voc_layers.py, qui comprend le nouveau sch√©ma: <br><br><pre> <code class="plaintext hljs"> --- voc_layers.py 2016-05-20 10:04:35.426326765 -0700 +++ rgb_voc_layers.py 2016-05-31 08:59:29.680669202 -0700 ... - # load indices for images and labels - split_f = '{}/ImageSets/Segmentation/{}.txt'.format(self.voc_dir, - self.split) - self.indices = open(split_f, 'r').read().splitlines() + # load lines for images and labels + self.lines = open(self.input_file, 'r').read().splitlines()</code> </pre><br>  Et modifi√© train.prototxt pour utiliser mon code rgb_voc_layers.  Notez que les arguments sont √©galement diff√©rents. <br><br><pre> <code class="plaintext hljs"> --- voc-fcn32s/train.prototxt 2016-05-03 09:32:05.276438269 -0700 +++ rgb_voc_fcn32s/train.prototxt 2016-05-27 15:47:36.496258195 -0700 @@ -4,9 +4,9 @@ top: "data" top: "label" python_param { - module: "layers" - layer: "SBDDSegDataLayer" - param_str: "{\'sbdd_dir\': \'../../data/sbdd/dataset\', \'seed\': 1337, \'split\': \'train\', \'mean\': (104.00699, 116.66877, 122.67892)}" + module: "rgb_voc_layers" + layer: "rgbDataLayer" + param_str: "{\'input_file\': \'data/rgb_voc/train.txt\', \'seed\': 1337, \'split\': \'train\', \'mean\': (104.00699, 1</code> </pre><br>  Presque le m√™me changement dans val.prototxt: <br><br><pre> <code class="plaintext hljs"> --- voc-fcn32s/val.prototxt 2016-05-03 09:32:05.276438269 -0700 +++ rgb_voc_fcn32s/val.prototxt 2016-05-27 15:47:44.092258203 -0700 @@ -4,9 +4,9 @@ top: "data" top: "label" python_param { - module: "layers" - layer: "VOCSegDataLayer" - param_str: "{\'voc_dir\': \'../../data/pascal/VOC2011\', \'seed\': 1337, \'split\': \'seg11valid\', \'mean\': (104.00699, 116.66877, 122.67892)}" + module: "rgb_voc_layers" + layer: "rgbDataLayer" + param_str: "{\'input_file\': \'data/rgb_voc/test.txt\', \'seed\': 1337, \'split\': \'seg11valid\', \'mean\': (104.00699, 116.66877, 122.67892)}"</code> </pre><br><h3>  Solver.py </h3><br>  Ex√©cutez r√©soudre.py pour commencer votre s√©ance d'entra√Ænement: <br><br><pre> <code class="plaintext hljs"> $ python rgb_voc_fcn32s / solve.py</code> </pre><br>  Il modifie certains des m√©canismes normaux de Caffe.  En particulier, le nombre d'it√©rations est d√©fini en bas du fichier.  Dans ce param√®tre particulier, l'it√©ration est une image car la taille du r√©seau change pour chaque image et les images sont ignor√©es une par une. <br><br>  L'un des avantages de travailler avec Nvidia est que de tr√®s bons √©quipements sont disponibles.  J'ai un Titan int√©gr√© dans un poste de travail, et ma direction n'a pas h√©sit√© √† me laisser l'utiliser pour quelque chose d'aussi douteux que ce projet.  Ma derni√®re course d'entra√Ænement √©tait de 4000 it√©rations, ce qui a pris un peu plus de deux heures sur Titan. <br><br><h3>  J'ai appris quelques trucs </h3><br><ul><li>  Une poign√©e d'images (moins de 50) ont suffi pour entra√Æner le r√©seau √† reconna√Ætre les intrus nocturnes. </li><li>  Les prises de vue nocturnes ont appris au r√©seau √† penser que les ombres sur le sentier sont des chats. </li><li>  Les prises de vue n√©gatives, c'est-√†-dire des images sans pixels segment√©s, aident √† r√©soudre le probl√®me des ombres. </li><li>  Il est facile de recycler le r√©seau √† l'aide d'une cam√©ra fixe afin que tout ce qui diff√®re soit class√© comme quelque chose de al√©atoire. </li><li>  Les chats et les humains, superpos√©s √† des arri√®re-plans al√©atoires, aident √† r√©soudre les probl√®mes li√©s au surentra√Ænement. </li></ul><br>  Comme vous pouvez le voir, le processus est it√©ratif. <br><br><h3>  Recommandations </h3><br>  [1] R-CNN plus rapide: vers la d√©tection d'objets en temps r√©el avec les r√©seaux de propositions de r√©gions Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">abs / 1506.01497v3</a> . <br>  [2] Une √©valuation empirique de l'apprentissage en profondeur sur la conduite sur route Brody Huval, Tao Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayampallil, Mykhaylo Andriluka, Pranav Rajpurkar, Toki Migimatsu, Royce Cheng-Yue, Fernando Cojuj, Andrew Y. Ng <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arXiv: 1504.01716v3</a> , <a href="">github.com/brodyh/caffe.git</a> . <br>  [3] R√©seaux enti√®rement convolutifs pour la segmentation s√©mantique Jonathan Long, Evan Shelhamer, Trevor Darrell <a href="">arXiv: 1411.4038v2</a> , <a href="">github.com/shelhamer/fcn.berkeleyvision.org.git</a> . <br><br><h3>  Conclusions </h3><br>  Afin d'apprendre au r√©seau neuronal √† reconna√Ætre les chats de nuit, il a fallu ajouter les donn√©es n√©cessaires, en les accumulant.  Apr√®s cela, la derni√®re √©tape a √©t√© prise - le syst√®me est connect√© √† la vanne, qui d√©marre le pulv√©risateur.  L'id√©e est que d√®s que le chat p√©n√®tre dans la pelouse et veut s'adapter, il commence √† √™tre arros√©.  Le chat se vide.  La t√¢che est ainsi r√©solue, la femme est heureuse, et tout cet √©trange miracle est un r√©seau neuronal qui enseigne √† reconna√Ætre les chats, d√©couvre qu'Internet n'a pas assez d'images sources pour la formation et qui l'a appris, est devenu le seul r√©seau neuronal au monde √† pouvoir reconna√Ætre les chats de nuit. <br><br>  Il convient de noter que tout cela a √©t√© fait par une personne qui n'est pas un hyperprogrammeur qui a travaill√© dans Yandex ou Google toute sa vie et avec l'aide de mat√©riel, assez bon march√©, compact et simple. <br><br><h3>  Un peu de publicit√© :) </h3><br>  Merci de rester avec nous.  Aimez-vous nos articles?  Vous voulez voir des mat√©riaux plus int√©ressants?  Soutenez-nous en passant une commande ou en le recommandant √† vos amis, une <b>r√©duction de 30% pour les utilisateurs Habr sur un serveur d'entr√©e de gamme analogique unique que nous avons invent√© pour vous:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Toute la v√©rit√© sur VPS (KVM) E5-2650 v4 (6 c≈ìurs) 10 Go DDR4 240 Go SSD 1 Gbps √† partir de 20 $ ou comment diviser le serveur?</a>  (les options sont disponibles avec RAID1 et RAID10, jusqu'√† 24 c≈ìurs et jusqu'√† 40 Go de DDR4). <br><br>  <b>Dell R730xd 2 fois moins cher?</b>  Nous avons seulement <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2 x Intel TetraDeca-Core Xeon 2x E5-2697v3 2.6GHz 14C 64GB DDR4 4x960GB SSD 1Gbps 100 TV √† partir de 199 $</a> aux Pays-Bas!</b>  <b><b>Dell R420 - 2x E5-2430 2.2Ghz 6C 128GB DDR3 2x960GB SSD 1Gbps 100TB - √† partir de 99 $!</b></b>  Pour en savoir plus sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cr√©ation d'un b√¢timent d'infrastructure.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classe utilisant des serveurs Dell R730xd E5-2650 v4 co√ªtant 9 000 euros pour un sou?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr473334/">https://habr.com/ru/post/fr473334/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr473318/index.html">Enqu√™tes t√©l√©phoniques et recherches CRM dans les CFD 3CX, nouveau plugin WP-Live Chat Support, mise √† jour de l'application Android</a></li>
<li><a href="../fr473320/index.html">SpecFlowMaster: comment am√©liorer la qualit√© des tests</a></li>
<li><a href="../fr473324/index.html">Sortir Jira de la d√©charge, par o√π commencer</a></li>
<li><a href="../fr473330/index.html">Testeurs hom√©opathiques ou probl√®mes de recrutement chroniques</a></li>
<li><a href="../fr473332/index.html">Mitya Alexandrov et Dmitry Konstantinov √† la r√©union jug.msk.ru</a></li>
<li><a href="../fr473338/index.html">TDD: comment √©crire correctement les sp√©cifications (d√©crit)</a></li>
<li><a href="../fr473340/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 386 (21-27 octobre 2019)</a></li>
<li><a href="../fr473342/index.html">"La longue route vous attend ..." ou r√©soudre le probl√®me de pr√©vision en C # en utilisant Ml.NET (DataScience)</a></li>
<li><a href="../fr473344/index.html">Concerts et √©v√©nements KudaGo dans votre miroir</a></li>
<li><a href="../fr473346/index.html">Cr√©ation d'une API REST avec Node.js et une base de donn√©es Oracle. 2e partie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
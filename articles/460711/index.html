<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚òÇÔ∏è üë®‚Äçüë©‚Äçüë¶ üåâ Redes neuronales y aprendizaje profundo, cap√≠tulo 3, parte 3: ¬øc√≥mo elegir hiperpar√°metros de redes neuronales? üßöüèº üßïüèª üìí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Contenido 

- Cap√≠tulo 1: uso de redes neuronales para reconocer n√∫meros escritos a mano 
- Cap√≠tulo 2: c√≥mo funciona el algoritmo de retropropagaci√≥n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neuronales y aprendizaje profundo, cap√≠tulo 3, parte 3: ¬øc√≥mo elegir hiperpar√°metros de redes neuronales?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460711/"><div class="spoiler">  <b class="spoiler_title">Contenido</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cap√≠tulo 1: uso de redes neuronales para reconocer n√∫meros escritos a mano</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cap√≠tulo 2: c√≥mo funciona el algoritmo de retropropagaci√≥n</a> </li><li>  Cap√≠tulo 3: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1: mejorar el m√©todo de entrenamiento de redes neuronales</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2: ¬øPor qu√© la regularizaci√≥n ayuda a reducir el reciclaje?</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 3: ¬øc√≥mo elegir hiperpar√°metros de red neuronal?</a> <br></li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cap√≠tulo 4: prueba visual de que las redes neuronales son capaces de calcular cualquier funci√≥n</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cap√≠tulo 5: ¬øpor qu√© las redes neuronales profundas son tan dif√≠ciles de entrenar?</a> </li><li>  Cap√≠tulo 6: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1: aprendizaje profundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2: progreso reciente en el reconocimiento de im√°genes</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ep√≠logo: ¬øexiste un algoritmo simple para crear inteligencia?</a> </li></ul></div></div><br>  Hasta ahora, no he explicado c√≥mo elijo los valores de los hiperpar√°metros: la tasa de aprendizaje Œ∑, el par√°metro de regularizaci√≥n Œª, etc.  Acabo de dar buenos valores de trabajo.  En la pr√°ctica, cuando usa una red neuronal para atacar un problema, puede ser dif√≠cil encontrar buenos hiperpar√°metros.  Imagine, por ejemplo, que nos acaban de informar sobre el problema MNIST y comenzamos a trabajar en √©l, sin saber nada sobre los valores de los hiperpar√°metros adecuados.  Supongamos que tuvimos suerte por casualidad, y en los primeros experimentos elegimos muchos hiperpar√°metros como ya hicimos en este cap√≠tulo: 30 neuronas ocultas, un tama√±o de mini paquete de 10, entrenamiento para 30 eras y el uso de entrop√≠a cruzada.  Sin embargo, elegimos la tasa de aprendizaje Œ∑ = 10.0 y el par√°metro de regularizaci√≥n Œª = 1000.0.  Y esto es lo que vi con tal carrera: <br><a name="habracut"></a><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mnist_loader &gt;&gt;&gt; training_data, validation_data, test_data = \ ... mnist_loader.load_data_wrapper() &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> network2 &gt;&gt;&gt; net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">1000.0</span></span>, ... evaluation_data=validation_data, monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">1030</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">990</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">1009</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> ... Epoch <span class="hljs-number"><span class="hljs-number">27</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">1009</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">28</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">983</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">29</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">967</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span></code> </pre> <br>  ¬°Nuestra clasificaci√≥n no funciona mejor que el muestreo aleatorio!  ¬°Nuestra red funciona como un generador de ruido aleatorio! <br><br>  "Bueno, eso es f√°cil de arreglar", se podr√≠a decir, "simplemente reduzca los hiperpar√°metros como la velocidad de aprendizaje y la regularizaci√≥n".  Desafortunadamente, a priori no tiene informaci√≥n sobre qu√© exactamente estos hiperpar√°metros necesita ajustar.  Quiz√°s el principal problema es que nuestras 30 neuronas ocultas nunca funcionar√°n, independientemente de c√≥mo se seleccionen los otros hiperpar√°metros.  ¬øQuiz√°s necesitamos al menos 100 neuronas ocultas?  O 300?  ¬øO muchas capas ocultas?  ¬øO un enfoque diferente para la codificaci√≥n de salida?  ¬øQuiz√°s nuestra red est√° aprendiendo, pero necesitamos entrenarla m√°s?  ¬øQuiz√°s el tama√±o de los mini paquetes es demasiado peque√±o?  ¬øTal vez nos hubiera ido mejor si volvi√©ramos a la funci√≥n cuadr√°tica de valor?  ¬øQuiz√°s debamos probar un enfoque diferente para inicializar los pesos?  Y as√≠ sucesivamente.  En el espacio de los hiperpar√°metros, es f√°cil perderse.  Y esto realmente puede traer muchos inconvenientes si su red es muy grande o usa grandes cantidades de datos de entrenamiento, y puede entrenarla durante horas, d√≠as o semanas sin recibir resultados.  En tal situaci√≥n, su confianza comienza a pasar.  ¬øQuiz√°s las redes neuronales fueron el enfoque equivocado para resolver su problema?  ¬øQuiz√°s renunci√≥ y hizo apicultura? <br><br>  En esta secci√≥n, explicar√© algunos enfoques heur√≠sticos que puede usar para configurar hiperpar√°metros en una red neuronal.  El objetivo es ayudarlo a elaborar un flujo de trabajo que le permita configurar hiperpar√°metros bastante bien.  Por supuesto, no puedo cubrir todo el tema de la optimizaci√≥n de hiperpar√°metros.  Esta es un √°rea enorme, y este no es un problema que pueda resolverse por completo, o de acuerdo con las estrategias correctas para resolver el acuerdo universal.  Siempre existe la oportunidad de probar alg√∫n otro truco para extraer resultados adicionales de su red neuronal.  Pero la heur√≠stica en esta secci√≥n deber√≠a darle un punto de partida. <br><br><h3>  Estrategia general </h3><br>  Cuando se usa una red neuronal para atacar un nuevo problema, la primera dificultad es obtener resultados no triviales de la red, es decir, exceder una probabilidad aleatoria.  Esto puede ser sorprendentemente dif√≠cil, especialmente cuando se enfrenta a una nueva clase de tareas.  Veamos algunas estrategias que se pueden usar para este tipo de dificultad. <br><br>  Supongamos, por ejemplo, que usted es el primero en atacar la tarea MNIST.  Empiezas con gran entusiasmo, pero el fracaso total de tu primera red es un poco desalentador, como se describe en el ejemplo anterior.  Entonces necesita desmontar el problema en partes.  Necesita deshacerse de todas las im√°genes de entrenamiento y de apoyo, excepto las im√°genes de ceros y unos.  Luego, intente entrenar la red para distinguir 0 de 1. Esta tarea no solo es esencialmente m√°s f√°cil que distinguir los diez d√≠gitos, sino que tambi√©n reduce la cantidad de datos de entrenamiento en un 80%, acelerando el aprendizaje en 5 veces.  Esto le permite realizar experimentos mucho m√°s r√°pido y le brinda la oportunidad de comprender r√°pidamente c√≥mo crear una buena red. <br><br>  Los experimentos pueden acelerarse a√∫n m√°s reduciendo la red a un tama√±o m√≠nimo que probablemente tenga una capacitaci√≥n significativa.  Si cree que es muy probable que la red [784, 10] pueda clasificar los d√≠gitos MNIST mejor que una muestra aleatoria, entonces comience a experimentar con ella.  Ser√° mucho m√°s r√°pido que el entrenamiento [784, 30, 10], y ya puedes hacerlo m√°s tarde. <br><br>  Se puede obtener otra aceleraci√≥n de los experimentos aumentando la frecuencia de seguimiento.  En el programa network2.py, monitoreamos la calidad del trabajo al final de cada era.  Al procesar 50,000 im√°genes por √©poca, tenemos que esperar un tiempo bastante largo, aproximadamente 10 segundos por √©poca en mi computadora port√°til durante la capacitaci√≥n en red [784, 30, 10], antes de recibir comentarios sobre la calidad de la capacitaci√≥n en red.  Por supuesto, diez segundos no son tan largos, pero si desea probar varias docenas de hiperpar√°metros diferentes, comienza a molestar, y si desea probar cientos o miles de opciones, simplemente devasta.  La retroalimentaci√≥n se puede recibir mucho m√°s r√°pido al rastrear la precisi√≥n de la confirmaci√≥n con mayor frecuencia, por ejemplo, cada 1000 im√°genes de entrenamiento.  Adem√°s, en lugar de utilizar el conjunto completo de 10.000 im√°genes de confirmaci√≥n, podemos obtener una estimaci√≥n mucho m√°s r√°pida utilizando solo 100 im√°genes de confirmaci√≥n.  Lo principal es que la red ve suficientes im√°genes para aprender realmente y para obtener una estimaci√≥n de efectividad lo suficientemente buena.  Por supuesto, nuestra network2.py a√∫n no proporciona dicho seguimiento.  Pero como muletas para lograr este efecto con fines ilustrativos, recortamos nuestros datos de entrenamiento a las primeras 1000 im√°genes MNIST.  Intentemos ver qu√© sucede (por la simplicidad del c√≥digo, no utilic√© la idea de dejar solo las im√°genes 0 y 1; esto tambi√©n se puede realizar con un poco m√°s de esfuerzo). <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">1000.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Todav√≠a obtenemos ruido puro, pero tenemos una gran ventaja: la retroalimentaci√≥n se actualiza en fracciones de segundo, y no cada diez segundos.  Esto significa que puede experimentar mucho m√°s r√°pido con la selecci√≥n de hiperpar√°metros, o incluso experimentar con muchos hiperpar√°metros diferentes casi simult√°neamente. <br><br>  En el ejemplo anterior, dej√© el valor de Œª igual a 1000.0, como antes.  Pero dado que cambiamos el n√∫mero de ejemplos de entrenamiento, necesitamos cambiar Œª para que el debilitamiento de los pesos sea el mismo.  Esto significa que cambiamos Œª por 20.0.  En este caso, resultar√° lo siguiente: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">20.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">12</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">14</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">25</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">18</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Si!  Tenemos una se√±al  No es particularmente bueno, pero lo hay.  Esto ya se puede tomar como punto de partida y cambiar los hiperpar√°metros para intentar obtener mejoras adicionales.  Supongamos que decidimos que necesitamos aumentar la velocidad de aprendizaje (como probablemente entendi√≥, decidimos incorrectamente, por la raz√≥n que discutiremos m√°s adelante, pero intentemos hacerlo por ahora).  Para probar nuestra suposici√≥n, giramos Œ∑ a 100.0: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">100.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">20.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Todo esta mal!  Aparentemente, nuestra suposici√≥n era incorrecta, y el problema no estaba en el valor muy bajo de la velocidad de aprendizaje.  Intentamos ajustar Œ∑ a un valor peque√±o de 1.0: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">20.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">62</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">42</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">43</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">61</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Eso esta mejor!  Y as√≠ podemos continuar m√°s all√°, torciendo cada hiperpar√°metro y mejorando gradualmente la eficiencia.  Despu√©s de estudiar la situaci√≥n y encontrar un valor mejorado para Œ∑, procedemos a la b√∫squeda de un buen valor para Œª.  Luego realizaremos un experimento con una arquitectura m√°s compleja, por ejemplo, con una red de 10 neuronas ocultas.  Luego, nuevamente ajustamos los par√°metros para Œ∑ y Œª.  Luego aumentaremos la red a 20 neuronas ocultas.  Un peque√±o retoque de los hiperpar√°metros.  Y as√≠ sucesivamente, evaluando la efectividad en cada paso utilizando parte de nuestros datos de respaldo y utilizando estas estimaciones para seleccionar los mejores hiperpar√°metros.  En el proceso de mejoras, se necesita cada vez m√°s tiempo para ver el efecto de los hiperpar√°metros de ajuste, por lo que podemos reducir gradualmente la frecuencia de seguimiento. <br><br>  Como estrategia general, este enfoque parece prometedor.  Sin embargo, quiero volver a ese primer paso en la b√∫squeda de hiperpar√°metros que permitan que la red aprenda al menos de alguna manera.  De hecho, incluso en el ejemplo anterior, la situaci√≥n era demasiado optimista.  Trabajar con una red que no aprende nada puede ser extremadamente molesto.  Puede ajustar los hiperpar√°metros durante varios d√≠as y no recibir respuestas significativas.  Por lo tanto, me gustar√≠a enfatizar una vez m√°s que en las primeras etapas debe asegurarse de que pueda obtener comentarios r√°pidos de los experimentos.  Intuitivamente, puede parecer que simplificar el problema y la arquitectura solo lo retrasar√°.  De hecho, esto acelera el proceso, porque puede encontrar una red con una se√±al significativa mucho m√°s r√°pido.  Despu√©s de recibir dicha se√±al, a menudo podr√° obtener mejoras r√°pidas al ajustar los hiperpar√°metros.  Como en muchas situaciones de la vida, lo m√°s dif√≠cil es comenzar el proceso. <br><br>  De acuerdo, esta es una estrategia general.  Ahora echemos un vistazo a las recomendaciones espec√≠ficas para prescribir hiperpar√°metros.  Me concentrar√© en la velocidad de aprendizaje Œ∑, el par√°metro de regularizaci√≥n L2 Œª y el tama√±o del mini paquete.  Sin embargo, muchos comentarios ser√°n aplicables a otros hiperpar√°metros, incluidos los relacionados con la arquitectura de red, otras formas de regularizaci√≥n y algunos hiperpar√°metros, que aprenderemos en el libro m√°s adelante, por ejemplo, el coeficiente de impulso. <br><br><h3>  Velocidad de aprendizaje </h3><br>  Supongamos que lanzamos tres redes MNIST con tres velocidades de aprendizaje diferentes, Œ∑ = 0.025, Œ∑ = 0.25 y Œ∑ = 2.5, respectivamente.  Dejaremos el resto de los hiperpar√°metros como estaban en las secciones anteriores: 30 eras, el tama√±o del mini paquete es 10, Œª = 5.0.  Tambi√©n volveremos a usar las 50,000 im√°genes de entrenamiento.  Aqu√≠ hay un gr√°fico que muestra el comportamiento del costo de la capacitaci√≥n (creado por el programa multiple_eta.py): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ec/dc3/761/1ecdc37614b9207a1f03ce2aad97e61d.png"><br><br>  En Œ∑ = 0.025, el costo disminuye suavemente hasta la √∫ltima era.  Con Œ∑ = 0.25, el costo inicialmente disminuye, pero despu√©s de 20 √©pocas est√° saturado, por lo que la mayor√≠a de los cambios resultan ser peque√±as y, obviamente, fluctuaciones aleatorias.  Con Œ∑ = 2.5, el costo var√≠a mucho desde el principio.  Para entender la raz√≥n de estas fluctuaciones, recordamos que el descenso de gradiente estoc√°stico deber√≠a bajar gradualmente al valle de la funci√≥n de costo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/37e/5f9/af1/37e5f9af1985610568cba31157e35763.png"><br><br>  Esta imagen ayuda a imaginar intuitivamente lo que est√° sucediendo, pero no es una explicaci√≥n completa e integral.  M√°s precisamente, pero brevemente, el descenso de gradiente utiliza una aproximaci√≥n de primer orden para la funci√≥n de costo para comprender c√≥mo reducir el costo.  Para Œ∑ m√°s grande, los miembros de una funci√≥n de costo de orden m√°s alto se vuelven m√°s importantes y pueden dominar el comportamiento al romper el descenso del gradiente.  Esto es especialmente probable al acercarse a los m√≠nimos y m√≠nimos locales de la funci√≥n de costo, ya que al lado de tales puntos el gradiente se vuelve peque√±o, lo que facilita el dominio de los miembros de un orden superior. <br><br>  Sin embargo, si Œ∑ es demasiado grande, entonces los pasos ser√°n tan grandes que pueden saltar un m√≠nimo, por lo que el algoritmo ascender√° desde el valle.  Probablemente esto es lo que hace que el precio oscile en Œ∑ = 2.5.  La elecci√≥n de Œ∑ = 0.25 lleva al hecho de que los pasos iniciales realmente nos llevan a un m√≠nimo de la funci√≥n de costo, y solo cuando llegamos a ella, comenzamos a experimentar dificultades para saltar.  Y cuando elegimos Œ∑ = 0.025, no tenemos tales dificultades durante las primeras 30 √©pocas.  Por supuesto, la elecci√≥n de un valor tan peque√±o de Œ∑ crea otra dificultad, es decir, ralentiza el descenso de gradiente estoc√°stico.  El mejor enfoque ser√≠a comenzar con Œ∑ = 0.25, aprender 20 eras y luego ir a Œ∑ = 0.025.  M√°s adelante discutiremos una tasa de aprendizaje tan variable.  Mientras tanto, deteng√°monos en la cuesti√≥n de encontrar un valor adecuado para la velocidad de aprendizaje Œ∑. <br><br>  Con esto en mente, podemos elegir Œ∑ de la siguiente manera.  Primero, evaluamos el valor umbral Œ∑ al cual el costo de los datos de entrenamiento comienza a disminuir inmediatamente, pero no fluct√∫a y no aumenta.  Esta estimaci√≥n no tiene que ser precisa.  El orden puede estimarse comenzando con Œ∑ = 0.01.  Si el costo disminuye en las primeras eras, entonces vale la pena intentar Œ∑ = 0.1, luego 1.0, y as√≠ sucesivamente, hasta que encuentre un valor en el que el valor fluct√∫e o aumente en las primeras eras.  Y viceversa, si el valor fluct√∫a o aumenta en las primeras √©pocas con Œ∑ = 0.01, intente Œ∑ = 0.001, Œ∑ = 0.0001, hasta que encuentre el valor en el que el costo disminuye en las primeras eras.  Este procedimiento le dar√° el orden del valor umbral Œ∑.  Si lo desea, puede refinar su evaluaci√≥n eligiendo el valor m√°s alto para Œ∑, en el cual el costo disminuye en las primeras √©pocas, por ejemplo, Œ∑ = 0.5 o Œ∑ = 0.2 (no se necesita ultra precisi√≥n aqu√≠).  Esto nos da una estimaci√≥n del valor umbral Œ∑. <br><br>  El valor real de Œ∑, obviamente, no debe exceder el umbral seleccionado.  De hecho, para que el valor Œ∑ siga siendo √∫til durante muchas √©pocas, ser√° mejor que use un valor dos veces menor que el umbral.  Tal elecci√≥n generalmente le permitir√° aprender de muchas √©pocas sin ralentizar mucho su aprendizaje. <br><br>  En el caso de los datos MNIST, seguir esta estrategia conducir√° a una estimaci√≥n del orden de umbral de Œ∑ en 0.1.  Despu√©s de un cierto refinamiento, obtenemos el valor Œ∑ = 0.5.  Siguiendo la receta anterior, debemos usar Œ∑ = 0.25 para nuestra velocidad de aprendizaje.  Pero, de hecho, descubr√≠ que Œ∑ = 0.5 funcion√≥ bien durante 30 eras, por lo que no me preocupaba disminuirlo. <br><br>  Todo esto parece bastante sencillo.  Sin embargo, usar el costo de la capacitaci√≥n para seleccionar Œ∑ parece contradecir lo que dije antes: que elegimos hiperpar√°metros, evaluando la efectividad de la red utilizando datos confirmatorios seleccionados.  De hecho, utilizaremos la precisi√≥n de la confirmaci√≥n para seleccionar los hiperpar√°metros de regularizaci√≥n, el tama√±o del mini paquete y par√°metros de red como el n√∫mero de capas y neuronas ocultas, etc.  ¬øPor qu√© hacemos las cosas de manera diferente con la velocidad de aprendizaje?  Honestamente, esta elecci√≥n se debe a mis preferencias est√©ticas personales y probablemente sea parcial.  El argumento es que otros hiperpar√°metros deber√≠an mejorar la precisi√≥n de la clasificaci√≥n final en el conjunto de prueba, por lo que tiene sentido elegirlos en funci√≥n de la precisi√≥n de la confirmaci√≥n.  Sin embargo, la tasa de aprendizaje solo afecta indirectamente la precisi√≥n de la clasificaci√≥n final.  Su objetivo principal es controlar el tama√±o del paso del descenso del gradiente y hacer un seguimiento del costo del entrenamiento de la mejor manera para reconocer un tama√±o de paso demasiado grande.  Pero a√∫n as√≠ esta es una preferencia est√©tica personal.  En las primeras etapas del entrenamiento, el costo del entrenamiento generalmente disminuye solo si aumenta la precisi√≥n de la confirmaci√≥n, por lo que en la pr√°ctica no deber√≠a importar qu√© criterios usar. <br><br><h3>  Usar una parada temprana para determinar la cantidad de eras de entrenamiento </h3><br>  Como mencionamos en este cap√≠tulo, una parada temprana significa que al final de cada era, necesitamos calcular la precisi√≥n de la clasificaci√≥n en los datos de soporte.  Cuando deja de mejorar, dejamos de funcionar.  Como resultado, establecer el n√∫mero de eras se convierte en un asunto simple.  En particular, esto significa que no necesitamos determinar espec√≠ficamente c√≥mo la cantidad de √©pocas depende de otros hiperpar√°metros.  Esto sucede de forma autom√°tica.  Adem√°s, una parada temprana tambi√©n nos impide autom√°ticamente volver a entrenar.  Esto, por supuesto, es bueno, aunque podr√≠a ser √∫til desactivar la parada temprana en las primeras etapas de los experimentos para que pueda ver signos de reentrenamiento y usarlos para ajustar el enfoque de la regularizaci√≥n. <br><br>  Para implementar el RO, necesitamos describir m√°s espec√≠ficamente lo que significa "detener la mejora de la precisi√≥n de la clasificaci√≥n".  Como hemos visto, la precisi√≥n puede ir muy lejos, incluso cuando la tendencia general est√° mejorando.  Si nos detenemos por primera vez, cuando la precisi√≥n disminuye, es casi seguro que no alcanzaremos posibles mejoras adicionales.  El mejor enfoque es dejar de aprender si la mejor precisi√≥n de clasificaci√≥n no mejora durante mucho tiempo.  Supongamos, por ejemplo, que estamos involucrados en MNIST.  Entonces podemos decidir detener el proceso si la precisi√≥n de la clasificaci√≥n no ha mejorado en las √∫ltimas diez eras.  Esto garantiza que no nos detenemos demasiado pronto debido a fallas en el entrenamiento, pero no esperaremos para siempre por cualquier mejora que no suceda. <br><br>  Esta regla de "no mejora en diez eras" es adecuada para el estudio inicial de MNIST.  Sin embargo, las redes a veces pueden alcanzar una meseta cerca de cierta precisi√≥n de clasificaci√≥n, permanecer all√≠ durante bastante tiempo y luego comenzar a mejorar nuevamente.  Si necesita lograr un rendimiento muy bueno, entonces la regla de "ninguna mejora en diez eras" podr√≠a ser demasiado agresiva para eso.  Por lo tanto, recomiendo usar la regla "sin mejora en diez eras" para los experimentos primarios, y gradualmente adopte reglas m√°s suaves cuando comience a comprender mejor el comportamiento de su red: "no hay mejora en m√°s de veinte eras", "no hay mejora en m√°s de cincuenta eras", etc. m√°s lejos  ¬°Por supuesto, esto nos da otro hiperpar√°metro para la optimizaci√≥n!  Pero en la pr√°ctica, este hiperpar√°metro suele ser f√°cil de ajustar para obtener buenos resultados.  Y para tareas que no sean MNIST, la regla de "no mejora en diez eras" puede ser demasiado agresiva o no lo suficientemente agresiva, dependiendo de los detalles de una tarea en particular.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sin embargo, habiendo experimentado un poco, generalmente es bastante f√°cil encontrar una estrategia adecuada de parada temprana. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Todav√≠a no hemos utilizado una parada temprana en nuestros experimentos con MNIST. </font><font style="vertical-align: inherit;">Esto se debe al hecho de que hicimos muchas comparaciones de diferentes enfoques de aprendizaje. </font><font style="vertical-align: inherit;">Para tales comparaciones, es √∫til usar el mismo n√∫mero de eras en todos los casos. </font><font style="vertical-align: inherit;">Sin embargo, vale la pena cambiar network2.py introduciendo el RO en el programa.</font></font><br><br><h3>  Las tareas </h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modifique network2.py para que el PO aparezca all√≠ de acuerdo con la regla "sin cambios para n √©pocas", donde n es un par√°metro configurable. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Piense en una regla de detenci√≥n temprana que no sea "sin cambios en las eras". </font><font style="vertical-align: inherit;">Idealmente, la regla deber√≠a buscar un compromiso entre obtener precisi√≥n con una alta confirmaci√≥n y un tiempo de entrenamiento bastante corto. </font><font style="vertical-align: inherit;">Agregue una regla a network2.py y ejecute tres experimentos que comparen la precisi√≥n de la validaci√≥n y el n√∫mero de eras de entrenamiento con la regla "sin cambios en 10 eras".</font></font></li></ul><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Plan de cambio de velocidad de aprendizaje </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mientras mantuvimos la velocidad de aprendizaje Œ∑ constante. </font><font style="vertical-align: inherit;">Sin embargo, a menudo es √∫til modificarlo. </font><font style="vertical-align: inherit;">En las primeras etapas del proceso de capacitaci√≥n, es muy probable que se asignen pesos completamente incorrectos. </font><font style="vertical-align: inherit;">Por lo tanto, ser√° mejor usar una alta tasa de entrenamiento, lo que har√° que los pesos cambien m√°s r√°pido. </font><font style="vertical-align: inherit;">Entonces puede reducir la velocidad del entrenamiento para hacer un ajuste m√°s fino de las escalas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øC√≥mo delineamos un plan para cambiar la velocidad de aprendizaje? Aqu√≠ puede aplicar muchos enfoques. Una opci√≥n natural es usar la misma idea b√°sica que en RO. Mantenemos constante la velocidad de aprendizaje hasta que la precisi√≥n de la confirmaci√≥n comience a deteriorarse. Luego reducimos el CO en cierta cantidad, digamos, dos o diez veces. Repetimos esto muchas veces hasta que el CO sea 1024 (o 1000) veces menor que el inicial. Y termina el entrenamiento.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un plan para cambiar la velocidad de aprendizaje puede mejorar la eficiencia y tambi√©n abre enormes oportunidades para elegir un plan. </font><font style="vertical-align: inherit;">Y esto puede ser un dolor de cabeza: puede pasar siempre optimizando el plan. </font><font style="vertical-align: inherit;">Para los primeros experimentos, sugerir√≠a usar un solo valor constante de CO. </font><font style="vertical-align: inherit;">Esto le dar√° una buena primera aproximaci√≥n. </font><font style="vertical-align: inherit;">M√°s adelante, si desea obtener la mejor eficiencia de la red, vale la pena experimentar con el plan para cambiar la velocidad de aprendizaje como lo describ√≠. </font><font style="vertical-align: inherit;">Un </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabajo cient√≠fico</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bastante f√°cil de leer </font><a href=""><font style="vertical-align: inherit;">de</font></a><font style="vertical-align: inherit;"> 2010 demuestra las ventajas de las velocidades de aprendizaje variables al atacar MNIST.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ejercicio </font></font></h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modifique network2.py para que implemente el siguiente plan para cambiar la velocidad de aprendizaje: reduzca a la mitad el CR cada vez que la precisi√≥n de la confirmaci√≥n satisfaga la regla de "no cambiar en 10 √©pocas", y deje de aprender cuando la velocidad de aprendizaje descienda a 1/128 de la inicial. </font></font></li></ul><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El par√°metro de regularizaci√≥n Œª </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recomiendo comenzar sin regularizaci√≥n (Œª = 0,0) y determinar el valor de Œ∑, como se indic√≥ anteriormente. </font><font style="vertical-align: inherit;">Usando el valor seleccionado de Œ∑, podemos usar los datos de soporte para seleccionar un buen valor de Œª. </font><font style="vertical-align: inherit;">Comience con Œª = 1.0 (no tengo un buen argumento a favor de tal elecci√≥n), y luego aumente o disminuya en 10 veces para aumentar la eficiencia al trabajar con datos de confirmaci√≥n. </font><font style="vertical-align: inherit;">Habiendo encontrado el orden correcto de magnitud, podemos ajustar el valor de Œª con mayor precisi√≥n. </font><font style="vertical-align: inherit;">Despu√©s de esto, es necesario volver a la optimizaci√≥n Œ∑ nuevamente.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ejercicio </font></font></h3><br><ul><li>     ,        ,  Œª  Œ∑.      ,        Œª?      ,        Œ∑? </li></ul><br><h3>        </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si usa las recomendaciones de esta secci√≥n, ver√° que los valores seleccionados de Œ∑ y Œª no siempre se corresponden exactamente con los que us√© anteriormente. Es solo que el libro tiene limitaciones de texto, lo que a veces hace que sea poco pr√°ctico optimizar los hiperpar√°metros. Piense en todas las comparaciones de los diferentes enfoques de entrenamiento en los que hemos estado trabajando: comparando la funci√≥n de costo cuadr√°tico y la entrop√≠a cruzada, los m√©todos antiguos y nuevos de inicializar pesos, correr con y sin regularizaci√≥n, etc. Para que estas comparaciones tengan sentido, trat√© de no cambiar los hiperpar√°metros entre los enfoques comparados (o escalarlos correctamente). Por supuesto, no hay ninguna raz√≥n para que los mismos hiperpar√°metros sean √≥ptimos para todos los diferentes enfoques de aprendizaje, por lo que los hiperpar√°metros que uso fueron el resultado de un compromiso.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como alternativa, podr√≠a intentar optimizar al m√°ximo todos los hiperpar√°metros para cada enfoque de aprendizaje. </font><font style="vertical-align: inherit;">Ser√≠a un enfoque mejor y m√°s honesto, ya que tomar√≠amos lo mejor de cada enfoque de aprendizaje. </font><font style="vertical-align: inherit;">Sin embargo, hicimos docenas de comparaciones, y en la pr√°ctica esto ser√≠a demasiado costoso computacionalmente. </font><font style="vertical-align: inherit;">Por lo tanto, decid√≠ comprometerme, usar opciones de hiperpar√°metros suficientemente buenas (pero no necesariamente √≥ptimas).</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mini Pack Size </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øC√≥mo elegir el tama√±o del mini-paquete? </font><font style="vertical-align: inherit;">Para responder a esta pregunta, primero supongamos que participamos en capacitaci√≥n en l√≠nea, es decir, usamos un mini paquete de tama√±o 1.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El problema obvio con el aprendizaje en l√≠nea es que el uso de mini-paquetes que consisten en un solo ejemplo de capacitaci√≥n conducir√° a serios errores al estimar el gradiente. Pero, de hecho, estos errores no presentar√°n un problema tan grave. La raz√≥n es que las estimaciones de gradiente individuales no tienen que ser muy precisas. Solo necesitamos obtener una estimaci√≥n suficientemente precisa para que nuestra funci√≥n de costos disminuya. Es como si estuviera tratando de llegar al polo norte magn√©tico, pero tendr√≠a una br√∫jula poco confiable, con cada medici√≥n equivocada en 10-20 grados. Si revisas la br√∫jula con bastante frecuencia y, en promedio, indicar√° la direcci√≥n correcta, eventualmente podr√°s llegar al polo norte magn√©tico.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dado este argumento, parece que deber√≠amos usar el aprendizaje en l√≠nea. Pero en realidad la situaci√≥n es algo m√°s complicada. En la tarea del √∫ltimo cap√≠tulo, se√±al√© que para calcular la actualizaci√≥n de gradiente para todos los ejemplos en el mini paquete, puede usar t√©cnicas matriciales al mismo tiempo, en lugar de un bucle. Dependiendo de los detalles de su hardware y la biblioteca de √°lgebra lineal, puede resultar mucho m√°s r√°pido calcular la estimaci√≥n para el mini-paquete de, digamos, 100 que calcular la estimaci√≥n de gradiente para el mini-paquete en un ciclo para 100 ejemplos de entrenamiento. Esto puede resultar, por ejemplo, solo 50 veces m√°s lento, y no 100. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al principio parece que esto no nos ayuda mucho. Con un tama√±o de mini paquete de 100, la regla de entrenamiento para pesas se ve as√≠:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mtable" id="MJXp-Span-2"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-3" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-4" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-7"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-9" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-10" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-12" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-14" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-15"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-16"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">100</font></font></span></span></span></span></span></span><span class="MJXp-munderover" id="MJXp-Span-17"><span class=""><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19" style="margin-left: 0px;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span><span class="MJXp-mi" id="MJXp-Span-20"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-21"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-23" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="76.867ex" height="6.154ex" viewBox="0 -1558.2 33095.6 2649.6" role="img" focusable="false" style="vertical-align: -2.535ex; max-width: 638px;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(30815,0)"><g id="mjx-eqn-100" transform="translate(0,157)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-28"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-31" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-30" x="890" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-30" x="1390" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-29" x="1891" y="0"></use></g></g><g transform="translate(10345,0)"><g transform="translate(-15,0)"><g transform="translate(0,157)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2192" x="994" y="0"></use><g transform="translate(2272,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2032" x="1013" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-3D" x="3561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="4617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2212" x="5556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-3B7" x="6557" y="0"></use><g transform="translate(7060,0)"><g transform="translate(120,0)"><rect stroke="none" width="1621" height="60" x="0" y="220"></rect><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-31" x="560" y="676"></use><g transform="translate(60,-686)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-30" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-30" x="1001" y="0"></use></g></g></g><g transform="translate(9089,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJSZ2-2211" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-78" x="735" y="-1487"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2207" x="10700" y="0"></use><g transform="translate(11533,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-78" x="1011" y="-213"></use></g></g></g></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> w \rightarrow w' = w-\eta \frac{1}{100} \sum_x \nabla C_x \tag{100} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donde el resumen va sobre los ejemplos de entrenamiento en el mini paquete. </font><font style="vertical-align: inherit;">Comparar con</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-24"><span class="MJXp-mtable" id="MJXp-Span-25"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-26" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-27" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-29" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-30"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-32" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-33" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-34"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-35" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-mi" id="MJXp-Span-37"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-38"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-40" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="76.867ex" height="2.901ex" viewBox="0 -883.9 33095.6 1249" role="img" focusable="false" style="vertical-align: -0.848ex; max-width: 638px;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(30815,0)"><g id="mjx-eqn-101" transform="translate(0,-30)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-28"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-31" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-30" x="890" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-31" x="1390" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-29" x="1891" y="0"></use></g></g><g transform="translate(12164,0)"><g transform="translate(-15,0)"><g transform="translate(0,-30)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2192" x="994" y="0"></use><g transform="translate(2272,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2032" x="1013" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-3D" x="3561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="4617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2212" x="5556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-3B7" x="6557" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2207" x="7060" y="0"></use><g transform="translate(7894,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-78" x="1011" y="-213"></use></g></g></g></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> w \rightarrow w' = w-\eta \nabla C_x \tag{101} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para el aprendizaje en l√≠nea </font><font style="vertical-align: inherit;">Incluso si tarda 50 veces m√°s tiempo en actualizar el mini-paquete, la capacitaci√≥n en l√≠nea parece ser la mejor opci√≥n, ya que nos actualizaremos m√°s a menudo. </font><font style="vertical-align: inherit;">Pero supongamos, sin embargo, que en el caso del mini-paquete, aumentamos la velocidad de aprendizaje en 100 veces, luego la regla de actualizaci√≥n se convierte en:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-41"><span class="MJXp-mtable" id="MJXp-Span-42"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-43" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-44" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-46" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-49" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-50" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-52" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-munderover" id="MJXp-Span-54"><span class=""><span class="MJXp-mo" id="MJXp-Span-55" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56" style="margin-left: 0px;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> x</font></font></span></span></span><span class="MJXp-mi" id="MJXp-Span-57"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àá </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-58"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-59" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-60" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="76.867ex" height="5.31ex" viewBox="0 -1402.6 33095.6 2286.5" role="img" focusable="false" style="vertical-align: -2.053ex; max-width: 638px;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(30815,0)"><g id="mjx-eqn-102" transform="translate(0,354)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-28"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-31" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-30" x="890" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-32" x="1390" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-29" x="1891" y="0"></use></g></g><g transform="translate(11275,0)"><g transform="translate(-15,0)"><g transform="translate(0,354)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2192" x="994" y="0"></use><g transform="translate(2272,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2032" x="1013" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-3D" x="3561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-77" x="4617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2212" x="5556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-3B7" x="6557" y="0"></use><g transform="translate(7227,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJSZ2-2211" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-78" x="735" y="-1487"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMAIN-2207" x="8838" y="0"></use><g transform="translate(9672,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhgzHC3HqQAh70gqIMNW7QIx4hR7nw#MJMATHI-78" x="1011" y="-213"></use></g></g></g></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-3"> w \rightarrow w' = w-\eta \sum_x \nabla C_x \tag{102} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esto es similar a 100 etapas separadas de aprendizaje en l√≠nea con una velocidad de aprendizaje de Œ∑. </font><font style="vertical-align: inherit;">Sin embargo, un paso en el aprendizaje en l√≠nea solo toma 50 veces m√°s tiempo. </font><font style="vertical-align: inherit;">Por supuesto, en realidad esto no es exactamente 100 niveles de aprendizaje en l√≠nea, ya que en el minipaquete todos los ‚àáC </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> se eval√∫an para el mismo conjunto de pesos, en contraste con el aprendizaje acumulativo que ocurre en el caso en l√≠nea. </font><font style="vertical-align: inherit;">Y, sin embargo, parece que el uso de mini paquetes m√°s grandes acelerar√° el proceso.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teniendo en cuenta todos estos factores, elegir el mejor tama√±o de mini paquete es un compromiso. Elija demasiado peque√±o y no obtenga el beneficio completo de buenas bibliotecas matriciales optimizadas para hardware r√°pido. Elija demasiado grande y no actualizar√° el peso con la frecuencia suficiente. Debe elegir un valor de compromiso que maximice la velocidad de aprendizaje. Afortunadamente, la elecci√≥n del tama√±o de mini paquete a la que se maximiza la velocidad es relativamente independiente de otros hiperpar√°metros (excepto la arquitectura general), por lo tanto, para encontrar un buen tama√±o de mini paquete, no es necesario optimizarlos. Por lo tanto, ser√° suficiente usar valores aceptables (no necesariamente √≥ptimos) para otros hiperpar√°metros, y luego probar varios tama√±os diferentes de mini-paquetes, escalando Œ∑, como se indic√≥ anteriormente.Cree un gr√°fico de la precisi√≥n de la confirmaci√≥n en funci√≥n del tiempo (¬°tiempo transcurrido real, no eras!), Y elija un tama√±o de mini paquete que ofrezca la mejora de rendimiento m√°s r√°pida. Con el tama√±o de mini paquete seleccionado, puede proceder a optimizar otros hiperpar√°metros.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por supuesto, como ya sin duda entendi√≥, en nuestro trabajo no llev√© a cabo tal optimizaci√≥n. </font><font style="vertical-align: inherit;">En nuestra implementaci√≥n de la Asamblea Nacional, no se utiliza en absoluto un enfoque r√°pido para actualizar los mini paquetes. </font><font style="vertical-align: inherit;">Simplemente utilic√© el mini-paquete tama√±o 10 sin comentarlo ni explicarlo, en casi todos los ejemplos. </font><font style="vertical-align: inherit;">En general, podr√≠amos acelerar el aprendizaje al reducir el tama√±o del mini-paquete. </font><font style="vertical-align: inherit;">No hice esto, en particular, porque mis experimentos preliminares sugirieron que la aceleraci√≥n ser√≠a bastante modesta. </font><font style="vertical-align: inherit;">Pero en implementaciones pr√°cticas, definitivamente nos gustar√≠a implementar el enfoque m√°s r√°pido para actualizar los mini paquetes, y tratar de optimizar su tama√±o para maximizar la velocidad general.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> T√©cnicas automatizadas </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Describ√≠ estos enfoques heur√≠sticos como algo que necesita ser ajustado a mano. La optimizaci√≥n manual es una buena manera de tener una idea de c√≥mo funciona NS. Sin embargo, y, por cierto, no es sorprendente que ya se haya realizado una gran cantidad de trabajo en la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">automatizaci√≥n de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> este proyecto. Una t√©cnica com√∫n es una b√∫squeda de cuadr√≠cula que tamiza sistem√°ticamente una cuadr√≠cula en el espacio de los hiperpar√°metros. En </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2012</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> se puede encontrar una descripci√≥n general de los logros y limitaciones de esta t√©cnica (as√≠ como recomendaciones sobre alternativas de f√°cil implementaci√≥n) </font><font style="vertical-align: inherit;">. Se han propuesto muchas t√©cnicas sofisticadas. No los revisar√© todos, pero quiero se√±alar el prometedor trabajo de 2012, utilizando </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la optimizaci√≥n bayesiana de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> hiperpar√°metros. El c√≥digo del trabajo est√° </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">abierto a todos.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , y con cierto √©xito fue utilizado por otros investigadores. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Resumir </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Usando las reglas de pr√°ctica que he descrito, no obtendr√° los mejores resultados de su PS de todos los posibles. Pero es probable que le brinden un buen punto de partida y una base para futuras mejoras. En particular, b√°sicamente describ√≠ hiperpar√°metros de forma independiente. En la pr√°ctica, hay una conexi√≥n entre ellos. Puede experimentar con Œ∑, decidir que ha encontrado el valor correcto, luego comenzar a optimizar Œª y descubrir que viola su optimizaci√≥n Œ∑. En la pr√°ctica, es √∫til moverse en diferentes direcciones, acerc√°ndose gradualmente a los buenos valores. Sobre todo, tenga en cuenta que los enfoques heur√≠sticos que he descrito son simples reglas de pr√°ctica, pero no algo tallado en piedra. Debe buscar se√±ales de que algo no funciona y tener ganas de experimentar. En particularControle cuidadosamente el comportamiento de su red neuronal, especialmente la precisi√≥n de la confirmaci√≥n.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La complejidad de la elecci√≥n de los hiperpar√°metros se ve agravada por el hecho de que el conocimiento pr√°ctico de su elecci√≥n se extiende a muchos trabajos y programas de investigaci√≥n, y a menudo solo est√° en la cabeza de los profesionales individuales. Hay una gran cantidad de trabajo con descripciones de qu√© hacer (a menudo en conflicto entre s√≠). Sin embargo, hay varios trabajos particularmente √∫tiles que sintetizan y resaltan una gran parte de este conocimiento. En </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">el</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Joshua Benji partir de 2012 da consejos pr√°cticos sobre el uso de descenso de gradiente de propagaci√≥n hacia atr√°s y la formaci√≥n de la Asamblea Nacional, incluyendo la Asamblea Nacional y profundo. Benjio describe muchos de los detalles con mucho m√°s detalle. Que yo, incluida una b√∫squeda sistem√°tica de hiperpar√°metros. Otro buen trabajo es el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabajo.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1998 Yanna Lekuna y otros. Ambas obras aparecen en el libro extremadamente √∫til de 2012, que contiene muchos trucos de uso frecuente en la Asamblea Nacional: " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Redes neuronales: trucos artesanales</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ". El libro es costoso, pero muchos de sus art√≠culos fueron publicados en Internet por sus autores, y se pueden encontrar en los motores de b√∫squeda.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De estos art√≠culos, y especialmente de nuestros propios experimentos, una cosa queda clara: el problema de optimizar los hiperpar√°metros no se puede resolver por completo. Siempre hay otro truco que puedes intentar para mejorar la eficiencia. Los escritores dicen que un libro no puede terminarse, sino que solo puede descartarse. Lo mismo es cierto para la optimizaci√≥n NS: el espacio de los hiperpar√°metros es tan grande que la optimizaci√≥n no se puede completar, sino que solo se puede detener, dejando el NS a los descendientes. Por lo tanto, su objetivo ser√° desarrollar un flujo de trabajo que le permita llevar a cabo r√°pidamente una buena optimizaci√≥n, mientras le da la oportunidad de probar opciones de optimizaci√≥n m√°s detalladas si es necesario.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Las dificultades con la selecci√≥n de hiperpar√°metros hacen que algunas personas se quejen de que los NS requieren demasiado esfuerzo en comparaci√≥n con otras t√©cnicas de MO. He escuchado muchas variantes de quejas como: ‚ÄúS√≠, un NS bien ajustado puede brindar la mejor eficiencia al resolver un problema. Pero por otro lado, puedo probar un bosque aleatorio [o SVM, o cualquier otra tecnolog√≠a favorita], y simplemente funciona. No tengo tiempo para averiguar qu√© NA es el adecuado para m√≠ ". Por supuesto, desde un punto de vista pr√°ctico, es bueno tener t√©cnicas f√°ciles de usar con un amigo. Esto es especialmente bueno cuando reci√©n est√° comenzando a trabajar con una tarea, y todav√≠a no est√° claro si el MO puede ayudarlo a resolverlo. Por otro lado, si es importante para usted lograr resultados √≥ptimos, es posible que deba probar varios enfoques que requieren un conocimiento m√°s especializado. Seria genialsi MO siempre fue f√°cil, pero no hay razones por las que deber√≠a ser a priori trivial.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Otras tecnicas </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cada una de las t√©cnicas desarrolladas en este cap√≠tulo es valiosa en s√≠ misma, pero esta no es la √∫nica raz√≥n por la que las describ√≠. </font><font style="vertical-align: inherit;">Es m√°s importante familiarizarse con algunos de los problemas que pueden surgir en el campo de NA y con un estilo de an√°lisis que pueda ayudar a superarlos. </font><font style="vertical-align: inherit;">En cierto modo, estamos aprendiendo a pensar sobre el NS. </font><font style="vertical-align: inherit;">En el resto de este cap√≠tulo, describir√© brevemente un conjunto de otras t√©cnicas. </font><font style="vertical-align: inherit;">Sus descripciones no ser√°n tan profundas como en las anteriores, pero deben transmitir algunas sensaciones con respecto a la variedad de t√©cnicas encontradas en el campo de NA.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Variaciones del descenso de gradiente estoc√°stico </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El descenso de gradiente estoc√°stico a trav√©s de la propagaci√≥n hacia atr√°s nos sirvi√≥ durante el ataque al problema de clasificar n√∫meros escritos a mano de MNIST. </font><font style="vertical-align: inherit;">Sin embargo, existen muchos otros enfoques para optimizar la funci√≥n de costos, y algunas veces muestran una eficiencia superior a la del descenso de gradiente estoc√°stico con mini paquetes. </font><font style="vertical-align: inherit;">En esta secci√≥n, describo brevemente dos de estos enfoques, el hessiano y el impulso.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Arpillera </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para comenzar, dejemos de lado a la Asamblea Nacional. </font><font style="vertical-align: inherit;">En cambio, simplemente consideramos el problema abstracto de minimizar la funci√≥n de costo C de muchas variables, w = w1, w2, ..., es decir, C = C (w). </font><font style="vertical-align: inherit;">Seg√∫n </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">el teorema de Taylor,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> la funci√≥n de costo en el punto w puede ser aproximada:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-61"><span class="MJXp-mtable" id="MJXp-Span-62"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-63" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-64" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-66" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-68" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-69"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-71" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-72" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-74" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-76" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-77" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-munderover" id="MJXp-Span-78"><span class=""><span class="MJXp-mo" id="MJXp-Span-79" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80" style="margin-left: 0px;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> j </font></font></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-81" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi" id="MJXp-Span-82"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi" id="MJXp-Span-84"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-85"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-87" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-88"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-89"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-91" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span><span class="MJXp-mspace" id="MJXp-Span-92" style="width: 0em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-93" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-94" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-96"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span><span class="MJXp-munderover" id="MJXp-Span-97"><span class=""><span class="MJXp-mo" id="MJXp-Span-98" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-99" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-101"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-102"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-103"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-105" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span><span class="MJXp-mfrac" id="MJXp-Span-106" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-107"><span class="MJXp-mi" id="MJXp-Span-108" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ</font></font></span><span class="MJXp-mn MJXp-script" id="MJXp-Span-109" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-110"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi" id="MJXp-Span-111"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-112"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-114" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span><span class="MJXp-mi" id="MJXp-Span-115"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àÇ </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-116"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-118" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></span></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-119"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-120"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-122" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-123" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></span><span class="MJXp-mo" id="MJXp-Span-124" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">...</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-4"> C(w+\Delta w) = C(w) + \sum_j \frac{\partial C}{\partial w_j} \Delta w_j \nonumber \\ + \frac{1}{2} \sum_{jk} \Delta w_j \frac{\partial^2 C}{\partial w_j \partial w_k} \Delta w_k + \ldots \tag{103} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Podemos reescribirlo de manera m√°s compacta como </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-125"><span class="MJXp-mtable" id="MJXp-Span-126"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-127" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-128" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-130" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-132" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-133"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-135" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-136" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-137"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-138" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-139"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-140" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-141" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-142"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-144" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ãÖ </font></font></span><span class="MJXp-mi" id="MJXp-Span-145"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-147" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-148" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-149"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-150"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-151"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-152"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-153" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-154" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T</font></font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H</font></font></span><span class="MJXp-mi" id="MJXp-Span-156"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî</font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-157"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mo" id="MJXp-Span-158" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></span><span class="MJXp-mo" id="MJXp-Span-159" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">...</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> C(w+\Delta w) = C(w) + \nabla C \cdot \Delta w + \frac{1}{2} \Delta w^T H \Delta w + \ldots \tag{104} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donde ‚àáC es el vector de gradiente ordinario, y H es la matriz, conocida como la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">matriz de Hesse</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , en lugar de jk en la que ‚àÇ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C / ‚àÇw </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àÇw </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Supongamos que aproximamos C al abandonar los t√©rminos de orden superior que se esconden detr√°s de los puntos suspensivos en la f√≥rmula:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-160"><span class="MJXp-mtable" id="MJXp-Span-161"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-162" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-163" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-165" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-167" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-168"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-170" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-171" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚âà </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-173" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-175" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-176" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-177"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-178"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-179" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ãÖ </font></font></span><span class="MJXp-mi" id="MJXp-Span-180"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-182" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-183" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-184"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-185"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-186"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-187"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-188" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-189" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T</font></font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-190"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H</font></font></span><span class="MJXp-mi" id="MJXp-Span-191"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî</font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-6"> C(w+\Delta w) \approx C(w) + \nabla C \cdot \Delta w + \frac{1}{2} \Delta w^T H \Delta w \tag{105} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Usando √°lgebra, se puede demostrar que la expresi√≥n en el lado derecho se puede minimizar seleccionando: </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-193"><span class="MJXp-mtable" id="MJXp-Span-194"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-195" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-196" style="text-align: center;"><span class="MJXp-mi" id="MJXp-Span-197"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mo" id="MJXp-Span-200" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-201"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H </font></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-203" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-204"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mn" id="MJXp-Span-205"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span></span><span class="MJXp-mi" id="MJXp-Span-206"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-7"> \Delta w = -H^{-1} \nabla C \tag{106} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hablando estrictamente, para que esto sea solo un m√≠nimo, y no solo un extremo, debemos suponer que la matriz de Hesse es m√°s positiva. </font><font style="vertical-align: inherit;">Intuitivamente, esto significa que la funci√≥n C es como un valle, no una monta√±a o una silla de montar. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si (105) es una buena aproximaci√≥n a la funci√≥n de costo, se espera que la transici√≥n del punto w al punto w + Œîw = w - H - 1 ‚àíC reduzca significativamente la funci√≥n de costo. </font><font style="vertical-align: inherit;">Esto ofrece un posible algoritmo de minimizaci√≥n de costos:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Seleccione el punto de partida w. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Actualice w a un nuevo punto, w ‚Ä≤ = w - H </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àí1</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àáC, donde Hessian H y ‚àáC se calculan en w.</font></font></li><li>  w'   , w‚Ä≤‚Ä≤=w‚Ä≤‚àíH‚Ä≤ <sup>‚àí1</sup> ‚àá‚Ä≤C,   H  ‚àáC   w'. </li><li>  ... </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En la pr√°ctica, (105) es solo una aproximaci√≥n, y es mejor dar pasos m√°s peque√±os. Haremos esto actualizando constantemente w por Œîw = ‚àíŒ∑H - 1‚àáC, donde Œ∑ es la velocidad de aprendizaje. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este enfoque para minimizar la funci√≥n de costos se conoce como optimizaci√≥n de Hesse. Hay resultados te√≥ricos y emp√≠ricos que muestran que los m√©todos de Hesse convergen al m√≠nimo en menos pasos que un descenso de gradiente est√°ndar. En particular, al incluir informaci√≥n sobre los cambios de segundo orden en la funci√≥n de costos, es posible evitar muchas patolog√≠as encontradas en el descenso de gradiente en el enfoque de Hesse. Adem√°s, hay versiones del algoritmo de retropropagaci√≥n que se pueden usar para calcular el Hessian.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si la optimizaci√≥n de Hesse es tan genial, ¬øpor qu√© no la usamos en nuestro NS? </font><font style="vertical-align: inherit;">Desafortunadamente, aunque tiene muchas propiedades deseables, hay una muy indeseable: es muy dif√≠cil de poner en pr√°ctica. </font><font style="vertical-align: inherit;">Parte del problema es el gran tama√±o de la matriz de Hesse. </font><font style="vertical-align: inherit;">Supongamos que tenemos un NS con 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pesos y compensaciones. </font><font style="vertical-align: inherit;">Luego, en la matriz de Hesse correspondiente habr√° 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √ó 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> elementos. </font><font style="vertical-align: inherit;">Demasiados! </font><font style="vertical-align: inherit;">Como resultado </font><font style="vertical-align: inherit;">, resulta muy dif√≠cil </font><font style="vertical-align: inherit;">calcular H </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àí1</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àáC en la pr√°ctica. </font><font style="vertical-align: inherit;">Pero esto no significa que sea in√∫til saber de ella. </font><font style="vertical-align: inherit;">Muchas opciones de descenso de gradiente est√°n inspiradas en la optimizaci√≥n de Hesse, simplemente evitan el problema de matrices excesivamente grandes. </font><font style="vertical-align: inherit;">Echemos un vistazo a una de esas t√©cnicas, el descenso por gradiente de impulso.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Descenso de gradiente basado en impulsos </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Intuitivamente, la ventaja de la optimizaci√≥n de Hesse es que incluye no solo informaci√≥n sobre el gradiente, sino tambi√©n informaci√≥n sobre su cambio. El descenso de gradiente basado en impulsos se basa en una intuici√≥n similar, pero evita grandes matrices de segundas derivadas. Para comprender la t√©cnica de impulso, recordemos nuestra primera imagen de descenso en gradiente, en la que examinamos una bola rodando por un valle. Luego vimos que el descenso en gradiente, contrario a su nombre, solo se asemeja ligeramente a una bola que cae al fondo. La t√©cnica de pulso cambia el descenso del gradiente en dos lugares, lo que lo hace m√°s parecido a una imagen f√≠sica. Primero, introduce el concepto de "velocidad" para los par√°metros que estamos tratando de optimizar. El gradiente est√° tratando de cambiar la velocidad, no la "ubicaci√≥n" directamente, similar a c√≥mo las fuerzas f√≠sicas cambian la velocidad,y solo afecta indirectamente la ubicaci√≥n. En segundo lugar, el m√©todo de impulso es un tipo de t√©rmino de fricci√≥n que reduce gradualmente la velocidad.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Demos una definici√≥n matem√°ticamente m√°s precisa. </font><font style="vertical-align: inherit;">Introducimos las variables de velocidad v = v1, v2, ..., una para cada variable correspondiente w </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (en la red neuronal, estas variables incluyen naturalmente todos los pesos y desplazamientos). </font><font style="vertical-align: inherit;">Luego cambiamos la regla de actualizaci√≥n de descenso de gradiente w ‚Üí w ‚Ä≤ = w - Œ∑‚àáC a</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-208"><span class="MJXp-mtable" id="MJXp-Span-209"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-210" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-211" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo" id="MJXp-Span-213" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-214"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-216" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-217" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-218"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œº </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-219"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo" id="MJXp-Span-220" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-221"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-mi" id="MJXp-Span-222"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-223"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-8"> v \rightarrow v' = \mu v - \eta \nabla C \tag{107} </script></p><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-224"><span class="MJXp-mtable" id="MJXp-Span-225"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-226" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-227" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-228"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-229" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-230"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-231" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-232" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-233" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-235" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-msup" id="MJXp-Span-236"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-237" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-238" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-9"> w \rightarrow w' = w+v' \tag{108} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En ecuaciones, Œº es un hiperpar√°metro que controla la cantidad de frenado o fricci√≥n del sistema. Para comprender el significado de las ecuaciones, primero es √∫til considerar el caso en el que Œº = 1, es decir, cuando no hay fricci√≥n. En este caso, el estudio de las ecuaciones muestra que ahora la "fuerza" ‚àáC cambia la velocidad v, y la velocidad controla la velocidad de cambio w. Intuitivamente, se puede ganar velocidad agregando constantemente miembros de gradiente. Esto significa que si el gradiente se mueve en aproximadamente una direcci√≥n durante varias etapas de entrenamiento, podemos obtener una velocidad de movimiento suficientemente alta en esta direcci√≥n. Imagine, por ejemplo, lo que sucede al descender:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/37e/5f9/af1/37e5f9af1985610568cba31157e35763.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Con cada paso hacia abajo, la velocidad aumenta, y nos movemos cada vez m√°s r√°pido al fondo del valle. Esto permite que la t√©cnica de velocidad funcione mucho m√°s r√°pido que el descenso de gradiente est√°ndar. Por supuesto, el problema es que, habiendo llegado al fondo del valle, nos deslizaremos por √©l. O, si el gradiente cambia demasiado r√°pido, podr√≠a resultar que nos estamos moviendo en la direcci√≥n opuesta. Este es el punto de introducir el hiperpar√°metro Œº en (107). Dije anteriormente que Œº controla la cantidad de fricci√≥n en el sistema; m√°s precisamente, la cantidad de fricci√≥n debe ser imaginada como 1-Œº. Cuando Œº = 1, como vimos, no hay fricci√≥n, y la velocidad est√° completamente determinada por el gradiente ‚àáC. Y viceversa, cuando Œº = 0, hay mucha fricci√≥n, no se gana velocidad y las ecuaciones (107) y (108) se reducen a las ecuaciones de descenso de gradiente habituales, w ‚Üí w ‚Ä≤ = w - Œ∑‚àáC. En la pr√°ctica,El uso del valor de Œº en el intervalo entre 0 y 1 nos puede dar la ventaja de la capacidad de ganar velocidad sin peligro de deslizarnos al m√≠nimo. Podemos seleccionar dicho valor para Œº utilizando los datos de confirmaci√≥n pendientes de la misma manera que elegimos los valores para Œ∑ y Œª.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasta ahora he evitado nombrar el hiperpar√°metro Œº. El hecho es que el nombre est√°ndar para Œº fue mal elegido: se llama coeficiente de impulso. Esto puede ser confuso porque Œº no se parece en nada al concepto de impulso de la f√≠sica. Est√° mucho m√°s fuertemente asociado con la fricci√≥n. Sin embargo, el t√©rmino "coeficiente de impulso" se usa ampliamente, por lo que continuaremos us√°ndolo tambi√©n.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una buena caracter√≠stica de la t√©cnica de impulso es que no se necesita hacer casi nada para cambiar la implementaci√≥n del descenso de gradiente para incluir esta t√©cnica en ella. </font><font style="vertical-align: inherit;">Todav√≠a podemos usar la propagaci√≥n hacia atr√°s para calcular gradientes, como antes, y usar ideas como verificar minipacks seleccionados estoc√°sticamente. </font><font style="vertical-align: inherit;">En este caso, podemos obtener algunos de los beneficios de la optimizaci√≥n de Hesse utilizando informaci√≥n sobre los cambios de gradiente. </font><font style="vertical-align: inherit;">Sin embargo, todo esto sucede sin fallas y solo con cambios menores en el c√≥digo. </font><font style="vertical-align: inherit;">En la pr√°ctica, la t√©cnica de impulso se usa ampliamente y a menudo ayuda a acelerar el aprendizaje.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ejercicios </font></font></h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øQu√© saldr√° mal si usamos Œº&gt; 1 en la t√©cnica de pulso? </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øQu√© saldr√° mal si usamos Œº &lt;0 en la t√©cnica de pulso? </font></font></li></ul><br><br><h3>  Desaf√≠o </h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Agregue un descenso de gradiente estoc√°stico basado en el impulso a network2.py. </font></font></li></ul><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Otros enfoques para minimizar la funci√≥n de costos </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se han desarrollado muchos otros enfoques para minimizar la funci√≥n de costos, y no se ha llegado a un acuerdo sobre el mejor enfoque. </font><font style="vertical-align: inherit;">Profundizando en el tema de las redes neuronales, es √∫til profundizar en otras tecnolog√≠as, comprender c√≥mo funcionan, cu√°les son sus fortalezas y debilidades, y c√≥mo ponerlas en pr√°ctica. </font><font style="vertical-align: inherit;">En el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabajo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que mencion√© anteriormente </font><font style="vertical-align: inherit;">, se introducen y comparan varias de estas t√©cnicas, incluido el descenso de gradiente emparejado y el m√©todo BFGS (y tambi√©n estudian el m√©todo BFGS estrechamente relacionado con la restricci√≥n de memoria, o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L-BFGS</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Otra tecnolog√≠a que recientemente ha mostrado </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultados prometedores.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, este es el gradiente acelerado de Nesterov, que mejora la t√©cnica del pulso. </font><font style="vertical-align: inherit;">Sin embargo, el descenso de gradiente simple funciona bien para muchas tareas, especialmente cuando se usa el impulso, por lo que nos quedaremos con el descenso de gradiente estoc√°stico hasta el final del libro.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Otros modelos de neurona artificial </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasta ahora, hemos creado nuestro NS utilizando neuronas sigmoideas. </font><font style="vertical-align: inherit;">En principio, el NS construido sobre neuronas sigmoideas puede calcular cualquier funci√≥n. </font><font style="vertical-align: inherit;">Pero en la pr√°ctica, las redes construidas en otros modelos de neuronas a veces est√°n por delante de las sigmoideas. </font><font style="vertical-align: inherit;">Dependiendo de la aplicaci√≥n, las redes basadas en dichos modelos alternativos pueden aprender m√°s r√°pido, generalizarse mejor a los datos de verificaci√≥n o hacer ambas cosas. </font><font style="vertical-align: inherit;">Perm√≠tanme mencionar un par de modelos alternativos de neuronas para darle una idea de algunas opciones de uso com√∫n. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quiz√°s la variaci√≥n m√°s simple ser√≠a una neurona tang que reemplaza una funci√≥n sigmoidea con una tangente hiperb√≥lica. </font><font style="vertical-align: inherit;">La salida de una neurona tang con entrada x, un vector de pesos w, y un desplazamiento b se especifica como</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-239"><span class="MJXp-mtable" id="MJXp-Span-240"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-241" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-242" style="text-align: center;"><span class="MJXp-mi" id="MJXp-Span-243"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tanh </font></font></span><font style="vertical-align: inherit;"><span class="MJXp-mo" id="MJXp-Span-245" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-246"><font style="vertical-align: inherit;">w </font></span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;">‚ãÖ </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248"><font style="vertical-align: inherit;">x </font></span><span class="MJXp-mo" id="MJXp-Span-249" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;">+ </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-250"><font style="vertical-align: inherit;">b </font></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">)</font></span></font><span class="MJXp-mo" id="MJXp-Span-244" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-245" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-246"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-249" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-250"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-10"> \tanh(w \cdot x+b) \tag{109} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donde tanh es </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tangente hiperb√≥lica</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> natural </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Resulta que est√° muy conectado con la neurona sigmoidea. </font><font style="vertical-align: inherit;">Para ver esto, recuerde que tanh se define como</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-252"><span class="MJXp-mtable" id="MJXp-Span-253"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-254" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-255" style="text-align: center;"><span class="MJXp-mi" id="MJXp-Span-256"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tanh </font></font></span><font style="vertical-align: inherit;"><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259"><font style="vertical-align: inherit;">z </font></span><span class="MJXp-mo" id="MJXp-Span-260" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">) </font></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">‚â° </font></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-263"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-264" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">e </font></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-263"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-265" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;">z</font></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mo" id="MJXp-Span-266" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"> - </font></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">e </font></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mrow MJXp-script" id="MJXp-Span-269" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-270"><font style="vertical-align: inherit;">- </font></span></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mrow MJXp-script" id="MJXp-Span-269" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271"><font style="vertical-align: inherit;">z</font></span></span></span></span></span></font><span class="MJXp-mo" id="MJXp-Span-257" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-260" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-263"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-264" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-265" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mo" id="MJXp-Span-266" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-269" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-270"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271"><font style="vertical-align: inherit;"></font></span></span></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-272"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-273" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-274" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-275" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> + </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-276"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-277" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-278" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-279"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-280"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z</font></font></span></span></span></span></span></span></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-11"> \tanh(z) \equiv \frac{e^z-e^{-z}}{e^z+e^{-z}} \tag{110} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Usando un poco de √°lgebra, es f√°cil ver que </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-281"><span class="MJXp-mtable" id="MJXp-Span-282"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-283" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-284" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">œÉ </font></font></span><span class="MJXp-mo" id="MJXp-Span-286" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z </font></font></span><span class="MJXp-mo" id="MJXp-Span-288" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-289" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-290" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-291"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 </font></font></span><span class="MJXp-mo" id="MJXp-Span-292" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-293"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tanh </font></font></span><font style="vertical-align: inherit;"><span class="MJXp-mo" id="MJXp-Span-295" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296"><font style="vertical-align: inherit;">z </font></span><span class="MJXp-mrow" id="MJXp-Span-297"><span class="MJXp-mo" id="MJXp-Span-298" style="margin-left: 0.111em; margin-right: 0.111em;"><font style="vertical-align: inherit;">/</font></span></span><span class="MJXp-mn" id="MJXp-Span-299"><font style="vertical-align: inherit;"> 2 </font></span><span class="MJXp-mo" id="MJXp-Span-300" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">)</font></span></font><span class="MJXp-mo" id="MJXp-Span-294" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-295" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mrow" id="MJXp-Span-297"><span class="MJXp-mo" id="MJXp-Span-298" style="margin-left: 0.111em; margin-right: 0.111em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mn" id="MJXp-Span-299"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-300" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-301"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-12"> \sigma(z) = \frac{1+\tanh(z/2)}{2} \tag{111} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">es decir, tanh solo est√° escalando el sigmoide. </font><font style="vertical-align: inherit;">Gr√°ficamente, tambi√©n puede ver que la funci√≥n tanh tiene la misma forma que la sigmoidea: </font></font><br><br><img src="https://habrastorage.org/webt/2d/al/jw/2daljwgmoaw7v8g4bz7jkiy8fwo.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">una diferencia entre las neuronas tang y las neuronas sigmoideas es que la salida de la primera se extiende de -1 a 1, y no de 0 a 1. Esto significa que al crear una red basada en neuronas tang, es posible que deba normalizar sus salidas (y, dependiendo de los detalles de la aplicaci√≥n, quiz√°s las entradas) de forma un poco diferente que en las redes sigmoideas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al igual que las sigmoideas, las neuronas tang, en principio, pueden calcular cualquier funci√≥n (aunque hay algunos trucos), marcando entradas de -1 a 1. Adem√°s, las ideas de propagaci√≥n hacia atr√°s y descenso de gradiente estoc√°stico son tan f√°ciles de aplicar a tang -neuronas, as√≠ como a sigmoides.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ejercicio </font></font></h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Demuestre la ecuaci√≥n (111). </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øQu√© tipo de neurona se debe usar en redes, tang o sigmoide? ¬°La respuesta, por decirlo suavemente, no es obvia! Sin embargo, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">existen </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">argumentos te√≥ricos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y alguna evidencia emp√≠rica de que las neuronas tang a veces funcionan mejor. Repasemos brevemente uno de los argumentos te√≥ricos a favor de las neuronas tang. Supongamos que usamos neuronas sigmoides, y todas las activaciones en la red ser√°n positivas. Considere los pesos w </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jk</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> incluidos para la neurona No. j en la capa No. l + 1. Las reglas de retropropagaci√≥n (BP4) nos dicen que el gradiente asociado con esto ser√° igual a </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Como las activaciones son positivas, el signo de este gradiente ser√° el mismo que el de Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Esto significa que si Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j es</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> positivo, entonces todos los pesos w </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jk</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> disminuir√°n durante el descenso del gradiente, y si Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j es</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> negativo, entonces todos los pesos w </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jk</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aumentar√° durante el descenso del gradiente. En otras palabras, todos los pesos asociados con la misma neurona aumentar√°n o disminuir√°n juntos. Y esto es un problema, porque es posible que deba aumentar algunos pesos mientras reduce otros. Pero esto solo puede suceder si algunas activaciones de entrada tienen signos diferentes. Esto sugiere la necesidad de reemplazar el sigmoide con otra funci√≥n de activaci√≥n, por ejemplo, la tangente hiperb√≥lica, que permite que las activaciones sean tanto positivas como negativas. De hecho, dado que tanh es sim√©trico con respecto a cero, tanh (‚àíz) = ‚àítanh (z), uno puede esperar que, en t√©rminos generales, las activaciones en capas ocultas se distribuyan por igual entre positivo y negativo. Esto ayudar√° a garantizar que no haya sesgos sistem√°ticos en las actualizaciones de las escalas en una direcci√≥n u otra.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øCu√°n seriamente debe considerarse este argumento? </font><font style="vertical-align: inherit;">Despu√©s de todo, es heur√≠stico, no proporciona evidencia estricta de que las neuronas tang sean superiores a las sigmoideas. </font><font style="vertical-align: inherit;">¬øQuiz√°s las neuronas sigmoideas tienen algunas propiedades que compensan este problema? </font><font style="vertical-align: inherit;">De hecho, en muchos casos, la funci√≥n de tanh mostr√≥ ventajas m√≠nimas o nulas en comparaci√≥n con la sigmoidea. </font><font style="vertical-align: inherit;">Desafortunadamente, no tenemos m√©todos simples e implementados r√°pidamente para verificar qu√© tipo de neurona aprender√° m√°s r√°pido o demostrar√° ser m√°s eficaz en generalizar para un caso particular. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otra variante de una neurona sigmoidea es una neurona lineal rectificada, o unidad lineal rectificada, ReLU. </font><font style="vertical-align: inherit;">La salida ReLU con entrada x, el vector de los pesos w y el desplazamiento b se especifica de la siguiente manera:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-307"><span class="MJXp-mtable" id="MJXp-Span-308"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-309" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-310" style="text-align: center;"><span class="MJXp-mo" id="MJXp-Span-311" style="margin-left: 0.333em; margin-right: 0.333em;">max</span><span class="MJXp-mo" id="MJXp-Span-312" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mn" id="MJXp-Span-313">0</span><span class="MJXp-mo" id="MJXp-Span-314" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-315">w</span><span class="MJXp-mo" id="MJXp-Span-316" style="margin-left: 0.267em; margin-right: 0.267em;">‚ãÖ</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-317">x</span><span class="MJXp-mo" id="MJXp-Span-318" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-319">b</span><span class="MJXp-mo" id="MJXp-Span-320" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-13"> \max(0, w \cdot x+b) \tag{112} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La funci√≥n de enderezamiento gr√°fico max (0, z) se ve as√≠: </font></font><br><br><img src="https://habrastorage.org/webt/tu/1x/uv/tu1xuvrfyle3eismzxadvwjzjqq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tales neuronas, obviamente, son muy diferentes de las neuronas sigmoideas y tang. Sin embargo, son similares en que tambi√©n se pueden usar para calcular cualquier funci√≥n, y se pueden entrenar usando la propagaci√≥n hacia atr√°s y el descenso de gradiente estoc√°stico. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øCu√°ndo debo usar ReLU en lugar de neuronas sigmoides o tang? En trabajos recientes sobre reconocimiento de im√°genes ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Se encontraron serias ventajas de usar ReLU en casi toda la red. Sin embargo, al igual que con las neuronas tang, todav√≠a no tenemos una comprensi√≥n realmente profunda de cu√°ndo exactamente qu√© ReLU ser√°n preferibles y por qu√©. Para tener una idea de algunos problemas, recuerde que las neuronas sigmoideas dejan de aprender cuando est√°n saturadas, es decir, cuando la salida est√° cerca de 0 o 1. Como hemos visto muchas veces en este cap√≠tulo, el problema es que los miembros œÉ 'reducen el gradiente eso ralentiza el aprendizaje. Las neuronas Tang sufren dificultades similares en la saturaci√≥n. Al mismo tiempo, un aumento en la entrada ponderada en ReLU nunca lo saturar√°, por lo tanto, no se producir√° una desaceleraci√≥n correspondiente en el entrenamiento. Por otro lado, cuando la entrada ponderada en el ReLU es negativa, el gradiente desaparece y la neurona deja de aprender.Estos son solo algunos de los muchos problemas que hacen que no sea trivial entender cu√°ndo y c√≥mo las ReLU se comportan mejor que las neuronas sigmoideas o tangibles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pint√© una imagen de incertidumbre, enfatizando que todav√≠a no tenemos una teor√≠a s√≥lida de la elecci√≥n de las funciones de activaci√≥n. De hecho, este problema es a√∫n m√°s complicado de lo que describ√≠, ya que hay infinitas funciones de activaci√≥n posibles. ¬øCu√°l nos dar√° la red de aprendizaje m√°s r√°pido? ¬øCu√°l dar√° la mayor precisi√≥n en las pruebas? Me sorprende cu√°n pocos estudios realmente profundos y sistem√°ticos han sido sobre estos temas. Idealmente, deber√≠amos tener una teor√≠a que nos diga en detalle c√≥mo elegir (y posiblemente cambiar sobre la marcha) nuestras funciones de activaci√≥n. Por otro lado, ¬°no deber√≠amos detenernos por la falta de una teor√≠a completa! Ya tenemos herramientas poderosas, y con su ayuda podemos lograr un progreso significativo. Hasta el final del libro usar√© las neuronas sigmoideas como las principales,ya que funcionan bien y dan ilustraciones concretas de ideas clave relacionadas con la Asamblea Nacional. Pero tenga en cuenta que las mismas ideas se pueden aplicar a otras neuronas, y estas opciones tienen sus ventajas.</font></font><br><br><h3>     </h3><br><blockquote> :          ,      ,   ?         ? <br><br> :   ,      .          ,     .    .      :         ,     ,     ? <br><br> ‚Äî         </blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una vez en una conferencia sobre los conceptos b√°sicos de la mec√°nica cu√°ntica, not√© algo que parec√≠a un h√°bito gracioso: al final del informe, las preguntas de la audiencia a menudo comenzaron con la frase: "Realmente me gusta tu punto de vista, pero ..." Los fundamentos cu√°nticos no son mi campo habitual, y llam√© la atenci√≥n sobre este estilo de hacer preguntas porque en otras conferencias cient√≠ficas pr√°cticamente no me reun√≠ con el interlocutor para mostrar simpat√≠a por el punto de vista del hablante. En ese momento, decid√≠ que la prevalencia de tales preguntas indicaba que el progreso en los fundamentos cu√°nticos se hab√≠a logrado bastante y que las personas apenas comenzaban a ganar impulso. M√°s tarde me di cuenta de que esta evaluaci√≥n era demasiado dura. Los oradores lucharon con algunos de los problemas m√°s dif√≠ciles que las mentes humanas han encontrado. ¬°Naturalmente, el progreso fue lento!Sin embargo, todav√≠a val√≠a la pena escuchar las noticias de las personas que pensaban en esta √°rea, incluso si ten√≠an poco o nada.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En este libro puede haber notado una "marca nerviosa" similar a la frase "Estoy muy impresionado". Para explicar lo que tenemos, a menudo recurr√≠ a palabras como "heur√≠sticamente" o "m√°s o menos hablando", seguido de una explicaci√≥n de un fen√≥meno particular. Estas historias son cre√≠bles, pero la evidencia emp√≠rica fue a menudo bastante superficial. Si estudia la literatura de investigaci√≥n, ver√° que historias de este tipo aparecen en muchos trabajos de investigaci√≥n sobre redes neuronales, a menudo en compa√±√≠a de una peque√±a cantidad de evidencia que los respalda. ¬øC√≥mo nos relacionamos con tales historias?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En muchos campos de la ciencia, especialmente donde se consideran fen√≥menos simples, uno puede encontrar evidencia muy estricta y confiable de hip√≥tesis muy generales. Pero en la Asamblea Nacional hay una gran cantidad de par√°metros e hiperpar√°metros, y hay relaciones extremadamente complejas entre ellos. En sistemas tan incre√≠blemente complejos, es incre√≠blemente dif√≠cil hacer declaraciones generales confiables. La comprensi√≥n del NS en toda su plenitud, como los fundamentos cu√°nticos, pone a prueba los l√≠mites de la mente humana. A menudo tenemos que prescindir de la evidencia a favor o en contra de varios casos particulares espec√≠ficos de una declaraci√≥n general. Como resultado, a veces es necesario cambiar o abandonar estas declaraciones, a medida que surgen nuevas pruebas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uno de los enfoques para esta situaci√≥n es considerar que cualquier historia heur√≠stica sobre el NS implica un cierto desaf√≠o. Por ejemplo, considere la explicaci√≥n que cit√© sobre por qu√© funciona una excepci√≥n (abandono) del </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabajo en 2012.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: ‚ÄúEsta t√©cnica reduce la compleja adaptaci√≥n articular de las neuronas, ya que una neurona no puede confiar en la presencia de ciertos vecinos. Al final, tiene que aprender rasgos m√°s confiables que pueden ser √∫tiles para trabajar junto con muchos subconjuntos aleatorios diferentes de neuronas ". Una declaraci√≥n rica y provocativa, sobre la base de la cual puede construir un programa de investigaci√≥n completo, en el que necesitar√° descubrir qu√© es verdad, d√≥nde est√° mal y qu√© debe aclararse y modificarse. Y ahora realmente hay toda una industria de investigadores que estudian la excepci√≥n (y sus muchas variaciones), tratando de entender c√≥mo funciona y qu√© limitaciones tiene. As√≠ es con muchos otros enfoques heur√≠sticos que discutimos. Cada uno de ellos no es solo una explicaci√≥n potencial,pero tambi√©n un desaf√≠o para la investigaci√≥n y una comprensi√≥n m√°s detallada.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por supuesto, ninguna persona tendr√° tiempo suficiente para investigar todas estas explicaciones heur√≠sticas con suficiente profundidad. Toda la comunidad de investigadores de NS tardar√° d√©cadas en desarrollar una teor√≠a realmente poderosa del entrenamiento de NS basada en la evidencia. ¬øSignifica esto que vale la pena rechazar las explicaciones heur√≠sticas como pruebas laxas y carentes de evidencia?</font></font> No!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Necesitamos una heur√≠stica que inspire nuestro pensamiento. Esto es similar a la era de los grandes descubrimientos geogr√°ficos: los primeros estudiosos a menudo actuaban (e hicieron descubrimientos) bas√°ndose en creencias que se equivocaron de manera seria. M√°s tarde, corregimos estos errores, reponiendo nuestro conocimiento geogr√°fico. Cuando comprendes algo mal, como los investigadores entendieron la geograf√≠a, y como entendemos hoy el NS, es m√°s importante estudiar audazmente lo desconocido que estar escrupulosamente en cada paso de tu razonamiento. Por lo tanto, debe considerar estas historias como instrucciones √∫tiles sobre c√≥mo reflexionar sobre las NS, manteniendo una conciencia saludable de sus limitaciones y monitoreando cuidadosamente la confiabilidad de la evidencia en cada caso. En otras palabras, necesitamos buenas historias para motivarnos e inspirarnos, e investigaciones minuciosas y escrupulosas, a fin depara descubrir hechos reales.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/460711/">https://habr.com/ru/post/460711/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../460699/index.html">Habr Weekly # 10 / Super servicios y pasaporte electr√≥nico, tel√©fonos inteligentes y rusos, "gadgets esp√≠as", vida sin sat√©lites</a></li>
<li><a href="../460701/index.html">Curso "Start in Data Science": el primer paso para trabajar con datos</a></li>
<li><a href="../460703/index.html">Blue Ocean of Opportunity: de cero a 400 mil entrevistas en video</a></li>
<li><a href="../460707/index.html">¬øEs hora de que los desarrolladores de juegos dejen de escuchar a sus fan√°ticos?</a></li>
<li><a href="../460709/index.html">Reflexiones sobre Agile</a></li>
<li><a href="../460713/index.html">Desarrollo de aplicaciones en SwiftUI. Parte 1: flujo de datos y Redux</a></li>
<li><a href="../460717/index.html">Noticias semanales: pruebas de red satelital OneWeb, interfaces neuronales de m√°scara Ilona y dispositivos electr√≥nicos no esp√≠a</a></li>
<li><a href="../460719/index.html">Clases de la Fundaci√≥n de la Industria. Breve introducci√≥n</a></li>
<li><a href="../460723/index.html">NVIDIA Jetson Nano: pruebas y primeras impresiones</a></li>
<li><a href="../460725/index.html">El c√≥digo de autodocumentaci√≥n es (generalmente) sin sentido</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏏 👨🏾‍🤝‍👨🏻 💨 Apprenez OpenGL. Leçon 5.10 - Occlusion ambiante de l'espace d'écran 🚲 🙌🏿 💧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="SSAO 
 Le sujet de l'éclairage de fond a été soulevé par nous dans une leçon sur les bases de l'éclairage , mais seulement en passant. Permettez-moi d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprenez OpenGL. Leçon 5.10 - Occlusion ambiante de l'espace d'écran</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/421385/"><img align="left" src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="OGL3" width="300"><h2>  SSAO </h2><br>  Le sujet de l'éclairage de fond a été soulevé par nous dans une leçon sur les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bases de l'éclairage</a> , mais seulement en passant.  Permettez-moi de vous rappeler que la composante d'arrière-plan de l'éclairage est essentiellement une valeur constante qui est ajoutée à tous les calculs de l'éclairage de la scène pour simuler le processus <i>de diffusion de la lumière</i> .  Dans le monde réel, la lumière subit de nombreux reflets avec des degrés d'intensité variables, ce qui conduit à un éclairage tout aussi inégal de parties de la scène éclairées indirectement.  Évidemment, une fusée à intensité constante n'est pas très plausible. <br><br>  Un type de calcul approximatif de l'ombrage de l'éclairage indirect est l'algorithme d' <i>occlusion ambiante (AO</i> ), qui simule l'atténuation de l'éclairage indirect au voisinage des coins, des rides et d'autres irrégularités de surface.  Ces éléments, en général, se chevauchent considérablement par la géométrie adjacente et laissent donc moins de rayons de lumière s'échapper à l'extérieur, obscurcissant ces zones. <br><br>  Vous trouverez ci-dessous une comparaison du rendu sans et en utilisant l'algorithme AO.  Faites attention à la façon dont l'intensité de l'éclairage d'arrière-plan diminue au voisinage des coins des murs et des autres coupures prononcées de la surface: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6s/8z/kv/6s8zkvpob8nbgaails8mtfutgw8.png"></div><br>  Bien que l'effet ne soit pas très visible, la présence de l'effet dans toute la scène lui donne du réalisme en raison de l'illusion supplémentaire de profondeur créée par les petits détails de l'effet d'auto-occultation. <br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Table des matières</b> <div class="spoiler_text">  Partie 1. Pour commencer <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Opengl</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Création de fenêtres</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bonjour fenêtre</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bonjour triangle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shaders</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Textures</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transformations</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Systèmes de coordonnées</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Appareil photo</a> </li></ol><br>  Partie 2. Éclairage de base <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les couleurs</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bases d'éclairage</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Matériaux</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes de texture</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sources lumineuses</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sources d'éclairage multiples</a> </li></ol><br>  Partie 3. Télécharger des modèles 3D <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bibliothèque Assimp</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classe de polygone de maillage</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classe de modèle 3D</a> </li></ol><br>  Partie 4. Fonctionnalités avancées d'OpenGL <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Test de profondeur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Test au pochoir</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mélange de couleurs</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Couper les visages</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tampon de trame</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes cubiques</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traitement avancé des données</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GLSL avancé</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shader géométrique</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Instanciation</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lissage</a> </li></ol><br>  Partie 5. Éclairage avancé <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Éclairage avancé.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Modèle Blinn-Fong.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Correction gamma</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes fantômes</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes ombrées omnidirectionnelles</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartographie normale</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mappage de parallaxe</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HDR</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bloom</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rendu différé</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SSAO</a> </li></ol><br>  Partie 6. PBR <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Théorie</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sources de lumière analytiques</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Irradiation diffuse.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Exposition miroir.</a> </li></ol><br></div></div><br>  Il convient de noter que les algorithmes de calcul de l'AO sont assez gourmands en ressources, car ils nécessitent une analyse de la géométrie environnante.  Dans une mise en œuvre naïve, il serait possible d'émettre simplement beaucoup de rayons à chaque point de la surface et de déterminer le degré de son ombrage, mais cette approche atteint très rapidement la limite de ressources acceptable pour les applications interactives.  Heureusement, en 2007, Crytek a publié un document décrivant sa propre approche de la mise en œuvre de l'algorithme <i>Screen-Space Ambient Occlusion (SSAO</i> ) utilisé dans la version finale de Crysis.  L'approche a calculé le degré d'ombrage dans l'espace d'écran, en utilisant uniquement le tampon de profondeur actuel au lieu de données réelles sur la géométrie environnante.  Une telle optimisation a radicalement accéléré l'algorithme par rapport à l'implémentation de référence et en même temps a donné des résultats pour la plupart plausibles, ce qui a fait de cette approche de calcul approximatif de l'ombrage d'arrière-plan une industrie de facto standard. <br><br>  Le principe sur lequel l'algorithme est basé est assez simple: pour chaque fragment d'un quad en plein écran, le <i>facteur d'occlusion est</i> calculé en fonction des valeurs de profondeur des fragments environnants.  Le coefficient d'ombrage calculé est ensuite utilisé pour réduire l'intensité de l'éclairage de fond (jusqu'à l'exclusion complète).  L'obtention d'un coefficient nécessite de collecter des données de profondeur à partir d'une pluralité d'échantillons de la région sphérique entourant le fragment en question et de comparer ces valeurs de profondeur avec la profondeur du fragment en question.  Le nombre d'échantillons ayant une profondeur supérieure au fragment actuel détermine directement le coefficient d'ombrage.  Regardez ce diagramme: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/y5/yh/8o/y5yh8oeqvguchqopeu7nz0g-tsy.png"></div><br>  Ici, chaque point gris se trouve à l'intérieur d'un certain objet géométrique et contribue donc à la valeur du coefficient d'ombrage.  Plus il y a d'échantillons à l'intérieur de la géométrie des objets environnants, moins sera l'intensité résiduelle de l'ombrage d'arrière-plan dans cette zone. <br><br>  Évidemment, la qualité et le réalisme de l'effet dépendent directement du nombre d'échantillons prélevés.  Avec un petit nombre d'échantillons, la précision de l'algorithme diminue et conduit à l'apparition d'un artefact de <i>bande</i> ou de « <i>bande</i> » dû à des transitions brusques entre régions avec des coefficients d'ombrage très différents.  Un grand nombre d'échantillons tue simplement les performances.  La randomisation du noyau des échantillons permet d'obtenir des résultats quelque peu similaires pour réduire légèrement le nombre d'échantillons requis.  Une réorientation par rotation vers un angle aléatoire d'un ensemble de vecteurs d'échantillonnage est implicite.  Cependant, l'introduction de l'aléatoire pose immédiatement un nouveau problème sous la forme d'un motif de bruit notable, qui nécessite l'utilisation de filtres de flou pour lisser le résultat.  Ci-dessous, un exemple de l'algorithme (auteur - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">John Chapman</a> ) et de ses problèmes typiques: bandes et modèle de bruit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/r_/ay/l3/r_ayl3jjozsa6fyuni69ejkwpei.jpeg"></div><br>  Comme on peut le voir, une bande notable due au petit nombre d'échantillons est bien supprimée en introduisant une randomisation de l'orientation des échantillons. <br><br>  L'implémentation SSAO spécifique de Crytek avait un style visuel reconnaissable.  Étant donné que les spécialistes de Crytek utilisaient un noyau sphérique de l'échantillon, cela affectait même les surfaces planes telles que les murs, les rendant ombragées - car la moitié du volume du noyau de l'échantillon était submergée sous la géométrie.  Ci-dessous est une capture d'écran d'une scène de Crysis montrée en niveaux de gris basée sur la valeur du facteur d'ombrage.  Ici, l'effet de la "grisaille" est clairement visible: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/j9/zr/r8/j9zrr81dluj-5eobuqcgst48om8.jpeg"></div><br>  Pour éviter cet effet, nous allons passer du noyau sphérique de l'échantillon à un hémisphère orienté le long de la normale à la surface: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/br/pf/3v/brpf3vfbmzd9pmna58ub5x7-age.png"></div><br>  Lors de l'échantillonnage à partir d'un tel <i>hémisphère à orientation normale,</i> nous n'avons pas à prendre en compte les fragments se trouvant sous la surface de la surface adjacente dans le calcul du coefficient d'ombrage.  Cette approche supprime les ombres inutiles, en général, donne des résultats plus réalistes.  Cette leçon utilisera l'approche hémisphérique et un code un peu plus raffiné de la brillante leçon SSAO de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">John Chapman</a> . <br><br><h2>  Tampon de données brutes </h2><br>  Le processus de calcul du facteur d'ombrage dans chaque fragment nécessite la disponibilité de données sur la géométrie environnante.  Plus précisément, nous avons besoin des données suivantes: <br><br><ul><li>  Positionner le vecteur pour chaque fragment; </li><li>  Vecteur normal pour chaque fragment; </li><li>  Couleur diffuse pour chaque fragment; </li><li>  Le cœur de l'échantillon </li><li>  Un vecteur de rotation aléatoire pour chaque fragment utilisé pour réorienter le noyau de l'échantillon. </li></ul><br>  En utilisant des données sur les coordonnées du fragment dans l'espace des espèces, nous pouvons orienter l'hémisphère du noyau de l'échantillon le long du vecteur normal spécifié dans l'espace des espèces pour le fragment actuel.  Ensuite, le noyau résultant est utilisé pour faire des échantillons avec divers décalages à partir d'une texture qui stocke des données sur les coordonnées des fragments.  Nous faisons de nombreux échantillons dans chaque fragment, et pour chaque échantillon que nous faisons, nous comparons sa valeur de profondeur avec la valeur de profondeur du tampon de coordonnées de fragment pour estimer la quantité d'ombrage.  La valeur résultante est ensuite utilisée pour limiter la contribution du composant d'arrière-plan dans le calcul d'éclairage final.  En utilisant un vecteur de rotation aléatoire par fragments, nous pouvons réduire considérablement le nombre d'échantillons requis pour obtenir un résultat décent, et cela sera ensuite démontré. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wv/xo/aj/wvxoajroexwvjgq77n81-fjhats.png"></div><br>  Le SSAO étant un effet réalisé dans l'espace écran, il est possible d'effectuer un calcul direct en effectuant un quadrillage plein écran.  Mais alors nous n'aurons pas de données sur la géométrie de la scène.  Pour contourner cette restriction, nous rendrons toutes les informations nécessaires dans la texture, qui seront ensuite utilisées dans le shader SSAO pour accéder à des informations géométriques et autres sur la scène.  Si vous avez suivi attentivement ces leçons, vous devez déjà savoir dans l'approche décrite l'apparence de l'algorithme d'ombrage différé.  C'est en grande partie pourquoi l'effet SSAO en tant que natif apparaît dans le rendu avec un ombrage différé - après tout, les textures qui stockent les coordonnées et les normales sont déjà disponibles dans le G-buffer. <br><br><blockquote>  Dans cette leçon, l'effet est implémenté au-dessus d'une version légèrement simplifiée du code de la leçon sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">éclairage différé</a> .  Si vous ne vous êtes pas encore familiarisé avec les principes de l'éclairage différé, je vous recommande fortement de vous tourner vers cette leçon. <br></blockquote><br>  Étant donné que l'accès aux informations de fragment sur les coordonnées et les normales devrait déjà être disponible en raison du tampon G, le shader de fragment de l'étape de traitement de la géométrie est assez simple: <br><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core layout (location = 0) out vec4 gPosition; layout (location = 1) out vec3 gNormal; layout (location = 2) out vec4 gAlbedoSpec; in vec2 TexCoords; in vec3 FragPos; in vec3 Normal; void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//        gPosition = FragPos; //       gNormal = normalize(Normal); //    -   gAlbedoSpec.rgb = vec3(0.95); }</span></span></span></span></code> </pre> <br>  Étant donné que l'algorithme SSAO est un effet dans l'espace d'écran et que le facteur d'ombrage est calculé en fonction de la zone visible de la scène, il est judicieux d'effectuer des calculs dans l'espace d'affichage.  Dans ce cas, la variable <i>FragPos</i> obtenue à partir du vertex shader stocke la position exactement dans la fenêtre.  Il convient de s'assurer que les coordonnées et les normales sont stockées dans le G-buffer dans l'espace de vue, car tous les autres calculs y seront effectués. <br><br><blockquote>  Il y a la possibilité de restaurer le vecteur de position sur la base uniquement d'une profondeur de fragment connue et d'une certaine quantité de magie mathématique, qui est décrite, par exemple, dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blog de</a> Matt Pettineo.  Bien sûr, cela nécessite un coût de calcul important, mais cela élimine le besoin de stocker les données de position dans le G-buffer, ce qui prend beaucoup de mémoire vidéo.  Cependant, dans un souci de simplicité de l'exemple de code, nous laisserons cette approche à l'étude personnelle. </blockquote><br>  La texture du tampon de couleur <i>gPosition</i> est configurée comme suit: <br><br><pre> <code class="cpp hljs">glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;gPosition); glBindTexture(GL_TEXTURE_2D, gPosition); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);</code> </pre> <br>  Cette texture stocke les coordonnées des fragments et peut être utilisée pour obtenir des données de profondeur pour chaque point à partir du noyau des échantillons.  Je note que la texture utilise un format de données à virgule flottante - cela permettra aux coordonnées des fragments de ne pas être réduites à l'intervalle [0., 1.].  <i>Faites</i> également attention au mode de répétition - <i>GL_CLAMP_TO_EDGE</i> est défini.  Ceci est nécessaire pour éliminer la possibilité de ne pas suréchantillonner volontairement l'espace de l'écran.  Le dépassement de l'intervalle principal des coordonnées de texture nous donnera des données de position et de profondeur incorrectes. <br><br>  Ensuite, nous nous engagerons dans la formation d'un noyau hémisphérique des échantillons et la création d'une méthode d'orientation aléatoire. <br><br><h2>  Création d'un hémisphère à orientation normale </h2><br>  Ainsi, la tâche consiste à créer un ensemble de points d'échantillonnage situés à l'intérieur d'un hémisphère orienté le long de la normale à la surface.  Étant donné que la création d'un échantillon de noyau pour toutes les directions possibles de la normale est impossible à calculer, nous utilisons la transition vers l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">espace tangent</a> , où la normale est toujours représentée comme un vecteur dans la direction du demi-axe positif <i>Z.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/br/pf/3v/brpf3vfbmzd9pmna58ub5x7-age.png"></div><br>  En supposant que le rayon de l'hémisphère est un processus unique, la formation d'un noyau d'un échantillon de 64 points ressemble à ceci: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//      0.0 - 1.0 std::uniform_real_distribution&lt;float&gt; randomFloats(0.0, 1.0); std::default_random_engine generator; std::vector&lt;glm::vec3&gt; ssaoKernel; for (unsigned int i = 0; i &lt; 64; ++i) { glm::vec3 sample( randomFloats(generator) * 2.0 - 1.0, randomFloats(generator) * 2.0 - 1.0, randomFloats(generator) ); sample = glm::normalize(sample); sample *= randomFloats(generator); float scale = (float)i / 64.0; ssaoKernel.push_back(sample); }</span></span></code> </pre> <br>  Ici, nous sélectionnons au hasard les coordonnées <i>x</i> et <i>y</i> dans l'intervalle [-1., 1.] et la coordonnée <i>z</i> dans l'intervalle [0., 1.] (si l'intervalle est le même que pour <i>x</i> et <i>y</i> , nous obtiendrions un noyau sphérique échantillonnage).  Les vecteurs d'échantillons résultants seront limités aux hémisphères, car le noyau de l'échantillon sera finalement orienté le long de la normale à la surface. <br><br>  À l'heure actuelle, tous les points d'échantillonnage sont répartis de manière aléatoire à l'intérieur du noyau, mais pour des raisons de qualité de l'effet, les échantillons plus proches de l'origine du noyau devraient contribuer davantage au calcul du coefficient d'ombrage.  Cela peut être réalisé en modifiant la distribution des points d'échantillonnage formés en augmentant leur densité près de l'origine.  Cette tâche est facilement accomplie à l'aide de la fonction d'interpolation d'accélération: <br><br><pre> <code class="cpp hljs">scale = lerp(<span class="hljs-number"><span class="hljs-number">0.1f</span></span>, <span class="hljs-number"><span class="hljs-number">1.0f</span></span>, scale * scale); sample *= scale; ssaoKernel.push_back(sample); }</code> </pre> <br>  La fonction <i>lerp ()</i> est définie comme: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lerp</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> a, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> b, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> f)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a + f * (b - a); }</code> </pre> <br>  Une telle astuce nous donne une distribution modifiée, où la plupart des points d'échantillonnage se trouvent près de l'origine du noyau. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h7/dy/xm/h7dyxm-1zerxg1krzbxszp7kzqi.png"></div><br>  Chacun des vecteurs échantillons obtenus sera utilisé pour déplacer les coordonnées du fragment dans l'espace des espèces afin d'obtenir des données sur la géométrie environnante.  Pour obtenir des résultats décents lorsque vous travaillez dans la fenêtre, vous aurez peut-être besoin d'un nombre impressionnant d'échantillons, ce qui affectera inévitablement les performances.  Cependant, l'introduction de bruit pseudo-aléatoire ou la rotation des vecteurs d'échantillonnage dans chaque fragment traité réduira considérablement le nombre requis d'échantillons de qualité comparable. <br><br><h2>  Rotation aléatoire du noyau de l'échantillon </h2><br>  Ainsi, l'introduction de l'aléatoire dans la distribution des points dans le noyau de l'échantillon peut réduire considérablement l'exigence du nombre de ces points pour obtenir un effet de qualité décent.  Il serait possible de créer un vecteur de rotation aléatoire pour chaque fragment de la scène, mais c'est trop cher de mémoire.  Il est plus efficace de créer une petite texture contenant un ensemble de vecteurs de rotation aléatoire, puis de l’utiliser avec le mode de répétition <i>GL_REPEAT</i> . <br><br>  Créez un tableau 4x4 et remplissez-le de vecteurs de rotation aléatoire orientés le long du vecteur normal dans l'espace tangent: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;glm::vec3&gt; ssaoNoise; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; i++) { glm::<span class="hljs-function"><span class="hljs-function">vec3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">noise</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( randomFloats(generator) * </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2.0</span></span></span></span><span class="hljs-function"><span class="hljs-params"> - </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, randomFloats(generator) * </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2.0</span></span></span></span><span class="hljs-function"><span class="hljs-params"> - </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0f</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>; ssaoNoise.push_back(noise); }</code> </pre> <br>  Puisque le noyau est aligné le long du demi-axe positif <i>Z</i> dans l'espace tangent, nous laissons la composante <i>z</i> égale à zéro - cela assurera la rotation uniquement autour de l'axe <i>Z.</i> <br><br>  Ensuite, créez une texture 4x4 et remplissez-la avec notre tableau de vecteurs de rotation.  Assurez-vous d'utiliser le <i>mode de</i> relecture <i>GL_REPEAT</i> pour le pavage de texture: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> noiseTexture; glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;noiseTexture); glBindTexture(GL_TEXTURE_2D, noiseTexture); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, &amp;ssaoNoise[<span class="hljs-number"><span class="hljs-number">0</span></span>]); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);</code> </pre> <br>  Eh bien, nous avons maintenant toutes les données nécessaires à la mise en œuvre directe de l'algorithme SSAO! <br><br><h2>  Shader SSAO </h2><br>  Un shader d'effet sera exécuté pour chaque fragment d'un quadruple plein écran, calculant le coefficient d'ombrage dans chacun d'eux.  Étant donné que les résultats seront utilisés dans une autre étape de rendu qui crée l'éclairage final, nous devrons créer un autre objet framebuffer pour stocker le résultat du shader: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ssaoFBO; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoFBO); glBindFramebuffer(GL_FRAMEBUFFER, ssaoFBO); <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ssaoColorBuffer; glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoColorBuffer); glBindTexture(GL_TEXTURE_2D, ssaoColorBuffer); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RED, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoColorBuffer, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  Comme le résultat de l'algorithme est le seul nombre réel dans [0., 1.], pour le stockage, il suffira de créer une texture avec le seul composant disponible.  C'est pourquoi <i>GL_RED</i> est défini comme format interne pour le tampon de couleur. <br><br>  En général, le processus de rendu d'étape SSAO ressemble à ceci: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//  :  G- glBindFramebuffer(GL_FRAMEBUFFER, gBuffer); [...] glBindFramebuffer(GL_FRAMEBUFFER, 0); //  G-      SSAO glBindFramebuffer(GL_FRAMEBUFFER, ssaoFBO); glClear(GL_COLOR_BUFFER_BIT); glActiveTexture(GL_TEXTURE0); glBindTexture(GL_TEXTURE_2D, gPosition); glActiveTexture(GL_TEXTURE1); glBindTexture(GL_TEXTURE_2D, gNormal); glActiveTexture(GL_TEXTURE2); glBindTexture(GL_TEXTURE_2D, noiseTexture); shaderSSAO.use(); SendKernelSamplesToShader(); shaderSSAO.setMat4("projection", projection); RenderQuad(); glBindFramebuffer(GL_FRAMEBUFFER, 0); //  :    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); shaderLightingPass.use(); [...] glActiveTexture(GL_TEXTURE3); glBindTexture(GL_TEXTURE_2D, ssaoColorBuffer); [...] RenderQuad();</span></span></code> </pre> <br>  Le shader <i>SSAO</i> accepte les textures du tampon G dont il a besoin en entrée, ainsi que la texture du bruit et le noyau de l'échantillon: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out float FragColor; in vec2 TexCoords; uniform sampler2D gPosition; uniform sampler2D gNormal; uniform sampler2D texNoise; uniform vec3 samples[64]; uniform mat4 projection; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//             //      1280x720 const vec2 noiseScale = vec2(1280.0/4.0, 720.0/4.0); void main() { [...] }</span></span></span></span></code> </pre> <br>  Notez la variable <i>noiseScale</i> .  Notre petite texture avec du bruit devrait être carrelée sur toute la surface de l'écran, mais puisque les coordonnées de texture <i>TexCoords sont</i> dans [0., 1.] cela ne se produira pas sans notre intervention.  À ces fins, nous calculons le facteur pour les coordonnées de texture, qui se trouve comme le rapport de la taille de l'écran à la taille de la texture de bruit: <br><br><pre> <code class="cpp hljs">vec3 fragPos = texture(gPosition, TexCoords).xyz; vec3 normal = texture(gNormal, TexCoords).rgb; vec3 randomVec = texture(texNoise, TexCoords * noiseScale).xyz;</code> </pre> <br>  Puisque lors de la création de la texture de bruit <i>texNoise</i> , nous avons défini le mode de répétition sur <i>GL_REPEAT</i> , il sera maintenant répété plusieurs fois sur la surface de l'écran.  Avec <i>randomVec</i> , <i>fragPos</i> et <i>les</i> valeurs <i>normales</i> , nous pouvons créer une matrice de transformation TBN de l'espace tangent à l'espace des espèces: <br><br><pre> <code class="cpp hljs">vec3 tangent = normalize(randomVec - normal * dot(randomVec, normal)); vec3 bitangent = cross(normal, tangent); mat3 TBN = mat3(tangent, bitangent, normal);</code> </pre> <br>  En utilisant le processus de Gram-Schmidt, nous créons une base orthogonale inclinée de manière aléatoire dans chaque fragment en fonction de la valeur aléatoire <i>randomVec</i> .  Un point important: dans ce cas, peu importe pour nous que la matrice TBN soit précisément orientée le long de la surface du triangle (comme dans le cas de la cartographie de parallaxe, environ Per.), Nous n'avons donc pas besoin de données tangentes et bi-tangentes précalculées. <br><br>  Ensuite, nous parcourons le tableau du noyau de l'échantillon, convertissons chaque vecteur échantillon de l'espace tangent à l'espace des espèces et obtenons sa somme avec la position actuelle du fragment.  Ensuite, nous comparons la valeur de profondeur de la quantité résultante avec la valeur de profondeur obtenue par échantillonnage à partir de la texture G-buffer correspondante. <br><br>  Bien que cela semble déroutant, passons par les étapes: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> occlusion = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; kernelSize; ++i) { <span class="hljs-comment"><span class="hljs-comment">//     vec3 sample = TBN * samples[i]; //      - sample = fragPos + sample * radius; [...] }</span></span></code> </pre> <br>  Ici, <i>kernelSize</i> et <i>radius</i> sont des variables qui contrôlent les caractéristiques de l'effet.  Dans ce cas, ils sont respectivement de 64 et 0,5.  À chaque itération, nous traduisons le vecteur de base de l'échantillon dans l'espace des espèces.  Ensuite, nous ajoutons à la valeur obtenue du déplacement de l'échantillon dans l'espace des espèces la valeur de la position du fragment dans l'espace des espèces.  Dans ce cas, la valeur de décalage est multipliée par la variable de rayon, qui contrôle le rayon du cœur de l'échantillon d'effet SSAO. <br><br>  Après ces étapes, nous devons convertir le vecteur <i>échantillon</i> résultant en espace d'écran, afin de pouvoir sélectionner dans la texture du tampon G qui stocke les positions et les profondeurs des fragments en utilisant la valeur projetée obtenue.  Puisque l' <i>échantillon</i> est dans la fenêtre, nous avons besoin de la matrice de projection <i>projection</i> : <br><br><pre> <code class="cpp hljs">vec4 offset = vec4(sample, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); offset = projection * offset; <span class="hljs-comment"><span class="hljs-comment">//     offset.xyz /= offset.w; //   offset.xyz = offset.xyz * 0.5 + 0.5; //    [0., 1.]</span></span></code> </pre> <br>  Après la conversion en espace de clip, nous effectuons manuellement la division en perspective en divisant simplement les composants <i>xyz</i> par le composant <i>w</i> .  Le vecteur résultant en coordonnées de périphérique normalisées ( <i>NDC</i> ) est traduit dans l'intervalle de valeurs [0., 1.] afin qu'il puisse être utilisé comme coordonnées de texture: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> sampleDepth = texture(gPosition, offset.xy).z;</code> </pre> <br>  Nous utilisons les composants <i>xy</i> du vecteur <i>échantillon</i> pour sélectionner dans la texture les positions du G-buffer.  Nous obtenons la valeur de profondeur (composantes <i>z</i> ) correspondant au vecteur échantillon lorsqu'il est vu depuis la position de l'observateur (il s'agit du premier fragment visible non blindé).  Si en même temps la profondeur d'échantillonnage obtenue est supérieure à la profondeur stockée, alors on augmente le coefficient d'ombrage: <br><br><pre> <code class="cpp hljs">occlusion += (sampleDepth &gt;= sample.z + bias ? <span class="hljs-number"><span class="hljs-number">1.0</span></span> : <span class="hljs-number"><span class="hljs-number">0.0</span></span>);</code> </pre> <br>  Notez le décalage de <i>biais</i> , qui est ajouté à la profondeur du fragment d'origine (défini dans l'exemple à 0,025).  Ce décalage n'est pas toujours requis, mais la présence d'une variable vous permet de contrôler l'apparence de l'effet SSAO et, dans certaines situations, supprime les problèmes d'ondulations dans les zones ombrées. <br><br>  Mais ce n'est pas tout, car une telle implémentation conduit à des artefacts perceptibles.  Il se manifeste dans les cas où un fragment situé près du bord d'une certaine surface est considéré.  Dans de telles situations, lors de la comparaison des profondeurs, l'algorithme capturera inévitablement les profondeurs des surfaces, qui peuvent se situer très loin derrière celle considérée.  À ces endroits, l'algorithme augmentera considérablement par erreur le degré d'ombrage, ce qui créera des halos sombres visibles sur les bords des objets.  L'artefact est traité en introduisant une vérification de distance supplémentaire (un exemple de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">John Chapman</a> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zv/yv/eq/zvyveqh3zc_rjcy6fo-z8d76eme.png"></div><br>  La vérification limitera la contribution au coefficient d'ombrage uniquement pour les valeurs de profondeur situées dans le rayon de l'échantillon: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> rangeCheck = smoothstep(<span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, radius / <span class="hljs-built_in"><span class="hljs-built_in">abs</span></span>(fragPos.z - sampleDepth)); occlusion += (sampleDepth &gt;= sample.z + bias ? <span class="hljs-number"><span class="hljs-number">1.0</span></span> : <span class="hljs-number"><span class="hljs-number">0.0</span></span>) * rangeCheck;</code> </pre> <br>  Nous utilisons également la fonction GLSL <i>smoothstep ()</i> , qui implémente une interpolation douce du troisième paramètre entre le premier et le second.  En même temps, renvoyer 0 si le troisième paramètre est inférieur ou égal au premier, ou 1 si le troisième paramètre est supérieur ou égal au second.  Si la différence de profondeur est dans le <i>rayon</i> , alors sa valeur sera lissée en douceur dans l'intervalle [0., 1.] conformément à cette courbe: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jq/9h/p4/jq9hp4-yun_sc277m6pslbjyin0.png"></div><br>  Si nous utilisions des limites claires dans les conditions de vérification de la profondeur, cela ajouterait des artefacts sous forme de limites nettes aux endroits où les valeurs de la différence de profondeurs sont en dehors des limites du <i>rayon</i> . <br><br>  Avec la touche finale, nous normalisons la valeur du coefficient d'ombrage en utilisant la taille du noyau de l'échantillon et enregistrons le résultat.  Nous inversons également la valeur finale en la soustrayant de l'unité, afin que vous puissiez utiliser la valeur finale directement pour moduler le composant d'arrière-plan de l'éclairage sans étapes supplémentaires: <br><br><pre> <code class="cpp hljs">} occlusion = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - (occlusion / kernelSize); FragColor = occlusion;</code> </pre> <br>  Pour une scène avec une nanosuit couchée qui nous est familière, l'exécution du shader SSAO donne la texture suivante: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-z/a4/fx/-za4fxhsbref6easc-cgxnsp94q.png"></div><br>  Comme vous pouvez le voir, l'effet de l'ombrage d'arrière-plan crée une bonne illusion de profondeur.  Seule l'image de sortie du shader vous permet déjà de distinguer les détails du costume et de vous assurer qu'il repose vraiment sur le sol et ne lévite pas à une certaine distance de celui-ci. <br><br>  Néanmoins, l'effet est loin d'être idéal, car le motif de bruit introduit par la texture des vecteurs à rotation aléatoire est facilement perceptible.  Pour lisser le résultat du calcul SSAO, nous appliquons un filtre de flou. <br><br><h2>  Ombrage d'arrière-plan flou </h2><br>  Après avoir construit le résultat de SSAO et avant le mélange final de l'éclairage, il est nécessaire de brouiller la texture qui stocke les données sur le coefficient d'ombrage.  Pour ce faire, nous aurons un autre framebuffer: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ssaoBlurFBO, ssaoColorBufferBlur; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoBlurFBO); glBindFramebuffer(GL_FRAMEBUFFER, ssaoBlurFBO); glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoColorBufferBlur); glBindTexture(GL_TEXTURE_2D, ssaoColorBufferBlur); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RED, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoColorBufferBlur, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  La mise en mosaïque d'une texture de bruit dans l'espace d'écran fournit des caractéristiques d'aléatoire bien définies que vous pouvez utiliser à votre avantage lors de la création d'un filtre de flou: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out float FragColor; in vec2 TexCoords; uniform sampler2D ssaoInput; void main() { vec2 texelSize = 1.0 / vec2(textureSize(ssaoInput, 0)); float result = 0.0; for (int x = -2; x &lt; 2; ++x) { for (int y = -2; y &lt; 2; ++y) { vec2 offset = vec2(float(x), float(y)) * texelSize; result += texture(ssaoInput, TexCoords + offset).r; } } FragColor = result / (4.0 * 4.0); }</span></span></code> </pre> <br>  Le shader transite simplement les texels de la texture SSAO avec un décalage de -2 à +2, ce qui correspond à la taille réelle de la texture de bruit.  Le décalage est égal à la taille exacte d'un texel: la fonction textureSize <i>()</i> est utilisée pour le calcul, qui renvoie <i>vec2</i> avec les dimensions de la texture spécifiée.  T.O.  Le shader fait simplement la moyenne des résultats stockés dans la texture, ce qui donne un flou rapide et assez efficace: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5p/0g/i7/5p0gi7qn_v5w738uyindxexally.png"></div><br>  Au total, nous avons une texture avec des données d'ombrage d'arrière-plan pour chaque fragment sur l'écran - tout est prêt pour l'étape de réduction finale de l'image! <br><br><h2>  Appliquer un ombrage d'arrière-plan </h2><br>  L'étape d'application du coefficient d'ombrage dans le calcul final de l'éclairage est étonnamment simple: pour chaque fragment, il suffit de multiplier simplement la valeur de la composante de fond de la source lumineuse par le coefficient d'ombrage de la texture préparée.  Vous pouvez prendre un shader prêt à l'emploi avec le modèle Blinn-Fong de la leçon sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ombrage différé</a> et le corriger un peu: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D gPosition; uniform sampler2D gNormal; uniform sampler2D gAlbedo; uniform sampler2D ssao; struct Light { vec3 Position; vec3 Color; float Linear; float Quadratic; float Radius; }; uniform Light light; void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//    G- vec3 FragPos = texture(gPosition, TexCoords).rgb; vec3 Normal = texture(gNormal, TexCoords).rgb; vec3 Diffuse = texture(gAlbedo, TexCoords).rgb; float AmbientOcclusion = texture(ssao, TexCoords).r; //   -    //   :   -  vec3 ambient = vec3(0.3 * Diffuse * AmbientOcclusion); vec3 lighting = ambient; //    (0, 0, 0)   - vec3 viewDir = normalize(-FragPos); //   vec3 lightDir = normalize(light.Position - FragPos); vec3 diffuse = max(dot(Normal, lightDir), 0.0) * Diffuse * light.Color; //   vec3 halfwayDir = normalize(lightDir + viewDir); float spec = pow(max(dot(Normal, halfwayDir), 0.0), 8.0); vec3 specular = light.Color * spec; //   float dist = length(light.Position - FragPos); float attenuation = 1.0 / (1.0 + light.Linear * dist + light.Quadratic * dist * dist); diffuse *= attenuation; specular *= attenuation; lighting += diffuse + specular; FragColor = vec4(lighting, 1.0); }</span></span></span></span></code> </pre> <br>  Il n'y a que deux changements majeurs: la transition vers les calculs dans la fenêtre et la multiplication du composant d'éclairage d'arrière-plan par la valeur d' <i>AmbientOcclusion</i> .  Un exemple de scène avec un seul point bleu: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bz/8_/1i/bz8_1in-othscilg_udfyscghg0.png"></div><br>  Le code source complet est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  La manifestation de l'effet SSAO dépend fortement de paramètres tels que <i>kernelSize</i> , <i>radius</i> et <i>polarisation</i> , souvent les affiner est une évidence pour l'artiste de travailler sur un lieu / scène particulier.  Il n'y a pas de «meilleure» combinaison universelle de paramètres: pour certaines scènes, un petit rayon du noyau de l'échantillon est bon, tandis que d'autres bénéficient de l'augmentation du rayon et du nombre d'échantillons.  L'exemple utilise 64 points d'échantillonnage, ce qui, franchement, est redondant, mais vous pouvez toujours modifier le code et voir ce qui se passe avec un plus petit nombre d'échantillons. <br><br>  En plus des uniformes répertoriés responsables de la définition de l'effet, il est possible de contrôler explicitement la gravité de l'effet d'ombrage d'arrière-plan.  Pour ce faire, il suffit d'élever le coefficient à un degré contrôlé par un autre uniforme: <br><br><pre> <code class="cpp hljs">occlusion = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - (occlusion / kernelSize); FragColor = <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(occlusion, power);</code> </pre> <br>  Je vous conseille de passer un peu de temps sur le jeu avec les paramètres, car cela donnera une meilleure compréhension de la nature des changements dans l'image finale. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour résumer, il convient de dire que bien que l'effet visuel de l'utilisation de SSAO soit plutôt subtil, mais dans les scènes avec un éclairage bien placé, il ajoute indéniablement une fraction notable de réalisme. </font><font style="vertical-align: inherit;">Avoir un tel outil dans votre arsenal est certainement précieux.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ressources supplémentaires </font></font></h2><br><ol><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tutoriel SSAO</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Un excellent article de leçon de John Chapman, sur la base duquel le code de cette leçon est construit.</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Connaissez vos artefacts SSAO</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Un article très précieux montrant avec lucidité non seulement les problèmes les plus urgents avec la qualité SSAO, mais aussi les moyens de les résoudre. </font><font style="vertical-align: inherit;">Lecture recommandée.</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SSAO avec reconstruction de profondeur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Addendum à la leçon principale de SSAO par OGLDev concernant une technique couramment utilisée pour restaurer les coordonnées des fragments en fonction de la profondeur. </font><font style="vertical-align: inherit;">L'importance de cette approche est due aux économies de mémoire importantes dues au manque de nécessité de stocker des positions dans le G-buffer. </font><font style="vertical-align: inherit;">L'approche est si universelle qu'elle s'applique aux SSAO dans la mesure où.</font></font></li></ol><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Nous avons un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">télégramme conf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour la coordination des transferts. </font><font style="vertical-align: inherit;">Si vous avez un désir sérieux d'aider à la traduction, alors vous êtes les bienvenus!</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr421385/">https://habr.com/ru/post/fr421385/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr421375/index.html">Comment l'incertitude tue le commerce</a></li>
<li><a href="../fr421377/index.html">7 idées fausses d'un chef de projet novice à Gamedev</a></li>
<li><a href="../fr421379/index.html">Culture toxique Intel</a></li>
<li><a href="../fr421381/index.html">Cours gratuit d'administrateur Cisco ASA</a></li>
<li><a href="../fr421383/index.html">Epic Growth Conference Autumn 2018 - conférence de marketing de produit à Moscou</a></li>
<li><a href="../fr421387/index.html">Entretien avec Lennart Pottering sur Linux Piter sur les changements dans Linux, sur systemd et pourquoi assister à des conférences</a></li>
<li><a href="../fr421389/index.html">Séparation des pouvoirs administratifs à Zimbra</a></li>
<li><a href="../fr421391/index.html">HackThings - un grand hackathon sur l'Internet des objets du 7 au 9 septembre à Skoltech</a></li>
<li><a href="../fr421393/index.html">Panier Mailchimp abandonné: un guide pour les paresseux</a></li>
<li><a href="../fr421395/index.html">Rapport du Club de Rome 2018, chapitre 3.7: «Climat: bonne nouvelle mais gros problèmes»</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
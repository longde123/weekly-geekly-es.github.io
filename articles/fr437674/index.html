<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåµ üìì üë≤üèæ M√©thodes de reconnaissance d'objets 3D pour les v√©hicules sans pilote. Rapport Yandex üöµüèΩ üë©üèΩ‚Äçü§ù‚Äçüë©üèº üö™</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les voitures sans pilote ne peuvent se passer de comprendre ce qui se trouve autour et o√π exactement. En d√©cembre dernier, le d√©veloppeur Viktor Otlig...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>M√©thodes de reconnaissance d'objets 3D pour les v√©hicules sans pilote. Rapport Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/437674/">  Les voitures sans pilote ne peuvent se passer de comprendre ce qui se trouve autour et o√π exactement.  En d√©cembre dernier, le d√©veloppeur Viktor Otliga <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">vitonka a</a> fait une pr√©sentation sur la d√©tection d'objets 3D au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data-Christmas tree</a> .  Victor travaille en direction des v√©hicules sans pilote Yandex, dans le groupe traitant de la situation de la circulation (et enseigne √©galement au ShAD).  Il a expliqu√© comment nous r√©solvons le probl√®me de la reconnaissance des autres usagers de la route dans un nuage de points en trois dimensions, en quoi ce probl√®me diff√®re de la reconnaissance des objets dans une image et comment tirer profit du partage de diff√©rents types de capteurs. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/celzhoWh2TE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Bonjour √† tous!  Je m'appelle Victor Otliga, je travaille au bureau Yandex de Minsk et je d√©veloppe des v√©hicules sans pilote.  Aujourd'hui, je vais parler d'une t√¢che assez importante pour les drones - la reconnaissance des objets 3D autour de nous. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/ky/wn/hu/kywnhuprs-iq34tx4rgohnvwqm8.jpeg"><br><br>  Pour rouler, vous devez comprendre ce qui vous entoure.  Je vais vous dire bri√®vement quels capteurs et capteurs sont utilis√©s sur les v√©hicules sans pilote et lesquels nous utilisons.  Je vais vous dire quelle est la t√¢che de d√©tection des objets 3D et comment mesurer la qualit√© de la d√©tection.  Ensuite, je vais vous dire sur quoi cette qualit√© peut √™tre mesur√©e.  Et puis je ferai une br√®ve revue des bons algorithmes modernes, y compris ceux sur lesquels nos solutions sont bas√©es.  Et au final - petits r√©sultats, une comparaison de ces algorithmes, dont le n√¥tre. <br><br><img src="https://habrastorage.org/webt/pk/sf/vo/pksfvoxtqwlyf6k-wido8ixektg.jpeg"><br><br>  Voil√† √† quoi ressemble notre prototype fonctionnel de voiture sans pilote.  Un tel taxi peut √™tre lou√© par toute personne sans chauffeur dans la ville d'Innopolis en Russie, ainsi qu'√† Skolkovo.  Et si vous regardez bien, il y a un gros d√© sur le dessus.  Qu'y a-t-il √† l'int√©rieur? <br><br><img src="https://habrastorage.org/webt/ei/3c/mq/ei3cmqe3l4kjfzjju-s1ndavkwi.jpeg"><br><br>  √Ä l'int√©rieur d'un simple ensemble de capteurs.  Il existe une antenne GNSS et GSM pour d√©terminer o√π se trouve la voiture et communiquer avec le monde ext√©rieur.  O√π sans un capteur aussi classique qu'un appareil photo.  Mais aujourd'hui, nous nous int√©resserons aux lidars. <br><br><img src="https://habrastorage.org/webt/cm/s6/pd/cms6pdxey7d4ykgktlc8lvyd8fc.jpeg"><br><br><img src="https://habrastorage.org/webt/un/ia/bg/uniabgh6yomlr2rourl7ynj3coc.jpeg"><br><br>  Lidar produit environ un tel nuage de points autour de lui, qui ont trois coordonn√©es.  Et vous devez travailler avec eux.  Je vais vous expliquer comment, √† l'aide d'une image de cam√©ra et d'un nuage lidar, reconna√Ætre des objets. <br><br><img src="https://habrastorage.org/webt/yx/rt/si/yxrtsiwsnt_gcdgjbz42pp8lqvc.jpeg"><br><br>  Quel est le d√©fi?  L'image de la cam√©ra entre dans l'entr√©e, la cam√©ra est synchronis√©e avec le lidar.  Il serait √©trange d'utiliser l'image de l'appareil photo il y a une seconde, de prendre le nuage lidar d'un moment compl√®tement diff√©rent et d'essayer de reconna√Ætre des objets dessus. <br><br><img src="https://habrastorage.org/webt/xa/g6/aj/xag6ajjiigpo5m737kklxiwkmb0.jpeg"><br><br>  Nous synchronisons en quelque sorte les cam√©ras et les lidars, c'est une t√¢che difficile distincte, mais nous y parvenons avec succ√®s.  Ces donn√©es entrent en entr√©e, et √† la fin, nous voulons obtenir des bo√Ætes, des bo√Ætes de d√©limitation qui limitent l'objet: pi√©tons, cyclistes, voitures et autres usagers de la route et pas seulement. <br><br>  La t√¢che √©tait fix√©e.  Comment allons-nous l'√©valuer? <br><br><img src="https://habrastorage.org/webt/ew/hm/wd/ewhmwdgektceevdbmgu838n5wui.jpeg"><br><br>  Le probl√®me de la reconnaissance 2D d'objets dans une image a √©t√© largement √©tudi√©. <br><br><img src="https://habrastorage.org/webt/-c/ri/cu/-cricuguziob4idgyr_u-ihfq-e.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Vous pouvez utiliser des m√©triques standard ou leurs analogues.  Il y a un coefficient Jacquard ou une intersection sur l'union, un merveilleux coefficient qui montre √† quel point nous avons d√©tect√© un objet.  Nous pouvons prendre une bo√Æte o√π, comme nous le supposons, l'objet est situ√©, et une bo√Æte o√π il se trouve r√©ellement.  Comptez cette m√©trique.  Il existe des seuils standard - disons que pour les voitures, ils prennent souvent un seuil de 0,7.  Si cette valeur est sup√©rieure √† 0,7, nous pensons avoir r√©ussi √† d√©tecter l'objet, que l'objet est l√†.  Nous sommes grands, nous pouvons aller plus loin. <br><br>  De plus, afin de d√©tecter un objet et de comprendre qu'il se trouve quelque part, nous voudrions prendre une sorte de confiance que nous voyons vraiment l'objet l√†-bas, et le mesurer aussi.  Vous pouvez mesurer simple, consid√©rer la pr√©cision moyenne.  Vous pouvez prendre la courbe de rappel de pr√©cision et la zone en dessous et dire: plus elle est grande, mieux c'est. <br><br><img src="https://habrastorage.org/webt/p7/jk/z5/p7jkz5xnyyhehx99e73nijtb798.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Habituellement, pour mesurer la qualit√© de la d√©tection 3D, ils prennent un ensemble de donn√©es et le divisent en plusieurs parties, car les objets peuvent √™tre proches ou plus √©loign√©s, ils peuvent √™tre partiellement masqu√©s par autre chose.  Par cons√©quent, l'√©chantillon de validation est souvent divis√© en trois parties.  Objets faciles √† d√©tecter, de complexit√© moyenne et complexes, distants ou fortement obscurcis.  Et ils mesurent s√©par√©ment en trois parties.  Et dans les r√©sultats de la comparaison, nous prendrons √©galement une telle partition. <br><br><img src="https://habrastorage.org/webt/6v/d9/tx/6vd9tx38777pdvhxt4iij_rc4xu.jpeg"><br><br>  Vous pouvez mesurer la qualit√© comme en 3D, un analogue d'intersection sur union, mais pas le rapport des surfaces, mais, par exemple, les volumes.  Mais une voiture sans pilote, en r√®gle g√©n√©rale, ne se soucie pas vraiment de ce qui se passe dans la coordonn√©e Z. Nous pouvons prendre une vue plongeante d'en haut et prendre une sorte de m√©trique, comme si nous regardions tout cela en 2D.  L'homme navigue plus ou moins en 2D, et un v√©hicule sans pilote est le m√™me.  La hauteur de la bo√Æte n'est pas tr√®s importante. <br><br><img src="https://habrastorage.org/webt/gs/gg/js/gsggjsnlbhi0qd_ppdpnvqvlncm.jpeg"><br><br>  Que mesurer? <br><br><img src="https://habrastorage.org/webt/-p/vq/qn/-pvqqnyi_yovi_bit9x6lergyva.jpeg"><br><br>  Probablement tous ceux qui ont au moins fait face √† la t√¢che de d√©tecter en 3D par le nuage lidar ont entendu parler d'un ensemble de donn√©es tel que KITTI. <br><br><img src="https://habrastorage.org/webt/bp/bz/wn/bpbzwnd-1o69xdoonrm1k81vndo.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Dans certaines villes d'Allemagne, un ensemble de donn√©es a √©t√© enregistr√©, une voiture √©quip√©e de capteurs est all√©e, elle avait des capteurs GPS, des cam√©ras et des lidars.  Ensuite, il a √©t√© balis√© sur environ 8 000 sc√®nes et divis√© en deux parties.  Une partie est la formation, sur laquelle tout le monde peut se former, et la seconde est la validation, afin de mesurer les r√©sultats.  L'√©chantillon de validation KITTI est consid√©r√© comme une mesure de qualit√©.  Tout d'abord, il y a un tableau des leaders sur le site du jeu de donn√©es KITTI, vous pouvez y envoyer votre d√©cision, vos r√©sultats sur le jeu de donn√©es de validation et comparer avec les d√©cisions d'autres acteurs du march√© ou chercheurs.  Mais cet ensemble de donn√©es est √©galement disponible publiquement, vous pouvez t√©l√©charger, ne le dire √† personne, v√©rifier le v√¥tre, comparer avec vos concurrents, mais ne pas t√©l√©charger publiquement. <br><br><img src="https://habrastorage.org/webt/12/mu/8_/12mu8_z9hlu8-zuvhlm1bofiko4.jpeg"><br><br>  Les ensembles de donn√©es externes sont bons, vous n'avez pas √† y consacrer votre temps et vos ressources, mais en r√®gle g√©n√©rale, une voiture qui a voyag√© en Allemagne peut √™tre √©quip√©e de capteurs compl√®tement diff√©rents.  Et c'est toujours bien d'avoir votre propre jeu de donn√©es interne.  De plus, il est plus difficile d'√©tendre un jeu de donn√©es externe au d√©triment des autres, mais il est plus facile de g√©rer le v√¥tre.  Par cons√©quent, nous utilisons le merveilleux service Yandex.Tolok. <br><br><img src="https://habrastorage.org/webt/i4/ha/ns/i4hansnkczrkhpeq9_liyn8t9bk.jpeg"><br><br>  Nous avons finalis√© notre syst√®me de t√¢ches sp√©ciales.  √Ä l'utilisateur qui veut aider avec le balisage et obtenir une r√©compense pour cela, nous distribuons une image de la cam√©ra, distribuons un nuage lidar que vous pouvez faire pivoter, zoomer, d√©zoomer et lui demander de mettre des bo√Ætes qui limitent nos zones de d√©limitation afin qu'une voiture ou un pi√©ton y p√©n√®tre ou autre chose.  Ainsi, nous collectons des √©chantillons internes pour un usage personnel. <br><br>  Supposons que nous ayons d√©cid√© quelle t√¢che nous allons r√©soudre, comment nous supposerons que nous l'avons fait bien ou mal.  Nous avons pris quelque part les donn√©es. <br><br>  Quels sont les algorithmes?  Commen√ßons par 2D.  La t√¢che de d√©tection 2D est tr√®s bien connue et √©tudi√©e. <br><br><img src="https://habrastorage.org/webt/6x/vq/ta/6xvqtadjyarjzn9h9v0xz6cqrny.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Certes, beaucoup de gens connaissent l'algorithme SSD, qui est l'une des m√©thodes de pointe pour d√©tecter les objets 2D, et en principe, nous pouvons supposer que, d'une certaine mani√®re, le probl√®me de la d√©tection d'objets dans l'image est assez bien r√©solu.  Si quelque chose, nous pouvons utiliser ces r√©sultats comme une sorte d'informations suppl√©mentaires. <br><br>  Mais notre nuage lidar a ses propres caract√©ristiques qui le distinguent grandement de l'image.  Premi√®rement, elle est tr√®s clairsem√©e.  Si l'image est une structure dense, les pixels sont proches, tout est dense, alors le nuage est tr√®s mince, il n'y a pas tellement de points et il n'a pas de structure r√©guli√®re.  Purement physiquement, il y a beaucoup plus de points pr√®s de l√† que dans la distance, et plus vous allez loin, moins il y a de points, moins il y a de pr√©cision, plus il est difficile de d√©terminer quelque chose. <br><br>  Eh bien, les points, en principe, du cloud viennent dans un ordre incompr√©hensible.  Personne ne garantit qu'un point sera toujours ant√©rieur √† un autre.  Ils viennent dans un ordre relativement al√©atoire.  Vous pouvez en quelque sorte accepter de les trier ou de les r√©organiser √† l'avance, puis de soumettre les mod√®les √† l'entr√©e, mais cela sera assez g√™nant, vous devez prendre le temps de les modifier, etc. <br><br>  Nous aimerions trouver un syst√®me qui sera invariant √† nos probl√®mes, r√©soudra tous ces probl√®mes.  Heureusement, l'ann√©e derni√®re, CVPR a pr√©sent√© un tel syst√®me.  Il y avait une telle architecture - PointNet.  Comment fonctionne-t-elle? <br><br><img src="https://habrastorage.org/webt/ny/ay/np/nyaynp7lrsoopcumwsbjmm9ynik.jpeg"><br><br>  Un nuage de n points arrive √† l'entr√©e, chacun avec trois coordonn√©es.  Ensuite, chaque point est en quelque sorte normalis√© par une petite transformation sp√©ciale.  De plus, il est conduit √† travers un r√©seau enti√®rement connect√© afin d'enrichir ces points de signes.  Ensuite, la transformation a lieu et, √† la fin, elle s'enrichit en plus.  √Ä un moment donn√©, n points sont obtenus, mais chacun a environ 1024 caract√©ristiques, ils sont en quelque sorte standardis√©s.  Mais jusqu'√† pr√©sent, nous n'avons pas r√©solu le probl√®me concernant l'invariance des d√©placements, des virages, etc.  Ici, il est propos√© de faire un maximum de regroupement, de prendre le maximum parmi les points sur chaque canal et d'obtenir un vecteur de 1024 signes, qui sera un descripteur de notre nuage, qui contiendra des informations sur l'ensemble du nuage.  Et puis avec ce descripteur, vous pouvez faire beaucoup de choses diff√©rentes. <br><br><img src="https://habrastorage.org/webt/qj/lr/hc/qjlrhclpvd2smfl3q2j28bft0sw.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Par exemple, vous pouvez le coller aux descripteurs de points individuels et r√©soudre le probl√®me de segmentation, pour chaque point afin de d√©terminer √† quel objet il appartient.  C'est juste une route ou une personne ou une voiture.  Et voici les r√©sultats de l'article. <br><br><img src="https://habrastorage.org/webt/kh/-o/cw/kh-ocwqrkgelcs958zio30nc7ek.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Vous remarquerez peut-√™tre que cet algorithme fait un tr√®s bon travail.  En particulier, j'aime beaucoup cette petite table dans laquelle certaines des donn√©es sur le comptoir ont √©t√© jet√©es, et il a n√©anmoins d√©termin√© o√π sont les pieds et o√π se trouve le comptoir.  Et cet algorithme, en particulier, peut √™tre utilis√© comme une brique pour construire d'autres syst√®mes. <br><br>  Une approche qui utilise cela est l'approche Frustum PointNets ou l'approche pyramidale tronqu√©e.  L'id√©e est quelque chose comme √ßa: reconnaissons les objets en 2D, nous sommes bons √† le faire. <br><br><img src="https://habrastorage.org/webt/lh/xb/uv/lhxbuvbemlftwpvufw7hbpmmhog.jpeg"><br><br>  Puis, sachant comment fonctionne la cam√©ra, nous pouvons estimer dans quelle zone l'objet qui nous int√©resse, la machine, peut se trouver.  Pour projeter, d√©coupez uniquement cette zone, et d√©j√† sur elle, r√©solvez le probl√®me de trouver un objet int√©ressant, par exemple une machine.  C'est beaucoup plus facile que de rechercher n'importe quel nombre de voitures dans le cloud.  La recherche d'une voiture exactement dans le m√™me nuage semble √™tre beaucoup plus claire et plus efficace. <br><br><img src="https://habrastorage.org/webt/lt/t-/0v/ltt-0v8iobuju4yfoj-ips2uka8.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  L'architecture ressemble √† ceci.  Tout d'abord, nous s√©lectionnons en quelque sorte les r√©gions qui nous int√©ressent, dans chaque r√©gion, nous faisons une segmentation, puis nous r√©solvons le probl√®me de trouver une bo√Æte englobante qui limite l'objet qui nous int√©resse. <br><br><img src="https://habrastorage.org/webt/2w/lj/8g/2wlj8gt2m9vyiljomkkz0tjvd_y.jpeg"><br><br>  L'approche a fait ses preuves.  Sur les photos, vous pouvez voir que cela fonctionne assez bien, mais il pr√©sente √©galement des inconv√©nients.  L'approche est √† deux niveaux, de ce fait, elle peut √™tre lente.  Nous devons d'abord appliquer des r√©seaux et reconna√Ætre des objets 2D, puis couper, puis r√©soudre le probl√®me de segmentation et d'allocation du cadre de d√©limitation sur un morceau du nuage, afin qu'il puisse fonctionner un peu lentement. <br><br>  Une autre approche.  Pourquoi ne transformons-nous pas notre nuage en une sorte de structure qui ressemble √† une image?  L'id√©e est la suivante: regardons-la d'en haut et √©chantillonnons notre nuage lidar.  Nous obtenons des cubes d'espaces. <br><br><img src="https://habrastorage.org/webt/sc/7l/3h/sc7l3h0ewwcfmiuejsxnl7ozx5c.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  √Ä l'int√©rieur de chaque cube, nous avons obtenu quelques points.  Nous pouvons compter certaines fonctionnalit√©s dessus, mais nous pouvons utiliser PointNet, qui pour chaque morceau d'espace comptera une sorte de descripteur.  Nous obtiendrons un voxel, chaque voxel a une description caract√©ristique, et il ressemblera plus ou moins √† une structure dense, comme une image.  Nous pouvons d√©j√† cr√©er diff√©rentes architectures, par exemple une architecture de type SSD pour d√©tecter des objets. <br><br><img src="https://habrastorage.org/webt/x_/tb/c_/x_tbc_hsv_yuahyllkmlxijsowe.jpeg"><br><br>  Cette derni√®re approche, qui a √©t√© l'une des toutes premi√®res approches pour combiner les donn√©es de plusieurs capteurs.  Ce serait un p√©ch√© d'utiliser uniquement des donn√©es lidar alors que nous avons √©galement des donn√©es de cam√©ra.  L'une de ces approches est appel√©e le r√©seau de d√©tection d'objets 3D √† vues multiples.  Son id√©e est la suivante: alimenter trois canaux de donn√©es d'entr√©e √† l'entr√©e d'un grand r√©seau. <br><br><img src="https://habrastorage.org/webt/tz/xv/ty/tzxvty86li7jozjwozhqlun8r9a.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien depuis la diapositive</a></sub></sup> </h5><br>  Il s'agit d'une image de la cam√©ra et, en deux versions, d'un nuage lidar: d'en haut, avec une vue plongeante et une sorte de vue de face, ce que nous voyons devant nous.  Nous soumettons cela √† l'entr√©e du neurone, et il configurera tout en lui-m√™me, nous donnera le r√©sultat final - l'objet. <br><br>  Je veux comparer ces mod√®les.  Sur l'ensemble de donn√©es KITTI, sur les lecteurs de validation, la qualit√© est √©valu√©e en pourcentage de pr√©cision moyenne. <br><br><img src="https://habrastorage.org/webt/pt/ny/8x/ptny8xzcmojphtluvg5pxm1-mlq.jpeg"><br><br>  Vous remarquerez peut-√™tre que F-PointNet fonctionne assez bien et assez rapidement, bat tout le monde dans diff√©rents domaines - du moins selon les auteurs. <br><br>  Notre approche est bas√©e sur plus ou moins toutes les id√©es que j'ai √©num√©r√©es.  Si vous comparez, vous obtenez l'image suivante.  Si nous n'occupons pas la premi√®re place, alors au moins la seconde.  De plus, sur les objets difficiles √† d√©tecter, nous entrons dans les chefs.  Et surtout, notre approche est assez rapide.  Cela signifie qu'il est d√©j√† assez bien applicable pour les syst√®mes en temps r√©el, et il est particuli√®rement important pour un v√©hicule sans pilote de surveiller ce qui se passe sur la route et de mettre en √©vidence tous ces objets. <br><br><img src="https://habrastorage.org/webt/ad/dx/bk/addxbko462x7r4doq22akwwkpik.jpeg"><br><br>  En conclusion - un exemple de notre d√©tecteur: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/celzhoWh2TE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  On voit que la situation est compliqu√©e: certains objets sont ferm√©s, certains ne sont pas visibles par la cam√©ra.  Pi√©tons, cyclistes.  Mais le d√©tecteur s'en sort assez bien.  Je vous remercie! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr437674/">https://habr.com/ru/post/fr437674/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr437660/index.html">Mise √† jour du profil √† vie dans Visual Studio 2019 Preview 2</a></li>
<li><a href="../fr437664/index.html">R√©cup√©ration du compos√©</a></li>
<li><a href="../fr437666/index.html">Annonce de l'aper√ßu de F # 4.6</a></li>
<li><a href="../fr437670/index.html">Mises √† jour du backend MSVC dans Visual Studio 2019 Preview 2: nouvelles optimisations, am√©liorations OpenMP et Build Throughput</a></li>
<li><a href="../fr437672/index.html">cyberd: Calculer les connaissances du web3</a></li>
<li><a href="../fr437676/index.html">Les universit√©s et les acc√©l√©rateurs d'entreprise comme levier pour lancer une start-up B2B aux √âtats-Unis</a></li>
<li><a href="../fr437680/index.html">Ma collection de bricolage sur Youtube</a></li>
<li><a href="../fr437682/index.html">√âcriture d'un autre outil de cr√©ation de mod√®les Kubernetes</a></li>
<li><a href="../fr437684/index.html">Algorithme supr√™me - Compendium biais√©</a></li>
<li><a href="../fr437686/index.html">Learning Go: √©crire un messager p2p avec un cryptage de bout en bout</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
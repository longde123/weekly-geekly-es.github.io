<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìØ üòñ üôÜüèΩ Nous consid√©rons les statistiques sur les exp√©riences sur hh.ru üè∞ üö£üèø üóëÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous! 

 Aujourd'hui, je vais vous dire comment nous, √† hh.ru, consid√©rons les statistiques manuelles sur les exp√©riences. Nous verrons d'o√π...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous consid√©rons les statistiques sur les exp√©riences sur hh.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hh/blog/424251/">  Bonjour √† tous! <br><br>  Aujourd'hui, je vais vous dire comment nous, √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hh.ru,</a> consid√©rons les statistiques manuelles sur les exp√©riences.  Nous verrons d'o√π proviennent les donn√©es, comment nous les traitons et quels pi√®ges nous rencontrons.  Dans cet article, je partagerai une architecture et une approche communes, il y aura un minimum de scripts et de code r√©els.  Le public principal est les analystes d√©butants qui s'int√©ressent √† la structure de l'infrastructure d'analyse des donn√©es dans hh.ru.  Si ce sujet est int√©ressant - √©crivez dans les commentaires, nous pouvons nous plonger dans le code dans les articles suivants. <br><br>  Vous pouvez lire comment les mesures automatiques pour les exp√©riences A / B sont prises en compte dans notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">autre article</a> . <br><br><img src="https://habrastorage.org/webt/2t/ni/z7/2tniz7lywqs_e1q19yafq1n6vss.jpeg" alt="image"><br><a name="habracut"></a><br><h2>  Quelles donn√©es analysons-nous et d'o√π viennent-elles </h2><br>  Nous analysons les journaux d'acc√®s et tous les journaux personnalis√©s que nous √©crivons nous-m√™mes. <br><br><blockquote>  95.108.213.12 - - [13 / ao√ªt / 2018: 04: 00: 02 +0300] 200 "GET / employeur / 2574971 HTTP / 1.1" 12012 "-" "Mozilla / 5.0 (compatible; YandexBot / 3.0; + http: / /yandex.com/bots) "" - "" gardabani.headhunter.ge "" 0,063 "-" "1534122002.858" - "" 192.168.2.38:1500 "" [0,064] "{15341220027959c8c01c51a6e01b682f} 200 https 1 -" " - "- - [35827] [0,000 0] <br>  178.23.230.16 - - [13 / ao√ªt / 2018: 04: 00: 02 +0300] 200 "GET / vacancy / 24266672 HTTP / 1.1" 24229 " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hh.ru/vacancy/24007186?query=bmw</a> " "Mozilla / 5.0 ( Macintosh; Intel Mac OS X 10_10_5) AppleWebKit / 603.3.8 (KHTML, comme Gecko) Version / 10.1.2 Safari / 603.3.8 "-" "hh.ru" "0.210" "last_visit = 1534111115966 :: 1534121915966;  hhrole = anonyme;  r√©gions = 1;  tmr_detect = 0% 7C1534121918520;  total_searches = 3;  unique_banner_user = 1534121429.273825242076558 "" 1534122002.859 "" - "" 192.168.2.239:1500 "" [0.208] "{1534122002649b7eef2e901d8c9c0469} 200 https 1 -" - "- - [35927] [0.001 0] </blockquote><br>  Dans notre architecture, chaque service √©crit des journaux localement, puis via les journaux client-serveur auto-√©crits (y compris les journaux d'acc√®s nginx) sont collect√©s sur un r√©f√©rentiel central (ci-apr√®s la journalisation).  Les d√©veloppeurs ont acc√®s √† cette machine et peuvent enregistrer manuellement les journaux si n√©cessaire.  Mais comment, dans un d√©lai raisonnable, peut engloutir plusieurs centaines de gigaoctets de journaux?  Bien s√ªr, versez-les dans du hadoop! <br><br><h3>  D'o√π viennent les donn√©es dans hadoop? </h3><br>  Hadoop stocke non seulement les journaux de service, mais t√©l√©charge √©galement la base de donn√©es prod.  Chaque jour, dans hadoop, nous t√©l√©chargeons certaines des tables n√©cessaires √† l'analyse. <br><br>  Les journaux de service entrent dans hadoop de trois mani√®res. <br><br><ol><li>  <b>Chemin vers le front</b> - cron est lanc√© depuis le stockage des journaux la nuit et rsync t√©l√©charge les journaux bruts sur hdfs. </li><li>  <b>La mani√®re est √† la mode</b> - les journaux des services sont vers√©s non seulement dans le stockage commun, mais aussi dans kafka, o√π flume les lit, fait le pr√©traitement et les enregistre dans hdfs. </li><li>  <b>Le chemin est √† l'ancienne</b> - dans les jours qui ont pr√©c√©d√© kafka, nous avons √©crit notre propre service, qui lit les journaux bruts du stockage, les extrait du pr√©traitement et les t√©l√©charge sur hdfs. </li></ol><br>  Examinons chaque approche plus en d√©tail. <br><br><h4>  Chemin du front </h4><br>  Cron ex√©cute un script bash standard. <br><br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash LOGGING_DATE_PATH_PART=$(date -d yesterday +\%Y/\%m/\%d) HADOOP_DATE_PATH_PART=$(date -d yesterday +year=\%Y/month=\%m/day=\%d) ls /logging/java/${LOGGING_DATE_PATH_PART}/hh-banner-sync/banner-versions*.log | while read source_filename; do dest_filename=$(basename "$source_filename") /usr/bin/rsync --no-relative --no-implied-dirs --bwlimit=12288 ${source_filename} rsync://hadoop2.hhnet.ru/hdfs-raw/banner-versions/${HADOOP_DATE_PATH_PART}/${dest_filename}; done</span></span></code> </pre> <br>  Comme nous nous en souvenons, dans le r√©f√©rentiel de journaux, tous les journaux sont sous forme de fichiers ordinaires, la structure des dossiers est approximativement la suivante: /logging/java/2018/08/10/{service_nameasure/*.log <br><br>  Hadoop stocke ses fichiers dans approximativement la m√™me structure de dossiers hdfs-raw / banner-versions / year = 2018 / month = 08 / day = 10 <br>  ann√©e, mois, jour que nous utilisons comme partitions. <br><br>  Ainsi, il suffit de former les bons chemins (lignes 3-4), puis de s√©lectionner tous les journaux n√©cessaires (ligne 6) et d'utiliser rsync pour les remplir dans hadoop (ligne 8). <br><br>  <b>Les avantages de cette approche:</b> <br><br><ul><li>  D√©veloppement rapide </li><li>  Tout est transparent et clair. </li></ul><br>  <b>Inconv√©nients:</b> <br><br><ul><li>  Pas de pr√©traitement </li></ul><br><h4>  Mani√®re √† la mode </h4><br>  Puisque nous t√©l√©chargeons les journaux dans le r√©f√©rentiel avec un script auto-√©crit, il √©tait logique de visser la possibilit√© de les t√©l√©charger non seulement sur le serveur, mais aussi sur kafka. <br><br>  <b>Avantages</b> <br><br><ul><li>  Journaux en ligne (les journaux dans hadoop apparaissent lorsque vous remplissez kafka) </li><li>  Vous pouvez faire un pr√©traitement </li><li>  Il supporte bien la charge et vous pouvez t√©l√©charger de gros journaux </li></ul><br>  <b>Inconv√©nients</b> <br><br><ul><li>  Configuration plus difficile </li><li>  Je dois √©crire du code </li><li>  Plus de parties du processus de coul√©e </li><li>  Surveillance et analyse plus complexes des incidents </li></ul><br><h4>  Fa√ßon √† l'ancienne </h4><br>  Il ne diff√®re de la mode qu'en l'absence de kafka.  Par cons√©quent, il h√©rite de tous les inconv√©nients et seulement certains des avantages de l'approche pr√©c√©dente.  Un service distinct (ustats-uploader) en java lit p√©riodiquement les fichiers n√©cessaires, les pr√©traite et les t√©l√©charge sur hadoop. <br><br>  <b>Avantages</b> <br><br><ul><li>  Vous pouvez faire un pr√©traitement </li></ul><br>  <b>Inconv√©nients</b> <br><br><ul><li>  Configuration plus difficile </li><li>  Je dois √©crire du code </li></ul><br>  Et donc les donn√©es sont entr√©es dans hadoop et pr√™tes pour l'analyse.  Arr√™tons-nous un peu et rappelons-nous ce qu'est le hadoop et pourquoi des centaines de gigaoctets peuvent y √™tre consomm√©s beaucoup plus rapidement qu'un grep ordinaire. <br><br><h3>  Hadoop </h3><br>  Hadoop est un entrep√¥t de donn√©es distribu√©.  Les donn√©es ne se trouvent pas sur un serveur s√©par√©, mais sont r√©parties entre plusieurs machines et sont √©galement stock√©es non pas dans une seule instance, mais dans plusieurs - cela a √©t√© fait pour garantir la fiabilit√©.  La base de la vitesse de traitement des donn√©es r√©side dans un changement d'approche par rapport aux bases de donn√©es conventionnelles. <br><br>  Dans le cas d'une base de donn√©es r√©guli√®re, nous en extrayons les donn√©es et les envoyons au client, qui effectue une sorte d'analyse et renvoie le r√©sultat √† l'analyste.  Ainsi, pour compter plus rapidement, nous devons avoir de nombreux clients et parall√©liser les demandes (par exemple, pour diviser les donn√©es par mois - et chaque client peut lire les donn√©es de son mois). <br><br>  Dans hadoop, l'inverse est vrai.  Nous envoyons le code (exactement ce que nous voulons calculer) aux donn√©es, et ce code est ex√©cut√© sur le cluster.  Comme nous le savons, les donn√©es se trouvent sur de nombreuses machines, de sorte que chaque machine ex√©cute uniquement du code sur ses donn√©es et renvoie le r√©sultat au client. <br><br>  Beaucoup ont probablement entendu parler de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©duction</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">carte</a> , mais l'√©criture de code pour l'analyse n'est pas tr√®s pratique et rapide, tandis que l'√©criture en SQL est beaucoup plus simple.  Par cons√©quent, il est apparu des services qui peuvent transformer SQL en carte-r√©duire de mani√®re transparente pour l'utilisateur, et l'analyste peut ne pas soup√ßonner comment sa demande est r√©ellement consid√©r√©e. <br><br>  Dans hh.ru, nous utilisons pour cela ruche et presto.  Hive a √©t√© le premier, mais nous passons progressivement √† presto, car il est beaucoup plus rapide pour nos demandes.  En tant qu'interface graphique, nous utilisons hue et zeppelin. <br><br>  Il est plus pratique pour moi de consid√©rer les analyses en python dans jupyter, cela nous permet de le lire en un seul clic et d'obtenir des tableaux Excel correctement format√©s √† la sortie, ce qui fait gagner beaucoup de temps.  √âcrivez dans les commentaires, ce sujet fait l'objet d'un article s√©par√©. <br><br>  Revenons √† l'analyse elle-m√™me. <br><br><h2>  Comment comprendre ce que nous voulons consid√©rer? </h2><br><h3>  Le chef de produit est venu avec la t√¢che de calculer les r√©sultats de l'exp√©rience </h3><br>  Nous envoyons une newsletter par e-mail dans laquelle nous envoyons les offres d'emploi appropri√©es pour le candidat (tout le monde aime-t-il de tels mailings?).  Nous avons d√©cid√© de changer un peu la conception de la lettre et voulons savoir si elle s'est am√©lior√©e.  Pour cela nous consid√©rerons: <br><br><ul><li>  le nombre de transitions vers les postes vacants √† partir de la lettre; </li><li>  r√©troaction apr√®s la transition </li></ul><br>  Permettez-moi de vous rappeler que tout ce que nous avons, c'est un journal d'acc√®s et une base de donn√©es.  Nous devons formuler nos mesures en termes de clics sur les liens. <br><br><h4>  Nombre de transitions vers un poste vacant √† partir d'une lettre </h4><br>  La transition est une demande GET vers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hh.ru/vacancy/26646861</a> .  Pour comprendre d'o√π vient la transition, nous ajoutons des balises utm de la forme? Utm_source = email_campaign_123.  Pour les demandes GET dans le journal d'acc√®s, il y aura des informations sur les param√®tres, et nous ne pouvons filtrer les transitions qu'√† partir de notre liste de diffusion. <br><br><h4>  Le nombre de r√©ponses apr√®s la transition </h4><br>  Ici, nous pourrions simplement calculer le nombre de r√©ponses aux offres d'emploi √† partir de la newsletter, mais les statistiques seraient incorrectes, car les r√©ponses pourraient √™tre affect√©es par autre chose, √† l'exception de notre lettre, par exemple, une annonce dans ClickMe a √©t√© achet√©e pour une offre d'emploi, et donc le nombre de r√©ponses consid√©rablement grandi. <br><br>  Nous avons deux options pour formuler le nombre de r√©ponses: <br><br><ol><li>  La r√©ponse est un POST sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hh.ru/applicant/vacancy_response/popup?vacancy_id=26646861</a> , qui a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rent hh.ru/vacancy/26646861?utm_source=email_campaign_123</a> . </li><li>  La nuance de cette approche est que si l'utilisateur est pass√© √† un poste vacant, puis a fait un peu le tour du site et a ensuite r√©pondu √† un poste vacant, nous ne le comptons pas. </li><li>  Nous pouvons nous souvenir de l'ID de l'utilisateur qui est pass√© √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hh.ru/vacancy/26646861</a> et calculer le nombre d'avis pour le poste vacant pendant la journ√©e sur la base de la base de donn√©es. </li></ol><br>  Le choix de l'approche est d√©termin√© par les besoins de l'entreprise, g√©n√©ralement la premi√®re option est suffisante, mais tout d√©pend de ce que le chef de produit attend. <br><br><h2>  Pi√®ges pouvant survenir </h2><br><ol><li>  Toutes les donn√©es ne sont pas dans hadoop, vous devez ajouter des donn√©es de la base de donn√©es prod.  Par exemple, dans les journaux, g√©n√©ralement uniquement l'ID, et si vous avez besoin d'un nom - il se trouve dans la base de donn√©es.  Parfois, vous devez rechercher un utilisateur par resume_id, et cela est √©galement stock√© dans la base de donn√©es.  Pour ce faire, nous d√©chargeons une partie de la base de donn√©es dans hadoop afin que la jointure soit plus simple. </li><li>  Les donn√©es peuvent √™tre des courbes.  C'est g√©n√©ralement un d√©sastre pour hadoop et la fa√ßon dont nous y chargeons les donn√©es.  Selon les donn√©es, une valeur vide peut √™tre nulle, aucune, aucune, une cha√Æne vide, etc. Vous devez √™tre prudent dans chaque cas, car les donn√©es sont vraiment diff√©rentes, charg√©es de diff√©rentes mani√®res et √† diff√©rentes fins. </li><li>  Compte long pour toute la p√©riode.  Par exemple, nous devons calculer nos transitions et nos r√©ponses pour le mois.  Cela repr√©sente environ 3 t√©raoctets de journaux.  M√™me hadoop prendra cela pendant un certain temps.  Habituellement, √©crire une demande de travail √† 100% la premi√®re fois est assez difficile, nous l'√©crivons donc par essais et erreurs.  Chaque fois, attendre 20 minutes, c'est tr√®s long.  Fa√ßons de r√©soudre: <br><br><ul><li>  D√©bogage de la demande sur les journaux en 1 jour.  √âtant donn√© que nous avions partitionn√© les donn√©es dans hadoop, il est assez rapide de calculer quelque chose pour 1 jour de journaux. </li><li>  T√©l√©chargez les journaux n√©cessaires dans la table temporaire.  En r√®gle g√©n√©rale, nous comprenons les URL qui nous int√©ressent et nous pouvons cr√©er une table temporaire pour les journaux √† partir de ces URL. </li></ul><br>  Personnellement, la premi√®re option me convient mieux, mais, parfois, je dois faire une table temporaire, cela d√©pend de la situation. </li><li>  Distorsions dans les m√©triques finales <br><ul><li>  Il est pr√©f√©rable de filtrer les journaux.  Vous devez faire attention, par exemple, au code de r√©ponse, √† la redirection, etc. Mieux vaut moins de donn√©es, mais plus pr√©cises, dont vous √™tes s√ªr. </li><li>  Le moins d'√©tapes interm√©diaires possible dans la m√©trique.  Par exemple, le passage √† un poste vacant est une √©tape (demande GET pour / vacancy / 123).  La r√©ponse est deux (transition vers la vacance + POST).  Plus la cha√Æne est courte, moins il y a d'erreurs et plus pr√©cis√©ment la m√©trique.  Parfois, il arrive que les donn√©es entre les transitions soient perdues et il est g√©n√©ralement impossible de calculer quelque chose.  Pour r√©soudre ce probl√®me, nous devons r√©fl√©chir √† ce que nous allons consid√©rer et comment avant de d√©velopper une exp√©rience.  Votre journal s√©par√© des √©v√©nements n√©cessaires aide beaucoup.  Nous pouvons filmer les √©v√©nements n√©cessaires, et ainsi la cha√Æne d'√©v√©nements sera plus pr√©cise, et le comptage est plus facile. </li><li>  Les bots peuvent g√©n√©rer un tas de transitions.  Vous devez comprendre o√π les bots peuvent aller (par exemple, sur les pages o√π l'autorisation est requise, ils ne devraient pas l'√™tre) et filtrer ces donn√©es. </li><li>  Grosses bosses - par exemple, dans l'un des groupes, il peut y avoir un candidat, ce qui g√©n√®re 50% de toutes les r√©ponses.  Il y aura une asym√©trie des statistiques, ces donn√©es doivent √©galement √™tre filtr√©es. </li></ul></li><li>  Il est difficile de formuler ce qu'il faut consid√©rer en termes de journal d'acc√®s.  Cela permet de conna√Ætre la base de code, l'exp√©rience et les outils de d√©veloppement Chrome.  Nous lisons la description de la m√©trique du produit, la r√©p√©tons avec nos mains sur le site et voyons quelles transitions sont g√©n√©r√©es. </li></ol><br>  Enfin, parlons de l'apparence du r√©sultat des calculs. <br><br><h2>  R√©sultat du calcul </h2><br>  Dans notre exemple, il existe 2 groupes et 2 mesures qui forment un entonnoir. <br><img src="https://habrastorage.org/webt/mn/fx/cm/mnfxcmiwrbhfvxnqomoy_v_zztw.png" alt="image"><br>  Recommandations pour la communication des r√©sultats: <br><br><ol><li>  Ne surchargez pas les pi√®ces jusqu'√† ce que vous en ayez besoin.  Simple et plus petit, c'est mieux (par exemple, ici, nous pourrions afficher chaque poste vacant s√©par√©ment ou les clics par jour).  Concentrez-vous sur une chose. </li><li>  Des d√©tails peuvent √™tre n√©cessaires lors des r√©sultats de la d√©monstration, alors r√©fl√©chissez aux questions que vous pourriez poser et pr√©parez les d√©tails.  (Dans notre exemple, le d√©tail peut √™tre fonction de la vitesse de transition apr√®s l'envoi de l'e-mail - 1 jour, 3 jours, une semaine, regroupement des postes vacants par domaine professionnel) </li><li>  N'oubliez pas la signification statistique.  Par exemple, une variation de 1% avec 100 clics et 15 clics est insignifiante et pourrait √™tre al√©atoire.  Utilisez des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">calculatrices</a> </li><li>  Automatisez autant que possible, car vous devrez compter plusieurs fois.  Habituellement, au milieu d'une exp√©rience, on veut d√©j√† comprendre comment les choses se passent.  Apr√®s l'exp√©rience, des questions peuvent se poser et vous devrez clarifier quelque chose.  Ainsi, il faudra compter 3-4 fois, et si chaque calcul est une s√©quence de 10 requ√™tes puis une copie manuelle pour exceller, cela fera mal et passera beaucoup de temps.  Apprenez le python, cela vous fera gagner une tonne de temps. </li><li>  Utilisez une repr√©sentation graphique des r√©sultats lorsque cela est justifi√©.  Les outils int√©gr√©s de ruche et de zeppelin vous permettent de cr√©er des graphiques simples hors de la bo√Æte. </li></ol><br>  Il est n√©cessaire de consid√©rer assez souvent diverses mesures, car nous √©mettons presque toutes les t√¢ches dans le cadre d'une exp√©rience A / B.  Il n'y a rien de compliqu√© dans les calculs, apr√®s 2-3 exp√©riences, une compr√©hension vient de la fa√ßon de proc√©der.  N'oubliez pas que les journaux d'acc√®s stockent de nombreuses informations utiles qui peuvent faire √©conomiser de l'argent aux entreprises, vous aider √† promouvoir votre id√©e et prouver laquelle des options de changement est la meilleure.  L'essentiel est de pouvoir obtenir ces informations. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424251/">https://habr.com/ru/post/fr424251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424241/index.html">Imprimez votre monde</a></li>
<li><a href="../fr424243/index.html">5 fa√ßons simples d'am√©liorer la communication avec les clients</a></li>
<li><a href="../fr424245/index.html">√âcrire un client Telegram est facile</a></li>
<li><a href="../fr424247/index.html">KotlinConf 2018 Live - regardez l'√©mission du 4 au 5 octobre</a></li>
<li><a href="../fr424249/index.html">Mat√©riel de la r√©union #RuPostgres - vid√©os, pr√©sentations, analyse du quiz et reportage photo</a></li>
<li><a href="../fr424255/index.html">Comment utiliser correctement l'analyse statique</a></li>
<li><a href="../fr424257/index.html">Cartes hexagonales dans Unity: parties 1 √† 3</a></li>
<li><a href="../fr424259/index.html">Security Week 36: Telnet devrait √™tre ferm√©</a></li>
<li><a href="../fr424261/index.html">Comment r√©soudre tout probl√®me de programmation</a></li>
<li><a href="../fr424263/index.html">Mise √† niveau d'IDA Pro. Nous r√©parons les jambages des modules processeurs</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
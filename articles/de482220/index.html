<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüåæ ‚öñÔ∏è üÜì Lokalisierung von Aruco-Markern üåñ ü§æüèø ü§òüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im letzten Beitrag haben wir dar√ºber gesprochen, wie man von Punkt A nach Punkt B kommt, ohne etwas zu treffen. Aber um etwas zu umgehen, muss man ver...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lokalisierung von Aruco-Markern</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482220/">  <a href="https://habr.com/ru/post/479636/">Im letzten Beitrag haben</a> wir dar√ºber gesprochen, wie man von Punkt A nach Punkt B kommt, ohne etwas zu treffen.  Aber um etwas zu umgehen, muss man verstehen, wo wir sind und wo es dynamische Hindernisse gibt (unsere Gegner und nicht nur). <br><br>  Ein Mensch hat Augen, Ohren und Software, die von der Natur und seiner pers√∂nlichen Erfahrung festgelegt wurden, damit er sich leicht im Raum bewegen und navigieren kann.  Das Lokalisierungssystem ist fast das Auge und das Ohr f√ºr Roboter.  Es wird ben√∂tigt, damit der Roboter im Weltraum navigieren und sich an die Umgebung anpassen kann. <br><br>  Heute werden wir dar√ºber sprechen, wie wir das Problem der Positionsbestimmung von Robotern auf dem Eurobot-Feld gel√∂st haben, wie wir all dies tun, starten und selbst konfigurieren k√∂nnen. <br><br><img src="https://habrastorage.org/webt/wd/ob/7l/wdob7lxsj1x5z0ubs94tyz5hf08.png"><br><a name="habracut"></a><br><h2>  Zielbedingungen des Lokalisierungssystems </h2><br>  Eines der Prinzipien von Eurobot Open ist die Autonomie.  Autonomie von allem, was sich hinter dem Spielfeld befindet.  Alle Berechnungen, Entscheidungen und Lokalisierungen sollten entweder an Robotern oder an speziellen Standorten auf dem Feld vorgenommen werden. <br><br>  Die Gr√∂√üe des Feldes betr√§gt 2 x 3 Meter, und der Fehler in der Gr√∂√üe und Position der darauf befindlichen Elemente von Feld zu Feld liegt normalerweise innerhalb von 3 bis 5 mm. <br><br>  Das Bild unten zeigt ein Diagramm des Eurobot 2019-Feldes mit markierten Bereichen, auf denen wir etwas anderes als Roboter platzieren k√∂nnen. <br><br><img src="https://habrastorage.org/webt/ed/sn/nr/edsnnr36r2ksmv9sr7pzjz1khhk.png"><br><br><ul><li>  6 - Experiment Zone (eine der zus√§tzlichen Aufgaben) </li><li>  10 - Leuchtturmzonen </li><li>  11 - Ein spezieller Turm zur Installation eines zentralen Ortungsger√§ts (im Folgenden als CCC bezeichnet).  Befindet sich √ºber dem Feld in einer H√∂he von 1 Meter </li><li>  Auch auf den Robotern selbst k√∂nnen Beacons installiert werden. </li></ul><br>  F√ºr all diese Bereiche und die Abmessungen der Roboter selbst gelten strenge Gewichts- und Gr√∂√üenbeschr√§nkungen, weshalb es unm√∂glich ist, ein gro√ües produktives Supermodul herzustellen, in das alles passt.  Die Vorbereitungen f√ºr den Start sind auf 3 Minuten begrenzt.  W√§hrend dieser Zeit m√ºssen ein oder zwei Personen aus dem Team die Roboter und alles, was damit zusammenh√§ngt, herausnehmen, arrangieren, konfigurieren und f√ºr den Start vorbereiten.  Je weniger Junk Sie einstellen und einstellen m√ºssen, desto unwahrscheinlicher ist es, dass Sie vor Beginn des Kampfes einen Fehler machen oder eine Geldstrafe erhalten. <br><br><img src="https://habrastorage.org/webt/73/ic/e7/73ice79-lmosmu6rt-gi5gdz744.jpeg"><br>  <i>und noch eine zweite solche volle Kiste</i> <br><br><h3>  Wir analysieren Optionen </h3><br>  Mit dem Bewusstsein unserer F√§higkeiten und dem Wunsch, eine Positionierungsgenauigkeit von mindestens einigen Millimetern zu erreichen, wollen wir uns ansehen, wie wir dieses Problem im Allgemeinen l√∂sen k√∂nnen: <br><br><ul><li>  <b>Die Rad-</b> Kilometerz√§hler-Messung mit direkt am Antrieb angebrachten Encodern oder zus√§tzlichen Messr√§dern erm√∂glicht es Ihnen, die vom Roboter zur√ºckgelegte Strecke abzulesen und deren Position relativ zum Startpunkt zu bestimmen.  Viele Eurobot-Teams verwenden es als prim√§re Lokalisierungsmethode.  Dies ist eine der schnellsten Quellen f√ºr Bewegungsinformationen f√ºr den Roboter.  In der Praxis besteht jedoch insbesondere beim Fahren auf Omni-R√§dern (eine kleinere Aufstandsfl√§che als bei klassischen R√§dern, Rollenspiel und gr√∂√üere Herstellungsfehler) die Gefahr, dass die Kilometerz√§hler das Problem der kumulativen Fehler aufweisen, die irgendwie korrigiert werden m√ºssen.  Sie k√∂nnen mit bekannten Koordinaten an der Oberfl√§che ausrichten oder mit einem zus√§tzlichen System komplexieren.  Wenn Sie Encoder an den Antriebsr√§dern verwenden, besteht das Problem des Durchrutschens der R√§der bei scharfen Man√∂vern und bei Kollisionen des Roboters.  Messr√§der k√∂nnen dieses Problem l√∂sen, sind aber in einem kleinen Roboter schwer zu platzieren. <br><br><img src="https://habrastorage.org/webt/v0/8u/bd/v08ubdzodh5zpr8kr7ee3fhbo5y.png"><br>  <i>Selbstgebautes Omni-Messrad mit Einzelradaufh√§ngung und magnetischem Encoder, das wir 2018 verwendet haben</i> <br></li><li>  <b>Lidare</b> haben erhebliche Vorteile: Wir erhalten eine fast kreisf√∂rmige Sicht und Abst√§nde zu Hindernissen.  Unter den Minuspunkten sind der hohe Preis, die Schwierigkeit, kleine entfernte Objekte vom M√ºll zu unterscheiden, und ein relativ komplizierter Lokalisierungsalgorithmus hervorzuheben.  Preiswerte Lidars (wie Rplidar) haben eine relativ niedrige Bildwiederholfrequenz und Winkelaufl√∂sung und werden auch von anderen Lidars, Entfernungsmessern usw. beleuchtet. Bei Robotern ist es schwierig, auf der Seitenebene einen Lidar zu finden, um die klassischen SLAM-Algorithmen zu verwenden, jedoch mit den bereitgestellten H√∂henregeln f√ºr Lokalisierungssysteme haben nur wenige statische Objekte zum Binden.  Das Skoltech-Team ist jedoch seit mehreren Jahren erfolgreich mit dem Hokuyo ust-10lx unterwegs und belegte im vergangenen Jahr den zweiten Platz im europ√§ischen Finale des Eurobot-Wettbewerbs in Frankreich. </li><li>  Wir haben auch <b>Tr√§gheitssysteme in</b> Betracht gezogen, aber in unserem Fall passten sie nicht gut zusammen.  Der Beschleunigungsmesser ist laut, das Gyroskop schwebt, Sie k√∂nnen den Kompass in Innenr√§umen vergessen.  Selbst die Verwendung eines Kalman-Filters erreicht nicht die gew√ºnschte Genauigkeit.  Es stellt sich heraus, dass die IMU nur in sehr kurzer Zeit effektiv zur Korrektur eingesetzt werden kann.  Das Maximum an n√ºtzlichen Informationen, die wir mit pixhawk2 erhalten konnten, ist der Winkel w√§hrend einer scharfen Kurve (z. B. bei einer Kollision). </li><li>  <b>GPS</b> funktioniert in Innenr√§umen nicht und die Genauigkeit ohne RTK betr√§gt Meter. </li><li>  <b>Ultraschallortung</b> .  Eine der Implementierungen finden Sie hier: <a href="https://m.habr.com/ru/post/451408/">m.habr.com/de/post/451408</a> .  Leider ist die Genauigkeit f√ºr unsere Aufgaben nicht sehr hoch (+ -2cm), das √úbersprechen wirkt sich stark aus, oder wenn Sie Sensoren mit diesem Schutz verwenden, wird eine niedrige Abfragefrequenz erzielt.  Eines der russischen Teams setzt diese L√∂sung mit unterschiedlichem Erfolg ein, und das deutsche Turag-Team setzt recht erfolgreich auf eine √§hnliche Technologie, die im Labor entwickelt wurde. </li><li>  <b>Die visuelle Odometrie</b> gibt keine Auskunft √ºber die Position der Gegner, da es nicht sehr viele Punkte auf dem Spielfeld gibt, an denen man sich zuverl√§ssig festhalten kann. </li><li>  <b>\ Tof Stereokameras</b> haben einen engen Winkel, der es nicht erlaubt, das Feld abzudecken, wenn sie sich auf dem zentralen Verfolgungsger√§t befinden, oder eine kreisf√∂rmige oder zumindest akzeptable Sicht zu erhalten, wenn sie auf einem Roboter installiert sind. </li><li>  <b>Die Treuhandmarkierungen</b> , die wir ausgew√§hlt haben und die wir genauer untersuchen werden. </li></ul><br><h3>  Treuhandmarkierungen </h3><br>  Die Markernavigation gibt es schon lange.  Rein theoretisch kann der sogenannte Marker ein beliebiges Objekt sein.  Bei der Verwendung treten jedoch viele Probleme auf: <br><br><ul><li>  Einschr√§nkungen aufgrund der Kameraaufl√∂sung; </li><li>  Unzuverl√§ssigkeit der Erkennung bei Verwendung von Farbe als Hauptinformationsquelle; </li><li>  die Notwendigkeit, die Ausrichtung des Markers zu bestimmen; </li><li>  kontrastarme Markierungen funktionieren nur bei gutem Licht gut; </li><li>  Hohe Rechenleistung des Equipments ist erforderlich (Echtzeitverarbeitung eingehender Frames). </li></ul><br>  Um die oben genannten Probleme zu umgehen, m√ºssen Sie f√ºr die Erkennung normalerweise etwas Einfaches und Eindeutiges verwenden, z. B. einen farbigen Kreis oder ein Quadrat (und ich h√§tte gerne eine gelbe Ente). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/636/59e/f61/63659ef613cf69454b7b3b9d788d934e.png" alt="Bild"><br>  <i>verschiedene Arten von Markern</i> <br><br>  Tats√§chlich besteht h√§ufig zus√§tzlich zur Bestimmung der Position eines Markers die Notwendigkeit, seine Eindeutigkeit zu bestimmen, um beispielsweise mehrere Objekte gleichzeitig zu erfassen.  Um dies zu tun, k√∂nnen Sie die Farbe oder Form √§ndern, aber dann werden wir schnell feststellen, dass die Zuverl√§ssigkeit der Erkennung abnimmt. <br>  Dieses Problem ist weit verbreitet und es gibt viele Markierungsstandards.  Der bekannteste von ihnen ist qr-Code, der jedoch aufgrund von Redundanz und der Notwendigkeit einer hohen Aufl√∂sung nur selten bei Lokalisierungsproblemen eingesetzt wird.  In der Regel sind alle Marker zweifarbig (meistens s / w), haben eine einfache Form (meistens ein Quadrat) und kodieren den Bezeichner irgendwie in sich.  Die bekanntesten Marker f√ºr die Lokalisierung sind Aruco, April Tag, ARToolKit. <br><br>  Jeder, der mehr √ºber sie erfahren m√∂chte, ist ein interessanter <a href="https://www.researchgate.net/publication/303752217_An_evaluation_of_artificial_fiducial_markers_in_underwater_environments">Artikel</a> , der auch die Zuverl√§ssigkeit ihrer Erkennung vergleicht. <br><br><div class="spoiler">  <b class="spoiler_title">Fraktale Markierungen</b> <div class="spoiler_text">  Es gibt Zeiten, in denen wir ein Objekt sowohl aus der Ferne als auch direkt erkennen m√ºssen.  Die Verwendung mehrerer Marker unterschiedlicher Gr√∂√üe ist eine M√∂glichkeit, aber Sie k√∂nnen es schlauer machen und ‚Äûfraktale‚Äú Marker verwenden, von denen verschiedene Teile in verschiedenen Ma√üst√§ben des Bildes funktionieren. <br><br>  <a href="https://docs.google.com/document/u/1/d/1SdsOTjGdu5o8gy2Ot2FDqYDS9ALgyhOBJcJHOZBR7B4/mobilebasic">docs.google.com/document/u/1/d/1SdsOTjGdu5o8gy2Ot2FDqYDS9ALgyhOBJcJHOZBR7B4/mobilebasic</a> <br></div></div><br>  In unserem Fall haben wir viele positive Aspekte bei der Verwendung von Markern: <br><br><ul><li>  Mit der M√∂glichkeit, eine statische Kamera mit einem guten Betrachtungswinkel und einer guten Markierung zu installieren, ist keine schwer zu findende Ausr√ºstung erforderlich und m√∂glicherweise nicht sehr schwierig zu implementieren. </li><li>  Die entfernte Kamera kann die Position aller Objekte auswerten, auf die wir Marker setzen k√∂nnen. </li><li>  Die Berechnungen werden nicht auf dem Bordger√§t des Roboters, sondern auf einem separaten Computer durchgef√ºhrt (es besteht jedoch ein Problem mit der Zuverl√§ssigkeit und Verz√∂gerungen bei der Daten√ºbertragung). </li><li>  die F√§higkeit, jedes andere mit dem Sehen verbundene Problem zu l√∂sen. </li></ul><br>  Nach der Analyse der oben genannten Systeme haben wir uns auf den Nachweis von Markern festgelegt.  Dies erm√∂glichte es uns nicht nur, unsere Odroids von Robotern zu befreien, sondern ihnen auch, die gesamte Situation auf dem Feld aus der Vogelperspektive zu betrachten. <br><br><h3>  Wie funktioniert das? </h3><br>  Die ‚ÄûZuverl√§ssigkeit‚Äú der Markererkennung ist ein relativer Begriff.  Unterschiedliche Aufgaben erfordern ein unterschiedliches Ma√ü an Genauigkeit und Stabilit√§t.  Die Angabe dieser Parameter h√§ngt vom Videosensor, den Objektiven, den Lichtverh√§ltnissen usw. ab. <br><br><img src="https://habrastorage.org/webt/yi/xs/5m/yixs5m5g6pv5xya8axbd-zqov-4.png"><br>  In unserem Fall ist es bei einer Feldgr√∂√üe von 2x3 Metern und einer Kamera nur einen Meter dar√ºber erforderlich, eine Ultraweitwinkeloptik mit einem Sichtfeld von mindestens 120-140 Grad zu verwenden, um die Sichtbarkeit des gesamten Spielraums zu gew√§hrleisten, was sich negativ auf die Erkennung (und Genauigkeit) kleiner Marker in der Ferne auswirkt Ecke des Spielfeldes und unter beliebigen Lichtverh√§ltnissen machen diese Aufgabe noch schwieriger. <br>  Wie die Praxis gezeigt hat, k√∂nnen selbst unter normalen, v√∂llig nat√ºrlichen Beleuchtungsbedingungen fehlerhafte Definitionen der Markierungsposition auftreten. <br><br><img src="https://habrastorage.org/webt/km/-n/cl/km-nclpq-m4g3jcgvwxls4eixb0.png"><br><br>  Die folgenden Bilder zeigen also zwei aufeinanderfolgende Bilder mit Markierungserkennungsergebnissen: Die Richtung der Z-Achse (blau) wird um 180 Grad ge√§ndert. <br><br><img src="https://habrastorage.org/webt/sd/a5/ha/sda5haouwemxqiobswwckpb8dhw.png"><br><br><img src="https://habrastorage.org/webt/tu/gj/ii/tugjiiiol9ts2m4laiexh7nwnue.png"><br>  <i><a href="https://www.youtube.com/watch%3Fv%3DxzG2jQfxLlY">www.youtube.com/watch?v=xzG2jQfxLlY</a></i> <br><br><h3>  In einen wettbewerbsf√§higen Zustand bringen </h3><br><h4>  √Ñndern Sie den Algorithmus </h4><br>  Um die Position des Roboters auf dem Feld genau zu bestimmen, m√ºssen Sie die Winkelposition der Kamera, die allgemeine Transformation des Koordinatensystems und die Position der Kamera relativ zur Position des Feldes kennen.  F√ºr diese Konvertierung haben wir einen eigenen Algorithmus entwickelt.  Da eine Person das zentrale Kontrollzentrum manuell aufh√§ngt und die Felder leicht voneinander abweichen, ist es nicht m√∂glich, immer dieselbe Kameraposition zu erhalten.  Die Winkelverschiebung der Kamera relativ zum Feld wirkt sich sehr negativ auf die Positionserkennung der Roboter aus.  Die grundlegende L√∂sung besteht darin, mehrere statische Marker zu bestimmen, die wir vor dem Match f√ºr die Kalibrierung setzen k√∂nnen. <br><br>  Die Aruco-Bibliothek in opencv bietet die M√∂glichkeit, die 6dof-Markierungsposition relativ zur Kamera zu bestimmen.  Zuerst haben wir versucht, es zu verwenden, aber es stellte sich als sehr instabil und ungenau heraus.  In unserem Fall, wenn die Position der Kamera bekannt ist, sie fest ist und sich Roboter (und zugeh√∂rige Markierungen) auf einer Ebene bewegen, die nicht durch den Befestigungspunkt der Kamera verl√§uft, ist es sinnvoll, uns auf die Aufgabe zu beschr√§nken, die 3D-Position zu ermitteln (z-const, x-y, + Drehung um eine Achse z) durch die Triangulation eines Punktes in einer Ebene unter einem sichtbaren Winkel. <br><br>  Es wird erwartet, dass eine Verringerung der Abmessung und eine Vergr√∂√üerung der Basis der Triangulation (die Gr√∂√üe des Markers im Verh√§ltnis zum Abstand von der Ebene der Marker zur Kamera) des gel√∂sten Problems den Grad der Unsicherheit und des Rauschens der Erfassungsergebnisse verringert. <br>  Dazu anstelle der Standardfunktion <br><br><pre><code class="cpp hljs">cv::aruco::estimatePoseSingleMarkers(markerCorners, <span class="hljs-number"><span class="hljs-number">0.05</span></span>, cameraMatrix, distCoeffs, rvecs, tvecs);</code> </pre> <br><br>  Um anhand der gefundenen Ecken der Marker die 6dof-Position des Markers zu bestimmen, haben wir unseren Positionssch√§tzer nach folgenden Grunds√§tzen geschrieben: <br><br><ul><li>  Die Position der 3D-Kamera ist im Voraus bekannt. </li><li>  Markerh√∂he ist im Voraus bekannt; </li><li>  als Ergebnis der Erfassung sind Pixel (v, u) von 4 Markierecken bekannt; </li><li>  Als Ergebnis der Kamerakalibrierung wird eine 4x4-Kameramatrix definiert. </li><li>  Wenn Sie die 'Kameramatrix', die Position und Ausrichtung der Kamera und die Position der Pixelwinkel des Markers kennen, k√∂nnen Sie die Projektion der Position der Winkel im 3D-Raum auf der z-Ebene abrufen, auf der sich die Scheitelpunkte des Markers befinden (die H√∂he des Markers wird durch seine Nummer bestimmt). </li><li>  Durch Ausf√ºhren des vorherigen Schritts f√ºr alle 4 Markierungsecken und Mitteln der erhaltenen Daten ist es m√∂glich, 3D-Koordinaten der Markierungsscheitelpunkte im Kamerakoordinatensystem zu erhalten. </li><li>  Bei Anwendung der Transformation von der SK-Kamera auf die SK des Spielfelds werden die Koordinaten des Markers im SK-Feld erhalten. </li></ul><br><h4>  L√∂sen von Beleuchtungs- und Leistungsproblemen </h4><br>  Die Stabilit√§t und Geschwindigkeit der Erkennung von Markern h√§ngt stark von den Umgebungslichtbedingungen und der Hintergrundstruktur ab. Je mehr verschiedene Objekte sich im Rahmen befinden, desto l√§nger dauert die Verarbeitung.  Da die Regeln f√ºr die Eurobot-Beleuchtung und den Hintergrund in keiner Weise geregelt sind, k√∂nnen sie sich von Zeit zu Zeit stark √§ndern. Es kann auch andere Bereiche geben, Personen im Hintergrund.  Insbesondere sind zus√§tzliche Belichtungen durch feindliche Roboter, Kamerablitze oder Scheinwerfer zu erwarten, die in das Sichtfeld der Kamera fallen. <br><br>  Um den Einfluss der Umgebungsbeleuchtung auf die Erkennungsstabilit√§t von Markern zu verringern, wurde ein spezielles ‚ÄûDesign‚Äú entwickelt, bei dem invertierte Aruco-Marker verwendet wurden.  Der dunkle Teil wird durch eine retroreflektierende Folie ersetzt, und eine aktive LED-Hintergrundbeleuchtung ist direkt auf der Kamera installiert.  Die Bildverarbeitung erfolgt im Negativ, w√§hrend der Kontrast des Hintergrunds viel geringer ist als der Kontrast der eigenen Marker. <br><br>  Durch Erh√∂hen des Kontrasts des Markers k√∂nnen Sie Bereiche von Interesse auf dem Frame effektiv ausw√§hlen und nur in diesen nach Markern suchen, nicht im gesamten Frame, wodurch die Produktivit√§t erheblich verbessert wird. <br><br><img src="https://habrastorage.org/webt/fz/p0/4n/fzp04n01ugkpz4b8yuqrasmv2qy.png"><br>  <i>Vergleich der Kontrastunterschiede zwischen einem Standardmarker und einem Marker mit reflektierender Oberfl√§che</i> <br><br><h3>  Wir w√§hlen Eisen </h3><br>  Da die Lichtverh√§ltnisse nicht definiert sind und die Geschwindigkeit der Roboter sehr hoch sein kann, haben wir von Anfang an nach einer Kamera mit Global Shutter und nicht mit Rolling Shutter gesucht.  Der Unterschied besteht darin, dass der Globale gleichzeitig Informationen √ºber die Helligkeit der Pixel sammelt und zeilenweise rollt, wodurch es zu Verzerrungen in der geometrischen Form sich bewegender Objekte kommen kann. <br>  Die g√ºnstigste Kamera ist oCam-1mgn, die wir 2 Jahre lang benutzt haben.  Es ist jedoch schwarzwei√ü und hat eine Aufl√∂sung von nur 1 Mpx, was sich am unteren Rand einer akzeptablen Aufl√∂sung befindet (die Anzahl der Bildpixel pro 1 "Pixel" des Markers). <br>  Urspr√ºnglich befand sich der Detektor auf derselben Platine wie die Roboter selbst - odroid xu4, und die Arbeitsgeschwindigkeit betrug etwa 20 fps. Der Wunsch, zus√§tzliche Funktionen in die zentrale Leitstelle zu integrieren und zu verstehen, dass eine bessere Kamera erforderlich war, f√ºhrte dazu, dass der PC durch einen leistungsf√§higeren Intel ersetzt wurde Nuc, und die Kamera ... die Kamera, die wir f√ºr die neue Saison noch aufheben. <br><br><h3>  Wir starten das Projekt </h3><br>  Es wird weiterhin davon ausgegangen, dass Sie ROS Kinetic oder Melodic bereits konfiguriert haben. <br><br>  Als erstes m√ºssen Sie OpenCV 3, Eigen3 und das Projekt <a href="https://bitbucket.org/eurobot1718/ocam_usb_cam">https://bitbucket.org/eurobot1718/ocam_usb_cam</a> herunterladen und installieren (f√ºr die Ocam-Kamera) oder ein anderes Projekt verwenden, dessen Struktur der Ver√∂ffentlichung von Daten in Themen √§hnelt. <br><br>  Wir klonen das Repository mit dem Arude-Detektor-Projekt: <a href="https://gitlab.com/eurobot2019/aruco_detector">https://gitlab.com/eurobot2019/aruco_detector</a> und gui daf√ºr <a href="https://github.com/alexpostnikov/aruco-gui">https://github.com/alexpostnikov/aruco-gui</a> <br>  Nach der Installation der Projekte m√ºssen Sie die Kamera kalibrieren, die Dispersionsmatrix und die Kamera-Verzerrungsmatrix abrufen und dann alles in die yaml-Datei ‚Äûcamera_params.yml‚Äú packen.  Ein einfaches Beispiel ist die Verwendung eines Schachbretts.  <a href="https://github.com/sourishg/fisheye-stereo-calibration">Link</a> zur Implementierung in C ++, in der Sie lediglich die Parameter der Karte und der Kamera sowie den Namen der Ausgabedatei erfassen und angeben m√ºssen. <br><br>  Die wichtigsten Einstellungen befinden sich in der Datei aruco_detector_params.yml: <br><br><ul><li>  <b>len_of_cube_markers</b> und <b>width_marker die</b> L√§nge und Breite der Marker in Metern; </li><li>  <b>marker_height</b> - Vergleich des Markers und seiner H√∂he; </li><li>  <b>Marker</b> - Ein Array, das beschreibt, ob ein bestimmter Marker zu einem bestimmten Roboter geh√∂rt.  Es zeigt die Marker im Uhrzeigersinn an.  Und bei Gegnern spielt die Reihenfolge der Marker in config ebenfalls keine Rolle, da ihre Richtung f√ºr uns nicht wichtig ist.  Sie m√ºssen nur den Markierungscode angeben.  Wir haben auch Markierungen auf der oberen Abdeckung, deren Nummern sind separat hervorgehoben; </li><li>  <b>static_markers_ids</b> - Marker, die w√§hrend des Kalibrierungsprozesses gesucht werden; </li><li>  <b>marker_position</b> - ein W√∂rterbuch mit dem Versatz und der Drehung jedes Markers relativ zur Mitte des Roboters; </li><li>  <b>Helligkeit_Schwelle</b> kann nicht ber√ºhrt werden - dies wird f√ºr die anf√§ngliche automatische Kalibrierung des Lichts verwendet; </li><li>  <b>camera_position_yellow</b> und ein √§hnlicher Parameter dienen als Standardeinstellungen f√ºr den Fall, dass die Kalibrierung fehlschl√§gt. </li></ul><br>  Die Transformationsmatrix vom Kamerakoordinatensystem zum Feldkoordinatensystem befindet sich in der Datei transform_from_cam_to_map.xml <br><br>  Nach all den Einstellungen m√ºssen Sie es endlich ausf√ºhren.  Die Pfade zu der Datei mit den Parametern, der Standardseite und dem Pfad zum Videoger√§t werden in der Datei aruco_detector_debug.launch festgelegt, die wir starten werden.  F√ºr einen vollst√§ndigen Start ist es jedoch besser, das Bash-Skript aruco.bash zu verwenden, das zus√§tzlich zum Detektor gui (127.0.0.1‚ñ∫000) startet.  Hier k√∂nnen wir die Seite ausw√§hlen, die Kalibrierung starten und das System steuern.  Im zweiten Fenster werden interessierende Bereiche und gefundene Markierungen angezeigt. <br><br><img src="https://habrastorage.org/webt/qe/ch/qf/qechqfeowcgq9xevhj8fplpmjqc.gif"><br><br>  Nun wird in den Themen "/ enemy_robot1 / aruco", "/ enemy_robot2 / aruco", "/ big_robot / aruco", "/ small_robot / aruco" die Position der gefundenen Roboter ver√∂ffentlicht. <br><br>  Hurra!  Wir konnten die Koordinaten der Roboter ermitteln.  Das ist nur so, wie Sie sehen k√∂nnen, sie sind falsch.  Dies liegt daran, dass vor der Verwendung die Position der Kamera relativ zum Feld kalibriert werden muss.  Daf√ºr ist es notwendig <br><br><ul><li>  Setze die W√ºrfel in die Ecken des Feldes, w√§hrend es wichtig ist, dass sie von den Seiten gedreht werden, die in der Konfiguration angegeben sind </li><li>  Stellen Sie die Neigung der Kamera so ein, dass der gesamte erforderliche Raum in den Rahmen f√§llt </li><li>  Passen Sie die Helligkeit der Hintergrundbeleuchtung an, bis die Marker zuverl√§ssig erkannt werden </li><li>  W√§hlen Sie in GUI die gew√ºnschte Seite aus und klicken Sie auf "Kalibrieren". </li><li>  dann sollte sich der Status von "Suche statische W√ºrfel" zu "Suche W√ºrfel" √§ndern </li></ul><br><h2>  Wir machen Marker und TsUS </h2><br>  Gem√§√ü den Regeln k√∂nnen wir unsere Roboter nach Belieben einf√§rben und zus√§tzlich einen speziellen Platz auf den Robotern unserer und anderer Leute verwenden, auf dem Sie etwas bis zu einer Gr√∂√üe von 10 x 10 x 8 cm platzieren k√∂nnen.  Ein spezieller Platz befindet sich auf der Abdeckung des Roboters, hat eine feste H√∂he und eine bessere Sichtbarkeit f√ºr die zentrale Leitstelle, au√üer wenn sich der Roboter unter der Kamera befindet. <br><br><img src="https://habrastorage.org/webt/mm/_a/zu/mm_azulfvnfcqxm869zluovaq9e.png"><br>  <i>H√∂he und Abmessungen der Leuchtt√ºrme am Roboter</i> <br><br>  Daher verwenden wir als Hauptmarker f√ºr unsere Roboter 10 x 10 x 108 cm gro√üe Parallelepipede, die auf 4 Seiten von Aruco aufgeklebt sind, sowie zus√§tzliche Markierer auf der Oberseite unserer Roboter zur Lokalisierung in einem komplexen Bereich unter der Kamera. <br><br>  Da wir nichts auf den feindlichen Deckel kleben k√∂nnen, haben wir beschlossen, Markierungen in Form eines Pyramidenstumpfes anzubringen, um den Sichtbereich zu vergr√∂√üern.  Und wie Sie sehen, ist der Marker viel besser sichtbar geworden. <br><br><img src="https://habrastorage.org/webt/9_/xo/re/9_xoreh7phv_pp5ci_u7utyw5cm.png"><br><br>  Wir drucken die Basis f√ºr den W√ºrfel \ Pyramide auf einem 3D-Drucker, damit er stark genug ist und eine bequeme und zuverl√§ssige Halterung hat. <br><br><img src="https://habrastorage.org/webt/r9/-l/ek/r9-lekwcd5xkzs_lys0hkrkjw4m.png"><br><br>  Hier befinden sich Modelle zum Bedrucken eines W√ºrfels, einer Pyramide und einer Gegenhalterung <a href="https://yadi.sk/d/swUJUwxTnTVYFw">.</a> <br><br>  Dieser W√ºrfel ist mit einem Reflektor verklebt (wir verwenden wei√ües AVERY <br>  DENNISON V6700B (50 mm breit, obwohl teurer, funktioniert es um ein Vielfaches besser als billiges Chinesisch), und die Markierungen selbst sind darauf geklebt.  Der einfachste Weg, dies zu tun, besteht darin, die Markierungen auf dem Plotter auszuschneiden, obwohl Sie sie in ein paar beruhigenden Stunden aus Papier oder Film ausschneiden k√∂nnen (ein Satz besteht aus 16 Markierungen). <br><br>  <a href="https://yadi.sk/d/0E5ajh4pumiahA">Hier ist</a> unser letztes Jahr. <br><br><img src="https://habrastorage.org/webt/2h/1b/9w/2h1b9wwkizem2k9ptbwmwc64spm.png"><br>  <i>verschiedene "Generationen" unserer Marker</i> <br><br>  Sie k√∂nnen auch als statische Marker f√ºr die Kalibrierung verwendet werden.  Dazu platzieren Sie sie in den √§u√üersten Ecken des Feldes und klicken auf - kalibrieren. <br><br><h3>  Montage eines zentralen Ortungsger√§tes </h3><br><h4>  Was wird ben√∂tigt: </h4><br>  <b>Einplatinencomputer.</b>  Diese Zeichnungen sind f√ºr den Standort von Intel NUC gemacht, aber Sie k√∂nnten √ºberlegen, ob Sie sie in das Geh√§use legen, zum Beispiel Odroid xu4 oder Himbeer pi4. <br><br>  <b>oCam</b> .  Eigentlich die Kamera, f√ºr die alles l√§uft.  Wir haben das Standardobjektiv f√ºr einen weiten Betrachtungswinkel auf <a href="https://air-hobby.ru/katalog/product/2262-linza-runcam-rc25g-fpv-lens-25mm-fov140-wide-angle.html">2,5 mm</a> ge√§ndert <br>  <b>Anzeige (7-Zoll-HDMI-LCD (B)</b> mit <b>Waveshare-Funktion)</b> . Mithilfe dieser Funktion werden die Kalibrierung und eine Reihe anderer Vorg√§nge ausgef√ºhrt. <br><br>  <b>LED-Streifen.</b>  Zum Beleuchten der reflektierenden Oberfl√§che von Markern.  Es ist besser, die hellste verf√ºgbare zu verwenden. <br><br>  <b>Batterie 16,8 V LiPo.</b>  Wir verwenden 4s5200mAh.  Dies sind die gleichen Batterien wie beim Roboter, da dies praktisch ist und lange h√§lt. <br><br>  <b>DC-DC-Abw√§rtswandler.</b>  Zum Einschalten des LED-Streifens.  Nuc und der Router werden direkt von der Batterie mit Strom versorgt, da alle Stromkabel bereits vorhanden sind. <br><br>  Gedruckte Teile.  Dies sind insbesondere eine Kamerahalterung, ein Display und Ecken zum Zusammenbauen des Geh√§uses: <a href="https://yadi.sk/d/swUJUwxTnTVYFw">https://yadi.sk/d/swUJUwxTnTVYFw</a> <br><br>  <b>Geh√§use Details.</b>  In unserem Fall handelte es sich um eine 2-mm-Carbonplatte.  Dies ist jedoch nicht die beste Option, da kohlenstoffleitend, schwierig zu verarbeiten und nicht so leicht wie beispielsweise Plexiglas - vielleicht die einfachste Option.  Obwohl viel h√§rter.  Finden Sie den Link oben. <br><br>  <b>Router (Zyxel keenetic extra).</b>  Wir mussten es aus dem Koffer nehmen, um in Gr√∂√üe und Gewicht zu passen.  Im Allgemeinen empfehlen wir dies jedoch nicht. <br>  Viele kleine Dinge.  Schrauben M3 * 8 ~ 40 Stk., Gestelle f√ºr Leiterplatten 3x10 ~ 12 Stk., Dr√§hte, Schraubendreher, WAGO usw. <br><br><h4>  Versammlung </h4><br>  Zuerst m√ºssen Sie die gedruckten Ecken vorbereiten und Muttern hineinpressen.  Es kann sein, dass es nur wenige Presspassungen gibt und sie leicht geklebt werden m√ºssen oder <a href="http://www.dart.moscow/index.php%3Fproductcode%3D160923">geschmolzene Muttern verwenden m√ºssen</a> <br>  Als n√§chstes m√ºssen Sie dieses Teil in der Basis installieren.  Es erm√∂glicht eine eindeutige Positionierung des zentralen Kontrollzentrums an seinem Platz. <br><br><img src="https://habrastorage.org/webt/cv/0u/vr/cv0uvrzekp09qx2typzni7gzmm4.png"><br><br>  Jetzt montieren wir die Kamerahalterung, setzen die oCam dort ein, kleben die Hintergrundbeleuchtung vom LED-Streifen so nah wie m√∂glich an das Objektiv und befestigen das Modul an der Basis. <br><br><img src="https://habrastorage.org/webt/x8/c5/sz/x8c5szf7llbkchzglqbbrz22yas.png"><br><br><img src="https://habrastorage.org/webt/k1/oj/w5/k1ojw5cbuwtnireb0axfynlffrk.png"><br><br>  Danach k√∂nnen Sie alle Seitenw√§nde montieren und an den zuvor beschriebenen Ecken befestigen.  Die L√∂cher f√ºr sie sind besser im Voraus zu kontern. <br><br><img src="https://habrastorage.org/webt/ne/mo/v0/nemov0qtrzitlompmpymxhm9npw.png"><br><br>  Wir setzen einen Single-Board-Computer und einen Router.  In unserem Fall sind dies NUC und Zyxel keenetic extra. <br><br><img src="https://habrastorage.org/webt/7l/vc/85/7lvc85rwy0gzifdg9w7a9-n0k8a.png"><br><br><img src="https://habrastorage.org/webt/er/t9/8t/ert98t1wicsogrkpabregc60o2e.png"><br><br><img src="https://habrastorage.org/webt/7y/hk/rc/7yhkrcmukr6oyrgqqyeoiwwz_io.png"><br>  <i>Und wir bekommen das zusammengebaute Trackingsystem.</i>  <i>Es bleibt nur die Neigung der Kamera einzustellen.</i> <br><br><img src="https://habrastorage.org/webt/zm/lp/zr/zmlpzrgcfrd68o_xnoaw69sdgeg.png"><br>  <i>Lokalisierungs-Debugging im Jahr 2018</i> <br><br><h3>  Was ist das Ergebnis </h3><br>  Also erz√§hlten wir alle Geheimnisse, die es uns erm√∂glichen, unser System mit eigenen H√§nden zu wiederholen.  Mit ihm k√∂nnen Sie schnell und ohne √Ñnderungen Ihr System zur Lokalisierung des Roboters auf dem Eurobot-Feld machen.  Und mit minimalen √Ñnderungen machen Sie ein ziemlich universelles und zuverl√§ssiges Tracking-System f√ºr etwas.  Es ist jedoch zu ber√ºcksichtigen, dass bei Verwendung von aruco 8x8, einer Markierungsgr√∂√üe von 10x8 cm und einer Kamera mit 1 Mpx der Erfassungsradius nicht besonders vergr√∂√üert werden kann. Wenn wir jedoch strenge Einschr√§nkungen in Bezug auf Gr√∂√üe und Leistung haben, verwenden wir im Allgemeinen nur interessantere Ger√§te. <br><br>  In diesem Jahr wurde in den Regeln die Verwendung von aruco 4x4 sowie deren nicht √ºberschneidende Bereiche f√ºr jede Seite des Feldes erw√§hnt.  In naher Zukunft planen wir, dies in unsere L√∂sung zu integrieren, damit wir in Zukunft keine Angst mehr vor der √úberschneidung von Markernummern haben.  Ein weiteres Muss, aber noch nicht erledigt, ist die manuelle Kalibrierung auf dem Feld. <br>  Im n√§chsten Artikel werden wir √ºber die niedrigere Ebene von Robotern sprechen, wie die Kinematik von Robotern ber√ºcksichtigt wird, wie wir Server, Engines und Kegel steuern, wenn wir mit Freertos arbeiten. <br><br>  Ich m√∂chte mich bedanken: <br><br>  <a href="https://github.com/alexpostnikov/aruco-gui">Alexey Postnikov</a> (in dessen Auftrag es sich wahrscheinlich gelohnt hat, alles zu ver√∂ffentlichen) - f√ºr den gesamten Code in diesem Artikel und direkte Unterst√ºtzung beim Schreiben des Artikels. <br>  <a href="https://habr.com/ru/users/eppy/">Egor Alexandrov</a> - f√ºr alle Zeichnungen und Modelle Hilfe beim Schreiben des Artikels und 34 Kommas. <br>  <a href="https://habr.com/ru/users/toma_sin/">Tamara Sinelnikova</a> - f√ºr die Hilfe beim Schreiben des Artikels. <br><br>  Und der Rest des Teams! <br><br>  Noch weniger als vier Monate bis zum Beginn des Wettbewerbs, aber das Sberbank Eurobot-Team ist immer noch offen f√ºr neue Teilnehmer.  Unser Telegramm: <a href="https://t.me/SetUpSber">https://t.me/SetUpSber</a> <br><br>  Vorherige Artikel: <br><br>  <a href="https://habr.com/ru/post/478836/">Was ist √ºblich zwischen einem Revolver, Unterlegscheiben und einem autonomen Roboter</a> <br>  <a href="https://habr.com/ru/post/479636/">Eigener Navigationsstack.</a>  <a href="https://habr.com/ru/post/479636/">Besser als ROS?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482220/">https://habr.com/ru/post/de482220/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482208/index.html">Geschenke, mit denen Sie das neue Jahr verpassen</a></li>
<li><a href="../de482210/index.html">Bot f√ºr Tetris und Reverse Engineering Animation. Analyse der mobilen Strecke der zweiten Programmiermeisterschaft</a></li>
<li><a href="../de482212/index.html">Sprechen Sie √ºber ... K√§se?</a></li>
<li><a href="../de482216/index.html">23 Antworten auf Depressionen von einem professionellen Psychiater Maxim Malyavin (dpmmax)</a></li>
<li><a href="../de482218/index.html">Java Digest f√ºr den 27. Dezember</a></li>
<li><a href="../de482222/index.html">Webanwendung auf Kotlin + Spring Boot + Vue.js (Add-On)</a></li>
<li><a href="../de482224/index.html">Wenn ein Designer ein kleiner Programmierer sein muss</a></li>
<li><a href="../de482226/index.html">Top 20 Apps, die ein Gesundheitsdienstleister nicht verpassen darf</a></li>
<li><a href="../de482228/index.html">Wir schreiben einen "Taschenrechner" in C #. Teil I. Wertberechnung, Ableitung, Vereinfachung und andere G√§nse</a></li>
<li><a href="../de482230/index.html">Der Kampf der WEB-Server. Teil 2 - Realistisches HTTPS-Szenario:</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
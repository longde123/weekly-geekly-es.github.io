<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÉüèº üë©‚Äçüë©‚Äçüëß‚Äçüëß üôçüèª Princ√≠pios para a constru√ß√£o de sistemas de an√°lise de streaming üòÖ üßëüèº‚Äçü§ù‚Äçüßëüèª ü§ûüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O design de an√°lises de streaming e sistemas de processamento de dados de streaming tem suas pr√≥prias nuances, seus pr√≥prios problemas e sua pr√≥pria p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Princ√≠pios para a constru√ß√£o de sistemas de an√°lise de streaming</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/477834/"><img src="https://habrastorage.org/webt/rk/pz/c5/rkpzc5nw7uyyv0vsp_00trtag44.jpeg" alt="imagem"><br><br>  O design de an√°lises de streaming e sistemas de processamento de dados de streaming tem suas pr√≥prias nuances, seus pr√≥prios problemas e sua pr√≥pria pilha tecnol√≥gica.  Conversamos sobre isso na pr√≥xima <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">li√ß√£o aberta</a> , realizada na v√©spera do lan√ßamento do curso de <a href="https://otus.pw/IxY2/">Engenharia de Dados</a> . <br><br>  No webinar discutido: <br><br><ul><li>  quando o processamento de streaming √© necess√°rio; </li><li>  quais elementos est√£o no SPOD, que ferramentas podemos usar para implementar esses elementos; </li><li>  como criar seu pr√≥prio sistema de an√°lise de fluxo de cliques. </li></ul><br>  Professor - <a href="https://otus.ru/teacher/370/">Yegor Mateshuk</a> , engenheiro de dados s√™nior da MaximaTelecom. <br><a name="habracut"></a><br><h3>  Quando √© necess√°rio o streaming?  Stream vs Batch </h3><br>  Primeiro de tudo, devemos descobrir quando precisamos de streaming e quando o processamento em lote.  Vamos explicar os pontos fortes e fracos dessas abordagens. <br><br>  <b>Portanto, as desvantagens do processamento em lote:</b> <br><br><ul><li>  os dados s√£o entregues com um atraso.  Como temos um certo per√≠odo de c√°lculos, nesse per√≠odo sempre ficamos para tr√°s em tempo real.  E quanto mais itera√ß√£o, mais ficamos para tr√°s.  Assim, temos um atraso de tempo, que em alguns casos √© cr√≠tico; </li><li>  carga de pico no ferro √© criada.  Se calcularmos muito no modo de lote, no final do per√≠odo (dia, semana, m√™s), temos um pico de carga, porque voc√™ precisa calcular muitas coisas.  O que isso leva a?  Primeiro, come√ßamos a descansar contra limites que, como voc√™ sabe, n√£o s√£o infinitos.  Como resultado, o sistema √© executado periodicamente at√© o limite, o que geralmente resulta em falhas.  Em segundo lugar, como todos esses trabalhos come√ßam ao mesmo tempo, eles competem e s√£o calculados muito lentamente, ou seja, voc√™ n√£o pode contar com um resultado r√°pido. </li></ul><br>  <b>Mas o processamento em lote tem suas vantagens:</b> <br><br><ul><li>  alta efici√™ncia.  N√£o aprofundaremos, pois a efici√™ncia est√° associada √† compacta√ß√£o, √†s estruturas e ao uso de formatos de coluna etc. O fato √© que o processamento em lote, se voc√™ considerar o n√∫mero de registros processados ‚Äã‚Äãpor unidade de tempo, ser√° mais eficiente; </li><li>  facilidade de desenvolvimento e suporte.  Voc√™ pode processar qualquer parte dos dados testando e recontando conforme necess√°rio. </li></ul><br>  <b>Vantagens do processamento de dados de streaming (streaming):</b> <br><br><ul><li>  resultar em tempo real.  N√£o esperamos o final de nenhum per√≠odo: assim que os dados (mesmo que em quantidade muito pequena) cheguem at√© n√≥s, podemos process√°-los e transmiti-los imediatamente.  Ou seja, o resultado, por defini√ß√£o, est√° lutando por tempo real; </li><li>  carga uniforme em ferro.  √â claro que existem ciclos di√°rios etc., no entanto, a carga ainda √© distribu√≠da ao longo do dia e resulta mais uniforme e previs√≠vel. </li></ul><br>  <b>A principal desvantagem do processamento de streaming:</b> <br><ul><li>  complexidade de desenvolvimento e suporte.  Primeiro, testar, gerenciar e recuperar dados √© um pouco mais dif√≠cil quando comparado ao lote.  A segunda dificuldade (na verdade, esse √© o problema mais b√°sico) est√° associada a revers√µes.  Se os trabalhos n√£o funcionaram e houve uma falha, √© muito dif√≠cil capturar exatamente o momento em que tudo ocorreu.  E resolver o problema exigir√° mais esfor√ßo e recursos do que o processamento em lote. </li></ul><br>  Portanto, se voc√™ est√° pensando <b>se precisa de fluxos</b> , responda as seguintes perguntas: <br><br><ol><li>  Voc√™ realmente precisa em tempo real? </li><li>  Existem muitas fontes de streaming? </li><li>  Perder um registro √© cr√≠tico? </li></ol><br>  Vejamos <b>dois exemplos</b> : <br><br>  <i>Exemplo 1. An√°lise de estoque para varejo:</i> <br><ul><li>  a exibi√ß√£o de mercadorias n√£o muda em tempo real; </li><li>  os dados geralmente s√£o entregues no modo em lote; </li><li>  a perda de informa√ß√µes √© cr√≠tica. </li></ul><br>  Neste exemplo, √© melhor usar o lote. <br><br>  <i>Exemplo 2. An√°lise para um portal da web:</i> <br><br><ul><li>  a velocidade da an√°lise determina o tempo de resposta a um problema; </li><li>  os dados chegam em tempo real; </li><li>  Perdas de uma pequena quantidade de informa√ß√µes da atividade do usu√°rio s√£o aceit√°veis. </li></ul><br>  Imagine que a an√°lise reflete como os visitantes de um portal da web se sentem usando seu produto.  Por exemplo, voc√™ lan√ßou uma nova vers√£o e precisa entender dentro de 10 a 30 minutos se tudo est√° em ordem, se algum recurso personalizado foi quebrado.  Digamos que o texto do bot√£o "Pedido" se foi - a an√°lise permitir√° que voc√™ responda rapidamente a uma queda acentuada no n√∫mero de pedidos e voc√™ entender√° imediatamente que precisa reverter. <br><br>  Assim, no segundo exemplo, √© melhor usar fluxos. <br><br><h3>  Elementos SPOD </h3><br>  Os engenheiros de processamento de dados capturam, movem, entregam, convertem e armazenam esses mesmos dados (sim, o armazenamento de dados tamb√©m √© um processo ativo!). <br>  Portanto, para construir um sistema de processamento de dados de streaming (SPOD), precisaremos dos seguintes elementos: <br><br><ol><li>  <b>carregador de dados</b> (meios de entrega de dados ao armazenamento); </li><li>  <b>barramento de troca de dados</b> (nem sempre √© necess√°rio, mas n√£o h√° como transmitir sem ele, porque voc√™ precisa de um sistema atrav√©s do qual trocar√° dados em tempo real); </li><li>  <b>armazenamento de dados</b> (como sem ele); </li><li>  <b>Mecanismo de ETL</b> (necess√°rio para realizar v√°rias opera√ß√µes de filtragem, classifica√ß√£o e outras); </li><li>  <b>BI</b> (para exibir resultados); </li><li>  <b>orquestrador</b> (vincula todo o processo, organizando o processamento de dados em v√°rios est√°gios). </li></ol><br>  No nosso caso, consideraremos a situa√ß√£o mais simples e focaremos apenas nos tr√™s primeiros elementos. <br><br><h3>  Ferramentas de processamento de fluxo de dados </h3><br>  Temos v√°rios "candidatos" para o papel de <b>carregador</b> de <b>dados</b> : <br><br><ul><li>  Apache flume </li><li>  Apache nifi </li><li>  Streamset </li></ul><br><h4>  Apache flume </h4><br>  O primeiro sobre o qual falaremos √© o <b>Apache Flume</b> , uma ferramenta para transportar dados entre diferentes fontes e reposit√≥rios. <br><br><img src="https://habrastorage.org/webt/dg/by/a3/dgbya30snrkaceq0y7bvtct59wc.png" alt="imagem"><br><br>  Pr√≥s: <br><br><ul><li>  existe quase todo lugar </li><li>  h√° muito usado </li><li>  flex√≠vel e extens√≠vel o suficiente </li></ul><br>  Contras: <br><br><ul><li>  configura√ß√£o inconveniente </li><li>  dif√≠cil de monitorar </li></ul><br>  Quanto √† sua configura√ß√£o, √© algo como isto: <br><br><img src="https://habrastorage.org/webt/hf/-i/bz/hf-ibz-bp5n8ydo3c1viwsxw9qe.png" alt="imagem"><br><br>  Acima, criamos um canal simples que fica na porta, pega os dados de l√° e simplesmente os registra.  Em princ√≠pio, para descrever um processo, isso ainda √© normal, mas quando voc√™ tem dezenas desses processos, o arquivo de configura√ß√£o se transforma em um inferno.  Algu√©m adiciona alguns configuradores visuais, mas por que se preocupar se existem ferramentas que o tornam pronto para uso?  Por exemplo, o mesmo NiFi e StreamSets. <br><br><h4>  Apache nifi </h4><br>  De fato, ele desempenha o mesmo papel que o Flume, mas com uma interface visual, o que √© uma grande vantagem, especialmente quando h√° muitos processos. <br><br>  Alguns fatos sobre o NiFi <br><br><ul><li>  originalmente desenvolvido na NSA; </li><li>  O Hortonworks agora √© suportado e desenvolvido; </li><li>  parte do HDF da Hortonworks; </li><li>  possui uma vers√£o especial do MiNiFi para coletar dados de dispositivos. </li></ul><br>  O sistema se parece com isso: <br><br><img src="https://habrastorage.org/webt/jz/1k/l7/jz1kl7seqymd9rxx2tog4k88wni.png" alt="imagem"><br><br>  Temos um campo de criatividade e est√°gios de processamento de dados que lan√ßamos l√°.  Existem muitos conectores para todos os sistemas poss√≠veis, etc. <br><br><h4>  Streamset </h4><br>  √â tamb√©m um sistema de controle de fluxo de dados com uma interface visual.  Foi desenvolvido por pessoas da Cloudera, √© facilmente instalado como Parcel no CDH, possui uma vers√£o especial do SDC Edge para coletar dados de dispositivos. <br><br>  Consiste em dois componentes: <br><br><ul><li>  SDC - um sistema que realiza processamento direto de dados (gratuito); </li><li>  StreamSets Control Hub - um centro de controle para v√°rios SDCs com recursos adicionais para o desenvolvimento de linhas de pagamento (pagas). </li></ul><br>  Parece algo como isto: <br><br><img src="https://habrastorage.org/webt/kx/3z/jw/kx3zjwqx_ijbfxdlg7hvizllnt4.png" alt="imagem"><br><br>  Momento desagrad√°vel - o StreamSets tem pe√ßas gratuitas e pagas. <br><br><h4>  Barramento de dados </h4><br>  Agora vamos descobrir onde faremos o upload desses dados.  Requerentes: <br><br><ul><li>  Apache kafka </li><li>  Rabbitmq </li><li>  NATS </li></ul><br>  O Apache Kafka √© a melhor op√ß√£o, mas se voc√™ tiver RabbitMQ ou NATS em sua empresa e precisar adicionar um pouco de an√°lise, a implanta√ß√£o do Kafka a partir do zero n√£o ser√° muito lucrativa. <br><br>  Em todos os outros casos, Kafka √© uma √≥tima op√ß√£o.  Na verdade, √© um intermedi√°rio de mensagens com escala horizontal e largura de banda enorme.  √â perfeitamente integrado a todo o ecossistema de ferramentas para trabalhar com dados e pode suportar cargas pesadas.  Tem uma interface universal e √© o sistema circulat√≥rio do nosso processamento de dados. <br><br>  Por dentro, o Kafka √© dividido em T√≥pico - um determinado fluxo de dados separado de mensagens com o mesmo esquema ou, pelo menos, com o mesmo objetivo. <br><br>  Para discutir a pr√≥xima nuance, lembre-se de que as fontes de dados podem variar um pouco.  O formato dos dados √© muito importante: <br><br><img src="https://habrastorage.org/webt/fq/kn/ci/fqkncilmsox7hmoye289ronvbyk.png" alt="imagem"><br><br>  O formato de serializa√ß√£o de dados Apache Avro merece men√ß√£o especial.  O sistema usa JSON para determinar a estrutura de dados (esquema) que √© serializada em um <b>formato bin√°rio compacto</b> .  Portanto, economizamos uma quantidade enorme de dados e a serializa√ß√£o / desserializa√ß√£o √© mais barata. <br><br>  Tudo parece estar bem, mas a presen√ßa de arquivos separados com circuitos apresenta um problema, pois precisamos trocar arquivos entre sistemas diferentes.  Parece simples, mas quando voc√™ trabalha em departamentos diferentes, os funcion√°rios do outro lado podem mudar alguma coisa e se acalmar, e tudo vai desmoronar para voc√™. <br><br>  Para n√£o transferir todos esses arquivos para unidades flash, disquetes e pinturas rupestres, existe um servi√ßo especial - registro de esquema.  Este √© um servi√ßo para sincronizar esquemas avro entre servi√ßos que escrevem e leem do Kafka. <br><br><img src="https://habrastorage.org/webt/do/jf/qd/dojfqd1m6nf5wr53xmvmg5hee_a.png" alt="imagem"><br><br>  Em termos de Kafka, o produtor √© quem escreve, o consumidor √© quem consome (l√™) os dados. <br><br><h4>  Data warehouse </h4><br>  Desafiantes (de fato, existem muitas mais op√ß√µes, mas s√£o necess√°rias apenas algumas): <br><br><ul><li>  HDFS + Hive </li><li>  Kudu + Impala </li><li>  Clickhouse </li></ul><br>  Antes de escolher um reposit√≥rio, lembre-se do que <b>√© idempot√™ncia</b> .  A Wikipedia diz que idempot√™ncia (latim idem - o mesmo + potens - capaz) - a propriedade de um objeto ou opera√ß√£o ao aplicar a opera√ß√£o ao objeto novamente, fornece o mesmo resultado que o primeiro.  No nosso caso, o processo de processamento de streaming deve ser constru√≠do para que, ao preencher novamente os dados de origem, o resultado permane√ßa correto. <br><br>  <b>Como conseguir isso</b> em sistemas de streaming: <br><br><ul><li>  identificar um ID exclusivo (pode ser composto) </li><li>  use esse ID para deduplicar dados </li></ul><br>  O armazenamento HDFS + Hive <b>n√£o fornece idempot√™ncia</b> para a grava√ß√£o de streaming " <b>pronta</b> para uso", portanto, temos: <br><br><ul><li>  Kudu + Impala </li><li>  Clickhouse </li></ul><br>  <b>O Kudu</b> √© um reposit√≥rio adequado para consultas anal√≠ticas, mas com uma Chave Prim√°ria, para desduplica√ß√£o.  <b>Impala</b> √© a interface SQL para este reposit√≥rio (e v√°rios outros). <br><br>  Quanto ao ClickHouse, este √© um banco de dados anal√≠tico da Yandex.  Seu principal objetivo √© a an√°lise em uma tabela preenchida com um grande fluxo de dados brutos.  Das vantagens - existe um mecanismo ReplacingMergeTree para desduplica√ß√£o de chave (a desduplica√ß√£o foi projetada para economizar espa√ßo e pode deixar duplicados em alguns casos, √© necess√°rio levar em considera√ß√£o as <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/replacingmergetree/">nuances</a> ). <br><br>  Resta acrescentar algumas palavras sobre o <b>Divolte</b> .  Se voc√™ se lembra, falamos sobre o fato de que alguns dados precisam ser capturados.  Se voc√™ precisar organizar de forma r√°pida e f√°cil as an√°lises para um portal, o Divolte √© um excelente servi√ßo para capturar eventos do usu√°rio em uma p√°gina da Web via JavaScript. <br><br><img src="https://habrastorage.org/webt/wo/7m/ol/wo7molaoelkzjjatvyzzaihkrmm.png" alt="imagem"><br><br><h3>  Exemplo pr√°tico </h3><br>  O que estamos tentando fazer?  <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4016">Vamos tentar criar um</a> pipeline para coletar dados do Clickstream em tempo real.  <b>Clickstream</b> √© um espa√ßo virtual que um usu√°rio deixa enquanto est√° no site.  Vamos capturar dados usando o Divolte e grav√°-los em Kafka. <br><br><img src="https://habrastorage.org/webt/uj/mt/h-/ujmth-4jh9catnqqxt0ikp0w9xa.png" alt="imagem"><br><br>  Voc√™ precisa que o Docker funcione, al√©m de clonar o <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example">seguinte reposit√≥rio</a> .  Tudo o que acontece ser√° lan√ßado em cont√™ineres.  Para executar consistentemente v√°rios cont√™ineres ao mesmo tempo, o <a href="">docker-compose.yml</a> ser√° usado.  Al√©m disso, h√° um <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/blob/master/Dockerfile">Dockerfile</a> compilando nossos StreamSets com determinadas depend√™ncias. <br><br>  Existem tamb√©m tr√™s pastas: <br><br><ol><li>  <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/clickhouse-data">os dados da clickhouse</a> ser√£o gravados em <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/clickhouse-data">clickhouse-data</a> </li><li>  exatamente o mesmo pai ( <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/sdc-data">dados sdc</a> ) que teremos para o StreamSets, onde o sistema pode armazenar configura√ß√µes </li><li>  a terceira pasta ( <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/examples">exemplos</a> ) inclui um arquivo de solicita√ß√£o e um arquivo de configura√ß√£o de canal para StreamSets </li></ol><br><br><img src="https://habrastorage.org/webt/-r/xt/2r/-rxt2rlhxzdqqeyz7qv3z3dugxw.png" alt="imagem"><br><br>  Para iniciar, digite o seguinte comando: <br><br><pre><code class="bash hljs">docker-compose up</code> </pre> <br>  E gostamos de qu√£o lenta, mas seguramente, os cont√™ineres come√ßam.  Ap√≥s o in√≠cio, podemos ir para o endere√ßo <a href="http://localhost:8290/">http: // localhost: 18630 ‚Äã‚Äã/</a> e tocar imediatamente em Divolte: <br><br><img src="https://habrastorage.org/webt/cc/1m/im/cc1mimjszmzdoyiwb-elb2c_igu.png" alt="imagem"><br><br>  Temos o Divolte, que j√° recebeu alguns eventos e os gravou em Kafka.  Vamos tentar calcul√°-los usando StreamSets: <a href="http://localhost:18630/">http: // localhost: 18630 ‚Äã‚Äã/</a> (senha / login - admin / admin). <br><br><img src="https://habrastorage.org/webt/fc/hk/qz/fchkqzqe9pzpdws-xilz3ftdcb8.png" alt="imagem"><br><br>  Para n√£o sofrer, √© melhor <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4425">importar o</a> <b>Pipeline</b> , nomeando-o, por exemplo, <b>clickstream_pipeline</b> .  E da pasta de exemplos importamos <b>clickstream.json</b> .  Se estiver tudo bem, <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4701">veremos a seguinte imagem</a> : <br><br><img src="https://habrastorage.org/webt/o8/z9/x5/o8z9x5eaacqkehcfcgxattekpba.png" alt="imagem"><br><br>  Ent√£o, criamos uma conex√£o com o Kafka, registramos qual Kafka precisamos, registramos qual t√≥pico nos interessa, selecionamos os campos que nos interessam e, em seguida, colocamos um dreno em Kafka, registrando qual Kafka e qual t√≥pico.  As diferen√ßas s√£o que, em um caso, o formato Data √© Avro e, no segundo, √© apenas JSON. <br><br>  Vamos seguir em frente.  Podemos, por exemplo, <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4768">fazer uma visualiza√ß√£o</a> que captura certos registros em tempo real do Kafka.  Ent√£o escrevemos tudo. <br><br>  Ap√≥s o lan√ßamento, veremos que um fluxo de eventos voa para Kafka, e isso acontece em tempo real: <br><br><img src="https://habrastorage.org/webt/kr/a7/0n/kra70nxdaplug8-oywal1wb23oi.png" alt="imagem"><br><br>  Agora voc√™ pode criar um reposit√≥rio para esses dados no ClickHouse.  Para trabalhar com ClickHouse, voc√™ pode usar um cliente nativo simples executando o seguinte comando: <br><br><pre> <code class="bash hljs">docker run -it --rm --network divolte-ss-ch_default yandex/clickhouse-client --host clickhouse</code> </pre> <br>  Observe que esta linha indica a rede √† qual voc√™ deseja se conectar.  E, dependendo de como voc√™ nomeia a pasta com o reposit√≥rio, o nome da sua rede pode ser diferente.  Em geral, o comando ser√° o seguinte: <br><br><pre> <code class="bash hljs">docker run -it --rm --network {your_network_name} yandex/clickhouse-client --host clickhouse</code> </pre> <br>  A lista de redes pode ser visualizada com o comando: <br><br><pre> <code class="bash hljs">docker network ls</code> </pre> <br>  Bem, n√£o h√° mais nada: <br><br>  1. <b>Primeiro, "assine" nosso ClickHouse para Kafka</b> , "explicando a ele" que formato de dados precisamos l√°: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">IF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXISTS</span></span> clickstream_topic ( firstInSession UInt8, <span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span> UInt64, location <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, partyId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, sessionId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, pageViewId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, eventType <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgentString <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = Kafka <span class="hljs-keyword"><span class="hljs-keyword">SETTINGS</span></span> kafka_broker_list = <span class="hljs-string"><span class="hljs-string">'kafka:9092'</span></span>, kafka_topic_list = <span class="hljs-string"><span class="hljs-string">'clickstream'</span></span>, kafka_group_name = <span class="hljs-string"><span class="hljs-string">'clickhouse'</span></span>, kafka_format = <span class="hljs-string"><span class="hljs-string">'JSONEachRow'</span></span>;</code> </pre><br>  2. <b>Agora vamos criar uma tabela real</b> onde colocaremos os dados finais: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> clickstream ( firstInSession UInt8, <span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span> UInt64, location <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, partyId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, sessionId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, pageViewId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, eventType <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgentString <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree() <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> (<span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span>, pageViewId);</code> </pre> <br>  3. <b>E ent√£o forneceremos um relacionamento entre essas duas tabelas</b> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">MATERIALIZED</span></span> <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> clickstream_consumer <span class="hljs-keyword"><span class="hljs-keyword">TO</span></span> clickstream <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> clickstream_topic;</code> </pre> <br>  4. <b>E agora vamos selecionar os campos necess√°rios</b> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> clickstream;</code> </pre> <br>  Como resultado, a escolha na tabela de destino nos dar√° o resultado que precisamos. <br><br><img src="https://habrastorage.org/webt/wn/sr/qe/wnsrqei2fo7iydrf41zattwbddy.png"><br><br>  Isso √© tudo, foi o Clickstream mais simples que voc√™ pode criar.  Se voc√™ deseja concluir as etapas acima, <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">assista ao v√≠deo</a> inteiro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt477834/">https://habr.com/ru/post/pt477834/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt477816/index.html">Como encontrar um emprego com um bom contrato</a></li>
<li><a href="../pt477818/index.html">Como se tornar um cientista de dados em 2019</a></li>
<li><a href="../pt477820/index.html">VMware, Hyper-V, OpenStack, Kubernetes, Swarm - monitorando a partir de uma √∫nica interface no Quest Foglight</a></li>
<li><a href="../pt477826/index.html">Vis√£o geral e compara√ß√£o das tecnologias V2X</a></li>
<li><a href="../pt477832/index.html">Como se dar bem com a gera√ß√£o Z</a></li>
<li><a href="../pt477836/index.html">Como testamos o WD ActiveScale P100 para nosso armazenamento S3</a></li>
<li><a href="../pt477838/index.html">Analisador est√°tico PVS-Studio como ferramenta de prote√ß√£o contra vulnerabilidades de dia zero</a></li>
<li><a href="../pt477840/index.html">Analisador de c√≥digo est√°tico PVS-Studio como prote√ß√£o contra vulnerabilidades de dia zero</a></li>
<li><a href="../pt477844/index.html">5 etapas da ideia √† aplica√ß√£o pr√°tica de aprendizado de m√°quina com o SAP Data Intelligence</a></li>
<li><a href="../pt477846/index.html">Resumo de eventos para profissionais de RH em TI de dezembro de 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👃🏼 👩‍👩‍👧‍👧 🙍🏻 Princípios para a construção de sistemas de análise de streaming 😅 🧑🏼‍🤝‍🧑🏻 🤞🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O design de análises de streaming e sistemas de processamento de dados de streaming tem suas próprias nuances, seus próprios problemas e sua própria p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Princípios para a construção de sistemas de análise de streaming</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/477834/"><img src="https://habrastorage.org/webt/rk/pz/c5/rkpzc5nw7uyyv0vsp_00trtag44.jpeg" alt="imagem"><br><br>  O design de análises de streaming e sistemas de processamento de dados de streaming tem suas próprias nuances, seus próprios problemas e sua própria pilha tecnológica.  Conversamos sobre isso na próxima <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">lição aberta</a> , realizada na véspera do lançamento do curso de <a href="https://otus.pw/IxY2/">Engenharia de Dados</a> . <br><br>  No webinar discutido: <br><br><ul><li>  quando o processamento de streaming é necessário; </li><li>  quais elementos estão no SPOD, que ferramentas podemos usar para implementar esses elementos; </li><li>  como criar seu próprio sistema de análise de fluxo de cliques. </li></ul><br>  Professor - <a href="https://otus.ru/teacher/370/">Yegor Mateshuk</a> , engenheiro de dados sênior da MaximaTelecom. <br><a name="habracut"></a><br><h3>  Quando é necessário o streaming?  Stream vs Batch </h3><br>  Primeiro de tudo, devemos descobrir quando precisamos de streaming e quando o processamento em lote.  Vamos explicar os pontos fortes e fracos dessas abordagens. <br><br>  <b>Portanto, as desvantagens do processamento em lote:</b> <br><br><ul><li>  os dados são entregues com um atraso.  Como temos um certo período de cálculos, nesse período sempre ficamos para trás em tempo real.  E quanto mais iteração, mais ficamos para trás.  Assim, temos um atraso de tempo, que em alguns casos é crítico; </li><li>  carga de pico no ferro é criada.  Se calcularmos muito no modo de lote, no final do período (dia, semana, mês), temos um pico de carga, porque você precisa calcular muitas coisas.  O que isso leva a?  Primeiro, começamos a descansar contra limites que, como você sabe, não são infinitos.  Como resultado, o sistema é executado periodicamente até o limite, o que geralmente resulta em falhas.  Em segundo lugar, como todos esses trabalhos começam ao mesmo tempo, eles competem e são calculados muito lentamente, ou seja, você não pode contar com um resultado rápido. </li></ul><br>  <b>Mas o processamento em lote tem suas vantagens:</b> <br><br><ul><li>  alta eficiência.  Não aprofundaremos, pois a eficiência está associada à compactação, às estruturas e ao uso de formatos de coluna etc. O fato é que o processamento em lote, se você considerar o número de registros processados ​​por unidade de tempo, será mais eficiente; </li><li>  facilidade de desenvolvimento e suporte.  Você pode processar qualquer parte dos dados testando e recontando conforme necessário. </li></ul><br>  <b>Vantagens do processamento de dados de streaming (streaming):</b> <br><br><ul><li>  resultar em tempo real.  Não esperamos o final de nenhum período: assim que os dados (mesmo que em quantidade muito pequena) cheguem até nós, podemos processá-los e transmiti-los imediatamente.  Ou seja, o resultado, por definição, está lutando por tempo real; </li><li>  carga uniforme em ferro.  É claro que existem ciclos diários etc., no entanto, a carga ainda é distribuída ao longo do dia e resulta mais uniforme e previsível. </li></ul><br>  <b>A principal desvantagem do processamento de streaming:</b> <br><ul><li>  complexidade de desenvolvimento e suporte.  Primeiro, testar, gerenciar e recuperar dados é um pouco mais difícil quando comparado ao lote.  A segunda dificuldade (na verdade, esse é o problema mais básico) está associada a reversões.  Se os trabalhos não funcionaram e houve uma falha, é muito difícil capturar exatamente o momento em que tudo ocorreu.  E resolver o problema exigirá mais esforço e recursos do que o processamento em lote. </li></ul><br>  Portanto, se você está pensando <b>se precisa de fluxos</b> , responda as seguintes perguntas: <br><br><ol><li>  Você realmente precisa em tempo real? </li><li>  Existem muitas fontes de streaming? </li><li>  Perder um registro é crítico? </li></ol><br>  Vejamos <b>dois exemplos</b> : <br><br>  <i>Exemplo 1. Análise de estoque para varejo:</i> <br><ul><li>  a exibição de mercadorias não muda em tempo real; </li><li>  os dados geralmente são entregues no modo em lote; </li><li>  a perda de informações é crítica. </li></ul><br>  Neste exemplo, é melhor usar o lote. <br><br>  <i>Exemplo 2. Análise para um portal da web:</i> <br><br><ul><li>  a velocidade da análise determina o tempo de resposta a um problema; </li><li>  os dados chegam em tempo real; </li><li>  Perdas de uma pequena quantidade de informações da atividade do usuário são aceitáveis. </li></ul><br>  Imagine que a análise reflete como os visitantes de um portal da web se sentem usando seu produto.  Por exemplo, você lançou uma nova versão e precisa entender dentro de 10 a 30 minutos se tudo está em ordem, se algum recurso personalizado foi quebrado.  Digamos que o texto do botão "Pedido" se foi - a análise permitirá que você responda rapidamente a uma queda acentuada no número de pedidos e você entenderá imediatamente que precisa reverter. <br><br>  Assim, no segundo exemplo, é melhor usar fluxos. <br><br><h3>  Elementos SPOD </h3><br>  Os engenheiros de processamento de dados capturam, movem, entregam, convertem e armazenam esses mesmos dados (sim, o armazenamento de dados também é um processo ativo!). <br>  Portanto, para construir um sistema de processamento de dados de streaming (SPOD), precisaremos dos seguintes elementos: <br><br><ol><li>  <b>carregador de dados</b> (meios de entrega de dados ao armazenamento); </li><li>  <b>barramento de troca de dados</b> (nem sempre é necessário, mas não há como transmitir sem ele, porque você precisa de um sistema através do qual trocará dados em tempo real); </li><li>  <b>armazenamento de dados</b> (como sem ele); </li><li>  <b>Mecanismo de ETL</b> (necessário para realizar várias operações de filtragem, classificação e outras); </li><li>  <b>BI</b> (para exibir resultados); </li><li>  <b>orquestrador</b> (vincula todo o processo, organizando o processamento de dados em vários estágios). </li></ol><br>  No nosso caso, consideraremos a situação mais simples e focaremos apenas nos três primeiros elementos. <br><br><h3>  Ferramentas de processamento de fluxo de dados </h3><br>  Temos vários "candidatos" para o papel de <b>carregador</b> de <b>dados</b> : <br><br><ul><li>  Apache flume </li><li>  Apache nifi </li><li>  Streamset </li></ul><br><h4>  Apache flume </h4><br>  O primeiro sobre o qual falaremos é o <b>Apache Flume</b> , uma ferramenta para transportar dados entre diferentes fontes e repositórios. <br><br><img src="https://habrastorage.org/webt/dg/by/a3/dgbya30snrkaceq0y7bvtct59wc.png" alt="imagem"><br><br>  Prós: <br><br><ul><li>  existe quase todo lugar </li><li>  há muito usado </li><li>  flexível e extensível o suficiente </li></ul><br>  Contras: <br><br><ul><li>  configuração inconveniente </li><li>  difícil de monitorar </li></ul><br>  Quanto à sua configuração, é algo como isto: <br><br><img src="https://habrastorage.org/webt/hf/-i/bz/hf-ibz-bp5n8ydo3c1viwsxw9qe.png" alt="imagem"><br><br>  Acima, criamos um canal simples que fica na porta, pega os dados de lá e simplesmente os registra.  Em princípio, para descrever um processo, isso ainda é normal, mas quando você tem dezenas desses processos, o arquivo de configuração se transforma em um inferno.  Alguém adiciona alguns configuradores visuais, mas por que se preocupar se existem ferramentas que o tornam pronto para uso?  Por exemplo, o mesmo NiFi e StreamSets. <br><br><h4>  Apache nifi </h4><br>  De fato, ele desempenha o mesmo papel que o Flume, mas com uma interface visual, o que é uma grande vantagem, especialmente quando há muitos processos. <br><br>  Alguns fatos sobre o NiFi <br><br><ul><li>  originalmente desenvolvido na NSA; </li><li>  O Hortonworks agora é suportado e desenvolvido; </li><li>  parte do HDF da Hortonworks; </li><li>  possui uma versão especial do MiNiFi para coletar dados de dispositivos. </li></ul><br>  O sistema se parece com isso: <br><br><img src="https://habrastorage.org/webt/jz/1k/l7/jz1kl7seqymd9rxx2tog4k88wni.png" alt="imagem"><br><br>  Temos um campo de criatividade e estágios de processamento de dados que lançamos lá.  Existem muitos conectores para todos os sistemas possíveis, etc. <br><br><h4>  Streamset </h4><br>  É também um sistema de controle de fluxo de dados com uma interface visual.  Foi desenvolvido por pessoas da Cloudera, é facilmente instalado como Parcel no CDH, possui uma versão especial do SDC Edge para coletar dados de dispositivos. <br><br>  Consiste em dois componentes: <br><br><ul><li>  SDC - um sistema que realiza processamento direto de dados (gratuito); </li><li>  StreamSets Control Hub - um centro de controle para vários SDCs com recursos adicionais para o desenvolvimento de linhas de pagamento (pagas). </li></ul><br>  Parece algo como isto: <br><br><img src="https://habrastorage.org/webt/kx/3z/jw/kx3zjwqx_ijbfxdlg7hvizllnt4.png" alt="imagem"><br><br>  Momento desagradável - o StreamSets tem peças gratuitas e pagas. <br><br><h4>  Barramento de dados </h4><br>  Agora vamos descobrir onde faremos o upload desses dados.  Requerentes: <br><br><ul><li>  Apache kafka </li><li>  Rabbitmq </li><li>  NATS </li></ul><br>  O Apache Kafka é a melhor opção, mas se você tiver RabbitMQ ou NATS em sua empresa e precisar adicionar um pouco de análise, a implantação do Kafka a partir do zero não será muito lucrativa. <br><br>  Em todos os outros casos, Kafka é uma ótima opção.  Na verdade, é um intermediário de mensagens com escala horizontal e largura de banda enorme.  É perfeitamente integrado a todo o ecossistema de ferramentas para trabalhar com dados e pode suportar cargas pesadas.  Tem uma interface universal e é o sistema circulatório do nosso processamento de dados. <br><br>  Por dentro, o Kafka é dividido em Tópico - um determinado fluxo de dados separado de mensagens com o mesmo esquema ou, pelo menos, com o mesmo objetivo. <br><br>  Para discutir a próxima nuance, lembre-se de que as fontes de dados podem variar um pouco.  O formato dos dados é muito importante: <br><br><img src="https://habrastorage.org/webt/fq/kn/ci/fqkncilmsox7hmoye289ronvbyk.png" alt="imagem"><br><br>  O formato de serialização de dados Apache Avro merece menção especial.  O sistema usa JSON para determinar a estrutura de dados (esquema) que é serializada em um <b>formato binário compacto</b> .  Portanto, economizamos uma quantidade enorme de dados e a serialização / desserialização é mais barata. <br><br>  Tudo parece estar bem, mas a presença de arquivos separados com circuitos apresenta um problema, pois precisamos trocar arquivos entre sistemas diferentes.  Parece simples, mas quando você trabalha em departamentos diferentes, os funcionários do outro lado podem mudar alguma coisa e se acalmar, e tudo vai desmoronar para você. <br><br>  Para não transferir todos esses arquivos para unidades flash, disquetes e pinturas rupestres, existe um serviço especial - registro de esquema.  Este é um serviço para sincronizar esquemas avro entre serviços que escrevem e leem do Kafka. <br><br><img src="https://habrastorage.org/webt/do/jf/qd/dojfqd1m6nf5wr53xmvmg5hee_a.png" alt="imagem"><br><br>  Em termos de Kafka, o produtor é quem escreve, o consumidor é quem consome (lê) os dados. <br><br><h4>  Data warehouse </h4><br>  Desafiantes (de fato, existem muitas mais opções, mas são necessárias apenas algumas): <br><br><ul><li>  HDFS + Hive </li><li>  Kudu + Impala </li><li>  Clickhouse </li></ul><br>  Antes de escolher um repositório, lembre-se do que <b>é idempotência</b> .  A Wikipedia diz que idempotência (latim idem - o mesmo + potens - capaz) - a propriedade de um objeto ou operação ao aplicar a operação ao objeto novamente, fornece o mesmo resultado que o primeiro.  No nosso caso, o processo de processamento de streaming deve ser construído para que, ao preencher novamente os dados de origem, o resultado permaneça correto. <br><br>  <b>Como conseguir isso</b> em sistemas de streaming: <br><br><ul><li>  identificar um ID exclusivo (pode ser composto) </li><li>  use esse ID para deduplicar dados </li></ul><br>  O armazenamento HDFS + Hive <b>não fornece idempotência</b> para a gravação de streaming " <b>pronta</b> para uso", portanto, temos: <br><br><ul><li>  Kudu + Impala </li><li>  Clickhouse </li></ul><br>  <b>O Kudu</b> é um repositório adequado para consultas analíticas, mas com uma Chave Primária, para desduplicação.  <b>Impala</b> é a interface SQL para este repositório (e vários outros). <br><br>  Quanto ao ClickHouse, este é um banco de dados analítico da Yandex.  Seu principal objetivo é a análise em uma tabela preenchida com um grande fluxo de dados brutos.  Das vantagens - existe um mecanismo ReplacingMergeTree para desduplicação de chave (a desduplicação foi projetada para economizar espaço e pode deixar duplicados em alguns casos, é necessário levar em consideração as <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/replacingmergetree/">nuances</a> ). <br><br>  Resta acrescentar algumas palavras sobre o <b>Divolte</b> .  Se você se lembra, falamos sobre o fato de que alguns dados precisam ser capturados.  Se você precisar organizar de forma rápida e fácil as análises para um portal, o Divolte é um excelente serviço para capturar eventos do usuário em uma página da Web via JavaScript. <br><br><img src="https://habrastorage.org/webt/wo/7m/ol/wo7molaoelkzjjatvyzzaihkrmm.png" alt="imagem"><br><br><h3>  Exemplo prático </h3><br>  O que estamos tentando fazer?  <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4016">Vamos tentar criar um</a> pipeline para coletar dados do Clickstream em tempo real.  <b>Clickstream</b> é um espaço virtual que um usuário deixa enquanto está no site.  Vamos capturar dados usando o Divolte e gravá-los em Kafka. <br><br><img src="https://habrastorage.org/webt/uj/mt/h-/ujmth-4jh9catnqqxt0ikp0w9xa.png" alt="imagem"><br><br>  Você precisa que o Docker funcione, além de clonar o <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example">seguinte repositório</a> .  Tudo o que acontece será lançado em contêineres.  Para executar consistentemente vários contêineres ao mesmo tempo, o <a href="">docker-compose.yml</a> será usado.  Além disso, há um <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/blob/master/Dockerfile">Dockerfile</a> compilando nossos StreamSets com determinadas dependências. <br><br>  Existem também três pastas: <br><br><ol><li>  <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/clickhouse-data">os dados da clickhouse</a> serão gravados em <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/clickhouse-data">clickhouse-data</a> </li><li>  exatamente o mesmo pai ( <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/sdc-data">dados sdc</a> ) que teremos para o StreamSets, onde o sistema pode armazenar configurações </li><li>  a terceira pasta ( <a href="https://github.com/Gorini4/divolte-streamsets-clickhouse-example/tree/master/examples">exemplos</a> ) inclui um arquivo de solicitação e um arquivo de configuração de canal para StreamSets </li></ol><br><br><img src="https://habrastorage.org/webt/-r/xt/2r/-rxt2rlhxzdqqeyz7qv3z3dugxw.png" alt="imagem"><br><br>  Para iniciar, digite o seguinte comando: <br><br><pre><code class="bash hljs">docker-compose up</code> </pre> <br>  E gostamos de quão lenta, mas seguramente, os contêineres começam.  Após o início, podemos ir para o endereço <a href="http://localhost:8290/">http: // localhost: 18630 ​​/</a> e tocar imediatamente em Divolte: <br><br><img src="https://habrastorage.org/webt/cc/1m/im/cc1mimjszmzdoyiwb-elb2c_igu.png" alt="imagem"><br><br>  Temos o Divolte, que já recebeu alguns eventos e os gravou em Kafka.  Vamos tentar calculá-los usando StreamSets: <a href="http://localhost:18630/">http: // localhost: 18630 ​​/</a> (senha / login - admin / admin). <br><br><img src="https://habrastorage.org/webt/fc/hk/qz/fchkqzqe9pzpdws-xilz3ftdcb8.png" alt="imagem"><br><br>  Para não sofrer, é melhor <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4425">importar o</a> <b>Pipeline</b> , nomeando-o, por exemplo, <b>clickstream_pipeline</b> .  E da pasta de exemplos importamos <b>clickstream.json</b> .  Se estiver tudo bem, <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4701">veremos a seguinte imagem</a> : <br><br><img src="https://habrastorage.org/webt/o8/z9/x5/o8z9x5eaacqkehcfcgxattekpba.png" alt="imagem"><br><br>  Então, criamos uma conexão com o Kafka, registramos qual Kafka precisamos, registramos qual tópico nos interessa, selecionamos os campos que nos interessam e, em seguida, colocamos um dreno em Kafka, registrando qual Kafka e qual tópico.  As diferenças são que, em um caso, o formato Data é Avro e, no segundo, é apenas JSON. <br><br>  Vamos seguir em frente.  Podemos, por exemplo, <a href="https://youtu.be/NFjL8YQKuVg%3Ft%3D4768">fazer uma visualização</a> que captura certos registros em tempo real do Kafka.  Então escrevemos tudo. <br><br>  Após o lançamento, veremos que um fluxo de eventos voa para Kafka, e isso acontece em tempo real: <br><br><img src="https://habrastorage.org/webt/kr/a7/0n/kra70nxdaplug8-oywal1wb23oi.png" alt="imagem"><br><br>  Agora você pode criar um repositório para esses dados no ClickHouse.  Para trabalhar com ClickHouse, você pode usar um cliente nativo simples executando o seguinte comando: <br><br><pre> <code class="bash hljs">docker run -it --rm --network divolte-ss-ch_default yandex/clickhouse-client --host clickhouse</code> </pre> <br>  Observe que esta linha indica a rede à qual você deseja se conectar.  E, dependendo de como você nomeia a pasta com o repositório, o nome da sua rede pode ser diferente.  Em geral, o comando será o seguinte: <br><br><pre> <code class="bash hljs">docker run -it --rm --network {your_network_name} yandex/clickhouse-client --host clickhouse</code> </pre> <br>  A lista de redes pode ser visualizada com o comando: <br><br><pre> <code class="bash hljs">docker network ls</code> </pre> <br>  Bem, não há mais nada: <br><br>  1. <b>Primeiro, "assine" nosso ClickHouse para Kafka</b> , "explicando a ele" que formato de dados precisamos lá: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">IF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXISTS</span></span> clickstream_topic ( firstInSession UInt8, <span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span> UInt64, location <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, partyId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, sessionId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, pageViewId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, eventType <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgentString <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = Kafka <span class="hljs-keyword"><span class="hljs-keyword">SETTINGS</span></span> kafka_broker_list = <span class="hljs-string"><span class="hljs-string">'kafka:9092'</span></span>, kafka_topic_list = <span class="hljs-string"><span class="hljs-string">'clickstream'</span></span>, kafka_group_name = <span class="hljs-string"><span class="hljs-string">'clickhouse'</span></span>, kafka_format = <span class="hljs-string"><span class="hljs-string">'JSONEachRow'</span></span>;</code> </pre><br>  2. <b>Agora vamos criar uma tabela real</b> onde colocaremos os dados finais: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> clickstream ( firstInSession UInt8, <span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span> UInt64, location <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, partyId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, sessionId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, pageViewId <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, eventType <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgentString <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree() <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> (<span class="hljs-built_in"><span class="hljs-built_in">timestamp</span></span>, pageViewId);</code> </pre> <br>  3. <b>E então forneceremos um relacionamento entre essas duas tabelas</b> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">MATERIALIZED</span></span> <span class="hljs-keyword"><span class="hljs-keyword">VIEW</span></span> clickstream_consumer <span class="hljs-keyword"><span class="hljs-keyword">TO</span></span> clickstream <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> clickstream_topic;</code> </pre> <br>  4. <b>E agora vamos selecionar os campos necessários</b> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> clickstream;</code> </pre> <br>  Como resultado, a escolha na tabela de destino nos dará o resultado que precisamos. <br><br><img src="https://habrastorage.org/webt/wn/sr/qe/wnsrqei2fo7iydrf41zattwbddy.png"><br><br>  Isso é tudo, foi o Clickstream mais simples que você pode criar.  Se você deseja concluir as etapas acima, <a href="https://www.youtube.com/watch%3Fv%3DNFjL8YQKuVg">assista ao vídeo</a> inteiro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt477834/">https://habr.com/ru/post/pt477834/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt477816/index.html">Como encontrar um emprego com um bom contrato</a></li>
<li><a href="../pt477818/index.html">Como se tornar um cientista de dados em 2019</a></li>
<li><a href="../pt477820/index.html">VMware, Hyper-V, OpenStack, Kubernetes, Swarm - monitorando a partir de uma única interface no Quest Foglight</a></li>
<li><a href="../pt477826/index.html">Visão geral e comparação das tecnologias V2X</a></li>
<li><a href="../pt477832/index.html">Como se dar bem com a geração Z</a></li>
<li><a href="../pt477836/index.html">Como testamos o WD ActiveScale P100 para nosso armazenamento S3</a></li>
<li><a href="../pt477838/index.html">Analisador estático PVS-Studio como ferramenta de proteção contra vulnerabilidades de dia zero</a></li>
<li><a href="../pt477840/index.html">Analisador de código estático PVS-Studio como proteção contra vulnerabilidades de dia zero</a></li>
<li><a href="../pt477844/index.html">5 etapas da ideia à aplicação prática de aprendizado de máquina com o SAP Data Intelligence</a></li>
<li><a href="../pt477846/index.html">Resumo de eventos para profissionais de RH em TI de dezembro de 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
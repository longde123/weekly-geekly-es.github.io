<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëî üï° ‚ìÇÔ∏è Implementando modelos seq2seq no Tensorflow „Ä∞Ô∏è üçè üéí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A gera√ß√£o de dados usando uma rede neural recorrente est√° se tornando um m√©todo cada vez mais popular e est√° sendo usada em muitas √°reas da ci√™ncia da...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implementando modelos seq2seq no Tensorflow</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440472/"><p>  A gera√ß√£o de dados usando uma rede neural recorrente est√° se tornando um m√©todo cada vez mais popular e est√° sendo usada em muitas √°reas da ci√™ncia da computa√ß√£o.  Desde o in√≠cio do nascimento do conceito seq2seq em 2014, apenas cinco anos se passaram, mas o mundo viu muitas aplica√ß√µes, come√ßando com os modelos cl√°ssicos de tradu√ß√£o e reconhecimento de fala e terminando com a gera√ß√£o de descri√ß√µes de objetos em fotografias. </p><br><p> Por outro lado, com o tempo, a biblioteca Tensorflow, lan√ßada pelo Google especificamente para o desenvolvimento de redes neurais, ganhou popularidade.  Naturalmente, os desenvolvedores do Google n√£o podiam ignorar um paradigma t√£o popular como o seq2seq; portanto, a biblioteca Tensorflow fornece classes para desenvolvimento dentro desse paradigma.  Este artigo descreve este sistema de classes. </p><a name="habracut"></a><br><h2 id="rekurentnye-seti">  Redes Recorrentes </h2><br><p>  Atualmente, as redes recorrentes s√£o um dos formalismos mais conhecidos e pr√°ticos para a constru√ß√£o de redes neurais profundas.  As redes recursivas s√£o projetadas para processar dados seriais; portanto, diferentemente de uma c√©lula normal (neur√¥nio), que recebe dados como entrada e produz o resultado de c√°lculos, uma c√©lula recursiva cont√©m duas entradas e duas sa√≠das. </p><br><p>  Uma das entradas representa os dados do elemento atual da sequ√™ncia e a segunda entrada √© chamada de <i>estado</i> e √© transmitida como resultado dos c√°lculos de c√©lula no elemento anterior da sequ√™ncia. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/684/601/aa6/684601aa63886d86a1b4dafcf8ab079c.png" width="100" alt="imagem"><br><p>  A figura mostra a c√©lula A, para a qual os dados de um elemento de sequ√™ncia s√£o inseridos <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-1"> x_t </script>  bem como a condi√ß√£o n√£o indicada aqui <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.017ex" height="1.937ex" viewBox="0 -520.7 1729.5 834" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-73" x="0" y="0"></use><g transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMAIN-31" x="1140" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-2"> s_ {t-1} </script>  .  Na sa√≠da, a c√©lula A fornece o estado <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.916ex" height="1.817ex" viewBox="0 -520.7 825.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-74" x="663" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> s_t </script>  e o resultado do c√°lculo <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>h</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.165ex" height="2.419ex" viewBox="0 -780.1 932.1 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-74" x="815" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> h_t </script>  . </p><br><p>  Na pr√°tica, a sequ√™ncia de dados √© geralmente dividida em subsequ√™ncias de um determinado comprimento fixo e passada para o c√°lculo por subconjuntos inteiros (lotes).  Em outras palavras, as subsequ√™ncias s√£o exemplos de aprendizado.  As entradas, sa√≠das e estados das c√©lulas de uma rede recursiva s√£o sequ√™ncias de n√∫meros reais.  Para c√°lculo de entrada <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mn>1</mn></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.384ex" height="1.696ex" viewBox="0 -520.7 1026.4 730.2" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhjZm8WIj2iSfJK4M3zjXR0aqvvoXA#MJMAIN-31" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> x_1 </script>  √© necess√°rio usar um estado que n√£o foi o resultado de um c√°lculo em uma determinada sequ√™ncia de dados.  Tais estados s√£o chamados estados iniciais.  Se a sequ√™ncia for longa o suficiente, faz sentido manter o contexto dos c√°lculos em cada subsequ√™ncia.  Nesse caso, √© poss√≠vel transmitir o √∫ltimo estado calculado na sequ√™ncia anterior como o estado inicial.  Se a sequ√™ncia n√£o for t√£o longa ou a subsequ√™ncia for o primeiro segmento, voc√™ poder√° inicializar o estado inicial com zeros. </p><br><p>  No momento, para treinar redes neurais em quase todos os lugares, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">√© utilizado</a> o algoritmo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">propaga√ß√£o traseira de erros</a> .  O resultado do c√°lculo no conjunto de exemplos transmitidos (no nosso caso, o conjunto de subsequ√™ncias) √© verificado em rela√ß√£o ao resultado esperado (dados marcados).  A diferen√ßa entre os valores reais e esperados √© chamada de erro e esse erro √© propagado para os pesos da rede na dire√ß√£o oposta.  Assim, a rede se adapta aos dados rotulados e, como regra, o resultado dessa adapta√ß√£o funciona bem para os dados que a rede n√£o encontrou nos exemplos de treinamento inicial (hip√≥tese de generaliza√ß√£o). </p><br><p>  No caso de uma rede recursiva, temos v√°rias op√ß√µes em quais sa√≠das considerar o erro.  Vamos descrever aqui dois principais: </p><br><ol><li>  Voc√™ pode considerar o erro comparando a sa√≠da da √∫ltima c√©lula da subsequ√™ncia com a sa√≠da esperada.  Isso funciona bem para a tarefa de classifica√ß√£o.  Por exemplo, precisamos determinar a colora√ß√£o emocional de um tweet.  Para isso, selecionamos os tweets e os marcamos em tr√™s categorias: negativo, positivo e neutro.  A sa√≠da da c√©lula ser√° de tr√™s n√∫meros - o peso das categorias.  O tweet tamb√©m ser√° marcado com tr√™s n√∫meros - as probabilidades de o tweet pertencer √† categoria correspondente.  Depois de calcular o erro em um subconjunto dos dados, voc√™ pode propag√°-lo pela sa√≠da ou pelo estado que desejar. </li><li>  Voc√™ pode ler o erro imediatamente nas sa√≠das do c√°lculo da c√©lula para cada elemento da subsequ√™ncia.  Isso √© adequado para a tarefa de prever o pr√≥ximo elemento de uma sequ√™ncia dos anteriores.  Essa abordagem pode ser usada, por exemplo, no problema de determinar anomalias em s√©ries temporais de dados ou na tarefa de prever o pr√≥ximo caractere em um texto, para ger√°-lo posteriormente.  A propaga√ß√£o de erros tamb√©m √© poss√≠vel atrav√©s de estados ou sa√≠das. </li></ol><br><p>  Ao contr√°rio de uma rede neural regular totalmente conectada, uma rede recursiva √© profunda no sentido de que o erro se propaga n√£o apenas das sa√≠das da rede para seus pesos, mas tamb√©m para a esquerda, atrav√©s de conex√µes entre estados.  A profundidade da rede √© assim determinada pelo comprimento da subsequ√™ncia.  Para propagar o erro pelo estado da rede recursiva, existe um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">algoritmo</a> especial.  Sua caracter√≠stica √© que os gradientes dos pesos se multiplicam quando o erro se propaga da direita para a esquerda.  Se o erro inicial for maior que a unidade, como resultado, o erro poder√° se tornar muito grande.  Por outro lado, se o erro inicial for menor que a unidade, em algum lugar no in√≠cio da sequ√™ncia, o erro poder√° desaparecer.  Essa situa√ß√£o na teoria das redes neurais √© chamada de carrossel de erro padr√£o.  Para evitar tais situa√ß√µes durante o treinamento, foram inventadas c√©lulas especiais que n√£o apresentam tais desvantagens.  A primeira c√©lula desse tipo foi o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LSTM</a> , agora existe uma ampla gama de alternativas, das quais a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GRU</a> mais popular. </p><br><p>  Uma boa introdu√ß√£o √†s redes de recorr√™ncia pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste artigo</a> .  Outra fonte bem conhecida √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> do blog de Andrey Karpaty. </p><br><p>  A biblioteca Tensorflow possui muitas classes e fun√ß√µes para implementar redes recursivas.  Aqui est√° um exemplo de cria√ß√£o de uma rede recursiva din√¢mica baseada em uma c√©lula do tipo GRU: </p><br><pre><code class="python hljs">cell = tf.contrib.rnn.GRUCell(dimension) outputs, state = tf.nn.dynamic_rnn(cell, input, sequence_length=input_length, dtype=tf.float32)</code> </pre> <br><p>  Neste exemplo, uma c√©lula GRU √© criada, que √© usada para criar uma rede recursiva din√¢mica.  O tensor dos dados de entrada e os comprimentos reais das subsequ√™ncias s√£o transmitidos para a rede.  Os dados de entrada s√£o sempre especificados por um vetor de n√∫meros reais.  Para um √∫nico valor, por exemplo, um c√≥digo de s√≠mbolo ou uma palavra, o chamado  incorpora√ß√£o - mapeando esse c√≥digo para alguma sequ√™ncia de n√∫meros.  A fun√ß√£o de criar uma rede recursiva din√¢mica retorna um par de valores: uma lista de sa√≠das de rede para todos os valores da sequ√™ncia e o √∫ltimo estado calculado.  Como entrada, a fun√ß√£o pega uma c√©lula, dados de entrada e um tensor de comprimento de subsequ√™ncia. </p><br><p>  Uma rede din√¢mica recursiva difere de uma est√°tica, pois n√£o cria uma rede de c√©lulas de rede para a subsequ√™ncia antecipadamente (no est√°gio de determina√ß√£o do gr√°fico de c√°lculo), mas inicia as c√©lulas nas entradas dinamicamente durante o c√°lculo do gr√°fico nos dados de entrada.  Portanto, essa fun√ß√£o precisa conhecer os comprimentos das subsequ√™ncias dos dados de entrada para parar no momento certo. </p><br><h2 id="porozhdayuschie-modeli-na-osnove-rekurentnyh-setey">  Gerando modelos baseados em redes de recorr√™ncia </h2><br><h3 id="porozhdayuschie-rekurentnye-seti">  Gerando redes de recorr√™ncia </h3><br><p>  Antes, consideramos dois m√©todos para calcular os erros de redes recursivas: na √∫ltima sa√≠da ou em todas as sa√≠das para uma determinada sequ√™ncia.  Aqui consideramos o problema de gerar sequ√™ncias.  O treinamento da rede de geradores √© baseado no segundo m√©todo acima. </p><br><p>  Mais detalhadamente, estamos tentando treinar uma rede recursiva para prever o pr√≥ximo elemento de uma sequ√™ncia.  Como mencionado acima, a sa√≠da de uma c√©lula em uma rede recursiva √© simplesmente uma sequ√™ncia de n√∫meros.  Como esse vetor n√£o √© muito conveniente para o aprendizado, eles introduzem outro n√≠vel, que recebe esse vetor na entrada e na sa√≠da, dando o peso das previs√µes.  Esse n√≠vel √© chamado de <em>n√≠vel de proje√ß√£o</em> e permite comparar a sa√≠da da c√©lula em um determinado elemento da sequ√™ncia com a sa√≠da esperada nos dados rotulados. </p><br><p>  Para ilustrar, considere a tarefa de gerar texto representado como uma sequ√™ncia de caracteres.  O comprimento do vetor de sa√≠da do n√≠vel de proje√ß√£o √© igual ao tamanho do alfabeto do texto de origem.  O tamanho do alfabeto geralmente n√£o excede 150 caracteres, se voc√™ contar os caracteres dos idiomas russo e ingl√™s, al√©m de sinais de pontua√ß√£o.  A sa√≠da do n√≠vel de proje√ß√£o √© um vetor com o comprimento do alfabeto, em que cada s√≠mbolo corresponde a uma determinada posi√ß√£o nesse vetor - o √≠ndice desse s√≠mbolo.  Os dados rotulados tamb√©m s√£o um vetor que consiste em zeros, onde um fica na posi√ß√£o do caractere ap√≥s a sequ√™ncia. </p><br><p>  Para o treinamento, usamos duas seq√º√™ncias de dados: </p><br><ol><li>  Uma sequ√™ncia de caracteres no texto de origem, no in√≠cio do qual √© adicionado um caractere especial que n√£o faz parte do texto de origem.  √â geralmente referido como <em>ir</em> . </li><li>  A sequ√™ncia de caracteres do texto de origem como est√°, sem acr√©scimos. </li></ol><br><p>  Exemplo para o texto "m√£e lavou o quadro": </p><br><pre> <code class="python hljs">[<span class="hljs-string"><span class="hljs-string">'&lt;go&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">'] ['</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]</code> </pre> <br><p>  Para o treinamento, minibatches geralmente s√£o formados, consistindo em um pequeno n√∫mero de exemplos.  No nosso caso, essas s√£o cadeias que podem ter comprimentos diferentes.  O c√≥digo descrito abaixo usa o seguinte m√©todo para resolver o problema de diferentes comprimentos.  Das muitas linhas neste minipacote, o comprimento m√°ximo √© calculado.  Todas as outras linhas s√£o preenchidas com um caractere especial (preenchimento), para que todos os exemplos no minipacket tenham o mesmo comprimento.  No exemplo de c√≥digo abaixo, a cadeia de <em>pad</em> √© usada como um caractere.  Al√©m disso, para uma melhor gera√ß√£o, no final do exemplo, adicione o s√≠mbolo do final da frase - <em>eos</em> .  Assim, na realidade, os dados do exemplo ser√£o um pouco diferentes: </p><br><pre> <code class="python hljs">[<span class="hljs-string"><span class="hljs-string">'&lt;go&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;eos&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">'] ['</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;eos&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>]</code> </pre> <br><p>  A primeira sequ√™ncia √© alimentada na entrada da rede e a segunda sequ√™ncia √© usada como dados marcados.  O treinamento de previs√£o √© baseado no deslocamento da sequ√™ncia original de um caractere para a esquerda. </p><br><h3 id="obuchenie-i-porozhdenie">  Treinamento e desova </h3><br><h4 id="obuchenie">  Treinamento </h4><br><p>  O algoritmo de aprendizado √© bastante simples.  Para cada elemento da sequ√™ncia de entrada, calculamos o vetor de sa√≠da do seu n√≠vel de proje√ß√£o e o comparamos com o marcado.  A √∫nica quest√£o √© como calcular o erro.  Voc√™ pode usar o erro quadr√°tico m√©dio da raiz, mas para calcular o erro nessa situa√ß√£o, √© melhor usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a entropia cruzada</a> .  A biblioteca Tensorflow fornece v√°rias fun√ß√µes para seu c√°lculo, embora n√£o haja nada que interrompa a implementa√ß√£o da f√≥rmula de c√°lculo diretamente no c√≥digo. </p><br><p>  Para maior clareza, apresentamos algumas nota√ß√µes.  Por symbol_id, indicaremos o identificador do s√≠mbolo (seu n√∫mero de s√©rie no alfabeto).  O termo s√≠mbolo aqui √© bastante arbitr√°rio e significa simplesmente um elemento do alfabeto.  O alfabeto pode n√£o conter s√≠mbolos, mas palavras ou mesmo alguns conjuntos de atributos mais complexos.  O termo symbol_embedding ser√° usado para denotar o vetor de n√∫meros correspondentes a um determinado elemento do alfabeto.  Normalmente, esses conjuntos de n√∫meros s√£o armazenados em uma tabela de tamanhos que corresponde ao tamanho do alfabeto. </p><br><p>  O Tensorflow fornece um recurso que permite acessar a tabela de incorpora√ß√£o e substituir os √≠ndices de caracteres pelos vetores de incorpora√ß√£o.  Primeiro, definimos uma vari√°vel para armazenar a tabela: </p><br><pre> <code class="python hljs">embedding_table = tf.Variable(tf.random_uniform([alphabet_size, embedding_size]))</code> </pre> <br><p>  Depois disso, voc√™ pode converter os tensores de entrada em incorporadores: </p><br><pre> <code class="python hljs">input_embeddings = tf.nn.embedding_lookup(embedding_table, input_ids)</code> </pre> <br><p>  O resultado da chamada de fun√ß√£o √© um tensor da mesma dimens√£o que foi transferida para a entrada, mas como resultado, todos os √≠ndices de caracteres s√£o substitu√≠dos pelas sequ√™ncias de incorpora√ß√£o correspondentes. </p><br><h4 id="porozhdenie">  Spawn </h4><br><p>  Para calcular, uma c√©lula de uma rede recursiva precisa de um estado e do caractere atual.  O resultado do c√°lculo √© uma sa√≠da e um novo estado.  Se aplicarmos o n√≠vel de proje√ß√£o √† sa√≠da, podemos obter um vetor de pesos em que o peso na posi√ß√£o correspondente pode ser considerado (muito condicionalmente) como a probabilidade desse s√≠mbolo aparecer na pr√≥xima posi√ß√£o na sequ√™ncia. </p><br><p>  V√°rias estrat√©gias podem ser usadas para selecionar o pr√≥ximo s√≠mbolo com base no vetor de peso gerado pelo n√≠vel de proje√ß√£o: </p><br><ul><li>  Estrat√©gia de busca gananciosa.  Cada vez que selecionamos o s√≠mbolo com o maior peso, ou seja,  provavelmente nesta situa√ß√£o, mas n√£o necessariamente o mais apropriado no contexto de toda a sequ√™ncia. </li><li>  Estrat√©gia para escolher a melhor sequ√™ncia (busca por feixe).  N√£o selecionamos um s√≠mbolo de uma vez, mas lembre-se de v√°rias variantes dos s√≠mbolos mais prov√°veis.  Depois que todas essas op√ß√µes s√£o calculadas para todos os elementos da sequ√™ncia gerada, selecionamos a sequ√™ncia de caracteres mais prov√°vel, levando em considera√ß√£o o contexto de toda a sequ√™ncia.  Geralmente, isso √© realizado por meio de uma matriz cuja largura √© igual ao comprimento da sequ√™ncia e a altura ao n√∫mero de variantes de caracteres geradores (largura de busca da viga).  Ap√≥s a gera√ß√£o das variantes de sequ√™ncia, uma das variantes do algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Viterbi</a> √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">usada</a> para selecionar a sequ√™ncia mais prov√°vel. </li></ul><br><h2 id="sistema-tipov-seq2seq-v-biblioteke-tensorflow">  Sistema de tipo seq2seq da biblioteca Tensorflow </h2><br><p>  Diante do exposto, fica claro que a implementa√ß√£o de modelos generativos baseados em redes de recorr√™ncia √© uma tarefa bastante dif√≠cil de codificar.  Portanto, naturalmente, foram propostos sistemas de classes para facilitar a solu√ß√£o desse problema.  Um desses sistemas √© chamado seq2seq, depois descrevemos a funcionalidade de seus principais tipos. </p><br><p>  Mas, antes de tudo, algumas palavras sobre o nome da biblioteca.  O nome seq2seq √© a abrevia√ß√£o de sequ√™ncia para sequ√™ncia (de sequ√™ncia para sequ√™ncia).  A id√©ia original de gerar uma sequ√™ncia foi proposta para implementar um sistema de tradu√ß√£o.  A sequ√™ncia de entrada de palavras foi alimentada na entrada de uma rede recursiva, chamada codificador neste sistema.  A sa√≠da dessa rede recursiva foi o estado do c√°lculo da c√©lula no √∫ltimo caractere da sequ√™ncia.  Esse estado foi apresentado como o estado inicial da segunda rede recursiva, o decodificador, treinado para gerar a pr√≥xima palavra.  As palavras foram usadas como s√≠mbolos nas duas redes.  Erros no decorador foram propagados para o codificador atrav√©s do estado transmitido.  O pr√≥prio vetor de estado nessa terminologia foi chamado de vetor de pensamento.  A apresenta√ß√£o intermedi√°ria foi usada nos modelos de tradu√ß√£o tradicionais e, como regra, era um gr√°fico representando a estrutura do texto de entrada para tradu√ß√£o.  O sistema de tradu√ß√£o gerou texto de sa√≠da com base nessa estrutura intermedi√°ria. </p><br><p>  Na verdade, a implementa√ß√£o do seq2seq no Tensorflow pertence √† parte do decodificador, sem afetar o codificador.  Portanto, seria correto chamar a biblioteca 2seq, mas a for√ßa da tradi√ß√£o e a in√©rcia do pensamento aqui prevaleceram obviamente sobre o senso comum. </p><br><p>  Os dois principais metatipos na biblioteca seq2seq s√£o: </p><br><ol><li>  Classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">auxiliar</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Decodificador de</a> classe. </li></ol><br><p>  Os desenvolvedores da biblioteca identificaram esses tipos com base nas seguintes considera√ß√µes.  Vamos considerar o processo de aprendizagem e o processo de gera√ß√£o, que descrevemos acima, de um √¢ngulo ligeiramente diferente. </p><br><p>  Para o treinamento, voc√™ precisa: </p><br><ol><li>  Para cada caractere, passe o c√°lculo do estado atual e a incorpora√ß√£o do caractere atual. </li><li>  Lembre-se do estado de sa√≠da e da proje√ß√£o calculada para a sa√≠da. </li><li>  Obtenha o pr√≥ximo caractere na sequ√™ncia e v√° para a etapa 1. </li></ol><br><p>  Depois disso, voc√™ pode come√ßar a contar erros comparando os resultados dos c√°lculos com os seguintes caracteres da sequ√™ncia. </p><br><p>  Para ger√°-lo √© necess√°rio: </p><br><ol><li>  Para cada caractere, passe o c√°lculo do estado atual e a incorpora√ß√£o do caractere atual. </li><li>  Lembre-se do estado de sa√≠da e da proje√ß√£o calculada para a sa√≠da. </li><li>  Calcule o pr√≥ximo caractere como o m√°ximo dos √≠ndices do n√≠vel de proje√ß√£o e v√° para a etapa 1. </li></ol><br><p>  Como pode ser visto na descri√ß√£o, os algoritmos s√£o muito semelhantes.  Portanto, os desenvolvedores da biblioteca decidiram encapsular o procedimento para obter o pr√≥ximo caractere na classe Helper.  Para o treinamento, basta ler o pr√≥ximo caractere da sequ√™ncia e, para ger√°-lo, selecionar o caractere com o peso m√°ximo (√© claro, para pesquisas gananciosas). </p><br><p>  Portanto, a classe base Helper implementa o m√©todo next_inputs para obter o pr√≥ximo caractere do estado atual e do estado, bem como o m√©todo de amostra para obter √≠ndices de caracteres no n√≠vel de proje√ß√£o.  A classe TrainingHelper √© fornecida para treinamento, e a classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GreedyEmbeddingHelper</a> est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dispon√≠vel</a> para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gera√ß√£o</a> gananciosa.  Infelizmente, o modelo de pesquisa de vigas n√£o se encaixa nesse sistema de tipos, portanto, uma classe especial <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">BeamSearchDecoder √©</a> implementada na biblioteca para isso.  n√£o usando o Helper. </p><br><p>  A classe Decoder fornece uma interface para implementar um decodificador.  De fato, a classe fornece dois m√©todos: </p><br><ol><li>  inicialize para inicializar no in√≠cio do trabalho. </li><li>  etapa para implementar uma etapa ou gera√ß√£o de aprendizado.  O conte√∫do desta etapa √© determinado pelo auxiliar correspondente. </li></ol><br><p>  A biblioteca implementa a classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">BasicDecoder</a> , que pode ser usada para treinamento e cria√ß√£o com os assistentes TrainingHelper e GreedyEmbeddingHelper.  Essas tr√™s classes geralmente s√£o suficientes para implementar modelos de gera√ß√£o baseados em redes de recorr√™ncia. </p><br><p>  Finalmente, as fun√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dynamic_decode</a> s√£o usadas para organizar a passagem por uma entrada ou sequ√™ncia gerada. </p><br><p>  A seguir, consideraremos um exemplo ilustrativo, que mostra m√©todos para construir modelos de gera√ß√£o para v√°rios tipos de biblioteca seq2seq. </p><br><h2 id="illyustrativnyy-primer">  Exemplo ilustrativo </h2><br><p>  Antes de tudo, deve-se dizer que todos os exemplos s√£o implementados no Python 2.7.  Uma lista de bibliotecas adicionais pode ser encontrada no arquivo requirements.txt. </p><br><p>  Como exemplo ilustrativo, considere parte dos dados do concurso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Desafio de normaliza√ß√£o de texto - idioma russo</a> realizado pela Kaggle pelo Google em 2017.  O objetivo deste concurso era converter o texto em russo em um formato adequado para leitura.  O texto do concurso foi dividido em express√µes digitadas.  Os dados do treinamento foram especificados em um arquivo CSV do seguinte formato: </p><br><pre> <code class="plaintext hljs">"sentence_id","token_id","class","before","after" 0,0,"PLAIN","","" 0,1,"PLAIN","","" 0,2,"PLAIN","","" 0,3,"DATE","1862 ","    " 0,4,"PUNCT",".","." 1,0,"PLAIN","","" 1,1,"PLAIN","","" 1,2,"PLAIN","","" 1,3,"PLAIN","","" 1,4,"PLAIN","","" 1,5,"PLAIN","","" 1,6,"PLAIN","","" 1,7,"PLAIN","","" 1,8,"PLAIN","","" 1,9,"PUNCT",".","." ...</code> </pre> <br><p>  No exemplo acima, uma express√£o do tipo DATE √© interessante; nela, "1862" √© traduzido em "mil oitocentos e sessenta e dois anos".  Para ilustrar, consideramos os dados do tipo DATE apenas como pares do formul√°rio (express√£o anterior, express√£o posterior).  In√≠cio do arquivo de dados: </p><br><pre> <code class="plaintext hljs">before,after 1862 ,     1811 ,    12  2013,      15  2013,      1905 ,    17  2014,      7  2010 ,      1 ,  1843 ,     30  2007 ,      1846 ,     1996 ,     9 ,  ...</code> </pre> <br><p>  Construiremos o modelo de gera√ß√£o usando a biblioteca seq2seq, na qual o codificador ser√° implementado no n√≠vel do s√≠mbolo (ou seja, os elementos do alfabeto s√£o s√≠mbolos) e o decodificador usar√° as palavras como alfabeto.  C√≥digo de exemplo, como dados, est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reposit√≥rio no Github</a> . </p><br><p>  Os dados do treinamento s√£o divididos em tr√™s subconjuntos: train.csv, test.csv e dev.csv, para verifica√ß√£o de treinamento, teste e reciclagem, respectivamente.  Os dados est√£o no diret√≥rio de dados.  Tr√™s modelos s√£o implementados no reposit√≥rio: seq2seq_greedy.py, seq2seq_attention.py e seq2seq_beamsearch.py.  Aqui, examinamos o c√≥digo para o modelo b√°sico de pesquisa gananciosa. </p><br><p>  Todos os modelos usam a classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estimator</a> para implementar.  O uso dessa classe permite simplificar a codifica√ß√£o sem se distrair com pe√ßas que n√£o s√£o do modelo.  Por exemplo, n√£o h√° necessidade de implementar um ciclo de transfer√™ncia de dados para treinamento, criar sess√µes para trabalhar com o Tensorflow, pensar em transferir dados para o Tensorboard, etc.  O Estimador requer apenas duas fun√ß√µes para sua implementa√ß√£o: para transfer√™ncia de dados e para a constru√ß√£o de um modelo.  Os exemplos tamb√©m usam a classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Dataset</a> para transmitir dados para processamento.  Essa implementa√ß√£o moderna √© muito mais r√°pida que os dicion√°rios tradicionais para transferir dados no formul√°rio feed_dict. </p><br><h3 id="formirovanie-dannyh">  Gera√ß√£o de dados </h3><br><p>  Considere um c√≥digo de gera√ß√£o de dados para treinamento e gera√ß√£o. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse_fn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(line_before, line_after)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Encode in Bytes for TF source = [c.encode('utf8') for c in line_before.decode('utf8').rstrip('\n')] t = [w.encode('utf8') for w in nltk.word_tokenize(line_after.decode('utf8').strip())] learn_target = t + ['&lt;eos&gt;'] + ['&lt;pad&gt;'] target = ['&lt;go&gt;'] + t + ['&lt;eos&gt;'] return (source, len(source)), (target, learn_target, len(target)) def generator_fn(data_file): with open(data_file, 'rb') as f: reader = csv.DictReader(f, delimiter=',', quotechar='"') for row in reader: yield parse_fn(row['before'], row['after']) def input_fn(data_file, params=None): params = params if params is not None else {} shapes = (([None], ()), ([None], [None], ())) types = ((tf.string, tf.int32), (tf.string, tf.string, tf.int32)) defaults = (('&lt;pad&gt;', 0), ('&lt;pad&gt;', '&lt;pad&gt;', 0)) dataset = tf.data.Dataset.from_generator(functools.partial(generator_fn, data_file), output_shapes=shapes, output_types=types) dataset = dataset.repeat(params['epochs']) return (dataset.padded_batch(params.get('batch_size', 50), shapes, defaults).prefetch(1))</span></span></code> </pre> <br><p>  A fun√ß√£o input_fn √© usada para criar uma cole√ß√£o de dados que o Estimator passa para treinamento e gera√ß√£o.  O tipo de dados √© definido primeiro.  Este √© um par da forma ((sequ√™ncia do codificador, comprimento), (sequ√™ncia do decodificador, sequ√™ncia do decodificador com um prefixo, comprimento)).  A string "" √© usada como prefixo, cada sequ√™ncia do codificador termina com uma palavra especial "".  Al√©m disso, devido ao fato de as seq√º√™ncias (entrada e sa√≠da) terem um comprimento desigual, o s√≠mbolo de preenchimento com o valor "" √© usado. <br></p><p>  O c√≥digo de prepara√ß√£o de dados l√™ o arquivo de dados, divide a string do codificador em caracteres e a string do decodificador em palavras, usando a biblioteca nltk para isso.  Uma linha processada dessa maneira √© um exemplo de dados de treinamento.  A cole√ß√£o gerada √© dividida em minipacotes e a quantidade de dados √© clonada de acordo com o n√∫mero de eras de treinamento (cada √©poca √© uma passagem de dados). </p><br><h3 id="rabota-so-slovaryami">  Trabalhar com dicion√°rios </h3><br><p>  Os dicion√°rios s√£o armazenados como uma lista em arquivos, uma linha para uma palavra ou caractere.  Para construir dicion√°rios, use o script build_vocabs.py.  Os dicion√°rios gerados est√£o localizados no diret√≥rio de dados como arquivos no formato vocab. *. Txt. </p><br><p>  C√≥digo para leitura de dicion√°rios: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Read vocabs and inputs dropout = params['dropout'] source, source_length = features training = (mode == tf.estimator.ModeKeys.TRAIN) vocab_source = tf.contrib.lookup.index_table_from_file(vocabulary_file=params['source_vocab_file'], num_oov_buckets=params['num_oov_buckets']) with open(params['source_vocab_file']) as f: num_sources = sum(1 for _ in f) + params['num_oov_buckets'] vocab_target = tf.contrib.lookup.index_table_from_file(vocabulary_file=params['target_vocab_file'], num_oov_buckets=params['num_oov_buckets']) with open(params['target_vocab_file']) as f: num_targets = sum(1 for _ in f) + params['num_oov_buckets']</span></span></code> </pre> <br><p>  Aqui, provavelmente, a fun√ß√£o index_table_from_file, que l√™ entradas de dicion√°rio de um arquivo, √© interessante e seu par√¢metro num_oov_buckets √© o n√∫mero de cestas fora do vocabul√°rio.  Por padr√£o, esse n√∫mero √© igual a um, ou seja,  todas as palavras que n√£o est√£o no dicion√°rio t√™m o mesmo √≠ndice igual ao tamanho do dicion√°rio + 1. Temos tr√™s palavras desconhecidas: "", "" e "", para as quais queremos ter √≠ndices diferentes.  Portanto, defina esse par√¢metro como o n√∫mero tr√™s.  Infelizmente, voc√™ precisa ler o arquivo de entrada novamente para obter o n√∫mero de palavras no dicion√°rio como uma constante de tempo para definir o gr√°fico do modelo. <br></p><p>  Ainda precisamos criar uma tabela para implementar a incorpora√ß√£o - _source_embedding, bem como converter cadeias de palavras em cadeias de identifica√ß√£o: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># source embeddings matrix _source_embedding = tf.Variable(tf.random_uniform([num_sources, params['embedding_size']])) source_ids = vocab_source.lookup(source) source_embedding = tf.nn.embedding_lookup(_source_embedding, source_ids)</span></span></code> </pre> <br><h3 id="realizaciya-kodirovschika">  Implementa√ß√£o do codificador </h3><br><p>  Para o codificador, usaremos uma rede recursiva bidirecional com v√°rios n√≠veis.     ,     ,      . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># add multilayer bidirectional RNN cell_fw = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) cell_bw = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, source_embedding, sequence_length=source_length, dtype=tf.float32) # prepare output output = tf.concat(outputs, axis=-1) encoder_output = tf.layers.dense(output, params['dim']) # prepare state state_fw, state_bw = states cells = [] for fw, bw in zip(state_fw, state_bw): state = tf.concat([fw, bw], axis=-1) cells += [tf.layers.dense(state, params['dim'])] encoder_state = tuple(cells)</span></span></code> </pre> <br><p>       GRU,    MultiRNNCell,   ,   rnn.Cell.    , <br> sequence_length ‚Äî     ,     ,    . </p><br><p> ,       ,       ,           .      ,      128,        256.     ,        ,      128.        . </p><br><p>     .  Porque    , ,    bidirectional_dynamic_rnn,   ,     .           ,      .     , ..       . , ,  .            ,   ,       . </p><br><h3 id="realizaciya-dekodirovschika">   </h3><br><p>     ,    .           . </p><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># decoder RNN cell decoder_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) decoder_initial_state = encoder_state # projection layer projection_layer = tf.layers.Dense(num_targets, use_bias=False) # embedding table for targets target_embedding = tf.Variable(tf.random_uniform([num_targets, params['embedding_size']]))</span></span></code> </pre> <br><h4 id="obuchenie-1">  </h4><br><p>    TrainingHelper + BasicDecoder. </p><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># target embeddings matrix target, learn_target, target_length = labels target_ids = vocab_target.lookup(target) target_learn_ids = vocab_target.lookup(learn_target) # train encoder _target_embedding = tf.nn.embedding_lookup(target_embedding, target_ids) train_helper = tf.contrib.seq2seq.TrainingHelper(_target_embedding, target_length) train_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, train_helper, decoder_initial_state, output_layer=projection_layer) train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(train_decoder) train_output = train_outputs.rnn_output train_sample_id = train_outputs.sample_id</span></span></code> </pre> <br><h4 id="porozhdenie-1">  </h4><br><p>        . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># prediction decoder prediction_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper( embedding=target_embedding, start_tokens=tf.fill([batch_size], tf.to_int32(vocab_target.lookup(tf.fill([], '&lt;go&gt;')))), end_token=tf.to_int32(vocab_target.lookup(tf.fill([], '&lt;eos&gt;')))) prediction_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, prediction_helper, decoder_initial_state, output_layer=projection_layer) prediction_output, _, _ = tf.contrib.seq2seq.dynamic_decode(prediction_decoder, maximum_iterations=params['max_iters']) # prepare prediction reverse_vocab_target = tf.contrib.lookup.index_to_string_table_from_file(params['target_vocab_file']) pred_strings = reverse_vocab_target.lookup(tf.to_int64(prediction_output.sample_id)) predictions = { 'ids': prediction_output.sample_id, 'text': pred_strings }</span></span></code> </pre> <br><p>     GreedyEmbeddingHelper       "",     "".        . , ,    dynamic_decode      .    ,    ,   . ,     ,        . <br><br></p><h4 id="funkciya-poter-i-optimizaciya">     </h4><br><p>     ,        seq2seq. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># loss masks = tf.sequence_mask(lengths=target_length, dtype=tf.float32) loss = tf.contrib.seq2seq.sequence_loss(logits=train_output, targets=target_learn_ids, weights=masks)</span></span></code> </pre> <br><p>    ,     ,      sequence_mask. </p><br><p>     Adam   ,   . </p><br><pre> <code class="python hljs">optimizer = tf.train.AdamOptimizer(learning_rate=params.get(<span class="hljs-string"><span class="hljs-string">'lr'</span></span>, <span class="hljs-number"><span class="hljs-number">.001</span></span>)) grads, vs = zip(*optimizer.compute_gradients(loss)) grads, gnorm = tf.clip_by_global_norm(grads, params.get(<span class="hljs-string"><span class="hljs-string">'clip'</span></span>, <span class="hljs-number"><span class="hljs-number">.5</span></span>)) train_op = optimizer.apply_gradients(zip(grads, vs), global_step=tf.train.get_or_create_global_step())</code> </pre> <br><h4 id="rezultaty-obucheniya">   </h4><br><p>         .     0.9   . , ,     ,    .   ,    . </p><br><pre> <code class="plaintext hljs">24  1944                 1  2003              1992 .           11  1927               1969            1  2016             1047          1863            17      22  2014              </code> </pre> <br><p>        .   ‚Äî   ,   ‚Äî  ,   ‚Äî  . </p><br><p>  ,    ‚Äî   .             .    ,    ( ),       .       .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>        ,     . </p><br><h2 id="zaklyuchenie">  Conclus√£o </h2><br><p>            seq2seq.      ,          ,     .    ,  . </p><br><p>           .  Tensorflow   ,   ,     .   ,         ,   .        ,        . ,      ,   padding  ,   embedding     ?       , ,       .         ‚Äî     . ,    ,    . ,    ,    ,    . ,       . ,          , , ,        . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440472/">https://habr.com/ru/post/pt440472/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440462/index.html">As 7 principais estrat√©gias de marketing de conte√∫do a n√£o perder em 2019</a></li>
<li><a href="../pt440464/index.html">Trabalhar com o servi√ßo Digital Ocean Managed Databases no .NET Core</a></li>
<li><a href="../pt440466/index.html">Controle remoto Web UART</a></li>
<li><a href="../pt440468/index.html">2 vezes mais, 10 vezes mais r√°pido, 24 horas por dia - tudo pelo bem das pessoas</a></li>
<li><a href="../pt440470/index.html">Incorporar um int√©rprete Python em um aplicativo java usando o projeto Panama</a></li>
<li><a href="../pt440474/index.html">Efeitos de filtragem SVG. Parte 4. Imagens em duas cores com feComponentTransfer</a></li>
<li><a href="../pt440476/index.html">"Comece com mitaps", ou Voc√™ precisa de cursos de programa√ß√£o?</a></li>
<li><a href="../pt440478/index.html">3CX v16 Beta 1 com suporte ao Raspberry Pi</a></li>
<li><a href="../pt440486/index.html">Pre√ßo da qualidade: 7 princ√≠pios para otimizar os custos dos testes</a></li>
<li><a href="../pt440488/index.html">Mapas de Sombra Reflexiva: Parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
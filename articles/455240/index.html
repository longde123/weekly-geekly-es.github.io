<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèº üö• üò≥ Uso de la tasa de defectos rechazados para mejorar el informe de errores üè¥‚Äç‚ò†Ô∏è üë®‚Äçüë©‚Äçüëß‚Äçüë¶ ü•ë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬°Gran viernes a todos, amigos! A finales de junio, estamos lanzando un nuevo grupo en el curso de Especialista en Control de Calidad , que ser√° el foc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Uso de la tasa de defectos rechazados para mejorar el informe de errores</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/455240/">  ¬°Gran viernes a todos, amigos!  A finales de junio, estamos lanzando un nuevo grupo en el curso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Especialista</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Control de Calidad</a> , que ser√° el foco de la publicaci√≥n de hoy. <br><br><img src="https://habrastorage.org/webt/4m/5q/dj/4m5qdjzecdf-vqrx-npu-mr0w2c.png"><br><br>  Hay muchos indicadores por los cuales puede medir la efectividad del equipo de evaluadores.  Uno de ellos es el √≠ndice de defectos rechazados, o el n√∫mero de informes de error rechazados dividido por el n√∫mero total de informes recibidos.  Debe pensar que si el n√∫mero de informes rechazados es cero, entonces eso es bueno, pero no es tan simple.  Veamos los tipos de errores rechazados, veamos c√≥mo afectan la tasa de errores rechazados y calculemos la proporci√≥n correcta para su equipo. <a name="habracut"></a><br><br>  Hay tres categor√≠as de errores rechazados: <br><br><ul><li>  Errores irreproducibles; </li><li>  Errores incorrectos </li><li>  Errores duplicados </li></ul><br>  Comencemos con los propios errores. <br><br><h2>  Errores irreproducibles </h2><br>  Hay dos tipos de errores irreproducibles.  El primero es un error que es realmente dif√≠cil de reproducir.  Esto puede ser un error resultante de la interacci√≥n de varios par√°metros, algunos de los cuales ni siquiera conoce. <br><br>  Suponga que realiz√≥ varias pruebas seguidas, y una de las pruebas cambi√≥ el par√°metro de configuraci√≥n del valor predeterminado A a otro valor B. El error ocurre solo cuando el par√°metro de configuraci√≥n contiene el valor B y el valor de entrada es C. Cuando Al intentar reproducir el error, lo m√°s probable es que desee comenzar con un estado conocido para inicializar el sistema (o, posiblemente, realizar una instalaci√≥n limpia).  No se producir√° ning√∫n error porque el par√°metro de configuraci√≥n ahora nuevamente contiene el valor predeterminado A. <br><br>  Otra variante de este tipo de error irreproducible es cuando la prueba realmente encontr√≥ un defecto, pero no hay datos en la informaci√≥n de reproducci√≥n: un paso, un valor de entrada espec√≠fico o la comprensi√≥n de que el error ocurre solo con un determinado procedimiento.  Como resultado, los intentos de reproducir el error no conducen a nada. <br><br>  Sin embargo, en los dos casos anteriores, hay un defecto en el producto en s√≠. <br>  El segundo tipo de error irreproducible es cuando el error no puede repetirse porque no existe.  Es posible que el probador haya notado algo, pero lo haya malinterpretado, o que el sistema utilizado para las pruebas tenga alg√∫n tipo de problema, como un componente de hardware defectuoso, un controlador incompatible o una configuraci√≥n de acceso incorrecta.  Los intentos de reproducir el error en un sistema configurado correctamente fallan. <br><br>  Estos dos tipos de errores generalmente se marcan en los sistemas de informe de errores como "rechazados, no se pueden reproducir". <br><br><h2>  Errores incorrectos </h2><br>  Este tipo de error ocurre si el probador decide que el producto debe comportarse de cierta manera e informa un error cuando el comportamiento no cumpli√≥ con sus expectativas.  Sin embargo, un estudio m√°s detallado de los requisitos muestra que las expectativas del probador eran err√≥neas y que el producto realmente funcionaba correctamente.  Es decir, el producto probado funcion√≥ correctamente y el probador, que no estaba suficientemente familiarizado con los requisitos, cometi√≥ un error. <br><br>  Dichos errores generalmente se marcan en los sistemas de informe de errores como "rechazado - no error" o "rechazado - por la arquitectura" (es decir, el comportamiento es coherente con la arquitectura). <br><br><h2>  Errores duplicados </h2><br>  Los errores repetidos son aquellos errores que uno ya ha informado, y el siguiente informa despu√©s.  Un error es repetitivo solo si los "s√≠ntomas" de su apariencia son los mismos.  Y si la causa ra√≠z del error es la misma, pero los "s√≠ntomas" resultaron ser diferentes, ¬°esto no es una repetici√≥n del error! <br><br>  Estos errores generalmente se marcan en los sistemas de informe de errores como "rechazados - duplicados / repetidos". <br><br><h2>  C√≥mo los errores rechazados afectan a un equipo </h2><br>  Obviamente, un error incorrecto es una especie de p√©rdida de tiempo que el evaluador dedic√≥ a reproducir el error e informarlo, el tiempo que los que clasifican los errores pasan ley√©ndolos y entendi√©ndolos, y el tiempo que los desarrolladores pasan tratando de reproducir un error irreproducible o para arreglar (y mal funcionamiento) algo que no necesitaba esta soluci√≥n. <br><br>  Adem√°s del hecho de que el √≠ndice de error rechazado o RDR es una medida de la ineficiencia del equipo de evaluadores, tambi√©n habla sobre la profesionalidad de los evaluadores en general.  Un error que no se puede reproducir debido a la falta de informaci√≥n necesaria en el informe indica que los evaluadores no fueron meticulosos y no trabajaron lo suficiente para reproducir este error siguiendo los pasos descritos anteriormente.  Adem√°s, para los errores que se reproducen con poca frecuencia, los evaluadores generalmente no notaron la baja frecuencia de reproducci√≥n en el informe. <br><br>  La aparici√≥n de un error incorrecto indica que los evaluadores no entienden completamente los requisitos del producto.  Los errores repetidos indican que los evaluadores no realizaron una b√∫squeda m√≠nima en la base de datos de errores local para verificar si ocurri√≥ antes.  O significa que el especialista que inform√≥ este error no fue el primero en incluir las palabras clave correctas en el nombre para facilitar la b√∫squeda de sus otros colegas. <br><br>  A su vez, si resulta que el error que encontr√© es rechazado, estoy resentido porque me consideraron un laico.  Por un lado, esto significa que defender√© los errores encontrados.  Cuando mi informe es rechazado, procedo de la siguiente manera: <br><br><ul><li>  Compruebo nuevamente si el error se est√° reproduciendo en mi sistema y agrego los pasos de reproducci√≥n si me perd√≠ algo; </li><li>  Si mi malentendido de los requisitos fue causado por un requisito ambiguo o documentaci√≥n incorrecta, insistir√© en que el error se marque como un error de documentaci√≥n y se cierre solo cuando la documentaci√≥n se corrija; </li><li>  Si creo que el comportamiento del producto cuando se cumple el requisito es incorrecto, hablar√© sobre los requisitos con arquitectos y desarrolladores, tratar√© de convencerlos de que los requisitos deben actualizarse (al final, ¬°represento la opini√≥n del cliente!); </li><li>  Si el error se rechaza como un duplicado, me asegurar√© de que no est√© marcado de la misma manera o que no aparezca "de acuerdo con el mismo escenario". </li></ul><br>  Por otro lado, una cierta probabilidad de rechazo de error me hace cauteloso.  Si no estoy completamente seguro de haber encontrado un error, pasar√© un poco m√°s de tiempo antes de informar.  A menudo le pregunto a un colega si interpreto los requisitos correctamente, o verifico si el error se reproduce en el sistema de otra persona. <br><br><h2>  Opini√≥n en contra de la ausencia total de errores rechazados </h2><br>  El equipo de prueba debe monitorear y esforzarse por reducir el nivel de RDR.  La √∫nica pregunta es, ¬øqu√© RDR debe considerarse bueno? <br><br>  A primera vista, parece que 0% es el resultado √≥ptimo, pero estoy totalmente en desacuerdo con esto.  Creo que cuando la RDR se mantiene en un nivel saludable, esto es normal, porque si est√° cerca de cero, el equipo de prueba obviamente sufre problemas no menos graves que, por ejemplo, una RDR excesivamente alta. <br><br>  El equipo de prueba debe hacer grandes esfuerzos para lograr una RDR extremadamente baja.  Cada error rechazado se analizar√° para comprender qu√© sali√≥ mal, y cada evaluador que inform√≥ un error rechazado tendr√° que explicar qu√© sucedi√≥ realmente y c√≥mo se puede evitar tal situaci√≥n en el futuro.  Como resultado, los evaluadores informar√°n errores en los que est√©n absolutamente seguros. <br><br>  Si notan un comportamiento que creen que da√±ar√° la usabilidad del producto, preferir√°n darlo por sentado, en lugar de justificar que han encontrado un error que, de hecho, no es un error basado en los requisitos.  Si tienen evidencia de que ha ocurrido un error, pero no hay un buen escenario para reproducirlo, preferir√°n no informarlo;  Realmente no quieren molestarse.  Si encuentran un error fr√≠volo, pueden decidir no informarlo en absoluto, porque los errores menores no siempre lo solucionan, entonces, ¬øpor qu√© arriesgarse y tener miedo de que el error que encontr√≥ sea rechazado? <br><br>  En resumen, luchar por una RDR muy baja causa estr√©s y un comportamiento poco saludable en el equipo de prueba, y tambi√©n aumenta la probabilidad de que algunos errores pasen desapercibidos. <br><br>  Necesitamos probadores que no solo reporten errores obvios, sino que tambi√©n adviertan cualquier comportamiento sospechoso en el proyecto.  Creemos que los probadores que otorgan gran importancia a garantizar que el error no se escape, incluso a costa de los informes duplicados, son mejores que los probadores que pasan horas comprobando si un error ya se ha informado en los informes o no, por temor a que hacer un duplicado  Queremos que los evaluadores se sientan c√≥modos al cuestionar la palabra del arquitecto del sistema o la especificaci√≥n de requisitos, incluso si eso significa que algunos de sus errores se marcar√°n como rechazados. <br><br>  Necesitamos probadores que no tengan miedo de cometer errores de vez en cuando.  Esto significa que se necesita equilibrio, por lo que se considera aceptable una peque√±a RDR. <br><br><h2>  Encontrar el coeficiente de defecto √≥ptimo rechazado </h2><br>  Mi regla general es que la RDR debe ser del 15 por ciento.  Este valor se basa en mi experiencia con el equipo probador, que, seg√∫n todas las cuentas, fue un equipo bueno y efectivo.  Fue nuestro RDR durante varios proyectos que se sucedieron uno tras otro, mientras que el otro equipo, que trabaj√≥ en los mismos proyectos y en paralelo con nosotros, aunque era menos consciente del producto y se consideraba menos efectivo, ten√≠a un 30% de RDR . <br><br>  No creo que haya otra justificaci√≥n para este significado que no sea mi sentimiento interior.  Esto definitivamente no es cient√≠fico.  No discutir√© con un equipo que est√© dirigido al 10 o 20 por ciento, pero creo que soportar un 30 por ciento o establecer una meta del 5 por ciento ya es un problema. <br><br>  Al final, esta es una decisi√≥n que debe tomar el equipo probador, en funci√≥n de las caracter√≠sticas del producto, el nivel de experiencia del equipo, el modelo de desarrollo, la experiencia del equipo de desarrollo y mucho m√°s.  Le recomiendo que vigile RDR y piense si necesita hacer algo con √©l.  Y si es demasiado alto o bajo, se deben tomar las medidas apropiadas. <br><br>  Por tradici√≥n, esperamos sus comentarios y lo invitamos a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">seminario web gratuito</a> , que se realizar√° el 14 de junio.  Hasta pronto! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/455240/">https://habr.com/ru/post/455240/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455226/index.html">¬øPor qu√© aplicar un ling√ºista aplicado?</a></li>
<li><a href="../455228/index.html">El que resucit√≥ a Duke Nukem: Entrevista con Randy Pitchford, asistente de Gearbox</a></li>
<li><a href="../455230/index.html">Tipos de referencia anulables en C # 8.0 y an√°lisis est√°tico</a></li>
<li><a href="../455234/index.html">Tipos de referencia anulables en C # 8.0 y an√°lisis est√°tico</a></li>
<li><a href="../455236/index.html">Comodo revoca certificados sin motivo</a></li>
<li><a href="../455242/index.html">Menos o√≠dos o c√≥mo no estropear el sonido en el juego desde el principio</a></li>
<li><a href="../455244/index.html">Comic "Soldar es f√°cil" en la versi√≥n actualizada (2019)</a></li>
<li><a href="../455246/index.html">La inscripci√≥n para el D√≠a de la Experiencia del Cliente en San Petersburgo est√° abierta el 20 de junio.</a></li>
<li><a href="../455248/index.html">Principales errores de desarrollo al trabajar con PostgreSQL</a></li>
<li><a href="../455250/index.html">El que resucit√≥ a Duke Nukem: entrevista con Randy Pitchford, mago de Gearbox</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìù üëÜüèΩ üëµüèø Criando um bot para participar do mini cup da AI. Experi√™ncia GPU üöµüèæ üèÇüèª üëØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continua√ß√£o do artigo 1 e do artigo 2 . 


 Abaixo, abaixo, mostrarei a experi√™ncia do autor no uso da GPU para c√°lculos, inclusive como parte da cria...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Criando um bot para participar do mini cup da AI. Experi√™ncia GPU</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417757/"><p><img src="https://habrastorage.org/webt/0y/a5/cb/0ya5cbi1psai9jbzlfxhlhnzx4w.jpeg"></p><br><p>  Continua√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo 1</a> e do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo 2</a> . </p><br><p>  Abaixo, abaixo, mostrarei a experi√™ncia do autor no uso da GPU para c√°lculos, inclusive como parte da cria√ß√£o de um bot para participar do mini cup da AI.  Mas, em vez disso, este √© um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ensaio</a> sobre o assunto da GPU. </p><br><p>  - Seu nome √© m√°gico ... <br>  -Sabe Joel? A m√°gica est√° saindo ... </p><a name="habracut"></a><br><p> Na inf√¢ncia, falamos sobre a idade em que a qu√≠mica ainda n√£o est√° em andamento na escola ou est√° apenas come√ßando a ocorrer, o autor ficou fascinado com a rea√ß√£o ardente; aconteceu que seus pais n√£o interferiram nele e o terreno baldio de Moscou perto da casa foi ocasionalmente iluminado por flashes de v√°rias atividades infantis, um foguete caseiro em preto p√≥lvora, caramelo de nitrato de a√ß√∫car, etc.  Duas circunst√¢ncias limitaram as fantasias das crian√ßas: a decomposi√ß√£o da nitroglicerina em um laborat√≥rio dom√©stico com um teto sibilante de √°cidos e o trajeto at√© uma sala da pol√≠cia na tentativa de obter produtos qu√≠micos em uma das empresas de defesa espalhadas pela √°rea metropolitana de Aviamotornaya. </p><br><p>  E ent√£o apareceu uma escola de f√≠sica com computadores yamaha msx, uma calculadora MK program√°vel em casa e n√£o havia tempo para qu√≠mica.  Os interesses da crian√ßa mudaram para computadores.  E o que o autor faltou no primeiro contato com o computador foi a rea√ß√£o ardente, seus programas estavam em chamas, n√£o havia essa sensa√ß√£o de poder natural.  Voc√™ podia ver o processo de otimiza√ß√£o de c√°lculos em jogos, mas naquela √©poca o autor n√£o sabia como substituir o c√°lculo de sin () pela tabela de valores dessa fun√ß√£o, n√£o havia Internet ... </p><br><p>  Assim, o autor foi capaz de obter uma sensa√ß√£o de alegria pelo poder da computa√ß√£o, queima limpa, uso a GPU nos c√°lculos. </p><br><p>  Em um habr, existem alguns bons artigos sobre c√°lculos na GPU.  Tamb√©m existem muitos exemplos na Internet, por isso foi decidido escrever no s√°bado de manh√£ sobre sentimentos pessoais e √© poss√≠vel empurrar outras pessoas para o paralelismo de massas. </p><br><p>  Vamos come√ßar com formul√°rios simples.  A computa√ß√£o de GPU suporta v√°rias estruturas, mas as mais famosas s√£o NVIDIA CUDA e OpenCL.  Tomaremos o CUDA e imediatamente teremos que restringir nosso conjunto de linguagens de programa√ß√£o para C ++.  Existem bibliotecas para conectar-se ao CUDA em outras linguagens de programa√ß√£o, por exemplo, ALEA GPU em C #, mas esse √© o t√≥pico de um artigo de revis√£o separado. </p><br><p>  Assim como eles n√£o podiam fabricar um carro de massa com um motor a jato ao mesmo tempo, embora alguns de seus indicadores sejam mais altos que os de um motor de combust√£o interna, nem sempre √© poss√≠vel usar c√°lculos paralelos em problemas reais.  O principal aplicativo para computa√ß√£o paralela: voc√™ precisa de uma tarefa que contenha algum elemento de caractere de massa, multiplicidade.  No nosso caso de cria√ß√£o de um bot, uma rede neural (muitos neur√¥nios, conex√µes neurais) cai sob a massa e uma popula√ß√£o de bots (calculando a din√¢mica do movimento, colis√µes para cada bot levam algum tempo, se os bots forem de 300 a 1000, o processador central se render√° e voc√™ observar√° apenas lentamente latente do seu programa, como longas pausas entre os quadros de visualiza√ß√£o). </p><br><p>  A melhor op√ß√£o de massa √© quando cada elemento dos c√°lculos n√£o depende do resultado dos c√°lculos em outro elemento da lista, por exemplo, a tarefa simples de classificar uma matriz j√° est√° coberta de todos os tipos de truques, pois a posi√ß√£o do n√∫mero na matriz depende de outros n√∫meros e n√£o pode ser levada √† testa em um <strong>ciclo paralelo</strong> .  Para simplificar a reda√ß√£o: o primeiro sinal de caractere de massa bem-sucedido √© que, se voc√™ n√£o precisar alterar a posi√ß√£o de um elemento na matriz, poder√° realizar c√°lculos livremente, pegar os valores de outros elementos para isso, mas n√£o mov√™-lo de seu lugar.  Algo como um conto de fadas: n√£o mude a ordem dos elementos, caso contr√°rio, a GPU se transformar√° em uma ab√≥bora. </p><br><p>  Nas linguagens de programa√ß√£o modernas, existem constru√ß√µes que podem ser executadas em paralelo em v√°rios n√∫cleos de um processador central ou threads l√≥gicos e s√£o amplamente usadas, mas o autor concentra o leitor no paralelismo em massa, quando o n√∫mero de m√≥dulos em execu√ß√£o excede centenas ou milhares de unidades. </p><br><p>  Os primeiros elementos das estruturas paralelas apareceram: um <strong>ciclo paralelo</strong> .  Para a maioria das tarefas, ser√° suficiente.  Em um sentido amplo, esta √© a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">quintess√™ncia</a> <br>  computa√ß√£o paralela. </p><br><p>  Um exemplo de grava√ß√£o do loop principal no CUDA (kernel): </p><br><pre><code class="hljs perl"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tid = blockIdx.x * blockDim.x + threadIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> threadN = gridDim.x * blockDim.x; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span> = tid; <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span> &lt; numElements; <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span> += threadN) { <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>    <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span>,     ,       thread     pos.  :    thread    ,  thread   <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span>=<span class="hljs-number"><span class="hljs-number">1146</span></span>     thread c  <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span>=<span class="hljs-number"><span class="hljs-number">956</span></span>.        .           . }</code> </pre> <br><p>  Muito foi escrito na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o e nas revis√µes do CUDA</a> , sobre blocos de GPU, sobre Threads que s√£o produzidos nesses blocos, como paralelizar a tarefa neles.  Mas se voc√™ tiver uma matriz de dados e ela consistir claramente em elementos de massa, use o formul√°rio de loop acima, pois √© visualmente semelhante a um loop regular no formul√°rio, o que √© agrad√°vel, mas infelizmente n√£o no conte√∫do. </p><br><p>  Eu acho que o leitor j√° entende que a classe de tarefas est√° se estreitando rapidamente em rela√ß√£o √† programa√ß√£o paralela em massa.  Se estamos falando sobre a cria√ß√£o de jogos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mecanismos de renderiza√ß√£o em</a> 3D, redes neurais, edi√ß√£o de v√≠deo e outras tarefas semelhantes, ent√£o a limpeza de a√ß√µes de leitores independentes est√° muito desgastada, existem programas grandes, pequenos programas, estruturas, bibliotecas conhecidas e desconhecidas para essas tarefas.  Ou seja, a √°rea permanece apenas a partir do t√≥pico, para criar seu pr√≥prio pequeno foguete de computa√ß√£o, n√£o o SpaceX e o Roscosmos, mas algo caseiro, mas completamente ruim para os c√°lculos. </p><br><p><img src="https://habrastorage.org/webt/p6/f-/yt/p6f-ytvdsye66m74evqa0xisslc.png"></p><br><p>  Aqui est√° uma foto de um foguete completamente flamejante retratado. </p><br><p>  Falando de tarefas que um ciclo paralelo em suas m√£os n√£o ser√° capaz de resolver.  E os criadores da CUDA na pessoa dos desenvolvedores da NVIDIA j√° pensaram nisso. </p><br><p>  Em alguns lugares, existe uma biblioteca Thrust √∫til at√© que "nenhuma op√ß√£o" seja feita de maneira diferente.  A prop√≥sito, n√£o encontrou sua opini√£o completa no Habr√©. </p><br><p>  Para entender como funciona, primeiro voc√™ precisa dizer tr√™s frases sobre os princ√≠pios da CUDA.  Se precisar de mais palavras, voc√™ pode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ler o</a> link. </p><br><p>  Os princ√≠pios da CUDA: </p><br><p>  As computa√ß√µes ocorrem na GPU, cujo programa √© o kernel, e voc√™ deve escrev√™-lo em C. O kernel, por sua vez, se comunica apenas com a mem√≥ria da GPU e √© necess√°rio carregar os dados na mem√≥ria do processador de v√≠deo do programa principal e envi√°-los de volta ao programa.  Algoritmos sofisticados no CUDA exigem flexibilidade da mente. </p><br><p>  Portanto, a biblioteca Thrust remove a rotina e assume algumas das tarefas "complexas" do CUDA, como somar matrizes ou classific√°-las.  Voc√™ n√£o precisa mais escrever um kernel separado, carregar ponteiros na mem√≥ria e copiar dados desses ponteiros para a mem√≥ria da GPU.  Todo o mist√©rio acontecer√° diante de seus olhos no programa principal e com uma velocidade ligeiramente inferior √† CUDA.  A biblioteca Thrust √© escrita em CUDA, portanto, este √© um campo √∫nico em termos de desempenho. </p><br><p>  O que voc√™ precisa fazer no Thrust √© criar uma matriz (thrust :: vector) dentro de sua biblioteca, compat√≠vel com matrizes regulares (std :: vector).  Naturalmente, isso n√£o √© tudo t√£o simples, mas o significado do que o autor disse √© semelhante √† verdade.  Na verdade, existem duas matrizes, uma na GPU (dispositivo) e a outra no programa principal (host). </p><br><p>  Um exemplo mostrar√° a simplicidade da sintaxe (matrizes X, Y, Z): </p><br><pre> <code class="hljs vhdl">// initialize X <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, .... thrust::<span class="hljs-keyword"><span class="hljs-keyword">sequence</span></span>(X.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), X.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>()); // compute Y = -X thrust::transform(X.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), X.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), Y.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), thrust::negate&lt;int&gt;()); // fill Z <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> twos thrust::fill(Z.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), Z.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), <span class="hljs-number"><span class="hljs-number">2</span></span>); // compute Y = X <span class="hljs-keyword"><span class="hljs-keyword">mod</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> thrust::transform(X.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), X.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), Z.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), Y.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), thrust::modulus&lt;int&gt;()); // replace <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> the ones <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> Y <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tens thrust::replace(Y.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), Y.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>);</code> </pre> <br><p>  Voc√™ pode ver como √© inofensivo no contexto da cria√ß√£o do kernel CUDA, e o conjunto de fun√ß√µes no Thrust √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">grande</a> .  Come√ßando do trabalho com vari√°veis ‚Äã‚Äãaleat√≥rias, que no CUDA √© feito por uma biblioteca cuRAND separada (de prefer√™ncia executada por um kernel separado), para classificar, somar e escrever suas fun√ß√µes de acordo com a funcionalidade pr√≥xima √†s fun√ß√µes do kernel. </p><br><p>  O autor tem pouca experi√™ncia usando CUDA e C ++, dois meses.  Sobre este ano, sobre C #.  Isso, √© claro, contradiz levemente o in√≠cio do artigo sobre seu conhecimento precoce de computadores, f√≠sica escolar e matem√°tica aplicada como educa√ß√£o.  Eu vou dizer.  Mas por que estou escrevendo este artigo, n√£o √© que eu tenha dominado tudo isso, mas que o C ++ acabou sendo uma linguagem confort√°vel (eu costumava ter um pouco de medo disso, no contexto de artigos no tipo Haber "fun√ß√µes lambda ‚Üí sobrecarga de operadores internos, como redefinir tudo "), √© claro que os anos de seu desenvolvimento levaram a ambientes de desenvolvimento bastante amig√°veis ‚Äã‚Äã(IDEs).  A pr√≥pria linguagem em sua vers√£o mais recente, parece que coleta lixo da mem√≥ria, n√£o sei como era antes.  Pelo menos, os programas escritos pelo autor nas constru√ß√µes algor√≠tmicas mais simples geraram algoritmos computacionais para bots por dias e n√£o houve vazamentos de mem√≥ria e outras falhas em alta carga.  Isso tamb√©m se aplica √† CUDA, a princ√≠pio parece complicado, mas √© baseado em princ√≠pios simples e, √© claro, √© dif√≠cil inicializar locais na GPU em locais, se houver muitos deles, mas voc√™ ter√° seu pr√≥prio pequeno foguete, com fuma√ßa da placa de v√≠deo. </p><br><p>  Das classes de objetos para treinamento com a GPU, o autor recomenda <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aut√¥matos celulares</a> .  Houve um aumento de popularidade e moda para eles, mas as redes neurais conquistaram a mente dos desenvolvedores. <br>  At√©: </p><br><p>  "toda quantidade na f√≠sica, incluindo tempo e espa√ßo, √© finita e discreta". <br>  do que n√£o um aut√¥mato celular. </p><br><p>  Mas √© lindo quando tr√™s f√≥rmulas simples podem criar isso: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wNiBFQgrNp8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Se for interessante ler sobre aut√¥matos celulares na CUDA, escreva nos coment√°rios, haver√° material digitado para um pequeno artigo. <br>  E esta √© a fonte de aut√¥matos celulares (no v√≠deo, h√° links para as fontes): </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/KJe9H6qS82I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  A ideia de escrever um artigo depois do caf√© da manh√£, de uma s√≥ vez, parece-me dar certo.  Segunda hora do caf√©.  Tenha um bom leitor de final de semana. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt417757/">https://habr.com/ru/post/pt417757/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt417747/index.html">Re: ‚ÄúCompara√ß√£o de frameworks JS: React, Vue e Hyperapp‚Äù</a></li>
<li><a href="../pt417749/index.html">Projeto Loon como projeto comercial: o primeiro contrato √© assinado</a></li>
<li><a href="../pt417751/index.html">Kunstkamera: E-meter - Dispositivo de Scientology para medir thetans</a></li>
<li><a href="../pt417753/index.html">Compacta√ß√£o de grandes matrizes de n√∫meros primos</a></li>
<li><a href="../pt417755/index.html">Estudo: 80% das OICs de 2017 s√£o consideradas fraudulentas</a></li>
<li><a href="../pt417759/index.html">Seja meu pato de borracha</a></li>
<li><a href="../pt417761/index.html">O GitLab est√° migrando do Azure para o Google Cloud Platform. Not√≠cias sobre mudan√ßas e datas de manuten√ß√£o</a></li>
<li><a href="../pt417763/index.html">MVIDroid: uma revis√£o da nova biblioteca MVI (Model-View-Intent)</a></li>
<li><a href="../pt417767/index.html">An√°lise de sentimentos de texto usando redes neurais convolucionais</a></li>
<li><a href="../pt417769/index.html">Design da mem√≥ria do usu√°rio: Como projetar para idades</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
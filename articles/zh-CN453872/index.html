<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>♏️ 📚 🤒 使用神经网络还原照片 😻 👩‍👩‍👦‍👦 👨🏻‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="大家好，我是Mail.ru Group计算机视觉团队的研究程序员。 在今年的“胜利纪念日”中，我们决定进行一个军事图片恢复项目 。 什么是照片恢复？ 它包括三个阶段： 



- 我们发现所有图像缺陷：断裂，磨损，破洞； 
- 根据缺陷周围的像素值对发现的缺陷进行涂漆； 
- 使图像着色。 
 在本...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>使用神经网络还原照片</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/453872/"><img src="https://habrastorage.org/getpro/habr/post_images/333/44a/c78/33344ac788b63200841180799417f934.jpg"><br><br> 大家好，我是Mail.ru Group计算机视觉团队的研究程序员。 在今年的“胜利纪念日”中，我们决定进行一个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">军事图片恢复项目</a> 。 什么是照片恢复？ 它包括三个阶段： <br><br><ul><li> 我们发现所有图像缺陷：断裂，磨损，破洞； <br></li><li> 根据缺陷周围的像素值对发现的缺陷进行涂漆； <br></li><li> 使图像着色。 <br></li></ul><br> 在本文中，我将详细介绍恢复的每个阶段，并告诉您如何以及在何处获取数据，我们学到了哪些网络，我们做了什么以及我们踩踏了什么耙子。 <br><a name="habracut"></a><br><h1> 缺陷搜索 </h1><br> 我们要查找与上传的照片中的缺陷相关的所有像素。 首先，我们需要了解人们将上传什么样的战争年代照片。 我们转向了不朽军团项目的组织者，他们与我们共享了数据。 在对它们进行分析之后，我们注意到人们经常上传具有中等或大量缺陷的单张或多张肖像。 <br><br> 然后有必要收集训练样本。 分割任务的训练样本是图像和蒙版，上面标记了所有缺陷。 最简单的方法是将照片提供给标记。 当然，人们擅长发现缺陷，但是问题是标记是一个很长的过程。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d5d/a19/892/d5da1989220f10bcaac3944d27d64276.png"><br><br> 标记一张照片中与缺陷有关的像素可能需要一个小时到整个工作日，因此很难在几周内收集100张以上的照片样本。 因此，我们试图以某种方式补充我们的数据并自行编写缺陷：我们拍摄了一张干净的照片，对其应用了人工缺陷，并得到了一个遮罩，向我们显示图像中哪些特定部分受到了损坏。 我们训练样本的主要部分是79张手动标记的照片，其中11张已转移到测试样本中。 <br><br> 分割问题的最流行方法：将Unet与预先训练的编码器配合使用，并减少数量 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">B</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">e</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.854ex" height="2.057ex" viewBox="0 -780.1 1659.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhhfo8Ap529f2DvQbVLvVmWfeskSag#MJMATHI-42" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhhfo8Ap529f2DvQbVLvVmWfeskSag#MJMATHI-63" x="759" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhhfo8Ap529f2DvQbVLvVmWfeskSag#MJMATHI-65" x="1193" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1"> Bce </script>  （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">二进制交叉熵</a> ）和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-5"><span class="MJXp-mrow" id="MJXp-Span-6"><span class="MJXp-mo" id="MJXp-Span-7" style="margin-left: 0.278em; margin-right: 0.278em;">骰</span></span><span class="MJXp-mrow" id="MJXp-Span-8"><span class="MJXp-mo" id="MJXp-Span-9" style="margin-left: 0.278em; margin-right: 0.278em;">子</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-2">骰子</script>  （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">索伦森-骰子系数</a> ）。 <br><br> 这种方法在缺陷分割问题中会出现什么问题？ <br><br><ul><li> 即使在我们看来，照片中有很多缺陷，非常脏，并且随着时间的流逝非常破碎，但缺陷所占的面积仍然比图像的未损坏部分小得多。 要解决此问题，您可以增加 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-10"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11">B</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">e</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-3"> Bce </script>  ，最佳权重将是所有纯像素数与属于缺陷的像素数之比。 <br></li><li> 第二个问题是，如果我们将Unet与预先训练好的编码器（例如Albunet-18）一起使用，则会丢失很多位置信息。  Albunet-18的第一层由卷积组成，卷积的核心为5，步幅等于2。 这样可以使网络快速工作。 为了更好地定位缺陷，我们牺牲了网络时间：我们在第一层之后删除了最大池，将步幅减小为1，并将卷积核减小为3。 <br></li><li> 如果我们处理小图像，例如将图片压缩为256 x 256或512 x 512，则小缺陷将由于插值而简单消失。 因此，您需要处理较大的图片。 现在，在生产中，我们正在分割1024 x 1024的照片中的缺陷。因此，有必要在大图像的大批量作物中训练神经网络。 因此，一张视频卡上的批量较小会出现问题。 <br></li><li> 在培训期间，一张卡片上放置了大约20张图片。 因此，BatchNorm层中的均值和方差的估计不准确。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">就地BatchNorm</a>帮助我们解决了这个问题，首先，它可以节省内存，其次，它具有一个版本的Synchronized BatchNorm，该版本可以在所有卡之间同步统计信息。 现在，我们考虑的平均值和方差不是在一张卡上显示20张图片，而是在4张卡上显示80张图片。 这改善了网络融合。 <br></li></ul><br> 最后，增加体重 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-14"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15">B</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17">e</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-4"> Bce </script> 通过更改体系结构并使用就地BatchNorm，我们开始搜索照片中的缺陷。 但是便宜地通过添加测试时间增强，您甚至可以做得更好。 我们可以在输入映像中运行一次网络，然后对其进行镜像并再次运行网络，这可以帮助我们发现小的缺陷。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c75/95b/702/c7595b702dcb921dac612b0218ce13e4.png"><br><br> 结果，我们的网络在18小时内融合了四个GeForce 1080Ti。 推理需要290毫秒。 结果已经足够长了，但这是因为我们正在寻找小的缺陷这一事实是有代价的。 验证方式 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-18"><span class="MJXp-mrow" id="MJXp-Span-19"><span class="MJXp-mo" id="MJXp-Span-20" style="margin-left: 0.278em; margin-right: 0.278em;">骰</span></span><span class="MJXp-mrow" id="MJXp-Span-21"><span class="MJXp-mo" id="MJXp-Span-22" style="margin-left: 0.278em; margin-right: 0.278em;">子</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-5">骰子</script> 等于0.35，并且 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-23"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">R</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25">O</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-26">C</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">A</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">U</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29">C</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-6"> ROCAUC </script>  -0.93。 <br><br><h1> 片段还原 </h1><br>  Unet帮助我们再次解决了这个问题。 对于输入，我们给了他原始图像和一个蒙版，在蒙版上我们用单位标记干净的空间，并用0标记要绘制的像素。 我们按以下方式收集数据：我们从Internet上获取了一个包含图片的大型数据集，例如OpenImagesV4，并人为地添加了形状类似于现实生活中的缺陷的缺陷。 之后，他们培训了网络以修复丢失的零件。 <br><br> 我们如何修改此任务的Unet？ <br><br> 您可以使用部分卷积代替常规卷积。 她的想法是，当我们使用内核折叠图片的某个区域时，我们没有考虑与缺陷相关的像素值。 这有助于使绘画更准确。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NVIDIA文章中</a>的示例。 在中心图中，他们将Unet与通常的卷积一起使用，在右边-与Partial Convolution一起使用： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5a5/280/a4b/5a5280a4be71695d16ab08af876c5d23.png"><br><br> 我们对网络进行了5天的培训。 在最后一天，我们冻结了BatchNorm，这有助于使图像的绘制部分的边界不那么明显。 <br><br> 网络在50毫秒内处理512 x 512的图片。 验证PSNR为26.4。 但是，无法无条件地信任此任务中的指标。 因此，我们首先对数据运行了几个好的模型，对结果进行匿名处理，然后投票给我们更喜欢的模型。 因此，我们选择了最终模型。 <br><br> 我提到过，我们人为地添加了缺陷以清洁图像。 训练时，您需要仔细监视叠加缺陷的最大大小，因为对于网络在学习过程中从未见过的非常大的缺陷，它将疯狂地幻想并给出绝对不适用的结果。 因此，如果您需要对较大的缺陷进行涂装，则在培训期间也要应用较大的缺陷。 <br><br> 这是算法的示例： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/abd/6cb/c8c/abd6cbc8c05396042bf83c00516b630e.png"><br><br><h1> 上色 </h1><br> 我们将缺陷分割并上漆，第三步是颜色的重建。 让我提醒您，在“不朽军团”的照片中，有很多单身或团体肖像。 我们希望我们的网络与他们合作良好。 我们决定进行自己的着色，因为我们所知的任何服务都无法快速，良好地绘制人像。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/015/bce/bf1/015bcebf15ef1ee069fdf08f16e00542.png"><br><br>  GitHub有一个流行的用于给照片着色的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">存储库</a> 。 平均来说，他做得很好，但是他有几个问题。 例如，他喜欢将衣服涂成蓝色。 因此，我们也拒绝了。 <br><br> 因此，我们决定制作一个用于着色的神经网络。 最明显的想法：拍摄黑白图像并预测红色，绿色和蓝色三个通道。 但是，总的来说，我们可以简化我们的工作。 我们不能使用颜色的RGB表示，而可以使用YCbCr表示。 分量Y是亮度（亮度）。 下载的黑白图像是Y通道，我们将重用它。 仍然需要预测Cb和Cr：Cb是蓝色和亮度的差异，而Cr是红色和亮度的差异。 <br><br><img src="https://habrastorage.org/webt/k8/ke/l_/k8kel_xrjco6euolh8ypkchjm8g.jpeg"><br><br> 我们为什么选择YCbCr视图？ 人眼对亮度的变化比对颜色的变化更敏感。 因此，我们重用了眼睛最初容易感觉到的Y分量（亮度），并预测了Cb和Cr，在这些分量中我们可能会犯更多的错误，因为人们注意到颜色的“假”更少。 当频道带宽不足以完全传输所有颜色时，此功能开始在彩色电视的曙光中得到积极使用。 图像被转印到YCbCr，不变地转印到Y分量，并且Cb和Cr被压缩两次。 <br><br><h1> 如何组装基线 </h1><br> 您可以再次使用带有预训练编码器的Unet，并最小化实际CbCr和预测的CbCr之间的L1损耗。 我们想给肖像上色，所以除了来自OpenImages的照片，我们还需要添加特定于我们任务的照片。 <br><br> 在哪里可以获得军人的彩色照片？ 互联网上有些人将旧照片作为爱好或订购。 他们非常谨慎地执行此操作，试图完全遵守所有细微差别。 给制服，肩章，勋章上色，他们使用档案材料，因此他们的工作结果值得信赖。 我们总共使用了200张手绘照片。 第二个有用的数据源是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">工农红军</a>的所在地。 在伟大的卫国战争期间，几乎所有可能的军装变形都为它的一位创作者拍照。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f72/999/7d9/f729997d9fd02755fd95967ff09d27ca.png"><br><br> 在一些照片中，他从著名的档案照片中重复了人们的姿势。 他在白色背景上拍摄特别好，这使我们可以很好地增强数据，在背景中添加各种自然物体。 我们还使用普通的现代人物肖像，以徽章和战时服装的其他属性作为补充。 <br><br> 我们培训了AlbuNet-50-这是Unet，其中AlbuNet-50被用作编码器。 网络开始产生足够的效果：皮肤是粉红色的，眼睛是灰蓝色的，肩带是淡黄色的。 但是问题是她在画上画了斑点。 这是由于以下事实：从L1错误的角度来看，不做任何事情比尝试预测某种颜色有时更有利可图。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/435/4a9/63c/4354a963c4cd2789c434002e44fdda26.png"><br>  <i>我们正在将结果与地面真相照片进行比较-昵称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Klimbim</a>的艺术家的手动着色</i> <br><br> 如何解决这个问题？ 我们需要一个鉴别器：一个神经网络，我们将向该神经网络提供输入图像，并且它将说明该图像看起来有多逼真。 在下面，一张照片是手绘的，第二张是神经网络的。 您认为哪一个？ <br><br><img src="https://habrastorage.org/getpro/habr/post_images/253/86a/abd/25386aabd9080c14daf71b60d9968453.png"><br><br><div class="spoiler">  <b class="spoiler_title">答案</b> <div class="spoiler_text"> 左照片是手工绘制的。 <br></div></div><br> 作为区分符，我们使用文章<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Self-Attention GAN中</a>的区分<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">符</a> 。 这是一个小的卷积网络，在最后一层内置了所谓的“自我注意”。 它使您可以更“注意”图像细节。 我们还使用频谱归一化。 确切的解释和动机可以在文章中找到。 我们训练了一个网络，结合了L1损失和鉴别器返回的错误。 现在，网络可以更好地绘制图像的细节，并且背景更加一致。 另一个例子：左边是仅训练有L1损失的网络的结果，右边是具有L1损失和鉴别器错误的网络的结果。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aa4/724/ada/aa4724ada4e0bbdc52dbcaadd5bb3fdc.png"><br><br> 在四台Geforce 1080Ti上，培训耗时两天。 在512 x 512图片中，网络在30 ms内完成工作，验证的MSE为34.4。 就像修复问题一样，指标不能完全信任。 因此，我们选择了6个具有最佳验证指标的模型，并盲目投票赞成最佳模型。 <br><br> 在生产中推出该模型后，我们继续进行实验，得出的结论是，最好不要将每个像素的L1损失减到最小，而将感知损失降到最低。 要进行计算，您需要通过VGG-16网络运行网络预测和源照片，获取较低层的属性映射，然后根据MSE比较它们。 这种方法可绘制更多区域，并有助于获得更彩色的图像。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db9/303/509/db93035094c4906cf82c246151432cbc.jpg"><br><br><h1> 结论与结论 </h1><br>  Unet是一个很酷的模型。 在第一个分割问题中，我们在训练和使用高分辨率图像时遇到了一个问题，因此我们使用就地BatchNorm。 在第二个任务（修复）中，我们使用了部分卷积，而不是通常的卷积，这有助于获得更好的结果。 在Unet的着色问题中，我们添加了一个小型鉴别器网络，该网络对生成器进行了罚款，以使其看起来不真实，并使用了感知损失。 <br><br> 第二个结论是访问器很重要。 而且不仅在训练前标记图片的阶段，而且还用于验证最终结果，因为在绘画缺陷或着色方面，您仍然需要在人的帮助下验证结果。 我们为用户提供三张照片：原始照片（已删除缺陷），彩色已删除缺陷（着色）以及彩色照片（以防发现和绘制缺陷的算法错误）。 <br><br> 我们拍了一些<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">军事相册</a>项目的照片，并用我们的神经网络对其进行了处理。 这是获得的结果： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a51/ade/15e/a51ade15e9cee54ec8269dc1e22df0af.jpg"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在这里，</a>您可以在原始分辨率和处理的每个阶段看到它们。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN453872/">https://habr.com/ru/post/zh-CN453872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN453862/index.html">为什么要使用pathlib</a></li>
<li><a href="../zh-CN453864/index.html">在控制台上使用鼠标和键盘会欺骗吗？</a></li>
<li><a href="../zh-CN453866/index.html">具有React Hooks，HOC或Render Prop的API请求</a></li>
<li><a href="../zh-CN453868/index.html">带nRF52832玻璃面板的触摸式迷你开关</a></li>
<li><a href="../zh-CN453870/index.html">我们在powershell上编写Reverse socks5代理。第1部分</a></li>
<li><a href="../zh-CN453874/index.html">从俄罗斯轮盘赌到安全LOTO：如何保护数据中心人员</a></li>
<li><a href="../zh-CN453876/index.html">就像Yandex.Practicum中一样，前端不同步获胜：Redux-Saga，postMessage和Jupyter的杂技数字</a></li>
<li><a href="../zh-CN453882/index.html">解决方案架构师专业指南（+有用链接列表）</a></li>
<li><a href="../zh-CN453884/index.html">HYIP相机或DSLR更换？</a></li>
<li><a href="../zh-CN453886/index.html">程序工程</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï¥üèª ‚õΩÔ∏è ‚õπüèΩ TJBOT als Beispiel f√ºr IBM Watson-Services üíµ üëßüèΩ ‚óæÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Im Fr√ºhjahr 2019 fand der n√§chste Think Developers Workshop statt, bei dem jeder einen TJBota-Kartonroboter mit IBM Watson Services zusamm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TJBOT als Beispiel f√ºr IBM Watson-Services</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ibm/blog/458374/">  Hallo Habr!  Im Fr√ºhjahr 2019 fand der n√§chste Think Developers Workshop statt, bei dem jeder einen TJBota-Kartonroboter mit IBM Watson Services zusammenbauen konnte.  Unter dem Cutter finden Sie eine detaillierte Anleitung zum Zusammenbau eines solchen Roboters, n√ºtzliche Links und einfache Rezepte, die einige der kognitiven F√§higkeiten von Watson Services demonstrieren, sowie eine kleine Ank√ºndigung von zwei Juli-Seminaren zu Watson Services im Moskauer B√ºro von IBM. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sz/da/wu/szdawu-surn1rikward-thsn57e.png" alt="Bild"></div><br><a name="habracut"></a><br>  IBM Watson Services sind ein kognitives System, das nat√ºrliche Sprache verarbeiten, Bilder erkennen und lernen kann.  Zur bequemen Verwendung dieser Dienste in einer beliebigen Anwendung ist eine API vorhanden. <br><br>  TJBot ist ein Open Source-Projekt, das den Zugriff auf Watson-Dienste erleichtert.  Dies ist ein Roboter, den jeder Himbeer-Pi und jede vorgefertigte k√ºnstliche Intelligenz herstellen kann.  TJBot kann mit Rezepten wiederbelebt werden. <br><br>  Rezepte sind schrittweise Anleitungen, mit denen Sie Ihren TJBot mit Watson-Diensten wie Speech to Text, Visual Recognition und Language Translator verbinden k√∂nnen.  Die Rezepte basieren auf dem Raspberry Pi. <br><br><h3>  Was wird f√ºr TJBota ben√∂tigt? </h3><br><ul><li>  Raspberry Pi 3 + OS SD-Karte </li><li>  USB-Mikrofon </li><li>  Bluetooth-Lautsprecher oder Lautsprecher mit 3,5 mm.  Audio-Buchse </li><li>  Servoantrieb </li><li>  NeoPixel RGB LED (8mm) </li><li>  Postings Mama Mama und Papa Mama </li><li>  Himbeer-Pi-Kamera </li><li>  Netzteil </li><li>  Fall (kann auf einem 3D-Drucker gedruckt oder aus Pappe lasergeschnitten werden. Die erforderlichen Layouts finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ) </li></ul><br><img src="https://habrastorage.org/webt/_g/nt/qz/_gntqzyt-xiwhicse9bgy6gyksy.png"><br><br>  Montageanleitung finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Das Anschlussdiagramm der Diode und des Servos zur Platine in der Abbildung unten. <br><br><img src="https://habrastorage.org/webt/p9/ha/vg/p9havg5oykyg-hrm1bocavxvfqg.png" alt="Bild"><br><br>  Das Geh√§use ist ‚Äûum‚Äú die Platine herum montiert, daher m√ºssen Sie zuerst das Betriebssystem auf die Speicherkarte schreiben. <br><br>  Am einfachsten ist es, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NOBS</a> zu installieren, aber jedes andere Linux ist f√ºr uns geeignet.  Formatieren Sie vor der Installation von NOOBS die Speicherkarte, laden Sie das Archiv mit den Installationsdateien herunter und exportieren Sie sie auf Ihren Computer.  Als n√§chstes m√ºssen Sie die Dateien aus dem NOOBS-Ordner auf die Speicherkarte √ºbertragen.  Wenn Sie Himbeere zum ersten Mal starten (mit einer zuvor eingelegten Speicherkarte), wird das Installationsmen√º des Betriebssystems ge√∂ffnet.  Detaillierte Anweisungen finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><h3>  Programmvorbereitungen </h3><br>  Als erstes m√ºssen Sie die Pakete installieren: <br><br><pre><code class="bash hljs">curl -sL http://ibm.biz/tjbot-bootstrap | sudo sh ‚Äì</code> </pre> <br>  Laden Sie jetzt die vorgefertigten Rezepte vom Github herunter: <br><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/ibmtjbot/tjbot.git</code> </pre><br>  Gehen Sie in das Verzeichnis mit dem Rezept: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> tjbot / recipes / speech_to_text</code> </pre><br>  Dieser Ordner enth√§lt die Konfigurationsdatei config.js und die Datei mit dem ausf√ºhrbaren Skript stt.js. <br><br>  Installiere npm: <br><br><pre> <code class="bash hljs">sudo apt-get install npm</code> </pre> <br><h3>  Verbinden Sie Watson-Dienste </h3><br>  Um Watson-Dienste nutzen zu k√∂nnen, m√ºssen Sie die folgenden Schritte ausf√ºhren. <br><br>  Wir gehen zu dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Seite √ºber</a> . <br><br><img src="https://habrastorage.org/webt/ih/cc/_0/ihcc_02huxat4scvowxowcjutyc.png" alt="Bild"><br><br>  Registrieren Sie sich und gehen Sie in das Verzeichnis.  Im Katalog suchen wir nach "Speech to Text".  Speech to Text ist ein Dienst, mit dem Sprache in Text √ºbersetzt wird.  Zugriff auf die API finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><img src="https://habrastorage.org/webt/9c/wk/dx/9cwkdxz6uj-ooxto4lmoujqjegk.png" alt="Bild"><br><br>  Text-to-Speech und visuelle Erkennung werden auch ben√∂tigt, wenn wir mit Bilderkennung arbeiten.  Wir klicken auf Rede zu Text, wir gelangen auf die Seite mit einer Beschreibung dieser Komponente und Nutzungspl√§nen. <br><br><img src="https://habrastorage.org/webt/uv/31/pi/uv31pidkj-2za05y0ojbv1khdo0.png" alt="Bild"><br><br>  Ein kostenloser Plan reicht uns.  Klicken Sie auf Erstellen und dann im Men√º links auf Service-Anmeldeinformationen. <br><br><img src="https://habrastorage.org/webt/dx/ti/5s/dxti5scdsq3vrgnmgkwap2c9yhk.png" alt="Bild"><br><br>  Von hier aus m√ºssen Sie die Anmeldeinformationen und APIKEY kopieren und in die Datei config.js einf√ºgen. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// Create the credentials object for export exports.credentials = {}; // Watson Speech to Text // https://www.ibm.com/watson/services/speech-to-text/ exports.credentials.speech_to_text = { "apikey": "...", "iam_apikey_description": "...", "iam_apikey_name": "...", "iam_role_crn": "...", "iam_serviceid_crn": "...", "url": "https://gateway-lon.watsonplatform.net/speech-to-text/api" };</span></span></code> </pre><br>  Wenn wir nun einen weiteren Watson-Dienst hinzuf√ºgen m√∂chten, m√ºssen wir in der Konfigurationsdatei jedem Dienst einen Block mit Apikey und URL hinzuf√ºgen, der in der folgenden Konstruktion eingeschlossen ist: <br><br><pre> <code class="javascript hljs">exports.credentials.[ text_to_speech/visual_recognition/speech_to_text ] = { ‚Ä¶ };</code> </pre><br><h3>  Die Wiederbelebung von TjBota </h3><br>  Betrachten Sie die Datei mit dem ausf√ºhrbaren Bot-Skript stt.js.  Es verf√ºgt √ºber eine vorgefertigte diskoParty () - Funktion zum √úberpr√ºfen des Betriebs des Bots ohne Verwendung von Watson-Diensten.  Diese Funktion l√§sst die Bot-Diode in verschiedenen Farben blinken. <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">discoParty</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">30</span></span>; i++) { setTimeout(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> randIdx = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.floor(<span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.random() * tjColors.length); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> randColor = tjColors[randIdx]; tj.shine(randColor); }, i * <span class="hljs-number"><span class="hljs-number">250</span></span>); } } discoParty();</code> </pre><br>  Im selben Skript gibt es eine Funktion, mit der Sie die Farbe der Diode mithilfe der Sprache des Entwicklers √§ndern k√∂nnen. <br><br>  F√ºhren Sie das Skript aus: <br><br><pre> <code class="bash hljs">sudo node stt.js</code> </pre><br>  Sagen Sie dem Bot, dass er das Licht blau schalten soll, um die Farbe der Diode auf blau umzuschalten, schalten Sie das Licht ein, um die Diode einzuschalten, oder schalten Sie das Licht aus, um es auszuschalten.  Unterst√ºtzte Farben zur Erkennung (bisher wird nur Englisch unterst√ºtzt): Gelb, Gr√ºn, Orange, Lila, Magenta, Rot, Blau, Aqua und Wei√ü. <br><br>  TjBot hat viele Grundfunktionen.  Um beispielsweise das Servo zu √ºberpr√ºfen, k√∂nnen Sie die Funktion tj.wave () verwenden, mit der der Bot Sie mit einer Welle des Griffs begr√º√üt.  Diese Kurzbeschreibungsfunktionen finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Stellen Sie sich nun das folgende Szenario vor, in dem sowohl visuelle Erkennung als auch Text-zu-Sprache verwendet werden. <br><br>  Text to Speech ist ein Dienst, der gedruckten Text mit verschiedenen Stimmen, Tasten und Sprachen in Sprache umwandelt.  Die API finden Sie unter folgendem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> .  Mit dem visuellen Erkennungsdienst k√∂nnen Sie beschreiben, was auf dem Bild angezeigt wird.  Es erkennt die Gesichter von Menschen mit einer Bestimmung ihres ungef√§hren Alters und Geschlechts, ihrer Nahrung, ihres Geschirrs und ihrer Gegenst√§nde und kann nach √§hnlichen Bildern suchen.  Die API f√ºr diesen Service finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  Mit diesen Diensten bringen wir dem Bot das Sehen und Sprechen bei.  Basierend auf dem von der Kamera empfangenen Bild senden uns die Watson-Dienste (visuelle Erkennung) ein JSON-Objekt mit Bild-Tags als Antwort, und Text-to-Speech hilft dabei, diese auszusprechen. <br><br>  Erstellen Sie zun√§chst Anmeldeinformationen auf cloud.ibm.com.  Wir kopieren sie und f√ºgen sie in die Konfigurationsdatei config.js ein. <br><br>  Bearbeiten Sie als N√§chstes das ausf√ºhrbare Skript stt.js.  Wir finden die folgenden Zeilen darin: <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// these are the hardware capabilities that our TJ needs for this recipe var hardware = ['led', 'microphone'];</span></span></code> </pre><br>  Das Hardware-Array enth√§lt die verwendeten Bot-Ger√§te.  Wenn wir ein Servo im Skript verwenden m√∂chten, m√ºssen wir "Servo" im Array signieren. Wenn wir eine Kamera ben√∂tigen, f√ºgen Sie dem Array "Kamera" hinzu, um die Spalte zu verwenden, in die wir "Lautsprecher" schreiben. <br>  Unser Skript verwendet also eine Spalte bzw. eine Kamera. Wir signieren dies im Hardware-Array. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// these are the hardware capabilities that our TJ needs for this recipe var hardware = ['led', 'servo', 'camera', 'speaker', 'microphone']; // set up TJBot's configuration var tjConfig = { log: { level: 'verbose' }, speak: { language: 'en-US', // see TJBot.prototype.languages.speak voice: undefined, // use a specific voice; if undefined, a voice is chosen based on robot.gender and speak.language speakerDeviceId: "plughw:0,0" // plugged-in USB card 1, device 0; see aplay -l for a list of playback devices }, listen: { microphoneDeviceId: "plughw:1,0", // plugged-in USB card 1, device 0; see arecord -l for a list of recording devices inactivityTimeout: -1, // -1 to never timeout or break the connection. Set this to a value in seconds eg 120 to end connection after 120 seconds of silence language: 'en-US' // see TJBot.prototype.languages.listen }, };</span></span></code> </pre><br>  Aus den Grundfunktionen der tj-Bibliothek ben√∂tigen wir die Funktionen tj.see () und tj.speak (). <br><br>  Die Funktion tj.see () erstellt ein Foto (das Objekt wird im Ordner tmp gespeichert), sendet es mit Watson-Diensten an die Cloud, analysiert das Bild und erstellt ein json-Objekt, das aus Tags besteht - W√∂rter, die das Foto beschreiben (Sie k√∂nnen verschiedene Beschreibungen und Vertrauensgrade ausw√§hlen) und Der Prozentsatz der Zuverl√§ssigkeit dieser Tags.  Wir werden den Inhalt der Antwort von Diensten an die Konsole ausgeben. <br><br>  Die Funktion tj.speak () kann Text mithilfe von Watson-Diensten in eine Audiodatei umwandeln und dann wiedergeben.  Wenn mithilfe der Watson-Dienste eine Person auf dem Foto erkannt wird, winkt TJBot mit dem Stift. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// instantiate our TJBot! var tj = new TJBot(hardware, tjConfig, credentials); tj.see().then(function(objects){ var tags = objects.map(function(object){ return object.class; }); if (tags.includes('person')){ tj.wave(); } console.log(tags); for(var i=0;i&lt;tags.length;i++){ tj.speak(tags[i]); } });</span></span></code> </pre><br>  Dieses Rezept zeigt, wie einfach es ist, Watson-Dienste in Ihrem Projekt zu verwenden.  Eine kurze Beschreibung dieser Dienste und Links zu ihnen waren bereits in diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel enthalten</a> .  Testen Sie alle Watson-Dienste kostenlos. <br><br>  Au√üerdem werden in K√ºrze Seminare im IBM-B√ºro in Moskau abgehalten, in denen Sie sich mit anderen Watson-Servicefunktionen vertraut machen k√∂nnen. <br><br>  Am 9. Juli 2019 findet die Unveil AI Blackbox mit IBM Watson OpenScale Workshop zum neuen Cloud-Produkt Watson OpenScale statt.  Bei dieser Veranstaltung k√∂nnen Sie sich mit den Prinzipien neuronaler Netze vertraut machen, versuchen, ein neuronales Netz zu erstellen, zu trainieren und es mithilfe der Watson AI OpenScale-Plattform zu testen.  Sie m√ºssen sich √ºber diesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> f√ºr die Veranstaltung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorregistrieren</a> . <br><br>  Am 10. Juli 2019 findet das Seminar ‚ÄûBild- und Videoerkennung in der IBM Cloud‚Äú statt.  In diesem Seminar erfahren Sie, wie Sie mit Watson Studio k√ºnstliche Intelligenz in Ihre Anwendung implementieren.  Detaillierte Veranstaltungsbeschreibung und Registrierungslink <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458374/">https://habr.com/ru/post/de458374/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458358/index.html">Meins ist immer noch legal: die Erfahrung mit dem Abbau von Lightcoins im Jahr 2019</a></li>
<li><a href="../de458362/index.html">Einzeilige Multiplikationstabelle</a></li>
<li><a href="../de458364/index.html">Fischnetzf√§lle - wie Microsoft Azure bei der Durchf√ºhrung eines Phishing-Angriffs hilft</a></li>
<li><a href="../de458370/index.html">Wie schnell die Ergebnisse Ivan geholfen haben</a></li>
<li><a href="../de458372/index.html">TestMace - eine leistungsstarke IDE f√ºr die Arbeit mit API</a></li>
<li><a href="../de458376/index.html">Keine andere Programmiersprache. Teil 1: Dom√§nenlogik</a></li>
<li><a href="../de458378/index.html">Verwenden von Avocode f√ºr das Site-Layout. Bewertung f√ºr Anf√§nger. Bonus - Registrieren Sie eine 30-t√§gige Testphase</a></li>
<li><a href="../de458382/index.html">Warum unterrichten wir das?</a></li>
<li><a href="../de458384/index.html">HP 3D Strukturierter Lichtscanner Pro S3 √úberpr√ºfung und Test</a></li>
<li><a href="../de458388/index.html">Deep (Learning + Random) Wald- und Artikelanalyse</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéÖ üë©üèΩ‚Äç‚öñÔ∏è üíî Explorer OpenCV sur StereoPi: carte de profondeur √† partir de la vid√©o üëã ü§∂üèΩ üëÜüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Aujourd'hui, nous voulons partager une s√©rie d'exemples sur Python pour les apprenants OpenCV sur le Raspberry Pi, √† savoir la carte StereoPi √† double...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Explorer OpenCV sur StereoPi: carte de profondeur √† partir de la vid√©o</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446872/"><img src="https://habrastorage.org/webt/hb/xt/po/hbxtpox_r6mswlkshq4w3cpovr4.gif"><br><br>  Aujourd'hui, nous voulons partager une s√©rie d'exemples sur Python pour les apprenants OpenCV sur le Raspberry Pi, √† savoir la carte StereoPi √† double chambre.  Le code fini (plus l'image Raspbian) vous aidera √† passer par toutes les √©tapes, en commen√ßant par la capture d'une image et en terminant par l'obtention d'une carte de profondeur de la vid√©o captur√©e. <br><a name="habracut"></a><br><h3>  Introduction </h3><br>  Je dois souligner tout de suite que ces exemples sont pour une immersion confortable dans le sujet, et non pour une solution de production.  Si vous √™tes un utilisateur avanc√© d'OpenCV et que vous avez eu affaire √† des framboises, alors vous savez que pour un travail √† part enti√®re, il est conseill√© de coder une bouch√©e, et m√™me d'utiliser un GPU framboise.  √Ä la fin de l'article, j'aborderai plus en d√©tail les ¬´goulots d'√©tranglement¬ª de la solution python et les performances globales. <br><br><h3>  Avec quoi travaillons-nous </h3><br>  Nous avons une configuration telle que le fer: <br><br><img src="https://habrastorage.org/webt/or/pd/9u/orpd9ufeuctr0lbmsk0kfogroao.jpeg"><br><br>  Carte StereoPi √† bord du Raspberry Pi Compute Module 3+.  Les deux cam√©ras les plus simples sont connect√©es pour la version Raspberry Pi V1 (sur le capteur ov5647). <br><br>  Ce qui est install√©: <br><br><ul><li>  Raspbian Stretch (noyau 4.14.98-v7 +) </li><li>  Python 3.5.3 </li><li>  OpenCV 3.4.4 (pr√©compil√©, ¬´pip¬ª de Python Wheels) </li><li>  Picamera 1.13 </li><li>  StereoVision lib 1.0.3 (https://github.com/erget/StereoVision) </li></ul><br>  Le processus d'installation de tous les logiciels d√©passe le cadre de cet article, et nous vous sugg√©rons simplement de t√©l√©charger l'image Raspbian finie (liens vers le github √† la fin de l'article). <br><br><h3>  Premi√®re √©tape: capturer une image </h3><br>  Pour ce faire, utilisez le script 1_test.py <br><br>  Ouvrez la console, allez du dossier d'accueil au dossier avec des exemples: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> stereopi-tutorial</code> </pre> <br>  Ex√©cutez le script: <br><br><pre> <code class="bash hljs">python 1_test.py</code> </pre> <br>  Apr√®s le d√©marrage, un aper√ßu de notre image st√©r√©o s'affiche √† l'√©cran.  Le processus peut √™tre interrompu en appuyant sur le bouton Q. Cela enregistrera la derni√®re image captur√©e, qui sera utilis√©e dans l'un des scripts suivants pour configurer la carte de profondeur. <br><br>  Ce script vous permet de vous assurer que tout le mat√©riel fonctionne correctement, ainsi que d'obtenir la premi√®re image pour une utilisation future. <br><br>  Voici √† quoi ressemble le premier script: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wllLrNUw3SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Deuxi√®me √©tape: collecter des images pour l'√©talonnage </h3><br>  Si nous parlons d'un cheval sph√©rique dans le vide, pour obtenir une carte de profondeur de bonne qualit√©, nous devons avoir deux cam√©ras absolument identiques, dont les axes vertical et optique sont parfaitement parall√®les et les axes horizontaux co√Øncident.  Mais dans le monde r√©el, toutes les cam√©ras sont l√©g√®rement diff√©rentes et il n'est pas possible de les organiser parfaitement.  Par cons√©quent, une astuce d'√©talonnage logiciel a √©t√© invent√©e.  √Ä l'aide de deux cam√©ras du monde r√©el, un grand nombre de photos d'un objet pr√©c√©demment connu sont prises (nous avons une photo avec un √©chiquier), puis un algorithme sp√©cial calcule toutes les ¬´imperfections¬ª et essaie de corriger les photos afin qu'elles soient proches de l'id√©al. <br><br>  Ce script fait la premi√®re √©tape du travail, √† savoir qu'il aide √† faire une s√©rie de photos pour l'√©talonnage. <br><br>  Avant chaque photo, le script d√©marre un compte √† rebours de 5 secondes.  Cette fois, en r√®gle g√©n√©rale, il suffit de d√©placer la carte dans une nouvelle position, pour s'assurer que sur les deux cam√©ras, elle ne rampe pas sur les bords et ne fixe pas sa position (afin qu'il n'y ait pas de flou sur la photo).  Par d√©faut, la taille de la s√©rie est d√©finie sur 30 photos. <br><br>  Lancement: <br><br><pre> <code class="bash hljs">python 2_chess_cycle.py</code> </pre> <br>  Processus: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1XCAlU3k-xs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  En cons√©quence, nous avons une s√©rie de photos dans le dossier / sc√®nes. <br><br><h3>  Nous coupons les images en paires </h3><br>  Le troisi√®me script 3_pairs_cut.py coupe les photos prises en images ¬´gauche¬ª et ¬´droite¬ª et les enregistre dans le dossier / pairs.  En fait, nous pourrions exclure ce script et faire la d√©coupe √† la vol√©e, mais il est tr√®s utile dans d'autres exp√©riences.  Par exemple, vous pouvez enregistrer des tranches de diff√©rentes s√©ries, utiliser vos scripts pour travailler avec ces paires, ou m√™me supprimer les photos prises sur d'autres cam√©ras st√©r√©o par paires. <br><br>  De plus, avant de couper chaque image, le script affiche son image, ce qui vous permet souvent de voir les photos ayant √©chou√© avant la prochaine √©tape de calibrage et de simplement les supprimer. <br><br>  Ex√©cutez le script: <br><br><pre> <code class="bash hljs">python 3_pairs_cut.py</code> </pre> <br>  Petite vid√©o: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/95DWmPECbDc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Dans l'image finale, il y a un ensemble de photographies et de paires de coupes que nous avons utilis√©es pour nos exp√©riences. <br><br><h3>  Calibration </h3><br>  Le script 4_calibration.py dessine toutes les paires avec les √©chiquiers et calcule les corrections n√©cessaires pour corriger les images.  Dans le sc√©nario, un rejet automatique des photographies sur lesquelles aucun √©chiquier n'a √©t√© trouv√© a √©t√© effectu√©, de sorte qu'en cas de photographies infructueuses, le travail ne s'arr√™te pas.  Une fois les 30 paires d'images t√©l√©charg√©es, le calcul d√©marre.  Cela nous prend environ une minute et demie.  Une fois termin√©, le script prend l'une des paires st√©r√©o et, sur la base des param√®tres d'√©talonnage calcul√©s, les ¬´corrige¬ª, affichant une image rectifi√©e √† l'√©cran.  √Ä ce stade, vous pouvez √©valuer la qualit√© de l'√©talonnage. <br><br>  Ex√©cut√© par la commande: <br><br><pre> <code class="bash hljs">python 4_calibration.py</code> </pre> <br>  Script d'√©talonnage en cours: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/vtPhu23tKGo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Configuration de la carte de profondeur </h3><br>  Le script 5_dm_tune.py charge l'image prise par le premier script et les r√©sultats de l'√©talonnage.  Ensuite, une interface s'affiche qui vous permet de modifier les param√®tres de la carte de profondeur et de voir ce qui change.  Astuce: avant de r√©gler les param√®tres, prenez un cadre dans lequel vous aurez simultan√©ment des objets √† diff√©rentes distances: proche (30-40 centim√®tres), √† une distance moyenne (m√®tre ou deux) et √† distance.  Cela vous permettra de choisir les param√®tres dans lesquels les objets proches seront rouges et les objets distants seront bleu fonc√©. <br><br>  L'image contient un fichier avec nos param√®tres de carte de profondeur.  Vous pouvez charger nos param√®tres dans un script en cliquant simplement sur le bouton ¬´Charger les param√®tres¬ª <br><br>  Nous lan√ßons: <br><br><pre> <code class="bash hljs">python 5_dm_tune.py</code> </pre> <br>  Voici √† quoi ressemble le processus de configuration: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Z4j3NrMyeGE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Carte de profondeur en temps r√©el </h3><br>  Le dernier script 6_dm_video.py construit une carte de profondeur √† partir de la vid√©o en utilisant les r√©sultats des scripts pr√©c√©dents (calibration et param√©trage de la carte de profondeur). <br><br>  Lancement: <br><br><pre> <code class="bash hljs">python 6_dm_video.py</code> </pre> <br>  En fait, le r√©sultat: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/f29arVstfZA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Nous esp√©rons que nos scripts vous seront utiles dans vos exp√©riences! <br><br>  Juste au cas o√π, j'ajouterai que tous les scripts ont un traitement de frappe, et vous pouvez interrompre le travail en appuyant sur le bouton Q. Si vous arr√™tez "grossi√®rement", par exemple, Ctrl + C, le processus d'interaction de Python avec la cam√©ra peut se casser et un red√©marrage de la framboise sera n√©cessaire. <br><br><h3>  Pour avanc√© </h3><br><ul><li>  Le premier script du processus affiche le temps moyen entre les captures d'image et, √† la fin, le FPS moyen.  Il s'agit d'un outil simple et pratique pour s√©lectionner de tels param√®tres d'image dans lesquels le python ne "s'√©touffe" toujours pas.  Avec lui, nous avons ramass√© 1280x480 √† 20 FPS, dans lequel la vid√©o est rendue sans d√©lai. </li><li>  Vous remarquerez peut-√™tre que nous capturons une paire st√©r√©o en r√©solution 1280x480, puis la redimensionnons √† 640x240. <br><br>  Une question raisonnable: pourquoi tout cela, et pourquoi ne pas saisir imm√©diatement la vignette et ne pas charger notre python en le r√©duisant? <br><br>  R√©ponse: avec la capture directe √† tr√®s basse r√©solution, il y a toujours des probl√®mes dans le c≈ìur de framboise (l'image se casse).  Par cons√©quent, nous prenons une r√©solution plus grande, puis r√©duisons l'image.  Ici, nous utilisons une petite astuce: l'image n'est pas mise √† l'√©chelle avec python, mais avec l'aide du GPU, donc il n'y a pas de charge sur le noyau du bras. </li><li>  Pourquoi capturer une vid√©o au format BGRA, pas BGR? <br>  Nous utilisons des ressources GPU pour r√©duire la taille de l'image, et le natif du module de redimensionnement est le format BGRA.  Si nous utilisons BGR au lieu de BGRA, nous aurons deux inconv√©nients.  Le premier est l√©g√®rement inf√©rieur au FPS final (dans nos tests - 20%).  Le second est le portage constant dans la console "PiCameraAlfaStripping: utiliser l'alpha-stripping pour convertir au format non alpha;  vous pouvez trouver un format alpha √©quivalent plus rapidement ¬ª.  La recherche sur Google a conduit √† la section de documentation de Picamera, qui d√©crit cette astuce. </li><li>  O√π est le PiRGBArray? <br><br>  C'est comme la classe native Picamera pour travailler avec l'appareil photo, mais ici, elle n'est pas utilis√©e.  Il s'est d√©j√† av√©r√© que dans nos tests, travailler avec un tableau numpy ¬´fait √† la main¬ª est beaucoup plus rapide (une fois et demie) que d'utiliser PiRGBArray.  Cela ne signifie pas que PiRGBArray est mauvais, ce sont probablement nos mains tordues. </li><li>  Quel est le pourcentage charg√© dans le calcul de la carte de profondeur? <br>  R√©pondons avec une photo: <br><br><img src="https://habrastorage.org/webt/nn/ez/ef/nnezefyxuiuxx7difz1xctii16w.jpeg"><br><br>  On voit que sur les 4 c≈ìurs du processeur, en fait, un seul est charg√©, soit 70%.  Et cela malgr√© le fait que nous travaillons avec une interface graphique et que nous fournissons des images et des cartes de profondeur √† l'utilisateur.  Cela signifie qu'il y a une bonne marge de performance, et un r√©glage fin d'OpenCV avec OpenMP et d'autres goodies en C, ainsi qu'un mode ¬´combat¬ª sans interface graphique peuvent donner des r√©sultats tr√®s int√©ressants. </li><li>  Quelle est la carte de profondeur FPS maximale obtenue avec ces param√®tres? <br><br>  Le maximum atteint par nous √©tait de 17 FPS, lors de la capture de 20 images par seconde de la cam√©ra.  Les param√®tres de vitesse les plus ¬´r√©actifs¬ª dans les param√®tres de la carte de profondeur sont MinDisparity et NumOfDisparities.  Ceci est logique, car ils d√©terminent le nombre "d'√©tapes" effectu√©es au sein de l'algorithme par la fen√™tre de recherche pour comparer les trames.  Le deuxi√®me plus r√©actif est preFilterCap, il affecte, en particulier, la ¬´fluidit√©¬ª de la carte de profondeur. </li><li>  Qu'en est-il de la temp√©rature du processeur? <br><br>  Sur Compute Module 3+ Lite (une nouvelle s√©rie, avec un ¬´cap¬ª de fer sur le processus), il montre √† peu pr√®s les r√©sultats suivants: <br><br><img src="https://habrastorage.org/webt/ba/p7/kw/bap7kwdbbhd0y2bmvebpqzimqpa.jpeg"></li><li>  Comment utiliser le GPU? <br><br>  Au minimum, il peut √™tre utilis√© pour l'istorisation et la rectification d'images en temps r√©el, car il existe des exemples ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici sur WebGL</a> ), Python <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pi3d</a> , ainsi que le projet Processing ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemples pour les framboises</a> ). <br><br>  Il y a un autre d√©veloppement int√©ressant de Koichi Nakamura, appel√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">py-videocore</a> .  Dans notre correspondance avec lui, il a exprim√© l'id√©e que pour acc√©l√©rer StereoBM, vous pouvez utiliser ses tris core et OpenCV <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">avec le support Cuda</a> .  En g√©n√©ral, pour l'optimisation - un bord intact, comme on dit. </li></ul><br>  Merci de votre attention et voici le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien promis vers la source</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr446872/">https://habr.com/ru/post/fr446872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr446860/index.html">Histoire de 3dfx Voodoo1</a></li>
<li><a href="../fr446862/index.html">√Ä quoi s'attendent les concepteurs √† DUMP-2019: Aper√ßu de la section Conception</a></li>
<li><a href="../fr446864/index.html">√ânergie, chaleur et eau</a></li>
<li><a href="../fr446866/index.html">Syst√®mes d'exploitation: trois pi√®ces faciles. Partie 2: Abstraction: Processus (traduction)</a></li>
<li><a href="../fr446870/index.html">Syst√®mes de particules: une histoire de No√´l</a></li>
<li><a href="../fr446876/index.html">Moscou, 18 avril - QIWI SERVER PARTY 4.0</a></li>
<li><a href="../fr446880/index.html">Graphiques incorrects: notre exp√©rience</a></li>
<li><a href="../fr446882/index.html">Le MIPT a re√ßu le droit d'accueillir la Coupe du monde de programmation ICPC en 2020 √† Moscou</a></li>
<li><a href="../fr446884/index.html">Que lire et regarder de la science-fiction fra√Æche: Mars, les cyborgs et l'IA rebelle</a></li>
<li><a href="../fr446886/index.html">Les meilleurs experts de l'Expo 3D: Sunny Wong. Plus de 25 millions d'entorses peuvent √™tre √©vit√©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéÖ ‚ôàÔ∏è üë∞üèº C√°lculo de canibalizaci√≥n basado en la prueba cl√°sica A / B y el m√©todo bootstrap ‚úçüèª üë©üèæ‚Äçü§ù‚Äçüë®üèª üëéüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este art√≠culo analiza un m√©todo para calcular la canibalizaci√≥n para una aplicaci√≥n m√≥vil basada en la prueba cl√°sica A / B. En este caso, las accione...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√°lculo de canibalizaci√≥n basado en la prueba cl√°sica A / B y el m√©todo bootstrap</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451488/">  Este art√≠culo analiza un m√©todo para calcular la canibalizaci√≥n para una aplicaci√≥n m√≥vil basada en la prueba cl√°sica A / B.  En este caso, las acciones objetivo se consideran y eval√∫an como parte del proceso de reasignaci√≥n de una fuente publicitaria (Direct, Criteo, AdWords UAC y otras) en comparaci√≥n con las acciones objetivo en el grupo en el que se deshabilit√≥ el anuncio. <br><br>  El art√≠culo ofrece una visi√≥n general de los m√©todos cl√°sicos para comparar muestras independientes con una breve base te√≥rica y una descripci√≥n de las bibliotecas utilizadas, incluyendo  describe brevemente la esencia del m√©todo bootstrap y su implementaci√≥n en la biblioteca FaceBook Bootstrapped, as√≠ como los problemas que surgen en la pr√°ctica al aplicar estas t√©cnicas y c√≥mo resolverlos. <br><a name="habracut"></a><br>  La evidencia se ofusca o no se proporciona para mantener un acuerdo de confidencialidad. <br><br>  En el futuro, planeo complementar y modificar ligeramente este art√≠culo a medida que aparezcan nuevos hechos, por lo que esta versi√≥n puede considerarse la primera versi√≥n.  Estar√≠a agradecido por los comentarios y cr√≠ticas. <br><br><h3>  Introduccion </h3> <br>  La canibalizaci√≥n es el proceso de flujo de tr√°fico, completo y dirigido, de un canal a otro. <br><br>  Los especialistas en marketing suelen utilizar este indicador como un coeficiente K adicional para calcular el CPA: el CPA calculado se multiplica por 1 + K.  En este caso, CPA significa el costo total de atraer tr√°fico / la cantidad de acciones dirigidas que se monetizan directamente, es decir, que trajeron el beneficio real, por ejemplo, una llamada dirigida y / o monetizadas indirectamente, por ejemplo, aumentar el volumen de la base de datos de anuncios, aumentar la audiencia, etc. <br><br>  Cuando los canales gratuitos (por ejemplo, visitas de SERPs org√°nicos, clics en enlaces en sitios que son gratuitos para nosotros) se canibalizan por pagos (directos, Adwords en lugar de org√°nicos, publicidad en feeds de redes sociales en lugar de hacer clic en anuncios, es gratis colocado en grupos, etc.), esto conlleva riesgos de p√©rdida financiera, por lo que es importante conocer la tasa de canibalizaci√≥n. <br><br>  En nuestro caso, la tarea consist√≠a en calcular la canibalizaci√≥n de las transiciones "org√°nicas" a la aplicaci√≥n mediante transiciones desde la red de publicidad de Criteo.  La vigilancia es un dispositivo o usuario-usuario (GAID / ADVID e IDFA). <br><br><h3>  Preparaci√≥n del experimento </h3><br>  Puede preparar a la audiencia para el experimento dividiendo a los usuarios en la interfaz del sistema anal√≠tico de AdJust en grupos para aislar a aquellos que ver√°n anuncios de una determinada red publicitaria (muestra de control) y aquellos que no mostrar√°n anuncios usando GAID o ADVID e IDFA, respectivamente (AdJust proporciona la API de Audience Builder).  Luego, en la muestra de control, puede incluir una campa√±a publicitaria en la red publicitaria estudiada en el experimento. <br><br>  Observo por m√≠ mismo que, como parece intuitivamente, la siguiente implementaci√≥n del experimento ser√≠a m√°s competente en este caso: seleccionar cuatro grupos: aquellos que ten√≠an retargeting deshabilitado de todos los canales (1), como el grupo experimental, y aquellos que ten√≠an solo retargeting habilitado con Criteo (2);  aquellos que solo ten√≠an retargeting desactivado con Criteo (3), aquellos que ten√≠an todo el retargeting (4) activado.  Entonces ser√≠a posible calcular (1) / (2), habiendo recibido el valor real de canibalizar las campa√±as publicitarias de la red Criteo para transiciones "org√°nicas" a la aplicaci√≥n, y (3) / (4), haber recibido canibalizar a Criteo en el entorno "natural" (despu√©s de todo, Criteo, obviamente puede canibalizar otros canales pagos tambi√©n).  El mismo experimento debe repetirse para otras redes publicitarias para descubrir el impacto de cada una de ellas;  En un mundo ideal, ser√≠a bueno explorar la canibalizaci√≥n cruzada entre todas las fuentes pagas clave que conforman la mayor parte del tr√°fico total, pero tomar√≠a mucho tiempo (tanto para preparar experimentos desde el punto de vista del desarrollo como para evaluar los resultados), lo que causar√≠a cr√≠tica por meticulosidad irracional. <br><br>  De hecho, nuestro experimento se llev√≥ a cabo en las condiciones (3) y (4), las muestras se dividieron en una proporci√≥n del 10% al 90%, el experimento se realiz√≥ durante 2 semanas. <br><br><h3>  Preparaci√≥n y verificaci√≥n de datos. </h3><br>  Antes de comenzar cualquier estudio, un paso importante es la capacitaci√≥n previa competente y la limpieza de datos. <br><br>  Cabe se√±alar que, de hecho, los dispositivos activos para el per√≠odo de experimento fueron 2 veces menos (42.5% y 50% de los grupos de control y experimentales, respectivamente) que los dispositivos en las muestras iniciales completas, lo que se explica por la naturaleza de los datos: <br><br><ol><li>  en primer lugar (y esta es la raz√≥n clave), la selecci√≥n para reorientar desde Ajustar contiene los identificadores de todos los dispositivos que alguna vez han instalado la aplicaci√≥n, es decir, aquellos dispositivos que ya no est√°n en uso y aquellos con los que la aplicaci√≥n ya estaba eliminado </li><li>  en segundo lugar, no es necesario que todos los dispositivos hayan iniciado sesi√≥n en la aplicaci√≥n durante el experimento. </li></ol><br>  Sin embargo, calculamos la canibalizaci√≥n en base a los datos de una muestra completa.  Para m√≠ personalmente, la exactitud de dicho c√°lculo todav√≠a parece un punto discutible; en general, en mi opini√≥n, es m√°s correcto limpiar a todos aquellos que desinstalaron la aplicaci√≥n y no la instalaron con las etiquetas correspondientes, as√≠ como a aquellos que no han iniciado sesi√≥n en la aplicaci√≥n durante m√°s de un a√±o. este per√≠odo de tiempo el usuario podr√≠a cambiar el dispositivo;  menos: de esta forma, para el experimento, aquellos usuarios que no cambiaron a la aplicaci√≥n, pero que pod√≠an hacerlo, podr√≠an ser eliminados de la selecci√≥n si les mostramos anuncios en la red de Criteo.  Quiero se√±alar que en un buen mundo, todos estos descuidos forzados y suposiciones deben investigarse y verificarse por separado, pero vivimos en un mundo donde hacerlo r√°pido y furioso. <br><br>  En nuestro caso, es importante verificar los siguientes puntos: <br><br><ol><li>  Verificamos la intersecci√≥n en nuestras muestras iniciales: experimental y de control.  En un experimento implementado correctamente, tales intersecciones no deber√≠an ser, sin embargo, en nuestro caso, hubo varios duplicados de la muestra experimental en el control.  En nuestro caso, la proporci√≥n de estos duplicados en el volumen total de dispositivos involucrados en el experimento fue peque√±a; por lo tanto, descuidamos esta condici√≥n.  Si hubo&gt; 1% de duplicados, el experimento deber√≠a considerarse incorrecto y deber√≠a realizarse un segundo experimento, habiendo limpiado previamente los duplicados. </li><li>  Verificamos que los datos en el experimento se vieron realmente afectados: el retargeting deber√≠a haberse desactivado en la muestra experimental (al menos con Criteo, en el experimento configurado correctamente, de todos los canales), por lo tanto, es necesario verificar la ausencia de DeviceID del experimento en el retargeting con Criteo.  En nuestro caso, DeviceID del grupo experimental, sin embargo, cay√≥ en la reorientaci√≥n, pero hubo menos del 1%, lo que es insignificante. </li></ol><br><h3>  Evaluaci√≥n directa del experimento. </h3><br>  Consideraremos el cambio en las siguientes m√©tricas de destino: absoluto: el n√∫mero de llamadas y relativo: el n√∫mero de llamadas por usuario en el control (vio anuncios en la red Criteo) y grupos experimentales (los anuncios fueron deshabilitados).  En el siguiente c√≥digo, los datos variables se refieren a la estructura pandas.DataFrame, que se forma a partir de los resultados de una muestra experimental o de control. <br><br>  Existen m√©todos param√©tricos y no param√©tricos para evaluar la significancia estad√≠stica de la diferencia de valores en muestras no relacionadas.  Los criterios de evaluaci√≥n param√©trica dan una mayor precisi√≥n, pero tienen limitaciones en su aplicaci√≥n; en particular, una de las condiciones principales es que los valores medidos para las observaciones en la muestra deben distribuirse normalmente. <br><br><h4>  1. El estudio de la distribuci√≥n de valores en las muestras para normalidad. </h4><br>  El primer paso es examinar las muestras existentes para el tipo de distribuci√≥n de valores y la igualdad de las variaciones de las muestras usando pruebas est√°ndar: los criterios de Kolmogorov-Smirnov y Shapiro-Wilks y la prueba de Bartlett implementada en la biblioteca sklearn.stats, tomando el valor p = 0.05: <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : def norm_test(df, pvalue = 0.05, test_name = 'kstest'): if test_name == 'kstest': st = stats.kstest(df, 'norm') if test_name == 'shapiro': st = stats.shapiro(df) sys.stdout.write('According to {} {} is {}normal\n'.format(test_name, df.name, {True:'NOT ', False:''}[st[1] &lt; pvalue])) #    : def barlett_test(df1, df2, pvalue = 0.05): st = stats.bartlett(df1, df2) sys.stdout.write('Variances of {} and {} is {}equals\n'.format(df1.name, df2.name, {True:'NOT ', False:''}[st[1] &lt; pvalue]))</span></span></code> </pre> <br>  Adem√°s, para una evaluaci√≥n visual de los resultados, puede usar la funci√≥n de histograma. <br><br><pre> <code class="python hljs">data_agg = data.groupby([<span class="hljs-string"><span class="hljs-string">'bucket'</span></span>]).aggregate({<span class="hljs-string"><span class="hljs-string">'device_id'</span></span>: <span class="hljs-string"><span class="hljs-string">'nunique'</span></span>, <span class="hljs-string"><span class="hljs-string">'calls'</span></span>: <span class="hljs-string"><span class="hljs-string">'sum'</span></span>}).fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>) data_conv = data_agg[<span class="hljs-string"><span class="hljs-string">'calls_auto'</span></span>]/data_agg[<span class="hljs-string"><span class="hljs-string">'device_id'</span></span>] data_conv.hist(bins=<span class="hljs-number"><span class="hljs-number">20</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/8m/zc/u4/8mzcu4-emautrimdpvczuttfkf8.png" alt="imagen"><br><br>  Puede leer el histograma de esta manera: 10 veces en la muestra hubo una conversi√≥n de 0.08, 1 - 0.14.  Esto no dice nada sobre el n√∫mero de dispositivos como observaciones para ninguno de los indicadores de conversi√≥n. <br><br>  En nuestro caso, la distribuci√≥n del valor del par√°metro tanto en valores absolutos como en relaci√≥n (el n√∫mero de llamadas al dispositivo) en las muestras no es normal. <br>  En este caso, puede usar la prueba no param√©trica de Wilcoxon implementada en la biblioteca est√°ndar sklearn.stats, o tratar de llevar la distribuci√≥n de valores en las muestras a la forma normal y aplicar uno de los criterios param√©tricos: la prueba t de Student o la prueba Shapiro-Wilks. <br><br><h4>  2. M√©todos para reducir la distribuci√≥n de valores en muestras a la forma normal </h4><br>  <b>2.1.</b>  <b>Subcapas</b> <br><br>  Un enfoque para llevar la distribuci√≥n a la normalidad es el m√©todo del subgrupo.  Su esencia es simple, y la siguiente tesis matem√°tica es la base te√≥rica: de acuerdo con el teorema del l√≠mite central cl√°sico, la distribuci√≥n de medias tiende a ser normal: la suma de n variables aleatorias distribuidas id√©nticamente independientes tiene una distribuci√≥n cercana a la normal y, de manera equivalente, la distribuci√≥n de medias muestrales de las primeras n aleatorias distribuidas id√©nticamente independientes Las cantidades tienden a la normalidad.  Por lo tanto, podemos dividir los cubos existentes en subcubetas y, en consecuencia, tomando los valores promedio de subcapas para cada uno de los cubos, podemos obtener una distribuci√≥n cercana a la normal: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   subbucket' data['subbucket'] = data['device_id'].apply(lambda x: randint(0,1000)) # Variant 1 data['subbucket'] = data['device_id'].apply(lambda x: hash(x)%1000) # Variant 2</span></span></code> </pre> <br>  Puede haber muchas opciones para dividir, todo depende de la imaginaci√≥n y los principios morales del desarrollador: puede tomar un azar honesto o usar hash del cubo original, teniendo en cuenta el mecanismo para emitirlo en el esquema. <br><br>  Sin embargo, en la pr√°ctica, de varias docenas de lanzamientos de c√≥digo, recibimos la distribuci√≥n normal solo una vez, es decir, este m√©todo no est√° garantizado ni es estable. <br><br>  Adem√°s, la proporci√≥n de acciones y usuarios objetivo con respecto al n√∫mero total de acciones y usuarios en el subgrupo puede no ser coherente con los backets iniciales, por lo que primero debe verificar que se mantenga la proporci√≥n. <br><br><pre> <code class="python hljs">data[data[<span class="hljs-string"><span class="hljs-string">'calls'</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>].device_id.nunique()/data.device_id.nunique() <span class="hljs-comment"><span class="hljs-comment"># Total buckets = data.groupby(['bucket']).aggregate({'device_id': 'nunique', 'calls': 'sum'}) buckets[buckets['calls'] &gt; 0].device_id.nunique()/buckets.device_id.nunique() # Buckets subbuckets = data.groupby(['subbucket']).aggregate({'device_id': 'nunique', 'calls': 'sum'}) subbuckets[subbuckets['calls'] &gt; 0].device_id.nunique()/subbuckets.device_id.nunique() # Subbuckets</span></span></code> </pre> <br>  En el proceso de dicha verificaci√≥n, descubrimos que las relaciones de conversi√≥n para subgrupos en relaci√≥n con la selecci√≥n original no se conservan.  Dado que necesitamos garantizar adicionalmente la consistencia de la proporci√≥n de la proporci√≥n de llamadas en las muestras de salida y de origen, utilizamos el equilibrio de clases, agregando ponderaci√≥n para que los datos se seleccionen por separado por subgrupos: por separado de las observaciones con acciones objetivo y por separado de las observaciones sin acciones objetivo en la proporci√≥n correcta.  Adem√°s, en nuestro caso, las muestras se distribuyeron de manera desigual;  intuitivamente, parece que el promedio no deber√≠a cambiar, pero la forma en que la no uniformidad de las muestras afecta la varianza no es obvio a partir de la f√≥rmula de dispersi√≥n.  Para aclarar si la diferencia en el tama√±o de las muestras afecta el resultado, se utiliza el criterio Xi-cuadrado: si se detecta una diferencia estad√≠sticamente significativa, se tomar√°n muestras de un marco de datos m√°s grande con un tama√±o m√°s peque√±o: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">class_arrays_balancer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df1, df2, target = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'calls'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, pvalue=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.05</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> df1_target_size = len(df1[df1[target] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>]) print(df1.columns.to_list()) df2_target_size = len(df2[df2[target] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>]) total_target_size = df1_target_size + df2_target_size chi2_target, pvalue_target, dof_target, expected_target = chi2_contingency([[df1_target_size, total_target_size], [df2_target_size, total_target_size]]) df1_other_size = len(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>]) df2_other_size = len(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>]) total_other_size = df1_other_size + df2_other_size chi2_other, pvalue_other, dof_other, expected_other = chi2_contingency([[df1_other_size, total_other_size], [df2_other_size, total_other_size]]) df1_target, df2_target, df1_other, df2_other = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> pvalue_target &lt; pvalue: sample_size = min([df1_target_size, df2_target_size]) df1_rnd_indx = np.random.choice(df1_target_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df2_rnd_indx = np.random.choice(df2_target_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df1_target = pd.DataFrame((np.asarray(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">1</span></span>])[df1_rnd_indx]).tolist(), columns = df1.columns.tolist()) df2_target = pd.DataFrame((np.asarray(df2[df2[target] == <span class="hljs-number"><span class="hljs-number">1</span></span>])[df2_rnd_indx]).tolist(), columns = df2.columns.tolist()) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p_value_other &lt; pvalue: sample_size = min([df1_other_size, df2_other_size]) df1_rnd_indx = np.random.choice(df1_other_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df2_rnd_indx = np.random.choice(df2_other_size, size=sample_size, replace=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) df1_other = pd.DataFrame((np.asarray(df1[df1[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>])[df1_rnd_indx]).tolist(), columns = df1.columns.tolist()) df2_other = pd.DataFrame((np.asarray(df2[df2[target] == <span class="hljs-number"><span class="hljs-number">0</span></span>])[df2_rnd_indx]).tolist(), columns = df2.columns.tolist()) df1 = pd.concat([df1_target, df1_other]) df2 = pd.concat([df2_target, df2_other]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df1, df2 exp_classes, control_classes = class_arrays_balancer(data_exp, data_control)</code> </pre> <br>  En la salida, obtenemos datos equilibrados en tama√±o y consistentes con las relaciones de conversi√≥n iniciales, las m√©tricas estudiadas (calculadas para los valores promedio para el subgrupo) en las que ya est√°n distribuidas normalmente, lo que puede verse tanto visualmente como por los resultados de aplicar los criterios de prueba que ya conocemos. normalidad (con valor p&gt; = 0.05).  Por ejemplo, para indicadores relativos: <br><br><pre> <code class="python hljs">data_conv = (data[data[<span class="hljs-string"><span class="hljs-string">'calls'</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>].groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.sum()*<span class="hljs-number"><span class="hljs-number">1.0</span></span>/data.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).device_id.nunique()) data_conv.hist(bins = <span class="hljs-number"><span class="hljs-number">50</span></span>)</code> </pre> <br>  Ahora, la prueba t se puede aplicar al promedio sobre sub-bucket'es (por lo tanto, no es device_id, no es un dispositivo, sino un sub-bucket que act√∫a como una observaci√≥n). <br><br>  Despu√©s de asegurarnos de que los cambios son estad√≠sticamente significativos, podemos, con la conciencia tranquila, hacer lo que comenzamos a hacer: calcular la canibalizaci√≥n: <br><br><pre> <code class="python hljs">(data_exp.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg() - data_cntrl.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg() )/ data_exp.groupby([<span class="hljs-string"><span class="hljs-string">'subbucket'</span></span>]).calls.avg()</code> </pre> <br>  El denominador debe ser el tr√°fico sin anuncios, es decir, experimental. <br><br><h4>  3. M√©todo Bootstrap </h4><br>  El m√©todo bootstrap es una extensi√≥n del m√©todo sub-bucket y representa su versi√≥n m√°s avanzada y mejorada;  Puede encontrar una implementaci√≥n de software de este m√©todo en Python en la biblioteca de Facebook Bootstrapped. <br>  Brevemente, la idea de bootstrap se puede describir de la siguiente manera: un m√©todo no es m√°s que un constructor de muestras generadas de manera similar a los m√©todos de subgrupos al azar, pero con posibles repeticiones.  Podemos decir la ubicaci√≥n de la poblaci√≥n general (si se puede llamar a la muestra original) con el retorno.  En la salida, se forman promedios (o medianas, cantidades, etc.) a partir de los promedios para cada una de las submuestras generadas. <br><br>  <i>Los principales m√©todos de la biblioteca FaceBook Bootstrap</i> : <br><pre> <code class="python hljs">bootstrap()</code> </pre>  - implementa un mecanismo para la formaci√≥n de submuestras;  devuelve el l√≠mite inferior (percentil 5) y el l√≠mite superior (percentil 95) de forma predeterminada;  para devolver una distribuci√≥n discreta en este rango, debe establecer el par√°metro <i>return_distribution = True</i> (lo genera la funci√≥n auxiliar <i>generate_distributions ()</i> ). <br><br>  Puede especificar el n√∫mero de iteraciones utilizando el par√°metro <i>num_iterations</i> , en el que se generar√°n submuestras, y el n√∫mero de submuestras iteration_batch_size para cada iteraci√≥n.  La salida de <i>generate_distributions ()</i> generar√° una muestra con un tama√±o igual al n√∫mero de iteraciones <i>num_iterations</i> , <i>cuyos</i> elementos ser√°n el promedio de los valores de las muestras <i>iteration_batch_size</i> calculadas en cada iteraci√≥n.  Con grandes vol√∫menes de muestras, es posible que los datos ya no quepan en la memoria, por lo que en tales casos es aconsejable reducir el valor de <i>iteration_batch_size</i> . <br><br>  <i>Ejemplo</i> : deje que la muestra original sea 2,000,000;  <i>num_iterations</i> = 10,000, <i>iteration_batch_size</i> = 300. Luego, en cada una de 10,000 iteraciones, se almacenar√°n 300 listas de 2,000,000 de elementos en la memoria. <br><br>  La funci√≥n tambi√©n permite la computaci√≥n paralela en varios n√∫cleos de procesador, en varios hilos, configurando el n√∫mero requerido usando el par√°metro <i>num_threads</i> . <br><br><pre> <code class="python hljs">bootstrap_ab()</code> </pre> <br>  realiza las mismas acciones que la funci√≥n <i>bootstrap ()</i> descrita anteriormente, sin embargo, adem√°s, los valores promedio tambi√©n se agregan mediante el m√©todo especificado en <i>stat_func</i> - from <i>num_iterations</i>  A continuaci√≥n, se calcula la m√©trica especificada en el par√°metro compare_func y se estima la significancia estad√≠stica. <br><br><pre> <code class="python hljs">compare_functions</code> </pre> <br>  - una clase de funciones que proporciona herramientas para la formaci√≥n de m√©tricas para la evaluaci√≥n: <br><pre> <code class="python hljs">compare_functions.difference() compare_functions.percent_change() compare_functions.ratio() compare_functions.percent_difference() <span class="hljs-comment"><span class="hljs-comment"># difference = (test_stat - ctrl_stat) # percent_change = (test_stat - ctrl_stat) * 100.0 / ctrl_stat # ratio = test_stat / ctrl_stat # percent_difference = (test_stat - ctrl_stat) / ((test_stat + ctrl_stat) / 2.0) * 100.0</span></span></code> </pre> <br><pre> <code class="python hljs">stats_functions</code> </pre>  - una clase de funciones de las cuales se selecciona el m√©todo de agregaci√≥n de la m√©trica estudiada: <br><pre> <code class="python hljs">stats_functions.mean stats_functions.sum stats_functions.median stats_functions.std</code> </pre> <br>  Como <i>stat_func,</i> tambi√©n puede usar una funci√≥n personalizada definida por el usuario, por ejemplo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(test_stat, ctrl_stat)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (test_stat - ctrl_stat)/test_stat bs.bootstrap_ab(test.values, control.values, stats_functions.mean, test_func, num_iterations=<span class="hljs-number"><span class="hljs-number">5000</span></span>, alpha=<span class="hljs-number"><span class="hljs-number">0.05</span></span>, iteration_batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span>, scale_test_by=<span class="hljs-number"><span class="hljs-number">1</span></span>, num_threads=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br>  De hecho, <i>(test_stat - ctrl_stat) / test_stat</i> es la f√≥rmula para calcular nuestra canibalizaci√≥n. <br><br>  Alternativamente, o con el prop√≥sito de un experimento pr√°ctico, inicialmente puede obtener distribuciones usando <i>bootstrap ()</i> , verificar la significaci√≥n estad√≠stica de las diferencias en las m√©tricas objetivo usando la prueba t y luego aplicarles las manipulaciones necesarias. <br>  Un ejemplo de c√≥mo se puede obtener la distribuci√≥n normal de "calidad" utilizando este m√©todo: <br><br><img src="https://habrastorage.org/webt/pc/is/ws/pciswsulv_wuinbcqkn-hgmluwe.png"><br><br>  Se puede encontrar documentaci√≥n m√°s detallada en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la p√°gina del repositorio</a> . <br><br>  Por el momento, esto es todo de lo que quer√≠a (o pude hablar).  Trat√© de describir breve pero claramente los m√©todos utilizados y el proceso de su implementaci√≥n.  Es posible que las metodolog√≠as requieran un ajuste, por lo que agradecer√© sus comentarios y revisiones. <br><br>  Tambi√©n quiero agradecer a mis colegas por su ayuda en la preparaci√≥n de este trabajo.  Si el art√≠culo recibe comentarios predominantemente positivos, indicar√© aqu√≠ sus nombres o apodos (por acuerdo previo). <br><br>  ¬°Mis mejores deseos para todos!  :) <br><br>  PD <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Estimado Championship Channel</a> , la tarea de evaluar los resultados de las pruebas A / B es una de las m√°s importantes en Data Science, porque ni un lanzamiento de un nuevo modelo ML en producci√≥n est√° completo sin A / B.  ¬øQuiz√°s es hora de organizar una competencia para desarrollar un sistema para evaluar los resultados de las pruebas A / B?  :) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/451488/">https://habr.com/ru/post/451488/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../451468/index.html">El resumen de materiales frescos del mundo del front-end para la √∫ltima semana No. 364 (6 al 12 de mayo de 2019)</a></li>
<li><a href="../451476/index.html">LLVM en t√©rminos de Go</a></li>
<li><a href="../451478/index.html">Acelerar la exploraci√≥n de datos utilizando la biblioteca de perfiles de pandas</a></li>
<li><a href="../451480/index.html">¬øPor qu√© el Ministerio de Industria y Comercio proh√≠be el almacenamiento de datos en equipos extranjeros?</a></li>
<li><a href="../451482/index.html">Competencias de un programador moderno desde un √°ngulo diferente</a></li>
<li><a href="../451492/index.html">Siete variables inesperadas de Bash</a></li>
<li><a href="../451496/index.html">Mitap Netologii "Carreras en ciencia de datos para principiantes"</a></li>
<li><a href="../451498/index.html">Food Design Digest, abril de 2019</a></li>
<li><a href="../451502/index.html">Eventos digitales en Mosc√∫ del 13 al 19 de mayo</a></li>
<li><a href="../451504/index.html">Fotos en la web 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
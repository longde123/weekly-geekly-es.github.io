<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöã üòã ‚òØÔ∏è Kostenlose Tensorprozessoren von Google in der Colaboratory Cloud üë©üèø‚Äçü§ù‚Äçüë®üèΩ üêñ üç§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Google hat k√ºrzlich freien Zugriff auf seine Tensor Processing Unit (TPU) auf der Cloud-basierten Plattform f√ºr maschinelles Lernen von Colaboratory b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kostenlose Tensorprozessoren von Google in der Colaboratory Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428117/">  Google hat k√ºrzlich freien Zugriff auf seine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensor</a> Processing Unit (TPU) auf der Cloud-basierten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Plattform f√ºr</a> maschinelles Lernen von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Colaboratory</a> bereitgestellt.  Der Tensorprozessor ist ein spezialisierter integrierter Schaltkreis (ASIC), der von Google f√ºr maschinelle Lernaufgaben unter Verwendung der TensorFlow-Bibliothek entwickelt wurde.  Ich habe mich entschlossen, ein TPU-Faltungsnetzwerk auf Keras zu erlernen, das Objekte in CIFAR-10-Bildern erkennt.  Der vollst√§ndige L√∂sungscode kann auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laptop</a> angezeigt und ausgef√ºhrt werden. <br><br><img src="https://habrastorage.org/webt/sl/ut/ho/slutho5dsyeduk2biql9rcsblnu.jpeg"><br>  <i>Foto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.google.com</a></i> <br><a name="habracut"></a><br><h2>  Tensorprozessoren </h2><br>  Auf Habr√© wurde bereits geschrieben, wie TPUs angeordnet sind ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ) und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">warum TPUs f√ºr das Training neuronaler Netze gut geeignet sind</a> .  Daher werde ich nicht auf die Details der TPU-Architektur eingehen, sondern nur die Funktionen ber√ºcksichtigen, die beim Training neuronaler Netze ber√ºcksichtigt werden m√ºssen. <br><br>  Jetzt gibt es drei Generationen von Tensorprozessoren. Die TPU-Leistung der letzten und dritten Generation betr√§gt 420 TFlops (Billionen von Gleitkommaoperationen pro Sekunde) und enth√§lt 128 GB Speicher mit hoher Bandbreite.  Im Colaboratory sind jedoch nur TPUs der zweiten Generation verf√ºgbar, die √ºber 180 TFlops Leistung und 64 GB Speicher verf√ºgen.  In Zukunft werde ich diese TPUs ber√ºcksichtigen. <br><br>  Der Tensorprozessor besteht aus vier Chips, von denen jeder zwei Kerne enth√§lt, insgesamt acht Kerne in TPU.  Das TPU-Training wird parallel auf allen Kernen mithilfe der Replikation durchgef√ºhrt: Eine Kopie des TensorFlow-Diagramms mit einem Achtel des Datenvolumens wird auf jedem Kern ausgef√ºhrt. <br><br>  Die Basis des Tensorprozessors ist eine Matrixeinheit (MXU).  Es verwendet die listige Datenstruktur eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">systolischen Arrays mit</a> 128 x 128 f√ºr eine effiziente Implementierung von Matrixoperationen.  Um die Nutzung der TPU-Ausr√ºstungsressourcen zu maximieren, muss die Dimension des Mini-Samples oder der Mini-Features daher ein Vielfaches von 128 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> ) sein.  Aufgrund der Natur des TPU-Speichersystems ist es auch w√ºnschenswert, dass die Abmessung des Mini-Samples und der Merkmale ein Vielfaches von 8 ist. <br><br><h2>  Laborplattform </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Colaboratory</a> ist Googles Cloud-Plattform zur Weiterentwicklung der Technologie f√ºr maschinelles Lernen.  Sie k√∂nnen eine virtuelle Maschine mit den installierten beliebten Bibliotheken TensorFlow, Keras, sklearn, pandas usw. kostenlos herunterladen.  Am bequemsten ist es, wenn Sie Laptops √§hnlich wie Jupyter im Labor ausf√ºhren k√∂nnen.  Laptops werden auf Google Drive gespeichert. Sie k√∂nnen sie verteilen und sogar die Zusammenarbeit organisieren.  So sieht der Laptop im Labor aus (das <i>Bild kann angeklickt werden</i> ): <br><br> <a href=""><img src="https://habrastorage.org/webt/4b/gp/sn/4bgpsnbpkhwyqrid6fixnaurcbw.png"></a> <br><br>  Sie schreiben den Code in einem Browser auf einem Laptop, er l√§uft auf einer virtuellen Maschine in der Google Cloud.  Das Auto wird Ihnen f√ºr 12 Stunden ausgestellt, danach h√§lt es an.  Nichts hindert Sie jedoch daran, eine andere virtuelle Maschine zu starten und weitere 12 Stunden zu arbeiten.  Denken Sie daran, dass nach dem Stoppen der virtuellen Maschine alle Daten von ihr gel√∂scht werden.  Vergessen Sie daher nicht, die erforderlichen Daten auf Ihrem Computer oder Google Drive zu speichern und nach dem Neustart der virtuellen Maschine erneut herunterzuladen. <br><br>  Detaillierte Anweisungen zur Arbeit an der Colaboratory-Plattform finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><h2>  Schlie√üen Sie den Tensorprozessor an das Labor an </h2><br>  Standardm√§√üig verwendet Colaboratory keine GPU- oder TPU-Berechnungsbeschleuniger.  Sie k√∂nnen sie √ºber das Men√º Laufzeit -&gt; Laufzeittyp √§ndern -&gt; Hardwarebeschleuniger verbinden.  W√§hlen Sie in der angezeigten Liste "TPU" aus: <br><img src="https://habrastorage.org/webt/1f/7r/vt/1f7rvtfjvdowdjwrz0ctgyyly7s.png" alt="Bild"><br><br>  Nach Auswahl des Beschleunigertyps wird die virtuelle Maschine, an die der Colaboratory-Laptop angeschlossen ist, neu gestartet und die TPU wird verf√ºgbar. <br><br>  Wenn Sie Daten auf die virtuelle Maschine heruntergeladen haben, werden diese w√§hrend des Neustarts gel√∂scht.  Sie m√ºssen die Daten erneut herunterladen. <br><br><h2>  Keras Neural Network f√ºr die CIFAR-10-Erkennung </h2><br>  Versuchen wir beispielsweise, ein Keras-Neuronales Netzwerk auf TPU zu trainieren, das Bilder aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CIFAR-10-Datensatz</a> erkennt.  Dies ist ein beliebter Datensatz, der kleine Bilder von Objekten aus 10 Klassen enth√§lt: Flugzeug, Auto, Vogel, Katze, Hirsch, Hund, Frosch, Pferd, Schiff und LKW.  Klassen √ºberschneiden sich nicht, jedes Objekt im Bild geh√∂rt nur einer Klasse an. <br><br>  Laden Sie den CIFAR-10-Datensatz mit Keras herunter: <br><br><pre><code class="python hljs">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</code> </pre> <br>  Um ein neuronales Netzwerk zu erstellen, habe ich eine separate Funktion.  Wir werden dasselbe Modell zweimal erstellen: die erste Version des Modells f√ºr TPU, auf der wir trainieren werden, und die zweite f√ºr die CPU, auf der wir Objekte erkennen. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_layer = Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=tf.float32, name=<span class="hljs-string"><span class="hljs-string">'Input'</span></span>) x = BatchNormalization()(input_layer) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = BatchNormalization()(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = Flatten()(x) x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) output_layer = Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[input_layer], outputs=[output_layer]) model.compile( optimizer=tf.train.AdamOptimizer(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[<span class="hljs-string"><span class="hljs-string">'sparse_categorical_accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Bisher k√∂nnen Keras-Optimierer nicht f√ºr TPUs verwendet werden. Daher wird beim Kompilieren eines Modells der Optimierer von TensorFlow angegeben. <br><br>  Wir erstellen ein Keras-Modell f√ºr die CPU, das wir im n√§chsten Schritt in ein Modell f√ºr TPU konvertieren werden: <br><br><pre> <code class="python hljs">cpu_model = create_model()</code> </pre> <br><h2>  Konvertieren Sie das neuronale Keras-Netzwerk in das TPU-Modell </h2><br>  Modelle auf Keras und TensorFlow k√∂nnen ohne √Ñnderungen auf der GPU trainiert werden.  Sie k√∂nnen dies bisher nicht auf TPU tun, daher m√ºssen Sie das von uns erstellte Modell in ein Modell f√ºr TPU konvertieren. <br><br>  Zuerst m√ºssen Sie herausfinden, wo sich die uns zur Verf√ºgung stehende TPU befindet.  Auf der Colaboratory-Plattform kann dies mit dem folgenden Befehl erfolgen: <br><br><pre> <code class="python hljs">TPU_WORKER = <span class="hljs-string"><span class="hljs-string">'grpc://'</span></span> + os.environ[<span class="hljs-string"><span class="hljs-string">'COLAB_TPU_ADDR'</span></span>]</code> </pre> <br>  In meinem Fall stellte sich heraus, dass die TPU-Adresse <code>grpc://10.102.233.146:8470</code> .  Die Adressen waren f√ºr verschiedene Starts unterschiedlich. <br><br>  Jetzt k√∂nnen Sie das Modell f√ºr TPU mit der Funktion <code>keras_to_tpu_model</code> : <br><br><pre> <code class="python hljs">tf.logging.set_verbosity(tf.logging.INFO) tpu_model = tf.contrib.tpu.keras_to_tpu_model( cpu_model, strategy=tf.contrib.tpu.TPUDistributionStrategy( tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))</code> </pre> <br>  Die erste Zeile enth√§lt die Protokollierung auf Info-Ebene.  Hier ist das Modellkonvertierungsprotokoll: <br><br> <code>INFO:tensorflow:Querying Tensorflow master (b'grpc://10.102.233.146:8470') for TPU system metadata. <br> INFO:tensorflow:Found TPU system: <br> INFO:tensorflow:*** Num TPU Cores: 8 <br> INFO:tensorflow:*** Num TPU Workers: 1 <br> INFO:tensorflow:*** Num TPU Cores Per Worker: 8 <br> ... <br> WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.</code> <br> <br>  Sie k√∂nnen sehen, dass TPU an der zuvor angegebenen Adresse gefunden wurde und 8 Kerne hat.  Wir sehen auch eine Warnung, dass <code>tpu_model</code> experimentell ist und jederzeit ge√§ndert oder gel√∂scht werden kann.  Ich hoffe, dass es im Laufe der Zeit m√∂glich sein wird, Keras-Modelle ohne Konvertierung direkt auf TPU zu trainieren. <br><br><h2>  Wir trainieren Modell auf TPU </h2><br>  Das Modell f√ºr TPU kann auf die f√ºr Keras √ºbliche Weise trainiert werden, indem die <code>fit</code> aufgerufen wird: <br><br><pre> <code class="python hljs">history = tpu_model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>*<span class="hljs-number"><span class="hljs-number">8</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br>  Was sind die Funktionen hier.  Wir erinnern uns, dass die Mini-Stichprobengr√∂√üe ein Vielfaches von 128 sein muss, um TPUs effektiv nutzen zu k√∂nnen. Au√üerdem wird an jedem TPU-Kern mit einem Achtel aller Daten in der Mini-Stichprobe trainiert.  Daher setzen wir die Gr√∂√üe des Mini-Samples w√§hrend des Trainings auf 128 * 8, wir erhalten 128 Bilder f√ºr jeden TPU-Kern.  Sie k√∂nnen eine gr√∂√üere Gr√∂√üe verwenden, z. B. 256 oder 512, dann ist die Leistung h√∂her. <br><br>  In meinem Fall erfordert das Training einer √Ñra durchschnittlich 6 s. <br><br>  Die Qualit√§t der Bildung in der 50. √Ñra: <br> <code>Epoch 50/50 <br> - 6s - loss: 0.2727 - sparse_categorical_accuracy: 0.9006</code> <br> <br>  Der Anteil der richtigen Antworten auf die Trainingsdaten betrug 90,06%.  Wir √ºberpr√ºfen die Qualit√§t der Testdaten mit TPU: <br><br><pre> <code class="python hljs">scores = tpu_model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, batch_size=batch_size * <span class="hljs-number"><span class="hljs-number">8</span></span>) print(<span class="hljs-string"><span class="hljs-string">"     : %.2f%%"</span></span> % (scores[<span class="hljs-number"><span class="hljs-number">1</span></span>]*<span class="hljs-number"><span class="hljs-number">100</span></span>))</code> </pre> <br> <code>     : 80.79%</code> <br> <br>  Speichern Sie nun die Gewichte des trainierten Modells: <br><br><pre> <code class="python hljs">tpu_model.save_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  TensorFlow gibt uns eine Nachricht, dass die Gewichte von der TPU zur CPU √ºbertragen werden: <br> <code>INFO:tensorflow:Copying TPU weights to the CPU</code> <br> <br>  Es ist zu beachten, dass die Gewichte des trainierten Netzwerks auf der Festplatte der virtuellen Colaboratory-Maschine gespeichert wurden.  Wenn die virtuelle Maschine gestoppt wird, werden alle Daten von ihr gel√∂scht.  Wenn Sie trainierte Gewichte nicht verlieren m√∂chten, speichern Sie sie auf Ihrem Computer: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> files files.download(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br><h2>  Objekte auf der CPU erkennen </h2><br>  Versuchen wir nun, ein auf TPU trainiertes Modell zu verwenden, um Objekte in Bildern mithilfe der CPU zu erkennen.  Erstellen Sie dazu das Modell erneut und laden Sie die auf TPU trainierten Gewichte hinein: <br><br><pre> <code class="python hljs">model = create_model() model.load_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  Das Modell ist auf dem Zentralprozessor einsatzbereit.  Versuchen wir, mit seiner Hilfe eines der Bilder der CIFAR-10-Testsuite zu erkennen: <br><br><pre> <code class="python hljs">index=<span class="hljs-number"><span class="hljs-number">111</span></span> plt.imshow(toimage(x_test[index])) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/za/z3/f-/zaz3f-jatj-5crlgsih84gsakg0.png"><br><br>  Das Bild ist klein, aber Sie k√∂nnen verstehen, dass dies ein Flugzeug ist.  Wir beginnen mit der Anerkennung: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      CIFAR-10 classes=['', '', '', '', '', '', '', '', '', ''] x = x_test[index] #  , .. Keras    x = np.expand_dims(x, axis=0) #   prediction = model.predict(x) #       print(prediction) #     prediction = np.argmax(prediction) print(classes[prediction])</span></span></code> </pre> <br>  Wir erhalten eine Liste der Ausgabewerte von Neuronen, von denen fast alle nahe Null sind, mit Ausnahme des ersten Werts, der der Ebene entspricht. <br><br> <code>[[9.81738389e-01 2.91262069e-07 1.82225723e-02 9.78524668e-07 <br> 5.89265142e-07 6.76223244e-10 1.03252004e-10 9.23009047e-09 <br> 3.71878523e-05 3.16599618e-08]] <br> </code> <br> <br>  Anerkennung war erfolgreich! <br><br><h2>  Zusammenfassung </h2><br>  Es war m√∂glich, die Funktionsf√§higkeit von TPU auf der Colaboratory-Plattform zu demonstrieren. Es kann zum Trainieren neuronaler Netze auf Keras verwendet werden.  Das CIFAR-10-Dataset ist jedoch zu klein, es reicht nicht aus, um TPU-Ressourcen vollst√§ndig zu laden.  Die Beschleunigung im Vergleich zur GPU stellte sich als gering heraus (Sie k√∂nnen sich selbst √ºberpr√ºfen, indem Sie die GPU als Beschleuniger anstelle der TPU ausw√§hlen und das Modell erneut trainieren). <br><br>  Auf Habr√© gibt es einen Artikel, in dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Leistung von TPUs und GPUs V100 beim Training des Netzwerks ResNet-50 gemessen wurde</a> .  Bei dieser Aufgabe zeigte die TPU die gleiche Leistung wie die vier V100-GPUs.  Es ist sch√∂n, dass Google einen so leistungsstarken Lernbeschleuniger f√ºr neuronale Netze kostenlos zur Verf√ºgung stellt! <br><br>  Video, das das Training des neuronalen Keras-Netzwerks auf TPU demonstriert. <br><iframe width="560" height="315" src="https://www.youtube.com/embed/60xbDEpA49M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  N√ºtzliche Links </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Labor-Laptop mit vollst√§ndigem Keras TPU-Modell-Lerncode</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laborheft mit Keras TPU-Trainingsbeispiel zum Erkennen von Kleidung und Schuhen von Fashion MNIST</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensorprozessoren in der Google Cloud</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Merkmale der Architektur und Verwendung von Tensorprozessoren</a> . </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428117/">https://habr.com/ru/post/de428117/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428107/index.html">Containerisierung von Angular 6 SPA-Vorlagen ASP .NET Core 2.1-Anwendungen</a></li>
<li><a href="../de428109/index.html">Unternehmenswand</a></li>
<li><a href="../de428111/index.html">Arithmetik beliebiger Genauigkeit in Erlang</a></li>
<li><a href="../de428113/index.html">Auf die Frage nach Bezier-Kurven, Arduino-Geschwindigkeit und einem interessanten Ort oder wie ich das Wochenende verbracht habe</a></li>
<li><a href="../de428115/index.html">Webentwicklung f√ºr E-Commerce: 5 Technologietrends f√ºr 2019</a></li>
<li><a href="../de428119/index.html">"Klassenfeld-Vorschlag" oder "Was ist beim tc39-Commit schief gelaufen"</a></li>
<li><a href="../de428121/index.html">Stan Drapkin. Hochrangige Kryptografiefallen in .NET</a></li>
<li><a href="../de428123/index.html">Sicherheitswoche 41: Gute Nachrichten</a></li>
<li><a href="../de428125/index.html">Wer sind Produktanalysen und warum werden sie in einem Team ben√∂tigt?</a></li>
<li><a href="../de428127/index.html">Nginx-Cache: alles neu - gut vergessen alt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
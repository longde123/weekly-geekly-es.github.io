<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥧 😰 🚣🏾 Comment nous avons créé un service de recommandation pour la sélection de vêtements sur les réseaux de neurones ♐️ 👩‍🏭 🙆🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je veux parler de la façon dont nous avons créé un système de recherche de vêtements similaires (plus précisément des vêtements, des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment nous avons créé un service de recommandation pour la sélection de vêtements sur les réseaux de neurones</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438542/"><img src="https://habrastorage.org/webt/bh/ne/uw/bhneuwiip47lykb6jg-yigfnk3o.png" alt="image"><br><br>  Dans cet article, je veux parler de la façon dont nous avons créé un système de recherche de vêtements similaires (plus précisément des vêtements, des chaussures et des sacs) à partir de photographies.  Il s'agit, en termes commerciaux, d'un service de recommandation basé sur des réseaux de neurones. <br><br>  Comme la plupart des solutions informatiques modernes, nous pouvons comparer le développement de notre système avec l'ensemble constructeur Lego, lorsque nous prenons beaucoup de petits détails, des instructions et créons un modèle prêt à l'emploi à partir de cela.  Voici une telle instruction: quels détails prendre et comment les appliquer pour que votre GPU puisse sélectionner des produits similaires sur une photo, vous trouverez dans cet article. <br><br>  De quelles parties est construit notre système: <br><br><ul><li>  détecteur et classificateur de vêtements, chaussures et sacs sur images; </li><li>  robot, indexeur ou module pour travailler avec des catalogues électroniques de magasins; </li><li>  module de recherche d'images similaires; </li><li>  API JSON pour une interaction pratique avec n'importe quel appareil et service; </li><li>  interface Web ou application mobile pour afficher les résultats. </li></ul><br>  À la fin de l'article, nous décrirons tous les «râteaux» sur lesquels nous avons marché pendant le développement et des recommandations sur la façon de les neutraliser. <br><br><h3>  Énoncé du problème et création de la rubrique </h3><br>  La tâche et le principal cas d'utilisation du système semblent assez simples et clairs: <br><br><ul><li>  l'utilisateur soumet à l'entrée (par exemple via une application mobile) une photographie dans laquelle se trouvent des vêtements et / ou des sacs et / ou des chaussures; </li><li>  le système détermine (détecte) tous ces objets; </li><li>  trouve à chacun d'eux les produits les plus similaires (pertinents) dans de véritables boutiques en ligne; </li><li>  donne aux produits utilisateur la possibilité d'accéder à une page de produit spécifique pour achat. </li></ul><br>  En termes simples, l'objectif de notre système est de répondre à la fameuse question: "Et vous n'avez pas la même chose, uniquement avec des boutons en nacre?" <br><a name="habracut"></a><br>  Avant de vous précipiter dans le pool de codage, de balisage et de formation des réseaux de neurones, vous devez déterminer assez clairement les catégories qui seront à l'intérieur de votre système, c'est-à-dire les catégories que le réseau de neurones détectera.  Il est important de comprendre que plus la liste des catégories est large et détaillée, plus elle est universelle, car un grand nombre de petites catégories étroites telles que la mini-robe, la robe midi, la maxi-robe peuvent toujours être combinées avec une seule touche dans une catégorie de type robe MAIS PAS vice versa.  En d'autres termes, le rubricator doit être bien pensé et compilé au tout début du projet, afin de ne pas refaire le même travail 3 fois plus tard.  Nous avons compilé le rubricator, en prenant comme base plusieurs grands magasins, tels que Lamoda.ru, Amazon.com, et avons essayé de le rendre aussi large que possible d'une part, et aussi polyvalent que possible, d'autre part, de sorte qu'il serait plus facile d'associer des catégories de détecteurs à différentes catégories à l'avenir boutiques en ligne (je vais vous en dire plus sur la façon de créer ce groupe dans la section des robots et des indexeurs).  Voici un exemple de ce qui s'est passé. <br><br><img src="https://habrastorage.org/webt/bg/ku/zq/bgkuzqn0q-wovsd8x8aq7hlwlio.png" alt="image"><br>  <i>Exemples de catégories</i> <br><br>  Dans notre catalogue, il n'y a actuellement que 205 catégories: vêtements pour femmes, vêtements pour hommes, chaussures pour femmes, chaussures pour hommes, sacs, vêtements pour nouveau-nés.  La version complète de notre classificateur est disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le lien</a> . <br><br><h3>  Indexeur ou module pour travailler avec des catalogues électroniques de magasins </h3><br>  Afin de rechercher des produits similaires à l'avenir, nous devons créer une base étendue de ce que nous recherchons.  D'après notre expérience, la qualité de la recherche d'images similaires dépend directement de la taille de la base de recherche, qui doit dépasser au moins 100 000 images, et de préférence 1 million d'images.  Si vous ajoutez 1-2 petites boutiques en ligne à la base de données, vous n'obtiendrez probablement pas de résultats impressionnants simplement parce que dans 80% des cas, il n'y a rien de vraiment similaire à l'article souhaité dans votre catalogue. <br><br>  Donc, pour créer une grande base de données d'images dont vous avez besoin pour traiter les catalogues de diverses boutiques en ligne, voici ce que ce processus comprend: <br><br><ul><li>  Vous devez d'abord trouver les flux XML des magasins en ligne, vous pouvez généralement les trouver soit librement disponibles sur Internet, soit en faisant la demande auprès du magasin lui-même, ou dans divers agrégateurs tels que Admitad; </li><li>  le flux est traité (analysé) par un programme spécial - un robot, qui télécharge toutes les images du flux, les place sur le disque dur (plus précisément, sur le stockage réseau auquel votre serveur est connecté), écrit toutes les méta-informations sur les marchandises dans la base de données; </li><li>  puis un autre processus est lancé - l'indexeur, qui calcule des vecteurs binaires à 128 dimensions pour chaque image.  Vous pouvez combiner le robot et l'indexeur en un seul module ou programme, mais nous avons historiquement développé qu'il s'agissait de processus différents.  Cela est principalement dû au fait qu'au départ, nous avons calculé des descripteurs (hachages) pour chaque image distribuée sur un grand parc de machines, car il s'agissait d'un processus très gourmand en ressources.  Si vous ne travaillez qu'avec des réseaux de neurones, alors la 1ère machine avec un GPU vous suffit; </li><li>  les vecteurs binaires sont écrits dans la base de données, tous les processus sont terminés et le tour est joué - votre base de données de produits est prête pour une recherche ultérieure; </li><li>  mais une petite astuce demeure: puisque tous les magasins ont des catalogues différents avec des catégories différentes à l'intérieur, alors vous devez comparer les catégories de tous les flux contenus dans votre base de données avec les catégories du détecteur (plus précisément, le classificateur) de marchandises, nous appelons cela le processus de cartographie.  Il s'agit d'une routine manuelle, mais très utile, au cours de laquelle l'opérateur, éditant manuellement un fichier XML régulier, compare les catégories de flux dans la base de données avec les catégories du détecteur.  Voici le résultat: </li></ul><br><img src="https://habrastorage.org/webt/wb/je/hp/wbjehp3opuvabmnniuv8alvxwqm.png" alt="image"><br>  <i>Exemple de fichier de mappage de catégorie: catalog-classifier</i> <br><br><h3>  Détection et classification </h3><br>  Afin de trouver quelque chose de similaire à ce que notre œil a trouvé sur la photo, nous devons d'abord détecter ce «quelque chose» (c'est-à-dire localiser et sélectionner l'objet).  Nous avons parcouru un long chemin dans la création d'un détecteur, à partir de la formation de cascades OpenCV qui ne fonctionnaient pas du tout sur cette tâche, et se terminant par une technologie moderne pour détecter et classifier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R-FCN</a> et le classificateur basé sur le réseau neuronal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ResNet</a> . <br><br>  En tant que données utilisées pour la formation et les tests (les soi-disant échantillons de formation et de test), nous avons pris toutes sortes d'images sur Internet: <br><br><ul><li>  recherche sur les images Google / Yandex; </li><li>  ensembles de données balisés par des tiers; </li><li>  réseaux sociaux; </li><li>  sites de magazines de mode; </li><li>  Boutiques Internet de vêtements, chaussures, sacs. </li></ul><br>  Le balisage a été effectué à l'aide d'un outil samopisny, le résultat du balisage a été des ensembles d'images et des fichiers * .seg, qui stockent les coordonnées des objets et les étiquettes de classe pour eux.  En moyenne, de 100 à 200 images ont été étiquetées pour chaque catégorie, le nombre total d'images dans 205 classes était de 65 000. <br><br>  Une fois que les échantillons de formation et de test sont prêts, nous avons fait une double vérification du balisage, en donnant toutes les images à un autre opérateur.  Cela nous a permis de filtrer un grand nombre d'erreurs qui affectent fortement la qualité de la formation du réseau neuronal, c'est-à-dire le détecteur et le classificateur.  Ensuite, nous commençons à former le réseau neuronal à l'aide d'outils standard et «décollons» le prochain instantané du réseau neuronal «dans la chaleur du jour» dans quelques jours.  En moyenne, le temps de formation du détecteur et classificateur sur le volume de données de 65 000 images sur un GPU Titan X est d'environ 3 jours. <br><br>  Un réseau neuronal prêt à l'emploi doit en quelque sorte être vérifié pour la qualité, c'est-à-dire pour évaluer si la version actuelle du réseau est devenue meilleure que la précédente et de combien.  Comment nous l'avons fait: <br><br><ul><li>  l'échantillon de test comprenait 12 000 images et était disposé exactement de la même manière que la formation; </li><li>  nous avons écrit un petit outil qui a exécuté l'échantillon de test complet à travers le détecteur et compilé un tableau de ce type (la version complète du tableau est disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ); </li><li>  ce tableau est ajouté à Excel dans un nouvel onglet et comparé au précédent manuellement ou à l'aide des formules Excel intégrées; </li><li>  à la sortie, nous obtenons les indicateurs généraux du détecteur et classificateur TPR / FPR dans tout le système dans et pour chaque catégorie séparément. </li></ul><br><img src="https://habrastorage.org/webt/vq/ou/it/vqouitv0rpqps36tme91uu5ynpw.png" alt="image"><br>  <i>Exemple de tableau de rapport sur la qualité du détecteur et classificateur</i> <br><br><h3>  Module de recherche d'images similaires </h3><br>  Après avoir détecté des articles de garde-robe sur la photo, nous démarrons le moteur de recherche d'images similaires, voici comment cela fonctionne: <br><br><ul><li>  pour tous les fragments d'image découpés (biens détectés), les vecteurs de caractéristiques binaires du réseau neuronal 128 bits sont calculés en forme et en couleur (d'où ils viennent, voir ci-dessous); </li><li>  les mêmes vecteurs calculés plus tôt au stade de l'indexation pour toutes les images de marchandises stockées dans la base de données sont déjà chargés dans la mémoire RAM de l'ordinateur (car pour rechercher des similaires, il sera nécessaire de faire un grand nombre de recherches et de comparaisons par paires, nous avons chargé la base de données entière immédiatement en mémoire, ce qui nous a permis d'augmenter la vitesse de recherche est des dizaines de fois, tandis que la base d'environ 100 000 produits ne tient pas plus de 2 à 3 Go de RAM); </li><li>  les coefficients de recherche pour cette catégorie proviennent de l'interface ou de propriétés codées en dur, par exemple, dans la catégorie «robe», nous recherchons plus en couleur qu'en forme (par exemple, recherche de forme en 8 à 2 couleurs), et dans la catégorie «chaussures à talons hauts» nous regardons 1-to-1 form-color puisque la forme et la couleur sont également importantes ici; </li><li>  En outre, les vecteurs pour le recadrage (fragments) de l'image d'entrée sont comparés par paires avec l'image de la base de données, en tenant compte des coefficients (la distance de Hamming entre les vecteurs est comparée); </li><li>  en conséquence, un tableau de produits similaires à partir de la base de données est formé pour chaque fragment de produit coupé, et un poids est attribué à chaque produit (selon une formule simple, en tenant compte de la normalisation, de sorte que tous les poids se situent dans la plage de 0 à 1) pour la possibilité de sortie vers l'interface, ainsi que pour d'autres tri; </li><li>  un tableau de produits similaires est affiché dans l'interface via le web-JSON-API. </li></ul><br>  Les réseaux de neurones pour la formation de vecteurs de réseau de neurones en forme et en couleur sont formés comme suit. <br><br><ol><li>  Pour former le réseau neuronal en forme, nous prenons toutes les images étiquetées, découpons les fragments selon le balisage et les répartissons dans des dossiers selon la classe: c'est-à-dire tous les pulls dans un dossier, tous les T-shirts dans un autre et toutes les chaussures à talons hauts dans le troisième, etc. d.  Ensuite, nous formons un classificateur ordinaire basé sur cet échantillon.  Ainsi, nous «expliquons» en quelque sorte au réseau neuronal notre compréhension de la forme de l'objet. </li><li>  Pour former le réseau neuronal en couleur, nous prenons toutes les images balisées, découpons les fragments selon le balisage et les répartissons dans des dossiers selon la couleur: c'est-à-dire que nous mettons tous les T-shirts, chaussures, sacs, etc. dans le dossier «vert».  couleur verte (par conséquent, tous les objets de couleur verte s'accumulent généralement dans un dossier), dans le dossier «dépouillé», nous mettons toutes les choses dans une bande, et dans le dossier «rouge-blanc» toutes les choses rouge-blanc.  Ensuite, nous formons un classifieur distinct pour ces classes, comme s'il «expliquait» au réseau neuronal sa compréhension de la couleur d'une chose. </li></ol><br><img src="https://habrastorage.org/webt/b8/0-/qg/b80-qglyjgkpn6trfxxdm6b55gm.png" alt="image"><br>  <i>Un exemple de marquage d'images par couleur pour obtenir des vecteurs de réseaux neuronaux de signes par couleur.</i> <br><br>  Fait intéressant, une telle technologie fonctionne bien même sur des arrière-plans complexes, c'est-à-dire lorsque des fragments de choses sont découpés non pas clairement le long du contour (masque), mais le long d'un cadre rectangulaire, que le marqueur a défini. <br><br>  La recherche de similaires est basée sur l'extraction de vecteurs de caractéristiques binaires du réseau neuronal de cette manière: la sortie de l'avant-dernière couche est prise, compressée, normalisée et binarisée.  Dans notre travail, nous avons compressé en un vecteur 128 bits.  Vous pouvez le faire un peu différemment, par exemple, comme décrit dans l'article de Yahoo « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep Learning of Binary Hash Codes for Fast Image Retrieval</a> », mais l'essence de tous les algorithmes est à peu près la même - des images similaires à l'image sont recherchées en comparant les propriétés que le réseau neuronal opère au sein des couches. <br><br>  Initialement, en tant que technologie de recherche d'images similaires, nous avons utilisé des hachages ou des descripteurs d'images basés (calculés plus précisément) sur certains algorithmes mathématiques, tels que l'opérateur Sobel (ou hachage de contour), l'algorithme SIFT (ou points singuliers), le traçage d'un histogramme ou la comparaison du nombre d'angles dans une image .  Cette technologie a fonctionné et a donné des résultats plus ou moins sains, mais les hachages ne sont en rien comparables à la technologie de recherche d'images similaires en fonction des propriétés attribuées par un réseau de neurones.  Si vous essayez d'expliquer la différence en 2 mots, l'algorithme de comparaison d'images basé sur le hachage est une «calculatrice» qui est configurée pour comparer les images à l'aide d'une formule et qui fonctionne en continu.  Une comparaison utilisant des fonctionnalités d'un réseau de neurones est «l'intelligence artificielle», formée par une personne pour résoudre un problème spécifique d'une certaine manière.  Vous pouvez donner un exemple aussi grossier: si vous recherchez des pulls en hash à rayures noires et blanches, vous trouverez probablement toutes les choses en noir et blanc comme des similaires.  Et si vous recherchez en utilisant un réseau de neurones, alors: <br><br><ul><li>  dans les premiers endroits, vous trouverez tous les pulls à rayures noires et blanches, </li><li>  puis tous les pulls en noir et blanc </li><li>  puis tous les pulls à rayures. </li></ul><br><h3>  API JSON pour une interaction pratique avec n'importe quel appareil et service </h3><br>  Nous avons créé une API WEB-JSON simple et pratique pour communiquer notre système avec tous les appareils et systèmes, ce qui, bien sûr, n'est pas une innovation, mais plutôt une bonne norme de développement solide. <br><br><h3>  Interface Web ou application mobile pour afficher les résultats </h3><br>  Pour vérifier visuellement les résultats, ainsi que pour démontrer le système aux clients, nous avons développé des interfaces simples: <br><br><ul><li>  interface Web, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://demo.likethis.me/</a> </li><li>  l'application mobile est disponible <a href="">ici</a> </li></ul><br><h3>  Erreurs commises dans le projet </h3><br><ul><li>  Dans un premier temps, il est nécessaire de définir plus clairement la tâche, et il s'agit, en fonction de la tâche, de sélectionner des photographies à mettre en page.  Si vous devez rechercher des photos UGC (User Generated Content) - il s'agit d'un cas et d'exemples de mise en page.  Si vous avez besoin d'une recherche de photos à partir de magazines sur papier glacé, il s'agit d'un cas différent, et si vous avez besoin d'une recherche de photos où un grand objet est situé sur un fond blanc, il s'agit d'une histoire distincte et d'un échantillon complètement différent.  Nous avons tout mélangé en un seul tas, ce qui a affecté la qualité du détecteur et du classificateur. </li><li>  Sur les photos, vous devez toujours marquer TOUS les objets, au moins du fait que cela convient au moins à votre tâche, par exemple, lorsque vous choisissez une sélection de garde-robe similaire, vous devez immédiatement marquer tous les accessoires (perles, lunettes, bracelets, etc.), la tête chapeaux, etc.  Parce que maintenant que nous avons un énorme ensemble de formation, afin d'ajouter une autre catégorie, nous devons redistribuer TOUTES les photos, et c'est un travail très volumineux. </li><li>  La détection est probablement mieux effectuée avec un réseau de masques, la transition vers Mask-CNN et une solution moderne basée sur Detectron est l'un des domaines du développement du système. </li><li>  Ce serait bien de décider immédiatement comment vous allez déterminer la qualité de la sélection d'images similaires - il y a 2 méthodes: «à l'œil» et c'est la méthode la plus simple et la moins chère et la 2e - la méthode «scientifique», lorsque vous collectez des données auprès d '«experts» (personnes, que je teste votre algorithme de recherche similaire) et sur la base de ces données, formez un échantillon de test et un catalogue spécifiquement pour la recherche d'images similaires.  Cette méthode est bonne en théorie et semble assez convaincante (pour vous et pour les clients), mais en pratique, sa mise en œuvre est difficile et assez coûteuse. </li></ul><br><h3>  Conclusion et plans de développement ultérieurs </h3><br>  Cette technologie est tout à fait prête et utilisable, elle fonctionne maintenant chez l'un de nos clients dans la boutique en ligne en tant que service de recommandation.  De plus, récemment, nous avons commencé à développer un système similaire dans une autre industrie (c'est-à-dire que nous travaillons maintenant avec d'autres types de marchandises). <br><br>  Des plans immédiats: le transfert du réseau à Mask-CNN, ainsi que le re-marquage et le re-marquage des images pour améliorer la qualité du détecteur et du classifieur. <br><br>  En conclusion, je veux dire que selon nos sentiments, une technologie similaire et en général les réseaux de neurones sont capables de résoudre jusqu'à 80% des tâches complexes et hautement intellectuelles que notre cerveau rencontre quotidiennement.  La seule question est de savoir qui est le premier à mettre en œuvre une telle technologie et à décharger une personne du travail de routine, lui laissant ainsi un espace de créativité et de développement, ce qui est, à notre avis, le but le plus élevé de l'homme! <br><br><h3>  Les références </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Technologie R-FCN</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Réseau neuronal ResNet</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rechercher des images similaires à l'aide d'un réseau neuronal</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr438542/">https://habr.com/ru/post/fr438542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr438530/index.html">Podcasts hipster # 1</a></li>
<li><a href="../fr438534/index.html">Modbus sur le microcontrôleur russe K1986BE92QI</a></li>
<li><a href="../fr438536/index.html">Sous le capot du chatbot: ce que RocketBot peut et comment cela fonctionne</a></li>
<li><a href="../fr438538/index.html">Teamlead Conf 2019 Msk: à propos d'un autre format de communication</a></li>
<li><a href="../fr438540/index.html">Tendances de la gestion des documents et du stockage des données pour 2019</a></li>
<li><a href="../fr438544/index.html">Nous regardons des films à la maison: 10 documents sur la construction d'un home cinéma et le choix de l'équipement</a></li>
<li><a href="../fr438546/index.html">Analyse des approches de liaison de modules dans Node.js</a></li>
<li><a href="../fr438548/index.html">Lombok, sources.jar et débogage pratique</a></li>
<li><a href="../fr438550/index.html">Un autre manifeste</a></li>
<li><a href="../fr438554/index.html">Gestion de l'état et des événements entre les composants de GameObject</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
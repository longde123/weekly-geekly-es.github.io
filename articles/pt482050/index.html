<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî´ üë©üèº‚Äç‚úàÔ∏è üíØ T√©cnica de redu√ß√£o de rede de convolu√ß√£o Jedi - poda üë©üèΩ‚Äçü§ù‚Äçüë®üèø üßïüèº üëáüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Antes de voc√™ novamente, a tarefa de detectar objetos. Prioridade - velocidade com precis√£o aceit√°vel. Voc√™ pega a arquitetura do YOLOv3 e a treina. A...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>T√©cnica de redu√ß√£o de rede de convolu√ß√£o Jedi - poda</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482050/"><p><img src="https://habrastorage.org/webt/tf/oa/br/tfoabr16w_dawnzb9hnjndyv_bg.png" alt="imagem"></p><br><p>  Antes de voc√™ novamente, a tarefa de detectar objetos.  Prioridade - velocidade com precis√£o aceit√°vel.  Voc√™ pega a arquitetura do YOLOv3 e a treina.  A precis√£o (mAp75) √© maior que 0,95.  Mas a velocidade de execu√ß√£o ainda √© baixa.  Inferno </p><br><p>  Hoje vamos ignorar a quantiza√ß√£o.  E, por baixo do corte, considere a <strong>poda de modelos</strong> - aparar pe√ßas de rede redundantes para acelerar a infer√™ncia sem perder a precis√£o.  Visualmente - onde, quanto e como cortar.  Vamos descobrir como fazer isso manualmente e onde voc√™ pode automatizar.  No final, h√° um reposit√≥rio no keras. </p><a name="habracut"></a><br><h3 id="vvedenie">  1. Introdu√ß√£o </h3><br><p>  No √∫ltimo local de trabalho, Perm Macroscop, eu tenho um h√°bito - sempre monitorar o tempo de execu√ß√£o dos algoritmos.  E o tempo de execu√ß√£o da rede sempre deve ser verificado atrav√©s do filtro de adequa√ß√£o.  Normalmente, o estado da arte no produto n√£o passa nesse filtro, o que me levou √† poda. </p><br><p>  A poda √© um tema antigo sobre o qual falamos nas <a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">palestras de</a> 2017 em <a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">Stanford</a> .  A id√©ia principal √© reduzir o tamanho da rede treinada sem perder a precis√£o, removendo v√°rios n√≥s.  Parece legal, mas eu raramente ou√ßo sobre o seu uso.  Provavelmente, n√£o h√° implementa√ß√µes suficientes, n√£o h√° artigos em russo ou apenas todos consideram o poda e o sil√™ncio. <br>  Mas v√° desmontar </p><br><h3 id="vzglyad-v-biologiyu">  Um olhar sobre a biologia </h3><br><p>  Adoro quando, nas id√©ias do Deep Learning, v√™m da biologia.  Eles, como a evolu√ß√£o, podem ser confi√°veis ‚Äã‚Äã(voc√™ sabia que a ReLU √© muito semelhante √† <a href="http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf" rel="nofollow">fun√ß√£o de ativar neur√¥nios no c√©rebro</a> ?) </p><br><p>  O processo de poda do modelo tamb√©m est√° pr√≥ximo da biologia.  A resposta da rede aqui pode ser comparada com a plasticidade do c√©rebro.  Alguns exemplos interessantes est√£o no livro de <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">Norman Dodge</a> : </p><br><ol><li>  O c√©rebro de uma mulher que tinha apenas metade do nascimento reprogramava-se para desempenhar as fun√ß√µes da metade desaparecida </li><li>  O cara se matou na parte do c√©rebro respons√°vel pela vis√£o.  Com o tempo, outras partes do c√©rebro assumiram essas fun√ß√µes.  (n√£o tente novamente) </li></ol><br><p>  Portanto, no seu modelo, voc√™ pode cortar alguns dos pacotes fracos.  Em casos extremos, os pacotes restantes ajudar√£o a substituir os pacotes cortados. </p><br><h3 id="lyubish-transfer-learning-ili-uchish-s-nulya">  Voc√™ gosta de Transfer Learning ou aprende do zero? </h3><br><p>  <strong>Op√ß√£o n√∫mero um.</strong>  Voc√™ est√° usando o Transfer Learning no Yolov3.  Retina, Mask-RCNN ou U-Net.  Mas, na maioria das vezes, n√£o precisamos reconhecer 80 classes de objetos, como no COCO.  Na minha pr√°tica, tudo √© limitado a 1-2 aulas.  Pode-se supor que a arquitetura para 80 classes seja redundante aqui.  Implora o pensamento de que a arquitetura precisa ser reduzida.  Al√©m disso, eu gostaria de fazer isso sem perder os pesos pr√©-treinados existentes. </p><br><p>  <strong>Op√ß√£o n√∫mero dois.</strong>  Talvez voc√™ tenha muitos dados e recursos de computa√ß√£o ou apenas precise de uma arquitetura super personalizada.  Isso n√£o importa.  Mas voc√™ aprende a rede do zero.  A ordem usual √© olhar para a estrutura de dados, selecionar uma arquitetura que seja REDUZIDA em termos de energia e impedir que os desistentes sejam treinados novamente.  Vi desist√™ncias 0,6, Carl. </p><br><p>  Nos dois casos, a rede pode ser reduzida.  Promovido.  Agora vamos descobrir que tipo de <del>  circuncis√£o </del>  poda </p><br><h3 id="obschiy-algoritm">  Algoritmo geral </h3><br><p>  Decidimos que poder√≠amos remover a convolu√ß√£o.  Parece muito simples: </p><br><p><img src="https://habrastorage.org/webt/ey/yt/-g/eyyt-g-b6pfzjrbnim_ssosyqqk.png"></p><br><p>  A remo√ß√£o de qualquer convolu√ß√£o √© um estresse para a rede, o que geralmente leva a um aumento no erro.  Por um lado, esse crescimento de erro √© um indicador de como removemos corretamente a convolu√ß√£o (por exemplo, um grande crescimento indica que estamos fazendo algo errado).  Mas um pequeno crescimento √© bastante aceit√°vel e √© frequentemente eliminado por um treinamento posterior f√°cil e subsequente com uma pequena RL.  Adicionamos uma etapa de reciclagem: </p><br><p><img src="https://habrastorage.org/webt/kb/ui/5d/kbui5dm1k8sgflm5xzu0wggbbhs.png"></p><br><p>  Agora precisamos entender quando queremos interromper nosso ciclo de aprendizagem &lt;-&gt; Poda.  Pode haver op√ß√µes ex√≥ticas quando precisamos reduzir a rede para um determinado tamanho e velocidade de execu√ß√£o (por exemplo, para dispositivos m√≥veis).  No entanto, a op√ß√£o mais comum √© continuar o ciclo at√© que o erro se torne mais alto do que o permitido.  Adicionar condi√ß√£o: </p><br><p><img src="https://habrastorage.org/webt/1i/pi/52/1ipi52uqhkciw2ne-1zt2rbdmje.png"></p><br><p>  Ent√£o, o algoritmo fica claro.  Resta desmontar como determinar as convolu√ß√µes exclu√≠das. </p><br><h3 id="poisk-udalyaemyh-svertok">  Pesquisa por convolu√ß√£o a ser exclu√≠da </h3><br><p>  Precisamos remover algumas convolu√ß√µes.  Ir adiante e "disparar" qualquer uma √© uma m√° id√©ia, embora funcione.  Mas se voc√™ tem cabe√ßa, pode pensar e tentar selecionar convolu√ß√µes "fracas" para remo√ß√£o.  Existem v√°rias op√ß√µes: </p><br><ol><li>  <a href="https://openreview.net/pdf%3Fid%3DrJqFGTslg" rel="nofollow">A menor medida L1 ou poda_de_magnitude_ baixa</a> .  A ideia de que convolu√ß√µes com pesos pequenos contribuem pouco para a decis√£o final </li><li>  A menor medida L1, levando em considera√ß√£o a m√©dia e o desvio padr√£o.  Complementamos a avalia√ß√£o da natureza da distribui√ß√£o. </li><li>  <a href="https://arxiv.org/abs/1512.08571" rel="nofollow">Mascarar as convolu√ß√µes e eliminar o m√≠nimo que afeta a precis√£o resultante</a> .  Uma defini√ß√£o mais precisa de convuls√µes insignificantes, mas que consomem muito tempo e consomem muitos recursos. </li><li>  Outros </li></ol><br><p>  Cada uma das op√ß√µes tem direito √† vida e seus pr√≥prios recursos de implementa√ß√£o.  Aqui consideramos a variante com a menor medida L1 </p><br><h3 id="ruchnoy-process-dlya-yolov3">  Processo manual para YOLOv3 </h3><br><p>  A arquitetura original cont√©m blocos residuais.  Mas, por mais legais que sejam em redes profundas, eles nos atrapalham um pouco.  A dificuldade √© que voc√™ n√£o pode excluir reconcilia√ß√µes com diferentes √≠ndices nessas camadas: </p><br><p><img src="https://habrastorage.org/webt/mh/p-/-k/mhp--ksk3ifgurz5jx6exgcrm5c.png"></p><br><p>  Portanto, selecionamos as camadas das quais podemos remover livremente reconcilia√ß√µes: </p><br><p><img src="https://habrastorage.org/webt/qy/ek/zo/qyekzofcur-q0auqurg3egxnato.png"></p><br><p>  Agora vamos construir um ciclo de trabalho: </p><br><ol><li>  Descarregar a ativa√ß√£o </li><li>  Queremos saber quanto cortar </li><li>  Cortar </li><li>  Aprenda 10 eras com LR = 1e-4 </li><li>  Teste </li></ol><br><p>  A descarga de convolu√ß√µes √© √∫til para avaliar qual parte podemos remover em uma determinada etapa.  Exemplos de descarregamento: </p><br><p><img src="https://habrastorage.org/webt/rp/jo/pk/rpjopk6dzfrl6psoucr8tgj0log.png"></p><br><p>  Vemos que em quase todos os lugares 5% das convolu√ß√µes t√™m uma norma L1 muito baixa e podemos remov√™-las.  Em cada etapa, esse descarregamento era repetido e uma avalia√ß√£o era feita de quais camadas e quanto poderia ser cortado. </p><br><p>  Todo o processo foi conclu√≠do em 4 etapas (aqui e em toda parte os n√∫meros do RTX 2060 Super): </p><br><div class="scrollable-table"><table><thead><tr><th>  Etapa </th><th>  mAp75 </th><th>  O n√∫mero de par√¢metros, milh√µes </th><th>  Tamanho da rede, mb </th><th>  Do original,% </th><th>  Tempo de execu√ß√£o, ms </th><th>  Condi√ß√£o da circuncis√£o </th></tr></thead><tbody><tr><td>  0 0 </td><td>  0,9656 </td><td>  60 </td><td>  241 </td><td>  100 </td><td>  180 </td><td>  - </td></tr><tr><td>  1 </td><td>  0,9622 </td><td>  55 </td><td>  218 </td><td>  91 </td><td>  175 </td><td>  5% de todos </td></tr><tr><td>  2 </td><td>  0,9625 </td><td>  50. </td><td>  197 </td><td>  83 </td><td>  168 </td><td>  5% de todos </td></tr><tr><td>  3 </td><td>  0,9633 </td><td>  39. </td><td>  155 </td><td>  64 </td><td>  155 </td><td>  15% para camadas com mais de 400 convolu√ß√µes </td></tr><tr><td><del>  4 </del></td><td><del>  0,9555 </del></td><td><del>  31 </del></td><td><del>  124 </del></td><td><del>  51 </del></td><td><del>  146 </del></td><td><del>  10% para camadas com mais de 100 convolu√ß√µes </del></td></tr></tbody></table></div><br><p>  Na etapa 2, um efeito positivo foi adicionado - o tamanho do patch 4 entrou na mem√≥ria, o que acelerou bastante o processo de reciclagem. <br>  Na etapa 4, o processo foi interrompido porque  mesmo o ensino superior prolongado n√£o elevou o mAp75 a valores antigos. <br>  Como resultado, conseguimos acelerar a infer√™ncia em <strong>15%</strong> , reduzir o tamanho em <strong>35%</strong> e n√£o perder a precis√£o. </p><br><h3 id="avtomatizaciya-dlya-bolee-prostyh-arhitektur">  Automa√ß√£o para arquiteturas mais simples </h3><br><p>  Para arquiteturas de rede mais simples (sem adi√ß√£o condicional, blocos concatenados e residuais), √© bem poss√≠vel se concentrar no processamento de todas as camadas convolucionais e automatizar o processo de corte de convolu√ß√µes. </p><br><p>  Eu implementei <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">essa</a> op√ß√£o <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">aqui</a> . <br>  √â simples: voc√™ s√≥ tem uma fun√ß√£o de perda, um otimizador e geradores de lote: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pruning <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequence train_batch_generator = BatchGenerator... score_batch_generator = BatchGenerator... opt = Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>) pruner = pruning.Pruner(<span class="hljs-string"><span class="hljs-string">"config.json"</span></span>, <span class="hljs-string"><span class="hljs-string">"categorical_crossentropy"</span></span>, opt) pruner.prune(train_batch, valid_batch)</code> </pre> <br><p>  Se necess√°rio, voc√™ pode alterar os par√¢metros de configura√ß√£o: </p><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"input_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"output_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model_pruned.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"finetuning_epochs"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, # the number of epochs for train between pruning steps <span class="hljs-attr"><span class="hljs-attr">"stop_loss"</span></span>: <span class="hljs-number"><span class="hljs-number">0.1</span></span>, # loss for stopping process <span class="hljs-attr"><span class="hljs-attr">"pruning_percent_step"</span></span>: <span class="hljs-number"><span class="hljs-number">0.05</span></span>, # part of convs for delete on every pruning step <span class="hljs-attr"><span class="hljs-attr">"pruning_standart_deviation_part"</span></span>: <span class="hljs-number"><span class="hljs-number">0.2</span></span> # shift for limit pruning part }</code> </pre> <br><p>  Al√©m disso, uma restri√ß√£o baseada no desvio padr√£o √© implementada.  O objetivo √© limitar uma parte dos exclu√≠dos, excluindo convolu√ß√µes com medidas L1 j√° "suficientes": </p><br><p><img src="https://habrastorage.org/webt/bh/_9/nq/bh_9nqasnp91xifixn7ilhco0mw.png"></p><br><p>  Assim, podemos remover apenas convolu√ß√µes fracas de distribui√ß√µes semelhantes √† direita e n√£o afetar a remo√ß√£o de distribui√ß√µes como a esquerda: </p><br><p><img src="https://habrastorage.org/webt/pr/r5/zp/prr5zpjrdvh1wow6slejnn6axya.png"></p><br><p>  Quando a distribui√ß√£o se aproxima do normal, o coeficiente pruning_standart_deviation_part pode ser selecionado em: </p><br><p><img src="https://habrastorage.org/webt/dl/yl/7d/dlyl7dub216jsr67dcbnhez5fl8.png"><br>  Eu recomendo uma suposi√ß√£o de 2 sigma.  Ou voc√™ n√£o pode se concentrar nesse recurso, deixando o valor &lt;1.0. </p><br><p>  A sa√≠da √© um gr√°fico do tamanho da rede, perda e tempo de execu√ß√£o da rede para todo o teste, normalizado para 1,0.  Por exemplo, aqui o tamanho da rede foi reduzido quase duas vezes sem perda de qualidade (uma pequena rede de convolu√ß√£o para pesos de 100k): </p><br><p><img src="https://habrastorage.org/webt/ig/hu/x_/ighux_gyoaptm71iu2hk_txga_g.png"></p><br><p>  A velocidade de opera√ß√£o est√° sujeita a flutua√ß√µes normais e n√£o mudou muito.  H√° uma explica√ß√£o para isso: </p><br><ol><li>  O n√∫mero de convolu√ß√µes muda de conveniente (32, 64, 128) para n√£o o mais conveniente para placas de v√≠deo - 27, 51 etc.  Aqui posso estar enganado, mas provavelmente isso afeta. </li><li>  A arquitetura n√£o √© ampla, mas consistente.  Reduzindo a largura, n√£o tocamos na profundidade.  Assim, reduzimos a carga, mas n√£o alteramos a velocidade. </li></ol><br><p>  Portanto, a melhoria foi expressa em uma redu√ß√£o na carga de CUDA durante a execu√ß√£o em 20 a 30%, mas n√£o em uma diminui√ß√£o no tempo de execu√ß√£o </p><br><h3 id="itogi">  Sum√°rio </h3><br><p>  Reflita.  Consideramos duas op√ß√µes de remo√ß√£o - para o YOLOv3 (quando voc√™ precisa trabalhar com as m√£os) e para redes com arquiteturas mais f√°ceis.  Pode-se observar que em ambos os casos √© poss√≠vel obter uma redu√ß√£o no tamanho e na acelera√ß√£o da rede sem perda de precis√£o.  Resultados: </p><br><ul><li>  Downsizing </li><li>  Executar acelera√ß√£o </li><li>  Redu√ß√£o de carga CUDA </li><li>  Como resultado, respeito pelo meio ambiente (otimizamos o uso futuro dos recursos de computa√ß√£o. Em algum lugar, <a href="https://meduza.io/feature/2019/12/12/kto-takaya-greta-tunberg-i-pochemu-ona-stala-chelovekom-goda-zhurnal-time" rel="nofollow">Greta Tunberg</a> se alegra sozinho) </li></ul><br><h3 id="appendix">  Ap√™ndice </h3><br><ul><li>  Ap√≥s a etapa de remo√ß√£o, voc√™ tamb√©m pode torcer a quantiza√ß√£o (por exemplo, com TensorRT) </li><li>  O Tensorflow fornece recursos para <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="nofollow">poda</a> de <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="nofollow">baixa magnitude</a> .  Isso funciona. </li><li>  Quero desenvolver o <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">reposit√≥rio</a> e terei prazer em ajudar </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt482050/">https://habr.com/ru/post/pt482050/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt482034/index.html">Yandex: h√° tudo ... sobre os usu√°rios</a></li>
<li><a href="../pt482038/index.html">Estamos resumindo os resultados de 2019 na Haber Career</a></li>
<li><a href="../pt482040/index.html">Apresenta programas de cria√ß√£o de perfil em C ++</a></li>
<li><a href="../pt482042/index.html">Trabalhando com a biblioteca Newtonsoft.Json com um exemplo real. Parte 2</a></li>
<li><a href="../pt482044/index.html">10 pr√°ticas recomendadas para proteger imagens do Docker. Parte 2</a></li>
<li><a href="../pt482052/index.html">Conjunto de dados de ano novo 2019: dicion√°rio tonal aberto do idioma russo</a></li>
<li><a href="../pt482054/index.html">3. Pilha el√°stica: an√°lise de log de seguran√ßa. Dashboards</a></li>
<li><a href="../pt482058/index.html">Predador ou presa? Quem proteger√° as autoridades de certifica√ß√£o</a></li>
<li><a href="../pt482060/index.html">Modelo de mandato de controle de acesso (MAC): vis√£o geral e aplicativos</a></li>
<li><a href="../pt482064/index.html">Facilidade de desenvolvimento de sites multil√≠ngues no CMS Umbraco 8</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
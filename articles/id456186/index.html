<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💃 😂 👁‍🗨 CS231n: Jaringan saraf konvolusional untuk pengenalan pola 🙎 🙍🏾 🤩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Selamat datang di salah satu kuliah di CS231n: Jaringan Syaraf Konvolusional untuk Pengenalan Visual . 



 Isi 


- Tinjauan Arsitektur 
- Lapisan da...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CS231n: Jaringan saraf konvolusional untuk pengenalan pola</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/456186/"><p>  Selamat datang di salah satu kuliah di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CS231n: Jaringan Syaraf Konvolusional untuk Pengenalan Visual</a> . </p><br><p><img src="https://habrastorage.org/webt/b0/yc/wm/b0ycwm3fl6uveqvlr-usz5w9iqa.png"></p><a name="habracut"></a><br><h1>  Isi </h1><br><ul><li>  Tinjauan Arsitektur </li><li>  Lapisan dalam jaringan saraf convolutional <br>  - lapisan konvolusional <br>  - Lapisan subsampling <br>  - Lapisan normalisasi <br>  - Lapisan yang terhubung sepenuhnya <br>  - Konversi lapisan yang terhubung sepenuhnya ke lapisan convolutional </li><li>  Arsitektur Jaringan Syaraf Konvolusional <br>  - Lapisan template <br>  - Pola ukuran layer <br>  - Studi Kasus (LeNet, AlexNet, ZFNet, GoogLeNet, VGGNet) <br>  - Aspek komputasi </li><li>  Bacaan lebih lanjut </li></ul><br><h1>  Jaringan Syaraf Tiruan Convolutional (CNN / ConvNets) </h1><br><p>  Jaringan saraf konvolusional sangat mirip dengan jaringan saraf biasa yang kami pelajari pada bab terakhir (merujuk pada bab terakhir dari kursus CS231n): mereka terdiri dari neuron, yang, pada gilirannya, berisi bobot dan perpindahan variabel.  Setiap neuron menerima beberapa data input, menghitung produk skalar dan, secara opsional, menggunakan fungsi aktivasi nonlinear.  Seluruh jaringan, seperti sebelumnya, adalah satu-satunya fungsi evaluasi yang dapat dibedakan: dari set piksel awal (gambar) di satu ujung ke distribusi probabilitas milik kelas tertentu di ujung lainnya.  Jaringan ini masih memiliki fungsi kehilangan (misalnya, SVM / Softmax) pada lapisan terakhir (terhubung penuh), dan semua tips dan rekomendasi yang diberikan pada bab sebelumnya mengenai jaringan saraf biasa juga relevan untuk jaringan saraf convolutional. </p><br><p>  Jadi apa yang telah berubah?  Arsitektur jaringan saraf convolutional secara eksplisit melibatkan memperoleh gambar pada input, yang memungkinkan kita untuk mempertimbangkan sifat-sifat tertentu dari data input dalam arsitektur jaringan itu sendiri.  Properti ini memungkinkan Anda untuk mengimplementasikan fungsi distribusi langsung secara lebih efisien dan sangat mengurangi jumlah parameter dalam jaringan. </p><br><h1>  Tinjauan Arsitektur </h1><br><p>  Kami mengingat jaringan saraf biasa.  Seperti yang kita lihat pada bab sebelumnya, jaringan saraf menerima data input (satu vektor) dan mengubahnya dengan "mendorong" melalui serangkaian <em>lapisan tersembunyi</em> .  Setiap lapisan tersembunyi terdiri dari sejumlah neuron tertentu, yang masing-masing terhubung ke semua neuron dari lapisan sebelumnya dan di mana neuron pada setiap lapisan sepenuhnya independen dari neuron lain pada tingkat yang sama.  Lapisan yang terhubung sepenuhnya terakhir disebut "lapisan keluaran" dan dalam masalah klasifikasi adalah distribusi nilai berdasarkan kelas. </p><br><p>  <em>Jaringan saraf konvensional tidak dapat melakukan skala dengan baik untuk gambar yang lebih besar</em> .  Dalam set data CIFAR-10, gambar berukuran 32x32x3 (tinggi 32 piksel, lebar 32 piksel, 3 saluran warna).  Untuk memproses gambar seperti itu, neuron yang terhubung penuh di lapisan tersembunyi pertama dari jaringan saraf normal akan memiliki bobot 32x32x3 = 3072.  Jumlah ini masih dapat diterima, tetapi menjadi jelas bahwa struktur seperti itu tidak akan bekerja dengan gambar yang lebih besar.  Sebagai contoh, gambar yang lebih besar - 200x200x3, akan menyebabkan jumlah bobot menjadi 200x200x3 = 120.000. Selain itu, kita akan membutuhkan lebih dari satu neuron tersebut, sehingga jumlah total bobot dengan cepat akan mulai tumbuh.  Menjadi jelas bahwa konektivitasnya berlebihan dan sejumlah besar parameter akan dengan cepat mengarahkan jaringan ke pelatihan ulang. </p><br><p>  <em>Representasi 3D neuron</em> .  Jaringan saraf convolutional menggunakan fakta bahwa data input adalah gambar, sehingga membentuk arsitektur yang lebih sensitif untuk tipe data ini.  Secara khusus, tidak seperti jaringan saraf biasa, lapisan dalam jaringan saraf convolutional mengatur neuron dalam 3 dimensi - lebar, tinggi, kedalaman ( <em>Catatan</em> : kata "kedalaman" mengacu pada dimensi ke-3 dari neuron aktivasi, dan bukan kedalaman jaringan saraf itu sendiri diukur dalam jumlah layer).  Misalnya, gambar input dari dataset CIFAR-10 adalah data input dalam representasi 3D, dimensi yang 32x32x3 (lebar, tinggi, kedalaman).  Seperti yang akan kita lihat nanti, neuron dalam satu lapisan akan dikaitkan dengan sejumlah kecil neuron di lapisan sebelumnya, bukannya terhubung ke semua neuron sebelumnya di lapisan.  Selain itu, lapisan output untuk gambar dari set data CIFAR-10 akan memiliki dimensi 1 × 1 × 10, karena ketika mendekati akhir jaringan saraf kita akan mengurangi ukuran gambar menjadi vektor perkiraan kelas yang terletak di sepanjang kedalaman (dimensi 3). </p><br><p>  Visualisasi: </p><br><div class="scrollable-table"><table><thead><tr><th>  Jaringan saraf standar </th><th>  Jaringan Saraf Konvolusional </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/2da/120/014/2da120014faf76c47fa4294c7206e291.jpg"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/d45/f30/a26/d45f30a26e57d437828f90567867c96f.jpg"></td></tr></tbody></table></div><br><hr><br><p>  <em>Sisi kiri:</em> jaringan saraf 3 lapis standar. <br>  <em>Di sisi kanan:</em> jaringan saraf convolutional memiliki neuron dalam 3 dimensi (lebar, tinggi, kedalaman), seperti yang ditunjukkan pada salah satu lapisan.  Setiap lapisan jaringan saraf konvolusional mengubah representasi 3D dari input menjadi representasi 3D dari output sebagai neuron aktivasi.  Dalam contoh ini, lapisan input merah berisi gambar, sehingga ukurannya akan sama dengan ukuran gambar, dan kedalamannya adalah 3 (tiga saluran - merah, hijau, biru). </p><br><blockquote>  Jaringan saraf convolutional terdiri dari beberapa lapisan.  Setiap lapisan adalah API sederhana: mengubah representasi 3D input menjadi representasi 3D output dari fungsi terdiferensiasi, yang mungkin atau mungkin tidak mengandung parameter. </blockquote><br><h1>  Lapisan digunakan untuk membangun jaringan saraf convolutional </h1><br><p>  Seperti yang telah kami jelaskan di atas, jaringan saraf konvolusional sederhana adalah seperangkat lapisan, di mana setiap lapisan mengubah satu representasi menjadi yang lain menggunakan fungsi terdiferensiasi.  Kami menggunakan tiga jenis utama lapisan untuk membangun jaringan saraf convolutional: <em>lapisan konvolusional</em> , <em>lapisan</em> <em>subsampling</em> , dan <em>lapisan</em> yang <em>sepenuhnya terhubung</em> (sama seperti yang kami gunakan dalam jaringan saraf normal).  Kami mengatur lapisan ini secara berurutan untuk mendapatkan arsitektur SNA. </p><br><p> <em>Contoh Arsitektur: Gambaran Umum.</em>  Di bawah ini kita akan membahas rinciannya, tetapi untuk sekarang, untuk dataset CIFAR-10, arsitektur jaringan saraf convolutional kami mungkin <code>[INPUT -&gt; CONV -&gt; RELU -&gt; POOL -&gt; FC]</code> .  Sekarang lebih terinci: </p><br><ul><li>  <code>INPUT</code> [32x32x3] akan berisi nilai asli piksel gambar, dalam kasus kami gambar tersebut berukuran lebar 32px, tinggi 32px, dan 3 saluran warna R, G, B. </li><li>  Lapisan <code>CONV</code> akan menghasilkan satu set neuron keluaran yang akan dikaitkan dengan area lokal dari gambar sumber input;  setiap neuron tersebut akan menghitung produk skalar di antara bobotnya dan bagian kecil dari gambar aslinya yang terkait dengannya.  Nilai output dapat berupa representasi 3D <code>323212</code> , jika, misalnya, kami memutuskan untuk menggunakan 12 filter. </li><li>  Lapisan <code>RELU</code> akan menerapkan fungsi aktivasi elemen <code>max(0, x)</code> .  Konversi ini tidak akan mengubah dimensi data - <code>[32x32x12]</code> . </li><li>  Lapisan <code>POOL</code> akan melakukan operasi pengambilan sampel gambar dalam dua dimensi - tinggi dan lebar, yang sebagai hasilnya akan memberi kita representasi 3D baru <code>[161612]</code> . </li><li>  Lapisan <code>FC</code> (sepenuhnya terhubung lapisan) akan menghitung nilai berdasarkan kelas, dimensi yang dihasilkan akan <code>[1x1x10]</code> , di mana masing-masing dari 10 nilai akan sesuai dengan nilai kelas tertentu di antara 10 kategori gambar dari CIFAR-10.  Seperti dalam jaringan saraf konvensional, setiap neuron dari lapisan ini akan dikaitkan dengan semua neuron dari lapisan sebelumnya (representasi 3D). </li></ul><br><p>  Ini adalah bagaimana jaringan saraf convolutional mengubah gambar asli, lapis demi lapis, dari nilai piksel awal ke estimasi kelas akhir.  Perhatikan bahwa beberapa layer berisi opsi, dan beberapa tidak.  Secara khusus, lapisan <code>CONV/FC</code> melakukan transformasi, yang tidak hanya fungsi yang tergantung pada data input, tetapi juga tergantung pada nilai internal dari bobot dan perpindahan dalam neuron itu sendiri.  <code>RELU/POOL</code> , <code>RELU/POOL</code> lain, menggunakan fungsi non-parameter.  Parameter dalam lapisan <code>CONV/FC</code> akan dilatih oleh gradient descent sehingga input menerima label output yang benar. </p><br><p>  Untuk meringkas: </p><br><ul><li>  Arsitektur jaringan saraf convolutional, dalam representasi yang paling sederhana, adalah seperangkat lapisan terurut yang mengubah representasi gambar menjadi representasi lain, misalnya, perkiraan keanggotaan kelas. </li><li>  Ada beberapa jenis lapisan (CONV - lapisan konvolusional, FC - sepenuhnya terhubung, fungsi aktivasi RELU, POOL - lapisan subsampel - yang paling populer). </li><li>  Setiap lapisan input menerima representasi 3D, mengubahnya menjadi representasi 3D output menggunakan fungsi terdiferensiasi. </li><li>  Setiap lapisan mungkin dan mungkin tidak memiliki parameter (CONV / FC - memiliki parameter, RELU / POOL - no). </li><li>  Setiap lapisan mungkin dan mungkin tidak memiliki parameter hyper (CONV / FC / POOL - have, RELU - no) </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d92/59b/e82/d9259be829b1cdb3d98a399ebc56defa.jpg"><br>  <em>Representasi awal berisi nilai-nilai piksel dari gambar (di sebelah kiri) dan perkiraan untuk kelas-kelas yang menjadi objek objek di dalam gambar (di sebelah kanan).</em>  <em>Setiap transformasi tampilan ditandai sebagai kolom.</em> </p><br><h1>  Lapisan konvolusional </h1><br><p>  <em>Lapisan convolutional</em> adalah <em>lapisan</em> utama dalam pembangunan jaringan saraf convolutional. </p><br><p>  <em>Gambaran umum tanpa menyelam ke fitur otak.</em>  Mari kita pertama-tama mencoba mencari tahu apa yang lapisan CONV masih hitung tanpa membenamkan dan menyentuh subjek otak dan neuron.  Parameter lapisan convolutional terdiri dari seperangkat filter terlatih.  Setiap filter adalah kotak kecil sepanjang lebar dan tinggi, tetapi memanjang di seluruh kedalaman representasi input. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/497/c0f/e18/497c0fe1851288e36fad00c004d4f9cf.png"></p><br><p>  Misalnya, filter standar pada lapisan pertama dari jaringan saraf convolutional dapat memiliki dimensi 5x5x3 (lebar dan tinggi 5px, 3 - jumlah saluran warna).  Selama pass langsung, kami memindahkan (tepatnya - kami runtuh) filter sepanjang lebar dan tinggi representasi input dan menghitung produk skalar antara nilai filter dan nilai yang sesuai dari representasi input di titik mana pun.  Dalam proses memindahkan filter sepanjang lebar dan tinggi representasi input, kami membentuk peta aktivasi 2 dimensi yang berisi nilai-nilai menerapkan filter ini untuk masing-masing bidang representasi input.  Secara intuitif, menjadi jelas bahwa jaringan akan mengajarkan filter untuk mengaktifkan ketika mereka melihat tanda visual tertentu, misalnya, garis lurus pada sudut tertentu atau representasi berbentuk roda di tingkat yang lebih tinggi.  Sekarang kami telah menerapkan semua filter kami ke gambar asli, misalnya, ada 12. Sebagai hasil dari menerapkan 12 filter, kami menerima 12 kartu aktivasi dimensi 2. Untuk menghasilkan representasi output, kami menggabungkan kartu-kartu ini (berurutan dalam dimensi 3) dan mendapatkan representasi Dimensi [WxHx12]. </p><br><p>  <em>Ikhtisar yang kami sambungkan ke otak dan neuron</em>  Jika Anda adalah penggemar otak dan neuron, Anda dapat membayangkan bahwa setiap neuron "melihat" bagian besar dari representasi input dan mentransfer informasi tentang bagian ini ke neuron tetangga.  Di bawah ini kita akan membahas detail konektivitas neuron, lokasinya di ruang angkasa, dan mekanisme untuk berbagi parameter. </p><br><p>  <em>Konektivitas lokal.</em>  Ketika kita berurusan dengan input data dengan sejumlah besar dimensi, misalnya, seperti dalam kasus gambar, maka, seperti yang telah kita lihat, sama sekali tidak perlu untuk menghubungkan neuron dengan semua neuron pada lapisan sebelumnya.  Sebagai gantinya, kami hanya akan menghubungkan neuron ke area lokal dari representasi input.  Derajat konektivitas spasial adalah salah satu dari hiper-parameter dan disebut <em>bidang reseptif</em> (bidang reseptif neuron adalah ukuran filter / inti konvolusi yang sama).  Tingkat konektivitas sepanjang dimensi ke-3 (kedalaman) selalu sama dengan kedalaman representasi asli.  Sangat penting untuk fokus pada hal ini lagi, memperhatikan bagaimana kita mendefinisikan dimensi spasial (lebar dan tinggi) dan kedalaman: koneksi neuron adalah lebar dan tinggi lokal, tetapi <em>selalu</em> meluas ke seluruh kedalaman representasi input. </p><br><p>  <em>Contoh 1.</em> Bayangkan bahwa representasi input memiliki ukuran 32x32x3 (RGB, CIFAR-10).  Jika ukuran filter (bidang reseptif neuron) adalah 5 × 5, maka setiap neuron dalam lapisan konvolusional akan memiliki bobot di wilayah 5 × 5 × 3 dari representasi asli, yang pada akhirnya akan mengarah pada pembentukan 5 × 5 × 3 = 75 ikatan (bobot) + 1 parameter offset.  Harap dicatat bahwa tingkat keterhubungan secara mendalam harus sama dengan 3, karena ini adalah dimensi dari representasi aslinya. </p><br><p>  <em>Contoh 2.</em> Bayangkan bahwa representasi input memiliki ukuran 16x16x20.  Dengan menggunakan sebagai contoh bidang reseptif dari neuron ukuran 3x3, setiap neuron lapisan konvolusional akan memiliki 3x3x320 = 180 koneksi (bobot) + 1 parameter perpindahan.  Perhatikan bahwa konektivitas lokal memiliki lebar dan tinggi, tetapi kedalaman penuh (20). </p><br><div class="scrollable-table"><table><thead><tr><th>  # 1 </th><th>  # 2 </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/490/db9/7a0/490db97a0f3fa98eb2f44e84764f8991.jpg"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/61f/e81/589/61fe81589ab491d1d3ba612b3bdf5b51.jpg"></td></tr></tbody></table></div><br><p>  <em>Dari sisi kiri:</em> representasi input ditampilkan dengan warna merah (misalnya, gambar berukuran 32x332 CIFAR-10) dan contoh representasi neuron di lapisan konvolusional pertama.  Setiap neuron dalam lapisan konvolusional hanya dikaitkan dengan area lokal dari representasi input, tetapi sepenuhnya mendalam (dalam contoh, di sepanjang semua saluran warna).  Harap dicatat bahwa ada banyak neuron dalam gambar (dalam contoh - 5) dan mereka berada di sepanjang dimensi ke-3 (kedalaman) - penjelasan mengenai pengaturan ini akan diberikan di bawah ini. <br>  <em>Di sisi kanan:</em> neuron dari jaringan saraf masih tetap tidak berubah: mereka masih menghitung produk skalar antara bobot dan input data, menerapkan fungsi aktivasi, tetapi konektivitas mereka sekarang dibatasi oleh area lokal spasial. </p><br><p>  <em>Lokasi spasial.</em>  Kami telah menemukan konektivitas masing-masing neuron di lapisan konvolusional dengan representasi input, tetapi belum membahas berapa banyak neuron ini atau bagaimana mereka berada.  Tiga parameter hiper mempengaruhi ukuran tampilan output: <em>kedalaman</em> , <em>langkah,</em> dan <em>perataan</em> . </p><br><ol><li>  <em>Kedalaman</em> representasi output adalah parameter hiper: itu sesuai dengan jumlah filter yang ingin kita terapkan, yang masing-masing mempelajari sesuatu yang lain dalam representasi asli.  Misalnya, jika lapisan konvolusional pertama menerima gambar sebagai input, maka neuron yang berbeda di sepanjang dimensi ke-3 (kedalaman) dapat diaktifkan dengan adanya orientasi garis yang berbeda di area tertentu atau kelompok warna tertentu.  Himpunan neuron yang "melihat" pada area yang sama dari representasi input, kita akan memanggil <em>kolom yang dalam</em> (atau "serat" - serat). </li><li>  Kita perlu menentukan <em>langkah</em> (ukuran offset dalam piksel) dengan mana filter akan bergerak.  Jika langkahnya 1, maka kami menggeser filter dengan 1 piksel dalam satu iterasi.  Jika langkahnya 2 (atau, yang bahkan lebih jarang digunakan, 3 atau lebih), maka offset terjadi untuk setiap dua piksel dalam satu iterasi.  Langkah yang lebih besar menghasilkan representasi output yang lebih kecil. </li><li>  Seperti yang akan segera kita lihat, kadang-kadang perlu untuk melengkapi representasi input di sepanjang tepi dengan nol.  Ukuran perataan (jumlah kolom / baris nol empuk) juga merupakan parameter hiper.  Fitur bagus menggunakan alignment adalah kenyataan bahwa alignment akan memungkinkan kita untuk mengontrol dimensi representasi output (paling sering kita akan menjaga dimensi asli tampilan - menjaga lebar dan tinggi representasi input dengan lebar dan tinggi representasi output). </li></ol><br><p>  Kita dapat menghitung dimensi akhir dari representasi output dengan menghadirkannya sebagai fungsi dari ukuran representasi input ( <strong>W</strong> ), ukuran bidang reseptif dari neuron pada lapisan konvolusional ( <strong>F</strong> ), langkah ( <strong>S</strong> ) dan ukuran alignment ( <strong>P</strong> ) di perbatasan.  Anda dapat melihat sendiri bahwa rumus yang tepat untuk menghitung jumlah neuron dalam representasi output adalah sebagai berikut <strong>(W - F + 2P) / S + 1</strong> .  Misalnya, untuk representasi input ukuran 7x7 dan ukuran filter 3x3, langkah 1 dan penyelarasan 0, kita mendapatkan representasi output berukuran 5x5.  Pada langkah 2, kita akan mendapatkan representasi output 3x3.  Mari kita lihat contoh lain, kali ini diilustrasikan secara grafis: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/90a/f0b/d67/90af0bd67ba498239688c81fd61bbc66.jpg"><br>  <em>Ilustrasi pengaturan ruang.</em>  <em>Dalam contoh ini, hanya satu dimensi spasial (sumbu x), satu neuron dengan bidang reseptif <strong>F = 3</strong> , ukuran representasi input <strong>W = 5</strong> dan perataan <strong>P = 1</strong> .</em>  <em><strong>Di sisi kiri</strong> : bidang reseptif neuron bergerak dengan langkah <strong>S = 1</strong> , yang sebagai hasilnya memberikan ukuran representasi output (5 - 3 + 2) / 1 + 1 = 5. <strong>Di sisi kanan</strong> : neuron menggunakan bidang reseptif ukuran <strong>S = 2</strong> , yang pada hasilnya adalah ukuran representasi output (5 - 3 + 2) / 2 + 1 = 3. Perhatikan bahwa ukuran langkah <strong>S = 3</strong> tidak dapat digunakan, karena dengan ukuran langkah ini bidang reseptif tidak akan menangkap bagian dari gambar.</em>  <em>Jika kita menggunakan rumus kita, maka (5 - 3 + 2) = 4 bukan kelipatan 3. Bobot neuron dalam contoh ini adalah [1, 0, -1] (seperti yang ditunjukkan pada gambar paling kanan), dan offsetnya adalah nol.</em>  <em>Bobot ini dibagi oleh semua neuron kuning.</em> </p><br><p>  <em>Menggunakan perataan</em> .  Perhatikan contoh di sebelah kiri, yang berisi 5 elemen pada output dan 5 elemen pada output.  Ini berhasil karena ukuran bidang reseptif (filter) adalah 3 dan kami menggunakan perataan <strong>P = 1</strong> .  Jika tidak ada keselarasan, maka ukuran representasi output akan sama dengan 3, karena justru banyak neuron yang cocok di sana.  Secara umum, pengaturan ukuran pelurusan <strong>P = (F - 1) / 2</strong> dengan langkah yang sama dengan <strong>S = 1</strong> memungkinkan Anda untuk mendapatkan ukuran representasi keluaran yang sama dengan representasi input.  Pendekatan serupa menggunakan penyelarasan sering diterapkan dalam praktek, dan kami akan membahas alasan di bawah ini ketika kita berbicara tentang arsitektur jaringan saraf convolutional. </p><br><p>  <em>Batas ukuran langkah</em> .  Harap dicatat bahwa parameter-hiper yang bertanggung jawab untuk pengaturan spasial juga terkait dengan keterbatasan.  Misalnya, jika representasi input memiliki ukuran <strong>W = 10</strong> , <strong>P = 0</strong> dan ukuran bidang penerima <strong>F = 3</strong> , maka menjadi tidak mungkin untuk menggunakan ukuran langkah sama dengan <strong>S = 2</strong> , karena <strong>(W - F + 2P) / S + 1 = (10 - 3 + 0) / 2 + 1 = 4.5</strong> , yang memberikan nilai integer dari jumlah neuron.  Dengan demikian, konfigurasi parameter hiper dianggap tidak valid dan perpustakaan untuk bekerja dengan jaringan saraf convolutional akan mengeluarkan pengecualian, memaksa penyelarasan, atau bahkan memotong representasi input.  Seperti yang akan kita lihat di bagian selanjutnya dari bab ini, definisi parameter-hiper dari lapisan konvolusional masih merupakan sakit kepala yang dapat dikurangi dengan menggunakan rekomendasi tertentu dan "aturan nada yang baik" ketika merancang arsitektur jaringan saraf convolutional. </p><br><p>  <em>Contoh kehidupan nyata</em> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Arsitektur</a> jaringan saraf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">convolutional Krizhevsky et al.</a>  , yang memenangkan kompetisi ImageNet pada 2012, menerima 227x227x3 gambar.  Pada lapisan konvolusional pertama, ia menggunakan bidang reseptif ukuran <strong>F = 11</strong> , langkah <strong>S = 4,</strong> dan ukuran penyelarasan <strong>P = 0</strong> .  Sejak (227 - 11) / 4 + 1 = 55, dan lapisan konvolusional adalah <strong>K = 96</strong> , dimensi output dari presentasi adalah 55x55x96.  Setiap neuron 55x55x96 dalam representasi ini dikaitkan dengan wilayah berukuran 11x11x3 dalam representasi input.  Selain itu, semua 96 neuron di kolom dalam dikaitkan dengan wilayah 11x11x3 yang sama, tetapi dengan bobot yang berbeda.  Dan sekarang sedikit humor - jika Anda memutuskan untuk berkenalan dengan dokumen asli (belajar), maka perhatikan bahwa dokumen tersebut menyatakan bahwa input menerima 224x224 gambar, yang tidak mungkin benar, karena (224 - 11) / 4 + 1 sama sekali tidak memberikan nilai integer.  Situasi seperti ini sering membingungkan orang dalam cerita dengan jaringan saraf convolutional.  Dugaan saya adalah bahwa Alex menggunakan ukuran pelurusan <strong>P = 3</strong> , tetapi lupa menyebutkan ini dalam dokumen. </p><br><p>  <em>Opsi berbagi.</em>  Mekanisme untuk berbagi parameter di lapisan konvolusional digunakan untuk mengontrol jumlah parameter.  Perhatikan contoh di atas, seperti yang Anda lihat ada 55x55x96 = 290.400 neuron pada lapisan konvolusional pertama dan masing-masing neuron memiliki 11x11x3 = 363 bobot + 1 nilai offset.  Secara total, jika kita mengalikan dua nilai ini, kita mendapatkan 290400x364 = 105 705 600 parameter <em>hanya</em> pada lapisan pertama dari jaringan saraf convolutional.  Jelas, ini sangat penting! </p><br><p>  Ternyata adalah mungkin untuk mengurangi jumlah parameter secara signifikan dengan membuat satu asumsi: jika beberapa properti yang dihitung dalam posisi (x, y) penting bagi kami, maka properti ini yang dihitung dalam posisi (x2, y2) juga penting bagi kami.  Dengan kata lain, menunjukkan kedalaman dua dimensi "lapisan" sebagai "lapisan dalam" (misalnya, tampilan [55x55x96] berisi 96 lapisan dalam, masing-masing berukuran 55x55), kami akan membangun neuron secara mendalam dengan bobot dan perpindahan yang sama.  Dengan skema berbagi parameter ini, lapisan konvolusional pertama dalam contoh kita sekarang akan berisi 96 set bobot unik (masing-masing set untuk setiap lapisan kedalaman), secara total akan ada 96x11x11x3 = 34.848 bobot unik atau 34.944 parameter (+96 offset).  Selain itu, semua neuron 55x55 di setiap lapisan dalam sekarang akan menggunakan parameter yang sama.  Dalam praktiknya, selama propagasi balik, setiap neuron dalam representasi ini akan menghitung gradien untuk bobotnya sendiri, tetapi gradien ini akan dijumlahkan pada setiap lapisan kedalaman dan memperbarui hanya satu set bobot di setiap level. </p><br><p>  Perhatikan bahwa jika semua neuron dalam lapisan dalam yang sama menggunakan bobot yang sama, maka untuk propagasi langsung melalui lapisan konvolusional, konvolusi antara nilai-nilai bobot neuron dan data input akan dihitung.  Itulah sebabnya lazim untuk memanggil satu set bobot - <strong>filter (inti)</strong> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/dd6/2e1/d75/dd62e1d75bda9b592dabb91627d68aa6.jpg"><br>  <em>Contoh filter yang diperoleh dengan melatih model Krizhevsky et al.</em>  <em>Masing-masing dari 96 filter yang ditampilkan di sini berukuran 11x11x3 dan masing-masing dibagikan oleh semua neuron 55x55 dari satu lapisan dalam.</em>  <em>Harap perhatikan bahwa asumsi berbagi bobot yang sama masuk akal: jika deteksi garis horizontal penting di satu bagian gambar, maka secara intuitif jelas bahwa deteksi semacam itu penting di bagian lain gambar ini.</em>  <em>Oleh karena itu, tidak masuk akal untuk melatih ulang setiap waktu untuk menemukan garis horizontal di setiap 55x55 tempat gambar yang berbeda di lapisan convolutional.</em> </p><br><p>  Harus diingat bahwa asumsi parameter berbagi mungkin tidak selalu masuk akal.  Misalnya, jika gambar dengan struktur terpusat diumpankan ke input dari jaringan saraf convolutional, di mana kami ingin dapat mempelajari satu properti di satu bagian gambar dan properti lain di bagian lain gambar.  Contoh praktisnya adalah gambar wajah terpusat.  Dapat diasumsikan bahwa tanda mata atau rambut yang berbeda dapat diidentifikasi pada area gambar yang berbeda, oleh karena itu, dalam hal ini, relaksasi bobot digunakan dan lapisan tersebut disebut <strong>terhubung secara lokal</strong> . </p><br><p>  <strong>Contoh-contoh kotor</strong> .  Diskusi sebelumnya harus ditransfer ke bidang spesifik dan pada contoh dengan kode.  Bayangkan representasi input adalah array <code>numpy</code> <code>X</code>  Lalu: </p><br><ul><li>  <em>Kolom dalam</em> ( <em>utas</em> ) pada posisi <code>(x,y)</code> akan direpresentasikan sebagai berikut <code>X[x,y,:]</code> . </li><li>  <em>Lapisan dalam</em> , atau seperti yang kita sebut lapisan sebelumnya - <em>peta aktivasi</em> pada kedalaman <code>d</code> akan direpresentasikan sebagai berikut <code>X[:,:,d]</code> . </li></ul><br><p>  <em>Contoh lapisan konvolusional</em> . ,    <code>X</code>   <code>X.shape: (11,11,4)</code> .   ,    <strong>P=1</strong> ,    () <strong>F=5</strong>   <strong>S=1</strong> .     44,     — (11-5)/2+1=4.     (  <code>V</code> ),     (      ): </p><br><ul><li> <code>V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0</code> </li> <li> <code>V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0</code> </li> <li> <code>V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0</code> </li> <li> <code>V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0</code> </li> </ul><br><p> ,   <code>numpy</code> ,  <code>*</code>      .    ,    <code>W0</code>      <code>b0</code>  .    <code>W0</code>   <code>W0.shape: (5,5,4)</code> ,      5,    4.                   .       ,           ,        2  ( ).             : </p><br><ul><li> <code>V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1</code> </li> <li> <code>V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1</code> </li> <li> <code>V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1</code> </li> <li> <code>V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1</code> </li> <li> <code>V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1</code> (,       <code>y</code> ) </li><li> <code>V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1</code> (,      ) </li></ul><br><p>         —    <code>W1</code>   <code>b1</code> .      ,               <code>V</code> .    ,         , , <code>ReLU</code> ,        .      . </p><br><p> <strong></strong> .     : </p><br><ul><li>      <strong>W1 x H1 x D1</strong> </li><li>  4 -: <br><ul><li>   <strong>K</strong> , </li><li>    <strong>F</strong> , </li><li>   <strong>S</strong> , </li><li>   <strong>P</strong> . </li></ul></li><li>     <strong>W2 x H2 x D2</strong> ,  <br><ul><li> <strong>W2 = (W1 — F + 2P)/S + 1</strong> </li><li> <strong>H2 = (H1 — F + 2P)/S + 1</strong> </li><li> <strong>D2 = K</strong> </li></ul></li><li>      <strong>F x F x D1</strong>    ,  <strong>(F x F x D1) x K</strong>   <strong>K</strong> . </li><li>   , <code>d</code> - ( <strong>W2 x H2</strong> )       <code>d</code> -      <strong>S</strong>      <code>d</code> -. </li></ul><br><p>    -  <strong>F = 3, S = 1, P = 1</strong> .        .      "   ". </p><br><p> <strong>.</strong>        .   3D-   ( —  ,  — ,  —  ),        —   .    <strong>W1 = 5, H1 = 5, D1 = 3</strong> ,     <strong>K = 2, F = 3, S = 2, P = 1</strong> . ,       33,     2.        (5 — 3 + 2)/2 + 1 = 3.  ,  ,   <strong>P = 1</strong>        .         ,         ()  ,   . </p><br><p> (   ,     html+css   ,       ) </p><br><p> <strong>    </strong> .               ().                   : </p><br><ol><li>        <strong>im2col</strong> . ,        227x227x3         11113   4,           11113 = 363 .   ,     4    ,   (227 — 11) / 4 + 1 = 55     ,          <strong>X_col</strong>  3633025,               3025.  ,   ,    ,  (),           . </li><li>          . ,    96   11113,       <strong>W_row</strong>  96363. </li><li>               — <strong>np.dot(W_row, X_col)</strong> ,           .         963025. </li><li>              555596. </li></ol><br><p>   , ,     —              ,    . ,    ,      —        (,    BLAS API).  ,    <strong>im2col</strong>        ,        . </p><br><p> <strong> </strong> .   (  )   (   ,    )     (  - ).     ,     . </p><br><p> <strong>11 </strong> .          11,       <a href="">Network in Network</a> .  ,      11,   ,       . ,    2-  ,   11    (     ).         ,       ,         3-  ,         . ,     32323,          11, ,  ,        3  (R, G, B —  , ). </p><br><p> <strong>   </strong> .      -      <em></em> .           .           ,   <em></em> .       <strong>w</strong>  3     <strong>x</strong> : <strong>w[0] <em>x[0] + w[1]</em> x[1] + w[2] <em>x[2] <strong>.      0.    1       :</strong> w[0]</em> x[0] + w[1] <em>x[2] + w[2]</em> x[4]</strong> .      ""  1    .        ,             . ,    2    33,     ,             55 (   55 <em>  </em> ).              . </p><br><h1>   </h1><br><p>   —           .         ,             ,        .          ,       MAX.     22   2,        2 ,    75% .   MAX            22.     .   ,  : </p><br><ul><li>    <strong>W1 x H1 x D1</strong> </li><li>  2 -: <br><ul><li>    <strong>F</strong> , </li><li>  <strong>S</strong> , </li></ul></li><li>    <strong>W2 x H2 x D2</strong> , : <br><ul><li> <strong>W2 = (W1 — F)/S + 1</strong> </li><li> <strong>H2 = (H1 — F)/S + 1</strong> </li><li> <strong>D2 = D1</strong> </li></ul></li><li>   ,         </li><li>       (zero-padding    ). </li></ul><br><p>    ,           :    <strong>F=3, S=2</strong> (   <em> </em> ),    — <strong>F=2, S=2</strong> .      -   . </p><br><p> <strong>   </strong> .      ,       , ,       L2-.         ,           ,      . </p><br><div class="scrollable-table"><table><thead><tr><th>  # 1 </th><th>  # 2 </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/cd7/174/14d/cd717414dcf32dac4df73c00f1e7c6c3.jpg"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/1a4/b2a/379/1a4b2a3795d8f073e921d766e70ce6ec.jpg"></td></tr></tbody></table></div><br><p> <em>              . <strong></strong> :       22422464        22   2,     11211264.  ,      . <strong></strong> :     —    (max-pooling),      2.      4  (   22)</em> </p><br><p> <strong> </strong> .      ,     max(a,b)    —            .  ,              (  <em></em> ),        . </p><br><p> <strong>  </strong> .        ,           . ,   <a href="">  :   </a> ,           .             .              ,     (VAEs)     (GANs). ,     -   ,    . </p><br><h1>   </h1><br><p>            ,      ,       . ,      ,            .         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a> . </p><br><h1>   </h1><br><p>           ,       .             . </p><br><h1>       </h1><br><p>  ,           ,                 (  ).      -   ,        .    ,         : </p><br><ul><li>       ,       .  ,   ,   ,   ,                  ,     . </li><li> ,         . ,    <strong>K=4096</strong> ( ),     7712          - <strong>F=7, P=0, S=1, K=4096</strong> .        ,               114096,      . </li></ul><br><p> <strong>    </strong> .    ,            .        ,       2242243                  77512 (     AlexNet,    ,     5  ,           7 — 224/2/2/2/2/2 = 7).   AlexNet      4096 , ,     1000 ,     .               : </p><br><ul><li>    ,  ""    77512,       <strong>F=7</strong> ,       114096. </li><li>           <strong>F=1</strong> ,      114096. </li><li>           <strong>F=1</strong> ,      111000. </li></ul><br><p>    ,  ,     (   )   <strong>W</strong>         . ,       "" ()             . </p><br><p> ,     224224  ,  77512   —    32 ,        384384       1212512,   384/32 = 12.                 ,    ,    ,   661000,   (12 — 7)/1 + 1 = 6.  ,        111000     66    384384 . </p><br><blockquote>        (  )     384384,   224244   32 ,    ,        . </blockquote><p>  ,             ,      36 ,    36    .        ,    ,         .                   . </p><br><p> ,           ,     32 ?          (   ). ,        16 ,             2 :               16     . </p><br><h1>     </h1><br><p>        ,  ,   3   :  ,   (    ,    )   .        ReLU   ,   -  .                . </p><br><p>            CONV-RELU-,    POOL-       ,        .  -      .      , ,   .  ,        : </p><br><pre> <code class="plaintext hljs">INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?] * M -&gt; [FC -&gt; RELU]*K -&gt; FC</code> </pre> <br><p>   <code>*</code>  ,  <code>POOL?</code>    .  , <code>N &gt;= 0</code> ( <code>N &lt;= 3</code> ), <code>M &gt;= 0</code> , <code>K &gt;= 0</code> ( <code>K &lt; 3</code> ). ,       ,     : </p><br><ul><li> <code>INPUT -&gt; FC</code> ,   . <code>N = M = K = 0</code> . </li><li> <code>INPUT -&gt; CONV -&gt; RELU -&gt; FC</code> </li> <li> <code>INPUT -&gt; [CONV -&gt; RELU -&gt; POOL] * 2 -&gt; FC -&gt; RELU -&gt; FC</code> ,           . </li><li> <code>INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL] * 3 -&gt; [FC -&gt; RELU] * 2 -&gt; FC</code> .     2      .  ,        ,                   . </li></ul><br><p> <em>               </em> .      3    33 ( RELU   ,  ).          ""   33  .      ""   33     ,     —     55.        ""  33     ,    —   77.  ,      33           77.         ""  77 (  )      ,    . -,        ,      3      ,       . -,        <strong>C</strong> ,   ,    77     <strong>(C(77)) = 49xxC</strong> ,        33    <strong>3((33)) = 27</strong> .   ,                 ,            .           —          ,      . </p><br><p> <strong></strong> .    ,       ,       Google,         Microsoft.               . </p><br><p> <strong> :  ,        ImageNet.</strong>                ,    ,   90%       .       — "  ":  ,       ,        ,         ImageNet —   ,       .               . </p><br><h1>      </h1><br><p>         -,        .    ,      : </p><br><p> <strong> </strong> ( )    2  .    32 (, CIFAR-10), 64, 96 (, STL-10),  224 (, ImageNet), 384  512. </p><br><p>  <strong> </strong>      (, 33 ,  55),    <strong>S=1</strong> ,    ,    ,         .  , <strong>F=3</strong>   <strong>P=1</strong>        .  <strong>F=5, P=2</strong> .    <strong>F</strong>   ,   <strong>P=(F-1)/2</strong>     .   -       (  77),                 . </p><br><p> <strong> </strong>      .            22 ( <strong>F=2</strong> )   2 ( <strong>S=2</strong> ). ,     75%    (- ,       ). ,   ,     33 ( )  2 ( ).       33   ,               .       . </p><br><p> <em>      .</em>     ,          ,        .   ,      1       ,                   ,             . </p><br><p> <em>     1   ?</em>       .     ,    1        (       ),        . </p><br><p> <em>  ?</em>                ,    .         ,     ,            ,          . </p><br><p> <em>    </em> .    (        ),       ,     . ,      64     33   1   2242243,       22422464. , ,  10  ,  72   ( ,       ).            GPU,     .  ,             77   2.  ,     AlexNet,    1111   4. </p><br><h1>    </h1><br><p>           .    : </p><br><ul><li> <strong>LeNet</strong> .         Yann LeCun  1990.       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">LeNet</a> ,     ZIP-,   . </li><li> <strong>AlexNet</strong> .  ,        ,  Alex Krizhevsky, Ilya Sutskever  Geoff Hinton. AlexNet     ImageNet ILSVRC  2012         ( : 16%  26%).        LeNet,   ,       (               ). </li><li> <strong>ZFNet</strong> .  ILSVRC 2013       Matthew Zeiler  Rob Fergus.      ZFNet.     AlexNet,     -,                 . </li><li> <strong>GoogLeNet</strong> .  ILSVRC 2014       Szegedy et al.  Google.      Inception-,         (4   60   AlexNet).                ,      ,     .       ,    — Inveption-v4. </li><li> <strong>VGGNet</strong> .    2014 ILSVRC    Karen Simonyan  Andrew Zisserman,       VGGNet.               ,        .      16   +        (33    22   ).            .    VGGNet —        (140).          ,       ,          ,       . </li><li> <strong>ResNet</strong> . Residual-   Kaiming He et al.     ILSVRC 2015.        .          .            (  2016). </li></ul><br><p> <strong>VGGNet  </strong> .   VGGNet    .   VGGNet    ,         33,  1   1,       22   2.          (     )    : </p><br><pre> <code class="plaintext hljs">INPUT: [224x224x3] memory: 224*224*3=150K weights: 0 CONV3-64: [224x224x64] memory: 224*224*64=3.2M weights: (3*3*3)*64 = 1,728 CONV3-64: [224x224x64] memory: 224*224*64=3.2M weights: (3*3*64)*64 = 36,864 POOL2: [112x112x64] memory: 112*112*64=800K weights: 0 CONV3-128: [112x112x128] memory: 112*112*128=1.6M weights: (3*3*64)*128 = 73,728 CONV3-128: [112x112x128] memory: 112*112*128=1.6M weights: (3*3*128)*128 = 147,456 POOL2: [56x56x128] memory: 56*56*128=400K weights: 0 CONV3-256: [56x56x256] memory: 56*56*256=800K weights: (3*3*128)*256 = 294,912 CONV3-256: [56x56x256] memory: 56*56*256=800K weights: (3*3*256)*256 = 589,824 CONV3-256: [56x56x256] memory: 56*56*256=800K weights: (3*3*256)*256 = 589,824 POOL2: [28x28x256] memory: 28*28*256=200K weights: 0 CONV3-512: [28x28x512] memory: 28*28*512=400K weights: (3*3*256)*512 = 1,179,648 CONV3-512: [28x28x512] memory: 28*28*512=400K weights: (3*3*512)*512 = 2,359,296 CONV3-512: [28x28x512] memory: 28*28*512=400K weights: (3*3*512)*512 = 2,359,296 POOL2: [14x14x512] memory: 14*14*512=100K weights: 0 CONV3-512: [14x14x512] memory: 14*14*512=100K weights: (3*3*512)*512 = 2,359,296 CONV3-512: [14x14x512] memory: 14*14*512=100K weights: (3*3*512)*512 = 2,359,296 CONV3-512: [14x14x512] memory: 14*14*512=100K weights: (3*3*512)*512 = 2,359,296 POOL2: [7x7x512] memory: 7*7*512=25K weights: 0 FC: [1x1x4096] memory: 4096 weights: 7*7*512*4096 = 102,760,448 FC: [1x1x4096] memory: 4096 weights: 4096*4096 = 16,777,216 FC: [1x1x1000] memory: 1000 weights: 4096*1000 = 4,096,000 TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd) TOTAL params: 138M parameters</code> </pre> <br><p>          ,    ,     (  )     ,        .        100     140 . </p><br><h1>   </h1><br><p>           .   GPU  3/4/6  ,   GPU — 12  .      ,    : </p><br><ul><li>  :           ,      (  ). ,      .          ,                         . </li><li>  : ,    ,         .    ,      ,     3  . </li><li>            ,         ,      .. </li></ul><br><p>           (,   ),          .    ,    4     (      4 ,       —  8),       1024  ,    ,      .   " ",        ,        . </p><br><p> …   call-to-action — ,     share :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Telegram</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VKontakte</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id456186/">https://habr.com/ru/post/id456186/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id456172/index.html">Bagian 2: RocketChip: menghubungkan RAM</a></li>
<li><a href="../id456174/index.html">Cara mengatur hackathon sebagai siswa 101. Bagian Dua</a></li>
<li><a href="../id456178/index.html">Tema dan gaya Android tanpa sihir. Dan cara memasaknya dengan SwitchCompat</a></li>
<li><a href="../id456180/index.html">Bagaimana saya menemukan kerentanan pertama saya?</a></li>
<li><a href="../id456184/index.html">Software Defined Radio - bagaimana cara kerjanya? Bagian 8</a></li>
<li><a href="../id456188/index.html">Token, segarkan token, dan buat pembungkus asinkron untuk permintaan REST</a></li>
<li><a href="../id456192/index.html">Dari monolit hingga layanan mikro: pengalaman M.Video-Eldorado dan MegaFon</a></li>
<li><a href="../id456194/index.html">Pergi struktur data lembar contekan</a></li>
<li><a href="../id456196/index.html">Kesalahpahaman mendasar tentang SCRUM</a></li>
<li><a href="../id456200/index.html">Sejarah Internet: ARPANET - The Origin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç™ üë∂üèø üë©üèæ‚Äçü§ù‚Äçüë®üèº Migrando um Aplicativo Real do MySQL Independente para o Percona XtraDB Cluster üë®üèæ üõåüèø ü§òüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Infelizmente, na Internet, n√£o h√° informa√ß√µes suficientes sobre a migra√ß√£o de aplicativos reais e a opera√ß√£o de produ√ß√£o do Percona XtraDB Cluster (a ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migrando um Aplicativo Real do MySQL Independente para o Percona XtraDB Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422347/"><img src="https://habrastorage.org/getpro/habr/post_images/2b3/23e/2d3/2b323e2d35539763c7a0d17a4694d5af.png" alt="imagem"><br><br>  Infelizmente, na Internet, n√£o h√° informa√ß√µes suficientes sobre a migra√ß√£o de aplicativos reais e a opera√ß√£o de produ√ß√£o do Percona XtraDB Cluster (a seguir designado PXC).  Vou tentar corrigir essa situa√ß√£o e contar sobre a nossa experi√™ncia com a minha hist√≥ria.  N√£o haver√° instru√ß√µes de instala√ß√£o passo a passo e o artigo n√£o deve ser considerado como um substituto para a documenta√ß√£o insuficiente, mas como um conjunto de recomenda√ß√µes. <br><a name="habracut"></a><br><h3>  O problema </h3><br>  Eu trabalho como administrador de sistema no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ultimate-guitar.com</a> .  Como fornecemos um servi√ßo da Web, naturalmente possu√≠mos back-end e um banco de dados, que √© o n√∫cleo do servi√ßo.  O tempo de atividade do servi√ßo depende diretamente do desempenho do banco de dados. <br><br>  O Percona MySQL 5.7 foi usado como banco de dados.  A reserva foi implementada usando o mestre do esquema de replica√ß√£o mestre.  Escravos foram usados ‚Äã‚Äãpara ler alguns dados. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05a/ca3/bc6/05aca3bc6ba1c357cd98c280e8a07772.png" alt="imagem"><br><br>  Mas esse esquema n√£o nos serviu das seguintes desvantagens: <br><br><ul><li>  Devido ao fato de que na replica√ß√£o do MySQL, os escravos ass√≠ncronos podem ficar indefinidamente.  Todos os dados cr√≠ticos tiveram que ser lidos do mestre. </li><li>  A partir do par√°grafo anterior segue a complexidade do desenvolvimento.  O desenvolvedor n√£o p√¥de apenas fazer uma solicita√ß√£o ao banco de dados, mas foi obrigado a pensar se ele estava pronto em cada caso espec√≠fico para o backlog do escravo e, se n√£o, ler os dados no assistente. </li><li>  Comuta√ß√£o manual em caso de acidente.  A implementa√ß√£o da comuta√ß√£o autom√°tica foi problem√°tica devido ao fato de a arquitetura MySQL n√£o possuir prote√ß√£o integrada contra o c√©rebro dividido.  Ter√≠amos que nos escrever um √°rbitro com uma l√≥gica complexa de escolha de um mestre.  Ao escrever para os dois mestres, os conflitos podem surgir ao mesmo tempo, interrompendo a replica√ß√£o principal e levando ao c√©rebro dividido cl√°ssico. </li></ul><br>  Alguns n√∫meros secos, para que voc√™ entenda com o que trabalhamos: <br><br>  Tamanho do banco de dados: 300 GB <br>  QPS: ~ 10k <br>  Rela√ß√£o RW: 96/4% <br>  Configura√ß√£o do servidor principal: <br>  CPU: 2x E5-2620 v3 <br>  RAM: 128 Gb <br>  SSD: Intel Optane 905p 960 Gb <br>  Rede: 1 Gbps <br><br>  Temos um carregamento OLTP cl√°ssico com muita leitura, o que precisa ser feito muito rapidamente e com uma pequena quantidade de escrita.  A carga no banco de dados √© muito pequena devido ao fato de o cache ser usado ativamente no Redis e no Memcached. <br><br><h3>  Sele√ß√£o de decis√£o </h3><br>  Como voc√™ deve ter adivinhado no t√≠tulo, escolhemos o PXC, mas aqui vou explicar por que o escolhemos. <br><br>  Tivemos 4 op√ß√µes: <br><br><ol><li>  Alterar DBMS </li><li>  Replica√ß√£o de Grupo MySQL </li><li>  Dane-se a funcionalidade necess√°ria usando scripts em cima do mestre de replica√ß√£o principal. </li><li>  Cluster MySQL Galera (ou seus garfos, por exemplo, PXC) </li></ol><br>  A op√ß√£o de alterar o banco de dados praticamente n√£o foi considerada, porque  o aplicativo √© grande, em muitos lugares est√° vinculado √† funcionalidade ou sintaxe do mysql, e a migra√ß√£o para o PostgreSQL, por exemplo, levar√° muito tempo e recursos. <br><br>  A segunda op√ß√£o foi replica√ß√£o de grupo do MySQL.  Uma vantagem incontest√°vel disso √© que ele se desenvolve no ramo de baunilha do MySQL, o que significa que no futuro se tornar√° generalizado e ter√° um grande conjunto de usu√°rios ativos. <br><br>  Mas ele tem algumas desvantagens.  Em primeiro lugar, imp√µe mais restri√ß√µes ao esquema do aplicativo e do banco de dados, o que significa que ser√° mais dif√≠cil migrar.  Segundo, a replica√ß√£o de grupo resolve o problema da toler√¢ncia a falhas e do c√©rebro dividido, mas a replica√ß√£o no cluster ainda √© ass√≠ncrona. <br><br>  Tamb√©m n√£o gostamos da terceira op√ß√£o para muitas bicicletas, que inevitavelmente precisamos implementar ao resolver o problema dessa maneira. <br><br>  Galera permitiu resolver completamente o problema de failover do MySQL e parcialmente o problema com a relev√¢ncia dos dados nos escravos.  Em parte porque a assincronia de replica√ß√£o √© mantida.  Depois que uma transa√ß√£o √© confirmada em um n√≥ local, as altera√ß√µes s√£o enviadas para os n√≥s restantes de forma ass√≠ncrona, mas o cluster garante que os n√≥s n√£o fiquem muito atrasados ‚Äã‚Äãe, se come√ßarem a ficar lentos, diminui artificialmente o trabalho.  O cluster garante que, ap√≥s a confirma√ß√£o da transa√ß√£o, ningu√©m possa confirmar altera√ß√µes conflitantes, mesmo no n√≥ que ainda n√£o as replicou. <br><br>  Ap√≥s a migra√ß√£o, o esquema de opera√ß√£o do banco de dados deve ficar assim: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d8/435/190/2d8435190207a5bb711d131d852a572f.png" alt="imagem"><br><br><h3>  A migra√ß√£o </h3><br>  Por que a migra√ß√£o √© o segundo item depois de escolher uma solu√ß√£o?  √â simples - o cluster cont√©m v√°rios requisitos que o aplicativo e o banco de dados devem seguir, e precisamos atend√™-los antes da migra√ß√£o. <br><br><ul><li>  <b>Mecanismo InnoDB para todas as tabelas.</b>  MyISAM, Memory e outros back-end n√£o s√£o suportados.  √â corrigido de maneira simples - convertemos todas as tabelas para o InnoDB. </li><li>  <b>Binlog em formato ROW.</b>  O cluster n√£o precisa de um binlog para funcionar e, se voc√™ n√£o precisar de escravos cl√°ssicos, pode desativ√°-lo, mas o formato do binlog deve ser ROW. </li><li>  <b>Todas as tabelas devem ter uma CHAVE PRIM√ÅRIA / ESTRANGEIRA.</b>  Isso √© necess√°rio para a grava√ß√£o simult√¢nea correta na mesma tabela de n√≥s diferentes.  Para as tabelas que n√£o cont√™m uma chave exclusiva, voc√™ pode usar a chave prim√°ria composta ou o incremento autom√°tico. </li><li>  <b>N√£o use 'LOCK TABLES', 'GET_LOCK () / RELEASE_LOCK ()', 'FLUSH TABLES {{table}} COM LER LOCK' ou o n√≠vel de isolamento 'SERIALIZABLE' para transa√ß√µes.</b> </li><li>  <b>N√£o use as consultas 'CREATE TABLE ... AS SELECT'</b> , pois  eles combinam mudan√ßa de esquema e dados.  √â facilmente dividido em duas consultas, a primeira das quais cria uma tabela e a segunda √© preenchida com dados. </li><li>  <b>N√£o use 'DISCARD TABLESPACE' e 'IMPORT TABLESPACE'</b> , pois  eles n√£o s√£o replicados </li><li>  <b>Defina as op√ß√µes 'innodb_autoinc_lock_mode' como '2'.</b>  Essa op√ß√£o pode corromper os dados ao trabalhar com a replica√ß√£o STATEMENT, mas como apenas a replica√ß√£o ROW √© permitida no cluster, n√£o haver√° problemas. </li><li>  <b>Como 'log_output', apenas 'FILE' √© suportado.</b>  Se voc√™ tiver uma entrada de log na tabela, ser√° necess√°rio remov√™-la. </li><li>  <b>Transa√ß√µes XA n√£o s√£o suportadas.</b>  Se eles foram usados, voc√™ ter√° que reescrever o c√≥digo sem eles. </li></ul><br>  Devo observar que quase todas essas restri√ß√µes podem ser removidas se voc√™ definir a vari√°vel 'pxc_strict_mode = PERMISSIVE', mas se seus dados forem importantes para voc√™, √© melhor n√£o fazer isso.  Se voc√™ tiver definido 'pxc_strict_mode = ENFORCING', o MySQL n√£o permitir√° que voc√™ execute as opera√ß√µes acima ou impede que o n√≥ seja iniciado. <br><br>  Depois de cumprir todos os requisitos do banco de dados e testar exaustivamente a opera√ß√£o de nosso aplicativo no ambiente de desenvolvimento, podemos prosseguir para o pr√≥ximo est√°gio. <br><br><h3>  Implanta√ß√£o e configura√ß√£o de cluster </h3><br>  Temos v√°rios bancos de dados em execu√ß√£o em nossos servidores e outros bancos de dados n√£o precisam migrar para o cluster.  Mas um pacote com cluster MySQL substitui o mysql cl√°ssico.  Tivemos v√°rias solu√ß√µes para esse problema: <br><br><ul><li>  <b>Use a virtualiza√ß√£o e inicie o cluster na VM.</b>  N√£o gostamos dessa op√ß√£o devido aos grandes custos indiretos (em compara√ß√£o com o restante) e √† apar√™ncia de outra entidade que precisa ser atendida </li><li>  <b>Crie sua vers√£o do pacote, que colocar√° o mysql em um local n√£o padr√£o.</b>  Assim, ser√° poss√≠vel ter v√°rias vers√µes do mysql em um servidor.  Uma boa op√ß√£o se voc√™ tiver muitos servidores, mas o suporte constante ao seu pacote, que precisa ser atualizado regularmente, pode levar bastante tempo. </li><li>  <b>Use o Docker.</b> </li></ul><br>  Escolhemos o Docker, mas o usamos na op√ß√£o m√≠nima.  Para armazenamento de dados, o volume local √© usado.  O modo operacional '--net host' √© usado para reduzir a lat√™ncia da rede e a carga da CPU. <br><br>  Tamb√©m tivemos que criar nossa pr√≥pria vers√£o da imagem do Docker.  O motivo √© que a imagem padr√£o da Percona n√£o suporta a posi√ß√£o de restaura√ß√£o na inicializa√ß√£o.  Isso significa que cada vez que a inst√¢ncia √© reiniciada, ela n√£o executa a sincroniza√ß√£o r√°pida do IST, que carrega apenas as altera√ß√µes necess√°rias, mas um SST lento, que recarrega completamente o banco de dados. <br><br>  Outra quest√£o √© o tamanho do cluster.  Em um cluster, cada n√≥ armazena todo o conjunto de dados.  Portanto, a leitura √© dimensionada perfeitamente com o aumento do tamanho do cluster.  Com o registro, a situa√ß√£o √© oposta - ao confirmar, cada transa√ß√£o √© validada pela aus√™ncia de conflitos em todos os n√≥s.  Naturalmente, quanto mais n√≥s, mais tempo levar√° a confirma√ß√£o. <br>  Aqui tamb√©m temos v√°rias op√ß√µes: <br><br><ul><li>  <b>2 n√≥s + √°rbitro.</b>  2 n√≥s + √°rbitro.  Uma boa op√ß√£o para testes.  Durante a implanta√ß√£o do segundo n√≥, o mestre n√£o deve registrar. <br></li><li>  <b>3 n√≥s.</b>  A vers√£o cl√°ssica.  Equil√≠brio de velocidade e confiabilidade.  Observe que nesta configura√ß√£o um n√≥ deve esticar toda a carga, porque  no momento da adi√ß√£o do terceiro n√≥, o segundo ser√° o doador. <br></li><li>  <b>4+ n√≥s.</b>  Com um n√∫mero par de n√≥s, √© necess√°rio adicionar um √°rbitro para evitar o c√©rebro dividido.  Uma op√ß√£o que funciona bem para uma quantidade muito grande de leitura.  A confiabilidade do cluster tamb√©m est√° aumentando. </li></ul><br>  At√© o momento, optamos pela op√ß√£o com 3 n√≥s. <br><br>  A configura√ß√£o do cluster copia quase completamente a configura√ß√£o independente do MySQL e difere apenas em algumas op√ß√µes: <br><br>  <b>"Wsrep_sst_method = xtrabackup-v2"</b> Esta op√ß√£o define o m√©todo de copiar n√≥s.  Outras op√ß√µes s√£o mysqldump e rsync, mas elas bloqueiam o n√≥ pela dura√ß√£o da c√≥pia.  N√£o vejo raz√£o para usar o m√©todo de c√≥pia n√£o-xtrabackup-v2. <br><br>  <b>"Gcache"</b> √© um an√°logo do <b>binlog</b> do cluster.  √â um buffer circular (em um arquivo) de tamanho fixo no qual todas as altera√ß√µes s√£o gravadas.  Se voc√™ desativar um dos n√≥s do cluster e ativ√°-lo novamente, ele tentar√° ler as altera√ß√µes ausentes no Gcache (sincroniza√ß√£o IST).  Se n√£o houver as altera√ß√µes exigidas pelo n√≥, ser√° necess√°rio recarregar completamente o n√≥ (sincroniza√ß√£o SST).  O tamanho do gcache √© definido da seguinte forma: wsrep_provider_options = 'gcache.size = 20G;'. <br><br>  <b>wsrep_slave_threads</b> Ao contr√°rio da replica√ß√£o cl√°ssica em um cluster, √© poss√≠vel aplicar v√°rios "conjuntos de grava√ß√£o" ao mesmo banco de dados em paralelo.  Esta op√ß√£o indica o n√∫mero de trabalhadores que aplicam as altera√ß√µes.  √â melhor n√£o deixar o valor padr√£o de 1, porque  durante a aplica√ß√£o do trabalhador de um conjunto de grava√ß√£o grande, o restante aguardar√° na fila e a replica√ß√£o do n√≥ come√ßar√° a ficar lenta.  Alguns aconselham definir esse par√¢metro como 2 * CPU THREADS, mas acho que voc√™ precisa examinar o n√∫mero de opera√ß√µes de grava√ß√£o simult√¢neas que possui. <br><br>  Definimos o valor 64. Em um valor mais baixo, o cluster √†s vezes n√£o conseguiu aplicar todos os conjuntos de grava√ß√£o da fila durante rajadas de carga (por exemplo, ao iniciar coroas pesadas). <br><br>  <b>wsrep_max_ws_size O</b> tamanho de uma √∫nica transa√ß√£o em um cluster √© limitado a 2 GB.  Mas grandes transa√ß√µes n√£o se encaixam bem com o conceito PXC.  √â melhor concluir 100 transa√ß√µes de 20 MB cada uma do que uma por 2 GB.  Portanto, primeiro limitamos o tamanho da transa√ß√£o no cluster a 100 MB e depois reduzimos o limite para 50 MB. <br><br>  Se voc√™ tiver o modo estrito ativado, poder√° definir a vari√°vel " <b>binlog_row_image</b> " como "minimal".  Isso reduzir√° o tamanho das entradas no binlog em v√°rias vezes (10 vezes no teste da Percona).  Isso economizar√° espa√ßo em disco e permitir√° transa√ß√µes que n√£o se enquadram no limite com "binlog_row_image = full". <br><br>  <b>Limites para SST.</b>  Para o Xtrabackup, usado para preencher n√≥s, voc√™ pode definir um limite para o uso da rede, n√∫mero de threads e m√©todo de compacta√ß√£o.  Isso √© necess√°rio para que, quando o n√≥ estiver preenchido, o servidor doador n√£o comece a ficar lento.  Para fazer isso, a se√ß√£o "sst" √© adicionada ao arquivo my.cnf: <br><br><pre><code class="hljs powershell">[<span class="hljs-type"><span class="hljs-type">sst</span></span>] rlimit = <span class="hljs-number"><span class="hljs-number">80</span></span>m compressor = <span class="hljs-string"><span class="hljs-string">"pigz -3"</span></span> decompressor = <span class="hljs-string"><span class="hljs-string">"pigz -dc"</span></span> backup_threads = <span class="hljs-number"><span class="hljs-number">4</span></span></code> </pre> <br>  Limitamos a velocidade da c√≥pia a 80 Mb / s.  Usamos pigz para compacta√ß√£o, esta √© uma vers√£o multithread do gzip. <br><br>  <b>GTID</b> Se voc√™ usa escravos cl√°ssicos, recomendo ativar o GTID no cluster.  Isso permitir√° que voc√™ conecte o escravo a qualquer n√≥ do cluster sem recarregar o escravo. <br><br>  Al√©m disso, quero falar sobre dois mecanismos de cluster, seu significado e configura√ß√£o. <br><br><h4>  Controle de fluxo </h4><br>  O controle de fluxo √© uma maneira de gerenciar a carga de grava√ß√£o em um cluster.  Ele n√£o permite que os n√≥s demorem muito na replica√ß√£o.  Dessa maneira, a replica√ß√£o ‚Äúquase s√≠ncrona‚Äù √© alcan√ßada.  O mecanismo de opera√ß√£o √© bastante simples - assim que o comprimento da fila de recep√ß√£o atinge o valor definido, ele envia a mensagem "Pausa de controle de fluxo" para os outros n√≥s, que os informam para fazer uma pausa na confirma√ß√£o de novas transa√ß√µes at√© que o n√≥ atrasado termine a limpeza da fila . <br><br>  V√°rias coisas se seguem disso: <br><br><ol><li>  A grava√ß√£o no cluster ocorrer√° na velocidade do n√≥ mais lento.  (Mas pode ser refor√ßado.) </li><li>  Se voc√™ tiver muitos conflitos ao confirmar transa√ß√µes, poder√° configurar o Flow Control de forma mais agressiva, o que deve reduzir o n√∫mero deles. </li><li>  O atraso m√°ximo de um n√≥ em um cluster √© uma constante, mas n√£o por tempo, mas pelo n√∫mero de transa√ß√µes na fila.  O tempo de espera depende do tamanho m√©dio da transa√ß√£o e do n√∫mero de wsrep_slave_threads. </li></ol><br>  Voc√™ pode visualizar as configura√ß√µes de controle de fluxo assim: <br><br> <code>mysql&gt; SHOW GLOBAL STATUS LIKE 'wsrep_flow_control_interval_%'; <br> wsrep_flow_control_interval_low | 36 <br> wsrep_flow_control_interval_high | 71 <br></code> <br>  Primeiro de tudo, estamos interessados ‚Äã‚Äãno par√¢metro wsrep_flow_control_interval_high.  Ele controla o comprimento da fila, ap√≥s o qual a pausa do FC √© ativada.  Este par√¢metro √© calculado pela f√≥rmula: gcs.fc_limit * ‚àöN (onde N = o n√∫mero de n√≥s no cluster.). <br><br>  O segundo par√¢metro √© wsrep_flow_control_interval_low.  √â respons√°vel pelo valor do comprimento da fila, ao atingir o FC desativado.  Calculado pela f√≥rmula: wsrep_flow_control_interval_high * gcs.fc_factor.  Por padr√£o, gcs.fc_factor = 1. <br><br>  Assim, alterando o comprimento da fila, podemos controlar o atraso da replica√ß√£o.  Reduzir o comprimento da fila aumentar√° o tempo que o cluster gasta na pausa do FC, mas reduzir√° o atraso dos n√≥s. <br><br>  Voc√™ pode definir a vari√°vel de sess√£o " <b>wsrep_sync_wait</b> = 7".  Isso for√ßar√° o PXC a executar solicita√ß√µes de leitura ou grava√ß√£o somente ap√≥s aplicar todos os conjuntos de grava√ß√£o na fila atual.  Naturalmente, isso aumentar√° a lat√™ncia de solicita√ß√µes.  O aumento da lat√™ncia √© diretamente proporcional ao comprimento da fila. <br><br>  Tamb√©m √© desej√°vel reduzir o tamanho m√°ximo da transa√ß√£o ao m√≠nimo poss√≠vel, para que transa√ß√µes longas n√£o ocorram acidentalmente. <br><br><h4>  EVS ou Despejo autom√°tico </h4><br>  Esse mecanismo permite eliminar n√≥s inst√°veis ‚Äã‚Äã(por exemplo, perda de pacotes ou atrasos longos) ou que respondem lentamente.  Gra√ßas a isso, problemas de comunica√ß√£o com um n√≥ n√£o colocam o cluster inteiro, mas permitem que o n√≥ seja desativado e continue trabalhando no modo normal.  Esse mecanismo √© especialmente √∫til quando o cluster est√° operando atrav√©s da WAN ou partes da rede que n√£o est√£o sob seu controle.  Por padr√£o, o EVS est√° desativado. <br><br>  Para habilit√°-lo, adicione a op√ß√£o "evs.version = 1;" ao par√¢metro <b>wsrep_provider_options</b>  e "evs.auto_evict = 5;"  (o n√∫mero de opera√ß√µes ap√≥s as quais o n√≥ √© desativado. Um valor 0 desativa o EVS.) H√° tamb√©m v√°rios par√¢metros que permitem ajustar o EVS: <br><br><ul><li>  <b>evs.delayed_margin O</b> tempo que leva para um n√≥ responder.  Por padr√£o, 1 segundo, mas ao trabalhar em uma rede local, ele pode ser reduzido para 0,05-0,1 segundos ou menos. </li><li>  <b>evs.inactive_check_period</b> Per√≠odo de verifica√ß√µes.  Padr√£o 0,5 s </li></ul><br>  De fato, o tempo que um n√≥ pode funcionar em caso de problemas antes que o EVS seja acionado √© evs.inactive_check_period * evs.auto_evict.  Voc√™ tamb√©m pode definir "evs.inactive_timeout" e um n√≥ que n√£o responder ser√° imediatamente descartado, por padr√£o 15 segundos. <br><br>  Uma nuance importante √© que esse mecanismo em si n√£o retornar√° o n√≥ ao restaurar a comunica√ß√£o.  Ele deve ser reiniciado manualmente. <br><br>  Montamos o EVS em casa, mas n√£o tivemos a chance de test√°-lo em batalha. <br><br><h3>  Balanceamento de carga </h3><br>  Para que os clientes usem os recursos de cada n√≥ uniformemente e executem solicita√ß√µes apenas em n√≥s do cluster ativo, precisamos de um balanceador de carga.  A Percona oferece 2 solu√ß√µes: <br><br><ul><li>  <b>ProxySQL.</b>  Este √© o proxy L7 para MySQL. </li><li>  <b>Haproxy.</b>  Mas o Haproxy n√£o sabe como verificar o status de um n√≥ do cluster e determinar se est√° pronto para executar solicita√ß√µes.  Para resolver esse problema, prop√µe-se usar um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">script</a> adicional <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">percona-clustercheck</a> </li></ul><br>  Inicialmente, quer√≠amos usar o ProxySQL, mas ap√≥s o benchmarking, a lat√™ncia perde para o Haproxy em cerca de 15 a 20%, mesmo quando se usa o modo fast_forward (reescrita de consultas, roteamento e muitas outras fun√ß√µes do ProxySQL n√£o funcionam nesse modo, as solicita√ß√µes s√£o proxy como est√£o) . <br><br>  Haproxy √© mais r√°pido, mas o script Percona tem algumas desvantagens. <br><br>  Primeiramente, ele √© escrito em bash, o que n√£o contribui para sua personaliza√ß√£o.  Um problema mais s√©rio √© que ele n√£o armazena em cache o resultado da verifica√ß√£o do MySQL.  Portanto, se tivermos 100 clientes, cada um deles verificando o estado do n√≥ uma vez a cada 1 segundo, o script far√° uma solicita√ß√£o ao MySQL a cada 10 ms.  Se, por algum motivo, o MySQL come√ßar a funcionar lentamente, o script de valida√ß√£o come√ßar√° a criar um grande n√∫mero de processos, o que definitivamente n√£o melhorar√° a situa√ß√£o. <br><br>  Foi decidido escrever <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">uma solu√ß√£o</a> em que a verifica√ß√£o do status do MySQL e a resposta do Haproxy n√£o estejam relacionadas uma √† outra.  O script verifica o estado do n√≥ em segundo plano em intervalos regulares e armazena em cache o resultado.  O servidor da Web fornece ao Haproxy o resultado em cache. <br><br><div class="spoiler">  <b class="spoiler_title">Exemplo de configura√ß√£o do Haproxy</b> <div class="spoiler_text"> <code>listen db <br> bind 127.0.0.1:3302 <br> mode tcp <br> balance first <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 id 1 <br> server node2 192.168.0.2:3302 check port 9200 backup id 2 <br> server node3 192.168.0.3:3302 check port 9200 backup id 3 <br> <br> listen db_slave <br> bind 127.0.0.1:4302 <br> mode tcp <br> balance leastconn <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 backup <br> server node2 192.168.0.2:3302 check port 9200 <br> server node3 192.168.0.3:3302 check port 9200 <br></code> <br>  Este exemplo mostra uma √∫nica configura√ß√£o do assistente.  Os servidores de cluster restantes atuam como escravos. <br></div></div><br><h3>  Monitoramento </h3><br>  Para monitorar o status do cluster, usamos Prometheus + mysqld_exporter e Grafana para visualizar os dados.  Porque  O mysqld_exporter coleta v√°rias m√©tricas para criar pain√©is voc√™ mesmo √© bastante tedioso.  Voc√™ pode pegar os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pain√©is</a> prontos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">da Percona</a> e personaliz√°-los para si mesmo. <br><br>  Tamb√©m usamos o Zabbix para coletar m√©tricas e alertas b√°sicos de cluster. <br><br>  As principais m√©tricas de cluster que voc√™ deseja monitorar: <br><br><ul><li>  <b>wsrep_cluster_status</b> Deve ser definido como Prim√°rio em todos os n√≥s.  Se o valor for "n√£o prim√°rio", esse n√≥ perdeu o contato com o quorum do cluster. </li><li>  <b>wsrep_cluster_size</b> O n√∫mero de n√≥s no cluster.  Isso tamb√©m inclui n√≥s "perdidos", que devem estar no cluster, mas, por algum motivo, n√£o est√£o dispon√≠veis.  Quando o n√≥ √© desligado suavemente, o valor dessa vari√°vel diminui. </li><li>  <b>wsrep_local_state</b> Indica se o n√≥ √© um membro ativo do cluster e est√° pronto para ser <b>usado</b> . </li><li>  <b>wsrep_evs_state</b> Um par√¢metro importante se voc√™ tiver o Despejo Autom√°tico ativado (desativado por padr√£o).  Essa vari√°vel indica que o EVS considera esse n√≥ √≠ntegro. </li><li>  <b>wsrep_evs_evict_list A</b> lista de n√≥s que foram lan√ßados pelo EVS a partir do cluster.  Em uma situa√ß√£o normal, a lista deve estar vazia. </li><li>  <b>wsrep_evs_delayed</b> Lista de candidatos para remo√ß√£o do EVS.  Tamb√©m deve estar vazio. </li></ul><br>  Principais m√©tricas de desempenho: <br><br><ul><li>  <b>wsrep_evs_repl_latency</b> Mostra o atraso de comunica√ß√£o (tamanho m√≠nimo / m√©dio / m√°ximo / desvio s√™nior / tamanho do pacote) dentro do cluster.  Ou seja, mede a lat√™ncia da rede.  Valores crescentes podem indicar sobrecarregar os n√≥s da rede ou do cluster.  Essa m√©trica √© registrada mesmo quando o EVS est√° desligado. </li><li>  <b>wsrep_flow_control_paused_ns O</b> tempo (em ns) desde o in√≠cio do n√≥ que passou na pausa do controle de fluxo.  Idealmente, deve ser 0. O crescimento desse par√¢metro indica problemas com o desempenho do cluster ou a falta de "wsrep_slave_threads".  Voc√™ pode determinar qual n√≥ fica mais lento com o par√¢metro " <b>wsrep_flow_control_sent</b> ". </li><li>  <b>wsrep_flow_control_paused A</b> porcentagem de tempo desde a √∫ltima execu√ß√£o de "FLUSH STATUS;" que o n√≥ passou no controle de fluxo pausou.  Assim como a vari√°vel anterior, ela deve tender a zero. </li><li>  <b>wsrep_flow_control_status</b> Indica se o Flow Control est√° em execu√ß√£o no momento.  No n√≥ inicial da pausa do FC, o valor dessa vari√°vel estar√° LIGADO. </li><li>  <b>wsrep_local_recv_queue_avg Comprimento</b> m√©dio da fila de recebimento.  O crescimento desse par√¢metro indica problemas com o desempenho do n√≥. </li><li>  <b>wsrep_local_send_queue_avg</b> O comprimento m√©dio da fila de envio.  O crescimento desse par√¢metro indica problemas de desempenho da rede. </li></ul><br>  N√£o h√° recomenda√ß√µes universais sobre os valores desses par√¢metros.  √â claro que eles devem tender a zero, mas em carga real provavelmente n√£o ser√° esse o caso e voc√™ dever√° determinar por si mesmo onde passa o limite do estado normal do cluster. <br><br><h3>  Backup </h3><br>  O backup de cluster praticamente n√£o √© diferente do mysql independente.  Para uso em produ√ß√£o, temos v√°rias op√ß√µes. <br><br><ul><li>  Remova o backup de um dos n√≥s "gain" usando xtrabackup.  A op√ß√£o mais f√°cil, mas durante o desempenho do cluster de backup ser√° desperdi√ßada. </li><li>  Use escravos cl√°ssicos e fa√ßa backup de r√©plicas. </li></ul><br>  Os backups independentes e com a vers√£o do cluster criada usando o xtrabackup s√£o port√°teis entre si.  Ou seja, o backup obtido do cluster pode ser implantado no mysql independente e vice-versa.  Naturalmente, a vers√£o principal do MySQL deve corresponder, de prefer√™ncia a menor.  Os backups feitos usando o mysqldump tamb√©m s√£o naturalmente port√°teis. <br><br>  A √∫nica ressalva √© que, ap√≥s implantar o backup, voc√™ deve executar o script mysql_upgrade, que verificar√° e corrigir√° a estrutura de algumas tabelas do sistema. <br><br><h3>  Migra√ß√£o de dados </h3><br>  Agora que descobrimos a configura√ß√£o, o monitoramento e outras coisas, podemos come√ßar a migrar para o prod. <br><br>  A migra√ß√£o de dados em nosso esquema era bastante simples, mas n√≥s erramos um pouco;). <br>  Legenda - o mestre 1 e o mestre 2 s√£o conectados pelo mestre de replica√ß√£o mestre.  A grava√ß√£o vai apenas para o master 1. O Master 3 √© um servidor limpo. <br><br>  Nosso plano de migra√ß√£o (no plano, omitirei as opera√ß√µes com escravos por simplicidade e falarei apenas sobre servidores principais). <br><br><h4>  Tentativa 1 </h4><br><ol><li>  Remova o backup do banco de dados do mestre 1 usando xtrabackup. </li><li>  Copie o backup para o mestre 3 e execute o cluster no modo de n√≥ √∫nico. </li><li>  Configure a replica√ß√£o principal entre os mestres 3 e 1. </li><li>  Alterne a leitura e a grava√ß√£o para o mestre 3. Verifique o aplicativo. </li><li>  No mestre 2, desative a replica√ß√£o e inicie o MySQL em cluster.  Estamos esperando que ele copie o banco de dados do mestre 3. Durante a c√≥pia, tivemos um cluster de um n√≥ no status ‚ÄúDoador‚Äù e um n√≥ ainda n√£o funcionando.  Durante a c√≥pia, obtivemos v√°rios bloqueios e, no final, os dois n√≥s ca√≠ram com um erro (a cria√ß√£o de um novo n√≥ n√£o pode ser conclu√≠da devido a bloqueios).  Esse pequeno experimento nos custou quatro minutos de inatividade. </li><li>  Volte a ler e escrever para o mestre 1. </li></ol><br>  A migra√ß√£o n√£o funcionou devido ao fato de que, ao testar o circuito no ambiente de desenvolvimento no banco de dados, praticamente n√£o havia tr√°fego de grava√ß√£o, e ao repetir o mesmo circuito sob carga, problemas surgiram. <br>  Alteramos um pouco o esquema de migra√ß√£o para evitar esses problemas e tentamos novamente, pela segunda vez com √™xito;). <br><br><h4>  Tentativa 2 </h4><br><ol><li>  Reiniciamos o master 3 para que funcione novamente no modo de n√≥ √∫nico. </li><li>  N√≥s aumentamos o cluster MySQL novamente no master 2.  No momento, o tr√°fego da replica√ß√£o foi apenas para o cluster, portanto n√£o houve problemas repetidos com bloqueios e o segundo n√≥ foi adicionado com √™xito ao cluster. </li><li>  Mais uma vez, mude a leitura e a grava√ß√£o para o mestre 3. Verificamos o funcionamento do aplicativo. </li><li>  Desativar a replica√ß√£o principal com o mestre 1. Ative o cluster mysql no mestre 1 e aguarde at√© que ele seja iniciado.  Para n√£o pisar no mesmo rake, √© importante que o aplicativo n√£o grave no n√≥ Doador (para obter detalhes, consulte a se√ß√£o sobre balanceamento de carga).  Depois de iniciar o terceiro n√≥, teremos um cluster totalmente funcional de tr√™s n√≥s. </li><li>  Voc√™ pode remover um backup de um dos n√≥s do cluster e criar o n√∫mero de escravos cl√°ssicos necess√°rios. </li></ol><br>  A diferen√ßa entre o segundo esquema e o primeiro √© que trocamos o tr√°fego para o cluster somente depois de aumentar o segundo n√≥ no cluster. <br><br>  Este procedimento levou cerca de 6 horas para n√≥s. <br><br><h3>  Multi-mestre </h3><br>  Ap√≥s a migra√ß√£o, nosso cluster trabalhou no modo de mestre √∫nico, ou seja, todo o registro foi para um dos servidores e apenas os dados foram lidos do restante. <br><br>  Depois de mudar a produ√ß√£o para o modo multimestre, encontramos um problema - os conflitos de transa√ß√£o surgiam com mais frequ√™ncia do que esper√°vamos.  Foi especialmente ruim com consultas que modificam muitos registros, por exemplo, atualizando o valor de todos os registros em uma tabela.  As transa√ß√µes que foram executadas com sucesso no mesmo n√≥ sequencialmente no cluster s√£o executadas em paralelo e uma transa√ß√£o mais longa recebe um erro de deadlock.  N√£o demorarei, ap√≥s v√°rias tentativas de corrigir isso no n√≠vel do aplicativo, abandonamos a ideia de multimestre. <br><br><h3>  Outras nuances </h3><br><ul><li>  Um cluster pode ser um escravo.  Ao usar esta fun√ß√£o, recomendo adicionar √† configura√ß√£o todos os n√≥s, exceto aquele que √© a op√ß√£o escrava ‚Äúskip_slave_start = 1‚Äù.  Caso contr√°rio, cada novo n√≥ iniciar√° a replica√ß√£o a partir do mestre, o que causar√° erros de replica√ß√£o ou corrup√ß√£o de dados na r√©plica. </li><li>  Como eu disse doador, um n√≥ n√£o pode atender adequadamente os clientes.  Deve-se lembrar que em um cluster de tr√™s n√≥s, as situa√ß√µes s√£o poss√≠veis quando um n√≥ sai, o segundo √© um doador e apenas um n√≥ permanece para o atendimento ao cliente. </li></ul><br><h3>  Conclus√µes </h3><br>  Ap√≥s a migra√ß√£o e algum tempo de opera√ß√£o, chegamos √†s seguintes conclus√µes. <br><br><ul><li>  O cluster Galera funciona e √© bastante est√°vel (pelo menos enquanto n√£o houver quedas anormais de n√≥s ou seu comportamento anormal).  Em termos de toler√¢ncia a falhas, conseguimos exatamente o que quer√≠amos. </li><li>  As declara√ß√µes multimestre da Percona s√£o principalmente de marketing.  Sim, √© poss√≠vel usar o cluster nesse modo, mas isso exigir√° uma altera√ß√£o profunda do aplicativo para este modelo de uso. </li><li>  N√£o h√° replica√ß√£o s√≠ncrona, mas agora controlamos o atraso m√°ximo dos n√≥s (nas transa√ß√µes).  Juntamente com a limita√ß√£o do tamanho m√°ximo de transa√ß√£o de 50 MB, podemos prever com bastante precis√£o o tempo m√°ximo de atraso dos n√≥s.  Tornou-se mais f√°cil para os desenvolvedores escreverem c√≥digo. </li><li>  No monitoramento, observamos picos de curto prazo no crescimento da fila de replica√ß√£o.  O motivo est√° na nossa rede de 1 Gbit / s.  √â poss√≠vel operar um cluster nessa rede, mas os problemas aparecem durante as explos√µes de carga.  Agora, estamos planejando atualizar a rede para 10 Gbit / s. </li></ul><br>  Total de tr√™s "lista de desejos" que recebemos cerca de um ano e meio.  O requisito mais importante √© a toler√¢ncia a falhas. <br><br>  Nosso arquivo de configura√ß√£o PXC para os interessados: <br><br><div class="spoiler">  <b class="spoiler_title">my.cnf</b> <div class="spoiler_text"> <code>[mysqld] <br> #Main <br> server-id = 1 <br> datadir = /var/lib/mysql <br> socket = mysql.sock <br> port = 3302 <br> pid-file = mysql.pid <br> tmpdir = /tmp <br> large_pages = 1 <br> skip_slave_start = 1 <br> read_only = 0 <br> secure-file-priv = /tmp/ <br> <br> #Engine <br> innodb_numa_interleave = 1 <br> innodb_flush_method = O_DIRECT <br> innodb_flush_log_at_trx_commit = 2 <br> innodb_file_format = Barracuda <br> join_buffer_size = 1048576 <br> tmp-table-size = 512M <br> max-heap-table-size = 1G <br> innodb_file_per_table = 1 <br> sql_mode = "NO_ENGINE_SUBSTITUTION,NO_AUTO_CREATE_USER,ERROR_FOR_DIVISION_BY_ZERO" <br> default_storage_engine = InnoDB <br> innodb_autoinc_lock_mode = 2 <br> <br> #Wsrep <br> wsrep_provider = "/usr/lib64/galera3/libgalera_smm.so" <br> wsrep_cluster_address = "gcomm://192.168.0.1:4577,192.168.0.2:4577,192.168.0.3:4577" <br> wsrep_cluster_name = "prod" <br> wsrep_node_name = node1 <br> wsrep_node_address = "192.168.0.1" <br> wsrep_sst_method = xtrabackup-v2 <br> wsrep_sst_auth = "USER:PASS" <br> pxc_strict_mode = ENFORCING <br> wsrep_slave_threads = 64 <br> wsrep_sst_receive_address = "192.168.0.1:4444" <br> wsrep_max_ws_size = 50M <br> wsrep_retry_autocommit = 2 <br> wsrep_provider_options = "gmcast.listen_addr=tcp://192.168.0.1:4577; ist.recv_addr=192.168.0.1:4578; gcache.size=30G; pc.checksum=true; evs.version=1; evs.auto_evict=5; gcs.fc_limit=80; gcs.fc_factor=0.75; gcs.max_packet_size=64500;" <br> <br> #Binlog <br> expire-logs-days = 4 <br> relay-log = mysql-relay-bin <br> log_slave_updates = 1 <br> binlog_format = ROW <br> binlog_row_image = minimal <br> log_bin = mysql-bin <br> log_bin_trust_function_creators = 1 <br> <br> #Replication <br> slave-skip-errors = OFF <br> relay_log_info_repository = TABLE <br> relay_log_recovery = ON <br> master_info_repository = TABLE <br> gtid-mode = ON <br> enforce-gtid-consistency = ON <br> <br> #Cache <br> query_cache_size = 0 <br> query_cache_type = 0 <br> thread_cache_size = 512 <br> table-open-cache = 4096 <br> innodb_buffer_pool_size = 72G <br> innodb_buffer_pool_instances = 36 <br> key_buffer_size = 16M <br> <br> #Logging <br> log-error = /var/log/stdout.log <br> log_error_verbosity = 1 <br> slow_query_log = 0 <br> long_query_time = 10 <br> log_output = FILE <br> innodb_monitor_enable = "all" <br> <br> #Timeout <br> max_allowed_packet = 512M <br> net_read_timeout = 1200 <br> net_write_timeout = 1200 <br> interactive_timeout = 28800 <br> wait_timeout = 28800 <br> max_connections = 22000 <br> max_connect_errors = 18446744073709551615 <br> slave-net-timeout = 60 <br> <br> #Static Values <br> ignore_db_dir = "lost+found" <br> <br> [sst] <br> rlimit = 80m <br> compressor = "pigz -3" <br> decompressor = "pigz -dc" <br> backup_threads = 8 <br></code> <br></div></div><br><h3>  Fontes e links √∫teis </h3><br>  ‚Üí <a href="">Nossa imagem do Docker</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Documenta√ß√£o do Percona XtraDB Cluster 5.7</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Monitorando o status do cluster - Galera Cluster Documentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vari√°veis ‚Äã‚Äãde status do Galera - Galera Cluster Documentation</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt422347/">https://habr.com/ru/post/pt422347/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt422335/index.html">Os menores computadores Linux</a></li>
<li><a href="../pt422337/index.html">Yandex lan√ßou uma nuvem</a></li>
<li><a href="../pt422339/index.html">"Acho que o JavaScript n√£o √© adequado para a web." 10 perguntas ao programador, 4 release (de Berlim)</a></li>
<li><a href="../pt422341/index.html">IoT - promova enquanto outros pensam</a></li>
<li><a href="../pt422345/index.html">Servidor nas nuvens: Resumo do Projeto</a></li>
<li><a href="../pt422355/index.html">Jogos ao longo do tempo: acelerando o aplicativo no n√≠vel de percep√ß√£o</a></li>
<li><a href="../pt422357/index.html">Aprendizado profundo para determinar o estilo e o g√™nero das pinturas</a></li>
<li><a href="../pt422361/index.html">S√≠ndrome corporativa</a></li>
<li><a href="../pt422363/index.html">Confer√™ncia PyCon Russia 2018: v√≠deo de todos os relat√≥rios e apresenta√ß√µes</a></li>
<li><a href="../pt422365/index.html">A Yandex apresentou uma queixa contra uma decis√£o judicial para remover links para conte√∫do pirata</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
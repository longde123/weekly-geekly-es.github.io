<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📫 🍩 👩‍❤️‍💋‍👨 Perendaman dalam jaringan saraf convolutional. Bagian 5/1 - 9 👩🏽‍🎨 🐳 👩‍👩‍👧‍👦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kursus lengkap dalam bahasa Rusia dapat ditemukan di tautan ini . 
 Kursus bahasa Inggris asli tersedia di tautan ini . 



 Kuliah baru dijadwalkan s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Perendaman dalam jaringan saraf convolutional. Bagian 5/1 - 9</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/456740/"><p>  Kursus lengkap dalam bahasa Rusia dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . <br>  Kursus bahasa Inggris asli tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . </p><br><p><img src="https://habrastorage.org/webt/1m/hz/qn/1mhzqnwa288uxjmptqhexriiahc.png"><br>  <i>Kuliah baru dijadwalkan setiap 2-3 hari.</i> </p><a name="habracut"></a><br><h1>  Isi </h1><br><ol><li>  Wawancara dengan Sebastian Trun </li><li>  Pendahuluan </li><li>  Dataset Anjing dan Kucing </li><li>  Gambar berbagai ukuran </li><li>  Gambar berwarna.  Bagian 1 </li><li>  Gambar berwarna.  Bagian 2 </li><li>  Operasi konvolusi pada gambar berwarna </li><li>  Pengoperasian subsampling dengan nilai maksimum dalam gambar berwarna </li><li>  CoLab: kucing dan anjing </li><li>  Softmax dan sigmoid </li><li>  Periksa </li><li>  Ekstensi gambar </li><li>  Pengecualian </li><li>  CoLab: anjing dan kucing.  Pengulangan </li><li>  Teknik lain untuk mencegah pelatihan ulang </li><li>  Latihan: klasifikasi gambar berwarna </li><li>  Solusi: klasifikasi gambar warna </li><li>  Ringkasan </li></ol><br><h1>  Wawancara dengan Sebastian Trun </h1><br><p>  - Jadi, hari ini kita di sini lagi, bersama dengan Sebastian dan kita akan berbicara tentang pelatihan ulang.  Topik ini sangat menarik bagi kami, terutama di bagian praktis dari kursus saat ini tentang bekerja dengan TensorFlow. <br>  - Sebastian, apakah Anda pernah mengalami overfitting - over, fit?  Jika Anda mengatakan bahwa Anda belum menemukan, maka saya pasti akan mengatakan bahwa saya tidak dapat mempercayai Anda! <br>  - Jadi, alasan pelatihan ulang adalah apa yang disebut <strong>trade-off bias-variance</strong> (kompromi antara nilai-nilai parameter bias dan penyebarannya).  Sebuah jaringan saraf di mana sejumlah kecil bobot tidak dapat mempelajari cukup banyak contoh, situasi serupa dalam pembelajaran mesin disebut distorsi. <br>  - Ya. <br>  - Jaringan saraf dengan begitu banyak parameter dapat secara sewenang-wenang memilih solusi yang tidak Anda sukai, hanya karena begitu banyak parameter ini.  Hasil memilih solusi jaringan saraf tergantung pada variabilitas sumber data.  Dengan demikian, aturan sederhana dapat dirumuskan: semakin banyak parameter dalam jaringan mengenai ukuran (jumlah) data, semakin besar kemungkinan untuk mendapatkan solusi acak dan bukan yang benar.  Misalnya, Anda bertanya pada diri sendiri, "Siapa pria di ruangan ini dan siapa wanita itu?"  Jaringan saraf yang kompleks dapat memberi tahu Anda bahwa, misalnya, semua yang namanya dimulai dengan T adalah laki-laki dan tidak pernah berlatih lagi.  Ada dua solusi.  Yang pertama menggunakan set data penghentian (sejumlah kecil dari set pelatihan untuk memvalidasi keakuratan model).  Anda dapat mengambil data, membaginya menjadi dua bagian - 90% untuk pelatihan, dan 10% untuk menguji dan melakukan apa yang disebut cross-validation, di mana Anda memeriksa keakuratan model pada data yang tidak dilihat oleh jaringan saraf - segera setelah nilai kesalahan dimulai untuk tumbuh setelah siklus pelatihan tertentu - sekarang saatnya untuk berhenti belajar.  Solusi kedua adalah memperkenalkan pembatasan ke dalam jaringan saraf.  Misalnya, untuk membatasi nilai parameter perpindahan dan bobot, menjadikannya lebih dekat dan lebih dekat ke nol.  Semakin terbatas bobotnya, semakin sedikit model yang akan dilatih ulang. <br>  - Saya mengerti benar bahwa kita dapat memiliki kumpulan data untuk pelatihan dan pengujian serta validasi, bukan? <br>  - Benar.  Jika Anda memiliki dataset untuk validasi, maka Anda harus memiliki dataset yang belum pernah Anda sentuh atau tunjukkan ke jaringan saraf Anda.  Jika Anda menunjukkan model tersebut kumpulan data tertentu berkali-kali, maka, tentu saja, proses pelatihan ulang akan dimulai, yang sangat buruk bagi kami. <br>  - Mungkin Anda akan mengingat kasus-kasus paling menarik ketika model Anda dilatih ulang? <br>  - Ah, ya ... ada kejadian seperti itu di masa muda saya ketika saya sedang mengembangkan jaringan saraf untuk bermain catur.  Itu pada tahun 1993. Yang menarik adalah bahwa dari data catur di mana jaringan saraf dilatih, jaringan dengan cepat menentukan bahwa jika seorang ahli memindahkan ratu ke tengah papan catur, maka ada peluang 60% untuk menang.  Yang mulai dia lakukan adalah membuka "lorong" dengan bidak dan memindahkan ratu ke tengah papan catur.  Itu adalah keputusan yang bodoh untuk setiap pemain catur, yang dengan jelas memberikan kesaksian tentang pelatihan ulang model. <br>  - Hebat!  Jadi, kami telah membahas beberapa teknik mengenai cara meningkatkan model kami.  Menurut Anda apa sisi pembelajaran yang paling diremehkan? <br>  - 90% pekerjaan Anda diremehkan, karena 90% pekerjaan Anda terdiri dari pembersihan data. <br>  - Di sini saya sepenuhnya setuju dengan Anda! <br>  - Seperti yang ditunjukkan oleh praktik, kumpulan data apa pun mengandung beberapa jenis sampah.  Sangat sulit untuk membawa data ke jenis yang tepat, untuk membuatnya konsisten, itu adalah proses yang sangat memakan waktu. <br>  - Ya, bahkan jika Anda bekerja dengan set data seperti gambar atau video, di mana, tampaknya, semua informasi sudah ada di sana, di dalam, masih ada kebutuhan untuk pra-proses gambar. <br>  - Satu-satunya orang yang datanya ideal adalah profesor, karena mereka memiliki kesempatan untuk berpura-pura dalam presentasi di PowerPoint bahwa semuanya berjalan sebagaimana mestinya dan semuanya sempurna!  Pada kenyataannya, 90% dari waktu Anda akan ditempati oleh pembersihan data. <br>  - Luar biasa.  Jadi, mari cari tahu lebih banyak tentang pelatihan ulang dan teknik yang memungkinkan kita meningkatkan model pembelajaran mendalam kami. </p><br><h1>  Pendahuluan </h1><br><p>  - hai!  Dan lagi, selamat datang di kursus! <br>  “Dalam pelajaran terakhir, kami mengembangkan jaringan saraf convolutional kecil untuk mengklasifikasikan gambar item pakaian dalam nuansa abu-abu dari dataset FASHION MNIST.  Kami telah melihat dalam praktiknya bahwa jaringan saraf kecil kami dapat mengklasifikasikan gambar yang masuk dengan akurasi yang cukup tinggi.  Namun, di dunia nyata kita harus bekerja dengan gambar resolusi tinggi dan berbagai ukuran.  Salah satu keuntungan besar SNA adalah kenyataan bahwa mereka dapat bekerja sama baiknya dengan gambar berwarna.  Oleh karena itu, kami akan memulai pelajaran kami saat ini dengan mengeksplorasi bagaimana SNA bekerja dengan gambar berwarna. <br>  - Kemudian, dalam frekuensi yang sama, Anda akan membangun jaringan saraf convolutional yang dapat mengklasifikasikan gambar kucing dan anjing.  Dalam perjalanan ke implementasi jaringan saraf convolutional yang mampu mengklasifikasikan gambar kucing dan anjing, kita juga akan belajar bagaimana menggunakan berbagai teknik untuk memecahkan salah satu masalah paling umum dengan jaringan saraf - pelatihan ulang.  Dan pada akhir pelajaran ini, pada bagian praktis, Anda akan mengembangkan jaringan saraf convolutional Anda sendiri untuk mengklasifikasikan gambar warna.  Ayo mulai! </p><br><h1>  Dataset Kucing dan Anjing </h1><br><p>  Sampai saat itu, kami hanya bekerja dengan gambar skala abu-abu dan ukuran 28x28 dari dataset FASHION MNIST. </p><br><p><img src="https://habrastorage.org/webt/e4/1o/cb/e41ocb39ngplbr8osyfccvji0mm.png"></p><br><p>  Dalam aplikasi nyata, kami terpaksa menjumpai gambar dengan berbagai ukuran, misalnya yang ditunjukkan di bawah ini: </p><br><p><img src="https://habrastorage.org/webt/xs/oc/u2/xsocu2t1m1ywlkqk5_qdfslglow.png"></p><br><p>  Seperti yang kami sebutkan di awal pelajaran ini, dalam pelajaran ini kami akan mengembangkan jaringan saraf convolutional yang dapat mengklasifikasikan gambar warna anjing dan kucing. </p><br><p>  Untuk mengimplementasikan rencana kami, kami akan menggunakan gambar kucing dan anjing dari kumpulan data Microsoft Asirra.  Setiap gambar dalam set data ini diberi label 1 atau 0 jika masing-masing ada anjing atau kucing. </p><br><p><img src="https://habrastorage.org/webt/pn/4e/uf/pn4euf-gaaxlv8_2eakpvntjtkw.png"></p><br><p>  Terlepas dari kenyataan bahwa dataset Microsoft Asirra berisi lebih dari 3 juta gambar yang ditandai untuk kucing dan anjing, hanya 25.000 yang tersedia untuk umum.  Pelatihan jaringan saraf convolutional kami pada 25.000 gambar ini akan memakan banyak waktu.  Itulah sebabnya kami akan menggunakan sejumlah kecil gambar untuk melatih jaringan saraf convolutional kami dari 25.000 yang tersedia. </p><br><p>  Subset gambar pelatihan kami terdiri dari 2.000 PC dan 1.000 PC gambar untuk validasi model.  Dalam dataset pelatihan, 1.000 gambar berisi kucing dan 1.000 gambar lainnya berisi anjing.  Kami akan berbicara tentang kumpulan data untuk validasi sedikit kemudian di bagian pelajaran ini. </p><br><p><img src="https://habrastorage.org/webt/oa/wh/dg/oawhdglv3_dtccwky_e1pjwygog.png"></p><br><p>  Bekerja dengan kumpulan data ini, kita akan menghadapi dua kesulitan utama - bekerja dengan gambar dengan ukuran berbeda dan bekerja dengan gambar berwarna. </p><br><p>  Mari kita mulai mengeksplorasi cara bekerja dengan gambar berbagai ukuran. </p><br><h1>  Gambar berbagai ukuran </h1><br><p>  Tes pertama kami adalah menyelesaikan masalah pemrosesan gambar dengan berbagai ukuran.  Itu karena jaringan saraf pada input membutuhkan data berukuran tetap. </p><br><p> Sebagai contoh, Anda dapat mengingat dari bagian kami sebelumnya menggunakan parameter <code>input_shape</code> saat membuat layer <code>Flatten</code> : </p><br><p><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"></p><br><p>  Sebelum mengirimkan gambar elemen pakaian ke jaringan saraf, kami mengonversinya menjadi array 1D dengan ukuran tetap - 28x28 = 784 elemen (piksel).  Karena gambar dalam dataset Fashion MNIST adalah ukuran yang sama, array satu dimensi yang dihasilkan adalah ukuran yang sama dan terdiri dari 784 elemen. </p><br><p>  Namun, bekerja dengan gambar berbagai ukuran (tinggi dan lebar) dan mengubahnya menjadi array satu dimensi, kami mendapatkan array dengan ukuran yang berbeda. </p><br><p>  Karena jaringan saraf pada input membutuhkan data dengan ukuran yang sama, itu tidak cukup untuk hanya pergi dengan konversi ke array satu dimensi dari nilai piksel. </p><br><p>  Memecahkan masalah klasifikasi gambar, kami selalu menggunakan salah satu opsi untuk menyatukan data input - mengurangi ukuran gambar ke nilai umum (mengubah ukuran). </p><br><p><img src="https://habrastorage.org/webt/dt/rt/7f/dtrt7frns4fdinexvf0e3bow5gi.png"></p><br><p>  Dalam tutorial ini, kami akan mengubah ukuran semua gambar dengan ukuran tinggi 150 piksel dan lebar 150 piksel.  Mengkonversi gambar ke ukuran tunggal, dengan demikian kami menjamin bahwa gambar dengan ukuran yang tepat akan tiba di input jaringan saraf dan, ketika ditransfer ke lapisan <code>flatten</code> , kami mendapatkan array satu dimensi dengan ukuran yang sama. </p><br><pre> <code class="python hljs">tf.keras.layers.Flatten(input_shape(<span class="hljs-number"><span class="hljs-number">150</span></span>,<span class="hljs-number"><span class="hljs-number">150</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><p>  Hasilnya, kami mendapat array satu dimensi yang terdiri dari 150x150 = 22.500 nilai (piksel). </p><br><p>  Masalah selanjutnya yang akan kita hadapi adalah masalah warna - warna gambar.  Kita akan membicarakannya di bagian selanjutnya. </p><br><h1>  Gambar berwarna.  Bagian 1 </h1><br><p>  Untuk memahami dan memahami bagaimana jaringan saraf konvolusional bekerja dengan gambar berwarna, kita harus mempelajari bagaimana SNA bekerja secara umum.  Mari menyegarkan apa yang sudah kita ketahui. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b5/c0c/687/3b5c0c68738975962dc882b9ab1522b2.png" alt="gambar"></p><br><p>  Contoh di atas adalah gambar skala abu-abu dan bagaimana komputer mengartikannya sebagai array dua dimensi dari nilai piksel. </p><br><p>  Contoh di bawah ini adalah gambar, kali ini <strong>berwarna,</strong> dan bagaimana komputer mengartikannya sebagai array nilai piksel tiga dimensi. </p><br><p><img src="https://habrastorage.org/webt/n-/2u/ic/n-2uicbpmraz7i2sggtwqckexbc.png"></p><br><p>  Tinggi dan lebar array 3D akan ditentukan oleh tinggi dan lebar gambar, dan kedalaman (kedalaman) menentukan jumlah saluran warna gambar. </p><br><p>  Sebagian besar gambar berwarna dapat direpresentasikan oleh tiga saluran warna - merah (merah), hijau (hijau) dan biru (biru). </p><br><p><img src="https://habrastorage.org/webt/kn/14/zm/kn14zmbazrhrnbhtweoil9m-ipk.png"></p><br><p>  Gambar yang terdiri dari saluran merah, hijau, dan biru disebut gambar RGB.  Kombinasi dari ketiga saluran ini menghasilkan gambar berwarna.  Di masing-masing gambar RGB, setiap saluran diwakili oleh array dua dimensi piksel yang terpisah. </p><br><p><img src="https://habrastorage.org/webt/56/h5/g6/56h5g6loe_bu4_oiuu0-vy_unoc.png"></p><br><p>  Karena jumlah saluran yang kita miliki adalah tiga, maka sebagai hasilnya kita akan memiliki tiga array dua dimensi.  Dengan demikian, gambar berwarna yang terdiri dari 3 saluran warna akan memiliki representasi berikut: </p><br><p><img src="https://habrastorage.org/webt/nn/2r/q6/nn2rq6itb9gz5suamhcl5kvjwtu.png"></p><br><h1>  Gambar berwarna.  Bagian 2 </h1><br><p>  Jadi, karena gambar kita sekarang akan terdiri dari 3 warna, yang berarti akan menjadi array nilai piksel tiga dimensi, maka kode kita perlu diubah sesuai. </p><br><p>  Jika Anda melihat kode yang kami gunakan dalam pelajaran terakhir kami ketika kami memecahkan masalah mengklasifikasikan elemen pakaian dalam gambar, kita dapat melihat bahwa kami menunjukkan dimensi dari data input: </p><br><pre> <code class="python hljs">model = Sequential() model.add(Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre> <br><p>  Dua parameter pertama dari tuple <code>(28,28,1)</code> adalah nilai tinggi dan lebar gambar.  Gambar-gambar dalam dataset Fashion MNIST berukuran 28x28 piksel.  Parameter terakhir dalam tuple <code>(28,28,1)</code> menunjukkan jumlah saluran warna.  Dalam dataset Fashion MNIST, gambar hanya dalam nuansa saluran abu-abu-1 warna. </p><br><p>  Sekarang tugasnya menjadi sedikit lebih rumit, dan gambar kucing dan anjing kita menjadi berbeda ukuran (tetapi dikonversi menjadi satu - 150x150 piksel) dan berisi 3 saluran warna, maka tupel nilai juga harus berbeda: </p><br><pre> <code class="python hljs">model = Sequential() model.add(Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">150</span></span>,<span class="hljs-number"><span class="hljs-number">150</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)))</code> </pre> <br><p>  Pada bagian selanjutnya, kita akan melihat bagaimana konvolusi dihitung dengan adanya tiga saluran warna pada gambar. </p><br><h1>  Operasi konvolusi pada gambar berwarna </h1><br><p>  Dalam pelajaran sebelumnya, kami belajar bagaimana melakukan operasi konvolusi pada gambar skala abu-abu.  Tetapi bagaimana cara melakukan operasi konvolusi pada gambar berwarna?  Mari kita mulai dengan mengulangi bagaimana operasi konvolusi dilakukan pada gambar skala abu-abu. </p><br><p>  Semuanya dimulai dengan filter (inti) dengan ukuran tertentu. </p><br><p><img src="https://habrastorage.org/webt/hv/jo/1h/hvjo1h8-b8xxaxnd5yzoj_6cr78.png"></p><br><p>  Filter terletak pada piksel gambar tertentu yang akan dikonversi, lalu setiap nilai filter dikalikan dengan nilai piksel yang sesuai dalam gambar dan semua nilai ini dijumlahkan.  Nilai piksel akhir diatur pada gambar baru di tempat piksel asli yang dikonversi berada.  Operasi ini diulang untuk setiap piksel dari gambar asli. </p><br><p>  Perlu juga diingat bahwa selama operasi konvolusi, agar tidak kehilangan informasi di perbatasan gambar, kita dapat menerapkan pelurusan dan menempelkan tepi gambar dengan angka nol: </p><br><p><img src="https://habrastorage.org/webt/fc/wa/1s/fcwa1sx3ekaufxf0zzstuzzk7bo.png"></p><br><p>  Sekarang mari kita cari tahu bagaimana kita dapat melakukan operasi konvolusi pada gambar berwarna. </p><br><p>  Sama seperti ketika mengonversi gambar dalam nuansa abu-abu, kita mulai dengan memilih ukuran filter (inti) dari ukuran tertentu. </p><br><p><img src="https://habrastorage.org/webt/ho/s2/8d/hos28dmxwzluclof1hpjtwa8eq0.png"></p><br><p>  Satu-satunya perbedaan sekarang adalah bahwa sekarang filter itu sendiri akan menjadi tiga dimensi, dan nilai parameter kedalaman akan sama dengan nilai jumlah saluran warna pada gambar - 3 (dalam kasus kami, RGB).  Untuk setiap "lapisan" saluran warna, kami juga akan menerapkan operasi konvolusi dengan filter dengan ukuran yang dipilih.  Mari kita lihat bagaimana ini akan menjadi contoh. </p><br><p><img src="https://habrastorage.org/webt/77/yz/ms/77yzmskwfveucvryfrqnfqk9ti0.png"></p><br><p>  Bayangkan kita memiliki gambar RGB dan kita ingin menerapkan operasi konvolusi dengan filter 3D berikutnya.  Perlu memperhatikan fakta bahwa filter kami terdiri dari 3 filter dua dimensi.  Untuk kesederhanaan, mari kita bayangkan bahwa gambar RGB kami berukuran 5x5 piksel. </p><br><p><img src="https://habrastorage.org/webt/eg/46/54/eg4654ymcuktxfo-sybo7c2jw9q.png"></p><br><p>  Ingat juga bahwa setiap saluran warna adalah array dua dimensi dari nilai warna piksel. </p><br><p><img src="https://habrastorage.org/webt/th/sk/9y/thsk9yyqd91koooaqcftklhyq-i.png"></p><br><p>  Seperti halnya pengoperasian konvolusi pada gambar dalam nuansa abu-abu, serta dengan gambar berwarna - kami akan melakukan penyelarasan dan melengkapi gambar di tepinya dengan nol untuk mencegah hilangnya informasi di perbatasan. </p><br><p><img src="https://habrastorage.org/webt/us/vl/h7/usvlh7czpbmfn2iwbibynpr_aem.png"></p><br><p>  Sekarang kami siap untuk operasi konvolusi! </p><br><p>  Mekanisme konvolusi untuk gambar berwarna akan serupa dengan proses yang kami lakukan dengan gambar skala abu-abu.  Satu-satunya perbedaan antara operasi yang dilakukan pada gambar skala abu-abu dan warna adalah bahwa operasi konvolusi sekarang perlu dilakukan 3 kali untuk setiap saluran warna. </p><br><p><img src="https://habrastorage.org/webt/-8/mq/x5/-8mqx5ehxcqfg_4jttweanhhrhc.png"></p><br><p>  Kemudian, setelah kami melakukan operasi konvolusi pada setiap saluran warna, tambahkan tiga nilai yang diperoleh dan tambahkan 1 ke mereka (nilai standar yang digunakan saat melakukan operasi semacam ini).  Nilai baru yang dihasilkan ditetapkan pada posisi yang sama pada gambar baru, di mana posisi piksel yang dikonversi saat itu. </p><br><p>  Kami melakukan operasi konversi yang serupa (operasi konvolusi) untuk setiap piksel pada gambar asli kami dan untuk setiap saluran warna. </p><br><p>  Dalam contoh khusus ini, gambar yang dihasilkan memiliki ukuran tinggi dan lebar yang sama dengan gambar RGB asli kami. </p><br><p>  Seperti yang Anda lihat, menerapkan operasi konvolusi dengan filter 3D tunggal menghasilkan nilai output tunggal. </p><br><p><img src="https://habrastorage.org/webt/y_/kq/c7/y_kqc7d4p07hq7v-qkfxwakwuwg.png"></p><br><p>  Namun, ketika bekerja dengan jaringan saraf convolutional, adalah praktik umum untuk menggunakan lebih dari satu filter 3D.  Jika kami menggunakan lebih dari satu filter 3D, hasilnya akan menjadi beberapa nilai output - setiap nilai adalah hasil dari satu filter. </p><br><p><img src="https://habrastorage.org/webt/36/ci/01/36ci013hfcfdcdthe23etkcg-_g.png"></p><br><p>  Dalam contoh kami di atas, karena kami menggunakan 3 filter, representasi 3D yang dihasilkan akan memiliki kedalaman 3 - setiap lapisan akan sesuai dengan nilai output dari konversi satu filter di atas gambar dengan semua saluran warnanya. </p><br><p>  Jika, misalnya, alih-alih 3 filter, kami memutuskan untuk menggunakan 16, maka representasi 3D output akan berisi 16 lapisan kedalaman. </p><br><p>  Dalam kode, kita dapat mengontrol jumlah filter yang dibuat dengan memberikan nilai yang sesuai untuk parameter <code>filters</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Conv2D(filters, kernel_size, ...)</code> </pre> <br><p>  Kami juga dapat menentukan ukuran filter melalui parameter <code>kernel_size</code> .  Misalnya, untuk membuat 3 filter ukuran 3x3, seperti yang terjadi pada contoh di atas, kita dapat menulis kode sebagai berikut: </p><br><pre> <code class="python hljs">tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">3</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), ...)</code> </pre> <br><p>  Ingatlah bahwa selama pelatihan jaringan saraf convolutional, nilai-nilai dalam filter 3D akan diperbarui untuk meminimalkan nilai fungsi kehilangan. </p><br><p>  Sekarang kita tahu bagaimana melakukan operasi konvolusi pada gambar berwarna, sekarang saatnya mencari cara untuk menerapkan operasi subsampling ke hasil maksimum dengan nilai maksimum (penyatuan maks yang sama). </p><br><h1>  Pengoperasian subsampling dengan nilai maksimum dalam gambar berwarna </h1><br><p>  Sekarang mari kita belajar bagaimana melakukan operasi subsampling pada nilai maksimum pada gambar berwarna.  Bahkan, operasi subsampling dengan nilai maksimum bekerja dengan cara yang sama seperti bekerja dengan gambar dalam nuansa abu-abu dengan sedikit perbedaan - operasi subsampling sekarang perlu diterapkan pada setiap representasi output yang kami terima sebagai hasil dari penerapan filter.  Mari kita lihat sebuah contoh. </p><br><p>  Untuk kesederhanaan, mari kita bayangkan tampilan output kami terlihat seperti ini: </p><br><p><img src="https://habrastorage.org/webt/b0/-k/u1/b0-ku1roxi7hyplaadecnribfvw.png"></p><br><p>  Seperti sebelumnya, kita akan menggunakan kernel 2x2 dan langkah 2 untuk melakukan operasi subsampling pada nilai maksimum.  Operasi subsampling dengan nilai maksimum dimulai dengan "instalasi" kernel 2x2 di sudut kiri atas setiap representasi output (representasi yang diperoleh setelah menerapkan operasi konvolusi). </p><br><p><img src="https://habrastorage.org/webt/sc/hv/68/schv68ab1pzdg-lcazzelhmmvr8.png"></p><br><p>  Sekarang kita dapat memulai operasi subsampling dengan nilai maksimum.  Sebagai contoh, dalam representasi output pertama kami, nilai-nilai berikut jatuh ke dalam kernel 2x2 - 1, 9, 5, 4. Karena nilai maksimum di kernel ini adalah 9, itu yang dikirim ke representasi output baru.  Operasi serupa diulang untuk setiap representasi input. </p><br><p>  Sebagai hasilnya, kita harus mendapatkan hasil berikut: </p><br><p><img src="https://habrastorage.org/webt/9v/um/_0/9vum_0x2p4a78inha_xv3rnce8y.png"></p><br><p>  Setelah melakukan operasi subsampling dengan nilai maksimum, hasilnya adalah 3 array dua dimensi, masing-masing 2 kali lebih kecil dari representasi input asli. </p><br><p>  Jadi, dalam kasus khusus ini, ketika melakukan operasi subsampling dengan nilai maksimum pada representasi input tiga dimensi, kita mendapatkan representasi output tiga dimensi dari kedalaman yang sama, tetapi dengan nilai tinggi dan lebar setengah dari nilai awal. </p><br><p>  Jadi, inilah keseluruhan teori yang kita perlukan untuk penelitian lebih lanjut.  Sekarang mari kita lihat bagaimana ini bekerja dalam kode! </p><br><h1>  CoLab: kucing dan anjing </h1><br><p>  CoLab asli dalam bahasa Inggris tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . <br>  CoLab dalam bahasa Rusia tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . </p><br><p>  Dalam tutorial ini, kita akan membahas cara mengategorikan gambar kucing dan anjing.  Kami akan mengembangkan penggolong gambar menggunakan model <code>tf.keras.Sequential</code> , dan menggunakan <code>tf.keras.Sequential</code> untuk memuat data. </p><br><h3 id="idei-kotorye-budut-zatronuty-v-etoy-chasti">  Gagasan yang akan dibahas di bagian ini: </h3><br><p>  Kami akan mendapatkan pengalaman praktis dalam mengembangkan classifier dan mengembangkan pemahaman intuitif konsep-konsep berikut: </p><br><ol><li>  Membangun model aliran data ( <em>jalur input data</em> ) menggunakan <code>tf.keras.preprocessing.image.ImageDataGenerator</code> (Bagaimana cara efisien bekerja dengan data pada disk yang berinteraksi dengan model?) </li><li>  Pelatihan ulang - apa itu dan bagaimana menentukannya? </li></ol><br><p>  <strong>Sebelum kita mulai ...</strong> </p><br><p>  Sebelum memulai kode di editor, kami sarankan Anda mengatur ulang semua pengaturan di <strong>Runtime -&gt; Reset semua</strong> di menu atas.  Tindakan semacam itu akan membantu menghindari masalah dengan kekurangan memori, jika Anda bekerja secara paralel atau bekerja dengan beberapa editor. </p><br><h1 id="importirovanie-paketov">  Paket impor </h1><br><p>  Mari kita mulai dengan mengimpor paket yang Anda butuhkan: </p><br><ul><li>  <code>os</code> - baca file dan struktur direktori; </li><li>  <code>numpy</code> - untuk beberapa operasi matriks di luar TensorFlow; </li><li>  <code>matplotlib.pyplot</code> - merencanakan dan menampilkan gambar dari dataset uji dan validasi. </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><p>  Impor <code>TensorFlow</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging logger = tf.get_logger() logger.setLevel(logging.ERROR)</code> </pre> <br><h1 id="zagruzka-dannyh">  Pemuatan data </h1><br><p>  Kami memulai pengembangan classifier kami dengan memuat dataset.  Kumpulan data yang kami gunakan adalah versi yang disaring dari kumpulan data <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Anjing vs Kucing</a> dari layanan Kaggle (pada akhirnya, kumpulan data ini disediakan oleh Microsoft Research). </p><br><p>  Di masa lalu, CoLab dan saya menggunakan dataset dari modul <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TensorFlow Dataset</a> itu sendiri, yang sangat nyaman untuk bekerja dan pengujian.  Namun, dalam CoLab ini, kita akan menggunakan kelas <code>tf.keras.preprocessing.image.ImageDataGenerator</code> untuk membaca data dari disk.  Oleh karena itu, pertama-tama kita perlu mengunduh kumpulan data Anjing VS Kucing dan unzip. </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span> zip_dir = tf.keras.utils.get_file(<span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filterted.zip'</span></span>, origin=_URL, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Kumpulan data yang kami unduh memiliki struktur berikut: </p><br><pre> <code class="plaintext hljs">cats_and_dogs_filtered |__ train |______ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...] |______ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...] |__ validation |______ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...] |______ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]</code> </pre> <br><p>  Untuk mendapatkan daftar direktori lengkap, Anda dapat menggunakan perintah berikut: </p><br><pre> <code class="python hljs">zip_dir_base = os.path.dirname(zip_dir) !find $zip_dir_base -type d -<span class="hljs-keyword"><span class="hljs-keyword">print</span></span></code> </pre> <br><p>  Akibatnya, kami mendapatkan sesuatu yang serupa: </p><br><pre> <code class="plaintext hljs">/root/.keras/datasets /root/.keras/datasets/cats_and_dogs_filtered /root/.keras/datasets/cats_and_dogs_filtered/train /root/.keras/datasets/cats_and_dogs_filtered/train/dogs /root/.keras/datasets/cats_and_dogs_filtered/train/cats /root/.keras/datasets/cats_and_dogs_filtered/validation /root/.keras/datasets/cats_and_dogs_filtered/validation/dogs /root/.keras/datasets/cats_and_dogs_filtered/validation/cats</code> </pre> <br><p>  Sekarang tetapkan jalur yang benar ke direktori dengan set data untuk pelatihan dan validasi ke variabel: </p><br><pre> <code class="python hljs">base_dir = os.path.join(os.path.dirname(zip_dir), <span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filtered'</span></span>) train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) validation_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'validation'</span></span>) train_cats_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) train_dogs_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>) validation_cats_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) validation_dogs_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>)</code> </pre> <br><h4 id="razbiraemsya-s-dannymi-i-ih-strukturoy">  Memahami data dan strukturnya </h4><br><p>  Mari kita lihat berapa banyak gambar kucing dan anjing yang kita miliki dalam kumpulan data pengujian dan validasi (direktori). </p><br><pre> <code class="python hljs">num_cats_tr = len(os.listdir(train_cats_dir)) num_dogs_tr = len(os.listdir(train_dogs_dir)) num_cats_val = len(os.listdir(validation_cats_dir)) num_dogs_val = len(os.listdir(validation_dogs_dir)) total_train = num_cats_tr + num_dogs_tr total_val = num_cats_val + num_dogs_val</code> </pre> <br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_val) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_val) print(<span class="hljs-string"><span class="hljs-string">'--'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_train) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_val)</code> </pre> <br><p>  Output dari blok terakhir adalah sebagai berikut: </p><br><pre> <code class="plaintext hljs">    : 1000     : 1000     : 500     : 500 --      : 2000      : 1000</code> </pre> <br><h1 id="ustanovka-parametrov-modeli">  Pengaturan parameter model </h1><br><p>  Untuk kenyamanan, kami akan menempatkan pemasangan variabel yang kami butuhkan untuk pemrosesan data lebih lanjut dan pelatihan model dalam pengumuman terpisah: </p><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#          IMG_SHAPE = 150 #  150x150      </span></span></code> </pre> <br><h1 id="podgotovka-dannyh">  Persiapan data </h1><br><p>  Sebelum gambar dapat digunakan sebagai input untuk jaringan kami, mereka harus dikonversi ke tensor dengan nilai floating point.  Daftar langkah yang harus diambil untuk melakukan ini: </p><br><ol><li>  Baca gambar dari disk </li><li>  Dekode konten gambar dan konversikan ke format yang diinginkan dengan mempertimbangkan profil RGB </li><li>  Konversikan ke tensor dengan nilai floating point </li><li>  Untuk menormalkan nilai tensor dari interval dari 0 hingga 255 ke interval dari 0 hingga 1, karena jaringan saraf bekerja lebih baik dengan nilai input yang kecil. </li></ol><br><p>  Untungnya, semua operasi ini dapat dilakukan menggunakan kelas <code>tf.keras.preprocessing.image.ImageDataGenerator</code> . </p><br><p>  Kita dapat melakukan semua ini menggunakan beberapa baris kode: </p><br><pre> <code class="python hljs">train_image_generator = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>) validation_image_generator = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>)</code> </pre> <br><p>  Setelah kami menetapkan generator untuk satu set data pengujian dan validasi, metode <strong>flow_from_directory akan</strong> memuat gambar dari disk, menormalkan data, dan mengubah ukuran gambar hanya dengan satu baris kode: </p><br><pre> <code class="python hljs">train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE,IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><p>  Kesimpulan: </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>  Generator data validasi: </p><br><pre> <code class="python hljs">val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE, directory=validation_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, target_size=(IMG_SHAPE,IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><p>  Kesimpulan: </p><br><pre> <code class="plaintext hljs">Found 1000 images belonging to 2 classes.</code> </pre> <br><h4 id="vizualiziruem-izobrazheniya-iz-trenirovochnogo-nabora">  Visualisasikan gambar dari set pelatihan. </h4><br><p>  Kami dapat memvisualisasikan gambar dari dataset pelatihan menggunakan <code>matplotlib</code> : </p><br><pre> <code class="python hljs">sample_training_images, _ = next(train_data_gen)</code> </pre> <br><p>  Fungsi <code>next</code> mengembalikan blok gambar dari kumpulan data.  Satu blok adalah tupel <em>(banyak gambar, banyak label)</em> .  Saat ini, kami akan melepaskan label, karena kami tidak membutuhkannya - kami tertarik dengan gambar itu sendiri. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#        15 def plotImages(images_arr): fig, axes = plt.subplots(1, 5, figsize=(20, 20)) axes = axes.flatten() for img, ax in zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show()</span></span></code> </pre> <br><pre> <code class="python hljs">plotImages(sample_training_images[:<span class="hljs-number"><span class="hljs-number">5</span></span>]) <span class="hljs-comment"><span class="hljs-comment">#   0-4</span></span></code> </pre> <br><p>  Contoh output (2 gambar, bukan semua 5): </p><br><p><img src="https://habrastorage.org/webt/ag/sd/hr/agsdhrbpj3jqtgd-xwbnzoh-7go.png"></p><br><h1 id="sozdanie-modeli">  Pembuatan model </h1><br><h3 id="opisyvaem-model">  Kami menggambarkan model </h3><br><p>  Model ini terdiri dari 4 blok konvolusi, setelah masing-masing terdapat blok dengan lapisan subsampel.  Selanjutnya, kami memiliki lapisan yang terhubung penuh dengan 512 neuron dan <code>relu</code> aktivasi <code>relu</code> .  Model ini akan memberikan distribusi probabilitas untuk dua kelas - anjing dan kucing - menggunakan <code>softmax</code> . </p><br><pre> <code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(IMG_SHAPE, IMG_SHAPE, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><h4 id="kompilirovanie-modeli">  Kompilasi model </h4><br><p>  Seperti sebelumnya, kami akan menggunakan pengoptimal <code>adam</code> .  Kami menggunakan <code>sparse_categorical_crossentropy</code> sebagai fungsi kerugian.  Kami juga ingin memantau akurasi model di setiap iterasi pelatihan, jadi kami meneruskan nilai <code>accuracy</code> ke parameter <code>metrics</code> : </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h4 id="predstavlenie-modeli">  Tampilan model </h4><br><p>  Mari kita lihat struktur model kita berdasarkan level menggunakan metode <strong>ringkasan</strong> : </p><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><p>  Kesimpulan: </p><br><pre> <code class="plaintext hljs">Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6272) 0 _________________________________________________________________ dense (Dense) (None, 512) 3211776 _________________________________________________________________ dense_1 (Dense) (None, 2) 1026 ================================================================= Total params: 3,453,634 Trainable params: 3,453,634 Non-trainable params: 0</code> </pre> <br><h4 id="trenirovka-modeli">   </h4><br><p>    ! </p><br><p>         ( <code>ImageDataGenerator</code> )    <code>fit_generator</code>     <code>fit</code> : </p><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">100</span></span> history = model.fit_generator( train_data_gen, steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))), epochs=EPOCHS, validation_data=val_data_gen, validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))) )</code> </pre> <br><h4 id="vizualizaciya-rezultatov-trenirovki">    </h4><br><p>       : </p><br><pre> <code class="python hljs">acc = history.history[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>] val_acc = history.history[<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>] loss = history.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>] val_loss = history.history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>] epochs_range = range(EPOCHS) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">8</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(epochs_range, acc, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.plot(epochs_range, val_acc, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'lower right'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'     '</span></span>) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) plt.plot(epochs_range, loss, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.plot(epochs_range, val_loss, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'     '</span></span>) plt.savefig(<span class="hljs-string"><span class="hljs-string">'./foo.png'</span></span>) plt.show()</code> </pre> <br><p>  Kesimpulan: </p><br><p><img src="https://habrastorage.org/webt/z5/wn/we/z5wnwe2v8nmxrkwlrpgwgdr38qg.png"></p><br><p>     ,                   70%      (    ). </p><br><p>     .          ,             . </p><br><p> <em> …   .</em> </p><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ... dan ajakan bertindak standar - daftar, beri nilai tambah, dan bagikan :) </font></font></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Telegram</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VKontakte</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id456740/">https://habr.com/ru/post/id456740/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id456724/index.html">5 cara yang sangat sederhana untuk mempercepat aplikasi VueJS Anda secara signifikan</a></li>
<li><a href="../id456730/index.html">Pesan "{Anda Tidak Tahu JS} Jenis dan Konstruksi Grammar"</a></li>
<li><a href="../id456732/index.html">Untuk menjadi seorang mentor</a></li>
<li><a href="../id456736/index.html">Resep PostgreSQL: cURL: dapatkan, kirim dan ... email</a></li>
<li><a href="../id456738/index.html">Jaringan saraf dan pembelajaran mendalam, bab 1: menggunakan jaringan saraf untuk mengenali angka tulisan tangan</a></li>
<li><a href="../id456744/index.html">10 masalah yang saya pecahkan dengan pengingat pada ponsel cerdas saya</a></li>
<li><a href="../id456746/index.html">Data besar - tanggung jawab besar, stres besar dan uang besar</a></li>
<li><a href="../id456748/index.html">Thermal printer 2003 dari pasar loak: apa yang bisa dilakukan di 2019?</a></li>
<li><a href="../id456754/index.html">GitOps: membandingkan metode Tarik dan Dorong</a></li>
<li><a href="../id456756/index.html">Mengapa CockroachDB mengubah lisensi Open Source</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
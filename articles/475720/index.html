<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèº‚Äçü§ù‚Äçüßëüèª üë©üèø‚Äç‚öñÔ∏è üë∏üèø 8 mejores tendencias de la Conferencia Internacional sobre Representaciones de Aprendizaje (ICLR) 2019 üëÖ ‚ú°Ô∏è üö™</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El tema del an√°lisis de datos y Data Science se est√° desarrollando a un ritmo sorprendente en estos d√≠as. Para comprender la relevancia de sus m√©todos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>8 mejores tendencias de la Conferencia Internacional sobre Representaciones de Aprendizaje (ICLR) 2019</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/475720/">  El tema del an√°lisis de datos y Data Science se est√° desarrollando a un ritmo sorprendente en estos d√≠as.  Para comprender la relevancia de sus m√©todos y enfoques, es necesario mantenerse al tanto del trabajo de los colegas, y es en las conferencias donde es posible obtener informaci√≥n sobre las tendencias modernas.  Desafortunadamente, no todos los eventos se pueden visitar, por lo tanto, los art√≠culos sobre conferencias anteriores son de inter√©s para especialistas que no han encontrado el tiempo y la oportunidad de presencia personal.  Nos complace presentarle una traducci√≥n del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Chip Huyen</a> sobre la conferencia <b>ICLR 2019</b> sobre tendencias y enfoques de vanguardia en el campo de la ciencia de datos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ee/b87/b6c/0eeb87b6c08fb4afdc9ee67338bc2c78.jpg"></div><a name="habracut"></a><br>  Las representaciones de aprendizaje son un conjunto de m√©todos, t√©cnicas y enfoques que detectan autom√°ticamente las representaciones necesarias para identificar las caracter√≠sticas de los datos sin procesar.  Las presentaciones de aprendizaje reemplazan la invenci√≥n manual de las caracter√≠sticas y le permiten estudiar las propiedades clave de los objetos en funci√≥n de sus atributos y utilizarlas para resolver problemas espec√≠ficos. <br><br>  El art√≠culo da una mirada subjetiva a una serie de problemas de la industria.  Sin embargo, uno espera que incluso una revisi√≥n subjetiva proporcione suficiente alimento para pensar a un especialista interesado.  Adem√°s, discutiremos lo siguiente: <br><br><ul><li>  Los m√©todos artificiales para corregir la composici√≥n sociodemogr√°fica de la conferencia evocan una variedad de sentimientos en la comunidad: desde la indignaci√≥n agresiva hasta la ignorancia cobarde.  Elegir el comportamiento √≥ptimo en dicho entorno ser√≠a una tarea interesante para un especialista en teor√≠a de juegos. </li><li>  Los trabajos en los campos del aprendizaje por representaci√≥n y el aprendizaje por transferencia est√°n aumentando en popularidad y despiertan el inter√©s activo de la comunidad. </li><li>  Las redes neuronales recursivas contin√∫an perdiendo popularidad entre los investigadores, pero en la pr√°ctica no se descartar√°n pronto. </li><li>  El √°rea de las GAN contin√∫a desarroll√°ndose r√°pidamente, aunque no a todos los investigadores les gusta este hecho.  El potencial de las GAN solo se est√° revelando y se puede esperar una cantidad de trabajos interesantes en esta direcci√≥n en el futuro cercano. </li><li>  El aprendizaje reforzado contin√∫a excitando las mentes de los investigadores, siendo el tema m√°s popular en la conferencia.  Los especialistas se est√°n acercando a la posibilidad de aplicar m√©todos de RL a tareas reales, lo que es muy escaso para los adherentes en esta √°rea. </li><li>  Sorprendentemente, recientemente ha habido poco inter√©s en los usos biol√≥gicos y gen√©ticos del aprendizaje autom√°tico.  Se abre una buena oportunidad para los investigadores que buscan un tema para un mayor crecimiento. </li><li>  Los art√≠culos generalmente aceptados y los art√≠culos sobre m√©todos retro todav√≠a logran llegar a la conferencia, sin embargo, la competencia entre ellos es mayor y los investigadores tienen que hacer m√°s esfuerzos para obtener resultados interesantes que en direcciones m√°s populares y de moda.  En ese momento, piense en el hecho de que los materiales para la aplicaci√≥n del aprendizaje autom√°tico cl√°sico se han agotado. </li></ul><br>  Una revisi√≥n detallada de la conferencia de Chip Hyun se puede encontrar a continuaci√≥n. <br><br><h2>  1. Inclusi√≥n </h2><br>  Los organizadores de la [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conferencia Internacional sobre Representaciones de Aprendizaje 2019</a> - Ed.] Destacaron la importancia de la inclusi√≥n en el campo de la inteligencia artificial.  Los dos primeros discursos principales, un discurso de apertura de Alexander Rush y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la oradora invitada Cynthia Dvork</a> , se dedicaron a la justicia y la igualdad. <br><br>  Algunas estad√≠sticas preocupantes de ICLR 2019: <br><br><ul><li>  las mujeres solo el 8.6% de los oradores y el 15% de los participantes, </li><li>  2/3 de todos los investigadores LGBTQ + no revelan su propia orientaci√≥n en el trabajo, </li><li>  Los 8 oradores invitados son representantes de la raza cauc√°sica. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d47/f99/793/d47f9979367c8f199448e7745ed80283.png"></div><br>  Desafortunadamente [de la autora], la mayor√≠a de los investigadores de inteligencia artificial no est√°n interesados ‚Äã‚Äãen absoluto en el tema de la igualdad.  Si los seminarios sobre otros temas estaban llenos, entonces <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el taller de IA para el bien social estaba bastante vac√≠o hasta que apareci√≥ Yoshua Benjio</a> .  Durante las muchas conversaciones que tuve en la ICLR, nadie mencion√≥ la "diversidad".  Un caso fue una excepci√≥n: me invitaron a un evento t√©cnico inadecuado, que me sorprendi√≥ mucho, y mi buen amigo respondi√≥: "Una peque√±a respuesta insultante: fuiste invitada porque eres una mujer". <br><br>  La raz√≥n del estado de cosas observado es que el tema de la diversidad no es "t√©cnico" y, por lo tanto, no ayudar√° a promover una carrera cient√≠fica.  Otra raz√≥n es que hay un rechazo a la propaganda social y p√∫blica.  Un amigo m√≠o una vez me aconsej√≥ que no le prestara atenci√≥n al tipo que me trolle√≥ en un chat grupal, porque "le gusta burlarse de las personas que hablan de igualdad y diversidad".  Tengo amigos a quienes no les gusta hablar sobre la diversidad en Internet porque no quieren estar "asociados con este tema". <br><br><h2>  2. Aprendizaje de representaci√≥n y aprendizaje de transferencia </h2><br>  El objetivo principal del aprendizaje de Representaci√≥n sin supervisi√≥n es detectar rasgos en los datos no asignados que son √∫tiles para su uso en tareas posteriores.  En el campo de Procesamiento del lenguaje natural, la capacitaci√≥n en desempe√±o a menudo se realiza a trav√©s del modelado del lenguaje.  Las representaciones resultantes se utilizan para tareas como el an√°lisis de sentimientos, el reconocimiento de nombres y la traducci√≥n autom√°tica. <br><br>  Algunos de los estudios de rendimiento no docentes m√°s interesantes del a√±o pasado comienzan con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ELMo (Peters et al.)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ULMFiT (Howard et al.)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GPT OpenAI (Radford et al.)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">BERT.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Devlin et al.)</a> Y, por supuesto, el altamente peligroso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GPT-2 (Radford et al.)</a> . <br><br>  El GPT-2 completo se demostr√≥ en el ICLR, y es sorprendente.  Puede ingresar un bosquejo arbitrario del comienzo del texto, y el modelo escribir√° el resto del art√≠culo.  Un modelo puede escribir art√≠culos de noticias, fan fiction, art√≠culos cient√≠ficos, incluso definiciones de palabras ficticias.  Hasta ahora, el resultado a√∫n no parece humano, pero el equipo est√° trabajando duro en el GPT-3.  Espero con inter√©s ver las capacidades del nuevo modelo. <br><br>  El enfoque de aprendizaje de transferencia fue adoptado principalmente por la comunidad de especialistas en visi√≥n por computadora.  Sin embargo, la formaci√≥n del modelo de clasificaci√≥n de im√°genes ImageNet todav√≠a se lleva a cabo en el modo de formaci√≥n del profesorado.  La pregunta que pueden escuchar constantemente los representantes de ambas comunidades es: "¬øC√≥mo usar√≠amos la capacitaci√≥n de presentaci√≥n no docente para trabajar con im√°genes?" <br><br>  Aunque la mayor√≠a de los laboratorios de investigaci√≥n conocidos ya est√°n trabajando en esta tarea, solo se present√≥ un art√≠culo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Actualizaci√≥n de las reglas de metaaprendizaje para la ense√±anza de los</a> env√≠os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">no docentes</a> ", en la ICLR <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Metz et al.)</a>  En lugar de actualizar los pesos, el algoritmo actualiza la regla de aprendizaje.  Las vistas obtenidas de la regla de aprendizaje se muestran en una peque√±a muestra de datos etiquetados en el modo de clasificaci√≥n de im√°genes.  Los investigadores pudieron encontrar reglas de aprendizaje que les permitieron alcanzar una precisi√≥n de m√°s del 70% en MNIST y Fashion MNIST. <br><br>  Los autores descubrieron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte del c√≥digo</a> , pero no todo, porque "est√° vinculado a la inform√°tica".  El ciclo externo requiere aproximadamente 100 mil pasos de entrenamiento y 200 horas en 256 procesadores. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/057/120/627/057120627e83b429f79d3b33cc323264.png"></div><br>  Tengo la sensaci√≥n de que en un futuro pr√≥ximo veremos muchas m√°s obras de este tipo.  Es posible utilizar la ense√±anza sin un maestro en tareas como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la codificaci√≥n autom√°tica, la</a> predicci√≥n de rotaci√≥n de im√°genes (el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documento Gidaris et al.</a> Fue un √©xito en ICLR 2018), pronosticando el pr√≥ximo fotograma en un video, etc. <br><br><h2>  3. ML retro </h2><br>  Las ideas en el aprendizaje autom√°tico son como la moda: son c√≠clicas.  Mirar una sesi√≥n de p√≥sters ahora es como caminar en un museo hist√≥rico.  Incluso el tan esperado debate sobre la ICLR termin√≥ con un debate sobre el tema de "antecedentes versus estructura", que vuelve <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">a la discusi√≥n de Yann LeKun y Christopher Manning</a> el a√±o pasado y se asemeja al debate centenario entre los defensores de la teor√≠a bayesiana y los del enfoque de probabilidad de Freventy (frecuencia). <br><br>  El proyecto "Grounded Language Learning and Understanding" en MIT Media Lab se suspendi√≥ en 2001, pero este a√±o Grounded Language Learning present√≥ dos trabajos envueltos en la portada de "aprendizaje de refuerzo". <br><br><ul><li>  DOM-Q-NET: RL a tierra en lenguaje estructurado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Jia et al.)</a> - Algoritmo RL para navegar p√°ginas web haciendo clic en enlaces y rellenando campos, mientras que el prop√≥sito de la navegaci√≥n se expresa en un lenguaje natural. </li><li>  BabyAI: una plataforma para estudiar la eficacia de la muestra del aprendizaje de idiomas con base <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Chevalier-Boisvert et al.)</a> Es una plataforma compatible con OpenAI Gym con un agente bot artificial que imita a un maestro humano que ayuda a los agentes a aprender un lenguaje sint√©tico. </li></ul><br>  AnonReviewer4 resumi√≥ perfectamente mis pensamientos sobre estos dos art√≠culos: <br><br><blockquote>  ‚Äú... los m√©todos propuestos aqu√≠ son muy similares a los m√©todos que se han considerado durante mucho tiempo en la literatura sobre an√°lisis sem√°ntico.  Solo este trabajo cita art√≠culos sobre RL profundo.  Creo que ser√≠a muy √∫til para los autores familiarizarse con esta literatura.  Creo que la comunidad de an√°lisis sem√°ntico tambi√©n se beneficiar√° de esto ... Pero estas dos comunidades, aparentemente, tienen poco contacto entre s√≠, aunque en algunos casos est√°n trabajando en problemas muy similares ". </blockquote><br>  DFA (Aut√≥matas finitos deterministas) tambi√©n encontr√≥ su lugar en el mundo del aprendizaje profundo este a√±o en dos art√≠culos: <br><br><ul><li>  Representaci√≥n de lenguajes formales: una comparaci√≥n entre aut√≥matas finitos y redes neuronales recurrentes (Mikhalenko et al.), </li><li>  Aprendizaje de representaciones de estado finito de redes de pol√≠ticas recurrentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Koul et al.)</a> . </li></ul><br>  La principal motivaci√≥n para ambos trabajos es la siguiente: en relaci√≥n con el gran espacio de estados ocultos en los RNN, ¬øes posible reducir el n√∫mero de estados al √∫ltimo?  Soy esc√©ptico de que el DFA pueda representar eficazmente a RNN en problemas de lenguaje, pero me gusta la idea de ense√±ar RNN durante el entrenamiento y luego convertirlo a DFA para obtener conclusiones l√≥gicas, como se presenta en Koul et al.  Las representaciones finales finales requieren solo tres estados de memoria discretos y 10 observaciones para jugar pong.  DFA tambi√©n ayuda a interpretar RNN. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/860/22c/671/86022c671de8c49e01d5ae4d0c7f220c.png"></div><br><h2>  4. RNN est√° perdiendo popularidad entre los investigadores </h2><br>  Al considerar el calendario de crecimiento de los art√≠culos sobre diversos temas en 2019 en relaci√≥n con 2018, queda claro que RNN se caracteriza por la mayor ca√≠da.  Esto no es sorprendente, porque a pesar de que el uso de RNN es intuitivo para los tipos de datos en serie, sufren una falla grave: no pueden ser paralelizados.  En consecuencia, es imposible aprovechar el factor m√°s importante que estimula el progreso en la investigaci√≥n desde 2012: la potencia inform√°tica.  Los RNN nunca han sido populares en CV o RL, y para PNL son reemplazados por arquitecturas basadas en Atenci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/6fd/d56/fb56fdd5663e30ee0f93a22029b27c73.png"></div><br>  ¬øEsto significa que RNN est√° muerto?  De hecho, no.  Art√≠culo "Neuronas ordenadas: integraci√≥n de estructuras de √°rboles en redes neuronales recurrentes" <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Shen et al.).</a>  recibi√≥ uno de los m√°s altos premios este a√±o.  Adem√°s de esto y los dos art√≠culos sobre aut√≥matas mencionados anteriormente, este a√±o se revisaron nueve art√≠culos m√°s de RNN, la mayor√≠a de los cuales profundizan en los fundamentos matem√°ticos en lugar de abrir nuevas posibilidades. <br><br>  Los RNN siguen llenos de vida y son impulsores en la industria, especialmente para las empresas que se ocupan de series temporales como las empresas comerciales.  Desafortunadamente, las empresas comerciales no suelen publicar detalles de su trabajo.  Incluso si las RNN no son muy atractivas para los investigadores en este momento, pueden recuperar su popularidad en el futuro. <br><br><h2>  5. Las GAN todav√≠a est√°n arriba </h2><br>  A pesar de que el tema GAN en la escala relativa en comparaci√≥n con el a√±o anterior muestra un crecimiento negativo, en la escala absoluta el n√∫mero de obras aument√≥ de ~ 70 a ~ 100.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ian Goodfellow dio una charla sobre GAN</a> y estuvo constantemente rodeado de fan√°ticos.  El √∫ltimo d√≠a, tuvo que entregar su placa para que la gente no pudiera ver su nombre. <br><br>  Toda la primera sesi√≥n de p√≥sters estuvo dedicada a la GAN.  Hay nuevas arquitecturas GAN, mejoras en la arquitectura GAN antigua, an√°lisis GAN, aplicaciones GAN desde la generaci√≥n de im√°genes hasta la generaci√≥n de texto y s√≠ntesis de audio.  Hay PATE-GAN, GANSynth, ProbGAN, InstaGAN, RelGAN, MisGAN, SPIGAN, LayoutGAN, KnockoffGAN, etc. y no tengo idea de lo que eso significa.  Desafortunadamente, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Andrew Brock llam√≥ a su modelo gigante BigGAN, no giGANtic</a> :) <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/271/e31/50f/271e3150fbfe40e17a42c4fb77617c32.png"></div><br>  La sesi√≥n de p√≥sters mostr√≥ cu√°n sesgada es la comunidad cuando se trata de GAN.  Algunos de los comentarios que escuch√© de los opositores de la GAN se ve√≠an as√≠: "No puedo esperar a que todo este bombo con la GAN disminuya", "cuando alguien menciona el t√©rmino" adversario ", mi cerebro simplemente se apaga".  En mi opini√≥n, son simplemente envidiosos. <br><br><h2>  6. Falta de estudios biol√≥gicos en profundidad. </h2><br>  Teniendo en cuenta la gran emoci√≥n causada por el p√∫blico al determinar la secuencia de genes en el ADN, as√≠ como la aparici√≥n de ni√±os modificados que utilizan la tecnolog√≠a CRISPR, [fue] sorprendente para m√≠ que no hubo un aumento en el trabajo sobre el uso del aprendizaje profundo en biolog√≠a en ICLR.  Hubo seis art√≠culos sobre el tema. <br><br>  Dos sobre temas de arquitectura tomados de la biolog√≠a: <br><br><ul><li>  Los algoritmos de aprendizaje biol√≥gicamente plausibles pueden escalar a grandes conjuntos de datos (Xiao et al.), </li><li>  Una teor√≠a unificada de las primeras representaciones visuales desde la retina hasta la corteza a trav√©s de las CNN profundas con restricciones anat√≥micas (Lindsey et al.). </li></ul><br>  Un trabajo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en capacitaci√≥n de dise√±o para ARN (Runge et al.)</a> . <br><br>  Tres trabajos de manipulaci√≥n de prote√≠nas: <br><br><ul><li>  Localizaci√≥n de prote√≠nas a nivel humano con redes neuronales convolucionales (Rumetshofer et al.), </li><li>  Estructura de la prote√≠na de aprendizaje con un simulador diferenciable (Ingraham et al.), </li><li>  Aprendizaje de incrustaciones de secuencias de prote√≠nas utilizando informaci√≥n de la estructura (Bepler et al.). </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ab6/7ec/4a9/ab67ec4a9f80858fa58b48810806e587.png"></div><br>  No hubo art√≠culos sobre el tema de los genomas y no se realizaron seminarios.  No importa cu√°n triste parezca, sin embargo, se abren grandes oportunidades para los investigadores de educaci√≥n profunda en biolog√≠a y los bi√≥logos en educaci√≥n profunda. <br><br>  Un hecho: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jack Lindsay, el primer autor del art√≠culo anterior sobre la huella digital,</a> a√∫n no se ha graduado de Stanford College. <br><br><h2>  7. El aprendizaje reforzado sigue siendo el tema m√°s popular. </h2><br>  Los documentos presentados en la conferencia demuestran que la comunidad RL est√° pasando de m√©todos sin modelos a algoritmos basados ‚Äã‚Äãen modelos con algoritmos eficientes basados ‚Äã‚Äãen muestreo y metaaprendizaje.  El cambio probablemente se debi√≥ a los resultados extremadamente altos en los puntos de referencia de Mujoco establecidos por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TD3 (Fujimoto et al., 2018)</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SAC (Haarnoja et al., 2018)</a> , as√≠ como en el espacio de operaciones discretas en Atari establecido por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">R2D2 (Kapturowski et al. , ICLR 2019)</a> . <br><br>  En el proceso de capacitaci√≥n, los algoritmos basados ‚Äã‚Äãen modelos utilizan los datos disponibles para obtener un modelo ambiental y lo utilizan para planificar las estrategias de los agentes en este entorno o para generar nuevos datos.  Los algoritmos basados ‚Äã‚Äãen modelos finalmente han logrado la precisi√≥n asint√≥tica de sus contrapartes libres de modelos, utilizando 10-100 veces menos datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(MB-MPO (Rothfuss et al.)</a> ).  La nueva ventaja hace que los m√©todos basados ‚Äã‚Äãen modelos sean adecuados para tareas de un nivel real de complejidad.  Si despu√©s del entrenamiento el simulador del entorno tendr√° fallas, lo cual es muy probable, entonces sus deficiencias se pueden compensar mediante el uso de modelos m√°s complejos, como el conjunto de simuladores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Rajeswaran et al.)</a> .  Otra forma de usar RL para resolver problemas de un nivel real de complejidad es permitir que el simulador admita esquemas de aleatorizaci√≥n complejos.  La estrategia obtenida en una variedad de simuladores ambientales puede considerar el mundo real como "otra aleatorizaci√≥n" y puede tener √©xito en tareas de un nivel real de complejidad <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(OpenAI)</a> . <br><br>  Los algoritmos de metaaprendizaje que le permiten obtener una r√°pida transferencia de aprendizaje a nuevas tareas tambi√©n se han mejorado tanto en t√©rminos de rendimiento como en t√©rminos de eficiencia de la muestra ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ProMP (Rothfuss et al.)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PEARL (Rakelly et al.)</a> ).  Estas mejoras nos acercaron al "momento ImageNet para RL", en el que podemos usar estrategias de decisi√≥n aprendidas de otras tareas, en lugar de entrenarlas desde cero (lo cual es imposible para tareas complejas). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d3f/12a/aa2/d3f12aaa2382875e6d0dd041b6d2c5bb.png"></div><br>  Una parte impresionante del trabajo aceptado, junto con un seminario sobre la estructura y la probabilidad a priori en RL, se dedic√≥ a la integraci√≥n del conocimiento ambiental en los algoritmos de aprendizaje.  Si una de las principales fortalezas de los primeros algoritmos de RL profundos fue la generalizaci√≥n (por ejemplo, DQN usa la misma arquitectura para todos los juegos de Atari, sin saber nada sobre un juego espec√≠fico), ahora los nuevos algoritmos usan la integraci√≥n de conocimiento a priori para resolver problemas m√°s complejos tareas  Por ejemplo, en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Red de Transportadores (Jakab et al.), Un</a> agente utiliza conocimiento a priori para realizar un trabajo de exploraci√≥n m√°s informativo. <br><br>  En resumen, podemos decir que en los √∫ltimos 5 a√±os, la comunidad RL ha desarrollado muchas herramientas efectivas para resolver los problemas de la capacitaci√≥n de refuerzo en modo sin modelo.  Ahora es el momento de encontrar algoritmos m√°s transportables y eficientes en muestras para aplicar RL a tareas del mundo real. <br><br>  Uno de los hechos: Sergey Levin es probablemente la persona con m√°s trabajo en la ICLR este a√±o, en particular, 15 de sus art√≠culos han sido aceptados para su publicaci√≥n. <br><br><h2>  8. Los art√≠culos comunes se desvanecen r√°pidamente en segundo plano. </h2><br>  Cuando le pregunt√© al famoso investigador qu√© pensaba sobre el trabajo aceptado este a√±o, se ri√≥ entre dientes: "La mayor√≠a de ellos ser√°n olvidados tan pronto como termine la conferencia".  En un campo acelerado como el aprendizaje autom√°tico, los resultados se refutan en semanas, si no en d√≠as.  No es sorprendente que la mayor√≠a de los documentos aceptados ya est√©n desactualizados en el momento de la presentaci√≥n.  Por ejemplo, seg√∫n Borealis AI para ICLR 2018, " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">siete de los ocho art√≠culos sobre defensa contra ataques adversos fueron refutados incluso antes de que comenzara el ICLR</a> . Esto demuestra que los m√©todos heur√≠sticos sin ninguna base te√≥rica est√°n lejos de ser tan confiables como parecen. " <br><br>  A menudo escuch√© comentarios durante la conferencia, se√±alando la contribuci√≥n tangible del azar a la decisi√≥n de aceptar / rechazar el trabajo.  No mencionar√© art√≠culos espec√≠ficos, sin embargo, algunos de los art√≠culos m√°s discutidos y citados en los √∫ltimos a√±os fueron rechazados por las conferencias en el primer post.  Sin embargo, muchos de los trabajos aceptados ser√°n relevantes por a√±os, sin siquiera ser citados. <br><br>  Como persona que investiga en esta √°rea, a menudo me encuentro con una crisis existencial.  Cualquier idea que se me ocurra, parece que alguien m√°s ya se est√° dando cuenta de esto, y mejor y m√°s r√°pido.  ¬øDe qu√© sirve publicar un art√≠culo si nadie lo necesita? <br><br><h2>  Conclusi√≥n </h2><br>  Por supuesto, todav√≠a hay tendencias que me gustar√≠a abarcar. <br><br><ul><li>  Optimizaci√≥n y regularizaci√≥n: el debate de Adam contra SGD contin√∫a.  Se han propuesto muchos m√©todos nuevos, y algunos de ellos son bastante emocionantes.  Parece que hoy en d√≠a cada laboratorio est√° desarrollando su propio optimizador, incluso nuestro equipo est√° trabajando en un nuevo optimizador, que deber√≠a lanzarse en un futuro pr√≥ximo. </li><li>  :         ,    -      .    ,  ,  .     , ,        GAN ,    . </li></ul><br>    ,      .     ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">   (55 )</a> .           ICLR 2019  ,   ,      . <br><br> <i>    </i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8ea/c4e/df8/8eac4edf869602700d6e5f842f08ae0a.png"></div><br>    ICLR.   ,         ,     ,     .       . NeurIPS  ,            : ¬´     ,       ,   ¬ª. <br><br>   ,     , ‚Äî    ,   .     ,   ,           .       ,           . 10  10,    [ICLR ‚Äî .]. <br><br> <i>      - ,    , , ,      .  ¬´ ¬ª        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">  (Oleksii Hrinchuk)</a></i> <br><br><hr><br>     .      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CleverDATA</a>      ,           ,           .        .   Data Science ,         ,         .     ,     ,   - ,      ! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/475720/">https://habr.com/ru/post/475720/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../475694/index.html">Errores de libros de texto y curiosidades de estudio</a></li>
<li><a href="../475698/index.html">Down the Rabbit Hole: A Story of One Varnishreload Error - parte 1</a></li>
<li><a href="../475702/index.html">Registros de informes aproximadamente Tecnolog√≠a: Explicaci√≥n de datos # 3</a></li>
<li><a href="../475708/index.html">Inteligencia artificial - Int√©rprete de idiomas</a></li>
<li><a href="../475712/index.html">Entrega con clic cero y en SEO SERP: c√≥mo llegar a la posici√≥n cero en Yandex y Google</a></li>
<li><a href="../475728/index.html">¬øCu√°l es el pr√≥ximo miembro ...? - Estamos buscando una f√≥rmula para el en√©simo t√©rmino de la secuencia, generando funciones y transformaci√≥n Z</a></li>
<li><a href="../475730/index.html">C√≥mo dise√±ar hojas de c√°lculo web grandes y complejas</a></li>
<li><a href="../475732/index.html">Actualizaci√≥n 3CX v16 Actualizaci√≥n 4 Alpha y 3CX para Android, planes de desarrollo de PBX</a></li>
<li><a href="../475736/index.html">C√≥mo volamos aviones no tripulados a trav√©s de vertederos y buscamos fugas de metano</a></li>
<li><a href="../475738/index.html">5 cursos gratuitos para administradores de TI de Microsoft</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
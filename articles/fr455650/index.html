<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï° üë©üèº‚Äçü§ù‚Äçüë®üèª üìÉ Comment nous avons form√© un r√©seau de neurones pour classer les vis üë∏üèª üì° üíô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un r√©seau de neurones peut identifier un chat sur une photo, trouver un canap√©, am√©liorer l'enregistrement vid√©o, dessiner une image de chiots ou un s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment nous avons form√© un r√©seau de neurones pour classer les vis</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/455650/">  Un r√©seau de neurones peut identifier un chat sur une photo, trouver un canap√©, am√©liorer l'enregistrement vid√©o, dessiner une image de chiots ou un simple croquis.  Nous y sommes d√©j√† habitu√©s.  Des nouvelles sur les r√©seaux de neurones apparaissent presque tous les jours et sont devenues monnaie courante.  Les entreprises de Grid Dynamics ont d√©fini la t√¢che non pas ordinaire, mais difficile - apprendre au r√©seau neuronal √† trouver une vis ou un boulon sp√©cifique dans un immense catalogue d'une boutique en ligne √† partir d'une seule photographie.  La t√¢che est plus difficile que de trouver un chat. <br><br><img src="https://habrastorage.org/webt/a7/vv/1w/a7vv1w1gjwm8knv6kvrtvmd30vc.jpeg"><br><br>  Le probl√®me de la boutique en ligne de vis est en stock.  Des milliers ou des dizaines de milliers de mod√®les.  Chaque vis a sa propre description et ses propres caract√©ristiques, il n'y a donc aucun espoir pour les filtres.  Que faire  Rechercher manuellement ou rechercher dans l'hypermarch√© sur les √©tag√®res?  Dans les deux cas, c'est une perte de temps.  En cons√©quence, le client se fatigue et va enfoncer un clou.  Pour l'aider, nous utiliserons un r√©seau de neurones.  Si elle peut trouver des joints ou des canap√©s, alors laissez-la faire quelque chose d'utile - ramasser des vis et des boulons.  Comment apprendre √† un r√©seau de neurones √† s√©lectionner des vis rapidement et avec pr√©cision pour un utilisateur, nous vous le dirons dans la transcription du rapport de <strong>Maria Matskevichus</strong> , qui chez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Grid Dynamics</a> est engag√©e dans l'analyse de donn√©es et l'apprentissage automatique. <br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Une courte d√©mo de ce qui s'est pass√©</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/XZWdNCJ-zvE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><br><h2>  Probl√®mes d'acheteur </h2><br>  Imaginez - nous avons achet√© une table, mais une petite vis a √©t√© perdue et une table ne peut pas √™tre assembl√©e sans elle.  Nous allons dans la boutique en ligne √† la recherche et nous voyons 15 000 positions uniques, dont chacune est peut-√™tre notre vis. <br><br>  Nous passons aux filtres - il y en a environ 10, chacun ayant 5 √† 100 attributs.  Choisissez le type de chapeau et sa couleur: chapeau plat - Cuivre plat et jaune - Laiton.  Nous recevons le probl√®me. <br><br><img src="https://habrastorage.org/webt/r7/kl/zt/r7klztf19kbxdk7g6tl6jgmwsfm.jpeg"><br><br>  Qu'est ce que c'est  Nous ne cherchions pas cela.  Renvoyez la personne responsable de l'extradition! <br><br>  Apr√®s un certain temps, nous s√©lectionnons n√©anmoins 2 vis de table adapt√©es. <br><br><img src="https://habrastorage.org/webt/xn/ta/o1/xntao1sbhfrwxngdq2ktgjmfnga.jpeg"><br><br>  Il ne reste plus qu'√† d√©chiffrer la description et les caract√©ristiques.  Chaque fabricant d√©crit les vis √† sa mani√®re.  Il n'y a pas d'exigences sp√©cifiques pour d√©crire les param√®tres d'un mod√®le particulier. <br><br>  Tout ce qui cr√©e des difficult√©s pour le client.  Perte de temps, de nerfs et de travail de support technique, ce qui aide le client √† trouver le mod√®le souhait√©.  Ayant r√©alis√© ces probl√®mes de l'acheteur, notre client - une grande entreprise am√©ricaine - a d√©cid√© de fournir au client une recherche rapide, pr√©cise et simple par photo, au lieu d'une recherche s√©mantique lente et pas toujours r√©ussie. <br><br><img src="https://habrastorage.org/webt/vv/j6/ka/vvj6kac8ogeii9gknobzy_lp_z8.jpeg"><br><br><h2>  Difficult√©s de mise en ≈ìuvre </h2><br>  Nous avons entrepris la t√¢che et nous sommes rendu compte qu'il y avait plusieurs probl√®mes. <br><br>  <strong>Les vis se ressemblent.</strong>  Regardez les photos. <br><br><img src="https://habrastorage.org/webt/yh/tt/vy/yhttvysy1-fpbxmdtc2nnxpiyhu.jpeg"><br><br>  Ce sont des vis diff√©rentes.  Si vous retournez les photos, vous pouvez voir que la caract√©ristique importante est diff√©rente - la t√™te. <br><br><img src="https://habrastorage.org/webt/p1/jx/kl/p1jxkll1hxawlcfkxjlmwp6tc5c.jpeg"><br><br>  Et sur cette photo? <br><br><img src="https://habrastorage.org/webt/6q/aj/tv/6qajtvlljafp_cq_wap9y49abmo.jpeg"><br><br>  Ici, les mod√®les sont les m√™mes.  L'√©clairage est diff√©rent, mais sur les deux photos, il y a un mod√®le √† vis. <br><br>  <strong>Il existe des esp√®ces rares qui n√©cessitent une classification.</strong>  Par exemple, avec des "oreilles" ou une bague. <br><br><img src="https://habrastorage.org/webt/y5/xu/t8/y5xut8u9qqvn_yuglz2jnryrnre.jpeg"><br><br>  <strong>Exigences minimales pour l'utilisation de l'application.</strong>  L'utilisateur peut t√©l√©charger une photo avec n'importe quel fond, avec des objets √©trangers, avec des ombres, avec un mauvais √©clairage, et l'application doit donner le r√©sultat.  Une vis ou un boulon sur fond blanc est une raret√©. <br><br><img src="https://habrastorage.org/webt/ni/tk/46/nitk46f2hdufffnl0iseynuyd8m.jpeg"><br><br>  <strong>L'application devrait fonctionner en temps r√©el.</strong>  L'utilisateur attend le r√©sultat ici et maintenant. <br><br>  <strong>Concurrents.</strong>  Amazon - un concurrent de notre client - a r√©cemment lanc√© son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">outil de recherche de pi√®ces</a> .  Il s'agit d'une application qui recherche des vis et des boulons √† partir d'une photographie. <br><br><img src="https://habrastorage.org/webt/pc/-s/ls/pc-slse0i24woqx1kstagelupx8.jpeg"><br><br>  En plus d'Amazona, nous avions deux concurrents en d√©marrage avec leurs propres solutions pour le client.  Nous devions battre non seulement Amazon, mais aussi les startups, ce qui n'√©tait pas difficile.  L'un des concurrents a sugg√©r√© l'id√©e de prendre les 20 boulons les plus populaires et de <strong>d√©tecter les objets d'</strong> entra√Ænement sur eux.  Mais √† la question de savoir ce qui se passera lorsque les r√©seaux de neurones fourniront 100, 1000 ou les 15000 vis du site du client, comment la d√©tection d'objets fonctionnera et o√π obtenir autant de donn√©es, le concurrent n'a pas trouv√© de r√©ponse. <br><br><h2>  Solution </h2><br>  <strong>Il doit √™tre √©volutif</strong> et ne pas d√©pendre du nombre de vari√©t√©s de vis et de la taille du catalogue.  Pour r√©soudre le probl√®me, nous avons d√©cid√© de consid√©rer une vis comme un ensemble de caract√©ristiques ou d'attributs.  Chaque attribut est un ensemble d'attributs. <br><br><img src="https://habrastorage.org/webt/xy/g8/_a/xyg8_ao4gsrat9z-h1rx2jonc9c.jpeg"><br><br>  S√©lection des caract√©ristiques suivantes: <br><br><ul><li>  t√™te de chapeau (32 attributs); </li><li>  rev√™tement ext√©rieur - finition (15 attributs); </li><li>  pointe - pointe (12 attributs); </li><li>  couverture des fils - couverture des fils (4 attributs). </li></ul><br>  Nous avons examin√© la carte de tous les panneaux et r√©alis√© que pour d√©crire 15 000 vis diff√©rentes, il n'en fallait que 50. Ils constitueront une combinaison de panneaux diff√©rents avec des attributs diff√©rents.  Il faut 50 vis et une pi√®ce pour mesurer l'√©chelle de la vis sur la photo. <br><br>  Ils ont donc d√©cid√©.  Nous avons d√©cid√© de l'id√©e.  Des donn√©es suppl√©mentaires sont n√©cessaires. <br><br><h2>  Les donn√©es </h2><br>  Nous avons re√ßu des donn√©es du client et √©tions un peu contrari√©s.  Donn√©es du catalogue - photographies d'objets sur fond blanc. <br><br><img src="https://habrastorage.org/webt/wi/j1/6i/wij16itobierywpgzvfe73nc2cw.jpeg"><br><br>  Mais ils ne correspondent pas tout √† fait aux donn√©es que l'application va traiter.  L'utilisateur voudra utiliser n'importe quel arri√®re-plan, prendra des photos dans la paume de sa main ou tiendra un boulon avec ses doigts.  Les donn√©es sur lesquelles le r√©seau est form√© ne co√Øncideront pas avec l'image r√©elle. <br><br>  Ensuite, nous avons d√©cid√© de suivre les conseils de <strong>Richard Soker</strong> . <br><br><blockquote>  Au lieu d'apprendre une m√©thode d'enseignement sans enseignant pendant un mois, il est plus facile de prendre une semaine, d'annoter les donn√©es et de former le classificateur. </blockquote><br>  Nous avons donc fait - imprim√© beaucoup d'arri√®re-plans color√©s sur l'imprimante, achet√© ces 50 boulons et photographi√© les donn√©es d'entra√Ænement sur les arri√®re-plans.  Nous avons donc obtenu toutes les options possibles pour les surfaces des tables et des tapis. <br><br><img src="https://habrastorage.org/webt/my/rx/fa/myrxfayjmxipzesfqvfqzbukmhy.jpeg"><br><br>  Apr√®s avoir collect√© les donn√©es, l'√©tape suivante consiste √† comprendre o√π dans l'image le boulon se trouve, le cas √©ch√©ant. <br><br><h2>  Localisation </h2><br>  Nous avons examin√© deux approches de localisation: <strong>la d√©tection d'objets</strong> et <strong>la segmentation s√©mantique</strong> . <br><br><img src="https://habrastorage.org/webt/xe/yo/zv/xeyozvhmupnhillkiqp_pg9k-ta.jpeg"><br><br>  <strong>La d√©tection d'objet</strong> renvoie la bo√Æte de la zone minimale autour de l'objet.  <strong>La segmentation s√©mantique</strong> renvoie le masque.  Dans notre cas, le masque est plus adapt√©.  Il conserve sa forme, supprime l'arri√®re-plan, les ombres en exc√®s et vous permet de mieux classer les vis que la d√©tection d'objets. <br><br><img src="https://habrastorage.org/webt/re/zj/jg/rezjjg8pjjemrbtkmicc9u2n1r4.jpeg"><br><br>  La t√¢che de la segmentation s√©mantique est de renvoyer la probabilit√© de son appartenance √† une classe pour chaque pixel.  Pour former un tel mod√®le, des donn√©es √©tiquet√©es sont n√©cessaires.  Nous avons utilis√© l'application <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´labelme¬ª</a> , avec laquelle nous avons marqu√© l'√©chantillon.  Nous avons obtenu environ un millier de masques avec une pi√®ce de monnaie et une vis. <br><br><img src="https://habrastorage.org/webt/zm/oz/k4/zmozk4jv2bkrzfnema6gb_rizsk.jpeg"><br><br><h3>  Mod√®le </h3><br>  Nous avons pris <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">U-Net</a> .  Ce r√©seau est tr√®s appr√©ci√© de Kaggle, et nous le sommes aussi maintenant. <br><br><img src="https://habrastorage.org/webt/ct/_b/mu/ct_bmu46ku4wjcpxqahqrn7j9em.jpeg"><br><br>  U-Net est une impl√©mentation r√©ussie de codeur-d√©codeur. <br><br><ul><li>  <strong>Un chemin de construction ou un encodeur</strong> .  C'est la partie de U-Net, qui essaie de repr√©senter l'ensemble des donn√©es, pr√©sentes sous forme de repr√©sentation vectorielle dans un espace plus compress√©.  Elle apprend ces signes et trouve les plus significatifs. </li><li>  <strong>Un chemin ou d√©codeur en expansion</strong> .  Tente de d√©coder une carte d'entit√©s et de comprendre o√π se trouve l'objet dans l'image. </li></ul><br>  Nous avons d√©cid√© du mod√®le.  Maintenant, nous s√©lectionnons la fonction de perte, dont nous minimiserons la valeur dans le processus d'apprentissage. <br><br><h3>  Fonction de perte </h3><br>  L'option classique de segmentation est le <strong>coefficient de d√©s</strong> : <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>D</mi><mo stretchy=&quot;false&quot;>(</mo><mi>P</mi><mo>,</mo><mi>G</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>P</mi><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>G</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>P</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mo>+</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>G</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="36.381ex" height="2.66ex" viewBox="0 -832 15664.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-44" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-28" x="828" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-50" x="1218" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-2C" x="1969" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-47" x="2414" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-29" x="3201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-3D" x="3868" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-66" x="5174" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-72" x="5725" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-61" x="6176" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-63" x="6706" y="0"></use><g transform="translate(7139,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-32" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-7C" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-50" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-63" x="1780" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-64" x="2214" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-6F" x="2737" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-74" x="3223" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-47" x="3584" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-7C" x="4371" y="0"></use></g><g transform="translate(11789,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-7C" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-50" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-7C" x="1030" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-2B" x="1530" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-7C" x="2531" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMATHI-47" x="2809" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455650/&amp;usg=ALkJrhi1zxzaj3ss3Ve1Lzo8LrcT27QaAg#MJMAIN-7C" x="3596" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>D</mi><mo stretchy="false">(</mo><mi>P</mi><mo>,</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>P</mi><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>G</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mrow class="MJX-TeXAtom-ORD"><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>P</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>G</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> D (P, G) = \ frac {2 | P \ cdot G |} {| P | + | G |} </script></p><br><br>  Il s'agit de la moyenne harmonique entre pr√©cision et rappel.  La moyenne harmonique signifie que nous pesons √©galement l'erreur du premier type et l'erreur du deuxi√®me type.  Nos donn√©es ne sont pas √©quilibr√©es, et cela ne nous convient pas tr√®s bien. <br><br><img src="https://habrastorage.org/webt/s4/tv/vo/s4tvvo5frbz97yeg95ghcmcgjqo.jpeg"><br><br>  Il y a toujours beaucoup de fond et l'objet lui-m√™me ne suffit pas.  Par cons√©quent, le mod√®le donnera toujours une tr√®s haute pr√©cision et un rappel tr√®s faible.  Pour peser les erreurs du premier et du deuxi√®me type de diff√©rentes mani√®res, nous avons d√©cid√© de prendre l' <strong>indice Tversky</strong> : <br><br><p><math> </math> $$ afficher $$ S (P, G, Œ±, Œ≤) = \ frac {| P \ cdot G |} {| P \ cdot G | + Œ± | P / G | + Œ≤ | G / P |} $$ afficher $$ </p><br><br>  L'indice Tversky a deux coefficients, Œ± et Œ≤, pond√®rent les deux erreurs diff√©remment.  Si nous prenons Œ± = Œ≤ = 0,5, nous obtenons le m√™me coefficient de d√©s.  Si nous s√©lectionnons d'autres param√®tres, nous obtenons l' <strong>indice de Jaccard</strong> - l'une des mesures de similitude des objets.  Pour Œ± = Œ≤ = 1 - l'indice Tversky est √©gal √† l'indice Jaccard. <br><br>  Vous pouvez √©galement obtenir un score FŒ≤.  Pour Œ± + Œ≤ = 1, l'indice Tversky correspond au score FŒ≤. <br><br>  Pour s√©lectionner Œ± et Œ≤, nous avons men√© plusieurs exp√©riences.  Ils ont √©mis l'hypoth√®se que le <strong>mod√®le serait condamn√© √† une amende plus s√©v√®re pour les erreurs du deuxi√®me type</strong> .  Ce n'est pas si mal quand un mod√®le classe un pixel d'arri√®re-plan comme pixel d'objet.  S'il y a un petit cadre d'arri√®re-plan autour de l'objet, c'est normal.  Mais lorsque le mod√®le classe un pixel de vis comme pixel d'arri√®re-plan - des trous apparaissent sur la vis, il devient in√©gal, et cela interf√®re avec notre classification. <br><br>  Par cons√©quent, nous avons d√©cid√© d'augmenter le param√®tre Œ≤ et de le rapprocher de 1, et du param√®tre Œ± √† 0. <br><br><img src="https://habrastorage.org/webt/kq/cd/rw/kqcdrwc-hbnghdommkqtb_o9yxg.jpeg"><br><br>  L'image montre que le meilleur masque a √©t√© obtenu avec Œ≤ = 0,7 et Œ± = 0,3.  Nous avons d√©cid√© de nous arr√™ter l√†-dessus et de former le mod√®le sur toutes nos donn√©es. <br><br><h3>  La formation </h3><br>  La strat√©gie d'apprentissage est assez d√©licate.  Puisque nous avons annot√© manuellement les donn√©es dans le temps personnel, nous avons d√©cid√© d'utiliser une fonction de U-Net.  Il segmente chaque nouvelle classe sur un nouveau canal - ajoute un nouveau canal et un objet est localis√© dessus. <br><br>  Par cons√©quent, dans notre formation, il n'y avait pas une seule image contenant √† la fois une pi√®ce et un verrou.  Toutes les images contenaient une classe: 10% - pi√®ces, 90% - vis. <br><br><img src="https://habrastorage.org/webt/x1/nu/85/x1nu85eenmhkjxjhloakvkixbgq.jpeg"><br><br>  Cela a permis de r√©partir correctement les efforts et de gagner du temps sur une pi√®ce - c'est un, mais la forme est simple.  Nous avons facilement appris √† le segmenter, ce qui nous a permis de transf√©rer 90% de nos efforts aux vis.  Ils ont des formes et des couleurs diff√©rentes, et il est important d'apprendre √† les segmenter. <br><br>  Notre r√©seau a appris √† segmenter m√™me les instances qui ne faisaient pas partie de notre √©chantillon.  Par exemple, des boulons d'une forme inhabituelle √©taient absents, mais le mod√®le les a √©galement bien segment√©s.  Elle a appris √† g√©n√©raliser les signes de vis et boulons et √† l'utiliser pour de nouvelles donn√©es, ce qui est formidable. <br><br><img src="https://habrastorage.org/webt/qj/tw/zf/qjtwzf-39r0_d1p6lmtkceh5slc.jpeg"><br><br><h2>  Classification </h2><br>  Il s'agit de l'√©tape suivante apr√®s la localisation de l'objet.  Peu de gens forment des r√©seaux de neurones convolutifs pour classer les objets; ils utilisent souvent l' <strong>apprentissage par transfert</strong> .  Examinons l'architecture d'un r√©seau neuronal convolutif, puis rappelons bri√®vement ce qu'est l'apprentissage par transfert. <br><br><img src="https://habrastorage.org/webt/x_/nj/mp/x_njmpkiczozha_bxuyxsdjjtso.jpeg"><br><br>  Dans les premi√®res couches, le r√©seau apprend √† reconna√Ætre les limites et les angles.  Plus tard, il reconna√Æt des formes simples: rectangles, cercles, carr√©s.  Plus il est proche du sommet, plus il reconna√Æt les traits caract√©ristiques des donn√©es sur lesquelles il est form√©.  Tout en haut, le mod√®le reconna√Æt les classes. <br><br>  La plupart des objets du monde se composent de formes simples et ont des caract√©ristiques communes.  Vous pouvez faire partie d'un r√©seau form√© √† une √©norme quantit√© de donn√©es et utiliser ces attributs pour notre classification.  Le r√©seau sera form√© sur un petit ensemble de donn√©es sans grandes d√©penses de ressources.  C'est ce que nous avons fait. <br><br><img src="https://habrastorage.org/webt/az/au/rj/azaurjthm-u2bi6m1v_cudav72g.jpeg"><br><br>  Une fois que vous avez d√©cid√© de la technologie g√©n√©rale de l'apprentissage par transfert, vous devez s√©lectionner un mod√®le pr√©-form√©. <br><br><h3>  S√©lection du mod√®le </h3><br>  Notre application fonctionne en temps r√©el.  Le mod√®le doit √™tre l√©ger et mobile - avoir peu de param√®tres, mais √™tre pr√©cis.  Pour tenir compte de ces deux facteurs, nous avons sacrifi√© un peu de pr√©cision au profit de la l√©g√®ret√©.  Par cons√©quent, nous n'avons pas choisi le mod√®le le plus pr√©cis mais le plus l√©ger - <strong>Xception</strong> . <br><br><img src="https://habrastorage.org/webt/fh/79/k0/fh79k0s5gfidknkaqnekdmfb6ps.jpeg"><br><br>  Dans Xception, au lieu de la convolution habituelle - <strong>Convolution</strong> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Convolution s√©parable</a> est utilis√©e.  Par cons√©quent, Xception est plus l√©ger que d'autres r√©seaux, par exemple avec VGG. <br><br><img src="https://habrastorage.org/webt/vm/uj/wt/vmujwtib1valz_zzxcspvvgudw4.jpeg"><br><br>  La convolution ordinaire effectue √† la fois la convolution intercanale et interdimensionnelle.  Et partages de convolution s√©parables: d'abord, convolution interdimensionnelle - en <strong>profondeur</strong> , puis interchannel.  Les r√©sultats se combinent. <br><br>  Xception ex√©cute une convolution s√©parable, alors qu'elle produit le m√™me bon r√©sultat que la convolution ordinaire, mais il y a moins de param√®tres. <br><br><img src="https://habrastorage.org/webt/dr/4x/tv/dr4xtvgjidi4f42dlbkng81b2zg.jpeg"><br><br>  Nous substituons les valeurs dans les formules pour calculer les param√®tres, par exemple, pour 16 filtres.  Pour la convolution ordinaire, vous devez calculer les param√®tres 7 fois plus que pour la convolution s√©parable.  Pour cette raison, Xception est plus pr√©cis et moins. <br><br><img src="https://habrastorage.org/webt/4l/aq/u3/4laqu3wafqnk9iqbp3dexyy8zy0.jpeg"><br><br><h3>  La formation </h3><br>  Tout d'abord, nous avons d√©cid√© de construire une base de r√©f√©rence et form√© le mod√®le dans l'image originale.  Nous avions 4 classificateurs et chacun √©tait responsable d'un attribut sp√©cifique.  Le r√©sultat n'√©tait pas satisfaisant. <br><br><img src="https://habrastorage.org/webt/ae/ne/ak/aeneakp61lkwkildsz8kqgdr1ge.jpeg"><br><br>  Ensuite, ils ont form√© le mod√®le sur la bo√Æte, qui a renvoy√© la d√©tection d'objet.  Vous avez une bonne augmentation de la pr√©cision de la couverture des threads.  Mais pour le reste des classificateurs, le r√©sultat est √©galement insatisfaisant. <br><br><img src="https://habrastorage.org/webt/zn/cm/xn/zncmxnp-ly_8o3id4pfil5cosqu.jpeg"><br><br>  Ensuite, ils ont d√©cid√© de ne donner aux classificateurs que la partie de la vis qu'ils voulaient et classeraient.  La t√™te ne donne que des chapeaux, Astuce - seulement un fer de lance.  Pour ce faire, nous avons pris des masques, obtenu un contour autour duquel un rectangle de la zone minimale a √©t√© encercl√© et calcul√© l'angle de rotation. <br><br><img src="https://habrastorage.org/webt/jl/lo/wq/jllowqowcwjrki7s1gth-pl_004.jpeg"><br><br>  √Ä ce moment, nous ne savons toujours pas de quel c√¥t√© la t√™te de vis et la pointe.  Pour le savoir, ils ont coup√© la bo√Æte en deux et ont regard√© le carr√©. <br><br><img src="https://habrastorage.org/webt/h_/k1/cz/h_k1czvxjoiapjnjbth5ny7cit0.jpeg"><br><br>  La zone qui contient la t√™te est toujours plus grande que la zone qui contient la pointe.  En comparant la zone, nous d√©terminons dans quelle partie, quelle partie de la vis.  Cela a fonctionn√©, mais pas pour tous les cas. <br><br><img src="https://habrastorage.org/webt/z4/va/ci/z4vaciqdgvun8erixvsvr9iea6o.jpeg"><br><br>  Lorsque la longueur de la vis est comparable au diam√®tre du capuchon, au lieu d'un rectangle, un carr√© est obtenu.  Lorsque nous la tournons, nous obtenons une image, comme au num√©ro 3. Le mod√®le ne classe pas bien cette option. <br><br>  Ensuite, nous avons pris toutes les vis longues, calcul√© les angles de rotation pour elles et construit le r√©seau neuronal peu profond <strong>Rotation Net</strong> , qui prend la vis et pr√©dit l'angle de rotation. <br><br><img src="https://habrastorage.org/webt/bu/m2/tn/bum2tncic229p7s1y0wldwrlkhk.jpeg"><br><br>  Ensuite, ce mod√®le auxiliaire a √©t√© utilis√© pour les petites vis et boulons courts.  Nous avons obtenu un bon r√©sultat - tout fonctionne, les petites vis tournent aussi.  √Ä ce stade, l'erreur est pratiquement r√©duite √† z√©ro.  Nous avons pris ces donn√©es, form√© les classificateurs et constat√© que pour chacun des classificateurs, √† l'exception de Fini, la pr√©cision augmentait consid√©rablement.  C'est formidable - nous travaillons plus loin. <br><br><img src="https://habrastorage.org/webt/sm/l3/en/sml3encb5d6y6jueenvwg9bpooa.jpeg"><br><br>  Mais pour une raison quelconque, Finish n'a pas d√©coll√©.  Nous avons √©tudi√© les erreurs et vu l'image. <br><br><img src="https://habrastorage.org/webt/jq/_e/k2/jq_ek25gfktmad7pggi96ia7di4.jpeg"><br><br>  La m√™me paire de vis dans diff√©rentes conditions d'√©clairage et diff√©rents r√©glages de cam√©ra diff√®rent en couleur.  Cela peut confondre non seulement le mod√®le, mais aussi la personne.  Le gris peut devenir rose, le jaune peut devenir orange.  Rappelez-vous la robe bleu-or - la m√™me histoire.  La surface r√©fl√©chissante de la vis est trompeuse. <br><br>  Nous avons √©tudi√© des cas similaires sur Internet et trouv√© des scientifiques chinois qui ont essay√© de classer les voitures par couleurs et ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rencontr√©</a> le m√™me probl√®me pour les voitures. <br><br><img src="https://habrastorage.org/webt/2u/uc/43/2uuc433a4s3uwvt8zzy-ebswcxy.jpeg"><br><br>  Comme solution, les scientifiques chinois ont cr√©√© un r√©seau peu profond.  Sa caract√©ristique est en deux branches qui sont concat√©n√©es √† la fin.  Cette architecture est appel√©e <strong>ColorNet</strong> . <br><br><img src="https://habrastorage.org/webt/aw/33/fc/aw33fcyy4nk8z-3lromrjc7ytyu.jpeg"><br><br>  Nous avons impl√©ment√© une solution pour notre t√¢che, et nous avons obtenu une augmentation de la pr√©cision de pr√®s de 2 fois.  Avec de tels r√©sultats et mod√®les, vous pouvez travailler et rechercher la vis m√™me du tableau dans le catalogue de la boutique en ligne. <br><br><img src="https://habrastorage.org/webt/cb/bn/yy/cbbnyyxrcjlsluvxnpf9sieuwl4.jpeg"><br><br>  Nous n'avions que 4 classificateurs pour 4 attributs, et il y en a beaucoup d'autres.  Donc, vous devez cr√©er une sorte de filtre qui prendra les donn√©es du catalogue et les filtrera d'une certaine mani√®re. <br><br><h2>  Filtrage </h2><br>  Chaque classificateur renvoie une √©tiquette souple et une classe.  Nous avons pris les valeurs des balises logicielles et de notre base de donn√©es, compt√© un certain <strong>score</strong> - en multipliant toutes les balises pour chaque fonctionnalit√©. <br><br><img src="https://habrastorage.org/webt/jq/fj/k9/jqfjk93kayaexrfjop70einshzc.jpeg"><br><br>  Le score montre la confiance de tous les classificateurs que cette combinaison de fonctionnalit√©s appara√Ætra tr√®s probablement.  Plus le score est √©lev√©, plus la vis du catalogue et la vis de l'image sont similaires. <br><br><h2>  Pipeline </h2><br>  Il s'est av√©r√© une telle application. <br><br><img src="https://habrastorage.org/webt/av/nq/a9/avnqa9l-l5lo9fxxtovxs68omru.jpeg"><br><br><ul><li>  <strong>Entr√©e</strong> : commencez par une image brute. </li><li>  <strong>Localisation</strong> : d√©terminez o√π se trouve le boulon ou la vis et o√π se trouve la pi√®ce. </li><li>  <strong>Transformation et rotation</strong> . </li><li>  <strong>Classification</strong> : nous d√©coupons soigneusement tout, classons et d√©terminons la taille. </li><li>  <strong>Filtrage</strong> . </li><li>  <strong>Quittez</strong> vers une position SKU sp√©cifique. </li></ul><br><h2>  Comment mettre en ≈ìuvre un projet complexe </h2><br>  <strong>Mangez l'√©l√©phant en morceaux</strong> .  Divisez le gros probl√®me en plusieurs parties. <br><br>  <strong>√âtiquetez les donn√©es qui refl√©teront la r√©alit√©.</strong>  N'ayez pas peur du balisage des donn√©es - c'est le moyen le plus s√ªr, qui garantira rapidement la qualit√© maximale du mod√®le.  Les m√©thodes de synth√®se des donn√©es produisent g√©n√©ralement des r√©sultats moins bons que l'utilisation de donn√©es r√©elles. <br><br>  <strong>Testez-le</strong> .  Avant de construire de nombreux mod√®les, nous avons pris de petits morceaux de donn√©es, les avons √©tiquet√©s avec nos mains et test√© le fonctionnement de chaque hypoth√®se.  Ce n'est qu'apr√®s cela qu'ils ont form√© U-Net, classificateurs, Rotation. <br><br>  <strong>Ne r√©inventez pas la roue</strong> .  Souvent, le probl√®me auquel vous √™tes confront√© a d√©j√† une solution.  Regardez sur Internet, lisez des articles - assurez-vous de trouver quelque chose! <br><br>  L'histoire de notre application Visual Search ne concerne pas seulement la classification des vis.  Il s'agit de savoir comment r√©aliser un projet complexe, qui n'a pas d'analogues, mais m√™me s'il y en a, ils ne r√©pondent pas aux exigences que nous avons fix√©es pour l'application. <br><br>  Pour plus d'informations sur les projets Grid Dynamics et les autres d√©fis rencontr√©s par l'√©quipe Data Science, consultez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blog technologique de</a> l'entreprise. <br><br><blockquote>  Des rapports avec un tel biais - l'utilisation d'algorithmes d'apprentissage automatique dans de vrais projets non standard - nous recherchons simplement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">UseData Conf</a> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici</a> plus sur les domaines qui nous int√©ressent le plus. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Envoyez des applications</a> si vous savez comment farcir les mod√®les pour qu'ils volent.  Si vous savez que la convergence ne garantit pas la vitesse et √™tes pr√™t √† vous dire ce qui est le plus important √† surveiller, nous vous attendons le 16 septembre. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455650/">https://habr.com/ru/post/fr455650/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455640/index.html">¬´La machine √† √©motions¬ª de Marvin Minsky: Chapitre 4. ¬´Comment nous reconnaissons la conscience¬ª</a></li>
<li><a href="../fr455642/index.html">L'architecture du service de file d'attente de messages distribu√©s dans Yandex.Cloud</a></li>
<li><a href="../fr455644/index.html">Nous utilisons les donn√©es dans la pratique</a></li>
<li><a href="../fr455646/index.html">Semaine de s√©curit√© 24: portes d√©rob√©es d'usine sur les smartphones Android</a></li>
<li><a href="../fr455648/index.html">Cycle de vie ML</a></li>
<li><a href="../fr455652/index.html">Deep Learning vs bon sens: d√©velopper un chat bot</a></li>
<li><a href="../fr455658/index.html">Intel Core i7-2600K l√©gendaire: test de Sandy Bridge en 2019 (partie 3)</a></li>
<li><a href="../fr455662/index.html">Grand √©cran m√©canique avec m√©canisme √† came comme d√©codeur</a></li>
<li><a href="../fr455666/index.html">G√©n√©rer des ventes sortantes dans une entreprise de services informatiques</a></li>
<li><a href="../fr455668/index.html">Nous √©crivons sous FPGA sans HDL. Comparaison d'outils de d√©veloppement de haut niveau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë®‚Äçüëß ü•ñ üî≠ Neuronale Echtzeitnetze zur Handverfolgung ‚åöÔ∏è üéÉ üè†</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="K√ºrzlich haben GoogleAI-Forscher ihre Herangehensweise an die Aufgabe gezeigt, H√§nde zu verfolgen und Gesten in Echtzeit zu bestimmen. Ich war mit ein...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronale Echtzeitnetze zur Handverfolgung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466781/">  K√ºrzlich haben GoogleAI-Forscher ihre Herangehensweise an die Aufgabe gezeigt, H√§nde zu verfolgen und Gesten in Echtzeit zu bestimmen.  Ich war mit einer √§hnlichen Aufgabe besch√§ftigt und beschloss daher herauszufinden, wie sie sich der L√∂sung n√§herten, welche Technologien sie verwendeten und wie sie bei der Echtzeitarbeit auf einem mobilen Ger√§t eine gute Genauigkeit erzielten.  Auch startete das Modell auf Android und getestet unter realen Bedingungen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gu/t9/pf/gut9pfmq0kfr2wtsh3kd3a191js.gif"></div><a name="habracut"></a><br><h3>  Warum ist das wichtig? </h3><br>  Handerkennung ist eine eher nicht triviale Aufgabe, die gleichzeitig sehr gefragt ist.  Diese Technologie kann in Anwendungen mit zus√§tzlicher Realit√§t f√ºr die Interaktion mit virtuellen Objekten verwendet werden.  Es kann auch die Grundlage f√ºr das Verst√§ndnis der Geb√§rdensprache oder f√ºr die Erstellung gestenbasierter Steuerungsschnittstellen sein. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/r-/vt/e_/r-vte__yxhdzjrypy3vyacploek.gif" alt="Bild"></div><br><h3>  Was ist die Schwierigkeit? </h3><br>  Die nat√ºrliche Wahrnehmung von H√§nden in Echtzeit ist eine echte Herausforderung f√ºr das Computer-Sehen. H√§nde √ºberlappen sich h√§ufig selbst oder einander (Daumen dr√ºcken oder H√§ndesch√ºtteln).  W√§hrend Gesichter kontrastreiche Muster aufweisen, beispielsweise im Bereich der Augen und des Mundes, erm√∂glicht das Fehlen solcher Zeichen in den H√§nden eine zuverl√§ssige Erkennung nur anhand ihrer visuellen Zeichen. <br><br>  H√§nde sind st√§ndig in Bewegung, √§ndern Neigungswinkel und √ºberlappen sich.  F√ºr eine akzeptable Benutzererfahrung muss die Erkennung mit hohen FPS (25+) funktionieren.  Dar√ºber hinaus sollte dies alles auf mobilen Ger√§ten funktionieren, was die Geschwindigkeitsanforderungen sowie die Ressourcenbeschr√§nkungen erh√∂ht. <br><br><h3>  Was hat GoogleAI getan? </h3><br>  Sie implementierten Technologien zur pr√§zisen Verfolgung von H√§nden und Fingern mithilfe von maschinellem Lernen (ML).  Das Programm ermittelt 21 Schl√ºsselpunkte der Hand im 3D-Raum (H√∂he, L√§nge und Tiefe) und klassifiziert anhand dieser Daten die Gesten, die die Hand zeigt.  All dies auf der Basis von nur einem Videobild, funktioniert in Echtzeit auf Mobilger√§ten und skaliert mit mehreren H√§nden. <br><br><h3>  Wie haben sie das gemacht? </h3><br>  Der Ansatz wird mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MediaPipe</a> implementiert, einem plattform√ºbergreifenden Open-Source-Framework zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von</a> Datenverarbeitungs-Pipelines (Video, Audio, Zeitreihen).  So etwas wie Deepstream von Nvidia, aber mit einer Reihe von Funktionen und plattform√ºbergreifend. <br><br>  Die L√∂sung besteht aus 3 Hauptmodellen, die zusammenarbeiten: <br><br>  <b>Palm Detector (BlazePalm)</b> <br><br><ul><li>  Nimmt das vollst√§ndige Bild vom Video auf </li><li>  gibt orientierten Begrenzungsrahmen zur√ºck (Begrenzungsrahmen) </li></ul><br>  <b>Modell zur Bestimmung der wichtigsten Punkte auf der Hand</b> <br><br><ul><li>  macht ein beschnittenes Bild von einer Hand </li><li>  Gibt 21 wichtige Punkte einer Hand im 3D-Raum + Konfidenzindikator zur√ºck (weitere Details weiter unten im Artikel). </li></ul><br>  <b>Gestenerkennungsalgorithmus</b> <br><br><ul><li>  nimmt wichtige Punkte der Hand </li><li>  Gibt den Namen der Geste zur√ºck, die die Hand zeigt </li></ul><br>  Die Architektur √§hnelt der in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Posensch√§tzungsaufgabe verwendeten</a> .  Durch die Bereitstellung eines pr√§zise zugeschnittenen und ausgerichteten Handbilds wird der Bedarf an Datenerweiterungen (Rotationen, √úbersetzungen und Skalierungen) erheblich reduziert. Stattdessen kann sich das Modell auf die Genauigkeit der Koordinatenvorhersage konzentrieren. <br><br><h3>  Palmendetektor </h3><br>  Um die Handfl√§che zu finden, wird ein Modell namens BlazePalm verwendet - ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Single Shot Detector</a> (SSD) -Modell, das f√ºr die Arbeit an einem mobilen Ger√§t in Echtzeit optimiert ist. <br><br>  In einer GoogleAI-Studie wurde ein Handfl√§chendetektor anstelle eines gesamten Armdetektors trainiert (Handfl√§che ist die Basis einer Handfl√§che ohne Finger).  Der Vorteil dieses Ansatzes besteht darin, dass es einfacher ist, eine Handfl√§che oder Faust mit gestikulierenden Fingern zu erkennen als die ganze Hand, und die Handfl√§che kann auch mithilfe von quadratischen Begrenzungsrahmen (Ankern) ausgew√§hlt werden, wobei Seitenverh√§ltnisse ignoriert werden und somit die Anzahl der erforderlichen Anker um das 3-5-fache reduziert wird <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Feature-</a> Extraktor " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Feature Pyramid Networks for Object Detection"</a> (FPN) wurde auch verwendet, um den Bildkontext auch f√ºr kleine Objekte besser zu verstehen. <br><br>  Als Verlustfunktion wurde ein Fokusverlust genommen, der das Ungleichgewicht der Klassen, die beim Erzeugen einer gro√üen Anzahl von Ankern auftreten, gut bew√§ltigt. <br><br>  Klassische <b>Kreuzentropie</b> : <b>CE (pt) = -log (pt)</b> <br>  Fokusverlust: <b>FL (pt) = - (1-pt) log (pt)</b> <br><br>  Weitere Informationen zum Focall-Verlust finden Sie im ausgezeichneten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pager</a> von Facebook AI Research (empfohlene Lekt√ºre). <br><br>  Unter Verwendung der obigen Techniken wurde eine durchschnittliche Genauigkeit von 95,7% erreicht.  Bei Verwendung einer einfachen Kreuzentropie und ohne FPN - 86,22%. <br><br><h3>  Wichtige Punkte definieren </h3><br>  Nachdem der Handfl√§chendetektor die Position der Handfl√§che im gesamten Bild bestimmt hat, verschiebt sich der Bereich um einen bestimmten Faktor nach oben und dehnt sich aus, um die gesamte Hand abzudecken.  Weiter auf dem zugeschnittenen Bild ist das Regressionsproblem gel√∂st - die genaue Position von 21 Punkten im 3D-Raum wird bestimmt. <br><br>  F√ºr das Training wurden 30.000 reale Bilder manuell markiert.  Es wurde auch ein realistisches 3D-Modell der Hand erstellt, mit dessen Hilfe k√ºnstlichere Beispiele auf verschiedenen Hintergr√ºnden erzeugt wurden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tc/-u/fz/tc-ufzxvhtraznlirykqi08jwew.png"></div><br>  <i>Oben: Echte Handbilder mit markierten Schl√ºsselpunkten.</i>  <i>Unten: K√ºnstliche Bilder der Hand, die mit einem 3D-Modell erstellt wurden</i> <br><br><h3>  Gestenerkennung </h3><br>  F√ºr die Gestenerkennung wurde ein einfacher Algorithmus verwendet, der den Zustand jedes Fingers (z. B. gekr√ºmmt oder gerade) anhand der Schl√ºsselpunkte der Hand bestimmt.  Dann werden alle diese Bedingungen mit den vorhandenen Gesten verglichen.  Mit dieser einfachen, aber effektiven Methode k√∂nnen Sie grundlegende Gesten mit guter Qualit√§t erkennen. <br><br><h3>  Optimierungen </h3><br>  Das Hauptgeheimnis der schnellen Inferenz in Echtzeit ist in einer wichtigen Optimierung verborgen.  Der Palmenmelder, der die meiste Zeit in Anspruch nimmt, startet nur bei Bedarf (ziemlich selten).  Dies wird erreicht, indem die Position der Hand im n√§chsten Frame basierend auf den vorherigen Schl√ºsselpunkten der Hand berechnet wird. <br><br>  F√ºr die Nachhaltigkeit dieses Ansatzes wurde dem Modell ein weiterer Ausweg zur Bestimmung der wichtigsten Punkte hinzugef√ºgt - ein Skalar, der zeigt, wie sicher das Modell ist, dass die Hand auf dem zugeschnittenen Bild vorhanden ist und korrekt eingesetzt wird.  Wenn der Konfidenzwert unter einen bestimmten Schwellenwert f√§llt, wird der Palmendetektor gestartet und auf den gesamten Rahmen angewendet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e0/nt/p2/e0ntp2dskan4eybazalerwsckwq.png"></div><br><h3>  Realit√§tspr√ºfung </h3><br>  Ich habe diese L√∂sung auf einem Android-Ger√§t (Xiaomi Redmi Note 5) f√ºr einen Test unter realen Bedingungen gestartet.  Das Modell verh√§lt sich gut, bildet das Skelett der Hand korrekt ab und berechnet die Tiefe mit einer anst√§ndigen Anzahl von Bildern pro Sekunde. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4d/5l/sw/4d5lswgbe_0m1ebnyw-vt0hq6to.gif"></div><br>  Von den Minuspunkten ist zu beobachten, wie Genauigkeit und Geschwindigkeit bei einer konstanten Bewegung der Hand entlang des Rahmens zu sinken beginnen.  Dies liegt daran, dass das Modell den Detektor st√§ndig neu starten muss, da er beim Bewegen die Position der Hand verliert.  Wenn die Geschwindigkeit, mit der Sie eine sich bewegende Hand finden, f√ºr Sie wichtiger ist als die Definition von Gesten, sollten Sie nach anderen Ans√§tzen suchen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e4/zl/re/e4zlreadcwadclrbs2r52kczdua.gif"></div><br>  Einige Probleme treten auch auf, wenn sich die Hand mit dem Gesicht oder √§hnlichen komplexen Hintergr√ºnden schneidet.  Ansonsten ist die gro√üartige Arbeit von GoogleAI ein gro√üer Beitrag zur zuk√ºnftigen Entwicklung der Technologie. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GoogleAI-Blog-Artikel</a> <br>  <a href="">Github Mediapipe Hand Tracking</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466781/">https://habr.com/ru/post/de466781/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466769/index.html">Dolch 2 ist elementar (Teil 2)</a></li>
<li><a href="../de466773/index.html">Sicherheitswoche 37: Sicherheitsl√ºcke in Android, Microsoft versus Deepfakes, Popularit√§t von Windows 7</a></li>
<li><a href="../de466775/index.html">So funktioniert es: Frequenzauswahl f√ºr 5G</a></li>
<li><a href="../de466777/index.html">Empfehlungen zum Erstellen von Anwendungen in React Native. Teil 1</a></li>
<li><a href="../de466779/index.html">Englisch lernen: 8 M√∂glichkeiten, h√∂flich Nein zu sagen</a></li>
<li><a href="../de466785/index.html">Was die Berge lehren: die Wahl eines IT-Spezialisten</a></li>
<li><a href="../de466787/index.html">Volltextsuche in Android</a></li>
<li><a href="../de466793/index.html">Startups im russischen Fu√üball: Sie existieren</a></li>
<li><a href="../de466799/index.html">Maltego ist n√§her am K√∂rper. Teil 2</a></li>
<li><a href="../de466801/index.html">Umgehen des LinkedIn-Suchlimits durch Spielen mit der API</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
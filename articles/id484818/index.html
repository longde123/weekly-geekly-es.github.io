<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸš¢ ğŸ’½ ğŸ¦Š Buku "C ++. Praktek pemrograman multithreaded " ğŸ‘µğŸ½ ğŸ‘¨ğŸ»â€ğŸš’ â™ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hai, habrozhiteli! Bahasa C ++ dipilih ketika Anda perlu membuat aplikasi yang benar-benar secepat kilat. Dan pemrosesan kompetitif berkualitas tinggi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Buku "C ++. Praktek pemrograman multithreaded "</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/484818/"> <a href="https://habr.com/ru/company/piter/blog/484818/"><img src="https://habrastorage.org/webt/cr/ym/3u/crym3urkeecjcfe-nsvq0nrw59y.jpeg" align="left" alt="gambar"></a>  Hai, habrozhiteli!  Bahasa C ++ dipilih ketika Anda perlu membuat aplikasi yang benar-benar secepat kilat.  Dan pemrosesan kompetitif berkualitas tinggi akan membuat mereka lebih cepat.  Fitur-fitur baru dari C ++ 17 memungkinkan Anda untuk menggunakan kekuatan penuh dari pemrograman multi-threaded untuk dengan mudah menyelesaikan masalah pemrosesan grafis, pembelajaran mesin, dll. termasuk pengembang yang paling berpengalaman. <br><br>  Dalam buku ini â€¢ Tinjauan lengkap fitur C ++ 17.  â€¢ Luncurkan dan kontrol aliran.  â€¢ Sinkronisasi operasi kompetitif.  â€¢ Pengembangan kode kompetitif.  â€¢ Debugging aplikasi multithreaded.  Buku ini cocok untuk pengembang tingkat menengah yang menggunakan C dan C ++.  Pengalaman pemrograman kompetitif tidak diperlukan. <br><a name="habracut"></a><br><h3>  Pengembangan Kode Kompetitif </h3><br><h3>  8.1.  Cara untuk mendistribusikan pekerjaan di antara utas </h3><br>  Bayangkan Anda perlu membangun rumah.  Untuk melakukan ini, Anda harus menggali lubang fondasi, mengisi fondasi itu sendiri, membangun dinding, meletakkan pipa dan kabel listrik, dll. Secara teoritis, dengan keterampilan yang memadai, semuanya dapat dilakukan secara mandiri, tetapi kemungkinan besar itu akan membutuhkan banyak waktu dan Anda harus beralih dari satu pekerjaan ke pekerjaan lain. satu lagi.  Tapi Anda bisa mempekerjakan asisten.  Maka akan perlu untuk memilih berapa banyak asisten untuk dipekerjakan, dan memutuskan apa yang harus mereka dapat.  Anda dapat, misalnya, merekrut dua pekerja dan bekerja dengan mereka.  Maka Anda masih harus beralih dari satu pekerjaan ke pekerjaan lain, tetapi sekarang segalanya akan berjalan lebih cepat, karena akan ada lebih banyak artis. <br><br>  Anda dapat memilih opsi lain - menyewa tim spesialis, seperti tukang batu, tukang kayu, tukang listrik dan tukang ledeng.  Masing-masing akan bekerja dalam kekhususannya sendiri, oleh karena itu, sampai tukang ledeng memiliki bagian depan pekerjaan, ia akan duduk diam.  Namun segalanya akan berjalan lebih cepat dari sebelumnya, karena ada lebih banyak pekerja, dan sementara tukang listrik akan melakukan perkabelan di dapur, tukang ledeng dapat pergi ke kamar mandi.  Tetapi ketika tidak ada pekerjaan untuk spesialis tertentu, lebih banyak downtime diperoleh.  Namun, dapat dicatat bahwa bahkan dengan penghentian diperhitungkan, pekerjaan bergerak lebih cepat ketika spesialis datang untuk bekerja, daripada tim pekerja.  Spesialis tidak perlu terus-menerus mengubah alat, dan pasti masing-masing dari mereka akan melakukan tugas mereka lebih cepat daripada pekerja.  Apakah ini akan benar-benar tergantung pada keadaan spesifik: semuanya dipelajari dalam praktik. <br><br>  Bahkan jika Anda melibatkan spesialis, Anda masih perlu memilih jumlah pekerja yang berbeda dari berbagai spesialisasi.  Mungkin masuk akal untuk menyewa, misalnya, lebih banyak tukang batu daripada tukang listrik.  Selain itu, komposisi tim Anda dan efektivitas keseluruhan pekerjaannya dapat berubah jika Anda harus membangun beberapa rumah sekaligus.  Bahkan jika ada sedikit pekerjaan untuk tukang ledeng di satu rumah, maka ketika membangun beberapa rumah sekaligus, itu bisa diambil sepanjang hari.  Selain itu, jika Anda tidak perlu membayar spesialis untuk downtime, Anda dapat merekrut tim yang lebih besar, bahkan jika jumlah orang yang bekerja secara bersamaan tidak berubah. <br><br>  Tetapi berhenti berbicara tentang konstruksi.  Apa hubungannya semua ini dengan utas?  Dan Anda dapat menerapkan pertimbangan serupa pada mereka.  Anda harus memutuskan berapa banyak utas untuk digunakan dan tugas apa yang harus mereka lakukan.  Apakah kita memerlukan utas universal yang melakukan pekerjaan yang diperlukan pada saat tertentu, atau utas khusus yang disesuaikan dengan baik hanya pada satu hal?  Atau mungkin perlu menggabungkan keduanya?  Keputusan ini harus dibuat terlepas dari alasan untuk memparalelkan program, dan kinerja serta kejelasan kode secara signifikan tergantung pada seberapa sukses mereka.  Oleh karena itu, sangat penting untuk membayangkan opsi apa yang tersedia untuk membuat keputusan yang kompeten ketika mengembangkan struktur aplikasi.  Pada bagian ini, kami akan mempertimbangkan sejumlah metode untuk mendistribusikan tugas, mulai dengan distribusi data antara utas untuk melakukan pekerjaan lain. <br><br><h3>  8.1.1.  Distribusi data antar utas sebelum diproses </h3><br>  Yang paling mudah untuk diparalelkan adalah algoritma sederhana, seperti std :: for_each, yang melakukan operasi pada setiap elemen kumpulan data.  Untuk memparalelkan algoritma ini, Anda dapat menetapkan setiap elemen ke salah satu utas pemrosesan.  Di masa depan, ketika mempertimbangkan masalah kinerja, akan menjadi jelas bahwa opsi distribusi terbaik untuk mencapai kinerja yang optimal tergantung pada karakteristik struktur data. <br><br>  Saat mendistribusikan data, kasus paling sederhana adalah ketika elemen N pertama ditugaskan ke satu aliran, elemen N berikutnya ke yang lain, dan seterusnya (Gbr. 8.1), tetapi skema lain dapat digunakan.  Terlepas dari metode distribusi data, setiap utas hanya memproses elemen yang ditugaskan padanya, tanpa berinteraksi dengan utas lainnya hingga selesai diproses. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ie/ex/rm/ieexrmf49u6qerfqmuhtcgpbgpe.png" alt="gambar"></div><br>  Struktur harus akrab bagi siapa saja yang telah <a href="http://www.mpi-forum.org/">bekerja</a> dengan pemrograman di dalam Message Passing Interface (MPI, <a href="http://www.mpi-forum.org/">www.mpi-forum.org</a> ) atau lingkungan OpenMP (http://www.openmp.org/): tugas dibagi menjadi banyak tugas yang dieksekusi secara paralel, alur kerja menjalankannya secara independen satu sama lain, dan hasilnya dikumpulkan pada tahap akhir informasi.  Pendekatan ini digunakan dalam contoh dengan fungsi akumulasi dari bagian 2.4: baik tugas paralel maupun tahap reduksi adalah akumulasi.  Untuk algoritma for_each yang sederhana, langkah terakhir tidak ada, karena tidak ada yang dikurangi. <br><br>  Fakta bahwa campuran didefinisikan sebagai esensi dari tahap akhir memainkan peran yang sangat penting: implementasi dasar mirip dengan yang ditunjukkan pada Listing 2.9 akan melakukan campuran ini sebagai tahap sekuensial akhir.  Tetapi seringkali tahap ini juga diparalelkan: akumulasi adalah operasi pengurangan, sehingga kode pada Listing 2.9 dapat diubah untuk mendapatkan panggilan rekursif dari kode yang sama ketika, misalnya, jumlah utas lebih besar daripada jumlah minimum elemen yang diproses oleh utas.  Anda juga dapat memaksa alur kerja untuk melakukan langkah-langkah rollup segera setelah masing-masing menyelesaikan tugas mereka, daripada memulai utas baru setiap kali. <br><br>  Untuk semua efektivitasnya, teknik ini tidak serbaguna.  Terkadang data tidak dapat dibagi secara akurat sebelumnya, karena komposisi setiap bagian hanya diketahui selama pemrosesan.  Secara khusus, ini terbukti ketika menggunakan algoritma rekursif seperti Quicksort, sehingga mereka membutuhkan pendekatan yang berbeda. <br><br><h3>  8.1.2.  Distribusi data rekursif </h3><br>  Algoritme Quicksort memiliki dua tahap utama: memecah data menjadi dua bagian - segala sesuatu yang muncul ke salah satu elemen (referensi), dan segala sesuatu yang datang setelahnya dalam urutan akhir, dan penyortiran rekursif dari kedua bagian ini.  Tidak mungkin untuk memparalelasinya dengan memisahkan data awal, karena dimungkinkan untuk menentukan "setengah" mana yang termasuk dalam pemrosesan elemen.  Jika Anda bermaksud untuk memparalelkan algoritma ini, Anda perlu menggunakan esensi rekursi.  Pada setiap tingkat rekursi, semakin banyak panggilan ke fungsi quick_sort dilakukan, karena Anda harus mengurutkan keduanya yang lebih besar dari referensi dan yang lebih kecil dari itu.  Panggilan rekursif ini tidak tergantung satu sama lain karena merujuk pada set elemen yang terpisah.  Karena itu, mereka adalah kandidat pertama untuk daya saing.  Distribusi rekursif ini ditunjukkan pada Gambar.  8.2. <br><br>  Implementasi ini sudah dipenuhi di Bab 4. Alih-alih membuat dua panggilan rekursif untuk bagian yang lebih besar dan lebih kecil, kami menggunakan fungsi std :: async (), yang menjalankan tugas asinkron untuk setengah yang lebih kecil di setiap langkah.  Karena penggunaan std :: async (), Perpustakaan C ++ Thread harus memutuskan kapan memulai tugas di utas baru, dan kapan - dalam mode sinkron. <br><br>  Ada satu keadaan penting: saat menyortir kumpulan data besar, memulai utas baru untuk setiap rekursi akan mengarah pada peningkatan cepat dalam jumlah utas.  Saat memeriksa masalah kinerja, akan ditampilkan bahwa terlalu banyak utas dapat memperlambat aplikasi.  Selain itu, dengan sejumlah besar aliran data mungkin tidak cukup.  Gagasan untuk membagi seluruh tugas dalam mode rekursif seperti ini tampaknya sangat berhasil, Anda hanya perlu memantau jumlah utas secara cermat.  Dalam kasus sederhana, fungsi std :: async () menangani ini, tetapi ada opsi lain. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ji/l3/rzjil3fye0-nfj2quxo75cvxon4.png" alt="gambar"></div><br>  Salah satunya adalah dengan menggunakan fungsi std :: thread :: hardware_concurrency () untuk memilih jumlah utas, seperti yang dilakukan dalam versi paralel fungsi akumulasi () dari Listing 2.9.  Kemudian, alih-alih memulai utas baru untuk setiap panggilan rekursif, Anda dapat menempatkan fragmen untuk diurutkan pada tumpukan aman-benang, misalnya, seperti yang dibahas dalam bab 6 dan 7. Jika utas tidak ada hubungannya atau telah selesai memproses semua fragmennya atau sedang menunggu fragmen diurutkan, ia dapat ambil satu fragmen dari tumpukan dan urutkan. <br><br>  Listing 8.1 menunjukkan implementasi sederhana dari teknologi ini.  Seperti dalam kebanyakan contoh lain, itu hanya menunjukkan maksud, dan bukan kode yang siap untuk penggunaan praktis.  Jika Anda menggunakan kompiler C ++ 17 dan perpustakaan Anda mendukungnya, Anda harus menggunakan algoritma paralel yang disediakan oleh perpustakaan standar sesuai dengan deskripsi yang diberikan pada bab 10. <br><br>  Daftar 8.1.  Algoritma Quicksort paralel yang menggunakan tumpukan fragmen menunggu penyortiran <br><br><img src="https://habrastorage.org/webt/ko/nb/h6/konbh6b_q40lp0uz-gxyunwws3g.png" alt="gambar"><br><img src="https://habrastorage.org/webt/5s/md/52/5smd5279wgwzktq4thil54lidqy.png" alt="gambar"><br><img src="https://habrastorage.org/webt/ro/js/kt/rojsktncuxgmls2wtndzt9ywhqy.png" alt="gambar"><br><br>  Di sini, fungsi parallel_quick_sort <b>(19)</b> menempatkan sebagian besar tanggung jawab fungsional pada kelas sorter <b>(1)</b> , yang menyediakan cara mudah untuk mengelompokkan tumpukan fragmen yang tidak disortir <b>(2)</b> dan beberapa utas <b>(3)</b> .  Pekerjaan utama dilakukan dalam fungsi komponen do_sort <b>(9)</b> , yang ditempati oleh partisi data biasa <b>(10)</b> .  Kali ini, alih-alih memulai utas baru untuk setiap fragmen, ia mendorong fragmen ini pada tumpukan (11) dan memulai utas baru hanya jika ada sumber daya prosesor gratis (12).  Karena sebuah fragmen dengan nilai yang lebih rendah dari referensi yang dapat diproses oleh aliran lain, kita harus menunggu kesiapannya <b>(13)</b> .  Agar waktu tidak terbuang (jika kami memiliki satu utas atau semua utas lainnya sudah terisi), upaya dilakukan untuk memproses fragmen dari tumpukan untuk periode tunggu ini <b>(14)</b> .  Fungsi try_sort_chunk mengambil fragmen dari stack <b>(7)</b> , mengurutkannya <b>(8),</b> dan menyimpan hasilnya dalam janji janji sehingga mereka dapat menerima aliran yang meletakkan fragmen ini di stack <b>(15)</b> . <br><br>  Sekarang, utas yang baru saja diluncurkan berada dalam satu lingkaran dan mencoba untuk mengurutkan fragmen dari tumpukan <b>(17)</b> jika flag end_of_data <b>(16)</b> tidak disetel.  Di antara pemeriksaan, mereka menyerahkan sumber daya komputasi ke utas lain sehingga mereka dapat mendorong pekerjaan tambahan ke tumpukan.  Pekerjaan kode dalam hal menempatkan thread ini dalam urutan tergantung pada destructor kelas penyortir Anda <b>(4)</b> .  Ketika semua data diurutkan, fungsi do_sort akan mengembalikan kontrol (bahkan sambil mempertahankan aktivitas utas pekerja), utas utama akan kembali dari parallel_quick_sort <b>(20)</b> dan menghancurkan objek sorter.  Ini akan mengatur flag end_of_data <b>(5)</b> dan akan menunggu utasnya selesai bekerja <b>(6).</b> Mengatur bendera akan menghentikan loop pada fungsi utas (16). <br><br>  Dengan pendekatan ini, masalah jumlah utas yang tidak terbatas yang melekat pada fungsi spawn_task yang meluncurkan utas baru akan menghilang dan ketergantungan pada pustaka utas C ++, yang memilih jumlah utas untuk Anda, seperti halnya ketika menggunakan std :: async (), akan menghilang.  Sebagai gantinya, untuk mencegah pengalihan tugas terlalu sering, jumlah utas dibatasi oleh nilai yang dikembalikan oleh fungsi std :: thread :: hardware_concurrency ().  Tetapi masalah lain muncul: mengelola aliran ini dan bertukar data di antara mereka sangat menyulitkan kode.  Selain itu, terlepas dari kenyataan bahwa thread memproses elemen data individual, semuanya mengakses stack, menambahkan fragmen baru ke dalamnya dan mengambil fragmen untuk diproses.  Persaingan yang ketat seperti itu dapat mengurangi kinerja, bahkan jika tumpukan bebas kunci (karenanya, non-pemblokiran) digunakan, dan alasannya akan segera dipertimbangkan. <br><br>  Pendekatan ini adalah versi khusus dari kumpulan utas - satu set utas, yang masing-masing menerima pekerjaan dari daftar pekerjaan yang ditangguhkan, melaksanakannya, dan kemudian beralih ke daftar untuk yang baru.  Beberapa potensi masalah yang melekat pada kumpulan thread (termasuk kompetisi ketika mengakses daftar karya), dan cara untuk menyelesaikannya dibahas pada Bab 9. Tentang penskalaan aplikasi yang dibuat sehingga dijalankan pada beberapa prosesor, kita akan membahas bab ini nanti (lihat ayat 8.2.1). <br><br>  Saat mendistribusikan data baik sebelum pemrosesan maupun dalam mode rekursif, diasumsikan bahwa data tersebut diperbaiki terlebih dahulu, dan pencarian sedang dilakukan untuk distribusi mereka.  Tetapi ini tidak selalu terjadi: jika data dibuat dalam mode dinamis atau berasal dari sumber eksternal, pendekatan ini tidak berfungsi.  Dalam hal ini, mungkin lebih masuk akal untuk mendistribusikan pekerjaan sesuai dengan jenis tugas, dan tidak berdasarkan data itu sendiri. <br><br><h3>  8.1.3.  Distribusi pekerjaan berdasarkan jenis tugas </h3><br>  Distribusi pekerjaan antar utas dengan menugaskan masing-masing (di muka atau secara rekursif selama pemrosesan data) bagian-bagian data yang berbeda dalam hal apa pun didasarkan pada asumsi bahwa utas akan melakukan pekerjaan yang sama pada setiap bagian.  Distribusi alternatif pekerjaan adalah spesialisasi aliran, di mana masing-masing melakukan tugas yang terpisah, karena tukang ledeng dan listrik melakukan tugas yang berbeda dalam membangun rumah.  Streaming dapat bekerja dengan data yang berbeda atau sama, tetapi dalam kasus terakhir mereka melakukannya untuk tujuan yang berbeda. <br><br>  Pembagian kerja yang aneh ini muncul sebagai akibat dari pemisahan tugas dengan bantuan persaingan: masing-masing utas memiliki tugas yang terpisah, yang ia lakukan secara independen dari aliran lain.  Terkadang utas lainnya dapat mengirimkan data ke arus atau menghasilkan acara yang harus ditanggapi, tetapi secara umum, setiap aliran berkonsentrasi pada kinerja berkualitas tinggi dari satu tugas.  Ini adalah desain dasar yang baik, di mana setiap bagian kode harus bertanggung jawab atas satu hal. <br><br><h3>  Distribusi pekerjaan berdasarkan jenis tugas untuk berbagi tanggung jawab </h3><br>  Aplikasi single-threaded harus mengatasi konflik yang terkait dengan prinsip tanggung jawab tunggal, ketika ada beberapa tugas yang harus dilakukan terus menerus untuk waktu tertentu, atau aplikasi harus mengatasi pemrosesan peristiwa yang masuk secara tepat waktu (misalnya, pengguna menekan kunci atau data masuk melalui jaringan) di hadapan tugas-tugas lain yang belum selesai.  Dalam lingkungan komputasi single-threaded, Anda harus secara independen membuat kode yang menjalankan bagian dari tugas A, bagian dari tugas B, memeriksa untuk melihat apakah kunci ditekan dan tidak ada paket jaringan, dan kemudian secara siklus kembali ke bagian berikutnya dari tugas A. Ini mempersulit kode untuk mengeksekusi tugas A karena kebutuhan untuk mempertahankan keadaannya dan secara berkala mengembalikan kontrol ke loop utama.  Jika Anda menambahkan terlalu banyak tugas ke siklus, pekerjaan dapat melambat secara signifikan dan pengguna mungkin akan melihat reaksi lambat terhadap penekanan tombol.  Saya yakin bahwa setiap orang mengamati manifestasi ekstrem dari situasi serupa di aplikasi tertentu: Anda menetapkan tugas untuk aplikasi tersebut, dan antarmuka tidak bereaksi terhadap apa pun sampai selesai. <br><br>  Di sini mengalir ke atas panggung.  Jika Anda menjalankan setiap tugas dalam utas terpisah, maka sistem operasi dapat melakukan ini sebagai ganti Anda.  Dalam kode untuk tugas A, Anda bisa fokus menyelesaikan tugas tanpa khawatir mempertahankan status dan kembali ke loop utama, atau tentang berapa banyak waktu yang akan berlalu sebelum ini terjadi.  Artinya, sistem operasi akan secara otomatis menyimpan status dan beralih ke tugas B atau C pada waktu yang tepat, dan jika sistem tempat program akan dijalankan memiliki beberapa inti atau prosesor, akan dimungkinkan untuk secara bersamaan menjalankan tugas A dan B. Kode untuk memproses penekanan tombol atau tanda terima paket jaringan sekarang dapat dieksekusi tepat waktu, dan semua orang akan mendapat manfaat: pengguna akan menerima respons program yang memadai, dan Anda, sebagai pengembang, akan menerima kode yang disederhanakan, karena setiap aliran dapat diarahkan  untuk melakukan operasi yang terkait langsung dengan tugasnya, tanpa mencampurkannya dengan aliran kontrol dan interaksi pengguna. <br><br>  Gambaran ideal muncul.  Tapi bisakah semuanya menjadi seperti itu?  Seperti biasa, semuanya tergantung pada keadaan tertentu.  Jika independensi penuh dihormati dan arus tidak perlu saling bertukar data, maka itulah yang akan terjadi.  Sayangnya, situasi serupa jarang diamati.  Seringkali, tindakan yang diperlukan untuk pengguna memiliki bentuk tugas latar belakang yang mudah, dan mereka perlu memberi tahu pengguna tentang tugas tersebut, memperbarui antarmuka pengguna dalam beberapa cara.  Atau pengguna mungkin perlu menghentikan tugas, sehingga antarmuka pengguna harus entah bagaimana mengirim pesan ke tugas latar belakang, menyebabkannya berhenti dieksekusi.  Dalam kedua kasus, perlu untuk mempertimbangkan desain dan sinkronisasi yang tepat, tetapi tugas yang dilakukan akan tetap terfragmentasi.  Utas antarmuka pengguna masih mengontrol antarmuka ini, tetapi mungkin ditugaskan untuk melakukan pembaruan atas permintaan utas lainnya.  Utas yang mengimplementasikan tugas latar masih berkonsentrasi pada operasi yang diperlukan untuk menyelesaikannya, juga terjadi bahwa salah satu utas latar memungkinkan tugas untuk menghentikan utas lainnya.  Dalam kedua kasus, arus tidak peduli dari mana permintaan itu berasal, mereka hanya peduli pada fakta bahwa permintaan itu dirancang untuk mereka dan secara langsung berkaitan dengan tanggung jawab mereka. <br><br>  Ada dua bahaya serius dalam berbagi tanggung jawab di antara banyak utas.  Pertama, mungkin ternyata tanggung jawab yang tidak pantas didistribusikan.  Tanda ini adalah terlalu banyak data yang dibagikan oleh stream, atau fakta bahwa stream yang berbeda harus menunggu satu sama lain.          .      .        , , ,    ,             .   ,        ,     â€”   , ,        . <br><br>                .             ,     ,         . <br><br><h3>      </h3><br>                 ,            .      : ,     ,         . <br><br>            â€”        .   ,     ,      .   ,     ,       ,           . <br><br>      ,    8.1.1,   ,           . ,                  . <br><br>     ,        :    ,       . ,        20          ,      3 .      ,         .  ,   ,    ,  ,   12       ,  24  â€”   . .  20     .      .         .       , ,  ,   ,   12 . ,   12       ,        .      ,  :  ,   ,     ,  ,       ,        .      3         12 . <br><br>      ,    9 ,         .            . ,  ,      .          25   ,    â€”  .  ,       ,    : ,   100   ,  ,    1 ,    100 ,    1     100 .     ,  ,        .       ,     ,  , . <br><br>       ,    ,     ,   ,      . <br><br><h3> 8.2. ,      </h3><br>            ,  ,      .        ,  ,     .     ,       16      ,     . <br><br>    ,        â€”   ,    ,    (      ),      .          ,    :      ? <br><br><h3> 8.2.1.     ? </h3><br>  ( )     ,          .   ,    ,        ,          .     ,     .      ,     . ,         ,         (   )       .     ,   ,      ,            . <br><br>     16-       16  :          16 .    ,        16 .   ,    ,         (   ).    ,    16    ,      ,           ,      1.       (oversubscription). <br><br>          ,       ,    C++11 (Standard Thread Library)   std::thread::hardware_concurrency().             . <br><br>   std::thread::hardware_concurrency()    :       -  ,   ,        .   ,        ,  std::thread::hardware_concurrency(),     .  std::async()    ,           .           . <br><br>      ,    ,    ,      .              â€”   ,   ,     . ,     ,   ,       ,          C++.   ,     std::async(),       ,   ,    .       ,     .   ,      ,      std::thread::hardware_concurrency(),     .      ,      ,  ,    . <br><br>       ,                 .          ,     ,      ,    ,        . <br><br>         ,        â€”          . <br><br>  Â»Informasi lebih lanjut tentang buku ini dapat ditemukan di <a href="https://www.piter.com/collection/new/product/c-praktika-mnogopotochnogo-programmirovaniya%3F_gs_cttl%3D120%255E_%255Eamp%255E_%255Egs_direct_link%3D1%255E_%255Eamp%255E_%255Egsaid%3D82744%255E_%255Eamp%255E_%255Egsmid%3D29789%255E_%255Eamp%255E_%255Egstid%3Dc">situs web penerbit</a> <br>  Â» <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_X.pdf">Isi</a> <br>  Â» <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_p.pdf">Kutipan</a> <br><br>    25%   â€” <b>C++</b> <br><br>  Setelah pembayaran versi kertas buku, sebuah buku elektronik dikirim melalui email. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id484818/">https://habr.com/ru/post/id484818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id484804/index.html">Apa yang harus dienkripsi dalam sistem perusahaan? Dan mengapa melakukan ini?</a></li>
<li><a href="../id484806/index.html">Perbedaan antara cPanel dan Plesk Obsidian</a></li>
<li><a href="../id484812/index.html">Pengalaman saya dengan Plesk</a></li>
<li><a href="../id484814/index.html">6. Fortinet Memulai v6.0. Penyaringan Web dan Kontrol Aplikasi</a></li>
<li><a href="../id484816/index.html">Menggunakan kait operasi untuk membuat cadangan file pada macOS dengan cepat</a></li>
<li><a href="../id484820/index.html">FAQ.Net - program pencatatan gratis untuk Windows dengan desain yang diperbarui</a></li>
<li><a href="../id484822/index.html">Blazor: cara mencegah komponen agar tidak sakit atau dua pendekatan untuk memisahkan kode dari markup</a></li>
<li><a href="../id484824/index.html">Perang untuk mematikan lampu</a></li>
<li><a href="../id484826/index.html">Kecerdasan buatan memperburuk kedokteran yang buruk bahkan lebih</a></li>
<li><a href="../id484834/index.html">Bagaimana membangun strategi perusahaan untuk pelatihan dan pengembangan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
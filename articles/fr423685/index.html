<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç¥ üë©üèæ‚Äçü§ù‚Äçüë©üèΩ ü•ù Concurrence PostgreSQL: pas sph√©rique, pas cheval, pas dans le vide üíΩ üë®üèæ‚Äçüé§ üë§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La mise √† l'√©chelle d'un SGBD est un avenir en constante √©volution. Les SGBD s'am√©liorent et √©voluent mieux sur les plates-formes mat√©rielles, tandis ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Concurrence PostgreSQL: pas sph√©rique, pas cheval, pas dans le vide</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/423685/"><img src="https://habrastorage.org/webt/b0/s3/rq/b0s3rqkffufh7baruji0jc_vbgq.jpeg"><br><br>  La mise √† l'√©chelle d'un SGBD est un avenir en constante √©volution.  Les SGBD s'am√©liorent et √©voluent mieux sur les plates-formes mat√©rielles, tandis que les plates-formes mat√©rielles elles-m√™mes augmentent la productivit√©, le nombre de c≈ìurs et la m√©moire - Achilles rattrape la tortue, mais ne l'a toujours pas fait.  Le probl√®me de la mise √† l'√©chelle du SGBD bat son plein. <br><br>  Postgres Professional avait un probl√®me avec la mise √† l'√©chelle non seulement th√©oriquement, mais aussi pratiquement: avec ses clients.  Et plus d'une fois.  Un de ces cas sera discut√© dans cet article. <br><br>  PostgreSQL √©volue bien sur les syst√®mes NUMA s'il s'agit d'une seule carte m√®re avec plusieurs processeurs et plusieurs bus de donn√©es.  Quelques optimisations peuvent √™tre lues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Cependant, il existe une autre classe de syst√®mes, ils ont plusieurs cartes m√®res, dont l'√©change de donn√©es s'effectue via une interconnexion, tandis qu'une instance du syst√®me d'exploitation fonctionne sur eux et pour l'utilisateur, cette conception ressemble √† une seule machine.  Et bien que formellement, ces syst√®mes puissent √©galement √™tre attribu√©s √† NUMA, mais ils sont essentiellement plus proches des superordinateurs, comme  l'acc√®s √† la m√©moire locale du n≈ìud et l'acc√®s √† la m√©moire du n≈ìud voisin diff√®rent radicalement.  La communaut√© PostgreSQL estime que la seule instance Postgres ex√©cut√©e sur de telles architectures est une source de probl√®mes, et il n'y a pas encore d'approche syst√©matique pour les r√©soudre. <br><a name="habracut"></a><br>  En effet, l'architecture logicielle utilisant la m√©moire partag√©e est fondamentalement con√ßue pour le fait que le temps d'acc√®s des diff√©rents processus √† leur m√©moire propre et distante est plus ou moins comparable.  Dans le cas o√π nous travaillons avec de nombreux n≈ìuds, le pari sur la m√©moire partag√©e en tant que canal de communication rapide cesse de se justifier, car en raison de la latence, il est beaucoup "moins cher" d'envoyer une demande pour effectuer une certaine action sur le n≈ìud (n≈ìud) o√π des donn√©es int√©ressantes que d'envoyer ces donn√©es sur le bus.  Par cons√©quent, pour les supercalculateurs et, en g√©n√©ral, les syst√®mes √† nombreux n≈ìuds, les solutions de cluster sont pertinentes. <br><br>  Cela ne signifie pas qu'il faut mettre un terme √† la combinaison de syst√®mes multi-n≈ìuds et d'une architecture de m√©moire partag√©e Postgres classique.  Apr√®s tout, si les processus postgres passent la plupart de leur temps √† effectuer des calculs complexes localement, cette architecture sera m√™me tr√®s efficace.  Dans notre situation, le client avait d√©j√† achet√© un puissant serveur multi-n≈ìuds, et nous devions y r√©soudre les probl√®mes de PostgreSQL. <br><br>  Mais les probl√®mes √©taient s√©rieux: les demandes d'√©criture les plus simples (changer plusieurs valeurs de champ dans un enregistrement) ont √©t√© ex√©cut√©es en quelques minutes √† une heure.  Comme il a √©t√© confirm√© par la suite, ces probl√®mes se sont manifest√©s dans toute leur splendeur pr√©cis√©ment en raison du grand nombre de c≈ìurs et, par cons√©quent, du parall√©lisme radical dans l'ex√©cution des requ√™tes avec un √©change relativement lent entre les n≈ìuds. <br><br>  Par cons√©quent, l'article se r√©v√©lera, pour ainsi dire, √† deux fins: <br><br><ul><li>  Partager l'exp√©rience: que faire si dans un syst√®me √† plusieurs n≈ìuds la base de donn√©es ralentit s√©rieusement.  Par o√π commencer, comment diagnostiquer o√π aller. </li><li>  D√©crivez comment les probl√®mes du SGBD PostgreSQL lui-m√™me peuvent √™tre r√©solus avec un niveau de concurrence √©lev√©.  Notamment comment la modification de l'algorithme de prise de verrous affecte les performances de PostgreSQL. </li></ul><br><h3>  Serveur et DB </h3><br>  Le syst√®me √©tait compos√© de 8 lames avec 2 prises chacune.  Au total, plus de 300 c≈ìurs (hors hypertreading).  Un pneu rapide (technologie propri√©taire du fabricant) relie les pales.  Ce n'est pas un supercalculateur, mais pour une instance du SGBD, la configuration est impressionnante. <br>  La charge est √©galement assez importante.  Plus d'un t√©raoctet de donn√©es.  Environ 3000 transactions par seconde.  Plus de 1000 connexions aux postgres. <br><br>  Ayant commenc√© √† faire face aux attentes d'enregistrement horaire, la premi√®re chose que nous avons faite a √©t√© d'√©crire sur le disque comme cause de retards.  D√®s que des retards incompr√©hensibles ont commenc√©, les tests ont commenc√© √† se faire exclusivement sur <code>tmpfs</code> .  L'image n'a pas chang√©.  Le disque n'y est pour rien. <br><br><h3>  Prise en main des diagnostics: vues </h3><br>  Les probl√®mes √©tant probablement dus √† la forte concurrence des processus qui ¬´frappent¬ª les m√™mes objets, la premi√®re chose √† v√©rifier est les verrous.  Dans PostgreSQL, il existe une vue <code>pg.catalog.pg_locks</code> et <code>pg_stat_activity</code> pour une telle v√©rification.  Le second, d√©j√† dans la version 9.6, a ajout√© des informations sur ce que le processus attend ( <i>Amit Kapila, Ildus Kurbangaliev</i> ) - <code>wait_event_type</code> .  Les valeurs possibles pour ce champ sont d√©crites <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Mais d'abord, comptez: <br><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># SELECT COUNT(*) FROM pg_locks; count ‚Äî---‚Äî 88453 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity; count ‚Äî---‚Äî 1826 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity WHERE state ='active'; count ‚Äî---‚Äî 1005</span></span></code> </pre> <br>  Ce sont de vrais chiffres.  Atteint jusqu'√† 200 000 verrous. <br>  Dans le m√™me temps, de tels verrous √©taient suspendus √† la demande malheureuse: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_locks <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> pid =<span class="hljs-number"><span class="hljs-number">580707</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>; count | mode ‚Äî<span class="hljs-comment"><span class="hljs-comment">-----+---------------‚Äî 93 | AccessShareLock 1 | ExclusiveLock</span></span></code> </pre> <br>  Lors de la lecture du tampon, le SGBD utilise le verrouillage de <code>share</code> , tout en √©crivant - <code>exclusive</code> .  Autrement dit, les verrous en √©criture repr√©sentaient moins de 1% de toutes les demandes. <br>  Dans la vue <code>pg_locks</code> , les types de verrous ne ressemblent pas toujours √† ceux d√©crits <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans la documentation</a> utilisateur. <br><br>  Voici la plaque d'allumettes: <br><br><pre> <code class="plaintext hljs">AccessShareLock = LockTupleKeyShare RowShareLock = LockTupleShare ExclusiveLock = LockTupleNoKeyExclusive AccessExclusiveLock = LockTupleExclusive</code> </pre> <br>  La requ√™te SELECT mode FROM pg_locks a montr√© que CREATE INDEX (sans CONCURRENTLY) attendrait 234 INSERTs et 390 INSERTs pour le <code>buffer content lock</code> .  Une solution possible consiste √† ¬´apprendre¬ª aux INSERT de diff√©rentes sessions √† se croiser moins dans les tampons. <br><br><h3>  Il est temps d'utiliser la perf </h3><br>  L'utilitaire <b><code>perf</code></b> collecte de nombreuses informations de diagnostic.  En mode <code>record</code> ... il √©crit les statistiques des √©v√©nements syst√®me dans des fichiers (par d√©faut, ils sont en <code>./perf_data</code> ), et en mode <code>report</code> , il analyse les donn√©es collect√©es, par exemple, vous pouvez filtrer les √©v√©nements qui ne concernent que les <code>postgres</code> ou un <code>pid</code> donn√©: <br><br><pre> <code class="plaintext hljs">$ perf record -u postgres  $ perf record -p 76876  ,  $ perf report &gt; ./my_results</code> </pre> <br>  En cons√©quence, nous verrons quelque chose comme <br><br><img src="https://habrastorage.org/webt/rn/ta/rv/rntarvj2jticq7glciiqockk3-y.jpeg"><br><br>  Comment utiliser <code>perf</code> pour diagnostiquer PostgreSQL est d√©crit, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , ainsi que dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wiki pg</a> . <br><br>  Dans notre cas, m√™me le mode le plus simple a donn√© des informations importantes √† <code>perf top</code> - <code>perf top</code> , qui fonctionne, bien s√ªr, dans l'esprit du syst√®me d'exploitation le <code>top</code> performant.  Avec <code>perf top</code> nous avons vu que la plupart du temps, le processeur passe dans les <code>PinBuffer()</code> base, ainsi que dans les fonctions <code>PinBuffer()</code> et <code>LWLockAttemptLock().</code>  . <br><br>  <code>PinBuffer()</code> est une fonction qui augmente le compteur de r√©f√©rences au tampon (mappage d'une page de donn√©es √† la RAM), gr√¢ce √† laquelle les processus postgres savent quels tampons peuvent √™tre forc√©s et lesquels ne le peuvent pas. <br><br>  <code>LWLockAttemptLock()</code> - <code>LWLock</code> de capture de <code>LWLock</code> .  <code>LWLock</code> est une sorte de verrou avec deux niveaux de <code>shared</code> et d' <code>exclusive</code> , sans d√©finir d' <code>deadlock</code> , les verrous sont pr√©-allou√©s √† <code>shared memory</code> , les processus en attente attendent dans une file d'attente. <br><br>  Ces fonctions ont d√©j√† √©t√© s√©rieusement optimis√©es dans PostgreSQL 9.5 et 9.6.  Les verrous √† l'int√©rieur d'eux ont √©t√© remplac√©s par l'utilisation directe des op√©rations atomiques. <br><br><h3>  Graphes de flamme </h3><br>  C‚Äôest impossible sans eux: m√™me s‚Äôils √©taient inutiles, il vaudrait quand m√™me la peine d‚Äôen parler - ils sont d‚Äôune beaut√© exceptionnelle.  Mais ils sont utiles.  Voici une illustration de <code>github</code> , pas de notre cas (ni nous ni le client ne sommes encore pr√™ts √† divulguer les d√©tails). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75b/909/e8d/75b909e8de5177a48fa7d73f53eff437.svg"><br><br>  Ces belles images montrent tr√®s clairement ce que prennent les cycles du processeur.  Le m√™me <code>perf</code> peut collecter des donn√©es, mais le <code>flame graph</code> visualise intelligemment les donn√©es et construit des arbres bas√©s sur les piles d'appels collect√©es.  Vous pouvez en savoir plus sur le profilage avec des graphiques de flamme, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , et t√©l√©charger tout ce dont vous avez besoin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Dans notre cas, une √©norme quantit√© de <code>nestloop</code> √©tait visible sur les graphiques de flamme.  Apparemment, les jointures d'un grand nombre de tables dans de nombreuses demandes de lecture simultan√©es ont provoqu√© un grand nombre de verrous de <code>access share</code> . <br><br>  Les statistiques collect√©es par <code>perf</code> montrent o√π vont les cycles du processeur.  Et bien que nous ayons vu que la plupart du temps du processeur passe sur les verrous, nous n'avons pas vu ce qui conduit exactement √† de si longues attentes en mati√®re de verrous, car nous ne voyons pas exactement o√π les attentes de verrouillage se produisent, car  Le temps CPU n'est pas perdu √† attendre. <br><br>  Afin de voir les attentes elles-m√™mes, vous pouvez cr√©er une demande √† la vue syst√®me <code>pg_stat_activity</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> wait_event_type, wait_event, <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_activity <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> wait_event_type, wait_event;</code> </pre> <br>  a r√©v√©l√© que: <br><br><pre> <code class="plaintext hljs">LWLockTranche | buffer_content | UPDATE ************* LWLockTranche | buffer_content | INSERT INTO ******** LWLockTranche | buffer_content | \r | | insert into B4_MUTEX | | values (nextval('hib | | returning ID Lock | relation | INSERT INTO B4_***** LWLockTranche | buffer_content | UPDATE ************* Lock | relation | INSERT INTO ******** LWLockTranche | buffer_mapping | INSERT INTO ******** LWLockTranche | buffer_content | \r</code> </pre> <br>  (les ast√©risques ici remplacent simplement les d√©tails de la demande que nous ne divulguons pas). <br><br>  Vous pouvez voir les valeurs <code>buffer_content</code> (blocage du contenu des tampons) et <code>buffer_mapping</code> (blocage des composants de la plaque de hachage <code>shared_buffers</code> ). <br><br><h3>  Pour obtenir de l'aide sur gdb </h3><br>  Mais pourquoi tant d'attentes pour ces types de serrures?  Pour des informations plus d√©taill√©es sur les attentes, j'ai d√ª utiliser le d√©bogueur <code>GDB</code> .  Avec <code>GDB</code> nous pouvons obtenir une pile d'appels de processus sp√©cifiques.  En appliquant l'√©chantillonnage, c'est-√†-dire  Apr√®s avoir collect√© un certain nombre de piles d'appels al√©atoires, vous pouvez vous faire une id√©e des piles qui ont les attentes les plus longues. <br><br>  Consid√©rez le processus de compilation des statistiques.  Nous consid√©rerons la collecte ¬´manuelle¬ª de statistiques, bien que dans la vie r√©elle des scripts sp√©ciaux soient utilis√©s pour le faire automatiquement. <br><br>  Tout d'abord, <code>gdb</code> doit √™tre attach√© au processus PostgreSQL.  Pour ce faire, recherchez le <code>pid</code> processus serveur, par exemple <br><br><pre> <code class="plaintext hljs">$ ps aux | grep postgres</code> </pre> <br>  Disons que nous avons trouv√©: <br><br><pre> <code class="plaintext hljs">postgres 2025 0.0 0.1 172428 1240 pts/17  S   23  0:00 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data</code> </pre> <br>  et maintenant ins√©rez le <code>pid</code> dans le d√©bogueur: <br><br><pre> <code class="plaintext hljs">igor_le:~$gdb -p 2025</code> </pre> <br>  Une fois √† l'int√©rieur du d√©bogueur, nous √©crivons <code>bt</code> [c'est-√†-dire <code>backtrace</code> ] ou <code>where</code> .  Et nous obtenons beaucoup d'informations sur ce type: <br><br><pre> <code class="plaintext hljs">(gdb) bt #0 0x00007fbb65d01cd0 in __write_nocancel () from /lib64/libc.so.6 #1 0x00000000007c92f4 in write_pipe_chunks ( data=0x110e6e8 "2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [392‚Äê1] db=bp,user=bp,app=[unknown],client=192.168.70.163 (http://192.168.70.163) LOG: relation 23554 new block 493: 248.389503\n2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [393‚Äê1] db=bp,user=bp,app=["..., len=409, dest=dest@entry=1) at elog.c:3123 #2 0x00000000007cc07b in send_message_to_server_log (edata=0xc6ee60 &lt;errordata&gt;) at elog.c:3024 #3 EmitErrorReport () at elog.c:1479</code> </pre> <br>  Apr√®s avoir collect√© des statistiques, y compris des piles d'appels de tous les processus postgres, collect√©es √† plusieurs reprises √† diff√©rents moments, nous avons vu que le <code>buffer partition lock</code> √† l'int√©rieur du <code>relation extension lock</code> dur√© 3706 secondes (environ une heure), c'est-√†-dire qu'il se verrouille sur un morceau de la table de hachage du tampon , qui √©tait n√©cessaire pour remplacer l'ancien tampon, afin de le remplacer par la suite par un nouveau correspondant √† la partie √©tendue de la table.  Un certain nombre de verrous de <code>buffer content lock</code> de <code>buffer content lock</code> √©taient √©galement perceptibles, ce qui correspondait √† l'attente de verrouillage des pages de l'index de l' <code>B-tree</code> pour l'insertion. <br><br><img src="https://habrastorage.org/webt/6c/y6/cw/6cy6cwmfye29jw84dkzoabjlgvg.jpeg"><br><br>  Au d√©but, deux explications sont venues pour un temps d'attente aussi monstrueux: <br><br><ul><li>  Quelqu'un d'autre a pris ce <code>LWLock</code> et est rest√©.  Mais c'est peu probable.  Parce que rien de compliqu√© ne se passe √† l'int√©rieur du verrou de partition tampon. </li><li>  Nous avons rencontr√© un comportement pathologique de <code>LWLock</code> .  Autrement dit, malgr√© le fait que personne n'a pris le verrou trop longtemps, son attente a dur√© trop longtemps. </li></ul><br><h3>  Patchs de diagnostic et traitement des arbres </h3><br>  En r√©duisant le nombre de connexions simultan√©es, nous d√©chargerions probablement le flux de demandes de verrous.  Mais ce serait comme se rendre.  Au lieu de cela, <i>Alexander Korotkov</i> , l'architecte en chef de Postgres Professional (bien s√ªr, il a aid√© √† pr√©parer cet article), a propos√© une s√©rie de correctifs. <br><br>  Tout d'abord, il √©tait n√©cessaire d'avoir une image plus d√©taill√©e de la catastrophe.  Peu importe la qualit√© des outils finis, les correctifs de diagnostic de leur propre fabrication seront √©galement utiles. <br><br>  Un correctif a √©t√© √©crit qui ajoute une journalisation d√©taill√©e du temps pass√© dans l' <code>relation extension</code> , ce qui se passe √† l'int√©rieur de la fonction <code>RelationAddExtraBlocks()</code> . Nous d√©couvrons donc ce que le temps est pass√© √† l'int√©rieur de <code>RelationAddExtraBlocks().</code> <br><br>  Et √† l'appui de lui, un autre correctif a √©t√© √©crit dans <code>pg_stat_activity</code> sur ce que nous faisons maintenant en ce qui <code>relation extension</code> .  Cela a √©t√© fait de cette fa√ßon: lorsque la <code>relation</code> d√©veloppe, <code>application_name</code> devient <code>RelationAddExtraBlocks</code> .  Ce processus est d√©sormais facilement analys√© avec un maximum de d√©tails √† l'aide de <code>gdb bt</code> et <code>perf</code> . <br><br>  En fait, les correctifs m√©dicaux (et non diagnostiques) ont √©t√© √©crits deux fois.  Le premier correctif a chang√© le comportement des verrous de feuille de <code>B‚Äêtree</code> : auparavant, lors de la demande d'insertion, la feuille √©tait bloqu√©e en tant que <code>share</code> , puis elle devenait <code>exclusive</code> .  Maintenant, il devient imm√©diatement <code>exclusive</code> .  Maintenant, ce correctif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">a d√©j√† √©t√© valid√©</a> pour <b>PostgreSQL 12</b> .  Heureusement, cette ann√©e, <i>Alexander Korotkov a</i> re√ßu le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">statut de committer</a> - le deuxi√®me committer PostgreSQL en Russie et le second dans l'entreprise. <br><br>  La valeur <code>NUM_BUFFER_PARTITIONS</code> a √©galement √©t√© augment√©e de 128 √† 512 pour r√©duire la charge sur les verrous de mappage: la table de hachage du gestionnaire de tampons a √©t√© divis√©e en morceaux plus petits, dans l'espoir que la charge sur chaque pi√®ce sp√©cifique soit r√©duite. <br><br>  Apr√®s avoir appliqu√© ce correctif, les verrous sur le contenu des tampons ont disparu, mais malgr√© l'augmentation de <code>NUM_BUFFER_PARTITIONS</code> , <code>buffer_mapping</code> est rest√©, c'est-√†-dire que nous vous rappelons de bloquer des morceaux de la table de hachage du gestionnaire de tampons: <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping ----‚Äê‚Äê‚Äê--‚Äê‚Äê‚Äê+‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê------‚Äê‚Äê‚Äê 12549 | 1218 | 0 | 15</code> </pre> <br>  Et m√™me ce n'est pas grand-chose.  B - l'arbre n'est plus un goulot d'√©tranglement.  L'extension du <code>heap-</code> est apparue. <br><br><h3>  Traitement de la conscience </h3><br>  Ensuite, Alexander a avanc√© l'hypoth√®se et la solution suivantes: <br><br>  Nous attendons beaucoup de temps sur le <code>buffer parittion lock</code> du <code>buffer parittion lock</code> lors de l' <code>buffer parittion lock</code> tampon.  Peut-√™tre sur le m√™me <code>buffer parittion lock</code> il y a une page tr√®s demand√©e, par exemple, la racine d'un <code>B‚Äêtree</code>  √Ä ce stade, il existe un flux continu de demandes de <code>shared lock</code> partir des demandes de lecture. <br><br>  La file d'attente √† <code>LWLock</code> ¬´pas juste¬ª.  √âtant donn√© que <code>shared lock</code> peuvent √™tre pris autant de fois que n√©cessaire, alors si le <code>shared lock</code> d√©j√† pris, les <code>shared lock</code> suivants passent sans file d'attente.  Ainsi, si le flux de verrous partag√©s est d'une intensit√© suffisante pour qu'il n'y ait pas de ¬´fen√™tres¬ª entre eux, alors l'attente d'un <code>exclusive lock</code> va presque √† l'infini. <br><br>  Pour r√©soudre ce probl√®me, vous pouvez essayer d'offrir - un patch de comportement "gentlemanly" des verrous.  Cela √©veille la conscience des <code>shared locker</code> et ils font honn√™tement la queue lorsqu'ils ont d√©j√† une <code>exclusive lock</code> (il est int√©ressant que les serrures lourdes - <code>hwlock</code> - n'aient pas de probl√®mes de conscience: elles font toujours la queue honn√™tement) <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping | reladdextra | inserts&gt;30sec ‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê--‚Äê-‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê------ 173985 | 1802 | 0 | 569 | 0 | 0</code> </pre> <br>  Tout va bien!  Il n'y a pas de longues <code>insert</code> .  Bien que les verrous sur les morceaux des plaques de hachage soient rest√©s.  Mais que faire, ce sont les propri√©t√©s des pneus de notre petit supercalculateur. <br><br>  Ce patch a √©galement √©t√© <a href="">offert √† la communaut√©</a> .  Mais quelle que soit l'√©volution du sort de ces correctifs dans la communaut√©, rien ne les emp√™che d'acc√©der aux prochaines versions de <b>Postgres Pro Enterprise</b> , con√ßues sp√©cifiquement pour les clients avec des syst√®mes lourdement charg√©s. <br><br><h3>  Moral </h3><br>  Des verrous de <code>share</code> l√©gers √† haute moralit√© - <code>exclusive</code> blocs <code>exclusive</code> sautent la file d'attente - ont r√©solu le probl√®me des retards horaires dans un syst√®me √† plusieurs n≈ìuds.  La balise de hachage du <code>buffer manager</code> n'a pas fonctionn√© en raison d'un flux de <code>share lock</code> trop important, ce qui n'a laiss√© aucune chance aux verrous n√©cessaires pour remplacer les anciens tampons et en charger de nouveaux.  Les probl√®mes avec l'extension du tampon pour les tables de base de donn√©es n'√©taient qu'une cons√©quence de cela.  Avant cela, il √©tait possible d'√©largir le goulot d'√©tranglement avec l'acc√®s √† la racine de l' <code>B-tree</code> <br><br>  PostgreSQL n'a pas √©t√© con√ßu pour les architectures NUMA et les superordinateurs.  L'adaptation √† de telles architectures Postgres est un travail √©norme qui n√©cessiterait (et √©ventuellement n√©cessiterait) les efforts coordonn√©s de nombreuses personnes et m√™me d'entreprises.  Mais les cons√©quences d√©sagr√©ables de ces probl√®mes architecturaux peuvent √™tre att√©nu√©es.  Et nous devons le faire: les types de charges qui ont entra√Æn√© des retards similaires √† ceux d√©crits sont assez typiques, des signaux de d√©tresse similaires provenant d'autres endroits continuent de nous parvenir.  Des probl√®mes similaires sont apparus plus t√¥t - sur les syst√®mes avec moins de c≈ìurs, seules les cons√©quences n'√©taient pas si monstrueuses et les sympt√¥mes ont √©t√© trait√©s avec d'autres m√©thodes et d'autres correctifs.  Maintenant, un autre m√©dicament est apparu - pas universel, mais clairement utile. <br><br>  Ainsi, lorsque PostgreSQL travaille avec la m√©moire de l'ensemble du syst√®me en tant que local, aucun bus √† grande vitesse entre les n≈ìuds ne peut se comparer au temps d'acc√®s √† la m√©moire locale.  Les t√¢ches surgissent √† cause de cela difficile, souvent urgent, mais int√©ressant.  Et l'exp√©rience de les r√©soudre est utile non seulement pour les d√©cisifs, mais aussi pour toute la communaut√©. <br><br><img src="https://habrastorage.org/webt/od/n1/sf/odn1sf_id7l60ezlyo-padxymmi.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr423685/">https://habr.com/ru/post/fr423685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr423671/index.html">Les rivaux de Tesla re√ßoivent un investissement d'un milliard de dollars de l'Arabie saoudite</a></li>
<li><a href="../fr423673/index.html">Risques li√©s au d√©veloppement de logiciels</a></li>
<li><a href="../fr423677/index.html">Pilotes Jetpack: Frankie West</a></li>
<li><a href="../fr423679/index.html">Une t√¢che avec un gratte-ciel et des ≈ìufs - pas la poubelle de Newton?</a></li>
<li><a href="../fr423683/index.html">Bas√© sur le bon sens: d√©velopper DevOps √† partir de z√©ro</a></li>
<li><a href="../fr423687/index.html">HyperX Pulsefire FPS Pro - plus rapide, plus m√©chant et plus abordable</a></li>
<li><a href="../fr423689/index.html">RTOS MAX - gratuit? Nous pr√©voyons d'ouvrir une licence pour une utilisation commerciale gratuite</a></li>
<li><a href="../fr423693/index.html">Une autre fa√ßon d'utiliser Webpack 4 et la s√©paration de code</a></li>
<li><a href="../fr423695/index.html">Comment prendre sa retraite avant 40 ans avec un million de dollars dans un compte bancaire</a></li>
<li><a href="../fr423697/index.html">Pr√©sentation de Spring Data JDBC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
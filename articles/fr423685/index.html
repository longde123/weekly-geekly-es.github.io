<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ´ ğŸ‘©ğŸ¾â€ğŸ¤â€ğŸ‘©ğŸ½ ğŸ¥ Concurrence PostgreSQL: pas sphÃ©rique, pas cheval, pas dans le vide ğŸ’½ ğŸ‘¨ğŸ¾â€ğŸ¤ ğŸ‘¤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La mise Ã  l'Ã©chelle d'un SGBD est un avenir en constante Ã©volution. Les SGBD s'amÃ©liorent et Ã©voluent mieux sur les plates-formes matÃ©rielles, tandis ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Concurrence PostgreSQL: pas sphÃ©rique, pas cheval, pas dans le vide</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/423685/"><img src="https://habrastorage.org/webt/b0/s3/rq/b0s3rqkffufh7baruji0jc_vbgq.jpeg"><br><br>  La mise Ã  l'Ã©chelle d'un SGBD est un avenir en constante Ã©volution.  Les SGBD s'amÃ©liorent et Ã©voluent mieux sur les plates-formes matÃ©rielles, tandis que les plates-formes matÃ©rielles elles-mÃªmes augmentent la productivitÃ©, le nombre de cÅ“urs et la mÃ©moire - Achilles rattrape la tortue, mais ne l'a toujours pas fait.  Le problÃ¨me de la mise Ã  l'Ã©chelle du SGBD bat son plein. <br><br>  Postgres Professional avait un problÃ¨me avec la mise Ã  l'Ã©chelle non seulement thÃ©oriquement, mais aussi pratiquement: avec ses clients.  Et plus d'une fois.  Un de ces cas sera discutÃ© dans cet article. <br><br>  PostgreSQL Ã©volue bien sur les systÃ¨mes NUMA s'il s'agit d'une seule carte mÃ¨re avec plusieurs processeurs et plusieurs bus de donnÃ©es.  Quelques optimisations peuvent Ãªtre lues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Cependant, il existe une autre classe de systÃ¨mes, ils ont plusieurs cartes mÃ¨res, dont l'Ã©change de donnÃ©es s'effectue via une interconnexion, tandis qu'une instance du systÃ¨me d'exploitation fonctionne sur eux et pour l'utilisateur, cette conception ressemble Ã  une seule machine.  Et bien que formellement, ces systÃ¨mes puissent Ã©galement Ãªtre attribuÃ©s Ã  NUMA, mais ils sont essentiellement plus proches des superordinateurs, comme  l'accÃ¨s Ã  la mÃ©moire locale du nÅ“ud et l'accÃ¨s Ã  la mÃ©moire du nÅ“ud voisin diffÃ¨rent radicalement.  La communautÃ© PostgreSQL estime que la seule instance Postgres exÃ©cutÃ©e sur de telles architectures est une source de problÃ¨mes, et il n'y a pas encore d'approche systÃ©matique pour les rÃ©soudre. <br><a name="habracut"></a><br>  En effet, l'architecture logicielle utilisant la mÃ©moire partagÃ©e est fondamentalement conÃ§ue pour le fait que le temps d'accÃ¨s des diffÃ©rents processus Ã  leur mÃ©moire propre et distante est plus ou moins comparable.  Dans le cas oÃ¹ nous travaillons avec de nombreux nÅ“uds, le pari sur la mÃ©moire partagÃ©e en tant que canal de communication rapide cesse de se justifier, car en raison de la latence, il est beaucoup "moins cher" d'envoyer une demande pour effectuer une certaine action sur le nÅ“ud (nÅ“ud) oÃ¹ des donnÃ©es intÃ©ressantes que d'envoyer ces donnÃ©es sur le bus.  Par consÃ©quent, pour les supercalculateurs et, en gÃ©nÃ©ral, les systÃ¨mes Ã  nombreux nÅ“uds, les solutions de cluster sont pertinentes. <br><br>  Cela ne signifie pas qu'il faut mettre un terme Ã  la combinaison de systÃ¨mes multi-nÅ“uds et d'une architecture de mÃ©moire partagÃ©e Postgres classique.  AprÃ¨s tout, si les processus postgres passent la plupart de leur temps Ã  effectuer des calculs complexes localement, cette architecture sera mÃªme trÃ¨s efficace.  Dans notre situation, le client avait dÃ©jÃ  achetÃ© un puissant serveur multi-nÅ“uds, et nous devions y rÃ©soudre les problÃ¨mes de PostgreSQL. <br><br>  Mais les problÃ¨mes Ã©taient sÃ©rieux: les demandes d'Ã©criture les plus simples (changer plusieurs valeurs de champ dans un enregistrement) ont Ã©tÃ© exÃ©cutÃ©es en quelques minutes Ã  une heure.  Comme il a Ã©tÃ© confirmÃ© par la suite, ces problÃ¨mes se sont manifestÃ©s dans toute leur splendeur prÃ©cisÃ©ment en raison du grand nombre de cÅ“urs et, par consÃ©quent, du parallÃ©lisme radical dans l'exÃ©cution des requÃªtes avec un Ã©change relativement lent entre les nÅ“uds. <br><br>  Par consÃ©quent, l'article se rÃ©vÃ©lera, pour ainsi dire, Ã  deux fins: <br><br><ul><li>  Partager l'expÃ©rience: que faire si dans un systÃ¨me Ã  plusieurs nÅ“uds la base de donnÃ©es ralentit sÃ©rieusement.  Par oÃ¹ commencer, comment diagnostiquer oÃ¹ aller. </li><li>  DÃ©crivez comment les problÃ¨mes du SGBD PostgreSQL lui-mÃªme peuvent Ãªtre rÃ©solus avec un niveau de concurrence Ã©levÃ©.  Notamment comment la modification de l'algorithme de prise de verrous affecte les performances de PostgreSQL. </li></ul><br><h3>  Serveur et DB </h3><br>  Le systÃ¨me Ã©tait composÃ© de 8 lames avec 2 prises chacune.  Au total, plus de 300 cÅ“urs (hors hypertreading).  Un pneu rapide (technologie propriÃ©taire du fabricant) relie les pales.  Ce n'est pas un supercalculateur, mais pour une instance du SGBD, la configuration est impressionnante. <br>  La charge est Ã©galement assez importante.  Plus d'un tÃ©raoctet de donnÃ©es.  Environ 3000 transactions par seconde.  Plus de 1000 connexions aux postgres. <br><br>  Ayant commencÃ© Ã  faire face aux attentes d'enregistrement horaire, la premiÃ¨re chose que nous avons faite a Ã©tÃ© d'Ã©crire sur le disque comme cause de retards.  DÃ¨s que des retards incomprÃ©hensibles ont commencÃ©, les tests ont commencÃ© Ã  se faire exclusivement sur <code>tmpfs</code> .  L'image n'a pas changÃ©.  Le disque n'y est pour rien. <br><br><h3>  Prise en main des diagnostics: vues </h3><br>  Les problÃ¨mes Ã©tant probablement dus Ã  la forte concurrence des processus qui Â«frappentÂ» les mÃªmes objets, la premiÃ¨re chose Ã  vÃ©rifier est les verrous.  Dans PostgreSQL, il existe une vue <code>pg.catalog.pg_locks</code> et <code>pg_stat_activity</code> pour une telle vÃ©rification.  Le second, dÃ©jÃ  dans la version 9.6, a ajoutÃ© des informations sur ce que le processus attend ( <i>Amit Kapila, Ildus Kurbangaliev</i> ) - <code>wait_event_type</code> .  Les valeurs possibles pour ce champ sont dÃ©crites <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Mais d'abord, comptez: <br><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># SELECT COUNT(*) FROM pg_locks; count â€”---â€” 88453 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity; count â€”---â€” 1826 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity WHERE state ='active'; count â€”---â€” 1005</span></span></code> </pre> <br>  Ce sont de vrais chiffres.  Atteint jusqu'Ã  200 000 verrous. <br>  Dans le mÃªme temps, de tels verrous Ã©taient suspendus Ã  la demande malheureuse: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_locks <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> pid =<span class="hljs-number"><span class="hljs-number">580707</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>; count | mode â€”<span class="hljs-comment"><span class="hljs-comment">-----+---------------â€” 93 | AccessShareLock 1 | ExclusiveLock</span></span></code> </pre> <br>  Lors de la lecture du tampon, le SGBD utilise le verrouillage de <code>share</code> , tout en Ã©crivant - <code>exclusive</code> .  Autrement dit, les verrous en Ã©criture reprÃ©sentaient moins de 1% de toutes les demandes. <br>  Dans la vue <code>pg_locks</code> , les types de verrous ne ressemblent pas toujours Ã  ceux dÃ©crits <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans la documentation</a> utilisateur. <br><br>  Voici la plaque d'allumettes: <br><br><pre> <code class="plaintext hljs">AccessShareLock = LockTupleKeyShare RowShareLock = LockTupleShare ExclusiveLock = LockTupleNoKeyExclusive AccessExclusiveLock = LockTupleExclusive</code> </pre> <br>  La requÃªte SELECT mode FROM pg_locks a montrÃ© que CREATE INDEX (sans CONCURRENTLY) attendrait 234 INSERTs et 390 INSERTs pour le <code>buffer content lock</code> .  Une solution possible consiste Ã  Â«apprendreÂ» aux INSERT de diffÃ©rentes sessions Ã  se croiser moins dans les tampons. <br><br><h3>  Il est temps d'utiliser la perf </h3><br>  L'utilitaire <b><code>perf</code></b> collecte de nombreuses informations de diagnostic.  En mode <code>record</code> ... il Ã©crit les statistiques des Ã©vÃ©nements systÃ¨me dans des fichiers (par dÃ©faut, ils sont en <code>./perf_data</code> ), et en mode <code>report</code> , il analyse les donnÃ©es collectÃ©es, par exemple, vous pouvez filtrer les Ã©vÃ©nements qui ne concernent que les <code>postgres</code> ou un <code>pid</code> donnÃ©: <br><br><pre> <code class="plaintext hljs">$ perf record -u postgres  $ perf record -p 76876  ,  $ perf report &gt; ./my_results</code> </pre> <br>  En consÃ©quence, nous verrons quelque chose comme <br><br><img src="https://habrastorage.org/webt/rn/ta/rv/rntarvj2jticq7glciiqockk3-y.jpeg"><br><br>  Comment utiliser <code>perf</code> pour diagnostiquer PostgreSQL est dÃ©crit, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , ainsi que dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wiki pg</a> . <br><br>  Dans notre cas, mÃªme le mode le plus simple a donnÃ© des informations importantes Ã  <code>perf top</code> - <code>perf top</code> , qui fonctionne, bien sÃ»r, dans l'esprit du systÃ¨me d'exploitation le <code>top</code> performant.  Avec <code>perf top</code> nous avons vu que la plupart du temps, le processeur passe dans les <code>PinBuffer()</code> base, ainsi que dans les fonctions <code>PinBuffer()</code> et <code>LWLockAttemptLock().</code>  . <br><br>  <code>PinBuffer()</code> est une fonction qui augmente le compteur de rÃ©fÃ©rences au tampon (mappage d'une page de donnÃ©es Ã  la RAM), grÃ¢ce Ã  laquelle les processus postgres savent quels tampons peuvent Ãªtre forcÃ©s et lesquels ne le peuvent pas. <br><br>  <code>LWLockAttemptLock()</code> - <code>LWLock</code> de capture de <code>LWLock</code> .  <code>LWLock</code> est une sorte de verrou avec deux niveaux de <code>shared</code> et d' <code>exclusive</code> , sans dÃ©finir d' <code>deadlock</code> , les verrous sont prÃ©-allouÃ©s Ã  <code>shared memory</code> , les processus en attente attendent dans une file d'attente. <br><br>  Ces fonctions ont dÃ©jÃ  Ã©tÃ© sÃ©rieusement optimisÃ©es dans PostgreSQL 9.5 et 9.6.  Les verrous Ã  l'intÃ©rieur d'eux ont Ã©tÃ© remplacÃ©s par l'utilisation directe des opÃ©rations atomiques. <br><br><h3>  Graphes de flamme </h3><br>  Câ€™est impossible sans eux: mÃªme sâ€™ils Ã©taient inutiles, il vaudrait quand mÃªme la peine dâ€™en parler - ils sont dâ€™une beautÃ© exceptionnelle.  Mais ils sont utiles.  Voici une illustration de <code>github</code> , pas de notre cas (ni nous ni le client ne sommes encore prÃªts Ã  divulguer les dÃ©tails). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75b/909/e8d/75b909e8de5177a48fa7d73f53eff437.svg"><br><br>  Ces belles images montrent trÃ¨s clairement ce que prennent les cycles du processeur.  Le mÃªme <code>perf</code> peut collecter des donnÃ©es, mais le <code>flame graph</code> visualise intelligemment les donnÃ©es et construit des arbres basÃ©s sur les piles d'appels collectÃ©es.  Vous pouvez en savoir plus sur le profilage avec des graphiques de flamme, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , et tÃ©lÃ©charger tout ce dont vous avez besoin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Dans notre cas, une Ã©norme quantitÃ© de <code>nestloop</code> Ã©tait visible sur les graphiques de flamme.  Apparemment, les jointures d'un grand nombre de tables dans de nombreuses demandes de lecture simultanÃ©es ont provoquÃ© un grand nombre de verrous de <code>access share</code> . <br><br>  Les statistiques collectÃ©es par <code>perf</code> montrent oÃ¹ vont les cycles du processeur.  Et bien que nous ayons vu que la plupart du temps du processeur passe sur les verrous, nous n'avons pas vu ce qui conduit exactement Ã  de si longues attentes en matiÃ¨re de verrous, car nous ne voyons pas exactement oÃ¹ les attentes de verrouillage se produisent, car  Le temps CPU n'est pas perdu Ã  attendre. <br><br>  Afin de voir les attentes elles-mÃªmes, vous pouvez crÃ©er une demande Ã  la vue systÃ¨me <code>pg_stat_activity</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> wait_event_type, wait_event, <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_activity <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> wait_event_type, wait_event;</code> </pre> <br>  a rÃ©vÃ©lÃ© que: <br><br><pre> <code class="plaintext hljs">LWLockTranche | buffer_content | UPDATE ************* LWLockTranche | buffer_content | INSERT INTO ******** LWLockTranche | buffer_content | \r | | insert into B4_MUTEX | | values (nextval('hib | | returning ID Lock | relation | INSERT INTO B4_***** LWLockTranche | buffer_content | UPDATE ************* Lock | relation | INSERT INTO ******** LWLockTranche | buffer_mapping | INSERT INTO ******** LWLockTranche | buffer_content | \r</code> </pre> <br>  (les astÃ©risques ici remplacent simplement les dÃ©tails de la demande que nous ne divulguons pas). <br><br>  Vous pouvez voir les valeurs <code>buffer_content</code> (blocage du contenu des tampons) et <code>buffer_mapping</code> (blocage des composants de la plaque de hachage <code>shared_buffers</code> ). <br><br><h3>  Pour obtenir de l'aide sur gdb </h3><br>  Mais pourquoi tant d'attentes pour ces types de serrures?  Pour des informations plus dÃ©taillÃ©es sur les attentes, j'ai dÃ» utiliser le dÃ©bogueur <code>GDB</code> .  Avec <code>GDB</code> nous pouvons obtenir une pile d'appels de processus spÃ©cifiques.  En appliquant l'Ã©chantillonnage, c'est-Ã -dire  AprÃ¨s avoir collectÃ© un certain nombre de piles d'appels alÃ©atoires, vous pouvez vous faire une idÃ©e des piles qui ont les attentes les plus longues. <br><br>  ConsidÃ©rez le processus de compilation des statistiques.  Nous considÃ©rerons la collecte Â«manuelleÂ» de statistiques, bien que dans la vie rÃ©elle des scripts spÃ©ciaux soient utilisÃ©s pour le faire automatiquement. <br><br>  Tout d'abord, <code>gdb</code> doit Ãªtre attachÃ© au processus PostgreSQL.  Pour ce faire, recherchez le <code>pid</code> processus serveur, par exemple <br><br><pre> <code class="plaintext hljs">$ ps aux | grep postgres</code> </pre> <br>  Disons que nous avons trouvÃ©: <br><br><pre> <code class="plaintext hljs">postgres 2025 0.0 0.1 172428 1240 pts/17  S   23  0:00 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data</code> </pre> <br>  et maintenant insÃ©rez le <code>pid</code> dans le dÃ©bogueur: <br><br><pre> <code class="plaintext hljs">igor_le:~$gdb -p 2025</code> </pre> <br>  Une fois Ã  l'intÃ©rieur du dÃ©bogueur, nous Ã©crivons <code>bt</code> [c'est-Ã -dire <code>backtrace</code> ] ou <code>where</code> .  Et nous obtenons beaucoup d'informations sur ce type: <br><br><pre> <code class="plaintext hljs">(gdb) bt #0 0x00007fbb65d01cd0 in __write_nocancel () from /lib64/libc.so.6 #1 0x00000000007c92f4 in write_pipe_chunks ( data=0x110e6e8 "2018â€06â€01 15:35:38 MSK [524647]: [392â€1] db=bp,user=bp,app=[unknown],client=192.168.70.163 (http://192.168.70.163) LOG: relation 23554 new block 493: 248.389503\n2018â€06â€01 15:35:38 MSK [524647]: [393â€1] db=bp,user=bp,app=["..., len=409, dest=dest@entry=1) at elog.c:3123 #2 0x00000000007cc07b in send_message_to_server_log (edata=0xc6ee60 &lt;errordata&gt;) at elog.c:3024 #3 EmitErrorReport () at elog.c:1479</code> </pre> <br>  AprÃ¨s avoir collectÃ© des statistiques, y compris des piles d'appels de tous les processus postgres, collectÃ©es Ã  plusieurs reprises Ã  diffÃ©rents moments, nous avons vu que le <code>buffer partition lock</code> Ã  l'intÃ©rieur du <code>relation extension lock</code> durÃ© 3706 secondes (environ une heure), c'est-Ã -dire qu'il se verrouille sur un morceau de la table de hachage du tampon , qui Ã©tait nÃ©cessaire pour remplacer l'ancien tampon, afin de le remplacer par la suite par un nouveau correspondant Ã  la partie Ã©tendue de la table.  Un certain nombre de verrous de <code>buffer content lock</code> de <code>buffer content lock</code> Ã©taient Ã©galement perceptibles, ce qui correspondait Ã  l'attente de verrouillage des pages de l'index de l' <code>B-tree</code> pour l'insertion. <br><br><img src="https://habrastorage.org/webt/6c/y6/cw/6cy6cwmfye29jw84dkzoabjlgvg.jpeg"><br><br>  Au dÃ©but, deux explications sont venues pour un temps d'attente aussi monstrueux: <br><br><ul><li>  Quelqu'un d'autre a pris ce <code>LWLock</code> et est restÃ©.  Mais c'est peu probable.  Parce que rien de compliquÃ© ne se passe Ã  l'intÃ©rieur du verrou de partition tampon. </li><li>  Nous avons rencontrÃ© un comportement pathologique de <code>LWLock</code> .  Autrement dit, malgrÃ© le fait que personne n'a pris le verrou trop longtemps, son attente a durÃ© trop longtemps. </li></ul><br><h3>  Patchs de diagnostic et traitement des arbres </h3><br>  En rÃ©duisant le nombre de connexions simultanÃ©es, nous dÃ©chargerions probablement le flux de demandes de verrous.  Mais ce serait comme se rendre.  Au lieu de cela, <i>Alexander Korotkov</i> , l'architecte en chef de Postgres Professional (bien sÃ»r, il a aidÃ© Ã  prÃ©parer cet article), a proposÃ© une sÃ©rie de correctifs. <br><br>  Tout d'abord, il Ã©tait nÃ©cessaire d'avoir une image plus dÃ©taillÃ©e de la catastrophe.  Peu importe la qualitÃ© des outils finis, les correctifs de diagnostic de leur propre fabrication seront Ã©galement utiles. <br><br>  Un correctif a Ã©tÃ© Ã©crit qui ajoute une journalisation dÃ©taillÃ©e du temps passÃ© dans l' <code>relation extension</code> , ce qui se passe Ã  l'intÃ©rieur de la fonction <code>RelationAddExtraBlocks()</code> . Nous dÃ©couvrons donc ce que le temps est passÃ© Ã  l'intÃ©rieur de <code>RelationAddExtraBlocks().</code> <br><br>  Et Ã  l'appui de lui, un autre correctif a Ã©tÃ© Ã©crit dans <code>pg_stat_activity</code> sur ce que nous faisons maintenant en ce qui <code>relation extension</code> .  Cela a Ã©tÃ© fait de cette faÃ§on: lorsque la <code>relation</code> dÃ©veloppe, <code>application_name</code> devient <code>RelationAddExtraBlocks</code> .  Ce processus est dÃ©sormais facilement analysÃ© avec un maximum de dÃ©tails Ã  l'aide de <code>gdb bt</code> et <code>perf</code> . <br><br>  En fait, les correctifs mÃ©dicaux (et non diagnostiques) ont Ã©tÃ© Ã©crits deux fois.  Le premier correctif a changÃ© le comportement des verrous de feuille de <code>Bâ€tree</code> : auparavant, lors de la demande d'insertion, la feuille Ã©tait bloquÃ©e en tant que <code>share</code> , puis elle devenait <code>exclusive</code> .  Maintenant, il devient immÃ©diatement <code>exclusive</code> .  Maintenant, ce correctif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">a dÃ©jÃ  Ã©tÃ© validÃ©</a> pour <b>PostgreSQL 12</b> .  Heureusement, cette annÃ©e, <i>Alexander Korotkov a</i> reÃ§u le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">statut de committer</a> - le deuxiÃ¨me committer PostgreSQL en Russie et le second dans l'entreprise. <br><br>  La valeur <code>NUM_BUFFER_PARTITIONS</code> a Ã©galement Ã©tÃ© augmentÃ©e de 128 Ã  512 pour rÃ©duire la charge sur les verrous de mappage: la table de hachage du gestionnaire de tampons a Ã©tÃ© divisÃ©e en morceaux plus petits, dans l'espoir que la charge sur chaque piÃ¨ce spÃ©cifique soit rÃ©duite. <br><br>  AprÃ¨s avoir appliquÃ© ce correctif, les verrous sur le contenu des tampons ont disparu, mais malgrÃ© l'augmentation de <code>NUM_BUFFER_PARTITIONS</code> , <code>buffer_mapping</code> est restÃ©, c'est-Ã -dire que nous vous rappelons de bloquer des morceaux de la table de hachage du gestionnaire de tampons: <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping ----â€â€â€--â€â€â€+â€------â€â€â€â€â€â€â€â€â€+â€â€â€------â€â€â€â€â€â€â€+â€â€------â€â€â€ 12549 | 1218 | 0 | 15</code> </pre> <br>  Et mÃªme ce n'est pas grand-chose.  B - l'arbre n'est plus un goulot d'Ã©tranglement.  L'extension du <code>heap-</code> est apparue. <br><br><h3>  Traitement de la conscience </h3><br>  Ensuite, Alexander a avancÃ© l'hypothÃ¨se et la solution suivantes: <br><br>  Nous attendons beaucoup de temps sur le <code>buffer parittion lock</code> du <code>buffer parittion lock</code> lors de l' <code>buffer parittion lock</code> tampon.  Peut-Ãªtre sur le mÃªme <code>buffer parittion lock</code> il y a une page trÃ¨s demandÃ©e, par exemple, la racine d'un <code>Bâ€tree</code>  Ã€ ce stade, il existe un flux continu de demandes de <code>shared lock</code> partir des demandes de lecture. <br><br>  La file d'attente Ã  <code>LWLock</code> Â«pas justeÂ».  Ã‰tant donnÃ© que <code>shared lock</code> peuvent Ãªtre pris autant de fois que nÃ©cessaire, alors si le <code>shared lock</code> dÃ©jÃ  pris, les <code>shared lock</code> suivants passent sans file d'attente.  Ainsi, si le flux de verrous partagÃ©s est d'une intensitÃ© suffisante pour qu'il n'y ait pas de Â«fenÃªtresÂ» entre eux, alors l'attente d'un <code>exclusive lock</code> va presque Ã  l'infini. <br><br>  Pour rÃ©soudre ce problÃ¨me, vous pouvez essayer d'offrir - un patch de comportement "gentlemanly" des verrous.  Cela Ã©veille la conscience des <code>shared locker</code> et ils font honnÃªtement la queue lorsqu'ils ont dÃ©jÃ  une <code>exclusive lock</code> (il est intÃ©ressant que les serrures lourdes - <code>hwlock</code> - n'aient pas de problÃ¨mes de conscience: elles font toujours la queue honnÃªtement) <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping | reladdextra | inserts&gt;30sec â€â€â€â€â€â€-â€â€â€â€â€+â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€+â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€+â€â€â€â€â€â€â€â€â€â€â€--â€-â€+â€â€â€â€â€â€-â€â€â€â€â€â€+â€â€â€â€------ 173985 | 1802 | 0 | 569 | 0 | 0</code> </pre> <br>  Tout va bien!  Il n'y a pas de longues <code>insert</code> .  Bien que les verrous sur les morceaux des plaques de hachage soient restÃ©s.  Mais que faire, ce sont les propriÃ©tÃ©s des pneus de notre petit supercalculateur. <br><br>  Ce patch a Ã©galement Ã©tÃ© <a href="">offert Ã  la communautÃ©</a> .  Mais quelle que soit l'Ã©volution du sort de ces correctifs dans la communautÃ©, rien ne les empÃªche d'accÃ©der aux prochaines versions de <b>Postgres Pro Enterprise</b> , conÃ§ues spÃ©cifiquement pour les clients avec des systÃ¨mes lourdement chargÃ©s. <br><br><h3>  Moral </h3><br>  Des verrous de <code>share</code> lÃ©gers Ã  haute moralitÃ© - <code>exclusive</code> blocs <code>exclusive</code> sautent la file d'attente - ont rÃ©solu le problÃ¨me des retards horaires dans un systÃ¨me Ã  plusieurs nÅ“uds.  La balise de hachage du <code>buffer manager</code> n'a pas fonctionnÃ© en raison d'un flux de <code>share lock</code> trop important, ce qui n'a laissÃ© aucune chance aux verrous nÃ©cessaires pour remplacer les anciens tampons et en charger de nouveaux.  Les problÃ¨mes avec l'extension du tampon pour les tables de base de donnÃ©es n'Ã©taient qu'une consÃ©quence de cela.  Avant cela, il Ã©tait possible d'Ã©largir le goulot d'Ã©tranglement avec l'accÃ¨s Ã  la racine de l' <code>B-tree</code> <br><br>  PostgreSQL n'a pas Ã©tÃ© conÃ§u pour les architectures NUMA et les superordinateurs.  L'adaptation Ã  de telles architectures Postgres est un travail Ã©norme qui nÃ©cessiterait (et Ã©ventuellement nÃ©cessiterait) les efforts coordonnÃ©s de nombreuses personnes et mÃªme d'entreprises.  Mais les consÃ©quences dÃ©sagrÃ©ables de ces problÃ¨mes architecturaux peuvent Ãªtre attÃ©nuÃ©es.  Et nous devons le faire: les types de charges qui ont entraÃ®nÃ© des retards similaires Ã  ceux dÃ©crits sont assez typiques, des signaux de dÃ©tresse similaires provenant d'autres endroits continuent de nous parvenir.  Des problÃ¨mes similaires sont apparus plus tÃ´t - sur les systÃ¨mes avec moins de cÅ“urs, seules les consÃ©quences n'Ã©taient pas si monstrueuses et les symptÃ´mes ont Ã©tÃ© traitÃ©s avec d'autres mÃ©thodes et d'autres correctifs.  Maintenant, un autre mÃ©dicament est apparu - pas universel, mais clairement utile. <br><br>  Ainsi, lorsque PostgreSQL travaille avec la mÃ©moire de l'ensemble du systÃ¨me en tant que local, aucun bus Ã  grande vitesse entre les nÅ“uds ne peut se comparer au temps d'accÃ¨s Ã  la mÃ©moire locale.  Les tÃ¢ches surgissent Ã  cause de cela difficile, souvent urgent, mais intÃ©ressant.  Et l'expÃ©rience de les rÃ©soudre est utile non seulement pour les dÃ©cisifs, mais aussi pour toute la communautÃ©. <br><br><img src="https://habrastorage.org/webt/od/n1/sf/odn1sf_id7l60ezlyo-padxymmi.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr423685/">https://habr.com/ru/post/fr423685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr423671/index.html">Les rivaux de Tesla reÃ§oivent un investissement d'un milliard de dollars de l'Arabie saoudite</a></li>
<li><a href="../fr423673/index.html">Risques liÃ©s au dÃ©veloppement de logiciels</a></li>
<li><a href="../fr423677/index.html">Pilotes Jetpack: Frankie West</a></li>
<li><a href="../fr423679/index.html">Une tÃ¢che avec un gratte-ciel et des Å“ufs - pas la poubelle de Newton?</a></li>
<li><a href="../fr423683/index.html">BasÃ© sur le bon sens: dÃ©velopper DevOps Ã  partir de zÃ©ro</a></li>
<li><a href="../fr423687/index.html">HyperX Pulsefire FPS Pro - plus rapide, plus mÃ©chant et plus abordable</a></li>
<li><a href="../fr423689/index.html">RTOS MAX - gratuit? Nous prÃ©voyons d'ouvrir une licence pour une utilisation commerciale gratuite</a></li>
<li><a href="../fr423693/index.html">Une autre faÃ§on d'utiliser Webpack 4 et la sÃ©paration de code</a></li>
<li><a href="../fr423695/index.html">Comment prendre sa retraite avant 40 ans avec un million de dollars dans un compte bancaire</a></li>
<li><a href="../fr423697/index.html">PrÃ©sentation de Spring Data JDBC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
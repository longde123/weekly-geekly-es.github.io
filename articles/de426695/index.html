<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕖 👑 👨🏿‍💻 Bildverarbeitungskameras für Enthusiasten. Wie verwende ich die Kamera für die Offline-Navigation? 💄 👨🏽‍⚖️ 🐾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir haben eine Kamera entwickelt, um AprilTag und ArTag mit mROS zu erkennen. Verbindung über Uart oder Ethernet herstellen. 

 Wir haben JeVois und O...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bildverarbeitungskameras für Enthusiasten. Wie verwende ich die Kamera für die Offline-Navigation?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/robogazon/blog/426695/"><h2>  Wir haben eine Kamera entwickelt, um AprilTag und ArTag mit mROS zu erkennen.  Verbindung über Uart oder Ethernet herstellen. </h2><br><br>  Wir haben JeVois und OpenMV ausprobiert, die Vor- und Nachteile erkannt und unsere Kamera zusammengebaut. <br><br><img src="https://habrastorage.org/webt/lp/nb/qx/lpnbqx9egbtr4id5i-oftxtjpj4.jpeg"><br><br>  Suchen Sie anhand der Daten nach visuellen Tags und der Ausrichtung des Roboters.  Wir entwickeln einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Roboter zum Sammeln von Golfbällen auf der Driving Range</a> .  Derzeit verkauft weltweit nur ein Unternehmen einen Roboter, um dieses Problem zu lösen.  Der Markt ist sehr vielversprechend und hat uns ermutigt, das Projekt von DIY in ein Technologie-Startup zu verwandeln. <br><a name="habracut"></a><br>  Wenn Sie GPS ohne RTK verwenden, um den Roboter zu navigieren, ist es schwierig, die Genauigkeit zu erreichen, die für die korrekte Suche nach einer Basis und einem Parkplatz erforderlich ist.  Mit Real Time Kinematic habe ich Probleme bei der Annäherung an Gebäude.  Wir haben verschiedene Optionen ausprobiert und beschlossen, unsere eigene Kamera zu bauen, um am Eingang zur Basis nach einer visuellen Markierung zu suchen. <br><br>  Teil der Entwicklung des Roboters war das Parken an der Dockingstation, um das Ballfach zu entladen und die Batterien aufzuladen.  Wir haben lange darüber nachgedacht, wie wir es parken sollen, waren uns einig, dass der Roboter ein optisch helles Objekt finden und ihm folgen würde. <br><br>  Die AprilTag- oder ArTag-Tags wurden als Ziel ausgewählt, je nachdem, wie sie sich im Feld zeigten.  Weil  Wir leiden nicht unter dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NIH-</a> Syndrom. Die Suche nach Bildverarbeitungskameras mit Unterstützung für diese Marker und Skriptunterstützung direkt an der Kamera hat begonnen. <br><br><h3>  Erster JeVois </h3><br>  Von dem, was schnell gefunden wurde - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JeVois</a> , entwickelt vom Labor der University of Southern California.  Leider musste ich über Amazon nach Russland bestellen, es gab keine internen Wiederverkäufer und anscheinend wird es keine geben - anscheinend werden Marketing und Vertrieb von den Entwicklern selbst durchgeführt (wir waren ziemlich überrascht, als wir von Jevois zu Jevois Inc. wechseln mussten, um eine Kamera zu kaufen und dann nach einem Link zum Verzeichnis suchen - wählen Sie die Kamera irgendwo in der Mitte von 10-12 Positionen aus). <br><br><img src="https://habrastorage.org/webt/2i/b6/yp/2ib6ypwgyxfvfswidighr735btq.png"><br><br>  Die ersten Läufe auf dem Computer waren sehr ermutigend. Im Allgemeinen funktionierte alles sofort und sah interessant genug aus.  Nach Tests mit Anschluss an die Steuerplatine wurden jedoch vier schwerwiegende Probleme deutlich: <br><br>  Die in den Werbematerialien angegebenen 60-90 FPS gelten für Auflösungen von 160x120 oder 320x240, die für das Parken überhaupt nicht geeignet sind - eine Erfassung aus einer Entfernung von mindestens 5 Metern ist immer noch wünschenswert.  Und damit ein Quadrat aus 6-8 Metern Höhe 160x120 in das Korn fällt, müssen Sie es mindestens einen halben Meter groß machen. Wenn Sie sich ihm nähern, schließt es zuerst den Rahmen vollständig und hört dann überhaupt auf zu erkennen. <br><br>  Verbrauch von 800mA, während die Stromversorgung nur über USB-Kabel mit Mini-USB erfolgt, die diesem Strom ohne großen Spannungsabfall standhalten können.  Es stellte sich als sehr schwierig heraus, ein Kabel mit einer Länge von mindestens einem halben Meter mit solchen Merkmalen zu finden - es wurden ungefähr 15 Optionen ausgewählt, und das Ergebnis war ohnehin nicht sehr zufriedenstellend. <br><br>  Die Kamera ist entweder nachts blind oder blinkt tagsüber.  Die automatische Balance funktioniert über Gut und Böse hinaus. <br><br>  Die Kamera wird von einem Lüfter gekühlt.  Der Lüfter ist sehr klein, die Geschwindigkeit ist hoch - hochfrequentes Geräusch oder einfach ein Quietschen. <br><br><blockquote>  Der kreischende Roboter ist das Letzte, was wir tun wollten. </blockquote><br>  Das Schreiben des Ausführungscodes in die Kamera ist eine separate Unterhaltung - die Installation der Umgebung ist ziemlich verwirrend, und das Zusammenbauen und Hochladen auf die SD-Karte dauert mindestens 2-5 Minuten.  Ja, es gibt keinen Blitz - alles befindet sich auf der SD-Karte. <br><br>  Fazit: Eine Kamera zum Spielen mit Enthusiasten in Innenräumen und bei guter Beleuchtung.  Gleichzeitig wäre es wünschenswert, wenn die Enthusiasten Studenten wären - die Benutzeroberfläche, die Dokumentation und die Arbeitsmethoden mit der Kamera erinnerten mich lebhaft an die Laborarbeit der Studenten, bei der der Bequemlichkeit der Arbeit mit dem System und anderen Exzessen fast keine Beachtung geschenkt wurde.  Hier geht es natürlich um C ++ - Module.  Python-Skripte können über Jevois Inventor bearbeitet werden, aber auch die FPS sind erheblich niedriger.  Außerhalb des Geländes überlebte die Kamera nicht einmal zwei Regenfälle, und der Ventilator verstopfte den Schmutz auf dem Feld mit Raumgeschwindigkeit. <br><br>  Das Ergebnis - es ist nicht für den Einsatz am Roboter geeignet, aber die grundsätzliche Möglichkeit des Parkens wurde bewiesen. <br><br><h3>  OpenMV 3 und alle seine Varianten </h3><br><img src="https://habrastorage.org/webt/jl/0l/xr/jl0lxryl0tksfb1vyvdomcyh8wm.jpeg"><br><br>  Zum Zeitpunkt der ersten Suche war es einfach nicht verfügbar - es gab eine Kampagne auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kickstarter</a> . <br><br>  Nachdem wir genug mit JeVois gespielt hatten und 100 Dollar in den Müll geworfen wurden, wurde ein Verkäufer mit Lagerbeständen gefunden und 2 Stück gekauft. <br><br>  Im Allgemeinen sind die Impressionen äußerst angenehm - eine bemerkenswert durchdachte Oberfläche in der OpenMV-IDE, eine transparente Python-Kompilierung, die es bequem macht, die Funktionsweise des Algorithmus zu beobachten und ihn zu debuggen.  Hier gab es jedoch Probleme: <br><br><ul><li>  Die Auflösung kann beliebig sein, aber AprilTag kann nur in einem Bereich von nicht mehr als 200 x 200 Pixel gesucht werden.  Wir kehren zum Problem des Getreides usw. zurück.  Der Entwickler <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">empfahl,</a> zuerst Blobs zu ziehen und dann die darin enthaltenen Codes zu überprüfen.  Aber auf etwas anderem als einem einfachen Hintergrund (idealerweise einer weißen Wand) funktioniert dies nicht. Grünes Gras und strahlende Sonne vor dem Hintergrund verwandeln alles in Brei.  Plus FPS fällt auf maximal 5. </li><li>  Günstiger Omnivisionssensor + günstige Optik = Seifenbild.  Optisch ist dies beim Betrachten eines Videostreams nicht sehr auffällig, aber beim Betrachten einzelner Frames ist es deutlich sichtbar. </li><li>  Es gibt keinen IR-Vorhang, aber eine IR-Beleuchtung.  [WHAAAAT?] </li><li>  Es gibt keinen Schutz vor der äußeren Umgebung.  Überhaupt nicht. </li></ul><br><img src="https://habrastorage.org/webt/wk/fw/pk/wkfwpkju7byid4w9pqq6g0iggpo.png"><br><br>  Das Skript wurde auf dieser Kamera getestet, es wurden mehrere Dutzend Parkläufe durchgeführt.  Nachdem der Roboter von Moskau nach St. Petersburg und zurück gerollt war, hörte die Kamera auf zu starten - der Leistungsregler wurde ausgeknockt.  Die offensichtliche Maßnahme war Verpackung und Leistungsstabilisierung.  Und hier wurde das Interessanteste entdeckt - das Gehäuse mit der richtigen IP für diese Kamera konnte einfach nicht gefunden werden, oder es handelte sich um Boxen mit transparenten Abdeckungen ohne interne Halterungen und dichte Kabelein- / -ausgänge.  Als Ergebnis der Suche wurde eine Masse billiger chinesischer Überwachungskameras mit den richtigen Fällen gefunden.  Die Kamera wurde gekauft und entkernt, eine zweite Kopie von OpenMV stand anstelle der Platine, alles funktionierte. <br>  Aber Abend und Nacht wurden zu einem fast unüberwindlichen Hindernis - es gibt keinen IR-Vorhang. <br><br>  Ergebnisse: Die Kamera ist SEHR praktisch für das Prototyping, die Ressourcen sind begrenzt, es gibt überhaupt keinen Schutz vor der äußeren Umgebung (die zweite Kamera ging dann zu einem industriellen Gefrierschrank und überlebte -30 nicht).  Nicht gut. <br><br>  Und dann wurde es für uns sehr interessant, welche Art von Boards wir von chinesischen Kameras bekommen haben <br><br><h4>  HiSilicon-Klone </h4><br>  Bei sorgfältiger Prüfung stellte sich heraus, dass das Board über einen 2-Kern-ARM, einen DSP-Prozessor, einen IR-Vorhang, eine IR-Beleuchtung und einen anständigen Sensor von Sony verfügt. Das Board ist mit einer Schutzmasse + einem Gehäuse für die Straße versehen.  Genau das, was Sie brauchen - es bleibt, Software zu sammeln. <br><br>  Inside erwies sich als ein ziemlich funktionierender Linux-Klon von HiSilicon + u-boot. <br>  Ich musste das SDK aus chinesischen Quellen herunterladen und mich mit Baugruppen befassen.  Im Prinzip wurde auf dem Weg nichts Schreckliches gefunden, außer dass mehrere Dateien im SDK repariert werden mussten - die Linux-Distribution, auf der das SDK ziemlich alt sein würde, und einige Header-Dateien haben sich seitdem geändert.  Nun, ich musste die Shell von zsh auf bash ändern.  Ich werde die Details weglassen. Dies sollte für immer ein separater Artikel sein. <br><br>  <b>Diese Ressourcen haben geholfen:</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Analysieren, Verbindung zur Kamera herstellen</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beispiel für ein Software-Baugruppendiagramm</a> <br><br>  Dann lief alles nach dem bekannten Schema: <br><br><img src="https://habrastorage.org/webt/ce/nx/u5/cenxu5leurcipqbzgfmzyxhdhhq.jpeg"><br><br>  Die meiste Zeit, die benötigt wurde, um das Bild vom Sensor zu erhalten, habe ich den Rest in nur 4 Stunden erledigt und nur den debuggten Algorithmus von Python nach C ++ portiert. <br>  Die Arbeit mit dem Sensor dauerte ungefähr anderthalb Wochen.  Natürlich gibt es in diesen Geräten kein / dev / video0, fast nackte Hardware mit direkter Arbeit mit Speicher und Ports. <br>  Wir müssen sofort sagen, dass die Beispiele aus dem SDK ohne Änderungen nur auf den Debug-Boards für diese SDKs funktionieren, da sonst viele kleinere Änderungen erforderlich sind.  So lustig es auch scheinen mag, das Hauptproblem besteht darin, festzustellen, welcher Sensor sich in der Kamera befindet, weil  Die Chinesen schreiben eine in die Beschreibung, eine andere ist auf der Tafel markiert, das dritte Modell ist in der Software initialisiert.  Beispielsweise verfügt die Kamera in der Beschreibung über einen IMX323-Sensor. Die Karte ist mit SC2235 gekennzeichnet. Beim Start in Init-Skripten wird sie als AR130 gestartet und von der Kamerasoftware als SC2235P initialisiert. <br><br>  Die Gründe für all dies sind recht einfach: Für den Endbenutzer, dass IMX323, SC2235 alle gleich sind, ist das Bild sehr ähnlich.  Der Kernel und die Rootfs mit int-Skripten wurden mit minimalen Änderungen aus dem SDK zusammengestellt und haben sich nicht um ein separates Initialisierungsskript für jedes Modell gekümmert - nur die Startparameter waren korrekt, und der Name wurde unverändert gelassen.  In der Software für die Arbeit mit der Kamera ist bereits die zweite Initialisierung des DSP mit dem Sensor gestartet, und das genaue Modell der Kamera ist dort bereits kritisch - daher haben die Protokolle bereits das genaue Modell - SC2235P.  P - Dies ist wichtig. Es handelt sich um einen anderen Sensor in Bezug auf die Eigenschaften, der sogar mit einer geringfügig anderen Busfrequenz und einer anderen Auflösung als der SC2235 arbeitet. <br><br>  Der zweite Teil der Quest sind Datenblätter zu Sensoren, die im Großen und Ganzen nicht vorhanden sind.  Daher musste ich das hi_i2c-Modul mit Drucken in das Protokoll über printk neu erstellen und in den von der Kamera entfernten Speicherauszug ersetzen, den DSP-Konfigurationsdämpfer des Videoprozessors schreiben und die Konfigurationen von der Arbeitskamera entfernen sowie mehrmals die Treiber aus dem DafangSoftware-Projekt überprüfen.  Im Detail zeichnet dies 3-4 separate Artikel, die ich nach NG schreiben möchte. <br><br>  Am Ende lief alles noch besser als erwartet - selbstbewusste Arbeit an der Erfassung von AprilTag aus 6 Metern Entfernung auch bei fast völliger Dunkelheit, 25-12 fps, PID-Parksteuerung usw. <br>  Das Ergebnis: Es ist das Beste für die Arbeit vor Ort. Viele Dinge wurden berücksichtigt, um sich vor äußeren Bedingungen zu schützen.  Das einzige, was nicht vollständig überprüft werden konnte, war die Arbeit in der hellen Sonne, das Wetter seit Oktober hat sich verschlechtert. <br><br><h3>  Idee für die Entwicklung </h3><br>  Und hier hatten wir eine Idee - wir haben ein Analogon von OpenMV mit viel besseren Hardwarefunktionen und Massenproduktion in der Hand.  Es bleibt, die Arbeit mit der Kamera auf die OpenMV-Ebene zu bringen, dort Mikropython zu erstellen, eine bequeme IDE zu erstellen und zu überprüfen, wie aktuelle Skripte von OpenMV funktionieren.  Darüber hinaus ist mRos dort vollständig portiert, was die Verwendung solcher Kameras für ROS-Systeme sofort erweitert. <br><br>  Aus diesem Grund planen wir, OpenMV-Analoga im März und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mROS</a> bis Mai zu liefern. <br><br>  Um den Preis für die Anpassung der Kamera zu senken, bieten wir sie Ihnen gerne an.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Füllen Sie das Formular aus</a> und wir werden uns mit Ihnen in Verbindung setzen, sobald wir bereit sind, die erste Charge zu bestellen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de426695/">https://habr.com/ru/post/de426695/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de426685/index.html">Wir steuern Hunderte verschiedener Smart-Home-Geräte mit Sprache und Text von einem Smartphone aus. Alexa Echo im Boten</a></li>
<li><a href="../de426687/index.html">Erstellen eines Roboterkoffers mit einem begrenzten Budget. Vakuumformen</a></li>
<li><a href="../de426689/index.html">Wir sind für den Markt eines anderen verantwortlich: Was soziale Netzwerke über CRM sagen</a></li>
<li><a href="../de426691/index.html">Programmierer im Krankenstand</a></li>
<li><a href="../de426693/index.html">Serviceroboternavigation auf einem Golfplatz. Einen Weg bauen und Hindernissen ausweichen</a></li>
<li><a href="../de426697/index.html">Arbeiten mit LibUsb-Geräten unter Android</a></li>
<li><a href="../de426699/index.html">Python-Test mit Pytest. Einfach, schnell, effizient und skalierbar. Vorwort und Einführung</a></li>
<li><a href="../de426701/index.html">Flattern - ein neuer Blick auf die plattformübergreifende Entwicklung</a></li>
<li><a href="../de426703/index.html">Was war am DataVizDay in Minsk interessant?</a></li>
<li><a href="../de426705/index.html">Entwicklung und Testen intelligenter Verträge für Hyperledger Fabric</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
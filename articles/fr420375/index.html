<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚óªÔ∏è ü•¶ üïØÔ∏è Apprenez OpenGL. Le√ßon 5.8 - Bloom üêô ‚öîÔ∏è üì∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bloom 
 En raison de la plage de luminosit√© limit√©e disponible pour les moniteurs conventionnels, la t√¢che d'afficher de mani√®re convaincante des sour...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprenez OpenGL. Le√ßon 5.8 - Bloom</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420375/"><img align="left" src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="OGL3" width="300"><h2>  Bloom </h2><br>  En raison de la plage de luminosit√© limit√©e disponible pour les moniteurs conventionnels, la t√¢che d'afficher de mani√®re convaincante des sources de lumi√®re vive et des surfaces fortement √©clair√©es est difficile par d√©finition.  L'une des m√©thodes courantes pour mettre en √©vidence les zones lumineuses sur le moniteur est une technique qui ajoute un halo de lueur autour des objets lumineux, donnant l'impression de ¬´diffuser¬ª la lumi√®re √† l'ext√©rieur de la source lumineuse.  En cons√©quence, l'observateur donne l'impression d'une luminosit√© √©lev√©e de ces zones √©clair√©es ou sources de lumi√®re. <br><br>  L'effet d√©crit d'un halo et de la sortie de lumi√®re au-del√† de la source est obtenu par une technique de post-traitement appel√©e <i>bloom</i> .  L'application de l'effet ajoute un halo de lueur caract√©ristique √† toutes les zones lumineuses de la sc√®ne affich√©e, comme le montre l'exemple ci-dessous: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oi/qw/mj/oiqwmjiua0ogznqfllr0q9v53fc.png"></div><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Table des mati√®res</b> <div class="spoiler_text">  Partie 1. Pour commencer <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Opengl</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cr√©ation de fen√™tres</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bonjour fen√™tre</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bonjour triangle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shaders</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Textures</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transformations</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Syst√®mes de coordonn√©es</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Appareil photo</a> </li></ol><br>  Partie 2. √âclairage de base <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les couleurs</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bases d'√©clairage</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mat√©riaux</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes de texture</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sources lumineuses</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sources d'√©clairage multiples</a> </li></ol><br>  Partie 3. T√©l√©charger des mod√®les 3D <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Biblioth√®que Assimp</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classe de polygone de maillage</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classe de mod√®le 3D</a> </li></ol><br>  Partie 4. Fonctionnalit√©s avanc√©es d'OpenGL <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Test de profondeur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Test au pochoir</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">M√©lange de couleurs</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Couper les visages</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tampon de trame</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes cubiques</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traitement avanc√© des donn√©es</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GLSL avanc√©</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shader g√©om√©trique</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Instanciation</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lissage</a> </li></ol><br>  Partie 5. √âclairage avanc√© <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√âclairage avanc√©.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®le Blinn-Fong.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Correction gamma</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes fant√¥mes</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartes ombr√©es omnidirectionnelles</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cartographie normale</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mappage de parallaxe</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HDR</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bloom</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rendu diff√©r√©</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SSAO</a> </li></ol><br>  Partie 6. PBR <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Th√©orie</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sources de lumi√®re analytiques</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Irradiation diffuse.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Exposition miroir.</a> </li></ol><br></div></div><br>  Bloom ajoute un indice visuel distinctif √† l'image sur la luminosit√© significative des objets couverts par le halo de l'effet appliqu√©.  Appliqu√© de mani√®re s√©lective et dans une mesure pr√©cise (auquel de nombreux jeux, h√©las, ne peuvent pas faire face), l'effet peut am√©liorer consid√©rablement l'expressivit√© visuelle de l'√©clairage utilis√© dans la sc√®ne, ainsi que rajouter du drame dans certaines situations. <br><br>  Cette technique fonctionne en conjonction avec le rendu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HDR</a> presque comme un ajout √©vident.  Apparemment, √† cause de cela, beaucoup de gens m√©langent √† tort ces deux termes √† l'interchangeabilit√© totale.  Cependant, ces techniques sont compl√®tement ind√©pendantes et sont utilis√©es √† des fins diff√©rentes.  Il est possible d'impl√©menter la floraison en utilisant le tampon d'image par d√©faut avec une profondeur de couleur de 8 bits, tout comme l'application du rendu HDR sans recourir √† l'utilisation de la floraison.  La seule chose est que le rendu HDR vous permet d'impl√©menter l'effet de mani√®re plus efficace (nous verrons cela plus tard). <br><br>  Pour mettre en ≈ìuvre la floraison, la sc√®ne illumin√©e est d'abord rendue de la mani√®re habituelle.  Ensuite, un tampon couleur HDR et un tampon couleur contenant uniquement des parties lumineuses de la sc√®ne sont extraits.  Cette image extraite de la partie lumineuse est ensuite floue et superpos√©e au-dessus de l'image HDR d'origine de la sc√®ne. <br><br>  Pour le rendre plus clair, nous analyserons le processus √©tape par √©tape.  Rendez une sc√®ne contenant 4 sources de lumi√®re vive affich√©es sous forme de cubes color√©s.  Tous ont une valeur de luminosit√© comprise entre 1,5 et 15,0.  Si le tampon de couleur est sorti sur le HDR, le r√©sultat est le suivant: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_2/_h/wn/_2_hwnque0owtvpdcyh_vo_p9pg.png"></div><br>  De ce tampon couleur HDR, nous extrayons tous les fragments dont la luminosit√© d√©passe une limite pr√©d√©termin√©e.  Il en r√©sulte une image ne contenant que des zones tr√®s √©clair√©es: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/q7/jb/uz/q7jbuz_9apwuc9cb2jzpe4a-4si.png"></div><br>  De plus, cette image de zones lumineuses est floue.  La gravit√© de l'effet est essentiellement d√©termin√©e par la force et le rayon du filtre de flou appliqu√©: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5u/cv/b7/5ucvb73pzpcbvbrn2pcp5khu1_i.png"></div><br>  L'image floue des zones lumineuses qui en r√©sulte est √† la base de l'effet final des halos autour des objets lumineux.  Cette texture est simplement m√©lang√©e avec l'image HDR originale de la sc√®ne.  Les zones lumineuses √©tant floues, leur taille a augment√©, ce qui donne finalement un effet visuel de luminosit√© qui d√©passe les limites des sources lumineuses: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wq/pt/lx/wqptlxwywvag8dzh0dck64yzrbg.png"></div><br>  Comme vous pouvez le voir, la floraison n'est pas la technique la plus sophistiqu√©e, mais atteindre sa haute qualit√© visuelle et sa fiabilit√© n'est pas toujours facile.  Pour l'essentiel, l'effet d√©pend de la qualit√© et du type de filtre de flou appliqu√©.  M√™me de petits changements dans les param√®tres du filtre peuvent changer consid√©rablement la qualit√© finale de l'√©quipement. <br><br>  Ainsi, les actions ci-dessus nous donnent un algorithme √©tape par √©tape de l'effet de post-traitement pour l'effet de floraison.  L'image ci-dessous r√©sume les actions requises: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t7/kt/pz/t7ktpzzm8bo_ccpmh70uu5x0rye.png"></div><br>  Tout d'abord, nous avons besoin d'informations sur les parties lumineuses de la sc√®ne en fonction d'une valeur seuil donn√©e.  Voil√† ce que nous allons faire. <br><br><h2>  Extraire les faits saillants </h2><br>  Donc, pour commencer, nous devons obtenir deux images bas√©es sur notre sc√®ne.  Il serait na√Øf de rendre deux fois, mais utilisez la m√©thode <i>MRT</i> ( <i>Multiple Render Targets</i> ) plus avanc√©e: nous sp√©cifions plus d'une sortie dans le fragment shader final, et gr√¢ce √† cela, deux images peuvent √™tre extraites en une seule passe!  Pour sp√©cifier dans quel tampon de couleur le shader sera sorti, le sp√©cificateur de <i>disposition</i> est utilis√©: <br><br><pre><code class="cpp hljs">layout (location = <span class="hljs-number"><span class="hljs-number">0</span></span>) out vec4 FragColor; layout (location = <span class="hljs-number"><span class="hljs-number">1</span></span>) out vec4 BrightColor;</code> </pre> <br>  Bien s√ªr, la m√©thode ne fonctionnera que si nous avons pr√©par√© plusieurs tampons pour l'√©criture.  En d'autres termes, pour impl√©menter plusieurs sorties du fragment shader, le tampon de trame utilis√© √† ce moment doit contenir un nombre suffisant de tampons de couleur connect√©s.  Si nous passons √† la le√ßon sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tampon de trame</a> , il est rappel√© que lors de la liaison de la texture en tant que tampon de couleur, nous pourrions indiquer le <i>num√©ro de la pi√®ce jointe</i> .  Jusqu'√† pr√©sent, nous n'avions pas besoin d'utiliser une pi√®ce jointe autre que <i>GL_COLOR_ATTACHMENT0</i> , mais cette fois <i>GL_COLOR_ATTACHMENT1</i> sera utile, car nous avons besoin de deux objectifs pour enregistrer √† la fois: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//       unsigned int hdrFBO; glGenFramebuffers(1, &amp;hdrFBO); glBindFramebuffer(GL_FRAMEBUFFER, hdrFBO); unsigned int colorBuffers[2]; glGenTextures(2, colorBuffers); for (unsigned int i = 0; i &lt; 2; i++) { glBindTexture(GL_TEXTURE_2D, colorBuffers[i]); glTexImage2D( GL_TEXTURE_2D, 0, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_FLOAT, NULL ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); //     glFramebufferTexture2D( GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0 + i, GL_TEXTURE_2D, colorBuffers[i], 0 ); }</span></span></code> </pre> <br>  De plus, en appelant <i>glDrawBuffers</i> , vous devrez explicitement dire √† OpenGL que nous allons sortir vers plusieurs tampons.  Sinon, la biblioth√®que ne sortira que la premi√®re pi√®ce jointe, ignorant les op√©rations d'√©criture sur les autres pi√®ces jointes.  En tant qu'argument de la fonction, un tableau d'identificateurs des pi√®ces jointes utilis√©es √† partir de l'√©num√©ration correspondante est transmis: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> attachments[<span class="hljs-number"><span class="hljs-number">2</span></span>] = { GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1 }; glDrawBuffers(<span class="hljs-number"><span class="hljs-number">2</span></span>, attachments);</code> </pre> <br>  Pour ce tampon de trame, tout shader de fragment qui sp√©cifie un sp√©cificateur d' <i>emplacement</i> pour ses sorties √©crit dans le tampon de couleur correspondant.  Et c'est une excellente nouvelle, car de cette fa√ßon, nous √©vitons la passe de rendu inutile pour extraire des donn√©es sur les parties lumineuses de la sc√®ne - vous pouvez tout faire √† la fois dans un seul shader: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core layout (location = 0) out vec4 FragColor; layout (location = 1) out vec4 BrightColor; [...] void main() { [...] </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//      FragColor = vec4(lighting, 1.0); //         //   -    ,    float brightness = dot(FragColor.rgb, vec3(0.2126, 0.7152, 0.0722)); if(brightness &gt; 1.0) BrightColor = vec4(FragColor.rgb, 1.0); else BrightColor = vec4(0.0, 0.0, 0.0, 1.0); }</span></span></span></span></code> </pre> <br>  Dans ce fragment, la partie contenant le code typique de calcul de l'√©clairage est omise.  Son r√©sultat est √©crit dans la premi√®re sortie du shader - la variable <i>FragColor</i> .  Ensuite, la couleur r√©sultante du fragment est utilis√©e pour calculer la valeur de luminosit√©.  Pour cela, une traduction pond√©r√©e en niveaux de gris est r√©alis√©e (par multiplication scalaire, on multiplie les composantes correspondantes des vecteurs et on les additionne, conduisant √† une valeur unique).  Ensuite, lorsque la luminosit√© d'un fragment d'un certain seuil est d√©pass√©e, nous enregistrons sa couleur dans la deuxi√®me sortie du shader.  Pour les cubes rempla√ßant des sources lumineuses, ce shader est √©galement ex√©cut√©. <br><br>  Apr√®s avoir compris l'algorithme, nous pouvons comprendre pourquoi cette technique fonctionne si bien avec le rendu HDR.  Le rendu au format HDR permet aux composants de couleur d'aller au-del√† de la limite sup√©rieure de 1,0, ce qui vous permet d'ajuster de mani√®re plus flexible le seuil de luminosit√© en dehors de l'intervalle standard [0., 1.], offrant la possibilit√© d'affiner les parties de la sc√®ne qui sont consid√©r√©es comme lumineuses.  Sans utiliser HDR, vous devrez vous contenter d'un seuil de luminosit√© dans l'intervalle [0., 1.], ce qui est tout √† fait acceptable, mais conduit √† une coupure de la luminosit√© plus ¬´nette¬ª, ce qui rend souvent la floraison trop intrusive et flashy (imaginez-vous sur un champ de neige en haute montagne) . <br><br>  Une fois le shader ex√©cut√©, deux tampons cibles contiendront une image normale de la sc√®ne, ainsi qu'une image contenant uniquement des zones lumineuses. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hp/rf/pr/hprfprhsu9v4q6_gvhhg43leup4.png"></div><br>  L'image des zones lumineuses doit maintenant √™tre trait√©e en utilisant le flou.  Vous pouvez accomplir cela avec un simple filtre rectangulaire ( <i>bo√Æte</i> ), qui a √©t√© utilis√© dans la section de post-traitement de la le√ßon de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tampon de trame</a> .  Mais un bien meilleur r√©sultat est obtenu par <i>filtrage de Gauss</i> . <br><br><h2>  Flou gaussien </h2><br>  La le√ßon de post-traitement nous a donn√© une id√©e du flou en utilisant une moyenne de couleurs simple de fragments d'images adjacents.  Cette m√©thode de flou est simple, mais l'image r√©sultante peut sembler plus attrayante.  Le flou gaussien est bas√© sur la courbe de distribution en forme de cloche du m√™me nom: les valeurs √©lev√©es de la fonction sont situ√©es plus pr√®s du centre de la courbe et tombent des deux c√¥t√©s.  Math√©matiquement, une courbe gaussienne peut √™tre exprim√©e avec diff√©rents param√®tres, mais la forme g√©n√©rale de la courbe reste la suivante: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0o/xq/eq/0oxqeqhhsip9d0iai3eit6cpooo.png"></div><br>  Le flou avec des poids bas√©s sur les valeurs de la courbe de Gauss est beaucoup mieux qu'un filtre rectangulaire: en raison du fait que la courbe a une plus grande surface au voisinage de son centre, ce qui correspond √† des poids plus grands pour les fragments pr√®s du centre du noyau du filtre.  En prenant, par exemple, le noyau 32x32, nous utiliserons les facteurs de pond√©ration les plus petits, plus le fragment est √©loign√© du noyau central.  C'est cette caract√©ristique de filtre qui donne un r√©sultat de flou gaussien visuellement plus satisfaisant. <br><br>  La mise en ≈ìuvre du filtre n√©cessitera un tableau bidimensionnel de coefficients de pond√©ration, qui pourrait √™tre rempli sur la base de l'expression bidimensionnelle d√©crivant la courbe gaussienne.  Cependant, nous rencontrerons imm√©diatement un probl√®me de performances: m√™me un noyau de flou relativement petit dans un fragment 32x32 n√©cessitera 1024 √©chantillons de texture pour chaque fragment de l'image trait√©e! <br><br>  Heureusement pour nous, l'expression de la courbe gaussienne a une caract√©ristique math√©matique tr√®s pratique - la s√©parabilit√©, qui permettra de faire deux expressions unidimensionnelles √† partir d'une expression bidimensionnelle qui d√©crivent les composantes horizontale et verticale.  Cela permettra de brouiller √† son tour dans deux approches: horizontalement, puis verticalement avec des ensembles de poids correspondant √† chacune des directions.  L'image r√©sultante sera la m√™me que lors du traitement d'un algorithme bidimensionnel, mais elle n√©cessitera beaucoup moins de puissance de traitement du processeur vid√©o: au lieu de 1024 √©chantillons de la texture, nous n'avons besoin que de 32 + 32 = 64!  C'est l'essence m√™me de la filtration gaussienne en deux passes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3g/my/aq/3gmyaqmqfsy1rk3hegbx_4s5rpc.png"></div><br>  Pour nous, tout cela signifie une chose: le flou d'une image devra √™tre fait deux fois, et ici l'utilisation d'objets de tampon de cadre sera utile.  Nous appliquons la technique dite de ping-pong: il y a quelques objets de tampon d'image et le contenu du tampon de couleur d'un tampon d'image est rendu avec un certain traitement dans le tampon de couleur du tampon d'image actuel, puis le tampon d'image source et le r√©cepteur d'image tampon sont √©chang√©s et ce processus est r√©p√©t√© un certain nombre de fois.  En fait, le tampon d'image actuel pour afficher l'image est simplement chang√©, et avec lui, la texture actuelle √† partir de laquelle l'√©chantillonnage est effectu√© pour le rendu.  L'approche vous permet de brouiller l'image d'origine en la pla√ßant dans le premier tampon de trame, puis de brouiller le contenu du premier tampon de trame, de la placer dans la seconde, puis de brouiller la seconde, de la placer dans la premi√®re, etc. <br><br>  Avant de passer au code de r√©glage du tampon de trame, jetons un coup d'≈ìil au code de shader de flou gaussien: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D image; uniform bool horizontal; uniform float weight[5] = float[] (0.227027, 0.1945946, 0.1216216, 0.054054, 0.016216); void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//     vec2 tex_offset = 1.0 / textureSize(image, 0); //    vec3 result = texture(image, TexCoords).rgb * weight[0]; if(horizontal) { for(int i = 1; i &lt; 5; ++i) { result += texture(image, TexCoords + vec2(tex_offset.x * i, 0.0)).rgb * weight[i]; result += texture(image, TexCoords - vec2(tex_offset.x * i, 0.0)).rgb * weight[i]; } } else { for(int i = 1; i &lt; 5; ++i) { result += texture(image, TexCoords + vec2(0.0, tex_offset.y * i)).rgb * weight[i]; result += texture(image, TexCoords - vec2(0.0, tex_offset.y * i)).rgb * weight[i]; } } FragColor = vec4(result, 1.0); }</span></span></span></span></code> </pre> <br>  Comme vous pouvez le voir, nous utilisons un √©chantillon assez petit de coefficients de la courbe gaussienne, qui sont utilis√©s comme poids pour les √©chantillons horizontalement ou verticalement par rapport au fragment actuel.  Le code a deux branches principales divisant l'algorithme en passe verticale et horizontale en fonction de la valeur de l'uniforme <i>horizontal</i> .  Le d√©calage pour chaque √©chantillon est d√©fini √©gal √† la taille de texel, qui est d√©finie comme l'inverse de la taille de texture (une valeur de type <i>vec2</i> retourn√©e par la fonction <i>textureSize</i> ()). <br><br>  Cr√©ez deux tampons de cadre contenant un tampon de couleur en fonction de la texture: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pingpongFBO[<span class="hljs-number"><span class="hljs-number">2</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pingpongBuffer[<span class="hljs-number"><span class="hljs-number">2</span></span>]; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">2</span></span>, pingpongFBO); glGenTextures(<span class="hljs-number"><span class="hljs-number">2</span></span>, pingpongBuffer); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">2</span></span>; i++) { glBindFramebuffer(GL_FRAMEBUFFER, pingpongFBO[i]); glBindTexture(GL_TEXTURE_2D, pingpongBuffer[i]); glTexImage2D( GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glFramebufferTexture2D( GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, pingpongBuffer[i], <span class="hljs-number"><span class="hljs-number">0</span></span> ); }</code> </pre> <br>  Apr√®s avoir obtenu la texture HDR de la sc√®ne et extrait la texture des zones lumineuses, nous remplissons le tampon de couleur de l'un des deux tampons d'image pr√©par√©s avec la texture de luminosit√© et commen√ßons le processus de ping-pong dix fois (cinq fois verticalement, cinq horizontalement): <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> horizontal = <span class="hljs-literal"><span class="hljs-literal">true</span></span>, first_iteration = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> amount = <span class="hljs-number"><span class="hljs-number">10</span></span>; shaderBlur.use(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; amount; i++) { glBindFramebuffer(GL_FRAMEBUFFER, pingpongFBO[horizontal]); shaderBlur.setInt(<span class="hljs-string"><span class="hljs-string">"horizontal"</span></span>, horizontal); glBindTexture( GL_TEXTURE_2D, first_iteration ? colorBuffers[<span class="hljs-number"><span class="hljs-number">1</span></span>] : pingpongBuffers[!horizontal] ); RenderQuad(); horizontal = !horizontal; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (first_iteration) first_iteration = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } glBindFramebuffer(GL_FRAMEBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  √Ä chaque it√©ration, nous s√©lectionnons et ancrons l'un des tampons d'image en fonction du flou horizontal ou vertical de cette it√©ration, et le tampon de couleur de l'autre tampon d'image est ensuite utilis√© comme texture d'entr√©e pour le shader de flou.  √Ä la premi√®re it√©ration, nous devons utiliser explicitement une image contenant des zones lumineuses ( <i>luminosit√©Texture</i> ) - sinon les deux tampons de cadre de ping-pong resteront vides.  Apr√®s dix passes, l'image d'origine prend la forme de cinq flous par un filtre gaussien complet.  L'approche utilis√©e nous permet de changer facilement le degr√© de flou: plus il y a d'it√©rations de ping-pong, plus le flou est fort. <br><br>  Dans notre cas, le r√©sultat du flou ressemble √† ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2j/du/ga/2jdugaud8hudvnsz8pkdjgaqvus.png"></div><br>  Pour terminer l'effet, il ne reste plus qu'√† combiner l'image floue avec l'image HDR d'origine de la sc√®ne. <br><br><h2>  M√©lange de textures </h2><br>  Ayant √† port√©e de main la texture HDR de la sc√®ne rendue et la texture floue des zones surexpos√©es, tout ce dont vous avez besoin pour r√©aliser le fameux effet de floraison ou lueur est de combiner ces deux images.  Le shader de fragment final (tr√®s similaire √† celui pr√©sent√© dans la le√ßon sur le format <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HDR</a> ) fait exactement cela - il m√©lange additivement deux textures: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D scene; uniform sampler2D bloomBlur; uniform float exposure; void main() { const float gamma = 2.2; vec3 hdrColor = texture(scene, TexCoords).rgb; vec3 bloomColor = texture(bloomBlur, TexCoords).rgb; hdrColor += bloomColor; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// additive blending //   vec3 result = vec3(1.0) - exp(-hdrColor * exposure); //     - result = pow(result, vec3(1.0 / gamma)); FragColor = vec4(result, 1.0); }</span></span></span></span></code> </pre> <br>  Ce qu'il faut rechercher: le mixage est effectu√© avant d'appliquer le <i>mappage de tonalit√©</i> .  Cela traduira correctement la luminosit√© suppl√©mentaire de l'effet dans la <i>plage</i> LDR ( <i>Low Dynamic Range</i> ), tout en conservant la distribution de luminosit√© relative dans la sc√®ne. <br><br>  Le r√©sultat du traitement - toutes les zones lumineuses ont re√ßu un effet de lueur notable: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/ga/s7/yegas7stvrwhww7-a_rzdu3g_lk.png"></div><br>  Les cubes qui remplacent les sources lumineuses sont d√©sormais beaucoup plus lumineux et transmettent mieux l'impression d'une source lumineuse.  Cette sc√®ne est assez primitive, car la mise en ≈ìuvre de l'effet d'un enthousiasme sp√©cial ne provoquera pas, mais dans les sc√®nes complexes avec un √©clairage r√©fl√©chi, une floraison qualitativement r√©alis√©e peut √™tre un √©l√©ment visuel crucial qui ajoute du drame. <br><br>  Le code source de l'exemple est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Je note que la le√ßon a utilis√© un filtre assez simple avec seulement cinq √©chantillons dans chaque direction.  En faisant plus d'√©chantillons dans un rayon plus grand ou en effectuant plusieurs it√©rations du filtre, vous pouvez visuellement am√©liorer l'effet.  De plus, il convient de dire que visuellement la qualit√© de l‚Äôeffet entier d√©pend directement de la qualit√© de l‚Äôalgorithme de flou utilis√©.  En am√©liorant le filtre, vous pouvez obtenir une am√©lioration significative et l'effet global.  Par exemple, un r√©sultat plus impressionnant est montr√© par la combinaison de plusieurs filtres avec diff√©rentes tailles de noyau ou diff√©rentes courbes gaussiennes.  Les ressources suivantes de Kalogirou et EpicGames expliquent comment am√©liorer la qualit√© de la floraison en modifiant le flou gaussien. <br><br><h2>  Ressources suppl√©mentaires </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Flou gaussien efficace avec √©chantillonnage lin√©aire</a> : une description qualitative du fonctionnement du filtre gaussien, coupl√©e √† l'√©tude de l'am√©lioration des performances de la m√©thode gr√¢ce √† l'utilisation du filtrage bilin√©aire des √©chantillons de texture OpenGL. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bloom Post Process Effect</a> : Un article d'EpicGames sur l'am√©lioration de la qualit√© d'un effet en combinant plusieurs courbes de Gauss. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comment faire une bonne floraison pour le rendu HDR</a> : Un article de Kalogirou d√©crivant l'am√©lioration de la floraison en modifiant l'algorithme de filtre de Gauss d'origine. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420375/">https://habr.com/ru/post/fr420375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420363/index.html">Webinaires HPE en ao√ªt-octobre: ‚Äã‚Äãnouveaux sujets (+ SHD, pratique de l'IA, stockage cl√© en main de p√©taoctets)</a></li>
<li><a href="../fr420367/index.html">Apocalypse climatis√©e: sc√©nario de panne de r√©seau intelligent</a></li>
<li><a href="../fr420369/index.html">Extreme Extended Edge ou commutation IEEE 802.1BR</a></li>
<li><a href="../fr420371/index.html">Sur la question de la construction de v√©los dans le domaine du stockage du courrier √©lectrique</a></li>
<li><a href="../fr420373/index.html">Presque OCR pour obtenir le mot de passe VPNBook. PHP + Mikrotik</a></li>
<li><a href="../fr420377/index.html">Comment nous avons commenc√© les appels vid√©o</a></li>
<li><a href="../fr420381/index.html">Pourquoi suffit-il de consid√©rer les r√©seaux de neurones comme une bo√Æte noire?</a></li>
<li><a href="../fr420383/index.html">"Yandex.Money ne vous int√©resse pas pour saisir votre candidature."</a></li>
<li><a href="../fr420385/index.html">Tests d'int√©gration bas√©s sur des conteneurs</a></li>
<li><a href="../fr420387/index.html">Trois Rubik's Cube intelligents: Xiaomi, Roobo et GoCube</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
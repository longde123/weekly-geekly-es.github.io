<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎸 🖌️ 🕵🏻 Sequence-to-Sequence Bagian 2 Model 📚 🌌 🙎🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya! 

 Bagian kedua dari terjemahan, yang kami posting beberapa minggu yang lalu, dalam persiapan untuk peluncuran aliran kedua dari kursus...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sequence-to-Sequence Bagian 2 Model</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/432302/"> Halo semuanya! <br><br>  Bagian kedua dari terjemahan, yang kami posting beberapa minggu yang lalu, dalam persiapan untuk peluncuran aliran kedua dari kursus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Ilmuwan data"</a> .  Depan adalah bahan lain yang menarik dan pelajaran terbuka. <br><br>  Sementara itu, kami melangkah lebih jauh ke dalam hutan model. <br><br>  <b>Model terjemahan neural</b> <br><br>  Sementara inti dari model urutan-ke-urutan dibuat oleh fungsi dari <code>tensorflow/tensorflow/python/ops/seq2seq.py</code> , masih ada beberapa trik yang digunakan dalam model terjemahan kami dalam <code>models/tutorials/rnn/translate/seq2seq_model.py</code> , tentang layak disebut. <br><br><img src="https://habrastorage.org/webt/3z/s9/fy/3zs9fym7zcpeqweylxlqhknznko.png"><a name="habracut"></a><br><br>  <b>Sampel softmax dan proyeksi keluaran</b> <br><br>  Seperti disebutkan di atas, kami ingin menggunakan softmax sampel untuk bekerja dengan kamus keluaran besar.  Untuk memecahkan kode dari itu, Anda harus melacak proyeksi output.  Kehilangan softmax sampel dan proyeksi keluaran dihasilkan oleh kode berikut di <code>seq2seq_model.py</code> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> num_samples &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> num_samples &lt; self.target_vocab_size: w_t = tf.get_variable(<span class="hljs-string"><span class="hljs-string">"proj_w"</span></span>, [self.target_vocab_size, size], dtype=dtype) w = tf.transpose(w_t) b = tf.get_variable(<span class="hljs-string"><span class="hljs-string">"proj_b"</span></span>, [self.target_vocab_size], dtype=dtype) output_projection = (w, b) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sampled_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(labels, inputs)</span></span></span><span class="hljs-function">:</span></span> labels = tf.reshape(labels, [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) <span class="hljs-comment"><span class="hljs-comment"># We need to compute the sampled_softmax_loss using 32bit floats to # avoid numerical instabilities. local_w_t = tf.cast(w_t, tf.float32) local_b = tf.cast(b, tf.float32) local_inputs = tf.cast(inputs, tf.float32) return tf.cast( tf.nn.sampled_softmax_loss( weights=local_w_t, biases=local_b, labels=labels, inputs=local_inputs, num_sampled=num_samples, num_classes=self.target_vocab_size), dtype)</span></span></code> </pre><br>  Pertama, perhatikan bahwa kami hanya membuat softmax sampel jika jumlah sampel (512 secara default) kurang dari ukuran kamus target.  Untuk kamus yang lebih kecil dari 512, lebih baik menggunakan kerugian softmax standar. <br><br>  Kemudian, buat proyeksi output.  Ini adalah pasangan yang terdiri dari matriks bobot dan vektor perpindahan.  Saat digunakan, sel rnn mengembalikan vektor bentuk dari jumlah sampel pelatihan berdasarkan <code>size</code> , dan bukan jumlah sampel pelatihan dengan <code>target_vocab_size</code> .  Untuk mengembalikan log, Anda perlu mengalikannya dengan matriks bobot dan menambahkan offset, yang terjadi di baris 124-126 di <code>seq2seq_model.py</code> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> output_projection <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> xrange(len(buckets)): self.outputs[b] = [tf.matmul(output, output_projection[<span class="hljs-number"><span class="hljs-number">0</span></span>]) + output_projection[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ...]</code> </pre> <br>  <b>Bucketing dan padding</b> <br><br>  Selain softmax sampel, model terjemahan kami juga menggunakan <i>bucketing</i> , metode yang memungkinkan Anda mengelola kalimat dengan panjang berbeda secara efisien.  Untuk memulai, jelaskan masalahnya.  Ketika menerjemahkan dari Bahasa Inggris ke Bahasa Prancis, kami memiliki kalimat bahasa Inggris dengan panjang L1 yang berbeda di pintu masuk dan kalimat bahasa Prancis dengan panjang L1 yang berbeda di pintu keluar.  Karena kalimat bahasa Inggris ditransmisikan sebagai <code>encoder_inputs</code> , dan kalimat bahasa Prancis ditampilkan sebagai <code>decoder_inputs</code> (dengan awalan simbol GO), perlu untuk membuat model seq2seq untuk setiap pasangan (L1, L2 + 1) dengan panjang kalimat bahasa Inggris dan Perancis.  Sebagai hasilnya, kami mendapatkan grafik besar yang terdiri dari banyak subgraph serupa.  Di sisi lain, kita dapat "mengisi" setiap kalimat dengan karakter PAD khusus.  Dan kemudian kita hanya perlu satu model seq2seq untuk panjang "penuh".  Tetapi model seperti itu tidak akan efektif dalam kalimat pendek - Anda harus menyandikan dan mendekode banyak karakter PAD yang tidak berguna. <br><br>  Sebagai kompromi antara membuat grafik untuk setiap pasangan panjang dan isian ke panjang tunggal, kami menggunakan sejumlah ember dan barang-barang setiap kalimat dengan panjang grup di atas.  Di <code>translate.py</code> kami menggunakan grup berikut secara default. <br><br><pre> <code class="python hljs">buckets = [(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>), (<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>), (<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>)]</code> </pre> <br><br>  Dengan demikian, jika kalimat bahasa Inggris dengan 3 token tiba di input, dan kalimat Perancis yang sesuai berisi 6 token di output, maka mereka akan pergi ke grup pertama dan akan diisi hingga panjang 5 pada input encoder dan panjang 10 pada input decoder.  Dan jika ada 8 token dalam penawaran bahasa Inggris, dan dalam 18 berbahasa Perancis yang sesuai, mereka tidak akan jatuh ke dalam grup (10, 15) dan akan ditransfer ke grup (20, 25), yaitu, tawaran bahasa Inggris akan meningkat menjadi 20 token, dan yang Prancis ke 25. <br><br>  Ingat bahwa ketika membuat input dekoder, kami menambahkan karakter <code>GO</code> khusus ke input.  Ini terjadi pada fungsi <code>get_batch()</code> di <code>seq2seq_model.py</code> , yang juga membalikkan kalimat bahasa Inggris.  <a href="">Pembalikan</a> input membantu meningkatkan hasil model terjemahan saraf <a href="">Sutskever et al., 2014 (pdf).</a>  Untuk akhirnya mengetahuinya, bayangkan ada kalimat "Aku pergi." Pada input, dipecah menjadi token <code>["I", "go", "."]</code> , Dan pada output ada kalimat "Je vais.", Patah ke token <code>["Je", "vais", "."]</code> .  Mereka akan ditambahkan ke grup (5, 10), dengan representasi dari enkoder input <code>[PAD PAD "." "go" "I"]</code>  <code>[PAD PAD "." "go" "I"]</code> dan dekoder masukan <code>[GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]</code>  <code>[GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]</code> . <br><br>  <b>Jalankan itu</b> <br><br>  Untuk melatih model yang dijelaskan di atas, Anda akan membutuhkan korps Anglo-Prancis yang besar.  Untuk pelatihan, kami akan menggunakan 10 ^ 9 korps Prancis-Inggris dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">situs web WMT'15</a> , dan menguji berita dari situs yang sama sebagai sampel yang berfungsi.  Kedua dataset akan dimuat ke <code>train_dir</code> ketika perintah selanjutnya dijalankan. <br><br><pre> <code class="plaintext hljs">python translate.py --data_dir [your_data_directory] --train_dir [checkpoints_directory] --en_vocab_size=40000 --fr_vocab_size=40000</code> </pre> <br>  Anda akan membutuhkan ruang hard drive 18GB dan beberapa jam untuk mempersiapkan gedung pelatihan.  <code>data_dir,</code> file kamus dibuat di <code>data_dir,</code> dan setelah itu <code>data_dir,</code> dan dikonversi ke pengidentifikasi bilangan bulat.  Perhatikan parameter yang bertanggung jawab untuk ukuran kamus.  Pada contoh di atas, semua kata di luar 40.000 kata yang paling sering digunakan akan dikonversi menjadi token UNK yang mewakili kata yang tidak dikenal.  Jadi, ketika mengubah ukuran kamus, biner akan mereformasi perumahan dengan token-id.  Setelah pelatihan persiapan data dimulai. <br><br>  Nilai yang ditentukan dalam <code>translate</code> sangat tinggi secara default.  Model-model besar yang belajar untuk waktu yang lama menunjukkan hasil yang baik, tetapi dapat memakan waktu terlalu banyak atau terlalu banyak memori GPU.  Anda dapat menentukan latihan model yang lebih kecil, seperti pada contoh di bawah ini. <br><br><pre> <code class="plaintext hljs">python translate.py --data_dir [your_data_directory] --train_dir [checkpoints_directory] --size=256 --num_layers=2 --steps_per_checkpoint=50</code> </pre> <br>  Perintah di atas akan melatih model dengan dua lapisan (secara default ada 3), yang masing-masing memiliki 256 unit (default - 1024), dengan pos pemeriksaan di setiap 50 langkah (default - 200).  Lakukan percobaan dengan opsi ini untuk melihat model ukuran mana yang tepat untuk GPU Anda. <br><br>  Selama pelatihan, setiap langkah biner <code>steps_per_checkpoin</code> t akan memberikan statistik tentang langkah-langkah sebelumnya.  Dengan parameter default (3 layer ukuran 1024), pesan pertama adalah sebagai berikut: <br><br><pre> <code class="plaintext hljs">global step 200 learning rate 0.5000 step-time 1.39 perplexity 1720.62 eval: bucket 0 perplexity 184.97 eval: bucket 1 perplexity 248.81 eval: bucket 2 perplexity 341.64 eval: bucket 3 perplexity 469.04 global step 400 learning rate 0.5000 step-time 1.38 perplexity 379.89 eval: bucket 0 perplexity 151.32 eval: bucket 1 perplexity 190.36 eval: bucket 2 perplexity 227.46 eval: bucket 3 perplexity 238.66</code> </pre> <br>  Perhatikan bahwa setiap langkah membutuhkan waktu kurang dari 1,4 detik, membingungkan sampel pelatihan dan membingungkan sampel kerja di masing-masing kelompok.  Setelah sekitar 30 ribu langkah, kita melihat bagaimana kebingungan kalimat pendek (grup 0 dan 1) menjadi tidak ambigu.  Gedung pelatihan berisi sekitar 22 juta kalimat, satu iterasi (satu run data pelatihan) memakan waktu sekitar 340 ribu langkah dengan jumlah sampel pelatihan dalam jumlah 64. Pada tahap ini, model dapat digunakan untuk menerjemahkan kalimat bahasa Inggris ke dalam bahasa Prancis menggunakan opsi <code>--decode</code> . <br><br><pre> <code class="plaintext hljs">python translate.py --decode --data_dir [your_data_directory] --train_dir [checkpoints_directory] Reading model parameters from /tmp/translate.ckpt-340000 &gt; Who is the president of the United States? Qui est le président des États-Unis ?</code> </pre> <br>  <b>Apa selanjutnya</b> <br><br>  Contoh di atas menunjukkan cara membuat penerjemah Bahasa Inggris-Prancis Anda sendiri dari ujung ke ujung.  Jalankan dan lihat bagaimana model bekerja.  Kualitasnya dapat diterima, tetapi model terjemahan yang ideal tidak dapat diperoleh dengan parameter default.  Berikut adalah beberapa hal yang dapat Anda tingkatkan. <br><br>  Pertama, kami menggunakan tokenization primitif, fungsi dasar dari <code>basic_tokenizer</code> di <code>data_utils</code> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tokenizer yang</a> lebih baik dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">situs web WMT'15</a> .  Jika Anda menggunakannya dan kamus besar, Anda bisa mendapatkan terjemahan yang lebih baik. <br><br>  Selain itu, parameter default model terjemahan tidak dikonfigurasikan dengan sempurna.  Anda dapat mencoba mengubah kecepatan belajar, redaman, inisialisasi bobot model.  Anda juga dapat mengganti <code>GradientDescentOptimizer</code> standar di <code>seq2seq_model.py</code> dengan sesuatu yang lebih maju, seperti <code>AdagradOptimizer</code> .  Coba dan perhatikan untuk hasil yang lebih baik! <br><br>  Akhirnya, model yang disajikan di atas dapat digunakan tidak hanya untuk terjemahan, tetapi juga untuk tugas urutan-ke-urutan lainnya.  Bahkan jika Anda ingin mengubah urutan menjadi pohon, misalnya, menghasilkan pohon parse, model ini dapat menghasilkan hasil yang canggih, seperti yang ditunjukkan oleh <a href="">Vinyals &amp; Kaiser et al., 2014 (pdf)</a> .  Jadi, Anda tidak hanya dapat membuat penerjemah, tetapi juga parser, chat bot, atau program lain yang Anda inginkan.  Eksperimen! <br><br>  Itu saja! <br><br>  Kami menunggu komentar dan pertanyaan Anda di sini atau kami mengundang Anda untuk bertanya kepada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">guru</a> mereka dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pelajaran terbuka</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id432302/">https://habr.com/ru/post/id432302/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id432292/index.html">Font variabel dan parametrik - win-win untuk desainer</a></li>
<li><a href="../id432294/index.html">Ansible Tower: Workflow Job Templates</a></li>
<li><a href="../id432296/index.html">Google membuat Anda dalam "gelembung pencarian" pribadi meskipun Anda keluar dari akun</a></li>
<li><a href="../id432298/index.html">Timeweb memasukkan pendaftar domain TOP-10 di zona .RU</a></li>
<li><a href="../id432300/index.html">Dukungan, layanan, sakit kepala, dan semuanya</a></li>
<li><a href="../id432304/index.html">Seorang ilmuwan saraf yang brilian yang mungkin memiliki kunci untuk menciptakan kecerdasan buatan sejati</a></li>
<li><a href="../id432306/index.html">Kelas Penyimpanan Memori dalam penyimpanan - jika Anda membutuhkannya lebih cepat</a></li>
<li><a href="../id432308/index.html">Tingkat modular Sci-Fi UE4: terinspirasi oleh Nostromo dan Serenity</a></li>
<li><a href="../id432310/index.html">Ktor sebagai klien HTTP untuk Android</a></li>
<li><a href="../id432312/index.html">Buat Peta Bentuk peta RF di Power BI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
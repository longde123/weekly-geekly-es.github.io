<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõèÔ∏è üïäÔ∏è üôÜ Comment couper un monolithe en services et maintenir les performances des caches en m√©moire sans perdre en coh√©rence üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ üë≤üèΩ üéöÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous. Je m'appelle Alexander, je suis d√©veloppeur Java dans le groupe d'entreprises Tinkoff. 

 Dans cet article, je souhaite partager mon e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment couper un monolithe en services et maintenir les performances des caches en m√©moire sans perdre en coh√©rence</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/tinkoff/blog/474994/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/io/g8/yg/iog8ygcpquu5zvi7xmlsecbbwmu.png"></div><br>  Bonjour √† tous.  Je m'appelle Alexander, je suis d√©veloppeur Java dans le groupe d'entreprises Tinkoff. <br><br>  Dans cet article, je souhaite partager mon exp√©rience dans la r√©solution de probl√®mes li√©s √† la synchronisation de l'√©tat des caches dans les syst√®mes distribu√©s.  Nous les avons rencontr√©s, brisant notre application monolithique en <s>microservices</s> .  √âvidemment, nous parlerons de la mise en cache des donn√©es au niveau de la JVM, car avec les caches externes, les probl√®mes de synchronisation sont r√©solus en dehors du contexte de l'application. <br><br>  Dans cet article, je parlerai de notre exp√©rience du passage √† une architecture orient√©e services, accompagn√©e d'un passage √† Kubernetes, et de la r√©solution des probl√®mes associ√©s.  Nous examinerons l'approche de l'organisation du syst√®me de mise en cache distribu√© IMDG (In-Memory Data Grid), ses avantages et ses inconv√©nients, raison pour laquelle nous avons d√©cid√© d'√©crire notre propre solution. <br><br>  Cet article d√©crit un projet dont le backend est √©crit en Java.  Par cons√©quent, nous parlerons √©galement des normes dans le domaine de la mise en cache temporaire en m√©moire.  Nous discutons de la sp√©cification JSR-107, de la sp√©cification JSR-347 d√©faillante et des fonctionnalit√©s de mise en cache dans Spring.  Bienvenue au chat! <br><a name="habracut"></a><br><br><h1>  Et d√©coupons l'application en services ... </h1><br>  Nous allons passer √† une architecture orient√©e services et passer √† Kubernetes - c'est ce que nous avons d√©cid√© il y a un peu plus de 6 mois.  Pendant longtemps, notre projet a √©t√© un monolithe, de nombreux probl√®mes li√©s √† la dette technique se sont accumul√©s, et nous avons √©crit de nouveaux modules d'application comme des services s√©par√©s.  En cons√©quence, la transition vers une architecture orient√©e services et une coupe monolithique √©tait in√©vitable. <br><br>  Notre application est charg√©e, en moyenne 500 rps vient aux services web (en pointe elle atteint 900 rps).  Afin de collecter l'int√©gralit√© du mod√®le de donn√©es en r√©ponse √† chaque demande, vous devez vous rendre plusieurs centaines de fois dans les diff√©rents caches. <br><br>  Nous essayons d'acc√©der au cache distant pas plus de trois fois par demande, en fonction de l'ensemble de donn√©es requis, et sur les caches JVM internes, la charge atteint 90 000 rps par cache.  Nous avons environ 30 caches de ce type pour diverses entit√©s et DTO-shki.  Sur certains caches charg√©s, nous ne pouvons m√™me pas nous permettre de supprimer la valeur, car cela peut entra√Æner une augmentation du temps de r√©ponse des services Web et un plantage de l'application. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mn/db/2v/mndb2vp6ot9byy_fqysaooom6j0.png"></div><br>  Voici √† quoi ressemble la surveillance de la charge, supprim√©e des caches internes sur chaque n≈ìud pendant la journ√©e.  Selon le profil de charge, il est facile de voir que la plupart des demandes sont des donn√©es lues.  Une charge d'√©criture uniforme est due √† la mise √† jour des valeurs dans les caches √† une fr√©quence donn√©e. <br><br>  Les temps d'arr√™t ne sont pas valables pour notre application.  Par cons√©quent, dans le but d'un d√©ploiement transparent, nous avons toujours √©quilibr√© tout le trafic entrant sur deux n≈ìuds et d√©ploy√© l'application √† l'aide de la m√©thode Rolling Update.  Kubernetes est devenu notre solution d'infrastructure id√©ale lors du passage aux services.  Ainsi, nous avons r√©solu plusieurs probl√®mes √† la fois. <br><br><h3>  Le probl√®me de la commande et de la mise en place permanente d'infrastructures pour de nouveaux services </h3><br>  On nous a donn√© un espace de noms dans le cluster pour chaque circuit, que nous avons trois: dev - pour les d√©veloppeurs, qa - pour les testeurs, prod - pour les clients. <br><br>  Avec l'espace de noms en surbrillance, l'ajout d'un nouveau service ou d'une nouvelle application revient √† √©crire quatre manifestes: D√©ploiement, Service, Ingress et ConfigMap. <br><br><h3>  Tol√©rance de charge √©lev√©e </h3><br>  L'entreprise est en expansion et en croissance constante - il y a un an, la charge moyenne √©tait deux fois inf√©rieure √† celle actuelle. <br><br>  La mise √† l'√©chelle horizontale dans Kubernetes vous permet de niveler les √©conomies d'√©chelle avec l'augmentation de la charge de travail du projet d√©velopp√©. <br><br><h3>  Maintenance, collecte de journaux et surveillance </h3><br>  La vie devient beaucoup plus facile lorsqu'il n'est pas n√©cessaire d'ajouter des journaux au syst√®me de journalisation lors de l'ajout de chaque n≈ìud, de configurer la cl√¥ture des m√©triques (sauf si vous avez un syst√®me de surveillance push), d'effectuer les param√®tres r√©seau et d'installer simplement le logiciel n√©cessaire au fonctionnement. <br><br>  Bien s√ªr, tout cela peut √™tre automatis√© en utilisant Ansible ou Terraform, mais au final, l'√©criture de plusieurs manifestes pour chaque service est beaucoup plus facile. <br><br><h3>  Haute fiabilit√© </h3><br>  Le m√©canisme int√©gr√© k8s des √©chantillons Liveness et Readiness vous permet de ne pas vous inqui√©ter du fait que l'application a commenc√© √† ralentir ou √† cesser compl√®tement de r√©pondre. <br><br>  Kubernetes contr√¥le d√©sormais le cycle de vie des modules de foyer contenant des conteneurs d'applications et le trafic qui leur est achemin√©. <br><br>  Avec les √©quipements d√©crits, nous devions r√©soudre un certain nombre de probl√®mes afin de rendre les services adapt√©s √† une mise √† l'√©chelle horizontale et √† l'utilisation d'un mod√®le de donn√©es commun pour de nombreux services.  Il fallait r√©soudre deux probl√®mes: <br><br><ol><li>  <b>L'√©tat de l'application.</b>  Lorsque le projet est d√©ploy√© dans le cluster k8s, des pods contenant des conteneurs de la nouvelle version de l'application commencent √† √™tre cr√©√©s et ne sont pas li√©s √† l'√©tat des pods de la version pr√©c√©dente.  De nouveaux modules d'application peuvent √™tre cr√©√©s sur des serveurs de cluster arbitraires qui satisfont aux restrictions sp√©cifi√©es.  De plus, d√©sormais, chaque conteneur d'application ex√©cut√© dans le pod Kubernetes peut √™tre d√©truit √† tout moment si la sonde Liveness indique qu'il doit √™tre red√©marr√©. </li><li>  <b>Coh√©rence des donn√©es.</b>  Il est n√©cessaire de maintenir la coh√©rence et l'int√©grit√© des donn√©es les uns avec les autres √† tous les n≈ìuds.  Cela est particuli√®rement vrai si plusieurs n≈ìuds fonctionnent dans un m√™me mod√®le de donn√©es.  Il est inacceptable que lorsque des demandes sont adress√©es √† diff√©rents n≈ìuds de l'application dans la r√©ponse, des donn√©es incoh√©rentes parviennent au client. </li></ol><br>  Dans le d√©veloppement moderne de syst√®mes √©volutifs, l'architecture sans √©tat est la solution aux probl√®mes ci-dessus.  Nous nous sommes d√©barrass√©s du premier probl√®me en d√©pla√ßant toutes les statistiques vers le stockage cloud S3. <br><br>  Cependant, en raison de la n√©cessit√© d'agr√©ger un mod√®le de donn√©es complexe et d'√©conomiser le temps de r√©ponse de nos services Web, nous ne pouvions pas refuser de stocker les donn√©es dans des caches en m√©moire.  Pour r√©soudre le deuxi√®me probl√®me, ils ont √©crit une biblioth√®que pour synchroniser l'√©tat des caches internes des n≈ìuds individuels. <br><br><h1>  Nous synchronisons les caches sur des n≈ìuds s√©par√©s </h1><br>  Comme donn√©es initiales, nous avons un syst√®me distribu√© compos√© de N n≈ìuds.  Chaque n≈ìud poss√®de environ 20 caches en m√©moire, dont les donn√©es sont mises √† jour plusieurs fois par heure. <br><br>  La plupart des caches ont une politique d'actualisation des donn√©es TTL (dur√©e de vie), certaines donn√©es sont mises √† jour avec une op√©ration CRON toutes les 20 minutes en raison de la charge √©lev√©e.  La charge de travail sur les caches varie de plusieurs milliers de rps la nuit √† plusieurs dizaines de milliers pendant la journ√©e.  La charge de pointe, en r√®gle g√©n√©rale, ne d√©passe pas 100 000 rps.  Le nombre d'enregistrements dans un stockage temporaire ne d√©passe pas plusieurs centaines de milliers et est plac√© dans le tas d'un n≈ìud. <br><br>  Notre t√¢che consiste √† assurer la coh√©rence des donn√©es entre le m√™me cache sur diff√©rents n≈ìuds, ainsi que le temps de r√©ponse le plus court possible.  R√©fl√©chissez aux moyens de r√©soudre g√©n√©ralement ce probl√®me. <br><br>  La premi√®re et la plus simple solution qui vient √† l'esprit est de mettre toutes les informations dans un cache distant.  Dans ce cas, vous pouvez vous d√©barrasser compl√®tement de l'√©tat de l'application, ne pas penser aux probl√®mes de coh√©rence et disposer d'un point d'acc√®s unique √† un entrep√¥t de donn√©es temporaire. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ez/zm/bg/ezzmbg3cuvhczrwpwmh5hg5a0-o.png"></div><br>  Cette m√©thode de stockage temporaire des donn√©es est assez simple et nous l'utilisons.  Nous mettons en cache une partie des donn√©es dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Redis</a> , qui est un stockage de donn√©es NoSQL en RAM.  Dans Redis, nous enregistrons g√©n√©ralement un cadre de r√©ponse de service Web, et pour chaque demande, nous devons enrichir ces donn√©es avec des informations pertinentes, ce qui n√©cessite d'envoyer plusieurs centaines de demandes au cache local. <br><br>  √âvidemment, nous ne pouvons pas extraire les donn√©es des caches internes pour le stockage √† distance, car le co√ªt de transmission d'un tel volume de trafic sur le r√©seau ne nous permettra pas de respecter le temps de r√©ponse requis. <br><br>  La deuxi√®me option consiste √† utiliser une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">grille de donn√©es en m√©moire</a> (IMDG), qui est un cache distribu√© en m√©moire.  Le sch√©ma d'une telle solution est le suivant: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l7/ku/k9/l7kuk9uaiuydck1hs1boeykflys.png"></div><br>  L'architecture IMDG est bas√©e sur le principe du partitionnement des donn√©es des caches internes des n≈ìuds individuels.  En fait, cela peut √™tre appel√© une table de hachage distribu√©e sur un cluster de n≈ìuds.  IMDG est consid√©r√© comme l'une des impl√©mentations les plus rapides du stockage distribu√© temporaire. <br><br>  Il existe de nombreuses impl√©mentations IMDG, la plus populaire √©tant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hazelcast</a> .  Le cache distribu√© vous permet de stocker des donn√©es dans la RAM sur plusieurs n≈ìuds d'application avec un niveau acceptable de fiabilit√© et de pr√©servation de la coh√©rence, ce qui est obtenu par la r√©plication des donn√©es. <br><br>  La t√¢che de construire un tel cache distribu√© n'est pas facile, mais l'utilisation d'une solution IMDG pr√™te √† l'emploi pour nous pourrait devenir un bon remplacement pour les caches JVM et √©liminer les probl√®mes de r√©plication, de coh√©rence et de distribution des donn√©es entre tous les n≈ìuds d'application. <br><br>  La plupart des fournisseurs IMDG pour les applications Java impl√©mentent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">JSR-107</a> , l'API Java standard pour travailler avec des caches internes.  En g√©n√©ral, cette norme a une histoire assez importante, dont je parlerai plus en d√©tail ci-dessous. <br><br>  Il √©tait une fois des id√©es pour impl√©menter votre interface pour interagir avec IMDG - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">JSR 347</a> .  Mais la mise en ≈ìuvre d'une telle API n'a pas re√ßu un soutien suffisant de la communaut√© Java, et nous avons maintenant une interface unique pour interagir avec les caches en m√©moire, quelle que soit l'architecture de notre application.  Bon ou mauvais est une autre question, mais cela nous permet d'ignorer compl√®tement toutes les difficult√©s de mise en ≈ìuvre d'un cache In-memory distribu√© et de travailler avec lui comme cache d'une application monolithique. <br><br>  Malgr√© les avantages √©vidents de l'utilisation d'IMDG, cette solution est toujours plus lente que le cache JVM standard, en raison de la surcharge n√©cessaire pour assurer la r√©plication continue des donn√©es r√©parties entre plusieurs n≈ìuds JVM, ainsi que la sauvegarde de ces donn√©es.  Dans notre cas, la quantit√© de donn√©es pour le stockage temporaire n'√©tait pas si grande, les donn√©es avec une marge s'inscrivaient dans la m√©moire d'une application, donc leur allocation √† plusieurs JVM semblait une solution inutile.  Et le trafic r√©seau suppl√©mentaire entre les n≈ìuds d'application soumis √† de lourdes charges peut avoir un impact consid√©rable sur les performances et augmenter le temps de r√©ponse des services Web.  Finalement, nous avons d√©cid√© d'√©crire notre propre solution √† ce probl√®me. <br><br>  Nous avons laiss√© des caches en m√©moire comme stockage temporaire de donn√©es et pour maintenir la coh√©rence, nous avons utilis√© le gestionnaire de files d'attente RabbitMQ.  Nous avons adopt√© le mod√®le de conception comportementale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Publisher - Subscriber¬ª</a> et maintenu la pertinence des donn√©es en supprimant l'enregistrement modifi√© du cache de chaque n≈ìud.  Le sch√©ma de solution est le suivant: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/05/y9/di/05y9dihavtlltrsgxxnkvuj5bhs.png"></div><br>  Le diagramme montre un cluster de N n≈ìuds, chacun ayant un cache en m√©moire standard.  Tous les n≈ìuds utilisent un mod√®le de donn√©es commun et doivent √™tre coh√©rents.  Lors du premier acc√®s au cache par une cl√© arbitraire, la valeur dans le cache est absente et nous y mettons la valeur r√©elle de la base de donn√©es.  Avec tout changement - supprimez l'enregistrement. <br><br>  Les informations r√©elles dans la r√©ponse de cache ici sont fournies en synchronisant la suppression d'une entr√©e lorsqu'elle est modifi√©e sur l'un des n≈ìuds.  Chaque n≈ìud du syst√®me a une file d'attente dans le gestionnaire de files d'attente RabbitMQ.  L'enregistrement dans toutes les files d'attente s'effectue via un point d'acc√®s de type Sujet commun.  Cela signifie que les messages envoy√©s au sujet tombent dans toutes les files d'attente qui lui sont associ√©es.  Ainsi, lors de la modification de la valeur sur n'importe quel n≈ìud du syst√®me, cette valeur sera supprim√©e du stockage temporaire de chaque n≈ìud, et l'acc√®s suivant lancera l'√©criture de la valeur actuelle dans le cache √† partir de la base de donn√©es. <br><br>  Soit dit en passant, un m√©canisme PUB / SUB similaire existe dans Redis.  Mais, √† mon avis, il est toujours pr√©f√©rable d'utiliser le gestionnaire de files d'attente pour travailler avec les files d'attente, et RabbitMQ √©tait parfait pour notre t√¢che. <br><br><h1>  Norme JSR 107 et sa mise en ≈ìuvre </h1><br>  L'API Java Cache standard pour le stockage temporaire des donn√©es en m√©moire (sp√©cification <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">JSR-107</a> ) a une histoire assez longue; elle a √©t√© d√©velopp√©e pendant 12 ans. <br><br>  Pendant si longtemps, les approches de d√©veloppement de logiciels ont chang√©, les monolithes ont √©t√© remplac√©s par une architecture de microservices.  En raison d'un manque de sp√©cifications aussi long pour l'API Cache, il y a m√™me eu des demandes pour d√©velopper des caches API pour les syst√®mes distribu√©s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">JSR-347</a> (Data Grids for the Java Platform).  Mais apr√®s la sortie tant attendue de JSR-107 et la sortie de JCache, la demande de cr√©er une sp√©cification distincte pour les syst√®mes distribu√©s a √©t√© retir√©e. <br><br>  Au cours des 12 longues ann√©es sur le march√©, le lieu de stockage temporaire des donn√©es est pass√© de HashMap √† ConcurrentHashMap avec la sortie de Java 1.5, et plus tard, de nombreuses impl√©mentations open source pr√™tes √† l'emploi de la mise en cache en m√©moire sont apparues. <br><br>  Apr√®s la sortie de JSR-107, les solutions des fournisseurs ont commenc√© √† impl√©menter progressivement la nouvelle sp√©cification.  Pour JCache, il existe m√™me des fournisseurs sp√©cialis√©s dans la mise en cache distribu√©e - les m√™mes grilles de donn√©es, dont la sp√©cification n'a jamais √©t√© impl√©ment√©e. <br><br>  Consid√©rez en quoi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">consiste le</a> package <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">javax.cache</a> et comment obtenir une instance de cache pour notre application: <br><pre><code class="java hljs">CachingProvider provider = Caching.getCachingProvider(<span class="hljs-string"><span class="hljs-string">"org.cache2k.jcache.provider.JCacheProvider"</span></span>); CacheManager cacheManager = provider.getCacheManager(); CacheConfiguration&lt;Integer, String&gt; config = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MutableConfiguration&lt;Integer, String&gt;() .setTypes(Integer.class, String.class) .setReadThrough(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>) . . .; Cache&lt;Integer, String&gt; cache = cacheManager.createCache(cacheName, config);</code> </pre> <br>  Ici, Caching est un chargeur de d√©marrage pour CachingProvider. <br><br>  Dans notre cas, JCacheProvider, qui est l'impl√©mentation cache2k du fournisseur JSR-107 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SPI</a> , sera charg√© √† partir de ClassLoader.  Pour le chargeur, vous n'aurez peut-√™tre pas √† sp√©cifier l'impl√©mentation du fournisseur, mais il essaiera alors de charger l'impl√©mentation qui se trouve dans <br><blockquote>  META-INF / services / javax.cache.spi.CachingProvider </blockquote><br>  Dans tous les cas, dans ClassLoader, il devrait y avoir une seule impl√©mentation de CachingProvider. <br><br>  Si vous utilisez la biblioth√®que javax.cache sans aucune impl√©mentation, une exception sera lev√©e lorsque vous essayez de cr√©er JCache.  Le but du fournisseur est de cr√©er et de g√©rer le cycle de vie de CacheManager, qui, √† son tour, est responsable de la gestion et de la configuration des caches.  Ainsi, pour cr√©er un cache, vous devez proc√©der comme suit: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fx/lp/fs/fxlpfsdfmlifqegpwtaynhiakt8.png"></div><br>  Les caches standard cr√©√©s √† l'aide de CacheManager doivent avoir une configuration compatible avec l'impl√©mentation.  La CacheConfiguration param√©tr√©e standard fournie par javax.cache peut √™tre √©tendue √† une impl√©mentation CacheProvider sp√©cifique. <br><br>  Aujourd'hui, il existe des dizaines d'impl√©mentations diff√©rentes de la sp√©cification JSR-107: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ehcache</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Guava</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">caf√©ine</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cache2k</a> .  De nombreuses impl√©mentations sont des grilles de donn√©es en m√©moire dans les syst√®mes distribu√©s - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hazelcast</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Oracle Coherence</a> . <br><br>  Il existe √©galement de nombreuses impl√©mentations de stockage temporaire qui ne prennent pas en charge l'API standard.  Pendant longtemps dans notre projet, nous avons utilis√© Ehcache 2, qui n'est pas compatible avec JCache (l'impl√©mentation de la sp√©cification est apparue avec Ehcache 3).  La n√©cessit√© d'une transition vers une impl√©mentation compatible JCache est apparue avec la n√©cessit√© de surveiller l'√©tat des caches en m√©moire.  √Ä l'aide de MetricRegistry standard, il a √©t√© possible de s√©curiser la surveillance uniquement √† l'aide de l'impl√©mentation JCacheGaugeSet, qui collecte des m√©triques √† partir de JCache standard. <br><br>  Comment choisir l'impl√©mentation du cache en m√©moire appropri√©e pour votre projet?  Vous devriez peut-√™tre faire attention aux points suivants: <br><br><ol><li>  Avez-vous besoin d'une assistance pour la sp√©cification JSR-107? </li><li>  Il convient √©galement de pr√™ter attention √† la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapidit√© de la</a> mise en ≈ìuvre s√©lectionn√©e.  Sous de fortes charges, les performances des caches internes peuvent avoir un impact significatif sur le temps de r√©ponse de votre syst√®me. </li><li>  Support au printemps.  Si vous utilisez le framework bien connu dans votre projet, il convient de prendre en compte le fait que toutes les impl√©mentations de cache JVM n'ont pas de CacheManager compatible dans Spring. </li></ol><br>  Si vous, comme nous, utilisez activement Spring dans votre projet, alors pour la mise en cache des donn√©es, vous adh√©rez tr√®s probablement √† l'approche orient√©e aspect (AOP) et utilisez l'annotation @Cacheable.  Spring utilise son propre SPI CacheManager pour que les aspects fonctionnent.  Le bean suivant est requis pour que les caches de printemps fonctionnent: <br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> org.springframework.cache.<span class="hljs-function"><span class="hljs-function">CacheManager </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cacheManager</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ CachingProvider provider = Caching.getCachingProvider(); CacheManager cacheManager = provider.getCacheManager(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JCacheCacheManager(cacheManager); }</code> </pre><br>  Pour travailler avec des caches dans le paradigme AOP, des consid√©rations transactionnelles doivent √©galement √™tre prises en compte.  Le cache de printemps doit n√©cessairement prendre en charge la gestion des transactions.  √Ä cette fin, spring CacheManager h√©rite des propri√©t√©s AbstractTransactionSupportingCacheManager, qui peuvent √™tre utilis√©es pour synchroniser les op√©rations put- / expict effectu√©es dans une transaction et les ex√©cuter uniquement apr√®s qu'une transaction r√©ussie a √©t√© valid√©e. <br><br>  L'exemple ci-dessus montre l'utilisation du wrapper JCacheCacheManager pour le gestionnaire de sp√©cifications de cache.  Cela signifie que toute impl√©mentation JSR-107 est √©galement compatible avec Spring CacheManager.  C'est une autre raison de choisir un cache en m√©moire avec prise en charge de la sp√©cification JSR pour votre projet.  Mais si ce support n'est toujours pas n√©cessaire, mais je veux vraiment utiliser @Cacheable, alors vous avez le support pour deux autres solutions de cache interne: EhCacheCacheManager et CaffeineCacheManager. <br><br>  Lors du choix de l'impl√©mentation du cache en m√©moire, nous n'avons pas pris en compte la prise en charge d'IMDG pour les syst√®mes distribu√©s, comme mentionn√© pr√©c√©demment.  Pour maintenir les performances des caches JVM sur notre syst√®me, nous avons √©crit notre propre solution. <br><br><h1>  Effacement des caches dans un syst√®me distribu√© </h1><br>  Les IMDG modernes utilis√©s dans les projets avec une architecture de microservices vous permettent de r√©partir les donn√©es en m√©moire entre tous les n≈ìuds de travail du syst√®me en utilisant un partitionnement de donn√©es √©volutif avec le niveau de redondance requis. <br><br>  Dans ce cas, de nombreux probl√®mes sont associ√©s √† la synchronisation, √† la coh√©rence des donn√©es, etc., sans parler de l'augmentation du temps d'acc√®s au stockage temporaire.  Un tel sch√©ma est redondant si la quantit√© de donn√©es utilis√©es tient dans la RAM d'un n≈ìud, et pour maintenir la coh√©rence des donn√©es, il suffit de supprimer cette entr√©e sur tous les n≈ìuds pour toute modification de la valeur du cache. <br><br>  Lors de la mise en ≈ìuvre d'une telle solution, l'id√©e d'utiliser certains EventListener vient d'abord √† l'esprit, dans JCache, il existe un CacheEntryRemovedListener pour l'√©v√©nement de suppression d'une entr√©e du cache.  Il semble qu'il suffit d'ajouter votre propre impl√©mentation d'√©couteur, qui enverra des messages au sujet lorsque l'enregistrement est supprim√©, et le cache eutectique sur tous les n≈ìuds est pr√™t - √† condition que chaque n≈ìud √©coute les √©v√©nements de la file d'attente associ√©e au sujet g√©n√©ral, comme le montre le diagramme ci-dessus. <br><br>  Lors de l'utilisation de cette solution, les donn√©es sur diff√©rents n≈ìuds seront incoh√©rentes en raison du fait que les listes d'√©v√©nements dans tout processus d'impl√©mentation JCache apr√®s qu'un √©v√©nement se soit produit.  Autrement dit, s'il n'y a pas d'enregistrement dans le cache local pour la cl√© donn√©e, mais qu'il existe un enregistrement pour la m√™me cl√© sur un autre n≈ìud, l'√©v√©nement ne sera pas envoy√© au sujet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_a/ev/5c/_aev5cw333ni_cnstj5elxbowhw.png"></div><br>  Examinez les autres moyens disponibles pour intercepter l'√©v√©nement d'une valeur supprim√©e du cache local. <br><br>  Dans le package javax.cache.event, √† c√¥t√© d'EventListeners, il y a √©galement un CacheEntryEventFilter, qui, selon JavaDoc, est utilis√© pour v√©rifier tout √©v√©nement CacheEntryEvent avant de passer cet √©v√©nement √† CacheEntryListener, qu'il s'agisse d'un enregistrement, d'une suppression, d'une mise √† jour ou d'un √©v√©nement li√© √† l'expiration de l'enregistrement en cache.  Lors de l'utilisation du filtre, notre probl√®me restera, car la logique sera ex√©cut√©e apr√®s l'enregistrement de l'√©v√©nement CacheEntryEvent et apr√®s l'ex√©cution de l'op√©ration CRUD dans le cache. <br><br>  N√©anmoins, il est possible de rattraper le d√©clenchement d'un √©v√©nement pour supprimer un enregistrement du cache.  Pour ce faire, utilisez l'outil int√©gr√© dans JCache qui vous permet d'utiliser les sp√©cifications de l'API pour √©crire et charger des donn√©es √† partir d'une source externe, si elles ne sont pas dans le cache.  Il existe deux interfaces pour cela dans le package javax.cache.integration: <br><br><ul><li>  CacheLoader - pour charger les donn√©es demand√©es par la cl√©, s'il n'y a aucune entr√©e dans le cache. </li><li>  CacheWriter - pour utiliser l'√©criture, la suppression et la mise √† jour des donn√©es sur une ressource externe lors de l'appel des op√©rations de cache correspondantes. </li></ul><br>  Pour garantir la coh√©rence, les m√©thodes CacheWriter sont atomiques par rapport √† l'op√©ration de cache correspondante.  Nous semblons avoir trouv√© une solution √† notre probl√®me. <br><br>  Nous pouvons maintenant maintenir la coh√©rence de la r√©ponse des caches en m√©moire sur les n≈ìuds lors de l'utilisation de notre impl√©mentation de CacheWriter, qui envoie des √©v√©nements √† la rubrique RabbitMQ chaque fois qu'il y a un changement dans l'enregistrement dans le cache local. <br><br><h1>  Conclusion </h1><br>  Lors du d√©veloppement de tout projet, lors de la recherche d'une solution adapt√©e aux probl√®mes √©mergents, il faut tenir compte de sa sp√©cificit√©.  Dans notre cas, les caract√©ristiques du mod√®le de donn√©es du projet, le code h√©rit√© h√©rit√© et la nature de la charge n'ont permis d'utiliser aucune des solutions existantes au probl√®me de mise en cache distribu√©e. <br><br>  Il est tr√®s difficile de rendre une impl√©mentation universelle applicable √† tout syst√®me d√©velopp√©.  Pour chacune de ces impl√©mentations, il existe des conditions optimales d'utilisation.  Dans notre cas, les sp√©cificit√©s du projet ont conduit √† la solution d√©crite dans cet article.  Si quelqu'un a un probl√®me similaire, nous serons heureux de partager notre solution et de la publier sur GitHub. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474994/">https://habr.com/ru/post/fr474994/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474982/index.html">Tutoriel JavaFX: FXML et SceneBuilder</a></li>
<li><a href="../fr474984/index.html">RabbitMQ contre Kafka: basculement et haute disponibilit√©</a></li>
<li><a href="../fr474988/index.html">Bienvenue chez Mitap: Carri√®res chez Data Science pour d√©butants</a></li>
<li><a href="../fr474990/index.html">Pratique: comment cr√©er un r√©seau Wi-Fi dans un parc de la ville</a></li>
<li><a href="../fr474992/index.html">Analyse des batteries d'ordinateurs portables d√©fectueuses. Notes de motard √©lectrique</a></li>
<li><a href="../fr474996/index.html">Le r√©sum√© des √©v√©nements informatiques de novembre (deuxi√®me partie)</a></li>
<li><a href="../fr475000/index.html">Test public du cloud Ethereum et des solutions de confidentialit√© et d'√©volutivit√© du cloud</a></li>
<li><a href="../fr475002/index.html">Le travail n'est pas un loup, partie 2. Passez le boss et survivez en probation</a></li>
<li><a href="../fr475004/index.html">Combien les d√©veloppeurs de diff√©rentes qualifications ont-ils gagn√© au premier semestre 2019</a></li>
<li><a href="../fr475006/index.html">Comment cr√©er un prototype de service de comparaison de documents en 28 heures et gagner un hackathon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
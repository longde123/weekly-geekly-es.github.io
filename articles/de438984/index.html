<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîì ‚úèÔ∏è üë¥üèæ Kubernetes-Handbuch, Teil 2: Erstellen und Arbeiten mit einem Cluster üôÑ üèáüèø üèÆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Letztes Mal haben wir zwei Ans√§tze f√ºr die Arbeit mit Microservices untersucht. Eine davon beinhaltet insbesondere die Verwendung von Docker-Container...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes-Handbuch, Teil 2: Erstellen und Arbeiten mit einem Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/438984/">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Letztes</a> Mal haben wir zwei Ans√§tze f√ºr die Arbeit mit Microservices untersucht.  Eine davon beinhaltet insbesondere die Verwendung von Docker-Containern, in denen Sie den Code von Microservices und Hilfsprogrammen ausf√ºhren k√∂nnen.  Heute werden wir unter Verwendung unserer vorhandenen Container-Images mit Kubernetes arbeiten. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/13/lv/dr/13lvdrwhhap-ouchegvweul0fg0.jpeg"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Wir stellen vor: Kubernetes</font> </h2><br>  Ich verspreche, und ich √ºbertreibe √ºberhaupt nicht, dass Sie sich beim Lesen dieses Artikels fragen: "Warum hei√üen Kubernetes nicht Supernetes?" <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d76/9f9/e76/d769f9e7670a725759dd7415949177a0.png"></div><br>  <i><font color="#999999">Supernetes</font></i> <br><br>  Wenn Sie den vorherigen Teil dieses Materials gelesen haben, wissen Sie, dass wir uns dort mit vielen Dingen befasst haben, die mit der Vorbereitung von Anwendungen f√ºr die Containerisierung und der Arbeit mit Docker-Containern zusammenh√§ngen.  Es mag Ihnen so erscheinen, als ob das Schwierigste jetzt auf Sie wartet, aber tats√§chlich ist das, wor√ºber wir hier sprechen werden, viel einfacher als das, was wir bereits herausgefunden haben.  Der einzige Grund, warum das Erlernen von Kubernetes f√ºr jemanden als entmutigende Aufgabe erscheint, liegt in der Menge zus√§tzlicher Informationen, die Sie ben√∂tigen, um Kubernetes zu verstehen und effektiv zu nutzen.  Wir haben bereits alle "zus√§tzlichen Informationen" besprochen, die f√ºr die erfolgreiche Entwicklung von Kubernetes erforderlich sind. <br><br><h3>  <font color="#3AC1EF">‚ñçWas ist Kubernetes?</font> </h3><br>  Im ersten Teil dieses Artikels wurden Sie nach dem Start von Microservices in Containern gebeten, √ºber das Problem der Skalierung containerisierter Anwendungen nachzudenken. <br>  Ich schlage vor, gemeinsam dar√ºber nachzudenken, im Format von Fragen und Antworten: <br><br>  <b>Frage:</b> Wie skalieren containerisierte Anwendungen? <br>  <b>Antwort:</b> Starten Sie zus√§tzliche Container. <br><br>  <b>Frage:</b> Und wie verteilt sich die Last auf sie?  Was ist, wenn ein bestimmter Server bereits maximal ausgelastet ist und der Container auf einem anderen Server bereitgestellt werden muss?  Wie finde ich den effizientesten Weg, um Hardware zu nutzen? <br>  <b>Antwort:</b> Also ... ich schaue im Internet nach ... <br><br>  <b>Frage:</b> Wie kann ich Programme aktualisieren, ohne das System zu st√∂ren?  Und wenn das Update einen Fehler enth√§lt, wie kann man zur Arbeitsversion der Anwendung zur√ºckkehren? <br><br>  Tats√§chlich ist es die Kubernetes-Technologie, die diese und viele andere Fragen w√ºrdig beantwortet.  Ich werde versuchen, die Definition von Kubernetes auf einen Satz einzugrenzen: "Kubernetes ist ein Containerverwaltungssystem, das die zugrunde liegende Infrastruktur (die Umgebung, in der die Container ausgef√ºhrt werden) abstrahiert." <br><br>  Ich glaube, dass Ihnen das Konzept des ‚ÄûContainermanagements‚Äú jetzt nicht besonders klar ist, obwohl wir dies bereits erw√§hnt haben.  Im Folgenden werden wir diese Technologie in der Praxis betrachten.  Das Konzept der "Abstraktion der Basisinfrastruktur" wird jedoch zuerst angetroffen.  Deshalb werden wir jetzt dar√ºber nachdenken. <br><br><h3>  <font color="#3AC1EF">‚ñçAbstraktion der Basisinfrastruktur</font> </h3><br>  Mit Kubernetes k√∂nnen Anwendungen von der Infrastruktur abstrahieren, sodass wir eine einfache API erhalten, an die Sie Anforderungen senden k√∂nnen.  Kubernetes versucht, diese Anforderungen mit all seinen Funktionen zu erf√ºllen.  In einer regul√§ren Sprache kann eine √§hnliche Anforderung beispielsweise wie folgt beschrieben werden: "Kubernetes, 4 Bildcontainer X erweitern".  Nach Erhalt des Befehls findet Kubernetes Knoten, die nicht zu besch√§ftigt sind (sie werden auch als "Knoten" bezeichnet - vom englischen "Knoten"), auf denen Sie neue Container bereitstellen k√∂nnen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/735/b88/a2a/735b88a2a717e9c01bfc197f3c1b20fd.png"></div><br>  <i><font color="#999999">API-Serveranforderung</font></i> <br><br>  Was bedeutet das f√ºr den Entwickler?  Dies bedeutet, dass er sich keine Gedanken √ºber die Anzahl der Knoten machen muss, dar√ºber, wo genau die Container gestartet werden oder wie sie interagieren.  Er muss sich nicht mit Hardwareoptimierung befassen oder sich um Knoten k√ºmmern, die m√∂glicherweise nicht richtig funktionieren (und etwas √Ñhnliches wird laut Murphys Gesetz sicherlich passieren), da bei Bedarf neue Knoten zum Kubernetes-Cluster hinzugef√ºgt werden k√∂nnen.  Wenn mit einigen vorhandenen Knoten etwas nicht stimmt, stellt Kubernetes Container auf den Knoten bereit, die sich noch in einem fehlerfreien Zustand befinden. <br><br>  Vieles von dem, was in der vorherigen Abbildung gezeigt wird, ist Ihnen bereits bekannt.  Es gibt aber auch etwas Neues: <br><br><ul><li>  API-Server  Das T√§tigen von Anrufen an diesen Server ist die einzige M√∂glichkeit, mit dem vorhandenen Cluster zu interagieren, unabh√§ngig davon, ob es sich um das Starten oder Stoppen von Containern, das √úberpr√ºfen des Systemstatus, das Arbeiten mit Protokollen oder das Ausf√ºhren anderer Aktionen handelt. </li><li>  Kubelet.  Dies ist ein Agent, der die Container innerhalb des Knotens √ºberwacht und mit dem Hauptknoten interagiert. </li></ul><br>  Bitte beachten Sie, dass wir in einigen vorhergehenden S√§tzen den Begriff ‚ÄûContainer‚Äú verwenden, aber hier w√§re es korrekter, den Begriff ‚ÄûPod‚Äú zu verwenden.  Diese Entit√§ten werden in russischsprachigen Ver√∂ffentlichungen oft als ‚ÄûH√ºlsen‚Äú bezeichnet, und manchmal werden in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> ‚ÄûH√ºlsen‚Äú genannt, um das Konzept der ‚ÄûH√ºlse‚Äú zu verdeutlichen. Sie sprechen von einer ‚ÄûHerde Wale‚Äú (H√ºlse der Wale) oder einer ‚ÄûErbsenschote‚Äú. aber niemand nennt sie "Herden" oder "Schoten".  Wenn wir von ihnen sprechen, werden wir das Wort "unter" verwenden.  Jetzt k√∂nnen Sie sie als Container betrachten. Wir werden weiter unten mehr √ºber Pods sprechen. <br><br>  Wir werden vorerst damit aufh√∂ren, da wir dar√ºber weiter sprechen k√∂nnen, und au√üerdem gibt es viele gute Materialien zur Theorie der Kubernetes.  Dies ist beispielsweise eine offizielle Dokumentation, obwohl sie nicht leicht zu lesen ist, oder B√ºcher wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses</a> . <br><br><h3>  <font color="#3AC1EF">‚ñç Standardisierung der Arbeit mit Cloud-Dienstleistern</font> </h3><br>  Eine weitere St√§rke von Kubernetes liegt in der Tatsache, dass diese Technologie zur Standardisierung der Arbeit mit Cloud-Service-Providern (Cloud Service Provider, CSP) beitr√§gt.  Dies ist eine k√ºhne Aussage.  Betrachten Sie das folgende Beispiel.  Ein Spezialist, der Azure oder die Google Cloud Platform gut kennt, muss an einem Projekt arbeiten, das f√ºr eine v√∂llig neue Cloud-Umgebung entwickelt wurde, mit der er nicht vertraut ist.  In dieser Situation kann viel schief gehen.  Beispielsweise k√∂nnen sich die Fristen f√ºr die Lieferung des Projekts verz√∂gern, das Kundenunternehmen des Projekts muss m√∂glicherweise mehr Cloud-Ressourcen als geplant mieten und so weiter. <br><br>  Bei der Verwendung von Kubernetes kann ein solches Problem einfach nicht auftreten, da die Arbeit mit Kubernetes unabh√§ngig davon, um welchen Cloud-Dienstanbieter es sich handelt, immer gleich aussieht.  Der Entwickler teilt dem API-Server deklarativ mit, was er ben√∂tigt, und Kubernetes arbeitet mit den Ressourcen des Systems, sodass der Entwickler die Details der Implementierung dieses Systems ignorieren kann. <br><br>  Verweilen Sie ein wenig bei dieser Idee, da dies eine sehr m√§chtige Gelegenheit f√ºr Kubernetes ist.  F√ºr Unternehmen bedeutet dies, dass ihre Entscheidungen nicht an einen bestimmten CSP gebunden sind.  Wenn ein Unternehmen ein besseres Angebot auf dem Cloud-Service-Markt findet, kann es dieses Angebot frei nutzen, indem es zu einem neuen Anbieter wechselt.  Dar√ºber hinaus geht die Erfahrung der Spezialisten des Unternehmens nirgendwo verloren. <br><br>  Lassen Sie uns nun √ºber die praktische Verwendung von Kubernetes sprechen <br><br><h2>  <font color="#3AC1EF">Kubernetes √úbung: Pods</font> </h2><br>  Wir haben den Start von Microservices in Containern konfiguriert, der Einrichtungsprozess war ziemlich langwierig, aber wir haben es geschafft, zu einem funktionierenden System zu gelangen.  Dar√ºber hinaus ist unsere L√∂sung, wie bereits erw√§hnt, nicht gut skalierbar und nicht st√∂rungsresistent.  Wir werden diese Probleme mit Kubernetes l√∂sen.  Als n√§chstes bringen wir unser System in eine Form, die dem folgenden Schema entspricht.  Die Container werden n√§mlich von Kubernetes verwaltet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/53d/19c/3ba/53d19c3bac2f8cdd66213c9b34e7b05b.png"></div><br>  <i><font color="#999999">Microservices arbeiten in einem von Kubernetes verwalteten Cluster</font></i> <br><br>  Hier verwenden wir Minikube f√ºr die lokale Bereitstellung des Clusters und zum Testen der Funktionen von Kubernetes. Alles, was wir hier tun, kann jedoch √ºber Cloud-Plattformen wie Azure oder Google Cloud Platform erfolgen. <br><br><h3>  <font color="#3AC1EF">‚ñçInstallation und Start von Minikube</font> </h3><br>  Befolgen Sie zum Installieren von Minikube die Anweisungen in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> .  W√§hrend der Installation von Minikube installieren Sie auch Kubectl.  Dies ist ein Client, mit dem Anforderungen an den Kubernetes-API-Server gestellt werden k√∂nnen. <br><br>  F√ºhren Sie zum Starten von Minikube den Befehl <code>minikube start</code> und f√ºhren Sie nach Abschluss den Befehl <code>kubectl get nodes</code> .  Infolgedessen sollten Sie Folgendes sehen: <br><br><pre> <code class="plaintext hljs">kubectl get nodes NAME       STATUS ROLES     AGE VERSION minikube   Ready &lt;none&gt;    11m v1.9.0</code> </pre> <br>  Minikube stellt uns einen Cluster zur Verf√ºgung, der nur aus einem Knoten besteht.  Das passt zwar ganz gut zu uns.  Diejenigen, die mit Kubernetes arbeiten, m√ºssen sich nicht genau darum k√ºmmern, wie viele Knoten sich im Cluster befinden, da Sie mit Kubernetes von solchen Details abstrahieren k√∂nnen. <br><br>  Sprechen wir jetzt √ºber Pods. <br><br><h3>  <font color="#3AC1EF">‚ñçPods</font> </h3><br>  Ich mag Container wirklich, und Sie m√∂gen sie jetzt wahrscheinlich auch.  Warum bietet Kubernetes uns die Verwendung von Pods an, Entit√§ten, die die minimal einsetzbaren Recheneinheiten in diesem System darstellen?  Unter welchen Funktionen wird es ausgef√ºhrt?  Tatsache ist, dass der Herd einen oder mehrere Container enthalten kann, die dieselbe Laufzeit haben. <br><br>  Aber ist es notwendig, zum Beispiel zwei Container in einem Herd auszuf√ºhren?  Wie sagt man ... Normalerweise gibt es nur einen Container pro Container, und das werden wir tun.  In den F√§llen, in denen beispielsweise zwei Container gemeinsam auf dasselbe Data Warehouse zugreifen m√ºssen oder wenn sie mithilfe der Interprozesskommunikationstechnik verbunden sind oder wenn sie aus einem anderen Grund eng miteinander verbunden sind, kann dies alles realisiert werden indem man sie in einem Herd laufen l√§sst.  Eine andere M√∂glichkeit, in der sich Pods unterscheiden, besteht darin, dass sie keine Docker-Container verwenden m√ºssen.  Bei Bedarf k√∂nnen Sie hier andere Technologien f√ºr die Containerisierung von Anwendungen anwenden, z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rkt</a> . <br><br>  Das folgende Diagramm zeigt die nummerierten Herdeigenschaften. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f6/2a4/bb1/4f62a4bb18bddccc49a9d224a4aa919d.png"></div><br>  <i><font color="#999999">Herdeigenschaften</font></i> <br><br>  Ber√ºcksichtigen Sie diese Eigenschaften. <br><br><ol><li>  Jeder Pod in einem Kubernetes-Cluster verf√ºgt √ºber eine eindeutige IP-Adresse. </li><li>  Ein Herd kann viele Beh√§lter enthalten.  Sie teilen die verf√ºgbaren Portnummern, <code>localhost</code> sie k√∂nnen beispielsweise Informationen √ºber <code>localhost</code> miteinander austauschen (nat√ºrlich k√∂nnen sie nicht dieselben Ports verwenden).  Die Interaktion mit Containern in anderen Pods wird anhand der IP-Adressen dieser Pods organisiert. </li><li>  Container in Pods teilen sich Datenspeichervolumen, IP-Adresse, Portnummern und IPC-Namespace. </li></ol><br>  Es ist zu beachten, dass Container ihre eigenen isolierten Dateisysteme haben, sie jedoch Daten mithilfe der Kubernetes-Ressource namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Volume gemeinsam nutzen k√∂nnen</a> . <br><br>  F√ºr uns reicht das, was bereits √ºber die Herde gesagt wurde, aus, um die Kubernetes weiterhin zu beherrschen.  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> mehr dar√ºber. <br><br><h3>  <font color="#3AC1EF">‚ñç Beschreibung des Herdes</font> </h3><br>  Das Folgende ist eine Manifestdatei f√ºr die <code>sa-frontend</code> Anwendung. <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Pod                                            # 1 metadata: name: sa-frontend                                  # 2 spec:                                                # 3 containers:   - image: rinormaloku/sentiment-analysis-frontend # 4     name: sa-frontend                              # 5     ports:       - containerPort: 80</code> </pre> <br>  Lassen Sie uns einige der darin angegebenen Parameter erkl√§ren. <br><br><ol><li>  <code>Kind</code> : Gibt die Art der Kubernetes-Ressource an, die erstellt werden soll.  In unserem Fall ist dies <code>Pod</code> . </li><li>  <code>Name</code> : Name der Ressource.  Wir haben es <code>sa-frontend</code> . </li><li>  <code>Spec</code> : Ein Objekt, das den gew√ºnschten Status der Ressource beschreibt.  Die wichtigste Eigenschaft hierbei ist die Anordnung der Container. </li><li>  <code>Image</code> : Das Bild des Containers, den wir in diesem Pod ausf√ºhren m√∂chten. </li><li>  <code>Name</code> : Ein eindeutiger Name f√ºr den darunter liegenden Container. </li><li>  <code>ContainerPort</code> : Der Port, den der Container √ºberwacht.  Dieser Parameter kann als Hinweis darauf angesehen werden, wer diese Datei liest (wenn Sie diesen Parameter weglassen, wird der Zugriff auf den Port nicht eingeschr√§nkt). </li></ol><br><h3>  <font color="#3AC1EF">‚ñçErstellen eines SA-Frontends</font> </h3><br>  Die Pod-Beschreibungsdatei, √ºber die wir gesprochen haben, finden Sie unter <code>resource-manifests/sa-frontend-pod.yaml</code> .  Sie m√ºssen entweder mit den Terminal-Tools in diesen Ordner wechseln oder beim Aufrufen des entsprechenden Befehls den vollst√§ndigen Pfad zur Datei angeben.  Hier ist dieser Befehl und ein Beispiel f√ºr eine Systemreaktion darauf: <br><br><pre> <code class="plaintext hljs">kubectl create -f sa-frontend-pod.yaml pod "sa-frontend" created</code> </pre> <br>  F√ºhren Sie den folgenden Befehl aus, um herauszufinden, ob es unter funktioniert: <br><br><pre> <code class="plaintext hljs">kubectl get pods NAME                          READY STATUS RESTARTS AGE sa-frontend                   1/1 Running 0 7s</code> </pre> <br>  Wenn der Status des Herds w√§hrend der Ausf√ºhrung dieses Befehls <code>ContainerCreating</code> , k√∂nnen Sie denselben Befehl mit dem <code>--watch</code> .  Aus diesem Grund werden Informationen dazu automatisch angezeigt, wenn sich der Herd im Betriebszustand befindet. <br><br><h3>  <font color="#3AC1EF">‚ñçZugriff auf die Anwendung von au√üen</font> </h3><br>  Um den Zugriff auf die Anwendung von au√üen zu organisieren, ist es richtig, eine Kubernetes-Ressource des Servicetyps zu erstellen, √ºber die wir weiter unten sprechen werden. Der K√ºrze halber verwenden wir hier jedoch eine einfache Portweiterleitung: <br><br><pre> <code class="plaintext hljs">kubectl port-forward sa-frontend 88:80 Forwarding from 127.0.0.1:88 -&gt; 80</code> </pre> <br>  Wenn Sie jetzt unter <code>127.0.0.1:88</code> einen Browser <code>127.0.0.1:88</code> , wird die Seite "React-Anwendung" angezeigt. <br><br><h3>  <font color="#3AC1EF">‚ñç Falscher Skalierungsansatz</font> </h3><br>  Wir haben bereits gesagt, dass eine der Funktionen von Kubernetes die Anwendungsskalierung ist.  Um diese Gelegenheit zu nutzen, f√ºhren wir eine weitere unter aus.  Erstellen Sie eine Beschreibung einer anderen <code>Pod</code> Ressource, indem Sie den folgenden Code in die Datei <code>sa-frontend-pod2.yaml</code> : <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Pod                                           metadata: name: sa-frontend2      #   spec:                                                containers:   - image: rinormaloku/sentiment-analysis-frontend     name: sa-frontend                                  ports:       - containerPort: 80</code> </pre> <br>  Wie Sie sehen k√∂nnen, ist die einzige √Ñnderung, wenn Sie diese Beschreibung mit der oben untersuchten vergleichen, der Wert der <code>Name</code> Eigenschaft. <br><br>  Erstellen Sie eine neue unter: <br><br><pre> <code class="plaintext hljs">kubectl create -f sa-frontend-pod2.yaml pod "sa-frontend2" created</code> </pre> <br>  Stellen Sie sicher, dass es ausgef√ºhrt wird: <br><br><pre> <code class="plaintext hljs">kubectl get pods NAME                          READY STATUS RESTARTS AGE sa-frontend                   1/1 Running 0 7s sa-frontend2                  1/1 Running 0 7s</code> </pre> <br>  Jetzt haben wir zwei Herde!  Es stimmt, hier gibt es nichts Besonderes zu genie√üen.  Bitte beachten Sie, dass die hier gezeigte L√∂sung f√ºr das Problem der Anwendungsskalierung viele Nachteile aufweist.  Wie das richtig geht, erfahren Sie im Abschnitt √ºber eine andere Kubernetes-Ressource namens Deployment. <br><br>  √úberlegen Sie nun, was wir nach dem Start von zwei identischen Herden erhalten haben.  Der Nginx-Webserver wird jetzt in zwei verschiedenen Pods ausgef√ºhrt.  In dieser Hinsicht k√∂nnen wir zwei Fragen stellen: <br><br><ol><li>  Wie kann ich von au√üen per URL auf diese Server zugreifen? </li><li>  Wie organisiere ich den Lastausgleich zwischen ihnen? </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1ff/3a9/6f4/1ff3a96f4b930fe55727d1063b3c117b.png"></div><br>  <i><font color="#999999">Falscher Skalierungsansatz</font></i> <br><br>  Unter den Kubernetes-Tools befinden sich Ressourcen des Formulars Service.  Reden wir √ºber sie. <br><br><h2>  <font color="#3AC1EF">Kubernetes Praxis: Dienstleistungen</font> </h2><br>  Kubernetes-Dienste fungieren als Zugangspunkte zu Herds√§tzen, die dieselbe Funktionalit√§t wie diese Herde bieten.  Services l√∂sen schwierige Aufgaben, indem sie mit Herden arbeiten und die Last zwischen ihnen ausgleichen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bbd/95f/bd8/bbd95fbd8562bed4a09ab4930a20f98d.png"></div><br>  <i><font color="#999999">Der Kubernetes-Dienst bedient IP-Adressen</font></i> <br><br>  In unserem Kubernetes-Cluster gibt es Pods, die verschiedene Funktionen implementieren.  Dies ist eine Front-End-Anwendung, eine Spring-Webanwendung und eine in Python geschriebene Flask-Anwendung.  Dies wirft die Frage auf, wie der Dienst verstehen soll, mit welcher Art von Pods er arbeiten muss, dh wie er anhand der Informationen herausfinden kann, welche Informationen das System f√ºr die Pods erstellen soll. <br><br>  Dies geschieht mit einer anderen Kubernetes-Abstraktion namens Label.  Die Arbeit mit Tags besteht aus zwei Schritten: <br><br><ol><li>  Durch die Zuweisung von Etiketten kann der Dienst bearbeitet werden. </li><li>  Durch Anwenden eines ‚ÄûSelektors‚Äú auf den Dienst, der bestimmt, welche Pods welchen Etiketten zugewiesen sind, funktioniert der Dienst. </li></ol><br>  Vielleicht ist dies als Illustration leichter vorstellbar als zu beschreiben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb9/fcf/f0c/bb9fcff0cded591f1a5ab8a0b825245a.png"></div><br>  <i><font color="#999999">Beschriftete Pods und ihre Manifestdateien</font></i> <br><br>  Wir sehen hier zwei Herde, denen mit der <code>app: sa-frontend</code> Konstrukt die gleichen Bezeichnungen zugewiesen wurden.  Der Dienst ist an Pods mit solchen Markierungen interessiert. <br><br><h3>  <font color="#3AC1EF">‚ñçTags</font> </h3><br>  Labels bieten Entwicklern eine einfache M√∂glichkeit, Kubernetes-Ressourcen zu organisieren.  Es handelt sich um Schl√ºssel-Wert-Paare, die Sie beliebigen Ressourcen zuweisen k√∂nnen.  √Ñndern Sie die Herdbeschreibungsdateien der Frontend-Anwendung und bringen Sie sie in die in der vorherigen Abbildung gezeigte Ansicht.  Speichern Sie danach diese Dateien und f√ºhren Sie die folgenden Befehle aus: <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-pod.yaml Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply pod "sa-frontend" configured kubectl apply -f sa-frontend-pod2.yaml Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply pod "sa-frontend2" configured</code> </pre> <br>  Wenn diese Befehle ausgef√ºhrt werden, gibt das System Warnungen aus (es passt nicht zu uns, dass wir <code>apply</code> anstelle von <code>create</code> , wir verstehen dies), aber nach einer Warnung meldet es, dass die entsprechenden Pods konfiguriert sind.  Wir k√∂nnen √ºberpr√ºfen, ob Etiketten Etiketten zugewiesen wurden, indem wir die Protokolle filtern, f√ºr die Informationen angezeigt werden sollen: <br><br><pre> <code class="plaintext hljs">kubectl get pod -l app=sa-frontend NAME           READY STATUS    RESTARTS AGE sa-frontend    1/1 Running   0 2h sa-frontend2   1/1 Running   0 2h</code> </pre> <br>  Eine andere M√∂glichkeit, um zu √ºberpr√ºfen, ob Beschriftungen tats√§chlich Beschriftungen zugewiesen wurden, besteht darin, den Schl√ºssel <code>--show-labels</code> an den vorherigen Befehl anzuh√§ngen.  Aus diesem Grund enthalten Informationen zu ihren Pods auch Daten zu ihren Marken. <br><br>  Jetzt wurden Tags zugewiesen und wir k√∂nnen den Dienst so konfigurieren, dass er mit ihnen funktioniert.  Daher werden wir die Beschreibung eines Dienstes wie <code>LoadBalancer</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e0f/081/7e9/e0f0817e9fc090628aa1d0d89577ce80.gif"></div><br>  <i><font color="#999999">Lastausgleich mit einem Dienst wie LoadBalancer</font></i> <br><br><h3>  <font color="#3AC1EF">‚ñç Servicebeschreibung</font> </h3><br>  Hier ist eine YAML-Beschreibung eines Dienstes wie <code>LoadBalancer</code> : <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Service              # 1 metadata: name: sa-frontend-lb spec: type: LoadBalancer       # 2 ports: - port: 80               # 3   protocol: TCP          # 4   targetPort: 80         # 5 selector:                # 6   app: sa-frontend       # 7</code> </pre> <br>  Erkl√§ren Sie diesen Text: <br><br><ol><li>  <code>Kind</code> : Wir erstellen einen Service, eine <code>Service</code> Ressource. </li><li>  <code>Type</code> : Der in der Spezifikation angegebene Ressourcentyp.  Wir haben den Typ <code>LoadBalancer</code> , weil wir mit diesem Service das Problem des Lastausgleichs zwischen den Herden l√∂sen wollen. </li><li>  <code>Port</code> : Port, an dem der Dienst Anforderungen akzeptiert. </li><li>  <code>Protocol</code> : Das vom Dienst verwendete Protokoll. </li><li>  <code>TargetPort</code> : Port, an den eingehende Anforderungen umgeleitet werden. </li><li>  <code>Selector</code> : Ein Objekt, das Informationen dar√ºber enth√§lt, mit welchen Pods der Dienst arbeiten soll. </li><li>  <code>app: sa-frontend</code> : Diese Eigenschaft gibt an, mit welchen Pods der Dienst arbeiten wird.  Dies sind n√§mlich die Pods, denen das Label <code>app: sa-frontend</code> zugewiesen ist. </li></ol><br>  Um einen Dienst zu erstellen, m√ºssen Sie den folgenden Befehl ausf√ºhren: <br><br><pre> <code class="plaintext hljs">kubectl create -f service-sa-frontend-lb.yaml service "sa-frontend-lb" created</code> </pre> <br>  Sie k√∂nnen den Status des Dienstes wie folgt √ºberpr√ºfen: <br><br><pre> <code class="plaintext hljs">kubectl get svc NAME             TYPE CLUSTER-IP      EXTERNAL-IP PORT(S) AGE sa-frontend-lb   LoadBalancer 10.101.244.40   &lt;pending&gt; 80:30708/TCP 7m</code> </pre> <br>  Hier k√∂nnen Sie sehen, dass sich die <code>EXTERNAL-IP</code> Eigenschaft im Status <code>&lt;pending&gt;</code> , aber Sie k√∂nnen nicht warten, bis sie sich √§ndert.  Dies liegt an der Tatsache, dass wir Minikube verwenden.  Wenn wir bei der Arbeit mit einem bestimmten Cloud-Dienstanbieter wie Azure oder der Google Cloud Platform einen √§hnlichen Dienst erstellen w√ºrden, h√§tte der Dienst eine √∂ffentliche IP-Adresse, die den Zugriff √ºber das Internet erm√∂glicht. <br><br>  Trotzdem erlaubt uns Minikube nicht, herumzuspielen, was uns einen n√ºtzlichen Befehl f√ºr das lokale Debuggen des Systems gibt: <br><br><pre> <code class="plaintext hljs">minikube service sa-frontend-lb Opening kubernetes service default/sa-frontend-lb in default browser...</code> </pre> <br>  Dank dieses Befehls wird ein Browser gestartet, der auf den Dienst zugreift.  Nachdem der Dienst die Anforderung erhalten hat, leitet er sie an einen der Herde weiter (es spielt keine Rolle, unter welchem ‚Äã‚Äãer sich befindet).  Diese Abstraktion erm√∂glicht es uns, eine Gruppe von Herden als eine Einheit zu betrachten und mit ihnen zu arbeiten, wobei der Dienst als ein einziger Zugangspunkt zu ihnen verwendet wird. <br><br>  In diesem Abschnitt haben wir dar√ºber gesprochen, wie Ressourcen Beschriftungen zugewiesen werden und wie sie beim Konfigurieren von Diensten als Selektoren verwendet werden.  Hier haben wir einen Service wie <code>LoadBalancer</code> beschrieben und erstellt.  Dank dessen haben wir das Problem der Skalierung der Anwendung (Skalierung besteht aus dem Hinzuf√ºgen neuer Herde mit den entsprechenden Beschriftungen zum Cluster) und der Organisation des Lastausgleichs zwischen den Herden unter Verwendung des Dienstes als Einstiegspunkt gel√∂st. <br><br><h2>  <font color="#3AC1EF">Kubernetes-Praxis: Bereitstellungen</font> </h2><br>  Die Bereitstellung ist eine Abstraktion von Kubernetes, mit der wir steuern k√∂nnen, was im Anwendungslebenszyklus immer vorhanden ist.  Es geht darum, Anwendungs√§nderungen zu verwalten.  Anwendungen, die sich nicht √§ndern, sind sozusagen ‚Äûtote‚Äú Anwendungen.  Wenn die Anwendung "lebt", kann es vorkommen, dass sich ihre Anforderungen regelm√§√üig √§ndern, ihr Code erweitert wird, dieser Code gepackt und bereitgestellt wird.  Dar√ºber hinaus k√∂nnen bei jedem Schritt des Prozesses Fehler gemacht werden. <br><br>  Mit einer Ressource vom Typ Bereitstellung k√∂nnen Sie den √úbergang von einer Version einer Anwendung zu einer anderen automatisieren.  Dies geschieht ohne Unterbrechung des Systems. Wenn w√§hrend dieses Vorgangs ein Fehler auftritt, haben wir die M√∂glichkeit, schnell zur vorherigen funktionierenden Version der Anwendung zur√ºckzukehren. <br><br><h3>  <font color="#3AC1EF">‚ñçVerwendung von Bereitstellungen</font> </h3><br>  Jetzt verf√ºgt der Cluster √ºber zwei Herde und einen Dienst, der den Zugriff von au√üen erm√∂glicht und die Last auf sie ausgleicht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/426/651/0c4/4266510c40a1faa6086178e5db23d20c.png"></div><br>  <i><font color="#999999">Aktueller Status des Clusters</font></i> <br><br>  Wir haben dar√ºber gesprochen, dass es keine gute Idee ist, zwei verschiedene Herde mit derselben Funktionalit√§t zu betreiben.  Wenn wir ein solches Schema verwenden, m√ºssen wir mit jedem Herd einzeln arbeiten, jeden bestimmten Herd erstellen, aktualisieren, l√∂schen und seinen Zustand beobachten.  Bei diesem Ansatz ist es nicht erforderlich, √ºber ein schnelles Update des Systems oder das schnelle Rollback eines nicht erfolgreichen Updates zu sprechen.  Wir sind mit diesem Sachverhalt nicht zufrieden, daher werden wir auf die M√∂glichkeit der Bereitstellung von Ressourcen zur√ºckgreifen, die auf die L√∂sung der oben genannten Probleme abzielen. <br><br>  Bevor wir mit der Arbeit fortfahren, formulieren wir die Ziele, die uns Richtlinien geben, die beim Parsen der Bereitstellungsmanifestdatei hilfreich sind.  Also hier ist was wir brauchen: <br><br><ol><li>  Wir m√∂chten in der Lage sein, zwei Herde basierend auf einem Container- <code>rinormaloku/sentiment-analysis-frontend</code> zu erstellen. </li><li>  Wir ben√∂tigen ein Anwendungsbereitstellungssystem, mit dem es bei der Aktualisierung ohne Unterbrechungen funktioniert. </li><li>  Wir m√∂chten, dass das <code>app: sa-frontend</code> Label zugewiesen wird <code>app: sa-frontend</code> , wodurch der <code>sa-frontend-lb</code> Dienst diese Pods erkennen kann. </li></ol><br>  Wir werden diese Anforderungen nun als Beschreibung der Bereitstellungsressource ausdr√ºcken. <br><br><h3>  <font color="#3AC1EF">‚ñç Bereitstellungsbeschreibung</font> </h3><br>  Hier ist eine YAML-Beschreibung einer Ressource vom Typ Bereitstellung, die unter Ber√ºcksichtigung der oben genannten Systemanforderungen erstellt wurde: <br><br><pre> <code class="plaintext hljs">apiVersion: extensions/v1beta1 kind: Deployment                                          # 1 metadata: name: sa-frontend spec: replicas: 2                                             # 2 minReadySeconds: 15 strategy:   type: RollingUpdate                                   # 3   rollingUpdate:     maxUnavailable: 1                                   # 4     maxSurge: 1                                         # 5 template:                                               # 6   metadata:     labels:       app: sa-frontend                                  # 7   spec:     containers:       - image: rinormaloku/sentiment-analysis-frontend         imagePullPolicy: Always                         # 8         name: sa-frontend         ports:           - containerPort: 80</code> </pre> <br>  Lassen Sie uns diese Beschreibung analysieren: <br><br><ol><li>  <code>Kind</code> : Hier steht, dass wir eine Ressource der <code>Deployment</code> . </li><li>  <code>Replicas</code> : Eine Eigenschaft des Bereitstellungsspezifikationsobjekts, die definiert, wie viele Instanzen (Replikate) von Herden ausgef√ºhrt werden sollen. </li><li>  <code>Type</code> : beschreibt die Strategie, die in dieser Bereitstellung beim Wechsel von der aktuellen zu einer neuen Version verwendet wird.  <code>RollingUpdate</code> Strategie von <code>RollingUpdate</code> bietet keine Systemausf√§lle w√§hrend Upgrades. </li><li>  <code>MaxUnavailable</code> : Dies ist eine Eigenschaft des <code>RollingUpdate</code> Objekts, mit der die maximale Anzahl nicht verf√ºgbarer Herde (im Vergleich zur gew√ºnschten Anzahl von Herden) festgelegt wird, wenn eine sequentielle Systemaktualisierung durchgef√ºhrt wird.  In unserer Bereitstellung, die das Vorhandensein von 2 Replikaten impliziert, gibt der Wert dieser Eigenschaft an, dass nach Abschluss eines Pods ein weiterer ausgef√ºhrt wird, wodurch die Anwendung w√§hrend des Updates verf√ºgbar wird. </li><li>  <code>MaxSurge</code> : Dies ist eine Eigenschaft des <code>RollingUpdate</code> Objekts, die die maximale Anzahl von Herden beschreibt, die einer Bereitstellung hinzugef√ºgt werden k√∂nnen (im Vergleich zu einer bestimmten Anzahl von Herden).  In unserem Fall bedeutet der Wert 1, dass wir beim Wechsel zu einer neuen Version des Programms dem Cluster ein weiteres Sub hinzuf√ºgen k√∂nnen, was dazu f√ºhrt, dass bis zu drei Herde gleichzeitig gestartet werden k√∂nnen. </li><li>  <code>Template</code> : Dieses Objekt definiert die Herdvorlage, mit der die beschriebene <code>Deployment</code> neue Herde erstellt.  Diese Einstellung ist Ihnen wahrscheinlich bekannt. </li><li>  <code>app: sa-frontend</code> : Bezeichnung f√ºr Herde, die nach einem bestimmten Muster erstellt wurden. </li><li>  <code>ImagePullPolicy</code> : <code>ImagePullPolicy</code> die Reihenfolge der Arbeit mit Bildern.  In unserem Fall ist diese Eigenschaft auf <code>Always</code> festgelegt, <code>Always</code> w√§hrend jeder Bereitstellung wird das entsprechende Image aus dem Repository heruntergeladen. </li></ol><br>  Nachdem wir das alles untersucht haben, wollen wir weiter √ºben.  F√ºhren Sie die Bereitstellung aus: <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-deployment.yaml deployment "sa-frontend" created</code> </pre> <br>  √úberpr√ºfen Sie den Status des Systems: <br><br><pre> <code class="plaintext hljs">kubectl get pods NAME                           READY STATUS RESTARTS AGE sa-frontend                    1/1 Running 0 2d sa-frontend-5d5987746c-ml6m4   1/1 Running 0 1m sa-frontend-5d5987746c-mzsgg   1/1 Running 0 1m sa-frontend2                   1/1 Running 0 2d</code> </pre> <br>  Wie Sie sehen k√∂nnen, haben wir jetzt 4 Pods.  Zwei davon wurden mithilfe der Bereitstellungsressource erstellt, zwei weitere haben wir selbst erstellt.  Jetzt k√∂nnen Sie die Pods, die wir selbst erstellt haben, mit Befehlen des folgenden Typs entfernen: <br><br><pre> <code class="plaintext hljs">kubectl delete pod &lt;pod-name&gt;</code> </pre> <br>  Hier ist √ºbrigens ein Auftrag f√ºr selbst√§ndiges Arbeiten.  L√∂schen Sie einen der mit der Bereitstellungsressource erstellten Herde und √ºberwachen Sie das System.  Denken Sie √ºber die Gr√ºnde nach, bevor Sie weiterlesen. <br><br>  Beim L√∂schen eines Herdes erf√§hrt die Bereitstellungsressource, dass sich der aktuelle Status des Systems (1 Sub) vom gew√ºnschten unterscheidet (2 Sub), sodass ein anderes Sub gestartet wird. <br><br>  Was ist die Verwendung von Bereitstellungsressourcen, abgesehen von der Tatsache, dass das System bei Verwendung im richtigen Zustand gehalten wird?  Ber√ºcksichtigen Sie die St√§rken dieser Ressourcen. <br><br><h3>  <font color="#3AC1EF">‚ñç Bereitstellen ohne Systemausfallzeit</font> </h3><br>  Angenommen, ein Produktmanager kommt zu uns und meldet, dass der Client, f√ºr den wir dieses Produkt erstellt haben, eine gr√ºne Schaltfl√§che in der Clientanwendung w√ºnscht.  Die Entwickler implementieren diese Anforderung und geben uns das einzige, was wir von ihnen ben√∂tigen - einen <code>rinormaloku/sentiment-analysis-frontend:green</code> namens <code>rinormaloku/sentiment-analysis-frontend:green</code> .  Jetzt kommt unsere Zeit.  Wir, das DevOps-Team, m√ºssen das aktualisierte System bereitstellen und sicherstellen, dass keine Ausfallzeiten auftreten.  Lassen Sie uns nun sehen, ob die Bem√ºhungen zur Entwicklung und Konfiguration der Bereitstellungsressource gerechtfertigt sind. <br><br>  Bearbeiten Sie die Datei <code>sa-frontend-deployment-green.yaml</code> und ersetzen Sie den Namen des <code>rinormaloku/sentiment-analysis-frontend:green</code> durch einen neuen mit <code>rinormaloku/sentiment-analysis-frontend:green</code> . Speichern Sie diese Datei dann als <code>sa-frontend-deployment-green.yaml</code> und f√ºhren Sie den folgenden Befehl aus: <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-deployment-green.yaml --record deployment "sa-frontend" configured</code> </pre> <br>  √úberpr√ºfen Sie den Systemstatus mit dem folgenden Befehl: <br><br><pre> <code class="plaintext hljs">kubectl rollout status deployment sa-frontend Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 of 2 updated replicas are available... deployment "sa-frontend" successfully rolled out</code> </pre> <br>  In √úbereinstimmung mit den Daten, die als Antwort auf diesen Befehl angezeigt werden, k√∂nnen wir den Schluss ziehen, dass die Updatebereitstellung erfolgreich war.  W√§hrend des Upgrades wurden die alten Replikate einzeln durch neue ersetzt.  ,   ,    ,   .     ,    ,    . <br><br><h4>   </h4><br>      ,     ,     : <br><br><pre> <code class="plaintext hljs">minikube service sa-frontend-lb</code> </pre> <br>       ,      . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/777/489/902/777489902694f46438ceae41ce59db9b.png"></div><br> <i><font color="#999999"> </font></i> <br><br>  ,     ,  ‚Äî    . <br><br><h4>      RollingUpdate </h4><br>  ,     <code>kubectl apply -f sa-frontend-deployment-green.yaml --record</code> , Kubernetes   ,     ,    .         ,       ,    <code>rinormaloku/sentiment-analysis-frontend:green</code> .       ,    ,   . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/465/7ee/290/4657ee29097dc99e4fa2a0ebd9180e7a.png"></div><br> <i><font color="#999999">     </font></i> <br><br>  <code>RollingUpdate</code>       ,  ,     <code>maxUnavailable: 1</code>  <code>maxSurge: 1</code> .  ,   Deployment ,     ,    ,     .  ,    ,    ,         . <br><br>         Deployment.     ,   .      . <br><br><h3> <font color="#3AC1EF">‚ñç    </font> </h3><br>   ,   ,   . ¬´!  !    !¬ª, ‚Äî  .        . ,   ,      : <br><br><pre> <code class="plaintext hljs">kubectl rollout history deployment sa-frontend deployments "sa-frontend" REVISION  CHANGE-CAUSE 1         &lt;none&gt;    2         kubectl.exe apply --filename=sa-frontend-deployment-green.yaml --record=true</code> </pre> <br>          : ¬´,    ,    ?¬ª. <br><br> ¬´.  ,   ?¬ª, ‚Äî   . <br><br>  ,         ,     : <br><br><pre> <code class="plaintext hljs">kubectl rollout undo deployment sa-frontend --to-revision=1 deployment "sa-frontend" rolled back</code> </pre> <br>      .   ,      . <br><br>       . <br><br>       . <br><br> ! <br><br>   ,  .   Kubernetes         ,  ,      . ,   ! <br><br>           . ,       .  <code>CHANGE-CAUSE</code>      <code>&lt;none&gt;</code> ,    ‚Äî <code>kubectl.exe apply ‚Äìfilename=sa-frontend-deployment-green.yaml ‚Äìrecord=true</code> ? <br><br>   ,         -- <code>record</code>     ,    . <br><br>       ,   ,  ,      . <br><br><h2> <font color="#3AC1EF">   Kubernetes:    </font> </h2><br>      Kubernetes,    ,     .      ,     . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7cb/af4/880/7cbaf4880d435df50761d22508f61e83.png"></div><br> <i><font color="#999999">  </font></i> <br><br>       . <br><br><h3> <font color="#3AC1EF">‚ñç  sa-logic</font> </h3><br>        <code>resource-manifests</code>    : <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-logic-deployment.yaml --record deployment "sa-logic" created</code> </pre> <br>  <code>sa-logic</code>   .     Python-.    <code>app: sa-logic</code> .          <code>sa-logic</code> ,   .   <code>sa-logic-deployment.yaml</code>     . <br><br>  -,        ,      ‚Äî  <code>sa-logic</code> . <br><br><h3> <font color="#3AC1EF">‚ñç sa-logic</font> </h3><br>   ,       Service.   ,   Java-,        <code>sa-webapp</code> ,      ,  Python-.  ,    ,       ,     Python-,   .     ,  ,  ,  . <br><br>      , ,    ,       ,   .  ,      <code>sa-logic</code>   ,       <code>sa-logic</code> . <br><br>   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f service-sa-logic.yaml service "sa-logic" created</code> </pre> <br>    ,        . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/693/79b/3e3/69379b3e373ad1bc728242db341411ab.png"></div><br> <i><font color="#999999">  </font></i> <br><br>   <code>sa-logic</code> ,   <code>sa-webapp</code> ,    ,    . <br><br>   <code>sa-webapp</code> . <br><br><h3> <font color="#3AC1EF">‚ñç  sa-webapp</font> </h3><br>      ,          Deployment    - . ,     <code>sa-web-app-deployment.yaml</code> ,      : <br><br><pre> <code class="plaintext hljs">- image: rinormaloku/sentiment-analysis-web-app imagePullPolicy: Always name: sa-web-app env:   - name: SA_LOGIC_API_URL     value: "http://sa-logic" ports:   - containerPort: 8080</code> </pre> <br>     <code>env</code> ?  ,   ,  ,   <code>SA_LOGIC_API_URL</code>   <code>http://sa-logic</code> .   ,    ,       .    ? <br><br>             kube-dns. <br><br><h3> <font color="#3AC1EF">‚ñçDNS-  Kubernetes</font> </h3><br>  Kubernetes   ,   <code>kube-dns</code> .        DNS-.     <code>kube-dns</code>   ,     DNS-    . <br><br>  ,      <code>sa-logic</code> ,   IP-.  <code>kube-dns</code>        IP- .        <code>http://sa-logic</code>  IP-. <br><br>      Deployment <code>sa-webapp</code> . <br><br><h3> <font color="#3AC1EF">‚ñç  sa-webapp</font> </h3><br>   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-web-app-deployment.yaml --record deployment "sa-web-app" created</code> </pre> <br>         <code>sa-webapp</code>   ,   .   React-    ,       <code>sa-webapp</code> . <br><br><h3> <font color="#3AC1EF">‚ñç sa-webapp</font> </h3><br>     <code>service-sa-web-app-lb.yaml</code> ,  ,  ,    ,   . ,   ,   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f service-sa-web-app-lb.yaml service "sa-web-app-lb" created</code> </pre> <br>    . ,     ,      . ,     <code>sa-frontend</code> ,        Java- <code>sa-webapp</code> ,    <code>http://localhost:8080/sentiment</code> .      ,       ,   <code>sa-webapp</code> ,    React-  ,     Java-. <br><br>           ,     . ,          ‚Äî  ,    ,     . <br><br>  ,       : <br><br><ol><li>  IP-   <code>sa-webapp</code> ,   : <br><br> <code>minikube service list <br> |-------------|----------------------|-----------------------------| <br> |  NAMESPACE  | NAME         | URL       | <br> |-------------|----------------------|-----------------------------| <br> | default     | kubernetes         | No node port       | <br> | default     | sa-frontend-lb       | http://192.168.99.100:30708 | <br> | default     | sa-logic         | No node port       | <br> | default     | sa-web-app-lb        | http://192.168.99.100:31691 | <br> | kube-system | kube-dns             | No node port | <br> | kube-system | kubernetes-dashboard | http://192.168.99.100:30000 | <br> |-------------|----------------------|-----------------------------|</code> </li> <li>   IP-   <code>sa-frontend/src/App.js</code> .   ,     : <br><br><pre> <code class="plaintext hljs">analyzeSentence() {       fetch('http://192.168.99.100:31691/sentiment', { /*    */})           .then(response =&gt; response.json())           .then(data =&gt; this.setState(data));   }</code> </pre> </li><li>  React-,       <code>sa-frontend</code>    <code>npm run build</code> . </li><li>   : <br><br><pre> <code class="plaintext hljs">docker build -f Dockerfile -t $DOCKER_USER_ID/sentiment-analysis-frontend:minikube.</code> </pre> </li><li>     Docker Hub: <br><br><pre> <code class="plaintext hljs">docker push $DOCKER_USER_ID/sentiment-analysis-frontend:minikube</code> </pre> </li><li>   <code>sa-frontend-deployment.yaml</code> ,       . </li><li>   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-deployment.yaml</code> </pre> </li></ol><br>     ,   , ,      ,    <code>minikube service sa-frontend-lb</code> .  ,   - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/53d/19c/3ba/53d19c3bac2f8cdd66213c9b34e7b05b.png"></div><br> <i><font color="#999999">  </font></i> <br><br><h2>  <font color="#3AC1EF">Zusammenfassung</font> </h2><br>   Kubernetes     ,        ,   ,   ,     .  Kubernetes   ,     ,           .    Kubernetes  Supernetes. <br><br>    ,   : <br><br><ul><li> ,    ,   React, Java  Python. </li><li>    Docker,  ,        <code>Dockerfile</code> . </li><li>    ,  ,  Docker Hub. </li></ul><br>  ,     Kubernetes: <br><br><ul><li>  </li><li>  Dienstleistungen </li><li>  </li><li>           </li><li>   </li></ul><br>      ,   ,   Kubernetes. <br><br>  <b>Liebe Leser!</b>    Kubernetes? <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438984/">https://habr.com/ru/post/de438984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438974/index.html">Virtuelle Realit√§t hilft bei psychischen St√∂rungen</a></li>
<li><a href="../de438976/index.html">Das Buch "Fr√ºhling. Alle Designmuster ¬ª</a></li>
<li><a href="../de438978/index.html">Immer und √ºberall lernen! Podcasts f√ºr Entwickler in englischer Sprache</a></li>
<li><a href="../de438980/index.html">Spring Boot 2: Was ist neu?</a></li>
<li><a href="../de438982/index.html">Kubernetes-Handbuch, Teil 1: Anwendungen, Microservices und Container</a></li>
<li><a href="../de438986/index.html">React Tutorial Teil 14: Workshop zu klassenbasierten Komponenten, Komponentenstatus</a></li>
<li><a href="../de438988/index.html">React Tutorial Teil 15: Komponentenstatus-Workshops</a></li>
<li><a href="../de438992/index.html">Entwicklertagebuch oder schlechte Entscheidungen</a></li>
<li><a href="../de438994/index.html">Intel Xeon W-3175X, ein hei√üer Schlagzeuger. Testen</a></li>
<li><a href="../de438996/index.html">Firmennetzwerk und MitM. Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
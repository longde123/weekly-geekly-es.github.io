<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔓 ✏️ 👴🏾 Kubernetes-Handbuch, Teil 2: Erstellen und Arbeiten mit einem Cluster 🙄 🏇🏿 🏮</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Letztes Mal haben wir zwei Ansätze für die Arbeit mit Microservices untersucht. Eine davon beinhaltet insbesondere die Verwendung von Docker-Container...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes-Handbuch, Teil 2: Erstellen und Arbeiten mit einem Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/438984/">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Letztes</a> Mal haben wir zwei Ansätze für die Arbeit mit Microservices untersucht.  Eine davon beinhaltet insbesondere die Verwendung von Docker-Containern, in denen Sie den Code von Microservices und Hilfsprogrammen ausführen können.  Heute werden wir unter Verwendung unserer vorhandenen Container-Images mit Kubernetes arbeiten. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/13/lv/dr/13lvdrwhhap-ouchegvweul0fg0.jpeg"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Wir stellen vor: Kubernetes</font> </h2><br>  Ich verspreche, und ich übertreibe überhaupt nicht, dass Sie sich beim Lesen dieses Artikels fragen: "Warum heißen Kubernetes nicht Supernetes?" <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d76/9f9/e76/d769f9e7670a725759dd7415949177a0.png"></div><br>  <i><font color="#999999">Supernetes</font></i> <br><br>  Wenn Sie den vorherigen Teil dieses Materials gelesen haben, wissen Sie, dass wir uns dort mit vielen Dingen befasst haben, die mit der Vorbereitung von Anwendungen für die Containerisierung und der Arbeit mit Docker-Containern zusammenhängen.  Es mag Ihnen so erscheinen, als ob das Schwierigste jetzt auf Sie wartet, aber tatsächlich ist das, worüber wir hier sprechen werden, viel einfacher als das, was wir bereits herausgefunden haben.  Der einzige Grund, warum das Erlernen von Kubernetes für jemanden als entmutigende Aufgabe erscheint, liegt in der Menge zusätzlicher Informationen, die Sie benötigen, um Kubernetes zu verstehen und effektiv zu nutzen.  Wir haben bereits alle "zusätzlichen Informationen" besprochen, die für die erfolgreiche Entwicklung von Kubernetes erforderlich sind. <br><br><h3>  <font color="#3AC1EF">▍Was ist Kubernetes?</font> </h3><br>  Im ersten Teil dieses Artikels wurden Sie nach dem Start von Microservices in Containern gebeten, über das Problem der Skalierung containerisierter Anwendungen nachzudenken. <br>  Ich schlage vor, gemeinsam darüber nachzudenken, im Format von Fragen und Antworten: <br><br>  <b>Frage:</b> Wie skalieren containerisierte Anwendungen? <br>  <b>Antwort:</b> Starten Sie zusätzliche Container. <br><br>  <b>Frage:</b> Und wie verteilt sich die Last auf sie?  Was ist, wenn ein bestimmter Server bereits maximal ausgelastet ist und der Container auf einem anderen Server bereitgestellt werden muss?  Wie finde ich den effizientesten Weg, um Hardware zu nutzen? <br>  <b>Antwort:</b> Also ... ich schaue im Internet nach ... <br><br>  <b>Frage:</b> Wie kann ich Programme aktualisieren, ohne das System zu stören?  Und wenn das Update einen Fehler enthält, wie kann man zur Arbeitsversion der Anwendung zurückkehren? <br><br>  Tatsächlich ist es die Kubernetes-Technologie, die diese und viele andere Fragen würdig beantwortet.  Ich werde versuchen, die Definition von Kubernetes auf einen Satz einzugrenzen: "Kubernetes ist ein Containerverwaltungssystem, das die zugrunde liegende Infrastruktur (die Umgebung, in der die Container ausgeführt werden) abstrahiert." <br><br>  Ich glaube, dass Ihnen das Konzept des „Containermanagements“ jetzt nicht besonders klar ist, obwohl wir dies bereits erwähnt haben.  Im Folgenden werden wir diese Technologie in der Praxis betrachten.  Das Konzept der "Abstraktion der Basisinfrastruktur" wird jedoch zuerst angetroffen.  Deshalb werden wir jetzt darüber nachdenken. <br><br><h3>  <font color="#3AC1EF">▍Abstraktion der Basisinfrastruktur</font> </h3><br>  Mit Kubernetes können Anwendungen von der Infrastruktur abstrahieren, sodass wir eine einfache API erhalten, an die Sie Anforderungen senden können.  Kubernetes versucht, diese Anforderungen mit all seinen Funktionen zu erfüllen.  In einer regulären Sprache kann eine ähnliche Anforderung beispielsweise wie folgt beschrieben werden: "Kubernetes, 4 Bildcontainer X erweitern".  Nach Erhalt des Befehls findet Kubernetes Knoten, die nicht zu beschäftigt sind (sie werden auch als "Knoten" bezeichnet - vom englischen "Knoten"), auf denen Sie neue Container bereitstellen können. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/735/b88/a2a/735b88a2a717e9c01bfc197f3c1b20fd.png"></div><br>  <i><font color="#999999">API-Serveranforderung</font></i> <br><br>  Was bedeutet das für den Entwickler?  Dies bedeutet, dass er sich keine Gedanken über die Anzahl der Knoten machen muss, darüber, wo genau die Container gestartet werden oder wie sie interagieren.  Er muss sich nicht mit Hardwareoptimierung befassen oder sich um Knoten kümmern, die möglicherweise nicht richtig funktionieren (und etwas Ähnliches wird laut Murphys Gesetz sicherlich passieren), da bei Bedarf neue Knoten zum Kubernetes-Cluster hinzugefügt werden können.  Wenn mit einigen vorhandenen Knoten etwas nicht stimmt, stellt Kubernetes Container auf den Knoten bereit, die sich noch in einem fehlerfreien Zustand befinden. <br><br>  Vieles von dem, was in der vorherigen Abbildung gezeigt wird, ist Ihnen bereits bekannt.  Es gibt aber auch etwas Neues: <br><br><ul><li>  API-Server  Das Tätigen von Anrufen an diesen Server ist die einzige Möglichkeit, mit dem vorhandenen Cluster zu interagieren, unabhängig davon, ob es sich um das Starten oder Stoppen von Containern, das Überprüfen des Systemstatus, das Arbeiten mit Protokollen oder das Ausführen anderer Aktionen handelt. </li><li>  Kubelet.  Dies ist ein Agent, der die Container innerhalb des Knotens überwacht und mit dem Hauptknoten interagiert. </li></ul><br>  Bitte beachten Sie, dass wir in einigen vorhergehenden Sätzen den Begriff „Container“ verwenden, aber hier wäre es korrekter, den Begriff „Pod“ zu verwenden.  Diese Entitäten werden in russischsprachigen Veröffentlichungen oft als „Hülsen“ bezeichnet, und manchmal werden in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> „Hülsen“ genannt, um das Konzept der „Hülse“ zu verdeutlichen. Sie sprechen von einer „Herde Wale“ (Hülse der Wale) oder einer „Erbsenschote“. aber niemand nennt sie "Herden" oder "Schoten".  Wenn wir von ihnen sprechen, werden wir das Wort "unter" verwenden.  Jetzt können Sie sie als Container betrachten. Wir werden weiter unten mehr über Pods sprechen. <br><br>  Wir werden vorerst damit aufhören, da wir darüber weiter sprechen können, und außerdem gibt es viele gute Materialien zur Theorie der Kubernetes.  Dies ist beispielsweise eine offizielle Dokumentation, obwohl sie nicht leicht zu lesen ist, oder Bücher wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses</a> . <br><br><h3>  <font color="#3AC1EF">▍ Standardisierung der Arbeit mit Cloud-Dienstleistern</font> </h3><br>  Eine weitere Stärke von Kubernetes liegt in der Tatsache, dass diese Technologie zur Standardisierung der Arbeit mit Cloud-Service-Providern (Cloud Service Provider, CSP) beiträgt.  Dies ist eine kühne Aussage.  Betrachten Sie das folgende Beispiel.  Ein Spezialist, der Azure oder die Google Cloud Platform gut kennt, muss an einem Projekt arbeiten, das für eine völlig neue Cloud-Umgebung entwickelt wurde, mit der er nicht vertraut ist.  In dieser Situation kann viel schief gehen.  Beispielsweise können sich die Fristen für die Lieferung des Projekts verzögern, das Kundenunternehmen des Projekts muss möglicherweise mehr Cloud-Ressourcen als geplant mieten und so weiter. <br><br>  Bei der Verwendung von Kubernetes kann ein solches Problem einfach nicht auftreten, da die Arbeit mit Kubernetes unabhängig davon, um welchen Cloud-Dienstanbieter es sich handelt, immer gleich aussieht.  Der Entwickler teilt dem API-Server deklarativ mit, was er benötigt, und Kubernetes arbeitet mit den Ressourcen des Systems, sodass der Entwickler die Details der Implementierung dieses Systems ignorieren kann. <br><br>  Verweilen Sie ein wenig bei dieser Idee, da dies eine sehr mächtige Gelegenheit für Kubernetes ist.  Für Unternehmen bedeutet dies, dass ihre Entscheidungen nicht an einen bestimmten CSP gebunden sind.  Wenn ein Unternehmen ein besseres Angebot auf dem Cloud-Service-Markt findet, kann es dieses Angebot frei nutzen, indem es zu einem neuen Anbieter wechselt.  Darüber hinaus geht die Erfahrung der Spezialisten des Unternehmens nirgendwo verloren. <br><br>  Lassen Sie uns nun über die praktische Verwendung von Kubernetes sprechen <br><br><h2>  <font color="#3AC1EF">Kubernetes Übung: Pods</font> </h2><br>  Wir haben den Start von Microservices in Containern konfiguriert, der Einrichtungsprozess war ziemlich langwierig, aber wir haben es geschafft, zu einem funktionierenden System zu gelangen.  Darüber hinaus ist unsere Lösung, wie bereits erwähnt, nicht gut skalierbar und nicht störungsresistent.  Wir werden diese Probleme mit Kubernetes lösen.  Als nächstes bringen wir unser System in eine Form, die dem folgenden Schema entspricht.  Die Container werden nämlich von Kubernetes verwaltet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/53d/19c/3ba/53d19c3bac2f8cdd66213c9b34e7b05b.png"></div><br>  <i><font color="#999999">Microservices arbeiten in einem von Kubernetes verwalteten Cluster</font></i> <br><br>  Hier verwenden wir Minikube für die lokale Bereitstellung des Clusters und zum Testen der Funktionen von Kubernetes. Alles, was wir hier tun, kann jedoch über Cloud-Plattformen wie Azure oder Google Cloud Platform erfolgen. <br><br><h3>  <font color="#3AC1EF">▍Installation und Start von Minikube</font> </h3><br>  Befolgen Sie zum Installieren von Minikube die Anweisungen in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> .  Während der Installation von Minikube installieren Sie auch Kubectl.  Dies ist ein Client, mit dem Anforderungen an den Kubernetes-API-Server gestellt werden können. <br><br>  Führen Sie zum Starten von Minikube den Befehl <code>minikube start</code> und führen Sie nach Abschluss den Befehl <code>kubectl get nodes</code> .  Infolgedessen sollten Sie Folgendes sehen: <br><br><pre> <code class="plaintext hljs">kubectl get nodes NAME       STATUS ROLES     AGE VERSION minikube   Ready &lt;none&gt;    11m v1.9.0</code> </pre> <br>  Minikube stellt uns einen Cluster zur Verfügung, der nur aus einem Knoten besteht.  Das passt zwar ganz gut zu uns.  Diejenigen, die mit Kubernetes arbeiten, müssen sich nicht genau darum kümmern, wie viele Knoten sich im Cluster befinden, da Sie mit Kubernetes von solchen Details abstrahieren können. <br><br>  Sprechen wir jetzt über Pods. <br><br><h3>  <font color="#3AC1EF">▍Pods</font> </h3><br>  Ich mag Container wirklich, und Sie mögen sie jetzt wahrscheinlich auch.  Warum bietet Kubernetes uns die Verwendung von Pods an, Entitäten, die die minimal einsetzbaren Recheneinheiten in diesem System darstellen?  Unter welchen Funktionen wird es ausgeführt?  Tatsache ist, dass der Herd einen oder mehrere Container enthalten kann, die dieselbe Laufzeit haben. <br><br>  Aber ist es notwendig, zum Beispiel zwei Container in einem Herd auszuführen?  Wie sagt man ... Normalerweise gibt es nur einen Container pro Container, und das werden wir tun.  In den Fällen, in denen beispielsweise zwei Container gemeinsam auf dasselbe Data Warehouse zugreifen müssen oder wenn sie mithilfe der Interprozesskommunikationstechnik verbunden sind oder wenn sie aus einem anderen Grund eng miteinander verbunden sind, kann dies alles realisiert werden indem man sie in einem Herd laufen lässt.  Eine andere Möglichkeit, in der sich Pods unterscheiden, besteht darin, dass sie keine Docker-Container verwenden müssen.  Bei Bedarf können Sie hier andere Technologien für die Containerisierung von Anwendungen anwenden, z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rkt</a> . <br><br>  Das folgende Diagramm zeigt die nummerierten Herdeigenschaften. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f6/2a4/bb1/4f62a4bb18bddccc49a9d224a4aa919d.png"></div><br>  <i><font color="#999999">Herdeigenschaften</font></i> <br><br>  Berücksichtigen Sie diese Eigenschaften. <br><br><ol><li>  Jeder Pod in einem Kubernetes-Cluster verfügt über eine eindeutige IP-Adresse. </li><li>  Ein Herd kann viele Behälter enthalten.  Sie teilen die verfügbaren Portnummern, <code>localhost</code> sie können beispielsweise Informationen über <code>localhost</code> miteinander austauschen (natürlich können sie nicht dieselben Ports verwenden).  Die Interaktion mit Containern in anderen Pods wird anhand der IP-Adressen dieser Pods organisiert. </li><li>  Container in Pods teilen sich Datenspeichervolumen, IP-Adresse, Portnummern und IPC-Namespace. </li></ol><br>  Es ist zu beachten, dass Container ihre eigenen isolierten Dateisysteme haben, sie jedoch Daten mithilfe der Kubernetes-Ressource namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Volume gemeinsam nutzen können</a> . <br><br>  Für uns reicht das, was bereits über die Herde gesagt wurde, aus, um die Kubernetes weiterhin zu beherrschen.  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> mehr darüber. <br><br><h3>  <font color="#3AC1EF">▍ Beschreibung des Herdes</font> </h3><br>  Das Folgende ist eine Manifestdatei für die <code>sa-frontend</code> Anwendung. <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Pod                                            # 1 metadata: name: sa-frontend                                  # 2 spec:                                                # 3 containers:   - image: rinormaloku/sentiment-analysis-frontend # 4     name: sa-frontend                              # 5     ports:       - containerPort: 80</code> </pre> <br>  Lassen Sie uns einige der darin angegebenen Parameter erklären. <br><br><ol><li>  <code>Kind</code> : Gibt die Art der Kubernetes-Ressource an, die erstellt werden soll.  In unserem Fall ist dies <code>Pod</code> . </li><li>  <code>Name</code> : Name der Ressource.  Wir haben es <code>sa-frontend</code> . </li><li>  <code>Spec</code> : Ein Objekt, das den gewünschten Status der Ressource beschreibt.  Die wichtigste Eigenschaft hierbei ist die Anordnung der Container. </li><li>  <code>Image</code> : Das Bild des Containers, den wir in diesem Pod ausführen möchten. </li><li>  <code>Name</code> : Ein eindeutiger Name für den darunter liegenden Container. </li><li>  <code>ContainerPort</code> : Der Port, den der Container überwacht.  Dieser Parameter kann als Hinweis darauf angesehen werden, wer diese Datei liest (wenn Sie diesen Parameter weglassen, wird der Zugriff auf den Port nicht eingeschränkt). </li></ol><br><h3>  <font color="#3AC1EF">▍Erstellen eines SA-Frontends</font> </h3><br>  Die Pod-Beschreibungsdatei, über die wir gesprochen haben, finden Sie unter <code>resource-manifests/sa-frontend-pod.yaml</code> .  Sie müssen entweder mit den Terminal-Tools in diesen Ordner wechseln oder beim Aufrufen des entsprechenden Befehls den vollständigen Pfad zur Datei angeben.  Hier ist dieser Befehl und ein Beispiel für eine Systemreaktion darauf: <br><br><pre> <code class="plaintext hljs">kubectl create -f sa-frontend-pod.yaml pod "sa-frontend" created</code> </pre> <br>  Führen Sie den folgenden Befehl aus, um herauszufinden, ob es unter funktioniert: <br><br><pre> <code class="plaintext hljs">kubectl get pods NAME                          READY STATUS RESTARTS AGE sa-frontend                   1/1 Running 0 7s</code> </pre> <br>  Wenn der Status des Herds während der Ausführung dieses Befehls <code>ContainerCreating</code> , können Sie denselben Befehl mit dem <code>--watch</code> .  Aus diesem Grund werden Informationen dazu automatisch angezeigt, wenn sich der Herd im Betriebszustand befindet. <br><br><h3>  <font color="#3AC1EF">▍Zugriff auf die Anwendung von außen</font> </h3><br>  Um den Zugriff auf die Anwendung von außen zu organisieren, ist es richtig, eine Kubernetes-Ressource des Servicetyps zu erstellen, über die wir weiter unten sprechen werden. Der Kürze halber verwenden wir hier jedoch eine einfache Portweiterleitung: <br><br><pre> <code class="plaintext hljs">kubectl port-forward sa-frontend 88:80 Forwarding from 127.0.0.1:88 -&gt; 80</code> </pre> <br>  Wenn Sie jetzt unter <code>127.0.0.1:88</code> einen Browser <code>127.0.0.1:88</code> , wird die Seite "React-Anwendung" angezeigt. <br><br><h3>  <font color="#3AC1EF">▍ Falscher Skalierungsansatz</font> </h3><br>  Wir haben bereits gesagt, dass eine der Funktionen von Kubernetes die Anwendungsskalierung ist.  Um diese Gelegenheit zu nutzen, führen wir eine weitere unter aus.  Erstellen Sie eine Beschreibung einer anderen <code>Pod</code> Ressource, indem Sie den folgenden Code in die Datei <code>sa-frontend-pod2.yaml</code> : <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Pod                                           metadata: name: sa-frontend2      #   spec:                                                containers:   - image: rinormaloku/sentiment-analysis-frontend     name: sa-frontend                                  ports:       - containerPort: 80</code> </pre> <br>  Wie Sie sehen können, ist die einzige Änderung, wenn Sie diese Beschreibung mit der oben untersuchten vergleichen, der Wert der <code>Name</code> Eigenschaft. <br><br>  Erstellen Sie eine neue unter: <br><br><pre> <code class="plaintext hljs">kubectl create -f sa-frontend-pod2.yaml pod "sa-frontend2" created</code> </pre> <br>  Stellen Sie sicher, dass es ausgeführt wird: <br><br><pre> <code class="plaintext hljs">kubectl get pods NAME                          READY STATUS RESTARTS AGE sa-frontend                   1/1 Running 0 7s sa-frontend2                  1/1 Running 0 7s</code> </pre> <br>  Jetzt haben wir zwei Herde!  Es stimmt, hier gibt es nichts Besonderes zu genießen.  Bitte beachten Sie, dass die hier gezeigte Lösung für das Problem der Anwendungsskalierung viele Nachteile aufweist.  Wie das richtig geht, erfahren Sie im Abschnitt über eine andere Kubernetes-Ressource namens Deployment. <br><br>  Überlegen Sie nun, was wir nach dem Start von zwei identischen Herden erhalten haben.  Der Nginx-Webserver wird jetzt in zwei verschiedenen Pods ausgeführt.  In dieser Hinsicht können wir zwei Fragen stellen: <br><br><ol><li>  Wie kann ich von außen per URL auf diese Server zugreifen? </li><li>  Wie organisiere ich den Lastausgleich zwischen ihnen? </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1ff/3a9/6f4/1ff3a96f4b930fe55727d1063b3c117b.png"></div><br>  <i><font color="#999999">Falscher Skalierungsansatz</font></i> <br><br>  Unter den Kubernetes-Tools befinden sich Ressourcen des Formulars Service.  Reden wir über sie. <br><br><h2>  <font color="#3AC1EF">Kubernetes Praxis: Dienstleistungen</font> </h2><br>  Kubernetes-Dienste fungieren als Zugangspunkte zu Herdsätzen, die dieselbe Funktionalität wie diese Herde bieten.  Services lösen schwierige Aufgaben, indem sie mit Herden arbeiten und die Last zwischen ihnen ausgleichen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bbd/95f/bd8/bbd95fbd8562bed4a09ab4930a20f98d.png"></div><br>  <i><font color="#999999">Der Kubernetes-Dienst bedient IP-Adressen</font></i> <br><br>  In unserem Kubernetes-Cluster gibt es Pods, die verschiedene Funktionen implementieren.  Dies ist eine Front-End-Anwendung, eine Spring-Webanwendung und eine in Python geschriebene Flask-Anwendung.  Dies wirft die Frage auf, wie der Dienst verstehen soll, mit welcher Art von Pods er arbeiten muss, dh wie er anhand der Informationen herausfinden kann, welche Informationen das System für die Pods erstellen soll. <br><br>  Dies geschieht mit einer anderen Kubernetes-Abstraktion namens Label.  Die Arbeit mit Tags besteht aus zwei Schritten: <br><br><ol><li>  Durch die Zuweisung von Etiketten kann der Dienst bearbeitet werden. </li><li>  Durch Anwenden eines „Selektors“ auf den Dienst, der bestimmt, welche Pods welchen Etiketten zugewiesen sind, funktioniert der Dienst. </li></ol><br>  Vielleicht ist dies als Illustration leichter vorstellbar als zu beschreiben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb9/fcf/f0c/bb9fcff0cded591f1a5ab8a0b825245a.png"></div><br>  <i><font color="#999999">Beschriftete Pods und ihre Manifestdateien</font></i> <br><br>  Wir sehen hier zwei Herde, denen mit der <code>app: sa-frontend</code> Konstrukt die gleichen Bezeichnungen zugewiesen wurden.  Der Dienst ist an Pods mit solchen Markierungen interessiert. <br><br><h3>  <font color="#3AC1EF">▍Tags</font> </h3><br>  Labels bieten Entwicklern eine einfache Möglichkeit, Kubernetes-Ressourcen zu organisieren.  Es handelt sich um Schlüssel-Wert-Paare, die Sie beliebigen Ressourcen zuweisen können.  Ändern Sie die Herdbeschreibungsdateien der Frontend-Anwendung und bringen Sie sie in die in der vorherigen Abbildung gezeigte Ansicht.  Speichern Sie danach diese Dateien und führen Sie die folgenden Befehle aus: <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-pod.yaml Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply pod "sa-frontend" configured kubectl apply -f sa-frontend-pod2.yaml Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply pod "sa-frontend2" configured</code> </pre> <br>  Wenn diese Befehle ausgeführt werden, gibt das System Warnungen aus (es passt nicht zu uns, dass wir <code>apply</code> anstelle von <code>create</code> , wir verstehen dies), aber nach einer Warnung meldet es, dass die entsprechenden Pods konfiguriert sind.  Wir können überprüfen, ob Etiketten Etiketten zugewiesen wurden, indem wir die Protokolle filtern, für die Informationen angezeigt werden sollen: <br><br><pre> <code class="plaintext hljs">kubectl get pod -l app=sa-frontend NAME           READY STATUS    RESTARTS AGE sa-frontend    1/1 Running   0 2h sa-frontend2   1/1 Running   0 2h</code> </pre> <br>  Eine andere Möglichkeit, um zu überprüfen, ob Beschriftungen tatsächlich Beschriftungen zugewiesen wurden, besteht darin, den Schlüssel <code>--show-labels</code> an den vorherigen Befehl anzuhängen.  Aus diesem Grund enthalten Informationen zu ihren Pods auch Daten zu ihren Marken. <br><br>  Jetzt wurden Tags zugewiesen und wir können den Dienst so konfigurieren, dass er mit ihnen funktioniert.  Daher werden wir die Beschreibung eines Dienstes wie <code>LoadBalancer</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e0f/081/7e9/e0f0817e9fc090628aa1d0d89577ce80.gif"></div><br>  <i><font color="#999999">Lastausgleich mit einem Dienst wie LoadBalancer</font></i> <br><br><h3>  <font color="#3AC1EF">▍ Servicebeschreibung</font> </h3><br>  Hier ist eine YAML-Beschreibung eines Dienstes wie <code>LoadBalancer</code> : <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Service              # 1 metadata: name: sa-frontend-lb spec: type: LoadBalancer       # 2 ports: - port: 80               # 3   protocol: TCP          # 4   targetPort: 80         # 5 selector:                # 6   app: sa-frontend       # 7</code> </pre> <br>  Erklären Sie diesen Text: <br><br><ol><li>  <code>Kind</code> : Wir erstellen einen Service, eine <code>Service</code> Ressource. </li><li>  <code>Type</code> : Der in der Spezifikation angegebene Ressourcentyp.  Wir haben den Typ <code>LoadBalancer</code> , weil wir mit diesem Service das Problem des Lastausgleichs zwischen den Herden lösen wollen. </li><li>  <code>Port</code> : Port, an dem der Dienst Anforderungen akzeptiert. </li><li>  <code>Protocol</code> : Das vom Dienst verwendete Protokoll. </li><li>  <code>TargetPort</code> : Port, an den eingehende Anforderungen umgeleitet werden. </li><li>  <code>Selector</code> : Ein Objekt, das Informationen darüber enthält, mit welchen Pods der Dienst arbeiten soll. </li><li>  <code>app: sa-frontend</code> : Diese Eigenschaft gibt an, mit welchen Pods der Dienst arbeiten wird.  Dies sind nämlich die Pods, denen das Label <code>app: sa-frontend</code> zugewiesen ist. </li></ol><br>  Um einen Dienst zu erstellen, müssen Sie den folgenden Befehl ausführen: <br><br><pre> <code class="plaintext hljs">kubectl create -f service-sa-frontend-lb.yaml service "sa-frontend-lb" created</code> </pre> <br>  Sie können den Status des Dienstes wie folgt überprüfen: <br><br><pre> <code class="plaintext hljs">kubectl get svc NAME             TYPE CLUSTER-IP      EXTERNAL-IP PORT(S) AGE sa-frontend-lb   LoadBalancer 10.101.244.40   &lt;pending&gt; 80:30708/TCP 7m</code> </pre> <br>  Hier können Sie sehen, dass sich die <code>EXTERNAL-IP</code> Eigenschaft im Status <code>&lt;pending&gt;</code> , aber Sie können nicht warten, bis sie sich ändert.  Dies liegt an der Tatsache, dass wir Minikube verwenden.  Wenn wir bei der Arbeit mit einem bestimmten Cloud-Dienstanbieter wie Azure oder der Google Cloud Platform einen ähnlichen Dienst erstellen würden, hätte der Dienst eine öffentliche IP-Adresse, die den Zugriff über das Internet ermöglicht. <br><br>  Trotzdem erlaubt uns Minikube nicht, herumzuspielen, was uns einen nützlichen Befehl für das lokale Debuggen des Systems gibt: <br><br><pre> <code class="plaintext hljs">minikube service sa-frontend-lb Opening kubernetes service default/sa-frontend-lb in default browser...</code> </pre> <br>  Dank dieses Befehls wird ein Browser gestartet, der auf den Dienst zugreift.  Nachdem der Dienst die Anforderung erhalten hat, leitet er sie an einen der Herde weiter (es spielt keine Rolle, unter welchem ​​er sich befindet).  Diese Abstraktion ermöglicht es uns, eine Gruppe von Herden als eine Einheit zu betrachten und mit ihnen zu arbeiten, wobei der Dienst als ein einziger Zugangspunkt zu ihnen verwendet wird. <br><br>  In diesem Abschnitt haben wir darüber gesprochen, wie Ressourcen Beschriftungen zugewiesen werden und wie sie beim Konfigurieren von Diensten als Selektoren verwendet werden.  Hier haben wir einen Service wie <code>LoadBalancer</code> beschrieben und erstellt.  Dank dessen haben wir das Problem der Skalierung der Anwendung (Skalierung besteht aus dem Hinzufügen neuer Herde mit den entsprechenden Beschriftungen zum Cluster) und der Organisation des Lastausgleichs zwischen den Herden unter Verwendung des Dienstes als Einstiegspunkt gelöst. <br><br><h2>  <font color="#3AC1EF">Kubernetes-Praxis: Bereitstellungen</font> </h2><br>  Die Bereitstellung ist eine Abstraktion von Kubernetes, mit der wir steuern können, was im Anwendungslebenszyklus immer vorhanden ist.  Es geht darum, Anwendungsänderungen zu verwalten.  Anwendungen, die sich nicht ändern, sind sozusagen „tote“ Anwendungen.  Wenn die Anwendung "lebt", kann es vorkommen, dass sich ihre Anforderungen regelmäßig ändern, ihr Code erweitert wird, dieser Code gepackt und bereitgestellt wird.  Darüber hinaus können bei jedem Schritt des Prozesses Fehler gemacht werden. <br><br>  Mit einer Ressource vom Typ Bereitstellung können Sie den Übergang von einer Version einer Anwendung zu einer anderen automatisieren.  Dies geschieht ohne Unterbrechung des Systems. Wenn während dieses Vorgangs ein Fehler auftritt, haben wir die Möglichkeit, schnell zur vorherigen funktionierenden Version der Anwendung zurückzukehren. <br><br><h3>  <font color="#3AC1EF">▍Verwendung von Bereitstellungen</font> </h3><br>  Jetzt verfügt der Cluster über zwei Herde und einen Dienst, der den Zugriff von außen ermöglicht und die Last auf sie ausgleicht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/426/651/0c4/4266510c40a1faa6086178e5db23d20c.png"></div><br>  <i><font color="#999999">Aktueller Status des Clusters</font></i> <br><br>  Wir haben darüber gesprochen, dass es keine gute Idee ist, zwei verschiedene Herde mit derselben Funktionalität zu betreiben.  Wenn wir ein solches Schema verwenden, müssen wir mit jedem Herd einzeln arbeiten, jeden bestimmten Herd erstellen, aktualisieren, löschen und seinen Zustand beobachten.  Bei diesem Ansatz ist es nicht erforderlich, über ein schnelles Update des Systems oder das schnelle Rollback eines nicht erfolgreichen Updates zu sprechen.  Wir sind mit diesem Sachverhalt nicht zufrieden, daher werden wir auf die Möglichkeit der Bereitstellung von Ressourcen zurückgreifen, die auf die Lösung der oben genannten Probleme abzielen. <br><br>  Bevor wir mit der Arbeit fortfahren, formulieren wir die Ziele, die uns Richtlinien geben, die beim Parsen der Bereitstellungsmanifestdatei hilfreich sind.  Also hier ist was wir brauchen: <br><br><ol><li>  Wir möchten in der Lage sein, zwei Herde basierend auf einem Container- <code>rinormaloku/sentiment-analysis-frontend</code> zu erstellen. </li><li>  Wir benötigen ein Anwendungsbereitstellungssystem, mit dem es bei der Aktualisierung ohne Unterbrechungen funktioniert. </li><li>  Wir möchten, dass das <code>app: sa-frontend</code> Label zugewiesen wird <code>app: sa-frontend</code> , wodurch der <code>sa-frontend-lb</code> Dienst diese Pods erkennen kann. </li></ol><br>  Wir werden diese Anforderungen nun als Beschreibung der Bereitstellungsressource ausdrücken. <br><br><h3>  <font color="#3AC1EF">▍ Bereitstellungsbeschreibung</font> </h3><br>  Hier ist eine YAML-Beschreibung einer Ressource vom Typ Bereitstellung, die unter Berücksichtigung der oben genannten Systemanforderungen erstellt wurde: <br><br><pre> <code class="plaintext hljs">apiVersion: extensions/v1beta1 kind: Deployment                                          # 1 metadata: name: sa-frontend spec: replicas: 2                                             # 2 minReadySeconds: 15 strategy:   type: RollingUpdate                                   # 3   rollingUpdate:     maxUnavailable: 1                                   # 4     maxSurge: 1                                         # 5 template:                                               # 6   metadata:     labels:       app: sa-frontend                                  # 7   spec:     containers:       - image: rinormaloku/sentiment-analysis-frontend         imagePullPolicy: Always                         # 8         name: sa-frontend         ports:           - containerPort: 80</code> </pre> <br>  Lassen Sie uns diese Beschreibung analysieren: <br><br><ol><li>  <code>Kind</code> : Hier steht, dass wir eine Ressource der <code>Deployment</code> . </li><li>  <code>Replicas</code> : Eine Eigenschaft des Bereitstellungsspezifikationsobjekts, die definiert, wie viele Instanzen (Replikate) von Herden ausgeführt werden sollen. </li><li>  <code>Type</code> : beschreibt die Strategie, die in dieser Bereitstellung beim Wechsel von der aktuellen zu einer neuen Version verwendet wird.  <code>RollingUpdate</code> Strategie von <code>RollingUpdate</code> bietet keine Systemausfälle während Upgrades. </li><li>  <code>MaxUnavailable</code> : Dies ist eine Eigenschaft des <code>RollingUpdate</code> Objekts, mit der die maximale Anzahl nicht verfügbarer Herde (im Vergleich zur gewünschten Anzahl von Herden) festgelegt wird, wenn eine sequentielle Systemaktualisierung durchgeführt wird.  In unserer Bereitstellung, die das Vorhandensein von 2 Replikaten impliziert, gibt der Wert dieser Eigenschaft an, dass nach Abschluss eines Pods ein weiterer ausgeführt wird, wodurch die Anwendung während des Updates verfügbar wird. </li><li>  <code>MaxSurge</code> : Dies ist eine Eigenschaft des <code>RollingUpdate</code> Objekts, die die maximale Anzahl von Herden beschreibt, die einer Bereitstellung hinzugefügt werden können (im Vergleich zu einer bestimmten Anzahl von Herden).  In unserem Fall bedeutet der Wert 1, dass wir beim Wechsel zu einer neuen Version des Programms dem Cluster ein weiteres Sub hinzufügen können, was dazu führt, dass bis zu drei Herde gleichzeitig gestartet werden können. </li><li>  <code>Template</code> : Dieses Objekt definiert die Herdvorlage, mit der die beschriebene <code>Deployment</code> neue Herde erstellt.  Diese Einstellung ist Ihnen wahrscheinlich bekannt. </li><li>  <code>app: sa-frontend</code> : Bezeichnung für Herde, die nach einem bestimmten Muster erstellt wurden. </li><li>  <code>ImagePullPolicy</code> : <code>ImagePullPolicy</code> die Reihenfolge der Arbeit mit Bildern.  In unserem Fall ist diese Eigenschaft auf <code>Always</code> festgelegt, <code>Always</code> während jeder Bereitstellung wird das entsprechende Image aus dem Repository heruntergeladen. </li></ol><br>  Nachdem wir das alles untersucht haben, wollen wir weiter üben.  Führen Sie die Bereitstellung aus: <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-deployment.yaml deployment "sa-frontend" created</code> </pre> <br>  Überprüfen Sie den Status des Systems: <br><br><pre> <code class="plaintext hljs">kubectl get pods NAME                           READY STATUS RESTARTS AGE sa-frontend                    1/1 Running 0 2d sa-frontend-5d5987746c-ml6m4   1/1 Running 0 1m sa-frontend-5d5987746c-mzsgg   1/1 Running 0 1m sa-frontend2                   1/1 Running 0 2d</code> </pre> <br>  Wie Sie sehen können, haben wir jetzt 4 Pods.  Zwei davon wurden mithilfe der Bereitstellungsressource erstellt, zwei weitere haben wir selbst erstellt.  Jetzt können Sie die Pods, die wir selbst erstellt haben, mit Befehlen des folgenden Typs entfernen: <br><br><pre> <code class="plaintext hljs">kubectl delete pod &lt;pod-name&gt;</code> </pre> <br>  Hier ist übrigens ein Auftrag für selbständiges Arbeiten.  Löschen Sie einen der mit der Bereitstellungsressource erstellten Herde und überwachen Sie das System.  Denken Sie über die Gründe nach, bevor Sie weiterlesen. <br><br>  Beim Löschen eines Herdes erfährt die Bereitstellungsressource, dass sich der aktuelle Status des Systems (1 Sub) vom gewünschten unterscheidet (2 Sub), sodass ein anderes Sub gestartet wird. <br><br>  Was ist die Verwendung von Bereitstellungsressourcen, abgesehen von der Tatsache, dass das System bei Verwendung im richtigen Zustand gehalten wird?  Berücksichtigen Sie die Stärken dieser Ressourcen. <br><br><h3>  <font color="#3AC1EF">▍ Bereitstellen ohne Systemausfallzeit</font> </h3><br>  Angenommen, ein Produktmanager kommt zu uns und meldet, dass der Client, für den wir dieses Produkt erstellt haben, eine grüne Schaltfläche in der Clientanwendung wünscht.  Die Entwickler implementieren diese Anforderung und geben uns das einzige, was wir von ihnen benötigen - einen <code>rinormaloku/sentiment-analysis-frontend:green</code> namens <code>rinormaloku/sentiment-analysis-frontend:green</code> .  Jetzt kommt unsere Zeit.  Wir, das DevOps-Team, müssen das aktualisierte System bereitstellen und sicherstellen, dass keine Ausfallzeiten auftreten.  Lassen Sie uns nun sehen, ob die Bemühungen zur Entwicklung und Konfiguration der Bereitstellungsressource gerechtfertigt sind. <br><br>  Bearbeiten Sie die Datei <code>sa-frontend-deployment-green.yaml</code> und ersetzen Sie den Namen des <code>rinormaloku/sentiment-analysis-frontend:green</code> durch einen neuen mit <code>rinormaloku/sentiment-analysis-frontend:green</code> . Speichern Sie diese Datei dann als <code>sa-frontend-deployment-green.yaml</code> und führen Sie den folgenden Befehl aus: <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-deployment-green.yaml --record deployment "sa-frontend" configured</code> </pre> <br>  Überprüfen Sie den Systemstatus mit dem folgenden Befehl: <br><br><pre> <code class="plaintext hljs">kubectl rollout status deployment sa-frontend Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 of 2 updated replicas are available... deployment "sa-frontend" successfully rolled out</code> </pre> <br>  In Übereinstimmung mit den Daten, die als Antwort auf diesen Befehl angezeigt werden, können wir den Schluss ziehen, dass die Updatebereitstellung erfolgreich war.  Während des Upgrades wurden die alten Replikate einzeln durch neue ersetzt.  ,   ,    ,   .     ,    ,    . <br><br><h4>   </h4><br>      ,     ,     : <br><br><pre> <code class="plaintext hljs">minikube service sa-frontend-lb</code> </pre> <br>       ,      . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/777/489/902/777489902694f46438ceae41ce59db9b.png"></div><br> <i><font color="#999999"> </font></i> <br><br>  ,     ,  —    . <br><br><h4>      RollingUpdate </h4><br>  ,     <code>kubectl apply -f sa-frontend-deployment-green.yaml --record</code> , Kubernetes   ,     ,    .         ,       ,    <code>rinormaloku/sentiment-analysis-frontend:green</code> .       ,    ,   . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/465/7ee/290/4657ee29097dc99e4fa2a0ebd9180e7a.png"></div><br> <i><font color="#999999">     </font></i> <br><br>  <code>RollingUpdate</code>       ,  ,     <code>maxUnavailable: 1</code>  <code>maxSurge: 1</code> .  ,   Deployment ,     ,    ,     .  ,    ,    ,         . <br><br>         Deployment.     ,   .      . <br><br><h3> <font color="#3AC1EF">▍    </font> </h3><br>   ,   ,   . «!  !    !», —  .        . ,   ,      : <br><br><pre> <code class="plaintext hljs">kubectl rollout history deployment sa-frontend deployments "sa-frontend" REVISION  CHANGE-CAUSE 1         &lt;none&gt;    2         kubectl.exe apply --filename=sa-frontend-deployment-green.yaml --record=true</code> </pre> <br>          : «,    ,    ?». <br><br> «.  ,   ?», —   . <br><br>  ,         ,     : <br><br><pre> <code class="plaintext hljs">kubectl rollout undo deployment sa-frontend --to-revision=1 deployment "sa-frontend" rolled back</code> </pre> <br>      .   ,      . <br><br>       . <br><br>       . <br><br> ! <br><br>   ,  .   Kubernetes         ,  ,      . ,   ! <br><br>           . ,       .  <code>CHANGE-CAUSE</code>      <code>&lt;none&gt;</code> ,    — <code>kubectl.exe apply –filename=sa-frontend-deployment-green.yaml –record=true</code> ? <br><br>   ,         -- <code>record</code>     ,    . <br><br>       ,   ,  ,      . <br><br><h2> <font color="#3AC1EF">   Kubernetes:    </font> </h2><br>      Kubernetes,    ,     .      ,     . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7cb/af4/880/7cbaf4880d435df50761d22508f61e83.png"></div><br> <i><font color="#999999">  </font></i> <br><br>       . <br><br><h3> <font color="#3AC1EF">▍  sa-logic</font> </h3><br>        <code>resource-manifests</code>    : <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-logic-deployment.yaml --record deployment "sa-logic" created</code> </pre> <br>  <code>sa-logic</code>   .     Python-.    <code>app: sa-logic</code> .          <code>sa-logic</code> ,   .   <code>sa-logic-deployment.yaml</code>     . <br><br>  -,        ,      —  <code>sa-logic</code> . <br><br><h3> <font color="#3AC1EF">▍ sa-logic</font> </h3><br>   ,       Service.   ,   Java-,        <code>sa-webapp</code> ,      ,  Python-.  ,    ,       ,     Python-,   .     ,  ,  ,  . <br><br>      , ,    ,       ,   .  ,      <code>sa-logic</code>   ,       <code>sa-logic</code> . <br><br>   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f service-sa-logic.yaml service "sa-logic" created</code> </pre> <br>    ,        . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/693/79b/3e3/69379b3e373ad1bc728242db341411ab.png"></div><br> <i><font color="#999999">  </font></i> <br><br>   <code>sa-logic</code> ,   <code>sa-webapp</code> ,    ,    . <br><br>   <code>sa-webapp</code> . <br><br><h3> <font color="#3AC1EF">▍  sa-webapp</font> </h3><br>      ,          Deployment    - . ,     <code>sa-web-app-deployment.yaml</code> ,      : <br><br><pre> <code class="plaintext hljs">- image: rinormaloku/sentiment-analysis-web-app imagePullPolicy: Always name: sa-web-app env:   - name: SA_LOGIC_API_URL     value: "http://sa-logic" ports:   - containerPort: 8080</code> </pre> <br>     <code>env</code> ?  ,   ,  ,   <code>SA_LOGIC_API_URL</code>   <code>http://sa-logic</code> .   ,    ,       .    ? <br><br>             kube-dns. <br><br><h3> <font color="#3AC1EF">▍DNS-  Kubernetes</font> </h3><br>  Kubernetes   ,   <code>kube-dns</code> .        DNS-.     <code>kube-dns</code>   ,     DNS-    . <br><br>  ,      <code>sa-logic</code> ,   IP-.  <code>kube-dns</code>        IP- .        <code>http://sa-logic</code>  IP-. <br><br>      Deployment <code>sa-webapp</code> . <br><br><h3> <font color="#3AC1EF">▍  sa-webapp</font> </h3><br>   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-web-app-deployment.yaml --record deployment "sa-web-app" created</code> </pre> <br>         <code>sa-webapp</code>   ,   .   React-    ,       <code>sa-webapp</code> . <br><br><h3> <font color="#3AC1EF">▍ sa-webapp</font> </h3><br>     <code>service-sa-web-app-lb.yaml</code> ,  ,  ,    ,   . ,   ,   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f service-sa-web-app-lb.yaml service "sa-web-app-lb" created</code> </pre> <br>    . ,     ,      . ,     <code>sa-frontend</code> ,        Java- <code>sa-webapp</code> ,    <code>http://localhost:8080/sentiment</code> .      ,       ,   <code>sa-webapp</code> ,    React-  ,     Java-. <br><br>           ,     . ,          —  ,    ,     . <br><br>  ,       : <br><br><ol><li>  IP-   <code>sa-webapp</code> ,   : <br><br> <code>minikube service list <br> |-------------|----------------------|-----------------------------| <br> |  NAMESPACE  | NAME         | URL       | <br> |-------------|----------------------|-----------------------------| <br> | default     | kubernetes         | No node port       | <br> | default     | sa-frontend-lb       | http://192.168.99.100:30708 | <br> | default     | sa-logic         | No node port       | <br> | default     | sa-web-app-lb        | http://192.168.99.100:31691 | <br> | kube-system | kube-dns             | No node port | <br> | kube-system | kubernetes-dashboard | http://192.168.99.100:30000 | <br> |-------------|----------------------|-----------------------------|</code> </li> <li>   IP-   <code>sa-frontend/src/App.js</code> .   ,     : <br><br><pre> <code class="plaintext hljs">analyzeSentence() {       fetch('http://192.168.99.100:31691/sentiment', { /*    */})           .then(response =&gt; response.json())           .then(data =&gt; this.setState(data));   }</code> </pre> </li><li>  React-,       <code>sa-frontend</code>    <code>npm run build</code> . </li><li>   : <br><br><pre> <code class="plaintext hljs">docker build -f Dockerfile -t $DOCKER_USER_ID/sentiment-analysis-frontend:minikube.</code> </pre> </li><li>     Docker Hub: <br><br><pre> <code class="plaintext hljs">docker push $DOCKER_USER_ID/sentiment-analysis-frontend:minikube</code> </pre> </li><li>   <code>sa-frontend-deployment.yaml</code> ,       . </li><li>   : <br><br><pre> <code class="plaintext hljs">kubectl apply -f sa-frontend-deployment.yaml</code> </pre> </li></ol><br>     ,   , ,      ,    <code>minikube service sa-frontend-lb</code> .  ,   - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/53d/19c/3ba/53d19c3bac2f8cdd66213c9b34e7b05b.png"></div><br> <i><font color="#999999">  </font></i> <br><br><h2>  <font color="#3AC1EF">Zusammenfassung</font> </h2><br>   Kubernetes     ,        ,   ,   ,     .  Kubernetes   ,     ,           .    Kubernetes  Supernetes. <br><br>    ,   : <br><br><ul><li> ,    ,   React, Java  Python. </li><li>    Docker,  ,        <code>Dockerfile</code> . </li><li>    ,  ,  Docker Hub. </li></ul><br>  ,     Kubernetes: <br><br><ul><li>  </li><li>  Dienstleistungen </li><li>  </li><li>           </li><li>   </li></ul><br>      ,   ,   Kubernetes. <br><br>  <b>Liebe Leser!</b>    Kubernetes? <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438984/">https://habr.com/ru/post/de438984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438974/index.html">Virtuelle Realität hilft bei psychischen Störungen</a></li>
<li><a href="../de438976/index.html">Das Buch "Frühling. Alle Designmuster »</a></li>
<li><a href="../de438978/index.html">Immer und überall lernen! Podcasts für Entwickler in englischer Sprache</a></li>
<li><a href="../de438980/index.html">Spring Boot 2: Was ist neu?</a></li>
<li><a href="../de438982/index.html">Kubernetes-Handbuch, Teil 1: Anwendungen, Microservices und Container</a></li>
<li><a href="../de438986/index.html">React Tutorial Teil 14: Workshop zu klassenbasierten Komponenten, Komponentenstatus</a></li>
<li><a href="../de438988/index.html">React Tutorial Teil 15: Komponentenstatus-Workshops</a></li>
<li><a href="../de438992/index.html">Entwicklertagebuch oder schlechte Entscheidungen</a></li>
<li><a href="../de438994/index.html">Intel Xeon W-3175X, ein heißer Schlagzeuger. Testen</a></li>
<li><a href="../de438996/index.html">Firmennetzwerk und MitM. Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
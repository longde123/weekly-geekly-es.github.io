<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§± ü§≥ üë©‚Äçüîß Cr√©ation de routage client / recherche s√©mantique sur Profi.ru ü•§ üßñüèΩ ‚òÇÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cr√©ation de routage client / recherche s√©mantique et mise en cluster de corpus externes arbitraires chez Profi.ru 
 TLDR 


 Ceci est un tr√®s court r√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cr√©ation de routage client / recherche s√©mantique sur Profi.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428674/"><h1 id="building-client-routing--semantic-search-and-clustering-arbitrary-external-corpuses-at-profiru">  Cr√©ation de routage client / recherche s√©mantique et mise en cluster de corpus externes arbitraires chez Profi.ru </h1><br><h2 id="tldr">  <strong>TLDR</strong> </h2><br><p>  Ceci est un tr√®s court r√©sum√© (ou un teaser) sur ce que nous avons r√©ussi √† faire en environ 2 mois dans le d√©partement Profi.ru DS (j'√©tais l√† un peu plus longtemps, mais l'int√©gration de moi-m√™me et de mon √©quipe √©tait une chose distincte √† √™tre fait au d√©but). </p><a name="habracut"></a><br><h2 id="projected-goals">  Objectifs projet√©s </h2><br><ol><li> Comprendre l'entr√©e / l'intention du client et acheminer les clients en cons√©quence (nous avons finalement opt√© pour un classificateur agnostique de la qualit√© d'entr√©e, bien que nous ayons √©galement pris en compte les mod√®les de niveau de caract√®res et les mod√®les de langage. </li><li>  Trouvez des services totalement nouveaux et des synonymes pour les services existants; </li><li>  Comme sous-objectif de (2) - apprendre √† construire des grappes appropri√©es sur des corpus externes arbitraires; </li></ol><br><h2 id="achieved-goals">  Objectifs atteints </h2><br><p>  √âvidemment, certains de ces r√©sultats ont √©t√© obtenus non seulement par notre √©quipe, mais par plusieurs √©quipes (c'est-√†-dire que nous n'avons √©videmment pas fait la partie de grattage pour les corpus de domaine et l'annotation manuelle, bien que je pense que le grattage peut √©galement √™tre r√©solu par notre √©quipe - vous avez juste besoin assez de procurations + probablement une certaine exp√©rience avec le s√©l√©nium). </p><br><p>  <strong>Objectifs commerciaux:</strong> </p><br><ol><li> ~ <code>88+%</code> (vs ~ <code>60%</code> avec la recherche √©lastique) de pr√©cision sur le routage client / classification d'intention (~ <code>5k</code> classes); </li><li>  La recherche est ind√©pendante de la qualit√© de la saisie (erreurs d'impression / saisie partielle); </li><li>  Le classificateur g√©n√©ralise, la structure morphologique de la langue est exploit√©e; </li><li>  Le classificateur bat s√©v√®rement la recherche √©lastique sur divers rep√®res (voir ci-dessous); </li><li>  Pour √™tre prudent - au moins <code>1,000</code> nouveaux services ont √©t√© trouv√©s + au moins <code>15,000</code> synonymes (contre l'√©tat actuel de <code>5,000</code> + <code>30,000</code> ).  Je m'attends √† ce que ce chiffre double, voire triple; </li></ol><br><p>  La derni√®re puce est une estimation approximative, mais conservatrice. <br>  Des tests AB suivront √©galement.  Mais je suis confiant dans ces r√©sultats. </p><br><p>  <strong>Objectifs "scientifiques":</strong> </p><br><ol><li>  Nous avons compar√© de mani√®re approfondie de nombreuses techniques modernes d'incorporation de phrases en utilisant une t√¢che de classification en aval + KNN avec une base de donn√©es de synonymes de service; </li><li>  Nous avons r√©ussi √† battre la recherche √©lastique faiblement supervis√©e (essentiellement leur classifieur est un sac de ngrammes) sur cette r√©f√©rence (voir d√©tails ci-dessous) en utilisant des m√©thodes <strong>NON SUPERVIS√âES</strong> ; </li><li>  Nous avons d√©velopp√© une nouvelle fa√ßon de construire des mod√®les de PNL appliqu√©s (un bi-LSTM + un sac de plongements vanille, essentiellement un texte rapide rencontre RNN) - cela prend en consid√©ration la morphologie de la langue russe et se g√©n√©ralise bien; </li><li>  Nous avons d√©montr√© que notre technique finale d'int√©gration (une couche de goulot d'√©tranglement du meilleur classificateur) combin√©e √† des algorithmes non supervis√©s de pointe (UMAP + HDBSCAN) peut produire des amas stellaires; </li><li>  Nous avons d√©montr√© en pratique la possibilit√©, la faisabilit√© et l'utilisabilit√© de: <br><ul><li>  Distillation des connaissances; </li><li>  Augmentations pour les donn√©es texte (sic!); </li></ul></li><li>  La formation de classificateurs bas√©s sur du texte avec des augmentations dynamiques a r√©duit consid√©rablement le temps de convergence (10x) par rapport √† la g√©n√©ration de jeux de donn√©es statiques plus grands (c'est-√†-dire que le CNN apprend √† g√©n√©raliser l'erreur affich√©e avec des phrases consid√©rablement moins augment√©es); </li></ol><br><h2 id="overall-project-structure">  Structure globale du projet </h2><br><p>  Cela n'inclut pas le classificateur final. <br>  Finalement, nous avons abandonn√© les faux mod√®les de perte de RNN et de triplet au profit du goulot d'√©tranglement du classificateur. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/1c2/449/157/1c24491576ed703ebc571dfd4d7d8da3.png"></p><br><h2 id="what-works-in-nlp-now">  Qu'est-ce qui fonctionne en PNL maintenant? </h2><br><p>  Une vue √† vol d'oiseau: <br><img src="https://habrastorage.org/getpro/habr/post_images/5a1/8f5/df1/5a18f5df1e133bef082edf9315011da7.png"></p><br><p>  Vous savez peut-√™tre aussi que la PNL conna√Æt peut-√™tre le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">moment Imagenet maintenant</a> . </p><br><h2 id="large-scale-umap-hack">  Hack UMAP √† grande √©chelle </h2><br><p>  Lors de la cr√©ation de clusters, nous sommes tomb√©s sur un moyen / hack d'appliquer essentiellement UMAP √† des ensembles de donn√©es de taille 100m + point (ou peut-√™tre m√™me 1 milliard).  Construisez essentiellement un graphique KNN avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FAISS</a> , puis r√©√©crivez simplement la boucle UMAP principale dans PyTorch √† l'aide de votre GPU.  Nous n'en avions pas besoin et avons abandonn√© le concept (nous n'avions que 10 √† 15 millions de points apr√®s tout), mais veuillez suivre ce <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fil</a> pour plus de d√©tails. </p><br><h2 id="what-works-best">  Ce qui fonctionne le mieux </h2><br><ul><li>  Pour une classification supervis√©e, le texte rapide rencontre le RNN (bi-LSTM) + un ensemble de n-grammes soigneusement choisi; </li><li>  Impl√©mentation - python ordinaire pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">n-grammes</a> + couche de sac PyTorch Embedding; </li><li>  Pour le clustering - la couche de goulot d'√©tranglement de ce mod√®le + UMAP + HDBSCAN; </li></ul><br><h2 id="best-classifier-benchmarks">  <strong>Meilleurs benchmarks classificateurs</strong> </h2><br><p>  <strong>Ensemble de d√©veloppement annot√© manuellement</strong> <br><img src="https://habrastorage.org/getpro/habr/post_images/04b/7cc/e7e/04b7cce7e8cee9cee4b066b6a353bed9.jpg"></p><br><p>  <strong>De gauche √† droite:</strong> <br>  (Pr√©cision Top1) </p><br><ul><li>  Algorithme actuel (recherche √©lastique); </li><li>  First RNN; </li><li>  Nouvelle annotation; </li><li>  Tuning </li><li>  Couche de sac d'int√©gration de texte rapide; </li><li>  Ajout de fautes de frappe et entr√©e partielle; </li><li>  G√©n√©ration dynamique d'erreurs et saisie partielle ( <strong>temps de formation r√©duit 10x</strong> ); </li><li>  Score final; </li></ul><br><p>  <strong>Ensemble de d√©veloppement annot√© manuellement + 1 √† 3 erreurs par requ√™te</strong> <br><img src="https://habrastorage.org/getpro/habr/post_images/ae2/a31/040/ae2a31040dbd77402d6b6dfee9eeba28.jpg"></p><br><p>  <strong>De gauche √† droite:</strong> <br>  (Pr√©cision Top1) </p><br><ul><li>  Algorithme actuel (recherche √©lastique); </li><li>  Couche de sac d'int√©gration de texte rapide; </li><li>  Ajout de fautes de frappe et entr√©e partielle; </li><li>  G√©n√©ration dynamique d'erreurs et saisie partielle; </li><li>  Score final; </li></ul><br><p>  <strong>Ensemble de d√©veloppement annot√© manuellement + entr√©e partielle</strong> <br><img src="https://habrastorage.org/getpro/habr/post_images/c3c/680/681/c3c680681dd3166b95246930f1f1b1a8.jpg"></p><br><p>  <strong>De gauche √† droite:</strong> <br>  (Pr√©cision Top1) </p><br><ul><li>  Algorithme actuel (recherche √©lastique); </li><li>  Couche de sac d'int√©gration de texte rapide; </li><li>  Ajout de fautes de frappe et entr√©e partielle; </li><li>  G√©n√©ration dynamique d'erreurs et saisie partielle; </li><li>  Score final; </li></ul><br><h2 id="large-scale-corpuses--n-gram-selection">  Corpus √† grande √©chelle / s√©lection n-gramme </h2><br><ul><li>  Nous avons collect√© les plus grands corpus pour la langue russe: <br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Areneum</a> - une version trait√©e est disponible ici - les auteurs de l'ensemble de donn√©es n'ont pas r√©pondu; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Taiga</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Common crawl</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wiki</a> - veuillez suivre ces articles; </li></ul></li><li>  Nous avons collect√© un dictionnaire de <code>100m</code> mots en utilisant l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exploration de 1 To</a> ; </li><li>  Utilisez √©galement ce <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hack</a> pour t√©l√©charger ces fichiers plus rapidement (du jour au lendemain); </li><li>  Nous avons s√©lectionn√© un ensemble optimal de <code>1m</code> n-grammes pour que notre classificateur se g√©n√©ralise le mieux ( <code>500k</code> n-grammes les plus populaires √† partir de texte rapide form√©s sur Wikipedia russe + <code>500k</code> n-grammes les plus populaires sur nos donn√©es de domaine); </li></ul><br><p>  <strong>Test de r√©sistance de nos 1M n-grammes sur 100M de vocabulaire:</strong> <br><img src="https://habrastorage.org/getpro/habr/post_images/198/1fe/38b/1981fe38b03b4cdf76022f4ff6ef0074.png" alt="image"></p><br><h2 id="text-augmentations">  Augmentations de texte </h2><br><p>  En bref: </p><br><ul><li>  Prenez un grand dictionnaire avec des erreurs (par exemple 10-100m de mots uniques); </li><li>  G√©n√©rer une erreur (d√©poser une lettre, √©changer une lettre en utilisant les probabilit√©s calcul√©es, ins√©rer une lettre al√©atoire, peut-√™tre utiliser la disposition du clavier, etc.); </li><li>  V√©rifiez que le nouveau mot est dans le dictionnaire; </li></ul><br><p>  Nous avons forc√© de nombreuses requ√™tes √† des services comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">celui-ci</a> (dans le but de proc√©der √† une r√©tro-ing√©nierie de leur jeu de donn√©es), et ils ont un tr√®s petit dictionnaire √† l'int√©rieur (ce service est √©galement aliment√© par un classificateur d'arbre avec des fonctionnalit√©s de n-gramme).  C'√©tait <strong>assez</strong> dr√¥le de voir <strong>qu'ils ne couvraient que 30 √† 50% des mots que nous avions sur certains corpus</strong> . </p><br><p>  <strong>Notre approche est de loin sup√©rieure si vous avez acc√®s √† un vocabulaire de grand domaine</strong> . </p><br><h2 id="best-unsupervised--semi-supervised-results">  Meilleurs r√©sultats non supervis√©s / semi-supervis√©s </h2><br><p>  KNN utilis√© comme r√©f√©rence pour comparer diff√©rentes m√©thodes d'int√©gration. </p><br><p>  (taille du vecteur) Liste des mod√®les test√©s: </p><br><ul><li>  (512) D√©tecteur de fausses phrases √† grande √©chelle form√© sur 200 Go de donn√©es d'analyse communes; </li><li>  (300) D√©tecteur de fausses phrases form√© pour distinguer une phrase al√©atoire de Wikip√©dia d'un service; </li><li>  (300) Texte rapide obtenu √† partir d'ici, pr√©-form√© sur le corpus araneum; </li><li>  (200) Texte rapide form√© sur nos donn√©es de domaine; </li><li>  (300) Fast-text form√© sur 200 Go de donn√©es Common Crawl; </li><li>  (300) Un r√©seau siamois avec perte de triplets form√© avec des services / synonymes / phrases al√©atoires de Wikip√©dia; </li><li>  (200) Premi√®re it√©ration de la couche d'int√©gration du sac d'int√©gration RNN, une phrase est cod√©e comme un sac complet d'int√©gration; </li><li>  (200) Idem, mais d'abord la phrase est divis√©e en mots, puis chaque mot est int√©gr√©, puis la moyenne est prise; </li><li>  (300) Comme ci-dessus mais pour le mod√®le final; </li><li>  (300) Comme ci-dessus mais pour le mod√®le final; </li><li>  (250) Couche goulot d'√©tranglement du mod√®le final (250 neurones); </li><li>  Ligne de base de recherche √©lastique faiblement supervis√©e; </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ca1/e0b/e9c/ca1e0be9c152d092d4149f9986b87289.png" alt="d√©faut"></p><br><p>  Pour √©viter les fuites, toutes les phrases al√©atoires ont √©t√© √©chantillonn√©es au hasard.  Leur longueur en mots √©tait la m√™me que la dur√©e des services / synonymes auxquels ils √©taient compar√©s.  Des mesures ont √©galement √©t√© prises pour s'assurer que les mod√®les ne se contentent pas d'apprendre en s√©parant les vocabulaires (les int√©grations ont √©t√© gel√©es, Wikip√©dia a √©t√© sous-√©chantillonn√© pour s'assurer qu'il y avait au moins un mot de domaine dans chaque phrase Wikip√©dia). </p><br><h2 id="cluster-visualization">  Visualisation de cluster </h2><br><p>  <strong>3D</strong> <br><img src="https://habrastorage.org/getpro/habr/post_images/4b7/f10/d19/4b7f10d19a785b5f690a28f2e2a039e6.gif"></p><br><p>  <strong>2D</strong> <br><img src="https://habrastorage.org/getpro/habr/post_images/ad7/0ad/441/ad70ad441ecae6f396c8bb76826484df.png"></p><br><h2 id="cluster-exploration-interface">  "Interface" d'exploration de clusters </h2><br><p>  Vert - nouveau mot / synonyme. <br>  Fond gris - probablement nouveau mot. <br>  Texte gris - synonyme existant. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/cda/d17/00f/cdad1700ff0701ff6643a4aa14041d31.jpg"></p><br><h2 id="ablation-tests-and-what-works-what-we-tried-and-what-we-did-not">  Tests d'ablation et ce qui fonctionne, ce que nous avons essay√© et ce que nous n'avons pas fait </h2><br><ol><li>  Voir les tableaux ci-dessus; </li><li>  Moyenne simple / moyenne tf-idf des int√©grations de texte rapide - une <strong>base de donn√©es TR√àS formidable</strong> ; </li><li>  Texte rapide&gt; Word2Vec pour le russe; </li><li>  L'incorporation de phrases par le type de d√©tection de fausses phrases fonctionne, mais p√¢lit en comparaison avec d'autres m√©thodes; </li><li>  BPE (phrasepiece) n'a montr√© aucune am√©lioration sur notre domaine; </li><li>  Les mod√®les au niveau des ombles ont eu du mal √† se g√©n√©raliser, malgr√© le r√©cent papier de Google; </li><li>  Nous avons essay√© un transformateur √† t√™tes multiples (avec des classificateurs et des t√™tes de mod√©lisation de langage), mais sur l'annotation disponible, il fonctionnait √† peu pr√®s de la m√™me mani√®re que les mod√®les LSTM √† base de vanille ordinaire.  Lorsque nous avons migr√© vers l'int√©gration de mauvaises approches, nous avons abandonn√© cette ligne de recherche en raison de la faible praticit√© du transformateur et de l'impossibilit√© d'avoir une t√™te LM avec une couche de sac d'int√©gration; </li><li>  <strong>BERT</strong> - semble √™tre exag√©r√©, certaines personnes affirment √©galement que les transformateurs s'entra√Ænent litt√©ralement pendant des semaines; </li><li>  <strong>ELMO</strong> - l'utilisation d'une biblioth√®que comme AllenNLP semble contre-productive √† mon avis √† la fois dans les environnements de recherche / production et d'√©ducation pour des raisons que je ne fournirai pas ici; </li></ol><br><h2 id="deploy">  D√©ployer </h2><br><p>  Fait en utilisant: </p><br><ul><li>  Conteneur Docker avec un simple service Web; </li><li>  Le processeur uniquement pour l'inf√©rence suffit; </li><li>  ~ <code>2.5 ms</code> par requ√™te sur CPU, le traitement par lots n'est pas vraiment n√©cessaire; </li><li>  ~ <code>1GB</code> Go de m√©moire RAM; </li><li>  Presque pas de d√©pendances, √† part <code>PyTorch</code> , <code>numpy</code> et <code>pandas</code> (et le serveur web ofc). </li><li>  Imitez la g√©n√©ration de n-gramme de texte rapide comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ceci</a> ; </li><li>  Incorporation de la couche de sac + index comme simplement stock√© dans un dictionnaire; </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428674/">https://habr.com/ru/post/fr428674/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428662/index.html">T√¢che de programmation de vente au d√©tail</a></li>
<li><a href="../fr428664/index.html">D√©marrage du noyau Linux. Partie 1</a></li>
<li><a href="../fr428666/index.html">Comment j'ai cr√©√© des animations qui changent l'humeur en utilisant des masques CSS</a></li>
<li><a href="../fr428668/index.html">Blizzard a annonc√© la sortie de la r√©√©dition de WarCraft III en 2019. Pr√©-commande ouverte</a></li>
<li><a href="../fr428672/index.html">Pr√©sentation de QuietOn Active Squelch</a></li>
<li><a href="../fr428676/index.html">Briser les fondements fondamentaux de C #: allouer de la m√©moire pour un type de r√©f√©rence sur la pile</a></li>
<li><a href="../fr428680/index.html">Cr√©ation et int√©gration de bot VK dans un groupe via VkBotLongPoll [Python]</a></li>
<li><a href="../fr428682/index.html">Fallout 76 auto-destructeur</a></li>
<li><a href="../fr428688/index.html">Configuration de l'environnement de travail dans Docker pour l'application yii-framework</a></li>
<li><a href="../fr428690/index.html">Comment enseigner √† votre petite amie comment programmer si vous n'√™tes pas professeur, mais elle croit en vous</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíâ ü¶ë üö¥üèø 7 Tage, 15 Ingenieure und 600 Server: Yandex.Money ist in ein neues Rechenzentrum umgezogen ‚òÇÔ∏è ü§∞üèº üï¥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="K√ºrzlich fand in der Abteilung Yandex.Money Operations ein bedeutendes Ereignis statt. Unser Unternehmen w√§chst rasant und es stellte sich heraus, das...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>7 Tage, 15 Ingenieure und 600 Server: Yandex.Money ist in ein neues Rechenzentrum umgezogen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yamoney/blog/481340/"><img src="https://habrastorage.org/webt/_d/ye/aq/_dyeaqhvhl5sh0awhpgw7t70b38.jpeg"><br><br>  K√ºrzlich fand in der Abteilung Yandex.Money Operations ein bedeutendes Ereignis statt.  Unser Unternehmen w√§chst rasant und es stellte sich heraus, dass sich nicht nur unsere Herzen, sondern auch die Anforderungen des Rechenzentrums √§ndern.  Genauer gesagt muss sich der Ort √§ndern.  Und jetzt, seit drei Monaten, lebt eines der Rechenzentren an einem neuen Ort. <br><br>  √úber den Umzug von Yandex.Money in ein neues Rechenzentrum werde ich Ihnen, dem Leiter der Betriebsabteilung, und Ivan, dem Leiter der Abteilung f√ºr IT-Infrastruktur und interne Systeme, berichten. <br><br>  Unter dem Strich - eine Chronologie der Ereignisse, wichtige Meilensteine ‚Äã‚Äãdes Umzugs, unerwartete Wendungen und Nachbesprechungen.  Wir teilen mit, wie wir das √ºberstanden haben. <br><a name="habracut"></a><br><h2>  Voraussetzungen f√ºr den Umzug </h2><br>  Zuvor befand sich eines der Rechenzentren von Yandex.Money in einem Vorort von Moskau.  Die Realit√§t ist, dass nicht alle Anbieter von optischen Kommunikationskan√§len au√üerhalb der Stadt die M√∂glichkeit haben, Kabelstrecken unabh√§ngig zu verlegen - das ist teuer.  Der erste Grund f√ºr unsere Entscheidung f√ºr den Umzug war die Tatsache, dass die Kommunikationskan√§le im alten Rechenzentrum auf denselben Wegen verliefen, was mit zus√§tzlichen Risiken verbunden war. <br><blockquote> Innerhalb der Moskauer Ringstra√üe gibt es viele Anbieter, und das Kabelsystem ist gut entwickelt.  Sie k√∂nnen Kan√§le von verschiedenen Anbietern kaufen, die unterschiedliche Vorgehensweisen aufweisen und sich nicht √ºberschneiden.  In der Region besteht ein erh√∂htes Risiko - zum Beispiel wird ein Bagger kommen und alle Gleise auf einmal ausheben. </blockquote><br>  Zweitens hatte das vorherige Rechenzentrum technologische Einschr√§nkungen, einschlie√ülich periodisch auftretender Probleme mit der Stromversorgung. <br><br>  Aber der Hauptgrund (= Schmerz) ist die Unf√§higkeit zu expandieren.  Dies bedeutete, dass das Geb√§ude keinen Platz mehr f√ºr zus√§tzliche Gestelle hatte, in denen neue Ger√§te untergebracht werden konnten.  Dies steht in direktem Zusammenhang mit unserer produktiven Umgebung, da Yandex.Money √ºber zwei Rechenzentren verf√ºgt und diese in Bezug auf die Kapazit√§ten symmetrisch sein m√ºssen. <br><br><h2>  Planung </h2><br>  Die Vorbereitung f√ºr den Umzug war in Phasen unterteilt: <br><br><ul><li>  Wettbewerbe: Gleichstrom, Kan√§le, Netzwerke, Racks, PDUs, Kabel; </li><li>  √úbertragen Sie Anwendungen und Datenbanken auf den 2. DC; </li><li>  Lehren - DC deaktivieren; </li><li>  Neue Architektur von Kernnetzen, IX; </li><li>  Einrichten eines neuen Netzwerkkerns im DC. </li></ul><br><br><h4>  Lieferantenauswahl </h4><br>  Das erste Yandex.Money-Rechenzentrum befindet sich in Moskau.  Um gro√üe Netzwerkverz√∂gerungen zu vermeiden, haben wir beschlossen, das zweite Rechenzentrum in der N√§he des ersten zu platzieren. <br><blockquote>  Innerhalb des MKAD sollen Netzwerkverz√∂gerungen minimiert und nicht n√§her als 20 km zur ersten Einrichtung sichergestellt werden, um die Unabh√§ngigkeit beider Rechenzentren von der gleichen st√§dtischen Infrastruktur und m√∂glichen technologischen oder Naturkatastrophen sicherzustellen. </blockquote><br>  Bei der Analyse des Marktes haben wir uns von einem so wichtigen Kriterium wie der Zertifizierung von Rechenzentren hinsichtlich Verf√ºgbarkeit und Zuverl√§ssigkeit leiten lassen.  Der in Russland und der Welt am weitesten verbreitete Standard ist der vom Uptime Institute entwickelte Standard, der Rechenzentren auf der ganzen Welt √ºberpr√ºft.  Es ist anzumerken, dass es viele Rechenzentren gibt, die nur die Projektdokumentation zertifiziert haben. Dies bedeutet jedoch nicht, dass das Rechenzentrum selbst gem√§√ü Standards gebaut, getestet und betrieben wird. <br><blockquote>  Ein Fall aus unserer Praxis: Ein Anbieter von Rechenzentrumsdiensten in Moskau gab uns bekannt, dass das Rechenzentrumsprojekt den Tier III-Standard erf√ºllt, und bot an, eine Vereinbarung mit dem Versprechen einer 100% igen Verf√ºgbarkeit, dh 0 Minuten Ausfallzeit pro Jahr, abzuschlie√üen!  Bei einem pers√∂nlichen Besuch der Website haben wir festgestellt, dass es keine offiziellen Zertifizierungen gibt, die das Qualit√§tsniveau garantieren, und die Infrastruktur greift eindeutig nicht auf Tier III zur√ºck.  Das Rechenzentrum befand sich im Erdgeschoss eines Wohngeb√§udes, und der einzige Generatoranh√§nger stand ohne physischen Schutz auf der Stra√üe. </blockquote><br>  Daher haben wir in die Wettbewerbsanforderungen nicht nur die Zertifizierung des Projekts, sondern auch die Zertifizierung der Implementierungs- und Managementprozesse aufgenommen. <br><br>  Des Weiteren haben wir mit Lieferanten von optischen Kommunikationskan√§len zwischen unseren DCs und Kan√§len Verkehrsknotenpunkte (IX) festgelegt, an denen wir Schnittstellen mit Anbietern oder unseren Partnern einrichten.  Das Hauptkriterium war, dass die optischen Kommunikationskan√§le unabh√§ngig sein sollten und unterschiedliche Wege gehen sollten. <br><br>  Nat√ºrlich gab es auch andere Anschaffungen - haupts√§chlich Netzwerkger√§te, Racks (Spezialschr√§nke f√ºr die Installation von Servern), Stromverteiler (intelligente Stromverteiler) sowie Kabel und Patchkabel. <br><br>  Es ist erw√§hnenswert, dass wir den Lieferanten, der das Ger√§t transportiert, besonders sorgf√§ltig ausgew√§hlt haben.  Es ist wichtig, dass das Unternehmen Erfahrung im Transport von Servern hat und die Umzugsunternehmen verstehen, dass dies nicht M√∂bel und Lasten sind. Sie sollten auch beim Fahren besonders vorsichtig sein.  Zus√§tzlich versicherten wir die transportierten Ger√§te bei Transportsch√§den. <br><br><h4>  Upgrade der Netzwerkinfrastruktur </h4><br>  In Bezug auf die Netzwerkinfrastruktur hatten wir zwei M√∂glichkeiten.  Die erste besteht darin, alte Netzwerkger√§te so zu transportieren, wie sie sind.  Die zweite besteht darin, zun√§chst eine neue Netzwerkinfrastruktur in einem neuen Rechenzentrum aufzubauen und erst dann die Serverausr√ºstung zu transportieren. <br><br>  Da wir verstanden haben, dass wir bereits auf die Netzwerkbandbreite im alten Rechenzentrum ‚Äûgesto√üen‚Äú sind und die Reserve und die Skalierbarkeit f√ºr mindestens die n√§chsten 3-5 Jahre ben√∂tigen, wurde beschlossen, die Netzwerkinfrastruktur im neuen Rechenzentrum von Grund auf neu aufzubauen und auf eine neue Ger√§tegeneration aufzur√ºsten . <br><br>  Beim Aufbau eines Netzwerks in einem neuen Rechenzentrum haben wir uns an das klassische Modell gehalten.  In jedem Rack sind die Server mit zwei Zugriffsschaltern verbunden, die wiederum mit den zentralen Aggregationsschaltern verbunden sind (sie sind auch der Kern des Netzwerks). <br><br><img src="https://habrastorage.org/webt/wt/hw/mq/wthwmq0qnhd8bajvhxsu8fhzode.png"><br><br><h4>  Lehren </h4><br>  Beim Umzug haben wir beschlossen, das Rechenzentrum vollst√§ndig auszuschalten, um alles auf einmal zu transportieren und an einem neuen Ort einzuschalten.  Dazu musste das Unternehmen lernen, auf eines der beiden Rechenzentren zu verzichten.  Es erforderte die Teilnahme fast aller unserer Administratoren, damit Informationssysteme auf verschiedenen Plattformen, auf verschiedenen Betriebssystemen und mit verschiedenen Datenbanken auf der verbleibenden Site ununterbrochen funktionieren. <br><blockquote>  F√ºr die kritischsten Dienste wurde eine Reserve bereitgestellt, die auch bei ausgeschaltetem Rechenzentrum verf√ºgbar blieb. </blockquote><br>  Nach der Durchf√ºhrung der Reservierungsarbeiten begannen die √úbungen.  Zuerst haben wir einzelne Netzwerke, Segmente und erst dann das Rechenzentrum vollst√§ndig getrennt.  2019 haben wir das Rechenzentrum zehnmal testweise heruntergefahren - wir haben beobachtet, wie sich unsere 300 Informationssysteme verhalten.  Wir haben die Autonomie wiederholt √ºberpr√ºft und waren √ºberzeugt, dass wir die Verbindung leicht trennen k√∂nnen. <br><br>  Und weiter‚Ä¶ <br><br><h2>  Woche X </h2><br>  An einem der Freitage sollte die gesamte Ausr√ºstung im Rechenzentrum abgeschaltet werden. Die neuesten Versionen wurden am Morgen herausgebracht, und dann wurde ein Moratorium f√ºr sie angek√ºndigt. <br><blockquote>  Yandex.Money kann 60 oder mehr Releases pro Tag haben, und alle werden an beide Rechenzentren weitergeleitet. </blockquote><br>  Wir haben die Releases gestoppt, um sicherzustellen, dass das System stabil funktioniert und keine Korrekturen in unseren Komponenten erforderlich sind.  Ab 15:00 Uhr l√∂schten sie allm√§hlich alle Anwendungen, Datenbanken und Server aus.  In der Nacht von Freitag auf Samstag warteten wir auf die Zeit, wir waren √ºberzeugt, dass nichts Schlimmes passierte, was bedeutet, dass wir gehen k√∂nnen.  Am Samstagmorgen begann ein 15-k√∂pfiges Team, die Ger√§te zu demontieren und in das neue Rechenzentrum zu transportieren. <br><br><img src="https://habrastorage.org/webt/aw/hb/oe/awhboefkhxui5klua789j7ec3nm.png"><br><br>  Wir haben den ganzen Samstag gebraucht, um die Ausr√ºstung zu zerlegen und zu transportieren.  Als n√§chstes begann der Prozess der Installation, des Umschaltens und des Anschlusses an die Stromversorgung. <br><br><img src="https://habrastorage.org/webt/ry/uz/h4/ryuzh4vxihy3vqokvj_ex2_-oam.png"><br><br>  Am Samstagabend haben wir den ersten Stapel Server montiert und verbunden.  Die Hauptarbeit begann am Sonntag - am Abend des Wochenendes war fast die gesamte Ausr√ºstung installiert.  Und wir haben die Kommutierung erst am Montagabend beendet. <br><br><img src="https://habrastorage.org/webt/bp/hz/ci/bphzci1xww3exwjgcnddnyhxvku.png"><br><br>  Am Dienstagmorgen haben wir die letzten Tests von Netzwerken und Kommunikationskan√§len durchgef√ºhrt und waren bereit, unsere Systeme zu verbessern.  Sie haben angefangen, die ersten Server zu erh√∂hen, aber etwas ist schief gelaufen ... <br><br>  Von Administratoren erhielten wir Massenbeschwerden, dass das Netzwerk auf den Servern nicht funktionierte: entweder vollst√§ndig oder eine von zwei Schnittstellen.  Sie begannen, nach Problemen auf der Seite von Netzwerkger√§ten, in Betriebssystemen und in den Einstellungen von Betriebssystemen zu suchen. <br><br>  Die Symptome waren √§hnlich - sie begannen zu untersuchen, was der Grund sein k√∂nnte.  Wir haben festgestellt, dass es sich lohnt, die Patchkabel neben den Switch-Ports st√§rker zu verschieben, und einige der funktionierenden Verbindungen erl√∂schen. <br><br><img src="https://habrastorage.org/webt/r-/l8/mx/r-l8mxy3b8vndwvgcxu_572lfny.gif"><br><br>  Als wir dies entdeckten, stellten wir fest, dass ein erheblicher Teil dieser Patchkabel (etwa 40% von 2000 St√ºck) defekt war.  Wir verlegten alle verf√ºgbaren Patchkabel eines anderen vertrauensw√ºrdigen Herstellers in ein neues Rechenzentrum und begannen dringend, die kritischsten Server erneut zu verbinden.  Es dauerte noch einen Tag. <br><br>  Ab Mittwochabend am Donnerstagmorgen begann das Team, den Hauptblock der Informationssysteme zu heben. <br><br>  Nachdem wir wichtige Services erh√∂ht und die Reserve des Zahlungssystems eingerichtet hatten, haben wir einen Teil der Testst√§nde des neuen Rechenzentrums und die Reserve der Backoffice-Systeme einbezogen, sodass alle unsere internen Systeme mit zwei Rechenzentren arbeiten.  Ende der Woche wurde nahezu die gesamte IT-Infrastruktur des transportierten Rechenzentrums in Betrieb genommen. <br><br>  Urspr√ºnglich gab es einen Plan f√ºr 5 Tage, aber mit einer Notfallsituation im Zusammenhang mit defekten Patchkabeln stellte sich heraus, dass es eine Woche war.  Im Folgenden haben wir die Zeitachse unserer Aktionen klar umrissen. <br><br>  <b>Umzugsplan - ausstehend:</b> <br><br><ul><li>  Freitag - wir l√∂schen Netzwerke und Anwendungen; </li><li>  Samstag - wir tragen und beginnen die Montage; </li><li>  Sonntag - Installation von Servern, Start von Netzwerken; </li><li>  Montag - wir beenden das Netzwerk, starten Anwendungen; </li><li>  Dienstag - alles einschalten. </li></ul><br><br>  <b>Realit√§t:</b> <br><br><ul><li>  Freitag - wir l√∂schen Netzwerke und Anwendungen; </li><li>  Samstag - wir tragen und beginnen die Montage; </li><li>  Sonntag - Installation von Servern, Start von Netzwerken; </li><li>  <font color="red">Montag - Verkabelung, Netzwerkstart;</font> </li><li>  Dienstag - Server einschalten, <font color="red">100+ funktioniert nicht;</font> </li><li>  Mittwoch - <font color="red">Hochzeit in Dr√§hten, Ersatz</font> , Einf√ºhrung von App und DB; </li><li>  Donnerstag - beendet den Ersatz f√ºr PS, starten Sie die App. </li></ul><br><br><h2>  Das Leben nach dem Umzug </h2><br>  <b>Was haben wir vom Umzug mitbekommen?</b> <br>  Erstens haben beide Rechenzentren jetzt die Stufe III des Uptime Institute.  Lieferanten von Rechenzentren garantieren uns eine Verf√ºgbarkeit von 99,982%, was 1,6 Stunden Ausfallzeit pro Jahr entspricht.  Wir sind von der Zuverl√§ssigkeit der Kommunikationskan√§le zwischen unseren Standorten √ºberzeugt.  Auch jetzt gibt es keine Einschr√§nkungen beim Ausbau unserer IT-Infrastruktur. <br><br>  Die Idee des Umzugs gab uns eine gro√üartige Gelegenheit, die Netzwerkausr√ºstung in Bezug auf die Bandbreite zu verbessern.  Wir haben auch Stromversorgungen in Racks √ºberarbeitet - installierte ‚ÄûSmart PDUs‚Äú, reservierte Stromserver. <br><br>  Und als wir umgezogen sind, konnten wir die Umschaltung ‚Äûk√§mmen‚Äú, und jetzt sieht es ordentlicher aus. <br><br><img src="https://habrastorage.org/webt/si/er/bg/sierbgikqjvev60m0geubzlxjr0.png"><br><br>  Daher begann das System im Allgemeinen stabiler zu arbeiten, und unsere Kunden erhalten einen besseren Service. <br><br>  <b>Welche Schlussfolgerungen haben Sie f√ºr sich gezogen?</b> <br>  Wenn Sie gro√üe Projekte durchf√ºhren, m√ºssen Sie √ºber die Risiken nachdenken und sich vorstellen, welche Fallstricke auftreten k√∂nnen.  Unser Beispiel mit Ethernet-Kabeln hat gezeigt, dass es nicht ausreicht, einen Testkauf zu t√§tigen und die Kabelprodukte des ausgew√§hlten Herstellers zu testen.  Um die Risiken zu verringern, war es erforderlich, eine Charge von 2000 Kabeln stichprobenartig zu testen. <br><br>  Es ist auch zu bedenken, dass einige Server den Umzug m√∂glicherweise nicht √ºberleben und sich aus verschiedenen Gr√ºnden einfach nicht einschalten lassen.  Auf die eine oder andere Weise wackelt die Stra√üe und ist mechanisch belastet.  Von den 600 transportierten Ger√§ten brachen 6 Bl√∂cke.  Von einer ausreichend gro√üen Anzahl von Servern hat nur 1% gelitten, keine einzige Festplatte ist abgest√ºrzt - wir glauben, dass dies ein hervorragendes Ergebnis ist. <br><br><hr><br>  So zog das Rechenzentrum von Yandex.Money an einen neuen Ort.  Wir hoffen, dass unsere Erfahrung Ihnen hilft, m√∂gliche Fehler zu vermeiden und Sie m√∂glicherweise zu anderen interessanten L√∂sungen f√ºhrt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de481340/">https://habr.com/ru/post/de481340/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de481330/index.html">Der dritte Punkt ist nicht √ºberfl√ºssig: Wie wir die Produktlistenkette durch Hinzuf√ºgen eines weiteren Glieds verk√ºrzt haben</a></li>
<li><a href="../de481332/index.html">Ank√ºndigung des Buches "Maschinelles Lernen ohne zus√§tzliche W√∂rter"</a></li>
<li><a href="../de481334/index.html">Aufgabennummer 2. Bestimmung der Bev√∂lkerungsstruktur</a></li>
<li><a href="../de481336/index.html">Wie Personen von "anonymen" Datens√§tzen erfasst werden</a></li>
<li><a href="../de481338/index.html">Xss-Schwachstellen ausnutzen</a></li>
<li><a href="../de481342/index.html">Freitagsumfrage: √úber Sprachen sprechen</a></li>
<li><a href="../de481344/index.html">Pl√§ne des IntelliJ Platform-Teams f√ºr 2020</a></li>
<li><a href="../de481346/index.html">5 gro√üe Ver√§nderungen in der Automobilindustrie</a></li>
<li><a href="../de481348/index.html">Pentest Active Directory. Teil 1</a></li>
<li><a href="../de481350/index.html">Wer arbeitet am Kosmodrom Plesetsk?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
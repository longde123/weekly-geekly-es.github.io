<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòà üë®‚Äçüéì üñïüèº La grande interview de Martin Kleppmann: ¬´Comprendre l'avenir des syst√®mes de donn√©es distribu√©s¬ª üò≠ üíï üîî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dr. Martin Kleppmann est chercheur en syst√®mes distribu√©s √† l'Universit√© de Cambridge et auteur du tr√®s appr√©ci√© "Designing Data-Intensive Application...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La grande interview de Martin Kleppmann: ¬´Comprendre l'avenir des syst√®mes de donn√©es distribu√©s¬ª</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jugru/blog/458056/"><img src="https://habrastorage.org/webt/ad/ax/dn/adaxdnyqcoiagri2sgsuibdstpy.jpeg"><br><br>  <b>Dr.</b>  <b>Martin Kleppmann</b> est chercheur en syst√®mes distribu√©s √† l'Universit√© de Cambridge et auteur du tr√®s appr√©ci√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"Designing Data-Intensive Applications"</a> (O'Reilly Media, 2017). <br><br>  Kevin Scott, CTO chez Microsoft, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">a d√©clar√© un jour</a> : ¬´Ce livre devrait √™tre une lecture obligatoire pour les ing√©nieurs logiciels.  "La conception d'applications √† forte intensit√© de donn√©es est une ressource rare qui relie la th√©orie et la pratique pour aider les d√©veloppeurs √† prendre des d√©cisions intelligentes lors de la conception et de la mise en ≈ìuvre de l'infrastructure et des syst√®mes de donn√©es." <br><br>  Les principaux int√©r√™ts de recherche de Martin incluent les logiciels de collaboration, les CRDT et la v√©rification formelle des algorithmes distribu√©s.  Auparavant, il √©tait ing√©nieur logiciel et entrepreneur dans plusieurs soci√©t√©s Internet, dont LinkedIn et Rapportive, o√π il a travaill√© sur une infrastructure de donn√©es √† grande √©chelle. <br><br>  <b>Vadim Tsesko</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@incubos</a> ) est un ing√©nieur logiciel principal chez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Odnoklassniki</a> qui travaille dans l'√©quipe Core Platform.  Les int√©r√™ts scientifiques et techniques de Vadim incluent les syst√®mes distribu√©s, les entrep√¥ts de donn√©es et la v√©rification des syst√®mes logiciels. <br><br><h2>  Contenu: </h2><br><ul><li>  Passer de la recherche commerciale √† la recherche universitaire; <br></li><li>  Discussion sur "Conception d'applications √† forte intensit√© de donn√©es"; <br></li><li>  Bon sens contre le battage m√©diatique artificiel et le marketing agressif; <br></li><li>  Pi√®ges du th√©or√®me de la PAC et d'autres erreurs de l'industrie; <br></li><li>  Avantages de la d√©centralisation; <br></li><li>  Blockchains, Dat, IPFS, Filecoin, WebRTC; <br></li><li>  Nouveaux CRDT.  V√©rification formelle avec Isabelle; <br></li><li>  Sourcing d'√©v√©nements.  Approche de bas niveau.  Transactions XA <br></li><li>  Apache Kafka, PostgreSQL, Memcached, Redis, Elasticsearch; <br></li><li>  Comment appliquer tous ces outils √† la vie r√©elle; <br></li><li>  Public cible attendu des pourparlers de Martin et de la conf√©rence Hydra. <br></li></ul><br><a name="habracut"></a><br><hr><br><h2>  Passer de la recherche commerciale √† la recherche universitaire </h2><br>  <b>Vadim</b> : La premi√®re question que je voudrais vous poser est vraiment importante pour moi.  Vous avez fond√© Go Test It et Rapportive, et vous conceviez et d√©veloppiez des syst√®mes √† grande √©chelle chez LinkedIn depuis un certain temps.  Vous avez ensuite d√©cid√© de passer de l'ing√©nierie industrielle au milieu universitaire.  Pourriez-vous expliquer la motivation de cette d√©cision?  Qu'avez-vous gagn√© et qu'avez-vous d√ª sacrifier? <br><br>  <b>Martin</b> : Ce fut un processus tr√®s int√©ressant.  Comme vous semblez le laisser entendre, peu de gens font le changement dans cette direction.  Beaucoup de gens passent du monde universitaire √† l'industrie, mais pas beaucoup en retour.  Ce qui est compr√©hensible, car j'ai d√ª subir une r√©duction de salaire assez importante pour retourner au monde universitaire.  Mais ce que j'aime vraiment dans la recherche, c'est la libert√© de travailler sur des sujets que je trouve int√©ressants et que je pense importants, m√™me si ces sujets ne conduisent pas imm√©diatement √† un produit commercialement viable dans les 6 prochains mois environ.  Bien s√ªr, dans une entreprise, ce que vous construisez doit se transformer en un produit qui peut √™tre vendu sous une forme ou une autre.  D'un autre c√¥t√©, les choses sur lesquelles je travaille actuellement sont des sujets qui sont vraiment importants pour l'avenir de la fa√ßon dont nous cr√©ons des logiciels et comment Internet fonctionne.  Mais nous ne comprenons pas encore assez bien ces sujets pour commencer √† construire des produits commerciaux: nous sommes toujours au niveau d'essayer de comprendre, fondamentalement, √† quoi ces technologies doivent ressembler.  Et comme il s'agit d'une recherche fondamentale, j'ai r√©alis√© qu'il vaut mieux le faire dans une universit√© que d'essayer de le faire dans une entreprise, car dans une universit√©, je suis libre de travailler sur des choses qui pourraient ne pas devenir commercialement viables avant dix ans, et c'est OK.  C'est OK de travailler avec un horizon temporel beaucoup plus long lorsque vous √™tes en recherche. <br><br><hr><br><h2>  ¬´Conception d'applications √† forte intensit√© de donn√©es¬ª </h2><br>  <b>Vadim</b> : Nous reviendrons certainement sur vos int√©r√™ts de recherche actuels.  En attendant, parlons de votre dernier livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Designing Data-Intensive Applications</a> .  Je suis un grand fan de votre livre et je pense que c'est l'un des meilleurs guides pour construire des syst√®mes distribu√©s modernes.  Vous avez couvert presque toutes les r√©alisations notables √† jour. <br><br>  <b>Martin</b> : Merci, je suis content que vous le trouviez utile. <br><br>  <b>Vadim</b> : Juste pour les lecteurs malchanceux qui n'ont pas encore lu votre livre, pourriez-vous citer plusieurs r√©alisations majeures dans le domaine des syst√®mes distribu√©s de nos jours? <br><br>  <b>Martin</b> : Eh bien, le but du livre n'est pas tant d'expliquer une technologie particuli√®re;  l'objectif est plut√¥t de vous donner un guide sur l'ensemble du paysage des diff√©rents syst√®mes utilis√©s pour le stockage et le traitement des donn√©es.  Il y a tellement de bases de donn√©es diff√©rentes, de processeurs de flux, d'outils de traitement par lots, de toutes sortes d'outils de r√©plication et ainsi de suite, et il est vraiment difficile d'avoir un aper√ßu.  Si vous essayez de cr√©er une application particuli√®re, il est vraiment difficile de savoir quelle base de donn√©es vous devez utiliser et quels outils sont les plus appropri√©s pour le probl√®me que vous essayez de r√©soudre.  Beaucoup de livres informatiques existants n'ont tout simplement pas r√©pondu √† ce probl√®me de mani√®re satisfaisante.  J'ai trouv√© que si vous lisez un livre sur Cassandra par exemple, cela vous dirait pourquoi Cassandra est merveilleux, mais il ne vous dirait g√©n√©ralement pas des choses pour lesquelles ce n'est pas un bon choix.  Donc, ce que je voulais vraiment faire dans ce livre √©tait d'identifier les principales questions que vous devez vous poser si vous essayez de construire une sorte de syst√®me √† grande √©chelle.  Et en r√©pondant √† ces questions, vous pouvez ensuite aider √† d√©terminer quelles technologies sont appropri√©es et lesquelles sont moins appropri√©es au probl√®me particulier que vous essayez de r√©soudre - car, en g√©n√©ral, il n'y a pas une technologie qui soit parfaite pour tout.  Et donc, le livre essaie de vous aider √† comprendre les avantages et les inconv√©nients des diff√©rentes technologies dans diff√©rents contextes. <br><br><hr><br><h2>  Bon sens contre le battage m√©diatique artificiel et le marketing agressif </h2><br>  <b>Vadim</b> : En effet, souvent - sinon toujours - il existe de nombreuses technologies avec des fonctions, des fonctionnalit√©s et des mod√®les de donn√©es qui se chevauchent.  Et vous ne pouvez pas croire tous ces mots √† la mode marketing.  Vous devez lire les livres blancs pour apprendre les composants internes et m√™me essayer de lire le code source pour comprendre comment cela fonctionne exactement. <br><br>  <b>Martin</b> : Et j'ai trouv√© que vous devez souvent lire entre les lignes parce que souvent la documentation ne vous dit pas vraiment pour quelles choses une base de donn√©es particuli√®re aspire.  La v√©rit√© est que chaque base de donn√©es aspire √† une sorte de charge de travail, la question est simplement de savoir lesquelles elles sont.  Alors oui, il faut parfois lire les directives de d√©ploiement pour les op√©rateurs et essayer de proc√©der √† une r√©tro-ing√©nierie √† partir de ce qui se passe r√©ellement sur le syst√®me. <br><br>  <b>Vadim</b> : Ne pensez-vous pas que l‚Äôindustrie n‚Äôa pas le vocabulaire commun ou un ensemble de crit√®res pour comparer diff√©rentes solutions pour le m√™me probl√®me?  Des choses similaires sont appel√©es par des noms diff√©rents, certaines choses sont omises et doivent toujours √™tre claires et explicites, comme les garanties de transaction.  Qu'en penses-tu? <br><br>  <b>Martin</b> : Oui, je pense que l'un des probl√®mes de notre industrie est que souvent, lorsque les gens parlent d'un outil particulier, il y a beaucoup de battage m√©diatique autour de tout.  Ce qui est compr√©hensible, car les outils sont fabriqu√©s par diverses entreprises, et √©videmment, ces entreprises veulent promouvoir leurs produits, et donc ces entreprises enverront des gens √† des conf√©rences pour parler de la beaut√© de leur produit, essentiellement.  Il sera d√©guis√© en discours technique, mais il s'agit essentiellement d'une activit√© commerciale.  En tant qu'industrie, nous pourrions vraiment faire avec plus d'honn√™tet√© les avantages et les inconv√©nients de certains produits.  Et une partie de cela n√©cessite une terminologie commune, car sinon vous ne pouvez tout simplement pas comparer les choses sur un pied d'√©galit√©.  Mais au-del√† d'une terminologie partag√©e, nous avons besoin de moyens de raisonner sur des choses que certaines technologies sont bonnes ou mauvaises. <br><br><hr><br><h2>  Pi√®ges du th√©or√®me de la PAC et autres erreurs de l'industrie </h2><br>  <b>Vadim</b> : Ma prochaine question est assez controvers√©e.  Pourriez-vous s'il vous pla√Æt nommer les erreurs majeures dans l'industrie que vous avez rencontr√©es au cours de votre carri√®re?  Peut-√™tre des technologies sur√©valu√©es ou des solutions largement utilis√©es dont nous aurions d√ª nous d√©barrasser il y a longtemps?  Ce pourrait √™tre un mauvais exemple, mais comparez JSON sur HTTP / 1.1 avec le gRPC beaucoup plus efficace sur HTTP / 2.  Ou existe-t-il un autre point de vue? <br><br>  <b>Martin</b> : Je pense que dans de nombreux cas, il y a de tr√®s bonnes raisons pour lesquelles une technologie fait une chose et pas une autre.  J'h√©site donc beaucoup √† appeler les choses des erreurs, car dans la plupart des cas, c'est une question de compromis.  Dans votre exemple de JSON sur HTTP / 1.1 contre les tampons de protocole sur HTTP / 2, je pense qu'il y a en fait des arguments tout √† fait raisonnables pour les deux c√¥t√©s.  Par exemple, si vous souhaitez utiliser des tampons de protocole, vous devez d√©finir votre sch√©ma, et un sch√©ma peut √™tre une chose merveilleuse car il aide √† documenter exactement la communication en cours.  Mais certaines personnes trouvent les sch√©mas ennuyeux, surtout s'ils en sont aux premiers stades de d√©veloppement et qu'ils changent tr√®s fr√©quemment de format de donn√©es.  Donc voil√†, il y a une question de compromis;  dans certaines situations, l'un est meilleur, dans d'autres, l'autre est meilleur. <br><br>  En termes d'erreurs r√©elles qui me paraissent tout simplement mauvaises, il n'y a qu'un assez petit nombre de choses.  Une opinion que j'ai est que le th√©or√®me de la PAC est fondamentalement mauvais et simplement inutile.  Chaque fois que les gens utilisent le th√©or√®me de la PAC pour justifier des d√©cisions de conception, je pense souvent qu'ils interpr√®tent mal ce que la PAC dit r√©ellement ou √©noncent l'√©vidence d'une mani√®re.  Le CAP en tant que th√©or√®me a un probl√®me qu'il √©nonce simplement l'√©vidence.  De plus, il parle d'un seul mod√®le de coh√©rence tr√®s √©troitement d√©fini, √† savoir la lin√©arisation, et d'un mod√®le de disponibilit√© tr√®s √©troitement d√©fini, √† savoir: vous voulez que chaque r√©plique soit enti√®rement disponible pour les lectures et les √©critures, m√™me si elle ne peut pas communiquer avec d'autres r√©pliques.  Ce sont des d√©finitions raisonnables, mais elles sont tr√®s √©troites, et de nombreuses applications ne tombent tout simplement pas dans le cas d'avoir besoin pr√©cis√©ment de cette d√©finition de coh√©rence ou pr√©cis√©ment de cette d√©finition de disponibilit√©.  Et pour toutes les applications qui utilisent une d√©finition diff√©rente de ces mots, le th√©or√®me CAP ne vous dit rien du tout.  C'est simplement une d√©claration vide.  Donc, je pense que c'est une erreur. <br><br>  Et pendant que nous nous d√©cha√Ænons, si vous me demandez de nommer des erreurs, une autre grosse erreur que je vois dans l'industrie technologique est l'extraction de crypto-monnaies, qui je pense est un gaspillage d'√©lectricit√© si flagrant.  Je n'arrive pas √† comprendre pourquoi les gens pensent que c'est une bonne id√©e. <br><br>  <b>Vadim</b> : En parlant du th√©or√®me du CAP, de nombreuses technologies de stockage sont en fait r√©glables, en termes de choses comme AP ou CP.  Vous pouvez choisir le mode dans lequel ils op√®rent. <br><br>  <b>Martin</b> : Oui.  De plus, il existe de nombreuses technologies qui ne sont ni coh√©rentes ni disponibles selon la d√©finition stricte du th√©or√®me de la PAC.  Ils sont litt√©ralement juste P!  Pas CP, pas CA, pas AP, juste P. Personne ne dit cela, car cela aurait l'air mauvais, mais honn√™tement, cela pourrait √™tre une d√©cision de conception parfaitement raisonnable √† prendre.  Il existe de nombreux syst√®mes pour lesquels cela est en fait tout √† fait correct.  C'est en fait l'une des raisons pour lesquelles je pense que CAP est une fa√ßon si inutile de parler des choses: parce qu'il y a une grande partie de l'espace de conception qu'il ne capture tout simplement pas, o√π il existe de bonnes conceptions parfaitement raisonnables pour les logiciels qu'il ne vous permet tout simplement pas d'en parler. <br><hr><br><h2>  Avantages de la d√©centralisation </h2><br>  <b>Vadim</b> : En ce qui concerne les applications gourmandes en donn√©es aujourd'hui, quels autres d√©fis majeurs, probl√®mes non r√©solus ou sujets de recherche chauds pouvez-vous citer?  Pour autant que je sache, vous √™tes un grand partisan du calcul et du stockage d√©centralis√©s. <br><br>  <b>Martin</b> : Oui.  L'une des th√®ses √† l'origine de mes recherches est qu'en ce moment nous comptons trop sur les serveurs et la centralisation.  Si vous pensez √† la fa√ßon dont Internet a √©t√© con√ßu √† l'origine √† l'√©poque o√π il a √©volu√© √† partir d'ARPANET, il √©tait con√ßu comme un r√©seau tr√®s r√©silient o√π les paquets pouvaient √™tre envoy√©s via plusieurs itin√©raires diff√©rents, et ils atteindraient toujours la destination.  Et si une bombe nucl√©aire frappait une ville am√©ricaine particuli√®re, le reste du r√©seau continuerait de fonctionner car il ne ferait que contourner les parties d√©faillantes du syst√®me.  C'√©tait une conception de la guerre froide. <br><br>  Et puis nous avons d√©cid√© de tout mettre dans le cloud, et maintenant, fondamentalement, tout doit passer par l'un des centres de donn√©es d'AWS, comme us-east-1 quelque part en Virginie.  Nous avons supprim√© cet id√©al de pouvoir utiliser de mani√®re d√©centralis√©e diff√©rentes parties du r√©seau, et nous avons install√© ces serveurs sur lesquels tout repose, et maintenant il est extr√™mement centralis√©.  Je suis donc int√©ress√© par la d√©centralisation, dans le sens de d√©placer une partie de la puissance et du contr√¥le des donn√©es loin de ces serveurs et de revenir aux utilisateurs finaux. <br><br>  Une chose que je veux ajouter dans ce contexte est que beaucoup de gens qui parlent de d√©centralisation parlent de choses comme les crypto-monnaies, car ils tentent √©galement une forme de d√©centralisation par laquelle le contr√¥le est √©loign√© d'une autorit√© centrale comme une banque et dans un r√©seau de n≈ìuds coop√©rants.  Mais ce n'est pas vraiment le genre de d√©centralisation qui m'int√©resse: je trouve que ces crypto-monnaies sont en fait toujours extr√™mement centralis√©es, dans le sens o√π si vous voulez faire une transaction Bitcoin, vous devez la faire sur le r√©seau Bitcoin - vous doivent utiliser le r√©seau de Bitcoin, donc tout est centralis√© sur ce r√©seau particulier.  La fa√ßon dont il est construit est d√©centralis√©e dans le sens o√π il n'a pas de n≈ìud de contr√¥le unique, mais le r√©seau dans son ensemble est extr√™mement centralis√© dans la mesure o√π toute transaction que vous devez effectuer doit √™tre effectu√©e via ce r√©seau.  Vous ne pouvez pas le faire d'une autre mani√®re.  Je pense que c'est toujours une forme de centralisation. <br><br>  Dans le cas d'une crypto-monnaie, cette centralisation peut √™tre in√©vitable, car vous devez faire des choses comme √©viter de doubler les d√©penses, et cela est difficile sans un r√©seau qui parvient √† un consensus sur les transactions qui ont eu lieu et celles qui ne l'ont pas √©t√©.  Et c'est exactement ce que fait le r√©seau Bitcoin.  Mais il existe de nombreuses applications qui ne n√©cessitent pas quelque chose comme une blockchain, qui peut en fait faire face √† un mod√®le beaucoup plus flexible de donn√©es circulant dans le syst√®me.  Et c'est le type de syst√®me d√©centralis√© qui m'int√©resse le plus. <br><br>  <b>Vadim</b> : Pouvez-vous nommer des technologies prometteuses ou sous-√©valu√©es dans le domaine des syst√®mes d√©centralis√©s en dehors de la blockchain?  J'utilise IPFS depuis un certain temps. <br><br>  <b>Martin</b> : Pour IPFS, je l'ai √©tudi√© un peu mais je ne l'ai pas utilis√© moi-m√™me.  Nous avons effectu√© quelques travaux avec le projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dat</a> , qui est quelque peu similaire √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IPFS</a> dans le sens o√π il s'agit √©galement d'une technologie de stockage d√©centralis√©.  La diff√©rence est que IPFS a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Filecoin</a> , une crypto-monnaie, qui lui est attach√©e comme moyen de payer pour les ressources de stockage, tandis que Dat n'a pas de blockchain attach√©e - c'est purement un moyen de r√©pliquer des donn√©es sur plusieurs machines de mani√®re P2P. <br><br>  Pour le projet sur lequel je travaille, Dat a √©t√© assez bien adapt√©, car nous voulions cr√©er un logiciel de collaboration dans lequel plusieurs utilisateurs diff√©rents pourraient chacun modifier un document ou une base de donn√©es, et toute modification de ces donn√©es serait envoy√©e √† n'importe qui sinon qui a besoin d'une copie de ces donn√©es.  Nous pouvons utiliser Dat pour effectuer cette r√©plication de mani√®re P2P, et Dat s'occupe de toutes les choses au niveau du r√©seau, telles que la travers√©e NAT et le passage √† travers les pare-feu - c'est un probl√®me assez d√©licat juste pour obtenir les paquets d'un bout √† l'autre .  Et puis nous avons construit une couche en plus de cela, en utilisant des CRDT, ce qui est un moyen de permettre √† plusieurs personnes de modifier un document ou un ensemble de donn√©es et d'√©changer ces modifications de mani√®re efficace.  Je pense que vous pouvez probablement cr√©er ce genre de chose sur IPFS √©galement: vous pouvez probablement ignorer l'aspect Filecoin et simplement utiliser l'aspect de r√©plication P2P, et il fera probablement le travail tout aussi bien. <br><br>  <b>Vadim</b> : Bien s√ªr, bien que l'utilisation d'IPFS puisse entra√Æner une baisse de la r√©activit√©, car le Dat sous-jacent WebRTC connecte directement les n≈ìuds P2P, et IPFS fonctionne comme une table de hachage distribu√©e. <br><br>  <b>Martin</b> : Eh bien, WebRTC est √† un niveau diff√©rent de la pile, car il est principalement destin√© √† connecter deux personnes qui pourraient avoir un appel vid√©o;  en fait, le logiciel que nous utilisons pour cette interview en ce moment pourrait bien utiliser WebRTC.  Et WebRTC vous donne un canal de donn√©es que vous pouvez utiliser pour envoyer des donn√©es binaires arbitraires dessus, mais la construction d'un syst√®me de r√©plication complet en plus de cela est encore un peu de travail.  Et c'est quelque chose que Dat ou IPFS font d√©j√†. <br><br>  Vous avez mentionn√© la r√©activit√© - c'est certainement une chose √† laquelle penser.  Imaginons que vous souhaitiez cr√©er les prochains documents Google de mani√®re d√©centralis√©e.  Avec Google Docs, l'unit√© de modifications que vous apportez est une seule touche.  Chaque lettre que vous tapez sur votre clavier peut √™tre envoy√©e en temps r√©el √† vos collaborateurs, ce qui est excellent du point de vue d'une collaboration rapide en temps r√©el.  Mais cela signifie √©galement qu'au cours de l'√©criture d'un document volumineux, vous pourriez avoir des centaines de milliers de ces modifications √† caract√®re unique qui s'accumulent, et beaucoup de ces technologies ne sont pas tr√®s efficaces actuellement pour compresser ce type de donn√©es d'√©dition.  Vous pouvez conserver toutes les modifications que vous avez d√©j√† apport√©es √† votre document, mais m√™me si vous n'envoyez qu'une centaine d'octets pour chaque frappe que vous effectuez et que vous √©crivez un document l√©g√®rement plus grand avec, disons, 100 000 frappes, vous soudainement maintenant avoir 10 Mo de donn√©es pour un document qui ne repr√©senterait normalement que quelques dizaines de kilo-octets.  Nous avons donc cette √©norme surcharge pour la quantit√© de donn√©es qui doit √™tre envoy√©e, √† moins que nous ne devenions plus intelligents pour compresser et empaqueter les modifications. <br><br>  Plut√¥t que d'envoyer √† quelqu'un la liste compl√®te de tous les caract√®res qui ont √©t√© saisis, nous pourrions simplement envoyer l'√©tat actuel du document, puis nous enverrons les mises √† jour qui se sont produites depuis.  Mais beaucoup de ces syst√®mes peer-to-peer n'ont pas encore un moyen de faire ces instantan√©s d'√©tat d'une mani√®re qui serait suffisamment efficace pour les utiliser pour quelque chose comme Google Docs.  C'est en fait un domaine sur lequel je travaille activement, en essayant de trouver de meilleurs algorithmes pour synchroniser diff√©rents utilisateurs pour quelque chose comme un document texte, o√π nous ne voulons pas conserver chaque touche car cela serait trop cher, et nous voulons pour utiliser plus efficacement la bande passante du r√©seau. <br><br><hr><br><h2>  Nouveaux CRDT.  V√©rification formelle avec isabelle </h2><br>  <b>Vadim</b> : Avez-vous r√©ussi √† compresser consid√©rablement ces donn√©es de frappe?  Avez-vous invent√© de nouveaux CRDT ou quelque chose de similaire? <br><br>  <b>Martin</b> : Oui.  Jusqu'√† pr√©sent, nous n'avons que des prototypes pour cela, il n'est pas encore enti√®rement mis en ≈ìuvre, et nous devons encore faire d'autres exp√©riences pour mesurer son efficacit√© r√©elle dans la pratique.  Mais nous avons d√©velopp√© des sch√©mas de compression qui semblent tr√®s prometteurs.  Dans mon prototype, je l'ai r√©duit d'environ 100 octets par √©dition √† quelque chose comme 1,7 octet de surcharge par √©dition.  Et c'est beaucoup plus raisonnable bien s√ªr.  Mais comme je l'ai dit, ces exp√©riences sont toujours en cours, et le nombre pourrait encore l√©g√®rement changer.  Mais je pense que l'essentiel est qu'il y a encore beaucoup de place pour l'optimisation, donc nous pouvons encore l'am√©liorer beaucoup. <br><br>  <b>Vadim</b> : C'est donc de cela que vous parlerez lors de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conf√©rence Hydra</a> , ai-je raison? <br><br>  <b>Martin</b> : Oui, exactement.  Je donnerai une br√®ve introduction au domaine des CRDT, des logiciels collaboratifs et de certains des probl√®mes qui se posent dans ce contexte.  Je d√©crirai ensuite certaines des recherches que nous avons effectu√©es dans ce domaine.  Cela a √©t√© assez amusant, car les recherches que nous avons men√©es ont port√© sur toute une gamme de pr√©occupations diff√©rentes.  Du c√¥t√© tr√®s appliqu√©, nous avons une impl√©mentation JavaScript de ces algorithmes, et nous l'utilisons pour cr√©er de vrais logiciels, essayant d'utiliser ce logiciel nous-m√™mes pour voir comment il se comporte.  √Ä l'autre extr√©mit√© du spectre, nous avons travaill√© avec des m√©thodes formelles pour prouver la validit√© de ces algorithmes, car certains de ces algorithmes sont assez subtils et nous voulons √™tre tr√®s s√ªrs que les syst√®mes que nous cr√©ons sont r√©ellement corrects, c'est-√†-dire que ils atteignent toujours un √©tat coh√©rent.  Il y a eu beaucoup d'algorithmes dans le pass√© qui n'ont pas r√©ussi √† le faire, qui √©taient tout simplement faux, c'est-√†-dire que, dans certains cas extr√™mes, ils resteraient incoh√©rents de fa√ßon permanente.  Et donc, afin d'√©viter ces probl√®mes que les algorithmes ont eu dans le pass√©, nous avons utilis√© des m√©thodes formelles pour prouver que nos algorithmes sont corrects. <br><br>  <b>Vadim</b> : Wow.  Utilisez-vous vraiment des d√©monstrateurs de th√©or√®mes, comme Coq ou Isabelle ou autre chose? <br><br>  <b>Martin</b> : Exactement, nous utilisons Isabelle pour √ßa. <br><br><blockquote>  Vous pouvez assister √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la conf√©rence de Martin</a> "Preuve d'exactitude des syst√®mes distribu√©s avec Isabelle" √† la conf√©rence The Strange Loop en septembre. </blockquote><br>  <b>Vadim</b> : √áa a l'air g√©nial!  Ces preuves vont-elles √™tre publi√©es? <br><br>  <b>Martin</b> : Oui, notre premier jeu d'√©preuves est d√©j√† public.  Nous l'avons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">publi√© il y a</a> un an et demi: c'√©tait un cadre de v√©rification des CRDT, et nous avons v√©rifi√© trois CRDT particuliers dans ce cadre, dont le principal √©tait RGA ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Replicated Growable Array</a> ), qui est un CRDT pour l'√©dition de texte collaborative.  Bien que ce ne soit pas tr√®s compliqu√©, c'est un algorithme assez subtil, et c'est donc un bon cas o√π une preuve est n√©cessaire, car il n'est pas √©vident simplement en le regardant qu'il est vraiment correct.  Et donc la preuve nous donne la certitude suppl√©mentaire qu'elle est vraiment correcte.  Notre travail pr√©c√©dent portait sur la v√©rification de quelques CRDT existants, et notre travail le plus r√©cent dans ce domaine concerne nos propres CRDT pour les nouveaux mod√®les de donn√©es que nous avons d√©velopp√©s et la v√©rification de nos propres CRDT corrects √©galement. <br><br>  <b>Vadim</b> : Quelle est la taille de la preuve par rapport √† la description de l'algorithme?  Parce que cela peut parfois √™tre un probl√®me. <br><br>  <b>Martin</b> : Oui, c'est un probl√®me - les preuves demandent souvent beaucoup de travail.  Je pense que dans notre dernier exemple ... En fait, laissez-moi jeter un coup d'≈ìil au code.  La description de l'algorithme et des structures de donn√©es est d'environ 60 lignes de code.  C'est donc un petit algorithme.  La preuve est de plus de 800 lignes.  Nous avons donc un rapport d'environ 12: 1 entre la preuve et le code.  Et c'est malheureusement assez typique.  La preuve est un gros travail suppl√©mentaire.  D'un autre c√¥t√©, une fois que nous en avons la preuve, nous avons acquis une tr√®s grande certitude quant √† l'exactitude de l'algorithme.  De plus, nous avons nous-m√™mes, en tant qu'humains, compris bien mieux l'algorithme.  Souvent, je trouve qu'en essayant de le formaliser, nous finissons par comprendre ce que nous essayons de formaliser beaucoup mieux qu'avant.  Et cela en soi est en fait un r√©sultat utile de ce travail: en plus de la preuve elle-m√™me, nous acqu√©rons une compr√©hension plus profonde, et cela est souvent tr√®s utile pour cr√©er de meilleures impl√©mentations. <br><br>  <b>Vadim</b> : Pourriez-vous s'il vous pla√Æt d√©crire le public cible de votre discours, quel sera le niveau de hardcore?  Quelles sont les connaissances pr√©liminaires que vous attendez du public? <br><br>  <b>Martin</b> : J'aime rendre mes discussions accessibles avec le moins de connaissances pr√©alables possible, et j'essaie d'√©lever tout le monde au m√™me niveau.  Je couvre beaucoup de mati√®re, mais je commence sur une base basse.  Je m'attendrais √† ce que les gens aient une exp√©rience g√©n√©rale des syst√®mes distribu√©s: comment envoyer des donn√©es sur un r√©seau en utilisant TCP, ou peut-√™tre une id√©e approximative du fonctionnement de Git, qui est un assez bon mod√®le pour ces choses.  Mais c'est √† peu pr√®s tout ce dont vous avez besoin, vraiment.  Ensuite, comprendre le travail que nous avons accompli en plus de cela n'est en fait pas trop difficile.  J'explique tout par l'exemple, en utilisant des images pour tout illustrer.  Esp√©rons que tout le monde pourra suivre. <br><br><hr><br><h2>  Sourcing d'√©v√©nements.  Approche de bas niveau.  Transactions XA </h2><br>  <b>Vadim</b> : Sonne vraiment super.  En fait, nous avons un peu de temps et je voudrais discuter de l'un de vos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles r√©cents</a> sur le traitement des √©v√©nements en ligne.  Vous √™tes un grand partisan de l'id√©e de sourcing d'√©v√©nements, n'est-ce pas? <br><br>  <b>Martin</b> : Oui, bien s√ªr. <br><br>  <b>Vadim</b> : Aujourd'hui, cette approche prend de l'ampleur, et dans la poursuite de tous les avantages d'un journal des op√©rations ordonn√© mondialement, de nombreux ing√©nieurs tentent de le d√©ployer partout.  Pourriez-vous s'il vous pla√Æt d√©crire certains cas o√π la recherche d'√©v√©nements n'est pas la meilleure option?  Juste pour √©viter son utilisation abusive et sa d√©ception √©ventuelle avec l'approche elle-m√™me. <br><br>  <b>Martin</b> : Il y a deux couches diff√©rentes de la pile dont nous devons d'abord parler.  Le sourcing d'√©v√©nements, tel que propos√© par Greg Young et quelques autres, est con√ßu comme un m√©canisme de mod√©lisation des donn√©es, c'est-√†-dire: si vous avez un sch√©ma de base de donn√©es et que vous commencez √† en perdre le contr√¥le car il y a tellement de tables diff√©rentes et elles '' Tout le monde est modifi√© par diff√©rentes transactions - alors le sourcing d'√©v√©nements est un moyen d'apporter une meilleure clart√© √† ce mod√®le de donn√©es, car les √©v√©nements peuvent exprimer tr√®s directement ce qui se passe au niveau de l'entreprise.  Quelle est l'action entreprise par l'utilisateur?  Et puis, les cons√©quences de cette action peuvent √™tre la mise √† jour de diverses tables et ainsi de suite.Effectivement, ce que vous faites avec le sourcing d'√©v√©nements, c'est que vous s√©parez l'action (l'√©v√©nement) de ses effets, qui se produisent quelque part en aval. <br><br>  Je suis venu dans ce domaine sous un angle l√©g√®rement diff√©rent, ce qui est un point de vue de niveau inf√©rieur d'utiliser des syst√®mes comme Kafka pour construire des syst√®mes hautement √©volutifs.  Cette vue est similaire en ce sens que si vous utilisez quelque chose comme Kafka, vous utilisez des √©v√©nements, mais cela ne signifie pas que vous utilisez n√©cessairement la recherche d'√©v√©nements.  Et inversement, vous n'avez pas besoin d'utiliser Kafka pour faire du sourcing d'√©v√©nements;  vous pouvez faire du sourcing d'√©v√©nements dans une base de donn√©es r√©guli√®re, ou vous pouvez utiliser une base de donn√©es sp√©ciale con√ßue sp√©cifiquement pour le sourcing d'√©v√©nements.  Ces deux id√©es sont donc similaires, mais aucune ne n√©cessite l'autre, elles ont juste un certain chevauchement. <br><br>  L'argument pour vouloir utiliser un syst√®me comme Kafka est principalement l'argument de l'√©volutivit√©: dans ce cas, vous avez simplement tellement de donn√©es qui arrivent que vous ne pouvez pas les traiter de mani√®re r√©aliste sur une base de donn√©es √† n≈ìud unique, vous devez donc les partitionner dans certains mani√®re, et en utilisant un journal des √©v√©nements comme Kafka vous donne un bon moyen de r√©partir ce travail sur plusieurs machines.  Il fournit une bonne m√©thode de mise √† l'√©chelle des syst√®mes.  C'est particuli√®rement utile si vous souhaitez int√©grer plusieurs syst√®mes de stockage diff√©rents.  Donc, si, par exemple, vous souhaitez mettre √† jour non seulement votre base de donn√©es relationnelle, mais aussi, disons, un index de recherche en texte int√©gral comme Elasticsearch, ou un syst√®me de mise en cache comme Memcached ou Redis ou quelque chose comme √ßa, et vous voulez qu'un √©v√©nement ait un effet de mise √† jour sur tous ces diff√©rents syst√®mes, alors quelque chose comme Kafka est tr√®s utile. <br><br>  En ce qui concerne la question que vous avez pos√©e (quelles sont les situations dans lesquelles je n'utiliserais pas cette approche de sourcing d'√©v√©nements ou de journal des √©v√©nements) - je pense qu'il est difficile de le dire avec pr√©cision, mais en r√®gle g√©n√©rale, je dirais: utilisez ce qui est le plus simple .  Autrement dit, tout ce qui est le plus proche du domaine que vous essayez de mettre en ≈ìuvre.  Et donc, si la chose que vous essayez d'impl√©menter est tr√®s bien mapp√©e vers une base de donn√©es relationnelle, dans laquelle vous ins√©rez et mettez √† jour et supprimez simplement certaines lignes, utilisez simplement une base de donn√©es relationnelle et ins√©rez, mettez √† jour et supprimez certaines lignes.  Il n'y a rien de mal √† utiliser des bases de donn√©es relationnelles et √† les utiliser telles quelles.  Ils ont bien fonctionn√© pour nous pendant assez longtemps et ils continuent de le faire.  Mais si vous vous trouvez dans une situation o√π vous avez vraiment du mal √† utiliser ce type de base de donn√©es, par exemple parce que la complexit√© du mod√®le de donn√©es devient incontr√¥lable, alors il est logique de passer √† quelque chose comme un sourcing d'√©v√©nements approche. <br><br>  Et de m√™me, au niveau inf√©rieur (√©volutivit√©), si la taille de vos donn√©es est telle que vous pouvez simplement les placer dans PostgreSQL sur une seule machine - c'est probablement bien, utilisez simplement PostgreSQL sur une seule machine.  Mais si vous √™tes au point o√π il n'y a aucun moyen pour qu'une seule machine puisse g√©rer votre charge, vous devez √©voluer sur un grand syst√®me, alors il devient logique d'examiner des syst√®mes plus distribu√©s comme Kafka.  Je pense que le principe g√©n√©ral ici est: utilisez ce qui est le plus simple pour la t√¢che particuli√®re que vous essayez de r√©soudre. <br><br>  <b>Vadim</b> : C'est vraiment un bon conseil.  √Ä mesure que votre syst√®me √©volue, vous ne pouvez pas pr√©dire avec pr√©cision la direction du d√©veloppement, toutes les requ√™tes, les mod√®les et les flux de donn√©es. <br><br>  <b>Martin</b> : Exactement, et pour ce genre de situations, les bases de donn√©es relationnelles sont incroyables, car elles sont tr√®s flexibles, surtout si vous incluez le support JSON dont elles disposent maintenant.  PostgreSQL a maintenant un assez bon support pour JSON.  Vous pouvez simplement ajouter un nouvel index si vous souhaitez interroger d'une mani√®re diff√©rente.  Vous pouvez simplement modifier le sch√©ma et continuer √† ex√©cuter les donn√©es dans une structure diff√©rente.  Et donc si la taille de l'ensemble de donn√©es n'est pas trop grande et la complexit√© n'est pas trop grande, les bases de donn√©es relationnelles fonctionnent bien et offrent une grande flexibilit√©. <br><br>  <b>Vadim</b> : Parlons un peu plus du sourcing d'√©v√©nements.  Vous avez mentionn√© un exemple int√©ressant avec plusieurs consommateurs consommant des √©v√©nements d'une file d'attente bas√©e sur Kafka ou quelque chose de similaire.  Imaginez que de nouveaux documents soient publi√©s et que plusieurs syst√®mes consomment des √©v√©nements: un syst√®me de recherche bas√© sur Elasticsearch, qui rend les documents consultables, un syst√®me de mise en cache qui les place dans un cache de valeurs-cl√©s bas√© sur Memcached, et un syst√®me de base de donn√©es relationnelle qui met √† jour certains tableaux en cons√©quence.  Un document peut √™tre une offre de vente de voiture ou une annonce immobili√®re.  Tous ces syst√®mes consommateurs fonctionnent simultan√©ment et simultan√©ment. <br><br>  <b>Martin</b> : Votre question est donc de savoir comment g√©rer le fait que si vous avez ces plusieurs consommateurs, certains d'entre eux pourraient avoir √©t√© mis √† jour, mais les autres n'ont pas encore vu de mise √† jour et sont toujours l√©g√®rement en retard? <br><br>  <b>Vadim</b> : Oui, exactement.  Un utilisateur acc√®de √† votre site Web, saisit une requ√™te de recherche, obtient des r√©sultats de recherche et clique sur un lien.  Mais elle obtient le code d'√©tat HTTP 404 car il n'y a pas une telle entit√© dans la base de donn√©es, qui n'a pas encore pu consommer et conserver le document. <br><br>  <b>Martin</b> : Oui, c'est un peu un d√©fi en fait.  Id√©alement, ce que vous voulez, c'est ce que nous appellerions la ¬´coh√©rence causale¬ª entre ces diff√©rents syst√®mes de stockage.  Si un syst√®me contient des donn√©es dont vous d√©pendez, les autres syst√®mes que vous regardez contiendront √©galement ces d√©pendances.  Malheureusement, la mise en place de ce type de coh√©rence causale entre diff√©rentes technologies de stockage est en fait tr√®s difficile, et ce n'est pas vraiment la faute de la recherche d'√©v√©nements, car quelle que soit l'approche ou le syst√®me que vous utilisez pour envoyer les mises √† jour aux diff√©rents syst√®mes, vous peut toujours se retrouver avec des probl√®mes de concurrence. <br><br>  Dans votre exemple d'√©criture de donn√©es sur Memcached et Elasticsearch, m√™me si vous essayez d'effectuer les √©critures sur les deux syst√®mes simultan√©ment, vous pourriez avoir un peu de retard sur le r√©seau, ce qui signifie qu'ils arrivent √† des heures l√©g√®rement diff√©rentes sur ces diff√©rents syst√®mes, et √™tre trait√© avec un timing l√©g√®rement diff√©rent.  Et donc quelqu'un qui lit √† travers ces deux syst√®mes peut voir un √©tat incoh√©rent.  Maintenant, il y a des projets de recherche qui travaillent au moins √† atteindre ce type de coh√©rence causale, mais c'est toujours difficile si vous voulez simplement utiliser quelque chose comme Elasticsearch ou Memcached ou ainsi sur √©tag√®re. <br><br>  Une bonne solution ici serait que vous soyez pr√©sent√©, conceptuellement, avec un instantan√© coh√©rent √† la fois dans l'index de recherche et le cache et la base de donn√©es.  Si vous travaillez uniquement dans une base de donn√©es relationnelle, vous obtenez quelque chose appel√© isolement de l'instantan√©, et le point de l'isolement de l'instantan√© est que si vous lisez √† partir de la base de donn√©es, il semble que vous ayez votre propre copie priv√©e de l'ensemble base de donn√©es.  Tout ce que vous regardez dans la base de donn√©es, toutes les donn√©es que vous interrogez seront l'√©tat √† ce moment-l√†, selon l'instantan√©.  Ainsi, m√™me si les donn√©es ont √©t√© modifi√©es par la suite par une autre transaction, vous verrez en fait les anciennes donn√©es, car ces anciennes donn√©es font partie d'un instantan√© coh√©rent. <br><br>  Et maintenant, dans le cas o√π vous avez Elasticsearch et Memcached, vraiment ce que vous voudriez id√©alement est un instantan√© coh√©rent sur ces deux syst√®mes.  Mais malheureusement, ni Memcached, ni Redis, ni Elasticsearch ne disposent d'un m√©canisme efficace pour r√©aliser ces types d'instantan√©s qui peuvent √™tre coordonn√©s avec diff√©rents syst√®mes de stockage.  Chaque syst√®me de stockage pense juste pour lui-m√™me et vous pr√©sente g√©n√©ralement la derni√®re valeur de chaque cl√©, et il n'a pas cette possibilit√© pour regarder en arri√®re et pr√©senter une version l√©g√®rement plus ancienne des donn√©es, car la version la plus r√©cente des donn√©es n'est pas encore coh√©rente. <br><br>  Je n'ai pas vraiment de bonne r√©ponse √† quoi ressemblerait la solution.  Je crains que la solution ne n√©cessite des modifications de code sur tous les syst√®mes de stockage qui participent √† ce genre de chose.  Il faudra donc modifier Elasticsearch, Redis, Memcached et tout autre syst√®me.  Et ils devraient ajouter une sorte de m√©canisme pour les instantan√©s ponctuels qui est suffisamment bon march√© pour que vous puissiez l'utiliser tout le temps, parce que vous voudrez peut-√™tre l'instantan√© plusieurs fois par seconde - ce n'est pas seulement une fois une instantan√© du jour, c'est tr√®s fin.  Et pour le moment, les syst√®mes sous-jacents ne sont pas l√† pour pouvoir faire ce genre d'instantan√©s sur diff√©rents syst√®mes de stockage.  C'est un sujet de recherche vraiment int√©ressant.  J'esp√®re que quelqu'un y travaillera, mais je n'ai pas encore trouv√© de r√©ponses vraiment convaincantes √† ce probl√®me. <br><br>  <b>Vadim</b> : Oui, nous avons besoin d'une sorte de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">contr√¥le de concurrence multiversion</a> partag√©. <br><br>  <b>Martin</b> : Exactement, comme les syst√®mes de transaction distribu√©s.  Les transactions distribu√©es XA vous y aideront, mais malheureusement, XA, en l'√©tat, n'est pas vraiment bien adapt√© car il ne fonctionne que si vous utilisez un contr√¥le de concurrence bas√© sur le verrouillage.  Cela signifie que si vous lisez certaines donn√©es, vous devez les verrouiller afin que personne ne puisse modifier ces donn√©es pendant que vous disposez de ce verrou.  Et ce type de contr√¥le de concurrence bas√© sur le verrouillage a des performances terribles, donc aucun syst√®me n'utilise r√©ellement cela dans la pratique de nos jours.  Mais si vous ne disposez pas de ce verrouillage, vous n'obtiendrez pas le comportement d'isolation n√©cessaire dans un syst√®me comme les transactions distribu√©es XA.  Alors peut-√™tre que nous avons besoin d'un nouveau protocole pour les transactions distribu√©es qui permet l'isolement de l'instantan√© comme m√©canisme d'isolement sur diff√©rents syst√®mes.  Mais je ne pense pas avoir encore vu quoi que ce soit qui impl√©mente cela. <br><br>  <b>Vadim</b> : Oui, j'esp√®re que quelqu'un y travaille. <br><br>  <b>Martin</b> : Oui, ce serait vraiment important.  Toujours dans le contexte des microservices, par exemple: la fa√ßon dont les gens font la promotion de la cr√©ation de microservices est que chaque microservice a son propre stockage, sa propre base de donn√©es, et vous n'avez pas un service acc√©dant directement √† la base de donn√©es d'un autre service, car cela romprait l'encapsulation du service.  Par cons√©quent, chaque service g√®re uniquement ses propres donn√©es. <br><br>  Par exemple, vous disposez d'un service de gestion des utilisateurs, et il a une base de donn√©es pour les utilisateurs, et tous les autres qui veulent en savoir plus sur les utilisateurs doivent passer par le service utilisateur.  Du point de vue de l'encapsulation, c'est bien: vous cachez des d√©tails du sch√©ma de la base de donn√©es aux autres services par exemple. <br><br> But from the point of view of consistency across different services ‚Äî well, you've got a huge problem now, because of exactly the thing we were discussing: we might have data in two different services that depends upon each other in some way, and you could easily end up with one service being slightly ahead of or slightly behind the other in terms of timing, and then you could end up with someone who reads across different services, getting inconsistent results. And I don't think anybody building microservices currently has an answer to that problem. <br><br> <b>Vadim</b> : It is somewhat similar to workflows in our society and government, which are inherently asynchronous and there are no guarantees of delivery. You can get your passport number, then you can change it, and you need to prove that you changed it, and that you are the same person. <br><br> <b>Martin</b> : Yes, absolutely. As humans we have ways of dealing with this, for example, we might know that oh, sometimes that database is a bit outdated, I'll just check back tomorrow. And then tomorrow it's fine. But if it's software that we're building, we have to program all that kind of handling into the software. The software can't think for itself. <br><br> <b>Vadim</b> : Definitely, at least not yet. I have another question about the advantages of event sourcing. Event sourcing gives you the ability to stop processing events in case of a bug, and resume consuming events having deployed the fix, so that the system is always consistent. It's a really strong and useful property, but it might not be acceptable in some cases like banking where you can imagine a system that continues to accept financial transactions, but the balances are stale due to suspended consumers waiting for a bugfix from developers. What might be a workaround in such cases? <br><br> <b>Martin</b> : I think it's a bit unlikely to stop the consumer, deploying the fix and then restart it, because, as you say, the system has got to continue running, you can't just stop it. I think what is more likely to happen is: if you discover a bug, you let the system continue running, but while it continues running with the buggy code, you produce another version of the code that is fixed, you deploy that fixed version separately and run the two in parallel for a while. In the fixed version of the code you might go back in history and reprocess all of the input events that have happened since the buggy code was deployed, and maybe write the results to a different database. Once you've caught up again you've got two versions of the database, which are both based on the same event inputs, but one of the two processed events with the buggy code and the other processed the events with the correct code. At that point you can do the switchover, and now everyone who reads the data is going to read the correct version instead of the buggy version, and you can shut down the buggy version. That way you never need to stop the system from running, everything keeps working all the time. And you can take the time to fix the bug, and you can recover from the bug because you can reprocess those input events again. <br><br> <b>Vadim</b> : Indeed, it's a really good option if the storage systems are under your control, and we are not talking about side effects applied to external systems. <br><br> <b>Martin</b> : Yes, you're right, once we send the data to external systems it gets more difficult because you might not be able to easily correct it. But this is again something you find in financial accounting, for example. In a company, you might have quarterly accounts. At the end of the quarter, everything gets frozen, and all of the revenue and profit calculations are based on the numbers for that quarter. But then it can happen that actually, some delayed transaction came in, because somebody forgot to file a receipt in time. The transaction comes in after the calculations for the quarter have been finalized, but it still belongs in that earlier quarter. <br><br> What accountants do in this case is that in the next quarter, they produce corrections to the previous quarter's accounts. And typically those corrections will be a small number, and that's no problem because it doesn't change the big picture. But at the same time, everything is still accounted for correctly. At the human level of these accounting systems that has been the case ever since accounting systems were invented, centuries ago. It's always been the case that some late transactions would come in and change the result for some number that you thought was final, but actually, it wasn't because the correction could still come in. And so we just build the system with the mechanism to perform such corrections. I think we can learn from accounting systems and apply similar ideas to many other types of data storage systems, and just accept the fact that sometimes they are mostly correct but not 100% correct and the correction might come in later. <br><br> <b>Vadim</b> : It's a different point of view to building systems. <br><br> <b>Martin</b> : It is a bit of a new way of thinking, yes. It can be disorienting when you come across it at first. But I don't think there's really a way round it, because this impreciseness is inherent in the fact that we do not know the entire state of the world ‚Äî it is fundamental to the way distributed systems work. We can't just hide it, we can't pretend that it doesn't happen, because that imprecision is necessarily exposed in the way we process the data. <br><br><hr><br><h2> Professional growth and development </h2><br> <b>Vadim</b> : Do you think that conferences like <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hydra</a> are anticipated? Most distributed systems are quite different, and it is hard to imagine that many attendees will get to work and will start applying what they have learned in day-to-day activities. <br><br> <b>Martin</b> : It is broad, but I think that a lot of the interesting ideas in distributed systems are conceptual. So the insights are not necessarily like ¬´use this database¬ª or ¬´use this particular technology¬ª. They are more like ways of thinking about systems and about software. And those kinds of ideas can be applied quite widely. My hope is that when attendees go away from this conference, the lessons they take away are not so much what piece of software they should be using or which programming language they should be using ‚Äì really, I don't mind about that ‚Äì but more like how to <i>think</i> about the systems they are building. <br><br> <b>Vadim</b> : Why do you think it's important to give conference talks on such complex topics as your talk, compared to publishing papers, covering all their details and intricacies? Or should anyone do both? <br><br> <b>Martin</b> : I think they serve different purposes. When we write papers, the purpose is to have a very definitive, very precise analysis of a particular problem, and to go really deep in that. On the other hand, the purpose of a talk is more to get people interested in a topic and to start a conversation around it. I love going to conferences partly because of the discussions I then have around the talk, where people come to me and say: ¬´oh, we tried something like this, but we ran into this problem and that problem, what do you think about that?¬ª Then I get to think about other people's problems, and that's really interesting because I get to learn a lot from that. <br><br> So, from my point of view, the selfish reason for going to conferences is really to learn from other people, what their experiences have been, and to help share the experiences that we've made in the hope that other people will find them useful as well. But fundamentally, a conference talk is often an introduction to a subject, whereas a paper is a deep analysis of a very narrow question. I think those are different genres and I think we need both of them. <br><br> <b>Vadim</b> : And the last question. How do you personally grow as a professional engineer and a researcher? Could you please recommend any conferences, blogs, books, communities for those who wish to develop themselves in the field of distributed systems? <br><br> <b>Martin</b> : That's a good question. Certainly, there are things to listen to and to read. There's no shortage of conference talks that have been recorded and put online. There are books like my own book for example, which provides a bit of an introduction to the topic, but also lots of references to further reading. So if there are any particular detailed questions that you're interested in, you can follow those references and find the original papers where these ideas were discussed. They can be a very valuable way of learning about something in greater depth. <br><br> A really important part is also trying to implement things and seeing how they work out in practice, and talking to other people and sharing your experiences. Part of the value of a conference is that you get to talk to other people as well, live. But you can have that through other mechanisms as well; for example, there's a Slack channel that people have set up for people <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">interested in distributed systems</a> . If that's your thing you can join that. You can, of course, talk to your colleagues in your company and try to learn from them. I don't think there's one right way of doing this ‚Äî there are many different ways through which you can learn and get a deeper experience, and different paths will work for different people. <br><br> <b>Vadim</b> : Thank you very much for your advice and interesting discussion! It has been a pleasure talking to you. <br><br> <b>Martin</b> : No problem, yeah, it's been nice talking to you. <br><br> <b>Vadim</b> : Let's meet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">at the conference</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr458056/">https://habr.com/ru/post/fr458056/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr458044/index.html">S√©curit√© de l'information provinciale - stagnation ou d√©veloppement?</a></li>
<li><a href="../fr458046/index.html">Gradle Cheat Sheet</a></li>
<li><a href="../fr458048/index.html">La d√©l√©gation comme outil de gestion</a></li>
<li><a href="../fr458050/index.html">Comment √©tait le Mobius 2019 Piter (et un peu plus sur le prochain Mobius)</a></li>
<li><a href="../fr458052/index.html">AMA avec Habr.10. Dernier * num√©ro</a></li>
<li><a href="../fr458060/index.html">Cr√©ation d'un shader d'herbe dans le moteur Unity</a></li>
<li><a href="../fr458062/index.html">Pr√©sentation de la plateforme UserGate</a></li>
<li><a href="../fr458064/index.html">PVS-Studio dans les nuages ‚Äã‚Äã- Ex√©cution de l'analyse sur Travis CI</a></li>
<li><a href="../fr458068/index.html">PVS-Studio pour Visual Studio</a></li>
<li><a href="../fr458070/index.html">PVS-Studio pour Visual Studio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
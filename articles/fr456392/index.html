<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßóüèº üë¶üèº üçü Parsim 25 To avec AWK et R ü§∞üèΩ üì¢ üë©üèº‚Äçüíª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Comment lire cet article : Je m'excuse du fait que le texte s'est av√©r√© si long et chaotique. Pour vous faire gagner du temps, je commence chaque chap...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Parsim 25 To avec AWK et R</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/456392/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/9d/3y/lc/9d3ylcjuqiv6r7vrv6p52apvmne.jpeg"></div><br>  <i><b>Comment lire cet article</b> : Je m'excuse du fait que le texte s'est av√©r√© si long et chaotique.</i>  <i>Pour vous faire gagner du temps, je commence chaque chapitre par l'introduction de ¬´Ce que j'ai appris¬ª, dans lequel j'explique l'essence du chapitre en une ou deux phrases.</i> <i><br><br></i>  <i><b>"Montrez simplement la solution!"</b></i>  <i>Si vous voulez simplement voir o√π je suis arriv√©, alors allez au chapitre "Devenez plus inventif", mais je pense que c'est plus int√©ressant et utile de lire sur les √©checs.</i> <br><br>  R√©cemment, j'ai √©t√© charg√© de mettre en place un processus de traitement d'un grand volume des s√©quences d'ADN d'origine (techniquement, il s'agit d'une puce SNP).  Il √©tait n√©cessaire d'obtenir rapidement des donn√©es sur un emplacement g√©n√©tique donn√© (appel√© SNP) pour la mod√©lisation ult√©rieure et d'autres t√¢ches.  Avec l'aide de R et AWK, j'ai pu nettoyer et organiser les donn√©es de mani√®re naturelle, acc√©l√©rant consid√©rablement le traitement des demandes.  Cela n'a pas √©t√© facile pour moi et a n√©cessit√© de nombreuses it√©rations.  Cet article vous aidera √† √©viter certaines de mes erreurs et √† montrer ce que j'ai fait au final. <br><a name="habracut"></a><br>  Tout d'abord, quelques explications introductives. <br><br><h2>  Les donn√©es </h2><br>  Notre centre de traitement des informations g√©n√©tiques de l'universit√© nous a fourni 25 To de donn√©es TSV.  Je les ai divis√©s en 5 paquets compress√©s par Gzip, chacun contenant environ 240 fichiers de quatre gigaoctets.  Chaque ligne contenait des donn√©es pour un SNP d'une personne.  Au total, des donn√©es sur environ 2,5 millions de SNP et environ 60 000 personnes ont √©t√© transmises.  En plus des informations SNP, il y avait de nombreuses colonnes dans les fichiers avec des nombres refl√©tant diverses caract√©ristiques, telles que l'intensit√© de lecture, la fr√©quence des diff√©rents all√®les, etc.  Il y avait environ 30 colonnes avec des valeurs uniques. <br><br><h4>  But </h4><br>  Comme pour tout projet de gestion des donn√©es, le plus important √©tait de d√©terminer comment les donn√©es seraient utilis√©es.  Dans ce cas, <b>pour la plupart, nous s√©lectionnerons des mod√®les et des workflows pour SNP bas√©s sur SNP</b> .  Autrement dit, nous aurons besoin en m√™me temps de donn√©es pour un seul SNP.  J'ai d√ª apprendre √† extraire tous les enregistrements li√©s √† l'un des 2,5 millions de SNP aussi simplement que possible, plus rapidement et moins cher. <br><br><h1>  Comment ne pas le faire </h1><br>  Je citerai un clich√© appropri√©: <br><br><blockquote>  Je n'ai pas √©chou√© mille fois, je viens de d√©couvrir mille fa√ßons de ne pas analyser un tas de donn√©es dans un format pratique pour les requ√™tes. </blockquote><br>
<h2>  Premi√®re tentative </h2><br>  <b>Ce que j'ai appris</b> : il n'y a pas de moyen bon march√© d'analyser 25 To √† la fois. <br><br>  Apr√®s avoir √©cout√© le sujet ¬´Advanced Big Data Processing Methods¬ª √† l'Universit√© Vanderbilt, j'√©tais s√ªr que c'√©tait un chapeau.  Il faudra peut-√™tre une heure ou deux pour configurer le serveur Hive pour qu'il ex√©cute toutes les donn√©es et rende compte du r√©sultat.  √âtant donn√© que nos donn√©es sont stock√©es dans AWS S3, j'ai utilis√© le service <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Athena</a> , qui vous permet d'appliquer des requ√™tes Hive SQL aux donn√©es S3.  Pas besoin de configurer / augmenter le cluster Hive, et m√™me de payer uniquement pour les donn√©es que vous recherchez. <br><br>  Apr√®s avoir montr√© √† Athena mes donn√©es et leur format, j'ai effectu√© quelques tests avec des requ√™tes similaires: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> intensityData <span class="hljs-keyword"><span class="hljs-keyword">limit</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>;</code> </pre> <br>  Et a rapidement obtenu des r√©sultats bien structur√©s.  C'est fait. <br><br>  Jusqu'√† ce que nous essayions d'utiliser les donn√©es dans le travail ... <br><br>  On m'a demand√© de retirer toutes les informations SNP afin de tester le mod√®le dessus.  J'ai lanc√© une requ√™te: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> intensityData <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> snp = <span class="hljs-string"><span class="hljs-string">'rs123456'</span></span>;</code> </pre> <br>  ... et attendu.  Apr√®s huit minutes et plus de 4 To des donn√©es demand√©es, j'ai obtenu le r√©sultat.  Athena facture des frais pour la quantit√© de donn√©es trouv√©es, √† 5 $ par t√©raoctet.  Cette seule demande a donc co√ªt√© 20 $ et huit minutes d'attente.  Pour ex√©cuter le mod√®le selon toutes les donn√©es, il a fallu attendre 38 ans et payer 50 millions de dollars, ce qui ne nous convenait √©videmment pas. <br><br><h2>  Il fallait utiliser Parquet ... </h2><br>  <b>Ce que j'ai appris</b> : soyez prudent avec la taille de vos dossiers de parquet et leur organisation. <br><br>  Au d√©but, j'ai essay√© de corriger la situation en convertissant tous les TSV en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fichiers Parquet</a> .  Ils sont pratiques pour travailler avec de grands ensembles de donn√©es, car les informations qu'ils contiennent sont stock√©es sous forme de colonnes: chaque colonne se trouve dans son propre segment m√©moire / disque, contrairement aux fichiers texte dans lesquels les lignes contiennent des √©l√©ments de chaque colonne.  Et si vous avez besoin de trouver quelque chose, alors lisez simplement la colonne n√©cessaire.  De plus, une plage de valeurs est stock√©e dans chaque fichier d'une colonne, donc si la valeur souhait√©e ne se trouve pas dans la plage de colonnes, Spark ne perdra pas de temps √† analyser le fichier entier. <br><br>  J'ai ex√©cut√© une t√¢che <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AWS Glue</a> simple pour convertir nos TSV en Parquet et j'ai d√©pos√© de nouveaux fichiers dans Athena.  Cela a pris environ 5 heures.  Mais lorsque j'ai lanc√© la demande, il a fallu environ le m√™me temps et un peu moins d'argent pour la compl√©ter.  Le fait est que Spark, essayant d'optimiser la t√¢che, a simplement d√©ball√© un bloc TSV et l'a plac√© dans son propre bloc Parquet.  Et comme chaque bloc √©tait suffisamment grand et contenait les enregistrements complets de nombreuses personnes, tous les SNP √©taient stock√©s dans chaque fichier, donc Spark a d√ª ouvrir tous les fichiers pour extraire les informations n√©cessaires. <br><br>  Curieusement, le type de compression par d√©faut (et recommand√©) dans Parquet - snappy - n'est pas s√©parable.  Par cons√©quent, chaque ex√©cuteur s'est attach√© √† la t√¢che de d√©compresser et de t√©l√©charger l'ensemble de donn√©es complet de 3,5 Go. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f42/584/fb3/f42584fb3e65319eef46f117c11525f3.png"><br><h2>  Nous comprenons le probl√®me </h2><br>  <b>Ce que j'ai appris</b> : le tri est difficile, surtout si les donn√©es sont distribu√©es. <br><br>  Il me semblait que maintenant je comprenais l'essence du probl√®me.  Tout ce que j'avais √† faire √©tait de trier les donn√©es par colonne SNP, pas par personnes.  Ensuite, plusieurs SNP seront stock√©s dans un bloc de donn√©es s√©par√©, puis la fonction intelligente Parquet "ouverte uniquement si la valeur est dans la plage" appara√Ætra dans toute sa splendeur.  Malheureusement, trier des milliards de lignes dispers√©es sur un cluster s'est av√©r√© √™tre une t√¢che ardue. <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-0" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1105127759318319105"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  AWS ne veut certainement pas rendre l'argent √† cause de "Je suis un √©tudiant distrait."  Apr√®s avoir commenc√© √† trier sur Amazon Glue, cela a fonctionn√© pendant 2 jours et s'est √©cras√©. <br><br><h2>  Et le partitionnement? </h2><br>  <b>Ce que j'ai appris</b> : les partitions dans Spark doivent √™tre √©quilibr√©es. <br><br>  Puis l'id√©e m'est venue de partitionner les donn√©es sur les chromosomes.  Il y en a 23 (et quelques autres, √©tant donn√© l'ADN mitochondrial et les zones non cartographi√©es). <br>  Cela vous permettra de diviser les donn√©es en portions plus petites.  Si vous ajoutez une seule ligne <code>partition_by = "chr"</code> √† la fonction d'exportation Spark dans le script Glue, les donn√©es doivent √™tre tri√©es dans des compartiments. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/652/f42/3dc/652f423dc8806401b6638a3cf8c1480b.png"><br>  <i>Le g√©nome se compose de nombreux fragments appel√©s chromosomes.</i> <br><br>  Malheureusement, cela n'a pas fonctionn√©.  Les chromosomes ont des tailles diff√©rentes, et donc une quantit√© d'informations diff√©rente.  Cela signifie que les t√¢ches envoy√©es par Spark aux travailleurs n'√©taient pas √©quilibr√©es et ex√©cut√©es lentement, car certains n≈ìuds se terminaient plus t√¥t et √©taient inactifs.  Cependant, les t√¢ches ont √©t√© achev√©es.  Mais lors de la demande d'un SNP, le d√©s√©quilibre a de nouveau caus√© des probl√®mes.  Le co√ªt du traitement des SNP sur des chromosomes plus gros (c'est-√†-dire d'o√π nous voulons obtenir les donn√©es) n'a diminu√© que d'environ 10 fois.  Beaucoup, mais pas assez. <br><br><h2>  Et si vous vous divisez en partitions encore plus petites? </h2><br>  <b>Ce que j'ai appris</b> : n'essayez jamais de faire 2,5 millions de partitions. <br><br>  J'ai d√©cid√© de me promener et de partitionner chaque SNP.  Cela garantissait la m√™me taille de partitions.  <b>MAUVAIS √âTAIT UNE ID√âE</b> .  J'ai profit√© de Glue et ajout√© la ligne innocente <code>partition_by = 'snp'</code> .  La t√¢che a commenc√© et a commenc√© √† s'ex√©cuter.  Un jour plus tard, j'ai v√©rifi√© et vu que rien n'√©tait √©crit en S3 jusqu'√† pr√©sent, alors j'ai tu√© la t√¢che.  Il semble que Glue √©crivait des fichiers interm√©diaires dans un endroit cach√© dans S3, et beaucoup de fichiers, peut-√™tre quelques millions.  En cons√©quence, mon erreur a co√ªt√© plus de mille dollars et n'a pas plu √† mon mentor. <br><br><h2>  Partitionnement + tri </h2><br>  <b>Ce que j'ai appris</b> : le tri est toujours difficile, tout comme la configuration de Spark. <br><br>  La derni√®re tentative de partitionnement a consist√© √† partitionner les chromosomes puis √† trier chaque partition.  En th√©orie, cela acc√©l√©rerait chaque demande, car les donn√©es SNP souhait√©es devraient se trouver dans plusieurs morceaux de parquet dans une plage donn√©e.  H√©las, le tri des donn√©es m√™me partitionn√©es s'est av√©r√© √™tre une t√¢che difficile.  En cons√©quence, je suis pass√© √† EMR pour un cluster personnalis√© et j'ai utilis√© huit instances puissantes (C5.4xl) et Sparklyr pour cr√©er un flux de travail plus flexible ... <br><br><pre> <code class="scala hljs"># <span class="hljs-type"><span class="hljs-type">Sparklyr</span></span> snippet to partition by chr and sort w/in partition # <span class="hljs-type"><span class="hljs-type">Join</span></span> the raw data <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> the snp bins raw_data group_by(chr) %&gt;% arrange(<span class="hljs-type"><span class="hljs-type">Position</span></span>) %&gt;% <span class="hljs-type"><span class="hljs-type">Spark_write_Parquet</span></span>( path = <span class="hljs-type"><span class="hljs-type">DUMP_LOC</span></span>, mode = <span class="hljs-symbol"><span class="hljs-symbol">'overwrit</span></span>e', partition_by = c(<span class="hljs-symbol"><span class="hljs-symbol">'ch</span></span>r') )</code> </pre> <br>  ... cependant, la t√¢che n'√©tait toujours pas termin√©e.  J'ai r√©gl√© chaque chose: j'ai augment√© l'allocation de m√©moire pour chaque ex√©cuteur de requ√™te, utilis√© des n≈ìuds avec une grande quantit√© de m√©moire, utilis√© des variables de diffusion, mais √† chaque fois cela s'est av√©r√© √™tre des demi-mesures, et progressivement les artistes ont commenc√© √† √©chouer, jusqu'√† ce que tout s'arr√™te. <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-1" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1128703858610450434"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br><h1>  Je deviens plus inventif </h1><br>  <b>Ce que j'ai appris</b> : parfois, les donn√©es sp√©ciales n√©cessitent des solutions sp√©ciales. <br><br>  Chaque SNP a une valeur de position.  Il s'agit du nombre correspondant au nombre de bases situ√©es le long de son chromosome.  Il s'agit d'un moyen bon et naturel d'organiser nos donn√©es.  Au d√©but, je voulais partitionner par r√©gion de chaque chromosome.  Par exemple, positions 1 - 2000, 2001 - 4000, etc.  Mais le probl√®me est que les SNP ne sont pas distribu√©s √©galement entre les chromosomes, c'est pourquoi la taille des groupes variera consid√©rablement. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f46/a8e/17b/f46a8e17b9af8d2ae9777c47017764c6.png"><br><br>  En cons√©quence, je suis venu √† √™tre divis√© en cat√©gories (grade) postes.  Selon les donn√©es d√©j√† t√©l√©charg√©es, j'ai lanc√© une demande de liste de SNP uniques, de leurs positions et de leurs chromosomes.  Il a ensuite tri√© les donn√©es √† l'int√©rieur de chaque chromosome et collect√© le SNP en groupes (bac) d'une taille donn√©e.  Dites 1000 SNP chacun.  Cela m'a donn√© une relation SNP avec un groupe en chromosome. <br><br>  Au final, j'ai fait des groupes (bin) sur 75 SNP, j'expliquerai la raison ci-dessous. <br><br><pre> <code class="bash hljs">snp_to_bin &lt;- unique_snps %&gt;% group_by(chr) %&gt;% arrange(position) %&gt;% mutate( rank = 1:n() bin = floor(rank/snps_per_bin) ) %&gt;% ungroup()</code> </pre> <br><h2>  Essayez d'abord avec Spark </h2><br>  <b>Ce que j'ai appris</b> : l'int√©gration de Spark est rapide, mais le partitionnement reste cher. <br><br>  Je voulais lire ce petit bloc de donn√©es (2,5 millions de lignes) dans Spark, le combiner avec des donn√©es brutes, puis partitionner par la colonne <code>bin</code> nouvellement ajout√©e. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># Join the raw data with the snp bins data_w_bin &lt;- raw_data %&gt;% left_join(sdf_broadcast(snp_to_bin), by ='snp_name') %&gt;% group_by(chr_bin) %&gt;% arrange(Position) %&gt;% Spark_write_Parquet( path = DUMP_LOC, mode = 'overwrite', partition_by = c('chr_bin') )</span></span></code> </pre> <br>  J'ai utilis√© <code>sdf_broadcast()</code> , donc Spark d√©couvre qu'il devrait envoyer une trame de donn√©es √† tous les n≈ìuds.  Ceci est utile si les donn√©es sont petites et requises pour toutes les t√¢ches.  Sinon, Spark essaie d'√™tre intelligent et distribue les donn√©es selon les besoins, ce qui peut provoquer des freins. <br><br>  Et encore une fois, mon id√©e n'a pas fonctionn√©: les t√¢ches ont fonctionn√© pendant un certain temps, ont termin√© la fusion, puis, comme les ex√©cuteurs ex√©cut√©s par partitionnement, elles ont commenc√© √† √©chouer. <br><br><h2>  Ajouter AWK </h2><br>  <b>Ce que j'ai appris</b> : ne dormez pas lorsque les bases vous apprennent.  Certes, quelqu'un a d√©j√† r√©solu votre probl√®me dans les ann√©es 1980. <br><br>  Jusqu'√† pr√©sent, la cause de tous mes √©checs avec Spark √©tait la confusion des donn√©es dans le cluster.  Peut-√™tre que la situation peut √™tre am√©lior√©e par le pr√©traitement.  J'ai d√©cid√© d'essayer de diviser les donn√©es brutes du texte en colonnes chromosomiques, alors j'esp√©rais fournir √† Spark des donn√©es ¬´pr√©-partitionn√©es¬ª. <br><br>  J'ai cherch√© sur StackOverflow pour savoir comment d√©composer les valeurs des colonnes et j'ai trouv√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une excellente r√©ponse.</a>  √Ä l'aide d'AWK, vous pouvez diviser un fichier texte en valeurs de colonne en √©crivant dans le script, plut√¥t qu'en envoyant les r√©sultats √† <code>stdout</code> . <br><br>  Pour les tests, j'ai √©crit un script Bash.  J'ai t√©l√©charg√© l'un des TSV emball√©s, puis l'ai d√©ball√© avec <code>gzip</code> et l'ai envoy√© √† <code>awk</code> . <br><br><pre> <code class="bash hljs">gzip -dc path/to/chunk/file.gz | awk -F <span class="hljs-string"><span class="hljs-string">'\t'</span></span> \ <span class="hljs-string"><span class="hljs-string">'{print $1",..."$30"&gt;"chunked/"$chr"_chr"$15".csv"}'</span></span></code> </pre> <br>  √áa a march√©! <br><br><h2>  Remplissage de noyau </h2><br>  <b>Ce que j'ai appris</b> : le <code>gnu parallel</code> est une chose magique, tout le monde devrait l'utiliser. <br><br>  La s√©paration a √©t√© plut√¥t lente, et quand j'ai commenc√© <code>htop</code> pour tester l'utilisation d'une instance EC2 puissante (et co√ªteuse), il s'est av√©r√© que j'utilisais un seul c≈ìur et environ 200 Mo de m√©moire.  Afin de r√©soudre le probl√®me et de ne pas perdre beaucoup d'argent, il a fallu trouver comment parall√©liser le travail.  Heureusement, dans l'√©tonnant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data Science de</a> Jeron Janssens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le</a> livre de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ligne de commande</a> , j'ai trouv√© un chapitre sur la parall√©lisation.  De l√†, j'ai appris sur <code>gnu parallel</code> , une m√©thode tr√®s flexible pour impl√©menter le multithreading sur Unix. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/835/7c0/e45/8357c0e45f4162d53ca1c3da0c78444a.png" width="300"></div><br>  Quand j'ai commenc√© la partition en utilisant un nouveau processus, tout allait bien, mais il y avait un goulot d'√©tranglement - le t√©l√©chargement d'objets S3 sur le disque n'√©tait pas trop rapide et pas compl√®tement parall√©lis√©.  Pour r√©soudre ce probl√®me, j'ai fait ceci: <br><br><ol><li>  J'ai d√©couvert qu'il est possible d'impl√©menter l'√©tape de t√©l√©chargement S3 directement dans le pipeline, √©liminant compl√®tement le stockage interm√©diaire sur disque.  Cela signifie que je peux √©viter d'√©crire des donn√©es brutes sur le disque et utiliser un stockage encore plus petit et donc moins cher sur AWS. <br></li><li>  La commande <code>aws configure set default.s3.max_concurrent_requests 50</code> consid√©rablement augment√© le nombre de threads que l'AWS CLI utilise (il y en a 10 par d√©faut). <br></li><li>  Je suis pass√© √† l'instance EC2 optimis√©e pour la vitesse du r√©seau, avec la lettre n dans le nom.  J'ai constat√© que la perte de puissance de calcul lors de l'utilisation de n instances est plus que compens√©e par une augmentation de la vitesse de t√©l√©chargement.  Pour la plupart des t√¢ches, j'ai utilis√© c5n.4xl. <br></li><li>  J'ai chang√© <code>gzip</code> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>pigz</code></a> , c'est un outil gzip qui peut faire des choses sympas pour parall√©liser la t√¢che initialement in√©gal√©e de d√©compresser des fichiers (cela a le moins aid√©). <br></li></ol><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Let S3 use as many threads as it wants aws configure set default.s3.max_concurrent_requests 50 for chunk_file in $(aws s3 ls $DATA_LOC | awk '{print $4}' | grep 'chr'$DESIRED_CHR'.csv') ; do aws s3 cp s3://$batch_loc$chunk_file - | pigz -dc | parallel --block 100M --pipe \ "awk -F '\t' '{print \$1\",...\"$30\"&gt;\"chunked/{#}_chr\"\$15\".csv\"}'" # Combine all the parallel process chunks to single files ls chunked/ | cut -d '_' -f 2 | sort -u | parallel 'cat chunked/*_{} | sort -k5 -n -S 80% -t, | aws s3 cp - '$s3_dest'/batch_'$batch_num'_{}' # Clean up intermediate data rm chunked/* done</span></span></code> </pre> <br>  Ces √©tapes sont combin√©es entre elles pour que tout fonctionne tr√®s rapidement.  Gr√¢ce √† la vitesse de t√©l√©chargement accrue et au refus d'√©crire sur le disque, je pouvais d√©sormais traiter un paquet de 5 t√©raoctets en quelques heures seulement. <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-2" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1129416944233226240"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  Ce tweet √©tait cens√© mentionner ¬´TSV¬ª.  H√©las. <br><br><h2>  Utilisation de donn√©es analys√©es √† nouveau </h2><br>  <b>Ce que j'ai appris</b> : Spark aime les donn√©es non compress√©es et n'aime pas combiner les partitions. <br><br>  Maintenant, les donn√©es √©taient en S3 dans un format d√©compress√© (lu, partag√©) et semi-ordonn√©, et je pouvais revenir √† Spark √† nouveau.  Une surprise m'attendait: je n'ai de nouveau pas r√©ussi √† atteindre le r√©sultat souhait√©!  Il √©tait tr√®s difficile de dire √† Spark exactement comment les donn√©es √©taient partitionn√©es.  Et m√™me quand je l'ai fait, il s'est av√©r√© qu'il y avait trop de partitions (95 000), et quand j'ai r√©duit leur nombre √† des limites coh√©rentes avec <code>coalesce</code> , cela a ruin√© mon partitionnement.  Je suis s√ªr que cela peut √™tre corrig√©, mais en quelques jours de recherche, je n'ai pas pu trouver de solution.  Au final, j'ai termin√© toutes les t√¢ches dans Spark, m√™me si cela a pris du temps, et mes fichiers de parquet fractionn√©s n'√©taient pas tr√®s petits (~ 200 Ko).  Cependant, les donn√©es √©taient l√† o√π elles √©taient n√©cessaires. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae5/43b/236/ae543b236b8d37d4a6794aa63d9ada94.png"><br>  <i>Trop petit et diff√©rent, merveilleux!</i> <br><br><h2>  Test des demandes Spark locales </h2><br>  <b>Ce que j'ai appris</b> : Spark a trop de temps pour r√©soudre des probl√®mes simples. <br><br>  En t√©l√©chargeant les donn√©es dans un format intelligent, j'ai pu tester la vitesse.  J'ai configur√© un script sur R pour d√©marrer le serveur Spark local, puis j'ai charg√© la trame de donn√©es Spark √† partir du r√©f√©rentiel sp√©cifi√© des groupes de parquet (bin).  J'ai essay√© de charger toutes les donn√©es, mais je n'ai pas pu faire en sorte que Sparklyr reconnaisse le partitionnement. <br><br><pre> <code class="scala hljs">sc &lt;- <span class="hljs-type"><span class="hljs-type">Spark_connect</span></span>(master = <span class="hljs-string"><span class="hljs-string">"local"</span></span>) desired_snp &lt;- <span class="hljs-symbol"><span class="hljs-symbol">'rs3477173</span></span>9' # <span class="hljs-type"><span class="hljs-type">Start</span></span> a timer start_time &lt;- <span class="hljs-type"><span class="hljs-type">Sys</span></span>.time() # <span class="hljs-type"><span class="hljs-type">Load</span></span> the desired bin into <span class="hljs-type"><span class="hljs-type">Spark</span></span> intensity_data &lt;- sc %&gt;% <span class="hljs-type"><span class="hljs-type">Spark_read_Parquet</span></span>( name = <span class="hljs-symbol"><span class="hljs-symbol">'intensity_dat</span></span>a', path = get_snp_location(desired_snp), memory = <span class="hljs-type"><span class="hljs-type">FALSE</span></span> ) # <span class="hljs-type"><span class="hljs-type">Subset</span></span> bin to snp and then collect to local test_subset &lt;- intensity_data %&gt;% filter(<span class="hljs-type"><span class="hljs-type">SNP_Name</span></span> == desired_snp) %&gt;% collect() print(<span class="hljs-type"><span class="hljs-type">Sys</span></span>.time() - start_time)</code> </pre> <br>  L'ex√©cution a dur√© 29,415 secondes.  Beaucoup mieux, mais pas trop bon pour tester quoi que ce soit en masse.  De plus, je n'ai pas pu acc√©l√©rer le travail avec la mise en cache, car lorsque j'essayais de mettre en cache la trame de donn√©es en m√©moire, Spark se bloquait toujours, m√™me lorsque j'allouais plus de 50 Go de m√©moire pour un ensemble de donn√©es pesant moins de 15. <br><br><h2>  Retour √† AWK </h2><br>  <b>Ce que j'ai appris</b> : les tableaux associatifs AWK sont tr√®s efficaces. <br><br>  J'ai compris que je pouvais atteindre une vitesse plus √©lev√©e.  Je me suis rappel√© que dans l‚Äôexcellent guide AWK de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bruce Barnett</a> , j‚Äôai lu sur une fonctionnalit√© int√©ressante appel√©e ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tableaux associatifs</a> ¬ª.  En fait, ce sont des paires cl√©-valeur, qui pour une raison quelconque √©taient appel√©es diff√©remment dans AWK, et donc je ne les ai pas particuli√®rement mentionn√©es.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Roman Cheplyaka a</a> rappel√© que le terme ¬´tableaux associatifs¬ª est beaucoup plus ancien que le terme ¬´paire cl√©-valeur¬ª.  M√™me si vous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">recherchez une valeur-cl√© dans Google Ngram</a> , vous ne verrez pas ce terme l√†, mais vous trouverez des tableaux associatifs!  De plus, la paire cl√©-valeur est le plus souvent associ√©e aux bases de donn√©es, il est donc beaucoup plus logique de comparer avec hashmap.  J'ai r√©alis√© que je pouvais utiliser ces tableaux associatifs pour connecter mes SNP √† la table bin et aux donn√©es brutes sans utiliser Spark. <br><br>  Pour cela, dans le script AWK, j'ai utilis√© le bloc <code>BEGIN</code> .  Il s'agit d'un morceau de code qui est ex√©cut√© avant le transfert de la premi√®re ligne de donn√©es vers le corps principal du script. <br><br><pre> <code class="cpp hljs">join_data.awk BEGIN { FS=<span class="hljs-string"><span class="hljs-string">","</span></span>; batch_num=substr(chunk,<span class="hljs-number"><span class="hljs-number">7</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>); chunk_id=substr(chunk,<span class="hljs-number"><span class="hljs-number">15</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(getline &lt; <span class="hljs-string"><span class="hljs-string">"snp_to_bin.csv"</span></span>) {bin[$<span class="hljs-number"><span class="hljs-number">1</span></span>] = $<span class="hljs-number"><span class="hljs-number">2</span></span>} } { print $<span class="hljs-number"><span class="hljs-number">0</span></span> &gt; <span class="hljs-string"><span class="hljs-string">"chunked/chr_"</span></span>chr<span class="hljs-string"><span class="hljs-string">"_bin_"</span></span>bin[$<span class="hljs-number"><span class="hljs-number">1</span></span>]<span class="hljs-string"><span class="hljs-string">"_"</span></span>batch_num<span class="hljs-string"><span class="hljs-string">"_"</span></span>chunk_id<span class="hljs-string"><span class="hljs-string">".csv"</span></span> }</code> </pre> <br>  La commande <code>while(getline...)</code> charg√© toutes les lignes du groupe CSV (bin), d√©finissez la premi√®re colonne (nom SNP) comme cl√© pour le tableau associatif <code>bin</code> et la deuxi√®me valeur (group) comme valeur.  Ensuite, dans le bloc <code>{</code> <code>}</code> , qui est appliqu√© √† toutes les lignes du fichier principal, chaque ligne est envoy√©e au fichier de sortie, qui obtient un nom unique en fonction de son groupe (bin): <code>..._bin_"bin[$1]"_...</code> <br><br>  Les <code>chunk_id</code> <code>batch_num</code> et <code>chunk_id</code> correspondaient aux donn√©es fournies par le pipeline, ce qui √©vitait l'√©tat de course, et chaque thread d'ex√©cution lanc√© en <code>parallel</code> √©crivait dans son propre fichier unique. <br><br>  Depuis que j'ai dispers√© toutes les donn√©es brutes dans des dossiers sur les chromosomes laiss√©s apr√®s ma pr√©c√©dente exp√©rience avec AWK, je pouvais maintenant √©crire un autre script Bash √† traiter sur le chromosome √† la fois et donner des donn√©es partitionn√©es plus profondes √† S3. <br><br><pre> <code class="bash hljs">DESIRED_CHR=<span class="hljs-string"><span class="hljs-string">'13'</span></span> <span class="hljs-comment"><span class="hljs-comment"># Download chromosome data from s3 and split into bins aws s3 ls $DATA_LOC | awk '{print $4}' | grep 'chr'$DESIRED_CHR'.csv' | parallel "echo 'reading {}'; aws s3 cp "$DATA_LOC"{} - | awk -v chr=\""$DESIRED_CHR"\" -v chunk=\"{}\" -f split_on_chr_bin.awk" # Combine all the parallel process chunks to single files and upload to rds using R ls chunked/ | cut -d '_' -f 4 | sort -u | parallel "echo 'zipping bin {}'; cat chunked/*_bin_{}_*.csv | ./upload_as_rds.R '$S3_DEST'/chr_'$DESIRED_CHR'_bin_{}.rds" rm chunked/*</span></span></code> </pre> <br>  Le script a deux sections <code>parallel</code> . <br><br>  Dans la premi√®re section, les donn√©es de tous les fichiers contenant des informations sur le chromosome souhait√© sont lues, puis ces donn√©es sont distribu√©es en flux qui dispersent les fichiers dans les groupes correspondants (bin).  Pour √©viter que des conditions de <code>chr_10_bin_52_batch_2_aa.csv</code> ne se produisent lorsque plusieurs flux sont √©crits dans le m√™me fichier, AWK transf√®re les noms de fichier pour √©crire des donn√©es √† diff√©rents endroits, par exemple, <code>chr_10_bin_52_batch_2_aa.csv</code> .  En cons√©quence, de nombreux petits fichiers sont cr√©√©s sur le disque (pour cela, j'ai utilis√© des volumes EBS de t√©raoctets). <br><br>  Le pipeline de la deuxi√®me section <code>parallel</code> passe par les groupes (bin) et combine leurs fichiers individuels en CSV communs avec <code>cat</code> , puis les envoie pour exportation. <br><br><h2>  Diffuser vers R? </h2><br>  <b>Ce que j'ai appris</b> : vous pouvez acc√©der √† <code>stdin</code> et <code>stdout</code> partir d'un script R, et donc l'utiliser dans le pipeline. <br><br>  Dans le script Bash, vous remarquerez peut-√™tre cette ligne: <code>...cat chunked/*_bin_{}_*.csv | ./upload_as_rds.R...</code>  <code>...cat chunked/*_bin_{}_*.csv | ./upload_as_rds.R...</code>  Il traduit tous les fichiers de groupe concat√©n√©s (bin) dans le script R ci-dessous.  <code>{}</code> est une technique <code>parallel</code> sp√©ciale qui ins√®re toutes les donn√©es envoy√©es par elle dans le flux sp√©cifi√© directement dans la commande elle-m√™me.  L'option <code>{#}</code> fournit un ID de thread unique et <code>{%}</code> repr√©sente le num√©ro de l'emplacement de travail (r√©p√©t√©, mais jamais en m√™me temps).  Une liste de toutes les options se trouve dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation.</a> <br><br><pre> <code class="lisp hljs"><span class="hljs-meta"><span class="hljs-meta">#!/usr/bin/env Rscript library(readr) library(aws.s3) # Read first command line argument data_destination &lt;- commandArgs(trailingOnly = TRUE)[1] data_cols &lt;- list(SNP_Name = 'c', ...) s3saveRDS( read_csv( file("stdin"), col_names = names(data_cols), col_types = data_cols ), object = data_destination )</span></span></code> </pre> <br>  Lorsque la variable de <code>file("stdin")</code> est transmise √† <code>readr::read_csv</code> , les donn√©es traduites dans le script R sont charg√©es dans le cadre, qui est ensuite √©crit directement dans S3 en tant que fichier <code>.rds</code> √† l'aide de <code>aws.s3</code> . <br><br>  RDS est un peu comme une version plus r√©cente de Parquet, sans les fioritures du stockage sur colonne. <br><br>  Apr√®s avoir termin√© le script Bash, j'ai re√ßu un <code>.rds</code> fichiers <code>.rds</code> trouvant dans S3, ce qui m'a permis d'utiliser une compression efficace et des types int√©gr√©s. <br><br>  Malgr√© l'utilisation du frein R, tout a fonctionn√© tr√®s rapidement.  Il n'est pas surprenant que les fragments sur R qui sont responsables de la lecture et de l'√©criture des donn√©es soient bien optimis√©s.  Apr√®s avoir test√© sur un chromosome de taille moyenne, la t√¢che s'est termin√©e sur l'instance C5n.4xl en environ deux heures. <br><br><h2>  Limitations de S3 </h2><br>  <b>Ce que j'ai appris</b> : gr√¢ce √† l'impl√©mentation intelligente des chemins, S3 peut traiter de nombreux fichiers. <br><br>  J'√©tais inquiet si S3 pouvait g√©rer un grand nombre de fichiers qui y √©taient transf√©r√©s.  Je pourrais donner un sens aux noms de fichiers, mais comment S3 les recherchera-t-il? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/841/0dc/c34/8410dcc34a563c683dd7602dc66d884a.png"><br> <i>  S3    ,        <code>/</code> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> FAQ- S3.</a></i> <br><br> , S3            -      .  (bucket)   ,   ‚Äî    . <br><br>          Amazon, ,    ¬´-----¬ª  .    :       get-,       . ,      20 . bin-. ,   ,      (,      ,      ).          . <br><br><h2>    ? </h2><br>   :     ‚Äî     . <br><br>       : ¬´    ?¬ª      ( gzip CSV-   7  )      .     ,  R     Parquet ( Arrow)     Spark.       R,         ,         ,       . <br><br><h2>   </h2><br> <b>  </b> :     ,    . <br><br>       ,      . <br>     EC2  ,                 ( ,  Spark    ).  ,          ,    AWS-      10 . <br><br>      R      . <br><br>   S3 ,       . <br><br><pre> <code class="bash hljs">library(aws.s3) library(tidyverse) chr_sizes &lt;- get_bucket_df( bucket = <span class="hljs-string"><span class="hljs-string">'...'</span></span>, prefix = <span class="hljs-string"><span class="hljs-string">'...'</span></span>, max = Inf ) %&gt;% mutate(Size = as.numeric(Size)) %&gt;% filter(Size != 0) %&gt;% mutate( <span class="hljs-comment"><span class="hljs-comment"># Extract chromosome from the file name chr = str_extract(Key, 'chr.{1,4}\\.csv') %&gt;% str_remove_all('chr|\\.csv') ) %&gt;% group_by(chr) %&gt;% summarise(total_size = sum(Size)/1e+9) # Divide to get value in GB # A tibble: 27 x 2 chr total_size &lt;chr&gt; &lt;dbl&gt; 1 0 163. 2 1 967. 3 10 541. 4 11 611. 5 12 542. 6 13 364. 7 14 375. 8 15 372. 9 16 434. 10 17 443. # ‚Ä¶ with 17 more rows</span></span></code> </pre> <br>    ,    ,   ,     <code>num_jobs</code>  ,       . <br><br><pre> <code class="bash hljs">num_jobs &lt;- 7 <span class="hljs-comment"><span class="hljs-comment"># How big would each job be if perfectly split? job_size &lt;- sum(chr_sizes$total_size)/7 shuffle_job &lt;- function(i){ chr_sizes %&gt;% sample_frac() %&gt;% mutate( cum_size = cumsum(total_size), job_num = ceiling(cum_size/job_size) ) %&gt;% group_by(job_num) %&gt;% summarise( job_chrs = paste(chr, collapse = ','), total_job_size = sum(total_size) ) %&gt;% mutate(sd = sd(total_job_size)) %&gt;% nest(-sd) } shuffle_job(1) # A tibble: 1 x 2 sd data &lt;dbl&gt; &lt;list&gt; 1 153. &lt;tibble [7 √ó 3]&gt;</span></span></code> </pre> <br>      purrr     . <br><br><pre> <code class="bash hljs">1:1000 %&gt;% map_df(shuffle_job) %&gt;% filter(sd == min(sd)) %&gt;% pull(data) %&gt;% pluck(1)</code> </pre> <br>     ,    .       Bash-    <code>for</code> .       10 .    ,             .  ,        . <br><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> DESIRED_CHR <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-string"><span class="hljs-string">"16"</span></span> <span class="hljs-string"><span class="hljs-string">"9"</span></span> <span class="hljs-string"><span class="hljs-string">"7"</span></span> <span class="hljs-string"><span class="hljs-string">"21"</span></span> <span class="hljs-string"><span class="hljs-string">"MT"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-comment"><span class="hljs-comment"># Code for processing a single chromosome fi</span></span></code> </pre> <br>     : <br><br><pre> <code class="bash hljs">sudo shutdown -h now</code> </pre> <br> ‚Ä¶   !   AWS CLI       <code>user_data</code>   Bash-    .     ,         . <br><br><pre> <code class="bash hljs">aws ec2 run-instances ...\ --tag-specifications <span class="hljs-string"><span class="hljs-string">"ResourceType=instance,Tags=[{Key=Name,Value=&lt;&lt;job_name&gt;&gt;}]"</span></span> \ --user-data file://&lt;&lt;job_script_loc&gt;&gt;</code> </pre> <br><h1> ! </h1><br> <b>  </b> : API        . <br><br> -        .      ,     .     API   .        <code>.rds</code>  Parquet-,       ,    .       R-. <br><br>      ,        ,    <code>get_snp</code> .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pkgdown</a> ,        . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a75/afb/f3a/a75afbf3a2c7c8ef5fa2a873f8ba50b9.png"><br><br><h2>   </h2><br> <b>  </b> :     ,   ! <br><br>          SNP      ,     (binning)   .     SNP,          (bin).      ( )    . <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Part of get_snp() ... # Test if our current snp data has the desired snp. already_have_snp &lt;- desired_snp %in% prev_snp_results$snps_in_bin if(!already_have_snp){ # Grab info on the bin of the desired snp snp_results &lt;- get_snp_bin(desired_snp) # Download the snp's bin data snp_results$bin_data &lt;- aws.s3::s3readRDS(object = snp_results$data_loc) } else { # The previous snp data contained the right bin so just use it snp_results &lt;- prev_snp_results } ...</span></span></code> </pre> <br>       ,       .    ,      . , <code>dplyr::filter</code>           ,           ,    . <br><br>  ,   <code>prev_snp_results</code>   <code>snps_in_bin</code> .     SNP   (bin),   ,       .        SNP   (bin)    : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Get bin-mates snps_in_bin &lt;- my_snp_results$snps_in_bin for(current_snp in snps_in_bin){ my_snp_results &lt;- get_snp(current_snp, my_snp_results) # Do something with results }</span></span></code> </pre> <br><h1>  R√©sultats </h1><br>    (  )    ,   .  ,           .      . <br><br>       ,       ,     ,     ‚Ä¶ <br><br>   .       .       (  ),  ,   (bin)   ,    SNP     0,1 ,     ,     S3 . <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-3" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1134151057385369600"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br><h2>  Conclusion </h2><br>   ‚Äî   .   ,     . ,    . ,   ,         ,     .  ,       ,  ,        ,    .  ,       ,    ,        ,      -     . <br><br>     .     ,        ,  ¬´¬ª  ,    .          . <br><br><h3>   : </h3><br><ul><li>      25   ; <br></li><li>      Parquet-   ; <br></li><li>   Spark   ; <br></li><li>      2,5  ; <br></li><li>    ,    Spark; <br></li><li>      ; <br></li><li>   Spark  ,      ; <br></li><li>  ,    ,  -       1980-; <br></li><li> <code>gnu parallel</code> ‚Äî   ,    ; <br></li><li> Spark        ; <br></li><li>  Spark        ; <br></li><li>    AWK  ; <br></li><li>    <code>stdin</code>  <code>stdout</code>  R-,       ; <br></li><li>     S3    ; <br></li><li>     ‚Äî     ; <br></li><li>     ,    ; <br></li><li> API        ; <br></li><li>     ,   ! <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr456392/">https://habr.com/ru/post/fr456392/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr456376/index.html">Not One Spring Boot: un aper√ßu des alternatives</a></li>
<li><a href="../fr456380/index.html">Journ√©e portes ouvertes de la Facult√© de Programmation en Netologie</a></li>
<li><a href="../fr456384/index.html">PVS-Studio Graphique de d√©veloppement des capacit√©s de diagnostic</a></li>
<li><a href="../fr456386/index.html">Biblioth√®ques ouvertes pour la visualisation du contenu audio</a></li>
<li><a href="../fr456388/index.html">Tableau de d√©veloppement de diagnostic dans PVS-Studio</a></li>
<li><a href="../fr456394/index.html">Cr√©ation de l'√©cran de d√©marrage omnipr√©sent sur iOS</a></li>
<li><a href="../fr456398/index.html">Plugins Vue-cli, fonctionnant avec des donn√©es complexes et des tests bas√©s sur les propri√©t√©s - Annonce Panda-Meetup Frontend</a></li>
<li><a href="../fr456400/index.html">Pourquoi la comp√©tition est meilleure que le bourrage: notre exp√©rience d'apprentissage de la gamification</a></li>
<li><a href="../fr456402/index.html">Dents de sagesse: Pull-Pull</a></li>
<li><a href="../fr456404/index.html">Looper - Plugin pour Sketch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👴🏾 🧕 🐫 Kinerja tinggi dan partisi asli: Zabbix dengan dukungan TimescaleDB 🚨 🖕🏻 🆘</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Zabbix adalah sistem pemantauan. Seperti sistem lainnya, sistem ini menghadapi tiga masalah utama dari semua sistem pemantauan: pengumpulan dan pemros...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kinerja tinggi dan partisi asli: Zabbix dengan dukungan TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/470902/">  Zabbix adalah sistem pemantauan.  Seperti sistem lainnya, sistem ini menghadapi tiga masalah utama dari semua sistem pemantauan: pengumpulan dan pemrosesan data, penyimpanan riwayat, dan pembersihannya. <br><br>  Langkah-langkah untuk memperoleh, memproses, dan merekam data membutuhkan waktu.  Tidak banyak, tetapi untuk sistem yang besar ini dapat menghasilkan penundaan yang besar.  Masalah penyimpanan adalah masalah akses data.  Mereka digunakan untuk laporan, cek, dan pemicu.  Keterlambatan mengakses data juga memengaruhi kinerja.  Ketika basis data tumbuh, data yang tidak relevan harus dihapus.  Penghapusan adalah operasi yang sulit yang juga memakan beberapa sumber daya. <br><br><img src="https://habrastorage.org/webt/jb/yy/zo/jbyyzopzw6gtfio8uhqbgushzo8.jpeg"><br><br>  Masalah keterlambatan saat pengumpulan dan penyimpanan di Zabbix diselesaikan dengan caching: beberapa jenis cache, caching dalam database.  Untuk mengatasi masalah ketiga, caching tidak cocok, oleh karena itu, Zabbix menggunakan TimescaleDB.  <strong>Andrey Gushchin</strong> , insinyur dukungan teknis di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Zabbix SIA,</a> akan membicarakan hal ini.  Andrey telah mendukung Zabbix selama lebih dari 6 tahun dan secara langsung menghadapi kinerja. <br><br>  Bagaimana cara kerja TimescaleDB, kinerja apa yang dapat diberikannya dibandingkan dengan PostgreSQL biasa?  Apa peran yang dimainkan Zabbix di TimescaleDB?  Bagaimana menjalankan dari awal dan bagaimana bermigrasi dengan PostgreSQL dan kinerja mana yang lebih baik?  Tentang semua ini di bawah potongan. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/umRk94j5M8o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Tantangan kinerja </h2><br>  Setiap sistem pemantauan menghadapi tantangan kinerja spesifik.  Saya akan berbicara tentang mereka bertiga: mengumpulkan dan memproses data, menyimpan, membersihkan riwayat. <br><br>  <strong>Pengumpulan dan pemrosesan data yang cepat.</strong>  Sistem pemantauan yang baik harus dengan cepat menerima semua data dan memprosesnya sesuai dengan pemicu ekspresi - sesuai dengan kriteria sendiri.  Setelah diproses, sistem juga harus dengan cepat menyimpan data ini ke database untuk menggunakannya nanti. <br><br>  <strong>Menyimpan cerita.</strong>  Sistem pemantauan yang baik harus menyimpan riwayat dalam basis data dan menyediakan akses mudah ke metrik.  Diperlukan sebuah cerita untuk menggunakannya dalam laporan, grafik, pemicu, ambang batas, dan item data yang dihitung untuk peringatan. <br><br>  <strong>Bersihkan riwayat.</strong>  Terkadang sehari tiba ketika Anda tidak perlu menyimpan metrik.  Mengapa Anda memerlukan data yang dikumpulkan 5 tahun yang lalu, satu atau dua bulan: beberapa node dihapus, beberapa host atau metrik tidak lagi diperlukan, karena mereka sudah usang dan berhenti mengumpulkan.  Sistem pemantauan yang baik harus menyimpan data historis dan menghapusnya dari waktu ke waktu sehingga basis data tidak bertambah. <br><br><blockquote>  Menghapus data yang sudah usang adalah masalah panas yang berdampak besar pada kinerja database. </blockquote><br><h2>  Caching Zabbix </h2><br>  Di Zabbix, panggilan pertama dan kedua diselesaikan menggunakan caching.  RAM digunakan untuk pengumpulan dan pemrosesan data.  Untuk penyimpanan - cerita dalam pemicu, grafik, dan elemen data yang dihitung.  Di sisi database, ada caching tertentu untuk sampel utama, misalnya, bagan. <br><br>  Caching di sisi server Zabbix itu sendiri adalah: <br><br><ul><li>  ConfigurationCache; </li><li>  ValueCache; </li><li>  HistoryCache; </li><li>  TrendsCache. </li></ul><br>  Mari kita pertimbangkan secara lebih detail. <br><br><h3>  ConfigurationCache </h3><br>  Ini adalah cache utama tempat kami menyimpan metrik, host, item data, pemicu - semua yang diperlukan untuk PreProcessing dan untuk mengumpulkan data. <br><br><img src="https://habrastorage.org/webt/g0/zd/er/g0zderqgjgddgeq0frjdyvgj-q0.png"><br><br>  Semua ini disimpan dalam ConfigurationCache agar tidak membuat pertanyaan yang tidak perlu dalam database.  Setelah server dimulai, kami memperbarui cache ini, membuat dan memperbarui konfigurasi secara berkala. <br><br><h3>  Pengumpulan data </h3><br>  Skema ini cukup besar, tetapi hal utama di dalamnya adalah <strong>perakit</strong> .  Ini adalah berbagai "poller" - proses perakitan.  Mereka bertanggung jawab untuk berbagai jenis perakitan: mereka mengumpulkan data melalui SNMP, IPMI, dan mentransfer semuanya ke PreProcessing. <br><br><img src="https://habrastorage.org/webt/z2/2r/jq/z22rjqgzyoam-61aadugsmowsbe.jpeg">  <em>Kolektor dilingkari oranye.</em> <br><br>  Zabbix telah menghitung elemen data agregasi yang diperlukan untuk mengagregasi validasi.  Jika kami memilikinya, kami mengambil datanya langsung dari ValueCache. <br><br><h3>  PreCiproses HistoryCache </h3><br>  Semua kolektor menggunakan ConfigurationCache untuk menerima pekerjaan.  Kemudian mereka meneruskannya ke PreProcessing. <br><br><img src="https://habrastorage.org/webt/f9/f-/yc/f9f-ycupjcyofnnz20injlmynty.png"><br><br>  PreProcessing menggunakan ConfigurationCache untuk menerima langkah-langkah PreProcessing.  Ini memproses data ini dengan berbagai cara. <br><br>  Setelah memproses data menggunakan PreProcessing, kami menyimpannya di HistoryCache untuk memprosesnya.  Ini mengakhiri pengumpulan data dan kami beralih ke proses utama di Zabbix - <strong>syncer sejarah</strong> , karena ini adalah arsitektur monolitik. <br><br>  <em>Catatan: PreProcessing adalah operasi yang cukup sulit.</em>  <em>Sejak v 4.2, ini telah diserahkan ke proksi.</em>  <em>Jika Anda memiliki Zabbix yang sangat besar dengan sejumlah besar elemen data dan frekuensi pengumpulan, ini sangat memudahkan pekerjaan.</em> <br><br><h3>  ValueCache, riwayat &amp; tren cache </h3><br><blockquote>  Syncer sejarah adalah proses utama yang secara atomis memproses setiap elemen data, yaitu setiap nilai. </blockquote><br>  Syncer histori mengambil nilai dari HistoryCache dan memeriksa di Konfigurasi untuk pemicu perhitungan.  Jika ya, itu menghitung. <br><br>  Syncer sejarah membuat acara, peningkatan untuk membuat peringatan, jika diperlukan oleh konfigurasi, dan catatan.  Jika ada pemicu untuk pemrosesan selanjutnya, maka ia mengingat nilai ini di ValueCache agar tidak mengakses tabel riwayat.  Jadi ValueCache diisi dengan data yang diperlukan untuk menghitung pemicu, elemen yang dihitung. <br><br>  Syncer sejarah menulis semua data ke database, dan itu ditulis ke disk.  Proses pemrosesan berakhir di sini. <br><br><img src="https://habrastorage.org/webt/u7/v0/08/u7v0080wzx7v_fh8ej-fas7b1wg.jpeg"><br><br><h3>  Caching DB </h3><br>  Di sisi DB, ada berbagai cache ketika Anda ingin menonton grafik atau laporan acara: <br><br><ul><li> <code>Innodb_buffer_pool</code> di sisi MySQL; </li><li>  <code>shared_buffers</code> di sisi PostgreSQL; </li><li>  <code>effective_cache_size</code> di sisi Oracle; </li><li>  <code>shared_pool</code> di sisi DB2. </li></ul><br>  Ada banyak cache lainnya, tetapi ini adalah yang utama untuk semua database.  Mereka memungkinkan Anda untuk menyimpan dalam memori data yang sering dibutuhkan untuk permintaan.  Mereka memiliki teknologi sendiri untuk ini. <br><br><h3>  Kinerja basis data sangat penting </h3><br>  Zabbix-server terus-menerus mengumpulkan data dan menulisnya.  Saat memulai ulang, itu juga membaca dari riwayat untuk mengisi ValueCache.  Skrip dan laporan menggunakan <strong>Zabbix API</strong> , yang dibangun berdasarkan antarmuka Web.  Zabbix API menghubungi basis data dan menerima data yang diperlukan untuk grafik, laporan, daftar acara, dan masalah terkini. <br><br><img src="https://habrastorage.org/webt/b5/48/rc/b548rcjuhprytj6zcpi_buqdr2c.png"><br><br>  Untuk visualisasi - <strong>Grafana</strong> .  Di antara pengguna kami, ini adalah solusi populer.  Itu dapat langsung mengirim permintaan melalui Zabbix API dan ke database, dan menciptakan daya saing tertentu untuk menerima data.  Oleh karena itu, kita memerlukan penyempurnaan basis data yang lebih baik dan lebih baik agar sesuai dengan hasil dan pengujian yang cepat. <br><br><h2>  Pengurus rumah tangga </h2><br>  Tantangan kinerja ketiga di Zabbix adalah membersihkan sejarah dengan Housekeeper.  Ini mengikuti semua pengaturan - elemen data menunjukkan berapa banyak untuk menjaga dinamika perubahan (tren) dalam beberapa hari. <br><br>  Kami menghitung TrendsCache dengan cepat.  Ketika data tiba, kami mengumpulkannya dalam satu jam dan menuliskannya dalam tabel untuk dinamika perubahan tren. <br><br>  Pengurus rumah memulai dan menghapus informasi dari database dengan "select" yang biasa.  Ini tidak selalu efektif, yang dapat dipahami dari grafik kinerja proses internal. <br><br><img src="https://habrastorage.org/webt/m0/3q/x_/m03qx_0sgbs_2bpjc_toewzmsbo.png"><br><br>  Grafik merah menunjukkan bahwa penyelia Sejarah terus-menerus sibuk.  Grafik oranye di atas adalah Housekeeper, yang terus berjalan.  Dia mengharapkan database untuk menghapus semua baris yang dia tentukan. <br><br>  Kapan mematikan Housekeeper?  Misalnya, ada "Item ID" dan Anda perlu menghapus 5 ribu baris terakhir dalam waktu tertentu.  Tentu saja, ini terjadi dengan indeks.  Tetapi biasanya dataset sangat besar, dan database masih membaca dari disk dan menaikkannya ke cache.  Ini selalu merupakan operasi yang sangat mahal untuk database dan, tergantung pada ukuran database, dapat menyebabkan masalah kinerja. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w4/c4/y7/w4c4y7m_lwigpvwzq4bfsftktw8.png" width="500"></div><br><br>  Pengurus rumah tangga hanya putuskan.  Di antarmuka Web ada pengaturan di "Administrasi umum" untuk Pengurus Rumah Tangga.  Nonaktifkan housekeeping internal untuk sejarah tren internal dan tidak lagi mengelola ini. <br><br>  Pengurus rumah tangga dimatikan, grafik diratakan - apa yang bisa menjadi masalah dalam kasus ini, dan apa yang bisa membantu dalam menyelesaikan panggilan kinerja ketiga? <br><br><h2>  Partisi - mempartisi atau mempartisi </h2><br>  Biasanya, partisi dikonfigurasi dengan cara yang berbeda pada setiap basis data relasional yang telah saya daftarkan.  Masing-masing memiliki teknologinya sendiri, tetapi mereka serupa, secara umum.  Membuat partisi baru sering menyebabkan masalah tertentu. <br><br>  Partisi biasanya dikonfigurasi tergantung pada "pengaturan" - jumlah data yang dibuat dalam satu hari.  Sebagai aturan, Partisi terbuka dalam satu hari, ini adalah minimum.  Untuk tren partisi baru - selama 1 bulan. <br><br>  Nilai dapat berubah jika "pengaturan" sangat besar.  Jika "pengaturan" kecil hingga 5.000 nvps (nilai baru per detik), rata-rata dari 5.000 hingga 25.000, maka besar di atas 25.000 nvps.  Ini adalah instalasi besar dan sangat besar yang membutuhkan konfigurasi database yang cermat. <br><br>  Pada instalasi yang sangat besar, proses satu hari mungkin tidak optimal.  Saya melihat partisi MySQL sebesar 40 GB atau lebih per hari.  Ini adalah jumlah data yang sangat besar yang dapat menyebabkan masalah, dan ini perlu dikurangi. <br><br><h3>  Apa yang memberi Partisi? </h3><br>  <strong>Tabel partisi</strong> .  Seringkali ini adalah file yang terpisah pada disk.  Rencana kueri lebih optimal memilih satu partisi.  Partisi biasanya digunakan dalam rentang - untuk Zabbix ini juga benar.  Kami menggunakan "timestamp" di sana - waktu dari awal era.  Kami memiliki nomor biasa.  Anda mengatur awal dan akhir hari - ini adalah partisi. <br><br>  <strong>Hapus cepat</strong> - <code>DELETE</code> .  Satu file / subtable dipilih, bukan pilihan baris untuk dihapus. <br><br>  <strong>Tampak mempercepat pengambilan data</strong> <code>SELECT</code> - menggunakan satu atau lebih partisi, bukan seluruh tabel.  Jika Anda meminta data dua hari lalu, mereka dipilih dari database lebih cepat karena Anda perlu memuat ke dalam cache dan mengeluarkan hanya satu file, bukan tabel besar. <br><br>  Seringkali, banyak basis data juga mempercepat sisipan <code>INSERT</code> ke dalam tabel anak. <br><br><h2>  Timescaledb </h2><br>  Untuk v 4.2, kami mengalihkan perhatian kami ke TimescaleDB.  Ini adalah ekstensi untuk PostgreSQL dengan antarmuka asli.  Ekstensi bekerja secara efektif dengan data deret waktu, tanpa kehilangan manfaat dari basis data relasional.  TimescaleDB juga secara otomatis partisi. <br><br>  TimescaleDB memiliki konsep <strong>hipertensi</strong> yang Anda buat.  Ini berisi <strong>potongan</strong> - partisi.  Bongkahan secara otomatis dikendalikan fragmen hipertensi yang tidak mempengaruhi fragmen lainnya.  Setiap chunk memiliki rentang waktunya sendiri. <br><br><img src="https://habrastorage.org/webt/0p/0g/mh/0p0gmhmshsg_htxuboh2w1xdmeo.jpeg"><br><br><h3>  TimescaleDB vs PostgreSQL </h3><br>  TimescaleDB bekerja sangat efisien.  Pembuat ekstensi mengklaim bahwa mereka menggunakan algoritma pemrosesan permintaan yang lebih benar, khususnya, &lt;code&gt; sisipan &lt;/code&gt;.  Ketika dimensi sisipan dataset bertambah, algoritma mempertahankan kinerja konstan. <br><br><img src="https://habrastorage.org/webt/_n/1v/vo/_n1vvoqc1hghllux5r_u7i_23q4.png"><br><br>  Setelah 200 juta baris, PostgreSQL biasanya mulai sangat melorot dan kehilangan kinerja hingga 0. TimescaleDB memungkinkan Anda untuk secara efisien memasukkan "sisipan" untuk sejumlah data. <br><br><h3>  Instalasi </h3><br>  Menginstal TimescaleDB cukup mudah untuk semua paket.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dokumentasi</a> menjelaskan semuanya secara rinci - itu tergantung pada paket-paket resmi PostgreSQL.  TimescaleDB juga dapat dikompilasi dan dikompilasi secara manual. <br><br>  Untuk basis data Zabbix, kami cukup mengaktifkan ekstensi: <br><br><pre> <code class="sql hljs">echo "<span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> EXTENSION <span class="hljs-keyword"><span class="hljs-keyword">IF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXISTS</span></span> timescaledb <span class="hljs-keyword"><span class="hljs-keyword">CASCADE</span></span>;" | sudo -u postgres psql zabbix</code> </pre> <br>  Anda mengaktifkan <code>extension</code> dan membuatnya untuk basis data Zabbix.  Langkah terakhir adalah membuat hipertensi. <br><br><h3>  Migrasi tabel histori ke TimescaleDB </h3><br>  Ada fungsi khusus <code>create_hypertable</code> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_unit'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_log'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_text'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_str'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'trends'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'trends_unit'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">86400</span></span>, migrate_data =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> config <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> db_extension=<span class="hljs-string"><span class="hljs-string">'timescaledb'</span></span>, hk_history_global=<span class="hljs-number"><span class="hljs-number">1</span></span>, hk_trends_global=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br>  Fungsi ini memiliki tiga parameter.  Yang pertama adalah <strong>tabel dalam database</strong> yang Anda butuhkan untuk membuat hipertensi.  Yang kedua adalah <strong>bidang</strong> yang digunakan untuk membuat <code>chunk_time_interval</code> - interval potongan partisi yang ingin Anda gunakan.  Dalam kasus saya, intervalnya satu hari - 86.400. <br><br>  Parameter ketiga adalah <code><strong>migrate_data</strong></code> .  Jika disetel ke <code>true</code> , maka semua data saat ini ditransfer ke potongan yang dibuat sebelumnya.  Saya sendiri menggunakan <code>migrate_data</code> .  Saya memiliki sekitar 1 TB, yang membutuhkan waktu lebih dari satu jam.  Bahkan dalam beberapa kasus, saat pengujian, saya menghapus data historis tipe karakter yang opsional untuk penyimpanan, agar tidak mentransfernya. <br><br>  Langkah terakhir adalah <code><strong>UPDATE</strong></code> : kami menetapkan <code>timescaledb</code> di <code>db_extension</code> sehingga database memahami bahwa ada ekstensi ini.  Zabbix mengaktifkannya dan sudah menggunakan sintaks dan query dengan benar ke database - fitur-fitur yang diperlukan untuk TimescaleDB. <br><br><h2>  Konfigurasi besi </h2><br>  Saya menggunakan dua server.  Yang pertama adalah <strong>mesin VMware</strong> .  Cukup kecil: 20 Prosesor Intel® Xeon® E5-2630 v 4 @ 2.20GHz, RAM 16 GB, dan SSD 200 GB. <br><br>  Saya menginstal PostgreSQL 10.8 di atasnya dengan Debian 10.8-1.pgdg90 +1 dan sistem file xfs.  Saya mengkonfigurasi semuanya secara minimal untuk menggunakan database khusus ini, minus apa yang akan digunakan Zabbix sendiri. <br><br>  Pada mesin yang sama adalah server Zabbix, PostgreSQL, dan <strong>agen beban</strong> .  Saya memiliki 50 agen aktif yang menggunakan <code>LoadableModule</code> untuk dengan sangat cepat menghasilkan berbagai hasil: angka, string.  Saya menyumbat database dengan banyak data. <br><br>  Awalnya, konfigurasi berisi <strong>5.000 item</strong> data per host.  Hampir setiap elemen mengandung pemicu, sehingga mirip dengan instalasi nyata.  Dalam beberapa kasus, ada lebih dari satu pemicu.  Ada <strong>3.000-7.000 pemicu per</strong> node jaringan. <br><br>  Interval untuk memperbarui item data adalah <strong>4-7 detik</strong> .  Saya mengatur beban itu sendiri dengan menggunakan tidak hanya 50 agen, tetapi juga menambahkan lebih banyak.  Juga, dengan bantuan elemen data, saya menyesuaikan beban secara dinamis dan mengurangi interval pembaruan menjadi 4 detik. <br><br><h3>  PostgreSQL  35.000 nvps </h3><br>  Jalankan pertama pada perangkat keras ini saya miliki di PostgreSQL murni - 35 ribu nilai per detik.  Seperti yang Anda lihat, memasukkan data membutuhkan sepersekian detik - semuanya baik dan cepat.  Satu-satunya hal yang mengisi 200 GB SSD dengan cepat. <br><br><img src="https://habrastorage.org/webt/wp/pk/vq/wppkvqe33kjs-udv8qc75jynloq.jpeg"><br><br>  Ini adalah dasbor kinerja server standar Zabbix. <br><br><img src="https://habrastorage.org/webt/nu/h1/jl/nuh1jlhlz3cyoxyrc94cybshjos.png"><br><br>  Grafik biru pertama adalah jumlah nilai per detik.  Grafik kedua di sebelah kanan adalah pemuatan proses perakitan.  Yang ketiga adalah memuat proses perakitan internal: sinkronisasi riwayat dan Housekeeper, yang telah berjalan cukup lama di sini. <br><br>  Grafik keempat menunjukkan penggunaan HistoryCache.  Ini adalah buffer sebelum memasukkan ke dalam database.  Grafik hijau kelima menunjukkan penggunaan ValueCache, yaitu, berapa banyak hit ValueCache untuk pemicu beberapa ribu nilai per detik. <br><br><h3>  PostgreSQL  50.000 nvps </h3><br>  Lalu saya menambah beban menjadi 50 ribu nilai per detik pada perangkat keras yang sama. <br><br><img src="https://habrastorage.org/webt/wj/47/u6/wj47u6j2fycdpnx55-mrrqrwcp4.jpeg"><br><br>  Saat memuat dari Housekeeper, sisipan 10 ribu nilai dicatat selama 2-3 detik. <br><br><img src="https://habrastorage.org/webt/fn/qo/go/fnqogopttou4hwlygqckfoieht0.png"><br>  <em>Pengurus rumah tangga sudah mulai menghalangi.</em> <br><br>  Grafik ketiga menunjukkan bahwa, secara umum, memuat penjerat dan penyelarasan riwayat masih di 60%.  Pada bagan keempat, HistoryCache sudah mulai terisi cukup aktif selama pekerjaan Housekeeper.  Ini 20% penuh - sekitar 0,5 GB. <br><br><h3>  PostgreSQL  80.000 nvps </h3><br>  Lalu saya menambah beban menjadi 80 ribu nilai per detik.  Ini adalah sekitar 400 ribu elemen data dan 280 ribu pemicu. <br><br><img src="https://habrastorage.org/webt/8q/zh/5z/8qzh5zsbwvouradg7j-qxeksqfi.jpeg"><br>  <em>Sisipan untuk memuat tiga puluh sinkronisasi riwayat sudah cukup tinggi.</em> <br><br>  Saya juga meningkatkan berbagai parameter: sinkronisasi riwayat, cache. <br><br><img src="https://habrastorage.org/webt/xs/3m/ia/xs3miafccbymaddfyzzj2l4e494.png"><br><br>  Di perangkat keras saya, beban sinkronisasi riwayat meningkat secara maksimal.  HistoryCache dengan cepat diisi dengan data - data untuk diproses terakumulasi dalam buffer. <br><br>  Selama ini saya mengamati bagaimana prosesor, RAM dan parameter sistem lainnya digunakan, dan menemukan bahwa pemanfaatan disk dimaksimalkan. <br><br><img src="https://habrastorage.org/webt/zy/el/im/zyelimg6_immdsthjxburb1gjmw.jpeg"><br><br>  Saya mendapatkan yang <strong>terbaik dari drive</strong> pada perangkat keras ini dan pada mesin virtual ini.  Pada intensitas ini, PostgreSQL mulai membuang data dengan cukup aktif, dan disk tidak lagi punya waktu untuk menulis dan membaca. <br><br><h3>  Server kedua </h3><br>  Saya mengambil server lain yang sudah memiliki 48 prosesor dan RAM 128 GB.  Tune-up - atur 60 syncer history, dan dapatkan kinerja yang bisa diterima <br><br><img src="https://habrastorage.org/webt/hl/ae/ig/hlaeigh1dtxphardj6hkwmtas8w.png"><br><br>  Bahkan, ini sudah menjadi batas kinerja di mana sesuatu harus dilakukan. <br><br><h3>  TimescaleDB.  80.000 nvps </h3><br>  Tugas utama saya adalah menguji kemampuan TimescaleDB dari beban Zabbix.  80 ribu nilai per detik banyak, frekuensi mengumpulkan metrik (kecuali Yandex, tentu saja) dan "pengaturan" yang cukup besar. <br><br><img src="https://habrastorage.org/webt/c-/45/yc/c-45yc-ctmrtj7o5td-ajwrtpdm.png"><br><br>  Ada kegagalan pada setiap bagan - ini hanya migrasi data.  Setelah kegagalan di server Zabbix, profil boot syncer sejarah telah banyak berubah - itu telah jatuh tiga kali. <br><br><blockquote>  TimescaleDB memungkinkan Anda untuk memasukkan data hampir 3 kali lebih cepat dan menggunakan lebih sedikit HistoryCache. </blockquote><br>  Dengan demikian, data akan dikirimkan kepada Anda tepat waktu. <br><br><h3>  TimescaleDB.  120.000 nvps </h3><br>  Lalu saya menambah jumlah elemen data menjadi 500 ribu.Tugas utama adalah memeriksa kemampuan TimescaleDB - saya mendapat nilai yang dihitung dari 125 ribu nilai per detik. <br><br><img src="https://habrastorage.org/webt/hi/hd/ce/hihdcemwxqcqfxnv3n5-4ypmvic.png"><br><br>  Ini adalah "pengaturan" yang berfungsi yang dapat bekerja untuk waktu yang lama.  Tetapi karena disk saya hanya 1,5 TB, saya mengisinya dalam beberapa hari. <br><br><img src="https://habrastorage.org/webt/vk/51/wz/vk51wzryy45k4sycilxbcj-pjcq.png"><br><br>  Yang paling penting, pada saat yang sama, partisi TimescaleDB baru dibuat. <br><br>  Untuk kinerja, ini sama sekali tidak terlihat.  Ketika partisi dibuat di MySQL, misalnya, semuanya berbeda.  Biasanya ini terjadi pada malam hari, karena memblokir penyisipan umum, bekerja dengan tabel dan dapat membuat degradasi layanan.  Dalam kasus TimescaleDB ini bukan. <br><br>  Sebagai contoh saya akan menunjukkan satu bagan dari set di komunitas.  TimescaleDB termasuk dalam gambar, karena ini beban penggunaan io.weight pada prosesor telah turun.  Penggunaan elemen-elemen proses internal juga telah menurun.  Dan ini adalah mesin virtual biasa pada disk pancake biasa, bukan SSD. <br><br><img src="https://habrastorage.org/webt/e6/bm/a-/e6bma-otl8o5mcrt9z8wkrsq5du.jpeg"><br><br><h2>  Kesimpulan </h2><br>  <strong>TimescaleDB adalah solusi yang bagus untuk "pengaturan" kecil</strong> yang mengandalkan kinerja disk.  Ini akan memungkinkan Anda untuk terus bekerja dengan baik sampai database dimigrasi ke besi lebih cepat. <br><br>  TimescaleDB mudah untuk dikonfigurasi, memberikan peningkatan kinerja, bekerja dengan baik dengan Zabbix dan <strong>memiliki keunggulan dibandingkan PostgreSQL</strong> . <br><br>  Jika Anda menggunakan PostgreSQL dan tidak berencana untuk mengubahnya, maka saya sarankan <strong>menggunakan PostgreSQL dengan ekstensi TimescaleDB bersamaan dengan Zabbix</strong> .  Solusi ini bekerja secara efektif untuk "pengaturan" menengah. <br><br><blockquote><p>  Kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengatakan</a> "kinerja tinggi" - maksud kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> .  Menunggu untuk berkenalan dengan teknologi dan praktik yang memungkinkan layanan untuk melayani jutaan pengguna, sangat singkat.  Kami telah menyusun daftar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">laporan</a> untuk 7 dan 8 November, tetapi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mitaps</a> masih dapat ditawarkan. <br><br>  Berlangganan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">buletin</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">telegram kami</a> , tempat kami mengungkapkan keripik konferensi yang akan datang, dan pelajari cara memanfaatkannya sebaik mungkin. </p></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id470902/">https://habr.com/ru/post/id470902/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id470882/index.html">Mengapa Anda menangkap mouse saya, atau permainan papan sebagai model interaksi sosial</a></li>
<li><a href="../id470884/index.html">Menulis dan membaca data dalam blockchain Bitcoin</a></li>
<li><a href="../id470888/index.html">Undang-undang Rusia dan internasional di bidang perlindungan data pribadi</a></li>
<li><a href="../id470892/index.html">Implementasi sederhana dari CAM kecil pada FPGA</a></li>
<li><a href="../id470894/index.html">Peluru</a></li>
<li><a href="../id470904/index.html">Jalur terlembut dan paling berbulu di Machine Learning dan Deep Neural Networks</a></li>
<li><a href="../id470908/index.html">Untuk pertama kalinya di dunia dengan bantuan teknologi aditif, perakitan mesin pesawat terbang berukuran besar diperoleh</a></li>
<li><a href="../id470910/index.html">Apa yang dapat dilakukan dengan anotasi kontrak layanan mikro?</a></li>
<li><a href="../id470916/index.html">Pos pemeriksaan elektronik "termurah" di Rusia dikendalikan dari smartphone</a></li>
<li><a href="../id470918/index.html">F # 9: Opsi Opsi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
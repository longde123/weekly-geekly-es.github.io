<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôåüèΩ üêã üßõüèø Starten Sie Ihren Detektor f√ºr neuronale Netze mit dem Neural Compute Stick und OpenVINO auf dem Raspberry Pi üå≥ üê± ‚úäüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mit der Verbreitung und Entwicklung neuronaler Netze besteht ein zunehmender Bedarf, sie auf eingebetteten Ger√§ten, Robotern und Drohnen mit geringem ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Starten Sie Ihren Detektor f√ºr neuronale Netze mit dem Neural Compute Stick und OpenVINO auf dem Raspberry Pi</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436744/">  Mit der Verbreitung und Entwicklung neuronaler Netze besteht ein zunehmender Bedarf, sie auf eingebetteten Ger√§ten, Robotern und Drohnen mit geringem Stromverbrauch einzusetzen.  Mit dem Neural Compute Stick-Ger√§t in Verbindung mit dem Intel OpenVINO-Framework k√∂nnen wir dieses Problem l√∂sen, indem wir die umfangreichen Berechnungen neuronaler Netze √ºbernehmen.  Dank dieser Funktion k√∂nnen Sie auf einfache Weise einen Klassifikator oder Detektor f√ºr neuronale Netze auf einem Ger√§t mit geringem Stromverbrauch wie dem Raspberry Pi in nahezu Echtzeit starten, ohne den Energieverbrauch erheblich zu erh√∂hen.  In diesem Beitrag zeige ich Ihnen, wie Sie mit dem OpenVINO-Framework (in C ++) und dem Neural Compute Stick ein einfaches Gesichtserkennungssystem auf dem Raspberry Pi starten. <br><br>  Wie √ºblich ist der gesamte Code auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> verf√ºgbar. <br><br><img src="https://habrastorage.org/webt/qu/b_/tj/qub_tj1u6ztw9irfy9ivtaaidcc.jpeg"><br><a name="habracut"></a><br><h3>  Ein bisschen √ºber Neural Compute Stick und OpenVINO </h3><br>  Im Sommer 2017 ver√∂ffentlichte Intel das NCS-Ger√§t ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neural Compute Stick</a> ), mit dem neuronale Netze auf Ger√§ten mit geringem Stromverbrauch betrieben werden k√∂nnen. Nach einigen Monaten konnte es gekauft und getestet werden, was ich auch tat.  NCS ist ein kleines Computermodul mit einem Geh√§use in azurblauer Farbe (das auch als Heizk√∂rper fungiert), das √ºber USB mit dem Hauptger√§t verbunden ist.  Im Inneren befindet sich unter anderem die Intel Myriad <abbr title="Vision-Verarbeitungseinheit">VPU</abbr> , bei der es sich im Wesentlichen um einen 12-Kern-Parallelprozessor handelt, der f√ºr Vorg√§nge gesch√§rft wurde, die h√§ufig in neuronalen Netzen auftreten.  NCS ist nicht zum Trainieren neuronaler Netze geeignet, aber die Inferenz in bereits trainierten neuronalen Netzen ist in der Geschwindigkeit mit der auf der GPU vergleichbar.  Alle Berechnungen in NCS werden mit 16-Bit-Gleitkommazahlen durchgef√ºhrt, wodurch Sie die Geschwindigkeit erh√∂hen k√∂nnen.  NCS ben√∂tigt zum Betrieb nur 1 Watt Leistung, dh bei 5 V wird am USB-Anschluss ein Strom von bis zu 200 mA verbraucht - dies ist sogar weniger als bei der Kamera f√ºr den Raspberry Pi (250 mA). <br><br><img src="https://habrastorage.org/webt/8d/u8/ov/8du8ov7hj1-f3vk8sjbenkyupvm.png"><br><br>  F√ºr die Arbeit mit dem ersten NCS wurde das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neural Compute SDK</a> (NCSDK) verwendet: Es enth√§lt Tools zum Kompilieren neuronaler Netze im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Caffe-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow-</a> Format im NCS-Format, Tools zum Messen ihrer Leistung sowie die Python- und C ++ - API zur Inferenz. <br><br>  Dann wurde eine neue Version des NCS-Frameworks ver√∂ffentlicht: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NCSDK2</a> .  Die API hat sich stark ver√§ndert, und obwohl mir einige √Ñnderungen seltsam erschienen, gab es einige n√ºtzliche Neuerungen.  Insbesondere wurde die automatische Konvertierung von Float 32 Bit zu Float 16 Bit nach C ++ hinzugef√ºgt (fr√ºher mussten Kr√ºcken in Form von Code von Numpy eingef√ºgt werden).  Auch erschienen Warteschlangen von Bildern und die Ergebnisse ihrer Verarbeitung. <br><br>  Im Mai 2018 ver√∂ffentlichte Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenVINO</a> (fr√ºher Intel Computer Vision SDK genannt).  Dieses Framework wurde entwickelt, um neuronale Netze auf verschiedenen Ger√§ten effizient zu starten: Intel-Prozessoren und Grafikkarten, <abbr title="Feldprogrammierbares Gate-Array">FPGA</abbr> sowie der Neural Compute Stick. <br><br>  Im November 2018 wurde eine neue Version des Beschleunigers ver√∂ffentlicht: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neural Compute Stick 2</a> .  Die Rechenleistung des Ger√§ts wurde erh√∂ht: In der Beschreibung auf der Website versprechen sie eine Beschleunigung auf das 8-fache, ich konnte die neue Version des Ger√§ts jedoch nicht testen.  Die Beschleunigung wird erreicht, indem die Anzahl der Kerne von 12 auf 16 erh√∂ht und neue f√ºr neuronale Netze optimierte Computerger√§te hinzugef√ºgt werden.  Es stimmt, ich habe keine Informationen √ºber den Stromverbrauch von Informationen gefunden. <br><br>  Die zweite Version von NCS ist bereits nicht mit NCSDK oder NCSDK2 kompatibel: OpenVINO, das neben beiden Versionen von NCS mit vielen anderen Ger√§ten arbeiten kann, hat seine Berechtigung bestanden.  OpenVINO selbst verf√ºgt √ºber eine hervorragende Funktionalit√§t und umfasst die folgenden Komponenten: <br><br><ol><li>  Modelloptimierer: Python-Skript, mit dem Sie neuronale Netze aus g√§ngigen Deep-Learning-Frameworks in das universelle OpenVINO-Format konvertieren k√∂nnen.  Die Liste der unterst√ºtzten Frameworks: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Caffe</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MXNET</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaldi</a> (Spracherkennungs-Framework), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ONNX</a> (offenes Format zur Darstellung neuronaler Netze). </li><li>  Inference Engine: C ++ - und Python-API f√ºr die Inferenz neuronaler Netzwerke, abstrahiert von einem bestimmten Inferenzger√§t.  Der API-Code sieht f√ºr CPU, GPU, FPGA und NCS nahezu identisch aus. </li><li>  Eine Reihe von Plugins f√ºr verschiedene Ger√§te.  Plugins sind dynamische Bibliotheken, die explizit in den Code des Hauptprogramms geladen werden.  Das Plugin f√ºr NCS interessiert uns am meisten. </li><li>  Eine Reihe vorgefertigter Modelle im universellen OpenVINO-Format (die vollst√§ndige Liste finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ).  Eine beeindruckende Sammlung hochwertiger neuronaler Netze: Detektoren von Gesichtern, Fu√üg√§ngern, Objekten;  Erkennen der Ausrichtung von Gesichtern, speziellen Gesichtspunkten, menschlichen K√∂rperhaltungen;  super Aufl√∂sung;  und andere.  Es ist erw√§hnenswert, dass nicht alle von NCS / FPGA / GPU unterst√ºtzt werden. </li><li>  Model Downloader: Ein weiteres Skript, das das Herunterladen von Modellen im OpenVINO-Format √ºber das Netzwerk vereinfacht (obwohl Sie problemlos darauf verzichten k√∂nnen). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV</a> Computer Vision <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Library</a> optimiert f√ºr Intel Hardware. </li><li>  Bibliothek f√ºr Computer Vision <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenVX</a> . </li><li>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Compute Library f√ºr tiefe neuronale Netze</a> . </li><li>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Math Kernel Library f√ºr tiefe neuronale Netze</a> . </li><li>  Ein Tool zur Optimierung neuronaler Netze f√ºr FPGA (optional). </li><li>  Dokumentations- und Beispielprogramme. </li></ol><br>  In meinen vorherigen Artikeln habe ich dar√ºber gesprochen, wie der YOLO-Gesichtsdetektor auf dem NCS ausgef√ºhrt wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(erster Artikel)</a> sowie wie Sie Ihren SSD-Gesichtsdetektor trainieren und auf dem Raspberry Pi und NCS ausf√ºhren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(zweiter Artikel)</a> .  In diesen Artikeln habe ich NCSDK und NCSDK2 verwendet.  In diesem Artikel werde ich Ihnen erkl√§ren, wie Sie etwas √Ñhnliches tun, aber mit OpenVINO werde ich einen kleinen Vergleich zwischen verschiedenen Gesichtsdetektoren und zwei Frameworks f√ºr deren Start durchf√ºhren und auf einige Fallstricke hinweisen.  Ich schreibe in C ++, weil ich glaube, dass Sie auf diese Weise eine bessere Leistung erzielen k√∂nnen, was im Fall von Raspberry Pi wichtig ist. <br><br><h3>  Installieren Sie OpenVINO </h3><br>  Nicht die schwierigste Aufgabe, obwohl es Feinheiten gibt.  Zum Zeitpunkt des Schreibens unterst√ºtzt OpenVINO nur Ubuntu 16.04 LTS, CentOS 7.4 und Windows 10. Ich habe Ubuntu 18 installiert und ben√∂tige <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kleine Kr√ºcken</a> , um es zu installieren.  Ich wollte OpenVINO auch mit NCSDK2 vergleichen, dessen Installation ebenfalls Probleme hat: Insbesondere werden die Versionen von Caffe und TensorFlow gestrafft und die Umgebungseinstellungen k√∂nnen leicht besch√§digt werden.  Am Ende entschied ich mich, einem einfachen Pfad zu folgen und beide Frameworks in einer virtuellen Maschine mit Ubuntu 16 zu installieren (ich verwende <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VirtualBox</a> ). <br><br>  Beachten Sie, dass Sie zum erfolgreichen Verbinden von NCS mit einer virtuellen Maschine VirtualBox-Gast-Add-Ons installieren und die USB 3.0-Unterst√ºtzung aktivieren m√ºssen.  Ich habe auch einen Universalfilter f√ºr USB-Ger√§te hinzugef√ºgt, wodurch das NCS problemlos verbunden wurde (obwohl die Webcam in den Einstellungen der virtuellen Maschine noch angeschlossen werden muss).  Um OpenVINO zu installieren und zu kompilieren, ben√∂tigen Sie ein Intel-Konto, w√§hlen Sie eine Framework-Option (mit oder ohne FPGA-Unterst√ºtzung) und befolgen Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anweisungen</a> .  NCSDK ist noch einfacher: Es startet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von GitHub</a> (vergessen Sie nicht, den Zweig ncsdk2 f√ºr die neue Version des Frameworks auszuw√§hlen). Danach m√ºssen Sie <code>make install</code> . <br><br>  Das einzige Problem, auf das ich beim Ausf√ºhren von NCSDK2 in einer virtuellen Maschine gesto√üen bin, ist ein Fehler der folgenden Form: <br><br><pre> <code class="plaintext hljs">E: [ 0] dispatcherEventReceive:236 dispatcherEventReceive() Read failed -1 E: [ 0] eventReader:254 Failed to receive event, the device may have reset</code> </pre><br>  Es tritt am Ende der korrekten Ausf√ºhrung des Programms auf und hat (wie es scheint) keine Auswirkungen.  Anscheinend ist dies ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kleiner Fehler im Zusammenhang mit VM</a> (dies sollte nicht auf Raspberry sein). <br><br>  Die Installation auf dem Raspberry Pi unterscheidet sich erheblich.  Stellen Sie zun√§chst sicher, dass Sie Raspbian Stretch installiert haben: Beide Frameworks funktionieren offiziell nur auf diesem Betriebssystem.  NCSDK2 muss <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im Nur-API-Modus kompiliert werden</a> , andernfalls wird versucht, Caffe und TensorFlow zu installieren, was Ihrer Himbeere wahrscheinlich nicht gef√§llt.  Im Fall von OpenVINO gibt es eine bereits <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zusammengestellte Version f√ºr Raspberry</a> , die Sie nur zum Entpacken und Konfigurieren der Umgebungsvariablen ben√∂tigen.  In dieser Version gibt es nur die C ++ - und Python-API sowie die OpenCV-Bibliothek, alle anderen Tools sind nicht verf√ºgbar.  Dies bedeutet, dass f√ºr beide Frameworks Modelle auf einem Computer mit Ubuntu im Voraus konvertiert werden m√ºssen.  Meine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichtserkennungsdemo</a> funktioniert sowohl auf Raspberry als auch auf dem Desktop. Daher habe ich die konvertierten neuronalen Netzwerkdateien meinem GitHub-Repository hinzugef√ºgt, um die Synchronisierung mit Raspberry zu vereinfachen.  Ich habe ein Raspberry Pi 2 Modell B, aber es sollte mit anderen Modellen abheben. <br><br>  Es gibt noch eine weitere Feinheit in Bezug auf das Zusammenspiel von Raspberry Pi und Neural Compute Stick: Wenn es bei einem Laptop ausreicht, das NCS nur in den n√§chsten USB 3.0-Anschluss zu stecken, m√ºssen Sie f√ºr Raspberry ein USB-Kabel finden, andernfalls blockiert NSC die verbleibenden drei USB-Anschl√ºsse mit seinem Geh√§use.  Es ist auch zu beachten, dass Raspberry √ºber alle USB 2.0-Versionen verf√ºgt, sodass die Inferenzrate aufgrund von Kommunikationsverz√∂gerungen geringer ist (ein detaillierter Vergleich wird sp√§ter erfolgen).  Wenn Sie jedoch zwei oder mehr NCS an Raspberry anschlie√üen m√∂chten, m√ºssen Sie h√∂chstwahrscheinlich einen USB-Hub mit zus√§tzlicher Stromversorgung finden. <br><br><h3>  Wie sieht OpenVINO-Code aus? </h3><br>  Ziemlich sperrig.  Es gibt viele verschiedene Aktionen, angefangen beim Laden des Plug-Ins bis hin zur Inferenz selbst. Deshalb habe ich eine Wrapper-Klasse f√ºr den Detektor geschrieben.  Der vollst√§ndige Code kann auf GitHub angezeigt werden, aber hier liste ich nur die wichtigsten Punkte auf.  Beginnen wir in der richtigen Reihenfolge: <br><br>  Die Definitionen aller ben√∂tigten Funktionen befinden sich in der Datei <code>inference_engine.hpp</code> im <code>InferenceEngine</code> Namespace. <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;inference_engine.hpp&gt; using namespace InferenceEngine;</span></span></span></span></code> </pre><br>  Die folgenden Variablen werden st√§ndig ben√∂tigt.  Wir ben√∂tigen <code>inputName</code> und <code>outputName</code> , um die Eingabe und Ausgabe des neuronalen Netzwerks zu adressieren.  Im Allgemeinen kann ein neuronales Netzwerk viele Ein- und Ausg√§nge haben, aber in unseren Detektoren gibt es jeweils einen.  Das variable <code>net</code> ist das Netzwerk selbst, die <code>request</code> ist ein Zeiger auf die letzte Inferenzanforderung, <code>inputBlob</code> ist ein Zeiger auf das Eingabedatenarray des neuronalen Netzwerks.  Die √ºbrigen Variablen sprechen f√ºr sich. <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">string</span></span> inputName; <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> outputName; ExecutableNetwork net; InferRequest::Ptr request; Blob::Ptr inputBlob; <span class="hljs-comment"><span class="hljs-comment">//input shape int netInputWidth; int netInputHeight; int netInputChannels; //output shape int maxNumDetectedFaces; //return code StatusCode ncsCode;</span></span></code> </pre><br>  Laden Sie jetzt das erforderliche Plugin herunter - wir ben√∂tigen das f√ºr NCS und NCS2 zust√§ndige, es kann unter dem Namen "MYRIAD" bezogen werden.  Ich m√∂chte Sie daran erinnern, dass ein Plugin im Kontext von OpenVINO nur eine dynamische Bibliothek ist, die auf ausdr√ºckliche Anfrage eine Verbindung herstellt.  Der Parameter der <code>PluginDispatcher</code> Funktion ist eine Liste von Verzeichnissen, in denen nach Plugins <code>PluginDispatcher</code> werden soll.  Wenn Sie die Umgebungsvariablen gem√§√ü den Anweisungen einrichten, reicht eine leere Zeile aus.  Als Referenz befinden sich Plugins in <code>[OpenVINO_install_dir]/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/</code> <br><br><pre> <code class="cpp hljs">InferencePlugin plugin = PluginDispatcher({<span class="hljs-string"><span class="hljs-string">""</span></span>}).getPluginByDevice(<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>);</code> </pre><br>  Erstellen Sie nun ein Objekt zum Laden des neuronalen Netzwerks, ber√ºcksichtigen Sie dessen Beschreibung und legen Sie die Gr√∂√üe des Stapels fest (die Anzahl der gleichzeitig verarbeiteten Bilder).  Ein neuronales Netzwerk im OpenVINO-Format wird durch zwei Dateien definiert: eine XML-Datei mit einer Beschreibung der Struktur und eine Bin-Datei mit Gewichten.  W√§hrend wir vorgefertigte Detektoren von OpenVINO verwenden, werden wir sp√§ter unsere eigenen erstellen.  Hier ist <code>std::string filename</code> der Name der Datei ohne die Erweiterung.  Beachten Sie au√üerdem, dass das NCS nur eine Stapelgr√∂√üe von 1 unterst√ºtzt. <br><br><pre> <code class="cpp hljs">CNNNetReader netReader; netReader.ReadNetwork(filename+<span class="hljs-string"><span class="hljs-string">".xml"</span></span>); netReader.ReadWeights(filename+<span class="hljs-string"><span class="hljs-string">".bin"</span></span>); netReader.getNetwork().setBatchSize(<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br>  Dann passiert folgendes: <br><br><ol><li>  Um in das neuronale Netzwerk einzutreten, setzen Sie den Datentyp auf vorzeichenloses 8-Bit-Zeichen.  Dies bedeutet, dass wir das Bild in dem Format eingeben k√∂nnen, in dem es von der Kamera stammt, und InferenceEngine sich um die Konvertierung k√ºmmert (NCS f√ºhrt Berechnungen im Float-16-Bit-Format durch).  Dies beschleunigt sich auf dem Raspberry Pi etwas - so wie ich es verstehe, erfolgt die Konvertierung auf dem NCS, sodass die Daten√ºbertragung √ºber USB weniger verz√∂gert wird. </li><li>  Wir erhalten die Eingabe- und Ausgabenamen, damit wir sp√§ter darauf zugreifen k√∂nnen. </li><li>  Wir erhalten die Beschreibung der Ausgaben (dies ist eine Zuordnung vom Namen der Ausgabe zu einem Zeiger auf einen Datenblock).  Wir erhalten einen Zeiger auf den Datenblock der ersten (einzelnen) Ausgabe. </li><li>  Wir erhalten seine Gr√∂√üe: 1 x 1 x maximale Anzahl von Erkennungen x L√§nge der Beschreibung der Erkennung (7).  √úber das Format der Beschreibung von Erkennungen - sp√§ter. </li><li>  Stellen Sie das Ausgabeformat auf 32 Bit ein.  Auch hier k√ºmmert sich die Konvertierung von Float 16 Bit um InferenceEngine. </li></ol><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//we can set input type to unsigned char: conversion will be performed on device netReader.getNetwork().getInputsInfo().begin()-&gt;second-&gt;setPrecision(Precision::U8); //get input and output names and their info structures inputName = netReader.getNetwork().getInputsInfo().begin()-&gt;first; outputName = netReader.getNetwork().getOutputsInfo().begin()-&gt;first; OutputsDataMap outputInfo(netReader.getNetwork().getOutputsInfo()); InputsDataMap inputInfo(netReader.getNetwork().getInputsInfo()); DataPtr &amp;outputData = (outputInfo.begin()-&gt;second); //get output shape: (1 x 1 x maxNumDetectedFaces x faceDescriptionLength(7)) const SizeVector outputDims = outputData-&gt;getTensorDesc().getDims(); maxNumDetectedFaces = outputDims[2]; //set input type to float32: calculations are all in float16, conversion is performed on device outputData-&gt;setPrecision(Precision::FP32);</span></span></code> </pre><br>  Nun der wichtigste Punkt: Wir laden das neuronale Netzwerk in das Plugin (dh in NCS).  Anscheinend ist das Kompilieren im gew√ºnschten Format im laufenden Betrieb.  Wenn das Programm bei dieser Funktion abst√ºrzt, ist das neuronale Netzwerk wahrscheinlich nicht f√ºr dieses Ger√§t geeignet. <br><br><pre> <code class="cpp hljs">net = plugin.LoadNetwork(netReader.getNetwork(), {});</code> </pre><br>  Und schlie√ülich - wir werden Versuchsschluss ziehen und die Eingabegr√∂√üen ermitteln (m√∂glicherweise kann dies eleganter erfolgen).  Zuerst √∂ffnen wir eine Inferenzanforderung, dann erhalten wir daraus einen Link zum Eingabedatenblock, und wir fordern bereits die Gr√∂√üe von ihm an. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//perform single inference to get input shape (a hack) request = net.CreateInferRequestPtr(); //open inference request //we need the blob size: (batch(1) x channels(3) x H x W) inputBlob = request-&gt;GetBlob(inputName); SizeVector blobSize = inputBlob-&gt;getTensorDesc().getDims(); netInputWidth = blobSize[3]; netInputHeight = blobSize[2]; netInputChannels = blobSize[1]; request-&gt;Infer(); //close request</span></span></code> </pre><br>  Versuchen wir, ein Bild in NCS hochzuladen.  Auf die gleiche Weise erstellen wir eine Inferenzanforderung, erhalten daraus einen Zeiger auf einen Datenblock und von dort einen Zeiger auf das Array selbst.  Als n√§chstes kopieren Sie einfach die Daten aus unserem Bild (hier sind sie bereits auf die gew√ºnschte Gr√∂√üe reduziert).  Es ist erw√§hnenswert, dass in <code>cv::Mat</code> und <code>inputBlob</code> Messungen in unterschiedlicher Reihenfolge gespeichert werden (in OpenCV √§ndert sich der Kanalindex schneller als alle, in OpenVINO ist er langsamer als alle), daher ist memcpy unverzichtbar.  Dann beginnen wir mit der asynchronen Inferenz. <br><br>  Warum asynchron?  Dadurch wird die Ressourcenzuweisung optimiert.  W√§hrend das NCS das neuronale Netzwerk ber√ºcksichtigt, k√∂nnen Sie den n√§chsten Frame verarbeiten - dies f√ºhrt zu einer sp√ºrbaren Beschleunigung des Raspberry Pi. <br><br><pre> <code class="cpp hljs">cv::Mat data; ... <span class="hljs-comment"><span class="hljs-comment">//get image somehow //create request, get data blob request = net.CreateInferRequestPtr(); inputBlob = request-&gt;GetBlob(inputName); unsigned char* blobData = inputBlob-&gt;buffer().as&lt;unsigned char*&gt;(); //copy from resized frame to network input int wh = netInputHeight*netInputWidth; for (int c = 0; c &lt; netInputChannels; c++) for (int h = 0; h &lt; wh; h++) blobData[c * wh + h] = data.data[netInputChannels*h + c]; //start asynchronous inference request-&gt;StartAsync();</span></span></code> </pre><br>  Wenn Sie mit neuronalen Netzen gut vertraut sind, haben Sie m√∂glicherweise eine Frage, an welchem ‚Äã‚ÄãPunkt wir die Werte der Eingangspixel des neuronalen Netzes skalieren (zum Beispiel bringen wir sie in den Bereich <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> [0,1] </script>  )  Tatsache ist, dass diese Transformation in OpenVINO-Modellen bereits in der Beschreibung des neuronalen Netzwerks enthalten ist, und wenn wir unseren Detektor verwenden, werden wir etwas √Ñhnliches tun.  Und da sowohl die Konvertierung in Float als auch die Skalierung von Eingaben von OpenVINO durchgef√ºhrt werden, m√ºssen wir nur die Gr√∂√üe des Bildes √§ndern. <br><br>  Jetzt (nach einigen n√ºtzlichen Arbeiten) werden wir die Inferenzanfrage vervollst√§ndigen.  Das Programm wird blockiert, bis die Ausf√ºhrungsergebnisse vorliegen.  Wir bekommen einen Zeiger auf das Ergebnis. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> * output; ncsCode = request-&gt;Wait(IInferRequest::WaitMode::RESULT_READY); output = request-&gt;GetBlob(outputName)-&gt;buffer().as&lt;<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*&gt;();</code> </pre><br>  Jetzt ist es an der Zeit zu √ºberlegen, in welchem ‚Äã‚ÄãFormat das NCS das Ergebnis des Detektors zur√ºckgibt.  Es ist erw√§hnenswert, dass sich das Format geringf√ºgig von dem bei Verwendung von NCSDK unterscheidet.  Im Allgemeinen ist der Detektorausgang vierdimensional und hat eine Dimension (1 x 1 x maximale Anzahl von Erkennungen x 7). Wir k√∂nnen davon ausgehen, dass dies ein Array der Gr√∂√üe ist ( <code>maxNumDetectedFaces</code> x 7). <br><br>  Der Parameter <code>maxNumDetectedFaces</code> wird in der Beschreibung des neuronalen Netzwerks festgelegt und kann leicht ge√§ndert werden, z. B. in der .prototxt-Beschreibung des Netzwerks im Caffe-Format.  Fr√ºher haben wir es von dem Objekt bekommen, das den Detektor darstellt.  Dieser Parameter bezieht sich auf die Besonderheiten der Klasse der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SSD-</a> Detektoren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(Single Shot Detector)</a> , die alle unterst√ºtzten NCS-Detektoren umfasst.  Eine SSD ber√ºcksichtigt immer die gleiche (und sehr gro√üe) Anzahl von Begrenzungsrahmen f√ºr jedes Bild. Nach dem Herausfiltern von Erkennungen mit niedriger Konfidenzbewertung und dem Entfernen √ºberlappender Frames mithilfe der nicht maximalen Unterdr√ºckung belassen sie normalerweise die 100-200 besten Werte.  Genau daf√ºr ist der Parameter verantwortlich. <br><br>  Die sieben Werte in der Beschreibung einer Erkennung lauten wie folgt: <br><br><ol><li>  die Bildnummer in dem Stapel, auf dem das Objekt erkannt wird (in unserem Fall sollte sie Null sein); </li><li>  Objektklasse (0 - Hintergrund, beginnend mit 1 - andere Klassen, nur Erkennungen mit einer positiven Klasse werden zur√ºckgegeben); </li><li>  Vertrauen in das Vorhandensein von Erkennung (im Bereich <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> [0,1] </script>  ); </li><li>  normalisierte x-Koordinate der oberen linken Ecke des Begrenzungsrahmens (im Bereich) <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> [0,1] </script>  ); </li><li>  √§hnlich - y-Koordinate; </li><li>  normalisierte Begrenzungsrahmenbreite (im Bereich <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-4"> [0,1] </script>  ); </li><li>  ebenfalls - H√∂he; </li></ol><br><div class="spoiler">  <b class="spoiler_title">Code zum Extrahieren von Begrenzungsrahmen aus der Detektorausgabe</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_detection_boxes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">* predictions, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> numPred, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> w, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> h, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> thresh, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt;&amp; probs, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;cv::Rect&gt;&amp; boxes)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> score = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cls = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> id = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//predictions holds numPred*7 values //data format: image_id, detection_class, detection_confidence, //box_normed_x, box_normed_y, box_normed_w, box_normed_h for (int i=0; i&lt;numPred; i++) { score = predictions[i*7+2]; cls = predictions[i*7+1]; id = predictions[i*7 ]; if (id&gt;=0 &amp;&amp; score&gt;thresh &amp;&amp; cls&lt;=1) { probs.push_back(score); boxes.push_back(Rect(predictions[i*7+3]*w, predictions[i*7+4]*h, (predictions[i*7+5]-predictions[i*7+3])*w, (predictions[i*7+6]-predictions[i*7+4])*h)); } } }</span></span></code> </pre><br>  Wir lernen <code>numPred</code> vom Detektor selbst und <code>w,h</code> - Bildgr√∂√üen zur Visualisierung. <br></div></div><br>  Nun dazu, wie das allgemeine Inferenzschema in Echtzeit aussieht.  Zuerst initialisieren wir das neuronale Netzwerk und die Kamera, starten <code>cv::Mat</code> f√ºr Rohbilder und eines f√ºr Bilder, die auf die gew√ºnschte Gr√∂√üe reduziert sind.  Wir f√ºllen unsere Frames mit Nullen - dies erh√∂ht die Sicherheit, dass das neuronale Netzwerk bei einem einzigen Start nichts findet.  Dann starten wir den Inferenzzyklus: <br><br><ul><li>  Wir laden den aktuellen Frame mithilfe einer asynchronen Anforderung in das neuronale Netzwerk - NCS hat bereits begonnen zu arbeiten, und zu diesem Zeitpunkt haben wir die M√∂glichkeit, n√ºtzliche Arbeit zum Hauptprozessor zu machen. </li><li>  Wir zeigen alle vorherigen Erkennungen im vorherigen Frame an und zeichnen einen Frame (falls erforderlich). </li><li>  Wir bekommen einen neuen Rahmen von der Kamera, komprimieren ihn auf die gew√ºnschte Gr√∂√üe.  F√ºr Raspberry empfehle ich die Verwendung des einfachsten Gr√∂√üen√§nderungsalgorithmus - in OpenCV ist dies die Interpolation der n√§chsten Nachbarn.  Dies hat keinen Einfluss auf die Qualit√§t der Detektorleistung, kann jedoch die Geschwindigkeit erh√∂hen.  Ich spiegele auch den Rahmen f√ºr eine einfache Visualisierung (optional). </li><li>  Jetzt ist es an der Zeit, das Ergebnis mit NCS zu erhalten, indem Sie die Inferenzanforderung abschlie√üen.  Das Programm wird blockiert, bis das Ergebnis eingeht. </li><li>  Wir verarbeiten neue Erkennungen, w√§hlen Frames aus. </li><li>  Der Rest: Tastenanschl√§ge trainieren, Frames z√§hlen usw. </li></ul><br><h3>  Wie man es kompiliert </h3><br>  In den InferenceEngine-Beispielen haben mir die umfangreichen CMake-Dateien nicht gefallen, und ich habe beschlossen, alles kompakt in mein Makefile umzuschreiben: <br><br><pre> <code class="bash hljs">g++ $(RPI_ARCH) \ -I/usr/include -I. \ -I$(OPENVINO_PATH)/deployment_tools/inference_engine/include \ -I$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/include \ -L/usr/lib/x86_64-linux-gnu \ -L/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/lib \ -L$(OPENVINO_PATH)/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 \ -L$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/lib/raspbian_9/armv7l \ vino.cpp wrapper/vino_wrapper.cpp \ -o demo -std=c++11 \ `pkg-config opencv --cflags --libs` \ -ldl -linference_engine $(RPI_LIBS)</code> </pre><br>  Dieses Team wird dank einiger Tricks sowohl an Ubuntu als auch an Raspbian arbeiten.  Die Pfade f√ºr die Suche nach Headern und dynamischen Bibliotheken habe ich sowohl f√ºr Raspberry als auch f√ºr die Ubuntu-Maschine angegeben.  Von den Bibliotheken m√ºssen Sie neben OpenCV auch <code>libinference_engine</code> und <code>libdl</code> - eine Bibliothek zum dynamischen Verkn√ºpfen anderer Bibliotheken, die zum Laden des Plugins ben√∂tigt wird.  Gleichzeitig muss <code>libmyriadPlugin</code> selbst nicht angegeben werden.  Unter anderem verbinde ich f√ºr Raspberry auch die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raspicam-</a> Bibliothek f√ºr die Arbeit mit der Kamera (dies ist <code>$(RPI_LIBS)</code> ).  Ich musste auch den C ++ 11 Standard verwenden. <br><br>  <code>-march=armv7-a</code> davon ist zu beachten, dass beim Kompilieren auf Raspberry das <code>-march=armv7-a</code> ben√∂tigt wird (dies ist <code>$(RPI_ARCH)</code> ).  Wenn Sie es nicht angeben, wird das Programm kompiliert, st√ºrzt jedoch mit einem stillen Segfault ab.  Sie k√∂nnen auch Optimierungen mit <code>-O3</code> hinzuf√ºgen, um die Geschwindigkeit zu erh√∂hen. <br><br><h3>  Was sind die Detektoren </h3><br>  NCS unterst√ºtzt nur Caffe SSD-Detektoren aus der Box, obwohl ich es mit ein paar schmutzigen Tricks geschafft habe, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">YOLO im Darknet-Format</a> darauf auszuf√ºhren.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Single Shot Detector (SSD)</a> ist eine beliebte Architektur unter leichten neuronalen Netzen. Mithilfe verschiedener Encoder (oder Backbone-Netze) k√∂nnen Sie das Verh√§ltnis von Geschwindigkeit und Qualit√§t sehr flexibel variieren. <br><br>  Ich werde mit verschiedenen Gesichtsdetektoren experimentieren: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Von hier</a> √ºbernommen wurde YOLO zuerst in das Caffe-Format und dann in das NCS-Format konvertiert (nur mit NCSDK).  Bild 448 x 448. </li><li>  Mein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mobilenet</a> + SSD-Detektor, √ºber dessen Training ich in einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fr√ºheren Ver√∂ffentlichung gesprochen habe</a> .  Ich habe immer noch eine beschnittene Version dieses Detektors, der nur kleine Gesichter sieht und gleichzeitig etwas schneller ist.  Ich werde die Vollversion meines Detektors sowohl auf NCSDK als auch auf OpenVINO √ºberpr√ºfen.  Bild 300 x 300. </li><li>  Detektor Gesichtserkennung-adas-0001 von OpenVINO: MobileNet + SSD.  Bild 384 x 672. </li><li>  OpenVINO Gesichtserkennungs-Retail-0004-Detektor: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Leichtes SqueezeNet</a> + SSD.  Bild 300 x 300. </li></ul><br>  F√ºr Detektoren von OpenVINO gibt es weder im Caffe-Format noch im NCSDK-Format Skalen, daher kann ich sie nur in OpenVINO starten. <br><br><h3>  Verwandeln Sie Ihren Detektor in das OpenVINO-Format </h3><br>  Ich habe zwei Dateien im Caffe-Format: .prototxt mit einer Beschreibung des Netzwerks und .caffemodel mit Gewichten.  Ich muss zwei Dateien im OpenVINO-Format von ihnen erhalten: .xml und .bin mit einer Beschreibung bzw. Gewichtung.  Verwenden Sie dazu das Skript mo.py von OpenVINO (auch bekannt als Model Optimizer): <br><br><pre> <code class="bash hljs">mo.py \ --framework caffe \ --input_proto models/face/ssd-face.prototxt \ --input_model models/face/ssd-face.caffemodel \ --output_dir models/face \ --model_name ssd-vino-custom \ --mean_values [127.5,127.5,127.5] \ --scale_values [127.5,127.5,127.5] \ --data_type FP16</code> </pre><br>  <code>output_dir</code> gibt das Verzeichnis an, in dem neue Dateien erstellt werden. <code>model_name</code> ist der Name f√ºr neue Dateien ohne Erweiterung. <code>data_type (FP16/FP32)</code> ist die Art des Guthabens im neuronalen Netzwerk (NCS unterst√ºtzt nur FP16).  Die <code>mean_values, scale_values</code> legen den Durchschnitt und die Skalierung f√ºr die Vorverarbeitung der Bilder fest, bevor sie in das neuronale Netzwerk gestartet werden.  Die spezifische Konvertierung sieht folgenderma√üen aus: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>P</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><msub><mtext>&amp;#xA0;</mtext><mi>W</mi></msub><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi><mo>&amp;#x2212;</mo><mi>M</mi><mi>i</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>l</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>t</mi><msub><mtext>&amp;#xA0;</mtext><mi>W</mi></msub><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi><mo stretchy=&quot;false&quot;>)</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>/</mo></mrow><mi>S</mi><mi>k</mi><mi>a</mi><mi>l</mi><mi>a</mi><msub><mtext>&amp;#xA0;</mtext><mi>W</mi></msub><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="48.437ex" height="2.66ex" viewBox="0 -832 20854.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-28" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-50" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-69" x="1141" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-78" x="1486" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="2059" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-6C" x="2525" y="0"></use><g transform="translate(2824,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-57" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="3915" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-72" x="4381" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-74" x="4833" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="5194" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2212" x="5883" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-4D" x="6884" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-69" x="7935" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-74" x="8281" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-74" x="8642" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="9004" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-6C" x="9470" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-77" x="9769" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="10485" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-72" x="10952" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-74" x="11403" y="0"></use><g transform="translate(11765,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-57" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="12856" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-72" x="13323" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-74" x="13774" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="14136" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-29" x="14602" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2F" x="14992" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-53" x="15492" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-6B" x="16138" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-61" x="16659" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-6C" x="17189" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-61" x="17487" y="0"></use><g transform="translate(18017,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-57" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="19108" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-72" x="19575" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-74" x="20026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMATHI-65" x="20388" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mo stretchy="false">(</mo><mi>P</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><msub><mtext>&nbsp;</mtext><mi>W</mi></msub><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi><mo>‚àí</mo><mi>M</mi><mi>i</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>l</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>t</mi><msub><mtext>&nbsp;</mtext><mi>W</mi></msub><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mi>S</mi><mi>k</mi><mi>a</mi><mi>l</mi><mi>a</mi><msub><mtext>&nbsp;</mtext><mi>W</mi></msub><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> (Pixel \ _Werte - Mittelwert \ _Werte) / Skala \ _Werte </script></p><br><br>  In diesem Fall werden die Werte aus dem Bereich konvertiert <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>255</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.977ex" height="2.66ex" viewBox="0 -832 3004.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2C" x="779" y="0"></use><g transform="translate(1224,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-32"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-35" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-35" x="1001" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5D" x="2725" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>255</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-6"> [0,255] </script>  in Reichweite <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhgeycfwOrEQkO8r_zj_MhUSUbcV3g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-7"> [0,1] </script>  .  Im Allgemeinen enth√§lt dieses Skript viele Parameter, von denen einige f√ºr einzelne Frameworks spezifisch sind. Ich empfehle, dass Sie sich das Handbuch f√ºr das Skript ansehen. <br><br>  Die OpenVINO-Distribution f√ºr Raspberry enth√§lt keine vorgefertigten Modelle, sie sind jedoch recht einfach herunterzuladen. <br><br><div class="spoiler">  <b class="spoiler_title">Zum Beispiel so.</b> <div class="spoiler_text"><pre> <code class="bash hljs"> wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.xml \ -O ./models/face/vino.xml; \ wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.bin \ -O ./models/face/vino.bin</code> </pre><br></div></div><br><h3>  Vergleich von Detektoren und Frameworks </h3><br>  Ich habe drei Vergleichsoptionen verwendet: 1) NCS + Virtual Machine mit Ubuntu 16.04, Core i7-Prozessor, USB 3.0-Anschluss;  2) NCS + Dieselbe Maschine, USB 3.0-Anschluss + USB 2.0-Kabel (der Austausch mit dem Ger√§t verz√∂gert sich l√§nger);  3) NCS + Raspberry Pi 2 Modell B, Raspbian Stretch, USB 2.0-Anschluss + USB 2.0-Kabel. <br><br>  Ich habe meinen Detektor sowohl mit OpenVINO als auch mit NCSDK2 gestartet, Detektoren von OpenVINO nur mit ihrem nativen Framework, YOLO nur mit NCSDK2 (h√∂chstwahrscheinlich kann er auch unter OpenVINO ausgef√ºhrt werden). <br><br>  Die FPS-Tabelle f√ºr verschiedene Detektoren sieht folgenderma√üen aus (die Zahlen sind ungef√§hr): <br><br><table><tbody><tr><th>  Modell </th><th>  USB 3.0 </th><th>  USB 2.0 </th><th>  Himbeer pi </th></tr><tr><td>  Benutzerdefinierte SSD mit NCSDK2 </td><td>  10.8 </td><td>  9.3 </td><td>  7.2 </td></tr><tr><td>  Benutzerdefinierte Langstrecken-SSD mit NCSDK2 </td><td>  11.8 </td><td>  10.0 </td><td>  7.3 </td></tr><tr><td>  YOLO v2 mit NCSDK2 </td><td>  5.3 </td><td>  4.6 </td><td>  3.6 </td></tr><tr><td>  Benutzerdefinierte SSD mit OpenVINO </td><td>  10.6 </td><td>  9.9 </td><td>  7.9 </td></tr><tr><td>  OpenVINO Gesichtserkennung-Einzelhandel-0004 </td><td>  15.6 </td><td>  14.2 </td><td>  9.3 </td></tr><tr><td>  OpenVINO Gesichtserkennung-adas-0001 </td><td>  5.8 </td><td>  5.5 </td><td>  3.9 </td></tr></tbody></table><br><br>  <em>Hinweis: Die Leistung wurde f√ºr das gesamte Demo-Programm gemessen, einschlie√ülich der Verarbeitung und Visualisierung von Frames.</em> <br><br>  YOLO war der langsamste und instabilste von allen.  Es √ºberspringt sehr oft die Erkennung und kann nicht mit beleuchteten Rahmen arbeiten. <br><br>  Der von mir trainierte Detektor arbeitet doppelt so schnell, ist widerstandsf√§higer gegen Bildverzerrungen und erkennt sogar kleine Gesichter.  Manchmal wird jedoch die Erkennung √ºbersprungen und manchmal werden falsche erkannt.  Wenn Sie die letzten Schichten davon abschneiden, wird es etwas schneller, aber es werden keine gro√üen Gesichter mehr angezeigt.  Derselbe √ºber OpenVINO gestartete Detektor wird bei Verwendung von USB 2.0 etwas schneller, die Qualit√§t √§ndert sich optisch nicht. <br><br>  Die OpenVINO-Detektoren sind nat√ºrlich sowohl YOLO als auch meinem Detektor weit √ºberlegen.  (Ich w√ºrde nicht einmal anfangen, meinen Detektor zu trainieren, wenn OpenVINO zu diesem Zeitpunkt in seiner aktuellen Form existieren w√ºrde).  Das Retail-0004-Modell ist deutlich schneller und verfehlt gleichzeitig praktisch nicht das Gesicht, aber ich habe es geschafft, es ein wenig zu t√§uschen (obwohl das Vertrauen in diese Erkennungen gering ist): <br><br><img src="https://habrastorage.org/webt/uj/ap/nl/ujapnlbjzkipljlzklgyvjzked4.png"><br>  <em>Wettbewerbsangriff der nat√ºrlichen Intelligenz auf k√ºnstliche</em> <br><br>  Der adas-0001-Detektor ist viel langsamer, funktioniert jedoch mit gro√üen Bildern und sollte genauer sein.  Ich habe den Unterschied nicht bemerkt, aber ich habe ziemlich einfache Frames √ºberpr√ºft. <br><br><h4>  Fazit </h4><br>  Im Allgemeinen ist es sehr sch√∂n, dass Sie auf einem Ger√§t mit geringem Stromverbrauch wie dem Raspberry Pi neuronale Netze verwenden k√∂nnen, und zwar fast in Echtzeit.  OpenVINO bietet sehr umfangreiche Funktionen f√ºr die Inferenz neuronaler Netze auf vielen verschiedenen Ger√§ten - viel breiter als im Artikel beschrieben.  Ich denke, Neural Compute Stick und OpenVINO werden in meiner Roboterforschung sehr n√ºtzlich sein. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de436744/">https://habr.com/ru/post/de436744/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de436720/index.html">Es gibt eine Meinung: IPv6 ist fehlgeschlagen - wer denkt das und warum?</a></li>
<li><a href="../de436722/index.html">Diagnostisches medizinisches Expertensystem zu Prolog</a></li>
<li><a href="../de436730/index.html">Unterhaltungselektronik Hall of Fame: Die Geschichten der besten Ger√§te der letzten 50 Jahre, Teil 5</a></li>
<li><a href="../de436740/index.html">Eigene Forschung, was k√∂nnen uns Open Source sagen?</a></li>
<li><a href="../de436742/index.html">Android Robotics bis 2019: Die wahre Geschichte; in 5 Teilen; Teil 1</a></li>
<li><a href="../de436746/index.html">So verschlechtern Sie die Leistung, indem Sie sie verbessern</a></li>
<li><a href="../de436748/index.html">Hexapod von Grund auf neu entwickeln (Teil 3) - Kinematik</a></li>
<li><a href="../de436750/index.html">Trendanalyse des russischen YouTube f√ºr 2018</a></li>
<li><a href="../de436752/index.html">Der Kuchen ist eine L√ºge</a></li>
<li><a href="../de436754/index.html">Q2VKPT: Quake II mit realistischer Beleuchtung komplett neu geschrieben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔚 ✊🏾 👶🏼 Die Architektur der künstlichen Intelligenz muss geändert werden 🏴󠁧󠁢󠁳󠁣󠁴󠁿 🤷🏼 🍣</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Verwendung der von Neumann-Architektur für Anwendungen mit künstlicher Intelligenz ist ineffizient. Was wird sie ersetzen? 
 Die Verwendung vorhan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Architektur der künstlichen Intelligenz muss geändert werden</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420943/"><h3>  Die Verwendung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von Neumann-Architektur</a> für Anwendungen mit künstlicher Intelligenz ist ineffizient.  Was wird sie ersetzen? </h3><br>  Die Verwendung vorhandener Architekturen zur Lösung der Probleme des maschinellen Lernens (MO) und der künstlichen Intelligenz (AI) ist unpraktisch geworden.  Der Energieverbrauch der KI ist erheblich gestiegen, und die CPU und die GPU scheinen zunehmend ungeeignete Werkzeuge für diese Arbeit zu sein. <br><br>  Die Teilnehmer mehrerer Symposien waren sich einig, dass sich die besten Möglichkeiten für signifikante Änderungen ergeben, wenn keine geerbten Merkmale vorhanden sind, die mitgeschleppt werden müssen.  Die meisten Systeme haben sich im Laufe der Zeit schrittweise weiterentwickelt - und selbst wenn dies einen sicheren Fortschritt gewährleistet, bietet ein solches Schema keine optimalen Lösungen.  Wenn etwas Neues auftaucht, wird es möglich, die Dinge neu zu betrachten und eine bessere Richtung zu wählen, als dies herkömmliche Technologien bieten.  Genau dies wurde kürzlich auf einer Konferenz diskutiert, auf der die Frage untersucht wurde, ob die komplementäre Metalloxid-Halbleiter-Struktur ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CMOS</a> ) die beste Basistechnologie ist, auf der es sich lohnt, AI-Anwendungen zu erstellen. <br><a name="habracut"></a><br>  Ein Chen, der von IBM zum Executive Director der Nanoelectronics Research Initiative (NRI) ernannt wurde, bereitete die Diskussion vor.  „Seit vielen Jahren erforschen wir neue, moderne Technologien, einschließlich der Suche nach einer Alternative zu CMOS, insbesondere aufgrund der Probleme im Zusammenhang mit dem Stromverbrauch und der Skalierung.  Nach all diesen Jahren hat sich die Meinung entwickelt, dass wir nichts Besseres als Grundlage für die Erstellung von Logikschaltungen gefunden haben.  Heutzutage konzentrieren sich viele Forscher auf KI, und sie bietet wirklich neue Denkweisen und neue Muster und sie haben neue technologische Produkte.  Werden neue KI-Geräte CMOS ersetzen können? “ <br><br><h2>  KI heute </h2><br>  Die meisten Anwendungen für MO und AI verwenden die von Neumann-Architektur.  "Es verwendet Speicher zum Speichern von Datenarrays und die CPU führt alle Berechnungen durch", erklärt Marvin Chen, Professor für Elektrotechnik an der Xinhua National University.  „Große Datenmengen bewegen sich über den Bus.  Heutzutage werden GPUs häufig auch für eingehende Schulungen verwendet, einschließlich Faltungsnetzwerke.  Eines der Hauptprobleme ist das Auftreten von Zwischendaten, die erforderlich sind, um Schlussfolgerungen zu ziehen.  Das Verschieben von Daten, insbesondere über den Chip hinaus, führt zu Energieverlust und Verzögerungen.  Dies ist ein Technologieengpass. “ <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7cd/968/73a/7cd96873afab685ee739ee78db59a7a8.png"><br>  <i>Für AI verwendete Architekturen</i> <br><br>  Was Sie heute brauchen, ist die Kombination von Datenverarbeitung und Speicher.  „Das Konzept des In-Memory-Computing wird seit vielen Jahren von Experten für Computerarchitektur vorgeschlagen“, sagt Chen.  - Es gibt verschiedene Schemata für SRAM und nichtflüchtigen Speicher, mit denen versucht wurde, ein solches Konzept zu verwenden und umzusetzen.  Wenn dies gelingt, können Sie im Idealfall viel Energie sparen, indem Sie die Datenübertragung zwischen CPU und Speicher eliminieren.  Das ist aber ideal. “ <br><br>  Aber für heute haben wir keine Berechnungen im Sinn.  "Wir haben immer noch AI 1.0 mit von Neumann-Architektur, weil Siliziumgeräte, die die Verarbeitung im Speicher implementieren, nie aufgetaucht sind", beklagt sich.  Chen  "Die einzige Möglichkeit, 3D-TSV in irgendeiner Weise zu verwenden, besteht darin, Hochgeschwindigkeitsspeicher mit der GPU zu verwenden, um das Bandbreitenproblem zu lösen."  Aber es bleibt immer noch ein Engpass für Energie und Zeit. " <br><br>  Wird es genügend Datenverarbeitung im Speicher geben, um das Problem des Energieverlusts zu lösen?  "Das menschliche Gehirn enthält hundert Milliarden Neuronen und 10 <sup>15</sup> Synapsen", sagte Sean Lee, stellvertretender Direktor der Taiwan Semiconductor Manufacturing Company.  "Schauen Sie sich jetzt IBM TrueNorth an."  TrueNorth ist ein Multi-Core-Prozessor, der 2014 von IBM entwickelt wurde. Er verfügt über 4.096 Kerne und jeweils 256 programmierbare künstliche Neuronen.  „Angenommen, wir möchten es skalieren und die Größe des Gehirns reproduzieren.  Die Differenz beträgt 5 Größenordnungen.  Wenn wir jedoch die Anzahl direkt erhöhen und TrueNorth multiplizieren und 65 mW verbrauchen, erhalten wir eine Maschine mit einem Verbrauch von 65 kW gegen das Gehirn einer Person, die 25 Watt verbraucht.  Der Verbrauch muss um mehrere Größenordnungen reduziert werden. " <br><br>  Lee bietet eine andere Möglichkeit, sich diese Gelegenheit vorzustellen.  "Der bisher effizienteste Supercomputer ist der Green500 aus Japan, der 17 Gflops pro Watt oder 1 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flop</a> bei 59 pJ ausgibt."  Auf der Green500-Website heißt es, dass das im japanischen Advanced Computing and Communications Center (RIKEN) installierte ZettaScaler-2.2-System während des Linpack-Testlaufs 18,4 Gflops / W gemessen hat, für den 858 TFlops erforderlich waren.  „Vergleichen Sie dies mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Landauer-Prinzip</a> , wonach bei Raumtemperatur die minimale Schaltenergie des Transistors in der Größenordnung von 2,75 zJ [10 <sup>-21</sup> J] liegt.  Auch hier beträgt der Unterschied mehrere Größenordnungen.  59 pJ ist ungefähr 10 <sup>-11</sup> gegenüber dem theoretischen Tief von ungefähr 10 <sup>-21</sup> .  Wir haben ein riesiges Forschungsfeld. " <br><br>  Ist es fair, solche Computer mit dem Gehirn zu vergleichen?  „Nachdem wir die jüngsten Erfolge einer eingehenden Ausbildung untersucht haben, werden wir feststellen, dass in den meisten Fällen Menschen und Maschinen in den letzten sieben Jahren in Folge miteinander konkurrieren“, sagt Kaushik Roy, emeritierter Professor für Elektrotechnik und Informatik an der Purdue University.  „1997 besiegte Deep Blue Kasparov, 2011 gewann IBM Watson das Spiel Jeopardy! Und 2016 besiegte Alpha Go Lee Sedola.  Dies sind die größten Erfolge.  Aber zu welchem ​​Preis?  Diese Maschinen verbrauchten 200 bis 300 kW.  Das menschliche Gehirn verbraucht etwa 20 Watt.  Riesige Lücke.  Woher kommt die Innovation? <br><br>  Im Mittelpunkt der meisten Anwendungen stehen MO und AI, die einfachsten Berechnungen, die in großem Maßstab durchgeführt werden.  „Wenn Sie das einfachste neuronale Netzwerk verwenden, führt es eine gewichtete Summierung durch, gefolgt von einer Schwellenwertoperation“, erklärt Roy.  - Dies kann in verschiedenen Arten von Matrizen erfolgen.  Es kann sich um ein Gerät aus der Spintronik oder einem resistiven Speicher handeln.  In diesem Fall werden die Eingangsspannung und die resultierende Leitfähigkeit jedem Schnittpunkt zugeordnet.  Am Ausgang erhalten Sie die Summe der Spannungen multipliziert mit der Leitfähigkeit.  Dies ist der Strom.  Dann können Sie ähnliche Geräte verwenden, die eine Schwellenwertoperation ausführen.  Architektur kann man sich als eine Ansammlung dieser Knoten vorstellen, die miteinander verbunden sind, um Berechnungen durchzuführen. “ <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b45/191/123/b45191123cc0afe303fe51cf0ae114e6.png"><br>  <i>Die Hauptkomponenten des neuronalen Netzwerks</i> <br><br><h2>  Neue Arten von Speicher </h2><br>  Die meisten potenziellen Architekturen sind mit neu auftretenden Arten von nichtflüchtigem Speicher verbunden.  "Was sind die wichtigsten Merkmale?"  „Fragt Jeffrey Barr, ein Forscher bei IBM Research.  „Ich würde einen nichtflüchtigen analogen Widerstandsspeicher wie einen Speicher mit Phasenwechsel, Memristoren usw. einsetzen.  Die Idee ist, dass diese Geräte alle Multiplikationen für vollständig verbundene Schichten neuronaler Netze in einem Zyklus ausführen können.  Bei einem Prozessorsatz kann dies eine Million Taktzyklen dauern, und bei einem analogen Gerät kann dies mithilfe der am Datenort arbeitenden Physik erfolgen.  Es gibt genug sehr interessante Aspekte in Bezug auf Zeit und Energie, damit sich aus dieser Idee etwas mehr entwickelt. " <br><br><img src="https://habrastorage.org/getpro/habr/post_images/68c/6e0/60b/68c6e060bf517fd1ac76b8ad79fdad3c.png"><br>  <i>Neue Speichertechnologien</i> <br><br>  Chen stimmt dem zu.  „PCM, STT hat ernsthafte Angebote zu gewinnen.  Diese drei Speichertypen sind gute Kandidaten für die Implementierung von In-Memory-Computing.  Sie sind zu grundlegenden logischen Operationen fähig.  Einige Arten haben Probleme mit der Zuverlässigkeit und können nicht für das Training verwendet werden, aber es ist möglich, eine Schlussfolgerung zu ziehen. " <br><br>  Es kann sich jedoch herausstellen, dass es nicht erforderlich ist, in diesen Speicher zu wechseln.  "Die Leute reden davon, SRAM genau für den gleichen Zweck zu verwenden", fügt Lee hinzu.  "Sie machen analoges Rechnen mit SRAM."  Der einzige Nachteil ist, dass der SRAM zu groß ist - 6 oder 8 Transistoren pro Bit.  Daher ist es keine Tatsache, dass wir diese neuen Technologien im analogen Rechnen einsetzen werden. “ <br><br>  Der Übergang zum analogen Rechnen impliziert auch, dass die Genauigkeit der Berechnungen keine Notwendigkeit mehr sein wird.  "AI ist spezialisiert, klassifiziert und prognostiziert", sagt er.  "Er trifft Entscheidungen, die unhöflich sein können."  In Sachen Genauigkeit können wir etwas aufgeben.  Wir müssen feststellen, welche Berechnungen fehlerresistent sind.  Dann können einige Technologien angewendet werden, um den Stromverbrauch zu reduzieren oder das Rechnen zu beschleunigen.  Probabilistische CMOS arbeiten seit 2003.  Dies beinhaltet das Verringern der Spannung bis zum Auftreten mehrerer Fehler, deren Anzahl tolerierbar bleibt.  Bereits heute verwenden die Menschen ungefähre Berechnungstechniken wie die Quantisierung.  Anstelle einer 32-Bit-Gleitkommazahl haben Sie 8-Bit-Ganzzahlen.  Analoge Computer sind ein weiteres bereits erwähntes Merkmal. “ <br><br><h2>  Verlasse das Labor </h2><br>  Die Verlagerung von Technologie aus dem Labor in die Öffentlichkeit kann eine Herausforderung sein.  "Manchmal muss man nach Alternativen suchen", sagt Barr.  - Als der zweidimensionale Flash-Speicher nicht gestartet wurde, schien der dreidimensionale Flash-Speicher keine so schwierige Aufgabe mehr zu sein.  Wenn wir vorhandene Technologien weiter verbessern, hier und dort eine Verdoppelung der Eigenschaften erzielen, werden die analogen Berechnungen im Speicher aufgegeben.  Wenn sich die folgenden Verbesserungen jedoch als unbedeutend herausstellen, sieht der analoge Speicher attraktiver aus.  Als Forscher müssen wir auf neue Möglichkeiten vorbereitet sein. “ <br><br>  Die Wirtschaft verlangsamt häufig die Entwicklung, insbesondere im Bereich des Gedächtnisses, aber Barr sagt, dass dies in diesem Fall nicht passieren wird.  „Einer unserer Vorteile ist, dass dieses Produkt nicht speicherbezogen ist.  Es wird nicht etwas mit geringfügigen Verbesserungen sein.  Dies ist kein Verbraucherprodukt.  Dies ist eine Sache, die mit der GPU konkurriert.  Sie werden zu einem Preis verkauft, der das 70-fache des DRAM-Preises beträgt. Es handelt sich also eindeutig um ein Nicht-Speicherprodukt.  Und die Kosten des Produkts unterscheiden sich nicht wesentlich vom Speicher.  Es hört sich gut an, aber wenn Sie Entscheidungen im Wert von Milliarden von Dollar treffen, sollten alle Kosten und der Produktentwicklungsplan glasklar sein.  Um diese Barriere zu überwinden, müssen wir beeindruckende Prototypen liefern. “ <br><br><h2>  CMOS-Ersatz </h2><br>  Die speicherinterne Datenverarbeitung kann beeindruckende Vorteile bieten, für die Implementierung der Technologie ist jedoch mehr erforderlich.  Kann irgendein anderes Material außer CMOS dabei helfen?  „Mit Blick auf den Übergang von verbrauchsarmen CMOS zu Tunnel-FETs sprechen wir von einer 1-2-fachen Verbrauchsreduzierung“, sagt Lee.  - Eine andere Möglichkeit sind dreidimensionale integrierte Schaltkreise.  Sie reduzieren die Kabellänge mit TSV.  Dies reduziert sowohl den Stromverbrauch als auch die Latenz.  Schauen Sie sich die Rechenzentren an, alle entfernen die Metallkabel und schließen die Optik an. " <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a95/b57/b95/a95b57b955aa7f86e612623ba201d926.jpg"><br>  <i>Vertikal - Stromverbrauch, horizontal - Geräteverzögerungen</i> <br><br>  Obwohl Sie einige Vorteile erzielen können, wenn Sie auf eine andere Technologie umsteigen, sind sie möglicherweise nicht wert.  "Es wird sehr schwierig sein, CMOS zu ersetzen, aber einige der besprochenen Geräte können die CMOS-Technologie ergänzen, sodass Berechnungen im Speicher durchgeführt werden", sagt Roy.  - CMOS kann speicherinterne Berechnungen in analoger Form unterstützen, möglicherweise in Zelle 8T.  Ist es möglich, eine Architektur mit einem klaren Vorteil gegenüber CMOS zu erstellen?  Wenn alles richtig gemacht ist, gibt mir CMOS tausendfach mehr Energieeffizienz.  Aber es braucht Zeit. “ <br><br>  CMOS wird eindeutig nicht ersetzt.  „Neue Technologien werden die alten nicht ablehnen und nicht auf anderen Substraten als CMOS hergestellt werden“, schließt Barr. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420943/">https://habr.com/ru/post/de420943/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420931/index.html">Wie man Kernkraftwerke testet</a></li>
<li><a href="../de420935/index.html">Alles, was Sie über die Ausrichtung in Flexbox wissen müssen</a></li>
<li><a href="../de420937/index.html">Über tragen SSD an realen Beispielen</a></li>
<li><a href="../de420939/index.html">Eine Geschichte über das Karrierewachstum oder warum ich mich als guten Manager betrachte</a></li>
<li><a href="../de420941/index.html">Blockchain P2P-Streitigkeiten</a></li>
<li><a href="../de420945/index.html">Erkundung neuer Welten mit dem Open ATV-Projekt der NASA</a></li>
<li><a href="../de420947/index.html">Auf die Frage nach Wellen, interessanten Menschen und Induktivitäten</a></li>
<li><a href="../de420951/index.html">Wie Yandex das Frontend vorbereitet. Vom Coursera-Programm bis zu Universitätskursen</a></li>
<li><a href="../de420955/index.html">Skyrmion-Anti-Skyrmion-Paar als mögliche Zukunft für die Datenspeicherung</a></li>
<li><a href="../de420957/index.html">Übersicht über den aktualisierten Sinterit Lisa 3D-Drucker und den neuen Sinterit Lisa 2 Pro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
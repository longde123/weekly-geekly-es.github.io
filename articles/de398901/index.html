<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💇 🍅 🗳️ Neuronales Netzwerk LipNet liest Lippen mit einer Genauigkeit von 93,4% 🍽️ 🗼 🤟🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Commander Dave Bowman und Co-Pilot Frank Poole, die dem Computer nicht vertrauten, beschlossen, ihn von der Kontrolle des Schiffes zu trennen. Dazu ko...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronales Netzwerk LipNet liest Lippen mit einer Genauigkeit von 93,4%</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/398901/"><img src="https://habrastorage.org/files/f5b/c98/b66/f5bc98b66e6b4c54a8b456037259caab.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Commander Dave Bowman und Co-Pilot Frank Poole, die dem Computer nicht vertrauten, beschlossen, ihn von der Kontrolle des Schiffes zu trennen. Dazu konferieren sie in einem schallisolierten Raum, aber HAL 9000 liest ihre Konversation auf den Lippen. </font></font><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aufnahme aus dem Film „Space Odyssey of 2001“</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Lippenlesen spielt eine wichtige Rolle in der Kommunikation. Weitere Experimente im Jahr 1976 zeigten, dass Menschen völlig </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unterschiedliche</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Phoneme </font><font style="vertical-align: inherit;">„hören“, </font><font style="vertical-align: inherit;">wenn Sie den falschen Klang auf die Bewegung der Lippen anwenden (siehe </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Lippen hören und Stimmen sehen“</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Nature 264, 746-748, 23. Dezember 1976, doi: 10.1038 / 264746a0). .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aus praktischer Sicht ist das Lippenlesen eine wichtige und nützliche Fähigkeit. Sie können den Gesprächspartner verstehen, ohne die Musik im Kopfhörer auszuschalten, die Gespräche aller Personen im Sichtfeld (z. B. aller Passagiere im Wartezimmer) lesen, Personen mit einem Fernglas oder einem Teleskop zuhören. Der Umfang der Fertigkeit ist sehr breit. Ein Profi, der es gemeistert hat, wird leicht einen gut bezahlten Job finden. Zum Beispiel im Bereich Sicherheit oder Competitive Intelligence.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Automatische Lippenlesesysteme haben auch ein großes praktisches Potenzial. Dies sind medizinische Hörgeräte der neuen Generation mit Spracherkennung, Systemen für stille Vorträge an öffentlichen Orten, biometrischer Identifizierung, Systemen für die geheime Übermittlung von Informationen für Spionage, Spracherkennung per Video von Überwachungskameras usw. Am Ende werden auch Computer der Zukunft Lippen lesen, wie der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HAL 9000</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Daher haben Wissenschaftler seit vielen Jahren versucht, automatische Lippenlesesysteme zu entwickeln, jedoch ohne großen Erfolg. Selbst für relativ einfaches Englisch, bei dem die Anzahl der Phoneme viel geringer ist als bei Russisch, ist die Erkennungsgenauigkeit gering.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Verstehen von Sprache basierend auf menschlichen Gesichtsausdrücken ist eine entmutigende Aufgabe. Menschen, die diese Fähigkeit beherrschen, versuchen, Dutzende von Konsonantenphonemen zu erkennen, von denen viele im Aussehen sehr ähnlich sind. Für eine nicht </font><font style="vertical-align: inherit;">geschulte </font><font style="vertical-align: inherit;">Person ist es besonders schwierig, zwischen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fünf Kategorien von visuellen Phonemen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (d. H. Visemen) der englischen Sprache zu unterscheiden. Mit anderen Worten, es ist fast unmöglich, die Aussprache einiger Konsonanten durch die Lippen zu unterscheiden. Es ist nicht überraschend, dass Menschen mit genauem Lippenlesen sehr schlecht abschneiden. Selbst die besten Hörgeschädigten weisen eine Genauigkeit von nur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">17 ± 12% von 30 einsilbigen oder 21 ± 11% der mehrsilbigen Wörter auf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (im Folgenden die Ergebnisse für die englische Sprache).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das automatische Ablesen der Lippen ist eine der Aufgaben der Bildverarbeitung, bei der es um die Einzelbildverarbeitung einer Videosequenz geht. Die Aufgabe wird durch die geringe Qualität der meisten praktischen Videomaterialien sehr kompliziert, die kein genaues Lesen des raumzeitlichen, d. H. Räumlich-zeitlichen Merkmals einer Person während eines Gesprächs ermöglichen. Gesichter bewegen sich und drehen sich in verschiedene Richtungen. Jüngste Entwicklungen auf dem Gebiet der Bildverarbeitung versuchen, die Bewegung des Gesichts im Rahmen zu verfolgen, um dieses Problem zu lösen. Trotz der Erfolge konnten sie bis vor kurzem nur einzelne Wörter, aber keine Sätze erkennen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein bedeutender Durchbruch in diesem Bereich wurde von Entwicklern der Universität Oxford erzielt. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das LipNet haben sie trainiert</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">war der erste auf der Welt, der Lippen auf der Ebene ganzer Sätze erfolgreich erkannte und Videomaterial verarbeitete. </font></font><br>
<br>
<img src="https://habrastorage.org/files/c91/f89/dae/c91f89daeefd4e0da9a55c41073a5285.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Frame-für-Frame- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Salience-Maps</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> für die englischen Wörter "Please" (oben) und "Lay" (unten), wenn sie von einem neuronalen Netzwerk verarbeitet werden, das Lippen liest, wobei die auffälligsten (hervorstechendsten) Merkmale von</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
LipNet hervorgehoben werden - ein wiederkehrendes neuronales Netzwerk vom Typ LSTM (Langzeit-Kurzzeitgedächtnis). Die Architektur ist in der Abbildung dargestellt. Das neuronale Netzwerk wurde mit der CTC-Methode (Connectionist Temporal Classification) trainiert, die in modernen Spracherkennungssystemen weit verbreitet ist, da kein Training für einen Satz von Eingabedaten erforderlich ist, die mit dem richtigen Ergebnis synchronisiert sind.</font></font><br>
<br>
<img src="https://habrastorage.org/files/856/4ac/a35/8564aca35bea4280bce7c669cce37fe2.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neuronale LipNet-Netzwerkarchitektur. </font><font style="vertical-align: inherit;">Am Eingang wird eine Folge von T-Frames geliefert, die dann von drei Schichten des raumzeitlichen (raumzeitlichen) Faltungs-Neuronalen Netzwerks (STCNN) verarbeitet werden, von denen jede von einer räumlichen Abtastschicht begleitet wird. </font><font style="vertical-align: inherit;">Für die extrahierten Merkmale wird die Abtastrate auf der Zeitachse erhöht (Upsampling), und dann werden sie durch doppeltes LTSM verarbeitet. </font><font style="vertical-align: inherit;">Jeder Zeitschritt am LTSM-Ausgang wird von einem zweischichtigen Direktverteilungsnetzwerk und der letzten SoftMax-Schicht verarbeitet.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In einem speziellen GRID-Angebotspaket weist das neuronale Netzwerk eine Erkennungsgenauigkeit von 93,4% auf. </font><font style="vertical-align: inherit;">Dies übertrifft nicht nur die Erkennungsgenauigkeit anderer Softwareentwicklungen (die in der folgenden Tabelle angegeben sind), sondern auch die Effizienz des Lesens auf den Lippen von speziell geschulten Personen.</font></font><br>
<br>
<table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Methode</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datensatz</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Größe</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problem</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Genauigkeit</font></font></th>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fu et al. </font><font style="vertical-align: inherit;">(2008)</font></font></td>
<td>AVICAR</td>
<td>851</td>
<td></td>
<td>37,9%</td>
</tr>
<tr>
<td>Zhao et al. (2009)</td>
<td>AVLetter</td>
<td>78</td>
<td></td>
<td>43,5%</td>
</tr>
<tr>
<td>Papandreou et al. (2009)</td>
<td>CUAVE</td>
<td>1800</td>
<td></td>
<td>83,0%</td>
</tr>
<tr>
<td>Chung &amp; Zisserman (2016a)</td>
<td>OuluVS1</td>
<td>200</td>
<td></td>
<td>91,4%</td>
</tr>
<tr>
<td>Chung &amp; Zisserman (2016b)</td>
<td>OuluVS2</td>
<td>520</td>
<td></td>
<td>94,1%</td>
</tr>
<tr>
<td>Chung &amp; Zisserman (2016a)</td>
<td>BBC TV</td>
<td>&gt;400000</td>
<td></td>
<td>65,4%</td>
</tr>
<tr>
<td>Wand et al. (2016)</td>
<td>GRID</td>
<td>9000</td>
<td></td>
<td>79,6%</td>
</tr>
<tr>
<td>LipNet</td>
<td>GRID</td>
<td>28853</td>
<td><b></b></td>
<td><b>93,4%</b></td>
</tr>
</tbody></table><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der spezielle GRID-Fall setzt sich nach folgender Vorlage zusammen: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Befehl (4) + Farbe (4) + Präposition (4) + Buchstabe (25) + Ziffer (10) + Adverb (4),</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
wobei die Anzahl der Anzahl der Wortvarianten für jede der sechs verbalen Kategorien entspricht . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit anderen Worten, die Genauigkeit von 93,4% ist immer noch das Ergebnis, das unter Gewächshauslaborbedingungen erhalten wird. </font><font style="vertical-align: inherit;">Natürlich wird das Ergebnis mit der Erkennung willkürlicher menschlicher Sprache viel schlechter sein. </font><font style="vertical-align: inherit;">Ganz zu schweigen von der Analyse von Daten aus echten Videos, bei denen das Gesicht einer Person nicht in hervorragender Beleuchtung und hoher Auflösung aus der Nähe aufgenommen wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Betrieb des neuronalen LipNet-Netzwerks wird im Demo-Video gezeigt.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/fa5QGremQf8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wissenschaftliche Arbeit vorbereitet für die Konferenz ICLR 2017 und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">veröffentlicht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 4. November 2016 in der Public Domain.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de398901/">https://habr.com/ru/post/de398901/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de398889/index.html">Опубликован отчёт НАСА об успешных испытаниях EmDrive</a></li>
<li><a href="../de398893/index.html">GSM-Basisstation in einem Bürodrucker versteckt</a></li>
<li><a href="../de398895/index.html">Wie ich mein Gehirn neu programmierte, um Mathematik zu verstehen</a></li>
<li><a href="../de398897/index.html">Yandex hat den Gesundheitsdienst ins Leben gerufen</a></li>
<li><a href="../de398899/index.html">Masterkeys Pro L: An alle Felder anpassen</a></li>
<li><a href="../de398903/index.html">Die dauerhafte Schönheit des Kosmos</a></li>
<li><a href="../de398905/index.html">TP-LINK HS110 - ein Heimassistent oder eine andere Steckdose mit WLAN?</a></li>
<li><a href="../de398907/index.html">Sinfonische Musik - Probleme mit der Wiedergabequalität, der Wahl des Formats und der Ausstattung</a></li>
<li><a href="../de398911/index.html">Was Resonanzregelgeräte sein könnten: Beispiel einer Marke von Cold Ray</a></li>
<li><a href="../de398913/index.html">Wie Valve versucht, den Spielern Höflichkeit beizubringen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
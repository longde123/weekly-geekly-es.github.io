<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üàÇÔ∏è üì∑ ü§∞ Data Warehouse-Architektur: Traditionell und Cloud üö£üèΩ üòÉ üßïüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Es wurde viel zum Thema Data Warehouse-Architektur geschrieben, aber es hat sich noch nicht so pr√§gnant und pr√§gnant getroffen wie in eine...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Data Warehouse-Architektur: Traditionell und Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441538/"> Hallo Habr!  Es wurde viel zum Thema Data Warehouse-Architektur geschrieben, aber es hat sich noch nicht so pr√§gnant und pr√§gnant getroffen wie in einem Artikel, √ºber den ich versehentlich gestolpert bin. <br><br>  Ich lade Sie ein, diesen Artikel in meiner √úbersetzung kennenzulernen.  Kommentare und Erg√§nzungen sind willkommen! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ih/f1/ie/ihf1iesoydew3ek8qb-gcne_5vq.png"></div><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(Bildquelle)</a> <br><a name="habracut"></a><br><h2>  Einf√ºhrung </h2><br>  Die Architektur von Data Warehouses √§ndert sich also.  In diesem Artikel werden herk√∂mmliche Enterprise Data Warehouses und Cloud-L√∂sungen mit geringeren Anfangskosten, verbesserter Skalierbarkeit und Leistung verglichen. <br><br>  Ein Data Warehouse ist ein System, in dem Daten aus verschiedenen Quellen innerhalb eines Unternehmens gesammelt und zur Unterst√ºtzung von Managemententscheidungen verwendet werden. <br><br>  Unternehmen wechseln zunehmend zu Cloud-basierten Data Warehouses anstelle herk√∂mmlicher lokaler Systeme.  Cloud-Datenspeicher unterscheiden sich in einigen Punkten von herk√∂mmlichen Speichern: <br><br><ul><li>  Keine Notwendigkeit, physische Ausr√ºstung zu kaufen; </li><li>  Cloud Data Warehouses sind schneller und kosteng√ºnstiger zu konfigurieren und zu skalieren. </li><li>  Cloud Data Warehouses k√∂nnen komplexe analytische Abfragen normalerweise viel schneller ausf√ºhren, da sie eine massive parallele Verarbeitung verwenden. </li></ul><br><h2>  Traditionelle Data Warehouse-Architektur </h2><br>  Die folgenden Konzepte heben einige der etablierten Designideen und -prinzipien hervor, die zum Erstellen traditioneller Data Warehouses verwendet werden. <br><br><h3>  Drei-Ebenen-Architektur </h3><br>  Sehr oft hat die traditionelle Data Warehouse-Architektur eine dreistufige Struktur, die aus den folgenden Ebenen besteht: <br><br><ul><li>  <b>Untere Ebene</b> : Diese Ebene enth√§lt den Datenbankserver, mit dem Daten aus vielen verschiedenen Quellen abgerufen werden, z. B. aus Transaktionsdatenbanken, die f√ºr Front-End-Anwendungen verwendet werden. </li><li>  <b>Mid-Tier</b> : Das Mid-Tier enth√§lt einen OLAP-Server, der die Daten in eine Struktur umwandelt, die f√ºr Analysen und komplexe Abfragen besser geeignet ist.  Ein OLAP-Server kann auf zwei Arten arbeiten: entweder als erweitertes relationales Datenbankverwaltungssystem, das mehrdimensionale Datenoperationen standardm√§√üigen relationalen OLAP-Operationen zuordnet, oder als Verwendung eines mehrdimensionalen OLAP-Modells, das mehrdimensionale Daten und Operationen direkt implementiert. </li><li>  <b>Oberste Ebene</b> : Die oberste Ebene ist die Client-Ebene.  Diese Ebene enth√§lt die Tools, die f√ºr die Datenanalyse, Berichterstellung und Datenanalyse auf hoher Ebene verwendet werden. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/t6/ho/tnt6hod27digrh97sinoyywqpuk.jpeg"></div><br><h3>  Kimball vs.  Inmon </h3><br>  Zwei Pioniere von Data Warehouses: Bill Inmon und Ralph Kimball bieten unterschiedliche Designans√§tze. <br><br>  Der Ansatz von <b>Ralph Kimball</b> basiert auf der Bedeutung von Data Marts, bei denen es sich um Data Warehouses handelt, die bestimmten Unternehmen geh√∂ren.  Ein Data Warehouse ist einfach eine <b>Kombination verschiedener Data Marts</b> , die die Berichterstellung und Analyse erleichtern.  Das auf Kimball basierende Data Warehouse-Projekt verwendet einen Bottom-up-Ansatz. <br><br>  <b>Der Ansatz von Bill Inmon</b> basiert auf der Tatsache, dass das Data Warehouse eine zentralisierte Speicherung aller Unternehmensdaten ist.  Bei diesem Ansatz erstellt die Organisation zun√§chst ein <b>normalisiertes</b> Data-Warehouse- <b>Modell</b> .  Anschlie√üend werden dimensionale Data Marts basierend auf dem Lagermodell erstellt.  Dies wird als Top-Down-Data-Warehouse-Ansatz bezeichnet. <br><br><h3>  Data Warehouse-Modelle </h3><br>  In der traditionellen Architektur gibt es drei allgemeine Modelle f√ºr Data Warehouses: virtueller Speicher, Datenpr√§sentation und Corporate Data Warehouse: <br><br><ul><li>  <b>Ein virtuelles Data Warehouse</b> besteht aus einer Reihe separater Datenbanken, die gemeinsam genutzt werden k√∂nnen, sodass der Benutzer effektiv auf alle Daten zugreifen kann, als w√§ren sie in einem Data Warehouse gespeichert. </li><li>  <b>Ein Datenpr√§sentationsmodell wird</b> verwendet, um bestimmte Gesch√§ftsbereiche zu melden und zu analysieren.  In diesem Speichermodell aggregierte Daten aus einer Reihe von Quellsystemen, die sich auf einen bestimmten Gesch√§ftsbereich beziehen, z. B. Vertrieb oder Finanzen. </li><li>  <b>Das</b> Data <b>Warehouse-Modell des Unternehmens</b> umfasst das Speichern aggregierter Daten, die sich √ºber das gesamte Unternehmen erstrecken.  Dieses Modell betrachtet das Data Warehouse als das Herzst√ºck eines Unternehmensinformationssystems mit integrierten Daten aus allen Gesch√§ftsbereichen. </li></ul><br><h3>  Stern vs.  Schneeflocke </h3><br>  Stern- und Schneeflockenschemata sind zwei M√∂glichkeiten, um Ihr Data Warehouse zu strukturieren. <br><br>  Ein Sternschema verf√ºgt √ºber ein zentrales Data Warehouse, das in einer Faktentabelle gespeichert ist.  Das Diagramm teilt die Faktentabelle in eine Reihe denormalisierter Dimensionstabellen auf.  Die Faktentabelle enth√§lt die aggregierten Daten, die f√ºr die Berichterstellung verwendet werden, und die Dimensionstabelle beschreibt die gespeicherten Daten. <br><br>  Denormalisierte Projekte sind weniger komplex, da die Daten gruppiert sind.  Die Faktentabelle verwendet nur einen Link zum Anh√§ngen an jede Dimensionstabelle.  Das einfachere sternf√∂rmige Design vereinfacht das Schreiben komplexer Abfragen erheblich. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/m-/2y/l5/m-2yl5ndg1js8sunldgzzho2zta.jpeg"></div><br>  Ein <b>Schneeflockenmuster</b> unterscheidet sich darin, dass es normalisierte Daten verwendet.  Normalisierung bedeutet eine effiziente Datenorganisation, sodass alle Datenabh√§ngigkeiten definiert sind und jede Tabelle ein Minimum an Redundanz enth√§lt.  Somit werden einzelne Messtabellen in separate Messtabellen gegabelt. <br><br>  Das <b>Schneeflockenschema ben√∂tigt</b> weniger Speicherplatz und sorgt f√ºr eine bessere Datenintegrit√§t.  Der Hauptnachteil ist die Komplexit√§t der Abfragen, die f√ºr den Zugriff auf die Daten erforderlich sind. Jede Abfrage muss mehrere Tabellenverkn√ºpfungen durchlaufen, um die entsprechenden Daten zu erhalten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uf/fo/di/uffodipv5qpwawoh-b07x596z20.jpeg"></div><br><h3>  ETL vs.  ELT </h3><br>  ETL und ELT sind zwei verschiedene M√∂glichkeiten, Daten in den Speicher zu laden. <br><br>  <b>ETLs (Extrahieren, Transformieren, Laden) rufen</b> zuerst Daten aus einem Pool von Datenquellen ab.  Die Daten werden in einer tempor√§ren Staging-Datenbank gespeichert.  Anschlie√üend werden Konvertierungsvorg√§nge ausgef√ºhrt, um die Daten zu strukturieren und in eine geeignete Form f√ºr das Ziel-Data-Warehouse-System zu transformieren.  Anschlie√üend werden die strukturierten Daten in den Speicher geladen und k√∂nnen analysiert werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9h/cl/gk/9hclgkwsprpqlae4yheechi-fls.jpeg"></div><br>  Bei <b>ELT (Extrahieren, Laden, Transformieren) werden</b> Daten sofort nach dem Extrahieren aus den Quelldatenpools geladen.  Es gibt keine Zwischendatenbank, was bedeutet, dass Daten sofort in ein einzelnes zentrales Repository hochgeladen werden. <br>  Daten werden zur Verwendung mit Business Intelligence- und Analysetools in ein Data Warehouse-System konvertiert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ce/dz/8y/cedz8yg5rm3wlqw2q5or50h_lrc.jpeg"></div><br><h3>  Organisatorische Reife </h3><br>  Die Data Warehouse-Struktur des Unternehmens h√§ngt auch von der aktuellen Situation und den aktuellen Anforderungen ab. <br><br>  Die Grundstruktur erm√∂glicht es Speicherendbenutzern, direkt auf Zusammenfassungsdaten von Quellsystemen zuzugreifen, Berichte zu erstellen und diese Daten zu analysieren.  Diese Struktur ist n√ºtzlich f√ºr F√§lle, in denen Datenquellen aus denselben Arten von Datenbanksystemen stammen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vv/zf/bv/vvzfbvvlkujpbu83jyvwkwx0tlq.jpeg"></div><br>  Die Speicherung mit einem Zwischenbereich ist der n√§chste logische Schritt in einer Organisation mit heterogenen Datenquellen mit vielen verschiedenen Datentypen und -formaten.  Der Staging-Bereich konvertiert die Daten in ein generisches strukturiertes Format, das mithilfe von Analyse- und Berichterstellungstools einfacher anzufordern ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o5/jl/yj/o5jlyjz8jwjjkuurs8wscmsv1pe.jpeg"></div><br>  Eine Variation der Zwischenstruktur ist das Hinzuf√ºgen von Data Marts zum Data Warehouse.  Data Marts speichern zusammenfassende Daten zu einem bestimmten T√§tigkeitsbereich, wodurch diese Daten f√ºr bestimmte Analyseformen leicht zug√§nglich sind. <br><br>  Durch Hinzuf√ºgen von Data Marts kann ein Finanzanalyst beispielsweise detailliertere Abfragen zu Verkaufsdaten durchf√ºhren und das Kundenverhalten vorhersagen.  Data Marts erleichtern die Analyse, indem sie Daten speziell auf die Bed√ºrfnisse der Endbenutzer zuschneiden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rc/sh/zq/rcshzquazyo1ig4renso2qhlk0w.jpeg"></div><br><h2>  Neue Data Warehouse-Architekturen </h2><br>  In den letzten Jahren sind Data Warehouses in die Cloud umgezogen.  Neue Cloud-Data-Warehouses halten sich nicht an die traditionelle Architektur und bieten jeweils eine eigene Architektur. <br><br>  In diesem Abschnitt werden kurz die Architekturen beschrieben, die von den beiden beliebtesten Cloud-Speichern verwendet werden: Amazon Redshift und Google BigQuery. <br><br><h3>  Amazon Rotverschiebung </h3><br>  <b>Amazon Redshift</b> ist eine Cloud-basierte Ansicht eines herk√∂mmlichen Data Warehouse. <br><br>  Redshift erfordert, dass Computerressourcen vorbereitet und als Cluster konfiguriert werden, die eine Sammlung von einem oder mehreren Knoten enthalten.  Jeder Knoten hat seinen eigenen Prozessor, Speicher und RAM.  Leader Node kompiliert die Anforderungen und √ºbergibt sie an die Rechenknoten, die die Anforderungen ausf√ºhren. <br><br>  An jedem Knoten werden Daten in Bl√∂cken gespeichert, die als <b>Slices bezeichnet werden</b> .  Redshift verwendet den Spaltenspeicher, dh jeder Datenblock enth√§lt Werte aus einer Spalte in mehreren Zeilen und nicht aus einer Zeile mit Werten aus mehreren Spalten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sr/2n/36/sr2n36eioy6n-snrf_hcmyes_wo.png"></div><br>  Redshift verwendet die MPP-Architektur (Massively Parallel Processing) und unterteilt gro√üe Datenmengen in Bl√∂cke, die Slices in jedem Knoten zugewiesen sind.  Anforderungen sind schneller, da Rechenknoten Anforderungen in jedem Slice gleichzeitig verarbeiten.  Der Leader Node-Knoten kombiniert die Ergebnisse und gibt sie an die Clientanwendung zur√ºck. <br><br>  Clientanwendungen wie BI und Analysetools k√∂nnen mithilfe der Open-Source-Treiber PostgreSQL JDBC und ODBC direkt eine Verbindung zu Redshift herstellen.  Auf diese Weise k√∂nnen Analysten ihre Aufgaben direkt an Redshift-Daten ausf√ºhren. <br><br>  Redshift kann nur strukturierte Daten laden.  Sie k√∂nnen Daten mit vorintegrierten Systemen, einschlie√ülich Amazon S3 und DynamoDB, in Redshift laden, indem Sie Daten von einem beliebigen lokalen Host mit einer SSH-Verbindung √ºbertragen oder andere Datenquellen mithilfe der Redshift-API integrieren. <br><br><h3>  Google Bigquery </h3><br>  F√ºr die BigQuery-Architektur ist kein Server erforderlich. Dies bedeutet, dass Google die Zuweisung von Computerressourcen dynamisch steuert.  Daher sind alle Ressourcenverwaltungsentscheidungen f√ºr den Benutzer verborgen. <br><br>  Mit BigQuery k√∂nnen Kunden Daten aus Google Cloud Storage und anderen lesbaren Datenquellen herunterladen.  Eine Alternative ist das Streaming von Daten, mit dem Entwickler dem Data Warehouse zeilenweise Daten in Echtzeit hinzuf√ºgen k√∂nnen, sobald sie verf√ºgbar sind. <br><br>  BigQuery verwendet eine Abfrage-Engine namens Dremel, die Milliarden von Datenzeilen in nur wenigen Sekunden scannen kann.  Dremel verwendet massiv parallele Abfragen, um Daten im Colossus-Basisdateiverwaltungssystem zu scannen.  Colossus verteilt Dateien in Teile von 64 Megabyte unter einer Vielzahl von Rechenressourcen, die als Knoten bezeichnet werden und in Clustern gruppiert sind. <br>  Dremel verwendet eine √§hnliche Spaltendatenstruktur wie Redshift.  Die Baumarchitektur sendet innerhalb von Sekunden Anforderungen an Tausende von Computern. <br><br>  Einfache SQL-Befehle werden zum Ausf√ºhren von Datenabfragen verwendet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lf/hs/fq/lfhsfqfrtm7vobg9bfj8igu0cxm.png"></div><br><br><h3>  Panoply </h3><br>  Panoply bietet ein umfassendes Datenmanagement als Service.  Die einzigartige selbstoptimierende Architektur nutzt maschinelles Lernen und die Verarbeitung nat√ºrlicher Sprachen (NLP), um die Daten√ºbertragung von der Quelle zur Analyse zu modellieren und zu optimieren und die Zeit von den Daten auf Werte so nahe wie m√∂glich zu reduzieren. <br><br>  Panoply Intelligent Data Infrastructure bietet die folgenden Funktionen: <br><br><ul><li>  Abfrage- und Datenanalyse - Ermittlung der besten Konfiguration f√ºr jeden Anwendungsfall, Anpassung im Laufe der Zeit und Erstellung von Indizes, Sortieren von Schl√ºsseln, Festplattenschl√ºsseln, Datentypen, Evakuieren und Partitionieren. </li><li>  Identifiziert Abfragen, die nicht den Best Practices entsprechen, z. B. verschachtelte Schleifen oder implizite Umwandlungen, und schreibt sie in eine entsprechende Abfrage um, die einen Bruchteil der Ausf√ºhrungszeit oder Ressourcen erfordert. </li><li>  Optimieren Sie die Serverkonfiguration im Laufe der Zeit basierend auf Abfragemustern und lernen Sie, welches Server-Setup am besten funktioniert.  Die Plattform wechselt nahtlos zwischen Servertypen und misst die Gesamtleistung. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7y/ds/_g/7yds_gzgj5dnevamau8q5_cppnm.png"></div><br><h3>  Jenseits des Cloud-Speichers </h3><br>  Cloud-basiertes Data Warehousing ist eine gro√üe Verbesserung gegen√ºber herk√∂mmlichen Architekturans√§tzen.  Benutzer haben jedoch immer noch eine Reihe von Problemen bei der Konfiguration: <br><br><ul><li>  <b>Das Hochladen von Daten</b> in Cloud-basierte Data Warehouses ist nicht trivial, und gro√üe Datenpipelines erfordern Konfiguration, Test und Unterst√ºtzung f√ºr den ETL-Prozess.  Dieser Teil des Prozesses wird normalerweise von Tools von Drittanbietern ausgef√ºhrt. </li><li>  <b>Aktualisierungen, Einf√ºgungen und L√∂schungen</b> k√∂nnen komplex sein und m√ºssen sorgf√§ltig durchgef√ºhrt werden, um eine Verschlechterung der Abfrageleistung zu vermeiden. </li><li>  <b>Halbstrukturierte</b> Daten sind schwer zu verarbeiten - sie m√ºssen in einem relationalen Datenbankformat normalisiert werden, das die Automatisierung gro√üer Datenfl√ºsse erfordert. </li><li>  <b>Verschachtelte Strukturen</b> werden in Cloud Data Warehouses normalerweise nicht unterst√ºtzt.  Sie m√ºssen die verschachtelten Tabellen in Formate konvertieren, die das Data Warehouse versteht. </li><li>  <b>Clusteroptimierung</b> .  Es gibt verschiedene Optionen zum Konfigurieren eines Redshift-Clusters zum Ausf√ºhren Ihrer Workloads.  Unterschiedliche Workloads, Datasets oder sogar unterschiedliche Arten von Abfragen erfordern m√∂glicherweise unterschiedliche Konfigurationen.  Um eine optimale Leistung zu erzielen, muss die Konfiguration st√§ndig √ºberpr√ºft und gegebenenfalls zus√§tzlich konfiguriert werden. </li><li>  <b>Abfrageoptimierung</b> - Benutzerabfragen folgen m√∂glicherweise nicht den Best Practices und dauern daher viel l√§nger.  Sie k√∂nnen mit Benutzern oder automatisierten Clientanwendungen zusammenarbeiten, um Abfragen so zu optimieren, dass das Data Warehouse wie erwartet funktioniert </li><li>  <b>Sicherung und Wiederherstellung</b> - Obwohl die Data Warehouse-Anbieter viele Optionen zum Sichern Ihrer Daten bereitstellen, sind sie nicht trivial zu konfigurieren und erfordern √úberwachung und Aufmerksamkeit. </li></ul><br>  <i>Link zum Originaltext: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">panoply.io/data-warehouse-guide/data-warehouse-architecture-traditional-vs-cloud</a></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441538/">https://habr.com/ru/post/de441538/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441528/index.html">Wie aus meinem Leben ein Kafka-Buch wurde</a></li>
<li><a href="../de441530/index.html">SDN wird ins All gebracht: Warum wird das ben√∂tigt?</a></li>
<li><a href="../de441532/index.html">Fledermausfisch Einf√ºhrung</a></li>
<li><a href="../de441534/index.html">Load Balancer f√ºr Orchestrierungssysteme</a></li>
<li><a href="../de441536/index.html">Sorten von SIMD</a></li>
<li><a href="../de441540/index.html">Vue-Mixins auf explizite Weise (anhand eines Beispiels f√ºr ein BEM-Modifikator-Plugin)</a></li>
<li><a href="../de441546/index.html">Hayabusa-2 "ber√ºhrte zuerst den Asteroiden</a></li>
<li><a href="../de441550/index.html">Das Leben eines einfachen Programmierers ist hart und klar</a></li>
<li><a href="../de441554/index.html">Die ganze Geschichte von Linux. Teil I: Wie alles begann</a></li>
<li><a href="../de441560/index.html">Digitale Veranstaltungen in Moskau vom 25. Februar bis 3. M√§rz</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
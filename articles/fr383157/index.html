<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úåüèª üèÄ üö∂ Comment nous avons test√© le stockage d√©fini par logiciel aka Virtual SAN üë¶ ü§ûüèΩ üí§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous avons d√©cid√© d'essayer dans la pratique une nouvelle tendance dans la communaut√© informatique, √† savoir le stockage d√©fini par logiciel.
 
 
 
 N...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment nous avons test√© le stockage d√©fini par logiciel aka Virtual SAN</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/383157/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons d√©cid√© d'essayer dans la pratique une nouvelle tendance dans la communaut√© informatique, √† savoir le stockage d√©fini par logiciel.</font></font><br>
<img src="https://habrastorage.org/files/146/dc9/6c2/146dc96c24854245997228a27e86ee41.jpg"><br>
<a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons demand√© √† nos merveilleux fournisseurs un terrain d'essai. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Configuration du stand:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3 serveurs SuperMicro X9SCL / X9SCM de la configuration suivante:</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Processeur Intel E3-1220V2: 4 c≈ìurs x 3,1 GHz</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RAM - 16 Go</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adaptateur RAID Adaptec 6405E: 2x300 Go SAS 10K, 1x180 Go SSD - tous les disques doivent √™tre configur√©s en mode JBOD</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2x500GB SATA 7.4K connect√©s aux connecteurs sur le tapis. </font><font style="vertical-align: inherit;">carte de circuit imprim√©</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Carte r√©seau 2x1 Go</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En fait, il existe de nombreuses solutions Virtual SAN maintenant, Starwind VSAN a chut√© en raison des limitations importantes de la version gratuite, qui a tu√© toutes les fonctionnalit√©s int√©ressantes, VMWARE VSAN a chut√© en raison des exigences mat√©rielles et du co√ªt de possession √©lev√©, ce qui n'est pas optimal pour les petits budgets r√©gionaux, ainsi que pour le fait que ceux-ci. Les sp√©cialistes VMWARE en marge ne recommandent pas d'utiliser leur VSAN pour les applications critiques. En cons√©quence, nous avons choisi une solution de Nutanix et EMC ScaleIO. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ScaleIO est un SAN virtuel d√©fini par logiciel d'EMC</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, peut fonctionner en mode libre sans presque aucune restriction (√©crit dans la licence pour une utilisation hors production!) - le seul inconv√©nient grave est que ce syst√®me n'a pas de m√©canismes int√©gr√©s pour la suppression automatique des donn√©es ou la mise en cache, j'utilise des disques SSD. (contrairement √† concurrents √† qui le SSD donne un s√©rieux avantage sur la vitesse des machines virtuelles). </font><font style="vertical-align: inherit;">Sur le plan architectural, il ressemble fortement au syst√®me de stockage IBM XIV d'entreprise haut de gamme - m√™me la taille de bloc est la m√™me - 1 Mo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'ai lu des exigences minimales contradictoires dans diff√©rentes sources:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici la configuration minimale requise pour une impl√©mentation ScaleIO 1.31 et 1.32:</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La solution ScaleIO 1.31 et 1.32 n'est prise en charge que sur ESXi 5.5 GA.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trois serveurs ESXi avec 100 Go de capacit√© libre par serveur</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©seau 1 gbps</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quatre disques SATA de 7 200 tr / min par n≈ìud</font></font></li>
</ul><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, dans la pratique, pour la version 1.32, ces restrictions n'√©taient pas respect√©es. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√âtant donn√© qu'en production, nous utilisons le VMWARE racialement correct et que nous n'aimons pas le Hyper-V non orthodoxe, nous avons s√©lectionn√© la version d'essai de VMWARE ESXi 6.0 pour le d√©ploiement en tant qu'hyperviseur. Par souci d'√©quit√©, il convient de noter que ScaleIO fonctionne correctement sur les hyperviseurs XEN, ESXi et Hyper-V suivants; sur ce dernier, avec l'aide de Windows 2012 r2, les artisans ont contourn√© le manque de mise en cache de la baie SSD √† l'aide des outils int√©gr√©s de 2012 R2, ce qui a bien s√ªr eu un effet positif sur les performances du syst√®me. (il existe une technique sur Internet)</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous devez d'abord installer l'hyperviseur ESXi sur tous les h√¥tes et installer l'appliance VCENTER pour g√©rer le cluster VMWARE. Le premier incident nous attendait juste l√† - ESXi n'a jamais voulu voir le contr√¥leur Adaptec 6405E, bien qu'il soit pr√©sent dans VMWARE HCL. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous t√©l√©chargeons les pilotes (Offline-Bundles et VIB) √† partir du site Web Adaptec pour VMWARE et via VMWARE powercli en utilisant </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cet outil,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nous pr√©parons une image personnalis√©e de l'hyperviseur avec des pilotes int√©gr√©s - apr√®s cela, tout s'est bien pass√©. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, la virtualisation de l'appliance VCENTER est d√©ploy√©e et, encore une fois, via vmware powercli, les plug-ins ScaleIO sont enregistr√©s et les mod√®les de machine virtuelle ScaleIO au format .ova sont copi√©s dans le magasin de donn√©es (selon les instructions d'installation de ScaleIO).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir red√©marr√© tous les h√¥tes, le syst√®me est pr√™t √† travailler sur l'installation de ScaleIO. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je recommande fortement de lire les instructions de d√©ploiement, sinon de nombreux points seront incompr√©hensibles: </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - par exemple, vous devez comprendre des choses telles que le domaine de protection et comment il se rapporte aux pools de stockage, </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - quelles sont les recommandations pour cr√©er des pools de stockage (qui ne devraient pas interf√©rer avec le disque dur et le SSD , bien que cela soit possible) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - pour comprendre ce qu'est FaultSets, bien que nous ne l'ayons pas utilis√©. Comprendre ce qu'est la politique ZeroPadding, la politique de cache RAM et ses options, la politique de rechange. De nombreuses </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nuances ScaleIO ne prend pas en charge la possibilit√© d'utiliser des disques SSD comme cache pour un tableau de donn√©es! C'est une caract√©ristique d√©sagr√©able. Les pools de SSD peuvent √™tre collect√©s, mais ce sera juste un pool uniquement flash - rien de plus!</font></font><br>
</b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous vous recommandons d'utiliser l'adaptateur RAID de cache en lecture / √©criture comme √©l√©ment de cache s'il est √©quip√© d'une batterie, et il existe √©galement une fonction RAM CACHE lors de la cr√©ation d'un domaine de protection qui utilise une partie de la RAM de l'h√¥te de virtualisation comme cache de baie! (sur 16 Go de RAM, nous avons r√©ussi √† allouer 1,3 Go de cache dans les param√®tres, lisez la documentation) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous avez √©galement besoin de 2 VLAN virtuels: gestion et donn√©es, vous devrez √©mettre chacun des 4 (dans la configuration minimale) gestion SVM (SVM - ScaleIO Virtual Machine) IP et DATA IP avec indication de la passerelle et des masques. (Il est fortement conseill√© de pr√©parer un plan d'adressage √† l'avance afin de ne pas remplir tous les champs obligatoires 10 fois).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au total, en mode minimum, l'installation cr√©e 4 SVM sur nos 3 h√¥tes (SVM - ScaleIO Virtual Machine), prend 8 cpu sur tous (2 sur l'h√¥te: 2 machines virtuelles sur le premier h√¥te, donc 4 vcpu), prend 12 Go de m√©moire sur tous. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SVM sur node1 - mdm principal, sds, sdc </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SVM sur node2 - mdm secondaire, sds, sdc </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SVM sur node3 - disjoncteur, sdc </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SVM sur n'importe quel n≈ìud - passerelle - (mise √† jour centralis√©e, surveillance, maintenance) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
mdm - Meta Data Manager - g√®re tables d'allocation de p√©riph√©riques </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
sds - serveur de donn√©es ScaleIO - contr√¥le la livraison des disques physiques via des disques RDM dans VMWARE (mappage de disque brut)</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
sdc - ScaleIO data client - dans le cas de VMWARE, il est ajout√©. modules du noyau qui sont int√©gr√©s pendant la phase de d√©ploiement ScaleIO et vous permettent d'obtenir de meilleures performances que lorsqu'ils fonctionnent sur la machine virtuelle SVM elle-m√™me. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En outre, un tr√®s grand avantage d'avoir SDC dans le noyau est que les volumes de donn√©es cr√©√©s sur ScaleIO sont pr√©sent√©s dans VMWARE directement sous forme de LUN pour cr√©er une banque de donn√©es, sans utiliser une couche suppl√©mentaire de virtualisation et de pr√©sentation des volumes via le m√©canisme iSCSI. </font></font><br>
<br>
<img src="https://habrastorage.org/files/4c3/4ec/bc3/4c34ecbc3e614098ba3e1ac3c061e78f.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le processus de d√©ploiement ne s'est pas d√©roul√© sans heurts, car nous n'avions pas les VLAN et les adresses IP n√©cessaires pour SVM pr√™t. Apr√®s avoir pr√©par√© les donn√©es et red√©marr√© l'assistant d'installation √† la derni√®re √©tape, ces erreurs ont commenc√© √† nous √©chapper: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√âchec: Ajouter le p√©riph√©rique SDS ScaleIO-4c1885e7 aux disques durs du pool de stockage (ScaleIO - Timeout)</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec ce qu'il √©tait connect√©, je ne peux pas le dire. Nous nous sommes assis, r√©essay√©. Les erreurs pr√©c√©dentes ont disparu, mais d'autres erreurs sont apparues sur l'un des SVM sur host2: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√âchec: Ajouter le p√©riph√©rique SDS ScaleIO-4c1885eb aux disques durs du pool de stockage (ScaleIO - Le SDS est d√©j√† attach√© √† ce MDM) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous nous sommes assis et avons pens√© ... d√©couvert sur l'un des SVM o√π le mdm secondaire √©tait situ√©, pour une raison quelconque lors de l'installation, les mappages RDM aux disques physiques n'ont pas √©t√© cr√©√©s et, par cons√©quent, le service SDS n'a pas augment√©. Ainsi, l'un des n≈ìuds que nous n'avons pas d√©marr√©. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ils ont de nouveau cliqu√© sur le bouton ¬´D√©ployer l'environnement scaleio¬ª et, voil√†, l'h√¥te et la machine virtuelle vide ont √©t√© trouv√©s inutilis√©s, ont √† nouveau entr√© les donn√©es sur les VLAN et les adresses IP, et l'h√¥te a d√©marr√© normalement sans erreur.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s cela, un moment int√©ressant attendait au stade de la cr√©ation du volume sur lequel nous placerons les donn√©es. Je n'ai pas pu trouver cet √©l√©ment dans l'interface graphique: ni dans le tableau de bord GUI install√© sur Windows, ni dans l'interface graphique VMWARE, ni dans l'interface Web de la passerelle. beaucoup d'instructions pour cr√©er √† partir de cli - trouv√©es par hasard sur un blog. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je donne une capture d'√©cran - o√π se trouve le bouton pr√©cieux pour cr√©er du volume dans l'interface graphique de VMWARE. </font></font><br>
<br>
<img src="https://habrastorage.org/files/6f3/891/a2a/6f3891a2a60b4135b40a528c2fc7d49e.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hourra, retrouv√©! Mais les "acclamations" ne tard√®rent pas. Selon la capture d'√©cran sur le pool de stockage avec le nom HDD (o√π j'ai combin√© les 6 disques SAS des 3 n≈ìuds), nous avons une capacit√© totale de 1,6 To (ce qui correspond g√©n√©ralement √† 6x300 Go), mais le volume avec un tel volume n'est pas cr√©√© ... et on ne sait pas quoi volume disponible pour l'utilisateur. J'ai lu des instructions sur Internet comment utiliser la CLI pour voir le volume disponible. Nous sommes pass√©s par SSH √† l'un des SVM MDM - je donne la commande:</font></font><br>
<br>
<pre><code class="cs hljs">ScaleIO<span class="hljs-number">-10</span><span class="hljs-number">-1</span><span class="hljs-number">-4</span><span class="hljs-number">-203</span>:~ <span class="hljs-meta"># scli --query_storage_pool --protection_domain_name pd2 --storage_pool_name hdds</span>
Error: MDM failed command.  Status: Invalid session. Please login and <span class="hljs-keyword">try</span> again.<font></font>
<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quelle? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'essaie sur le deuxi√®me MDM: l'erreur est quelque chose comme ne peut pas se connecter localhost: 6611 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur la passerelle, il est g√©n√©ralement dit qu'il n'y a pas de telles commandes. </font><font style="vertical-align: inherit;">Tout est stupeur! </font><font style="vertical-align: inherit;">Il n'est pas clair comment utiliser la CLI. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous √©tudions attentivement le guide d'utilisation sur ScaleIO, en particulier sur les principes de base de la CLI, et il indique tout en bas que vous devez √©galement vous connecter √† la CLI et la date du lien, comment le faire, mais vous devez le faire comme ceci:</font></font><br>
<pre><code class="bash hljs">ScaleIO-10-1-4-203:~ <span class="hljs-comment"># scli --login --username admin</span><font></font>
Enter password:<font></font>
</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et apr√®s cela, toutes les √©quipes CLI ont commenc√© √† travailler √† merveille.</font></font><br>
<br>
<pre><code class="bash hljs">scli --query_storage_pool --protection_domain_name pd2 --storage_pool_name hdds<font></font>
<font></font>
Storage Pool hdds (Id: 574711eb00000000) has 0 volumes and<font></font>
544.0 GB (557056 MB) available <span class="hljs-keyword">for</span> volume allocation<font></font>
Background device scanner: Disabled<font></font>
Zero padding is disabled<font></font>
Spare policy: 34% out of total<font></font>
Uses RAM Read Cache<font></font>
RAM Read Cache write handling mode is <span class="hljs-string">'cached'</span><font></font>
 1.6 TB (1667 GB) total capacity<font></font>
 1.1 TB (1100 GB) unused capacity<font></font>
 567.1 GB (580708 MB) spare capacity<font></font>
</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Attends quoi? le volume disponible dans notre bo√Ætier est de 544 Go?! Comment? Pourquoi? Une explication de l'architecture de stockage est requise ici (voir capture d'√©cran): </font></font><br>
<br>
<img src="https://habrastorage.org/files/372/7c1/3a7/3727c13a7e3e4c9ebfff7b3d9c8dd099.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
i.e. volume total du pool de stockage brut nomm√© HDD: 1,6 To moins 567,1 Go de capacit√© de r√©serve = 1,1 To de capacit√© inutilis√©e. La capacit√© de r√©serve est d√©termin√©e par le param√®tre Strat√©gie de r√©serve dans les param√®tres. Selon les recommandations de la documentation, pour une protection compl√®te contre la d√©faillance d'un n≈ìud, il est n√©cessaire que la capacit√© de stockage soit au moins 1 \ N du volume total de tous les disques physiques de tous les n≈ìuds inclus dans le pool de stockage, o√π N est le nombre de n≈ìuds qui se trouvent dans le pool (c.-√†-d. e si nous avons 3 n≈ìuds avec des disques dans ce pool de stockage, alors la capacit√© disponible dans notre cas est 1 \ 3 de 1,6 To (du volume total), respectivement 567,1 Go (580708 Mo).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainsi, nous obtenons 1,1 To d'espace inutilis√© dans le pool de stockage pour cr√©er du volume. Cependant, √† des fins de haute disponibilit√© et de fiabilit√©, ScaleIO stocke 2 copies de chaque bloc de donn√©es sur tous les disques physiques, respectivement, nous divisons le volume de 1,1 To par 2 fois, et en cons√©quence, nous obtenons le volume disponible pour cr√©er un volume de 544,0 Go. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pendant le test de fonctionnement du syst√®me, nous avons r√©ussi √† atteindre les indicateurs suivants (la vitesse √©tait de 85 √† 130 Mo / s, mais vous devez comprendre que ce n'est que la charge d'une machine virtuelle, lorsque vous √©tendez la baie en ajoutant des n≈ìuds avec des disques, je pense que tout sera proportionnel √† la croissance avec IOPS): </font></font><br>
<br>
<img src="https://habrastorage.org/files/21a/8c0/ce3/21a8c0ce34c844ce8a914a7c7b4386b4.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nutanix Comminity Edition 4.5 - gratuit pour une utilisation non commerciale</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En g√©n√©ral, la documentation de Nutanix, assez curieusement, est assez petite ... Certains points ont √©t√© clarifi√©s lors du processus d'installation. Nutanix combine √† la fois un hyperviseur et un syst√®me de gestion de cluster de virtualisation (ala VMWARE Vcenter) en une "personne", ainsi qu'un syst√®me de stockage distribu√© fourni sur NFS avec des fonctions de haute disponibilit√©. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Malheureusement, nous n'avons pas pu obtenir la version avec l'hyperviseur ESXi. Par cons√©quent, ils ont commenc√© √† tester la version Community Edition, et elle pr√©sente de nombreuses limitations: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - maximum 4 n≈ìuds </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - maximum 4 disques par n≈ìud (y compris les SSD, donc la capacit√© maximale par h√¥te est de 18 To (3 disques durs de 6 To)) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - Processeur Intel avec prise en charge VT-x 4 c≈ìurs minimum </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - contr√¥leurs SATA AHCI (Advanced Host Controller Interface) int√©gr√©s</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - Contr√¥leurs LSI en mode informatique (les tests Nutanix montrent de meilleures performances que l'IR) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - au moins 16 Go de m√©moire par h√¥te (32 Go ou plus pour la d√©duplication est fortement recommand√© - il ne s'allume pas pour 16) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - SSD minimum par h√¥te 200 Go </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - minimum le volume SSD par h√¥te pour prendre en charge la d√©duplication de 300 Go (de pr√©f√©rence plus de 400 480) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nutanix n'a pas d√©termin√© le contr√¥leur SAS ADAPTEC 6405E, nous n'avons donc pas pu utiliser de disques SAS (nous avons utilis√© des disques SATA et SSD connect√©s aux connecteurs de la carte m√®re).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'installation n√©cessite un support sur chaque h√¥te: nous n'avons pas mis l'image finie sur les lecteurs locaux du serveur - nous avons mis un lecteur flash de 8 Go sur chaque h√¥te (les exigences minimales sont de 8 Go pour le lecteur flash, mieux 16, l'hyperviseur KVM (Acropolis) et CVM - le contr√¥le de la machine virtuelle y est plac√© - et ainsi de suite pour chaque h√¥te!), Le nombre total de machines virtuelles CVM par le nombre d'h√¥tes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans notre cas, la configuration suivante a √©t√© obtenue: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - 16 gigaoctets de m√©moire par h√¥te </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - pour chaque h√¥te 2 disques durs HDD SATA 500 Go </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - pour chaque h√¥te 1 disque dur SSD 500 Go </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - pour la d√©duplication vous avez besoin d'au moins 24 Go de m√©moire par h√¥te + au moins 300 Go SSD par h√¥te, donc elle ne s'est pas retourn√©e contre nous. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En cas de non-respect des exigences minimales, le syst√®me n'est pas install√© ...</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous ne pouvez pas modifier l'hyperviseur dans Community Edition - seul KVM est install√© par d√©faut - c'est un √©norme inconv√©nient, car nous sommes habitu√©s √† utiliser VMWARE ESXi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s l'installation, une machine virtuelle de service (CVM - machine virtuelle de contr√¥le) appara√Æt sur chaque h√¥te, qui occupe 2 c≈ìurs de processeur et r√©serve 12 Go de RAM sur chaque h√¥te - en tenir compte lors de la planification. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s l'installation sur tous les n≈ìuds du cluster, nous cr√©ons des volumes pour le stockage des donn√©es: lors de la cr√©ation du StorageContainer, si le facteur de r√©plication 2, alors l'espace disque libre est de 50% inf√©rieur (tous les blocs de donn√©es sont dupliqu√©s sur d'autres disques, par exemple, nous avons 3 h√¥tes, sur chaque 2 disques SATA 500 Go, soit un total de 6 disques + disques SSD sur chacun des h√¥tes, seulement 2,88 To de volume total dont 1,44 To disponibles pour l'utilisateur pour le stockage).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s la cr√©ation, la matrice de disques est accessible et fournie via NFS: par exemple, elle s'est parfaitement connect√©e au cluster VMWARE 5.5 en tant que banque de donn√©es, respectivement, le stockage vmotion fonctionne √©galement, bien que la vitesse soit beaucoup plus lente que FC 4Gb \ sec (c'est compr√©hensible avec une connexion gigabit - c'√©tait int√©ressant conduirait sur 10G ou infiniband). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une machine live de 60 Go du cluster VMWARE a √©t√© d√©plac√©e d'environ 24 minutes vers le stockage Nutanix. Il est revenu 13 minutes au stockage FC de niveau entreprise. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√âcriture du fichier iso du serveur Windows sur la machine virtuelle vmware qui se trouve sur le stockage nutanix via nfs (1 Go / s) - 34 Mo / sec. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il n'y a pas d'outil interactif pour g√©rer les groupes de ports et vswitch - tout est fait √† partir de cli.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un point non √©vident sur les r√©seaux pour ex√©cuter des machines virtuelles: je vous conseille de lire attentivement la documentation. Pour les machines virtuelles √† l'int√©rieur de Nutanix, nous avons utilis√© les VLAN que tous nos autres syst√®mes de virtualisation utilisent pour acc√©der au r√©seau. Au stade de la configuration des r√©seaux virtuels, le num√©ro VLAN du r√©seau virtuel est simplement indiqu√© - il n'y a plus de param√®tres, et dans les propri√©t√©s de la machine virtuelle la carte r√©seau virtuelle est configur√©e pour correspondre au num√©ro de r√©seau - et c'est tout, il n'y a pas d'autres param√®tres dans l'interface graphique! Mais tout fonctionne. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour installer des machines virtuelles invit√©es Windows, vous devez connecter un deuxi√®me CDROM virtuel avec les pilotes VirtIO (par exemple, vous pouvez le prendre √† partir d'ici (placez d'abord le fichier iso sur le r√©f√©rentiel): </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fedoraproject.org/wiki/Windows_Virtio_Drivers#Direct_download</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le temps d'installation de Guest VM sur Windows 2012 R2 n'√©tait que de 7 minutes du d√©but √† la pleine charge du syst√®me de travail, la machine virtuelle fonctionne visuellement aussi rapidement - √©videmment, le SSD aide. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez placer une machine virtuelle sur le type de contr√¥leur de disque virtuel IDE (sans connecter les pilotes VirtIO), mais ce n'est pas une configuration recommand√©e - les performances seront bien moindres. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors d'une panne de courant de test de l'un des h√¥tes du cluster, HA a fonctionn√©, le syst√®me ne s'est pas bloqu√©, les ressources disque sont accessibles √† la fois sur le r√©seau et localement, les machines virtuelles qui √©taient sur l'h√¥te d√©connect√© ont red√©marr√© sur d'autres h√¥tes (s'il y a suffisamment de m√©moire),</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, apr√®s avoir allum√© le pouvoir du 3√®me h√¥te, le fait d√©sagr√©able √©tait que le statut du syst√®me a √©t√© maintenu dans Critical pendant tr√®s longtemps - je ne sais pas ce que cela tire, mais il n'y a pas grand-chose de bon. (de 1 heure √† 2). Par exemple, le m√™me cluster VMWARE apr√®s connexion √† l'h√¥te d√©termine rapidement son √©tat et se reconnecte au cluster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En g√©n√©ral, il convient de noter que l'interface Prism pour la gestion d'un cluster de Nutanix CE a une interface plut√¥t m√©diocre (quoique agr√©able). Seuls les param√®tres de base sont disponibles, mais en g√©n√©ral, ils sont suffisants √† premi√®re vue, il existe des analyses graphiques personnalisables, bien que, bien s√ªr, elles soient beaucoup plus faibles que dans VCENTER.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La sauvegarde n'est pas claire: apr√®s tout, ni les produits Symantec ni Veeam ne prennent en charge la virtualisation KVM ... √©videmment, par le biais d'instantan√©s, mais qu'en est-il de la r√©cup√©ration granulaire des donn√©es dans ce cas (fichier par fichier). </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visuellement, Nutanix √©tait beaucoup plus rapide, qu'au stade de la copie des images sur son syst√®me de stockage, qu'au stade de l'installation du syst√®me d'exploitation sur une nouvelle machine virtuelle √† partir de l'image, qu'au stade des red√©marrages de d√©marrage: presque instantan√©ment tout). </font><font style="vertical-align: inherit;">Il y a un d√©sir d'essayer Nutanix sur une configuration plus puissante et assurez-vous d'utiliser VMWARE EXSi. </font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien s√ªr, je ne peux pas fournir de donn√©es de performances particuli√®res pour les deux syst√®mes, mais vous pouvez obtenir des informations sur le "rake" lors de la configuration. </font><font style="vertical-align: inherit;">Si je m'excuse - la premi√®re note sur Habr√©.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr383157/">https://habr.com/ru/post/fr383157/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr383145/index.html">Examen du transformateur pour ordinateur portable ASUS Transformer Book T300 Chi</a></li>
<li><a href="../fr383147/index.html">TV pour Algernon: un aper√ßu des d√©codeurs qui rendent la t√©l√©vision plus intelligente</a></li>
<li><a href="../fr383151/index.html">Dr. Tarif calcul√© quel op√©rateur mobile a plus de 4G Internet (partie 2)</a></li>
<li><a href="../fr383153/index.html">Modules d'appartements ou voie de d√©veloppement de locaux d'habitation</a></li>
<li><a href="../fr383155/index.html">Android devrait avoir peur que Android</a></li>
<li><a href="../fr383159/index.html">–°–º–∞—Ä—Ç—Ñ–æ–Ω —Å –º–æ—â–Ω—ã–º –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä–æ–º. –í–µ—Ä—Å–∏—è DEXP: 10 –º–æ–¥–µ–ª–µ–π –æ—Ç 4 490 –¥–æ 13 990 —Ä—É–±–ª–µ–π, –æ—Ç 3 000 –¥–æ 5 200 –º–ê—á</a></li>
<li><a href="../fr383163/index.html">L'imprimante 3D imprime avec du verre chaud</a></li>
<li><a href="../fr383165/index.html">Annonce SmartBand 2</a></li>
<li><a href="../fr383167/index.html">IDF 2015. Tomorrow Summary</a></li>
<li><a href="../fr383169/index.html">Comment assembler un cin√©ma hi-fi √† la maison</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüöí üå∞ üéí Habra W√∂rterbuch. Teil 1 üìÇ üëéüèº üë©üèΩ‚Äçüé®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Freunde, guten Tag. 


 Ich habe das Problem der Zusammenstellung des Habrahabr-W√∂rterbuchs gel√∂st, um die Entstehung neuer Sprachen, Frameworks, Verw...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Habra W√∂rterbuch. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413223/"><p>  Freunde, guten Tag. </p><br><p>  Ich habe das Problem der Zusammenstellung des Habrahabr-W√∂rterbuchs gel√∂st, um die Entstehung neuer Sprachen, Frameworks, Verwaltungspraktiken usw. zu verfolgen.  Kurz gesagt, neue W√∂rter. </p><br><p>  Das Ergebnis war eine Liste englischer W√∂rter "im Nominativ und Singular". </p><br><p>  Er tat es in der Windows 10 x64-Umgebung, verwendete die Python 3-Sprache im Spyder-Editor in Anaconda 5.1.0 und verwendete eine kabelgebundene Netzwerkverbindung. </p><br><p>  In diesem Artikel erhalte ich ein W√∂rterbuch mit englischen W√∂rtern in einer begrenzten Auswahl.  Wenn sich das Thema als interessant herausstellt, plane ich in Zukunft ein W√∂rterbuch mit englischen und russischen W√∂rtern f√ºr eine vollst√§ndige Auswahl von Habrs Artikeln.  Mit der russischen Sprache ist alles komplizierter. </p><br><p>  <strong>Analyseprozess</strong> </p><br><p>  Ich habe die Scheibe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von hier genommen</a> .  Unten ist der Code f√ºr meine Version des Parsers. </p><br><p> Um Habrs W√∂rterbuch zu sammeln, m√ºssen Sie seine Artikel umgehen und den Text der Artikel daraus ausw√§hlen.  Ich habe die Metainformationen der Artikel nicht verarbeitet.  Artikel √ºber Habr√© haben meine "Nummer", z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://habr.com/post/346198/</a> .  Die Aufz√§hlung der Artikel kann von 0 bis 354366 erfolgen. Dies war der letzte Artikel zum Zeitpunkt des Projekts. </p><a name="habracut"></a><br><p>  F√ºr jede Ausgabe versuchen wir, eine HTML-Seite zu erhalten. Wenn dies erfolgreich ist, ziehen wir den Titel und den Text des Artikels aus der HTML-Struktur heraus.  Der Bypass-Code lautet wie folgt: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup dataset = pd.DataFrame() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">350000</span></span>,<span class="hljs-number"><span class="hljs-number">354366</span></span>): r = requests.<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>(<span class="hljs-string"><span class="hljs-string">'https://habrahabr.ru/post/'</span></span> +str(pid) + <span class="hljs-string"><span class="hljs-string">'/'</span></span>) soup = BeautifulSoup(r.text, <span class="hljs-string"><span class="hljs-string">'html5lib'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> soup.find("span", {"class": "post__title-text"}): title = soup.find("span", {"class": "post__title-text"}).text <span class="hljs-type"><span class="hljs-type">text</span></span> = soup.find("div", {"class": "post__text"}).text my_series = pd.Series([pid, title, <span class="hljs-type"><span class="hljs-type">text</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=[<span class="hljs-string"><span class="hljs-string">'id'</span></span>, <span class="hljs-string"><span class="hljs-string">'title'</span></span>, <span class="hljs-string"><span class="hljs-string">'text'</span></span>]) df_new = pd.DataFrame(my_series).transpose() dataset = dataset.append(df_new, ignore_index = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Empirisch festgestellt, dass die Artikel selbst weniger als dreimal so viele sind.  Ich habe auf 4366 Nummern trainiert - so viel l√§dt mein System in einer halben Stunde. </p><br><p>  Ich habe keine Geschwindigkeitsoptimierung durchgef√ºhrt, obwohl sie sagen, dass die Verarbeitung in 100 Threads viel schneller ist, wenn Sie sie starten. </p><br><p>  Ich habe das Ergebnis auf der Festplatte gespeichert </p><br><pre> <code class="hljs pgsql">dataset.to_excel(directory+<span class="hljs-string"><span class="hljs-string">'dataset.xlsx'</span></span>, sheet_name=<span class="hljs-string"><span class="hljs-string">'sheet1'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><p>  - um den langsamen Download aus dem Internet nicht zu wiederholen.  Die Datei hatte eine Gr√∂√üe von 10 Megabyte. </p><br><p>  Ich interessierte mich f√ºr die englischen Namen der Instrumente.  Ich brauchte keine Begriffe in verschiedenen Formen, ich wollte sofort normale Formen von W√∂rtern bekommen.  Es ist klar, dass die h√§ufigsten W√∂rter "in", "on" und "by" sind. Wir entfernen sie.  Um das W√∂rterbuch zu normalisieren, habe ich den englischen Stimmer Porter aus der ntlk-Bibliothek verwendet. </p><br><p>  Ich habe die indirekte Methode verwendet, um eine Liste von W√∂rterbuchw√∂rtern zu erstellen. Siehe den Code, der mit "from sklearn.feature_extraction.text import CountVectorizer" beginnt.  Ich werde das sp√§ter brauchen. </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk nltk.download(<span class="hljs-string"><span class="hljs-string">'stopwords'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> stopwords <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.stem.porter <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PorterStemmer corpus = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">0</span></span>, len(dataset.<span class="hljs-keyword"><span class="hljs-keyword">index</span></span>)): review = re.sub(<span class="hljs-string"><span class="hljs-string">'[^a-zA-Z]'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, dataset[<span class="hljs-string"><span class="hljs-string">'text'</span></span>][i]) review = review.lower() review = review.split() ps = PorterStemmer() review = [ps.stem(word) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> review <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(stopwords.words(<span class="hljs-string"><span class="hljs-string">'english'</span></span>))] review = <span class="hljs-string"><span class="hljs-string">' '</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(review) corpus.append(review) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CountVectorizer cv = CountVectorizer() X = cv.fit_transform(corpus).toarray() names = cv.get_feature_names() dfnames = pd.DataFrame(names).transpose() dfnames.to_excel(directory+<span class="hljs-string"><span class="hljs-string">'names.xlsx'</span></span>, sheet_name=<span class="hljs-string"><span class="hljs-string">'sheet1'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><p>  Das Objekt <strong>names</strong> ist das gesuchte W√∂rterbuch.  Wir haben es auf der Festplatte gespeichert. </p><br><p>  <strong>Ergebnis√ºbersicht</strong> </p><br><p>  Es stellte sich heraus, dass mehr als 30.000 bereits normalisierte W√∂rter vorhanden waren.  Und dies sind nur 4366 Artikelnummern und W√∂rter nur in Englisch. </p><br><p>  Aus dem Interessanten: </p><br><ol><li><p>  Artikelautoren verwenden viele seltsame ‚ÄûW√∂rter‚Äú, zum Beispiel: aaaaaaaaaaaa, aaaabbbbccccdddd oder zzzhoditqxfpqbcwr </p><br></li><li>  Von Objekt X erhalten wir die Top 10 der beliebtesten englischen W√∂rter in unserem Beispiel: </li></ol><br><p>  <strong>Word-PC</strong> <br>  iter 4133 <br>  op. 4030 <br>  R√ºckgabe 2866 <br>  ns 2834 <br>  ID 2740 <br>  Name 2556 <br>  neue 2410 <br>  Daten 2381 <br>  Zeichenfolge 2358 <br>  http 2304 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de413223/">https://habr.com/ru/post/de413223/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de413213/index.html">Apple WWDC 2018: Textsendung</a></li>
<li><a href="../de413215/index.html">GitHub ist jetzt offiziell im Besitz von Microsoft</a></li>
<li><a href="../de413217/index.html">Sind Elektroautos so umweltfreundlich?</a></li>
<li><a href="../de413219/index.html">Willkommen zum QA-Meetup SuperJob</a></li>
<li><a href="../de413221/index.html">Bakterien √ºberleben in einem "Reinraum" w√§hrend der Montage von Raumfahrzeugen und fressen Reinigungsprodukte</a></li>
<li><a href="../de413225/index.html">Sicherheitswoche 20: Nichttriviale Cyber-Angriffe</a></li>
<li><a href="../de413227/index.html">Was ist Gott unter Kleidern?</a></li>
<li><a href="../de413229/index.html">Erstellen Sie Caffe in Google Colaboratory: Kostenlose Grafikkarte in der Cloud</a></li>
<li><a href="../de413231/index.html">Einf√ºhrung in Smart Contracts</a></li>
<li><a href="../de413233/index.html">Der uLogin-Dienst sendet Daten von Formularen (E-Mail, Telefon) an eine Website eines Drittanbieters und schweigt dar√ºber</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
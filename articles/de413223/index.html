<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍🚒 🌰 🎒 Habra Wörterbuch. Teil 1 📂 👎🏼 👩🏽‍🎨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Freunde, guten Tag. 


 Ich habe das Problem der Zusammenstellung des Habrahabr-Wörterbuchs gelöst, um die Entstehung neuer Sprachen, Frameworks, Verw...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Habra Wörterbuch. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413223/"><p>  Freunde, guten Tag. </p><br><p>  Ich habe das Problem der Zusammenstellung des Habrahabr-Wörterbuchs gelöst, um die Entstehung neuer Sprachen, Frameworks, Verwaltungspraktiken usw. zu verfolgen.  Kurz gesagt, neue Wörter. </p><br><p>  Das Ergebnis war eine Liste englischer Wörter "im Nominativ und Singular". </p><br><p>  Er tat es in der Windows 10 x64-Umgebung, verwendete die Python 3-Sprache im Spyder-Editor in Anaconda 5.1.0 und verwendete eine kabelgebundene Netzwerkverbindung. </p><br><p>  In diesem Artikel erhalte ich ein Wörterbuch mit englischen Wörtern in einer begrenzten Auswahl.  Wenn sich das Thema als interessant herausstellt, plane ich in Zukunft ein Wörterbuch mit englischen und russischen Wörtern für eine vollständige Auswahl von Habrs Artikeln.  Mit der russischen Sprache ist alles komplizierter. </p><br><p>  <strong>Analyseprozess</strong> </p><br><p>  Ich habe die Scheibe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von hier genommen</a> .  Unten ist der Code für meine Version des Parsers. </p><br><p> Um Habrs Wörterbuch zu sammeln, müssen Sie seine Artikel umgehen und den Text der Artikel daraus auswählen.  Ich habe die Metainformationen der Artikel nicht verarbeitet.  Artikel über Habré haben meine "Nummer", z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://habr.com/post/346198/</a> .  Die Aufzählung der Artikel kann von 0 bis 354366 erfolgen. Dies war der letzte Artikel zum Zeitpunkt des Projekts. </p><a name="habracut"></a><br><p>  Für jede Ausgabe versuchen wir, eine HTML-Seite zu erhalten. Wenn dies erfolgreich ist, ziehen wir den Titel und den Text des Artikels aus der HTML-Struktur heraus.  Der Bypass-Code lautet wie folgt: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup dataset = pd.DataFrame() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">350000</span></span>,<span class="hljs-number"><span class="hljs-number">354366</span></span>): r = requests.<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>(<span class="hljs-string"><span class="hljs-string">'https://habrahabr.ru/post/'</span></span> +str(pid) + <span class="hljs-string"><span class="hljs-string">'/'</span></span>) soup = BeautifulSoup(r.text, <span class="hljs-string"><span class="hljs-string">'html5lib'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> soup.find("span", {"class": "post__title-text"}): title = soup.find("span", {"class": "post__title-text"}).text <span class="hljs-type"><span class="hljs-type">text</span></span> = soup.find("div", {"class": "post__text"}).text my_series = pd.Series([pid, title, <span class="hljs-type"><span class="hljs-type">text</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=[<span class="hljs-string"><span class="hljs-string">'id'</span></span>, <span class="hljs-string"><span class="hljs-string">'title'</span></span>, <span class="hljs-string"><span class="hljs-string">'text'</span></span>]) df_new = pd.DataFrame(my_series).transpose() dataset = dataset.append(df_new, ignore_index = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Empirisch festgestellt, dass die Artikel selbst weniger als dreimal so viele sind.  Ich habe auf 4366 Nummern trainiert - so viel lädt mein System in einer halben Stunde. </p><br><p>  Ich habe keine Geschwindigkeitsoptimierung durchgeführt, obwohl sie sagen, dass die Verarbeitung in 100 Threads viel schneller ist, wenn Sie sie starten. </p><br><p>  Ich habe das Ergebnis auf der Festplatte gespeichert </p><br><pre> <code class="hljs pgsql">dataset.to_excel(directory+<span class="hljs-string"><span class="hljs-string">'dataset.xlsx'</span></span>, sheet_name=<span class="hljs-string"><span class="hljs-string">'sheet1'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><p>  - um den langsamen Download aus dem Internet nicht zu wiederholen.  Die Datei hatte eine Größe von 10 Megabyte. </p><br><p>  Ich interessierte mich für die englischen Namen der Instrumente.  Ich brauchte keine Begriffe in verschiedenen Formen, ich wollte sofort normale Formen von Wörtern bekommen.  Es ist klar, dass die häufigsten Wörter "in", "on" und "by" sind. Wir entfernen sie.  Um das Wörterbuch zu normalisieren, habe ich den englischen Stimmer Porter aus der ntlk-Bibliothek verwendet. </p><br><p>  Ich habe die indirekte Methode verwendet, um eine Liste von Wörterbuchwörtern zu erstellen. Siehe den Code, der mit "from sklearn.feature_extraction.text import CountVectorizer" beginnt.  Ich werde das später brauchen. </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk nltk.download(<span class="hljs-string"><span class="hljs-string">'stopwords'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> stopwords <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.stem.porter <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PorterStemmer corpus = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">0</span></span>, len(dataset.<span class="hljs-keyword"><span class="hljs-keyword">index</span></span>)): review = re.sub(<span class="hljs-string"><span class="hljs-string">'[^a-zA-Z]'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, dataset[<span class="hljs-string"><span class="hljs-string">'text'</span></span>][i]) review = review.lower() review = review.split() ps = PorterStemmer() review = [ps.stem(word) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> review <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(stopwords.words(<span class="hljs-string"><span class="hljs-string">'english'</span></span>))] review = <span class="hljs-string"><span class="hljs-string">' '</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(review) corpus.append(review) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CountVectorizer cv = CountVectorizer() X = cv.fit_transform(corpus).toarray() names = cv.get_feature_names() dfnames = pd.DataFrame(names).transpose() dfnames.to_excel(directory+<span class="hljs-string"><span class="hljs-string">'names.xlsx'</span></span>, sheet_name=<span class="hljs-string"><span class="hljs-string">'sheet1'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><p>  Das Objekt <strong>names</strong> ist das gesuchte Wörterbuch.  Wir haben es auf der Festplatte gespeichert. </p><br><p>  <strong>Ergebnisübersicht</strong> </p><br><p>  Es stellte sich heraus, dass mehr als 30.000 bereits normalisierte Wörter vorhanden waren.  Und dies sind nur 4366 Artikelnummern und Wörter nur in Englisch. </p><br><p>  Aus dem Interessanten: </p><br><ol><li><p>  Artikelautoren verwenden viele seltsame „Wörter“, zum Beispiel: aaaaaaaaaaaa, aaaabbbbccccdddd oder zzzhoditqxfpqbcwr </p><br></li><li>  Von Objekt X erhalten wir die Top 10 der beliebtesten englischen Wörter in unserem Beispiel: </li></ol><br><p>  <strong>Word-PC</strong> <br>  iter 4133 <br>  op. 4030 <br>  Rückgabe 2866 <br>  ns 2834 <br>  ID 2740 <br>  Name 2556 <br>  neue 2410 <br>  Daten 2381 <br>  Zeichenfolge 2358 <br>  http 2304 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de413223/">https://habr.com/ru/post/de413223/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de413213/index.html">Apple WWDC 2018: Textsendung</a></li>
<li><a href="../de413215/index.html">GitHub ist jetzt offiziell im Besitz von Microsoft</a></li>
<li><a href="../de413217/index.html">Sind Elektroautos so umweltfreundlich?</a></li>
<li><a href="../de413219/index.html">Willkommen zum QA-Meetup SuperJob</a></li>
<li><a href="../de413221/index.html">Bakterien überleben in einem "Reinraum" während der Montage von Raumfahrzeugen und fressen Reinigungsprodukte</a></li>
<li><a href="../de413225/index.html">Sicherheitswoche 20: Nichttriviale Cyber-Angriffe</a></li>
<li><a href="../de413227/index.html">Was ist Gott unter Kleidern?</a></li>
<li><a href="../de413229/index.html">Erstellen Sie Caffe in Google Colaboratory: Kostenlose Grafikkarte in der Cloud</a></li>
<li><a href="../de413231/index.html">Einführung in Smart Contracts</a></li>
<li><a href="../de413233/index.html">Der uLogin-Dienst sendet Daten von Formularen (E-Mail, Telefon) an eine Website eines Drittanbieters und schweigt darüber</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
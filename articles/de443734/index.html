<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚òπÔ∏è üëº üï∫ Neuronale Netze haben eine erstaunlich einfache Bildklassifizierungsstrategie. ü§üüèº üßñüèæ üï¥üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Faltungs-Neuronale Netze klassifizieren verzerrte Bilder im Gegensatz zu Menschen hervorragend. 


 In diesem Artikel werde ich zeigen, warum fortgesc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronale Netze haben eine erstaunlich einfache Bildklassifizierungsstrategie.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/443734/"><h3>  Faltungs-Neuronale Netze klassifizieren verzerrte Bilder im Gegensatz zu Menschen hervorragend. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/2e6/a7c/4c8/2e6a7c4c8f0ba811e57fa24193375289.jpg"><br><br>  In diesem Artikel werde ich zeigen, warum fortgeschrittene tiefe neuronale Netze verzerrte Bilder perfekt erkennen k√∂nnen und wie dies dazu beitr√§gt, die √ºberraschend einfache Strategie aufzuzeigen, die neuronale Netze zur Klassifizierung nat√ºrlicher Fotografien verwenden.  Diese im ICLR 2019 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ver√∂ffentlichten</a> Entdeckungen haben viele Konsequenzen: Erstens zeigen sie, dass es viel einfacher ist, eine ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ImageNet</a> ‚Äú -L√∂sung zu finden, als gedacht.  Zweitens helfen sie uns, interpretierbarere und verst√§ndlichere Bildklassifizierungssysteme zu schaffen.  Drittens erkl√§ren sie verschiedene Ph√§nomene, die in modernen Faltungs-Neuronalen Netzen (SNA) beobachtet werden, beispielsweise ihre Tendenz, nach Texturen zu suchen (siehe unsere andere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit</a> in ICLR 2019 und den entsprechenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blogeintrag</a> ) und die r√§umliche Anordnung von Teilen des Objekts zu ignorieren. <br><a name="habracut"></a><br><h2>  Gute alte Modelle "Wortsack" </h2><br>  In den guten alten Zeiten, vor dem Aufkommen des tiefen Lernens, war das Erkennen nat√ºrlicher Bilder recht einfach: Wir definieren eine Reihe wichtiger visueller Merkmale (‚ÄûW√∂rter‚Äú), bestimmen, wie oft jedes visuelle Merkmal in einem Bild (‚ÄûTasche‚Äú) vorkommt, und klassifizieren das Bild anhand dieser Zahlen.  Daher werden solche Modelle in der Bildverarbeitung als "Wortsack" (Wortsack oder BoW) bezeichnet.  Angenommen, wir haben zwei visuelle Merkmale, das menschliche Auge und den Stift, und wir m√∂chten die Bilder in zwei Klassen einteilen: "Menschen" und "V√∂gel".  Das einfachste BoW-Modell w√§re das Folgende: F√ºr jedes im Bild gefundene Auge erh√∂hen wir das Zeugnis zugunsten der ‚ÄûPerson‚Äú um 1. Und umgekehrt erh√∂hen wir f√ºr jeden Stift das Zeugnis zugunsten des ‚ÄûVogels‚Äú um 1. Welche Klasse mehr Beweise erh√§lt, das wird es sein. <br><br>  Eine bequeme Eigenschaft eines solch einfachen BoW-Modells ist die Interpretierbarkeit und Klarheit des Entscheidungsprozesses: Wir k√∂nnen genau pr√ºfen, welche besonderen Merkmale des Bildes f√ºr eine bestimmte Klasse sprechen, die r√§umliche Integration von Merkmalen ist sehr einfach (im Vergleich zur nichtlinearen Integration von Merkmalen in tiefen neuronalen Netzen) Verstehe einfach, wie das Modell seine Entscheidungen trifft. <br><br>  Traditionelle BoW-Modelle waren √§u√üerst beliebt und funktionierten vor dem Einbruch des Deep Learning hervorragend, gerieten jedoch aufgrund der relativ geringen Effizienz schnell aus der Mode.  Aber sind wir sicher, dass die neuronalen Netze eine grundlegend andere Entscheidungsstrategie als die BoW verwenden? <br><br><h2>  Tiefeninterpretiertes Netzwerk mit Taschenfunktionen (BagNet) </h2><br>  Um diese Annahme zu testen, kombinieren wir die Interpretierbarkeit und Klarheit von BoW-Modellen mit der Effizienz neuronaler Netze.  Die Strategie sieht folgenderma√üen aus: <br><ul><li>  Teilen Sie das Bild in kleine St√ºcke qx q. </li><li>  Wir leiten die Teile durch das neuronale Netzwerk, um f√ºr jedes Teil einen Nachweis der Klassenzugeh√∂rigkeit (Logs) zu erhalten. </li><li>  Fassen Sie die Beweise in allen Teilen zusammen, um eine L√∂sung auf der Ebene des gesamten Bildes zu erhalten. </li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/474/6f5/363/4746f53632bd9e3e7477de9ecb76d396.png"><br><br>  Um diese Strategie auf einfachste Weise umzusetzen, verwenden wir die Standard-ResNet-50-Architektur und ersetzen fast alle 3x3-Faltungen durch 1x1-Faltungen.  Infolgedessen "sieht" jedes verborgene Element in der letzten Faltungsschicht nur einen kleinen Teil des Bildes (dh sein Wahrnehmungsfeld ist viel kleiner als die Bildgr√∂√üe).  So vermeiden wir das auferlegte Markup des Bildes und kommen dem Standard-SNA so nahe wie m√∂glich, w√§hrend wir eine vorgeplante Strategie anwenden.  Wir nennen die resultierende Architektur BagNet-q, wobei q die Gr√∂√üe des Wahrnehmungsfeldes der obersten Schicht bezeichnet (wir haben das Modell mit q = 9, 17 und 33 getestet).  BagNet-q l√§uft etwa 2,5 l√§nger als das ResNet-50. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b5e/4b6/1c4/b5e4b61c431e103ac9a6ec3fe4b02894.jpg"><br><br>  Die Leistung von BagNet bei Daten aus der ImageNet-Datenbank ist selbst bei Verwendung kleiner Teile beeindruckend: Fragmente mit 17 x 17 Pixel reichen aus, um die Effizienz des AlexNet-Levels zu erreichen, und Fragmente mit 33 x 33 Pixel reichen aus, um eine Genauigkeit von 87% zu erreichen und in die Top 5 zu gelangen.  Sie k√∂nnen die Effizienz steigern, indem Sie die 3x3-Pakete sorgf√§ltiger platzieren und die Hyperparameter anpassen. <br><br>  Dies ist unser erstes gro√ües Ergebnis: ImageNet kann nur mit einer Reihe kleiner Bildfunktionen gel√∂st werden.  Die entfernten r√§umlichen Beziehungen der Teile der Komposition, wie die Form von Objekten oder die Interaktion zwischen Teilen des Objekts, k√∂nnen vollst√§ndig ignoriert werden.  Sie werden absolut nicht ben√∂tigt, um das Problem zu l√∂sen. <br><br>  Ein bemerkenswertes Merkmal von BagNet'ov ist die Transparenz ihres Entscheidungssystems.  Sie k√∂nnen beispielsweise herausfinden, welche Merkmale der Bilder f√ºr eine bestimmte Klasse am charakteristischsten sind.  Zum Beispiel wird Schleie, ein gro√üer Fisch, normalerweise durch das Bild von Fingern auf einem gr√ºnen Hintergrund erkannt.  Warum?  Denn auf den meisten Fotos in dieser Kategorie gibt es einen Fischer, der eine Schleie als Troph√§e h√§lt.  Und wenn BagNet das Bild f√§lschlicherweise als Linie erkennt, geschieht dies normalerweise, weil sich irgendwo auf dem Foto Finger auf einem gr√ºnen Hintergrund befinden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/175/197/727/175197727cc15da939117f5c2502d82c.jpg"><br>  <i>Die charakteristischsten Teile von Bildern.</i>  <i>Die obere Reihe in jeder Zelle entspricht der korrekten Erkennung und die untere Zeile den ablenkenden Fragmenten, die zu einer falschen Erkennung gef√ºhrt haben</i> <br><br>  Wir erhalten auch die genaue ‚ÄûW√§rmekarte‚Äú, die zeigt, welche Teile des Bildes zur Entscheidung beigetragen haben. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/89b/510/f5b/89b510f5b5d816a2a1d8590f4487abf6.jpg"><br>  <i>Heatmaps sind keine Ann√§herung, sie zeigen genau den Beitrag jedes Teils des Bildes.</i> <br><br>  BagNets zeigen, dass Sie mit ImageNet nur aufgrund schwacher statistischer Korrelationen zwischen lokalen Merkmalen von Bildern und der Kategorie von Objekten eine hohe Genauigkeit erzielen k√∂nnen.  Wenn dies ausreicht, warum sollten Standard-Neuronale Netze von ResNet-50 dann etwas grundlegend anderes lernen?  Warum sollte ResNet-50 komplexe Beziehungen in gro√üem Ma√üstab wie die Form eines Objekts untersuchen, wenn die F√ºlle lokaler Merkmale des Bildes ausreicht, um das Problem zu l√∂sen? <br><br>  Um die Hypothese zu testen, dass moderne SNAs einer Strategie folgen, die dem Betrieb der einfachsten BoW-Netzwerke √§hnelt, haben wir verschiedene Netzwerke - ResNet, DenseNet und VGG - auf die folgenden ‚ÄûZeichen‚Äú von BagNet getestet: <br><ul><li>  Die L√∂sungen sind unabh√§ngig vom r√§umlichen Mischen der Bildmerkmale (dies kann nur bei VGG-Modellen √ºberpr√ºft werden). </li><li>  √Ñnderungen verschiedener Teile des Bildes sollten nicht voneinander abh√§ngen (im Sinne ihres Einflusses auf die Klassenzugeh√∂rigkeit). </li><li>  Fehler, die von Standard-SNA und BagNet'ami gemacht wurden, sollten √§hnlich sein. </li><li>  Standard-SNS und BagNet sollten f√ºr √§hnliche Funktionen empfindlich sein. </li></ul><br><br>  In allen vier Experimenten fanden wir √ºberraschend √§hnliche Verhaltensweisen von SNS und BagNet.  Im letzten Experiment haben wir beispielsweise gezeigt, dass BagNet f√ºr dieselben Stellen in den Bildern wie die SNA am empfindlichsten ist (wenn sie sich beispielsweise √ºberlappen).  Tats√§chlich sagen BagNet-W√§rmekarten (r√§umliche Empfindlichkeitskarten) die Empfindlichkeit von DenseNet-169 besser voraus als W√§rmekarten, die mit Attributionsmethoden wie DeepLift (direkte Berechnung von W√§rmekarten f√ºr DenseNet-169) erhalten wurden.  Nat√ºrlich wiederholt der SNA das Verhalten von BagNet nicht genau, aber bestimmte Abweichungen zeigen dies.  Insbesondere werden die Abh√§ngigkeiten umso gr√∂√üer, je tiefer die Netzwerke werden, und desto gr√∂√üer werden die Abh√§ngigkeiten.  Daher sind tiefe neuronale Netze in der Tat eine Verbesserung gegen√ºber BagNet-Modellen, aber ich glaube nicht, dass sich die Grundlage ihrer Klassifizierung irgendwie √§ndert. <br><br><h2>  √úber die BoW-Klassifizierung hinausgehen </h2><br>  Die Beobachtung der SNA-Entscheidungsfindung im Stil von BoW-Strategien kann einige der seltsamen Merkmale der SNA erkl√§ren.  Dies erkl√§rt zun√§chst, warum der SNA so <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">an Texturen gebunden ist</a> .  Zweitens, warum der SNA nicht empfindlich auf das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mischen</a> von Bildteilen reagiert.  Dies kann sogar das Vorhandensein von gegnerischen Aufklebern und gegnerischen St√∂rungen erkl√§ren: Verwirrende Signale k√∂nnen an einer beliebigen Stelle im Bild platziert werden, und der SNS f√§ngt dieses Signal mit Sicherheit ab, unabh√§ngig davon, ob es zum Rest des Bildes passt. <br><br>  Tats√§chlich zeigt unsere Arbeit, dass der SNA beim Erkennen von Bildern viele schwache statistische Gesetze verwendet und nicht wie Menschen Teile des Bildes auf Objektebene integriert.  Gleiches gilt h√∂chstwahrscheinlich f√ºr andere Aufgaben und sensorische Modalit√§ten. <br><br>  Wir m√ºssen unsere Architekturen, Aufgaben und Trainingsmethoden sorgf√§ltig planen, um die Tendenz zu √ºberwinden, schwache statistische Korrelationen zu verwenden.  Ein Ansatz besteht darin, die Verzerrung des SNA-Trainings von kleinen lokalen Merkmalen auf globalere zu √ºbertragen.  Die andere besteht darin, die Merkmale zu entfernen oder zu ersetzen, auf die sich das neuronale Netzwerk nicht verlassen sollte, wie wir es in einer anderen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ver√∂ffentlichung</a> f√ºr ICLR 2019 getan haben, indem die Stil√ºbertragungsvorverarbeitung verwendet wird, um die Textur eines nat√ºrlichen Objekts zu beseitigen. <br><br>  Eines der gr√∂√üten Probleme bleibt jedoch die Klassifizierung von Bildern: Wenn lokale Merkmale ausreichen, gibt es keinen Anreiz, die reale "Physik" der nat√ºrlichen Welt zu studieren.  Wir m√ºssen die Aufgabe so umstrukturieren, dass Modelle verschoben werden, um die physikalische Natur von Objekten zu untersuchen.  Um dies zu tun, m√ºssen Sie h√∂chstwahrscheinlich √ºber die reine Beobachtungslehre hinaus zu den Korrelationen von Eingabe- und Ausgabedaten gehen, damit Modelle kausale Zusammenh√§nge extrahieren k√∂nnen. <br><br>  Zusammengenommen legen unsere Ergebnisse nahe, dass die SNA einer √§u√üerst einfachen Klassifizierungsstrategie folgen kann.  Die Tatsache, dass eine solche Entdeckung im Jahr 2019 gemacht werden kann, unterstreicht, wie wenig wir die internen Merkmale der Arbeit tiefer neuronaler Netze noch verstehen.  Der Mangel an Verst√§ndnis erlaubt es uns nicht, grundlegend verbesserte Modelle und Architekturen zu entwickeln, die die L√ºcke zwischen der Wahrnehmung von Mensch und Maschine schlie√üen.  Durch die Vertiefung unseres Verst√§ndnisses k√∂nnen wir Wege finden, um diese L√ºcke zu schlie√üen.  Dies kann √§u√üerst n√ºtzlich sein: Beim Versuch, die SNA in Richtung der physikalischen Eigenschaften von Objekten zu verschieben, erreichten wir pl√∂tzlich eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Widerstandsf√§higkeit gegen L√§rm auf</a> menschlicher Ebene.  Ich erwarte das Erscheinen einer Vielzahl anderer interessanter Ergebnisse auf unserem Weg zur Entwicklung der SNA, die die physische und kausale Natur unserer Welt wirklich verstehen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de443734/">https://habr.com/ru/post/de443734/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de443722/index.html">Design und Benennung von Warteschlangen</a></li>
<li><a href="../de443724/index.html">AMD Radeon VII: High-End-Chip (Teil 1)</a></li>
<li><a href="../de443726/index.html">Setup-Funktionen von Palo Alto Networks: SSL VPN</a></li>
<li><a href="../de443728/index.html">Google Plus funktioniert nicht mehr. Na und?</a></li>
<li><a href="../de443730/index.html">Strg-Alt-Entf: Geplante Veralterung von Programmierern</a></li>
<li><a href="../de443736/index.html">Einrichten von Network Management Tools (NUT) von Grund auf neu, um eine lokal verbundene USV zu verwalten</a></li>
<li><a href="../de443738/index.html">So finden Sie einen Job in Deutschland f√ºr IT-Profis</a></li>
<li><a href="../de443740/index.html">Erste Version des Testtools f√ºr die offene Produktsuche</a></li>
<li><a href="../de443744/index.html">Encyclopedia of Lighting von Naughty Dog</a></li>
<li><a href="../de443746/index.html">Spielemarkt, Trends und Vorhersagen - Gro√üartige Analysen von App Annie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👆🏿 🏮 🌩️ Como desenhar e ler som 👨🏿‍🍳 👩🏾‍🤝‍👩🏻 👨🏻‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Foto de Matthew Potter  CC-BY
 
 Como conectar informações de áudio e visuais? Esta pergunta é freqüentemente feita por cientistas e amadores de todo ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como desenhar e ler som</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/audiomania/blog/393257/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/pw/ry/9p/pwry9psyvxotycy6ivmkj-qkosw.jpeg"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Foto de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Matthew Potter </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CC-BY</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Como conectar informações de áudio e visuais? </font><font style="vertical-align: inherit;">Esta pergunta é freqüentemente feita por cientistas e amadores de todo o mundo. </font><font style="vertical-align: inherit;">Assim, em fevereiro de 2006, as notícias de que os cientistas conseguiram reproduzir sons de uma panela de barro com mais de 6500 anos se espalharam rapidamente pela Internet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O oleiro teria aplicado um ritmo musical ao pote durante sua fabricação. </font><font style="vertical-align: inherit;">Infelizmente, isso acabou sendo uma piada malsucedida de April Fools na televisão belga.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No entanto, Patrick Feaster </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conseguiu</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> processar o registro, cuja idade excede 1000 anos. </font><font style="vertical-align: inherit;">Nesta ocasião, em maio de 2011, ele falou na conferência da Association for Recorded Sound Collections (ARSC) com a abertura da "paleoespectrofonia".</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mergulhando na história: transcrevendo registros passados</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick usa tecnologia moderna (neste caso, não particularmente moderna, desde que o espectrograma foi inventado há muito tempo) para converter objetos visuais em sons. No entanto, a humanidade nem sempre seguiu esse caminho e tentou, pelo contrário, “capturar” o som nas imagens. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por um longo tempo (antes da criação do fonógrafo por Thomas Edison), as pessoas ficaram preocupadas com a questão: como criar uma maneira de fixar músicas que ajudassem a pessoa que assistia à gravação a tocar a melodia em suas cabeças tão facilmente quanto os músicos profissionais quando observavam a partitura. Infelizmente, de acordo com o Dr. Fister, essa tarefa é inatingível em princípio, uma vez que nosso cérebro na maioria dos casos não é bom o suficiente para converter informações visuais em áudio.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Talvez a solução para esse problema no passado não tenha sido coroada de sucesso, mas a história nos deixou muitas evidências de como pessoas de diferentes épocas tentaram criar sistemas de gravação de som semelhantes. O mais famoso desses sistemas formou a base do fono-autógrafo - o antecessor do fonógrafo, inventado pelo francês Edouard Martenville. Um fonoautógrafo era um dispositivo no qual o som passava através de um cone, fazendo vibrar a membrana conectada à agulha. A agulha, por sua vez, desenhava linhas ondulatórias em um cilindro de vidro coberto de papel sujo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com a ajuda de um fonógrafo, o som podia ser capturado, mas não havia como reproduzi-lo. Esse é o problema que Fister decidiu. Em 2008, ele, seus colegas e o especialista em áudio David Giovannoni se reuniram no Laboratório Nacional Lawrence Berkeley para decifrar um dos fonoautógrafos mais bem preservados de Martenville. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O Lawrence's Lab desenvolveu tecnologias para extrair sons de fotografias de alta qualidade que capturavam imagens de mídia de cera frágil ou discos quebrados. Usando essas tecnologias, os cientistas receberam do fonoautograma a gravação da música "Moonlight" ("Au Clair de la Lune"), feita em 1860. Acredita-se que este seja o primeiro registro em que podemos distinguir uma voz humana.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No entanto, a solução para esse problema não foi suficiente para Fister: posteriormente, ele não apenas gravou o som de mais de 50 fonoautogramas, mas também investigou tentativas anteriores de "gravar som". </font><font style="vertical-align: inherit;">Por mais estranho que pareça, o serviço do Google Livros ajudou esse cientista. </font><font style="vertical-align: inherit;">Usando isso, Fister escreveu personagens de livros que eram constantemente ignorados, considerados peculiaridades históricas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ele encontrou a mais antiga linha ondulada no livro de 1806. </font><font style="vertical-align: inherit;">Através de outras técnicas, ele foi capaz de decifrar a melodia de 1677, que foi gravada por muitos pontos. </font><font style="vertical-align: inherit;">Outro foi descoberto nos registros do século 10, onde as linhas mostravam qual chave deveria ser cantada. </font><font style="vertical-align: inherit;">Exemplos de tais entradas podem ser encontrados em seu site </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Phonozoic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Outra abordagem</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pesquisadores do MIT, Microsoft e Adobe seguem um caminho diferente: eles </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">reconstroem o</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> som a partir de uma imagem em movimento (ou melhor, vibrando). Pesquisadores desenvolveram um algoritmo para obter um sinal de áudio a partir de vibrações gravadas em vídeo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em um desses experimentos, eles conseguiram extrair fala legível da gravação de um pacote vazio por baixo dos chips. Em várias outras experiências, o mesmo poderia ser feito com a superfície da folha de alumínio, um copo de água e até com as folhas de uma planta doméstica. Em 2014, a equipe apresentou suas realizações na conferência anual do SIGGRAPH. ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vídeo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de uma apresentação de um dos pesquisadores que trabalhou no projeto na conferência TED.)</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O fato é que, quando um som entra em contato com um objeto, ele vibra. Os movimentos criados por essas vibrações são tão leves e invisíveis que uma pessoa não pode vê-las. No entanto, a câmera pode “vê-los”: para extrair o sinal de áudio do vídeo, os cientistas usaram a gravação de vídeo com uma taxa de captura de quadros maior que a frequência do sinal de áudio. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inicialmente, câmeras com uma frequência de gravação de 2000 e 6000 quadros por segundo foram usadas nos experimentos, mas os pesquisadores tentaram usar outras câmeras mais econômicas. Obviamente, não foi possível extrair fala articulada do vídeo gravado a uma taxa de quadros de 60 quadros por segundo, mas ainda assim parecia possível entender quantas pessoas estavam na sala, seu gênero e até os recursos de sua pronúncia.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
É claro que, ao pensar em usar esses desenvolvimentos, "histórias de espionagem" vêm à mente, no entanto, os próprios pesquisadores chamam seu projeto de oportunidade de descobrir novas facetas na imagem dos objetos e estudar suas propriedades anteriormente inexploradas. </font><font style="vertical-align: inherit;">E se há centenas de anos, as pessoas tentavam encontrar uma maneira de "gravar som", agora esse "registro" se torna um efeito colateral, o que, por sua vez, ajuda a revelar novas propriedades de objetos familiares.</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faça você mesmo</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como já mencionado, o primeiro fonoautograma foi decodificado graças à tecnologia de reprodução de som de fotografias de discos antigos (já </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">escrevemos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sobre essa tecnologia </font><font style="vertical-align: inherit;">em um de nossos materiais - ele também contém links para gravações de áudio descriptografadas). No entanto, Patrick Fister enfatiza que qualquer um pode lidar com essa tarefa - se ele souber o que fazer. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um processo detalhado é descrito </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">neste</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> material. Por conta própria, observamos que, para resolver o problema, você precisará de uma foto de alta qualidade, habilidades básicas do Photoshop (a onda desenhada no vinil deve ser digitalizada, "endireitada" - a ranhura na placa é torcida em espiral - remove todos os tipos de ruído e deslocamentos), bem como um computador relativamente poderoso com uma grande quantidade de RAM.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para converter a imagem resultante em um arquivo WAV, Patrick usa um software bastante exótico: este é o ImageToSound. É gratuito, mas, apesar disso, é muito difícil encontrar na rede (Patrick compartilhou a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fonte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O programa converte sequencialmente cada bloco de imagem (largura do bloco - 1 pixel) em uma amostra de áudio. Infelizmente, este software nem suporta o Windows 7 (o autor usa um computador separado com o Windows 98 para funcionar). Como alternativa, Fister sugere usar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o programa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> AEO-Light, mas alerta que ele próprio não está completamente familiarizado com os meandros de trabalhar com ele.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O último passo é controlar a velocidade de reprodução. Aqui a matemática simples vem em socorro. Primeiro, você precisa conhecer a velocidade de reprodução na placa original, o comprimento de uma revolução da onda digitalizada (após a "despiralização") em pixels e a frequência de amostragem do arquivo final. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se a imagem foi editada em um arquivo de áudio com uma frequência de amostragem de 44,1 kHz, isso significa que o segundo arquivo de áudio será igual a 44 100 pixels da imagem. Se, por exemplo, a velocidade de uma música em um disco de vinil era de 50 revoluções por minuto, e após a digitalização e a despiralização, uma revolução do disco levava 30.000 pixels, obtemos 1.500.000 pixels por minuto (50x30.000).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se dividirmos esse número por 60, obteremos o número de pixels por segundo (1.500.000 / 60 = 25.000). </font><font style="vertical-align: inherit;">Divida a taxa de amostragem pelo número de pixels por segundo (44 100/25 000 = 1,764). </font><font style="vertical-align: inherit;">Multiplique o número resultante pelo tamanho do arquivo de áudio (tempo de reprodução da música) e obtenha o tempo com que esse arquivo foi originalmente gravado. </font><font style="vertical-align: inherit;">Se a velocidade de reprodução da gravação original for desconhecida, Patrick recomenda que você escolha a velocidade final de ouvido. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick Fister adverte - este é um trabalho minucioso que exige tempo e paciência, mas ao mesmo tempo gera resultados surpreendentes: especialmente quando se trata das vozes do passado, que, ao que parece, foram perdidas para sempre. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS Mais materiais sobre o tema do áudio - em nosso blog " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">World of Hi-Fi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ".</font></font></i></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt393257/">https://habr.com/ru/post/pt393257/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt393243/index.html">Os conspirologistas se alegram: após o aparecimento dos OVNIs, a transmissão da NASA com a ISS foi cortada</a></li>
<li><a href="../pt393247/index.html">Algumas histórias típicas do desenvolvedor</a></li>
<li><a href="../pt393249/index.html">Коллекция Telegram ботов для гиков</a></li>
<li><a href="../pt393251/index.html">Ele sabe tudo sobre você</a></li>
<li><a href="../pt393253/index.html">O segundo trailer da WarCraft suscita sérias preocupações</a></li>
<li><a href="../pt393261/index.html">O MediaTek Labs convida você para o próximo seminário on-line gratuito sobre o desenvolvimento de gadgets para casa inteligente</a></li>
<li><a href="../pt393263/index.html">Como dividir os trilhões de dólares ganhos com a mineração no espaço?</a></li>
<li><a href="../pt393265/index.html">Impressoras invadidas em universidades alemãs imprimem muitos folhetos anti-semitas</a></li>
<li><a href="../pt393267/index.html">Relógio do sono</a></li>
<li><a href="../pt393269/index.html">8 pequenas coisas da China para organizar o local de trabalho de um especialista em TI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
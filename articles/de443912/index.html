<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📷 👨🏼 💨 Hausgemachte BigData. Teil 1. Spark-Streaming-Praxis in einem AWS-Cluster 🤽🏿 🥋 🍯</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Tag. 

 In diesem Artikel werden wir Apache Kafka, Apache Spark, Zookeeper und Spark-Shell auf der EC2 AWS-Plattform (Amazon Web Services) zu Ha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Hausgemachte BigData. Teil 1. Spark-Streaming-Praxis in einem AWS-Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/443912/"> Guten Tag. <br><br>  In diesem Artikel werden wir Apache Kafka, Apache Spark, Zookeeper und Spark-Shell auf der EC2 AWS-Plattform (Amazon Web Services) zu Hause installieren und lernen, wie Sie alles verwenden. <br><a name="habracut"></a><br><h3>  Einführung in Amazon Web Services </h3><br>  1.1.  Sie müssen sich unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aws.amazon.com/console</a> registrieren.  Geben Sie einen Namen ein und merken Sie sich das Passwort. <br><br>  1.2.  Konfigurieren Sie Knoteninstanzen für Zookeeper- und Kafka-Dienste. <br><br><ul><li>  Wählen Sie "Services-&gt; EC2" aus dem Menü.  Wählen Sie als Nächstes die Version des Betriebssystems des Images der virtuellen Maschine aus, wählen Sie Ubuntu Server 16.04 LTS (HVM), SSD-Volume-Typ, klicken Sie auf „Auswählen“. Wir konfigurieren die Serverinstanz: Geben Sie „t3.medium“ mit den Parametern 2vCPU, 4 GB Speicher, Allgemeiner Zweck ein Klicken Sie auf "Weiter: Instanzdetails konfigurieren". </li><li>  Fügen Sie die Anzahl der Instanzen 1 hinzu und klicken Sie auf "Weiter: Speicher hinzufügen". </li><li>  Wir akzeptieren den Standardwert für die Festplattengröße von 8 GB und ändern den Typ in "Magnetisch" (in den Produktionseinstellungen basierend auf Datenvolumen und Hochleistungs-SSD). </li><li>  Geben Sie im Abschnitt "Tag-Instanzen" für "Name" den Namen der Instanz des Knotens "Home1" ein (wobei 1 nur eine Seriennummer ist) und klicken Sie auf "Weiter: ...". </li><li>  Wählen Sie im Abschnitt "Sicherheitsgruppen konfigurieren" die Option "Vorhandene Sicherheitsgruppe verwenden" aus, indem Sie den Namen der Sicherheitsgruppe ("Spark_Kafka_Zoo_Project") auswählen und die Regeln für eingehenden Datenverkehr festlegen.  Klicken Sie auf "Weiter: ..." </li><li>  Scrollen Sie durch den Überprüfungsbildschirm, um Ihre Eingaben zu überprüfen und Launch zu starten. </li><li>  Um eine Verbindung zu den Clusterknoten herzustellen, müssen Sie ein Paar öffentlicher Schlüssel zur Identifizierung und Autorisierung erstellen (in unserem Fall die vorhandenen verwenden).  Wählen Sie dazu in der Liste den Operationstyp „Vorhandenes Paar verwenden“. </li></ul><br><h3>  Schlüsselerstellung </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laden Sie Putty</a> für den Client <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">herunter</a> oder verwenden Sie die SSH-Verbindung vom Terminal. </li><li>  Die .pem-Schlüsseldatei verwendet der Einfachheit halber das alte Format. Wir konvertieren es in das von Putty verwendete ppk-Format.  Führen Sie dazu das Dienstprogramm PuTTYgen aus und laden Sie den Schlüssel im alten PEM-Format in das Dienstprogramm.  Wir konvertieren den Schlüssel und speichern ihn (Save Private Key) zur späteren Verwendung im Home-Ordner mit der Erweiterung .ppk. </li></ul><br><h3>  Clusterstart </h3><br>  1.3.  Benennen Sie die Clusterknoten der Einfachheit halber in Node01-04-Notation um.  Um vom lokalen Computer aus über SSH eine Verbindung zu Clusterknoten herzustellen, müssen Sie die IP-Adresse des Knotens und seinen öffentlichen / privaten DNS-Namen ermitteln, jeden Clusterknoten einzeln auswählen und für die ausgewählte Instanz seinen öffentlichen / privaten DNS-Namen für die Verbindung über SSH und für die Installation notieren Software zur Textdatei HadoopAdm01.txt. <br><br>  Beispiel: ec2-35-162-169-76.us-west-2.compute.amazonaws.com <br><br><h3>  Installieren Sie Apache Kafka im SingleNode-Modus auf einem AWS-Clusterknoten </h3><br>  2.1.  Um die Software zu installieren, wählen Sie unseren Knoten aus (kopieren Sie dessen öffentliches DNS), um eine Verbindung über SSH herzustellen.  Wir konfigurieren die Verbindung über SSH.  Wir verwenden den gespeicherten Namen des ersten Knotens, um die Verbindung über SSH mithilfe des in Abschnitt 1.3 erstellten privaten / öffentlichen Schlüsselpaars „HadoopUser01.ppk“ zu konfigurieren.  Wir gehen über die Schaltfläche Durchsuchen zum Abschnitt Verbindung / Authentifizierung und suchen nach dem Ordner, in dem wir zuvor die Datei „HadoopUserXX.ppk“ gespeichert haben. <br><br>  Wir speichern die Verbindungskonfiguration in den Einstellungen. <br><br>  2.2.  Wir sind mit dem Knoten verbunden und verwenden login: ubuntu. <br><br>  • Mit Root-Rechten aktualisieren wir Pakete und installieren zusätzliche Pakete, die für die weitere Installation und Konfiguration des Clusters erforderlich sind. <br><br><pre><code class="plaintext hljs">sudo apt-get update sudo apt-get -y install wget net-tools netcat tar</code> </pre> <br>  • Installieren Sie Java 8 jdk und überprüfen Sie die Version von Java. <br><br><pre> <code class="plaintext hljs">sudo apt-get -y install openjdk-8-jdk</code> </pre><br>  • Für eine normale Leistung des Clusterknotens müssen Sie die Einstellungen für den Speicheraustausch anpassen.  VM-Swappines sind standardmäßig auf 60% eingestellt. Dies bedeutet, dass das System bei einer Speicherauslastung von 60% aktiv Daten vom RAM auf die Festplatte austauscht.  Abhängig von der Linux-Version kann der Parameter VM swappines auf 0 oder 1 gesetzt werden: <br><br><pre> <code class="plaintext hljs">sudo sysctl vm.swappiness=1</code> </pre><br>  • Um die Einstellungen während des Neustarts zu speichern, fügen Sie der Konfigurationsdatei eine Zeile hinzu. <br><br><pre> <code class="plaintext hljs">echo 'vm.swappiness=1' | sudo tee --append /etc/sysctl.conf</code> </pre><br>  • Bearbeiten von Einträgen in der Datei / etc / hosts zur bequemen Auflösung der Clusterknotennamen kafka und zookeeper in private IP-Adressen der zugewiesenen Clusterknoten. <br><br><pre> <code class="plaintext hljs">echo "172.31.26.162 host01" | sudo tee --append /etc/hosts</code> </pre><br>  Wir überprüfen die korrekte Erkennung von Namen, indem wir einen der Einträge pingen. <br><br>  • Laden Sie die neuesten aktuellen Versionen (http://kafka.apache.org/downloads) der Kafka- und Scala-Distributionen herunter und erstellen Sie ein Verzeichnis mit Installationsdateien. <br><br><pre> <code class="plaintext hljs">wget http://mirror.linux-ia64.org/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz tar -xvzf kafka_2.12-2.1.0.tgz ln -s kafka_2.12-2.1.0 kafka</code> </pre><br>  • Löschen Sie die tgz-Archivdatei, wir brauchen sie nicht mehr <br><br>  • Versuchen wir dazu, den Zookeeper-Dienst zu starten: <br><br><pre> <code class="plaintext hljs">~/kafka/bin/zookeeper-server-start.sh -daemon ~/kafka/config/zookeeper.properties</code> </pre><br>  Zookeeper startet mit Standardstartoptionen.  Sie können das Protokoll überprüfen: <br><br><pre> <code class="plaintext hljs"> tail -n 5 ~/kafka/logs/zookeeper.out</code> </pre><br>  Um sicherzustellen, dass der Zookeeper-Daemon nach dem Neustart gestartet wird, müssen wir Zookeper als Hintergrunddienst starten: <br><br><pre> <code class="plaintext hljs">bin/zookeeper-server-start.sh -daemon config/zookeeper.properties</code> </pre><br>  Um den Start von Zookepper zu überprüfen, überprüfen Sie <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181</code> </pre><br>  2.3.  Wir konfigurieren den Zookeeper- und Kafka-Dienst für die Arbeit.  Bearbeiten / erstellen Sie zunächst die Datei /etc/systemd/system/zookeeper.service (Dateiinhalt unten). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Zookeeper server Documentation=http://zookeeper.apache.org Requires=network.target remote-fs.target After=network.target remote-fs.target [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/zookeeper-server-start.sh /home/ubuntu/kafka/config/zookeeper.properties ExecStop=/home/ubuntu/kafka/bin/zookeeper-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre><br>  Bearbeiten / erstellen Sie als Nächstes für Kafka die Datei /etc/systemd/system/kafka.service (Dateiinhalt unten). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Kafka server (broker) Documentation=http://kafka.apache.org/documentation.html Requires=zookeeper.service [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/kafka-server-start.sh /home/ubuntu/kafka/config/server.properties ExecStop=/home/ubuntu/kafka/bin/kafka-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre><br>  • Aktivieren Sie systemd-Skripte für Kafka- und Zookeeper-Dienste. <br><br><pre> <code class="plaintext hljs">sudo systemctl enable zookeeper sudo systemctl enable kafka</code> </pre><br>  • Überprüfen Sie die Funktion von systemd-Skripten. <br><br><pre> <code class="plaintext hljs">sudo systemctl start zookeeper sudo systemctl start kafka sudo systemctl status zookeeper sudo systemctl status kafka sudo systemctl stop zookeeper sudo systemctl stop kafka</code> </pre><br>  • Überprüfen Sie die Wartungsfreundlichkeit der Dienste von Kafka und Zookeeper. <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181 netcat -vz localhost 9092</code> </pre><br>  • Überprüfen Sie die Zookeeper-Protokolldatei. <br><br><pre> <code class="plaintext hljs">cat logs/zookeeper.out</code> </pre><br><h3>  Erste Freude </h3><br>  2.4.  Wir erstellen unser erstes Thema auf dem zusammengebauten Kafka-Server. <br><ul><li>  Es ist wichtig, die Verbindung zu "host01: 2181" zu verwenden, wie Sie in der Konfigurationsdatei server.properties angegeben haben. </li><li>  Wir schreiben einige Daten in das Thema. </li></ul><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list host01:9092 --topic first_topic    </code> </pre><br>  Strg-C - Beenden Sie die Themenkonsole. <br><br>  • Versuchen Sie nun, die Daten aus dem Thema zu lesen. <br><br><pre> <code class="plaintext hljs">kafka-console-consumer.sh --bootstrap-server host01:9092 --topic last_topic --from-beginning</code> </pre><br>  • Zeigen Sie eine Liste der Kafka-Themen an. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --list</code> </pre><br>  • Bearbeiten der Kafka-Serverparameter für die Optimierung der Einrichtung einzelner Cluster <br>  # Sie müssen den ISR-Parameter auf 1 ändern. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --config min.insync.replicas=1 --topic __consumer_offsets --alter</code> </pre><br>  • Starten Sie den Kafka-Server neu und versuchen Sie erneut, den Consumer-Ohm anzuschließen <br><br>  • Sehen wir uns eine Liste der Themen an. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper host01:2181 --list</code> </pre><br><h3>  Konfigurieren Sie Apache Spark auf einem Cluster mit einem Knoten </h3><br>  Wir haben eine Instanz des Knotens mit den auf AWS installierten Zookeeper- und Kafka-Diensten vorbereitet. Jetzt müssen Sie Apache Spark installieren. <br><br>  3.1.  Laden Sie die neueste Apache Spark-Distribution herunter. <br><br><pre> <code class="plaintext hljs">wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.6.tgz</code> </pre><br>  • Entpacken Sie die Distribution und erstellen Sie einen symbolischen Link für Spark und löschen Sie unnötige Archivdateien. <br><br><pre> <code class="plaintext hljs">tar -xvf spark-2.4.0-bin-hadoop2.6.tgz ln -s spark-2.4.0-bin-hadoop2.6 spark rm spark*.tgz</code> </pre><br>  • Wechseln Sie in das Verzeichnis sbin und führen Sie den Funkenassistenten aus. <br><br><pre> <code class="plaintext hljs">./start-master.sh</code> </pre><br>  • Stellen Sie über einen Webbrowser eine Verbindung zum Spark-Server an Port 8080 her. <br><br>  • Führen Sie Spark-Slaves auf demselben Knoten aus <br><br><pre> <code class="plaintext hljs">./start-slave.sh spark://host01:7077</code> </pre><br>  • Führen Sie die Funkenschale mit dem Master auf Host01 aus. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre><br>  • Wenn der Start nicht funktioniert, fügen Sie den Pfad zu Spark in bash hinzu. <br><br><pre> <code class="plaintext hljs">vi ~/.bashrc #      SPARK_HOME=/home/ubuntu/spark export PATH=$SPARK_HOME/bin:$PATH</code> </pre><br><pre> <code class="plaintext hljs">source ~/.bashrc</code> </pre><br>  • Führen Sie die Funkenschale erneut mit dem Master auf Host01 aus. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre><br>  3.2.  Ein Einzelknotencluster mit Kafka, Zookeeper und Spark funktioniert.  Hurra! <br><br><h3>  Ein bisschen Kreativität </h3><br>  4.1.  Laden Sie den Scala-IDE-Editor herunter (unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">scala-ide.org</a> ).  Wir beginnen und beginnen Code zu schreiben.  Hier werde ich mich nicht mehr wiederholen, da es einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">guten Artikel über Habré gibt</a> . <br><br>  4.2.  Nützliche Literatur und Kurse helfen: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kurse.hadoopinrealworld.com/courses/enrolled/319237</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">data-flair.training/blogs/kafka-consumer</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.udemy.com/apache-spark-with-scala-hands-on-with-big-data</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de443912/">https://habr.com/ru/post/de443912/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de443902/index.html">Wie wir den internen Hackathon gewonnen haben, indem wir Skibidi, Zahnseide und Javascript gelernt haben</a></li>
<li><a href="../de443904/index.html">Was tun, wenn nicht genügend Würfel vorhanden sind, um einen Roboter zu bauen?</a></li>
<li><a href="../de443906/index.html">Video Analytics Harvester: Was Gehirn und Maschinen mit unseren Gesichtern machen</a></li>
<li><a href="../de443908/index.html">Wir steuern das Android-Gerät</a></li>
<li><a href="../de443910/index.html">Scratch-Programmierkonzepte</a></li>
<li><a href="../de443914/index.html">Wie haben wir SCRUM gemacht?</a></li>
<li><a href="../de443916/index.html">Das Kulturministerium und die Filmemacher schlagen vor, ein staatliches System zur Aufzeichnung von Zuschauern im Internet zu schaffen</a></li>
<li><a href="../de443918/index.html">Zwei neue minimalistische Taschenspiele</a></li>
<li><a href="../de443924/index.html">Die DSGVO schützt Ihre persönlichen Daten sehr gut, aber nur, wenn Sie sich in Europa befinden</a></li>
<li><a href="../de443926/index.html">Autos "Katamarane"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
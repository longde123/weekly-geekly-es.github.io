<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜô üôÖüèæ üíë Automatisches Fotostudio, Teil 1 üìà üë©üèΩ‚Äçü§ù‚Äçüë®üèº üõ∞Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor anderthalb Jahren st√∂berte ich im Blog eines der erfolgreichen russischen Portr√§tfotografen mit einem erkennbaren Stil, und der Gedanke kam mir in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Automatisches Fotostudio, Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460605/"><p>  Vor anderthalb Jahren st√∂berte ich im Blog eines der erfolgreichen russischen Portr√§tfotografen mit einem erkennbaren Stil, und der Gedanke kam mir in den Sinn, warum nicht einfach die Kamera auf ein Stativ stellen, die Lichter einmal ins Studio stellen, alle Kameraeinstellungen vornehmen und die automatische Fotoverarbeitung mit dem Vorgegebenen durchf√ºhren Profil?  Die Blog-Fotos waren gro√üartig, aber sehr √§hnlich. </p><br><p><img src="https://habrastorage.org/webt/0r/bv/dr/0rbvdr3qqwzvlftmkcttiqlrf7q.jpeg"></p><a name="habracut"></a><br><p> Da ich zu Leuten geh√∂re, die nicht wissen, wie man Bilder am Telefon macht und Kameras mag, hat mir die Idee sehr gut gefallen.  Ja, ich habe alle Arten von Fotokabinen und Fotost√§ndern gesehen, aber die Entwickler dieser Ger√§te haben es nicht einmal geschafft, normale Farben herzustellen.  Ich entschied, dass dies daran lag, dass die Entwickler die Fotografie nicht verstanden. </p><br><p>  Damit bei dieser Idee nicht dasselbe passiert wie bei den anderen (die sich im Anfangsstadium nicht r√ºhrten oder ins Stocken gerieten).  Ich entschied, dass das Wichtigste darin bestand, alles als Ganzes zum Laufen zu bringen und keine separate Komponente zu polieren, um zu gl√§nzen.  Und da ich nach der hauptberuflichen Vollzeitarbeit nur sehr wenig Entwicklungszeit habe, habe ich 1-2 Stunden maximale Kraft und am Wochenende etwas mehr. Sie sollten versuchen, nichts Neues zu lernen und das verf√ºgbare Wissen optimal zu nutzen. </p><br><p>  Ich m√∂chte in diesem Artikel erz√§hlen, welche Probleme ich auf meinem Weg hatte und wie ich sie gel√∂st habe. </p><br><p>  Eine kleine Erkl√§rung der Aufnahmebedingungen und -ausr√ºstung: Ich habe nur Kameras mit dem APS-C-Sensor-Minimum und professionellen Studioblitzen in Betracht gezogen. Dies ist die einzige M√∂glichkeit, zu jeder Tages- und Nachtzeit qualitativ hochwertige Bilder zu garantieren. </p><br><h1 id="vse-lyudi-raznogo-rosta">  Alle Menschen unterschiedlicher Statur </h1><br><p>  Das erste, was mich √ºberraschte, als ich die Kamera auf ein Stativ stellte, war, dass es nicht so einfach ist, in den Rahmen zu passen und sogar eine gute Komposition zu haben.  Wenn Sie sich von und zur Kamera bewegen, verschlechtert sich auch die gesamte Komposition, wenn sie f√ºr eine bestimmte Person, die an einem bestimmten Punkt steht, richtig platziert ist.  Ja, Sie k√∂nnen einen Stuhl setzen und sagen, dass Sie auf einem Stuhl sitzen m√ºssen, aber es wird nicht sehr interessant sein.  Sie k√∂nnen die Fotos immer noch zuschneiden, aber dann verschlechtert sich die Qualit√§t erheblich.  Nun, der letzte Weg, den ich gew√§hlt habe, ist, die Kamera automatisch zielen zu lassen. </p><br><p>  Hier gibt es auch 2 M√∂glichkeiten.  Richtig - die optische Achse ist immer horizontal, die Kamera bewegt sich auf und ab und es ist einfacher zu implementieren - passen Sie die Position der Kamera mit Neigungen an.  In diesem Fall kommt es zu vielversprechenden Verzerrungen, die jedoch w√§hrend der Verarbeitung recht gut korrigiert werden, wenn Sie sich an den Kamerawinkel erinnern. </p><br><p>  Da ich praktisch keine Erfahrung mit der Herstellung von Eisenger√§ten hatte, versuchte ich, etwas so gebrauchsfertiges wie m√∂glich zu finden.  Ich fand mehrere Ger√§te f√ºr Panoramaaufnahmen im Bereich von 1000 US-Dollar, die es erm√∂glichten, Neigungen und Drehungen manuell zu steuern und Panoramen automatisch aufzunehmen.  Aber es war unm√∂glich, sie von einem Computer aus zu steuern.  Es gibt auch einige Ger√§te zur Steuerung von Videokameras, zum Beispiel zum Aufnehmen von Kamerakranen.  Gute Ger√§te mit Hinweisen auf digitale Steuerung sind sehr teuer und es ist v√∂llig unklar, ob eine API verf√ºgbar ist.  Infolgedessen habe ich hier ein solches Ger√§t auf einer beliebten Seite gefunden: </p><br><p><img src="https://habrastorage.org/webt/m2/if/bo/m2ifboapdgi7iill_bsxkjnefr4.jpeg"></p><br><p>  Von der Elektronik gibt es nichts.  Vor einem Jahr war nur die Version mit Kollektormotoren (mit integrierten Getrieben) erh√§ltlich, die ich gekauft habe.  Es war notwendig, dieses Ding irgendwie von einem Computer aus zu verwalten.  Auf dem Forum unseres Instituts schlugen sie vor, dass die Verwendung des Arduino der g√ºnstigste Weg sei.  Also habe ich es getan.  Ich habe mir ein anderes Motorschild gekauft, da die Motoren dort mit 12 Volt betrieben werden.  Nachdem ich versucht hatte, dies einzuschalten, sp√ºrte ich alle Schmerzen, die Kollektormotoren einer Person bereiten k√∂nnen - es ist nicht nur unm√∂glich, sie in einem bestimmten Winkel zu drehen, es ist auch nicht einfach, sich nur ein wenig zu drehen.  Mein erster Gedanke war, dort einen Schrittmotor anzubringen.  Ich habe sehr lange nach einem Schrittmotor gesucht, der in diese Plattform passt, anstatt in den, der dort stand, aber nicht gefunden werden konnte.  Dann begann er dar√ºber nachzudenken, wie man das Servo hineinschrauben kann, kaufte es sogar, konnte aber auch nichts Zuverl√§ssiges finden.  Der n√§chste Gedanke war, den Beschleunigungsmesser an der Plattform zu befestigen und die Plattform allm√§hlich in einen vorbestimmten Winkel zu drehen.  Ich habe den Beschleunigungsmesser mit einem Gyroskop und einem Kompass verschraubt, aber er war sehr fehlerhaft und ich habe diese Idee auch abgelehnt (einen Monat sp√§ter wurde mir klar, dass das chinesische Netzteil f√ºr die Kamera f√ºr die St√∂rungen des Beschleunigungsmessers verantwortlich war, von denen es keine schlechten St√∂rungen gab).  Und dann habe ich versehentlich gelesen, wie das Servo angeordnet ist.  Ich mochte die Idee, einen Widerstand zu schrauben, um den Winkel zu messen, aber ich musste ihn irgendwie an eine Riemenscheibe anschlie√üen.  Ich musste zum ersten Mal in meinem Leben FreeCAD lernen und 3D-Druck verwenden.  Kurz gesagt, nach der Verarbeitung der Datei konnte alles gesammelt werden. </p><br><p><img src="https://habrastorage.org/webt/ty/a7/qm/tya7qme2ubxtwlvhvwqefkfcpbw.jpeg"></p><br><p>  Ich musste mich mit dem Programm f√ºr Arduino qu√§len, um einen bestimmten Winkel einzustellen, da die Kamera auf der Plattform ein gro√ües Tr√§gheitsmoment hat und nicht sofort stoppt.  Am Ende stellte sich jedoch heraus, dass der Winkel mit einer Genauigkeit von etwa 1 Grad eingestellt wurde. </p><br><p>  Nun zum automatischen Zielen - die Idee ist einfach, das Gesicht oben auf dem Rahmen zu machen.  Sie m√ºssen also nur ein Gesicht finden und die Plattform in jedem Bild aus der Live-Ansicht anpassen.  Ich wusste nichts √ºber das Identifizieren von Gesichtern, daher habe ich das Tutorial mit den Haar-Zeichen (Haarkaskaden) verwendet.  Ich fand heraus, dass diese Methode f√ºr Einzelpersonen nicht funktioniert.  Es findet auf jedem Frame eine Menge M√ºll neben dem, was ben√∂tigt wird, und verbraucht viel Prozessorzeit.  Dann fand er ein weiteres Beispiel f√ºr die Verwendung neuronaler Netze √ºber OpenCV.  Neuronale Netze funktionieren einwandfrei!  Aber ich war froh, bis ich anfing, Fotos parallel zu verarbeiten.  Und Linux begann irgendwie, Prozessorzeit zwischen dem Plattformverwaltungsthread und den Fotoverarbeitungsprozessen zuzuweisen.  Er ging den Weg des geringsten Widerstands - er fing an, Gesichter auf der Grafikkarte zu machen.  Alles begann perfekt zu funktionieren. </p><br><p>  Trotz der Tatsache, dass ich mich nicht mit den Details befassen wollte, f√ºhrte ich dennoch einen kleinen Test durch.  Und ich habe den Intel Neural Compute Stick 2 gekauft - ich habe versucht, statt einer Grafikkarte darauf zu z√§hlen.  Meine Ergebnisse sind ungef√§hr gleich (Ziffern - Verarbeitungszeit f√ºr ein Bild mit einer Gr√∂√üe von 800 x 533) - </p><br><ul><li>  Core i5 9400F - 59 </li><li>  Core i7 7500U - 108 </li><li>  Core i7 3770-110 </li><li>  GeForce GTX 1060 6Gb - 154 </li><li>  GeForce GTX 1050 2 GB - 199 </li><li>  Core i7 3770, Ubuntu 18.04 mit OpenCV von OpenVINO - 67 </li><li>  Intel Neural Compute Stick 2, Ubuntu 18.04 mit OpenCV von OpenVINO - 349 </li></ul><br><p>  Es stellte sich heraus, dass es ausreichte, Bilder der Gr√∂√üe 300 auf der kleineren Seite zu verarbeiten, damit das Gesicht einer Person, die in voller H√∂he im Rahmen stand, zuverl√§ssig lokalisiert wurde.  Funktioniert bei solchen Bildern schneller.  Ich verwende derzeit die GeForce GTX 1050. Ich bin sicher, dass sie erheblich verbessert werden kann, aber jetzt gibt es ein viel ernsthafteres Problem. </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/780ZNws3xek" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h1 id="ekspoziciya">  Ausstellung </h1><br><p>  Es ist kein Geheimnis, dass das Foto korrekt belichtet werden muss.  In meinem Fall ist dies umso wichtiger, als keine Retusche erfolgt.  Damit Hautfehler weniger auffallen, sollte das Foto so hell wie m√∂glich sein, kurz vor einer √úberbelichtung, jedoch ohne √úberbelichtung. </p><br><p>  Die Helligkeit des endg√ºltigen Bildes bei Blitzaufnahmen h√§ngt von folgenden Parametern ab: </p><br><ul><li>  Blitzleistung </li><li>  Die Entfernung vom Blitz zum Motiv </li><li>  Blende </li><li>  ISO-Wert </li><li>  Optionen beim Konvertieren von RAW </li></ul><br><p>  Nachdem der Frame erstellt wurde, k√∂nnen wir nur den letzten Parameter √§ndern.  Das √Ñndern √ºber einen weiten Bereich ist jedoch nicht sehr gut, da bei einer gro√üen positiven Korrektur der Belichtung des dunklen Rahmens Rauschen auftritt und im umgekehrten Fall in hellen Bereichen √úbersteuerungen auftreten k√∂nnen. </p><br><p>  Das TTL-System (Through The Lens) wird verwendet, um die Belichtung w√§hrend der Blitzaufnahme automatisch zu bestimmen.  Es funktioniert wie folgt: </p><br><ol><li>  Der Blitz macht eine Reihe von kleinen Blitzen. </li><li>  Zu diesem Zeitpunkt misst die Kamera die Belichtung, fokussiert und misst die Entfernung zum Fokusmotiv. </li><li>  Basierend auf diesen Daten wird die erforderliche Blitzleistung berechnet. </li><li>  Der Blitz wird erneut ausgel√∂st und zu diesem Zeitpunkt wird der Verschluss ge√∂ffnet und ein Bild aufgenommen. </li></ol><br><p>  Dieses System funktioniert hervorragend, wenn Sie die Bilder nach der Aufnahme manuell anpassen k√∂nnen.  Aber um das fertige Ergebnis zu erhalten, funktioniert es unbefriedigend.  Wenn das - ich habe den Profoto-Blitz f√ºr&gt; 100t.r. </p><br><p>  Ich habe bekannte Bedingungen, Blitze sollten die ganze Zeit an einem Ort stehen.  Sie k√∂nnen die Belichtung also einfach anhand der Position einer Person im Raum berechnen.  Das Problem entsteht - wie kann man die Position einer Person bestimmen? </p><br><p>  Die erste Idee bestand darin, die Entfernung zum Fokussierobjekt von EXIF ‚Äã‚Äãzu nehmen und f√ºr das erste Bild eine gro√üe Belichtungskorrektur im RAV-Wandler durchzuf√ºhren und f√ºr das n√§chste die Blitzleistung oder Blende anzupassen.  Es ist sehr wahrscheinlich, dass eine Person viele Aufnahmen macht und an einem Ort steht.  Es stellte sich jedoch heraus, dass die Entfernung in EXIF ‚Äã‚Äãsehr diskret geschrieben ist. Je weiter das Objekt entfernt ist, desto gr√∂√üer ist der Schritt.  Dar√ºber hinaus nimmt f√ºr verschiedene Objektive der Abstand zum Objekt unterschiedliche Wertes√§tze an, und einige messen ihn √ºberhaupt nicht. </p><br><p>  Die n√§chste Idee ist die Verwendung eines Ultraschall-Entfernungsmessers.  Dieses Ger√§t misst die Entfernung ziemlich genau, jedoch nur bis zu einem Meter und nur, wenn eine Person nicht in etwas gekleidet ist, das Schallwellen absorbiert.  Wenn Sie den Entfernungsmesser auf das Servo setzen und es wie ein Radar drehen, wird es etwas besser - es misst bis zu 1,5 Meter, was ebenfalls sehr klein ist (die Leute bekommen das Beste, wenn Sie sie aus einer Entfernung von 2 Metern abschie√üen). </p><br><p>  Nat√ºrlich wusste ich, dass selbst preiswerte Telefone bereits Tiefenkarten erstellen und den Hintergrund selektiv verwischen.  Aber ich wollte mich nicht darauf einlassen.  Leider gab es keine Wahl.  Zuerst wollte ich 2 Webcams kaufen, kombinieren und die Verschiebungskarte mit OpenCV lesen.  Aber zum Gl√ºck habe ich viele Tiefenkameras gefunden, die dies bereits in sich selbst tun.  Ich habe mich f√ºr Intel D435 entschieden (wenn jemand eines kaufen m√∂chte, wird es unter Linux im Hauptkernel-Zweig nicht unterst√ºtzt. Es gibt Patches f√ºr Debian und Ubuntu im librealsense-Repository. Ich musste sie f√ºr Fedora reparieren). </p><br><p><img src="https://habrastorage.org/webt/vn/aj/us/vnajusrbvur1soilielzggtbfnk.jpeg"></p><br><p>  Sobald ich alles angeschlossen hatte, schrieb ich ein Testprogramm, das den Abstand zu einem kleinen Quadrat in der Mitte misst.  Dieser Code funktioniert also immer noch.  Und es funktioniert ziemlich gut.  Nat√ºrlich m√ºssen Sie mit der RGB-Kamera nach einem Gesicht im Bild suchen und den Abstand zwischen Blitz und Gesicht berechnen.  Aber das sind Pl√§ne f√ºr die Zukunft. </p><br><p>  Entsprechend der Position einer Person im Raum ist es erforderlich, die Korrektur der Exposition zu berechnen.  Zuerst habe ich mir eine Formel ausgedacht, die nur f√ºr eine Punktlichtquelle im Vakuum funktioniert (tats√§chlich war das Fehlen reflektierender W√§nde und Decken von Bedeutung).  Aber dann machte er nur eine Reihe von Aufnahmen mit einer konstanten Blitzleistung und stellte die Belichtung in einem Equalizer mit dem Auge ein. Es stellte sich heraus, dass die Korrektur fast linear von der Entfernung abhing.  Ich benutze das Rembrandt-Beleuchtungsschema, ein Blitz mit einer Softbox befindet sich in der Ebene der Kamera. </p><br><p>  Bei der Belichtungskorrektur muss jedoch etwas unternommen werden.  Idealerweise m√ºssen Sie die Blitzleistung √§ndern, aber bisher √§ndern sich meine Membran und meine Additive &lt;1 / 6Ev - im Rav-Konverter.  Meine Flash-Synchronisierung kann √ºber Bluetooth √ºber die Telefon-App gesteuert werden.  In Zukunft m√∂chte ich herausfinden, wie das Protokoll dort angeordnet ist, und die Leistung der Blitze √§ndern. </p><br><p>  Hier ist ein Vergleich der konstanten Blitzleistung mit TTL und meiner Methode.  Es funktioniert viel stabiler und genauer TTL: </p><br><p><img src="https://habrastorage.org/webt/xu/bm/zx/xubmzxg6khtlsatd5h89el3ntv0.jpeg"></p><br><h1 id="raznoobrazie">  Vielfalt </h1><br><p>  Wenn ein M√§dchen (oder sogar ein Mann) zu einem Fotoshooting zum Fotografen kommt, m√∂chte sie (oder er) normalerweise ein Foto eines anderen Plans, eines gr√∂√üeren, bei dem nur ihr Gesicht und allgemeiner in voller L√§nge oder h√ºfthoch sind.  Nicht jeder wei√ü es, aber das Beste ist, dass der Plan durch √Ñndern der Brennweite des Objektivs ge√§ndert wird.  Das hei√üt, eine Person steht immer in einem Abstand von beispielsweise 2 Metern. Wenn wir in voller H√∂he schie√üen m√ºssen, wickeln wir das 35-mm-Objektiv ein, wenn nur das Gesicht 135 mm betr√§gt und wenn es h√ºfthoch ist, dann 50 mm oder 85 mm.  Nun, oder √§ndern Sie nicht die Objektive und stellen Sie das Objektiv mit Zoom ein.  Dem Benutzer anzubieten, den Zoom mit den H√§nden an der Kamera zu drehen, die auf einer beweglichen Plattform steht und ein Kabelb√ºndel durchbricht, klingt nicht sehr gut.  Also kaufte ich eine Packung Ersatzteile bei aliexpress, nahm einen Servoantrieb, der f√ºr mich zur Steuerung der Plattform nicht n√ºtzlich war, und tat dies: </p><br><p><img src="https://habrastorage.org/webt/aw/3v/9b/aw3v9bi7wh77k2vzpxrwoaz8fh4.jpeg"></p><br><p>  Und so funktioniert es: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oNCFHLUPTYo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Die Ergebnisse des ersten Tests in einem Fotostudio, zun√§chst wollte ich sehen, wie vielf√§ltig es w√§re, Bilder aufzunehmen, nichts zu bewegen oder w√§hrend der Aufnahme neu zu konfigurieren: </p><br><p><img src="https://habrastorage.org/webt/cw/bf/6f/cwbf6fwso80_qlfou26tit5gkaa.jpeg"></p><br><p>  Video verarbeiten: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/YzeVP0ef4ag" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h1 id="rezultat">  Ergebnis </h1><br><p>  Dies sind einige der besten Aufnahmen, die gemacht wurden: </p><br><p><img src="https://habrastorage.org/webt/dm/rj/74/dmrj74690z5rd7gjpkkwbdnvngu.jpeg"><br>  <em>Wie jeder um Erlaubnis zur Ver√∂ffentlichung gebeten hat, wenn Sie sich selbst erkennen und das Foto entfernen m√∂chten - schreiben Sie mir</em> </p><br><p>  Warum habe ich das getan?  Dies ist eine Sache, die noch nicht passiert ist, zumindest habe ich so etwas nicht gefunden.  Potenziell n√ºtzlich - jetzt gibt es viele Spezialisten wie Psychologen, Business-Trainer, Sporttrainer und Friseure, die ihre Dienste √ºber Blogs verkaufen. Sie ben√∂tigen viele Fotos und genau die Form, in der sie wollen, nicht den Fotografen.  Manche Leute m√∂gen es einfach nicht, wenn ein Fremder (Fotograf) sie beim Fotografieren ansieht.  Am einfachsten ist die gro√üartige Unterhaltung f√ºr Firmenveranstaltungen, Ausstellungen und andere Veranstaltungen. </p><br><p>  Ich habe den Softwareteil, die Verarbeitung von Fotos und die Benutzerinteraktion nicht beschrieben, da bereits so viel Text vorhanden ist, dass ich den zweiten Teil sp√§ter schreiben werde.  Diese Punkte sind bereits ziemlich gut ausgearbeitet, so dass Personen, die mit der Programmierung nicht vertraut sind, das System verwenden k√∂nnen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460605/">https://habr.com/ru/post/de460605/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460591/index.html">Root auf einem Tenda Nova MW6-Router erhalten</a></li>
<li><a href="../de460593/index.html">"Universal" im Entwicklungsteam: Nutzen oder Schaden?</a></li>
<li><a href="../de460597/index.html">So diagnostizieren Sie SDK-Integrationsprobleme. Die Erfahrung des SDK-Entwicklungsteams von Yandex Mobile Ads</a></li>
<li><a href="../de460599/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 468 (07/02/2019 - 08/07/2019)</a></li>
<li><a href="../de460603/index.html">V2G. Elektroautos werden dazu beitragen, die Produktion und den Verbrauch von Strom auszugleichen</a></li>
<li><a href="../de460607/index.html">Offensive Security App Store mit Hacking-Tools von Android</a></li>
<li><a href="../de460611/index.html">Failover: Perfektionismus ruiniert uns und ... Faulheit</a></li>
<li><a href="../de460615/index.html">Im Gefolge von Industrial Ninja: Wie PLC an den Positive Hack Days 9 gehackt wurde</a></li>
<li><a href="../de460617/index.html">Die ganze Wahrheit √ºber RTOS. Artikel 30. Initialisierungs- und Startverfahren f√ºr Nucleus SE</a></li>
<li><a href="../de460621/index.html">Tic Tac Toe Teil 4: Interaktion mit dem Flask Backend √ºber HTTP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
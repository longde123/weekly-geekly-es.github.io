<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ£ ğŸ‘´ğŸ» ğŸ¦— Verwenden der abgelehnten Fehlerrate zur Verbesserung der Fehlerberichterstattung ğŸŸï¸ ğŸ’…ğŸ¼ ğŸ‘©ğŸ½â€ğŸ”¬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Freitag allerseits, Freunde! Ende Juni starten wir eine neue Gruppe beim QA Specialist- Kurs, der im Mittelpunkt der heutigen VerÃ¶ffentlichung s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwenden der abgelehnten Fehlerrate zur Verbesserung der Fehlerberichterstattung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/455240/">  Guten Freitag allerseits, Freunde!  Ende Juni starten wir eine neue Gruppe beim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">QA Specialist-</a> Kurs, der im Mittelpunkt der heutigen VerÃ¶ffentlichung stehen wird. <br><br><img src="https://habrastorage.org/webt/4m/5q/dj/4m5qdjzecdf-vqrx-npu-mr0w2c.png"><br><br>  Es gibt viele Indikatoren, anhand derer Sie die EffektivitÃ¤t des Testerteams messen kÃ¶nnen.  Eine davon ist das VerhÃ¤ltnis der zurÃ¼ckgewiesenen Fehler oder die Anzahl der abgelehnten Fehlerberichte geteilt durch die Gesamtzahl der empfangenen Berichte.  Sie mÃ¼ssen denken, dass wenn die Anzahl der abgelehnten Berichte Null ist, das gut ist, aber es ist nicht so einfach.  Schauen wir uns die Arten der zurÃ¼ckgewiesenen Fehler an, sehen Sie, wie sie sich auf die Rate der zurÃ¼ckgewiesenen Fehler auswirken, und berechnen Sie das richtige VerhÃ¤ltnis fÃ¼r Ihr Team. <a name="habracut"></a><br><br>  Es gibt drei Kategorien von zurÃ¼ckgewiesenen Fehlern: <br><br><ul><li>  Nicht reproduzierbare Fehler; </li><li>  Falsche Fehler </li><li>  Doppelte Fehler. </li></ul><br>  Beginnen wir mit den Fehlern selbst. <br><br><h2>  Nicht reproduzierbare Fehler </h2><br>  Es gibt zwei Arten von nicht reproduzierbaren Fehlern.  Der erste ist ein Fehler, der wirklich schwer zu reproduzieren ist.  Dies kann ein Fehler sein, der aus dem Zusammenspiel mehrerer Parameter resultiert, von denen einige Sie nicht einmal kennen. <br><br>  Angenommen, Sie haben mehrere Tests hintereinander durchgefÃ¼hrt und einer der Tests hat den Konfigurationsparameter vom Standardwert A auf einen anderen Wert B geÃ¤ndert. Der Fehler tritt nur auf, wenn der Konfigurationsparameter den Wert B enthÃ¤lt und der Eingabewert C ist Wenn Sie versuchen, den Fehler zu reproduzieren, mÃ¶chten Sie hÃ¶chstwahrscheinlich mit einem bekannten Status beginnen, um das System zu initialisieren (oder mÃ¶glicherweise eine Neuinstallation durchzufÃ¼hren).  Es tritt kein Fehler auf, da der Konfigurationsparameter jetzt wieder den Standardwert A enthÃ¤lt. <br><br>  Eine andere Variante dieser Art von nicht reproduzierbarem Fehler besteht darin, dass der Test tatsÃ¤chlich einen Fehler festgestellt hat, die Wiedergabeinformationen jedoch keine Daten enthalten: einen Schritt, einen bestimmten Eingabewert oder das VerstÃ¤ndnis, dass der Fehler nur bei einem bestimmten Verfahren auftritt.  Versuche, den Fehler zu reproduzieren, fÃ¼hren daher zu nichts. <br><br>  In beiden oben genannten FÃ¤llen liegt jedoch tatsÃ¤chlich ein Defekt am Produkt selbst vor. <br>  Die zweite Art von nicht reproduzierbarem Fehler ist, wenn der Fehler nicht wiederholt werden kann, weil er nicht existiert.  Der Tester hat mÃ¶glicherweise etwas bemerkt, das jedoch falsch interpretiert wurde, oder das zum Testen verwendete System weist mÃ¶glicherweise ein Problem auf, z. B. eine fehlerhafte Hardwarekomponente, einen inkompatiblen Treiber oder falsche Zugriffseinstellungen.  Versuche, den Fehler auf einem ordnungsgemÃ¤ÃŸ konfigurierten System zu reproduzieren, schlagen fehl. <br><br>  Diese beiden Fehlertypen werden in den Fehlermeldesystemen normalerweise als "abgelehnt - kann nicht reproduziert werden" gekennzeichnet. <br><br><h2>  Falsche Fehler </h2><br>  Diese Art von Fehler tritt auf, wenn der Tester entscheidet, dass sich das Produkt auf eine bestimmte Weise verhalten soll, und einen Fehler meldet, wenn das Verhalten nicht den Erwartungen entspricht.  Eine detailliertere Untersuchung der Anforderungen zeigt jedoch, dass die Erwartungen des Testers falsch waren und das Produkt tatsÃ¤chlich ordnungsgemÃ¤ÃŸ funktionierte.  Das heiÃŸt, das getestete Produkt funktionierte ordnungsgemÃ¤ÃŸ, und der Tester, der mit den Anforderungen nicht ausreichend vertraut war, machte einen Fehler. <br><br>  Solche Fehler werden in Fehlerberichtssystemen normalerweise als "abgelehnt - kein Fehler" oder "abgelehnt - von der Architektur" gekennzeichnet (dh das Verhalten stimmt mit der Architektur Ã¼berein). <br><br><h2>  Doppelte Fehler </h2><br>  Wiederholte Fehler sind die Fehler, die man bereits gemeldet hat, und der nÃ¤chste meldet sich danach.  Ein Fehler wiederholt sich nur, wenn die â€Symptomeâ€œ seines Auftretens gleich sind.  Und wenn die Grundursache des Fehlers dieselbe ist, sich jedoch herausstellt, dass die â€Symptomeâ€œ unterschiedlich sind, ist dies keine Wiederholung des Fehlers! <br><br>  Diese Fehler werden in Fehlermeldesystemen normalerweise als "abgelehnt - duplizieren / wiederholen" gekennzeichnet. <br><br><h2>  Wie abgelehnte Fehler ein Team beeinflussen </h2><br>  Offensichtlich ist ein falscher Fehler eine Art Zeitverschwendung, die der Tester damit verbracht hat, den Fehler zu reproduzieren und zu melden, die Zeit, die diejenigen, die die Fehler sortieren, damit verbringen, sie zu lesen und zu verstehen, und die Zeit, die Entwickler damit verbringen, einen nicht reproduzierbaren Fehler zu reproduzieren oder um etwas zu reparieren (und zu stÃ¶ren), das dieses Update nicht benÃ¶tigte. <br><br>  Neben der Tatsache, dass die abgelehnte Fehlerquote oder RDR ein MaÃŸ fÃ¼r die Ineffizienz des Testerteams ist, spricht er auch Ã¼ber die ProfessionalitÃ¤t von Testern im Allgemeinen.  Ein Fehler, der aufgrund des Mangels an erforderlichen Informationen im Bericht nicht reproduziert werden kann, weist darauf hin, dass die Tester nicht genau waren und nicht hart genug gearbeitet haben, um diesen Fehler mithilfe der oben beschriebenen Schritte zu reproduzieren.  Bei Fehlern, die nur selten reproduziert werden, haben die Tester die niedrige Wiedergabefrequenz im Bericht im Allgemeinen nicht notiert. <br><br>  Das Auftreten eines falschen Fehlers zeigt an, dass Tester die Produktanforderungen nicht vollstÃ¤ndig verstehen.  Wiederholte Fehler weisen darauf hin, dass die Tester keine Mindestsuche in der lokalen Fehlerdatenbank durchgefÃ¼hrt haben, um zu Ã¼berprÃ¼fen, ob sie frÃ¼her aufgetreten ist.  Oder es bedeutet, dass der Spezialist, der diesen Fehler gemeldet hat, nicht der erste war, der die richtigen SchlÃ¼sselwÃ¶rter in den Namen aufgenommen hat, um die Suche nach seinen anderen Kollegen zu erleichtern. <br><br>  Wenn sich herausstellt, dass der gefundene Fehler zurÃ¼ckgewiesen wird, bin ich Ã¤rgerlich, weil ich als Laie angesehen wurde.  Einerseits bedeutet dies, dass ich die gefundenen Fehler verteidigen werde.  Wenn mein Bericht abgelehnt wird, gehe ich wie folgt vor: <br><br><ul><li>  Ich Ã¼berprÃ¼fe erneut, ob der Fehler in meinem System reproduziert wird, und fÃ¼ge die Wiedergabeschritte hinzu, wenn ich etwas verpasst habe. </li><li>  Wenn mein MissverstÃ¤ndnis der Anforderungen durch eine mehrdeutige Anforderung oder eine falsche Dokumentation verursacht wurde, werde ich darauf bestehen, dass der Fehler als Dokumentationsfehler markiert und erst geschlossen wird, wenn die Dokumentation korrigiert wird. </li><li>  Wenn ich der Meinung bin, dass das Verhalten des Produkts bei der ErfÃ¼llung der Anforderung falsch ist, werde ich mit Architekten und Entwicklern Ã¼ber die Anforderungen sprechen und versuchen, sie davon zu Ã¼berzeugen, dass die Anforderungen aktualisiert werden mÃ¼ssen (am Ende vertrete ich die Meinung des Kunden!). </li><li>  Wenn der Fehler als Duplikat zurÃ¼ckgewiesen wird, werde ich sicherstellen, dass er nicht auf die gleiche Weise markiert wurde oder nicht "gemÃ¤ÃŸ demselben Szenario" angezeigt wird. </li></ul><br>  Andererseits macht mich eine gewisse Wahrscheinlichkeit der Fehlerabweisung vorsichtig.  Wenn ich nicht ganz sicher bin, ob ich einen Fehler gefunden habe, werde ich vor dem Melden noch etwas Zeit damit verbringen, dies zu Ã¼berprÃ¼fen.  Ich frage oft einen Kollegen, ob ich die Anforderungen richtig interpretiere oder ob der Fehler auf dem System eines anderen reproduziert wird. <br><br><h2>  Stellungnahme gegen das vÃ¶llige Fehlen abgelehnter Fehler </h2><br>  Das Testteam sollte das RDR-Niveau Ã¼berwachen und sich bemÃ¼hen, es zu reduzieren.  Die Frage ist nur, welche RDR als gut anzusehen ist. <br><br>  Auf den ersten Blick scheint 0% das optimale Ergebnis zu sein, aber ich bin damit nicht einverstanden.  Ich glaube, wenn der RDR auf einem gesunden Niveau gehalten wird, ist dies normal, denn wenn er nahe Null liegt, leidet das Testteam offensichtlich unter nicht weniger schwerwiegenden Problemen als beispielsweise einem zu hohen RDR. <br><br>  Das Testteam muss groÃŸe Anstrengungen unternehmen, um einen extrem niedrigen RDR zu erreichen.  Jeder abgelehnte Fehler wird analysiert, um zu verstehen, was schief gelaufen ist, und jeder Tester, der einen abgelehnten Fehler gemeldet hat, muss erklÃ¤ren, was tatsÃ¤chlich passiert ist und wie eine solche Situation in Zukunft vermieden werden kann.  Infolgedessen melden Tester Fehler, bei denen sie absolut sicher sind. <br><br>  Wenn sie ein Verhalten bemerken, von dem sie glauben, dass es die Verwendbarkeit des Produkts beeintrÃ¤chtigt, ziehen sie es vor, dieses Verhalten als selbstverstÃ¤ndlich zu betrachten, anstatt zu rechtfertigen, dass sie einen Fehler gefunden haben, der tatsÃ¤chlich kein Fehler ist, der auf Anforderungen basiert.  Wenn sie Beweise dafÃ¼r haben, dass ein Fehler aufgetreten ist, es jedoch kein gutes Szenario fÃ¼r die Reproduktion gibt, werden sie es vorziehen, ihn nicht zu melden.  sie wollen sich wirklich nicht aufregen.  Wenn sie auf einen leichtfertigen Fehler stoÃŸen, entscheiden sie sich mÃ¶glicherweise, ihn Ã¼berhaupt nicht zu melden, da kleinere Fehler ihn nicht immer beheben. Warum also das Risiko eingehen und befÃ¼rchten, dass der gefundene Fehler zurÃ¼ckgewiesen wird? <br><br>  Kurz gesagt, das Streben nach einem sehr niedrigen RDR fÃ¼hrt zu Stress und ungesundem Verhalten im Testteam und erhÃ¶ht auch die Wahrscheinlichkeit, dass einige Fehler unbemerkt bleiben. <br><br>  Wir brauchen Tester, die nicht nur offensichtliche Fehler melden, sondern auch vor verdÃ¤chtigem Verhalten im Projekt warnen.  Wir glauben, dass Tester, die groÃŸen Wert darauf legen, dass der Fehler auch auf Kosten doppelter Berichte nicht verschwindet, besser sind als Tester, die stundenlang prÃ¼fen, ob in Berichten bereits ein Fehler gemeldet wurde oder nicht, aus Angst, dass dies der Fall ist mache ein Duplikat.  Wir mÃ¶chten, dass sich die Tester wohl fÃ¼hlen, indem sie das Wort des Systemarchitekten oder die Anforderungsspezifikation in Frage stellen, auch wenn dies bedeutet, dass einige ihrer Fehler als zurÃ¼ckgewiesen markiert werden. <br><br>  Wir brauchen Tester, die keine Angst haben, von Zeit zu Zeit Fehler zu machen.  Dies bedeutet, dass ein Gleichgewicht erforderlich ist, sodass einige kleine RDR als akzeptabel angesehen werden. <br><br><h2>  Finden des optimalen Ausschusskoeffizienten fÃ¼r zurÃ¼ckgewiesene Fehler </h2><br>  Meine Faustregel lautet, dass der RDR 15 Prozent betragen sollte.  Dieser Wert basiert auf meiner Erfahrung mit dem Testerteam, das in jeder Hinsicht ein gutes und effektives Team war.  Es war unser RDR wÃ¤hrend mehrerer Projekte, die nacheinander durchgefÃ¼hrt wurden, wÃ¤hrend das andere Team, das an denselben Projekten und parallel zu uns arbeitete, obwohl es weniger produktbewusst war und als weniger effektiv angesehen wurde, einen RDR von 30 Prozent hatte . <br><br>  Ich glaube nicht, dass es eine andere Rechtfertigung fÃ¼r diese Bedeutung gibt als mein inneres GefÃ¼hl.  Das ist definitiv nicht wissenschaftlich.  Ich werde nicht mit einem Team streiten, das auf 10 oder 20 Prozent ausgerichtet ist, aber ich denke, dass es bereits ein Problem ist, 30 Prozent zu ertragen oder ein Ziel von 5 Prozent zu setzen. <br><br>  Letztendlich ist dies eine Entscheidung, die vom Testerteam getroffen werden muss, basierend auf den Eigenschaften des Produkts, dem Fachwissen des Teams, dem Entwicklungsmodell, der Erfahrung des Entwicklungsteams und vielem mehr.  Ich empfehle Ihnen dringend, RDR im Auge zu behalten und darÃ¼ber nachzudenken, ob Sie etwas damit anfangen mÃ¼ssen.  Und wenn es zu hoch oder zu niedrig ist, sollten geeignete MaÃŸnahmen ergriffen werden. <br><br>  Traditionell warten wir auf Ihre Kommentare und laden Sie zu einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kostenlosen Webinar ein</a> , das am 14. Juni stattfinden wird.  Bis dann! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455240/">https://habr.com/ru/post/de455240/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455224/index.html">Fingermusik: Spielen Sie alles mit Spheros SpecDrums</a></li>
<li><a href="../de455226/index.html">Warum einen angewandten Linguisten bewerben?</a></li>
<li><a href="../de455228/index.html">Derjenige, der Herzog Nukem auferweckt hat: Interview mit Randy Pitchford, Gearbox Wizard</a></li>
<li><a href="../de455234/index.html">Nullable Referenztypen in C # 8.0 und statische Analyse</a></li>
<li><a href="../de455236/index.html">Comodo widerruft Zertifikate ohne Grund</a></li>
<li><a href="../de455242/index.html">Weniger Ohren oder wie man den Sound im Spiel nicht von Anfang an verdirbt</a></li>
<li><a href="../de455244/index.html">Comic "LÃ¶ten ist einfach" in der aktualisierten Version (2019)</a></li>
<li><a href="../de455246/index.html">Die Registrierung fÃ¼r den Customer Experience Day in St. Petersburg ist am 20. Juni geÃ¶ffnet</a></li>
<li><a href="../de455248/index.html">Top Entwicklungsfehler bei der Arbeit mit PostgreSQL</a></li>
<li><a href="../de455250/index.html">Derjenige, der Herzog Nukem wiederbelebt hat: Interview mit Randy Pitchford, Magier von Gearbox</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
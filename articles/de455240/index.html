<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏣 👴🏻 🦗 Verwenden der abgelehnten Fehlerrate zur Verbesserung der Fehlerberichterstattung 🎟️ 💅🏼 👩🏽‍🔬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Freitag allerseits, Freunde! Ende Juni starten wir eine neue Gruppe beim QA Specialist- Kurs, der im Mittelpunkt der heutigen Veröffentlichung s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwenden der abgelehnten Fehlerrate zur Verbesserung der Fehlerberichterstattung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/455240/">  Guten Freitag allerseits, Freunde!  Ende Juni starten wir eine neue Gruppe beim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">QA Specialist-</a> Kurs, der im Mittelpunkt der heutigen Veröffentlichung stehen wird. <br><br><img src="https://habrastorage.org/webt/4m/5q/dj/4m5qdjzecdf-vqrx-npu-mr0w2c.png"><br><br>  Es gibt viele Indikatoren, anhand derer Sie die Effektivität des Testerteams messen können.  Eine davon ist das Verhältnis der zurückgewiesenen Fehler oder die Anzahl der abgelehnten Fehlerberichte geteilt durch die Gesamtzahl der empfangenen Berichte.  Sie müssen denken, dass wenn die Anzahl der abgelehnten Berichte Null ist, das gut ist, aber es ist nicht so einfach.  Schauen wir uns die Arten der zurückgewiesenen Fehler an, sehen Sie, wie sie sich auf die Rate der zurückgewiesenen Fehler auswirken, und berechnen Sie das richtige Verhältnis für Ihr Team. <a name="habracut"></a><br><br>  Es gibt drei Kategorien von zurückgewiesenen Fehlern: <br><br><ul><li>  Nicht reproduzierbare Fehler; </li><li>  Falsche Fehler </li><li>  Doppelte Fehler. </li></ul><br>  Beginnen wir mit den Fehlern selbst. <br><br><h2>  Nicht reproduzierbare Fehler </h2><br>  Es gibt zwei Arten von nicht reproduzierbaren Fehlern.  Der erste ist ein Fehler, der wirklich schwer zu reproduzieren ist.  Dies kann ein Fehler sein, der aus dem Zusammenspiel mehrerer Parameter resultiert, von denen einige Sie nicht einmal kennen. <br><br>  Angenommen, Sie haben mehrere Tests hintereinander durchgeführt und einer der Tests hat den Konfigurationsparameter vom Standardwert A auf einen anderen Wert B geändert. Der Fehler tritt nur auf, wenn der Konfigurationsparameter den Wert B enthält und der Eingabewert C ist Wenn Sie versuchen, den Fehler zu reproduzieren, möchten Sie höchstwahrscheinlich mit einem bekannten Status beginnen, um das System zu initialisieren (oder möglicherweise eine Neuinstallation durchzuführen).  Es tritt kein Fehler auf, da der Konfigurationsparameter jetzt wieder den Standardwert A enthält. <br><br>  Eine andere Variante dieser Art von nicht reproduzierbarem Fehler besteht darin, dass der Test tatsächlich einen Fehler festgestellt hat, die Wiedergabeinformationen jedoch keine Daten enthalten: einen Schritt, einen bestimmten Eingabewert oder das Verständnis, dass der Fehler nur bei einem bestimmten Verfahren auftritt.  Versuche, den Fehler zu reproduzieren, führen daher zu nichts. <br><br>  In beiden oben genannten Fällen liegt jedoch tatsächlich ein Defekt am Produkt selbst vor. <br>  Die zweite Art von nicht reproduzierbarem Fehler ist, wenn der Fehler nicht wiederholt werden kann, weil er nicht existiert.  Der Tester hat möglicherweise etwas bemerkt, das jedoch falsch interpretiert wurde, oder das zum Testen verwendete System weist möglicherweise ein Problem auf, z. B. eine fehlerhafte Hardwarekomponente, einen inkompatiblen Treiber oder falsche Zugriffseinstellungen.  Versuche, den Fehler auf einem ordnungsgemäß konfigurierten System zu reproduzieren, schlagen fehl. <br><br>  Diese beiden Fehlertypen werden in den Fehlermeldesystemen normalerweise als "abgelehnt - kann nicht reproduziert werden" gekennzeichnet. <br><br><h2>  Falsche Fehler </h2><br>  Diese Art von Fehler tritt auf, wenn der Tester entscheidet, dass sich das Produkt auf eine bestimmte Weise verhalten soll, und einen Fehler meldet, wenn das Verhalten nicht den Erwartungen entspricht.  Eine detailliertere Untersuchung der Anforderungen zeigt jedoch, dass die Erwartungen des Testers falsch waren und das Produkt tatsächlich ordnungsgemäß funktionierte.  Das heißt, das getestete Produkt funktionierte ordnungsgemäß, und der Tester, der mit den Anforderungen nicht ausreichend vertraut war, machte einen Fehler. <br><br>  Solche Fehler werden in Fehlerberichtssystemen normalerweise als "abgelehnt - kein Fehler" oder "abgelehnt - von der Architektur" gekennzeichnet (dh das Verhalten stimmt mit der Architektur überein). <br><br><h2>  Doppelte Fehler </h2><br>  Wiederholte Fehler sind die Fehler, die man bereits gemeldet hat, und der nächste meldet sich danach.  Ein Fehler wiederholt sich nur, wenn die „Symptome“ seines Auftretens gleich sind.  Und wenn die Grundursache des Fehlers dieselbe ist, sich jedoch herausstellt, dass die „Symptome“ unterschiedlich sind, ist dies keine Wiederholung des Fehlers! <br><br>  Diese Fehler werden in Fehlermeldesystemen normalerweise als "abgelehnt - duplizieren / wiederholen" gekennzeichnet. <br><br><h2>  Wie abgelehnte Fehler ein Team beeinflussen </h2><br>  Offensichtlich ist ein falscher Fehler eine Art Zeitverschwendung, die der Tester damit verbracht hat, den Fehler zu reproduzieren und zu melden, die Zeit, die diejenigen, die die Fehler sortieren, damit verbringen, sie zu lesen und zu verstehen, und die Zeit, die Entwickler damit verbringen, einen nicht reproduzierbaren Fehler zu reproduzieren oder um etwas zu reparieren (und zu stören), das dieses Update nicht benötigte. <br><br>  Neben der Tatsache, dass die abgelehnte Fehlerquote oder RDR ein Maß für die Ineffizienz des Testerteams ist, spricht er auch über die Professionalität von Testern im Allgemeinen.  Ein Fehler, der aufgrund des Mangels an erforderlichen Informationen im Bericht nicht reproduziert werden kann, weist darauf hin, dass die Tester nicht genau waren und nicht hart genug gearbeitet haben, um diesen Fehler mithilfe der oben beschriebenen Schritte zu reproduzieren.  Bei Fehlern, die nur selten reproduziert werden, haben die Tester die niedrige Wiedergabefrequenz im Bericht im Allgemeinen nicht notiert. <br><br>  Das Auftreten eines falschen Fehlers zeigt an, dass Tester die Produktanforderungen nicht vollständig verstehen.  Wiederholte Fehler weisen darauf hin, dass die Tester keine Mindestsuche in der lokalen Fehlerdatenbank durchgeführt haben, um zu überprüfen, ob sie früher aufgetreten ist.  Oder es bedeutet, dass der Spezialist, der diesen Fehler gemeldet hat, nicht der erste war, der die richtigen Schlüsselwörter in den Namen aufgenommen hat, um die Suche nach seinen anderen Kollegen zu erleichtern. <br><br>  Wenn sich herausstellt, dass der gefundene Fehler zurückgewiesen wird, bin ich ärgerlich, weil ich als Laie angesehen wurde.  Einerseits bedeutet dies, dass ich die gefundenen Fehler verteidigen werde.  Wenn mein Bericht abgelehnt wird, gehe ich wie folgt vor: <br><br><ul><li>  Ich überprüfe erneut, ob der Fehler in meinem System reproduziert wird, und füge die Wiedergabeschritte hinzu, wenn ich etwas verpasst habe. </li><li>  Wenn mein Missverständnis der Anforderungen durch eine mehrdeutige Anforderung oder eine falsche Dokumentation verursacht wurde, werde ich darauf bestehen, dass der Fehler als Dokumentationsfehler markiert und erst geschlossen wird, wenn die Dokumentation korrigiert wird. </li><li>  Wenn ich der Meinung bin, dass das Verhalten des Produkts bei der Erfüllung der Anforderung falsch ist, werde ich mit Architekten und Entwicklern über die Anforderungen sprechen und versuchen, sie davon zu überzeugen, dass die Anforderungen aktualisiert werden müssen (am Ende vertrete ich die Meinung des Kunden!). </li><li>  Wenn der Fehler als Duplikat zurückgewiesen wird, werde ich sicherstellen, dass er nicht auf die gleiche Weise markiert wurde oder nicht "gemäß demselben Szenario" angezeigt wird. </li></ul><br>  Andererseits macht mich eine gewisse Wahrscheinlichkeit der Fehlerabweisung vorsichtig.  Wenn ich nicht ganz sicher bin, ob ich einen Fehler gefunden habe, werde ich vor dem Melden noch etwas Zeit damit verbringen, dies zu überprüfen.  Ich frage oft einen Kollegen, ob ich die Anforderungen richtig interpretiere oder ob der Fehler auf dem System eines anderen reproduziert wird. <br><br><h2>  Stellungnahme gegen das völlige Fehlen abgelehnter Fehler </h2><br>  Das Testteam sollte das RDR-Niveau überwachen und sich bemühen, es zu reduzieren.  Die Frage ist nur, welche RDR als gut anzusehen ist. <br><br>  Auf den ersten Blick scheint 0% das optimale Ergebnis zu sein, aber ich bin damit nicht einverstanden.  Ich glaube, wenn der RDR auf einem gesunden Niveau gehalten wird, ist dies normal, denn wenn er nahe Null liegt, leidet das Testteam offensichtlich unter nicht weniger schwerwiegenden Problemen als beispielsweise einem zu hohen RDR. <br><br>  Das Testteam muss große Anstrengungen unternehmen, um einen extrem niedrigen RDR zu erreichen.  Jeder abgelehnte Fehler wird analysiert, um zu verstehen, was schief gelaufen ist, und jeder Tester, der einen abgelehnten Fehler gemeldet hat, muss erklären, was tatsächlich passiert ist und wie eine solche Situation in Zukunft vermieden werden kann.  Infolgedessen melden Tester Fehler, bei denen sie absolut sicher sind. <br><br>  Wenn sie ein Verhalten bemerken, von dem sie glauben, dass es die Verwendbarkeit des Produkts beeinträchtigt, ziehen sie es vor, dieses Verhalten als selbstverständlich zu betrachten, anstatt zu rechtfertigen, dass sie einen Fehler gefunden haben, der tatsächlich kein Fehler ist, der auf Anforderungen basiert.  Wenn sie Beweise dafür haben, dass ein Fehler aufgetreten ist, es jedoch kein gutes Szenario für die Reproduktion gibt, werden sie es vorziehen, ihn nicht zu melden.  sie wollen sich wirklich nicht aufregen.  Wenn sie auf einen leichtfertigen Fehler stoßen, entscheiden sie sich möglicherweise, ihn überhaupt nicht zu melden, da kleinere Fehler ihn nicht immer beheben. Warum also das Risiko eingehen und befürchten, dass der gefundene Fehler zurückgewiesen wird? <br><br>  Kurz gesagt, das Streben nach einem sehr niedrigen RDR führt zu Stress und ungesundem Verhalten im Testteam und erhöht auch die Wahrscheinlichkeit, dass einige Fehler unbemerkt bleiben. <br><br>  Wir brauchen Tester, die nicht nur offensichtliche Fehler melden, sondern auch vor verdächtigem Verhalten im Projekt warnen.  Wir glauben, dass Tester, die großen Wert darauf legen, dass der Fehler auch auf Kosten doppelter Berichte nicht verschwindet, besser sind als Tester, die stundenlang prüfen, ob in Berichten bereits ein Fehler gemeldet wurde oder nicht, aus Angst, dass dies der Fall ist mache ein Duplikat.  Wir möchten, dass sich die Tester wohl fühlen, indem sie das Wort des Systemarchitekten oder die Anforderungsspezifikation in Frage stellen, auch wenn dies bedeutet, dass einige ihrer Fehler als zurückgewiesen markiert werden. <br><br>  Wir brauchen Tester, die keine Angst haben, von Zeit zu Zeit Fehler zu machen.  Dies bedeutet, dass ein Gleichgewicht erforderlich ist, sodass einige kleine RDR als akzeptabel angesehen werden. <br><br><h2>  Finden des optimalen Ausschusskoeffizienten für zurückgewiesene Fehler </h2><br>  Meine Faustregel lautet, dass der RDR 15 Prozent betragen sollte.  Dieser Wert basiert auf meiner Erfahrung mit dem Testerteam, das in jeder Hinsicht ein gutes und effektives Team war.  Es war unser RDR während mehrerer Projekte, die nacheinander durchgeführt wurden, während das andere Team, das an denselben Projekten und parallel zu uns arbeitete, obwohl es weniger produktbewusst war und als weniger effektiv angesehen wurde, einen RDR von 30 Prozent hatte . <br><br>  Ich glaube nicht, dass es eine andere Rechtfertigung für diese Bedeutung gibt als mein inneres Gefühl.  Das ist definitiv nicht wissenschaftlich.  Ich werde nicht mit einem Team streiten, das auf 10 oder 20 Prozent ausgerichtet ist, aber ich denke, dass es bereits ein Problem ist, 30 Prozent zu ertragen oder ein Ziel von 5 Prozent zu setzen. <br><br>  Letztendlich ist dies eine Entscheidung, die vom Testerteam getroffen werden muss, basierend auf den Eigenschaften des Produkts, dem Fachwissen des Teams, dem Entwicklungsmodell, der Erfahrung des Entwicklungsteams und vielem mehr.  Ich empfehle Ihnen dringend, RDR im Auge zu behalten und darüber nachzudenken, ob Sie etwas damit anfangen müssen.  Und wenn es zu hoch oder zu niedrig ist, sollten geeignete Maßnahmen ergriffen werden. <br><br>  Traditionell warten wir auf Ihre Kommentare und laden Sie zu einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kostenlosen Webinar ein</a> , das am 14. Juni stattfinden wird.  Bis dann! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455240/">https://habr.com/ru/post/de455240/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455224/index.html">Fingermusik: Spielen Sie alles mit Spheros SpecDrums</a></li>
<li><a href="../de455226/index.html">Warum einen angewandten Linguisten bewerben?</a></li>
<li><a href="../de455228/index.html">Derjenige, der Herzog Nukem auferweckt hat: Interview mit Randy Pitchford, Gearbox Wizard</a></li>
<li><a href="../de455234/index.html">Nullable Referenztypen in C # 8.0 und statische Analyse</a></li>
<li><a href="../de455236/index.html">Comodo widerruft Zertifikate ohne Grund</a></li>
<li><a href="../de455242/index.html">Weniger Ohren oder wie man den Sound im Spiel nicht von Anfang an verdirbt</a></li>
<li><a href="../de455244/index.html">Comic "Löten ist einfach" in der aktualisierten Version (2019)</a></li>
<li><a href="../de455246/index.html">Die Registrierung für den Customer Experience Day in St. Petersburg ist am 20. Juni geöffnet</a></li>
<li><a href="../de455248/index.html">Top Entwicklungsfehler bei der Arbeit mit PostgreSQL</a></li>
<li><a href="../de455250/index.html">Derjenige, der Herzog Nukem wiederbelebt hat: Interview mit Randy Pitchford, Magier von Gearbox</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
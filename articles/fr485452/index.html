<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’†ğŸ½ ğŸš« â˜•ï¸ Pourquoi Rust est Ã  la tÃªte de la rÃ©fÃ©rence du framework TechEmpower ğŸ´ ğŸ™ğŸ¾ ğŸ•˜</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En fait, je n'avais pas l'intention de voir de quelle couleur Ã©taient les tripes de Rust. J'ai choisi un projet de passe-temps sur Go, je suis allÃ© su...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi Rust est Ã  la tÃªte de la rÃ©fÃ©rence du framework TechEmpower</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485452/"><p>  En fait, je n'avais pas l'intention de voir de quelle couleur Ã©taient les tripes de Rust.  J'ai choisi un projet de passe-temps sur Go, je suis allÃ© sur GitHub pour voir l'Ã©tat de fasthttp: est-ce qu'il se dÃ©veloppe?  Eh bien, au moins pris en charge?  A grandi.  Je suis allÃ©, j'ai regardÃ© oÃ¹ se situe <a href="https://www.techempower.com/benchmarks/" rel="nofollow">fasthttp</a> dans les benchmarks <a href="https://www.techempower.com/benchmarks/" rel="nofollow">TechEmpower</a> .  Je regarde: et lÃ , fasthttp montre Ã  peine la moitiÃ© de ce que le leader rÃ©ussit - Ã  certains actix sur certains Rust.  Quelle douleur. </p><br><p>  Ici, je croisais les bras, me cognais la tÃªte au sol (trois fois) et criais: "AllÃ©luia, en vÃ©ritÃ©, Rust est un vrai dieu, comme j'Ã©tais aveugle avant!".  Mais soit les poignÃ©es n'ont pas fonctionnÃ©, soit le front a regrettÃ© ... Au lieu de cela, je suis entrÃ© dans le code des tests Ã©crits en Go et des tests actix-web en Rust.  Pour le trier. </p><br><p>  AprÃ¨s quelques heures, j'ai dÃ©couvert: </p><br><ol><li>  pourquoi le framework rouille actix-web occupe la premiÃ¨re place dans tous les tests TechEmpower, </li><li>  comment Java dÃ©marre Script. </li></ol><br><p>  Maintenant, je vais tout vous dire dans l'ordre. </p><a name="habracut"></a><br><h2 id="chto-za-techempower-framework-benchmark">  Qu'est-ce que TechEmpower Framework Benchmark? </h2><br><p>  Si un framework Web dÃ©montre s'il va ou, par exemple, pense parfois Ã  chuchoter Ã  des amis "je suis rapide", alors il tombera sÃ»rement dans le rÃ©fÃ©rentiel du framework TechEmpower.  Un endroit populaire pour mesurer les performances. </p><br><p>  Le site a un design particulier: les onglets des filtres, des tours, des conditions et des rÃ©sultats pour diffÃ©rents types de tests sont dispersÃ©s sur la page avec une main gÃ©nÃ©reuse.  Si gÃ©nÃ©reux et si gÃ©nÃ©reux que vous ne les remarquez tout simplement pas.  Mais cela vaut la peine de cliquer sur les onglets, les informations derriÃ¨re eux sont utiles. </p><br><p>  Le moyen le plus simple consiste Ã  obtenir les rÃ©sultats du test en clair, "Bonjour tout le monde!"  pour les serveurs Web.  Les auteurs du cadre lui donnent gÃ©nÃ©ralement un lien: nous sommes censÃ©s rester dans les cent premiers.  Le cas est correct et utile.  En gÃ©nÃ©ral, donner du texte en clair est bon pour beaucoup, et les dirigeants vont en groupe serrÃ©. </p><br><p>  Ã€ proximitÃ©, dans ces mÃªmes onglets, se trouvent les rÃ©sultats de tests d'autres types (scÃ©narios).  Il y en a sept, plus de dÃ©tails peuvent Ãªtre trouvÃ©s <a href="https://github.com/TechEmpower/FrameworkBenchmarks/wiki/Project-Information-Framework-Tests-Overview" rel="nofollow">ici</a> .  Ces scripts testent non seulement la faÃ§on dont le framework / la plateforme gÃ¨re le traitement d'une simple requÃªte http, mais Ã©galement une combinaison avec un client de base de donnÃ©es, un moteur de modÃ¨le ou un sÃ©rialiseur JSON. </p><br><p>  Il existe des donnÃ©es de test dans un environnement virtuel, sur un matÃ©riel physique.  En plus des graphiques, il existe des donnÃ©es tabulaires.  En gÃ©nÃ©ral, beaucoup de choses intÃ©ressantes, il vaut la peine de creuser, pas seulement de regarder la position de "votre" plate-forme. </p><br><p>  La premiÃ¨re chose qui m'est venue Ã  l'esprit aprÃ¨s avoir parcouru les rÃ©sultats du test: "Pourquoi tout est-il SI SI diffÃ©rent du texte en clair?!".  En texte clair, les dirigeants forment un groupe restreint, mais lorsqu'il s'agit de travailler avec la base de donnÃ©es, actix-web mÃ¨ne avec une marge importante.  Dans le mÃªme temps, il affiche un temps de traitement des demandes stable.  Shaitan. </p><br><p>  Autre anomalie: une solution JavaScript incroyablement puissante.  Il s'appelle ex4x.  Il s'est avÃ©rÃ© que son code Ã©tait lÃ©gÃ¨rement moins que complÃ¨tement Ã©crit en Java.  UtilisÃ© par le runtime Java, JDBC.  Le code JavaScript est traduit en bytecode et colle les bibliothÃ¨ques Java.  Ils l'ont littÃ©ralement pris - et ont attachÃ© Script Ã  Java.  Les astuces des visages pÃ¢les n'ont pas de limites. </p><br><h2 id="kak-posmotret-kod-i-chto-tam-vnutri">  Comment regarder le code et ce qu'il contient </h2><br><p>  Le code pour tous les tests est sur GitHub.  Tout est dans un seul rÃ©fÃ©rentiel, ce qui est trÃ¨s pratique.  Vous pouvez cloner et regarder, vous pouvez regarder directement sur GitHub.  Les tests impliquent plus de 300 combinaisons diffÃ©rentes de l'infrastructure avec des sÃ©rialiseurs, des moteurs de modÃ¨le et le client de base de donnÃ©es.  Dans diffÃ©rents langages de programmation, avec une approche diffÃ©rente du dÃ©veloppement.  Les implÃ©mentations dans une langue sont proches, cela peut Ãªtre comparÃ© Ã  l'implÃ©mentation dans d'autres langues.  Le code est maintenu par la communautÃ©, ce n'est pas le travail d'une seule personne ou Ã©quipe. </p><br><p>  Le code de rÃ©fÃ©rence est un endroit idÃ©al pour Ã©largir vos horizons.  Il est intÃ©ressant d'analyser comment diffÃ©rentes personnes rÃ©solvent les mÃªmes problÃ¨mes.  Il n'y a pas beaucoup de code, les bibliothÃ¨ques et les solutions utilisÃ©es sont faciles Ã  distinguer.  Je ne regrette pas du tout dâ€™Ãªtre arrivÃ© lÃ -bas.  J'ai beaucoup appris.  Tout d'abord Ã  propos de Rust. </p><br><p>  Avant Rust, j'avais une idÃ©e trÃ¨s vague.  Tout article sur C, C ++, D, et surtout Go est sÃ»r d'avoir quelques commentateurs qui expliquent en dÃ©tail et avec angoisse que la vanitÃ©, le non-sens et la stupiditÃ© sont Ã©crits dans autre chose, tant qu'il y a <del>  Gascogne </del>  Rouille.  Parfois, ils s'emballent tellement qu'ils donnent des exemples de code qu'une personne non prÃ©parÃ©e <del>  ou peu d'accepter </del>  conduit dans une stupeur: "Pourquoi, pourquoi, pourquoi tous ces symboles?!" </p><br><p>  Par consÃ©quent, l'ouverture du code Ã©tait effrayante. </p><br><p>  J'ai regardÃ©.  Il s'est avÃ©rÃ© que les programmes de Rust peuvent Ãªtre lus.  De plus, le code est si bien lu que j'ai mÃªme installÃ© Rust, j'ai essayÃ© de compiler le test et de le bricoler un peu. </p><br><p>  Ici j'ai failli abandonner cette affaire, car la compilation dure longtemps.  Un temps trÃ¨s long.  Si j'Ã©tais d'Artagnan, ou mÃªme simplement colÃ©rique, je me serais prÃ©cipitÃ© en Gascogne, et mille dÃ©mons traÃ®neraient avec dÃ©couragement.  Mais je l'ai fait.  J'ai encore bu du thÃ©.  Il semble que mÃªme pas une tasse: sur mon ordinateur portable, la premiÃ¨re compilation a pris environ 20 minutes, puis, tout va plus amusant.  Peut-Ãªtre jusqu'Ã  la prochaine grande mise Ã  jour des caisses. </p><br><h2 id="a-razve-delo-ne-v-samom-rust">  Mais n'est-ce pas Rust lui-mÃªme? </h2><br><p>  Non.  Pas un langage de programmation. </p><br><p>  Bien sÃ»r, Rust est une langue merveilleuse.  Puissant, flexible, mais par habitude et verbeux.  Mais le langage lui-mÃªme n'Ã©crira pas de code rapide.  La langue est l'un des outils, l'une des dÃ©cisions prises par le programmeur. </p><br><p>  Comme je l'ai dit - donner du texte en clair est rapidement obtenu par beaucoup.  Les performances des frameworks actix-web, fasthttp et une douzaine d'autres lors du traitement d'une simple demande sont assez comparables, c'est-Ã -dire que d'autres langages ont la capacitÃ© technique de rivaliser avec Rust. </p><br><p>  Actix-web lui-mÃªme, bien sÃ»r, est Â«Ã  blÃ¢merÂ»: un produit rapide, pragmatique et excellent.  La sÃ©rialisation est pratique, le moteur de modÃ¨le est bon - cela aide aussi beaucoup. </p><br><p>  Plus particuliÃ¨rement, les rÃ©sultats des tests effectuÃ©s avec la base de donnÃ©es diffÃ¨rent. </p><br><p>  AprÃ¨s avoir creusÃ© un peu dans le code, j'ai mis en Ã©vidence trois diffÃ©rences principales qui (il me semble) ont aidÃ© les tests actix Ã  se dÃ©marquer des concurrents dans les tests synthÃ©tiques: </p><br><ol><li>  Mode de fonctionnement pipelined pipelined tokio-postgres; </li><li>  Utiliser une seule connexion avec un test Rust au lieu d'un pool de connexions avec un test Ã©crit en Go; </li><li>  Mise Ã  jour des benchmarks actix avec une seule commande envoyÃ©e via une simple requÃªte au lieu d'envoyer plusieurs commandes UPDATE. </li></ol><br><h2 id="chto-esche-za-konveyernyy-rezhim">  Quel type de mode convoyeur? </h2><br><p>  Voici un extrait de la documentation tokio-postgres (utilisÃ© dans le cas-test de la bibliothÃ¨que cliente PostgreSQL) expliquant ce que ses dÃ©veloppeurs veulent dire: </p><br><pre><code class="plaintext hljs">Sequential Pipelined | Client | PostgreSQL | | Client | PostgreSQL | |----------------|-----------------| |----------------|-----------------| | send query 1 | | | send query 1 | | | | process query 1 | | send query 2 | process query 1 | | receive rows 1 | | | send query 3 | process query 2 | | send query 2 | | | receive rows 1 | process query 3 | | | process query 2 | | receive rows 2 | | | receive rows 2 | | | receive rows 3 | | | send query 3 | | | | process query 3 | | receive rows 3 | |</code> </pre> <br><p>  Le client en mode pipelined (pipelined) n'attend pas de rÃ©ponse PostgreSQL, mais envoie la requÃªte suivante pendant que PostgreSQL traite la prÃ©cÃ©dente.  On peut voir que de cette faÃ§on, vous pouvez traiter la mÃªme sÃ©quence de requÃªtes de base de donnÃ©es beaucoup plus rapidement. </p><br><p>  Si la connexion en mode pipeline est duplex (offrant la possibilitÃ© d'obtenir des rÃ©sultats en parallÃ¨le avec l'envoi), ce temps peut Ãªtre lÃ©gÃ¨rement rÃ©duit.  Il semble qu'il existe dÃ©jÃ  une version expÃ©rimentale de tokio-postgres oÃ¹ une connexion duplex est ouverte. </p><br><p>  Ã‰tant donnÃ© que le client PostgreSQL envoie plusieurs messages (Parse, Bind, Execute et Sync) Ã  chaque requÃªte SQL envoyÃ©e pour exÃ©cution et reÃ§oit une rÃ©ponse Ã  ceux-ci, le mode pipeline sera plus efficace mÃªme lors du traitement de requÃªtes uniques. </p><br><h2 id="a-pochemu-v-go-ne-tak">  Et pourquoi n'est-ce pas dans Go? </h2><br><p>  Parce que Go utilise gÃ©nÃ©ralement des pools de connexions de base de donnÃ©es.  Les connexions ne sont pas destinÃ©es Ã  Ãªtre utilisÃ©es en parallÃ¨le. </p><br><p>  Si vous exÃ©cutez les mÃªmes requÃªtes SQL via un pool, plutÃ´t qu'une seule connexion, vous pouvez thÃ©oriquement obtenir un temps d'exÃ©cution encore plus court avec un client sÃ©rie ordinaire que lorsque vous travaillez via une seule connexion, que ce soit trois fois en pipeline: </p><br><pre> <code class="plaintext hljs">| Connection | Connection 2 | Connection 3 | PostgreSQL | |----------------|----------------|----------------|-----------------| | send query 1 | | | | | | send query 2 | | process query 1 | | receive rows 1 | | send query 3 | process query 2 | | | receive rows 2 | | process query 3 | | | receive rows 3 | |</code> </pre><br><p>  On dirait que la peau de mouton (mode convoyeur) ne vaut pas la chandelle. </p><br><p>  Ce n'est que sous une charge Ã©levÃ©e que le nombre de connexions au serveur PostgreSQL peut poser problÃ¨me. </p><br><h2 id="a-pri-chyom-tut-voobsche-kolichestvo-soedineniy">  Et qu'est-ce que le nombre de connexions a Ã  voir avec Ã§a? </h2><br><p>  Le point ici est de savoir comment le serveur PostgreSQL rÃ©pond Ã  une augmentation du nombre de connexions. </p><br><p>  Le groupe de colonnes de gauche montre l'augmentation et la baisse des performances de PostgreSQL en fonction du nombre de connexions ouvertes: </p><br><p><img src="https://habrastorage.org/webt/nj/rl/io/njrlior5dxzdovhnxrv4spx8q_w.png"></p><br><p>  <em>( <a href="https://www.percona.com/blog/2018/06/27/scaling-postgresql-with-pgbouncer-you-may-need-a-connection-pooler-sooner-than-you-expect/" rel="nofollow">AdaptÃ© du post Percona</a> )</em> </p><br><p>  On peut voir qu'avec une augmentation du nombre de connexions ouvertes, les performances du serveur PostgreSQL chutent rapidement. </p><br><p>  De plus, l'ouverture d'une connexion directe n'est pas Â«gratuiteÂ».  ImmÃ©diatement aprÃ¨s l'ouverture, le client envoie des informations de service, "est d'accord" avec le serveur PostgreSQL sur la faÃ§on dont les demandes seront traitÃ©es. </p><br><p>  Par consÃ©quent, dans la pratique, vous devez limiter le nombre de connexions actives Ã  PostgreSQL, en les passant souvent en plus via pgbouncer ou une autre odyssÃ©e. </p><br><h2 id="tak-pochemu-actix-web-okazalsya-bystree">  Alors pourquoi Actix-Web a-t-il Ã©tÃ© plus rapide? </h2><br><p>  Tout d'abord, actix-web lui-mÃªme est sacrÃ©ment rapide.  C'est lui qui fixe le Â«plafondÂ», et il est lÃ©gÃ¨rement supÃ©rieur Ã  celui des autres.  Les autres bibliothÃ¨ques utilisÃ©es (serde, yarde) sont Ã©galement trÃ¨s, trÃ¨s productives.  Mais il me semble que dans les tests fonctionnant avec PostgreSQL, il a Ã©tÃ© possible de se dÃ©tacher car le serveur actix-web dÃ©marre un thread sur le cÅ“ur du processeur.  Chaque thread ouvre une seule connexion Ã  PostgreSQL. </p><br><p>  Moins il y a de connexions actives, plus PostgreSQL fonctionne rapidement (voir les graphiques ci-dessus). </p><br><p>  Le client fonctionnant en mode pipeline (tokio-postgres) vous permet d'utiliser efficacement une connexion avec PostgreSQL pour le traitement parallÃ¨le des requÃªtes des utilisateurs.  Les gestionnaires de requÃªtes HTTP dÃ©chargent leurs commandes SQL dans une file d'attente et s'alignent dans une autre pour recevoir les rÃ©sultats.  Les rÃ©sultats sont amusants, les retards sont minimes, tout le monde est content.  Les performances globales sont supÃ©rieures Ã  celles d'un systÃ¨me avec un pool de connexions. </p><br><p>  Vous devez donc abandonner le pool, Ã©crire un client de pipeline PostgreSQL, et le bonheur et la vitesse incroyable viendront tout de suite? </p><br><p>  C'est possible.  Mais pas tout d'un coup. </p><br><h2 id="kogda-konveyernyy-rezhim-vryad-li-spaset-i-uzh-tochno-ne-sohranit">  Lorsque le mode convoyeur est peu susceptible de sauver et ne sauvera certainement pas </h2><br><p>  Le schÃ©ma utilisÃ© dans le code de rÃ©fÃ©rence ne fonctionnera pas avec les transactions PostgreSQL. </p><br><p>  Dans le benchmark, les transactions ne sont pas nÃ©cessaires et le code est Ã©crit en tenant compte du fait qu'il n'y aura pas de transactions.  En pratique, cela arrive. </p><br><p>  Si le code backend ouvre une transaction PostgreSQL (par exemple, pour effectuer une modification dans deux tables atomiques diffÃ©rentes), toutes les commandes envoyÃ©es via cette connexion seront exÃ©cutÃ©es Ã  l'intÃ©rieur de cette transaction. </p><br><p>  Puisque la connexion avec PostgreSQL est utilisÃ©e en parallÃ¨le, tout y est mÃ©langÃ©.  Les commandes qui doivent Ãªtre exÃ©cutÃ©es dans une transaction telle que conÃ§ue par le dÃ©veloppeur sont mÃ©langÃ©es avec des commandes sql lancÃ©es par des gestionnaires de requÃªtes http parallÃ¨les.  Nous recevrons des pertes de donnÃ©es alÃ©atoires et des problÃ¨mes d'intÃ©gritÃ©. </p><br><p>  Alors bonjour transaction - au revoir utilisation parallÃ¨le d'une connexion.  Vous devrez vous assurer que la connexion n'est pas utilisÃ©e par d'autres gestionnaires de requÃªtes http.  Vous devrez soit arrÃªter le traitement des requÃªtes http entrantes avant de fermer la transaction, soit utiliser un pool pour les transactions, en ouvrant plusieurs connexions au serveur de base de donnÃ©es.  Il existe plusieurs implÃ©mentations de pool pour Rust, et aucune.  De plus, ils existent dans Rust sÃ©parÃ©ment de l'implÃ©mentation du client de base de donnÃ©es.  Vous pouvez choisir selon le goÃ»t, la couleur, l'odeur ou au hasard.  Go ne fonctionne pas de cette faÃ§on.  Le pouvoir des gÃ©nÃ©riques, oui. </p><br><p>  Un point important: dans le test, dont j'ai regardÃ© le code, les transactions ne s'ouvrent pas.  Cette question n'en vaut tout simplement pas la peine.  Le code de rÃ©fÃ©rence est optimisÃ© pour une tÃ¢che spÃ©cifique et des conditions de fonctionnement d'application trÃ¨s spÃ©cifiques.  La dÃ©cision d'utiliser une connexion par flux de serveur a probablement Ã©tÃ© prise consciemment et s'est avÃ©rÃ©e trÃ¨s efficace. </p><br><h2 id="est-v-kode-benchmarka-esche-chto-to-interesnoe">  Y a-t-il autre chose d'intÃ©ressant dans le code de rÃ©fÃ©rence? </h2><br><p>  Oui </p><br><p>  Le scÃ©nario de mesure des performances est dÃ©crit en dÃ©tail.  Ainsi que les critÃ¨res que le code participant aux tests doit satisfaire.  L'un d'eux est que toutes les requÃªtes adressÃ©es au serveur de base de donnÃ©es doivent Ãªtre exÃ©cutÃ©es sÃ©quentiellement. </p><br><p>  Le fragment de code suivant (lÃ©gÃ¨rement abrÃ©gÃ©) semble ne pas rÃ©pondre aux critÃ¨res: </p><br><pre> <code class="rust hljs"> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mut</span></span> worlds = <span class="hljs-built_in"><span class="hljs-built_in">Vec</span></span>::with_capacity(num); <span class="hljs-comment"><span class="hljs-comment">//  num    PostgreSQL for _ in 0..num { let w_id: i32 = self.rng.gen_range(1, 10_001); worlds.push( self.cl .query(&amp;self.world, &amp;[&amp;w_id]) .into_future() .map(move |(row, _)| { // ... }), ); } //     stream::futures_unordered(worlds) .collect() .and_then(move |worlds| { // ... })</span></span></code> </pre> <br><p>  Tout ressemble Ã  un lancement typique de processus parallÃ¨les.  Mais comme une connexion Ã  PostgreSQL est utilisÃ©e, les requÃªtes vers le serveur de base de donnÃ©es sont envoyÃ©es sÃ©quentiellement.  Un par un.  Au besoin.  Pas de crime. </p><br><p>  Pourquoi  Eh bien, tout d'abord, dans le code (il a Ã©tÃ© donnÃ© Ã  la rÃ©daction, qui a travaillÃ© au 18e tour), async / attente n'est pas encore utilisÃ©, il est apparu plus tard dans Rust.  Et grÃ¢ce Ã  futures <code>num</code> il est plus facile d'envoyer des requÃªtes SQL "en parallÃ¨le" - comme dans le code ci-dessus.  Cela vous permet d'obtenir une amÃ©lioration supplÃ©mentaire des performances: alors que PostgreSQL accepte et traite la premiÃ¨re requÃªte SQL, les autres y sont alimentÃ©es.  Le serveur Web n'attend pas le rÃ©sultat de chacun, mais passe Ã  d'autres tÃ¢ches et ne revient au traitement de la requÃªte http que lorsque toutes les requÃªtes SQL sont terminÃ©es. </p><br><p>  Pour PostgreSQL, le bonus est que le mÃªme type de requÃªte dans le mÃªme contexte (connexion) va de suite.  La probabilitÃ© que le plan de requÃªte ne soit pas reconstruit augmente. </p><br><p>  Il s'avÃ¨re que les avantages du mode pipeline (voir le schÃ©ma de la documentation tokio-postgres) sont pleinement exploitÃ©s mÃªme lors du traitement d'une seule requÃªte http. </p><br><p>  Quoi d'autre? </p><br><h2 id="ispolzovanie-uproschennogo-protokola-simple-query-dlya-paketnogo-obnovleniya">  Utilisation du protocole de requÃªte simple pour les mises Ã  jour par lots </h2><br><p>  Le protocole de communication entre le client et le serveur PostgreSQL permet des mÃ©thodes alternatives pour exÃ©cuter des commandes SQL.  Le protocole habituel (Extended Query) consiste Ã  envoyer plusieurs messages Ã  un client: Parse, Bind, Execute et Sync.  Une alternative est le protocole Simple Query, selon lequel un seul message suffit pour exÃ©cuter une commande et obtenir des rÃ©sultats - Query. </p><br><p>  La principale diffÃ©rence entre le protocole habituel est le transfert des paramÃ¨tres de requÃªte: ils sont transmis sÃ©parÃ©ment de la commande elle-mÃªme.  Câ€™est plus sÃ»r.  Le protocole simplifiÃ© suppose que tous les paramÃ¨tres de la requÃªte SQL seront convertis en chaÃ®ne et inclus dans le corps de la requÃªte. </p><br><p>  Une solution intÃ©ressante utilisÃ©e dans les benchmarks actix-web Ã©tait de mettre Ã  jour plusieurs entrÃ©es de table avec une seule commande envoyÃ©e via le protocole Simple Query. </p><br><p>  Selon le benchmark, lors du traitement d'une demande utilisateur, le serveur web doit mettre Ã  jour plusieurs enregistrements de la table, Ã©crire des nombres alÃ©atoires.  De toute Ã©vidence, la mise Ã  jour des enregistrements successivement avec des requÃªtes sÃ©quentielles prend plus de temps qu'une seule requÃªte mettant Ã  jour tous les enregistrements Ã  la fois. </p><br><p>  La demande gÃ©nÃ©rÃ©e dans le code de test ressemble Ã  ceci: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> world <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> randomnumber = temp.randomnumber <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> temp(<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>, randomnumber) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> temp.id = world.id</code> </pre> <br><p>  OÃ¹ <code>(1, 2), (2, 3)</code> sont les paires d'identificateurs de ligne / nouvelle valeur du champ de numÃ©ro alÃ©atoire. </p><br><p>  Le nombre d'enregistrements mis Ã  jour est variable, prÃ©parer la demande (PREPARE) Ã  l'avance n'a pas de sens.  Ã‰tant donnÃ© que les donnÃ©es Ã  mettre Ã  jour sont numÃ©riques et que la source peut Ãªtre fiable (le code de test lui-mÃªme), il n'y a aucun risque d'injection SQL, les donnÃ©es sont simplement incluses dans le corps SQL et tout est envoyÃ© Ã  l'aide du protocole Simple Query. </p><br><p>  Une rumeur simple circule.  J'ai rencontrÃ© une recommandation: "Ne travaillez que sur le protocole Simple Query, et tout sera rapide et correct."  Je la perÃ§ois avec beaucoup de scepticisme.  Simple Query vous permet de rÃ©duire le nombre de messages envoyÃ©s au serveur PostgreSQL en dÃ©plaÃ§ant le traitement des paramÃ¨tres de requÃªte cÃ´tÃ© client.  Vous pouvez voir le gain pour les requÃªtes gÃ©nÃ©rÃ©es dynamiquement avec un nombre variable de paramÃ¨tres.  Pour le mÃªme type de requÃªtes SQL (qui sont plus courantes), le gain n'est pas Ã©vident.  Eh bien et Ã  quel point le traitement des paramÃ¨tres de requÃªte se rÃ©vÃ©lera sÃ»r, dans le cas de Simple Query, il dÃ©termine la mise en Å“uvre de la bibliothÃ¨que cliente. </p><br><p>  Comme je l'ai Ã©crit ci-dessus, dans ce cas, le corps de la requÃªte SQL est gÃ©nÃ©rÃ© dynamiquement, les donnÃ©es sont numÃ©riques et gÃ©nÃ©rÃ©es par le serveur lui-mÃªme.  La combinaison parfaite pour Simple Query.  Mais mÃªme dans ce cas, il vaut la peine de tester d'autres options.  Les alternatives dÃ©pendent de la plateforme et du client PostgreSQL: pgx (client for Go) permet d'envoyer un paquet de commandes, JDBC - pour exÃ©cuter une commande plusieurs fois de suite avec des paramÃ¨tres diffÃ©rents.  Les deux solutions peuvent fonctionner Ã  la mÃªme vitesse ou mÃªme Ãªtre plus rapides. </p><br><h2 id="tak-pochemu-rust-lidiruet">  Alors, pourquoi Rust est-il en tÃªte? </h2><br><p>  Le chef, bien sÃ»r, n'est pas Rust.  Les tests basÃ©s sur actix-web mÃ¨nent - c'est lui qui fixe le "plafond" de la performance.  Il y a, par exemple, la fusÃ©e et le fer, qui occupent des positions modestes.  Mais pour le moment, c'est actix-web qui dÃ©termine le potentiel d'utilisation de Rust dans le dÃ©veloppement web.  Quant Ã  moi, le potentiel est trÃ¨s Ã©levÃ©. </p><br><p>  Un autre serveur "secret" non Ã©vident mais important basÃ© sur actix-web, qui a permis de prendre la premiÃ¨re place dans tous les benchmarks TechEmpower - dans la faÃ§on dont il fonctionne avec PostgreSQL: </p><br><ol><li>  Une seule connexion avec PostgreSQL par flux de serveur Web s'ouvre.  Cette connexion utilise le mode pipeline, ce qui lui permet d'Ãªtre efficacement utilisÃ© pour le traitement parallÃ¨le des demandes des utilisateurs. </li><li>  Moins il y a de connexions actives, plus PostgreSQL rÃ©pond rapidement.  La vitesse de traitement des demandes des utilisateurs augmente.  Dans le mÃªme temps, sous charge, l'ensemble du systÃ¨me fonctionne de maniÃ¨re plus stable (les dÃ©lais de traitement des demandes entrantes sont plus faibles, ils augmentent plus lentement). </li></ol><br><p>  Lorsque la vitesse est importante, cette option sera probablement plus rapide que l'utilisation de multiplexeurs (tels que pgbouncer et odyssey).  Et il Ã©tait certainement plus rapide dans les repÃ¨res. </p><br><p>  Il est trÃ¨s intÃ©ressant de voir comment async / wait, qui est apparu dans Rust, et le rÃ©cent drame avec actix-web affectera la popularitÃ© de Rust dans le dÃ©veloppement Web.  Il est Ã©galement intÃ©ressant de voir comment les rÃ©sultats des tests changeront aprÃ¨s les avoir traitÃ©s en asynchronisation / attente. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr485452/">https://habr.com/ru/post/fr485452/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr485428/index.html">Le mystÃ©rieux programme LyX. Partie 5</a></li>
<li><a href="../fr485430/index.html">Ã‰diteur de texte multi-utilisateurs simple avec chiffrement de bout en bout</a></li>
<li><a href="../fr485438/index.html">Test des composants React UI</a></li>
<li><a href="../fr485448/index.html">Une autre radio FM sur le RDA5807 exÃ©cutant Arduino</a></li>
<li><a href="../fr485450/index.html">Quoi de neuf dans SObjectizer-5.7.0 et qu'est-ce qui attend ce projet ensuite?</a></li>
<li><a href="../fr485454/index.html">Premiers pas avec les retours d'utilisateurs: conseils pour le modÃ¨le accrochÃ©</a></li>
<li><a href="../fr485458/index.html">Silencieux d'obusier</a></li>
<li><a href="../fr485460/index.html">20 bibliothÃ¨ques pour une application iOS spectaculaire</a></li>
<li><a href="../fr485462/index.html">Nous traitons avec eSIM (+ entretien avec un expert)</a></li>
<li><a href="../fr485464/index.html">Mon premier jeu html5, d'Alice Yandex et de rÃ©compenses aux applications mobiles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💆🏽 🚫 ☕️ Pourquoi Rust est à la tête de la référence du framework TechEmpower 🎴 🙍🏾 🕘</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En fait, je n'avais pas l'intention de voir de quelle couleur étaient les tripes de Rust. J'ai choisi un projet de passe-temps sur Go, je suis allé su...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi Rust est à la tête de la référence du framework TechEmpower</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485452/"><p>  En fait, je n'avais pas l'intention de voir de quelle couleur étaient les tripes de Rust.  J'ai choisi un projet de passe-temps sur Go, je suis allé sur GitHub pour voir l'état de fasthttp: est-ce qu'il se développe?  Eh bien, au moins pris en charge?  A grandi.  Je suis allé, j'ai regardé où se situe <a href="https://www.techempower.com/benchmarks/" rel="nofollow">fasthttp</a> dans les benchmarks <a href="https://www.techempower.com/benchmarks/" rel="nofollow">TechEmpower</a> .  Je regarde: et là, fasthttp montre à peine la moitié de ce que le leader réussit - à certains actix sur certains Rust.  Quelle douleur. </p><br><p>  Ici, je croisais les bras, me cognais la tête au sol (trois fois) et criais: "Alléluia, en vérité, Rust est un vrai dieu, comme j'étais aveugle avant!".  Mais soit les poignées n'ont pas fonctionné, soit le front a regretté ... Au lieu de cela, je suis entré dans le code des tests écrits en Go et des tests actix-web en Rust.  Pour le trier. </p><br><p>  Après quelques heures, j'ai découvert: </p><br><ol><li>  pourquoi le framework rouille actix-web occupe la première place dans tous les tests TechEmpower, </li><li>  comment Java démarre Script. </li></ol><br><p>  Maintenant, je vais tout vous dire dans l'ordre. </p><a name="habracut"></a><br><h2 id="chto-za-techempower-framework-benchmark">  Qu'est-ce que TechEmpower Framework Benchmark? </h2><br><p>  Si un framework Web démontre s'il va ou, par exemple, pense parfois à chuchoter à des amis "je suis rapide", alors il tombera sûrement dans le référentiel du framework TechEmpower.  Un endroit populaire pour mesurer les performances. </p><br><p>  Le site a un design particulier: les onglets des filtres, des tours, des conditions et des résultats pour différents types de tests sont dispersés sur la page avec une main généreuse.  Si généreux et si généreux que vous ne les remarquez tout simplement pas.  Mais cela vaut la peine de cliquer sur les onglets, les informations derrière eux sont utiles. </p><br><p>  Le moyen le plus simple consiste à obtenir les résultats du test en clair, "Bonjour tout le monde!"  pour les serveurs Web.  Les auteurs du cadre lui donnent généralement un lien: nous sommes censés rester dans les cent premiers.  Le cas est correct et utile.  En général, donner du texte en clair est bon pour beaucoup, et les dirigeants vont en groupe serré. </p><br><p>  À proximité, dans ces mêmes onglets, se trouvent les résultats de tests d'autres types (scénarios).  Il y en a sept, plus de détails peuvent être trouvés <a href="https://github.com/TechEmpower/FrameworkBenchmarks/wiki/Project-Information-Framework-Tests-Overview" rel="nofollow">ici</a> .  Ces scripts testent non seulement la façon dont le framework / la plateforme gère le traitement d'une simple requête http, mais également une combinaison avec un client de base de données, un moteur de modèle ou un sérialiseur JSON. </p><br><p>  Il existe des données de test dans un environnement virtuel, sur un matériel physique.  En plus des graphiques, il existe des données tabulaires.  En général, beaucoup de choses intéressantes, il vaut la peine de creuser, pas seulement de regarder la position de "votre" plate-forme. </p><br><p>  La première chose qui m'est venue à l'esprit après avoir parcouru les résultats du test: "Pourquoi tout est-il SI SI différent du texte en clair?!".  En texte clair, les dirigeants forment un groupe restreint, mais lorsqu'il s'agit de travailler avec la base de données, actix-web mène avec une marge importante.  Dans le même temps, il affiche un temps de traitement des demandes stable.  Shaitan. </p><br><p>  Autre anomalie: une solution JavaScript incroyablement puissante.  Il s'appelle ex4x.  Il s'est avéré que son code était légèrement moins que complètement écrit en Java.  Utilisé par le runtime Java, JDBC.  Le code JavaScript est traduit en bytecode et colle les bibliothèques Java.  Ils l'ont littéralement pris - et ont attaché Script à Java.  Les astuces des visages pâles n'ont pas de limites. </p><br><h2 id="kak-posmotret-kod-i-chto-tam-vnutri">  Comment regarder le code et ce qu'il contient </h2><br><p>  Le code pour tous les tests est sur GitHub.  Tout est dans un seul référentiel, ce qui est très pratique.  Vous pouvez cloner et regarder, vous pouvez regarder directement sur GitHub.  Les tests impliquent plus de 300 combinaisons différentes de l'infrastructure avec des sérialiseurs, des moteurs de modèle et le client de base de données.  Dans différents langages de programmation, avec une approche différente du développement.  Les implémentations dans une langue sont proches, cela peut être comparé à l'implémentation dans d'autres langues.  Le code est maintenu par la communauté, ce n'est pas le travail d'une seule personne ou équipe. </p><br><p>  Le code de référence est un endroit idéal pour élargir vos horizons.  Il est intéressant d'analyser comment différentes personnes résolvent les mêmes problèmes.  Il n'y a pas beaucoup de code, les bibliothèques et les solutions utilisées sont faciles à distinguer.  Je ne regrette pas du tout d’être arrivé là-bas.  J'ai beaucoup appris.  Tout d'abord à propos de Rust. </p><br><p>  Avant Rust, j'avais une idée très vague.  Tout article sur C, C ++, D, et surtout Go est sûr d'avoir quelques commentateurs qui expliquent en détail et avec angoisse que la vanité, le non-sens et la stupidité sont écrits dans autre chose, tant qu'il y a <del>  Gascogne </del>  Rouille.  Parfois, ils s'emballent tellement qu'ils donnent des exemples de code qu'une personne non préparée <del>  ou peu d'accepter </del>  conduit dans une stupeur: "Pourquoi, pourquoi, pourquoi tous ces symboles?!" </p><br><p>  Par conséquent, l'ouverture du code était effrayante. </p><br><p>  J'ai regardé.  Il s'est avéré que les programmes de Rust peuvent être lus.  De plus, le code est si bien lu que j'ai même installé Rust, j'ai essayé de compiler le test et de le bricoler un peu. </p><br><p>  Ici j'ai failli abandonner cette affaire, car la compilation dure longtemps.  Un temps très long.  Si j'étais d'Artagnan, ou même simplement colérique, je me serais précipité en Gascogne, et mille démons traîneraient avec découragement.  Mais je l'ai fait.  J'ai encore bu du thé.  Il semble que même pas une tasse: sur mon ordinateur portable, la première compilation a pris environ 20 minutes, puis, tout va plus amusant.  Peut-être jusqu'à la prochaine grande mise à jour des caisses. </p><br><h2 id="a-razve-delo-ne-v-samom-rust">  Mais n'est-ce pas Rust lui-même? </h2><br><p>  Non.  Pas un langage de programmation. </p><br><p>  Bien sûr, Rust est une langue merveilleuse.  Puissant, flexible, mais par habitude et verbeux.  Mais le langage lui-même n'écrira pas de code rapide.  La langue est l'un des outils, l'une des décisions prises par le programmeur. </p><br><p>  Comme je l'ai dit - donner du texte en clair est rapidement obtenu par beaucoup.  Les performances des frameworks actix-web, fasthttp et une douzaine d'autres lors du traitement d'une simple demande sont assez comparables, c'est-à-dire que d'autres langages ont la capacité technique de rivaliser avec Rust. </p><br><p>  Actix-web lui-même, bien sûr, est «à blâmer»: un produit rapide, pragmatique et excellent.  La sérialisation est pratique, le moteur de modèle est bon - cela aide aussi beaucoup. </p><br><p>  Plus particulièrement, les résultats des tests effectués avec la base de données diffèrent. </p><br><p>  Après avoir creusé un peu dans le code, j'ai mis en évidence trois différences principales qui (il me semble) ont aidé les tests actix à se démarquer des concurrents dans les tests synthétiques: </p><br><ol><li>  Mode de fonctionnement pipelined pipelined tokio-postgres; </li><li>  Utiliser une seule connexion avec un test Rust au lieu d'un pool de connexions avec un test écrit en Go; </li><li>  Mise à jour des benchmarks actix avec une seule commande envoyée via une simple requête au lieu d'envoyer plusieurs commandes UPDATE. </li></ol><br><h2 id="chto-esche-za-konveyernyy-rezhim">  Quel type de mode convoyeur? </h2><br><p>  Voici un extrait de la documentation tokio-postgres (utilisé dans le cas-test de la bibliothèque cliente PostgreSQL) expliquant ce que ses développeurs veulent dire: </p><br><pre><code class="plaintext hljs">Sequential Pipelined | Client | PostgreSQL | | Client | PostgreSQL | |----------------|-----------------| |----------------|-----------------| | send query 1 | | | send query 1 | | | | process query 1 | | send query 2 | process query 1 | | receive rows 1 | | | send query 3 | process query 2 | | send query 2 | | | receive rows 1 | process query 3 | | | process query 2 | | receive rows 2 | | | receive rows 2 | | | receive rows 3 | | | send query 3 | | | | process query 3 | | receive rows 3 | |</code> </pre> <br><p>  Le client en mode pipelined (pipelined) n'attend pas de réponse PostgreSQL, mais envoie la requête suivante pendant que PostgreSQL traite la précédente.  On peut voir que de cette façon, vous pouvez traiter la même séquence de requêtes de base de données beaucoup plus rapidement. </p><br><p>  Si la connexion en mode pipeline est duplex (offrant la possibilité d'obtenir des résultats en parallèle avec l'envoi), ce temps peut être légèrement réduit.  Il semble qu'il existe déjà une version expérimentale de tokio-postgres où une connexion duplex est ouverte. </p><br><p>  Étant donné que le client PostgreSQL envoie plusieurs messages (Parse, Bind, Execute et Sync) à chaque requête SQL envoyée pour exécution et reçoit une réponse à ceux-ci, le mode pipeline sera plus efficace même lors du traitement de requêtes uniques. </p><br><h2 id="a-pochemu-v-go-ne-tak">  Et pourquoi n'est-ce pas dans Go? </h2><br><p>  Parce que Go utilise généralement des pools de connexions de base de données.  Les connexions ne sont pas destinées à être utilisées en parallèle. </p><br><p>  Si vous exécutez les mêmes requêtes SQL via un pool, plutôt qu'une seule connexion, vous pouvez théoriquement obtenir un temps d'exécution encore plus court avec un client série ordinaire que lorsque vous travaillez via une seule connexion, que ce soit trois fois en pipeline: </p><br><pre> <code class="plaintext hljs">| Connection | Connection 2 | Connection 3 | PostgreSQL | |----------------|----------------|----------------|-----------------| | send query 1 | | | | | | send query 2 | | process query 1 | | receive rows 1 | | send query 3 | process query 2 | | | receive rows 2 | | process query 3 | | | receive rows 3 | |</code> </pre><br><p>  On dirait que la peau de mouton (mode convoyeur) ne vaut pas la chandelle. </p><br><p>  Ce n'est que sous une charge élevée que le nombre de connexions au serveur PostgreSQL peut poser problème. </p><br><h2 id="a-pri-chyom-tut-voobsche-kolichestvo-soedineniy">  Et qu'est-ce que le nombre de connexions a à voir avec ça? </h2><br><p>  Le point ici est de savoir comment le serveur PostgreSQL répond à une augmentation du nombre de connexions. </p><br><p>  Le groupe de colonnes de gauche montre l'augmentation et la baisse des performances de PostgreSQL en fonction du nombre de connexions ouvertes: </p><br><p><img src="https://habrastorage.org/webt/nj/rl/io/njrlior5dxzdovhnxrv4spx8q_w.png"></p><br><p>  <em>( <a href="https://www.percona.com/blog/2018/06/27/scaling-postgresql-with-pgbouncer-you-may-need-a-connection-pooler-sooner-than-you-expect/" rel="nofollow">Adapté du post Percona</a> )</em> </p><br><p>  On peut voir qu'avec une augmentation du nombre de connexions ouvertes, les performances du serveur PostgreSQL chutent rapidement. </p><br><p>  De plus, l'ouverture d'une connexion directe n'est pas «gratuite».  Immédiatement après l'ouverture, le client envoie des informations de service, "est d'accord" avec le serveur PostgreSQL sur la façon dont les demandes seront traitées. </p><br><p>  Par conséquent, dans la pratique, vous devez limiter le nombre de connexions actives à PostgreSQL, en les passant souvent en plus via pgbouncer ou une autre odyssée. </p><br><h2 id="tak-pochemu-actix-web-okazalsya-bystree">  Alors pourquoi Actix-Web a-t-il été plus rapide? </h2><br><p>  Tout d'abord, actix-web lui-même est sacrément rapide.  C'est lui qui fixe le «plafond», et il est légèrement supérieur à celui des autres.  Les autres bibliothèques utilisées (serde, yarde) sont également très, très productives.  Mais il me semble que dans les tests fonctionnant avec PostgreSQL, il a été possible de se détacher car le serveur actix-web démarre un thread sur le cœur du processeur.  Chaque thread ouvre une seule connexion à PostgreSQL. </p><br><p>  Moins il y a de connexions actives, plus PostgreSQL fonctionne rapidement (voir les graphiques ci-dessus). </p><br><p>  Le client fonctionnant en mode pipeline (tokio-postgres) vous permet d'utiliser efficacement une connexion avec PostgreSQL pour le traitement parallèle des requêtes des utilisateurs.  Les gestionnaires de requêtes HTTP déchargent leurs commandes SQL dans une file d'attente et s'alignent dans une autre pour recevoir les résultats.  Les résultats sont amusants, les retards sont minimes, tout le monde est content.  Les performances globales sont supérieures à celles d'un système avec un pool de connexions. </p><br><p>  Vous devez donc abandonner le pool, écrire un client de pipeline PostgreSQL, et le bonheur et la vitesse incroyable viendront tout de suite? </p><br><p>  C'est possible.  Mais pas tout d'un coup. </p><br><h2 id="kogda-konveyernyy-rezhim-vryad-li-spaset-i-uzh-tochno-ne-sohranit">  Lorsque le mode convoyeur est peu susceptible de sauver et ne sauvera certainement pas </h2><br><p>  Le schéma utilisé dans le code de référence ne fonctionnera pas avec les transactions PostgreSQL. </p><br><p>  Dans le benchmark, les transactions ne sont pas nécessaires et le code est écrit en tenant compte du fait qu'il n'y aura pas de transactions.  En pratique, cela arrive. </p><br><p>  Si le code backend ouvre une transaction PostgreSQL (par exemple, pour effectuer une modification dans deux tables atomiques différentes), toutes les commandes envoyées via cette connexion seront exécutées à l'intérieur de cette transaction. </p><br><p>  Puisque la connexion avec PostgreSQL est utilisée en parallèle, tout y est mélangé.  Les commandes qui doivent être exécutées dans une transaction telle que conçue par le développeur sont mélangées avec des commandes sql lancées par des gestionnaires de requêtes http parallèles.  Nous recevrons des pertes de données aléatoires et des problèmes d'intégrité. </p><br><p>  Alors bonjour transaction - au revoir utilisation parallèle d'une connexion.  Vous devrez vous assurer que la connexion n'est pas utilisée par d'autres gestionnaires de requêtes http.  Vous devrez soit arrêter le traitement des requêtes http entrantes avant de fermer la transaction, soit utiliser un pool pour les transactions, en ouvrant plusieurs connexions au serveur de base de données.  Il existe plusieurs implémentations de pool pour Rust, et aucune.  De plus, ils existent dans Rust séparément de l'implémentation du client de base de données.  Vous pouvez choisir selon le goût, la couleur, l'odeur ou au hasard.  Go ne fonctionne pas de cette façon.  Le pouvoir des génériques, oui. </p><br><p>  Un point important: dans le test, dont j'ai regardé le code, les transactions ne s'ouvrent pas.  Cette question n'en vaut tout simplement pas la peine.  Le code de référence est optimisé pour une tâche spécifique et des conditions de fonctionnement d'application très spécifiques.  La décision d'utiliser une connexion par flux de serveur a probablement été prise consciemment et s'est avérée très efficace. </p><br><h2 id="est-v-kode-benchmarka-esche-chto-to-interesnoe">  Y a-t-il autre chose d'intéressant dans le code de référence? </h2><br><p>  Oui </p><br><p>  Le scénario de mesure des performances est décrit en détail.  Ainsi que les critères que le code participant aux tests doit satisfaire.  L'un d'eux est que toutes les requêtes adressées au serveur de base de données doivent être exécutées séquentiellement. </p><br><p>  Le fragment de code suivant (légèrement abrégé) semble ne pas répondre aux critères: </p><br><pre> <code class="rust hljs"> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mut</span></span> worlds = <span class="hljs-built_in"><span class="hljs-built_in">Vec</span></span>::with_capacity(num); <span class="hljs-comment"><span class="hljs-comment">//  num    PostgreSQL for _ in 0..num { let w_id: i32 = self.rng.gen_range(1, 10_001); worlds.push( self.cl .query(&amp;self.world, &amp;[&amp;w_id]) .into_future() .map(move |(row, _)| { // ... }), ); } //     stream::futures_unordered(worlds) .collect() .and_then(move |worlds| { // ... })</span></span></code> </pre> <br><p>  Tout ressemble à un lancement typique de processus parallèles.  Mais comme une connexion à PostgreSQL est utilisée, les requêtes vers le serveur de base de données sont envoyées séquentiellement.  Un par un.  Au besoin.  Pas de crime. </p><br><p>  Pourquoi  Eh bien, tout d'abord, dans le code (il a été donné à la rédaction, qui a travaillé au 18e tour), async / attente n'est pas encore utilisé, il est apparu plus tard dans Rust.  Et grâce à futures <code>num</code> il est plus facile d'envoyer des requêtes SQL "en parallèle" - comme dans le code ci-dessus.  Cela vous permet d'obtenir une amélioration supplémentaire des performances: alors que PostgreSQL accepte et traite la première requête SQL, les autres y sont alimentées.  Le serveur Web n'attend pas le résultat de chacun, mais passe à d'autres tâches et ne revient au traitement de la requête http que lorsque toutes les requêtes SQL sont terminées. </p><br><p>  Pour PostgreSQL, le bonus est que le même type de requête dans le même contexte (connexion) va de suite.  La probabilité que le plan de requête ne soit pas reconstruit augmente. </p><br><p>  Il s'avère que les avantages du mode pipeline (voir le schéma de la documentation tokio-postgres) sont pleinement exploités même lors du traitement d'une seule requête http. </p><br><p>  Quoi d'autre? </p><br><h2 id="ispolzovanie-uproschennogo-protokola-simple-query-dlya-paketnogo-obnovleniya">  Utilisation du protocole de requête simple pour les mises à jour par lots </h2><br><p>  Le protocole de communication entre le client et le serveur PostgreSQL permet des méthodes alternatives pour exécuter des commandes SQL.  Le protocole habituel (Extended Query) consiste à envoyer plusieurs messages à un client: Parse, Bind, Execute et Sync.  Une alternative est le protocole Simple Query, selon lequel un seul message suffit pour exécuter une commande et obtenir des résultats - Query. </p><br><p>  La principale différence entre le protocole habituel est le transfert des paramètres de requête: ils sont transmis séparément de la commande elle-même.  C’est plus sûr.  Le protocole simplifié suppose que tous les paramètres de la requête SQL seront convertis en chaîne et inclus dans le corps de la requête. </p><br><p>  Une solution intéressante utilisée dans les benchmarks actix-web était de mettre à jour plusieurs entrées de table avec une seule commande envoyée via le protocole Simple Query. </p><br><p>  Selon le benchmark, lors du traitement d'une demande utilisateur, le serveur web doit mettre à jour plusieurs enregistrements de la table, écrire des nombres aléatoires.  De toute évidence, la mise à jour des enregistrements successivement avec des requêtes séquentielles prend plus de temps qu'une seule requête mettant à jour tous les enregistrements à la fois. </p><br><p>  La demande générée dans le code de test ressemble à ceci: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> world <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> randomnumber = temp.randomnumber <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> temp(<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>, randomnumber) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> temp.id = world.id</code> </pre> <br><p>  Où <code>(1, 2), (2, 3)</code> sont les paires d'identificateurs de ligne / nouvelle valeur du champ de numéro aléatoire. </p><br><p>  Le nombre d'enregistrements mis à jour est variable, préparer la demande (PREPARE) à l'avance n'a pas de sens.  Étant donné que les données à mettre à jour sont numériques et que la source peut être fiable (le code de test lui-même), il n'y a aucun risque d'injection SQL, les données sont simplement incluses dans le corps SQL et tout est envoyé à l'aide du protocole Simple Query. </p><br><p>  Une rumeur simple circule.  J'ai rencontré une recommandation: "Ne travaillez que sur le protocole Simple Query, et tout sera rapide et correct."  Je la perçois avec beaucoup de scepticisme.  Simple Query vous permet de réduire le nombre de messages envoyés au serveur PostgreSQL en déplaçant le traitement des paramètres de requête côté client.  Vous pouvez voir le gain pour les requêtes générées dynamiquement avec un nombre variable de paramètres.  Pour le même type de requêtes SQL (qui sont plus courantes), le gain n'est pas évident.  Eh bien et à quel point le traitement des paramètres de requête se révélera sûr, dans le cas de Simple Query, il détermine la mise en œuvre de la bibliothèque cliente. </p><br><p>  Comme je l'ai écrit ci-dessus, dans ce cas, le corps de la requête SQL est généré dynamiquement, les données sont numériques et générées par le serveur lui-même.  La combinaison parfaite pour Simple Query.  Mais même dans ce cas, il vaut la peine de tester d'autres options.  Les alternatives dépendent de la plateforme et du client PostgreSQL: pgx (client for Go) permet d'envoyer un paquet de commandes, JDBC - pour exécuter une commande plusieurs fois de suite avec des paramètres différents.  Les deux solutions peuvent fonctionner à la même vitesse ou même être plus rapides. </p><br><h2 id="tak-pochemu-rust-lidiruet">  Alors, pourquoi Rust est-il en tête? </h2><br><p>  Le chef, bien sûr, n'est pas Rust.  Les tests basés sur actix-web mènent - c'est lui qui fixe le "plafond" de la performance.  Il y a, par exemple, la fusée et le fer, qui occupent des positions modestes.  Mais pour le moment, c'est actix-web qui détermine le potentiel d'utilisation de Rust dans le développement web.  Quant à moi, le potentiel est très élevé. </p><br><p>  Un autre serveur "secret" non évident mais important basé sur actix-web, qui a permis de prendre la première place dans tous les benchmarks TechEmpower - dans la façon dont il fonctionne avec PostgreSQL: </p><br><ol><li>  Une seule connexion avec PostgreSQL par flux de serveur Web s'ouvre.  Cette connexion utilise le mode pipeline, ce qui lui permet d'être efficacement utilisé pour le traitement parallèle des demandes des utilisateurs. </li><li>  Moins il y a de connexions actives, plus PostgreSQL répond rapidement.  La vitesse de traitement des demandes des utilisateurs augmente.  Dans le même temps, sous charge, l'ensemble du système fonctionne de manière plus stable (les délais de traitement des demandes entrantes sont plus faibles, ils augmentent plus lentement). </li></ol><br><p>  Lorsque la vitesse est importante, cette option sera probablement plus rapide que l'utilisation de multiplexeurs (tels que pgbouncer et odyssey).  Et il était certainement plus rapide dans les repères. </p><br><p>  Il est très intéressant de voir comment async / wait, qui est apparu dans Rust, et le récent drame avec actix-web affectera la popularité de Rust dans le développement Web.  Il est également intéressant de voir comment les résultats des tests changeront après les avoir traités en asynchronisation / attente. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr485452/">https://habr.com/ru/post/fr485452/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr485428/index.html">Le mystérieux programme LyX. Partie 5</a></li>
<li><a href="../fr485430/index.html">Éditeur de texte multi-utilisateurs simple avec chiffrement de bout en bout</a></li>
<li><a href="../fr485438/index.html">Test des composants React UI</a></li>
<li><a href="../fr485448/index.html">Une autre radio FM sur le RDA5807 exécutant Arduino</a></li>
<li><a href="../fr485450/index.html">Quoi de neuf dans SObjectizer-5.7.0 et qu'est-ce qui attend ce projet ensuite?</a></li>
<li><a href="../fr485454/index.html">Premiers pas avec les retours d'utilisateurs: conseils pour le modèle accroché</a></li>
<li><a href="../fr485458/index.html">Silencieux d'obusier</a></li>
<li><a href="../fr485460/index.html">20 bibliothèques pour une application iOS spectaculaire</a></li>
<li><a href="../fr485462/index.html">Nous traitons avec eSIM (+ entretien avec un expert)</a></li>
<li><a href="../fr485464/index.html">Mon premier jeu html5, d'Alice Yandex et de récompenses aux applications mobiles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚è≥ ü¶Ü üßóüèº Klassifizierung der Landbedeckung mittels Eo-Learn. Teil 2 üôéüèª üç™ üè¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Teil 1 
 Teil 3 


 Wechseln von Daten zu Ergebnissen, ohne Ihren Computer zu verlassen 



 Ein Stapel von Bildern einer kleinen Zone in Slowenien un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Klassifizierung der Landbedeckung mittels Eo-Learn. Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452378/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 3</a> </p><br><p>  Wechseln von Daten zu Ergebnissen, ohne Ihren Computer zu verlassen </p><br><p><img src="https://habrastorage.org/webt/hq/kv/ie/hqkviehem-itsqlacwosv2hjdco.png"><br>  <em>Ein Stapel von Bildern einer kleinen Zone in Slowenien und eine Karte mit einer klassifizierten Landbedeckung, die mit den im Artikel beschriebenen Methoden erhalten wurde.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Vorwort </h2><br><p>  Der zweite Teil einer Reihe von Artikeln zur Klassifizierung der Landbedeckung mithilfe der Eo-Learn-Bibliothek.  Wir erinnern Sie daran, dass der erste Artikel Folgendes demonstrierte: </p><br><ul><li>  Teilen von AOI (Area of ‚Äã‚ÄãInterest) in Fragmente namens EOPatch </li><li>  Empfangen von Bildern und Wolkenmasken von Sentinel-2-Satelliten </li><li>  Berechnung zus√§tzlicher Informationen wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NDWI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NDVI</a> </li><li>  Erstellen einer Referenzmaske und Hinzuf√ºgen zu den Quelldaten </li></ul><br><p>  Dar√ºber hinaus haben wir eine Oberfl√§chenstudie der Daten durchgef√ºhrt. Dies ist ein √§u√üerst wichtiger Schritt, bevor wir mit dem maschinellen Lernen beginnen.  Die obigen Aufgaben wurden durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Beispiel in Form eines Jupyter-Notizbuchs erg√§nzt</a> , das nun Material aus diesem Artikel enth√§lt. </p><br><p>  In diesem Artikel werden wir die Aufbereitung der Daten abschlie√üen und 2017 das erste Modell f√ºr die Erstellung von Landbedeckungskarten f√ºr Slowenien erstellen. </p><br><h2 id="podgotovka-dannyh">  Datenaufbereitung </h2><br><p>  Die Menge an Code, die sich direkt auf maschinelles Lernen bezieht, ist im Vergleich zum vollst√§ndigen Programm recht gering.  Der L√∂wenanteil der Aufgabe besteht darin, die Daten zu l√∂schen und die Daten so zu manipulieren, dass eine nahtlose Verwendung mit dem Klassifikator gew√§hrleistet ist.  Dieser Teil der Arbeit wird unten beschrieben. </p><br><p><img src="https://habrastorage.org/webt/gd/sj/4i/gdsj4iapqdgkldjwowfx-6p7bgg.jpeg"></p><br><p>  <em>Ein Pipeline-Diagramm f√ºr maschinelles Lernen, das zeigt, dass der Code selbst, der ML verwendet, einen kleinen Bruchteil des gesamten Prozesses ausmacht.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a></em> </p><br><h3 id="filtraciya-oblachnyh-izobrazheniy">  Cloud-Bildfilterung </h3><br><p>  Wolken sind Entit√§ten, die normalerweise auf einer Skala erscheinen, die unseren durchschnittlichen EOPatch √ºberschreitet (1000 x 1000 Pixel, Aufl√∂sung 10 m).  Dies bedeutet, dass jede Site an zuf√§lligen Daten vollst√§ndig von Wolken bedeckt sein kann.  Solche Bilder enthalten keine n√ºtzlichen Informationen und verbrauchen nur Ressourcen. Daher √ºberspringen wir sie basierend auf dem Verh√§ltnis der g√ºltigen Pixel zur Gesamtzahl und legen einen Schwellenwert fest.  Wir k√∂nnen alle Pixel als g√ºltig bezeichnen, die nicht als Wolken klassifiziert sind und sich in einem Satellitenbild befinden.  Beachten Sie auch, dass wir die mit den Sentinel-2-Bildern gelieferten Masken nicht verwenden, da sie auf der Ebene der Vollbilder berechnet werden (die Gr√∂√üe des vollst√§ndigen S2-Bilds betr√§gt 10980 √ó 10980 Pixel, ungef√§hr 110 √ó 110 km), was bedeutet, dass es f√ºr unseren AOI gr√∂√ütenteils nicht ben√∂tigt wird.  Um die Wolken zu bestimmen, verwenden wir den Algorithmus aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">s2cloudless-</a> Paket, um eine Maske aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wolkenpixeln</a> zu erhalten. </p><br><p>  In unserem Notizbuch ist der Schwellenwert auf 0,8 eingestellt, sodass wir nur Bilder ausw√§hlen, die zu 80% mit normalen Daten gef√ºllt sind.  Dies mag nach einem ziemlich hohen Wert klingen, aber da Wolken f√ºr unsere AOI kein allzu gro√ües Problem darstellen, k√∂nnen wir es uns leisten.  Es ist zu bedenken, dass dieser Ansatz nicht gedankenlos auf irgendeinen Punkt auf dem Planeten angewendet werden kann, da das von Ihnen ausgew√§hlte Gebiet f√ºr einen bedeutenden Teil des Jahres mit Wolken bedeckt sein kann. </p><br><h3 id="temporalnaya-interpolyaciya">  Zeitliche Interpolation </h3><br><p>  Aufgrund der Tatsache, dass Bilder an bestimmten Daten √ºbersprungen werden k√∂nnen, sowie aufgrund inkonsistenter AOI-Erfassungsdaten kommt es im Bereich der Erdbeobachtung h√§ufig zu Datenmangel.  Eine M√∂glichkeit, dieses Problem zu l√∂sen, besteht darin, eine Maske mit Pixelg√ºltigkeit (aus dem vorherigen Schritt) aufzuerlegen und die Werte zu interpolieren, um "L√∂cher zu f√ºllen".  Als Ergebnis des Interpolationsprozesses k√∂nnen fehlende Pixelwerte berechnet werden, um ein EOPatch zu erstellen, das Schnappsch√ºsse an gleichm√§√üig verteilten Tagen enth√§lt.  In diesem Beispiel haben wir die lineare Interpolation verwendet, es gibt jedoch auch andere Methoden, von denen einige bereits in eo-learn <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">implementiert</a> sind. </p><br><p><img src="https://habrastorage.org/webt/uf/va/ho/ufvahoeiz3u3shfdshioiuommlo.png"><br>  <em>Auf der linken Seite befindet sich ein Stapel von Sentinel-2-Bildern einer zuf√§llig ausgew√§hlten AOI.</em>  <em>Transparente Pixel bedeuten fehlende Daten aufgrund von Wolken.</em>  <em>Das Bild rechts zeigt den Stapel nach der Interpolation unter Ber√ºcksichtigung von Wolkenmasken.</em> </p><br><p>  Zeitliche Informationen sind √§u√üerst wichtig f√ºr die Klassifizierung der Deckung und noch wichtiger f√ºr die Identifizierung einer Keimkultur.  Dies alles ist auf die Tatsache zur√ºckzuf√ºhren, dass eine gro√üe Menge an Informationen √ºber die Landbedeckung darin verborgen ist, wie sich das Grundst√ºck im Laufe des Jahres √§ndert.  Wenn Sie beispielsweise die interpolierten NDVI-Werte anzeigen, k√∂nnen Sie feststellen, dass die Werte in den W√§ldern und Feldern im Fr√ºhjahr / Sommer ihre H√∂chstwerte erreichen und im Herbst / Winter stark abfallen, w√§hrend das Wasser und die k√ºnstlichen Oberfl√§chen diese Werte das ganze Jahr √ºber ungef√§hr konstant halten.  K√ºnstliche Oberfl√§chen haben im Vergleich zu Wasser etwas h√∂here NDVI-Werte und wiederholen teilweise die Entwicklung von W√§ldern und Feldern, da in St√§dten h√§ufig Parks und andere Vegetation zu finden sind.  Sie sollten auch die Einschr√§nkungen ber√ºcksichtigen, die mit der Aufl√∂sung von Bildern verbunden sind. Oft k√∂nnen Sie in dem von einem Pixel abgedeckten Bereich mehrere Arten der Abdeckung gleichzeitig beobachten. </p><br><p><img src="https://habrastorage.org/webt/cj/mx/8s/cjmx8sdns2mzfv5nq9hko7apno4.png"><br>  <em>Zeitliche Entwicklung der NDVI-Werte f√ºr Pixel aus bestimmten Arten der Landbedeckung im Laufe des Jahres</em> </p><br><h3 id="otricatelnaya-buferizaciya">  Negative Pufferung </h3><br><p>  Obwohl eine Bildaufl√∂sung von 10 m f√ºr eine Vielzahl von Aufgaben ausreicht, sind die Nebenwirkungen kleiner Objekte erheblich.  Solche Objekte befinden sich an der Grenze zwischen verschiedenen Deckungstypen, und diesen Pixeln werden nur die Werte eines der Typen zugewiesen.  Aus diesem Grund ist beim Training des Klassifikators ein √ºberm√§√üiges Rauschen in den Eingabedaten vorhanden, was das Ergebnis verschlechtert.  Au√üerdem sind Stra√üen und andere Objekte mit einer Breite von 1 Pixel auf der Originalkarte vorhanden, obwohl sie anhand der Bilder √§u√üerst schwer zu identifizieren sind.  Wir wenden eine negative 1-Pixel-Pufferung auf die Referenzkarte an und entfernen fast alle Problembereiche aus der Eingabe. </p><br><p><img src="https://habrastorage.org/webt/-m/u4/ep/-mu4epr9om3nqrmfdeoedefadqi.png"><br>  <em>AOI-Referenzkarte vor (links) und nach (rechts) negativer Pufferung</em> </p><br><h3 id="sluchaynyy-vybor-dannyh">  Zuf√§llige Datenauswahl </h3><br><p>  Wie in einem fr√ºheren Artikel erw√§hnt, ist der gesamte AOI in ungef√§hr 300 Fragmente unterteilt, von denen jedes aus ~ 1 Million Pixel besteht.  Dies ist eine ziemlich beeindruckende Menge dieser Pixel. Daher ben√∂tigen wir f√ºr jedes EOPatch gleichm√§√üig etwa 40.000 Pixel, um einen Datensatz von 12 Millionen Kopien zu erhalten.  Da die Pixel gleichm√§√üig aufgenommen werden, spielt eine gro√üe Anzahl auf der Referenzkarte keine Rolle, da diese Daten unbekannt sind (oder nach dem vorherigen Schritt verloren gegangen sind).  Es ist sinnvoll, solche Daten herauszufiltern, um das Training des Klassifikators zu vereinfachen, da wir ihm nicht beibringen m√ºssen, das Etikett ‚ÄûKeine Daten‚Äú zu definieren.  Das gleiche Verfahren wird f√ºr den Testsatz wiederholt, da solche Daten die Qualit√§tsindikatoren von Klassifikatorvorhersagen k√ºnstlich verschlechtern. </p><br><h3 id="razdelenie-i-formirovanie-dannyh">  Datentrennung und -generierung </h3><br><p> Wir haben die Eingabedaten in Trainings- / Tests√§tze mit einem Verh√§ltnis von 80/20% auf EOPatch-Ebene unterteilt, was uns garantiert, dass sich diese S√§tze nicht √ºberschneiden.  Auf die gleiche Weise teilen wir auch die Pixel aus dem Satz f√ºr das Training in S√§tze f√ºr das Testen und die Kreuzvalidierung auf.  Nach der Trennung erhalten wir ein <code>numpy.ndarray</code> Array mit Dimensionen <code>(p,t,w,h,d)</code> , wobei: <br>  <em><code>p</code> ist die Anzahl der <code>EOPatch</code> im Datensatz</em> <em><br></em>  <code>t</code> - die Anzahl der interpolierten Bilder f√ºr jedes EOPatch <br>  * <code>w, h, d</code> - Breite, H√∂he und Anzahl der Ebenen in den Bildern. </p><br><p>  Nach Auswahl der Teilmengen entspricht die Breite <code>w</code> der Anzahl der ausgew√§hlten Pixel (z. B. 40.000), w√§hrend die Dimension <code>h</code> betr√§gt. Der Unterschied in der Form des Arrays √§ndert nichts. Dieses Verfahren ist nur erforderlich, um die Arbeit mit Bildern zu vereinfachen. </p><br><p>  Die Daten von den Sensoren und der Maske <code>d</code> in einem beliebigen Bild t bestimmen die Eingabedaten f√ºr das Training, wobei solche F√§lle insgesamt <code>p*w*h</code> .  Um die Daten in ein f√ºr den Klassifizierer verdauliches Formular zu konvertieren, m√ºssen wir die Dimension des Arrays von 5 auf die Matrix des Formulars <code>(p*w*h, d*t)</code> reduzieren.  Dies ist mit dem folgenden Code einfach zu bewerkstelligen: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np p, t, w, h, d = features_array.shape <span class="hljs-comment"><span class="hljs-comment">#   t axis   1   3 features_array = np.moveaxis(features_array, 1, 3) #    features_array = features_array.reshape(p*w*h, t*d)</span></span></code> </pre> <br><p>  Ein solches Verfahren erm√∂glicht es, neue Daten derselben Form vorherzusagen, sie dann zur√ºck zu konvertieren und mit Standardmitteln zu visualisieren. </p><br><h3 id="sozdanie-modeli-dlya-mashinnogo-obucheniya">  Erstellen eines maschinellen Lernmodells </h3><br><p>  Die optimale Auswahl des Klassifikators h√§ngt stark von der spezifischen Aufgabe ab, und selbst bei der richtigen Wahl sollten wir die Parameter eines bestimmten Modells nicht vergessen, die von Aufgabe zu Aufgabe ge√§ndert werden m√ºssen.  In der Regel m√ºssen viele Experimente mit unterschiedlichen Parameters√§tzen durchgef√ºhrt werden, um genau zu sagen, was in einer bestimmten Situation erforderlich ist. </p><br><p>  In dieser Artikelserie verwenden wir das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LightGBM-</a> Paket, da es ein intuitives, schnelles, verteiltes und produktives Framework zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von</a> Modellen ist, die auf Entscheidungsb√§umen basieren.  Zur Auswahl von Klassifikator-Hyperparametern k√∂nnen verschiedene Ans√§tze verwendet werden, z. B. die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rastersuche</a> , die an einem Testsatz getestet werden sollte.  Der Einfachheit halber √ºberspringen wir diesen Schritt und verwenden die Standardparameter. </p><br><p><img src="https://habrastorage.org/webt/ik/ds/gr/ikdsgrz5mfdrifwakch1pvv1wey.png"><br>  <em>Das Arbeitsschema von Entscheidungsb√§umen in LightGBM.</em>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> </p><br><p>  Die Implementierung des Modells ist recht einfach. Da die Daten bereits in Form einer Matrix vorliegen, geben wir diese Daten einfach an die Eingabe des Modells weiter und warten.  Gl√ºckwunsch!  Jetzt k√∂nnen Sie jedem sagen, dass Sie sich mit maschinellem Lernen besch√§ftigen und der modischste Typ auf einer Party sein werden, w√§hrend Ihre Mutter wegen der Rebellion von Robotern und dem Tod der Menschheit nerv√∂s sein wird. </p><br><h2 id="validaciya-modeli">  Modellvalidierung </h2><br><p>  Trainingsmodelle f√ºr maschinelles Lernen sind einfach.  Die Schwierigkeit besteht darin, sie <strong>gut</strong> zu trainieren.  Daf√ºr ben√∂tigen wir einen geeigneten Algorithmus, eine zuverl√§ssige Referenzkarte und eine ausreichende Menge an Rechenressourcen.  Aber selbst in diesem Fall sind die Ergebnisse m√∂glicherweise nicht das, was Sie wollten. Daher ist es unbedingt erforderlich, den Klassifikator mit Fehlermatrizen und anderen Metriken zu √ºberpr√ºfen, um zumindest ein gewisses Vertrauen in die Ergebnisse Ihrer Arbeit zu haben. </p><br><h3 id="matrica-oshibok">  Fehlermatrix </h3><br><p>  Fehlermatrizen sind die ersten Dinge, die bei der Bewertung der Qualit√§t von Klassifizierern ber√ºcksichtigt werden m√ºssen.  Sie zeigen die Anzahl der korrekt und falsch vorhergesagten Tags f√ºr jedes Tag auf der Referenzkarte und umgekehrt.  Normalerweise wird eine normalisierte Matrix verwendet, bei der alle Werte in den Zeilen durch den Gesamtbetrag geteilt werden.  Dies zeigt, ob der Klassifikator keine Tendenz zu einer bestimmten Art von Deckung im Verh√§ltnis zu einer anderen hat </p><br><p><img src="https://habrastorage.org/webt/rg/3m/xd/rg3mxdktoqpvxy76j_jvfkgpzw4.png"><br>  <em>Zwei normalisierte Fehlermatrizen des trainierten Modells.</em> </p><br><p>  F√ºr die meisten Klassen zeigt das Modell gute Ergebnisse.  Bei einigen Klassen treten Fehler aufgrund eines Ungleichgewichts in den Eingabedaten auf.  Wir sehen, dass das Problem beispielsweise B√ºsche und Wasser sind, bei denen das Modell Pixelbeschriftungen h√§ufig verwechselt und falsch identifiziert.  Andererseits korreliert das, was als Busch oder Wasser markiert ist, recht gut mit der Referenzkarte.  Aus dem folgenden Bild k√∂nnen wir ersehen, dass Probleme f√ºr Klassen mit einer geringen Anzahl von Trainingsinstanzen auftreten - dies ist haupts√§chlich auf die geringe Datenmenge in unserem Beispiel zur√ºckzuf√ºhren, aber dieses Problem kann bei jeder realen Aufgabe auftreten. </p><br><p><img src="https://habrastorage.org/webt/4f/8l/qz/4f8lqz3q4xyxjyp3xp3e9usb_qg.png"></p><br><p>  <em>Die H√§ufigkeit des Auftretens von Pixeln jeder Klasse im Trainingssatz.</em> </p><br><h3 id="reciever-operating-characteristic---roc-krivaya">  Betriebscharakteristik des Empf√§ngers - ROC-Kurve </h3><br><p>  Klassifizierer sagen Etiketten mit einer bestimmten Sicherheit voraus, aber dieser Schwellenwert f√ºr ein bestimmtes Etikett kann ge√§ndert werden.  Die ROC-Kurve zeigt die F√§higkeit des Klassifikators, beim √Ñndern der Empfindlichkeitsschwelle korrekte Vorhersagen zu treffen.  Normalerweise wird dieser Graph f√ºr <strong>bin√§re</strong> Systeme verwendet, aber er kann in unserem Fall verwendet werden, wenn wir f√ºr jede Klasse das Merkmal ‚ÄûLabel gegen alle anderen‚Äú berechnen.  Die x-Achse zeigt falsch positive Ergebnisse (wir m√ºssen ihre Anzahl minimieren) und die y-Achse zeigt wahr-positive Ergebnisse (wir m√ºssen ihre Anzahl erh√∂hen) bei verschiedenen Schwellenwerten.  Ein guter Klassifikator kann durch eine Kurve beschrieben werden, unter der die Fl√§che der Kurve maximal ist.  Dieser Indikator wird auch als Fl√§che unter der Kurve (AUC) bezeichnet.  Aus den Diagrammen der ROC-Kurven kann man die gleichen Schlussfolgerungen √ºber eine unzureichende Anzahl von Beispielen der ‚ÄûBusch‚Äú -Klasse ziehen, obwohl die Kurve f√ºr Wasser viel besser aussieht - dies liegt an der Tatsache, dass sich das Wasser optisch stark von anderen Klassen unterscheidet, selbst wenn die Anzahl der Beispiele in den Daten nicht ausreicht. </p><br><p><img src="https://habrastorage.org/webt/v2/b5/_c/v2b5_cp7omqsxgg9v-bqaqmlk8u.png"><br>  <em>ROC-Kurven des Klassifikators in Form von "Eins gegen Alle" f√ºr jede Klasse.</em>  <em>Zahlen in Klammern sind AUC-Werte.</em> </p><br><h3 id="vazhnost-priznakov">  Die Bedeutung der Symptome </h3><br><p>  Wenn Sie sich eingehender mit den Feinheiten des Klassifikators befassen m√∂chten, k√∂nnen Sie sich das Feature-Wichtigkeitsdiagramm ansehen, in dem angegeben ist, welche der Zeichen das Endergebnis st√§rker beeinflusst haben.  Einige Algorithmen f√ºr maschinelles Lernen, wie der in diesem Artikel verwendete, geben diese Werte zur√ºck.  Bei anderen Modellen muss diese Metrik von uns selbst ber√ºcksichtigt werden. </p><br><p><img src="https://habrastorage.org/webt/x9/ui/d6/x9uid68f7bbim-g4nfusppu9cuu.png"><br>  <em>Die Matrix der Wichtigkeit von Merkmalen f√ºr den Klassifikator aus dem Beispiel</em> </p><br><p>  Obwohl andere Zeichen im Fr√ºhjahr (NDVI) im Allgemeinen wichtiger sind, sehen wir, dass es ein genaues Datum gibt, an dem eines der Zeichen (B2 - blau) das wichtigste ist.  Wenn Sie sich die Bilder ansehen, stellt sich heraus, dass der AOI in dieser Zeit mit Schnee bedeckt war.  Es kann gefolgert werden, dass Schnee Informationen √ºber die darunter liegende Abdeckung preisgibt, was dem Klassifizierer bei der Bestimmung der Art der Oberfl√§che sehr hilft.  Es sei daran erinnert, dass ein solches Ph√§nomen spezifisch f√ºr den beobachteten AOI ist und im Allgemeinen nicht als verl√§sslich angesehen werden kann. </p><br><p><img src="https://habrastorage.org/webt/qv/h1/ak/qvh1ak0bil0qhgt0ax77j0vl1dc.png"><br>  <em>Schneebedecktes 3x3 EOPatch AOI Teil</em> </p><br><h2 id="rezultaty-predskazaniy">  Vorhersageergebnisse </h2><br><p>  Nach der Validierung verstehen wir die St√§rken und Schw√§chen unseres Modells besser.  Wenn wir mit dem aktuellen Stand der Dinge nicht zufrieden sind, k√∂nnen Sie √Ñnderungen an der Pipeline vornehmen und es erneut versuchen.  Nach der Optimierung des Modells definieren wir eine einfache EOTask, die EOPatch und das Klassifikatormodell akzeptiert, eine Vorhersage erstellt und auf das Fragment anwendet. </p><br><p><img src="https://habrastorage.org/webt/bn/d4/8u/bnd48uzm8dp75_2rjgba0enxwlg.png"><br>  <em>Bild von Sentinel-2 (links), Wahrheit (Mitte) und Vorhersage (rechts) f√ºr ein zuf√§lliges Fragment von AOI.</em>  <em>M√∂glicherweise stellen Sie einige Unterschiede in den Bildern fest, die durch die Verwendung einer negativen Pufferung auf der Originalkarte erkl√§rt werden k√∂nnen.</em>  <em>Im Allgemeinen ist das Ergebnis f√ºr dieses Beispiel zufriedenstellend.</em> </p><br><p>  Der weitere Weg ist frei.  Der Vorgang muss f√ºr alle Fragmente wiederholt werden.  Sie k√∂nnen sie sogar im GeoTIFF-Format exportieren und mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gdal_merge.py kleben</a> . </p><br><p>  Wir haben geklebtes GeoTIFF in unser GeoPedia-Portal hochgeladen. Die Ergebnisse finden Sie hier im Detail </p><br><p><img src="https://habrastorage.org/webt/mw/gu/jo/mwgujo8q9zai7myheycgaomcwni.png"><br>  <em>Screenshot der Vorhersage der Landbedeckung Slowenien 2017 unter Verwendung des Ansatzes aus diesem Beitrag.</em>  <em>Verf√ºgbar in einem interaktiven Format unter dem obigen Link</em> </p><br><p>  Sie k√∂nnen auch offizielle Daten mit dem Ergebnis des Klassifikators vergleichen.  Achten Sie auf den Unterschied zwischen den Konzepten der <em>Landnutzung</em> und <em>der Landbedeckung</em> , der h√§ufig bei maschinellen Lernaufgaben auftritt. Es ist nicht immer einfach, Daten aus offiziellen Registern Klassen in der Natur zuzuordnen.  Als Beispiel zeigen wir zwei Flugh√§fen in Slowenien.  Der erste ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Levets in der N√§he der Stadt Celje</a> .  Dieser Flughafen ist klein, wird haupts√§chlich f√ºr Privatjets genutzt und ist mit Gras bedeckt.  Offiziell ist das Gebiet als k√ºnstliche Oberfl√§che gekennzeichnet, obwohl der Klassifizierer das Gebiet korrekt als Gras identifizieren kann (siehe unten). </p><br><p><img src="https://habrastorage.org/webt/bj/ps/vo/bjpsvoabp90ud12fouuyg1dza3y.png"><br>  <em>Bild von Sentinel-2 (links), wahr (Mitte) und Vorhersage (rechts) f√ºr das Gebiet um den kleinen Sportflughafen.</em>  <em>Der Klassifikator definiert die Landebahn als Gras, obwohl sie in den vorliegenden Daten als k√ºnstliche Oberfl√§che markiert ist.</em> </p><br><p>  Auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gr√∂√üten Flughafen Sloweniens, Ljubljana</a> , sind Zonen, die auf der Karte als k√ºnstliche Oberfl√§che markiert sind, Stra√üen.  In diesem Fall unterscheidet der Klassifikator zwischen Strukturen, w√§hrend Gras und Felder im Nachbargebiet korrekt unterschieden werden. </p><br><p><img src="https://habrastorage.org/webt/bs/oa/c-/bsoac-m7f9jdus4nqh7gl0v8ij0.png"><br>  <em>Bild von Sentinel-2 (links), Wahrheit (Mitte) und Vorhersage (rechts) f√ºr das Gebiet um Ljubljana.</em>  <em>Der Klassifikator bestimmt die Landebahn und die Stra√üen und unterscheidet Gras und Felder in der Nachbarschaft korrekt</em> </p><br><p>  Voila! </p><br><p>  Jetzt wissen Sie, wie Sie ein zuverl√§ssiges Modell auf nationaler Ebene erstellen k√∂nnen!  Denken Sie daran, dies Ihrem Lebenslauf hinzuzuf√ºgen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de452378/">https://habr.com/ru/post/de452378/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de452366/index.html">Neuer CMOS-Sensor verbessert die Funktionen f√ºr bewegliche Objekte</a></li>
<li><a href="../de452368/index.html">F√ºnfzehn n√ºtzliche Kleinigkeiten f√ºr die elektronische Dokumentenverwaltung</a></li>
<li><a href="../de452370/index.html">Wie ein 3D-Drucker einem Teenager mit Bombenschlag half, eine neue Hand zu bekommen</a></li>
<li><a href="../de452372/index.html">Jetzt werden gute Entwickler an Ansichten und Abonnenten gemessen. Ist es schlecht</a></li>
<li><a href="../de452376/index.html">Die Magie der Zahlen in Dezimalzahlen</a></li>
<li><a href="../de452382/index.html">Nachrichten der Woche: Autonomous Runet Control Center, 8000 US-Dollar Bitcoin, Sicherheitsl√ºcke in Intel-Prozessoren</a></li>
<li><a href="../de452384/index.html">Der Prozessor beschleunigt die Optik auf 800 Gbit / s: wie es funktioniert</a></li>
<li><a href="../de452388/index.html">Sieb von Eratosthenes jenseits von O (n). Beweis</a></li>
<li><a href="../de452390/index.html">Software Defined Radio - wie funktioniert es? Teil 3</a></li>
<li><a href="../de452392/index.html">Eine Auswahl von Datens√§tzen f√ºr maschinelles Lernen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
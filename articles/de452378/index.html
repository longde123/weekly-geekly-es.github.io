<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⏳ 🦆 🧗🏼 Klassifizierung der Landbedeckung mittels Eo-Learn. Teil 2 🙎🏻 🍪 🏴</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Teil 1 
 Teil 3 


 Wechseln von Daten zu Ergebnissen, ohne Ihren Computer zu verlassen 



 Ein Stapel von Bildern einer kleinen Zone in Slowenien un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Klassifizierung der Landbedeckung mittels Eo-Learn. Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452378/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 3</a> </p><br><p>  Wechseln von Daten zu Ergebnissen, ohne Ihren Computer zu verlassen </p><br><p><img src="https://habrastorage.org/webt/hq/kv/ie/hqkviehem-itsqlacwosv2hjdco.png"><br>  <em>Ein Stapel von Bildern einer kleinen Zone in Slowenien und eine Karte mit einer klassifizierten Landbedeckung, die mit den im Artikel beschriebenen Methoden erhalten wurde.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Vorwort </h2><br><p>  Der zweite Teil einer Reihe von Artikeln zur Klassifizierung der Landbedeckung mithilfe der Eo-Learn-Bibliothek.  Wir erinnern Sie daran, dass der erste Artikel Folgendes demonstrierte: </p><br><ul><li>  Teilen von AOI (Area of ​​Interest) in Fragmente namens EOPatch </li><li>  Empfangen von Bildern und Wolkenmasken von Sentinel-2-Satelliten </li><li>  Berechnung zusätzlicher Informationen wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NDWI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NDVI</a> </li><li>  Erstellen einer Referenzmaske und Hinzufügen zu den Quelldaten </li></ul><br><p>  Darüber hinaus haben wir eine Oberflächenstudie der Daten durchgeführt. Dies ist ein äußerst wichtiger Schritt, bevor wir mit dem maschinellen Lernen beginnen.  Die obigen Aufgaben wurden durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Beispiel in Form eines Jupyter-Notizbuchs ergänzt</a> , das nun Material aus diesem Artikel enthält. </p><br><p>  In diesem Artikel werden wir die Aufbereitung der Daten abschließen und 2017 das erste Modell für die Erstellung von Landbedeckungskarten für Slowenien erstellen. </p><br><h2 id="podgotovka-dannyh">  Datenaufbereitung </h2><br><p>  Die Menge an Code, die sich direkt auf maschinelles Lernen bezieht, ist im Vergleich zum vollständigen Programm recht gering.  Der Löwenanteil der Aufgabe besteht darin, die Daten zu löschen und die Daten so zu manipulieren, dass eine nahtlose Verwendung mit dem Klassifikator gewährleistet ist.  Dieser Teil der Arbeit wird unten beschrieben. </p><br><p><img src="https://habrastorage.org/webt/gd/sj/4i/gdsj4iapqdgkldjwowfx-6p7bgg.jpeg"></p><br><p>  <em>Ein Pipeline-Diagramm für maschinelles Lernen, das zeigt, dass der Code selbst, der ML verwendet, einen kleinen Bruchteil des gesamten Prozesses ausmacht.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a></em> </p><br><h3 id="filtraciya-oblachnyh-izobrazheniy">  Cloud-Bildfilterung </h3><br><p>  Wolken sind Entitäten, die normalerweise auf einer Skala erscheinen, die unseren durchschnittlichen EOPatch überschreitet (1000 x 1000 Pixel, Auflösung 10 m).  Dies bedeutet, dass jede Site an zufälligen Daten vollständig von Wolken bedeckt sein kann.  Solche Bilder enthalten keine nützlichen Informationen und verbrauchen nur Ressourcen. Daher überspringen wir sie basierend auf dem Verhältnis der gültigen Pixel zur Gesamtzahl und legen einen Schwellenwert fest.  Wir können alle Pixel als gültig bezeichnen, die nicht als Wolken klassifiziert sind und sich in einem Satellitenbild befinden.  Beachten Sie auch, dass wir die mit den Sentinel-2-Bildern gelieferten Masken nicht verwenden, da sie auf der Ebene der Vollbilder berechnet werden (die Größe des vollständigen S2-Bilds beträgt 10980 × 10980 Pixel, ungefähr 110 × 110 km), was bedeutet, dass es für unseren AOI größtenteils nicht benötigt wird.  Um die Wolken zu bestimmen, verwenden wir den Algorithmus aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">s2cloudless-</a> Paket, um eine Maske aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wolkenpixeln</a> zu erhalten. </p><br><p>  In unserem Notizbuch ist der Schwellenwert auf 0,8 eingestellt, sodass wir nur Bilder auswählen, die zu 80% mit normalen Daten gefüllt sind.  Dies mag nach einem ziemlich hohen Wert klingen, aber da Wolken für unsere AOI kein allzu großes Problem darstellen, können wir es uns leisten.  Es ist zu bedenken, dass dieser Ansatz nicht gedankenlos auf irgendeinen Punkt auf dem Planeten angewendet werden kann, da das von Ihnen ausgewählte Gebiet für einen bedeutenden Teil des Jahres mit Wolken bedeckt sein kann. </p><br><h3 id="temporalnaya-interpolyaciya">  Zeitliche Interpolation </h3><br><p>  Aufgrund der Tatsache, dass Bilder an bestimmten Daten übersprungen werden können, sowie aufgrund inkonsistenter AOI-Erfassungsdaten kommt es im Bereich der Erdbeobachtung häufig zu Datenmangel.  Eine Möglichkeit, dieses Problem zu lösen, besteht darin, eine Maske mit Pixelgültigkeit (aus dem vorherigen Schritt) aufzuerlegen und die Werte zu interpolieren, um "Löcher zu füllen".  Als Ergebnis des Interpolationsprozesses können fehlende Pixelwerte berechnet werden, um ein EOPatch zu erstellen, das Schnappschüsse an gleichmäßig verteilten Tagen enthält.  In diesem Beispiel haben wir die lineare Interpolation verwendet, es gibt jedoch auch andere Methoden, von denen einige bereits in eo-learn <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">implementiert</a> sind. </p><br><p><img src="https://habrastorage.org/webt/uf/va/ho/ufvahoeiz3u3shfdshioiuommlo.png"><br>  <em>Auf der linken Seite befindet sich ein Stapel von Sentinel-2-Bildern einer zufällig ausgewählten AOI.</em>  <em>Transparente Pixel bedeuten fehlende Daten aufgrund von Wolken.</em>  <em>Das Bild rechts zeigt den Stapel nach der Interpolation unter Berücksichtigung von Wolkenmasken.</em> </p><br><p>  Zeitliche Informationen sind äußerst wichtig für die Klassifizierung der Deckung und noch wichtiger für die Identifizierung einer Keimkultur.  Dies alles ist auf die Tatsache zurückzuführen, dass eine große Menge an Informationen über die Landbedeckung darin verborgen ist, wie sich das Grundstück im Laufe des Jahres ändert.  Wenn Sie beispielsweise die interpolierten NDVI-Werte anzeigen, können Sie feststellen, dass die Werte in den Wäldern und Feldern im Frühjahr / Sommer ihre Höchstwerte erreichen und im Herbst / Winter stark abfallen, während das Wasser und die künstlichen Oberflächen diese Werte das ganze Jahr über ungefähr konstant halten.  Künstliche Oberflächen haben im Vergleich zu Wasser etwas höhere NDVI-Werte und wiederholen teilweise die Entwicklung von Wäldern und Feldern, da in Städten häufig Parks und andere Vegetation zu finden sind.  Sie sollten auch die Einschränkungen berücksichtigen, die mit der Auflösung von Bildern verbunden sind. Oft können Sie in dem von einem Pixel abgedeckten Bereich mehrere Arten der Abdeckung gleichzeitig beobachten. </p><br><p><img src="https://habrastorage.org/webt/cj/mx/8s/cjmx8sdns2mzfv5nq9hko7apno4.png"><br>  <em>Zeitliche Entwicklung der NDVI-Werte für Pixel aus bestimmten Arten der Landbedeckung im Laufe des Jahres</em> </p><br><h3 id="otricatelnaya-buferizaciya">  Negative Pufferung </h3><br><p>  Obwohl eine Bildauflösung von 10 m für eine Vielzahl von Aufgaben ausreicht, sind die Nebenwirkungen kleiner Objekte erheblich.  Solche Objekte befinden sich an der Grenze zwischen verschiedenen Deckungstypen, und diesen Pixeln werden nur die Werte eines der Typen zugewiesen.  Aus diesem Grund ist beim Training des Klassifikators ein übermäßiges Rauschen in den Eingabedaten vorhanden, was das Ergebnis verschlechtert.  Außerdem sind Straßen und andere Objekte mit einer Breite von 1 Pixel auf der Originalkarte vorhanden, obwohl sie anhand der Bilder äußerst schwer zu identifizieren sind.  Wir wenden eine negative 1-Pixel-Pufferung auf die Referenzkarte an und entfernen fast alle Problembereiche aus der Eingabe. </p><br><p><img src="https://habrastorage.org/webt/-m/u4/ep/-mu4epr9om3nqrmfdeoedefadqi.png"><br>  <em>AOI-Referenzkarte vor (links) und nach (rechts) negativer Pufferung</em> </p><br><h3 id="sluchaynyy-vybor-dannyh">  Zufällige Datenauswahl </h3><br><p>  Wie in einem früheren Artikel erwähnt, ist der gesamte AOI in ungefähr 300 Fragmente unterteilt, von denen jedes aus ~ 1 Million Pixel besteht.  Dies ist eine ziemlich beeindruckende Menge dieser Pixel. Daher benötigen wir für jedes EOPatch gleichmäßig etwa 40.000 Pixel, um einen Datensatz von 12 Millionen Kopien zu erhalten.  Da die Pixel gleichmäßig aufgenommen werden, spielt eine große Anzahl auf der Referenzkarte keine Rolle, da diese Daten unbekannt sind (oder nach dem vorherigen Schritt verloren gegangen sind).  Es ist sinnvoll, solche Daten herauszufiltern, um das Training des Klassifikators zu vereinfachen, da wir ihm nicht beibringen müssen, das Etikett „Keine Daten“ zu definieren.  Das gleiche Verfahren wird für den Testsatz wiederholt, da solche Daten die Qualitätsindikatoren von Klassifikatorvorhersagen künstlich verschlechtern. </p><br><h3 id="razdelenie-i-formirovanie-dannyh">  Datentrennung und -generierung </h3><br><p> Wir haben die Eingabedaten in Trainings- / Testsätze mit einem Verhältnis von 80/20% auf EOPatch-Ebene unterteilt, was uns garantiert, dass sich diese Sätze nicht überschneiden.  Auf die gleiche Weise teilen wir auch die Pixel aus dem Satz für das Training in Sätze für das Testen und die Kreuzvalidierung auf.  Nach der Trennung erhalten wir ein <code>numpy.ndarray</code> Array mit Dimensionen <code>(p,t,w,h,d)</code> , wobei: <br>  <em><code>p</code> ist die Anzahl der <code>EOPatch</code> im Datensatz</em> <em><br></em>  <code>t</code> - die Anzahl der interpolierten Bilder für jedes EOPatch <br>  * <code>w, h, d</code> - Breite, Höhe und Anzahl der Ebenen in den Bildern. </p><br><p>  Nach Auswahl der Teilmengen entspricht die Breite <code>w</code> der Anzahl der ausgewählten Pixel (z. B. 40.000), während die Dimension <code>h</code> beträgt. Der Unterschied in der Form des Arrays ändert nichts. Dieses Verfahren ist nur erforderlich, um die Arbeit mit Bildern zu vereinfachen. </p><br><p>  Die Daten von den Sensoren und der Maske <code>d</code> in einem beliebigen Bild t bestimmen die Eingabedaten für das Training, wobei solche Fälle insgesamt <code>p*w*h</code> .  Um die Daten in ein für den Klassifizierer verdauliches Formular zu konvertieren, müssen wir die Dimension des Arrays von 5 auf die Matrix des Formulars <code>(p*w*h, d*t)</code> reduzieren.  Dies ist mit dem folgenden Code einfach zu bewerkstelligen: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np p, t, w, h, d = features_array.shape <span class="hljs-comment"><span class="hljs-comment">#   t axis   1   3 features_array = np.moveaxis(features_array, 1, 3) #    features_array = features_array.reshape(p*w*h, t*d)</span></span></code> </pre> <br><p>  Ein solches Verfahren ermöglicht es, neue Daten derselben Form vorherzusagen, sie dann zurück zu konvertieren und mit Standardmitteln zu visualisieren. </p><br><h3 id="sozdanie-modeli-dlya-mashinnogo-obucheniya">  Erstellen eines maschinellen Lernmodells </h3><br><p>  Die optimale Auswahl des Klassifikators hängt stark von der spezifischen Aufgabe ab, und selbst bei der richtigen Wahl sollten wir die Parameter eines bestimmten Modells nicht vergessen, die von Aufgabe zu Aufgabe geändert werden müssen.  In der Regel müssen viele Experimente mit unterschiedlichen Parametersätzen durchgeführt werden, um genau zu sagen, was in einer bestimmten Situation erforderlich ist. </p><br><p>  In dieser Artikelserie verwenden wir das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LightGBM-</a> Paket, da es ein intuitives, schnelles, verteiltes und produktives Framework zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von</a> Modellen ist, die auf Entscheidungsbäumen basieren.  Zur Auswahl von Klassifikator-Hyperparametern können verschiedene Ansätze verwendet werden, z. B. die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rastersuche</a> , die an einem Testsatz getestet werden sollte.  Der Einfachheit halber überspringen wir diesen Schritt und verwenden die Standardparameter. </p><br><p><img src="https://habrastorage.org/webt/ik/ds/gr/ikdsgrz5mfdrifwakch1pvv1wey.png"><br>  <em>Das Arbeitsschema von Entscheidungsbäumen in LightGBM.</em>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> </p><br><p>  Die Implementierung des Modells ist recht einfach. Da die Daten bereits in Form einer Matrix vorliegen, geben wir diese Daten einfach an die Eingabe des Modells weiter und warten.  Glückwunsch!  Jetzt können Sie jedem sagen, dass Sie sich mit maschinellem Lernen beschäftigen und der modischste Typ auf einer Party sein werden, während Ihre Mutter wegen der Rebellion von Robotern und dem Tod der Menschheit nervös sein wird. </p><br><h2 id="validaciya-modeli">  Modellvalidierung </h2><br><p>  Trainingsmodelle für maschinelles Lernen sind einfach.  Die Schwierigkeit besteht darin, sie <strong>gut</strong> zu trainieren.  Dafür benötigen wir einen geeigneten Algorithmus, eine zuverlässige Referenzkarte und eine ausreichende Menge an Rechenressourcen.  Aber selbst in diesem Fall sind die Ergebnisse möglicherweise nicht das, was Sie wollten. Daher ist es unbedingt erforderlich, den Klassifikator mit Fehlermatrizen und anderen Metriken zu überprüfen, um zumindest ein gewisses Vertrauen in die Ergebnisse Ihrer Arbeit zu haben. </p><br><h3 id="matrica-oshibok">  Fehlermatrix </h3><br><p>  Fehlermatrizen sind die ersten Dinge, die bei der Bewertung der Qualität von Klassifizierern berücksichtigt werden müssen.  Sie zeigen die Anzahl der korrekt und falsch vorhergesagten Tags für jedes Tag auf der Referenzkarte und umgekehrt.  Normalerweise wird eine normalisierte Matrix verwendet, bei der alle Werte in den Zeilen durch den Gesamtbetrag geteilt werden.  Dies zeigt, ob der Klassifikator keine Tendenz zu einer bestimmten Art von Deckung im Verhältnis zu einer anderen hat </p><br><p><img src="https://habrastorage.org/webt/rg/3m/xd/rg3mxdktoqpvxy76j_jvfkgpzw4.png"><br>  <em>Zwei normalisierte Fehlermatrizen des trainierten Modells.</em> </p><br><p>  Für die meisten Klassen zeigt das Modell gute Ergebnisse.  Bei einigen Klassen treten Fehler aufgrund eines Ungleichgewichts in den Eingabedaten auf.  Wir sehen, dass das Problem beispielsweise Büsche und Wasser sind, bei denen das Modell Pixelbeschriftungen häufig verwechselt und falsch identifiziert.  Andererseits korreliert das, was als Busch oder Wasser markiert ist, recht gut mit der Referenzkarte.  Aus dem folgenden Bild können wir ersehen, dass Probleme für Klassen mit einer geringen Anzahl von Trainingsinstanzen auftreten - dies ist hauptsächlich auf die geringe Datenmenge in unserem Beispiel zurückzuführen, aber dieses Problem kann bei jeder realen Aufgabe auftreten. </p><br><p><img src="https://habrastorage.org/webt/4f/8l/qz/4f8lqz3q4xyxjyp3xp3e9usb_qg.png"></p><br><p>  <em>Die Häufigkeit des Auftretens von Pixeln jeder Klasse im Trainingssatz.</em> </p><br><h3 id="reciever-operating-characteristic---roc-krivaya">  Betriebscharakteristik des Empfängers - ROC-Kurve </h3><br><p>  Klassifizierer sagen Etiketten mit einer bestimmten Sicherheit voraus, aber dieser Schwellenwert für ein bestimmtes Etikett kann geändert werden.  Die ROC-Kurve zeigt die Fähigkeit des Klassifikators, beim Ändern der Empfindlichkeitsschwelle korrekte Vorhersagen zu treffen.  Normalerweise wird dieser Graph für <strong>binäre</strong> Systeme verwendet, aber er kann in unserem Fall verwendet werden, wenn wir für jede Klasse das Merkmal „Label gegen alle anderen“ berechnen.  Die x-Achse zeigt falsch positive Ergebnisse (wir müssen ihre Anzahl minimieren) und die y-Achse zeigt wahr-positive Ergebnisse (wir müssen ihre Anzahl erhöhen) bei verschiedenen Schwellenwerten.  Ein guter Klassifikator kann durch eine Kurve beschrieben werden, unter der die Fläche der Kurve maximal ist.  Dieser Indikator wird auch als Fläche unter der Kurve (AUC) bezeichnet.  Aus den Diagrammen der ROC-Kurven kann man die gleichen Schlussfolgerungen über eine unzureichende Anzahl von Beispielen der „Busch“ -Klasse ziehen, obwohl die Kurve für Wasser viel besser aussieht - dies liegt an der Tatsache, dass sich das Wasser optisch stark von anderen Klassen unterscheidet, selbst wenn die Anzahl der Beispiele in den Daten nicht ausreicht. </p><br><p><img src="https://habrastorage.org/webt/v2/b5/_c/v2b5_cp7omqsxgg9v-bqaqmlk8u.png"><br>  <em>ROC-Kurven des Klassifikators in Form von "Eins gegen Alle" für jede Klasse.</em>  <em>Zahlen in Klammern sind AUC-Werte.</em> </p><br><h3 id="vazhnost-priznakov">  Die Bedeutung der Symptome </h3><br><p>  Wenn Sie sich eingehender mit den Feinheiten des Klassifikators befassen möchten, können Sie sich das Feature-Wichtigkeitsdiagramm ansehen, in dem angegeben ist, welche der Zeichen das Endergebnis stärker beeinflusst haben.  Einige Algorithmen für maschinelles Lernen, wie der in diesem Artikel verwendete, geben diese Werte zurück.  Bei anderen Modellen muss diese Metrik von uns selbst berücksichtigt werden. </p><br><p><img src="https://habrastorage.org/webt/x9/ui/d6/x9uid68f7bbim-g4nfusppu9cuu.png"><br>  <em>Die Matrix der Wichtigkeit von Merkmalen für den Klassifikator aus dem Beispiel</em> </p><br><p>  Obwohl andere Zeichen im Frühjahr (NDVI) im Allgemeinen wichtiger sind, sehen wir, dass es ein genaues Datum gibt, an dem eines der Zeichen (B2 - blau) das wichtigste ist.  Wenn Sie sich die Bilder ansehen, stellt sich heraus, dass der AOI in dieser Zeit mit Schnee bedeckt war.  Es kann gefolgert werden, dass Schnee Informationen über die darunter liegende Abdeckung preisgibt, was dem Klassifizierer bei der Bestimmung der Art der Oberfläche sehr hilft.  Es sei daran erinnert, dass ein solches Phänomen spezifisch für den beobachteten AOI ist und im Allgemeinen nicht als verlässlich angesehen werden kann. </p><br><p><img src="https://habrastorage.org/webt/qv/h1/ak/qvh1ak0bil0qhgt0ax77j0vl1dc.png"><br>  <em>Schneebedecktes 3x3 EOPatch AOI Teil</em> </p><br><h2 id="rezultaty-predskazaniy">  Vorhersageergebnisse </h2><br><p>  Nach der Validierung verstehen wir die Stärken und Schwächen unseres Modells besser.  Wenn wir mit dem aktuellen Stand der Dinge nicht zufrieden sind, können Sie Änderungen an der Pipeline vornehmen und es erneut versuchen.  Nach der Optimierung des Modells definieren wir eine einfache EOTask, die EOPatch und das Klassifikatormodell akzeptiert, eine Vorhersage erstellt und auf das Fragment anwendet. </p><br><p><img src="https://habrastorage.org/webt/bn/d4/8u/bnd48uzm8dp75_2rjgba0enxwlg.png"><br>  <em>Bild von Sentinel-2 (links), Wahrheit (Mitte) und Vorhersage (rechts) für ein zufälliges Fragment von AOI.</em>  <em>Möglicherweise stellen Sie einige Unterschiede in den Bildern fest, die durch die Verwendung einer negativen Pufferung auf der Originalkarte erklärt werden können.</em>  <em>Im Allgemeinen ist das Ergebnis für dieses Beispiel zufriedenstellend.</em> </p><br><p>  Der weitere Weg ist frei.  Der Vorgang muss für alle Fragmente wiederholt werden.  Sie können sie sogar im GeoTIFF-Format exportieren und mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gdal_merge.py kleben</a> . </p><br><p>  Wir haben geklebtes GeoTIFF in unser GeoPedia-Portal hochgeladen. Die Ergebnisse finden Sie hier im Detail </p><br><p><img src="https://habrastorage.org/webt/mw/gu/jo/mwgujo8q9zai7myheycgaomcwni.png"><br>  <em>Screenshot der Vorhersage der Landbedeckung Slowenien 2017 unter Verwendung des Ansatzes aus diesem Beitrag.</em>  <em>Verfügbar in einem interaktiven Format unter dem obigen Link</em> </p><br><p>  Sie können auch offizielle Daten mit dem Ergebnis des Klassifikators vergleichen.  Achten Sie auf den Unterschied zwischen den Konzepten der <em>Landnutzung</em> und <em>der Landbedeckung</em> , der häufig bei maschinellen Lernaufgaben auftritt. Es ist nicht immer einfach, Daten aus offiziellen Registern Klassen in der Natur zuzuordnen.  Als Beispiel zeigen wir zwei Flughäfen in Slowenien.  Der erste ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Levets in der Nähe der Stadt Celje</a> .  Dieser Flughafen ist klein, wird hauptsächlich für Privatjets genutzt und ist mit Gras bedeckt.  Offiziell ist das Gebiet als künstliche Oberfläche gekennzeichnet, obwohl der Klassifizierer das Gebiet korrekt als Gras identifizieren kann (siehe unten). </p><br><p><img src="https://habrastorage.org/webt/bj/ps/vo/bjpsvoabp90ud12fouuyg1dza3y.png"><br>  <em>Bild von Sentinel-2 (links), wahr (Mitte) und Vorhersage (rechts) für das Gebiet um den kleinen Sportflughafen.</em>  <em>Der Klassifikator definiert die Landebahn als Gras, obwohl sie in den vorliegenden Daten als künstliche Oberfläche markiert ist.</em> </p><br><p>  Auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">größten Flughafen Sloweniens, Ljubljana</a> , sind Zonen, die auf der Karte als künstliche Oberfläche markiert sind, Straßen.  In diesem Fall unterscheidet der Klassifikator zwischen Strukturen, während Gras und Felder im Nachbargebiet korrekt unterschieden werden. </p><br><p><img src="https://habrastorage.org/webt/bs/oa/c-/bsoac-m7f9jdus4nqh7gl0v8ij0.png"><br>  <em>Bild von Sentinel-2 (links), Wahrheit (Mitte) und Vorhersage (rechts) für das Gebiet um Ljubljana.</em>  <em>Der Klassifikator bestimmt die Landebahn und die Straßen und unterscheidet Gras und Felder in der Nachbarschaft korrekt</em> </p><br><p>  Voila! </p><br><p>  Jetzt wissen Sie, wie Sie ein zuverlässiges Modell auf nationaler Ebene erstellen können!  Denken Sie daran, dies Ihrem Lebenslauf hinzuzufügen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de452378/">https://habr.com/ru/post/de452378/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de452366/index.html">Neuer CMOS-Sensor verbessert die Funktionen für bewegliche Objekte</a></li>
<li><a href="../de452368/index.html">Fünfzehn nützliche Kleinigkeiten für die elektronische Dokumentenverwaltung</a></li>
<li><a href="../de452370/index.html">Wie ein 3D-Drucker einem Teenager mit Bombenschlag half, eine neue Hand zu bekommen</a></li>
<li><a href="../de452372/index.html">Jetzt werden gute Entwickler an Ansichten und Abonnenten gemessen. Ist es schlecht</a></li>
<li><a href="../de452376/index.html">Die Magie der Zahlen in Dezimalzahlen</a></li>
<li><a href="../de452382/index.html">Nachrichten der Woche: Autonomous Runet Control Center, 8000 US-Dollar Bitcoin, Sicherheitslücke in Intel-Prozessoren</a></li>
<li><a href="../de452384/index.html">Der Prozessor beschleunigt die Optik auf 800 Gbit / s: wie es funktioniert</a></li>
<li><a href="../de452388/index.html">Sieb von Eratosthenes jenseits von O (n). Beweis</a></li>
<li><a href="../de452390/index.html">Software Defined Radio - wie funktioniert es? Teil 3</a></li>
<li><a href="../de452392/index.html">Eine Auswahl von Datensätzen für maschinelles Lernen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧓🏿 📜 📝 Mit Dex-Net 4.0 können Ambidextro-Roboter das Beste heraussuchen 🔮 🤕 🎅</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Möglichkeit, einen Griff zu wählen, hilft zweiarmigen Robotern, Objekte schneller als je zuvor aufzunehmen. 


 Seit einigen Jahren verfolgen wir ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mit Dex-Net 4.0 können Ambidextro-Roboter das Beste heraussuchen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438118/"><h3>  Die Möglichkeit, einen Griff zu wählen, hilft zweiarmigen Robotern, Objekte schneller als je zuvor aufzunehmen. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/b94/a52/853/b94a528531c30220fa11e83bdfb2178c.jpg"><br><br>  Seit einigen Jahren verfolgen wir den Fortschritt des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dex-Net-</a> Projekts, das versucht, einen universellen Griff für Roboter zu entwickeln. Mitte Januar wurde eine neue Arbeit in der Zeitschrift Science Robotics veröffentlicht, in der Wissenschaftler der University of California in Berkeley Dex-Net 4.0 vorstellen.  Die wichtigste und interessanteste Nachricht im Zusammenhang mit dieser Arbeit ist, dass die neueste Version von Dex-Net dank des zusätzlichen Ambidextry-Roboters, mit dem eines der Objekte ausgewählt werden kann, 95% der bisher unbekannten Objekte mit einer Geschwindigkeit von 300 Stück pro Stunde erfolgreich erfassen konnte zwei Arten von Aufnahmen. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/r-0PKne9e_w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Nehmen wir zum Vergleich an, dass eine Person solche Objekte doppelt so schnell anheben kann, von 400 auf 600 Stück pro Stunde.  Und ich würde sagen, dass man im Fall einer Person einen 100% igen Erfolg der Erfassung erwarten kann - oder zumindest eine gute Annäherung an diese Zahl, wenn dem Subjekt mehrere Versuche mit jedem der Objekte gestattet werden.  Deshalb haben wir eine sehr hohe Messlatte für Autos gesetzt.  Ein Teil unseres Erfolgs bei der Erfassung von Objekten (und unserer Fähigkeit, als Ganzes zu erfassen) ist unsere große Erfahrung in der Arbeit mit Objekten mit vielen Formen, Größen, Gewichten, mit der Reibung verschiedener Materialien und mit einer möglichen Verformung von Objekten während der Erfassung.  Ohne es zu merken, sind wir in der Lage, detaillierte Modelle von Objekten im Kopf zu erstellen, und sie helfen uns dabei, zuvor unsichtbare Objekte einfach zu greifen und anzuheben. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/391/1f2/0e2/3911f20e25fb01e231cb4d6b4758b501.jpg"><br><br>  Roboter haben jedoch keinen Zugang zu diesem experimentellen Modell der Welt.  Sie verlassen sich auf ein Training, das auf einer bestimmten Aufgabe basiert - und hier kommt Dex-Net ins Spiel.  Sie lernt, Dinge festzuhalten, Simulationen zu trainieren, Millionen von Modellen dreidimensionaler Objekte und ein bisschen Zufallsphysik zu verwenden, um Erfolge in Simulationen besser auf die reale Welt zu übertragen.  Künstliche Unsicherheit ermöglicht es dem System, mit Dingen wie Sensorrauschen und kleinen allmählichen Kalibrierungsverschiebungen zu arbeiten - natürlich könnten realistischere Ergebnisse durch das Training realer Roboter erzielt werden, aber dann würden solche Einschränkungen wie die Notwendigkeit, viele echte Roboter zu haben, in Kraft treten und diese geben Zeit zu arbeiten - und wer will auf sie warten? <br><br>  Die Einzigartigkeit von Dex-Net 4.0 liegt in der Tatsache, dass die Regeln für die Erfassung von Objekten "beidhändig" sind, dh der Roboter verfügt über zwei Erfassungen und entscheidet, welche derzeit verwendet werden soll.  Im Gegensatz zu ambidextralen Menschen hat dieser Roboter jedoch unterschiedliche Griffe an den Händen: eine Zwei-Finger-Klemme und einen Vakuumsauger.  Basierend auf einer vorläufigen Bewertung der Qualität der Erfassung wählt Dex-Net aus, welche der Erfassungen das Objekt zuverlässiger erfassen können.  Diese Technologie ermöglicht es, Objekte schnell und zuverlässig zu erfassen: ABB YuMi im obigen Video kann mit einer Effizienz von 95% etwa 300 bisher nicht sichtbare Objekte pro Stunde erfassen.  Mit Dex-Net können Sie andere Arten von Aufnahmen verbinden.  Nach zusätzlichem Training (und Hinzufügen von Captures zum Roboter können Sie ihm das Arbeiten mit elektrostatischen Griffen, Fünf-Finger-Händen, geckoartigen Griffen oder allem anderen beibringen. <br><br>  Natürlich ist es immer interessant, diese 5% der Fälle zu untersuchen, in denen der Roboter den Gegenstand nicht genommen hat, und hier einige Beispiele: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ef1/97d/171/ef197d1711be206d05d5e482f1a09b70.png"><br><br>  Das erste Foto zeigt „problematische“ Objekte, die aufgrund von „problematischer Geometrie, Transparenz, Spiegeloberfläche und Verformbarkeit“ besonders schwer zu heben sind.  Dex-Net verarbeitet solche Objekte nur in 63% der Fälle. Wenn Sie dem System jedoch erlauben, sich an frühere Fehler zu erinnern und das Motiv ein wenig zu verschieben, und die Unklarheit nicht klar ist, wie es erfasst werden soll, steigt die Zuverlässigkeit auf 80%. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/047/e52/a11/047e52a110fe958257093e508e8b430d.png"><br><br>  Das zweite Foto zeigt Objekte, die Dex-Net 4.0 aufgrund reflektierender Eigenschaften wie Transparenz, die die Wahrnehmung der Tiefe beeinflusst, und Materialeigenschaften wie Porosität und Duktilität (z. B. lose Verpackung) überhaupt nicht bewältigt. was die Fähigkeit beeinträchtigt, mit einem Saugnapf an der Oberfläche zu haften. "  Es ist erwähnenswert, dass der Zwei-Finger-Griff keine Kraftsensoren oder taktilen Sensoren enthält, sodass das System noch verbessert werden muss. <br><br>  Sie können auch Fälle berücksichtigen, in denen eine Effizienz, die nicht 100% erreicht, akzeptabel ist.  Es gibt viele realistische Möglichkeiten, um Fehler mit Greifern zu behandeln: Sie können den Roboter anweisen, alle Dinge aus dem Korb zu sammeln und den Rest an die Person zu senden, die mit komplexen Objekten fertig wird.  Oder vielleicht ist es irgendwann sinnvoll, die Verpackung von Objekten so zu ändern, dass es einfacher wird, Gegenstände aufzunehmen, die für die Robotererfassung besonders schwierig sind.  In jedem Fall handelt es sich eher um das „Wann“ als um das „Wenn“. Aufgrund der Attraktivität der Automatisierung der Lieferkette wird dieses „Wann“ wahrscheinlich sehr, sehr bald eintreten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438118/">https://habr.com/ru/post/de438118/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438106/index.html">Blinkt mit Vintage-LEDs oder warnt vor „Bränden“ im Projekt</a></li>
<li><a href="../de438108/index.html">SEO und Kontext: Was soll ich wählen und ob soll ich wählen?</a></li>
<li><a href="../de438110/index.html">Schienen + Postgres + Bindungen</a></li>
<li><a href="../de438112/index.html">Eine Silberkugel finden: Schauspieler + FRP in Reaktion</a></li>
<li><a href="../de438116/index.html">Umweltverträglichkeitsprüfung von Musikmedien: digitale Musik, analoge Aufnahmen und CDs</a></li>
<li><a href="../de438120/index.html">Die Zusammenfassung der Ereignisse für HR-Experten im Bereich IT für Februar 2019</a></li>
<li><a href="../de438122/index.html">Numerologie zu MS SQL - ein unterhaltsames Experiment</a></li>
<li><a href="../de438124/index.html">Piter GraphQL: Videos von Mitap in Wrike</a></li>
<li><a href="../de438126/index.html">Absolventen von IT-Praktika bei der Raiffeisenbank - wie es war</a></li>
<li><a href="../de438128/index.html">Viele Zeichen - viele neuronale Netze: Wie kann ein effektives Erkennungssystem für eine große Anzahl von Klassen aufgebaut werden?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
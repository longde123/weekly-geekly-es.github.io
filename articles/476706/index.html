<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîû üèá üë®üèø‚Äçüíº Cerebras Systems present√≥ una computadora con el procesador m√°s grande del mundo de 22 √ó 22 cent√≠metros üë®üèº‚Äçüéì üëåüèø üçø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El diagrama de la computadora CS-1 muestra que la mayor√≠a est√° dedicada a alimentar y enfriar el motor de escala de oblea (WSE) gigante "procesador en...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cerebras Systems present√≥ una computadora con el procesador m√°s grande del mundo de 22 √ó 22 cent√≠metros</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dcmiran/blog/476706/"><img src="https://habrastorage.org/getpro/habr/post_images/43e/87f/2b3/43e87f2b3b76001e51387e09935558ba.jpg"><br>  <i><font color="gray">El diagrama de la computadora CS-1 muestra que la mayor√≠a est√° dedicada a alimentar y enfriar el motor de escala de oblea (WSE) gigante "procesador en placa".</font></i>  <i><font color="gray">Foto: Sistemas Cerebras</font></i> <br><br>  En agosto de 2019, Cerebras Systems y su socio de fabricaci√≥n TSMC anunciaron el <a href="https://habr.com/ru/news/t/464271/">chip m√°s grande en la historia de la tecnolog√≠a inform√°tica</a> .  Con un √°rea de 46,225 mm¬≤ y 1.2 trillones de transistores, el chip Wafer Scale Engine (WSE) es aproximadamente 56.7 veces m√°s grande que la GPU m√°s grande (21.1 billones de transistores, 815 mm¬≤). <br><br>  Los esc√©pticos dijeron que desarrollar un procesador no es la tarea m√°s dif√≠cil.  ¬øPero as√≠ es como funcionar√° en una computadora real?  ¬øCu√°l es el porcentaje de trabajo defectuoso?  ¬øQu√© potencia y enfriamiento se requerir√°n?  ¬øCu√°nto costar√° tal m√°quina? <br><br>  Parece que los ingenieros de Cerebras Systems y TSMC pudieron resolver estos problemas.  El 18 de noviembre de 2019, en la conferencia <a href="https://sc19.supercomputing.org/">Supercomputing 2019</a> , presentaron oficialmente el <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">CS-1</a> , "la computadora m√°s r√°pida del mundo para la computaci√≥n en el campo del aprendizaje autom√°tico y la inteligencia artificial". <br><a name="habracut"></a><br>  Las primeras copias de CS-1 ya se han enviado a los clientes.  Uno de ellos est√° instalado en el Laboratorio Nacional Argonne del Departamento de Energ√≠a de EE. UU., En el que comenzar√° el ensamblaje de la supercomputadora m√°s poderosa en los EE. UU. A partir de los <a href="https://habr.com/ru/company/dcmiran/blog/476378/">m√≥dulos Aurora en la nueva arquitectura de GPU Intel</a> .  Otro cliente fue el Laboratorio Nacional de Livermore. <br><br>  El procesador con 400,000 n√∫cleos est√° dise√±ado para centros de datos para procesar computaci√≥n en el campo del aprendizaje autom√°tico y la inteligencia artificial.  Cerebras afirma que la computadora entrena los sistemas de inteligencia artificial por √≥rdenes de magnitud de manera m√°s eficiente que el equipo existente.  El rendimiento CS-1 es equivalente a "cientos de servidores basados ‚Äã‚Äãen GPU" que consumen cientos de kilovatios.  Al mismo tiempo, ocupa solo 15 unidades en el bastidor del servidor y consume unos 17 kW. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfc/5aa/1da/cfc5aa1da0e52944fc1b68e4fca15146.jpg"><br>  <i><font color="gray">Procesador WSE.</font></i>  <i><font color="gray">Foto: Sistemas Cerebras</font></i> <br><br>  Andrew Feldman, CEO y cofundador de Cerebras Systems, dice que el CS-1 es "la computadora de inteligencia artificial m√°s r√°pida del mundo".  Lo compar√≥ con los grupos de TPU de Google y observ√≥ que cada uno de ellos "toma 10 bastidores y consume m√°s de 100 kilovatios para proporcionar un tercio del rendimiento de una sola instalaci√≥n CS-1". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/523/1d3/b60/5231d3b60c445d641bb654d29b8fec21.jpg"><br>  <i><font color="gray">Computadora CS-1.</font></i>  <i><font color="gray">Foto: Sistemas Cerebras</font></i> <br><br>  Aprender redes neuronales grandes puede llevar semanas en una computadora est√°ndar.  Instalar un CS-1 con un chip procesador de 400,000 n√∫cleos y 1.2 billones de transistores realiza esta tarea en minutos o incluso segundos, <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/cerebras-unveils-ai-supercomputer-argonne-national-lab-first-installation">escribe</a> IEEE Spectrum.  Sin embargo, Cerebras no proporcion√≥ resultados de pruebas reales para probar declaraciones de alto rendimiento como <a href="https://mlperf.org/training-results-0-6">las pruebas MLPerf</a> .  En cambio, la compa√±√≠a estableci√≥ contactos directamente con clientes potenciales y permiti√≥ entrenar sus propios modelos de redes neuronales en CS-1. <br><br>  Los analistas dicen que este enfoque no es inusual: "Todos manejan sus propios modelos que han desarrollado para su propio negocio", dijo <a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a> , analista de inteligencia artificial de Moor Insights &amp; Strategies.  "Esto es lo √∫nico que le importa a los clientes". <br><br>  Muchas compa√±√≠as est√°n desarrollando chips especializados para IA, incluidos representantes tradicionales de la industria como Intel, Qualcomm, as√≠ como varias nuevas empresas en los Estados Unidos, el Reino Unido y China.  Google ha desarrollado un chip espec√≠ficamente para redes neuronales: un procesador tensorial o TPU.  Varios otros fabricantes hicieron lo mismo.  Los sistemas de inteligencia artificial funcionan en modo de subprocesos m√∫ltiples, y el cuello de botella est√° moviendo datos entre los chips: "Conectar los chips en realidad los ralentiza y requiere mucha energ√≠a", <a href="https://www.nytimes.com/2019/08/19/technology/artificial-intelligence-chip-cerebras.html">explica</a> Subramanian Iyer, profesor de la Universidad de California en Los √Ångeles que se especializa en Desarrollo de chips para inteligencia artificial.  Los fabricantes de equipos est√°n explorando muchas opciones diferentes.  Algunos intentan expandir las conexiones entre procesos. <br><br>  Fundada hace tres a√±os, la startup Cerebras, que recibi√≥ m√°s de $ 200 millones en financiamiento de riesgo, ha propuesto un nuevo enfoque.  La idea es guardar todos los datos en un chip gigante, y as√≠ acelerar los c√°lculos. <br><br><img src="https://habrastorage.org/webt/up/k1/ej/upk1ejv8zsqxtj9nadanm8898zc.jpeg"><br><br>  Toda la placa de microcircuito se divide en 400,000 secciones m√°s peque√±as (n√∫cleos), dado que algunas de ellas no funcionar√°n.  El chip est√° dise√±ado con la capacidad de enrutar √°reas defectuosas.  Los n√∫cleos programables SLAC (n√∫cleos de √°lgebra lineal dispersa) est√°n optimizados para √°lgebra lineal, es decir, para c√°lculos en espacio vectorial.  La compa√±√≠a tambi√©n desarroll√≥ la tecnolog√≠a de "cosecha dispersa" para mejorar el rendimiento inform√°tico en cargas de trabajo dispersas (que contienen ceros), como el aprendizaje profundo.  Los vectores y las matrices en el espacio vectorial generalmente contienen muchos elementos cero (del 50% al 98%), por lo que en las GPU tradicionales, la mayor parte del c√°lculo se desperdicia.  En contraste, los n√∫cleos SLAC prefiltran los datos nulos. <br><br>  El sistema Swarm proporciona comunicaciones entre los n√∫cleos con un rendimiento de 100 petabits por segundo.  Enrutamiento de hardware, latencia medida en nanosegundos. <br><br>  El costo de una computadora no se llama.  Los expertos independientes creen que el precio real depende del porcentaje de matrimonio.  Adem√°s, el rendimiento del chip y cu√°ntos n√∫cleos est√°n operativos en muestras reales no se conocen de manera confiable. <br><br><h1>  Software </h1><br>  Cerebras ha anunciado algunos detalles sobre la parte de software del sistema CS-1.  El software permite a los usuarios crear sus propios modelos de aprendizaje autom√°tico utilizando marcos est√°ndar como <a href="https://pytorch.org/">PyTorch</a> y <a href="https://www.tensorflow.org/">TensorFlow</a> .  Luego, el sistema distribuye 400,000 n√∫cleos y 18 gigabytes de memoria SRAM en el chip a las capas de la red neuronal para que todas las capas completen su trabajo aproximadamente al mismo tiempo que sus vecinos (tarea de optimizaci√≥n).  Como resultado, la informaci√≥n es procesada por todas las capas sin demora.  Con un subsistema de E / S Ethernet de 12 puertos y 100 Gigabits, el CS-1 puede procesar 1.2 terabits de datos por segundo. <br><br>  La conversi√≥n de la red neuronal de origen a una representaci√≥n ejecutable optimizada (Cerebras Linear Algebra Intermediate Representation, CLAIR) es realizada por el Cerebras Graph Compiler (CGC).  El compilador asigna recursos inform√°ticos y memoria para cada parte del gr√°fico, y luego los compara con la matriz inform√°tica.  Luego, la ruta de comunicaci√≥n se calcula de acuerdo con la estructura interna de la placa, √∫nica para cada red. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/098/093/569/098093569a8dca7e8dea9e26fc63a81a.jpg"><br>  <i><font color="gray">Distribuci√≥n de operaciones matem√°ticas de una red neuronal por n√∫cleos de procesador.</font></i>  <i><font color="gray"><a href="https://fortune.com/2019/11/19/artificial-intelligence-cerebras-supercomputer/">Foto</a> : Cerebras</font></i> <br><br>  Debido al enorme tama√±o de WSE, todas las capas en una red neuronal se ubican simult√°neamente en ella y funcionan en paralelo.  Este enfoque es exclusivo de WSE: ning√∫n otro dispositivo tiene suficiente memoria interna para adaptarse a todas las capas en un chip a la vez, dice Cerebras.  Tal arquitectura con la colocaci√≥n de toda la red neuronal en un chip proporciona enormes ventajas debido a su alto rendimiento y baja latencia. <br><br>  El software puede realizar la tarea de optimizaci√≥n para m√∫ltiples computadoras, permitiendo que el grupo de computadoras act√∫e como una m√°quina grande.  Un grupo de 32 computadoras CS-1 muestra un aumento de rendimiento de aproximadamente 32 veces, lo que indica una escalabilidad muy buena.  Feldman dice que esto es diferente de los cl√∫steres basados ‚Äã‚Äãen GPU: ‚ÄúHoy, cuando creas un cl√∫ster de GPU, no se comporta como una gran m√°quina.  Tienes muchos autos peque√±os ‚Äù. <br><br>  El <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">comunicado de prensa</a> dice que el Laboratorio Nacional de Argonne ha estado trabajando con Cerebras durante dos a√±os: "Al implementar CS-1, aumentamos dram√°ticamente la velocidad de entrenamiento de redes neuronales, lo que nos permiti√≥ aumentar la productividad de nuestra investigaci√≥n y lograr un √©xito significativo". <br><br>  Una de las primeras cargas para CS-1 ser√° una <a href="https://arxiv.org/abs/1903.01998">simulaci√≥n de red neuronal de una colisi√≥n de agujeros negros</a> y ondas gravitacionales, que se crean como resultado de esta colisi√≥n.  La versi√≥n anterior de esta tarea funcionaba en 1024 de 4392 nodos de la supercomputadora <a href="https://www.alcf.anl.gov/theta">Theta</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/476706/">https://habr.com/ru/post/476706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../476696/index.html">C√≥mo crear e implementar una aplicaci√≥n Full-Stack React</a></li>
<li><a href="../476698/index.html">C√≥mo Apple mata las tecnolog√≠as web</a></li>
<li><a href="../476700/index.html">Mes en la producci√≥n de radiadores de acero.</a></li>
<li><a href="../476702/index.html">C√≥mo una peque√±a ciudad del interior se convirti√≥ en un centro internacional de comercio electr√≥nico</a></li>
<li><a href="../476704/index.html">C√≥mo automatizar el dise√±o de correos electr√≥nicos con el mismo tipo de elementos: utilizamos objetos inteligentes</a></li>
<li><a href="../476708/index.html">Slurm Basic en Mosc√∫. D√≠a tres La colecci√≥n de contrainteligencia y el grupo, volando Pavel Selivanov y "Slurm Inspires!"</a></li>
<li><a href="../476710/index.html">Inscripci√≥n abierta: inmersi√≥n profunda en TI en Marte</a></li>
<li><a href="../476712/index.html">Servicio para reuniones aleatorias con extra√±os, pero no para citas. Historial de inicio de Random Coffee</a></li>
<li><a href="../476714/index.html">Operaci√≥n de aprendizaje autom√°tico en Mail.ru Mail</a></li>
<li><a href="../476718/index.html">Historia de una radio nacional: Mussolini de Rural Radio y Joseph Goebbels l√°mparas c√°lidas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
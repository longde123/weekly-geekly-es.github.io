<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💓 👨 😄 Aprendiendo conceptos a través de la interacción sensoriomotora 🐑 👸🏾 🧠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Experimento de pensamiento 
 Imagina que te has despertado en una habitación extraña. Esta no es una habitación acogedora en la que te quedaste dormid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aprendiendo conceptos a través de la interacción sensoriomotora</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436334/"><img src="https://habrastorage.org/webt/ow/ux/_b/owux_baoxeglnvw08tmmodz-usy.png"><br><br><h2>  Experimento de pensamiento </h2><br>  Imagina que te has despertado en una habitación extraña.  Esta no es una habitación acogedora en la que te quedaste dormido, sino una celda con poca luz y un piso húmedo y fresco.  Yeso agrietado en las paredes.  Y la única entrada y salida es supuestamente una enorme puerta de hierro, cerrada con un candado desde el interior.  Un poco más arriba en la pared hay una ventana enrejada que permite que pase algo de luz.  Si miras a tu alrededor, habrás llegado a la conclusión de que estás atrapado, eso sería perfectamente razonable.  Se ve horrible <br><a name="habracut"></a><br>  ¿Pero te satisfará?  Probablemente no.  Querrá explorar la habitación un poco más, tal vez tire del candado para probar su confiabilidad.  O desea probar la resistencia de estas paredes enyesadas.  ¿Quizás unos pocos golpes duros y haces un agujero por el cual puedes salir?  ¿O tal vez estas rejas en la ventana tienen aberturas tan grandes que puedes salir?  La interacción con el entorno le brinda mucha más información que la observación pasiva del mismo.  La visión puede ser una hipótesis, pero probarla requiere una interacción real con el medio ambiente. <br><br><h2>  Concepto de conceptos </h2><br>  <i>Contenido y conclusión</i> son conceptos.  <i>El perro</i> también es un concepto.  Además de <i>correr</i> , <i>bosque</i> , <i>belleza</i> , <i>verde</i> o <i>muerte</i> .  Los conceptos son abstracciones que distinguimos de la interacción cotidiana con el mundo.  Forman los bloques de conocimiento reutilizables que las personas necesitan para comprender el mundo. <br><br>  Cuando tenemos una comprensión conceptual de algo, significa que tenemos algo de experiencia con esto, de alguna manera lo dominamos.  En el caso del contenido, esta experiencia significa que podemos identificar objetos contenedores en el mundo que pueden contener algo, separarlos de los "no contenedores", poner algunas cosas dentro, recuperarlas y anticipar lo que sucederá. si de alguna manera interactuaremos con ellos.  Incluso podemos mirar cosas nuevas y comprender si pueden contener algo en sí mismas o viceversa, si pueden incluirse en algún otro tema. <br><br>  Los principales enfoques de la comprensión conceptual en IA, incluidos los sistemas de aprendizaje profundo entrenados en conjuntos de datos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageNet</a> , aparentemente tienen algunas de estas habilidades, pero carecen de una comprensión más profunda: la experiencia que proviene de la interacción.  Al percibir una imagen o incluso un video, estos enfoques pueden determinar si hay un tipo específico de "contenedor", por ejemplo, una taza, una casa o una botella, y también determinar dónde se encuentra este objeto en la imagen.  Pero casi seguramente fracasarán cuando se encuentren con un tipo inexplorado de tal objeto.  Una solicitud para ubicarse en algún lugar solo tendrá un malentendido tan completo en dicho sistema, ya que correlaciona el concepto de un objeto contenedor con una serie de signos visuales, pero no tiene una comprensión activa del término de contenido dentro de algo. <br><br><h2>  Conceptos de la experiencia sensoriomotora </h2><br>  Henri Poincaré fue uno de los primeros en enfatizar el papel de las representaciones sensoriomotoras en la comprensión humana.  En su libro Ciencia e hipótesis, argumentó que un ser inmóvil nunca podría dominar el concepto de espacio tridimensional.  No hace mucho tiempo, varios científicos cognitivos sugirieron que las representaciones conceptuales surgen de la integración de la percepción y la acción.  Por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">O'Regan y Noë</a> definen la experiencia sensoriomotora como "una estructura de reglas que define los cambios sensoriales producidos por diversas acciones motoras", y la observación pasiva como "un modo de explorar el mundo que se basa en el conocimiento de la experiencia sensoriomotora".  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Noë</a> agrega que "los conceptos son una especie de enfoque para administrar lo que está alrededor". <br><br>  Aunque la importancia de la experiencia sensoriomotora ha sido apreciada dentro de la comunidad cognitiva, estas ideas han llevado a unos pocos modelos computacionales específicos que exploran su papel en la configuración de conceptos.  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo</a> que presentamos en AAAI-18, mostramos un modelo computacional que explora conceptos a través de la interacción con el entorno. <br><br><h2>  Que hemos hecho </h2><br>  Planeamos realizar y estudiar las dos habilidades principales que conforman la comprensión conceptual: la capacidad de detectar activamente un concepto y la capacidad de sacar conclusiones o actuar sobre este concepto.  Además, queríamos investigar situaciones en las que las habilidades interactivas son preferibles a los enfoques pasivos, y comprender cómo el uso de conceptos simples ya estudiados puede ayudar a estudiar los más complejos. <br><br>  Comenzamos desarrollando un campo de entrenamiento virtual especial para explorar conceptos activos, un entorno que llamamos <b>PixelWorld</b> (disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> ).  En este mundo, las cosas se arreglan un poco más fácilmente que en el mundo real.  Este es un campo bidimensional discreto que contiene un agente de píxeles y uno o más objetos de otro tipo, que también consta de píxeles (por ejemplo, líneas, puntos o contenedores). <br><br>  El agente tiene una implementación bastante simple: percibe solo el espacio de 3 × 3 celdas a su alrededor y puede moverse hacia arriba, hacia abajo, hacia la izquierda, hacia la derecha o detenerse y enviar información.  Tal implementación requiere el estudio de incluso las ideas más básicas sobre el mundo, tanto el concepto mismo de un objeto como el concepto de conceptos de interacción.  A pesar del hecho de que esto puede parecer una privación sensorial excesiva, la eliminación de la rica percepción visual nos permite centrarnos en el papel de transformar el comportamiento multifacético en una visión significativa del mundo. <br><br>  Capacitamos agentes en dos tipos diferentes de tareas.  La primera tarea fue investigar el entorno e informar si el concepto necesario está presente en el entorno.  Por ejemplo, un contenedor.  Y fue recompensado si la respuesta era correcta.  La segunda tarea era actuar en relación con este concepto.  Por ejemplo, ponte en este contenedor.  Esto fue recompensado si cumplió correctamente la tarea y lo informó.  Para esto, utilizamos entrenamiento de refuerzo. <br><br>  Por ejemplo, le enseñamos al agente a determinar cuándo estaba encerrado en un objeto en un plano horizontal.  La siguiente animación muestra este comportamiento: el agente verifica si hay un muro a la derecha, luego verifica si hay un muro a la izquierda.  Tan pronto como se pasan con éxito ambas pruebas, informa que está "bajo custodia". <br><br><img src="https://habrastorage.org/webt/y1/zy/ws/y1zywsgod6kiywb0-bghx_a9mcc.gif"><br><br>  Entrenamos al siguiente agente para que entienda lo mismo cuando ya está rodeado por dos objetos a los lados: un contenedor sólido y un contenedor con un agujero.  La animación muestra que el agente ingresa al objeto correcto, verificando si es un contenedor sólido.  Detecta un agujero y luego se sube al contenedor izquierdo, lo que indica al final que está bajo custodia. <br><br><img src="https://habrastorage.org/webt/q5/z8/bc/q5z8bcy9drsaauj8jngkjj8hlig.gif"><br><br>  Podemos entender con más detalle lo que está haciendo el agente analizando los registros de sus acciones: <br><br><img src="https://habrastorage.org/webt/ow/ux/_b/owux_baoxeglnvw08tmmodz-usy.png"><br><br>  La figura anterior muestra cada acción realizada por el agente en la animación que se muestra arriba.  Cada cuadro representa una acción, el tiempo aumenta de izquierda a derecha.  "ABAJO", "DERECHA", "ARRIBA" y "IZQUIERDA" son las principales acciones del agente, y cada línea de "SMC" representa un caso especial de interacción sensoriomotora que el agente puede realizar.  SMC ( <i>contingencias sensoriomotoras - aprox. Transl.</i> ) Se puede representar como pequeños programas que, cuando se ejecutan, utilizan una secuencia de acciones básicas hasta que el agente decide detenerse y enviar una de las dos señales que significan éxito ("SIG1", verde) o derrota ("SIG0", rojo).  Cada uno de estos SMC surgió como un agente capacitado para resolver un problema conceptual más simple.  Por ejemplo, "SMC 3" fue entrenado para subir a un contenedor si inicialmente estaba en el piso a su izquierda.  Y esto es lo primero que hace el agente en la animación del paso 0 al 11.  Por lo tanto, el agente puede realizar tareas complejas, como llegar a una conclusión final sobre la conclusión, realizar una secuencia de SMC de bajo nivel correspondientes. <br><br>  Después de eso, expandimos nuestros conceptos más allá del término de conclusión e incluimos conceptos tales como estar encima de un objeto o estar a la izquierda de dos objetos: <br><br><img src="https://habrastorage.org/webt/oo/mf/0w/oomf0wooxm8m23mgghien6_mhvo.gif"><br><br><img src="https://habrastorage.org/webt/sy/sl/sd/syslsdh0ebfvow-8dsah06vr8sa.gif"><br><br>  Capacitar a estos agentes en un solo entorno no sería suficiente, porque para comprender qué aspectos del entorno están relacionados con los conceptos y cuáles no, se necesitan muchos entornos diferentes.  La presencia de tantos tipos de entornos también nos permite determinar los tipos en los que un enfoque activo y la reutilización del comportamiento previamente desarrollado se beneficiarían de los enfoques pasivos. <br><br>  Para satisfacer esta necesidad, aplicamos un tipo especial de grabación basada en lógica de primer orden para preparar matrices de datos para experimentos, utilizando expresiones lógicas tanto para generar medios como para marcarlos con respecto a qué concepto se representa dentro de ellos.  Hemos creado 96 matrices de este tipo organizadas en bloques de capacitación desde conceptos simples hasta complejos.  Tanto el sistema de grabación como los entornos mencionados anteriormente están contenidos en el lanzamiento de PixelWorld. <br><br><h2>  Lo que tenemos </h2><br>  Comparamos nuestro enfoque activo con el pasivo, utilizando una red neuronal convolucional, capacitada para determinar si un concepto está presente, basado en una percepción estática de todo el entorno.  Para los conceptos que usan "conclusión", el enfoque interactivo es claramente superior a la red convolucional.  Para los conceptos que involucran diversos objetos de muchas formas y relaciones espaciales, encontramos que la red de convolución funcionó mejor en algunos casos, pero peor en otros.  Cabe señalar que los enfoques pasivos, por definición, no pueden interactuar con el entorno, por lo que en este caso lo único que se podía esperar era una detección estática del concepto.  Solo nuestro enfoque proactivo puede tener éxito en entornos que requieren la comprensión de algún tipo de interacción o relación con el concepto. <br><br>  También encontramos que la reutilización del comportamiento mejoró los resultados para ambas tareas (detección e interacción), con los resultados más obvios en aquellos casos en que los conceptos incluían múltiples objetos o requerían secuencias complejas en el comportamiento. <br><br><h2>  Conclusiones </h2><br>  Nuestro trabajo muestra que las representaciones conceptuales sensoriomotoras interactivas pueden formalizarse y asimilarse.  Si bien los experimentos reflejados en este artículo ayudaron a identificar el papel de la interacción de manera general, su combinación con el enfoque del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sistema de visión generativa</a> podría ser útil para estudiar los conceptos del mundo real.  Además, la combinación de representaciones sensoriomotoras con técnicas como " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Redes de esquema</a> " permitiría al agente tener una representación interna del mundo exterior que pueda utilizar para la simulación y la planificación. <br><br>  Aunque la inteligencia artificial fuera de control es un tema que es mejor dejar para las películas de ciencia ficción, creemos que extraer conceptos de la interacción sensoriomotora es una de las claves para ir más allá de las técnicas modernas de inteligencia artificial pasiva. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436334/">https://habr.com/ru/post/es436334/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436324/index.html">Consejos y trucos de mi canal de Telegram @pythonetc, diciembre de 2018</a></li>
<li><a href="../es436326/index.html">Recentralización de la web. Por siempre esta vez</a></li>
<li><a href="../es436328/index.html">PVS-Studio 7.00</a></li>
<li><a href="../es436330/index.html">Creando un juego para Game Boy</a></li>
<li><a href="../es436332/index.html">PVS-Studio 7.00</a></li>
<li><a href="../es436338/index.html">¿Cómo funciona el aeropuerto de Vnukovo?</a></li>
<li><a href="../es436340/index.html">Nivel de registro separado para cada solicitud</a></li>
<li><a href="../es436342/index.html">Una introducción a la optimización robusta [... y una pequeña lista de compras que olvidé ...]</a></li>
<li><a href="../es436344/index.html">Fibaro Home Center 2 y termostato para calefacción por suelo radiante HeatIt. Cómo elevar la temperatura.</a></li>
<li><a href="../es436346/index.html">¿Siempre necesitas Docker, microservicios y programación reactiva?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
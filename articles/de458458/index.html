<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèø‚Äçü§ù‚Äçüßëüèº üë®üèª üêè Tiefenkameras - stille Revolution (wenn Roboter sehen) Teil 2 üë©üèΩ‚Äç‚úàÔ∏è üï∫üèª üóæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im ersten Teil dieses Textes haben wir Tiefenkameras untersucht, die auf Messungen des strukturellen Lichts und der Umlauflichtverz√∂gerung basieren un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tiefenkameras - stille Revolution (wenn Roboter sehen) Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458458/"><img src="https://habrastorage.org/webt/uy/lx/0t/uylx0tpbzxlqa5hnxqzjnriruoy.png"><br><br>  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Teil</a> dieses Textes haben wir Tiefenkameras untersucht, die auf Messungen des strukturellen Lichts und der Umlauflichtverz√∂gerung basieren und haupts√§chlich Infrarotbeleuchtung verwenden.  Sie eignen sich hervorragend f√ºr Innenr√§ume in Entfernungen von 10 bis 10 Metern und sind vor allem sehr billig.  Daher die massive Welle ihrer aktuellen Verwendung in Smartphones.  Aber ... Sobald wir nach drau√üen gehen, beleuchtet die Sonne sogar durch die Wolken das Infrarotlicht und ihre Arbeit verschlechtert sich stark. <br><br>  Wie Steve Blank ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aus einem anderen Grund</a> ) sagt: "Wenn Sie Erfolg haben wollen, verlassen Sie das Geb√§ude."  Im Folgenden werden wir √ºber Tiefenkameras sprechen, die im Freien arbeiten.  Heute wird dieses Thema stark von autonomen Autos bestimmt, aber, wie wir sehen werden, nicht nur. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/659/8b4/4b2/6598b44b2d0a420dd83a434753cc6ffb.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Innoviz sieht massenproduzierte selbstfahrende Autos mit Festk√∂rper-LiDAR vor</a></i> <br><br>  So k√∂nnen Tiefenkameras, d.h.  Ger√§te, die Videos aufnehmen, in deren Pixel der Abstand zum Szenenobjekt im Sonnenlicht liegt! <br><br>  Wen k√ºmmert es - willkommen bei kat! <br><a name="habracut"></a><br>  Beginnen wir mit den zeitlosen Klassikern ... <br><br><h1>  Methode 3: Tiefe von der Stereokamera + </h1><br>  Das Erstellen einer Tiefenkarte aus Stereo ist bekannt und wird seit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºber 40 Jahren verwendet</a> .  Im Folgenden finden Sie ein Beispiel f√ºr eine Kompaktkamera f√ºr 450 US-Dollar, mit der Gesten zusammen mit professioneller Fotografie oder VR-Helmen gesteuert werden k√∂nnen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/594/0ab/3b0/5940ab3b0cbc72369d80083d8d32be57.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a></i> <br><br>  Der Hauptvorteil solcher Kameras besteht darin, dass Sonnenlicht sie nicht nur nicht st√∂rt, sondern umgekehrt auch ihre Ergebnisse verbessert. Daher ist die aktive Verwendung solcher Kameras f√ºr alle Arten von Stra√üenkoffern beispielsweise ein hervorragendes Beispiel daf√ºr, wie ein dreidimensionales Modell einer alten Festung in wenigen Minuten aufgenommen werden kann: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AFH2yN3rM78" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein Beispiel f√ºr den Stra√üengebrauch der ZED-Kamera</a></i> <br><br>  Das sp√ºrbare Geld f√ºr die √úbersetzung der Tiefenkonstruktion von Stereo auf ein neues Niveau wurde nat√ºrlich vom Thema autonome Autos beeinflusst.  Von den 5 in Betracht gezogenen Methoden zum Erstellen eines Tiefenvideos st√∂ren nur zwei - diese und die n√§chste (Stereo und Plenoptik) - nicht die Sonne und nicht benachbarte Autos.  Gleichzeitig ist die Plenoptik √ºber gro√üe Entfernungen um ein Vielfaches teurer und ungenauer.  Auf jeden Fall k√∂nnen Dinge passieren, es ist schwierig, Prognosen zu erstellen, aber in diesem Fall lohnt es sich, Elon Mask zuzustimmen - Stereo von allen 5 Methoden hat die besten Aussichten.  Und die aktuellen Ergebnisse sind sehr ermutigend: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12e/cec/e3f/12ecece3f83fc654f64023e1391c38bb.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Direct SLAM in gro√üem Ma√üstab mit Stereokameras</a></i> <br><br>  Es ist jedoch interessant, dass nicht unbemannte Fahrzeuge (von denen bisher nur wenige hergestellt werden), sondern viel massivere Ger√§te, auf denen derzeit eine Stereotiefenkarte erstellt wird, einen noch st√§rkeren Einfluss auf die Entwicklung der Bautiefe aus Stereo haben werden, n√§mlich ... Richtig!  Smartphones! <br><br>  Vor drei Jahren gab es einfach den Boom der ‚Äûzwei√§ugigen‚Äú Smartphones, bei denen buchst√§blich alle Marken bekannt waren, weil sich die Qualit√§t der mit einer Kamera aufgenommenen Fotos und die Qualit√§t der mit zwei Kameras aufgenommenen Fotos dramatisch unterschieden. Unter dem Gesichtspunkt der Preiserh√∂hung f√ºr ein Smartphone war dies jedoch nicht so bedeutend: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ab7/6b4/b3e/ab76b4b3e9696443e5191d293b59e663.png"><br><br>  Dar√ºber hinaus ging der Prozess im vergangenen Jahr noch aktiv weiter: ‚ÄûHaben Sie 2 Kameras in Ihrem Smartphone?  Schei√üe!  Ich habe <s>drei</s> vier !!! ‚Äù: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48f/905/554/48f905554fab15bcc6ce668c0c5f9ef7.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Samsung Galaxy A8 &amp; A9</a></i> <br><br>  Sechs√§ugige Zukunft Sony wurde im ersten Teil erw√§hnt.  Im Allgemeinen werden mehr√§ugige Smartphones bei Herstellern immer beliebter. <br><br>  Die grundlegenden Ursachen dieses Ph√§nomens sind einfach: <br><br><ul><li>  Die Aufl√∂sung von Kamerahandys w√§chst und die Gr√∂√üe des Objektivs ist gering.  Infolgedessen steigt trotz zahlreicher Tricks der Ger√§uschpegel und die Qualit√§t nimmt ab, insbesondere bei Aufnahmen im Dunkeln. <br></li><li>  Dar√ºber hinaus k√∂nnen wir bei der zweiten Kamera das sogenannte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bayer-Filter</a> aus der Matrix entfernen, d.h.  Eine Kamera ist schwarzwei√ü und die zweite Farbe.  Dies erh√∂ht die Schwarzwei√üempfindlichkeit um etwa das Dreifache.  Das hei√üt,  Die Empfindlichkeit von 2 Kameras w√§chst bedingt nicht um das 2-fache, sondern um das 4-fache (!).  Es gibt zahlreiche Nuancen, aber eine solche Erh√∂hung der Empfindlichkeit ist f√ºr das Auge wirklich deutlich sichtbar. <br></li><li>  Wenn ein Stereopaar erscheint, haben wir unter anderem die M√∂glichkeit, die Sch√§rfentiefe programmgesteuert zu √§ndern, d. H.  Verwischen Sie den Hintergrund, von dem viele Fotos erheblich profitieren (dar√ºber haben wir in der zweiten H√§lfte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier geschrieben</a> ).  Diese Option neuer Smartphone-Modelle wurde schnell sehr beliebt. <br></li><li>  Mit zunehmender Anzahl von Kameras ist es auch m√∂glich, andere Objektive zu verwenden - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Weitwinkel</a> (Kurzfokus) und umgekehrt Langfokus, was die Qualit√§t beim "Ann√§hern" von Objekten erheblich verbessern kann. <br></li><li>  Interessanterweise bringt uns eine Zunahme der Anzahl der Kameras n√§her an das Thema eines verd√ºnnten Lichtfeldes heran, das viele seiner Merkmale und Vorteile aufweist. Dies ist jedoch eine andere Geschichte. <br></li><li>  Wir stellen au√üerdem fest, dass Sie durch Erh√∂hen der Anzahl der Kameras die Aufl√∂sung durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufl√∂sungswiederherstellungsmethoden</a> erh√∂hen k√∂nnen. <br></li></ul><br>  Im Allgemeinen gibt es so viele Pluspunkte, dass sich die Leute, wenn sie sich ihrer bewusst sind, fragen, warum mindestens zwei Kameras schon lange nicht mehr eingestellt wurden. <br><br>  Und dann stellt sich heraus, dass nicht alles so einfach ist.  Um zus√§tzliche Kameras sinnvoll einzusetzen, um das Bild zu verbessern (und nicht nur zu einer Kamera mit einem anderen Objektiv zu wechseln), m√ºssen wir eine sogenannte Disparit√§tskarte erstellen, die direkt in eine Tiefenkarte umgewandelt wird.  Und dies ist eine nicht triviale Aufgabe, zu deren L√∂sung gerade die Leistung von Smartphones gekommen ist.  Und selbst jetzt sind Tiefenkarten oft von eher zweifelhafter Qualit√§t.  Das hei√üt, bevor die genaue √úbereinstimmung "Pixel auf dem rechten Bild mit dem Pixel auf der linken Seite" noch √ºberleben muss.  Hier sind zum Beispiel echte Beispiele f√ºr Tiefenkarten f√ºr das iPhone: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/221/1f2/7d2/2211f27d2bfb2dc01da93559e8d1d8d1.png"><br>  <i>Quelle: <a href="">iPhone XS &amp; XR Tiefenkartenvergleich</a></i> <br><br>  Selbst mit dem Auge sind Massenprobleme im Hintergrund deutlich sichtbar, an den R√§ndern schweige ich √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durchscheinendes</a> Haar.  Daher gibt es zahlreiche Probleme, die sowohl beim √úbertragen von Farbe von einer Schwarzwei√ükamera auf eine Farbkamera als auch w√§hrend der weiteren Verarbeitung auftreten. <br><br>  Hier ist zum Beispiel ein ziemlich gutes Beispiel aus einem Bericht von Apple zum Thema ‚ÄûErstellen von Foto- und Videoeffekten mit Tiefe‚Äú: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83c/38f/efc/83c38fefc85d9e1ddef931b594e20469.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von Foto- und Videoeffekten ‚Ä¢ Verwenden von Depth, Apple, WWDC18</a></i> <br><br>  Sie k√∂nnen deutlich sehen, wie fehlerhaft die Tiefe unter den Haaren ist, und zwar vor einem mehr oder weniger gleichm√§√üigen Hintergrund, aber was noch wichtiger ist, auf der rechten Mattierungskarte ist der Kragen in den Hintergrund getreten (d. H. Er wird unscharf).  Ein weiteres Problem ist die tats√§chliche Aufl√∂sung der Tiefe und die Mattierungskarte ist erheblich niedriger als die Bildaufl√∂sung, was sich auch auf die Qualit√§t w√§hrend der Verarbeitung auswirkt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/848/dcb/5cf/848dcb5cf62ea5991a85b23160fc1ce9.png"><br><br>  All dies ist jedoch ein Wachstumsproblem.  Wenn vor 4 Jahren keine ernsthaften Auswirkungen auf das Video in Frage kamen, hat das Telefon sie einfach nicht "gezogen", aber heute wird sich die Videoverarbeitung mit Tiefe auf seriellen Top-Telefonen gezeigt (in derselben Pr√§sentation von Apple): <br><br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/481/5fe/6f8/4815fe6f8f9e7fd837a4e410df01a0da.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von Foto- und Videoeffekten ‚Ä¢ Verwenden von Depth, Apple, WWDC18</a></i> <br><br>  Im Allgemeinen erobert das Thema Multi-Multi-Handys und damit das Thema Tiefensch√§rfe von Stereo auf Mobiltelefonen die Massen kampflos: <br><br><img width="66%" src="https://habrastorage.org/webt/t2/ba/sz/t2basz3pj6tskae0fqox5ol3x-q.png"><br>  <i>Quelle: "auf diesen von Ihrem Internet gefunden"</i> <br><br>  Wichtigste Ergebnisse: <br><br><ul><li>  Die Tiefe von Stereo - gemessen an den Ausr√ºstungskosten - ist der billigste Weg, um Tiefe zu erhalten, da Kameras jetzt kosteng√ºnstig sind und immer schneller billiger werden.  Die Schwierigkeit besteht darin, dass die Weiterverarbeitung viel ressourcenintensiver ist als bei anderen Methoden. <br></li><li>  Bei Mobiltelefonen k√∂nnen Sie den Durchmesser des Objektivs nicht vergr√∂√üern, w√§hrend die Aufl√∂sung schnell zunimmt.  Infolgedessen kann die Verwendung von zwei oder mehr Kameras die Qualit√§t des Fotos erheblich verbessern, das Rauschen bei schlechten Lichtverh√§ltnissen reduzieren und die Aufl√∂sung erh√∂hen.  Da heutzutage h√§ufig ein Mobiltelefon f√ºr die Qualit√§t der Kamera ausgew√§hlt wird, ist dies ein √§u√üerst greifbares Plus.  Das Erstellen einer Tiefenkarte ist ein unauff√§lliger Nebenbonus. <br></li><li>  Die Hauptnachteile der Geb√§udetiefe von Stereo: <br><ul><li>  Sobald die Textur verschwindet oder einfach weniger kontrastreich wird, nimmt das Rauschen in der Tiefe stark zu, so dass selbst bei einfachen Objekten die Tiefe h√§ufig schlecht genutzt wird (schwerwiegende Fehler sind m√∂glich). <br></li><li>  Au√üerdem ist die Tiefe bei d√ºnnen und kleinen Objekten ("abgeschnittenen" Fingern oder sogar H√§nden, versenkten S√§ulen usw.) schlecht bestimmt. <br></li></ul></li><li>  Sobald Sie mit der Leistung von Eisen eine Tiefenkarte f√ºr Videos erstellen k√∂nnen, wird die Tiefe auf Smartphones einen starken Impuls f√ºr die Entwicklung von AR geben (irgendwann, v√∂llig unerwartet f√ºr die √ñffentlichkeit, wird die Qualit√§t von AR-Anwendungen auf allen neuen Telefonmodellen, einschlie√ülich der Budget-Modelle, pl√∂tzlich merklich h√∂her und eine neue Welle wird losgehen) .  V√∂llig unerwartet! <br></li></ul><br>  Die n√§chste Methode ist weniger trivial und ber√ºhmt, aber sehr cool.  Triff mich! <br><br><h1>  Methode 4: Lichtfeldtiefenkameras </h1><br>  Das Thema Plenoptik (vom lateinischen Plenus - voll und optikos - visuell) oder Lichtfelder ist der Masse noch relativ wenig bekannt, obwohl Fachleute damit begannen, sich sehr dicht damit zu befassen.  Auf vielen Top-Konferenzen wurden separate Abschnitte f√ºr Artikel zum Thema Lichtfeld zugewiesen (der Autor war einmal beeindruckt von der Anzahl der asiatischen Forscher auf der IEEE International Conference on Multimedia and Expo, die sich intensiv mit diesem Thema befassen). <br><br>  Laut Google Trends sind die USA und Australien an Light Field interessiert, gefolgt von Singapur und Korea.  Gro√übritannien  Russland liegt auf Platz 32 ... Wir werden den R√ºckstand aus Indien und S√ºdafrika korrigieren: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/651/993/87b/65199387b858541acc6ff99a129c2fe3.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Trends</a></i> <br><br>  Ihr bescheidener Diener hat vor einiger Zeit einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausf√ºhrlichen Artikel √ºber Habr√© verfasst,</a> in dem ausf√ºhrlich beschrieben wird, wie es funktioniert und was es gibt. Lassen Sie uns kurz darauf eingehen. <br><br>  Die Hauptidee besteht darin, an jedem Punkt nicht nur Licht, sondern eine zweidimensionale Anordnung von Lichtstrahlen zu fixieren, wodurch jeder Rahmen vierdimensional wird.  In der Praxis erfolgt dies mit einer Reihe von Mikrolinsen: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/90f/203/fb4/90f203fb49d7e464638a4f164e96fb26.gif"></a> <br>  <i>Quelle: <a href="">plenoptic.inf (empfohlen zum Klicken und Anzeigen in voller Aufl√∂sung)</a></i> <br><br>  Infolgedessen haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">viele neue M√∂glichkeiten</a> , aber die Aufl√∂sung f√§llt ernsthaft.  Nachdem sie viele komplizierte technische Probleme gel√∂st hatten, erh√∂hten sie die Aufl√∂sung bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lytro</a> (von Google gekauft) radikal, wo im Lytro Cinema die Aufl√∂sung des Kamerasensors auf 755 Megapixel RAW-Daten erh√∂ht wurde und wie die ersten Kameras sperrig aussah: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3ec/631/027/3ec6310271829f9272a4d3ef41462bde.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NAB: Neue Lytro-Lichtfeldkamera, die gro√üe √Ñnderungen an der Arbeit mit visuellen Effekten bewirken k√∂nnte, wird vorgestellt</a></i> <br><br>  Es ist interessant, dass selbst Profis den Aufl√∂sungsabfall von plenoptischen Kameras regelm√§√üig falsch einsch√§tzen, weil sie untersch√§tzen, wie gut sie mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Super Resolution-</a> Algorithmen arbeiten k√∂nnen, die viele Details der Bild-Mikroverschiebungen im Lichtfeld wirklich perfekt wiederherstellen (achten Sie auf verschwommene Stricknadeln und sich bewegende Schaukeln im Hintergrund). :: <br><br><img width="200%" src="https://habrastorage.org/getpro/habr/post_images/bc9/6cd/e55/bc96cde55e276f4420757de5359467b1.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Naive, intelligente und hochaufl√∂sende plenoptische Rahmenwiederherstellung</a> aus dem technischen Bericht von Adobe ‚ÄûSuperaufl√∂sung mit plenoptischer Kamera 2.0‚Äú</i> <br><br>  All dies w√§re von relativ theoretischem Interesse, wenn Google keine Plenoptik in Pixel 2 implementiert h√§tte, indem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2 Pixel mit einer Linse abgedeckt wurden</a> : <br><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/852/c36/209/852c36209a7528f576e20dc37e0ef1f3.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Google Blog</a></i> <br><br>  Als Ergebnis wurde ein Mikrostereopaar gebildet, das es erm√∂glichte, die Tiefe zu messen, bis zu der Google, getreu neuen Traditionen, neuronale Netze hinzuf√ºgte, und es stellte sich im Allgemeinen als wunderbar heraus: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/429/442/99e/42944299e72b7eb720f3babc5a757b79.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/da3/fe1/3ea/da3fe13eacb3cd5b0a558db1d843b686.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/c6f/a27/c4b/c6fa27c4bac8b9c5cb122e0c69ab814d.png"><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/2ba/e97/e67/2bae97e67ae10cd150ef28ccdc6cc458.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/88a/159/34f/88a15934f1192deb0da889a630fed232.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/d7d/eab/811/d7deab81164e7e886b42a95173c58641.png"><br><br>  Weitere Beispiele f√ºr Tiefe in voller Aufl√∂sung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in einer speziellen Galerie</a> . <br><br>  Interessanterweise wird die Tiefe von Google (wie Huawei und anderen) im Bild selbst gespeichert, sodass Sie sie von dort extrahieren und sehen k√∂nnen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d63/958/b09/d63958b09a9584752a90f014adfadc24.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drei geheime Funktionen der neuen Kamera-App von Google, die Sie umhauen werden</a></i> <br><br>  Und dann k√∂nnen Sie das Foto dreidimensional machen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/3a5/e71/48b3a5e7156a14dcf60c600472154f6c.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drei geheime Funktionen der neuen Kamera-App von Google, die Sie umhauen werden</a></i> <br><br>  Sie k√∂nnen auf der Website <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://depthy.me</a> , auf der Sie Ihr Foto hochladen k√∂nnen, unabh√§ngig damit experimentieren.  Interessanterweise ist die Site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der Quelle verf√ºgbar</a> , d. H.  Die Tiefenverarbeitung kann verbessert werden, daf√ºr gibt es viele M√∂glichkeiten, jetzt werden dort die einfachsten Verarbeitungsalgorithmen angewendet. <br><br>  Wichtige Punkte: <br><br><ul><li>  Auf einer der Google-Konferenzen wurde angek√ºndigt, dass m√∂glicherweise 4 Pixel mit einem Objektiv abgedeckt werden.  Dies verringert die direkte Aufl√∂sung des Sensors, verbessert jedoch die Tiefenkarte erheblich.  Erstens aufgrund des Auftretens von Stereopaaren in zwei senkrechten Richtungen und zweitens aufgrund der Tatsache, dass sich die Stereobasis bedingt um das 1,4-fache erh√∂ht (zwei Diagonalen).  Dies bedeutet auch eine deutliche Verbesserung der Tiefengenauigkeit in der Ferne. <br></li><li>  Plenoptics selbst (es ist auch ein kalkuliertes Foto) erm√∂glicht Folgendes: <br><ul><li>  Das ‚Äûehrliche‚Äú √Ñndern von Fokus und Sch√§rfentiefe nach dem Aufnehmen ist die bekannteste F√§higkeit von plenoptischen Sensoren. <br></li><li>  Blendenform berechnen. <br></li><li>  Berechnen Sie die Szenenbeleuchtung. <br></li><li>  Verschieben Sie den Aufnahmepunkt etwas, einschlie√ülich des Empfangs von Stereo (oder Multi-Angle-Frame) mit einem Objektiv. <br></li><li>  Berechnen Sie die Aufl√∂sung, da Sie mit der hohen Rechenkomplexit√§t der Super Resolution-Algorithmen den Frame tats√§chlich wiederherstellen k√∂nnen. <br></li><li>  Berechnen Sie eine Transparenzkarte f√ºr durchscheinende R√§nder. <br></li><li>  Und schlie√ülich erstellen Sie eine Tiefenkarte, die heute wichtig ist. <br></li></ul></li><li>  <b>Wenn die Hauptkamera des Telefons parallel zur Aufnahme in Echtzeit eine hochwertige Tiefenkarte erstellen kann, wird dies</b> m√∂glicherweise <b>eine Revolution ausl√∂sen</b> .  Dies h√§ngt weitgehend von der Rechenleistung an Bord ab (dies hindert uns daran, heute in Echtzeit bessere Tiefenkarten mit h√∂herer Aufl√∂sung zu erstellen).  Dies ist nat√ºrlich f√ºr AR am interessantesten, aber es gibt viele M√∂glichkeiten, Fotos zu √§ndern. <br></li></ul><br>  Und schlie√ülich fahren wir mit der letzten Methode zur √úberpr√ºfung der Tiefe fort. <br><br><h1>  Methode 5: Kameras auf Lidar-Technologien </h1><br>  Im Allgemeinen sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laser-Entfernungsmesser</a> fest in unserem Leben verankert, kosteng√ºnstig und bieten eine hohe Genauigkeit.  Die ersten Lidars (von LIDaR - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Light Identification Detection and Ranging</a> ), die als B√ºndel √§hnlicher Ger√§te gebaut wurden, die sich um eine horizontale Achse drehen, wurden zuerst vom Milit√§r verwendet und dann in Autopiloten von Autos getestet.  Sie erwiesen sich dort als recht gut, was zu einem starken Anstieg der Investitionen in der Region f√ºhrte.  Anfangs drehten sich die Lidare und ergaben mehrmals pro Sekunde ein √§hnliches Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/984/265/ed49842653721c8d7e6dae51c290166d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eine Einf√ºhrung in LIDAR: Der wichtigste selbstfahrende Autosensor</a></i> <br><br>  Es war unangenehm, aufgrund der beweglichen Teile unzuverl√§ssig und ziemlich teuer.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tony Ceba</a> liefert in seinen Vorlesungen interessante Daten zur Senkung der Lidarkosten.  Wenn Lidars f√ºr die ersten autonomen Google-Computer 70.000 US-Dollar kosten (zum Beispiel kostet der auf den ersten Computern verwendete spezialisierte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDL-64E</a> 75.000 US-Dollar): <br><img src="https://habrastorage.org/webt/w7/n4/4x/w7n44xwcg5gmcyi8v_dxc-yefd4.png"><br>  <i>Quelle: Dies und Weiter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vom Parken zu Parks - Bellevue &amp; die St√∂rung des Transports</a></i> <br><br>  In der Massenproduktion drohen dann neue Modelle der n√§chsten Generationen, den Preis deutlich unter 1000 US-Dollar zu senken: <br><img src="https://habrastorage.org/getpro/habr/post_images/178/fb1/712/178fb1712f85c4534ff25d11e54ad098.png"><br><br>  Man kann √ºber das Beispiel von Tony streiten (das Versprechen eines Startups sind nicht die endg√ºltigen Kosten), aber dass es in diesem Bereich einen Boom in der Forschung gibt, die rasche Zunahme der Produktionsl√§ufe, das Erscheinen v√∂llig neuer Produkte und ein allgemeiner Preisverfall unbestritten sind.  Wenig sp√§ter im Jahr 2017 lautete die Prognose f√ºr einen Preisverfall wie folgt (und der Moment der Wahrheit wird kommen, wenn sie massiv in Autos eingebaut werden): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d75/c6c/5b0/d75c6c5b04e509f698a5d967776ff68c.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LiDAR schlie√üt Sensing Triumvirate ab</a></i> <br><br>  Insbesondere haben vor relativ kurzer Zeit mehrere Hersteller sofort den sogenannten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Solid State Lidar auf</a> den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Markt gebracht</a> , der im Grunde keine beweglichen Teile aufweist, die eine radikal h√∂here Zuverl√§ssigkeit aufweisen, insbesondere beim Sch√ºtteln, bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">geringeren Kosten</a> usw.  Ich empfehle, dieses Video anzuschauen, in dem das Ger√§t in 84 Sekunden sehr deutlich erkl√§rt wird: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQi7J0ehKAA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Festk√∂rper-Lidarsensor</a></i> <br><br>  F√ºr uns ist wichtig, dass Solid State Lidar ein rechteckiges Bild liefert, d.h.  Tats√§chlich funktioniert es wie eine ‚Äûnormale‚Äú Tiefenkamera: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1f6/90e/e65/1f690ee65f60f431037d6c9191896005.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Innoviz sieht massenproduzierte selbstfahrende Autos mit Festk√∂rper-LiDAR vor</a></i> <br><br>  Das obige Beispiel zeigt ein Video mit ungef√§hr 1024 x 256, 25 FPS und 12 Bit pro Komponente.  Solche Lidars werden unter dem Haubengrill montiert (wenn sich das Ger√§t gut erw√§rmt): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18b/8dc/a13/18b8dca13a096a2337ad38b5728b26ea.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Festk√∂rper-LiDAR-Magna-Elektronik</a></i> <br><br>  Wie √ºblich leuchten die Chinesen, die bei der Herstellung von Elektrofahrzeugen weltweit an erster Stelle stehen und bei autonomen Autos eindeutig den ersten Platz in der Welt anstreben: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/b26/b00/c59b26b009b05ce5a872f3203c720a3d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Alibaba, RoboSense startet unbemanntes Fahrzeug mit Festk√∂rper-LIDAR</a></i> <br><br>  Insbesondere ihre Experimente mit einem nicht quadratischen ‚ÄûPixel‚Äú der Tiefe sind interessant. Wenn Sie eine gemeinsame Verarbeitung mit einer RGB-Kamera durchf√ºhren, k√∂nnen Sie die Aufl√∂sung erh√∂hen, und dies ist ein ziemlich interessanter Kompromiss (das ‚ÄûQuadrat‚Äú der Pixel ist in der Tat nur f√ºr eine Person wichtig): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7e9/13f/af2/7e913faf27197e1b893b56f13873e1d6.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MEMS Lidar f√ºr fahrerlose Fahrzeuge macht einen weiteren gro√üen Schritt</a></i> <br><br>  Lidare werden in unterschiedlichen Schemata montiert, abh√§ngig von den Kosten des Kits und der Leistung des Bordsystems, das alle diese Daten verarbeiten muss.  Dementsprechend √§ndern sich auch die allgemeinen Eigenschaften des Autopiloten.  Infolgedessen sind teurere Autos besser auf staubigen Stra√üen und k√∂nnen Autos, die an Kreuzungen an der Seite in Autos einfahren, leichter ‚Äûausweichen‚Äú. Billige Autos tragen nur dazu bei, die Anzahl der (zahlreichen) dummen Staus zu verringern: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/00d/dd1/d4e/00ddd1d4e9f980216796306e4a62fe2e.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/025/548/1df/0255481dfb9f5dcd102a9a5979ca2fb8.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7bf/842/4bf/7bf8424bf82edc861dc15434a03bfcbe.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beschreibung RoboSense RS-LiDAR-M1</a></i> <br><br>  Beachten Sie, dass niedrige Preise neben Festk√∂rpern ein paar weitere Bereiche versprechen, in denen sich Lidars entwickeln.  Hier etwas vorherzusagen ist eine undankbare Aufgabe, da zu viel nicht von den m√∂glichen technischen Eigenschaften der Technologie abh√§ngt, sondern beispielsweise von Patenten.  Es ist nur so, dass sich bereits mehrere Unternehmen mit Solid-State besch√§ftigen, daher sieht das Thema am vielversprechendsten aus.  Aber nichts √ºber den Rest zu sagen, w√§re unfair: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f9/3aa/265/3f93aa2653a9dde4393c007b925d07a2.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dieser LiDAR-Engpass 2017 verursacht einen modernen Goldrausch</a></i> <br><br>  Wenn wir von Lidars als Kameras sprechen, ist es erw√§hnenswert, ein weiteres wichtiges Merkmal zu erw√§hnen, das bei der Verwendung von Festk√∂rper-Lidars von Bedeutung ist.  Sie arbeiten von Natur aus wie Kameras mit einem bereits vergessenen beweglichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verschluss</a> , der beim Aufnehmen bewegter Objekte zu merklichen Verzerrungen f√ºhrt: <br><br><img width="66%" src="https://habrastorage.org/getpro/habr/post_images/b83/2e7/2a8/b832e72a8f8c67c65401da694df03c8e.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Was ist der Unterschied zwischen einem globalen (globalen) Verschluss und einem rollenden Verschluss</a> ?</i> <br><br>  Angesichts der Tatsache, dass sich auf der Stra√üe, insbesondere auf der Autobahn mit einer Geschwindigkeit von 150 km / h, alles recht schnell √§ndert, verzerrt diese Funktion von Lidars Objekte erheblich, einschlie√ülich solcher, die schnell auf uns zufliegen ... Einschlie√ülich der Tiefe ... Beachten Sie, dass die beiden vorherigen Methoden Tiefe zu bekommen ist kein solches Problem. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9b9/15b/979/9b915b9799869f23dcf7b2b3e1f5f1ca.gif"><br>  <i>Quelle: <a href="">Sch√∂ne Wikipedia-Animation mit Auto-Verzerrung</a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses Merkmal erfordert in Verbindung mit niedrigen FPS die Anpassung von Verarbeitungsalgorithmen, aber aufgrund der hohen Genauigkeit, auch bei gro√üen Entfernungen, haben Lidars auf keinen Fall besondere Konkurrenten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interessanterweise funktionieren Lidars von Natur aus sehr gut in ebenen Bereichen und schlechter an Grenzen, und Stereosensoren sind in geraden Bereichen schlecht und an Grenzen relativ gut. Au√üerdem ergeben Lidars eine relativ kleine FPS, und die Kameras sind viel gr√∂√üer. Infolgedessen erg√§nzen sie sich im Wesentlichen, was auch bei Lytro Cinema-Kameras verwendet wurde (auf dem Foto in der N√§he der Kamera befindet sich eine beleuchtete plenoptische Linse mit bis zu 300 FPS und </font><font style="vertical-align: inherit;">das </font><font style="vertical-align: inherit;">schwarze Quadrat von </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Malevich</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lidar </font><font style="vertical-align: inherit;">darunter </font><font style="vertical-align: inherit;">): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c1/eb9/ede/5c1eb9edeca7d67133487e93290435cd.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lytro ist bereit, das Filmemachen f√ºr immer zu ver√§ndern : deb√ºtiert auf der NAB mit dem Prototyp und dem Kurzfilm des Kinos</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn zwei Tiefensensoren in einer Filmkamera kombiniert wurden, kann bei anderen Ger√§ten (von Smartphones bis zu Autos) erwartet werden, dass die Massenverteilung von Hybridsensoren maximale Qualit√§t gew√§hrleistet. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In gewisser Weise handelt es sich bei Lidars immer noch um Investitionen, die sich in den letzten drei Jahren auf etwa 1,5 Milliarden US-Dollar beliefen (gl√ºcklicherweise wird dieser Markt </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in 6 Jahren</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auf </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">10 Milliarden</font></a><font style="vertical-align: inherit;"> US-Dollar gesch√§tzt, </font><font style="vertical-align: inherit;">und die folgende Grafik zeigt, wie die durchschnittliche Transaktionsgr√∂√üe gewachsen ist): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/fd6/3ae/e07fd63aee838e9a5c8958b0527ac4e9.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interessant M√§rz R√ºckblick auf die Trends auf dem Lidar-Markt durch Techcrunch</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Entwicklungszyklus eines innovativen Produkts selbst in hart umk√§mpften M√§rkten betr√§gt 1,5 bis 2 Jahre, sodass wir bald √§u√üerst interessante Produkte sehen werden. </font><font style="vertical-align: inherit;">Sie existieren bereits als Prototypen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wichtige Punkte:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pluspunkte von Lidars: </font></font><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die h√∂chste Genauigkeit, einschlie√ülich der besten unter allen Methoden auf gro√üe Entfernungen, </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Arbeiten Sie am besten auf ebenen Fl√§chen, auf denen die Stereoanlage nicht mehr funktioniert. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fast nicht mit der Sonne scheinen, </font></font><br></li></ul></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nachteile von Lidars: </font></font><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> hoher Stromverbrauch </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> relativ niedrige Bildrate </font></font><br></li><li> den laufenden Verschluss und die Notwendigkeit, ihn w√§hrend der Verarbeitung zu kompensieren, <br></li><li>  In der N√§he befindliche Lidare st√∂ren sich gegenseitig, was nicht so einfach zu kompensieren ist. <br></li></ul></li><li>  Trotzdem beobachten wir, wie buchst√§blich in 2 Jahren im Wesentlichen eine neue Art von Tiefenkameras mit hervorragenden Aussichten und einem riesigen potenziellen Markt entstanden ist.  In den kommenden Jahren k√∂nnen wir mit einer erheblichen Preissenkung rechnen, einschlie√ülich des Auftretens kleiner universeller Lidars f√ºr Industrieroboter. <br></li></ul><br><h1>  Videoverarbeitung mit Tiefe </h1><br>  √úberlegen Sie kurz, warum die Tiefe nicht so einfach zu handhaben ist. <br><br>  Im Folgenden finden Sie ein Beispiel f√ºr eingehende Rohdaten einer sehr guten Reihe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Intel RealSense-Kameras</a> .  An den Fingern in diesem Video k√∂nnen Sie den Betrieb der Kamera und die Verarbeitungsalgorithmen relativ einfach ‚Äûmit dem Auge‚Äú bewerten: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b2/319/b14/6b2319b143f48bdf0c57ffbe2acbc891.png"><br>  <i>Quelle: im Folgenden - die Materialien des Autors</i> <br><br>  Typische Probleme von Tiefenkameras sind deutlich sichtbar: <br><br><ul><li>  Daten sind im Wert instabil, Pixel in der Tiefe ‚ÄûRauschen‚Äú. <br></li><li>  Entlang der Grenzen √ºber eine ziemlich gro√üe Breite sind die Daten auch sehr verrauscht (aus diesem Grund maskieren sich die Tiefenwerte entlang der Grenzen oft einfach, um die Arbeit nicht zu beeintr√§chtigen). <br></li><li>  Um den Kopf herum sieht man viele "gehende" Pixel (anscheinend beginnt die N√§he zur Wand im R√ºcken + Haar zu beeinflussen). <br></li></ul><br>  Das ist aber noch nicht alles.  Wenn wir uns die Daten genauer ansehen, ist klar, dass an einigen Stellen die tieferen Daten die n√§heren ‚Äûdurchscheinen‚Äú: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a30/c5a/911/a30c5a911123f7a8f6ff8ebd8893163a.png"><br><br>  Dies liegt daran, dass das Bild zur Vereinfachung der Verarbeitung von der RGB-Kamera auf das Bild reduziert wird. Da die Grenzen nicht genau bestimmt werden, m√ºssen solche ‚Äû√úberlappungen‚Äú speziell verarbeitet werden, da sonst Probleme auftreten, wie z. B. solche ‚ÄûL√∂cher‚Äú in der Tiefe des Arms: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22f/1a3/5df/22f1a35dfdb61edcabe8a1675f5c855f.png"><br><br>  Bei der Verarbeitung treten viele Probleme auf, zum Beispiel: <br><br><ul><li>  "Leckage" der Tiefe von einem Objekt zum anderen. <br></li><li>  Instabilit√§t der Tiefe im Laufe der Zeit. <br></li><li>  Aliasing (Bildung einer "Leiter"), wenn die Unterdr√ºckung von Tiefenrauschen zur Diskretisierung von Tiefenwerten f√ºhrt: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/e3d/7a4/c10/e3d7a4c10e13824f1d79815661e17773.png"><br><br>  Es ist jedoch klar, dass sich das Bild stark verbessert hat.  Beachten Sie, dass langsamere Algorithmen die Qualit√§t immer noch erheblich verbessern k√∂nnen. <br><br>  Im Allgemeinen ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tiefenvideoverarbeitung</a> ein eigenst√§ndiges gro√ües Thema, das sich bisher nicht mit so vielen Menschen befasst, aber rasch an Popularit√§t gewinnt.  Der bisherige Markt, den sie komplett ver√§ndert hat, ist die Konvertierung von Filmen von 2D nach 3D.  Das Ergebnis der manuellen Erstellung von Stereo aus 2D-Videos verbesserte sich so schnell, zeigte ein viel vorhersehbareres Ergebnis, verursachte so weniger Kopfschmerzen und weniger Kosten, dass sie im 3D-Kino nach fast 100 Jahren Dreharbeiten (!) Ziemlich schnell fast vollst√§ndig aufh√∂rten und nur mit der Konvertierung begannen .  Es gab sogar eine eigene Spezialit√§t - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tiefenk√ºnstler</a> , und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereographen</a> der alten Schule standen unter Schock (‚Äûka-ak-a-ak?‚Äú).  Die Schl√ºsselrolle bei dieser Revolution spielte die rasche Verbesserung der Videoverarbeitungsalgorithmen.  Vielleicht werde ich eines Tages Zeit finden, eine separate Artikelserie dar√ºber zu schreiben, weil mein Material in gro√üen Mengen vorhanden ist. <br><br>  Etwa das Gleiche ist in naher Zukunft f√ºr Tiefenkameras von Robotern, Smartphones und autonomen Autos zu erwarten. <br><br>  <b>Wach auf!</b>  <b>Die Revolution kommt!</b> <br><br><h1>  Anstelle einer Schlussfolgerung </h1><br>  Vor ein paar Jahren brachte Ihr bescheidener Diener einen Vergleich verschiedener Ans√§tze, um Video mit Tiefe auf eine einzige Platte zu bringen.  Im Allgemeinen hat sich die Situation in dieser Zeit nicht ge√§ndert.  Die Trennung ist hier eher willk√ºrlich, da sich die Hersteller der Nachteile von Technologien bewusst sind und versuchen, diese auszugleichen (manchmal √§u√üerst erfolgreich).  Im Allgemeinen k√∂nnen jedoch verschiedene Ans√§tze verglichen werden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/491/11f/34d49111ff8005f743a89d9078864f1b.png"><br>  <i>Quelle: Materialien des Autors</i> <br><br>  Gehen wir √ºber den Tisch: <br><br><ul><li>  <b>Bei der Aufl√∂sung liegt die</b> Tiefe von Stereo im Vordergrund, aber alles h√§ngt sehr stark von der Szene ab (wenn es monophon ist, ist das Ding eine Pfeife). <br></li><li>  <b>In Bezug auf die Genauigkeit</b> sind Lidars un√ºbertroffen, die Situation mit der Plenoptik ist √ºbrigens die schlechteste. <br></li><li>  Aufgrund <b>der Komplexit√§t der Verarbeitung erhalten</b> nur ToF und Lidars die ‚ÄûTiefe‚Äú direkt. Um die Tiefe von Stereo und Plenoptik zu erhalten, sind viele sehr nicht triviale Berechnungen erforderlich. <br></li><li>  <b>Laut FPS sind</b> ToF-Kameras strukturell gut und werden in naher Zukunft, wenn das B√ºgeleisen hochgezogen wird, von Stereokameras eingeholt (die bis zu 300 fps liefern k√∂nnen).  Lidaram tr√§umt bisher nur davon. <br></li><li>  <b>Entsprechend den Ergebnissen bei schlechten Lichtverh√§ltnissen</b> wird erwartet <b>, dass</b> Stereo und Plenoptik verlieren. <br></li><li>  <b>Bei Arbeiten im Freien</b> - ToF- und strukturierte Lichtkameras funktionieren nicht gut. <br></li></ul><br>  Gleichzeitig ist es wichtig, die Situation in bestimmten M√§rkten gut zu verstehen.  Zum Beispiel scheint der plenoptische Ansatz deutlich hinterherzuhinken.  Wenn sich jedoch herausstellt, dass es das Beste f√ºr AR ist (und dies wird in den n√§chsten drei bis vier Jahren deutlich werden), wird es seinen rechtm√§√üigen Platz in <i>jedem</i> Telefon und Tablet einnehmen.  Es zeigt sich auch, dass Festk√∂rper-Lidars am besten aussehen (die ‚Äûgr√ºnsten‚Äú), aber dies ist die j√ºngste Technologie, und dies sind ihre eigenen Risiken, insbesondere die patentierten (auf dem Gebiet gibt es viele neue Patente, die nicht bald ablaufen werden): <br><img src="https://habrastorage.org/getpro/habr/post_images/94e/905/f90/94e905f90cdd1e525f148f983c557b00.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LiDAR: Ein √úberblick √ºber die Patentlandschaft</a></i> <br><br>  Wir vergessen jedoch nicht, dass der Markt f√ºr Tiefensensoren f√ºr Smartphones f√ºr das n√§chste Jahr auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">6 Milliarden US-Dollar</a> geplant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ist</a> und nicht weniger als 4 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">US-Dollar betragen</a> darf, da er im vergangenen Jahr mehr als 3 Milliarden US-Dollar betrug.  Dies ist eine enorme Geldsumme, die nicht nur zur Kapitalrendite (f√ºr die erfolgreichsten Investoren), sondern auch zur Entwicklung neuer Sensorgenerationen verwendet wird.  Es gibt noch kein √§hnliches Wachstum bei Lidars, aber nach allen Anzeichen wird es in den n√§chsten 3 Jahren buchst√§blich gehen.  Und dann ist dies ein gew√∂hnlicher Lawinen-√§hnlicher Exponentialprozess, der bereits mehr als einmal stattgefunden hat. <br><br>  Die nahe Zukunft der Tiefenkameras sieht √§u√üerst interessant aus! <br><br>  <b><s>Karthago muss kaputt sein ... Das</s> ganze Video wird bis Ende des Jahrhunderts dreidimensional sein!</b> <br><br>  Bleib dran! <br><br>  Wer hat nicht gelesen - der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erste Teil des Textes</a> ! <br><br><div class="spoiler">  <b class="spoiler_title">Danksagung</b> <div class="spoiler_text">  Ich m√∂chte mich herzlich bedanken bei: <br><ul><li>  Labor f√ºr Computergrafik VMK Moscow State University  MV Lomonosov f√ºr seinen Beitrag zur Entwicklung der Computergrafik in Russland und nicht nur <br></li><li>  Google, Apple und Intel f√ºr gro√üartige kompakte L√∂sungen und alle Lidar-Hersteller f√ºr schnelle Fortschritte. <br></li><li>  pers√∂nlich Konstantin Kozhemyakov, der viel getan hat, um diesen Artikel besser und visueller zu machen, <br></li><li>  und schlie√ülich vielen Dank an Roman Kazantsev, Eugene Lyapustin und Yegor Sklyarov f√ºr eine gro√üe Anzahl vern√ºnftiger Kommentare und Korrekturen, die diesen Text viel besser gemacht haben! <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458458/">https://habr.com/ru/post/de458458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458442/index.html">Warum ruft LLVM m√∂glicherweise eine nie aufgerufene Funktion auf?</a></li>
<li><a href="../de458444/index.html">Internet f√ºr den Sommerbewohner. Teil 4. Eine SIM-Karte reicht aus</a></li>
<li><a href="../de458446/index.html">Hyperscale-Rechenzentren: Wer baut sie und wie viel kosten sie?</a></li>
<li><a href="../de458450/index.html">Eigenschaften von Quantencomputern</a></li>
<li><a href="../de458454/index.html">Alexey Savvateev: Modelle des Internets und sozialer Netzwerke</a></li>
<li><a href="../de458460/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 466 (18.06.2019 - 26.06.2019)</a></li>
<li><a href="../de458462/index.html">Tauchen Sie tief in Linux-Namespaces ein</a></li>
<li><a href="../de458464/index.html">3 km Gigabit-Verbindung auf Lasermodems</a></li>
<li><a href="../de458468/index.html">Wie f√ºhre ich ein beeindruckendes Kanban-StandUp-Meeting durch?</a></li>
<li><a href="../de458470/index.html">Texturierung oder was Sie wissen m√ºssen, um ein Oberfl√§chenk√ºnstler zu werden. Teil 2. Masken und Texturen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
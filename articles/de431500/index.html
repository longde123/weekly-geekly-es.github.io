<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßïüèΩ üì¢ üíá Datenbanken und Kubernetes (R√ºckblick und Videobericht) ‚úçüèº ‚úçüèº üìò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am 8. November wurde in der Haupthalle der HighLoad ++ 2018- Konferenz im Rahmen des Abschnitts DevOps and Operations ein Bericht mit dem Titel Databa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Datenbanken und Kubernetes (R√ºckblick und Videobericht)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/431500/">  Am 8. November wurde in der Haupthalle der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++ 2018-</a> Konferenz im Rahmen des Abschnitts DevOps and Operations ein Bericht mit dem Titel Databases and Kubernetes erstellt.  Es geht um die hohe Verf√ºgbarkeit von Datenbanken und Ans√§tze zur Fehlertoleranz gegen√ºber Kubernetes und damit sowie um praktische Optionen f√ºr die Platzierung von DBMS in Kubernetes-Clustern und bestehende L√∂sungen daf√ºr (einschlie√ülich Stolon f√ºr PostgreSQL). <br><br><img src="https://habrastorage.org/webt/oq/mh/kp/oqmhkpy4pxg-olk9yybf_julwvu.jpeg"><br><br>  Aus Tradition freuen wir uns, ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Video mit einem Bericht</b></a> (ungef√§hr eine Stunde, <b>viel</b> informativer <b>als der</b> Artikel) und dem Hauptdruck in Textform zu pr√§sentieren.  Lass uns gehen! <a name="habracut"></a><br><br><h2>  Theorie </h2><br>  Dieser Bericht erschien als Antwort auf eine der beliebtesten Fragen, die uns in den letzten Jahren unerm√ºdlich an verschiedenen Orten gestellt wurden: Kommentare im Hub oder auf YouTube, in sozialen Netzwerken usw.  Es klingt einfach: "Ist es m√∂glich, die Datenbank in Kubernetes auszuf√ºhren?", Und wenn wir normalerweise mit "allgemein ja, aber ..." geantwortet haben, gab es eindeutig nicht genug Erkl√§rungen f√ºr diese "allgemein" und "aber", sondern um sie anzupassen in einer kurzen Nachricht nicht erfolgreich. <br><br>  F√ºr den Anfang fasse ich das Problem jedoch von der "Datenbank [Daten]" bis zum Stateful als Ganzes zusammen.  Ein DBMS ist nur ein Sonderfall von zustandsbehafteten Entscheidungen, von denen eine vollst√§ndigere Liste wie folgt dargestellt werden kann: <br><br><img src="https://habrastorage.org/webt/px/ps/2_/pxps2_ff80ru5qfth8bduiu_kdw.png"><br><br>  Bevor ich mich mit bestimmten F√§llen befasse, werde ich auf drei wichtige Merkmale der Arbeit / Verwendung von Kubernetes eingehen. <br><br><h3>  1. Kubernetes Hochverf√ºgbarkeitsphilosophie </h3><br>  Jeder kennt die Analogie ‚ÄûHaustiere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gegen Rinder</a> ‚Äú und versteht, dass klassische DBMS nur Haustiere sind, wenn Kubernetes eine Geschichte aus der Herdenwelt ist. <br><br>  Und wie sah die Architektur der ‚ÄûHaustiere‚Äú in der ‚Äûtraditionellen‚Äú Version aus?  Ein klassisches Beispiel f√ºr die Installation von MySQL ist die Replikation auf zwei Iron-Servern mit redundanter Stromversorgung, Festplatte, Netzwerk ... und allem anderen (einschlie√ülich eines Ingenieurs und verschiedener Hilfstools), um sicherzustellen, dass der MySQL-Prozess nicht fehlschl√§gt und wenn ein Problem mit einem der kritischen Probleme auftritt F√ºr seine Komponenten wird die Fehlertoleranz eingehalten: <br><br><img src="https://habrastorage.org/webt/0m/qg/s3/0mqgs3e3cco1zukmlah1jg2ubjs.png"><br><br>  Wie wird das gleiche in Kubernetes aussehen?  Hier gibt es normalerweise viel mehr Eisenserver, sie sind einfacher und sie haben keine redundante Stromversorgung und kein redundantes Netzwerk (in dem Sinne, dass der Verlust einer Maschine nichts beeinflusst) - all dies wird zu einem Cluster zusammengefasst.  Die Fehlertoleranz wird von der Software bereitgestellt: Wenn dem Knoten etwas passiert, erkennt Kubernetes die erforderlichen Instanzen auf dem anderen Knoten und startet sie. <br><br>  Was sind die Mechanismen f√ºr eine hohe Verf√ºgbarkeit in K8? <br><br><img src="https://habrastorage.org/webt/n2/gw/mh/n2gwmhiogm3uzv1m5igrzqpyifq.png"><br><br><ol><li>  Controller  Es gibt viele, aber zwei Hauptprobleme: <code>Deployment</code> (f√ºr zustandslose Anwendungen) und <code>StatefulSet</code> (f√ºr zustandsbehaftete Anwendungen).  Sie speichern die gesamte Logik der Aktionen, die im Falle eines Knotenabsturzes ausgef√ºhrt werden (Pod-Unzug√§nglichkeit). </li><li>  <code>PodAntiAffinity</code> - Die M√∂glichkeit, bestimmte Pods so anzugeben, dass sie sich nicht auf demselben Knoten befinden. </li><li>  <code>PodDisruptionBudgets</code> - <code>PodDisruptionBudgets</code> die Anzahl der Pod-Instanzen, die bei geplanten Arbeiten gleichzeitig <code>PodDisruptionBudgets</code> k√∂nnen. </li></ol><br><h3>  2. Kubernetes Konsistenzgarantien </h3><br>  Wie funktioniert das bekannte Single-Master-Fehlertoleranzschema?  Zwei Server (Master und Standby), auf die st√§ndig von der Anwendung zugegriffen wird, die wiederum √ºber den Load Balancer verwendet wird.  Was passiert bei einem Netzwerkproblem? <br><br><img src="https://habrastorage.org/webt/6p/1k/ve/6p1kvelnrzyrphtu6sb_agftgaa.gif"><br><br>  Klassisches <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Split-Brain</i></a> : Die Anwendung beginnt mit dem Zugriff auf beide DBMS-Instanzen, von denen sich jede als die Hauptinstanz betrachtet.  Um dies zu vermeiden, wurde keepalived durch corosync mit bereits drei Instanzen ersetzt, um bei der Abstimmung f√ºr den Master ein Quorum zu erreichen.  Selbst in diesem Fall gibt es jedoch Probleme: Wenn eine heruntergefallene DBMS-Instanz versucht, sich auf jede m√∂gliche Weise "umzubringen" (IP-Adresse entfernen, Datenbank in schreibgesch√ºtzt √ºbersetzen ...), wei√ü der andere Teil des Clusters nicht, was mit dem Master passiert ist - es kann passieren, dass dieser Knoten tats√§chlich noch funktioniert und Anforderungen an ihn gelangen, was bedeutet, dass wir den Assistenten immer noch nicht wechseln k√∂nnen. <br><br>  Um diese Situation zu l√∂sen, gibt es einen Mechanismus zum Isolieren des Knotens, um den gesamten Cluster vor fehlerhaften Vorg√§ngen zu sch√ºtzen. Dieser Vorgang wird als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>Fencing bezeichnet</i></a> .  Die praktische Essenz l√§uft darauf hinaus, dass wir mit externen Mitteln versuchen, das heruntergefallene Auto zu "t√∂ten".  Die Ans√§tze k√∂nnen unterschiedlich sein: vom Ausschalten des Computers √ºber IPMI und Blockieren des Ports am Switch bis zum Zugriff auf die API des Cloud-Anbieters usw.  Und erst nach diesem Vorgang k√∂nnen Sie den Assistenten wechseln.  Dies gew√§hrleistet eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><i>h√∂chstens einmalige</i></a> Garantie, die uns <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konsistenz</a></i> garantiert. <br><br><img src="https://habrastorage.org/webt/sl/xb/9r/slxb9rwf-lk8mcdaeqiuankz3z8.png"><br><br>  Wie kann man das auch in Kubernetes erreichen?  Zu diesem Zweck gibt es bereits erw√§hnte Controller, deren Verhalten im Falle einer Unzug√§nglichkeit eines Knotens unterschiedlich ist: <br><br><ol><li>  <code>Deployment</code> : "Mir wurde gesagt, dass es 3 Pods geben soll, und jetzt gibt es nur noch 2 Pods - ich werde einen neuen erstellen"; </li><li>  <code>StatefulSet</code> : "Pod weg?"  Ich werde warten: Entweder wird dieser Knoten zur√ºckkehren oder sie werden uns sagen, dass wir ihn t√∂ten sollen. "  Die Container selbst (ohne Bedienereingriff) werden nicht neu erstellt.  Auf diese Weise wird h√∂chstens die gleiche Garantie erreicht. </li></ol><br>  Im letzteren Fall ist jedoch ein Zaun erforderlich: Wir ben√∂tigen einen Mechanismus, der best√§tigt, dass dieser Knoten definitiv verschwunden ist.  Die automatische Ausf√ºhrung ist zum einen sehr schwierig (viele Implementierungen sind erforderlich), und zum anderen werden Knoten normalerweise nur langsam get√∂tet (der Zugriff auf IPMI kann Sekunden, zehn Sekunden oder sogar Minuten dauern).  Nur wenige Leute sind mit der Wartezeit pro Minute zufrieden, um die Basis auf den neuen Master umzustellen.  Es gibt jedoch einen anderen Ansatz, f√ºr den kein Zaunmechanismus erforderlich ist ... <br><br>  Ich werde seine Beschreibung au√üerhalb von Kubernetes beginnen.  Es verwendet einen speziellen Load Balancer, √ºber den Backends auf das DBMS zugreifen.  Seine Spezifit√§t liegt in der Tatsache, dass es die Eigenschaft der Konsistenz hat, d.h.  Schutz vor Netzwerkfehlern und Split-Brain, da Sie damit alle Verbindungen zum aktuellen Master entfernen, auf die Synchronisierung (Replikat) auf einem anderen Knoten warten und zu diesem wechseln k√∂nnen.  Ich habe keinen etablierten Begriff f√ºr diesen Ansatz gefunden und ihn als <i>konsistente Umschaltung bezeichnet</i> . <br><br><img src="https://habrastorage.org/webt/ct/oq/lk/ctoqlkp3efyctjlvsyiheesk2s4.gif"><br><br>  Die Hauptfrage bei ihm ist, wie man es universell macht und sowohl Cloud-Anbieter als auch private Installationen unterst√ºtzt.  Zu diesem Zweck werden den Anwendungen Proxyserver hinzugef√ºgt.  Jeder von ihnen akzeptiert Anfragen aus seiner Bewerbung (und leitet sie an das DBMS weiter), und von allen wird ein Quorum eingeholt.  Sobald ein Teil des Clusters ausf√§llt, entfernen die Proxys, die das Quorum verloren haben, sofort ihre Verbindungen zum DBMS. <br><br><img src="https://habrastorage.org/webt/nj/y0/-t/njy0-tahnwp8uxeyevxot_tlntq.png"><br><br><h3>  3. Datenspeicherung und Kubernetes </h3><br>  Der Hauptmechanismus ist das <i>Network Block Device</i> (auch bekannt als SAN) -Netzwerklaufwerk in verschiedenen Implementierungen f√ºr die gew√ºnschten Cloud-Optionen oder Bare Metal.  Das Einf√ºgen einer geladenen Datenbank (z. B. MySQL, f√ºr das 50.000 IOPS erforderlich sind) in die Cloud (AWS EBS) funktioniert jedoch aufgrund der <i>Latenz nicht</i> . <br><br><img src="https://habrastorage.org/webt/qq/wp/r7/qqwpr7fae-nbek0y2o6ex9lbzsa.png"><br><br>  Kubernetes kann in solchen F√§llen eine lokale Festplatte anschlie√üen - <i>Local Storage</i> .  Wenn ein Fehler auftritt (die Festplatte ist nicht mehr im Pod verf√ºgbar), m√ºssen wir diesen Computer reparieren - √§hnlich wie beim klassischen Schema bei einem Ausfall eines zuverl√§ssigen Servers. <br><br>  Beide Optionen ( <i>Netzwerkblockger√§t</i> und <i>lokaler Speicher</i> ) geh√∂ren zur Kategorie <i>ReadWriteOnce</i> : Der Speicher kann nicht an zwei Stellen (Pods) <i>bereitgestellt werden.</i> F√ºr diese Skalierung m√ºssen Sie eine neue Festplatte erstellen und mit einem neuen Pod verbinden (hierf√ºr ist ein K8s-Mechanismus integriert). und f√ºllen Sie dann die erforderlichen Daten aus (bereits von unseren Streitkr√§ften erstellt). <br><br>  Wenn wir den <i>ReadWriteMany-</i> Modus ben√∂tigen, stehen <i>Implementierungen des</i> <i>Network File System</i> (oder NAS) zur Verf√ºgung: F√ºr die √∂ffentliche Cloud sind dies <code>AzureFile</code> und <code>AWSElasticFileSystem</code> sowie f√ºr deren Installationen CephFS und Glusterfs f√ºr Fans verteilter Systeme sowie NFS. <br><br><img src="https://habrastorage.org/webt/eq/y6/gp/eqy6gpf2duz9ljtzc342bj9upg4.png"><br><br><h2>  √úbe </h2><br><h3>  1. Standalone </h3><br>  Diese Option ist der Fall, wenn Sie durch nichts daran gehindert werden, das DBMS im separaten Servermodus mit lokalem Speicher zu starten.  Von Hochverf√ºgbarkeit ist keine Rede ... obwohl sie bis zu einem gewissen Grad (d. H. Ausreichend f√ºr diese Anwendung) auf Eisenebene implementiert werden kann.  Es gibt viele F√§lle f√ºr diese Anwendung.  Zuallererst sind dies alle Arten von Staging- und Entwicklungsumgebungen, aber nicht nur: Auch sekund√§re Dienste fallen hierher. Das Deaktivieren f√ºr 15 Minuten ist nicht kritisch.  In Kubernetes wird dies von <code>StatefulSet</code> mit einem Pod implementiert: <br><br><img src="https://habrastorage.org/webt/hl/xk/ha/hlxkhaodepe50imvuobtoilrz6o.png"><br><br>  Im Allgemeinen ist dies eine praktikable Option, die aus meiner Sicht keine Nachteile hat, verglichen mit der Installation eines DBMS auf einer separaten virtuellen Maschine. <br><br><h3>  2. Repliziertes Paar mit manueller Umschaltung </h3><br>  <code>StatefulSet</code> erneut verwendet, aber das allgemeine Schema sieht folgenderma√üen aus: <br><br><img src="https://habrastorage.org/webt/vq/_i/to/vq_itonyvigrh0uezqek_lwtlt4.png"><br><br>  Wenn einer der Knoten abst√ºrzt ( <code>mysql-a-0</code> ), geschieht kein Wunder, aber wir haben eine Replik ( <code>mysql-b-0</code> ), auf die wir den Verkehr umschalten k√∂nnen.  In diesem Fall ist es wichtig, nicht nur vor dem Umschalten des Datenverkehrs zu vergessen, nicht nur DBMS-Anforderungen aus dem <code>mysql</code> Dienst zu entfernen, sondern sich auch manuell beim DBMS anzumelden und sicherzustellen, dass alle Verbindungen hergestellt sind (sie zu beenden). Au√üerdem m√ºssen Sie vom DBMS zum zweiten Knoten wechseln und das Replikat neu konfigurieren in die entgegengesetzte Richtung. <br><br>  Wenn Sie derzeit die klassische Version mit zwei Servern (Master + Standby) ohne automatisches <i>Failover verwenden</i> , entspricht diese L√∂sung Kubernetes.  Geeignet f√ºr MySQL, PostgreSQL, Redis und andere Produkte. <br><br><h3>  3. Skalieren der Leselast </h3><br>  In der Tat ist dieser Fall nicht zustandsbehaftet, weil wir nur √ºber das Lesen sprechen.  Hier befindet sich der Haupt-DBMS-Server au√üerhalb des betrachteten Schemas, und im Rahmen von Kubernetes wird eine "Farm von Slave-Servern" erstellt, die schreibgesch√ºtzt sind.  Der allgemeine Mechanismus - die Verwendung von Init-Containern zum F√ºllen von DBMS-Daten in jedem neuen Pod dieser Farm (unter Verwendung eines Hot-Dumps oder des √ºblichen Dumps mit zus√§tzlichen Aktionen usw. - h√§ngt vom verwendeten DBMS ab).  Um sicherzustellen, dass jede Instanz nicht zu weit vom Master entfernt ist, k√∂nnen Sie Lebendigkeitstests verwenden. <br><br><img src="https://habrastorage.org/webt/nz/pd/uk/nzpdukumat3zbax7vnkcs5jtsvs.png"><br><br><h3>  4. Smart Client </h3><br>  Wenn Sie ein <code>StatefulSet</code> aus drei Memcaches erstellen, bietet Kubernetes einen speziellen Service, der keine Anforderungen ausgleicht, sondern jeden Pod f√ºr seine eigene Domain erstellt.  Der Client kann mit ihnen arbeiten, wenn er selbst in der Lage ist, Shards und Replikationen durchzuf√ºhren. <br><br>  F√ºr ein Beispiel m√ºssen Sie nicht weit gehen: So funktioniert der Sitzungsspeicher in PHP sofort.  F√ºr jede Sitzungsanforderung werden Anforderungen gleichzeitig an alle Server gestellt, wonach die relevanteste Antwort aus ihnen ausgew√§hlt wird (√§hnlich wie bei einem Datensatz). <br><br><img src="https://habrastorage.org/webt/t8/iz/26/t8iz261adru0mbdw7cd2o5i3y8o.png"><br><br><h3>  5. Cloud Native-L√∂sungen </h3><br>  Es gibt viele L√∂sungen, die sich anf√§nglich auf den Ausfall von Knoten konzentrieren, d. H.  Sie selbst k√∂nnen ein <i>Failover</i> und eine Wiederherstellung von Knoten durchf√ºhren und bieten <i>Konsistenzgarantien</i> .  Dies ist keine vollst√§ndige Liste von ihnen, sondern nur ein Teil der popul√§ren Beispiele: <br><br><img src="https://habrastorage.org/webt/9u/ah/qz/9uahqzayfbdsokgyod153jwfjfs.png"><br><br>  Alle von ihnen werden einfach in <code>StatefulSet</code> platziert, wonach sich die Knoten finden und einen Cluster bilden.  Die Produkte selbst unterscheiden sich darin, wie sie drei Dinge implementieren: <br><br><ol><li>  Wie lernen Knoten voneinander?  Es gibt Methoden wie die Kubernetes-API, DNS-Eintr√§ge, statische Konfiguration, spezialisierte Knoten (Seed), die Erkennung von Diensten von Drittanbietern ... </li><li>  Wie verbindet sich der Client?  Durch einen Load Balancer, der an Hosts verteilt wird, oder der Client muss √ºber alle Hosts Bescheid wissen, und er wird entscheiden, wie er vorgehen soll. </li><li>  Wie erfolgt die horizontale Skalierung?  Auf keinen Fall voll oder schwierig / mit Einschr√§nkungen. </li></ol><br>  Unabh√§ngig von den gew√§hlten L√∂sungen f√ºr diese Probleme funktionieren alle diese Produkte gut mit Kubernetes, da sie urspr√ºnglich als "Herde" <i>(Vieh) geschaffen wurden</i> . <br><br><h3>  6. Stolon PostgreSQL </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit Stolon</a> k√∂nnen Sie PostgreSQL, das als <i>Haustier erstellt wurde</i> , in <i>Vieh</i> verwandeln.  Wie wird das erreicht? <br><br><img src="https://habrastorage.org/webt/g_/z4/pc/g_z4pcehfw6p985duphcgrbukzo.png"><br><br><ul><li>  Erstens ben√∂tigen wir eine Serviceerkennung, in deren Rolle m√∂glicherweise <b>etcd steht</b> (andere Optionen sind verf√ºgbar) - ein Cluster von ihnen wird in einem <code>StatefulSet</code> abgelegt. </li><li>  Ein weiterer Teil der Infrastruktur ist <code>StatefulSet</code> mit PostgreSQL-Instanzen.  Neben dem eigentlichen DBMS befindet sich neben jeder Installation auch eine Komponente namens <b>Keeper</b> , die die DBMS-Konfiguration ausf√ºhrt. </li><li>  Eine andere Komponente, <b>Sentinel,</b> wird als <code>Deployment</code> bereitgestellt und √ºberwacht die Konfiguration des Clusters.  Er entscheidet, wer Master und Standby sein wird, schreibt diese Informationen an etcd.  Der Keeper liest Daten aus etcd und f√ºhrt mit einer Instanz von PostgreSQL Aktionen aus, die dem aktuellen Status entsprechen. </li><li>  Eine weitere Komponente, die in <code>Deployment</code> bereitgestellt wird und PostgreSQL-Instanzen gegen√ºbersteht, <b>Proxy,</b> ist eine Implementierung des bereits erw√§hnten <i>Consistent Switchover-</i> Musters.  Diese Komponenten sind mit etcd verbunden, und wenn diese Verbindung unterbrochen wird, beendet der Proxy sofort die ausgehenden Verbindungen, da er von diesem Moment an die Rolle seines Servers nicht kennt (ist er jetzt Master oder Standby?). </li><li>  Schlie√ülich stehen Proxy-Instanzen dem √ºblichen <code>LoadBalancer</code> LoadBalancer gegen√ºber. </li></ul><br><h2>  Schlussfolgerungen </h2><br>  Ist es also m√∂glich, in Kubernetes zu stationieren?  Ja, nat√ºrlich ist es in einigen F√§llen m√∂glich ... Und wenn es angebracht ist, wird es so gemacht (siehe Stolon-Workflow) ... <br><br>  Jeder wei√ü, dass sich die Technologie in Wellen entwickelt.  Anfangs kann jedes neue Ger√§t sehr schwierig zu bedienen sein, aber im Laufe der Zeit √§ndert sich alles: Technologie wird verf√ºgbar.  Wohin gehen wir?  Ja, es wird so drinnen bleiben, aber wir werden nicht wissen, wie es funktionieren wird.  Kubernetes entwickelt aktiv <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Betreiber</a> .  Bisher gibt es nicht so viele von ihnen und sie sind nicht so gut, aber es gibt Bewegung in diese Richtung. <br><br><h2>  Videos und Folien </h2><br>  Video von der Auff√ºhrung (ca. eine Stunde): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BnegHj53pW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Pr√§sentation des Berichts: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  PS Wir haben auch im Internet einen sehr (!) Kurzen Textdruck aus diesem Bericht gefunden - danke an Nikolai Volynkin. <br><br><h2>  PPS </h2><br>  Weitere Berichte in unserem Blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberwachung und Kubernetes</a> ";  <i>(Dmitry Stolyarov; 28. Mai 2018 bei RootConf)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beste CI / CD-Praktiken mit Kubernetes und GitLab</a> ‚Äú;  <i>(Dmitry Stolyarov; 7. November 2017 bei HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unsere Erfahrung mit Kubernetes in kleinen Projekten</a> ";  <i>(Dmitry Stolyarov; 6. Juni 2017 bei RootConf)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit dapp sammeln wir Docker-Images f√ºr CI / CD schnell und bequem</a> ‚Äú <i>(Dmitry Stolyarov; 8. November 2016 bei HighLoad ++)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kontinuierliche Lieferpraktiken mit Docker</a> ‚Äú <i>(Dmitry Stolyarov; 31. Mai 2016 bei RootConf)</i> . </li></ul><br>  Sie k√∂nnten auch an folgenden Ver√∂ffentlichungen interessiert sein: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tipps und Tricks von Kubernetes: Beschleunigen des Bootstraps gro√üer Datenbanken</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CockroachDB DBMS Orchestration in Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431500/">https://habr.com/ru/post/de431500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431488/index.html">Klangmodulation</a></li>
<li><a href="../de431490/index.html">Extern - GUI f√ºr Golang</a></li>
<li><a href="../de431492/index.html">Reagieren Sie auf dem HolyJs 2018 am HeadHunter-Stand auf das Quiz des Wettbewerbs</a></li>
<li><a href="../de431496/index.html">Wie Technologie speziellen Klassenlehrern hilft</a></li>
<li><a href="../de431498/index.html">WebP wird das Web bald √ºbernehmen, aber es wird nicht lange dauern</a></li>
<li><a href="../de431502/index.html">Konferenz f√ºr iOS-Entwickler Kolesa Mobile 3.0. Videobericht</a></li>
<li><a href="../de431504/index.html">Phishing - funktioniert. Chronik des Diebstahls des iPhone XS, gefolgt von iCloud-Datendiebstahl</a></li>
<li><a href="../de431506/index.html">Xcode und erweitertes Debugging in LLDB: Teil 1</a></li>
<li><a href="../de431508/index.html">Effizientes Transaktionsmanagement im Fr√ºhjahr</a></li>
<li><a href="../de431510/index.html">So sammeln Sie Informationen aus der Kontur. Einkauf mit Selen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
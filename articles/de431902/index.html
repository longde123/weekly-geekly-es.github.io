<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíú üëÉüèº üëÜüèø Wie wir ein schnelles und zuverl√§ssiges Repository f√ºr Anzeigenansichten erstellt haben ‚úåüèø üßóüèæ üò•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine der unauff√§lligen, aber wichtigen Funktionen unserer Anzeigenseiten ist das Speichern und Anzeigen der Anzahl ihrer Aufrufe. Unsere Websites verf...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir ein schnelles und zuverl√§ssiges Repository f√ºr Anzeigenansichten erstellt haben</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/kolesa/blog/431902/"> Eine der unauff√§lligen, aber wichtigen Funktionen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserer Anzeigenseiten</a> ist das Speichern und Anzeigen der Anzahl ihrer Aufrufe.  Unsere Websites verfolgen seit √ºber 10 Jahren Anzeigenaufrufe.  Die technische Implementierung der Funktionalit√§t hat sich in dieser Zeit mehrmals ge√§ndert. Jetzt handelt es sich um einen (Mikro-) Dienst f√ºr unterwegs, der mit Redis als Cache- und Task-Warteschlange und mit MongoDB als persistentem Speicher arbeitet.  Vor einigen Jahren lernte er, nicht nur mit der Summe der Anzeigenansichten, sondern auch mit Statistiken f√ºr jeden Tag zu arbeiten.  Aber das alles hat er erst vor kurzem sehr schnell und zuverl√§ssig gelernt. <br><br><img src="https://habrastorage.org/webt/ee/nn/jp/eennjposwyrztis3a7s6cbkhq2e.png" alt="Bild"><br><br>  Insgesamt verarbeitet der Dienst ~ 300.000 Leseanforderungen und ~ 9.000 Schreibanforderungen pro Minute, von denen 99% bis zu 5 ms ausgef√ºhrt werden.  Dies sind nat√ºrlich keine astronomischen Indikatoren und kein Raketenstart auf dem Mars - aber auch keine so triviale Aufgabe, wie es eine einfache Speicherung von Zahlen erscheinen mag.  Es stellte sich heraus, dass all dies, um eine verlustfreie Datenspeicherung sicherzustellen und konsistente, relevante Werte zu lesen, einige Anstrengungen erfordert, die wir weiter unten diskutieren werden. <br><a name="habracut"></a><br><h3>  Projektaufgaben und √úbersicht </h3><br>  Obwohl Ansichtsz√§hler f√ºr das Gesch√§ft nicht so wichtig sind wie beispielsweise die Verarbeitung von Zahlungen oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kreditantr√§gen</a> , sind sie f√ºr unsere Benutzer in erster <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Linie</a> wichtig.  Die Leute sind fasziniert davon, die Popularit√§t ihrer Anzeigen zu verfolgen: Einige rufen sogar den Support an, wenn sie ungenaue Anzeigeinformationen bemerken (dies geschah bei einer der vorherigen Service-Implementierungen).  Dar√ºber hinaus speichern und zeigen wir detaillierte Statistiken in den pers√∂nlichen Konten der Benutzer an (um beispielsweise die Effektivit√§t der Nutzung kostenpflichtiger Dienste zu bewerten).  All dies sorgt daf√ºr, dass jedes Anzeigeereignis gespeichert und die relevantesten Werte angezeigt werden. <br><br>  Im Allgemeinen sehen die Funktionalit√§t und die Prinzipien des Projekts folgenderma√üen aus: <br><br><ul><li>  Die Webseite oder der Anwendungsbildschirm stellen eine Anfrage hinter den Anzeigenanzeigez√§hlern (die Anfrage ist normalerweise asynchron, um die Ausgabe grundlegender Informationen zu priorisieren).  Wenn die Seite der Anzeige selbst angezeigt wird, fordert der Kunde Sie stattdessen auf, die aktualisierte Anzahl der Aufrufe zu erh√∂hen und zur√ºckzugeben. </li><li>  Durch die Verarbeitung von Leseanforderungen versucht der Dienst, Informationen aus dem Redis-Cache abzurufen, und erg√§nzt das Unbekannte, indem er eine Anforderung an MongoDB abschlie√üt. </li><li>  Schreibanforderungen werden an zwei Strukturen im Rettich gesendet: die inkrementelle Aktualisierungswarteschlange (asynchron im Hintergrund verarbeitet) und den Cache der Gesamtzahl der Ansichten. </li><li>  Ein Hintergrundprozess im selben Dienst liest Elemente aus der Warteschlange, sammelt sie im lokalen Puffer und schreibt sie regelm√§√üig in MongoDB. </li></ul><br><h3>  Record View Counters: Fallstricke </h3><br>  Obwohl die oben beschriebenen Schritte recht einfach aussehen, besteht das Problem hier in der Organisation der Interaktion zwischen der Datenbank und den Microservice-Instanzen, damit die Daten nicht verloren gehen, nicht dupliziert werden und nicht verz√∂gert werden. <br><br>  Die Verwendung nur eines Repositorys (z. B. nur MongoDB) w√ºrde einige dieser Probleme l√∂sen.  Tats√§chlich funktionierte der Service fr√ºher, bis wir auf die Probleme der Skalierung, Stabilit√§t und Geschwindigkeit stie√üen. <br><br>  Eine naive Implementierung des Verschiebens von Daten zwischen Speichern k√∂nnte beispielsweise zu solchen Anomalien f√ºhren: <br><br><ul><li>  Datenverlust beim kompetitiven Schreiben in den Cache: <br><ol><li>  Prozess <b>A</b> erh√∂ht die Anzahl der Ansichten im Redis-Cache, stellt jedoch fest, dass f√ºr diese Entit√§t noch keine Daten vorhanden sind (es kann sich entweder um eine neue oder eine alte Deklaration handeln, die aus dem Cache extrudiert wurde). Daher muss der Prozess diesen Wert zuerst von MongoDB abrufen. <br></li><li>  Prozess <b>A</b> erh√§lt die Anzahl der Ansichten von MongoDB - zum Beispiel die Nummer 5;  f√ºgt dann 1 hinzu und schreibt an Redis <b>6</b> . </li><li>  Prozess <b>B</b> (beispielsweise von einem anderen Benutzer der Website initiiert, der ebenfalls dieselbe Anzeige eingegeben hat) f√ºhrt gleichzeitig dasselbe aus. </li><li>  Prozess <b>A</b> schreibt einen Wert von <b>6</b> in Redis. </li><li>  Prozess <b>B</b> schreibt einen Wert von <b>6</b> in Redis. </li><li>  Infolgedessen geht beim Aufzeichnen von Daten eine Ansicht aufgrund des Rennens verloren. <br>  <i>Das Szenario ist nicht so unwahrscheinlich: Wir haben beispielsweise einen kostenpflichtigen Dienst, der eine Anzeige auf der Hauptseite der Website platziert.</i>  <i>Bei einer neuen Ank√ºndigung kann ein solcher Ablauf dazu f√ºhren, dass aufgrund ihres pl√∂tzlichen Zustroms viele Ansichten gleichzeitig verloren gehen.</i> </li></ol></li><li>  Ein Beispiel f√ºr ein anderes Szenario ist der Datenverlust beim Verschieben von Ansichten von Redis nach MongoDb: <br><br><ol><li>  Der Prozess nimmt einen ausstehenden Wert von Redis auf und speichert ihn im Speicher, um sp√§ter in MongoDB zu schreiben. </li><li>  Eine Schreibanforderung schl√§gt fehl (oder der Prozess st√ºrzt ab, bevor er ausgef√ºhrt wird). </li><li>  Die Daten gehen wieder verloren, was beim n√§chsten Herausgeben des zwischengespeicherten Werts und Ersetzen durch den Wert aus der Datenbank deutlich wird. </li></ol><br></li></ul><br>  Andere Fehler k√∂nnen auftreten, deren Gr√ºnde auch in der nichtatomaren Natur von Operationen zwischen Datenbanken liegen, z. B. ein Konflikt beim L√∂schen und Erh√∂hen von Ansichten derselben Entit√§t. <br><br><h3>  Anzahl der Aufzeichnungsansichten: L√∂sung </h3><br>  Unser Ansatz zum Speichern und Verarbeiten von Daten in diesem Projekt basiert auf der Erwartung, dass MongoDB zu jedem Zeitpunkt wahrscheinlicher ausf√§llt als Redis.  Dies ist nat√ºrlich keine absolute <i>Regel</i> - zumindest nicht f√ºr jedes Projekt -, aber in unserer Umgebung sind wir es gewohnt, periodische Zeit√ºberschreitungen f√ºr Abfragen in MongoDB zu beobachten, die durch die Ausf√ºhrung von Festplattenoperationen verursacht werden, was zuvor einer der Gr√ºnde f√ºr den Verlust einiger Ereignisse war. <br><br>  Um viele der oben genannten Probleme zu vermeiden, verwenden wir Task-Warteschlangen f√ºr verz√∂gertes Speichern und Lua-Skripte, die es erm√∂glichen, Daten in mehreren Rettichstrukturen gleichzeitig atomar zu √§ndern.  In diesem Sinne lauten die Details zum Speichern von Ansichten wie folgt: <br><br><ol><li>  Wenn eine Schreibanforderung in den Microservice f√§llt, wird das Lua-Skript <b>IncrementIfExists ausgef√ºhrt</b> , um den Z√§hler nur dann zu erh√∂hen, wenn er bereits im Cache vorhanden ist.  Das Skript gibt sofort <b>-1 zur√ºck,</b> wenn keine Daten f√ºr die Entit√§t vorhanden sind, die im Rettich angezeigt wird.  Andernfalls wird der Wert der Ansichten im Cache √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HINCRBY erh√∂ht</a> , das Ereignis zur Warteschlange f√ºr die nachfolgende Speicherung in MongoDB ( <i>von</i> uns als <i>ausstehende Warteschlange bezeichnet</i> ) √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LPUSH hinzugef√ºgt</a> und die aktualisierte Anzahl von Ansichten zur√ºckgegeben. <br></li><li>  Wenn IncrementIfExists eine positive Zahl zur√ºckgibt, wird dieser Wert an den Client zur√ºckgegeben und die Anforderung endet. <br><br>  Andernfalls nimmt der Microservice den Ansichtsz√§hler von MongoDb auf, erh√∂ht ihn um 1 und sendet ihn an den Rettich. <br></li><li>  Das Schreiben auf den Rettich erfolgt √ºber ein anderes Lua-Skript - <b>Upsert</b> -, das die Gesamtzahl der Ansichten im Cache speichert, wenn dieser noch leer ist, oder um 1 erh√∂ht, wenn jemand anderes es geschafft hat, den Cache zwischen den Schritten 1 und 3 zu f√ºllen. <br></li><li>  Upsert f√ºgt der ausstehenden Warteschlange auch ein Ansichtsereignis hinzu und gibt einen aktualisierten Betrag zur√ºck, der dann an den Client gesendet wird. <br></li></ol><br>  Aufgrund der Tatsache, dass Lua-Skripte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">atomar ausgef√ºhrt werden</a> , vermeiden wir viele potenzielle Probleme, die durch ein wettbewerbsf√§higes Schreiben verursacht werden k√∂nnten. <br><br>  Ein weiteres wichtiges Detail ist die sichere √úbertragung von Updates aus der ausstehenden Warteschlange an MongoDB.  Zu diesem Zweck haben wir die in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Redis-Dokumentation</a> beschriebene Vorlage "Zuverl√§ssige Warteschlange" verwendet, die das Risiko eines Datenverlusts erheblich verringert, indem eine Kopie der verarbeiteten Elemente in einer separaten, anderen Warteschlange erstellt wird, bis sie schlie√ülich in einem dauerhaften Speicher gespeichert werden. <br><br>  Um die gesamten Prozessschritte besser zu verstehen, haben wir eine kleine Visualisierung vorbereitet.  Schauen wir uns zun√§chst ein normales, erfolgreiches Szenario an (die Schritte sind in der oberen rechten Ecke nummeriert und werden im Folgenden ausf√ºhrlich beschrieben): <br><br><img src="https://habrastorage.org/webt/0v/al/bq/0valbqz3kj6du62z0foxfcb6bay.gif" alt="Bild"><br><br><ol><li>  Der Microservice erh√§lt eine Schreibanforderung </li><li>  Der Request-Handler √ºbergibt es an ein Lua-Skript, das die Suche in den Cache schreibt (um sie sofort lesbar zu machen) und zur weiteren Verarbeitung in die Warteschlange. </li><li>  Die Hintergrund-Goroutine f√ºhrt (periodisch) die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BRPopLPush-</a> Operation aus, bei der ein Element atomar von einer Warteschlange in eine andere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verschoben wird</a> (wir nennen es "Verarbeitungswarteschlange" - eine Warteschlange mit aktuell verarbeiteten Elementen).  Das gleiche Element wird dann in einem Puffer im Prozessspeicher gespeichert. <br></li><li>  Eine weitere Schreibanforderung kommt an und wird verarbeitet, sodass 2 Elemente im Puffer und 2 Elemente in der Verarbeitungswarteschlange verbleiben. </li><li>  Nach einiger Zeit entscheidet der Hintergrundprozess, den Puffer in MongoDB zu leeren.  Das Schreiben mehrerer Werte aus dem Puffer wird von einer einzelnen Anforderung ausgef√ºhrt, was sich positiv auf den Durchsatz auswirkt.  Au√üerdem versucht der Prozess vor der Aufzeichnung, mehrere Ansichten zu einer zusammenzufassen und deren Werte f√ºr dieselben Anzeigen zusammenzufassen. <br>  <i>In jedem unserer Projekte werden 3 Microservice-Instanzen mit jeweils einem eigenen Puffer verwendet, der alle 2 Sekunden in der Datenbank gespeichert wird.</i>  <i>W√§hrend dieser Zeit werden ungef√§hr 100 Elemente in einem Puffer akkumuliert.</i> <i><br></i> </li><li>  Nach einem erfolgreichen Schreibvorgang entfernt der Prozess Elemente aus der Verarbeitungswarteschlange und signalisiert, dass die Verarbeitung erfolgreich abgeschlossen wurde. <br></li></ol><br>  Wenn alle Subsysteme in Ordnung sind, scheinen einige dieser Schritte redundant zu sein.  Und der aufmerksame Leser hat m√∂glicherweise auch eine Frage dazu, was der Gopher in der unteren linken Ecke tut. <br>  Alles wird erkl√§rt, wenn man das Szenario betrachtet, in dem MongoDB nicht verf√ºgbar ist: <br><br><img src="https://habrastorage.org/webt/hl/jd/bs/hljdbsmwzxn6i2k5xfgj2mm02em.gif" alt="Ein Beispiel f√ºr einen Dienst, wenn MongoDB abst√ºrzt"><br><br><ol><li>  Der erste Schritt ist identisch mit den Ereignissen aus dem vorherigen Szenario: Der Dienst empf√§ngt zwei Anforderungen zum Aufzeichnen und Verarbeiten von Ansichten. <br></li><li>  Der Prozess verliert die Verbindung zu MongoDB (der Prozess selbst wei√ü dies nat√ºrlich noch nicht). <br>  Der Gorutin-Handler versucht nach wie vor, seinen Puffer in die Datenbank zu leeren - diesmal jedoch ohne Erfolg.  Sie wartet wieder auf die n√§chste Iteration. <br></li><li>  Eine andere Hintergrund-Goroutine wacht auf und √ºberpr√ºft die Verarbeitungswarteschlange.  Sie entdeckt, dass die Elemente ihr vor langer Zeit hinzugef√ºgt wurden;  Als sie zu dem Schluss kommt, dass ihre Verarbeitung fehlgeschlagen ist, verschiebt sie sie zur√ºck in die ausstehende Warteschlange. <br></li><li>  Nach einer Weile wird die Verbindung mit MongoDB wiederhergestellt. <br></li><li>  Die erste Hintergrund-Goroutine versucht erneut, eine Schreiboperation auszuf√ºhren - diesmal erfolgreich - und entfernt schlie√ülich Elemente dauerhaft aus der Verarbeitungswarteschlange. <br></li></ol><br>  In diesem Schema gibt es mehrere wichtige Zeit√ºberschreitungen und Heuristiken, die durch Tests und gesunden Menschenverstand abgeleitet wurden: Beispielsweise werden Elemente nach 15 Minuten Inaktivit√§t von der Verarbeitungswarteschlange zur√ºck in die ausstehende Warteschlange verschoben.  Dar√ºber hinaus f√ºhrt die f√ºr diese Aufgabe verantwortliche Goroutine vor der Ausf√ºhrung eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sperre durch,</a> damit mehrere Instanzen des Mikrodienstes nicht gleichzeitig versuchen, die "eingefrorenen" Ansichten wiederherzustellen. <br><br>  Genau genommen bieten selbst diese Ma√ünahmen keine theoretisch fundierten Garantien (zum Beispiel ignorieren wir Szenarien wie das Einfrieren des Prozesses f√ºr 15 Minuten) - aber in der Praxis funktioniert dies recht zuverl√§ssig. <br><br>  Auch in diesem Schema sind uns mindestens zwei weitere Sicherheitsl√ºcken bekannt, deren Kenntnis wichtig ist: <br><br><ul><li>  Wenn der Microservice unmittelbar nach dem erfolgreichen Speichern in MongoDb, jedoch vor dem L√∂schen der Verarbeitungswarteschlangenliste abgest√ºrzt ist, werden diese Daten als nicht gespeichert betrachtet und nach 15 Minuten erneut gespeichert. <br>  <i>Um die Wahrscheinlichkeit eines solchen Szenarios zu verringern, haben wir wiederholt versucht, bei Fehlern aus der Verarbeitungswarteschlange zu entfernen.</i>  <i>In der Realit√§t haben wir solche F√§lle in der Produktion noch nicht beobachtet.</i> <br></li><li>  Beim Neustart kann der Rettich nicht nur den Cache verlieren, sondern auch einige nicht gespeicherte Ansichten aus den Warteschlangen, da er so konfiguriert ist, dass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RDB-Snapshots</a> regelm√§√üig alle paar Minuten gespeichert werden. <br>  <i>Obwohl dies theoretisch ein ernstes Problem sein kann (insbesondere wenn sich das Projekt mit wirklich kritischen Daten befasst), werden Knoten in der Praxis √§u√üerst selten neu gestartet.</i>  <i>Gleichzeitig verbringen Elemente laut √úberwachung weniger als 3 Sekunden in Warteschlangen, dh die m√∂glichen Verluste sind sehr begrenzt.</i> <br></li></ul><br>  Es scheint, dass es mehr Probleme gibt, als wir m√∂chten.  Tats√§chlich stellt sich jedoch heraus, dass das Szenario, gegen das wir uns urspr√ºnglich verteidigt haben - das Scheitern von MongoDB - tats√§chlich eine viel realere Bedrohung darstellt und das neue Datenverarbeitungsschema die Verf√ºgbarkeit des Dienstes erfolgreich sicherstellt und Verluste verhindert. <br><br>  Ein anschauliches Beispiel daf√ºr war, als die MongoDB-Instanz bei einem der Projekte die ganze Nacht √ºber absurd nicht verf√ºgbar war.  W√§hrend dieser ganzen Zeit sammelten sich die Anzahl der Ansichten und drehten sich im Rettich von einer Warteschlange zur n√§chsten, bis sie nach Behebung des Vorfalls schlie√ülich in der Datenbank gespeichert wurden.  Die meisten Benutzer haben den Fehler nicht einmal bemerkt. <br><br><h3>  Leseansicht z√§hlt </h3><br>  Leseanforderungen sind viel einfacher als Schreibanforderungen: Der Microservice √ºberpr√ºft zuerst den Cache im Rettich.  Alles, was nicht im Cache gefunden wird, wird mit Daten aus MongoDb gef√ºllt und an den Client zur√ºckgegeben. <br><br>  W√§hrend der Lesevorg√§nge wird nicht durchgehend in den Cache geschrieben, um den Aufwand f√ºr den Schutz vor wettbewerbsf√§higen Schreibvorg√§ngen zu vermeiden.  Die Trefferquote des Caches bleibt gut, da er h√§ufig dank anderer Schreibanforderungen bereits aufgew√§rmt wird. <br><br>  T√§gliche Ansichtsstatistiken werden direkt aus MongoDB gelesen, da sie viel seltener angefordert werden und das Zwischenspeichern schwieriger ist.  Dies bedeutet auch, dass das Lesen von Statistiken nicht mehr funktioniert, wenn die Datenbank nicht verf√ºgbar ist.  Es betrifft jedoch nur einen kleinen Teil der Benutzer. <br><br><h3>  MongoDB-Datenspeicherungsschema </h3><br>  Das MongoDB-Erfassungsschema f√ºr das Projekt basiert auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesen Empfehlungen der Datenbankentwickler selbst</a> und sieht folgenderma√üen aus: <br><br><ul><li>  Ansichten werden in 2 Sammlungen gespeichert: in einer gibt es ihren Gesamtbetrag, in der anderen - Statistiken nach Tag. <br></li><li>  Die Daten in der Statistiksammlung basieren auf <b>einem Dokument pro Anzeige und Monat</b> .  Bei neuen Ank√ºndigungen wird ein Dokument mit einunddrei√üig Null f√ºr den aktuellen Monat in die Sammlung eingef√ºgt.  Gem√§√ü dem oben genannten Artikel k√∂nnen Sie so sofort gen√ºgend Speicherplatz f√ºr ein Dokument auf der Festplatte zuweisen, sodass die Datenbank es beim Hinzuf√ºgen von Daten nicht verschieben muss. <br>  <i>Dieser Punkt macht das Lesen von Statistiken etwas umst√§ndlich (Anfragen m√ºssen auf der Microservice-Seite monatelang generiert werden), aber insgesamt bleibt das Schema recht intuitiv.</i> <br></li><li>  Die <b>Upsert-</b> Operation wird zum Aufzeichnen verwendet, um innerhalb derselben Anforderung ein Dokument f√ºr die gew√ºnschte Entit√§t zu aktualisieren und gegebenenfalls zu erstellen. <br></li></ul><br>  Wir verwenden die Transaktionsfunktionen von MongoDb nicht, um mehrere Sammlungen gleichzeitig zu aktualisieren. Dies bedeutet, dass wir das Risiko eingehen, dass die Daten nur in eine Sammlung geschrieben werden k√∂nnen.  Vorerst melden wir uns einfach in solchen F√§llen an;  Es gibt nur wenige davon, und dies stellt bislang nicht das gleiche signifikante Problem dar wie andere Szenarien. <br><br><h3>  Testen </h3><br>  Ich w√ºrde meinen eigenen Worten nicht vertrauen, dass die beschriebenen Szenarien wirklich funktionieren, wenn sie nicht durch Tests abgedeckt w√ºrden. <br><br>  Da der gr√∂√üte Teil des Projektcodes eng mit Radieschen und MongoDb zusammenarbeitet, handelt es sich bei den meisten darin enthaltenen Tests um Integrationstests.  Die Testumgebung wird durch Docker-Compose unterst√ºtzt, was bedeutet, dass sie schnell bereitgestellt werden kann, Reproduzierbarkeit durch Zur√ºcksetzen und Wiederherstellen des Status bei jedem Start bietet und das Experimentieren erm√∂glicht, ohne die Datenbanken anderer Personen zu beeintr√§chtigen. <br><br>  In diesem Projekt gibt es drei Haupttestbereiche: <br><br><ol><li>  Validierung der Gesch√§ftslogik in typischen Szenarien, den sogenannten  Gl√ºckspfad.  Diese Tests beantworten die Frage: Wenn alle Subsysteme in Ordnung sind, funktioniert der Service gem√§√ü den funktionalen Anforderungen? </li><li>  √úberpr√ºfen negativer Szenarien, in denen der Dienst voraussichtlich seine Arbeit fortsetzen wird.  Verliert der Dienst beispielsweise wirklich keine Daten, wenn MongoDb abst√ºrzt? <br>  Sind wir sicher, dass die Informationen mit regelm√§√üigen Zeit√ºberschreitungen, Einfrierungen und wettbewerbsf√§higen Aufzeichnungsvorg√§ngen √ºbereinstimmen? </li><li>  √úberpr√ºfen Sie negative Szenarien, in denen wir nicht erwarten, dass der Dienst fortgesetzt wird, aber dennoch ein Mindestma√ü an Funktionalit√§t bereitgestellt werden sollte.  Beispielsweise besteht keine Chance, dass der Dienst weiterhin Daten speichert und weitergibt, wenn weder Rettich noch Mongo verf√ºgbar sind. Wir m√∂chten jedoch sicherstellen, dass er in solchen F√§llen nicht abst√ºrzt, sondern eine Systemwiederherstellung erwartet und dann wieder funktioniert. </li></ol><br>  Um nach erfolglosen Szenarien zu suchen, arbeitet der Service Business Logic Code mit den Datenbank-Client-Schnittstellen, die in den erforderlichen Tests durch Implementierungen ersetzt werden, die Fehler zur√ºckgeben und / oder Netzwerkverz√∂gerungen simulieren.  Wir simulieren auch den Parallelbetrieb mehrerer Dienstinstanzen mithilfe des Musters " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Umgebungsobjekt</a> ".  Dies ist eine Variante des bekannten "Control Inversion" -Ansatzes, bei dem Funktionen nicht auf die Abh√§ngigkeiten selbst zugreifen, sondern sie √ºber das in den Argumenten √ºbergebene Umgebungsobjekt empfangen.  Mit diesem Ansatz k√∂nnen Sie unter anderem mehrere unabh√§ngige Kopien des Dienstes in einem Test simulieren, von denen jede √ºber einen eigenen Pool von Verbindungen zur Datenbank verf√ºgt und die Produktionsumgebung mehr oder weniger effizient reproduziert.  Einige Tests f√ºhren jede dieser Instanzen parallel aus und stellen sicher, dass alle dieselben Daten sehen und keine Rennbedingungen vorliegen. <br><br>  Wir haben auch einen rudiment√§ren, aber immer noch recht n√ºtzlichen Stresstest durchgef√ºhrt <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Belagerung</a> , die dazu beitrug, die zul√§ssige Last und die Reaktionsgeschwindigkeit des Dienstes grob abzusch√§tzen. <br><br><h3>  √úber die Leistung </h3><br>  Bei 90% der Anfragen ist die Verarbeitungszeit sehr gering und vor allem stabil.  Hier ist ein Beispiel f√ºr Messungen an einem der Projekte √ºber mehrere Tage: <br><br><img src="https://habrastorage.org/webt/ln/bk/zy/lnbkzy7-wnykbaelv4vzsd8b53q.png" alt="Bild"><br><br>  Interessanterweise ist ein Datensatz (der eigentlich eine Schreib- + Leseoperation ist, da er aktualisierte Werte zur√ºckgibt) etwas schneller als das Lesen (jedoch nur aus der Sicht eines Clients, der den tats√§chlich ausstehenden Schreibvorgang nicht beobachtet). <br>  Eine regelm√§√üige Zunahme der Verz√∂gerungen am Morgen ist ein Nebeneffekt der Arbeit unseres Analyseteams, das t√§glich eigene Statistiken auf der Grundlage der Daten des Dienstes sammelt und so eine ‚Äûk√ºnstliche Hochlast‚Äú f√ºr uns schafft. <br><br>      :           (          ‚Äî          MongoDB),       (      ),     : <br><br><img src="https://habrastorage.org/webt/6f/pz/v9/6fpzv9b8lmswdsjhmrn4gk_qugw.png" alt="Bild"><br><br><h3>  Fazit </h3><br> ,  -  , ,   Redis                . <br><br>       , 95%    ,     .      ,                .           5. <br><br>        Go, Redis  MongoDB             .                 ,       .         ,      ‚Äî      . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431902/">https://habr.com/ru/post/de431902/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431888/index.html">‚ÄûIch denke, Teamideen sind bei der Entwicklung eines Produkts am wichtigsten.‚Äú</a></li>
<li><a href="../de431890/index.html">So geben Sie eine Bestellung an der freiberuflichen B√∂rse auf</a></li>
<li><a href="../de431892/index.html">Wir verwenden Veeam Backup & Replication, um neue Systeme und Anwendungen vor dem Upgrade zu testen</a></li>
<li><a href="../de431894/index.html">Im Dezember werden sie √ºber die obligatorische Registrierung von LPWAN-Basisstationen entscheiden</a></li>
<li><a href="../de431898/index.html">Alles dreht sich um Agile - 2: Agile Implementierungsfunktionen</a></li>
<li><a href="../de431904/index.html">Wie wir HR-Spezialisten entladen haben: Informationen zur Ausstellung von Zahlungsb√∂gen</a></li>
<li><a href="../de431906/index.html">PIFR - eine Methode zur Erzeugung einer 3D-Maske, unabh√§ngig vom Drehwinkel des Gesichts</a></li>
<li><a href="../de431908/index.html">Einrichten der Tinkoff Bank API. Wie ist deine Intuition ....? Oder ein Lied √ºber Oauth 2.0</a></li>
<li><a href="../de431910/index.html">PSEFABRIC - ein neuer Ansatz f√ºr Netzwerkmanagement und -automatisierung. Schritt zum Ideal</a></li>
<li><a href="../de431912/index.html">Der gr√∂√üte Bot-No wurde in den USA festgenommen: Was bedeutet das f√ºr die digitale Community?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
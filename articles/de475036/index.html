<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👍 🚶🏾 🧕🏾 Cassandra-Migration zu Kubernetes: Funktionen und Lösungen ◻️ 👞 🐋</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir begegnen regelmäßig der Apache Cassandra-Datenbank und der Notwendigkeit, sie im Rahmen der auf Kubernetes basierenden Infrastruktur zu betreiben....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cassandra-Migration zu Kubernetes: Funktionen und Lösungen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/475036/"><img src="https://habrastorage.org/webt/5a/mf/ts/5amftsu06d04r-vmvx9to725ss0.png"><br><br>  Wir begegnen regelmäßig der Apache Cassandra-Datenbank und der Notwendigkeit, sie im Rahmen der auf Kubernetes basierenden Infrastruktur zu betreiben.  In diesem Artikel werden wir unsere Vision der notwendigen Schritte, Kriterien und vorhandenen Lösungen (einschließlich einer Übersicht der Bediener) für die Migration von Cassandra zu K8s teilen. <a name="habracut"></a><br><br><h2>  „Wer eine Frau kontrollieren kann, kommt mit dem Staat klar“ </h2><br>  Wer ist Cassandra?  Es handelt sich um ein verteiltes Speichersystem, mit dem große Datenmengen verwaltet und gleichzeitig eine hohe Verfügbarkeit ohne einen einzigen Ausfallpunkt gewährleistet werden kann.  Das Projekt braucht kaum eine lange Einführung, deshalb werde ich nur die Hauptmerkmale von Cassandra nennen, die im Zusammenhang mit einem bestimmten Artikel relevant sind: <br><br><ul><li>  Cassandra ist in Java geschrieben. </li><li>  Die Cassandra-Topologie umfasst mehrere Ebenen: <ul><li>  Knoten - eine bereitgestellte Instanz von Cassandra; </li><li>  Rack - Eine Gruppe von Cassandra-Instanzen, die durch ein Attribut in einem Rechenzentrum zusammengefasst sind. </li><li>  Rechenzentrum - die Gesamtheit aller Gruppen von Cassandra-Instanzen in einem Rechenzentrum; </li><li>  Cluster - eine Sammlung aller Rechenzentren. </li></ul></li><li>  Cassandra verwendet eine IP-Adresse, um den Host zu identifizieren. </li><li>  Um Lese- und Schreibvorgänge zu beschleunigen, speichert Cassandra einen Teil der Daten im RAM. </li></ul><br>  Nun zum eigentlichen möglichen Wechsel zu Kubernetes. <br><br><h2>  Checkliste für die Migration </h2><br>  Wenn wir über die Migration von Cassandra nach Kubernetes sprechen, hoffen wir, dass es bequemer wird, sie mit dem Umzug zu verwalten.  Was wird dafür benötigt, was hilft dabei? <br><br><h3>  1. Datenspeicherung </h3><br>  Wie bereits angegeben, speichert <i>Cassanda einen</i> Teil der Daten im RAM - in <i>Memtable</i> .  Es gibt jedoch noch ein anderes Datenelement, das auf der Festplatte gespeichert wird - in Form von <i>SSTable</i> .  Zu diesen Daten wird das Entity <i>Log Log</i> hinzugefügt - Aufzeichnungen aller Transaktionen, die ebenfalls auf der Festplatte gespeichert sind. <br><br><img src="https://habrastorage.org/webt/2g/2e/ck/2g2eck2szmozuahdx4oinucww9o.png"><br>  <i>Cassandra Write Transaction Scheme</i> <br><br>  In Kubernetes können wir PersistentVolume zum Speichern von Daten verwenden.  Dank gut entwickelter Mechanismen wird die Arbeit mit Daten in Kubernetes von Jahr zu Jahr einfacher. <br><br><img src="https://habrastorage.org/webt/3f/_6/eh/3f_6eh1n50l6dofpd9pds9s4ewg.png"><br>  <i>Für jeden Pod mit Cassandra ordnen wir unser PersistentVolume zu</i> <br><br>  Es ist wichtig zu beachten, dass Cassandra selbst die Datenreplikation impliziert und dafür eingebaute Mechanismen bietet.  Wenn Sie einen Cassandra-Cluster aus einer großen Anzahl von Knoten erstellen, müssen Sie daher keine verteilten Systeme wie Ceph oder GlusterFS zum Speichern von Daten verwenden.  In diesem Fall ist es logisch, Daten auf dem Host-Datenträger mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lokalen persistenten Datenträgern zu speichern</a> oder <code>hostPath</code> . <br><br>  Eine weitere Frage ist, ob Sie für jeden Feature-Zweig eine eigene Entwicklungsumgebung erstellen möchten.  In diesem Fall wäre der richtige Ansatz, einen Cassandra-Knoten auszulösen und die Daten in einem verteilten Speicher zu speichern, d. H.  Erwähntes Ceph und GlusterFS sind Ihre Wahl.  Dann ist der Entwickler sicher, dass er auch dann keine Testdaten verliert, wenn einer der Knoten des Kuberntes-Clusters verloren geht. <br><br><h3>  2. Überwachung </h3><br>  Prometheus ist für die Überwachung in Kubernetes praktisch keine Alternative <i>(darüber haben wir im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">entsprechenden Bericht</a> ausführlich gesprochen)</i> .  Wie geht es Cassandra mit metrischen Exporteuren für Prometheus?  Und was ist in gewisser Weise noch wichtiger, mit Dashboards, die für Grafana geeignet sind? <br><br><img src="https://habrastorage.org/webt/g0/vq/et/g0vqetugsowufigbskokdr74_2q.png"><br>  <i>Ein Beispiel für die Darstellung von Diagrammen in Grafana für Cassandra</i> <br><br>  Es gibt nur zwei Exporteure: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">jmx_exporter</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cassandra_exporter</a> . <br><br>  Wir haben die erste für uns ausgewählt, weil: <br><br><ol><li>  JMX Exporter wächst und entwickelt sich, während Cassandra Exporter nicht in der Lage war, die richtige Community-Unterstützung zu erhalten.  Cassandra Exporter unterstützt die meisten Versionen von Cassandra immer noch nicht. </li><li>  Sie können es als javaagent ausführen, indem Sie das Flag -javaagent hinzufügen <code>-javaagent:&lt;plugin-dir-name&gt;/cassandra-exporter.jar=--listen=:9180</code> . </li><li>  Für ihn gibt es ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">passendes Dashboad</a> , das mit Cassandra Exporter nicht kompatibel ist. </li></ol><br><h3>  3. Auswahl von Kubernetes-Primitiven </h3><br>  Entsprechend der obigen Struktur des Cassandra-Clusters werden wir versuchen, alles, was dort beschrieben wird, in die Kubernetes-Terminologie zu übersetzen: <br><br><ul><li>  Cassandra Node → Pod </li><li>  Cassandra Rack → StatefulSet </li><li>  Cassandra Datacenter → Pool von StatefulSets </li><li>  Cassandra Cluster → ??? </li></ul><br>  Es stellt sich heraus, dass eine zusätzliche Entität fehlt, um den gesamten Cassandra-Cluster auf einmal zu verwalten.  Aber wenn etwas nicht da ist, können wir es schaffen!  Kubernetes verfügt über eine dedizierte Ressourcendefinitions-Engine namens " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benutzerdefinierte Ressourcendefinitionen"</a> . <br><br><img src="https://habrastorage.org/webt/pt/ob/st/ptobst6r86hra1aakwvpcypws8e.png"><br>  <i>Ankündigung zusätzlicher Ressourcen für Protokolle und Warnungen</i> <br><br>  Eine benutzerdefinierte Ressource allein bedeutet jedoch nichts: Sie benötigen einen <b>Controller</b> dafür.  Möglicherweise müssen Sie auf die Hilfe eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes-Betreibers</a> zurückgreifen ... <br><br><h3>  4. Identifizierung der Hülsen </h3><br>  Im obigen Punkt haben wir vereinbart, dass ein Cassandra-Knoten einem Pod in Kubernetes entspricht.  Die IP-Adressen des Pods sind jedoch jedes Mal anders.  Und die Knotenidentifikation in Cassandra erfolgt genau anhand der IP-Adresse ... Es stellt sich heraus, dass der Cassandra-Cluster nach jedem Entfernen des Pods einen neuen Knoten hinzufügt. <br><br>  Es gibt einen Ausweg und nicht einmal einen: <br><br><ol><li>  Wir können Aufzeichnungen nach Host-IDs (UUIDs, die Cassandra-Instanzen eindeutig identifizieren) oder nach IP-Adressen führen und dies in einigen Strukturen / Tabellen speichern.  Das Verfahren hat zwei Hauptnachteile: <br><br><ul><li>  Das Risiko eines Rennzustands, wenn zwei Knoten gleichzeitig fallen.  Nach dem Upgrade fordern die Cassandra-Knoten gleichzeitig eine IP-Adresse für sich selbst aus der Tabelle an und konkurrieren um dieselbe Ressource. </li><li>  Wenn der Cassandra-Knoten seine Daten verloren hat, können wir sie nicht mehr identifizieren. </li></ul></li><li>  Die zweite Lösung scheint ein kleiner Hack zu sein, aber dennoch: Wir können einen Service mit ClusterIP für jeden Cassandra-Knoten erstellen.  Probleme mit dieser Implementierung: <br><br><ul><li>  Wenn ein Cassandra-Cluster viele Knoten enthält, müssen viele Dienste erstellt werden. </li><li>  Die ClusterIP-Funktion wird über iptables implementiert.  Dies kann ein Problem sein, wenn der Cassandra-Cluster viele (1000 ... oder sogar 100?) Knoten hat.  Ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf IPVS basierendes Balancing</a> kann dieses Problem zwar lösen. </li></ul></li><li>  Die dritte Lösung ist die Verwendung eines Knotennetzwerks für Cassandra-Knoten anstelle eines dedizierten Pod-Netzwerks, indem die Einstellung <code>hostNetwork: true</code> .  Diese Methode unterwirft bestimmte Einschränkungen: <br><br><ul><li>  Knoten ersetzen.  Es ist erforderlich, dass der neue Host dieselbe IP-Adresse wie der vorherige Host hat (in Clouds wie AWS oder GCP ist dies fast unmöglich). </li><li>  Unter Verwendung des Netzwerks von Clusterknoten beginnen wir, um Netzwerkressourcen zu konkurrieren.  Daher ist es problematisch, mit Cassandra auf einem Clusterknoten mehr als einen Pod zu installieren. </li></ul></li></ol><br><h3>  5. Backups </h3><br>  Wir möchten die Vollversion der Daten für einen Cassandra-Knoten nach einem Zeitplan aufbewahren.  Kubernetes bietet mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CronJob</a> eine bequeme Möglichkeit, aber hier steckt Cassandra die Stöcke in die Räder. <br><br>  Lassen Sie mich daran erinnern, dass ein Teil der Daten von Cassandra im Speicher abgelegt wird.  Um eine vollständige Sicherung zu erstellen, müssen Sie Daten vom Speicher ( <i>Memtables</i> ) auf die Festplatte ( <i>SSTables</i> ) übertragen.  Zu diesem Zeitpunkt akzeptiert der Cassandra-Knoten keine Verbindungen mehr und fährt den Cluster vollständig herunter. <br><br>  Danach wird ein Backup ( <i>Snapshot</i> ) entfernt und das Schema ( <i>Keyspace</i> ) <i>gespeichert</i> .  Und dann stellt sich heraus, dass nur eine Sicherung nichts bringt: Sie müssen die Daten-IDs speichern, für die der Cassandra-Knoten verantwortlich war - dies sind spezielle Token. <br><br><img src="https://habrastorage.org/webt/ve/el/00/veel00wgdubtmtyhjn2gh9kx4rw.png"><br>  <i>Token-Verteilung, um zu identifizieren, welche Daten für die Cassandra-Knoten verantwortlich sind</i> <br><br>  Ein Beispielskript zum Entfernen von Cassandra aus Google in Kubernetes finden Sie unter <a href="">diesem Link</a> .  Der einzige Punkt, den das Skript nicht berücksichtigt, ist das Speichern der Daten auf dem Knoten, bevor der Snapshot entfernt wird.  Das heißt, die Sicherung erfolgt nicht für den aktuellen Status, sondern für den Status etwas früher.  Dies hilft jedoch, den Knoten nicht aus der Arbeit zu bringen, was sehr logisch erscheint. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">set</span></span> -eu <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [[ -z <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> ]]; <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> info <span class="hljs-string"><span class="hljs-string">"Please provide a keyspace"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> 1 <span class="hljs-keyword"><span class="hljs-keyword">fi</span></span> KEYSPACE=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> result=$(nodetool snapshot <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${KEYSPACE}</span></span></span><span class="hljs-string">"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [[ $? -ne 0 ]]; <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"Error while making snapshot"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> 1 <span class="hljs-keyword"><span class="hljs-keyword">fi</span></span> timestamp=$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$result</span></span></span><span class="hljs-string">"</span></span> | awk <span class="hljs-string"><span class="hljs-string">'/Snapshot directory: / { print $3 }'</span></span>) mkdir -p /tmp/backup <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> path <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> $(find <span class="hljs-string"><span class="hljs-string">"/var/lib/cassandra/data/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${KEYSPACE}</span></span></span><span class="hljs-string">"</span></span> -name <span class="hljs-variable"><span class="hljs-variable">$timestamp</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> table=$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${path}</span></span></span><span class="hljs-string">"</span></span> | awk -F <span class="hljs-string"><span class="hljs-string">"[/-]"</span></span> <span class="hljs-string"><span class="hljs-string">'{print $7}'</span></span>) mkdir /tmp/backup/<span class="hljs-variable"><span class="hljs-variable">$table</span></span> mv <span class="hljs-variable"><span class="hljs-variable">$path</span></span> /tmp/backup/<span class="hljs-variable"><span class="hljs-variable">$table</span></span> <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> tar -zcf /tmp/backup.tar.gz -C /tmp/backup . nodetool clearsnapshot <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${KEYSPACE}</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br>  <i>Beispiel für ein Bash-Skript zum Entfernen der Sicherung von einem einzelnen Cassandra-Knoten</i> <br><br><h2>  Vorgefertigte Lösungen für Cassandra in Kubernetes </h2><br>  Was verwenden sie derzeit, um Cassandra in Kubernetes bereitzustellen, und welches davon ist für die gegebenen Anforderungen am besten geeignet? <br><br><h3>  1. StatefulSet- oder Helm Chart-Lösungen </h3><br>  Die Verwendung der grundlegenden StatefulSets zum Starten eines Cassandra-Clusters ist eine gute Option.  Mit den Vorlagen Helm-Diagramm und Go können Sie dem Benutzer eine flexible Oberfläche für die Bereitstellung von Cassandra bereitstellen. <br><br>  Normalerweise funktioniert dies einwandfrei ... bis etwas Unerwartetes passiert - zum Beispiel ein Knoten fällt aus.  Die Standard-Kubernetes-Tools können einfach nicht alle oben genannten Funktionen berücksichtigen.  Darüber hinaus ist dieser Ansatz sehr begrenzt, da er für komplexere Zwecke erweitert werden kann: Austausch von Knoten, Sicherung, Wiederherstellung, Überwachung usw. <br><br>  Vertreter: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Karte aus dem Hauptlager von Helm</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grafik von bitnami</a> . </li></ul><br>  Beide Diagramme sind gleich gut, aber anfällig für die oben beschriebenen Probleme. <br><br><h3>  2. Lösungen basierend auf Kubernetes Operator </h3><br>  Solche Optionen sind interessanter, da sie umfangreiche Funktionen zur Clusterverwaltung bieten.  Um eine Cassandra-Anweisung wie jede andere Datenbank zu entwerfen, sieht ein gutes Muster aus wie Sidecar &lt;-&gt; Controller &lt;-&gt; CRD: <br><br><img src="https://habrastorage.org/webt/4y/3b/ac/4y3bacrtm3apdyirfanehdzf82w.png"><br>  <i>Knotenverwaltungsdiagramm in einer ordnungsgemäß gestalteten Cassandra-Anweisung</i> <br><br>  Berücksichtigen Sie die vorhandenen Operatoren. <br><br><h4>  1. Cassandra-Operator von instaclustr </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> </li><li>  Bereitschaft: Alpha </li><li>  Lizenz: Apache 2.0 </li><li>  Implementiert in: Java </li></ul><br>  Dies ist in der Tat ein vielversprechendes und sich schnell entwickelndes Projekt eines Unternehmens, das von Cassandra verwaltete Bereitstellungen anbietet.  Wie oben beschrieben, wird ein Sidecar-Container verwendet, der Befehle über HTTP akzeptiert.  Es ist in Java geschrieben, daher fehlt manchmal die erweiterte Funktionalität der Client-Go-Bibliothek.  Der Bediener unterstützt auch keine unterschiedlichen Racks für ein Rechenzentrum. <br><br>  Der Bediener hat jedoch solche Vorteile wie Überwachungsunterstützung, Cluster-Management auf hoher Ebene mithilfe von CRD und sogar Dokumentation zum Entfernen von Sicherungen. <br><br><h4>  2. Navigator von Jetstack </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> </li><li>  Bereitschaft: Alpha </li><li>  Lizenz: Apache 2.0 </li><li>  Umgesetzt in: Golang </li></ul><br>  Eine Anweisung zum Bereitstellen von DB-as-a-Service.  Unterstützt derzeit zwei Datenbanken: Elasticsearch und Cassandra.  Es bietet so interessante Lösungen wie die Zugriffskontrolle auf die Datenbank über RBAC (hierfür wird ein eigener separater Navigator-Apiserver angehoben).  Ein interessantes Projekt, das einen genaueren Blick wert wäre, aber das letzte Engagement wurde vor eineinhalb Jahren gemacht, was sein Potenzial deutlich reduziert. <br><br><h4>  3. Cassandra-Operator von vgkowski </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> </li><li>  Bereitschaft: Alpha </li><li>  Lizenz: Apache 2.0 </li><li>  Umgesetzt in: Golang </li></ul><br>  Sie betrachteten es nicht als „ernst“, da die letzte Übergabe an das Endlager vor mehr als einem Jahr erfolgte.  Die Betreiberentwicklung wird eingestellt: Die neueste Version von Kubernetes, die als unterstützt deklariert wurde, ist 1.9. <br><br><h4>  4. Cassandra-Operator von Rook </h4><br><ul><li>  <a href="">Github</a> </li><li>  Bereitschaft: Alpha </li><li>  Lizenz: Apache 2.0 </li><li>  Umgesetzt in: Golang </li></ul><br>  Ein Betreiber, dessen Entwicklung nicht so schnell vonstatten geht, wie wir es uns wünschen.  Es verfügt über eine durchdachte CRD-Struktur für die Verwaltung des Clusters, löst das Problem der Identifizierung von Knoten mithilfe von Service mit ClusterIP (der gleiche "Hack") ... aber für den Moment ist das alles.  Derzeit sind keine sofort einsatzbereiten Überwachungen und Backups verfügbar (wir haben übrigens damit begonnen, uns selbst <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu</a> überwachen).  Ein interessanter Punkt ist, dass Sie mit diesem Operator auch ScyllaDB bereitstellen können. <br><br>  <i>NB: Wir haben diesen Operator mit geringfügigen Änderungen in einem unserer Projekte verwendet.</i>  <i>Während des gesamten Betriebs (~ 4 Monate Betriebsdauer) gab es keine Probleme bei der Arbeit des Bedieners.</i> <br><br><h4>  5. CassKop von Orange </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> </li><li>  Bereitschaft: Alpha </li><li>  Lizenz: Apache 2.0 </li><li>  Umgesetzt in: Golang </li></ul><br>  Der jüngste Betreiber auf der Liste: Die erste Übergabe erfolgte am 23. Mai 2019.  Er hat bereits eine Vielzahl von Features aus unserer Liste in seinem Arsenal, von denen weitere Details im Projekt-Repository zu finden sind.  Der Operator basiert auf dem beliebten Operator-SDK.  Unterstützt die sofortige Überwachung.  Der Hauptunterschied zu anderen Betreibern ist die Verwendung des in Python implementierten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CassKop-Plugins</a> , das für die Kommunikation zwischen Cassandra-Knoten verwendet wird. <br><br><h2>  Schlussfolgerungen </h2><br>  Die Anzahl der Ansätze und möglichen Optionen für die Portierung von Cassandra auf Kubernetes spricht für sich: Das Thema ist gefragt. <br><br>  In dieser Phase können Sie eine der oben genannten Methoden auf eigene Gefahr und Gefahr ausprobieren: Keiner der Entwickler garantiert eine 100% ige Arbeit seiner Lösung in der Produktionsumgebung.  Aber jetzt sehen viele Produkte vielversprechend aus, um sie in Entwicklungsständen zu verwenden. <br><br>  Ich denke, in Zukunft muss diese Frau auf dem Schiff gehen! <br><br><h2>  PS </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Freie Migration von MongoDB nach Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Freie RabbitMQ-Migration auf Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenbanken und Kubernetes (Review und Videobericht)</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tipps und Tricks von K8: Beschleunigen des Bootstraps großer Datenbanken.</a> " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de475036/">https://habr.com/ru/post/de475036/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de475024/index.html">Laufen ist ein idealer Sport für Fernarbeiter. Teil 1: Der Weg zum ersten Rennen von hundert Kilometern</a></li>
<li><a href="../de475026/index.html">3 Kubernetes-Absturzgeschichten in der Produktion: Anti-Affinität, anmutiges Herunterfahren, Webhook</a></li>
<li><a href="../de475028/index.html">Bemerkungen zur Anwendung von ML im Geschäftsverkehr auf ŽijemeIT-Aktien</a></li>
<li><a href="../de475032/index.html">Gartner Hype Cycle 2019: Nachbesprechung</a></li>
<li><a href="../de475034/index.html">Grafik im Browser für Arduino und STM32</a></li>
<li><a href="../de475038/index.html">Der erste Satz "Angewandte Mathematik und Informatik" an der HSE in St. Petersburg: Wer sind sie und wie arbeiten sie mit ihnen?</a></li>
<li><a href="../de475044/index.html">Erstellen Sie Ihre eigenen Serverless basierend auf Fn</a></li>
<li><a href="../de475046/index.html">Rechtfertigt der Zweck die Mittel? (!) Schwarz und Grau SEO</a></li>
<li><a href="../de475048/index.html">Intuitive Erklärung des Hypothesentests und p-Wert</a></li>
<li><a href="../de475050/index.html">ESport - spielen, engagieren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
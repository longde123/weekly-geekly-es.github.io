<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî¢ üßòüèæ üå™Ô∏è Unser Weg zur zentralen Protokollspeicherung üêß üë©‚Äç‚úàÔ∏è üßï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Gr√º√üe an alle! Ich arbeite als Systemingenieur bei Onlanta . Bei einem unserer Projekte war ich an der Implementierung und Wartung von Elastic Stack b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Unser Weg zur zentralen Protokollspeicherung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/429260/">  Gr√º√üe an alle!  Ich arbeite als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Systemingenieur</a> bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Onlanta</a> .  Bei einem unserer Projekte war ich an der Implementierung und Wartung von Elastic Stack beteiligt.  Wir gingen vom virtuellen Sammeln von Protokollen zu einem zentralisierten, automatisierten Prozess √ºber.  Seit zwei Jahren haben wir die Architektur der L√∂sung praktisch nicht ge√§ndert und planen, in anderen Projekten ein praktisches Tool zu verwenden.  Ich teile Ihnen unsere Geschichte der Umsetzung sowie einige St√§rken und Schw√§chen in diesem Beitrag mit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23f/a8d/39d/23fa8d39daef5063c297e7cff9f3bbdc.png"></div>  <a href="">Quelle</a> <br><a name="habracut"></a><br>  Anfang 2016 waren die Protokolle unserer Administratoren und Entwickler sozusagen ‚Äûan Ihren Fingerspitzen‚Äú, dh ein Ingenieur, der mit ihnen √ºber SSH mit dem Host verbunden war, an dem der Dienst, an dem er interessiert war, das universelle Set von tail / grep / sed aufgedeckt hat / awk und hoffte, dass es m√∂glich sein w√ºrde, die notwendigen Daten auf diesem Host zu finden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b5/8cb/c53/2b58cbc53de559d692a6a0295f7fde4e.png"></div> <a href="">Quelle</a> <br><br>  Wir hatten auch einen separaten Server, auf dem alle Verzeichnisse mit Protokollen von allen Servern √ºber NFS bereitgestellt wurden, und der manchmal lange dar√ºber nachdachte, was jeder mit den Protokollen darauf machen wollte.  Nun, tmux mit mehreren Panels auf einigen aktiv aktualisierten Protokollen sah f√ºr Au√üenstehende auf einem gro√üen Monitor sehr beeindruckend aus und schuf eine aufregende Atmosph√§re der Beteiligung an den Sakramenten der Produktion. <br><br>  All dies funktionierte sogar, aber genau so lange, bis eine gro√üe Datenmenge schnell verarbeitet werden musste, und dies war meistens in den Momenten erforderlich, in denen etwas in den Sto√ü gefallen war. <br><br>  Manchmal dauerte es unanst√§ndig, Vorf√§lle zu untersuchen.  Ein erheblicher Teil davon wurde f√ºr die manuelle Aggregation von Protokollen, das Starten von <s>Kr√ºcken</s> verschiedener Skripte in Bash und Python, das Warten auf das Hochladen von Protokollen zur Analyse usw. aufgewendet. <br><br>  Mit einem Wort, all dies war sehr langsam, inspiriert von Niedergeschlagenheit und deutete eindeutig an, dass es Zeit war, sich um die zentrale Speicherung von Protokollen zu k√ºmmern. <br><br>  Um ehrlich zu sein, gab es kein kompliziertes Verfahren zur Auswahl von Kandidaten f√ºr die Rolle des technologischen Stacks, das uns dies erm√∂glichen w√ºrde: Damals war das ELK-Bundle bereits zu dieser Zeit beliebt, hatte eine gute Dokumentation, es gab eine gro√üe Anzahl von Artikeln im Internet f√ºr alle Komponenten.  Die Entscheidung war sofort: Sie m√ºssen es versuchen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ce1/6aa/c04/ce16aac040da82a959333b390b8fe04b.png"></div>  <a href="">Quelle</a> <br><br>  Die allererste Installation des Stacks erfolgte nach dem Webinar ‚ÄûLogstash: 0-60 in 60‚Äú auf drei virtuellen Maschinen, von denen jede eine Instanz von Elasticsearch, Logstash und Kibana startete. <br><br>  Au√üerdem sind einige Probleme bei der √úbermittlung von Protokollen von Endhosts an Logstash-Server aufgetreten.  Tatsache ist, dass Filebeat (eine Standard-Stack-L√∂sung f√ºr die Bereitstellung von Protokollen aus Textdateien) zu dieser Zeit mit gro√üen und schnell aktualisierten Dateien, die regelm√§√üig im RAM leckten und in unserem Fall insgesamt die Aufgabe nicht bew√§ltigen konnten, viel schlechter funktionierte. <br><br>  Hinzu kam die Notwendigkeit, einen Weg zu finden, um Anwendungsserverprotokolle von Computern mit IBM AIX bereitzustellen: Der Gro√üteil unserer Anwendungen wurde dann in WebSphere Application Server gestartet, das speziell unter diesem Betriebssystem funktionierte.  Filebeat ist in Go geschrieben, es gab 2016 keinen mehr oder weniger effizienten Go-Compiler f√ºr AIX, und ich wollte Logstash wirklich nicht als Agenten f√ºr die Bereitstellung verwenden. <br><br>  Wir haben verschiedene Log Delivery Agents getestet: Filebeat, Logstash-Forwarder-Java, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Log-Courier</a> , Python-Beaver und NXLog.  Von den Agenten erwarteten wir eine hohe Leistung, einen geringen Verbrauch an Systemressourcen, eine einfache Integration in Logstash und die F√§higkeit, grundlegende Datenmanipulationen mit den Kr√§ften des Agenten durchzuf√ºhren (z. B. die Zusammenstellung mehrzeiliger Ereignisse). <br><br>  √úber die Zusammenstellung von mehrzeiligen Ereignissen ist es gesondert zu erw√§hnen.  Tats√§chlich kann es nur auf der Seite des Agenten ausgef√ºhrt werden, der eine bestimmte Datei liest.  Trotz der Tatsache, dass Logstash fr√ºher einen mehrzeiligen Filter hatte und jetzt einen mehrzeiligen Codec hat, schlugen alle unsere Versuche, den Ereignisausgleich √ºber mehrere Logstash-Server mit der mehrzeiligen Verarbeitung zu kombinieren, fehl.  Diese Konfiguration macht einen effizienten Ereignisausgleich nahezu unm√∂glich. Daher war f√ºr uns der wichtigste Faktor bei der Auswahl der Agenten die mehrzeilige Unterst√ºtzung. <br><br>  Die Gewinner waren: Log-Courier f√ºr Maschinen mit Linux, NXLog f√ºr Maschinen mit AIX.  Mit dieser Konfiguration lebten wir fast ein Jahr ohne Probleme: Die Protokolle wurden geliefert, die Agenten fielen nicht (na ja, fast), alle waren gl√ºcklich. <br><br>  Im Oktober 2016 wurde die f√ºnfte Version der Elastic Stack-Komponenten ver√∂ffentlicht, einschlie√ülich Beats 5.0.  In dieser Version wurde viel Arbeit an allen Beats-Agenten geleistet, und wir konnten den Log-Courier (der zu diesem Zeitpunkt seine eigenen Probleme hatte) durch Filebeat ersetzen, den wir immer noch verwenden. <br><br>  Bei der Migration auf Version 5.0 wurden nicht nur Protokolle, sondern auch einige Metriken erfasst: Packetbeat wurde hier und da als Alternative zum Schreiben von HTTP-Anforderungsprotokollen in Dateien verwendet, und Metricbeat sammelte Systemmetriken und Metriken einiger Dienste. <br><br>  Zu diesem Zeitpunkt wurde die Arbeit unserer Ingenieure mit Protokollen viel einfacher: Jetzt musste nicht mehr bekannt sein, auf welchem ‚Äã‚ÄãServer das Protokoll angezeigt werden soll, an dem Sie interessiert sind. Der Informationsaustausch wurde vereinfacht, indem der Link zu Kibana einfach in Chatrooms oder E-Mails √ºbertragen und Berichte erstellt wurden, die zuvor erstellt wurden in wenigen Stunden begann in wenigen Sekunden erstellt zu werden.  Dies kann nicht gesagt werden, dass es nur eine Frage des Komforts war: Wir haben Ver√§nderungen in der Qualit√§t unserer Arbeit, in der Quantit√§t und Qualit√§t geschlossener Aufgaben sowie in der Geschwindigkeit der Reaktion auf Probleme an unseren St√§nden festgestellt. <br><br>  Irgendwann haben wir begonnen, das ElastAlert-Dienstprogramm von Yelp zu verwenden, um Warnungen an Ingenieure zu senden.  Und dann haben wir uns gedacht: Warum nicht in unser Zabbix integrieren, damit alle Warnungen ein Standardformat haben und zentral gesendet werden?  Die L√∂sung wurde ziemlich schnell gefunden: Mit ElastAlert k√∂nnen Sie beliebige Befehle ausf√ºhren, anstatt von uns verwendete Warnungen zu senden. <br><br>  Jetzt f√ºhren unsere ElastAlert-Regeln beim Ausl√∂sen ein Bash-Skript in mehreren Zeilen aus, an das die erforderlichen Daten in den Argumenten des Ereignisses √ºbergeben werden, das die Regel ausgel√∂st hat, und zabbix_sender wird vom Skript aufgerufen, das die Daten f√ºr den gew√ºnschten Knoten an Zabbix sendet. <br><br>  Da alle Informationen dar√ºber, wer das Ereignis generiert hat und wo, in Elasticsearch immer verf√ºgbar sind, gab es keine Schwierigkeiten bei der Integration.  Zum Beispiel hatten wir zuvor einen Mechanismus zum automatischen Erkennen von WAS-Anwendungsservern, und in den von ihnen generierten Ereignissen wird immer der Name des Servers, Clusters, der Zelle usw. geschrieben.  Dadurch konnten wir die Option query_key in ElastAlert-Regeln verwenden, sodass die Bedingungen der Regeln f√ºr jeden Server separat verarbeitet werden.  Das Skript mit zabbix_sender erh√§lt dann die genauen "Koordinaten" des Servers und die Daten werden f√ºr den entsprechenden Knoten an Zabbix gesendet. <br><br>  Eine andere L√∂sung, die uns sehr gef√§llt und die dank der zentralisierten Protokollsammlung erm√∂glicht wurde, ist ein Skript zum automatischen Erstellen von Aufgaben in JIRA: Einmal am Tag werden alle Fehler aus den Protokollen entfernt und, falls noch keine Aufgaben vorhanden sind, gestartet.  Gleichzeitig werden aus verschiedenen Indizes durch eine eindeutige Anforderungs-ID alle Informationen, die f√ºr die Untersuchung n√ºtzlich sein k√∂nnen, in die Aufgabe gezogen.  Das Ergebnis ist eine Art Standardwerkst√ºck mit den erforderlichen Mindestinformationen, die die Ingenieure bei Bedarf erg√§nzen k√∂nnen. <br><br>  Nat√ºrlich standen wir vor dem Problem, den Stack selbst zu √ºberwachen.  Dies wird teilweise mit Zabbix implementiert, teilweise mit demselben ElastAlert, und wir erhalten die wichtigsten Leistungsmetriken f√ºr Elasticsearch, Logstash und Kibana mithilfe der im Stack integrierten Standard√ºberwachung (der √úberwachungskomponente im X-Pack).  Au√üerdem haben wir auf den Servern mit den Stack-Diensten selbst <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Netzdaten</a> von Firehol installiert.  Dies ist n√ºtzlich, wenn Sie in Echtzeit und mit hoher Aufl√∂sung sehen m√∂chten, was gerade mit einem bestimmten Knoten passiert. <br><br>  Es war einmal, dass das Elasticsearch-√úberwachungsmodul darin leicht defekt war. Wir haben es gefunden, behoben, alle m√∂glichen n√ºtzlichen Metriken hinzugef√ºgt und eine Pull-Anfrage gestellt.  Jetzt kann netdata die neuesten Versionen von Elasticsearch √ºberwachen, einschlie√ülich grundlegender JVM-Metriken, Indizierung, Suchleistungsindikatoren, Transaktionsprotokollstatistiken, Indexsegmenten usw.  Wir m√∂gen Netdata und freuen uns, dass wir einen kleinen Beitrag dazu leisten konnten. <br><br>  Heute, nach fast drei Jahren, sieht unser Elastic Stack ungef√§hr so ‚Äã‚Äãaus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b0b/fc6/ab5/b0bfc6ab50dede8cdb09d80e22f90f07.png"></div><br>  Ingenieure arbeiten auf drei Arten mit dem Stapel: <br><br><ul><li>  Anzeigen und Analysieren von Protokollen und Metriken in Kibana; </li><li>  Dashboards in Grafana und Kibana; </li><li>  direkte Abfragen an Elasticsearch mithilfe von SQL oder der integrierten Abfrage DSL. </li></ul><br>  Insgesamt werden alle diese Ressourcen zugewiesen: 146 CPU, 484 GB RAM, 17 TB werden f√ºr das Elasticsearch Data Warehouse zugewiesen. <br><br>  Insgesamt arbeiten 13 virtuelle Maschinen im Rahmen von Elastic Stack: 4 Maschinen f√ºr ‚Äûhei√üe‚Äú Elasticsearch-Knoten, 4 f√ºr ‚Äûwarme‚Äú Knoten, 4 Maschinen mit Logstash und eine Ausgleichsmaschine.  Auf jedem Hot Node f√ºhrt Elasticsearch eine Kibana-Instanz aus.  Es ist von Anfang an passiert, und bisher mussten wir Kibana nicht bewegen, um Autos zu trennen. <br><br>  Die Entscheidung, Logstash auf getrennte Maschinen zu √ºbertragen, erwies sich jedoch als eine der korrektesten und effizientesten w√§hrend des Stapelbetriebs: Die hohe Konkurrenz um die CPU-Zeit zwischen JVM Elasticsearch und Logstash f√ºhrte zu nicht sehr angenehmen Spezialeffekten bei Lastausbr√ºchen.  M√ºllsammler litten am meisten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d15/1cb/e24/d151cbe24f19860ee8f88e6ff4d86fd6.jpg"></div>  <a href="">Quelle</a> <br><br>  Wir speichern Daten f√ºr die letzten 30 Tage im Cluster: Jetzt sind es ungef√§hr 12 Milliarden Ereignisse.  T√§glich schreiben ‚Äûhei√üe‚Äú Knoten neue Daten mit einem maximalen Komprimierungsverh√§ltnis (einschlie√ülich Shard-Replica-Daten) auf die 400-500-GB-Festplatte.  Unser Elasticsearch-Cluster hat eine Hot / Warm-Architektur, aber wir haben vor relativ kurzer Zeit darauf umgestellt, sodass immer noch weniger Daten auf "warmen" Knoten gespeichert sind als auf "hei√üen". <br><br>  Unsere typische Arbeitsbelastung: <br><br><ul><li>  Indexierung - durchschnittlich 13.000 U / min mit Spitzenwerten von bis zu 30.000 (ohne Indizierung in Replikatsplitter); </li><li>  Suche - 5200 rps. </li></ul><br>  Wir versuchen, eine CPU-Marge von 40-50% auf Elasticsearch-Hotknoten aufrechtzuerhalten, damit die Anzahl der indizierten Ereignisse und die hohen Anforderungen von Kibana / Grafana oder externen √úberwachungssystemen leicht pl√∂tzlich ansteigen.  Etwa 50% des Arbeitsspeichers auf Hosts mit Elasticsearch-Knoten sind immer f√ºr den Seiten-Cache und die Off-Heap-Anforderungen der JVM verf√ºgbar. <br><br>  In der Zeit seit dem Start des ersten Clusters konnten wir einige der positiven und negativen Seiten von Elastic Stack als Mittel zur Aggregation von Protokollen und als Such- und Analyseplattform f√ºr uns identifizieren. <br><br>  <b>Was uns am Stack besonders gef√§llt:</b> <br><br><ul><li>  Ein einziges √ñkosystem von Produkten, das gut miteinander integriert ist und fast alles bietet, was Sie brauchen.  Die Beats waren fr√ºher nicht sehr gut, aber jetzt haben wir keine Beschwerden √ºber sie. </li><li>  Logstash ist mit all seiner Monstrosit√§t ein sehr flexibler und leistungsstarker Pr√§prozessor, mit dem Sie viel mit Rohdaten tun k√∂nnen (und wenn etwas dies nicht zul√§sst, k√∂nnen Sie jederzeit ein Snippet in Ruby schreiben). </li><li>  Elasticsearch mit Plugins (und in j√ºngerer Zeit sofort verf√ºgbar) unterst√ºtzt SQL als Abfragesprache, was die Integration mit anderer Software und Personen vereinfacht, die SQL als Abfragesprache n√§her stehen. </li><li>  Hochwertige Dokumentation, mit der Sie schnell neue Mitarbeiter in das Projekt einf√ºhren k√∂nnen.  Der Betrieb des Stapels wird daher nicht zum Gesch√§ft einer Person, die √ºber bestimmte Erfahrungen und ‚Äûgeheimes Wissen‚Äú verf√ºgt. </li><li>  Es ist nicht erforderlich, im Voraus √ºber die Struktur der empfangenen Daten Bescheid zu wissen, um sie zu erfassen: Sie k√∂nnen Ereignisse so wie sie sind aggregieren und dann, wenn Sie verstehen, welche n√ºtzlichen Informationen Sie daraus extrahieren k√∂nnen, den Ansatz zur Verarbeitung √§ndern, ohne die ‚ÄûAbw√§rtskompatibilit√§t‚Äú zu verlieren.  Hierf√ºr gibt es viele praktische Tools auf dem Stapel: Feldaliasnamen in Indizes, Skriptfeldern usw. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dcc/e5b/075/dcce5b0751ee3394dd2426b878c24169.png"></div>  <a href="">Quelle</a> <br><br>  <b>Was wir nicht m√∂gen:</b> <br><br><ul><li>  X-Pack-Komponenten werden nur nach dem Abonnementmodell und sonst nichts verteilt: Wenn von Gold beispielsweise nur RBAC- oder PDF-Berichte unterst√ºtzt werden, m√ºssen Sie f√ºr alles bezahlen, was Gold hat.  Dies ist besonders frustrierend, wenn Sie beispielsweise nur Graph from Platinum ben√∂tigen und Machine Learning und ein weiteres B√ºndel anderer Funktionen, die Sie m√∂glicherweise nicht wirklich ben√∂tigen, zum Kauf angeboten werden.  Unsere Versuche, vor etwa einem Jahr mit der Elastic-Verkaufsabteilung √ºber die Lizenzierung einzelner X-Pack-Komponenten zu kommunizieren, f√ºhrten zu nichts, aber vielleicht hat sich seitdem etwas ge√§ndert. </li><li>  Sehr h√§ufige Releases, bei denen die Abw√§rtskompatibilit√§t irgendwie (jedes Mal neu) unterbrochen wird.  Sie m√ºssen das √Ñnderungsprotokoll sehr sorgf√§ltig lesen und sich im Voraus auf Aktualisierungen vorbereiten.  Jedes Mal, wenn Sie sich entscheiden m√ºssen: Bleiben Sie bei der alten Version, die stabil funktioniert, oder versuchen Sie, ein Upgrade durchzuf√ºhren, um neue Funktionen und Leistungssteigerungen zu erhalten. </li></ul><br>  Im Allgemeinen sind wir sehr zufrieden mit unserer Wahl im Jahr 2016 und planen, die Erfahrung mit dem Betrieb von Elastic Stack auf unsere anderen Projekte zu √ºbertragen: Die vom Stack bereitgestellten Tools sind sehr eng in unseren Workflow integriert, und es w√§re sehr schwierig, sie jetzt abzulehnen. <br><br><div class="spoiler">  <b class="spoiler_title">Und auch in unserem Unternehmen ist eine Reihe von Stellenangeboten offen.</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teamleiter</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teamleiter (Windows)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ingenieur f√ºr Netzwerkinformationssicherheit</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vorverkaufsmanager (Cloud-Dienste)</a> </li></ul></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429260/">https://habr.com/ru/post/de429260/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429250/index.html">Hundert digitale Buchhaltungsrezepte</a></li>
<li><a href="../de429252/index.html">Statische Analyse mobiler Anwendungen</a></li>
<li><a href="../de429254/index.html">Auf den Bezier-Kurven und Arduino Speed, Teil Zwei</a></li>
<li><a href="../de429256/index.html">So erstellen Sie eine Gesamtstruktur in Actionscript3 / Flash in wenigen * Codezeilen</a></li>
<li><a href="../de429258/index.html">So erstellen Sie zuverl√§ssige Spielmechaniken nur mit Excel: Modellierung und Optimierung von L√∂sungen</a></li>
<li><a href="../de429262/index.html">Willkommen zum Herbst DIYorDIE Meetup am 17. November</a></li>
<li><a href="../de429264/index.html">Li-Ionen-USV-Zeit: Brandgefahr oder sicherer Schritt in die Zukunft?</a></li>
<li><a href="../de429266/index.html">Welche Geh√§lter f√ºr IT-Spezialisten von My Circle-Arbeitgebern angeboten werden, Daten f√ºr Mai-Oktober 2018</a></li>
<li><a href="../de429268/index.html">Riesenspinne und Minotaurus auf den Stra√üen von Toulouse</a></li>
<li><a href="../de429270/index.html">Erwachsenenjournalismus: von Russland bis zum Kreml</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
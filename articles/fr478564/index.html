<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëçüèº üî¨ üíö Comment nous, chez TsIAN, avons dompt√© des t√©raoctets de journaux üïµüèæ üîó ü§üüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous, je m'appelle Alexander, je travaille comme ing√©nieur au CIAN et je suis engag√© dans l'administration syst√®me et l'automatisation des p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment nous, chez TsIAN, avons dompt√© des t√©raoctets de journaux</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/cian/blog/478564/"><img src="https://habrastorage.org/getpro/habr/post_images/f5a/f37/994/f5af37994ecad978b8cd3edd3dc7ae0a.png"><br><br>  Bonjour √† tous, je m'appelle Alexander, je travaille comme ing√©nieur au CIAN et je suis engag√© dans l'administration syst√®me et l'automatisation des processus d'infrastructure.  Dans les commentaires d'un des articles pr√©c√©dents, on nous a demand√© de dire o√π nous obtenons 4 To de journaux par jour et ce que nous en faisons.  Oui, nous avons beaucoup de journaux et un cluster d'infrastructure distinct a √©t√© cr√©√© pour les traiter, ce qui nous permet de r√©soudre rapidement les probl√®mes.  Dans cet article, je parlerai de la fa√ßon dont nous l'avons adapt√© au cours de l'ann√©e pour travailler avec un flux de donn√©es sans cesse croissant. <br><a name="habracut"></a><br><h3>  Par o√π avons-nous commenc√© </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/6d2/1eb/3da/6d21eb3da4aa0189ae44b9ca951b15a8.jpg"><br><br>  Au cours des derni√®res ann√©es, la charge sur cian.ru a augment√© tr√®s rapidement et, au troisi√®me trimestre de 2018, le trafic de ressources a atteint 11,2 millions d'utilisateurs uniques par mois.  √Ä ce moment, √† des moments critiques, nous avons perdu jusqu'√† 40% des journaux, √† cause desquels nous ne pouvions pas traiter rapidement les incidents et avons consacr√© beaucoup de temps et d'efforts √† les r√©soudre.  Souvent, nous ne pouvions pas trouver la cause du probl√®me et il est r√©apparu apr√®s un certain temps.  C'√©tait l'enfer avec lequel tu devais faire quelque chose. <br><br>  √Ä cette √©poque, nous utilisions un cluster de 10 n≈ìuds de donn√©es avec ElasticSearch version 5.5.2 avec des param√®tres d'index typiques pour stocker les journaux.  Il a √©t√© introduit il y a plus d'un an comme une solution populaire et abordable: alors le flux de journaux n'√©tait pas si gros, il n'√©tait pas logique de proposer des configurations non standard. <br><br>  Logstash sur diff√©rents ports a fourni le traitement des journaux entrants sur cinq coordinateurs ElasticSearch.  Un indice, quelle que soit sa taille, comprenait cinq fragments.  Une rotation horaire et quotidienne a √©t√© organis√©e, en cons√©quence, environ 100 nouveaux fragments sont apparus dans le cluster toutes les heures.  Bien qu'il n'y ait pas beaucoup de journaux, le cluster a r√©ussi et personne n'a attir√© l'attention sur ses param√®tres. <br><br><h3>  Probl√®mes de croissance </h3><br>  Le volume des journaux g√©n√©r√©s a augment√© tr√®s rapidement, car deux processus se chevauchaient.  D'une part, il y avait de plus en plus d'utilisateurs du service.  D'autre part, nous avons commenc√© √† passer activement √† l'architecture de microservices, en sciant nos anciens monolithes en C # et Python.  Plusieurs dizaines de nouveaux microservices qui ont remplac√© des parties du monolithe ont g√©n√©r√© beaucoup plus de journaux pour le cluster d'infrastructure. <br><br>  C'est la mise √† l'√©chelle qui nous a amen√©s au fait que le cluster est devenu pratiquement incontr√¥lable.  Lorsque les journaux ont commenc√© √† arriver √† une vitesse de 20 000 messages par seconde, une rotation inutile fr√©quente a augment√© le nombre de fragments √† 6 000, et un n≈ìud repr√©sentait plus de 600 fragments. <br><br>  Cela a entra√Æn√© des probl√®mes d'allocation de RAM et lorsqu'un n≈ìud est tomb√©, le d√©placement simultan√© de tous les fragments a commenc√©, multipliant le trafic et chargeant les n≈ìuds restants, ce qui rendait presque impossible l'√©criture de donn√©es dans le cluster.  Et pendant cette p√©riode, nous nous sommes retrouv√©s sans journaux.  Et avec un probl√®me de serveur, nous avons en principe perdu 1/10 du cluster.  Un grand nombre de petits index a ajout√© de la complexit√©. <br><br>  Sans journaux, nous ne comprenions pas les causes de l'incident et pouvions √† nouveau t√¥t ou tard monter sur le m√™me r√¢teau, mais dans l'id√©ologie de notre √©quipe, c'√©tait inacceptable, car tous les m√©canismes de travail que nous avions √©taient aff√ªt√©s exactement √† l'oppos√© - ne r√©p√©tons jamais les m√™mes probl√®mes.  Pour ce faire, nous avions besoin d'un volume complet de journaux et de leur livraison en temps quasi r√©el, car une √©quipe d'ing√©nieurs de service surveillait les alertes non seulement √† partir des m√©triques, mais √©galement √† partir des journaux.  Pour comprendre l'√©tendue du probl√®me - √† cette √©poque, le volume total de journaux √©tait d'environ 2 To par jour. <br><br>  Nous nous sommes fix√© un objectif - √©liminer compl√®tement la perte de journaux et r√©duire le temps de leur livraison au cluster ELK √† un maximum de 15 minutes en cas de force majeure (nous nous sommes bas√©s sur ce chiffre √† l'avenir comme un KPI interne). <br><br><h3>  Nouveau m√©canisme de rotation et n≈ìuds chauds et chauds </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/363/96f/05e/36396f05e01c97e805388ff27d134e2a.jpg"><br><br>  Nous avons commenc√© la transformation du cluster en mettant √† jour la version d'ElasticSearch de 5.5.2 √† 6.4.3.  Encore une fois, un cluster de la version 5 nous est parvenu, et nous avons d√©cid√© de le rembourser et de le mettre √† jour compl√®tement - il n'y a toujours pas de journaux.  Nous avons donc effectu√© cette transition en quelques heures seulement. <br><br>  La transformation la plus ambitieuse √† ce stade a √©t√© l'introduction de trois n≈ìuds avec le coordinateur comme tampon interm√©diaire Apache Kafka.  Le courtier de messages nous a √©vit√© de perdre des journaux lors de probl√®mes avec ElasticSearch.  Dans le m√™me temps, nous avons ajout√© 2 n≈ìuds au cluster et bascul√© vers une architecture chaude-chaude avec trois n≈ìuds ¬´chauds¬ª dispos√©s dans diff√©rents racks du centre de donn√©es.  Nous leur avons redirig√© des journaux qui ne devraient en aucun cas √™tre perdus - nginx, ainsi que des journaux d'erreurs d'application.  Les journaux mineurs - d√©bogage, avertissement, etc., sont all√©s √† d'autres n≈ìuds et, apr√®s 24 heures, les journaux ¬´importants¬ª ont quitt√© les n≈ìuds ¬´chauds¬ª. <br><br>  Afin de ne pas augmenter le nombre de petits index, nous sommes pass√©s de la rotation temporelle au m√©canisme de retournement.  Il y avait beaucoup d'informations sur les forums que la rotation par taille d'index est tr√®s peu fiable, nous avons donc d√©cid√© d'utiliser la rotation par le nombre de documents dans l'index.  Nous avons analys√© chaque index et enregistr√© le nombre de documents apr√®s lesquels la rotation devrait fonctionner.  Ainsi, nous avons atteint la taille optimale du fragment - pas plus de 50 Go. <br><br><h3>  Optimisation de cluster </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/cf3/c46/45e/cf3c4645e6b74cf5491f9878dacfa185.jpg"><br><br>  Cependant, nous ne nous sommes pas compl√®tement d√©barrass√©s des probl√®mes.  Malheureusement, de petits indices sont apparus tout de m√™me: ils n'ont pas atteint le volume d√©fini, n'ont pas tourn√© et ont √©t√© supprim√©s par un nettoyage global des indices de plus de trois jours, car nous avons supprim√© la rotation par date.  Cela a entra√Æn√© une perte de donn√©es du fait que l'index du cluster a compl√®tement disparu et une tentative d'√©criture dans un index inexistant a bris√© la logique du conservateur que nous avons utilis√©e pour le contr√¥le.  L'alias pour l'enregistrement a √©t√© converti en index et a rompu la logique du rollover, provoquant une croissance incontr√¥l√©e de certains indices √† 600 Go. <br><br>  Par exemple, pour configurer la rotation: <br><br><pre><code class="plaintext hljs">urator-elk-rollover.yaml --- actions:   1:     action: rollover     options:       name: "nginx_write"       conditions:         max_docs: 100000000   2:     action: rollover     options:       name: "python_error_write"       conditions:         max_docs: 10000000</code> </pre> <br><br>  En l'absence d'alias de survol, une erreur s'est produite: <br><br><pre> <code class="plaintext hljs">ERROR   alias "nginx_write" not found. ERROR   Failed to complete action: rollover. &lt;type 'exceptions.ValueError'&gt;: Unable to perform index rollover with alias "nginx_write".</code> </pre><br><br>  Nous avons laiss√© la solution √† ce probl√®me pour la prochaine it√©ration et avons pris une autre question: nous sommes pass√©s √† la logique de Logstash, qui g√®re les journaux entrants (supprimant les informations inutiles et les enrichissant).  Nous l'avons plac√© dans docker, que nous lan√ßons via docker-compose, et au m√™me endroit, nous avons plac√© logstash-exporter, qui fournit des mesures √† Prometheus pour la surveillance op√©rationnelle du flux de journaux.  Nous nous sommes donc donn√© l'opportunit√© de modifier en douceur le nombre d'instances de logstash responsables du traitement de chaque type de journal. <br><br>  Pendant que nous am√©liorions le cluster, le trafic cian.ru est pass√© √† 12,8 millions d'utilisateurs uniques par mois.  En cons√©quence, il s'est av√©r√© que nos conversions n'ont pas suivi un peu les changements sur la production, et nous √©tions confront√©s au fait que les n≈ìuds "chauds" ne pouvaient pas faire face √† la charge et ralentissaient la livraison compl√®te des journaux.  Nous avons re√ßu les donn√©es "√† chaud" sans √©checs, mais nous avons d√ª intervenir dans la livraison du reste et faire un rollover manuel afin de r√©partir uniform√©ment les indices. <br><br>  Dans le m√™me temps, la mise √† l'√©chelle et la modification des param√®tres des instances de logstash dans le cluster √©taient compliqu√©es par le fait qu'il s'agissait d'un docker-compose local et que toutes les actions √©taient effectu√©es √† la main (pour ajouter de nouvelles extr√©mit√©s, vous deviez passer par tous les serveurs avec vos mains et faire docker-composer up -d partout). <br><br><h3>  Redistribution des journaux </h3><br>  En septembre de cette ann√©e, nous avons continu√© √† voir le monolithe, la charge sur le cluster a augment√© et le flux de journaux approchait 30 000 messages par seconde. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/28c/ff7/c76/28cff7c7661c901102a69fe49beeccd0.png"><br><br>  Nous avons commenc√© la prochaine it√©ration avec la mise √† jour du fer.  Nous sommes pass√©s de cinq coordinateurs √† trois, avons remplac√© les n≈ìuds de donn√©es et avons gagn√© en termes d'argent et de volume de stockage.  Pour les n≈ìuds, nous utilisons deux configurations: <br><br><ul><li>  Pour les n≈ìuds actifs: E3-1270 v6 / SSD 960 Go / 32 Go x 3 x 2 (3 pour Hot1 et 3 pour Hot2). <br></li><li>  Pour les n≈ìuds chauds: E3-1230 v6 / SSD 4 To / 32 Go x 4. <br></li></ul><br>  √Ä cette it√©ration, nous avons retir√© l'index avec les journaux d'acc√®s au microservice, qui prend autant d'espace que les journaux nginx frontaux, dans le deuxi√®me groupe de trois n≈ìuds actifs.  Nous stockons maintenant les donn√©es sur des n≈ìuds chauds pendant 20 heures, puis les transf√©rons pour les r√©chauffer dans d'autres journaux. <br><br>  Nous avons r√©solu le probl√®me de la disparition des petits indices en reconfigurant leur rotation.  Les index sont maintenant tourn√©s de toute fa√ßon toutes les 23 heures, m√™me s'il y a peu de donn√©es.  Cela a l√©g√®rement augment√© le nombre de fragments (ils sont devenus environ 800), mais du point de vue des performances du cluster, cela est tol√©rable. <br><br>  En cons√©quence, six n≈ìuds ¬´chauds¬ª et seulement quatre ¬´chauds¬ª se sont r√©v√©l√©s dans le cluster.  Cela entra√Æne un l√©ger retard dans les demandes sur de longs intervalles de temps, mais l'augmentation du nombre de n≈ìuds √† l'avenir r√©soudra ce probl√®me. <br><br>  Dans cette it√©ration, le probl√®me de l'absence de mise √† l'√©chelle semi-automatique a √©galement √©t√© r√©solu.  Pour ce faire, nous avons d√©ploy√© une grappe Nomad d'infrastructure - similaire √† ce que nous avons d√©j√† d√©ploy√© pour la production.  Bien que le nombre de Logstash ne change pas automatiquement en fonction de la charge, mais nous y arriverons. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c5/331/493/5c533149373a09c73e329e3bb43e0d81.png"><br><br><h3>  Plans futurs </h3><br>  La configuration impl√©ment√©e √©volue bien et maintenant nous stockons 13,3 To de donn√©es - tous les journaux en 4 jours, ce qui est n√©cessaire pour l'analyse d'urgence des alertes.  Nous convertissons une partie des journaux en m√©triques, que nous ajoutons √† Graphite.  Pour faciliter le travail des ing√©nieurs, nous avons des m√©triques pour le cluster d'infrastructure et des scripts pour la correction semi-automatique des probl√®mes typiques.  Apr√®s avoir augment√© le nombre de n≈ìuds de donn√©es, ce qui est pr√©vu pour l'ann√©e prochaine, nous passerons au stockage de donn√©es de 4 √† 7 jours.  Ce sera suffisant pour le travail op√©rationnel, car nous essayons toujours d'enqu√™ter sur les incidents d√®s que possible, et les donn√©es de t√©l√©m√©trie sont disponibles pour des enqu√™tes √† long terme. <br><br>  En octobre 2019, le trafic cian.ru est pass√© √† 15,3 millions d'utilisateurs uniques par mois.  Il s'agissait d'un test s√©rieux de la solution architecturale pour la livraison des journaux. <br><br>  Nous nous pr√©parons maintenant √† mettre √† niveau ElasticSearch vers la version 7. Cependant, pour cela, nous devrons mettre √† jour le mappage de nombreux index dans ElasticSearch, car ils sont pass√©s de la version 5.5 et ont √©t√© d√©clar√©s obsol√®tes dans la version 6 (ils n'existent tout simplement pas dans la version 7).  Et cela signifie que dans le processus de mise √† jour, il y aura certainement un cas de force majeure qui nous laissera sans journaux pour le moment.  Des 7 versions, nous attendons avec impatience Kibana avec une interface am√©lior√©e et de nouveaux filtres. <br><br>  Nous avons atteint l'objectif principal: nous avons cess√© de perdre des journaux et r√©duit le temps d'arr√™t du cluster d'infrastructure de 2 √† 3 gouttes par semaine √† quelques heures de service par mois.  Tout ce travail sur la production est presque invisible.  Cependant, maintenant nous pouvons d√©terminer avec pr√©cision ce qui se passe avec notre service, nous pouvons le faire rapidement en mode silencieux et ne pas craindre que les journaux soient perdus.  En g√©n√©ral, nous sommes satisfaits, heureux et nous nous pr√©parons √† de nouveaux exploits, dont nous parlerons plus tard. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr478564/">https://habr.com/ru/post/fr478564/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr478546/index.html">Websockets Exp√©rience en d√©veloppement et exploitation. Nous modifions le client</a></li>
<li><a href="../fr478550/index.html">Comment g√©rer une montre? Analyse de la piste front-end du deuxi√®me championnat de programmation</a></li>
<li><a href="../fr478552/index.html">Deuxi√®me applet, fermeture et boutons transparents dans Processing 3</a></li>
<li><a href="../fr478554/index.html">Webinaire "SRE - battage m√©diatique ou l'avenir?" 12 d√©cembre √† 11h00</a></li>
<li><a href="../fr478560/index.html">Les messageries instantan√©es gratuites sont-elles anonymes?</a></li>
<li><a href="../fr478566/index.html">iOS Mise en r√©seau lorsque l'application n'est pas en cours d'ex√©cution</a></li>
<li><a href="../fr478572/index.html">Bot sur les r√©seaux de neurones: comment fonctionne et apprend un assistant virtuel</a></li>
<li><a href="../fr478574/index.html">La v√©rit√© sur les freins ferroviaires: Partie 4 - Freins pour passagers</a></li>
<li><a href="../fr478580/index.html">Comment la puce graphique Super Nintendo a fonctionn√©: Guide Super PPU</a></li>
<li><a href="../fr478582/index.html">Rapport VPN mondial sur les appareils mobiles en 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
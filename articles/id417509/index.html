<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôáüèº üëäüèø ü§±üèº Kiat & trik Kubernetes: mempercepat bootstrap dari database besar üë©üèæ‚Äçüíª ü§öüèª üë©üèΩ‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dengan artikel ini, kami membuka serangkaian publikasi dengan instruksi praktis tentang bagaimana membuat hidup lebih mudah bagi kami (operasi) dan pe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kiat & trik Kubernetes: mempercepat bootstrap dari database besar</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/417509/">  Dengan artikel ini, kami membuka serangkaian publikasi dengan instruksi praktis tentang bagaimana membuat hidup lebih mudah bagi kami (operasi) dan pengembang dalam berbagai situasi yang terjadi secara harfiah setiap hari.  Semuanya dikumpulkan dari pengalaman nyata dalam memecahkan masalah dari klien dan telah meningkat dari waktu ke waktu, tetapi masih tidak mengklaim sebagai ideal - menganggapnya lebih sebagai ide dan kosong. <br><br>  Saya akan mulai dengan "trik" dalam mempersiapkan dump database besar seperti MySQL dan PostgreSQL untuk penyebaran cepat mereka untuk berbagai kebutuhan - terutama, pada platform untuk pengembang.  Konteks operasi yang dijelaskan di bawah ini adalah lingkungan khas kami, yang meliputi kluster Kubernet yang berfungsi dan penggunaan GitLab (dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dapp</a> ) untuk CI / CD.  Ayo pergi! <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a><br><br>  Kesulitan utama dalam Kubernetes ketika menggunakan fitur cabang adalah database besar, ketika pengembang ingin menguji / menunjukkan perubahan mereka pada database penuh (atau hampir lengkap) dari produksi.  Sebagai contoh: <br><br><ul><li>  Ada aplikasi dengan database di MySQL untuk 1 TB dan 10 pengembang yang mengembangkan fitur mereka sendiri. </li><li>  Pengembang menginginkan loop tes individual dan beberapa loop lebih spesifik untuk tes dan / atau demo. </li><li>  Selain itu, ada kebutuhan untuk mengembalikan dump malam dari basis produksi di sirkuit pengujian untuk waktu yang waras - untuk mereproduksi masalah dengan klien atau bug. </li><li>  Akhirnya, dimungkinkan untuk meringankan ukuran database setidaknya 150 GB - tidak begitu banyak, tetapi masih menghemat ruang.  Yaitu  kita masih perlu entah bagaimana mempersiapkan tempat sampah. </li></ul><br>  <i><b>Catatan</b> : Biasanya kita mencadangkan basis data MySQL menggunakan innobackupex Percona, yang memungkinkan kita menyimpan semua basis data dan pengguna ... - singkatnya, semua yang mungkin diperlukan.</i>  <i>Ini adalah contoh yang dipertimbangkan lebih lanjut dalam artikel, meskipun dalam kasus umum tidak masalah bagaimana Anda membuat cadangan.</i> <br><br>  Jadi, katakanlah kita memiliki cadangan basis data.  Apa yang harus dilakukan selanjutnya? <br><br><h2>  Langkah 1: Mempersiapkan database baru dari dump </h2><br>  Pertama-tama, kita akan membuat dalam <i>Penyebaran</i> Kubernetes, yang akan terdiri dari dua kontainer init <i>(mis., <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Wadah khusus</a> yang berjalan sebelum perapian aplikasi dan memungkinkan Anda untuk melakukan pra-konfigurasi)</i> dan satu perapian. <br><br>  Tapi di mana menempatkannya?  Kami memiliki basis data besar (1 TB) dan kami ingin meningkatkan sepuluh instansnya - kami membutuhkan server dengan disk besar (10+ TB).  Kami memesannya secara terpisah untuk tugas ini dan menandai simpul dengan server ini dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">label</a> khusus yang <code>dedicated: non-prod-db</code> .  Pada saat yang sama, kita akan menggunakan eponymous taint, yang akan dikatakan Kubernetes bahwa hanya aplikasi yang resisten (memiliki <i>toleransi</i> ) yang dapat bergulir ke simpul ini, mis., Menerjemahkan Kubernetes ke dalam bahasa, <code>dedicated Equal non-prod-db</code> . <br><br>  Menggunakan <code>nodeSelector</code> dan <code>tolerations</code> pilih node yang diinginkan (terletak di server dengan disk besar): <br><br><pre> <code class="plaintext hljs"> nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute"</code> </pre> <br>  ... dan ambil uraian isi simpul ini. <br><br><h3>  Kontainer Init: get-bindump </h3><br>  Wadah init pertama yang akan kita sebut <code>get-bindump</code> .  <code>emptyDir</code> (in <code>/var/lib/mysql</code> ), di mana dump basis data yang diterima dari server cadangan akan ditambahkan.  Untuk melakukan ini, wadah memiliki semua yang Anda butuhkan: kunci SSH, alamat server cadangan.  Tahap ini dalam kasus kami membutuhkan waktu sekitar 2 jam. <br><br>  Deskripsi wadah ini di <i>Penempatan adalah</i> sebagai berikut: <br><br><pre> <code class="plaintext hljs"> - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh</code> </pre> <br>  Skrip <code>get_bindump.sh</code> digunakan dalam wadah: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3>  Kontainer Init: persiapan-bindump </h3><br>  Setelah mengunduh cadangan, wadah init kedua diluncurkan - <code>prepare-bindump</code> .  Ini mengeksekusi <code>innobackupex --apply-log</code> (karena file sudah tersedia di <code>/var/lib/mysql</code> - berkat <code>emptyDir</code> dari <code>get-bindump</code> ) dan server MySQL mulai. <br><br>  Dalam wadah init inilah kita melakukan semua konversi yang diperlukan ke basis data, menyiapkannya untuk aplikasi yang dipilih: kita membersihkan tabel yang diizinkan, mengubah akses di dalam basis data, dll.  Kemudian kita mematikan server MySQL dan cukup mengarsipkan seluruh <code>/var/lib/mysql</code> ke file tar.gz.  Sebagai hasilnya, dump cocok dengan file 100 GB, yang sudah menjadi urutan besarnya lebih kecil dari 1 TB asli.  Tahap ini memakan waktu sekitar 5 jam. <br><br>  Deskripsi wadah init kedua dalam <i>Penerapan</i> : <br><br><pre> <code class="plaintext hljs"> - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br>  Skrip <code>prepare_bindump.sh</code> digunakan di dalamnya terlihat seperti ini: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3>  Di bawah </h3><br>  Akord terakhir adalah peluncuran perapian utama, yang terjadi setelah kontainer init dieksekusi.  Di pod, kami memiliki nginx sederhana, dan melalui <code>emtpyDir</code> terkompresi dan terpangkas 100 GB <code>emtpyDir</code> .  Fungsi nginx ini adalah untuk memberikan dump ini. <br><br>  Konfigurasi perapian: <br><br><pre> <code class="plaintext hljs"> - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Inilah tampilan seluruh Penempatan dengan initContainers ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- apiVersion: apps/v1beta1 kind: Deployment metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: 0 revisionHistoryLimit: 2 template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: log mountPath: /var/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: 0600 secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: somedb-db-dump spec: clusterIP: None selector: app: db-dumps ports: - name: http port: 80</code> </pre> </div></div><br>  Catatan tambahan: <br><br><ol><li>  Dalam kasus kami, kami menyiapkan tempat pembuangan baru <b>setiap malam</b> menggunakan pekerjaan yang dijadwalkan di GitLab.  Yaitu  setiap malam, <i>Penyebaran</i> ini secara otomatis diluncurkan, yang menarik dump baru dan menyiapkannya untuk distribusi ke semua lingkungan pengembang pengujian. </li><li>  Mengapa kita juga membuang volume <code>/dump</code> ke dalam wadah init (dan di dalam skrip terdapat pemeriksaan untuk keberadaan <code>/dump/version.txt</code> )?  Ini dilakukan jika server yang dijalankannya di-restart.  Kontainer akan mulai lagi dan tanpa pemeriksaan ini, dump akan mulai mengunduh lagi.  Jika kita sudah menyiapkan dump sekali, maka pada awal berikutnya (jika server reboot), <code>/dump/version.txt</code> flag <code>/dump/version.txt</code> akan menginformasikan tentang ini. </li><li>  Apa gambar <code>db-dumps</code> ?  Kami mengumpulkannya dengan dapp dan Dappfile-nya terlihat seperti ini: <br><br><pre> <code class="plaintext hljs">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "Install percona repositories" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "Add repository for borgbackup" apt_repository: repo="ppa:costamagnagianfranco/borgbackup" codename="xenial" update_cache=yes - name: "Add repository for mysql 5.6" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "Install packages" apt: name: "{{`{{ item }}`}}" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "Add get_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/get_bindump.sh" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "Add prepare_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/prepare_bindump.sh" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</code> </pre> </li></ol><br><h2>  Langkah 2: Meluncurkan basis data di lingkungan pengembang </h2><br>  Saat meluncurkan basis data MySQL di lingkungan pengujian pengembang, ia memiliki tombol di GitLab yang meluncurkan penempatan kembali <i>Penempatan</i> dengan MySQL dengan <code>RollingUpdate.maxUnavailable: 0</code> yang tersedia <code>RollingUpdate.maxUnavailable: 0</code> : <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">Bagaimana ini diterapkan?</b> <div class="spoiler_text">  Di GitLab, ketika Anda mengklik pada <i>reload db</i> , <i>Deployment</i> dengan spesifikasi berikut digunakan: <br><br><pre> <code class="plaintext hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br>  Yaitu  kami memberi tahu Kubernetes untuk memperbarui <i>Penempatan</i> (buat yang baru di bawah) dan pastikan bahwa setidaknya satu di bawah adalah siaran langsung.  Karena ketika membuat perapian baru, ia memiliki wadah init saat mereka bekerja, yang baru <b>tidak</b> masuk ke status <i>Running</i> , yang berarti bahwa yang lama terus bekerja.  Dan hanya pada saat MySQL itu sendiri mulai (dan probe kesiapan bekerja), lalu lintas beralih ke sana, dan yang lama (dengan database lama) dihapus. <br><br>  Detail tentang skema ini dapat ditemukan dalam materi berikut: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Melakukan Pembaruan Bergulir</a> <i>(dokumentasi Kubernetes)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bergulir Pembaruan dengan Penyebaran Kubernetes</a> <i>(Ta-Ching Chen)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Strategi penyebaran Kubernetes</a> <i>(Solusi Kontainer)</i> . </li></ul></div></div><br>  Pendekatan yang dipilih memungkinkan kita untuk menunggu sampai dump baru diunduh, dibuka ritsleting dan diluncurkan, dan hanya setelah itu dump yang lama akan dihapus dari MySQL.  Jadi, saat kami sedang mempersiapkan tempat pembuangan baru, kami bekerja dengan diam-diam dengan pangkalan lama. <br><br>  Wadah init dari <i>Penempatan</i> ini menggunakan perintah berikut: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br>  Yaitu  kami mengunduh dump database terkompresi yang disiapkan pada langkah 1, unzip ke <code>/var/lib/mysql</code> , dan kemudian mulai di bawah <i>Penempatan</i> , di mana MySQL diluncurkan dengan data yang sudah disiapkan.  Semua ini memakan waktu sekitar 2 jam. <br><br><div class="spoiler">  <b class="spoiler_title">Dan Penempatan adalah sebagai berikut ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: Deployment metadata: name: mysql spec: strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: service: mysql spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: getdump image: mysql-with-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: DUMP_URL value: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - name: mysql image: mysql:5.6 resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: 3306 name: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: MYSQL_ROOT_PASSWORD value: "password" volumes: - name: datadir emptyDir: {} - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</code> </pre> </div></div><br><h2>  Ringkasan </h2><br>  Ternyata kami selalu memiliki <i>Penyebaran</i> , yang diluncurkan setiap malam dan melakukan hal berikut: <br><br><ul><li>  Mendapat dump database baru </li><li>  entah bagaimana ia mempersiapkannya untuk operasi yang benar dalam lingkungan pengujian (misalnya, trankeytit beberapa tabel, menggantikan data pengguna nyata, membuat pengguna yang diperlukan, dll.); </li><li>  memberikan setiap pengembang kesempatan untuk meluncurkan basis data yang telah disiapkan ke namespace mereka di <i>Deployment</i> dengan menekan tombol di CI - berkat <i>Layanan yang</i> tersedia di dalamnya, basis data akan tersedia di <code>mysql</code> (misalnya, mungkin itu adalah nama layanan di namespace). </li></ul><br>  Sebagai contoh yang kami teliti, membuat dump dari replika asli membutuhkan waktu sekitar 6 jam, menyiapkan "gambar dasar" membutuhkan waktu 7 jam, dan memperbarui basis data di lingkungan pengembang membutuhkan waktu 2 jam.  Karena dua tindakan pertama dilakukan "di latar belakang" dan tidak terlihat oleh pengembang, sebenarnya mereka dapat menggunakan versi produksi dari basis data (dengan ukuran 1 TB) <b>selama 2 jam yang sama</b> . <br><br>  Pertanyaan, kritik dan koreksi terhadap skema yang diusulkan dan komponennya disambut dalam komentar! <br><br>  PS Tentu saja, kami memahami bahwa dalam kasus VMware dan beberapa alat lainnya, adalah mungkin untuk membuat snapshot dari mesin virtual dan meluncurkan virusalka baru dari snapshot (yang bahkan lebih cepat), tetapi opsi ini tidak termasuk menyiapkan pangkalan, dengan mempertimbangkan yang akan berubah hampir sama waktu ... Belum lagi fakta bahwa tidak semua orang memiliki kesempatan atau keinginan untuk menggunakan produk komersial. <br><br><h2>  PPS </h2><br>  Lainnya dari siklus tips &amp; trik K8: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Halaman kesalahan yang dipersonalisasi di NGINX Ingress</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Transfer sumber daya yang bekerja di sebuah cluster ke manajemen Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tentang alokasi node dan beban pada aplikasi web</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Akses ke situs dev</a> ." </li></ul><br>  Baca juga di blog kami: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bangun dan instal aplikasi di Kubernet menggunakan dapp dan GitLab CI</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Berlatihlah dengan dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 1: Membangun aplikasi sederhana</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Berlatihlah dengan dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 2. Penempatan gambar Docker di Kubernetes menggunakan Helm</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Orkestrasi DBMS CockroachDB di Kubernetes</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengalaman kami dengan Kubernetes dalam proyek-proyek kecil</a> ‚Äù <i>(laporan video, yang mencakup pengenalan perangkat teknis Kubernetes);</i> </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Utilitas yang berguna saat bekerja dengan Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id417509/">https://habr.com/ru/post/id417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id417497/index.html">4 tahun Ilmu Data di Grup Media Schibsted</a></li>
<li><a href="../id417501/index.html">Lifehacks memproduksi papan dua lapis (LUT)</a></li>
<li><a href="../id417503/index.html">Apa yang harus diingat pengembang web untuk melakukan SEO-Feng Shui</a></li>
<li><a href="../id417505/index.html">Intel Merilis Patch untuk Kerentanan Firmware ME Baru</a></li>
<li><a href="../id417507/index.html">Trik untuk menautkan dan mengunduh file Mach-O</a></li>
<li><a href="../id417511/index.html">Intel Mengakuisisi eASIC - Pengembang ASIC Struktural</a></li>
<li><a href="../id417513/index.html">Analog dengan Python dan JavaScript. Bagian dua</a></li>
<li><a href="../id417515/index.html">Apa yang saya pelajari dengan membuat 100 game dalam 5 tahun</a></li>
<li><a href="../id417517/index.html">Halaman sejarah Intel. Foto Kronik dan Kuis</a></li>
<li><a href="../id417521/index.html">Tinjau sertifikat SSL untuk pencabutan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
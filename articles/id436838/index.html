<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸš‰ ğŸ“ ğŸ“» Memahami jaringan saraf convolutional melalui visualisasi di PyTorch âš¡ï¸ ğŸ¤¶ ğŸ¤˜ğŸ¿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Di era kita, mesin telah berhasil mencapai akurasi 99% dalam memahami dan mendefinisikan fitur dan objek dalam gambar. Kami menjumpai ini setiap hari,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Memahami jaringan saraf convolutional melalui visualisasi di PyTorch</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436838/">  Di era kita, mesin telah berhasil mencapai akurasi 99% dalam memahami dan mendefinisikan fitur dan objek dalam gambar.  Kami menjumpai ini setiap hari, misalnya: pengenalan wajah di kamera ponsel cerdas, kemampuan untuk mencari foto di google, memindai teks dari kode batang atau buku dengan kecepatan yang baik, dll. Efisiensi mesin seperti ini dimungkinkan berkat jenis jaringan saraf khusus yang disebut neural convolutional jaringan.  Jika Anda seorang penggemar pembelajaran yang mendalam, Anda mungkin pernah mendengarnya, dan Anda dapat mengembangkan beberapa pengklasifikasi gambar.  Kerangka pembelajaran mendalam modern seperti Tensorflow dan PyTorch menyederhanakan pembelajaran mesin gambar.  Namun, pertanyaannya tetap: bagaimana data melewati lapisan jaringan saraf dan bagaimana komputer belajar darinya?  Untuk mendapatkan tampilan yang jelas dari awal, kita menyelami konvolusi, memvisualisasikan gambar setiap lapisan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/859/2c6/958/8592c6958985979587858374abd08f98.png" alt="gambar"><br><a name="habracut"></a><br><h2>  Jaringan Saraf Konvolusional </h2><br>  Sebelum Anda mulai mempelajari jaringan saraf convolutional (SNA), Anda perlu belajar cara bekerja dengan jaringan saraf.  Jaringan saraf meniru otak manusia untuk memecahkan masalah yang kompleks dan mencari pola dalam data.  Selama beberapa tahun terakhir, mereka telah menggantikan banyak pembelajaran mesin dan algoritma visi komputer.  Model dasar jaringan saraf terdiri dari neuron yang tersusun dalam lapisan.  Setiap jaringan saraf memiliki lapisan input dan output dan beberapa lapisan tersembunyi ditambahkan kepadanya tergantung pada kompleksitas masalah.  Saat mentransmisikan data melalui lapisan, neuron dilatih dan mengenali tanda-tanda.  Representasi jaringan saraf ini disebut model.  Setelah model dilatih, kami meminta jaringan untuk membuat perkiraan berdasarkan data uji. <br><br>  SNS adalah jenis jaringan saraf khusus yang bekerja dengan baik dengan gambar.  Ian Lekun mengusulkan mereka pada tahun 1998, di mana mereka mengenali nomor yang ada di gambar input.  SNA juga digunakan untuk pengenalan suara, segmentasi gambar dan pemrosesan teks.  Sebelum penciptaan jaringan saraf convolutional, perceptrons multilayer digunakan dalam konstruksi pengklasifikasi gambar.  Klasifikasi gambar mengacu pada tugas mengekstraksi kelas dari gambar raster multichannel (warna, hitam dan putih).  Multilayer perceptrons membutuhkan waktu lama untuk mencari informasi dalam gambar, karena setiap input harus dikaitkan dengan setiap neuron di lapisan berikutnya.  SNA berkeliling mereka menggunakan konsep yang disebut konektivitas lokal.  Ini berarti bahwa kami akan menghubungkan setiap neuron hanya ke daerah input lokal.  Ini meminimalkan jumlah parameter, yang memungkinkan berbagai bagian jaringan untuk berspesialisasi dalam atribut tingkat tinggi seperti tekstur atau pola berulang.  Bingung?  Mari kita bandingkan bagaimana gambar ditransmisikan melalui multi-layer perceptrons (MPs) dan jaringan saraf convolutional. <br><br><h2>  Perbandingan MP dan SNA </h2><br>  Jumlah total entri dalam lapisan input untuk perceptron multilayer akan menjadi 784, karena gambar input memiliki ukuran 28x28 = 784 (dataset MNIST dipertimbangkan).  Jaringan harus dapat memprediksi angka dalam gambar input, yang berarti bahwa output dapat menjadi milik salah satu dari kelas berikut dalam kisaran dari 0 hingga 9. Di lapisan output, kami mengembalikan perkiraan kelas, katakanlah, jika input ini adalah gambar dengan angka "3", kemudian pada lapisan output neuron yang sesuai "3" memiliki nilai yang lebih tinggi dibandingkan dengan neuron lainnya.  Sekali lagi muncul pertanyaan: "Berapa banyak lapisan tersembunyi yang kita butuhkan dan berapa banyak neuron yang harus ada di masing-masing?"  Misalnya, ambil kode MP berikut: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f8/efc/e14/3f8efce14418a7df0be2e813399def5d.png" alt="gambar"><br><br>  Kode di atas diimplementasikan menggunakan kerangka kerja yang disebut Keras.  Lapisan tersembunyi pertama memiliki 512 neuron yang terhubung ke lapisan input 784 neuron.  Lapisan tersembunyi berikutnya: lapisan pengecualian, yang memecahkan masalah pelatihan ulang.  0,2 berarti bahwa ada peluang 20% â€‹â€‹untuk tidak memperhitungkan neuron dari lapisan tersembunyi sebelumnya.  Kami kembali menambahkan lapisan tersembunyi kedua dengan jumlah neuron yang sama seperti pada lapisan tersembunyi pertama (512), dan kemudian lapisan eksklusif lainnya.  Akhirnya, mengakhiri set lapisan ini dengan lapisan output yang terdiri dari 10 kelas.  Kelas yang paling penting adalah jumlah yang diprediksi oleh model.  Ini adalah bagaimana jaringan multilayer terlihat setelah mengidentifikasi semua lapisan.  Salah satu kelemahan dari multi-level perceptron adalah terhubung sepenuhnya, yang membutuhkan banyak waktu dan ruang. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db3/df6/605/db3df6605d0ddb868eb14b347227b963.png" alt="gambar"><br><br>  Konvolt tidak menggunakan lapisan yang sepenuhnya terikat.  Mereka menggunakan layer jarang, yang mengambil matriks sebagai input, yang memberikan keunggulan dibandingkan MP.  Dalam MP, setiap node bertanggung jawab untuk memahami seluruh gambar.  Di SNA, kami memecah gambar menjadi area (area piksel kecil lokal).  Lapisan output menggabungkan data yang diterima dari setiap simpul tersembunyi untuk menemukan pola.  Di bawah ini adalah gambar bagaimana lapisan terhubung. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae6/f7f/d61/ae6f7fd618d5296a0deecabdd2e06e77.png" alt="gambar"><br><br>  Sekarang mari kita lihat bagaimana SNA menemukan informasi dalam foto.  Sebelum itu, kita perlu memahami bagaimana tanda-tanda diekstraksi.  Dalam SNA, kami menggunakan lapisan yang berbeda, setiap lapisan mempertahankan tanda-tanda gambar, misalnya, memperhitungkan gambar anjing, ketika jaringan perlu mengklasifikasikan anjing, ia harus mengidentifikasi semua tanda, seperti mata, telinga, lidah, kaki, dll.  Tanda-tanda ini rusak dan dikenali di tingkat jaringan lokal menggunakan filter dan inti. <br><br><h2>  Bagaimana komputer melihat gambar? </h2><br>  Seseorang yang melihat gambar dan memahami artinya terdengar sangat masuk akal.  Katakanlah Anda berjalan, dan perhatikan banyak pemandangan di sekitar Anda.  Bagaimana kita memahami alam dalam kasus ini?  Kami memotret lingkungan menggunakan organ indera utama kami - mata, dan kemudian mengirimkannya ke retina.  Semuanya terlihat cukup menarik, bukan?  Sekarang mari kita bayangkan bahwa komputer melakukan hal yang sama.  Di komputer, gambar ditafsirkan menggunakan seperangkat nilai piksel yang berkisar dari 0 hingga 255. Komputer melihat nilai-nilai piksel ini dan memahaminya.  Sekilas, dia tidak tahu benda dan warna.  Itu hanya mengenali nilai-nilai piksel, dan gambar itu setara dengan satu set nilai-nilai piksel untuk komputer.  Kemudian, dengan menganalisis nilai-nilai piksel, ia secara bertahap mengetahui apakah gambar itu berwarna abu-abu atau berwarna.  Gambar dalam skala abu-abu hanya memiliki satu saluran, karena setiap piksel mewakili intensitas satu warna.  0 berarti hitam, dan 255 berarti putih, varian hitam dan putih lainnya, yaitu abu-abu, ada di antaranya. <br><br>  Gambar berwarna memiliki tiga saluran, merah, hijau dan biru.  Mereka mewakili intensitas 3 warna (matriks tiga dimensi), dan ketika nilainya berubah secara bersamaan, ini memberikan satu set besar warna, benar-benar palet warna!  Setelah itu, komputer mengenali kurva dan kontur objek dalam gambar.  Semua ini dapat dipelajari dalam jaringan saraf convolutional.  Untuk ini, kami akan menggunakan PyTorch untuk memuat dataset dan menerapkan filter ke gambar.  Berikut ini adalah cuplikan kode. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Load the libraries import torch import numpy as np from torchvision import datasets import torchvision.transforms as transforms # Set the parameters num_workers = 0 batch_size = 20 # Converting the Images to tensors using Transforms transform = transforms.ToTensor() train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform) test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform) # Loading the Data train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers) test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers) import matplotlib.pyplot as plt %matplotlib inline dataiter = iter(train_loader) images, labels = dataiter.next() images = images.numpy() # Peeking into dataset fig = plt.figure(figsize=(25, 4)) for image in np.arange(20): ax = fig.add_subplot(2, 20/2, image+1, xticks=[], yticks=[]) ax.imshow(np.squeeze(images[image]), cmap='gray') ax.set_title(str(labels[image].item()))</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/304/163/1ad/3041631ad58d7300a35af90b39b94584.png" alt="gambar"><br><br>  Sekarang mari kita lihat bagaimana satu gambar dimasukkan ke dalam jaringan saraf. <br><br><pre> <code class="python hljs">img = np.squeeze(images[<span class="hljs-number"><span class="hljs-number">7</span></span>]) fig = plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">12</span></span>)) ax = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">111</span></span>) ax.imshow(img, cmap=<span class="hljs-string"><span class="hljs-string">'gray'</span></span>) width, height = img.shape thresh = img.max()/<span class="hljs-number"><span class="hljs-number">2.5</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(width): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(height): val = round(img[x][y],<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> img[x][y] !=<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> ax.annotate(str(val), xy=(y,x), color=<span class="hljs-string"><span class="hljs-string">'white'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> img[x][y]&lt;thresh <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-string"><span class="hljs-string">'black'</span></span>)</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/264/f15/bff/264f15bffe653ae237f3e2fa1fc5c868.png" alt="gambar"><br><br>  Ini adalah bagaimana angka "3" dipecah menjadi piksel.  Dari himpunan digit tulisan tangan, "3" dipilih secara acak, di mana nilai piksel ditampilkan.  Di sini ToTensor () menormalkan nilai piksel aktual (0â€“255) dan membatasinya hingga rentang dari 0 hingga 1. Mengapa ini?  Karena memudahkan perhitungan di bagian berikutnya, baik untuk menafsirkan gambar, atau untuk menemukan pola umum yang ada di dalamnya. <br><br><h2>  Buat filter Anda sendiri </h2><br>  Filter, sesuai namanya, menyaring informasi.  Dalam kasus jaringan saraf convolutional, ketika bekerja dengan gambar, informasi tentang piksel difilter.  Kenapa kita harus memfilter sama sekali?  Ingatlah bahwa komputer harus melalui proses belajar untuk memahami gambar, sangat mirip dengan cara seorang anak melakukannya.  Dalam hal ini, bagaimanapun, kita tidak perlu bertahun-tahun!  Singkatnya, dia belajar dari awal dan kemudian maju ke keseluruhan. <br><br>  Oleh karena itu, jaringan pada awalnya harus mengetahui semua bagian kasar dari gambar, yaitu tepi, kontur, dan elemen tingkat rendah lainnya.  Setelah mereka ditemukan, jalan untuk gejala yang kompleks diaspal.  Untuk sampai kepada mereka, pertama-tama kita harus mengekstrak atribut tingkat rendah, lalu yang menengah, dan yang lebih tinggi.  Filter adalah cara untuk mengekstrak informasi yang dibutuhkan pengguna, dan bukan hanya transfer data yang tidak jelas, karena itu komputer tidak memahami penataan gambar.  Pada awalnya, fungsi tingkat rendah dapat diekstraksi berdasarkan filter tertentu.  Filter di sini juga merupakan seperangkat nilai piksel, mirip dengan gambar.  Ini dapat dipahami sebagai bobot yang menghubungkan lapisan-lapisan dalam jaringan saraf convolutional.  Bobot atau filter ini dikalikan dengan nilai input untuk menghasilkan gambar perantara yang mewakili pemahaman komputer terhadap gambar.  Kemudian mereka dikalikan dengan beberapa filter lagi untuk memperluas tampilan.  Kemudian mendeteksi organ-organ yang terlihat dari seseorang (asalkan seseorang hadir dalam gambar).  Belakangan, dengan dimasukkannya beberapa filter dan beberapa lapisan lagi, komputer berseru: â€œOh, ya!  Ini laki-laki. " <br><br>  Jika kita berbicara tentang filter, maka kita memiliki banyak opsi.  Anda mungkin ingin mengaburkan gambar, lalu menerapkan filter blur, jika Anda perlu menambahkan ketajaman, maka filter ketajaman akan datang untuk menyelamatkan, dll. <br><br>  Mari kita lihat beberapa cuplikan kode untuk memahami fungsionalitas filter. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/679/6a4/bb4/6796a4bb4830bda29c6d14212274a286.png" alt="gambar"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/752/a89/805/752a89805fba54b5d0f9e90073ca9fde.png" alt="gambar"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/84f/8a1/f9c/84f8a1f9c92b1996b0e4eed4a2a7dd5b.png" alt="gambar"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/142/635/038/142635038ecef3606d53d5d9c85b26f8.png" alt="gambar"><br><br>  Ini adalah bagaimana gambar terlihat setelah menerapkan filter, dalam hal ini kami menggunakan filter Sobel. <br><br><h2>  Jaringan Saraf Konvolusional </h2><br>  Sejauh ini, kita telah melihat bagaimana filter digunakan untuk mengekstraksi fitur dari gambar.  Sekarang, untuk melengkapi seluruh jaringan saraf convolutional, kita perlu tahu tentang semua lapisan yang kita gunakan untuk mendesainnya.  Lapisan yang digunakan dalam SNA, <br><br><ol><li>  Lapisan konvolusional </li><li>  Lapisan pooling </li><li>  Lapisan terikat sepenuhnya </li></ol><br>  Dengan ketiga lapisan, penggolong gambar konvolusional terlihat seperti ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8b4/927/c31/8b4927c31b5f951d7026b30d68695bea.png" alt="gambar"><br><br>  Sekarang mari kita lihat apa yang dilakukan setiap layer. <br><br>  <b>Lapisan convolutional (CONV)</b> menggunakan filter yang melakukan operasi konvolusi dengan memindai gambar input.  Hyperparameter-nya meliputi ukuran filter, yang bisa 2x2, 3x3, 4x4, 5x5 (tetapi tidak terbatas pada ini) dan langkah S. Hasilnya O disebut peta fitur atau peta aktivasi di mana semua fitur dihitung menggunakan lapisan input dan filter.  Di bawah ini adalah gambar pembuatan peta fitur ketika menerapkan konvolusi, <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2a/14d/aab/a2a14daab68c91f8d92ba0c54509493b.png" alt="gambar"><br><br>  <b>Lapisan gabungan (POOL)</b> digunakan untuk memadatkan fitur yang biasanya digunakan setelah lapisan konvolusi.  Ada dua jenis operasi serikat - ini adalah serikat maksimum dan rata-rata, di mana nilai maksimum dan rata-rata dari karakteristik diambil, masing-masing.  Berikut ini adalah operasi operasi gabungan, <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c2d/03f/2f8/c2d03f2f8734efade8cbc80d44d3767e.png" alt="gambar"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/01a/e5c/558/01ae5c558fa6647bfb9c19b9edabbb37.png" alt="gambar"><br><br>  <b>Fully terhubung lapisan (FCs)</b> beroperasi dengan input datar, di mana setiap input terhubung ke semua neuron.  Mereka biasanya digunakan pada akhir jaringan untuk menghubungkan lapisan tersembunyi ke lapisan keluaran, yang membantu mengoptimalkan skor kelas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d28/558/188/d285581882fa97824cdc0ad6ecb31873.png" alt="gambar"><br><br><h3>  Visualisasi SNA di PyTorch </h3><br>  Sekarang kita memiliki ideologi lengkap untuk membangun SNA, mari kita terapkan SNA menggunakan kerangka PyTorch dari Facebook. <br><br>  <b>Langkah 1</b> : Unduh gambar input untuk dikirim melalui jaringan.  (Di sini kita melakukannya dengan Numpy dan OpenCV) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline img_path = <span class="hljs-string"><span class="hljs-string">'dog.jpg'</span></span> bgr_img = cv2.imread(img_path) gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY) <span class="hljs-comment"><span class="hljs-comment"># Normalise gray_img = gray_img.astype("float32")/255 plt.imshow(gray_img, cmap='gray') plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/291/d0f/3d2/291d0f3d28f3091716c3aba41dc35c59.png" alt="gambar"><br><br>  <b>Langkah 2</b> : Render Filter <br><br>  Mari kita visualisasikan filter untuk lebih memahami yang mana yang akan kita gunakan, <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np filter_vals = np.array([ [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>] ]) print(<span class="hljs-string"><span class="hljs-string">'Filter shape: '</span></span>, filter_vals.shape) <span class="hljs-comment"><span class="hljs-comment"># Defining the Filters filter_1 = filter_vals filter_2 = -filter_1 filter_3 = filter_1.T filter_4 = -filter_3 filters = np.array([filter_1, filter_2, filter_3, filter_4]) # Check the Filters fig = plt.figure(figsize=(10, 5)) for i in range(4): ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[]) ax.imshow(filters[i], cmap='gray') ax.set_title('Filter %s' % str(i+1)) width, height = filters[i].shape for x in range(width): for y in range(height): ax.annotate(str(filters[i][x][y]), xy=(y,x), color='white' if filters[i][x][y]&lt;0 else 'black')</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/4c7/75f/1fc/4c775f1fc19bd461679d5a45831f1e2e.png" alt="gambar"><br><br>  <b>Langkah 3</b> : Tentukan SNA <br><br>  SNA ini memiliki lapisan konvolusional dan lapisan penyatuan dengan fungsi maksimum, dan bobot diinisialisasi menggunakan filter yang ditunjukkan di atas, <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn.functional <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> F <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Net</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, weight)</span></span></span><span class="hljs-function">:</span></span> super(Net, self).__init__() <span class="hljs-comment"><span class="hljs-comment"># initializes the weights of the convolutional layer to be the weights of the 4 defined filters k_height, k_width = weight.shape[2:] # assumes there are 4 grayscale filters self.conv = nn.Conv2d(1, 4, kernel_size=(k_height, k_width), bias=False) # initializes the weights of the convolutional layer self.conv.weight = torch.nn.Parameter(weight) # define a pooling layer self.pool = nn.MaxPool2d(2, 2) def forward(self, x): # calculates the output of a convolutional layer # pre- and post-activation conv_x = self.conv(x) activated_x = F.relu(conv_x) # applies pooling layer pooled_x = self.pool(activated_x) # returns all layers return conv_x, activated_x, pooled_x # instantiate the model and set the weights weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor) model = Net(weight) # print out the layer in the network print(model)</span></span></code> </pre><br><blockquote><pre> <code class="plaintext hljs">Net( (conv): Conv2d(1, 4, kernel_size=(4, 4), stride=(1, 1), bias=False) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) )</code> </pre> </blockquote>  <b>Langkah 4</b> : Render Filter <br>  Sekilas filter yang digunakan, <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">viz_layer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(layer, n_filters= </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_filters): ax = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, n_filters, i+<span class="hljs-number"><span class="hljs-number">1</span></span>) ax.imshow(np.squeeze(layer[<span class="hljs-number"><span class="hljs-number">0</span></span>,i].data.numpy()), cmap=<span class="hljs-string"><span class="hljs-string">'gray'</span></span>) ax.set_title(<span class="hljs-string"><span class="hljs-string">'Output %s'</span></span> % str(i+<span class="hljs-number"><span class="hljs-number">1</span></span>)) fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>)) fig.subplots_adjust(left=<span class="hljs-number"><span class="hljs-number">0</span></span>, right=<span class="hljs-number"><span class="hljs-number">1.5</span></span>, bottom=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, top=<span class="hljs-number"><span class="hljs-number">1</span></span>, hspace=<span class="hljs-number"><span class="hljs-number">0.05</span></span>, wspace=<span class="hljs-number"><span class="hljs-number">0.05</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): ax = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, i+<span class="hljs-number"><span class="hljs-number">1</span></span>, xticks=[], yticks=[]) ax.imshow(filters[i], cmap=<span class="hljs-string"><span class="hljs-string">'gray'</span></span>) ax.set_title(<span class="hljs-string"><span class="hljs-string">'Filter %s'</span></span> % str(i+<span class="hljs-number"><span class="hljs-number">1</span></span>)) gray_img_tensor = torch.from_numpy(gray_img).unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>).unsqueeze(<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br>  Filter: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/885/5c9/cac/8855c9cace448bed1d831c3dc4731828.png" alt="gambar"><br><br>  <b>Langkah 5</b> : Hasil yang Difilter Menurut Lapisan <br><br>  Gambar-gambar yang muncul di lapisan CONV dan POOL ditunjukkan di bawah ini. <br><br><pre> <code class="python hljs">viz_layer(activated_layer) viz_layer(pooled_layer)</code> </pre><br>  Lapisan konvolusional <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6bb/4c8/1bc/6bb4c81bc6ef16044dfc22e9e36bbaa6.png" alt="gambar"><br><br>  Lapisan Pooling <br><br><img src="https://habrastorage.org/getpro/habr/post_images/789/278/823/78927882302ae10f6403ba3a498669fd.png" alt="gambar"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sumber</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id436838/">https://habr.com/ru/post/id436838/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id436800/index.html">Teknik proyek DIY. Bagian dua</a></li>
<li><a href="../id436822/index.html">Android Robotics hingga 2019: Kisah nyata; dalam 5 bagian; bagian 3</a></li>
<li><a href="../id436828/index.html">Transisi ke Boost-1.65.1 dan bug yang muncul</a></li>
<li><a href="../id436830/index.html">Android Robotics hingga 2019: Kisah nyata; dalam 5 bagian; bagian 5</a></li>
<li><a href="../id436836/index.html">Manfaat menganalisis aplikasi level 7 di firewall. Bagian 2. Keamanan</a></li>
<li><a href="../id436840/index.html">Jalan dari Gloss ke Neuroscience: Podcast Tematik tentang Karier di Media dan Pemasaran Konten</a></li>
<li><a href="../id436842/index.html">Solusi Veeam untuk pencadangan dan pemulihan mesin virtual pada platform Nutanix AHV. Bagian 2</a></li>
<li><a href="../id436846/index.html">Intisari bahan-bahan segar dari dunia front-end untuk minggu terakhir No. 348 (14-20 Januari 2019)</a></li>
<li><a href="../id436848/index.html">NSA mengumumkan rilis alat internal untuk rekayasa balik</a></li>
<li><a href="../id436850/index.html">Kesalahan umum saat menulis tes unit. Kuliah Yandex</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö∂üèø üïã üçº √úberblick √ºber AI & ML-L√∂sungen im Jahr 2018 und Prognosen f√ºr 2019: Teil 1 - NLP, Computer Vision üññüèø üóÉÔ∏è üò¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! Ich pr√§sentiere Ihnen eine √úbersetzung des Analytics Vidhya- Artikels mit einem √úberblick √ºber AI / ML-Ereignisse in den Trends 2018...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úberblick √ºber AI & ML-L√∂sungen im Jahr 2018 und Prognosen f√ºr 2019: Teil 1 - NLP, Computer Vision</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439688/"><blockquote> Hallo allerseits!  Ich pr√§sentiere Ihnen eine √úbersetzung des <i>Analytics Vidhya-</i> Artikels mit einem √úberblick √ºber AI / ML-Ereignisse in den Trends 2018 und 2019.  Das Material ist ziemlich gro√ü und daher in zwei Teile unterteilt.  Ich hoffe, dass der Artikel nicht nur spezialisierte Spezialisten interessiert, sondern auch diejenigen, die sich f√ºr das Thema KI interessieren.  Viel Spa√ü beim Lesen! <br><br><div class="spoiler">  <b class="spoiler_title">Artikelnavigation</b> <div class="spoiler_text">  <b>Teil 1</b> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verarbeitung nat√ºrlicher Sprache (NLP)</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NLP-Trends f√ºr 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Computer Vision</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Trends in der Bildverarbeitung f√ºr 2019</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 2</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tools und Bibliotheken</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AutoML-Trends f√ºr 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verst√§rkungslernen</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verst√§rkungstrends f√ºr 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">KI f√ºr gute Jungs - Bewegung in Richtung ‚Äûethische‚Äú KI</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ethische Trends in der KI f√ºr 2019</a> <br></div></div></blockquote><br><h2>  Einf√ºhrung </h2><br>  Die letzten Jahre f√ºr KI-Enthusiasten und Profis des maschinellen Lernens sind auf der Suche nach einem Traum vergangen.  Diese Technologien sind keine Nischen mehr, haben sich zum Mainstream entwickelt und wirken sich bereits jetzt auf das Leben von Millionen von Menschen aus.  KI-Ministerien wurden in verschiedenen L√§ndern eingerichtet [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weitere Details hier</a> - ca.  per.] und Budgets werden zugewiesen, um mit diesem Rennen Schritt zu halten. <br><br>  Gleiches gilt f√ºr Data-Science-Profis.  Vor ein paar Jahren konnte man sich wohl f√ºhlen, wenn man ein paar Werkzeuge und Tricks kannte, aber diesmal ist es vorbei.  Die Anzahl der j√ºngsten Ereignisse in der Datenwissenschaft und die Menge an Wissen, die erforderlich ist, um mit der Zeit in diesem Bereich Schritt zu halten, sind erstaunlich. <br><br>  Ich beschloss, einen Schritt zur√ºckzutreten und die Entwicklungen in einigen Schl√ºsselbereichen auf dem Gebiet der k√ºnstlichen Intelligenz aus Sicht von Data-Science-Experten zu betrachten.  Welche Ausbr√ºche sind aufgetreten?  Was ist 2018 passiert und was erwartet Sie 2019?  Lesen Sie diesen Artikel f√ºr Antworten! <a name="habracut"></a><br><br>  PS Wie in jeder Prognose sind nachfolgend meine pers√∂nlichen Schlussfolgerungen aufgef√ºhrt, die auf Versuchen beruhen, einzelne Fragmente zu einem Gesamtbild zu kombinieren.  Wenn sich Ihre Sichtweise von meiner unterscheidet, w√ºrde ich mich freuen, Ihre Meinung dar√ºber zu erfahren, was sich 2019 in der Datenwissenschaft noch √§ndern k√∂nnte. <br><br>  Die Bereiche, die wir in diesem Artikel behandeln werden, sind: <br><br>  - Nat√ºrliche Sprachprozesse (NLP) <br>  - Computer Vision <br>  - Tools und Bibliotheken <br>  - Verst√§rkungslernen <br>  - Ethikprobleme in der KI <br><br><a name="NLP"></a><h2>  Verarbeitung nat√ºrlicher Sprache (NLP) </h2><br>  Maschinen zu zwingen, W√∂rter und S√§tze zu analysieren, schien immer ein Wunschtraum zu sein.  Es gibt viele Nuancen und Merkmale in Sprachen, die selbst f√ºr Menschen manchmal schwer zu verstehen sind, aber 2018 war ein echter Wendepunkt f√ºr NLP. <br><br>  Wir haben einen gro√üartigen Durchbruch nach dem anderen gesehen: ULMFiT, ELMO, OpenAl Transformer, Google BERT, und dies ist keine vollst√§ndige Liste.  Die erfolgreiche Anwendung des Transfer-Lernens (die Kunst, vorab trainierte Modelle auf Daten anzuwenden) hat NLP die T√ºr f√ºr eine Vielzahl von Aufgaben ge√∂ffnet. <br><blockquote>  Transferlernen - Erm√∂glicht die Anpassung eines vorab trainierten Modells / Systems an Ihre spezifische Aufgabe mit relativ geringen Datenmengen. </blockquote>  Schauen wir uns einige dieser Schl√ºsselentwicklungen genauer an. <br><br><h3>  ULMFiT </h3><br>  ULMFiT wurde von Sebastian Ruder und Jeremy Howard (fast.ai) entwickelt und war das erste Framework, das in diesem Jahr Transferlernen erhielt.  F√ºr die Uneingeweihten steht das Akronym ULMFiT f√ºr ‚ÄûUniversal Language Model Fine-Tuning‚Äú.  Jeremy und Sebastian haben zu Recht das Wort ‚Äûuniversal‚Äú zu ULMFiT hinzugef√ºgt - dieses Framework kann auf fast jede NLP-Aufgabe angewendet werden! <br><br>  Das Beste an ULMFiT ist, dass Sie Modelle nicht von Grund auf neu trainieren m√ºssen!  Forscher haben bereits das Schwierigste f√ºr Sie getan - nehmen Sie an und bewerben Sie sich in Ihren Projekten.  ULMFiT √ºbertraf andere Methoden in sechs Textklassifizierungsaufgaben. <br><br>  Sie k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> Tutorial von Pratek Joshi [Pateek Joshi - ca.  trans.], wie Sie ULMFiT f√ºr jede Aufgabe der Textklassifizierung verwenden k√∂nnen. <br><br><h3>  ELMo </h3><br>  Ratet mal, was die Abk√ºrzung ELMo bedeutet?  Akronym f√ºr Einbettungen aus Sprachmodellen [Anh√§nge aus Sprachmodellen - ca.  trans.].  Und ELMo erregte direkt nach der Ver√∂ffentlichung die Aufmerksamkeit der ML-Community. <br><br>  ELMo verwendet Sprachmodelle, um Anh√§nge f√ºr jedes Wort zu erhalten, und ber√ºcksichtigt auch den Kontext, in dem das Wort in einen Satz oder Absatz passt.  Der Kontext ist ein kritischer Aspekt von NLP, bei dem die meisten Entwickler zuvor versagt haben.  ELMo verwendet bidirektionale LSTMs, um Anh√§nge zu erstellen. <br><blockquote>  Das Langzeitged√§chtnis (LSTM) ist eine Art Architektur von wiederkehrenden neuronalen Netzen, die 1997 von Sepp Hochreiter und J√ºrgen Schmidhuber vorgeschlagen wurde.  Wie die meisten wiederkehrenden neuronalen Netze ist ein LSTM-Netz in dem Sinne universell, dass es mit einer ausreichenden Anzahl von Netzelementen jede Berechnung durchf√ºhren kann, zu der ein normaler Computer in der Lage ist, was eine geeignete Gewichtsmatrix erfordert, die als Programm betrachtet werden kann.  Im Gegensatz zu herk√∂mmlichen wiederkehrenden neuronalen Netzen eignet sich das LSTM-Netz gut zum Training der Probleme der Klassifizierung, Verarbeitung und Vorhersage von Zeitreihen in F√§llen, in denen wichtige Ereignisse durch Zeitverz√∂gerungen mit unbestimmter Dauer und Grenzen getrennt sind. <br><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a> </blockquote>  Wie ULMFiT verbessert ELMo die Produktivit√§t bei der L√∂sung einer gro√üen Anzahl von NLP-Aufgaben erheblich, z. B. bei der Analyse der Textstimmung oder der Beantwortung von Fragen. <br><br><h3>  BERT von Google </h3><br>  Viele Experten stellen fest, dass die Ver√∂ffentlichung von BERT den Beginn einer neuen √Ñra in NLP markiert.  Nach ULMFiT und ELMo √ºbernahm BERT die F√ºhrung und zeigte hohe Leistung.  In der urspr√ºnglichen Ank√ºndigung hei√üt es: ‚ÄûBERT ist konzeptionell einfach und empirisch leistungsf√§hig.‚Äú <br><br>  BERT hat in 11 NLP-Aufgaben hervorragende Ergebnisse gezeigt!  Siehe die Ergebnisse in SQuAD-Tests: <br><br><img src="https://habrastorage.org/webt/rf/6n/cz/rf6nczjjvbcz1cg4nxfeo-lm7ou.png"><br><br>  Willst du es versuchen?  Sie k√∂nnen die Neuimplementierung in PyTorch oder den TensorFlow-Code von Google verwenden und versuchen, das Ergebnis auf Ihrem Computer zu wiederholen. <br><br><h3>  Facebook PyText </h3><br>  Wie konnte sich Facebook von diesem Rennen fernhalten?  Das Unternehmen bietet ein eigenes Open-Source-NLP-Framework namens PyText an.  Laut einer von Facebook ver√∂ffentlichten Studie hat PyText die Genauigkeit von Konversationsmodellen um 10% erh√∂ht und die Trainingszeit verk√ºrzt. <br><br>  PyText steht tats√§chlich hinter mehreren eigenen Facebook-Produkten wie Messenger.  Die Zusammenarbeit mit ihm wird Ihrem Portfolio also einen guten Punkt und unsch√§tzbares Wissen hinzuf√ºgen, das Sie zweifellos gewinnen werden. <br><br>  Sie k√∂nnen es selbst versuchen und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Code von GitHub herunterladen</a> . <br><br><h3>  Google Duplex </h3><br>  Es ist kaum zu glauben, dass Sie noch nichts von Google Duplex geh√∂rt haben.  Hier ist eine Demo, die lange Zeit in den Schlagzeilen aufblitzte: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NO0-5MuJvew" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Da es sich um ein Google-Produkt handelt, besteht kaum eine Chance, dass der Code fr√ºher oder sp√§ter f√ºr alle ver√∂ffentlicht wird.  Nat√ºrlich wirft diese Demonstration viele Fragen auf: von ethischen zu Datenschutzfragen, aber wir werden sp√§ter dar√ºber sprechen.  Genie√üen Sie vorerst nur, wie weit wir mit ML in den letzten Jahren gekommen sind. <br><br><a name="NLPtrends"></a><h2>  NLP-Trends 2019 </h2><br>  Wer kann besser als Sebastian Ruder selbst eine Vorstellung davon geben, wohin die NLP 2019 steuert?  Hier sind seine Ergebnisse: <br><blockquote><ol><li>  Die Verwendung von vorgefertigten Sprachinvestitionsmodellen wird weit verbreitet sein.  Fortgeschrittene Modelle ohne Unterst√ºtzung werden sehr selten sein. </li><li>  Es werden vorab trainierte Ansichten angezeigt, die spezielle Informationen codieren k√∂nnen, die die Anh√§nge des Sprachmodells erg√§nzen.  Abh√§ngig von den Anforderungen der Aufgabe k√∂nnen wir verschiedene Arten von vorgefertigten Pr√§sentationen gruppieren. </li><li>  Weitere Arbeiten werden im Bereich mehrsprachiger Anwendungen und mehrsprachiger Modelle erscheinen.  Insbesondere wenn wir uns auf die Einbettung von W√∂rtern in verschiedenen Sprachen st√ºtzen, werden wir die Entstehung tief vorgefertigter Darstellungen in verschiedenen Sprachen sehen. </li></ol></blockquote><a name="cv"></a><h2>  Computer Vision </h2><br><img src="https://habrastorage.org/webt/pu/aj/_c/puaj_c89feaiultos4yynrcj7x4.jpeg"><br><br>  Computer Vision ist heute das beliebteste Gebiet im Bereich des tiefen Lernens.  Es scheint, dass die ersten Fr√ºchte der Technologie bereits erhalten wurden und wir uns im Stadium der aktiven Entwicklung befinden.  Unabh√§ngig davon, ob es sich um ein Bild oder ein Video handelt, entstehen viele Frameworks und Bibliotheken, mit denen sich die Probleme der Bildverarbeitung leicht l√∂sen lassen. <br><br>  Hier ist meine Liste der besten L√∂sungen, die dieses Jahr zu sehen waren. <br><br><h3>  BigGANs raus </h3><br>  Ian Goodfellow entwarf die GANs im Jahr 2014 und das Konzept brachte eine Vielzahl von Anwendungen hervor.  Jahr f√ºr Jahr beobachteten wir, wie das urspr√ºngliche Konzept f√ºr die Anwendung in realen F√§llen fertiggestellt wurde.  Eines blieb jedoch bis zu diesem Jahr unver√§ndert: Computergenerierte Bilder waren zu leicht zu unterscheiden.  Im Rahmen trat immer eine gewisse Inkonsistenz auf, die den Unterschied sehr deutlich machte. <br><br>  In den letzten Monaten haben sich Verschiebungen in diese Richtung ergeben, und mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schaffung von BigGAN</a> k√∂nnen solche Probleme ein f√ºr alle Mal gel√∂st werden.  Schauen Sie sich die mit dieser Methode erzeugten Bilder an: <br><br><img src="https://habrastorage.org/webt/mo/w7/ow/mow7owldedw4r1jtwex6wbfwwje.png"><br><br>  Ohne ein Mikroskop ist es schwer zu sagen, was mit diesen Bildern nicht stimmt.  Nat√ºrlich wird jeder f√ºr sich selbst entscheiden, aber es besteht kein Zweifel daran, dass das GAN die Art und Weise ver√§ndert, wie wir digitale Bilder (und Videos) wahrnehmen. <br><br>  Als Referenz: Diese Modelle wurden zuerst auf dem ImageNet-Datensatz und dann auf dem JFT-300M trainiert, um zu demonstrieren, dass diese Modelle gut von einem Datensatz auf einen anderen √ºbertragen werden.  Hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zu einer Seite</a> aus der GAN-Mailingliste, auf der erkl√§rt wird, wie das GAN visualisiert und verstanden wird. <br><br><h3>  Model Fast.ai trainierte in 18 Minuten auf ImageNet </h3><br>  Dies ist eine wirklich coole Implementierung.  Es ist weit verbreitet, dass Sie f√ºr die Durchf√ºhrung von Deep-Learning-Aufgaben Terabyte an Daten und gro√üe Computerressourcen ben√∂tigen.  Gleiches gilt f√ºr das Training des Modells von Grund auf auf ImageNet-Daten.  Die meisten von uns dachten genauso, bevor ein paar Leute auf fast.ai nicht jedem das Gegenteil beweisen konnten. <br><br>  Ihr Modell ergab eine Genauigkeit von 93% mit beeindruckenden 18 Minuten.  Die von ihnen verwendete Hardware, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die</a> in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ihrem Blog</a> ausf√ºhrlich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beschrieben</a> wurde, bestand aus 16 √∂ffentlichen AWS-Cloud-Instanzen mit jeweils 8 NVIDIA V100-GPUs.  Sie erstellten einen Algorithmus unter Verwendung der Bibliotheken fast.ai und PyTorch. <br><br>  Die Gesamtkosten f√ºr die Montage betrugen nur 40 US-Dollar!  Jeremy hat ihre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ans√§tze und Methoden hier</a> ausf√ºhrlicher beschrieben.  Dies ist ein gemeinsamer Sieg! <br><br><h3>  vid2vid von NVIDIA </h3><br>  In den letzten 5 Jahren hat die Bildverarbeitung gro√üe Fortschritte gemacht, aber was ist mit Video?  Die Methoden zum Konvertieren von einem statischen in einen dynamischen Frame erwiesen sich als etwas komplizierter als erwartet.  K√∂nnen Sie eine Folge von Bildern aus einem Video entnehmen und vorhersagen, was im n√§chsten Bild passieren wird?  Solche Studien wurden bereits fr√ºher durchgef√ºhrt, aber die Ver√∂ffentlichungen waren bestenfalls vage. <br><br><img src="https://habrastorage.org/webt/hz/ox/hj/hzoxhjbehlnlzl8ivc-bgiz0vh0.png"><br><br>  NVIDIA hat beschlossen, seine Entscheidung Anfang dieses Jahres √∂ffentlich zug√§nglich zu machen [2018 - ca.  per.], die von der Gesellschaft positiv bewertet wurde.  Der Zweck von vid2vid besteht darin, eine Anzeigefunktion aus einem bestimmten Eingabevideo abzuleiten, um ein Ausgabevideo zu erstellen, das den Inhalt des Eingabevideos mit unglaublicher Genauigkeit wiedergibt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/S1OwOd-war8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Sie k√∂nnen ihre Implementierung auf PyTorch ausprobieren und hier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu GitHub bringen</a> . <br><br><a name="cvtrends"></a><h2>  Bildverarbeitungstrends f√ºr 2019 </h2><br>  Wie ich bereits erw√§hnt habe, werden wir 2019 eher die Entwicklung der Trends f√ºr 2018 als neue Durchbr√ºche sehen: selbstfahrende Autos, Gesichtserkennungsalgorithmen, virtuelle Realit√§t und mehr.  K√∂nnen Sie mir nicht zustimmen, wenn Sie eine andere Sichtweise oder Erg√§nzungen haben, teilen Sie es uns mit, was k√∂nnen wir 2019 noch erwarten? <br><br>  Das Thema Drohnen k√∂nnte in Erwartung der Zustimmung von Politikern und Regierung endlich gr√ºnes Licht in den Vereinigten Staaten bekommen (Indien liegt in dieser Angelegenheit weit zur√ºck).  Pers√∂nlich m√∂chte ich, dass mehr Forschung in realen Szenarien durchgef√ºhrt wird.  Konferenzen wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CVPR</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ICML</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bieten</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen</a> guten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberblick</a> √ºber die neuesten Errungenschaften in diesem Bereich, aber wie nah die Projekte an der Realit√§t sind, ist nicht sehr klar. <br><br>  "Visuelle Fragen beantworten" und "visuelle Dialogsysteme" k√∂nnten endlich mit einem lang erwarteten Deb√ºt herauskommen.  Diesen Systemen fehlt die F√§higkeit zur Verallgemeinerung, aber es wird erwartet, dass wir bald einen integrierten multimodalen Ansatz sehen werden. <br><br><img src="https://habrastorage.org/webt/s5/bn/uy/s5bnuydmsc8hf37vm26icbmwrgc.jpeg"><br><br>  Das Selbsttraining stand in diesem Jahr im Vordergrund.  Ich wette, dass es n√§chstes Jahr in einer viel gr√∂√üeren Anzahl von Studien Anwendung finden wird.  Dies ist eine wirklich coole Richtung: Zeichen werden direkt aus den Eingabedaten ermittelt, anstatt Zeit damit zu verschwenden, die Bilder manuell zu markieren.  Dr√ºcken wir die Daumen! <br><br><h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lesen Sie mehr: Teil 2 - Tools und Bibliotheken, AutoML, Reinforcement Learning, Ethik in der KI</a> </h4></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439688/">https://habr.com/ru/post/de439688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439676/index.html">Reagieren Sie auf Native- und C ++ - Integration f√ºr iOS und Android</a></li>
<li><a href="../de439678/index.html">Senden Sie an die Applied F # Challenge</a></li>
<li><a href="../de439680/index.html">Etwa 50% der Russen sind bereit, ihre pers√∂nlichen Daten zu verkaufen</a></li>
<li><a href="../de439682/index.html">Schulung Cisco 200-125 CCNA v3.0. Cisco Certified Network Specialist (CCNA). Tag 4. Gateway-Ger√§te</a></li>
<li><a href="../de439684/index.html">Bewerben Sie sich f√ºr die Applied F # Challenge</a></li>
<li><a href="../de439690/index.html">Vergleich der Leistung virtueller Maschinen von 6 Cloud-Plattformen: Selectel, MCS, I. Cloud, Google Cloud, AWS und Azure</a></li>
<li><a href="../de439692/index.html">AT & T wurde wegen √Ñnderung des Netzwerksymbols von 4G auf 5G E verklagt</a></li>
<li><a href="../de439694/index.html">Intelligentes Gewebe, das auf √Ñnderungen der K√∂rpertemperatur reagiert</a></li>
<li><a href="../de439696/index.html">Auf dem Wellenkamm oder "Ich will Mainstream" - aber lohnt es sich?</a></li>
<li><a href="../de439698/index.html">Einf√ºhrung in die Programmierung: Ein einfacher 3D-Shooter von Grund auf √ºber das Wochenende, Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
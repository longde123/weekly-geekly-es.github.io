<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ë üöà üõ†Ô∏è Professionelle lexikalische Analyse mit regul√§ren Ausdr√ºcken üëºüèª üë©‚Äçüéì üë©üèª‚Äç‚öïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Parsen von Text beginnt immer mit der lexikalischen Analyse oder dem Tokenisieren. Es gibt eine einfache M√∂glichkeit, dieses Problem f√ºr fast jede...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Professionelle lexikalische Analyse mit regul√§ren Ausdr√ºcken</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/462781/"><p>  Das Parsen von Text beginnt immer mit der lexikalischen Analyse oder dem Tokenisieren.  Es gibt eine einfache M√∂glichkeit, dieses Problem f√ºr fast jede Sprache mit regul√§ren Ausdr√ºcken zu l√∂sen.  Eine andere Verwendung des guten alten regul√§ren Ausdrucks. </p><a name="habracut"></a><br><p>  Ich habe oft die Aufgabe, Texte zu analysieren.  F√ºr einfache Aufgaben wie das Analysieren eines vom Benutzer eingegebenen Werts ist die grundlegende Funktionalit√§t f√ºr regul√§re Ausdr√ºcke ausreichend.  F√ºr komplexe und schwere Aufgaben wie das Schreiben eines Compilers oder die Analyse statischen Codes k√∂nnen Sie spezielle Tools (AntLR, JavaCC, Yacc) verwenden.  Aber ich sto√üe oft auf Aufgaben mittlerer Ebene, wenn es nicht gen√ºgend regul√§re Ausdr√ºcke gibt, aber ich keine Lust habe, schwere Werkzeuge in das Projekt zu ziehen.  Dar√ºber hinaus arbeiten diese Tools normalerweise zur Kompilierungsphase und erlauben zur Laufzeit keine √Ñnderung der Analyseparameter (z. B. Erstellen einer Liste von Schl√ºsselw√∂rtern aus einer Datei oder Datenbanktabelle). </p><br><p> Als Beispiel gebe ich eine Aufgabe an, die beim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beschleunigen von SQL-Abfragen entstanden ist</a> .  Wir haben die Protokolle unserer SQL-Abfragen analysiert und wollten nach bestimmten Regeln "schlechte" Abfragen finden.  Zum Beispiel Abfragen, bei denen dasselbe Feld mit ODER auf eine Reihe von Werten √ºberpr√ºft wird </p><br><pre><code class="sql hljs">name = 'John' OR name = 'Michael' OR name = 'Bob'</code> </pre> <br><p>  Wir wollten solche Anfragen durch ersetzen </p><br><pre> <code class="sql hljs">name IN ('John', 'Michael', 'Bob')</code> </pre> <br><p>  Regul√§re Ausdr√ºcke kommen nicht mehr zurecht, aber ich wollte auch keinen vollwertigen SQL-Parser mit AntLR erstellen.  Es w√§re m√∂glich, den Anforderungstext in Token aufzuteilen und einfachen Code zu verwenden, um das Parsen ohne spezielle Tools durchzuf√ºhren. </p><br><p>  Dieses Problem kann mit der Grundfunktionalit√§t regul√§rer Ausdr√ºcke gel√∂st werden.  Versuchen wir, die SQL-Abfrage in Token aufzuteilen.  Wir werden uns eine vereinfachte Version von SQL ansehen, um den Text nicht mit Details zu √ºberladen.  Um einen vollwertigen SQL-Lexer zu erstellen, m√ºssen Sie etwas komplexere regul√§re Ausdr√ºcke schreiben. </p><br><p>  Hier ist eine Reihe von Ausdr√ºcken f√ºr grundlegende SQL-Sprachtoken: </p><br><pre> <code class="plaintext hljs">1. keyword : \b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\b 2. id : [A-Za-z][A-Za-z0-9]* 3. real_number : [0-9]+\.[0-9]* 4. number : [0-9]+ 5. string : '[^']*' 6. space : \s+ 7. comment : \-\-[^\n\r]* 8. operation : [+\-\*/.=\(\)]</code> </pre> <br><p>  Ich m√∂chte auf den regul√§ren Ausdruck f√ºr das Schl√ºsselwort achten </p><br><pre> <code class="plaintext hljs">keyword : \b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\b</code> </pre> <br><p>  Es hat zwei Funktionen. </p><br><ol><li>  Der \ b-Operator wird beispielsweise am Anfang und am Ende verwendet, um das <strong>oder das</strong> Pr√§fix der Wortorganisation, die ein Schl√ºsselwort ist und die einige Regex-Engines ohne Verwendung des \ b-Operators in ein separates Token trennen, nicht abzuschneiden. </li><li>  Alle W√∂rter werden in nicht erfassenden Klammern (? :) gruppiert, die die √úbereinstimmung nicht erfassen.  Dies wird in Zukunft verwendet, um die Indizierung von regul√§ren Teilausdr√ºcken innerhalb des allgemeinen Ausdrucks nicht zu verletzen. </li></ol><br><p>  Jetzt k√∂nnen Sie alle diese Ausdr√ºcke mithilfe der Gruppierung und des Operators <strong>|</strong> zu einem Ganzen kombinieren </p><br><pre> <code class="plaintext hljs">(\b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\b)|([A-Za-z][A-Za-z0-9]*)|([0-9]+\.[0-9]*)|([0-9]+)|('[^']*')|(\s+)|(\-\-[^\n\r]*)|([+\-\*/.=\(\)])</code> </pre> <br><p>  Jetzt k√∂nnen Sie versuchen, diesen Ausdruck auf einen SQL-Ausdruck anzuwenden, beispielsweise auf einen solchen </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>) <span class="hljs-comment"><span class="hljs-comment">-- count of 'Johns' FROM person WHERE name = 'John'</span></span></code> </pre> <br><p>  Hier ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ergebnis</a> des Regex-Testers.  Durch Klicken auf den Link k√∂nnen Sie mit dem Ausdruck und dem Ergebnis der Analyse herumspielen.  Es ist ersichtlich, dass beispielsweise <strong>SELECT</strong> unmittelbar einer 1-Gruppe entspricht, die dem <strong>Schl√ºsselworttyp entspricht</strong> . </p><br><p><img src="https://habrastorage.org/webt/2_/aq/mp/2_aqmpj7fpnwgnmgwlf-rtp9rr4.png" alt="Bild"></p><br><p>  M√∂glicherweise stellen Sie fest, dass der gesamte Text der Anforderung in Teilzeichenfolgen unterteilt ist und jeweils einer bestimmten Gruppe entspricht.  Anhand der Gruppennummer k√∂nnen Sie diese mit dem Token-Typ (Token) korrelieren. </p><br><p>  Es ist nicht schwierig, den angegebenen Algorithmus in ein Programm in einer beliebigen Programmiersprache zu verwandeln, die regul√§re Ausdr√ºcke unterst√ºtzt.  Hier ist eine kleine Klasse, die dies in Java implementiert. </p><br><div class="spoiler">  <b class="spoiler_title">RegexTokenizer.java (+ noch ein paar Klassen)</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> org.example; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.ArrayList; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.Enumeration; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.List; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.regex.Matcher; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.regex.Pattern; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.stream.Collectors; <span class="hljs-comment"><span class="hljs-comment">/** *    . *   ,         . */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegexTokenizer</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Enumeration</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Token</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// ,      private final String content; //         private final ITokenType[] tokenTypes; private final Matcher matcher; //    private int currentPosition = 0; /** * @param content    * @param tokenTypes         */ public RegexTokenizer(String content, ITokenType[] tokenTypes) { this.content = content; this.tokenTypes = tokenTypes; //       List&lt;String&gt; regexList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; tokenTypes.length; i++) { ITokenType tokenType = tokenTypes[i]; regexList.add("(?&lt;g" + i + "&gt;" + tokenType.getRegex() + ")"); } String regex = regexList.stream().collect(Collectors.joining("|")); Pattern pattern = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); //    matcher = pattern.matcher(content); matcher.find(); } @Override public boolean hasMoreElements() { return currentPosition &lt; content.length(); } @Override public Token nextElement() { boolean found = currentPosition &gt; matcher.start() ? matcher.find() : true; int start = found ? matcher.start() : content.length(); int end = found ? matcher.end() : content.length(); if(found &amp;&amp; currentPosition == start) { currentPosition = end; //  -   for (int i = 0; i &lt; tokenTypes.length; i++) { String si = "g" + i; if (matcher.start(si) == start &amp;&amp; matcher.end(si) == end) { return createToken(content, tokenTypes[i], start, end); } } } throw new IllegalStateException("      " + currentPosition); } /** *  -  ,    ,     , *            (, ) * @param content     * @param tokenType   * @param start      * @param end      * @return  - */ protected Token createToken(String content, ITokenType tokenType, int start, int end) { return new Token(content.substring(start, end), tokenType, start); } /** *     SQL */ public enum SQLTokenType implements ITokenType { KEYWORD("\\b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\\b"), ID("[A-Za-z][A-Za-z0-9]*"), REAL_NUMBER("[0-9]+\\.[0-9]*"), NUMBER("[0-9]+"), STRING("'[^']*'"), SPACE("\\s+"), COMMENT("\\-\\-[^\\n\\r]*"), OPERATION("[+\\-\\*/.=\\(\\)]"); private final String regex; SQLTokenType(String regex) { this.regex = regex; } @Override public String getRegex() { return regex; } } public static void main(String[] args) { String s = "select count(id) -- count of 'Johns' \n" + "FROM person\n" + "where name = 'John'"; RegexTokenizer tokenizer = new RegexTokenizer(s, SQLTokenType.values()); while(tokenizer.hasMoreElements()) { Token token = tokenizer.nextElement(); System.out.println(token.getText() + " : " + token.getType()); } } } /** * -  () */ public class Token { //   private final String text; //   private final ITokenType type; //      private final int start; public Token(String text, ITokenType type, int start) { this.text = text; this.type = type; this.start = start; } public String getText() { return text; } public ITokenType getType() { return type; } public int getStart() { return start; } } /** *     */ public interface ITokenType { /** *       */ String getRegex(); }</span></span></code> </pre></div></div><br><p>  In dieser Klasse wird der Algorithmus unter Verwendung benannter Gruppen implementiert, die nicht in allen Engines vorhanden sind.  Mit dieser Funktion k√∂nnen Sie nicht nach Index, sondern nach Namen auf Gruppen zugreifen. Dies ist etwas praktischer als der Zugriff nach Index. </p><br><p>  Auf meinem I7 mit 2,3 GHz zeigt diese Klasse eine Analysegeschwindigkeit von 5 bis 20 MB pro Sekunde (abh√§ngig von der Komplexit√§t der Ausdr√ºcke).  Der Algorithmus kann parallelisiert werden, indem mehrere Dateien gleichzeitig analysiert werden, wodurch die Gesamtarbeitsgeschwindigkeit erh√∂ht wird. </p><br><p>  Ich habe mehrere √§hnliche Algorithmen im Netzwerk gefunden, bin jedoch auf Optionen gesto√üen, die keinen gemeinsamen regul√§ren Ausdruck bilden, aber konsistent regul√§re Ausdr√ºcke f√ºr jeden Token-Typ auf den Zeilenanfang anwenden, dann das gefundene Token vom Zeilenanfang verwerfen und erneut versuchen, alle regul√§ren Ausdr√ºcke anzuwenden.  Dies funktioniert etwa 10 bis 20 Mal langsamer, erfordert mehr Speicher und der Algorithmus ist komplizierter.  Ich habe eine h√∂here Arbeitsgeschwindigkeit nur mit meiner Implementierung regul√§rer Ausdr√ºcke erreicht, die auf DFA ( <strong>deterministic</strong> finite state machine) basiert.  In Regex-Motoren wird normalerweise NKA verwendet (eine nicht <strong>deterministische</strong> Finite-State-Maschine).  DFA ist 2-3 mal schneller, aber regul√§re Ausdr√ºcke sind aufgrund einer begrenzten Anzahl von Operatoren schwieriger zu schreiben. </p><br><p>  In meinem Beispiel f√ºr SQL habe ich regul√§re Ausdr√ºcke ein wenig vereinfacht, und der resultierende Tokenizer kann nicht als vollwertiger lexikalischer Analysator f√ºr SQL-Abfragen betrachtet werden. Der Zweck des Artikels besteht jedoch darin, das Prinzip aufzuzeigen und keinen echten SQL-Tokenizer zu erstellen.  Ich habe diesen Ansatz in meiner Praxis verwendet und vollwertige lexikalische Analysatoren f√ºr SQL, Java, C, XML, HTML, JSON, Pascal und sogar COBOL erstellt (ich musste daran basteln). </p><br><p>  Hier sind einige einfache Regeln zum Schreiben regul√§rer Ausdr√ºcke f√ºr die lexikalische Analyse. </p><br><ol><li>  Wenn dasselbe Token verschiedenen Typen zugewiesen werden kann (z. B. kann jedes Schl√ºsselwort als Bezeichner erkannt werden), muss zu Beginn ein engerer Typ definiert werden.  Dann wird zuerst der regul√§re Ausdruck daf√ºr angewendet und der Typ des Tokens bestimmt.  In meinem Beispiel werden die <strong>Schl√ºsselw√∂rter beispielsweise</strong> vor der <strong>ID</strong> definiert, und das <em>Auswahl-</em> Token wird als <strong>Schl√ºsselwort</strong> und nicht als <strong>ID</strong> erkannt </li><li>  Definieren Sie zuerst l√§ngere und dann k√ºrzere Token.  Beispielsweise m√ºssen Sie zuerst <em>&lt;=</em> , <em>&gt; = definieren</em> und dann trennen <em>&gt;</em> , <em>&lt;</em> , <em>=</em> In diesem Fall wird der Text <em>&lt;=</em> korrekt als ein einzelnes Token des Operators kleiner oder gleich erkannt und nicht als zwei separate Token <em>&lt;</em> und <em>=</em> </li><li>  Lernen Sie, <strong>Lookahead</strong> und <strong>Lookbehind zu verwenden</strong> .  Beispielsweise hat das Zeichen * in SQL die Bedeutung eines Multiplikationsoperators und aller Felder in der Tabelle.  Mit einem einfachen <strong>Lookbehind k√∂nnen Sie</strong> diese beiden F√§lle trennen, z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> regexp <strong>(? &lt;=. \ S <em>| select \ s</em> ) *</strong> findet das Zeichen * nur im Wert "alle Felder der Tabelle". </li><li>  Es ist manchmal n√ºtzlich, regul√§re Ausdr√ºcke f√ºr Fehler zu definieren, die im Text auftreten.  Wenn Sie beispielsweise die Syntax hervorheben, k√∂nnen Sie den Typ des unfertigen Zeichenfolgentokens als <code>'[^\n\r]*</code> .  W√§hrend der Bearbeitung von Text hat der Benutzer m√∂glicherweise keine Zeit, das Anf√ºhrungszeichen in der Zeichenfolge zu schlie√üen. Ihr Tokenizer kann diese Situation jedoch korrekt erkennen und hervorheben. </li></ol><br><p>  Mit diesen Regeln und der Anwendung dieses Algorithmus k√∂nnen Sie den Text f√ºr fast jede Sprache schnell in Token aufteilen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de462781/">https://habr.com/ru/post/de462781/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de462769/index.html">Anwendung von maschinellem Lernen und Datenwissenschaft in der Industrie</a></li>
<li><a href="../de462771/index.html">Sie hatten nichts zu verbergen</a></li>
<li><a href="../de462773/index.html">So arbeiten Sie mit Google Trends: Eine vollst√§ndige Anleitung f√ºr Anf√§nger</a></li>
<li><a href="../de462775/index.html">Homebridge-Automatisierung mit Node-Red</a></li>
<li><a href="../de462777/index.html">So bewerten Sie die Leistung von Linux-Servern: √ñffnen Sie Benchmarking-Tools</a></li>
<li><a href="../de462783/index.html">Matrix: 20 Jahre sp√§ter</a></li>
<li><a href="../de462787/index.html">Wie z√§hme ich einen Junior?</a></li>
<li><a href="../de462789/index.html">Von einem Entwickler ohne Gymnasium nach Deutschland</a></li>
<li><a href="../de462793/index.html">Matte mit einem Elefanten und einem Pferd. Die zyklische Methode "Gefangener des Kaukasus"</a></li>
<li><a href="../de462795/index.html">Deklaratives Schema und was daran in Magento 2 falsch ist</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘‚ğŸ¼ ğŸ”® ğŸ’…ğŸ¿ Moralische Maschine: gnadenlos oder bedeutungslos? ğŸ˜ ğŸ“ ğŸ‘©ğŸ½â€ğŸ’»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich habe mich entschlossen, diesen Artikel im Anschluss an diesen Beitrag zu schreiben. 


 Ich mÃ¶chte Sie an einen kurzen Punkt erinnern: In der Zeit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Moralische Maschine: gnadenlos oder bedeutungslos?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428181/"><p>  Ich habe mich entschlossen, diesen Artikel im Anschluss an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesen Beitrag</a> zu schreiben. </p><br><img src="https://habrastorage.org/webt/-x/08/ps/-x08pskb0ti0iupeu2iuduj3uus.jpeg"><br><br>  Ich mÃ¶chte Sie an einen kurzen Punkt erinnern: In der Zeitschrift Nature wurden die Ergebnisse einer mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Test</a> durchgefÃ¼hrten Studie verÃ¶ffentlicht. <br><p>  WorÃ¼ber mÃ¶chte ich schreiben? </p><br><p>  Erstens, warum diese Studie fÃ¼r die LÃ¶sung des genannten Problems und in der Form, in der sie durchgefÃ¼hrt wurde, absolut nutzlos ist. </p><br><p>  Zweitens, wie man eine solche Studie priorisiert. </p><br><p> Versuchen Sie drittens, verschiedene Unfallszenarien unter den im Test angegebenen Bedingungen zu simulieren. </p><a name="habracut"></a><br><p>  In diesem Beitrag hat der Autor nicht von Anfang an vergeblich einen Link zum Test eingefÃ¼gt.  Dies wÃ¼rde dazu beitragen, bedeutungslose Kommentare von Personen zu vermeiden, die die ursprÃ¼ngliche Botschaft der Studie nicht verstanden haben. <br>  Bitte machen Sie mindestens ein paar Mal <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Test</a></b> , um das Diskussionsthema zu verstehen. </p><br><h3>  Was sie versprochen haben, uns in der Studie zu zeigen </h3><br><p>  Die Diskussion des ersten Beitrags, episch fÃ¼r Habr, zeigte, dass die Mehrheit der Menschen nicht weiÃŸ, wie sie unter den gegebenen Bedingungen denken sollen, sondern anfÃ¤ngt zu phantasieren: "Sterben einige Menschen im Test?"  Immerhin kÃ¶nnen Sie beide FuÃŸgÃ¤nger und den Block / seitwÃ¤rts umgehen, um die Handbremse / das Zahnrad zu reiben / bremsen?  Aber ich wÃ¼rde ... ".  Verstehen Sie, dass dies ein vereinfachtes Beispiel fÃ¼r die Entwicklung von Aktionsalgorithmen und -richtlinien zur Regulierung des Autopilotverhaltens auf der StraÃŸe ist!  Unter dem Gesichtspunkt der Entwicklung von Sicherheitsregeln sind solche Extreme und Vereinfachungen gerechtfertigt.  Es geht um die mÃ¶glichen Konsequenzen, auf die die Menschen vorbereitet sein sollten.  Soldaten gehen nicht zu Minenfeldern, nicht weil dort jeder Quadratzentimeter abgebaut wird, sondern wegen der Wahrscheinlichkeit zu sterben.  Es ist normalerweise nicht sehr hoch, aber niemand wird es riskieren.  Daher ist im Test die Wahl zwischen 100% Tod aller Passagiere oder aller FuÃŸgÃ¤nger angemessen - so bezeichnen wir das Risiko, wenn man bedenkt, dass es inakzeptabel ist, Leben in unserer Gesellschaft zu riskieren. </p><br><p>  Die Botschaft der Studie lautet: Sie, die Menschen, die jetzt leben, mÃ¼ssen in einer Welt der Zukunft leben, die mit Autos auf dem Autopiloten gefÃ¼llt ist.  Und fÃ¼r uns, Entwickler von Automobilen, KI und anderen Dingen, ist es wichtig zu wissen, aber wie sollten sich Roboterroboter Ihrer Meinung nach verhalten?  Nun, hier sind Sie, ja, ja, Sie sind es - sagen Sie mir, was ich mit einem Robomobil tun soll, wenn Kopf und Katze darin fahren und es dabei ist, Obdachlose und Hunde zu vernichten?  Welche Ethik sollten Robomobile haben, wenn sie sich entscheiden mÃ¼ssen? </p><br><p>  Und nachdem wir das ursprÃ¼ngliche Motiv fÃ¼r die Studie identifiziert haben, mÃ¶chte ich einige Aspekte davon diskutieren. </p><br><h3>  Was die Studie tatsÃ¤chlich zeigte </h3><br><p>  Das erste, was auffÃ¤llt, ist, dass das Forschungsdesign Ã¼berhaupt nicht auf das erklÃ¤rte Ziel abzielt.  Die in Form von Dilemmata gestellten Aufgaben eignen sich nicht zur Schaffung einer â€Ethikâ€œ des Verhaltens von Roboterautos.  Eher nicht alle.  Hier sind die Dilemmata, die die Aufgabe erfÃ¼llen, â€Regeln fÃ¼r das Verhalten eines Roboterautos zu entwickeln, um die Schwere der Folgen eines Unfalls zu verringernâ€œ: </p><br><ul><li>  "Passagier / FuÃŸgÃ¤nger" - wÃ¤hlen Sie, wer gespeichert werden soll; </li><li>  "VerstoÃŸ gegen Verkehrsregeln" - entscheiden Sie, ob bewusstlose FuÃŸgÃ¤nger geopfert werden sollen; </li><li>  â€Anzahl potenzieller Opferâ€œ - WÃ¤hlen Sie aus, ob die Anzahl der Opfer Vorrang hat. </li></ul><br><p>  Und dann kommen die Parameter, die, wie sich herausstellt, fÃ¼r die Verurteilung in unserer zivilisierten Gesellschaft sehr wichtig sind.  Die Leute wurden ehrlich und unschuldig gefragt: Ihr Niveau an Sexismus, Lukismus, Ageismus?  Sind Sie fÃ¼r die Unterscheidung von Fett oder nicht klassifiziert?  Und schlieÃŸlich antworteten Hunderttausende ehrlich ... </p><br><p>  Bravo! </p><br><p>  Genau in den besten Traditionen unterhaltsamer Filme und Serien, wenn die Welt der Hauptfiguren tatsÃ¤chlich ein groÃŸer Sandkasten hinter einem hohen Zaun ist und es ihr Verhalten ist, das ein Experiment ist!  Soziologen, Psychologen und Kulturwissenschaftler erhielten unter dem Deckmantel der Ã¼beraus wichtigen Forschung auf dem Gebiet der Robotik und KI eine so aussagekrÃ¤ftige Stichprobe <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zum Trolley-Problem</a></b> , von der noch niemand zuvor getrÃ¤umt hatte!  Nun, auÃŸer dass die Hautfarbe nicht zur Umfrage hinzugefÃ¼gt wurde, aber dann wÃ¼rden die rassistischen ObertÃ¶ne der Studie mit WeiÃŸ genÃ¤ht ... oh. </p><br><p>  Im Ernst, dieser geschlechtsphÃ¤notypische Teil der Studie wird durch kategoriale Argumente abgeschnitten.  Das erste Argument ist der Humanismus. Als zivilisierte Menschen mÃ¼ssen wir den Vorrang des Wertes des menschlichen Lebens vor allen individuellen Unterschieden stellen.  Das heiÃŸt, die Formulierung der Frage ist als diskriminierend empÃ¶rend.  Das zweite Argument: Viele UnfÃ¤lle ereignen sich, und in der Grenze wird die Verteilung der Opfer nach Aussehen, Bildung, Geschlecht und Alter zu ihren gesellschaftlichen Anteilen tendieren. Daher ist es zumindest seltsam, dies zusÃ¤tzlich zu regeln.  Das dritte Argument: Es erscheint nicht ratsam, kÃ¼nstliche Intelligenz zu schaffen, die einen Anzug von Brioni von einem Pullover von Bershka unterscheidet, um weiter zu vergleichen, ob eine Person Status hat und ob es sich lohnt, sie zu vernichten.  AuÃŸerdem wÃ¼rde ich nicht darauf vertrauen, dass die KI urteilt - ein obdachloser FuÃŸgÃ¤nger oder ein Wissenschaftler?  (Hallo zu den Frisuren der angesehenen Wissenschaftler Perelman oder Gelfand :)) </p><br><p>  ZusÃ¤tzlich zu diesen unnÃ¶tigen Parametern verwerfen wir leicht die verbleibenden zwei: SpeziesspezifitÃ¤t und Nichteinmischung.  Ja, wir werden kleine Tiere vernichten, um Menschen zu retten, die gedacht hÃ¤tten.  Und was den Parameter â€Intervention / Nichtinterferenzâ€œ durch ManÃ¶vrieren betrifft, so ist dieser wesentliche Teil des Trolley-Problems nicht nur ein Hindernis fÃ¼r das Auto, da die Maschine nicht nach der Ethik handelt, sondern nach den darin festgelegten Algorithmen.  Und da wir uns die Aufgabe gestellt haben, wie sich das Auto bei einem Unfall mit einer Kollision mit Menschen verhalten soll, gehen wir im Wortlaut davon aus, dass es sich irgendwie verhalten muss.  Heutzutage bewÃ¤ltigt der Schienenverkehr erfolgreich unkomplizierte Kollisionen ohne Konsequenzen, und wir entwickeln eine Politik zur Minimierung der Opfer von VerkehrsunfÃ¤llen. <br>  Dies bedeutet, dass wir die rationalen KÃ¶rner der Forschung vom soziopsychologischen Experiment getrennt haben, um das AusmaÃŸ der Intoleranz in der Weltgesellschaft zu untersuchen.  Wir arbeiten weiter mit den ersten drei genannten Dilemmata.  Und es gibt etwas zu zerlegen.  Bei nÃ¤herer Betrachtung stellen sich heraus, dass sie unvollstÃ¤ndig sind ... </p><br><h3>  Drei Dilemmata von Roboterautos </h3><br><p>  <b>VerstoÃŸen FuÃŸgÃ¤nger gegen Verkehrsregeln?</b>  Hier drÃ¼ckt die Mehrheit ausdrÃ¼cklich den Sozialdarwinismus oder eine stillschweigend bedauerliche, bedauerliche Reaktion aus - vielmehr mÃ¼ssen sie diejenigen, die gegen die Regeln verstoÃŸen, zugunsten der Unschuldigen opfern.  Bewusste Menschen fahren nicht auf Schienen, weil sie wissen, dass der Zug nicht anhalten wird - lassen Sie sie wissen, dass das Robomobil auch nicht anhalten wird.  Alles ist logisch, wenn auch zynisch.  Aber in diesem listigen Dilemma verbirgt sich Einseitigkeit, UnvollstÃ¤ndigkeit.  FuÃŸgÃ¤nger, die gegen Verkehrsregeln verstoÃŸen, sind nur eine von vielen Situationen.  Aber wenn das Roboterauto kaputt geht ??  Diese Situation wurde nicht berÃ¼cksichtigt, aber sie (die Kameras des Autos haben ein Schild oder eine Ampel Ã¼bersehen) ist theoretisch viel wahrscheinlicher als ein plÃ¶tzlicher Bremsausfall.  Allerdings habe ich wieder in der Fantasie und insbesondere getroffen.  Es ist wichtiger, im Test nur die Ã¤quivalente ReziprozitÃ¤t der Situation zu zeigen.  Stellen Sie sich Folgendes vor: Wenn FuÃŸgÃ¤nger gegen Verkehrsregeln verstoÃŸen, sterben sie, und dies ist â€logischâ€œ und â€richtigâ€œ. Wenn das Robomobil verletzt, sollte er fÃ¼r diesen Fehler Selbstmord begehen?  Vergessen Sie nicht, dass gleichzeitig der AnfÃ¼hrer, der Landstreicher und die darin sitzende Katze sterben!  Dies ist eine wichtige Korrektur, im Test jedoch nicht. </p><br><p>  Weiter.  <b>Die Anzahl der potenziellen Opfer.</b>  Auch hier ist das nicht so einfach.  Verwerfen Sie Geschlechterstereotype und Respekt vor dem Alter, Verachtung fÃ¼r die Fetten und Obdachlosen.  Wir gehen davon aus, dass sie bei einem Unfall proportional zu der HÃ¤ufigkeit sterben, mit der sie in der Natur vorkommen.  Und wir werden entscheiden: Drei sterben besser als fÃ¼nf.  Klingt das logisch?  Gut.  Lassen Sie uns <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">all diese hÃ¶llische AbsurditÃ¤t unterbrechen</a> , aber wir haben eine abstrakte Simulation.  Was ist besser - 50 oder 51 Menschen zu tÃ¶ten?  1051 oder 1052?  Das ist also nicht so wichtig?  Was ist dann besser - 1 FuÃŸgÃ¤nger oder 50 Menschen in einem Bus zu tÃ¶ten?  Und jetzt ist es wichtig geworden?  Und wohin geht diese Linie?  Ist jede zusÃ¤tzliche Person wertvoll?  Aber ist es wichtig, wenn auf lange Sicht Tausende von Menschen bei VerkehrsunfÃ¤llen sterben?  Wie im Fall des Auftretens wird in der RealitÃ¤t eine angemessene SchÃ¤tzung der Anzahl potenzieller Opfer unter Verwendung von KI Ã¤uÃŸerst schwierig sein.  Das einzige, was Sinn macht, ist die Bedingung, dass nicht eingegriffen wird (kein ManÃ¶vrieren), wenn die Anzahl der Opfer gleich ist. </p><br><p>  Der dritte Aspekt sorgte in den Kommentaren zu diesem ersten Artikel Ã¼ber HabrÃ© fÃ¼r groÃŸe Kontroversen.  Und nach den Ergebnissen der Studie zu urteilen, ist sie fÃ¼r die Gesellschaft vÃ¶llig zweideutig, und hier liegt das Hauptproblem, das gelÃ¶st werden muss.  Es geht darum, <b>wen man riskiert - FuÃŸgÃ¤nger oder Passagiere?</b> </p><br><p>  Einige sagen, dass FuÃŸgÃ¤nger fÃ¼r nichts verantwortlich sind, was bedeutet, dass sie an erster Stelle gerettet werden mÃ¼ssen.  Im Allgemeinen ist es heute unter Stadtbewohnern Mode, sich um FuÃŸgÃ¤nger zu kÃ¼mmern, ganze StraÃŸen zu FuÃŸgÃ¤ngern zu machen, alle 50 Meter Kreuzungen mit einer Ampel zu erstellen, die Verkehrsgeschwindigkeit im Zentrum zu verringern und FuÃŸgÃ¤ngern Vorrang einzurÃ¤umen.  Auch hier ist es notwendig, sie irgendwie zu sichern, und eine Robotermaschine, die ohne Bremsen in der Menge fliegt, sollte sich selbst zerstÃ¶ren, um die am stÃ¤rksten gefÃ¤hrdeten Teilnehmer der Bewegung zu retten.  Aus meiner Sicht haben sie Recht, dass FuÃŸgÃ¤nger die Verhaltensbedingungen des Roboterautos eines anderen nicht unterschrieben haben.  Sie kÃ¶nnten generell gegen ihre EinfÃ¼hrung sein.  Gleichzeitig ist es unmÃ¶glich, sich den Passagier einer solchen Maschine vorzustellen, der mit den Bedingungen fÃ¼r ihre Verwendung nicht einverstanden ist.  Daher ist die Situation ein Interessenkonflikt.  Es ist bequemer fÃ¼r mich, dich zu tÃ¶ten, und ich werde dich tÃ¶ten, wie eine Person zu einer anderen sagt. </p><br><p>  Die zweiten sagen, dass jeder, der ein Roboterauto kauft und generell in dieses steigt, die Garantie haben sollte, dass sie ihn im Falle eines Unfalls retten und keinen Arzt, ein Kind oder zwei Katzen tÃ¶ten, um eine Kreuzung zu retten.  Einerseits sieht es logisch und gerechtfertigt aus, andererseits stellt der Passagier in diesem Fall sein Leben bewusst Ã¼ber andere.  Beim Kauf eines Autos mit einem Autopiloten steht jedem seiner Besitzer die <s>perfekte Waffe zur VerfÃ¼gung, eine Silberkugel, eine ungelenkte Rakete, eine</s> Maschine, die jede andere Person auf ihrem Weg legal vollstÃ¤ndig tÃ¶tet. </p><br><p>  Beide Seiten mit Schaum im Mund ziehen Ã¼ber das "erste Gesetz der Robotik", das aus der Science-Fiction stammt.  Es klingt demagogisch schÃ¶n, aber niemand versucht es zu verstehen oder in Bezug auf das Problem herauszufordern.  Sie ist jedoch auf diese Formulierung des Problems nicht anwendbar, da Konzepte ersetzt werden: Die Heuristik / KI der Maschine wÃ¤hlt nicht zwischen den Werten des menschlichen Lebens, sondern handelt streng nach den Algo-Rhythmen, die auf der Grundlage der von Menschen erfundenen subjektiven PrioritÃ¤ten erstellt wurden.  Und hier spielt es keine Rolle, welche Art von sozialem Konstrukt bei der Wahl von "tÃ¶ten / verschonen" als PrioritÃ¤t angesehen wird: die KÃ¶rpermasse, die wir zuvor abgelehnt haben, Alter und Status oder die sozialdarwinistische Selbstsucht des Autobesitzers. </p><br><p>  Der zweite Ansatz, ein einseitiger Angriff auf das Leben von FuÃŸgÃ¤ngern, macht die Forschung von einem Trolley-Problem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>zum klassischen Dilemma</b></a> eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Gefangenen</b></a> .  Wenn die Parteien zu einem Kompromiss kommen, ist eine allgemeine Entwicklung (EinfÃ¼hrung von Robomobilen) mit minimaler Verschlechterung fÃ¼r einige mÃ¶glich (Minimierung der Anzahl unvermeidlicher TodesfÃ¤lle durch Robomobile) - was der Wunsch nach dem Pareto-Optimum ist.  Es gibt jedoch immer einen Egoisten, der sich nur auf seine Interessen verlÃ¤sst.  "Er wird 20 Jahre alt, aber ich werde freigelassen."  "Er wird sterben, wenn er die StraÃŸe Ã¼berquert, obwohl die Bremsen mein Auto abgelehnt haben."  Vielleicht ist dieser Ansatz gerechtfertigt, wenn Ereignisse im Leben einzeln sind und zwei Teilnehmer am Spiel teilnehmen.  Wenn Zehntausende oder Hunderttausende von Teilnehmern anwesend sind und tÃ¤glich AusflÃ¼ge stattfinden, wird ein solches Ein-Tor-Spiel zur Diskriminierung von FuÃŸgÃ¤ngern. </p><br><p>  PersÃ¶nlich glaube ich, dass das Passagier- / FuÃŸgÃ¤nger-Dilemma im Rahmen des formulierten Problems zu einer Sackgasse fÃ¼hrt.  Eine Maschine, die mÃ¶glicherweise diejenigen tÃ¶tet, die sich darauf eingelassen haben, ist aus Sicht des gesunden Menschenverstandes absurd und wird natÃ¼rlich keine KÃ¤ufer auf dem Markt finden.  Ein Auto, das absichtlich FuÃŸgÃ¤nger tÃ¶tet, ist in einer zivilisierten Gesellschaft als Element positiver Diskriminierung und Bedrohung des Lebens der Menschen unmÃ¶glich. </p><br><p>  Wir gehen weiter.  Der Artikel diskutiert nicht wirklich und bedeutet keine Politik zur Minimierung der tragischen Folgen von UnfÃ¤llen mit Robomobilen.  Die Gesamtsummen sind in "Regionen" unterteilt, die sich in ihren PrioritÃ¤ten erheblich unterscheiden und eher zweideutig sind (es gibt ErklÃ¤rungen zu "religiÃ¶sen Merkmalen und kolonialem Einfluss", aber ... im Allgemeinen GrÃ¼ÃŸe an den Irak mit Afghanistan in "West" und Frankreich mit der Tschechischen Republik in " SÃ¼dlicher Sektor).  Und so dreht sich die Frage in der Sprache: Werden Sie fÃ¼r jedes Land Robomobile mit unterschiedlicher "Ethik" herstellen? </p><br><img src="https://habrastorage.org/webt/oy/wk/2i/oywk2inqjeerijr5wrja_v57new.jpeg"><br><p>  Die Autoren des Artikels in der Diskussion bezeichnen die drei von ihnen identifizierten â€grundlegenden GrundblÃ¶ckeâ€œ: Menschen (nicht Tiere) retten, mehr Leben retten, jÃ¼ngere retten.  Die Diagramme zeigen jedoch deutlich, dass die Menschen im Ã¶stlichen Sektor etwas weniger BevÃ¶lkerung und Jugendliche haben, als es ihnen egal ist.  Es stellt sich heraus, dass die ausgewÃ¤hlten vorrangigen Richtlinien der Meinung der Ã¼berwÃ¤ltigenden Mehrheit widersprechen werden.  Warum wurden dann Ã¼berhaupt Leute befragt? </p><br><h3>  Vielleicht einfach zÃ¤hlen? </h3><br><p>  Aber kommen wir zum unterhaltsamen Teil dieses Beitrags. </p><br><p>  Anstatt Menschen mit unterschiedlichen soziokulturellen Auswirkungen und wahrscheinlich in 99% der FÃ¤lle mit nicht zum Kern gehÃ¶render Ausbildung um Rat in Bezug auf Robotik zu bitten, wenden wir uns einem unparteiischen Instrument zu.  Nehmen wir die am Anfang des Artikels ausgewÃ¤hlten Dilemmata.  Unter den Testbedingungen erstellen wir die einfachste Computersimulation.  Und wir werden die Anzahl der toten Verkehrsteilnehmer bewerten. </p><br><p>  Und denken Sie daran: Unsere Aufgabe als Politiker im Bereich der Verkehrssicherheit ist es, die Gesamtzahl der Opfer zu reduzieren.  Wir werden im Rahmen und in den Konventionen des ursprÃ¼nglichen Moral Machine-Tests arbeiten, wobei der Schwerpunkt auf dem Lebensrisiko von Verkehrsunfallteilnehmern liegt und nicht auf komplexen realistischen Bewertungen einer Autokollision mit einem Hindernis oder Personen.  Wir haben kein EuroNCAP, wir werden Python haben. </p><br><p>  ZunÃ¤chst schreiben wir einen Code, der das Dilemma erfÃ¼llt, "diejenigen zu retten, die mehr sterben".  Im Rahmen des Moral Machine-Tests machen wir zufÃ¤llig 1 bis 5 Passagiere und FuÃŸgÃ¤nger, stellen die Bedingung ein, wenn FuÃŸgÃ¤nger&gt; Passagiere das Auto sofort auf einem Betonblock tÃ¶ten.  Wir tragen zum Beispiel 10.000 solcher UnfÃ¤lle. </p><br><div class="spoiler">  <b class="spoiler_title">Ich hÃ¶re nicht auf den Anspruchscode, sondern habe zum ersten Mal in meinem Leben etwas in Python geschrieben</b> <div class="spoiler_text"><pre><code class="plaintext">npedtotal = 0
npasstotal = 0
ndeadped = 0
ndeadpass = 0
#   0    0  

n=0
while n &lt; 10000:
#10000 

    nped = random.randint(1, 5)
    npass = random.randint(1, 5)
#      1  5

    npedtotal += nped
    npasstotal += npass
#     

    if nped &gt; npass:

        ndeadpass += npass

    else:
        ndeadped += nped

#     ,
#       .
#          .

    n += 1

print ("  ", npedtotal)
print (" ", npasstotal)
print (" ", ndeadped, "(",100*ndeadped/npedtotal, "%",")")
print (" ", ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")
print ("  ", ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")</code></pre></div></div><br>
<p>  â€¦ </p><br>
<blockquote>   29960<br>
  29924<br>
  13903 ( 46.4052069426 % )<br>
  8030 ( 26.8346477744 %)    21933 ( 36.6258098991 % )</blockquote><p>,   !   ,   !<br>
    .             .  ,      .     â€“    ,   Â« Â»         4  5,        ==  . ,   20   20 ,   ,   , 5  â€“    ,  5  â€“   .     :      ,  ,   .  &gt;  &gt;=        :</p><br>
<blockquote>   29981<br>
  29865<br>
  7859 ( 26.2132684033 % )<br>
  14069 ( 47.1086556169 %)<br>
   21928 ( 36.6407111586 % )</blockquote>   ,          occupants,  -   ,   .    ,    .  30000 , 100% â€” .<br>
<br>
     ,       ,   .    â€“    , ,    50%     ,     30000.<br>
<br>
    â€“       .  ,    ,        ,       !    ,     :  ,        , ,    ,      ,    . ,    :      .<br>
<br>
<div class="spoiler"><b class="spoiler_title">       ,   -</b><div class="spoiler_text">```python<br>
import random<br>
<br>
npedtotal = 0<br>
npasstotal = 0<br>
ndeadped = 0<br>
ndeadpass = 0<br>
#   0    0  <br>
<br>
n=0<br>
while n &lt; 10000:<br>
#10000 <br>
<br>
nped = random.randint(1, 5)<br>
 npass = random.randint(1, 5)<br>
 trafficlight = random.randint(0, 1)<br>
#      1  5<br>
#      <br>
<br>
npedtotal += nped<br>
 npasstotal += npass<br>
#     <br>
 if trafficlight == 0:<br>
<br>
ndeadped += nped<br>
<br>
else:<br>
<br>
if nped &gt; npass:<br>
<br>
ndeadpass += npass<br>
<br>
else:<br>
 ndeadped += nped<br>
<br>
#     ,<br>
#       .<br>
#          .<br>
<br>
n += 1<br>
<br>
print (Â«  Â», npedtotal)<br>
print (Â« Â», npasstotal)<br>
print (Â« Â», ndeadped, "(",100*ndeadped/npedtotal, "%",")")<br>
print (Â« Â», ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")<br>
print (Â«  Â», ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")<br>
```</div></div><br>
<br>
<blockquote>  "&gt;"<br>
   29978<br>
  29899<br>
  21869 ( 72.9501634532 % )<br>
  4042 ( 13.5188467842 %)<br>
   25911 ( 43.2737111078 % )<br>
<br>
 "&gt;="<br>
   30152<br>
  30138<br>
  19297 ( 63.9990713717 % )<br>
  6780 ( 22.4965160263 %)<br>
   26077 ( 43.2526123735 % )<br>
</blockquote> ,      ,           .          (       ).<br>
<br>
           ,             .                 â€“         .<br>
<br>
           .        ,    ,           .         Moral Machine,      ,     ,     .       -   ,       .<br>
<br>
,    ,       ,                .     â€“   ,   ,   .        .       â€“      ,   ,      ,           .      ,    â€“        .<br>
<br>
   ,   -              ,      .          ,   ,             ,    .  â€“   ,       ,      .<br>
<br>
 .      .            ,      .    .</div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428181/">https://habr.com/ru/post/de428181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428169/index.html">DJI kÃ¼ndigt Mavic 2 Enterprise an - ein leistungsstarkes Tool fÃ¼r Profis</a></li>
<li><a href="../de428173/index.html">Prettier, ESLint, Husky, Lint-Staged und EditorConfig: Tools zum Schreiben von aufgerÃ¤umtem Code</a></li>
<li><a href="../de428175/index.html">Schlaue PrÃ¤fixbaum-C-Implementierung</a></li>
<li><a href="../de428177/index.html">Was ist also falsch an der Arbeitssuche / den Arbeitnehmern in der IT?</a></li>
<li><a href="../de428179/index.html">Bei einer japanischen Auktion wurde ein Prototyp eines Wii-Controllers fÃ¼r den GameCube entwickelt</a></li>
<li><a href="../de428183/index.html">Implementierung des Levenberg-Marquardt-Algorithmus zur Optimierung neuronaler Netze auf TensorFlow</a></li>
<li><a href="../de428187/index.html">So schreiben Sie eine Erweiterung fÃ¼r die GNOME-Shell: Nicht stÃ¶ren</a></li>
<li><a href="../de428189/index.html">Wer ist ein Paladin?</a></li>
<li><a href="../de428191/index.html">Was sollen wir fÃ¼r einen Hackathon arrangieren oder wie haben wir einen internen Hackathon durchgefÃ¼hrt?</a></li>
<li><a href="../de428193/index.html">Ãœber Touren gehen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
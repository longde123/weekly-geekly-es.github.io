<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👂🏼 🔮 💅🏿 Moralische Maschine: gnadenlos oder bedeutungslos? 😍 🐓 👩🏽‍💻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich habe mich entschlossen, diesen Artikel im Anschluss an diesen Beitrag zu schreiben. 


 Ich möchte Sie an einen kurzen Punkt erinnern: In der Zeit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Moralische Maschine: gnadenlos oder bedeutungslos?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428181/"><p>  Ich habe mich entschlossen, diesen Artikel im Anschluss an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesen Beitrag</a> zu schreiben. </p><br><img src="https://habrastorage.org/webt/-x/08/ps/-x08pskb0ti0iupeu2iuduj3uus.jpeg"><br><br>  Ich möchte Sie an einen kurzen Punkt erinnern: In der Zeitschrift Nature wurden die Ergebnisse einer mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Test</a> durchgeführten Studie veröffentlicht. <br><p>  Worüber möchte ich schreiben? </p><br><p>  Erstens, warum diese Studie für die Lösung des genannten Problems und in der Form, in der sie durchgeführt wurde, absolut nutzlos ist. </p><br><p>  Zweitens, wie man eine solche Studie priorisiert. </p><br><p> Versuchen Sie drittens, verschiedene Unfallszenarien unter den im Test angegebenen Bedingungen zu simulieren. </p><a name="habracut"></a><br><p>  In diesem Beitrag hat der Autor nicht von Anfang an vergeblich einen Link zum Test eingefügt.  Dies würde dazu beitragen, bedeutungslose Kommentare von Personen zu vermeiden, die die ursprüngliche Botschaft der Studie nicht verstanden haben. <br>  Bitte machen Sie mindestens ein paar Mal <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Test</a></b> , um das Diskussionsthema zu verstehen. </p><br><h3>  Was sie versprochen haben, uns in der Studie zu zeigen </h3><br><p>  Die Diskussion des ersten Beitrags, episch für Habr, zeigte, dass die Mehrheit der Menschen nicht weiß, wie sie unter den gegebenen Bedingungen denken sollen, sondern anfängt zu phantasieren: "Sterben einige Menschen im Test?"  Immerhin können Sie beide Fußgänger und den Block / seitwärts umgehen, um die Handbremse / das Zahnrad zu reiben / bremsen?  Aber ich würde ... ".  Verstehen Sie, dass dies ein vereinfachtes Beispiel für die Entwicklung von Aktionsalgorithmen und -richtlinien zur Regulierung des Autopilotverhaltens auf der Straße ist!  Unter dem Gesichtspunkt der Entwicklung von Sicherheitsregeln sind solche Extreme und Vereinfachungen gerechtfertigt.  Es geht um die möglichen Konsequenzen, auf die die Menschen vorbereitet sein sollten.  Soldaten gehen nicht zu Minenfeldern, nicht weil dort jeder Quadratzentimeter abgebaut wird, sondern wegen der Wahrscheinlichkeit zu sterben.  Es ist normalerweise nicht sehr hoch, aber niemand wird es riskieren.  Daher ist im Test die Wahl zwischen 100% Tod aller Passagiere oder aller Fußgänger angemessen - so bezeichnen wir das Risiko, wenn man bedenkt, dass es inakzeptabel ist, Leben in unserer Gesellschaft zu riskieren. </p><br><p>  Die Botschaft der Studie lautet: Sie, die Menschen, die jetzt leben, müssen in einer Welt der Zukunft leben, die mit Autos auf dem Autopiloten gefüllt ist.  Und für uns, Entwickler von Automobilen, KI und anderen Dingen, ist es wichtig zu wissen, aber wie sollten sich Roboterroboter Ihrer Meinung nach verhalten?  Nun, hier sind Sie, ja, ja, Sie sind es - sagen Sie mir, was ich mit einem Robomobil tun soll, wenn Kopf und Katze darin fahren und es dabei ist, Obdachlose und Hunde zu vernichten?  Welche Ethik sollten Robomobile haben, wenn sie sich entscheiden müssen? </p><br><p>  Und nachdem wir das ursprüngliche Motiv für die Studie identifiziert haben, möchte ich einige Aspekte davon diskutieren. </p><br><h3>  Was die Studie tatsächlich zeigte </h3><br><p>  Das erste, was auffällt, ist, dass das Forschungsdesign überhaupt nicht auf das erklärte Ziel abzielt.  Die in Form von Dilemmata gestellten Aufgaben eignen sich nicht zur Schaffung einer „Ethik“ des Verhaltens von Roboterautos.  Eher nicht alle.  Hier sind die Dilemmata, die die Aufgabe erfüllen, „Regeln für das Verhalten eines Roboterautos zu entwickeln, um die Schwere der Folgen eines Unfalls zu verringern“: </p><br><ul><li>  "Passagier / Fußgänger" - wählen Sie, wer gespeichert werden soll; </li><li>  "Verstoß gegen Verkehrsregeln" - entscheiden Sie, ob bewusstlose Fußgänger geopfert werden sollen; </li><li>  „Anzahl potenzieller Opfer“ - Wählen Sie aus, ob die Anzahl der Opfer Vorrang hat. </li></ul><br><p>  Und dann kommen die Parameter, die, wie sich herausstellt, für die Verurteilung in unserer zivilisierten Gesellschaft sehr wichtig sind.  Die Leute wurden ehrlich und unschuldig gefragt: Ihr Niveau an Sexismus, Lukismus, Ageismus?  Sind Sie für die Unterscheidung von Fett oder nicht klassifiziert?  Und schließlich antworteten Hunderttausende ehrlich ... </p><br><p>  Bravo! </p><br><p>  Genau in den besten Traditionen unterhaltsamer Filme und Serien, wenn die Welt der Hauptfiguren tatsächlich ein großer Sandkasten hinter einem hohen Zaun ist und es ihr Verhalten ist, das ein Experiment ist!  Soziologen, Psychologen und Kulturwissenschaftler erhielten unter dem Deckmantel der überaus wichtigen Forschung auf dem Gebiet der Robotik und KI eine so aussagekräftige Stichprobe <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zum Trolley-Problem</a></b> , von der noch niemand zuvor geträumt hatte!  Nun, außer dass die Hautfarbe nicht zur Umfrage hinzugefügt wurde, aber dann würden die rassistischen Obertöne der Studie mit Weiß genäht ... oh. </p><br><p>  Im Ernst, dieser geschlechtsphänotypische Teil der Studie wird durch kategoriale Argumente abgeschnitten.  Das erste Argument ist der Humanismus. Als zivilisierte Menschen müssen wir den Vorrang des Wertes des menschlichen Lebens vor allen individuellen Unterschieden stellen.  Das heißt, die Formulierung der Frage ist als diskriminierend empörend.  Das zweite Argument: Viele Unfälle ereignen sich, und in der Grenze wird die Verteilung der Opfer nach Aussehen, Bildung, Geschlecht und Alter zu ihren gesellschaftlichen Anteilen tendieren. Daher ist es zumindest seltsam, dies zusätzlich zu regeln.  Das dritte Argument: Es erscheint nicht ratsam, künstliche Intelligenz zu schaffen, die einen Anzug von Brioni von einem Pullover von Bershka unterscheidet, um weiter zu vergleichen, ob eine Person Status hat und ob es sich lohnt, sie zu vernichten.  Außerdem würde ich nicht darauf vertrauen, dass die KI urteilt - ein obdachloser Fußgänger oder ein Wissenschaftler?  (Hallo zu den Frisuren der angesehenen Wissenschaftler Perelman oder Gelfand :)) </p><br><p>  Zusätzlich zu diesen unnötigen Parametern verwerfen wir leicht die verbleibenden zwei: Speziesspezifität und Nichteinmischung.  Ja, wir werden kleine Tiere vernichten, um Menschen zu retten, die gedacht hätten.  Und was den Parameter „Intervention / Nichtinterferenz“ durch Manövrieren betrifft, so ist dieser wesentliche Teil des Trolley-Problems nicht nur ein Hindernis für das Auto, da die Maschine nicht nach der Ethik handelt, sondern nach den darin festgelegten Algorithmen.  Und da wir uns die Aufgabe gestellt haben, wie sich das Auto bei einem Unfall mit einer Kollision mit Menschen verhalten soll, gehen wir im Wortlaut davon aus, dass es sich irgendwie verhalten muss.  Heutzutage bewältigt der Schienenverkehr erfolgreich unkomplizierte Kollisionen ohne Konsequenzen, und wir entwickeln eine Politik zur Minimierung der Opfer von Verkehrsunfällen. <br>  Dies bedeutet, dass wir die rationalen Körner der Forschung vom soziopsychologischen Experiment getrennt haben, um das Ausmaß der Intoleranz in der Weltgesellschaft zu untersuchen.  Wir arbeiten weiter mit den ersten drei genannten Dilemmata.  Und es gibt etwas zu zerlegen.  Bei näherer Betrachtung stellen sich heraus, dass sie unvollständig sind ... </p><br><h3>  Drei Dilemmata von Roboterautos </h3><br><p>  <b>Verstoßen Fußgänger gegen Verkehrsregeln?</b>  Hier drückt die Mehrheit ausdrücklich den Sozialdarwinismus oder eine stillschweigend bedauerliche, bedauerliche Reaktion aus - vielmehr müssen sie diejenigen, die gegen die Regeln verstoßen, zugunsten der Unschuldigen opfern.  Bewusste Menschen fahren nicht auf Schienen, weil sie wissen, dass der Zug nicht anhalten wird - lassen Sie sie wissen, dass das Robomobil auch nicht anhalten wird.  Alles ist logisch, wenn auch zynisch.  Aber in diesem listigen Dilemma verbirgt sich Einseitigkeit, Unvollständigkeit.  Fußgänger, die gegen Verkehrsregeln verstoßen, sind nur eine von vielen Situationen.  Aber wenn das Roboterauto kaputt geht ??  Diese Situation wurde nicht berücksichtigt, aber sie (die Kameras des Autos haben ein Schild oder eine Ampel übersehen) ist theoretisch viel wahrscheinlicher als ein plötzlicher Bremsausfall.  Allerdings habe ich wieder in der Fantasie und insbesondere getroffen.  Es ist wichtiger, im Test nur die äquivalente Reziprozität der Situation zu zeigen.  Stellen Sie sich Folgendes vor: Wenn Fußgänger gegen Verkehrsregeln verstoßen, sterben sie, und dies ist „logisch“ und „richtig“. Wenn das Robomobil verletzt, sollte er für diesen Fehler Selbstmord begehen?  Vergessen Sie nicht, dass gleichzeitig der Anführer, der Landstreicher und die darin sitzende Katze sterben!  Dies ist eine wichtige Korrektur, im Test jedoch nicht. </p><br><p>  Weiter.  <b>Die Anzahl der potenziellen Opfer.</b>  Auch hier ist das nicht so einfach.  Verwerfen Sie Geschlechterstereotype und Respekt vor dem Alter, Verachtung für die Fetten und Obdachlosen.  Wir gehen davon aus, dass sie bei einem Unfall proportional zu der Häufigkeit sterben, mit der sie in der Natur vorkommen.  Und wir werden entscheiden: Drei sterben besser als fünf.  Klingt das logisch?  Gut.  Lassen Sie uns <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">all diese höllische Absurdität unterbrechen</a> , aber wir haben eine abstrakte Simulation.  Was ist besser - 50 oder 51 Menschen zu töten?  1051 oder 1052?  Das ist also nicht so wichtig?  Was ist dann besser - 1 Fußgänger oder 50 Menschen in einem Bus zu töten?  Und jetzt ist es wichtig geworden?  Und wohin geht diese Linie?  Ist jede zusätzliche Person wertvoll?  Aber ist es wichtig, wenn auf lange Sicht Tausende von Menschen bei Verkehrsunfällen sterben?  Wie im Fall des Auftretens wird in der Realität eine angemessene Schätzung der Anzahl potenzieller Opfer unter Verwendung von KI äußerst schwierig sein.  Das einzige, was Sinn macht, ist die Bedingung, dass nicht eingegriffen wird (kein Manövrieren), wenn die Anzahl der Opfer gleich ist. </p><br><p>  Der dritte Aspekt sorgte in den Kommentaren zu diesem ersten Artikel über Habré für große Kontroversen.  Und nach den Ergebnissen der Studie zu urteilen, ist sie für die Gesellschaft völlig zweideutig, und hier liegt das Hauptproblem, das gelöst werden muss.  Es geht darum, <b>wen man riskiert - Fußgänger oder Passagiere?</b> </p><br><p>  Einige sagen, dass Fußgänger für nichts verantwortlich sind, was bedeutet, dass sie an erster Stelle gerettet werden müssen.  Im Allgemeinen ist es heute unter Stadtbewohnern Mode, sich um Fußgänger zu kümmern, ganze Straßen zu Fußgängern zu machen, alle 50 Meter Kreuzungen mit einer Ampel zu erstellen, die Verkehrsgeschwindigkeit im Zentrum zu verringern und Fußgängern Vorrang einzuräumen.  Auch hier ist es notwendig, sie irgendwie zu sichern, und eine Robotermaschine, die ohne Bremsen in der Menge fliegt, sollte sich selbst zerstören, um die am stärksten gefährdeten Teilnehmer der Bewegung zu retten.  Aus meiner Sicht haben sie Recht, dass Fußgänger die Verhaltensbedingungen des Roboterautos eines anderen nicht unterschrieben haben.  Sie könnten generell gegen ihre Einführung sein.  Gleichzeitig ist es unmöglich, sich den Passagier einer solchen Maschine vorzustellen, der mit den Bedingungen für ihre Verwendung nicht einverstanden ist.  Daher ist die Situation ein Interessenkonflikt.  Es ist bequemer für mich, dich zu töten, und ich werde dich töten, wie eine Person zu einer anderen sagt. </p><br><p>  Die zweiten sagen, dass jeder, der ein Roboterauto kauft und generell in dieses steigt, die Garantie haben sollte, dass sie ihn im Falle eines Unfalls retten und keinen Arzt, ein Kind oder zwei Katzen töten, um eine Kreuzung zu retten.  Einerseits sieht es logisch und gerechtfertigt aus, andererseits stellt der Passagier in diesem Fall sein Leben bewusst über andere.  Beim Kauf eines Autos mit einem Autopiloten steht jedem seiner Besitzer die <s>perfekte Waffe zur Verfügung, eine Silberkugel, eine ungelenkte Rakete, eine</s> Maschine, die jede andere Person auf ihrem Weg legal vollständig tötet. </p><br><p>  Beide Seiten mit Schaum im Mund ziehen über das "erste Gesetz der Robotik", das aus der Science-Fiction stammt.  Es klingt demagogisch schön, aber niemand versucht es zu verstehen oder in Bezug auf das Problem herauszufordern.  Sie ist jedoch auf diese Formulierung des Problems nicht anwendbar, da Konzepte ersetzt werden: Die Heuristik / KI der Maschine wählt nicht zwischen den Werten des menschlichen Lebens, sondern handelt streng nach den Algo-Rhythmen, die auf der Grundlage der von Menschen erfundenen subjektiven Prioritäten erstellt wurden.  Und hier spielt es keine Rolle, welche Art von sozialem Konstrukt bei der Wahl von "töten / verschonen" als Priorität angesehen wird: die Körpermasse, die wir zuvor abgelehnt haben, Alter und Status oder die sozialdarwinistische Selbstsucht des Autobesitzers. </p><br><p>  Der zweite Ansatz, ein einseitiger Angriff auf das Leben von Fußgängern, macht die Forschung von einem Trolley-Problem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>zum klassischen Dilemma</b></a> eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Gefangenen</b></a> .  Wenn die Parteien zu einem Kompromiss kommen, ist eine allgemeine Entwicklung (Einführung von Robomobilen) mit minimaler Verschlechterung für einige möglich (Minimierung der Anzahl unvermeidlicher Todesfälle durch Robomobile) - was der Wunsch nach dem Pareto-Optimum ist.  Es gibt jedoch immer einen Egoisten, der sich nur auf seine Interessen verlässt.  "Er wird 20 Jahre alt, aber ich werde freigelassen."  "Er wird sterben, wenn er die Straße überquert, obwohl die Bremsen mein Auto abgelehnt haben."  Vielleicht ist dieser Ansatz gerechtfertigt, wenn Ereignisse im Leben einzeln sind und zwei Teilnehmer am Spiel teilnehmen.  Wenn Zehntausende oder Hunderttausende von Teilnehmern anwesend sind und täglich Ausflüge stattfinden, wird ein solches Ein-Tor-Spiel zur Diskriminierung von Fußgängern. </p><br><p>  Persönlich glaube ich, dass das Passagier- / Fußgänger-Dilemma im Rahmen des formulierten Problems zu einer Sackgasse führt.  Eine Maschine, die möglicherweise diejenigen tötet, die sich darauf eingelassen haben, ist aus Sicht des gesunden Menschenverstandes absurd und wird natürlich keine Käufer auf dem Markt finden.  Ein Auto, das absichtlich Fußgänger tötet, ist in einer zivilisierten Gesellschaft als Element positiver Diskriminierung und Bedrohung des Lebens der Menschen unmöglich. </p><br><p>  Wir gehen weiter.  Der Artikel diskutiert nicht wirklich und bedeutet keine Politik zur Minimierung der tragischen Folgen von Unfällen mit Robomobilen.  Die Gesamtsummen sind in "Regionen" unterteilt, die sich in ihren Prioritäten erheblich unterscheiden und eher zweideutig sind (es gibt Erklärungen zu "religiösen Merkmalen und kolonialem Einfluss", aber ... im Allgemeinen Grüße an den Irak mit Afghanistan in "West" und Frankreich mit der Tschechischen Republik in " Südlicher Sektor).  Und so dreht sich die Frage in der Sprache: Werden Sie für jedes Land Robomobile mit unterschiedlicher "Ethik" herstellen? </p><br><img src="https://habrastorage.org/webt/oy/wk/2i/oywk2inqjeerijr5wrja_v57new.jpeg"><br><p>  Die Autoren des Artikels in der Diskussion bezeichnen die drei von ihnen identifizierten „grundlegenden Grundblöcke“: Menschen (nicht Tiere) retten, mehr Leben retten, jüngere retten.  Die Diagramme zeigen jedoch deutlich, dass die Menschen im östlichen Sektor etwas weniger Bevölkerung und Jugendliche haben, als es ihnen egal ist.  Es stellt sich heraus, dass die ausgewählten vorrangigen Richtlinien der Meinung der überwältigenden Mehrheit widersprechen werden.  Warum wurden dann überhaupt Leute befragt? </p><br><h3>  Vielleicht einfach zählen? </h3><br><p>  Aber kommen wir zum unterhaltsamen Teil dieses Beitrags. </p><br><p>  Anstatt Menschen mit unterschiedlichen soziokulturellen Auswirkungen und wahrscheinlich in 99% der Fälle mit nicht zum Kern gehörender Ausbildung um Rat in Bezug auf Robotik zu bitten, wenden wir uns einem unparteiischen Instrument zu.  Nehmen wir die am Anfang des Artikels ausgewählten Dilemmata.  Unter den Testbedingungen erstellen wir die einfachste Computersimulation.  Und wir werden die Anzahl der toten Verkehrsteilnehmer bewerten. </p><br><p>  Und denken Sie daran: Unsere Aufgabe als Politiker im Bereich der Verkehrssicherheit ist es, die Gesamtzahl der Opfer zu reduzieren.  Wir werden im Rahmen und in den Konventionen des ursprünglichen Moral Machine-Tests arbeiten, wobei der Schwerpunkt auf dem Lebensrisiko von Verkehrsunfallteilnehmern liegt und nicht auf komplexen realistischen Bewertungen einer Autokollision mit einem Hindernis oder Personen.  Wir haben kein EuroNCAP, wir werden Python haben. </p><br><p>  Zunächst schreiben wir einen Code, der das Dilemma erfüllt, "diejenigen zu retten, die mehr sterben".  Im Rahmen des Moral Machine-Tests machen wir zufällig 1 bis 5 Passagiere und Fußgänger, stellen die Bedingung ein, wenn Fußgänger&gt; Passagiere das Auto sofort auf einem Betonblock töten.  Wir tragen zum Beispiel 10.000 solcher Unfälle. </p><br><div class="spoiler">  <b class="spoiler_title">Ich höre nicht auf den Anspruchscode, sondern habe zum ersten Mal in meinem Leben etwas in Python geschrieben</b> <div class="spoiler_text"><pre><code class="plaintext">npedtotal = 0
npasstotal = 0
ndeadped = 0
ndeadpass = 0
#   0    0  

n=0
while n &lt; 10000:
#10000 

    nped = random.randint(1, 5)
    npass = random.randint(1, 5)
#      1  5

    npedtotal += nped
    npasstotal += npass
#     

    if nped &gt; npass:

        ndeadpass += npass

    else:
        ndeadped += nped

#     ,
#       .
#          .

    n += 1

print ("  ", npedtotal)
print (" ", npasstotal)
print (" ", ndeadped, "(",100*ndeadped/npedtotal, "%",")")
print (" ", ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")
print ("  ", ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")</code></pre></div></div><br>
<p>  … </p><br>
<blockquote>   29960<br>
  29924<br>
  13903 ( 46.4052069426 % )<br>
  8030 ( 26.8346477744 %)    21933 ( 36.6258098991 % )</blockquote><p>,   !   ,   !<br>
    .             .  ,      .     –    ,   « »         4  5,        ==  . ,   20   20 ,   ,   , 5  –    ,  5  –   .     :      ,  ,   .  &gt;  &gt;=        :</p><br>
<blockquote>   29981<br>
  29865<br>
  7859 ( 26.2132684033 % )<br>
  14069 ( 47.1086556169 %)<br>
   21928 ( 36.6407111586 % )</blockquote>   ,          occupants,  -   ,   .    ,    .  30000 , 100% — .<br>
<br>
     ,       ,   .    –    , ,    50%     ,     30000.<br>
<br>
    –       .  ,    ,        ,       !    ,     :  ,        , ,    ,      ,    . ,    :      .<br>
<br>
<div class="spoiler"><b class="spoiler_title">       ,   -</b><div class="spoiler_text">```python<br>
import random<br>
<br>
npedtotal = 0<br>
npasstotal = 0<br>
ndeadped = 0<br>
ndeadpass = 0<br>
#   0    0  <br>
<br>
n=0<br>
while n &lt; 10000:<br>
#10000 <br>
<br>
nped = random.randint(1, 5)<br>
 npass = random.randint(1, 5)<br>
 trafficlight = random.randint(0, 1)<br>
#      1  5<br>
#      <br>
<br>
npedtotal += nped<br>
 npasstotal += npass<br>
#     <br>
 if trafficlight == 0:<br>
<br>
ndeadped += nped<br>
<br>
else:<br>
<br>
if nped &gt; npass:<br>
<br>
ndeadpass += npass<br>
<br>
else:<br>
 ndeadped += nped<br>
<br>
#     ,<br>
#       .<br>
#          .<br>
<br>
n += 1<br>
<br>
print («  », npedtotal)<br>
print (« », npasstotal)<br>
print (« », ndeadped, "(",100*ndeadped/npedtotal, "%",")")<br>
print (« », ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")<br>
print («  », ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")<br>
```</div></div><br>
<br>
<blockquote>  "&gt;"<br>
   29978<br>
  29899<br>
  21869 ( 72.9501634532 % )<br>
  4042 ( 13.5188467842 %)<br>
   25911 ( 43.2737111078 % )<br>
<br>
 "&gt;="<br>
   30152<br>
  30138<br>
  19297 ( 63.9990713717 % )<br>
  6780 ( 22.4965160263 %)<br>
   26077 ( 43.2526123735 % )<br>
</blockquote> ,      ,           .          (       ).<br>
<br>
           ,             .                 –         .<br>
<br>
           .        ,    ,           .         Moral Machine,      ,     ,     .       -   ,       .<br>
<br>
,    ,       ,                .     –   ,   ,   .        .       –      ,   ,      ,           .      ,    –        .<br>
<br>
   ,   -              ,      .          ,   ,             ,    .  –   ,       ,      .<br>
<br>
 .      .            ,      .    .</div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428181/">https://habr.com/ru/post/de428181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428169/index.html">DJI kündigt Mavic 2 Enterprise an - ein leistungsstarkes Tool für Profis</a></li>
<li><a href="../de428173/index.html">Prettier, ESLint, Husky, Lint-Staged und EditorConfig: Tools zum Schreiben von aufgeräumtem Code</a></li>
<li><a href="../de428175/index.html">Schlaue Präfixbaum-C-Implementierung</a></li>
<li><a href="../de428177/index.html">Was ist also falsch an der Arbeitssuche / den Arbeitnehmern in der IT?</a></li>
<li><a href="../de428179/index.html">Bei einer japanischen Auktion wurde ein Prototyp eines Wii-Controllers für den GameCube entwickelt</a></li>
<li><a href="../de428183/index.html">Implementierung des Levenberg-Marquardt-Algorithmus zur Optimierung neuronaler Netze auf TensorFlow</a></li>
<li><a href="../de428187/index.html">So schreiben Sie eine Erweiterung für die GNOME-Shell: Nicht stören</a></li>
<li><a href="../de428189/index.html">Wer ist ein Paladin?</a></li>
<li><a href="../de428191/index.html">Was sollen wir für einen Hackathon arrangieren oder wie haben wir einen internen Hackathon durchgeführt?</a></li>
<li><a href="../de428193/index.html">Über Touren gehen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
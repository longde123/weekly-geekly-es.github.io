<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍💼 👩🏼‍💻 👉🏽 Klassifizierung handschriftlicher Zeichnungen. Bericht in Yandex 🧓🏿 👶 📒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor einigen Monaten veranstalteten unsere Kollegen von Google bei Kaggle einen Wettbewerb, um einen Klassifikator für Bilder zu erstellen, die im gefe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Klassifizierung handschriftlicher Zeichnungen. Bericht in Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/440666/">  Vor einigen Monaten veranstalteten unsere Kollegen von Google bei Kaggle einen Wettbewerb, um einen Klassifikator für Bilder zu erstellen, die im gefeierten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spiel</a> „Quick, Draw!“ Erhalten wurden.  Das Team, an dem der Yandex-Entwickler Roman Vlasov teilnahm, belegte den vierten Platz im Wettbewerb.  Während der maschinellen Lernsitzung im Januar teilte Roman die Ideen seines Teams, die endgültige Implementierung des Klassifikators und interessante Praktiken der Rivalen mit. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/HO8ymjF-UTw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Hallo allerseits!  Mein Name ist Roma Vlasov, heute werde ich Ihnen von Quick, Draw!  Doodle Recognition Challenge. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/hw/xb/vc/hwxbvcwdjtsmvlzi9q9zly8khwe.jpeg"><br><br>  Unser Team bestand aus fünf Personen.  Ich bin direkt vor dem Fusionsschluss zu ihr gekommen.  Wir hatten Pech, wir waren ein bisschen erschüttert, aber wir waren vom Geld beschattet, und sie waren von der Position des Goldes.  Und wir haben einen ehrenwerten vierten Platz belegt. <br><br>  (Während des Wettbewerbs beobachteten sich die Teams in der Bewertung, die gemäß den in einem Teil des vorgeschlagenen Datensatzes gezeigten Ergebnissen gebildet wurde. Die endgültige Bewertung wurde wiederum im anderen Teil des Datensatzes gebildet. Dies geschieht, damit die Teilnehmer des Wettbewerbs ihre Algorithmen nicht an bestimmte Daten anpassen. Daher sind die Positionen im Finale beim Wechsel zwischen den Bewertungen ein wenig "sheikap" (vom englischen Aufrütteln bis zum Mischen): Bei anderen Daten kann das Ergebnis anders ausfallen. Romans Team war das erste unter den ersten drei.  AU-Troika - ist Geld, Geld-Rankings Zone, da nur die ersten drei Stellen Preis Nach dem „Shake apa‚Team war bereits auf dem vierten Platz die gleiche Art und Weise das andere Team den Sieg verloren, die Position Gold -... Ed) verlassen .. <br><br><img src="https://habrastorage.org/webt/4x/zs/9d/4xzs9dipspiteybhjdudb9kdj7g.jpeg"><br><br>  Der Wettbewerb war auch deshalb bedeutsam, weil Jewgeni Babachnin Großmeister für ihn empfing, Ivan Sosin - Meister, Roman Solovyov blieb Großmeister, Alex Parinov erhielt einen Meister, ich wurde Experte und jetzt bin ich bereits Meister. <br><br><img src="https://habrastorage.org/webt/fy/-v/gv/fy-vgvzvgssn2kmnn3slpjajo5a.jpeg"><br><br>  Was ist das schnell, zeichnen?  Dies ist ein Dienst von Google.  Google wollte die KI bekannt machen und wollte mit diesem Dienst zeigen, wie neuronale Netze funktionieren.  Wenn Sie dorthin gehen, klicken Sie auf Lassen Sie uns zeichnen, und eine neue Seite wird angezeigt, auf der Sie aufgefordert werden: Zeichnen Sie einen Zickzack. Sie haben 20 Sekunden Zeit, dies zu tun.  Sie versuchen, wie hier in 20 Sekunden einen Zickzack zu zeichnen.  Wenn alles für Sie funktioniert, sagt das Netzwerk, dass es ein Zickzack ist und Sie weitermachen.  Es gibt nur sechs solcher Bilder. <br><br>  Wenn das Netzwerk von Google nicht erkennen konnte, was Sie gezeichnet haben, wurde die Aufgabe mit einem Kreuz versehen.  Später werde ich Ihnen sagen, was in Zukunft bedeuten wird, ob die Zeichnung vom Netzwerk erkannt wird oder nicht. <br><br>  Dieser Dienst versammelte eine ziemlich große Anzahl von Benutzern, und alle von Benutzern gezeichneten Bilder wurden protokolliert. <br><br><img src="https://habrastorage.org/webt/ni/kl/on/niklonrxxlfht_gy0u4yzg3k5og.jpeg"><br><br>  Es konnten fast 50 Millionen Bilder gesammelt werden.  Daraus wurden der Zug- und Testtermin für unseren Wettbewerb gebildet.  Übrigens sind die Datenmenge im Test und die Anzahl der Klassen nicht umsonst fett gedruckt.  Ich werde etwas später darüber sprechen. <br><br>  Das Datenformat war wie folgt.  Dies sind nicht nur RGB-Bilder, sondern grob gesagt das Protokoll von allem, was der Benutzer getan hat.  Wort ist unser Ziel, Ländercode ist, woher das Gekritzel kommt, Zeitstempel ist Zeit.  Das erkannte Etikett zeigt nur an, ob das Netzwerk von Google das Bild erkannt hat oder nicht.  Und das Zeichnen selbst ist eine Sequenz, eine Annäherung an die Kurve, die der Benutzer mit Punkten zeichnet.  Und Timings.  Dies ist die Zeit ab dem Beginn des Zeichnens des Bildes. <br><br><img src="https://habrastorage.org/webt/xw/_y/zw/xw_yzwjp5d8osd1ejay6gcncywu.jpeg"><br><br>  Die Daten wurden in zwei Formaten dargestellt.  Dies ist das erste Format und das zweite ist vereinfacht.  Von dort aus sägten sie Timings aus und näherten diese Punktmenge mit einer kleineren Punktmenge an.  Dazu verwendeten sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Douglas-Pecker-Algorithmus</a> .  Sie haben eine große Anzahl von Punkten, die sich einfach einer geraden Linie annähern, aber Sie können diese Linie tatsächlich mit nur zwei Punkten approximieren.  Dies ist die Idee des Algorithmus. <br><br>  Die Daten wurden wie folgt verteilt.  Alles ist einheitlich, aber es gibt einige Ausreißer.  Als wir das Problem gelöst haben, haben wir es uns nicht angesehen.  Die Hauptsache ist, dass es keine Klassen gab, die wirklich wenige sind. Wir mussten keine gewichteten Sampler und Daten-Oversampling durchführen. <br><br><img src="https://habrastorage.org/webt/cp/_z/8y/cp_z8ydmx3m7gaptzpm9pvfglvu.jpeg"><br><br>  Wie sahen die Bilder aus?  Dies ist die Flugzeugklasse, und Beispiele davon sind als erkannt und nicht erkannt gekennzeichnet.  Ihr Verhältnis lag irgendwo zwischen 1 und 9. Wie Sie sehen können, sind die Daten ziemlich verrauscht.  Ich würde vorschlagen, dass dies ein Flugzeug ist.  Wenn Sie nicht erkannt betrachten, ist es in den meisten Fällen nur Rauschen.  Jemand hat sogar versucht, "Flugzeug" zu schreiben, aber anscheinend auf Französisch. <br><br>  Die meisten Teilnehmer nahmen einfach Raster, renderten Daten aus dieser Zeilenfolge als RGB-Bilder und warfen sie in das Netzwerk.  Ich habe ungefähr auf die gleiche Weise gemalt: Ich habe eine Farbpalette genommen, ich habe die erste Zeile mit einer Farbe gemalt, die am Anfang dieser Palette stand, die letzte, mit einer anderen, die am Ende der Palette war, und überall dazwischen auf dieser Palette interpoliert.  Dies ergab übrigens ein besseres Ergebnis als beim Zeichnen wie auf der ersten Folie - nur schwarz. <br><br>  Andere Teammitglieder wie Ivan Sosin versuchten etwas andere Ansätze zum Zeichnen.  Mit einem Kanal zeichnete er einfach ein graues Bild, mit einem anderen Kanal zeichnete er jeden Strich mit einem Farbverlauf von Anfang bis Ende von 32 bis 255, und der dritte Kanal zeichnete einen Farbverlauf in allen Strichen von 32 bis 255. <br><br>  Eine weitere interessante Sache ist, dass Alex Parinov Informationen per Ländercode in das Netzwerk geworfen hat. <br><br><img src="https://habrastorage.org/webt/wm/z0/iw/wmz0iw6jp4sxzqm2z3zqtafkhbo.jpeg"><br><br>  Die im Wettbewerb verwendete Metrik ist Mean Average Precision.  Was ist das Wesentliche dieser Metrik für den Wettbewerb?  Sie können drei Prädiktoren angeben. Wenn diese drei Prädiktoren nicht korrekt sind, erhalten Sie 0. Wenn es einen korrekten gibt, wird dessen Reihenfolge berücksichtigt.  Das Ergebnis für das Ziel wird als 1 betrachtet, geteilt durch die Reihenfolge Ihrer Vorhersage.  Zum Beispiel haben Sie drei Vorhersagen gemacht, und die erste ist die richtige, dann teilen Sie 1 durch 1 und erhalten 1. Wenn der Prädiktor korrekt ist und seine Reihenfolge 2 ist, dann erhalten Sie 1 durch 2, erhalten Sie 0,5.  Nun, etc. <br><br><img src="https://habrastorage.org/webt/ar/fm/7k/arfm7knnnynq6iekr-ykcnxvdr8.jpeg"><br><br>  Mit der Datenvorverarbeitung - wie man Bilder zeichnet und so weiter - haben wir uns ein wenig entschieden.  Welche Architekturen haben wir verwendet?  Wir haben versucht, mutige Architekturen wie PNASNet, SENet und bereits klassische Architekturen wie SE-Res-NeXt zu verwenden. Sie treten zunehmend in neue Wettbewerbe ein.  Es gab auch ResNet und DenseNet. <br><br><img src="https://habrastorage.org/webt/rr/4p/ku/rr4pkuestkfvwxz4l-7absymotq.jpeg"><br><br><img src="https://habrastorage.org/webt/yz/4z/9_/yz4z9_fybssrwzh3recxexbrkbg.jpeg"><br><br><img src="https://habrastorage.org/webt/hw/eg/p9/hwegp98dpudcisrhvfbqx-92648.jpeg"><br><br>  Wie haben wir das gelehrt?  Alle Modelle, die wir genommen haben, haben wir auf Imagenet vorab trainiert.  Es gibt zwar viele Daten, 50 Millionen Bilder, aber wenn Sie ein auf Imagenet vorab geschultes Netzwerk verwenden, zeigt es ein besseres Ergebnis, als wenn Sie es nur von Grund auf neu trainieren. <br><br>  Welche Trainingstechniken haben wir angewendet?  Dies ist Cosing Annealing mit Warm Restarts, ich werde etwas später darüber sprechen.  Dies ist eine Technik, die ich in fast allen meinen letzten Wettbewerben verwende, und mit ihnen stellt sich heraus, dass es ziemlich gut ist, die Netze zu trainieren, um ein gutes Minimum zu erreichen. <br><br><img src="https://habrastorage.org/webt/9v/ch/ht/9vchht1fyo2sahp7bbxv7nnks3a.jpeg"><br><br>  Weiter Reduzieren Sie die Lernrate auf dem Plateau.  Sie beginnen, das Netzwerk zu trainieren, legen eine bestimmte Lernrate fest, lernen sie dann und Ihr Verlust konvergiert allmählich zu einem bestimmten Wert.  Sie überprüfen dies, zum Beispiel über zehn Epochen, der Verlust hat sich nicht geändert.  Sie reduzieren Ihre Lernrate um einen gewissen Wert und lernen weiter.  Es fällt wieder ein wenig ab, konvergiert bei einem bestimmten Minimum, und Sie senken erneut die Lernrate und so weiter, bis Ihr Netzwerk schließlich konvergiert. <br><br>  Weitere interessante Technik: Verringern Sie nicht die Lernrate, sondern erhöhen Sie die Stapelgröße.  Es gibt einen gleichnamigen Artikel.  Wenn Sie das Netzwerk trainieren, müssen Sie die Lernrate nicht verringern, sondern können nur die Stapelgröße erhöhen. <br><br>  Diese Technik wurde übrigens von Alex Parinov verwendet.  Er begann mit einem Stapel von 408, und als das Netzwerk auf sein Plateau kam, verdoppelte er einfach die Stapelgröße usw. <br><br>  Eigentlich erinnere ich mich nicht, welchen Wert die Chargengröße erreicht hat, aber interessanterweise gab es Teams auf Kaggle, die dieselbe Technik verwendeten. Ihre Chargengröße betrug ungefähr 10.000. Übrigens, moderne Frameworks für Deep Learning, wie z Mit PyTorch können Sie dies beispielsweise ganz einfach tun.  Sie generieren Ihren Stapel und senden ihn nicht so wie er ist in seiner Gesamtheit an das Netzwerk, sondern teilen ihn in Blöcke auf, sodass er in Ihre Grafikkarte passt, zählen die Farbverläufe und aktualisieren nach Berechnung des Verlaufs für den gesamten Stapel die Skalen. <br><br>  Übrigens kamen in diesem Wettbewerb immer noch große Chargengrößen hinzu, da die Daten ziemlich verrauscht waren und eine große Chargengröße Ihnen dabei half, den Gradienten genauer zu approximieren. <br><br>  Pseudo-Tupfen wurde ebenfalls verwendet, größtenteils von Roman Soloviev.  Er hat irgendwo die Hälfte der Daten aus dem Test abgetastet und auf solchen Chargen das Raster trainiert. <br><br>  Die Größe der Bilder spielte eine Rolle, aber Tatsache ist, dass Sie viele Daten haben, lange trainieren müssen und wenn Ihre Bildgröße ziemlich groß ist, werden Sie sehr lange trainieren.  Dies hat jedoch nicht so viel zur Qualität Ihres endgültigen Klassifikators beigetragen, sodass es sich gelohnt hat, einen Kompromiss einzugehen.  Und sie versuchten nur Bilder von nicht sehr großer Größe. <br><br>  Wie hat das alles gelernt?  Zuerst wurden Bilder von geringer Größe aufgenommen, mehrere Epochen wurden darauf ausgeführt, es dauerte schnell einige Zeit.  Dann wurden große Bilder gegeben, das Netzwerk lernte, dann noch mehr, noch mehr, um es nicht von Grund auf zu trainieren und nicht viel Zeit zu verbringen. <br><br>  Über Optimierer.  Wir haben SGD und Adam benutzt.  Auf diese Weise war es möglich, ein einzelnes Modell mit einer Geschwindigkeit von 0,941 bis 0,946 in einer öffentlichen Rangliste zu erhalten, was ziemlich gut ist. <br><br>  Wenn Sie Modelle auf irgendeine Weise zusammenstellen, erhalten Sie irgendwo 0,951.  Wenn Sie eine andere Technik anwenden, erhalten Sie die Endgeschwindigkeit auf dem öffentlichen Brett 0,954, wie wir erhalten haben.  Aber dazu später mehr.  Als nächstes werde ich Ihnen erzählen, wie wir die Modelle zusammengebaut haben und wie eine solche Endgeschwindigkeit erreicht wurde. <br><br>  Als nächstes möchte ich über das Schließen des Glühens mit warmen Neustarts oder den stochastischen Gradientenabstieg mit warmen Neustarts sprechen.  Grundsätzlich kann man im Prinzip jeden Optimierer verwenden, aber das Fazit lautet: Wenn Sie nur ein Netzwerk trainieren und es allmählich auf ein Minimum konvergiert, ist alles in Ordnung, Sie erhalten ein Netzwerk, es macht bestimmte Fehler. aber du kannst sie ein bisschen anders unterrichten.  Sie werden eine anfängliche Lernrate festlegen und diese gemäß dieser Formel schrittweise senken.  Sie unterschätzen es, Ihr Netzwerk erreicht ein bestimmtes Minimum, dann sparen Sie Gewichte und stellen erneut die Lernrate ein, die zu Beginn des Trainings lag, wodurch Sie von diesem Minimum irgendwo nach oben gehen und Ihre Lernrate erneut unterschätzen. <br><br>  Auf diese Weise können Sie mehrere Tiefs gleichzeitig besuchen, bei denen Sie den Verlust plus oder minus des gleichen haben.  Tatsache ist jedoch, dass Netzwerke mit diesen Gewichten bei Ihrem Datum unterschiedliche Fehler verursachen.  Wenn Sie sie mitteln, erhalten Sie eine bestimmte Annäherung und Ihre Geschwindigkeit ist höher. <br><br><img src="https://habrastorage.org/webt/ra/5d/mz/ra5dmzx9mcelguiqckvaihllrkc.jpeg"><br><br>  Wie wir unsere Modelle zusammengebaut haben.  Zu Beginn der Präsentation sagte ich, ich solle auf die Datenmenge im Test und die Anzahl der Klassen achten.  Wenn Sie der Anzahl der Ziele im Testsatz 1 hinzufügen und durch die Anzahl der Klassen dividieren, erhalten Sie die Nummer 330, und darüber wurde im Forum geschrieben - dass die Klassen im Test ausgeglichen sind.  Dies könnte verwendet werden. <br><br>  Auf dieser Grundlage erfand Roman Solovyov die Metrik, wir nannten sie den Proxy Score, der recht gut mit der Rangliste korrelierte.  Das Fazit lautet: Sie machen eine Vorhersage, nehmen die Top-1 Ihrer Vorhersagen und zählen die Anzahl der Objekte für jede Klasse.  Subtrahieren Sie 330 von jedem Wert und addieren Sie die resultierenden absoluten Werte. <br><br>  Solche Werte stellten sich heraus.  Dies hat uns geholfen, keine Test-Bestenliste zu erstellen, sondern lokal zu validieren und Koeffizienten für unsere Ensembles auszuwählen. <br><br>  Mit dem Ensemble könnte man eine solche Geschwindigkeit erreichen.  Was noch zu tun?  Angenommen, Sie haben die Information verwendet, dass die Klassen in Ihrem Test ausgeglichen sind. <br><br>  Das Gleichgewicht war anders.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein Beispiel für einen von ihnen</a> ist das Ausbalancieren der Jungs, die den ersten Platz gewonnen haben. <br><br>  Was haben wir gemacht  Unser Ausgleich war recht einfach, es wurde von Evgeny Babakhnin vorgeschlagen.  Wir haben unsere Vorhersagen zuerst nach Top-1 sortiert und Kandidaten aus ihnen ausgewählt - so dass die Anzahl der Klassen 330 nicht überschritt. Bei einigen Klassen stellt sich jedoch heraus, dass es weniger Vorhersagen als 330 gibt. Okay, lassen Sie uns nach Top-2 sortieren und Top 3, und wählen Sie auch Kandidaten. <br><br>  Inwiefern unterschied sich unser Ausgleich vom ersten Ausgleich?  Sie verwendeten einen iterativen Ansatz, nahmen die beliebteste Klasse und reduzierten die Wahrscheinlichkeiten für diese Klasse um eine kleine Anzahl - bis diese Klasse nicht mehr die beliebteste wurde.  Sie nahmen an der nächstbeliebtesten Klasse teil.  Also weiter und abgesenkt, bis die Anzahl aller Klassen gleich wurde. <br><br>  Jeder benutzte einen Plus- oder Minus-Ansatz für Trainingsnetzwerke, aber nicht jeder benutzte das Balancieren.  Mit Balancing könnten Sie in Gold gehen, und wenn Sie Glück hatten, dann in Mani. <br><br>  Wie kann ich ein Datum vorverarbeiten?  Alle haben das Plus-Minus-Datum auf die gleiche Weise vorverarbeitet - sie haben handgefertigte Funktionen erstellt, Timings mit verschiedenen Strichfarben codiert usw. Alexey Nozdrin-Plotnitsky, der den 8. Platz belegte, sprach darüber. <br><br><img src="https://habrastorage.org/webt/lq/jg/yb/lqjgybopsgcacrtnubcet3jub9e.jpeg"><br><br>  Er hat es anders gemacht.  Er sagte, dass all diese handgefertigten Funktionen nicht funktionieren. Sie müssen dies nicht tun. Ihr Netzwerk muss dies alles selbst lernen.  Stattdessen entwickelte er Lernmodule, mit denen Ihre Daten vorverarbeitet wurden.  Er warf ihnen die Quelldaten ohne Vorverarbeitung ein - die Koordinaten von Punkten und Zeitpunkten. <br><br>  Außerdem nahm er den Unterschied in den Koordinaten und mittelte ihn über die Zeitpunkte.  Und er hat eine ziemlich lange Matrix.  Er verwendete 1D-Faltung mehrmals, um eine 64xn-Matrix zu erhalten, wobei n die Gesamtzahl der Punkte ist, und 64 wird gemacht, um die resultierende Matrix einer Schicht eines Faltungsnetzwerks zuzuführen, das 64 Kanäle akzeptiert. Es stellte sich heraus, dass es sich um eine 64xn-Matrix handelte. Daraus musste ein Tensor von einiger Größe zusammengesetzt werden, so dass die Anzahl der Kanäle 64 betrug. Er normalisierte alle Punkte X, Y im Bereich von 0 bis 32, um einen Tensor der Größe 32x32 zu erhalten.  Ich weiß nicht, warum er 32x32 wollte, es ist passiert.  Und in diese Koordinate legte er ein Fragment dieser Matrix der Größe 64xn.  So erhielt er einfach den 32x32x64-Tensor, der weiter in Ihr Faltungs-Neuronales Netzwerk integriert werden könnte.  Ich habe alles </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440666/">https://habr.com/ru/post/de440666/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440654/index.html">Python lernen: Argparse-Modul</a></li>
<li><a href="../de440656/index.html">Professionelle Containerisierung von Node.js-Anwendungen mit Docker</a></li>
<li><a href="../de440658/index.html">Exploring Docker, Teil 4: Reduzieren der Größe von Bildern und Beschleunigen ihrer Montage</a></li>
<li><a href="../de440660/index.html">Docker lernen, Teil 5: Befehle</a></li>
<li><a href="../de440662/index.html">React Tutorial Teil 18: Die sechste Phase der Arbeit an einer TODO-Anwendung</a></li>
<li><a href="../de440670/index.html">Die Zentralbank veröffentlichte Empfehlungen zum kryptografischen Schutz von EBS</a></li>
<li><a href="../de440672/index.html">Methoden der Rationalität und das Maghreb-Gebet Mat</a></li>
<li><a href="../de440674/index.html">Verwenden von Streudiagrammen zur Visualisierung von Daten</a></li>
<li><a href="../de440676/index.html">Der Tag, an dem Dodo aufgehört hat. Synchrones Skript</a></li>
<li><a href="../de440678/index.html">DIY Hobby CNC Fräser. Geisteswissenschaften für die Geisteswissenschaften. Teil 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
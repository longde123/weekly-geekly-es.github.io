<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÇ üíù ‚úäüèª Redes neuronales ¬øA d√≥nde va todo? üñêüèæ üï¥üèº üëáüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El art√≠culo consta de dos partes: 


1. Una breve descripci√≥n de algunas arquitecturas de red para detectar objetos en una imagen y segmentaci√≥n de im...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neuronales ¬øA d√≥nde va todo?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482794/"><p>  El art√≠culo consta de dos partes: </p><br><ol><li>  Una breve descripci√≥n de algunas arquitecturas de red para detectar objetos en una imagen y segmentaci√≥n de im√°genes con los enlaces de recursos m√°s comprensibles para m√≠.  Trat√© de elegir explicaciones en video y preferiblemente en ruso. </li><li>  La segunda parte es un intento de comprender la direcci√≥n del desarrollo de las arquitecturas de redes neuronales.  Y tecnolog√≠as basadas en ellos. </li></ol><br><p><img src="https://habrastorage.org/webt/8a/ph/qb/8aphqb_xrv3ynavkgmuex1ib8qo.jpeg" alt="Comprender las arquitecturas de redes neuronales no es f√°cil"></p><br><p>  Figura 1 - Comprender la arquitectura de las redes neuronales no es f√°cil </p><br><p> Todo comenz√≥ con el hecho de que hizo dos aplicaciones de demostraci√≥n para clasificar y detectar objetos en un tel√©fono Android: </p><br><ul><li>  <a href="https://github.com/foobar167/junkyard/tree/master/object_classifier">Demostraci√≥n de fondo</a> , cuando los datos se procesan en el servidor y se transfieren al tel√©fono.  Clasificaci√≥n de im√°genes de tres tipos de osos: marr√≥n, negro y peluche. </li><li>  <a href="https://github.com/foobar167/android/tree/master/object_detection_demo">Demostraci√≥n frontal</a> cuando los datos se procesan en el tel√©fono.  Detecci√≥n de objetos de tres tipos: avellanas, higos y d√°tiles. </li></ul><a name="habracut"></a><br><p>  Hay una diferencia entre las tareas de clasificar im√°genes, detectar objetos en una imagen y <a href="https://medium.com/analytics-vidhya/image-classification-vs-object-detection-vs-image-segmentation-f36db85fe81">segmentar im√°genes</a> .  Por lo tanto, era necesario averiguar qu√© arquitecturas de redes neuronales detectan objetos en im√°genes y cu√°les pueden segmentarse.  Encontr√© los siguientes ejemplos de arquitecturas con los enlaces de recursos m√°s comprensibles para m√≠: </p><br><ul><li>  Una serie de arquitecturas basadas en R-CNN ( <strong>R</strong> egions con caracter√≠sticas de red <strong>N</strong> onural de onvoluci√≥n): R-CNN, Fast R-CNN, <a href="https://medium.com/%40smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">Faster R-CNN</a> , <a href="https://youtu.be/0vt05rQqk_I">Mask R-CNN</a> .  Para detectar un objeto en una imagen usando el mecanismo de Red de Propuesta de Regi√≥n (RPN), se asignan cuadros delimitadores.  Inicialmente, se utiliz√≥ el mecanismo de b√∫squeda selectiva m√°s lento en lugar del RPN.  Luego, las regiones limitadas seleccionadas se alimentan a la entrada de una red neuronal normal para su clasificaci√≥n.  En la arquitectura de R-CNN hay ciclos expl√≠citos de enumeraci√≥n "para" en regiones limitadas, en total hasta 2000 ejecuciones a trav√©s de la red interna AlexNet.  Debido a los bucles "for" expl√≠citos, la velocidad de procesamiento de im√°genes se ralentiza.  El n√∫mero de ciclos expl√≠citos, se ejecuta a trav√©s de la red neuronal interna, disminuye con cada nueva versi√≥n de la arquitectura, y se llevan a cabo docenas de otros cambios para aumentar la velocidad y reemplazar la tarea de detectar objetos con segmentaci√≥n de objetos en M√°scara R-CNN. </li><li>  <a href="https://youtu.be/L0tzmv--CGY">YOLO</a> ( <strong>O</strong> lly <strong>O</strong> Lok <strong>O</strong> once) es la primera red neuronal que reconoce objetos en tiempo real en dispositivos m√≥viles.  Caracter√≠stica distintiva: distinguir objetos en una ejecuci√≥n (solo mira una vez).  Es decir, no hay bucles "for" expl√≠citos en la arquitectura YOLO, por lo que la red es r√°pida.  Por ejemplo, esto es una analog√≠a: en NumPy no hay bucles "for" expl√≠citos en operaciones con matrices, que se implementan en NumPy en niveles inferiores de arquitectura a trav√©s del lenguaje de programaci√≥n C. YOLO utiliza una cuadr√≠cula de ventanas predefinidas.  Para evitar que se detecte el mismo objeto varias veces, se utiliza el coeficiente de superposici√≥n de ventana (IoU, Intersection <strong>o</strong> ver Union).  Esta arquitectura funciona en una amplia gama y tiene una gran <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25B1%25D0%25B0%25D1%2581%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">robustez</a> : el modelo se puede entrenar en fotograf√≠as, pero al mismo tiempo funciona bien en pinturas pintadas. </li><li>  <a href="https://youtu.be/P8e-G-Mhx4k">SSD</a> (Detector MultiBox <strong>S</strong> ingle <strong>S</strong> hot): se utilizan los "hacks" m√°s exitosos de la arquitectura YOLO (por ejemplo, supresi√≥n no m√°xima) y se agregan otros nuevos para hacer que la red neuronal sea m√°s r√°pida y precisa.  Caracter√≠stica distintiva: distinguir objetos en una ejecuci√≥n utilizando una cuadr√≠cula de ventanas dada (cuadro predeterminado) en la pir√°mide de im√°genes.  La pir√°mide de im√°genes est√° codificada en tensores de convoluci√≥n durante sucesivas operaciones de convoluci√≥n y agrupaci√≥n (con la operaci√≥n de agrupaci√≥n m√°xima, la dimensi√≥n espacial disminuye).  De esta manera, los objetos grandes y peque√±os se determinan en una sola ejecuci√≥n de red. </li><li>  MobileSSD ( <strong>Mobile</strong> NetV2 + <strong>SSD</strong> ) es una combinaci√≥n de dos arquitecturas de red neuronal.  La primera red <a href="https://habr.com/ru/post/352804/">MobileNetV2</a> es r√°pida y aumenta la precisi√≥n del reconocimiento.  MobileNetV2 se utiliza en lugar de VGG-16, que se utiliz√≥ originalmente en el <a href="https://arxiv.org/abs/1512.02325">art√≠culo original</a> .  La segunda red SSD determina la ubicaci√≥n de los objetos en la imagen. </li><li>  <a href="https://youtu.be/ge_RT5wvHvY">SqueezeNet</a> es una red neuronal muy peque√±a pero precisa.  Por s√≠ solo, no resuelve el problema de detectar objetos.  Sin embargo, se puede usar con una combinaci√≥n de diferentes arquitecturas.  Y ser utilizado en dispositivos m√≥viles.  Una caracter√≠stica distintiva es que los datos se comprimen primero en cuatro filtros convolucionales 1 √ó 1, y luego se expanden a cuatro filtros convolucionales 1 √ó 1 y cuatro 3 √ó 3.  Una de estas iteraciones de compresi√≥n-expansi√≥n de datos se llama "M√≥dulo de Fuego". </li><li>  <a href="https://youtu.be/b6jhopSMit8">DeepLab</a> (Segmentaci√≥n de imagen sem√°ntica con redes convolucionales profundas): segmentaci√≥n de objetos en la imagen.  Una caracter√≠stica distintiva de la arquitectura es una convoluci√≥n diluida, que preserva la resoluci√≥n espacial.  Esto es seguido por la etapa de postprocesamiento de los resultados utilizando un modelo gr√°fico probabil√≠stico (campo aleatorio condicional), que le permite eliminar peque√±os ruidos en la segmentaci√≥n y mejorar la calidad de la imagen segmentada.  Detr√°s del nombre formidable "modelo probabil√≠stico gr√°fico" est√° el filtro gaussiano habitual, que se aproxima en cinco puntos. </li><li>  Trat√© de entender el dispositivo <a href="https://arxiv.org/abs/1711.06897">RefineDet</a> (Red neuronal de <a href="https://arxiv.org/abs/1711.06897">refinamiento</a> de disparo √∫nico para la detecci√≥n de objetos), pero entend√≠ muy poco. </li><li>  Tambi√©n mir√© c√≥mo funciona la tecnolog√≠a de atenci√≥n: <a href="https://youtu.be/W2rWgXJBZhU">video1</a> , <a href="https://youtu.be/iDulhoQ2pro">video2</a> , <a href="https://youtu.be/H6Qiegq_36c">video3</a> .  Una caracter√≠stica distintiva de la arquitectura de "atenci√≥n" es la asignaci√≥n autom√°tica de regiones de mayor atenci√≥n a la imagen (RoI, <strong>R</strong> egions of f Iterest) utilizando una red neuronal llamada Unidad de Atenci√≥n.  Las regiones de mayor atenci√≥n son similares a las regiones limitadas (cuadros delimitadores), pero a diferencia de ellas, no est√°n fijas en la imagen y pueden tener bordes borrosos.  Luego, de las regiones de mayor atenci√≥n, se distinguen caracter√≠sticas (caracter√≠sticas) que se "alimentan" a redes neuronales recurrentes con <a href="https://youtu.be/5lUUrREboSk">arquitecturas LSDM, GRU o Vanilla RNN</a> .  Las redes neuronales recursivas pueden analizar la relaci√≥n de los signos en una secuencia.  Las redes neuronales recursivas se utilizaron originalmente para traducir texto a otros idiomas, y ahora para traducir <a href="https://youtu.be/e-WB4lfg30M">im√°genes en texto</a> y <a href="https://youtu.be/rAbhypxs1qQ">texto en im√°genes</a> . </li></ul><br><p>  Mientras estudiaba estas arquitecturas, <strong>me di cuenta de que no entend√≠a nada</strong> .  Y el punto no es que mi red neuronal tenga problemas con el mecanismo de atenci√≥n.  La creaci√≥n de todas estas arquitecturas parece una especie de gran hackathon donde los autores compiten en hacks.  Hack es una soluci√≥n r√°pida para una tarea de software dif√≠cil.  Es decir, no hay una conexi√≥n l√≥gica visible y comprensible entre todas estas arquitecturas.  Todo lo que los une es un conjunto de los hacks m√°s exitosos que se prestan entre s√≠, m√°s una <a href="https://youtu.be/Ilg3gGewQ5U">operaci√≥n de convoluci√≥n</a> com√∫n <a href="https://youtu.be/Ilg3gGewQ5U">con retroalimentaci√≥n</a> (propagaci√≥n inversa del error, propagaci√≥n inversa).  ¬°Ning√∫n <a href="https://habr.com/ru/post/272473/">pensamiento sist√©mico</a> !  No est√° claro qu√© cambiar y c√≥mo optimizar los logros existentes. </p><br><p>  Como resultado de la falta de una conexi√≥n l√≥gica entre los hacks, son extremadamente dif√≠ciles de recordar y poner en pr√°ctica.  Esto es conocimiento fragmentado.  En el mejor de los casos, se recuerdan varios momentos interesantes e inesperados, pero la mayor parte de lo que se entiende e incomprensible desaparece de la memoria en pocos d√≠as.  Ser√° bueno si en una semana recuerdo al menos el nombre de la arquitectura.  ¬°Pero tom√≥ varias horas e incluso d√≠as de tiempo de trabajo leer art√≠culos y ver videos de revisi√≥n! </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ffc/1b0/019/ffc1b0019fe7a23e2923d9642485290a.png" alt="Zool√≥gico de la red neuronal"></p><br><p>  Figura 2 - <a href="https://www.asimovinstitute.org/neural-network-zoo/">Zool√≥gico de redes neuronales</a> </p><br><p>  La mayor√≠a de los autores de art√≠culos cient√≠ficos, en mi opini√≥n personal, hacen todo lo posible para que incluso este conocimiento fragmentado no sea entendido por el lector.  Pero los participios en oraciones de diez l√≠neas con f√≥rmulas tomadas "desde el techo" es un tema para un art√≠culo separado (problema de <a href="https://en.wikipedia.org/wiki/Publish_or_perish">publicaci√≥n o fallecimiento</a> ). </p><br><p>  Por esta raz√≥n, se hizo necesario sistematizar la informaci√≥n en redes neuronales y, por lo tanto, aumentar la calidad de la comprensi√≥n y la memorizaci√≥n.  Por lo tanto, el tema principal de an√°lisis de las tecnolog√≠as y arquitecturas individuales de las redes neuronales artificiales fue la siguiente tarea: <strong>averiguar d√≥nde se mueve todo esto</strong> , y no el dispositivo de ninguna red neuronal en particular por separado. </p><br><p>  ¬øA d√≥nde va todo esto?  Los principales resultados: </p><br><ul><li>  El n√∫mero de nuevas empresas en el campo del aprendizaje autom√°tico <a href="https://habr.com/ru/company/recognitor/blog/455676/">ha disminuido considerablemente</a> en los √∫ltimos dos a√±os.  Posible raz√≥n: "las redes neuronales han dejado de ser algo nuevo". </li><li>  Todos podr√°n crear una red neuronal que funcione para resolver un problema simple.  Para hacer esto, tome el modelo terminado del "zool√≥gico modelo" y entrene la √∫ltima capa de la red neuronal ( <a href="https://youtu.be/yofjFQddwHE">aprendizaje de transferencia</a> ) en los datos terminados de <a href="https://toolbox.google.com/datasetsearch">Google Dataset Search</a> o de <a href="https://www.kaggle.com/datasets">25 mil conjuntos</a> de <a href="https://www.kaggle.com/datasets">datos Kaggle</a> en la <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">nube</a> gratuita de <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">Jupyter Notebook</a> . </li><li>  Los grandes fabricantes de redes neuronales comenzaron a crear <strong>"zool√≥gicos modelo"</strong> (zool√≥gico modelo).  Con ellos, puede crear r√°pidamente una aplicaci√≥n comercial: <a href="https://tfhub.dev/">TF Hub</a> para TensorFlow, <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> para PyTorch, <a href="https://github.com/facebookresearch/Detectron">Detectron</a> para Caffe2, <a href="https://github.com/wkentaro/chainer-modelzoo">chainer-modelzoo</a> para <a href="https://github.com/wkentaro/chainer-modelzoo">Chainer</a> y <a href="https://modelzoo.co/">otros</a> . </li><li>  Redes neuronales en tiempo real en dispositivos m√≥viles.  10 a 50 cuadros por segundo. </li><li>  El uso de redes neuronales en tel√©fonos (TF Lite), en navegadores (TF.js) y en <a href="https://youtu.be/19ZNz2N79u4">art√≠culos para el hogar</a> (IoT, Internet y <strong>T</strong> hings).  Especialmente en tel√©fonos que ya admiten redes neuronales a nivel de hardware (neuroaceleradores). </li><li>  "Cada dispositivo, ropa y posiblemente incluso comida tendr√°n una <strong>direcci√≥n IP-v6</strong> y se comunicar√°n entre s√≠" - <a href="https://youtu.be/GG7H8Xa4m8I%3Ft%3D85">Sebastian Trun</a> . </li><li>  El aumento en las publicaciones de aprendizaje autom√°tico ha comenzado a <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">superar la ley de Moore</a> (que se duplica cada dos a√±os) desde 2015.  Obviamente, se necesitan redes neuronales de an√°lisis de art√≠culos. </li><li>  Las siguientes tecnolog√≠as est√°n ganando popularidad: <br><ul><li>  <strong>PyTorch</strong> : la popularidad est√° creciendo r√°pidamente y parece superar a TensorFlow. </li><li>  Selecci√≥n autom√°tica de hiperpar√°metros <strong>AutoML</strong> : la popularidad est√° creciendo sin problemas. </li><li>  Disminuci√≥n gradual de la precisi√≥n y aumento de la velocidad de c√°lculo: <a href="https://youtu.be/rln_kZbYaWc">l√≥gica difusa</a> , algoritmos de refuerzo, c√°lculos inexactos (aproximados), cuantizaci√≥n (cuando los pesos de una red neuronal se convierten en enteros y cuantificados), neuroaceleradores. </li><li>  Traducci√≥n de <a href="https://youtu.be/e-WB4lfg30M">imagen en texto</a> y <a href="https://youtu.be/rAbhypxs1qQ">texto en imagen</a> . </li><li>  Creaci√≥n <a href="https://youtu.be/OrHLacCDZVQ">de objetos tridimensionales en video</a> , ahora en tiempo real. </li><li>  Lo principal en DL es una gran cantidad de datos, pero recopilarlos y marcarlos no es f√°cil.  Por lo tanto, se est√° desarrollando <a href="https://youtu.be/NcKTn4C91Yc">una anotaci√≥n automatizada</a> para redes neuronales que usan redes neuronales. </li></ul></li><li>  Con las redes neuronales, la inform√°tica de repente se convirti√≥ en una <strong>ciencia experimental</strong> y surgi√≥ una <a href="https://habr.com/ru/post/480348">crisis de reproducibilidad</a> . </li><li>  El dinero de TI y la popularidad de las redes neuronales surgieron simult√°neamente cuando la inform√°tica se convirti√≥ en un valor de mercado.  La econom√≠a del oro y las divisas se est√° convirtiendo <strong>en la computaci√≥n de la moneda de oro</strong> .  Vea mi art√≠culo sobre <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D0%25BE%25D0%25BD%25D0%25BE%25D1%2584%25D0%25B8%25D0%25B7%25D0%25B8%25D0%25BA%25D0%25B0">econof√≠sica</a> y la raz√≥n de la aparici√≥n del dinero de TI. </li></ul><br><p>  Gradualmente, aparece una nueva <a href="https://habr.com/ru/post/481844">metodolog√≠a de programaci√≥n ML / DL</a> (Machine Learning &amp; Deep Learning), que se basa en la presentaci√≥n del programa como una colecci√≥n de modelos entrenados de redes neuronales. </p><br><p><img src="https://habrastorage.org/webt/tx/_a/vl/tx_avlc4bdfe6cfu5hy2bug3nby.png" alt="ML / DL como una nueva metodolog√≠a de programaci√≥n"></p><br><p>  Figura 3 - ML / DL como una nueva metodolog√≠a de programaci√≥n </p><br><p>  Sin embargo, la <strong>"teor√≠a de las redes neuronales"</strong> no apareci√≥, dentro del marco de la cual uno puede pensar y trabajar sistem√°ticamente.  Lo que ahora se llama "teor√≠a" es en realidad algoritmos heur√≠sticos experimentales. </p><br><p>  Enlaces a mis y no solo recursos: </p><br><ul><li>  Bolet√≠n de ciencia de datos.  Principalmente procesamiento de im√°genes.  Quien quiera recibir, deje que env√≠e un correo electr√≥nico (foobar167 &lt;gaff-gaf&gt; gmail &lt;dot&gt; com).  Env√≠o enlaces a art√≠culos y videos a medida que se acumula material. </li><li>  Una <a href="">lista</a> general <a href="">de cursos y art√≠culos</a> que he tomado y que me gustar√≠a tomar. </li><li>  <a href="">Cursos y videos para principiantes</a> , de los cuales vale la pena comenzar a estudiar redes neuronales.  Adem√°s del folleto <a href="https://foobar167.github.io/page/vvedeniye-v-mashinnoye-obucheniye-i-iskusstvennyye-neyronnyye-seti.html">"Introducci√≥n al aprendizaje autom√°tico y las redes neuronales artificiales"</a> . </li><li>  <a href="">Herramientas √∫tiles</a> donde todos encontrar√°n algo interesante para ellos. </li><li>  Los <strong>canales de video para el an√°lisis de art√≠culos cient√≠ficos</strong> sobre Data Science resultaron ser extremadamente √∫tiles.  Encuentra, suscr√≠bete y env√≠a enlaces a tus colegas y a m√≠ tambi√©n.  Ejemplos: <br><ul><li>  <a href="https://www.youtube.com/user/keeroyz">Papeles de dos minutos</a> </li><li>  <a href="https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw">Henry AI Labs</a> </li><li>  <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">Asesino Yannic</a> </li><li>  <a href="https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA">CodeEmporium</a> </li><li>  <a href="https://www.dlology.com/">Blog de Chengwei Zhang,</a> tambi√©n <a href="https://github.com/Tony607">conocido</a> como <a href="https://github.com/Tony607">Tony607,</a> con instrucciones paso a paso y c√≥digo abierto. </li></ul></li></ul><br><p>  Gracias por su atencion! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/482794/">https://habr.com/ru/post/482794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../482784/index.html">La vida secreta de un servidor Linux o un ataque de fuerza bruta de un ventilador en el subsistema SSH</a></li>
<li><a href="../482786/index.html">Acertijo sin resolver</a></li>
<li><a href="../482788/index.html">¬øQu√© hay dentro del TPU Google Coral Edge ?: pruebas de velocidad y an√°lisis del dispositivo</a></li>
<li><a href="../482790/index.html">Olv√≠date del cifrado homom√≥rfico: ahora tenemos el cifrado funcional</a></li>
<li><a href="../482792/index.html">Proyecto ITER en 2019</a></li>
<li><a href="../482798/index.html">Ver el bosque detr√°s de los √°rboles</a></li>
<li><a href="../482800/index.html">Mis b√∫squedas del panel de control f√≠sico de una casa inteligente</a></li>
<li><a href="../482802/index.html">Inclusi√≥n remota de scripts Mikrotik desde Telegram v 2.0</a></li>
<li><a href="../482804/index.html">Java: contraiga los registros de varias l√≠neas en un registro de una sola l√≠nea utilizando Spring y Logback o Log4j2</a></li>
<li><a href="../482806/index.html">¬øLa propaganda del r√©gimen totalitario, el antisemitismo y la homofobia en el libro de texto sobre programaci√≥n de 2019? - es posible</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤱🏾 👩🏿‍🤝‍👩🏼 😓 Superlight Velocity Profiling: Theorie und Praxis. Teil 1 🧛🏼 👩🏾‍🤝‍👨🏿 👨🏼‍🌾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! Aus der Überschrift haben Sie bereits verstanden, worüber ich sprechen werde. Es wird viel Hardcore geben: 
 Wir werden Java, C, C ++, Assemble...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Superlight Velocity Profiling: Theorie und Praxis. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/raiffeisenbank/blog/466719/">  Hallo!  Aus der Überschrift haben Sie bereits verstanden, worüber ich sprechen werde.  Es wird viel Hardcore geben: <br>  Wir werden Java, C, C ++, Assembler, ein bisschen Linux, ein bisschen Kernel des Betriebssystems diskutieren.  Wir werden auch einen praktischen Fall analysieren, sodass der Artikel aus drei großen Teilen besteht (ziemlich umfangreich). <br><br><img src="https://habrastorage.org/webt/mp/cl/er/mpclerfppp9jx5ciuziyfv-n8oa.png"><br><br>  Im ersten Schritt werden wir versuchen, alles aus den vorhandenen Profilern herauszuholen. <br>  Im zweiten Teil erstellen wir unseren eigenen kleinen Profiler, und im dritten Teil erfahren Sie, wie Sie Profile erstellen, die für Profile nicht üblich sind, da vorhandene Tools dafür nicht sehr geeignet sind.  Wenn Sie bereit sind, diesen Weg zu gehen - ich warte unter dem Schnitt auf Sie :) <br><a name="habracut"></a><br><h3>  Inhalt </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeit und Mittel zum Verständnis - Profiler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">So funktionieren Sampling-Profiler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie oft müssen wir probieren</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wählen Sie einen Profiler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erfahren Sie, wie Sie ein Java-Anwendungsprofil erstellen.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erhöhen Sie die Perf-Abtastrate</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wir verwenden (explizit) Hardware-PMU / PEBS-Ereignisse</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kurze Zusammenfassung</a> </li></ul><br><a name="1"></a><h3>  Zeit und Mittel zum Verständnis - Profiler </h3><br>  Aus alltäglicher Sicht ist 1 Sekunde sehr klein.  Aber wir wissen, dass 1 Sekunde eine ganze Milliarde Nanosekunden ist.  Und lassen Sie es in nur 1 Nanosekunde ungefähr 4 Prozessorzyklen dauern. In 1 Sekunde werden im Computer viele Dinge erledigt, die unser Leben verbessern oder verschlechtern können. <br><br>  Angenommen, wir entwickeln eine Anwendung, die an sich kritisch genug ist, um zu beschleunigen, und für einige Codefragmente ist dies im Allgemeinen kritisch.  Diese Teile werden beispielsweise Hunderte von Mikrosekunden ausgeführt - schnell genug, aber sie [ <i>Codeabschnitte</i> ] wirken sich direkt auf den Erfolg unserer Anwendung und den Betrag des verdienten oder verlorenen Geldes aus.  Zum Beispiel <br>  Beim Senden von Aufträgen zum Abschluss von Umtauschtransaktionen kann eine Verzögerung von 100 Mikrosekunden den Umtausch 1 Million Rubel oder mehr für jede Transaktion kosten, die von einem, nicht zwei oder sogar nicht hundert abgeschlossen wird. <br><br>  Und die <b>Aufgabe</b> war für mich gestellt: Einerseits müssen Sie alle Bestellungen gleichzeitig senden und andererseits müssen Sie sie senden, damit die Abweichung zwischen der ersten und der letzten minimal ist.  Das heißt, es war notwendig, eine Funktion zu profilieren, die Bestellungen an die Börse sendet.  Eine typische Aufgabe, abgesehen von einer kleinen Nuance: Die charakteristische Ausführungszeit dieser Funktion beträgt <i>deutlich weniger als 100 μs</i> . <br><br>  Lassen Sie uns darüber nachdenken, wie wir diese 100 μs profilieren, um zu verstehen, was im Inneren geschieht. <br>  Was ist bei der Auswahl dieses Tools zu beachten? <br><br><ol><li>  Der Codeabschnitt, der uns interessiert, wird selten ausgeführt, dh 100 Mikrosekunden werden irgendwo einmal pro Sekunde ausgeführt.  Und das auf dem Prüfstand und in der Produktion noch weniger. </li><li>  Es wird schwierig sein, diesen Code in ein Mikrobenchmark zu isolieren, da er einen wesentlichen Teil des Projekts und sogar die Eingabe / Ausgabe über das Netzwerk betrifft. </li><li>  Und schließlich möchte ich vor allem, dass das resultierende Profil dem Verhalten auf unseren Produktionsservern entspricht. </li></ol><br>  Wie berücksichtigen wir all diese Nuancen und profilieren die interessierende Methode korrekt? <br><br>  Konzeptionell können alle Profiler in zwei Gruppen von Profilern unterteilt werden, die <i>instrumentieren</i> oder <i>abtasten</i> .  Betrachten wir jede Gruppe einzeln. <br><br>  <b>Werkzeugprofiler verursachen</b> einen erheblichen Aufwand, da sie unseren Bytecode ändern und einen Zeitdatensatz einfügen.  Daher der Hauptnachteil solcher Profiler: Sie können den ausführbaren Code erheblich beeinflussen.  Infolgedessen ist es schwierig zu sagen, inwieweit das resultierende Profil dem Verhalten auf Produktionsservern entspricht: Einige Optimierungen funktionieren möglicherweise anders, andere passieren und andere nicht.  Vielleicht erhalten wir auf anderen Zeitskalen - Sekunden, Minuten, Stunden - repräsentative Daten.  Auf einer Skala von 100 μs kann eine ausgelöste oder fehlgeschlagene Optimierung dazu führen, dass das Profil völlig nicht repräsentativ ist.  Schauen wir uns also eine andere Gruppe von Profilern genauer an. <br><br>  <b>Stichprobenprofiler</b> tragen entweder zu einem minimalen oder moderaten Overhead bei.  Diese Tools wirken sich nicht direkt auf den ausführbaren Code aus, und ihre Verwendung erfordert etwas mehr Aufmerksamkeit von Ihnen.  Daher werden wir uns mit den Samping-Profilern befassen.  Mal sehen, welche Daten und in welcher Form wir von ihnen erhalten. <br><br><a name="2"></a><h3>  Wie funktionieren Sampling-Profiler? </h3><br>  Betrachten Sie das folgende Beispiel, um zu verstehen, wie ein Stichprobenprofiler funktioniert: Die <b>sendToMoex-</b> Methode ruft mehrere andere Methoden auf.  Wir schauen: <br><br><pre><code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> sendToMoex() { a.qqq(); b.doo(); c.ccc() } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> doo() { da(); db(); }</code> </pre> <br>  Wenn wir den Status des Aufrufstapels zum Zeitpunkt der Ausführung dieses Programmabschnitts überwachen und regelmäßig aufzeichnen, erhalten wir Informationen in folgender Form: <br><br><img src="https://habrastorage.org/webt/gl/je/y5/gljey5esfyih7lqm1yjvpaxfese.png"><br><br>  Dies ist eine Reihe von Call-Stacks.  Unter der Annahme, dass die Samples gleichmäßig verteilt sind, gibt die Anzahl identischer Stapel die relative Ausführungszeit der Methode an, die sich oben auf dem Stapel befindet. <br><br>  In diesem Beispiel wurde die Da-Methode genauso oft durchgeführt wie die C.ccc-Methode, und dies ist das Zweifache der Db-Methode. Die Annahme, dass die Verteilung der Stichproben sogar gleichmäßig ist, ist jedoch möglicherweise nicht vollständig korrekt, und dann ist die Schätzung der Ausführungszeit falsch. <br><br><a name="3"></a><h3>  Wie oft müssen wir probieren? </h3><br>  Angenommen, wir möchten 1000 Samples in 100 Mikrosekunden aufnehmen, um zu verstehen, was im Inneren abgespielt wurde.  Als nächstes berechnen wir mit einem einfachen Anteil, dass wenn wir 1000 Proben in 100 μs machen müssen, es 10 Millionen Proben in 1 Sekunde oder 10.000.000 Proben / s sind. <br><br><img src="https://habrastorage.org/webt/x6/rw/2j/x6rw2jbbfxfouax9ncy8hkfn3nq.png"><br><br>  Wenn wir mit dieser Geschwindigkeit abtasten, werden wir in einer Ausführung des Codes 1000 Beispiele sammeln, aggregieren und verstehen, was schnell oder langsam funktioniert hat.  Danach werden wir die Leistung analysieren und den Code anpassen. <br><br>  Eine Frequenz von 10 Millionen Abtastungen pro Sekunde ist jedoch viel.  Und wenn wir von Anfang an eine solche Geschwindigkeit der Profilerstellung nicht erreichen?  Angenommen, wir haben für 10 μs nur 10 Proben gesammelt, nicht 1000. In diesem Fall müssen wir auf die nächste Ausführung des Profilcodes warten, die nach 1 Sekunde erfolgt (schließlich wird der Profilcode einmal pro Sekunde ausgeführt).  Also werden wir 10 weitere Proben sammeln.  Da sie bei uns gleichmäßig verteilt sind, können sie zu einem gemeinsamen Satz zusammengefasst werden.  Es reicht zu warten, bis der Profilcode 1000/10 = 100 Mal ausgeführt wird, und wir werden die erforderlichen 1000 Proben (jeweils 10 Proben von 100 Mal) sammeln. <br><br><a name="4"></a><h3>  Wählen Sie einen Profiler </h3><br>  Mit diesem theoretischen Wissen können wir weiter üben. <br><br>  Nehmen Sie den <b>Async-Profiler.</b>  Ein großartiges Tool (verwendet den Aufruf der virtuellen Maschine AsyncGetCallTrace), das den Aufrufstapel bis zur Anweisung des Bytecodes der virtuellen Java-Maschine sammelt.  Die native Async-Profiler-Abtastrate beträgt <i>1000 Abtastungen pro Sekunde</i> . <br><br>  Wir werden ein einfaches Verhältnis lösen: 10.000.000 Proben / Sek. - 1 Sekunde, 1000 Proben / Sek. - X Sekunden. <br>  Wir erhalten, dass bei der Standardabtastfrequenz des Async-Profilers die Profilerstellung etwa 3 Stunden dauert.  Das ist lang.  Idealerweise möchte ich das Profil so schnell wie möglich mit der Superluminalgeschwindigkeit zusammenbauen. <br><br>  Versuchen wir, den <b>Async-Profiler</b> zu übertakten.  Dazu finden wir in der Readme- <code>-i</code> Flag <code>-i</code> , das das Abtastintervall festlegt.  Versuchen wir, das Flag <code>-i1</code> (1 Nanosekunde) oder <code>-i0</code> im Allgemeinen zu setzen, damit der Profiler ohne Unterbrechung <code>-i0</code> .  Ich habe eine Frequenz von ungefähr 2,5 Tausend Proben pro Sekunde.  In diesem Fall beträgt die Gesamtdauer der Profilerstellung ca. 1 Stunde.  Natürlich nicht 3 Stunden, aber auch nicht sehr schnell.  Es scheint, dass Sie, um die erforderlichen Profilierungsgeschwindigkeiten zu erreichen, etwas qualitativ anderes tun müssen, um ein neues Niveau zu erreichen. <br><br>  Um deutlich höhere Frequenzen zu erreichen, müssen Sie den AsyncGetCallTrace-Aufruf abbrechen und <b>perf verwenden</b> , den Vollzeit-Linux-Profiler, der in jeder Linux-Distribution enthalten ist.  Perf weiß jedoch nichts über Java, und wir müssen perf noch trainieren, um mit Java zu arbeiten.  Lassen Sie uns in der Zwischenzeit versuchen, Perf auf diese beängstigende Weise auszuführen: <br><br><pre> <code class="java hljs">$ perf record –F <span class="hljs-number"><span class="hljs-number">10000</span></span> -p PID -g -- sleep <span class="hljs-number"><span class="hljs-number">1</span></span> [ perf record: Woken up <span class="hljs-number"><span class="hljs-number">1</span></span> times to write data ] [ perf record: .. <span class="hljs-number"><span class="hljs-number">0.215</span></span> MB perf.data (<span class="hljs-number"><span class="hljs-number">4032</span></span> samples) ]</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Mehr zur Notation</b> <div class="spoiler_text"><ul><li>  <i>perf record</i> bedeutet, dass wir ein Profil <i>aufnehmen</i> möchten. </li><li>  Das <code>-F</code> Flag und das Argument 10.000 sind die Abtastrate. </li><li>  Das Flag <code>-p</code> gibt an, dass wir nur die spezifische PID unseres Java-Prozesses profilieren möchten. </li><li>  Das Flag <code>-g</code> ist für das Sammeln von Anrufstapeln verantwortlich. </li><li>  Schließlich beschränken wir mit <i>Schlaf 1</i> den Profileintrag auf 1 Sekunde. </li></ul></div></div><br>  Warum müssen wir Call Stacks sammeln?  Wir profilieren alles in einer Reihe und extrahieren dann aus den gesammelten Daten den Teil, der uns interessiert (die Methode, die für die Bildung und den Versand von Bestellungen verantwortlich ist).  Der Marker, dass die gesammelte Stichprobe zu den Daten gehört, an denen wir interessiert sind, ist das Vorhandensein des <b>Stapelrahmens des</b> Methodenaufrufs <b>sendToMoex</b> . <br><br><a name="5"></a><h3>  Erfahren Sie, wie Sie ein Java-Anwendungsprofil erstellen. </h3><br>  Wir führen den Befehl perf record ... aus, warten 1 Sekunde und führen das perf-Skript aus, um zu sehen, was profiliert wurde.  Und wir werden etwas sehen, das nicht sehr klar ist: <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.746571</span></span>: <span class="hljs-number"><span class="hljs-number">3745505</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b53f8 [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.747565</span></span>: <span class="hljs-number"><span class="hljs-number">3728336</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b5372 [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.748613</span></span>: <span class="hljs-number"><span class="hljs-number">3731147</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b53ef [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map)</code> </pre><br>  Es scheinen Adressen zu sein, aber es gibt keine Namen von Java-Methoden.  Sie müssen also perf lehren, um diese Adressen mit den Namen der Methoden abzugleichen. <br><br>  In der Welt von C und C ++ werden sogenannte Debugging-Informationen verwendet, um Adressen und Funktionsnamen abzugleichen.  Eine Korrespondenz wird in einem speziellen Abschnitt der ausführbaren Datei gespeichert: Eine Methode liegt an solchen Adressen, eine andere Methode liegt an anderen Adressen.  Perf ruft diese Informationen auf und führt ein Mapping durch. <br><br>  Offensichtlich generiert der JIT-Compiler der virtuellen Maschine keine Debugging-Informationen in diesem Format.  Wir haben noch eine andere Möglichkeit - Daten über die Entsprechung von Adressen und Namen von Methoden in eine spezielle Perf-Map-Datei zu schreiben, die perf als Ergänzung zu den gelesenen Debugging-Informationen behandelt.  Diese Perf-Map-Datei muss sich im Ordner tmp befinden und die folgende Datenstruktur aufweisen: <br><div class="scrollable-table"><table><tbody><tr><th>  Startadresse des Methodencodes </th><th>  Codelänge </th><th>  Methodenname </th></tr><tr><td>  7f99a911d600 </td><td>  120 </td><td>  java.util.AbstractCollection. &lt;init&gt; </td></tr><tr><td>  7f99a911d9c0 </td><td>  180 </td><td>  java.util.AbstractList. &lt;init&gt; </td></tr><tr><td>  7f99a911de80 </td><td>  5c0 </td><td>  java.util.Arrays.copyOf </td></tr><tr><td>  7f99a911ed40 </td><td>  140 </td><td>  java.util.ArrayList $ Itr.hasNext </td></tr><tr><td>  7f99a911f200 </td><td>  3e0 </td><td>  java.util.ArrayList $ Itr.next <br></td></tr></tbody></table></div><br>  Die erste Spalte ist die Adresse des Anfangs des Methodencodes, die zweite ist seine Länge, die dritte Spalte ist der Name der Methode. <br><br>  Wir müssen also eine ähnliche Datei generieren.  Dies kann natürlich nicht manuell erfolgen (woher wissen wir, an welchen Adressen der JIT-Compiler den Code ablegt), daher verwenden wir das Skript create-java-perf-map.sh aus dem perf-map-agent-Projekt und übergeben ihm die PID unseres Java-Prozesses .  Die Datei ist fertig, überprüfen Sie ihren Inhalt und führen Sie das Perf-Skript erneut aus. <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.867498</span></span>: cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f527 Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.868176</span></span>: <span class="hljs-number"><span class="hljs-number">2127960</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f57f Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.868737</span></span>: <span class="hljs-number"><span class="hljs-number">1959990</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f627 Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map)</code> </pre> <br>  Voila!  Wir sehen die Namen der Java-Methoden!  Was gerade passiert ist: Wir haben dem Perf Profiler, der nichts über Java weiß, beigebracht, eine reguläre Java-Anwendung zu profilieren und die heißen Java-Methoden dieser Anwendung zu sehen! <br><br>  Um jedoch die Leistung des von uns abgefragten Programmteils zu analysieren, verfügen wir nicht über genügend Aufrufstapel, um die interessierenden Daten aus allen gesammelten Stichproben herauszufiltern. <br><br>  <b>Wie bekomme ich einen Call Stack?</b> <br><br>  Jetzt müssen Sie etwas anderes mit perf oder einer virtuellen Maschine tun, um Call Stacks zu erhalten.  Um zu verstehen, was zu tun ist, gehen wir einen Schritt zurück und sehen, wie der Stapel im Allgemeinen funktioniert.  Stellen Sie sich vor, wir haben drei Funktionen f1, f2, f3.  Außerdem ruft f1 f2 und f2 f3 auf. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f1() { f2(); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f2() { f3(); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f3() { ... }</code> </pre> <br>  Lassen Sie uns zum Zeitpunkt der Ausführung der Funktion <code>f3</code> sehen, in welchem ​​Zustand sich der Stapel befindet.  Wir sehen das <code>rsp</code> Register, das auf die Oberseite des Stapels zeigt.  Wir wissen auch, dass der Stapel die Adresse des vorherigen Stapelrahmens hat.  Und wie kann ich einen Call-Stack bekommen? <br><br>  Wenn wir irgendwie die Adresse dieses Bereichs erhalten könnten, könnten wir uns den Stapel als einfach verbundene Liste vorstellen und die Reihenfolge der Aufrufe verstehen, die uns zum aktuellen Ausführungspunkt gebracht haben. <br><br>  Was brauchen wir dafür?  Wir brauchen ein zusätzliches rbp-Register, das auf den gelben Bereich zeigt.  Es stellt sich heraus, dass das rbp-Register es perf ermöglicht, den Aufrufstapel abzurufen und die Sequenz zu verstehen, die uns zum aktuellen Punkt gebracht hat.  Ich empfehle, diese Details in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">System V Application Binary Interface zu</a> lesen.  Es beschreibt, wie Methoden unter Linux aufgerufen werden. <br><br><img src="https://habrastorage.org/webt/0m/0w/vx/0m0wvx8wcaplslb7k5illbb4hbm.png"><br><br>  Wir haben verstanden, was unser Problem ist.  Wir müssen die virtuelle Maschine zwingen, das rbp-Register für seinen ursprünglichen Zweck zu verwenden - als Zeiger auf den Anfang des Stapelrahmens.  So sollte der JIT-Compiler das rbp-Register verwenden.  Hierfür gibt es in der virtuellen Maschine ein Flag PreserveFramePointer.  Wenn wir dieses Flag an die virtuelle Maschine übergeben, beginnt die virtuelle Maschine, das rbp-Register für ihren traditionellen Zweck zu verwenden.  Und dann kann Perf den Stapel drehen.  Und wir bekommen einen echten Call-Stack im Profil.  Die Flagge wurde von dem berüchtigten Brendan Gregg in nur JDK8u60 beigesteuert. <br><br>  Wir starten die virtuelle Maschine mit einem neuen Flag.  Führen Sie <code>create-java-perf-map</code> und anschließend <code>perf record</code> und <code>perf script</code> .  Jetzt können wir mit Call Stacks ein genaues Profil erstellen: <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">18657</span></span> <span class="hljs-number"><span class="hljs-number">1901247.601878</span></span>: <span class="hljs-number"><span class="hljs-number">979583</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>f285d007b10 Interpreter (...) <span class="hljs-number"><span class="hljs-number">7</span></span>f285d0004e7 call_stub (...) <span class="hljs-number"><span class="hljs-number">67</span></span>d0db [unknown] (... libjvm.so) ... <span class="hljs-number"><span class="hljs-number">708</span></span>c start_thread (... libpthread<span class="hljs-number"><span class="hljs-number">-2.26</span></span>.so)</code> </pre><br>  Wir haben dem Perf Profiler, der in den meisten Linux-Distributionen enthalten ist, beigebracht, mit Java-Anwendungen zu arbeiten.  Daher können wir jetzt nicht nur die Hot-Abschnitte des Codes sehen, sondern auch die Reihenfolge der Aufrufe, die zum aktuellen Hotspot geführt haben.  Eine großartige Leistung, da der Perf Profiler nichts über Java weiß.  Wir haben das alles einfach gelehrt! <br><br><a name="7"></a><h3>  Erhöhen Sie die Perf-Abtastrate </h3><br>  Versuchen wir, die Leistung auf 10 Millionen Samples pro Sekunde zu übertakten.  Jetzt haben wir eine deutlich niedrigere Frequenz. <br><br>  Um alle Aufgaben zu automatisieren, die wir gerade ausgeführt haben, können Sie das Skript <code>perf-java-record-stack</code> aus dem Projekt perf-map-agent verwenden.  Er hat einen wunderbaren Stift - die Umgebungsvariable <code>perf_record-freq</code> , mit der Sie die Abtastfrequenz einstellen können.  Lassen Sie uns zunächst 100.000 Samples pro Sekunde einstellen und versuchen, sie auszuführen.  In der Konsole wird eine schreckliche Meldung angezeigt, dass wir die maximal zulässige Abtastfrequenz überschritten haben: <br><br><pre> <code class="javascript hljs">$ PERF_RECORD_FREQ=<span class="hljs-number"><span class="hljs-number">100000</span></span> ./bin/perf-java-record-stack PID ... Maximum frequency rate (<span class="hljs-number"><span class="hljs-number">30000</span></span>) reached. Please use -F freq option <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> lower value or consider tweaking /proc/sys/kernel/perf_event_max_sample_rate. ...</code> </pre><br>  In meinem Fall lag die Grenze bei 30.000 Proben pro Sekunde.  Perf sagt sofort, welches Kernel-Argument behoben werden muss, was wir entweder mit echo sudo tee für die gewünschte Datei oder direkt über <code>sysctl</code> tun werden.  Also: <br><br><pre> <code class="javascript hljs">$ echo <span class="hljs-string"><span class="hljs-string">'1000000'</span></span> | sudo tee /proc/sys/kernel/perf_event_max_sample_rate</code> </pre> <br>  oder so: <br><br><pre> <code class="javascript hljs">$ sudo sysctl kernel.perf_event_max_sample_rate=<span class="hljs-number"><span class="hljs-number">1000000</span></span></code> </pre><br>  Jetzt teilen wir dem Kernel mit, dass die Obergrenze der Frequenz jetzt 1 Million Samples pro Sekunde beträgt.  Wir starten den Profiler erneut und geben die Häufigkeit von 200.000 Abtastungen pro Sekunde an.  Der Profiler arbeitet 15 Sekunden lang und gibt uns 1 Million Proben.  Alles scheint in Ordnung zu sein.  Zumindest keine gewaltigen Fehlermeldungen.  Aber welche Frequenz haben wir tatsächlich bekommen?  Es stellt sich heraus, dass nur 70.000 Proben pro Sekunde.  Was ist schief gelaufen? <br><br>  Sehen wir uns die Ausgabe des <code>dmesg</code> : <br><br><pre> <code class="javascript hljs">[<span class="hljs-number"><span class="hljs-number">84430.412898</span></span>] perf: interrupt took too long (<span class="hljs-number"><span class="hljs-number">1783</span></span> &gt; <span class="hljs-number"><span class="hljs-number">200</span></span>), lowering kernel.perf_event_max_sample_rate to <span class="hljs-number"><span class="hljs-number">89700</span></span> ... [<span class="hljs-number"><span class="hljs-number">84431.618452</span></span>] perf: interrupt took too long (<span class="hljs-number"><span class="hljs-number">2229</span></span> &gt; <span class="hljs-number"><span class="hljs-number">2228</span></span>), lowering kernel.perf_event_max_sample_rate to <span class="hljs-number"><span class="hljs-number">71700</span></span></code> </pre><br>  Dies ist die Ausgabe des Linux-Kernels.  Es wurde festgestellt, dass wir zu oft abtasten und es zu lange dauert, sodass der Kernel die Frequenz senkt.  Es stellt sich heraus, dass wir ein anderes Handle im Kernel abschrauben müssen - es heißt <code>kernel.perf_cpu_time_max_percent</code> und steuert die Zeit, die der Kernel für Interrupts von perf <code>kernel.perf_cpu_time_max_percent</code> kann. <br><br>  Wir werden eine Abtastfrequenz von 200.000 Abtastungen pro Sekunde bestellen.  Und nach 15 Sekunden erhalten wir 3 Millionen Proben - 200.000 Proben pro Sekunde. <br><br><pre> <code class="javascript hljs">$ PERF_RECORD_FREQ=<span class="hljs-number"><span class="hljs-number">200000</span></span> ./bin/perf-java-record-stack PID Recording events <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span> seconds ... ... [ perf record: Captured ... (<span class="hljs-number"><span class="hljs-number">2.961</span></span><span class="hljs-number"><span class="hljs-number">.252</span></span> samples) ]</code> </pre><br>  Nun sehen wir uns das Profil an.  Führen Sie das <code>perf script</code> : <br><br><pre> <code class="javascript hljs">$ perf script ... java ... native_write_msr (<span class="hljs-regexp"><span class="hljs-regexp">/.../</span></span>vmlinux) java ... Loop2.main (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-29621.</span></span>map) java ... native_write_msr (<span class="hljs-regexp"><span class="hljs-regexp">/.../</span></span>vmlinux) ...</code> </pre><br>  Wir sehen seltsame Funktionen und das ausführbare vmlinux-Modul - den Linux-Kernel.  Dies ist definitiv nicht unser Code.  Was ist passiert?  Die Frequenz war so hoch, dass der Kernel-Code in die Samples fiel.  Das heißt, je höher wir die Frequenz erhöhen, desto mehr Beispiele gibt es, die sich nicht auf unseren Code, sondern auf den Linux-Kernel beziehen. <br><br>  Sackgasse. <br><br><a name="8"></a><h3>  Wir verwenden (explizit) Hardware-PMU / PEBS-Ereignisse </h3><br>  Dann entschied ich mich für die Verwendung der PMU / PEBS-Hardwaretechnologie - Performance Monitoring Unit, Precise Event Based Sampling.  Sie können Benachrichtigungen erhalten, dass ein Ereignis eine bestimmte Anzahl von Malen aufgetreten ist.  Dies wird als "Periode" bezeichnet.  Beispielsweise können wir Benachrichtigungen über die Ausführung jeder 20. Anweisung durch den Prozessor erhalten.  Schauen wir uns ein Beispiel an.  Lassen Sie den xor-Befehl jetzt ausgeführt werden, und der PMU-Zähler erhält den Wert 18;  dann kommt die mov-Anweisung - der Zähler ist 19;  und die nächste Anweisung, <b>% r14,% r13 hinzufügen</b> , PMU wird als "heiß" <b>angezeigt</b> . <br><br>  Dann beginnt ein neuer Zyklus: <code>inc</code> wird ausgeführt - die PMU wird auf 1 zurückgesetzt. Einige weitere Iterationen des Zyklus werden durchlaufen.  Am Ende halten wir bei der <code>mov</code> Anweisung an, die PMU schnappt 19. Die nächste add-Anweisung, und wieder markieren wir sie als heiß.  Siehe die Auflistung: <br><br><pre> <code class="plaintext hljs">mov aaa, bbbb xor %rdx, %rdx L_START: mov $0x0(%rbx, %rdx),%r14 add %r14, %r13 ; (PMU       "") cmp %rdx,100000000 jne L_START</code> </pre> <br>  Bemerken Sie nicht die Kuriositäten?  Ein Zyklus von fünf Anweisungen, aber jedes Mal markieren wir dieselbe Anweisung als heiß.  Offensichtlich ist dies nicht wahr: Alle Anweisungen sind "heiß".  Sie verbringen auch Zeit, und wir markieren nur eine.  Tatsache ist, dass wir zwischen der Periode und dem Zähler der Anzahl der Anweisungen in der Iteration einen gemeinsamen Faktor 4 haben. Es stellt sich heraus, dass wir bei jeder vierten Iteration dieselbe Anweisung als "heiß" markieren.  Um dieses Verhalten zu vermeiden, müssen Sie eine Zahl als Zeitraum auswählen, in dem die Wahrscheinlichkeit eines gemeinsamen Teilers zwischen der Anzahl der Iterationen in der Schleife und dem Zähler selbst minimiert wird.  Idealerweise sollte die Periode eine Primzahl sein, d.h.  Teilen Sie nur auf sich selbst und auf dem Gerät.  Für das obige Beispiel: Sie sollten einen Zeitraum von 23 wählen. Dann würden wir alle Anweisungen in diesem Zyklus gleichmäßig als „heiß“ markieren. <br><br>  Die PMU / PEBS-Technologie wird seit mindestens 2009 in ihrer modernen Form unterstützt, dh auf fast jedem Computer.  Um es explizit anzuwenden, ändern wir das Skript <code>perf-java-record-stack</code> .  Ersetzen Sie das <code>-F</code> Flag durch <code>-e</code> , das die Verwendung von PMU / PEBS explizit angibt. <br><br><pre> <code class="javascript hljs">... sudo perf record -F $PERF_RECORD_FREQ ... ...</code> </pre> <br>  Das Skript transformieren: <br><br><pre> <code class="javascript hljs">... sudo perf record -e cycles –c <span class="hljs-number"><span class="hljs-number">10007</span></span> ... ...</code> </pre> <br>  Sie wissen bereits, welche Eigenschaften eine Periode haben sollte - wir brauchen eine Primzahl.  In unserem Fall wird es der Zeitraum 10007 sein. <br><br>  Wir haben das modifizierte Perf-Java-Record-Stack-Skript gestartet und in 15 Sekunden 4,5 Millionen Samples empfangen - das sind fast 300.000 pro Sekunde, ein Sample alle 3 μs.  Das heißt, für eine Ausführung unseres Profilcodes werden für 100 μs 33 Proben gesammelt.  Bei dieser Frequenz beträgt die gesamte Profilerfassungszeit nur 30 Sekunden.  Trinken Sie nicht einmal eine Tasse Kaffee!  In Wirklichkeit ist alles etwas komplizierter.  Was passiert, wenn unser Code nicht einmal pro Sekunde, sondern alle 5 Sekunden ausgeführt wird?  Dann wird die Dauer der Profilerstellung auf 2,5 Minuten anwachsen, was ebenfalls ein anständiges Ergebnis ist. <br><br>  So erhalten Sie in 30 Sekunden ein Profil, das alle unsere Forschungsbedürfnisse vollständig abdeckt.  Sieg <br><br>  Aber das Gefühl eines schmutzigen Tricks ließ mich nicht los.  Kehren wir zu der Situation zurück, in der unser Code alle 5 Sekunden ausgeführt wird.  Die Profilerstellung dauert dann 150 Sekunden. In dieser Zeit werden etwa 45 Millionen Proben gesammelt.  Von diesen benötigen wir nur 1000, dh 0,002% der gesammelten Daten.  Alles andere ist Müll, der die Arbeit anderer Werkzeuge verlangsamt und zusätzlichen Aufwand verursacht.  Ja, das Problem ist gelöst, aber es ist in der Stirn gelöst, schmutzige, stumpfe Kraft. <br><br>  Und an diesem Abend, als ich mit Hilfe von Perf zum ersten Mal ein so detailliertes Profil bekam, hatte ich einen Traum.  Ich ging von der Arbeit nach Hause und dachte nach, aber es wäre schön, wenn das Eisen das Profil selbst und sogar die Genauigkeit von Mikrostrukturen und Mikrosekunden zusammensetzen könnte, und wir würden nur die Ergebnisse analysieren.  Wird mein Traum wahr?  Was meinen Sie? <br><br><a name="9"></a><h3>  Kurze Zusammenfassung: </h3><br><ul><li>  Um ein Profil einer Java-Anwendung mit perf zu erstellen, müssen Sie mithilfe von Skripten aus dem perf-map-agent-Projekt eine Datei mit Informationen zu Zeichen generieren </li><li>  Um Informationen nicht nur über wichtige Codeabschnitte, sondern auch über Stapel zu sammeln, müssen Sie eine virtuelle Maschine mit dem Flag -XX: + PreserveFramePointer ausführen </li><li>  Wenn Sie die Abtastfrequenz erhöhen möchten, sollten Sie auf sysctl'i und kernel.perf_cpu_time_max_percent und kernel.perf_event_max_sample_rate achten. </li><li>  Wenn Beispiele aus dem Kernel, die sich nicht auf die Anwendung beziehen, in das Profil aufgenommen werden, sollten Sie überlegen, den PMU / PEBS-Zeitraum explizit anzugeben. </li></ul><br>  Dieser Artikel (und seine nachfolgenden Teile) ist eine Abschrift des Berichts, die in Textform angepasst wurde.  Wenn Sie nicht nur lesen, sondern auch über die Profilerstellung hören möchten, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verweisen Sie</a> auf die Präsentation. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466719/">https://habr.com/ru/post/de466719/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466701/index.html">Let's Encrypt bedient fast 30% der Domains</a></li>
<li><a href="../de466705/index.html">Vivaldi Beta für Android - Echter Browser</a></li>
<li><a href="../de466709/index.html">Entwicklung einer monolithischen Unix-ähnlichen OS-C-Bibliothek (2)</a></li>
<li><a href="../de466711/index.html">Sicherheitslücke DaOffice darf jeden Benutzer aus dem sozialen Netzwerk entfernen</a></li>
<li><a href="../de466713/index.html">Ist es in 1C möglich, die Technologie externer Komponenten nicht zu beobachten? Oder wie man Kollegen mit 1C gratuliert?</a></li>
<li><a href="../de466721/index.html">[Ekaterinburg, Ankündigung] java.ural.Meetup @ 3 - Ankündigung der dritten Java Mitap + Video-Berichte von java.ural.Meetup @ 2</a></li>
<li><a href="../de466723/index.html">Apple Text Broadcast - 10. September 2019</a></li>
<li><a href="../de466725/index.html">Dolch 2 ist elementar (Teil 1)</a></li>
<li><a href="../de466727/index.html">Lazy Upgrade: Wie PostgreSQL 12 die Leistung verbessert</a></li>
<li><a href="../de466729/index.html">Das Buch "Data Mining. Informationen von Facebook, Twitter, LinkedIn, Instagram, GitHub abrufen »</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
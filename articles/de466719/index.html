<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§±üèæ üë©üèø‚Äçü§ù‚Äçüë©üèº üòì Superlight Velocity Profiling: Theorie und Praxis. Teil 1 üßõüèº üë©üèæ‚Äçü§ù‚Äçüë®üèø üë®üèº‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! Aus der √úberschrift haben Sie bereits verstanden, wor√ºber ich sprechen werde. Es wird viel Hardcore geben: 
 Wir werden Java, C, C ++, Assemble...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Superlight Velocity Profiling: Theorie und Praxis. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/raiffeisenbank/blog/466719/">  Hallo!  Aus der √úberschrift haben Sie bereits verstanden, wor√ºber ich sprechen werde.  Es wird viel Hardcore geben: <br>  Wir werden Java, C, C ++, Assembler, ein bisschen Linux, ein bisschen Kernel des Betriebssystems diskutieren.  Wir werden auch einen praktischen Fall analysieren, sodass der Artikel aus drei gro√üen Teilen besteht (ziemlich umfangreich). <br><br><img src="https://habrastorage.org/webt/mp/cl/er/mpclerfppp9jx5ciuziyfv-n8oa.png"><br><br>  Im ersten Schritt werden wir versuchen, alles aus den vorhandenen Profilern herauszuholen. <br>  Im zweiten Teil erstellen wir unseren eigenen kleinen Profiler, und im dritten Teil erfahren Sie, wie Sie Profile erstellen, die f√ºr Profile nicht √ºblich sind, da vorhandene Tools daf√ºr nicht sehr geeignet sind.  Wenn Sie bereit sind, diesen Weg zu gehen - ich warte unter dem Schnitt auf Sie :) <br><a name="habracut"></a><br><h3>  Inhalt </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeit und Mittel zum Verst√§ndnis - Profiler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">So funktionieren Sampling-Profiler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie oft m√ºssen wir probieren</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">W√§hlen Sie einen Profiler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erfahren Sie, wie Sie ein Java-Anwendungsprofil erstellen.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erh√∂hen Sie die Perf-Abtastrate</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wir verwenden (explizit) Hardware-PMU / PEBS-Ereignisse</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kurze Zusammenfassung</a> </li></ul><br><a name="1"></a><h3>  Zeit und Mittel zum Verst√§ndnis - Profiler </h3><br>  Aus allt√§glicher Sicht ist 1 Sekunde sehr klein.  Aber wir wissen, dass 1 Sekunde eine ganze Milliarde Nanosekunden ist.  Und lassen Sie es in nur 1 Nanosekunde ungef√§hr 4 Prozessorzyklen dauern. In 1 Sekunde werden im Computer viele Dinge erledigt, die unser Leben verbessern oder verschlechtern k√∂nnen. <br><br>  Angenommen, wir entwickeln eine Anwendung, die an sich kritisch genug ist, um zu beschleunigen, und f√ºr einige Codefragmente ist dies im Allgemeinen kritisch.  Diese Teile werden beispielsweise Hunderte von Mikrosekunden ausgef√ºhrt - schnell genug, aber sie [ <i>Codeabschnitte</i> ] wirken sich direkt auf den Erfolg unserer Anwendung und den Betrag des verdienten oder verlorenen Geldes aus.  Zum Beispiel <br>  Beim Senden von Auftr√§gen zum Abschluss von Umtauschtransaktionen kann eine Verz√∂gerung von 100 Mikrosekunden den Umtausch 1 Million Rubel oder mehr f√ºr jede Transaktion kosten, die von einem, nicht zwei oder sogar nicht hundert abgeschlossen wird. <br><br>  Und die <b>Aufgabe</b> war f√ºr mich gestellt: Einerseits m√ºssen Sie alle Bestellungen gleichzeitig senden und andererseits m√ºssen Sie sie senden, damit die Abweichung zwischen der ersten und der letzten minimal ist.  Das hei√üt, es war notwendig, eine Funktion zu profilieren, die Bestellungen an die B√∂rse sendet.  Eine typische Aufgabe, abgesehen von einer kleinen Nuance: Die charakteristische Ausf√ºhrungszeit dieser Funktion betr√§gt <i>deutlich weniger als 100 Œºs</i> . <br><br>  Lassen Sie uns dar√ºber nachdenken, wie wir diese 100 Œºs profilieren, um zu verstehen, was im Inneren geschieht. <br>  Was ist bei der Auswahl dieses Tools zu beachten? <br><br><ol><li>  Der Codeabschnitt, der uns interessiert, wird selten ausgef√ºhrt, dh 100 Mikrosekunden werden irgendwo einmal pro Sekunde ausgef√ºhrt.  Und das auf dem Pr√ºfstand und in der Produktion noch weniger. </li><li>  Es wird schwierig sein, diesen Code in ein Mikrobenchmark zu isolieren, da er einen wesentlichen Teil des Projekts und sogar die Eingabe / Ausgabe √ºber das Netzwerk betrifft. </li><li>  Und schlie√ülich m√∂chte ich vor allem, dass das resultierende Profil dem Verhalten auf unseren Produktionsservern entspricht. </li></ol><br>  Wie ber√ºcksichtigen wir all diese Nuancen und profilieren die interessierende Methode korrekt? <br><br>  Konzeptionell k√∂nnen alle Profiler in zwei Gruppen von Profilern unterteilt werden, die <i>instrumentieren</i> oder <i>abtasten</i> .  Betrachten wir jede Gruppe einzeln. <br><br>  <b>Werkzeugprofiler verursachen</b> einen erheblichen Aufwand, da sie unseren Bytecode √§ndern und einen Zeitdatensatz einf√ºgen.  Daher der Hauptnachteil solcher Profiler: Sie k√∂nnen den ausf√ºhrbaren Code erheblich beeinflussen.  Infolgedessen ist es schwierig zu sagen, inwieweit das resultierende Profil dem Verhalten auf Produktionsservern entspricht: Einige Optimierungen funktionieren m√∂glicherweise anders, andere passieren und andere nicht.  Vielleicht erhalten wir auf anderen Zeitskalen - Sekunden, Minuten, Stunden - repr√§sentative Daten.  Auf einer Skala von 100 Œºs kann eine ausgel√∂ste oder fehlgeschlagene Optimierung dazu f√ºhren, dass das Profil v√∂llig nicht repr√§sentativ ist.  Schauen wir uns also eine andere Gruppe von Profilern genauer an. <br><br>  <b>Stichprobenprofiler</b> tragen entweder zu einem minimalen oder moderaten Overhead bei.  Diese Tools wirken sich nicht direkt auf den ausf√ºhrbaren Code aus, und ihre Verwendung erfordert etwas mehr Aufmerksamkeit von Ihnen.  Daher werden wir uns mit den Samping-Profilern befassen.  Mal sehen, welche Daten und in welcher Form wir von ihnen erhalten. <br><br><a name="2"></a><h3>  Wie funktionieren Sampling-Profiler? </h3><br>  Betrachten Sie das folgende Beispiel, um zu verstehen, wie ein Stichprobenprofiler funktioniert: Die <b>sendToMoex-</b> Methode ruft mehrere andere Methoden auf.  Wir schauen: <br><br><pre><code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> sendToMoex() { a.qqq(); b.doo(); c.ccc() } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> doo() { da(); db(); }</code> </pre> <br>  Wenn wir den Status des Aufrufstapels zum Zeitpunkt der Ausf√ºhrung dieses Programmabschnitts √ºberwachen und regelm√§√üig aufzeichnen, erhalten wir Informationen in folgender Form: <br><br><img src="https://habrastorage.org/webt/gl/je/y5/gljey5esfyih7lqm1yjvpaxfese.png"><br><br>  Dies ist eine Reihe von Call-Stacks.  Unter der Annahme, dass die Samples gleichm√§√üig verteilt sind, gibt die Anzahl identischer Stapel die relative Ausf√ºhrungszeit der Methode an, die sich oben auf dem Stapel befindet. <br><br>  In diesem Beispiel wurde die Da-Methode genauso oft durchgef√ºhrt wie die C.ccc-Methode, und dies ist das Zweifache der Db-Methode. Die Annahme, dass die Verteilung der Stichproben sogar gleichm√§√üig ist, ist jedoch m√∂glicherweise nicht vollst√§ndig korrekt, und dann ist die Sch√§tzung der Ausf√ºhrungszeit falsch. <br><br><a name="3"></a><h3>  Wie oft m√ºssen wir probieren? </h3><br>  Angenommen, wir m√∂chten 1000 Samples in 100 Mikrosekunden aufnehmen, um zu verstehen, was im Inneren abgespielt wurde.  Als n√§chstes berechnen wir mit einem einfachen Anteil, dass wenn wir 1000 Proben in 100 Œºs machen m√ºssen, es 10 Millionen Proben in 1 Sekunde oder 10.000.000 Proben / s sind. <br><br><img src="https://habrastorage.org/webt/x6/rw/2j/x6rw2jbbfxfouax9ncy8hkfn3nq.png"><br><br>  Wenn wir mit dieser Geschwindigkeit abtasten, werden wir in einer Ausf√ºhrung des Codes 1000 Beispiele sammeln, aggregieren und verstehen, was schnell oder langsam funktioniert hat.  Danach werden wir die Leistung analysieren und den Code anpassen. <br><br>  Eine Frequenz von 10 Millionen Abtastungen pro Sekunde ist jedoch viel.  Und wenn wir von Anfang an eine solche Geschwindigkeit der Profilerstellung nicht erreichen?  Angenommen, wir haben f√ºr 10 Œºs nur 10 Proben gesammelt, nicht 1000. In diesem Fall m√ºssen wir auf die n√§chste Ausf√ºhrung des Profilcodes warten, die nach 1 Sekunde erfolgt (schlie√ülich wird der Profilcode einmal pro Sekunde ausgef√ºhrt).  Also werden wir 10 weitere Proben sammeln.  Da sie bei uns gleichm√§√üig verteilt sind, k√∂nnen sie zu einem gemeinsamen Satz zusammengefasst werden.  Es reicht zu warten, bis der Profilcode 1000/10 = 100 Mal ausgef√ºhrt wird, und wir werden die erforderlichen 1000 Proben (jeweils 10 Proben von 100 Mal) sammeln. <br><br><a name="4"></a><h3>  W√§hlen Sie einen Profiler </h3><br>  Mit diesem theoretischen Wissen k√∂nnen wir weiter √ºben. <br><br>  Nehmen Sie den <b>Async-Profiler.</b>  Ein gro√üartiges Tool (verwendet den Aufruf der virtuellen Maschine AsyncGetCallTrace), das den Aufrufstapel bis zur Anweisung des Bytecodes der virtuellen Java-Maschine sammelt.  Die native Async-Profiler-Abtastrate betr√§gt <i>1000 Abtastungen pro Sekunde</i> . <br><br>  Wir werden ein einfaches Verh√§ltnis l√∂sen: 10.000.000 Proben / Sek. - 1 Sekunde, 1000 Proben / Sek. - X Sekunden. <br>  Wir erhalten, dass bei der Standardabtastfrequenz des Async-Profilers die Profilerstellung etwa 3 Stunden dauert.  Das ist lang.  Idealerweise m√∂chte ich das Profil so schnell wie m√∂glich mit der Superluminalgeschwindigkeit zusammenbauen. <br><br>  Versuchen wir, den <b>Async-Profiler</b> zu √ºbertakten.  Dazu finden wir in der Readme- <code>-i</code> Flag <code>-i</code> , das das Abtastintervall festlegt.  Versuchen wir, das Flag <code>-i1</code> (1 Nanosekunde) oder <code>-i0</code> im Allgemeinen zu setzen, damit der Profiler ohne Unterbrechung <code>-i0</code> .  Ich habe eine Frequenz von ungef√§hr 2,5 Tausend Proben pro Sekunde.  In diesem Fall betr√§gt die Gesamtdauer der Profilerstellung ca. 1 Stunde.  Nat√ºrlich nicht 3 Stunden, aber auch nicht sehr schnell.  Es scheint, dass Sie, um die erforderlichen Profilierungsgeschwindigkeiten zu erreichen, etwas qualitativ anderes tun m√ºssen, um ein neues Niveau zu erreichen. <br><br>  Um deutlich h√∂here Frequenzen zu erreichen, m√ºssen Sie den AsyncGetCallTrace-Aufruf abbrechen und <b>perf verwenden</b> , den Vollzeit-Linux-Profiler, der in jeder Linux-Distribution enthalten ist.  Perf wei√ü jedoch nichts √ºber Java, und wir m√ºssen perf noch trainieren, um mit Java zu arbeiten.  Lassen Sie uns in der Zwischenzeit versuchen, Perf auf diese be√§ngstigende Weise auszuf√ºhren: <br><br><pre> <code class="java hljs">$ perf record ‚ÄìF <span class="hljs-number"><span class="hljs-number">10000</span></span> -p PID -g -- sleep <span class="hljs-number"><span class="hljs-number">1</span></span> [ perf record: Woken up <span class="hljs-number"><span class="hljs-number">1</span></span> times to write data ] [ perf record: .. <span class="hljs-number"><span class="hljs-number">0.215</span></span> MB perf.data (<span class="hljs-number"><span class="hljs-number">4032</span></span> samples) ]</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Mehr zur Notation</b> <div class="spoiler_text"><ul><li>  <i>perf record</i> bedeutet, dass wir ein Profil <i>aufnehmen</i> m√∂chten. </li><li>  Das <code>-F</code> Flag und das Argument 10.000 sind die Abtastrate. </li><li>  Das Flag <code>-p</code> gibt an, dass wir nur die spezifische PID unseres Java-Prozesses profilieren m√∂chten. </li><li>  Das Flag <code>-g</code> ist f√ºr das Sammeln von Anrufstapeln verantwortlich. </li><li>  Schlie√ülich beschr√§nken wir mit <i>Schlaf 1</i> den Profileintrag auf 1 Sekunde. </li></ul></div></div><br>  Warum m√ºssen wir Call Stacks sammeln?  Wir profilieren alles in einer Reihe und extrahieren dann aus den gesammelten Daten den Teil, der uns interessiert (die Methode, die f√ºr die Bildung und den Versand von Bestellungen verantwortlich ist).  Der Marker, dass die gesammelte Stichprobe zu den Daten geh√∂rt, an denen wir interessiert sind, ist das Vorhandensein des <b>Stapelrahmens des</b> Methodenaufrufs <b>sendToMoex</b> . <br><br><a name="5"></a><h3>  Erfahren Sie, wie Sie ein Java-Anwendungsprofil erstellen. </h3><br>  Wir f√ºhren den Befehl perf record ... aus, warten 1 Sekunde und f√ºhren das perf-Skript aus, um zu sehen, was profiliert wurde.  Und wir werden etwas sehen, das nicht sehr klar ist: <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.746571</span></span>: <span class="hljs-number"><span class="hljs-number">3745505</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b53f8 [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.747565</span></span>: <span class="hljs-number"><span class="hljs-number">3728336</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b5372 [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.748613</span></span>: <span class="hljs-number"><span class="hljs-number">3731147</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b53ef [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map)</code> </pre><br>  Es scheinen Adressen zu sein, aber es gibt keine Namen von Java-Methoden.  Sie m√ºssen also perf lehren, um diese Adressen mit den Namen der Methoden abzugleichen. <br><br>  In der Welt von C und C ++ werden sogenannte Debugging-Informationen verwendet, um Adressen und Funktionsnamen abzugleichen.  Eine Korrespondenz wird in einem speziellen Abschnitt der ausf√ºhrbaren Datei gespeichert: Eine Methode liegt an solchen Adressen, eine andere Methode liegt an anderen Adressen.  Perf ruft diese Informationen auf und f√ºhrt ein Mapping durch. <br><br>  Offensichtlich generiert der JIT-Compiler der virtuellen Maschine keine Debugging-Informationen in diesem Format.  Wir haben noch eine andere M√∂glichkeit - Daten √ºber die Entsprechung von Adressen und Namen von Methoden in eine spezielle Perf-Map-Datei zu schreiben, die perf als Erg√§nzung zu den gelesenen Debugging-Informationen behandelt.  Diese Perf-Map-Datei muss sich im Ordner tmp befinden und die folgende Datenstruktur aufweisen: <br><div class="scrollable-table"><table><tbody><tr><th>  Startadresse des Methodencodes </th><th>  Codel√§nge </th><th>  Methodenname </th></tr><tr><td>  7f99a911d600 </td><td>  120 </td><td>  java.util.AbstractCollection. &lt;init&gt; </td></tr><tr><td>  7f99a911d9c0 </td><td>  180 </td><td>  java.util.AbstractList. &lt;init&gt; </td></tr><tr><td>  7f99a911de80 </td><td>  5c0 </td><td>  java.util.Arrays.copyOf </td></tr><tr><td>  7f99a911ed40 </td><td>  140 </td><td>  java.util.ArrayList $ Itr.hasNext </td></tr><tr><td>  7f99a911f200 </td><td>  3e0 </td><td>  java.util.ArrayList $ Itr.next <br></td></tr></tbody></table></div><br>  Die erste Spalte ist die Adresse des Anfangs des Methodencodes, die zweite ist seine L√§nge, die dritte Spalte ist der Name der Methode. <br><br>  Wir m√ºssen also eine √§hnliche Datei generieren.  Dies kann nat√ºrlich nicht manuell erfolgen (woher wissen wir, an welchen Adressen der JIT-Compiler den Code ablegt), daher verwenden wir das Skript create-java-perf-map.sh aus dem perf-map-agent-Projekt und √ºbergeben ihm die PID unseres Java-Prozesses .  Die Datei ist fertig, √ºberpr√ºfen Sie ihren Inhalt und f√ºhren Sie das Perf-Skript erneut aus. <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.867498</span></span>: cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f527 Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.868176</span></span>: <span class="hljs-number"><span class="hljs-number">2127960</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f57f Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.868737</span></span>: <span class="hljs-number"><span class="hljs-number">1959990</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f627 Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map)</code> </pre> <br>  Voila!  Wir sehen die Namen der Java-Methoden!  Was gerade passiert ist: Wir haben dem Perf Profiler, der nichts √ºber Java wei√ü, beigebracht, eine regul√§re Java-Anwendung zu profilieren und die hei√üen Java-Methoden dieser Anwendung zu sehen! <br><br>  Um jedoch die Leistung des von uns abgefragten Programmteils zu analysieren, verf√ºgen wir nicht √ºber gen√ºgend Aufrufstapel, um die interessierenden Daten aus allen gesammelten Stichproben herauszufiltern. <br><br>  <b>Wie bekomme ich einen Call Stack?</b> <br><br>  Jetzt m√ºssen Sie etwas anderes mit perf oder einer virtuellen Maschine tun, um Call Stacks zu erhalten.  Um zu verstehen, was zu tun ist, gehen wir einen Schritt zur√ºck und sehen, wie der Stapel im Allgemeinen funktioniert.  Stellen Sie sich vor, wir haben drei Funktionen f1, f2, f3.  Au√üerdem ruft f1 f2 und f2 f3 auf. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f1() { f2(); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f2() { f3(); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f3() { ... }</code> </pre> <br>  Lassen Sie uns zum Zeitpunkt der Ausf√ºhrung der Funktion <code>f3</code> sehen, in welchem ‚Äã‚ÄãZustand sich der Stapel befindet.  Wir sehen das <code>rsp</code> Register, das auf die Oberseite des Stapels zeigt.  Wir wissen auch, dass der Stapel die Adresse des vorherigen Stapelrahmens hat.  Und wie kann ich einen Call-Stack bekommen? <br><br>  Wenn wir irgendwie die Adresse dieses Bereichs erhalten k√∂nnten, k√∂nnten wir uns den Stapel als einfach verbundene Liste vorstellen und die Reihenfolge der Aufrufe verstehen, die uns zum aktuellen Ausf√ºhrungspunkt gebracht haben. <br><br>  Was brauchen wir daf√ºr?  Wir brauchen ein zus√§tzliches rbp-Register, das auf den gelben Bereich zeigt.  Es stellt sich heraus, dass das rbp-Register es perf erm√∂glicht, den Aufrufstapel abzurufen und die Sequenz zu verstehen, die uns zum aktuellen Punkt gebracht hat.  Ich empfehle, diese Details in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">System V Application Binary Interface zu</a> lesen.  Es beschreibt, wie Methoden unter Linux aufgerufen werden. <br><br><img src="https://habrastorage.org/webt/0m/0w/vx/0m0wvx8wcaplslb7k5illbb4hbm.png"><br><br>  Wir haben verstanden, was unser Problem ist.  Wir m√ºssen die virtuelle Maschine zwingen, das rbp-Register f√ºr seinen urspr√ºnglichen Zweck zu verwenden - als Zeiger auf den Anfang des Stapelrahmens.  So sollte der JIT-Compiler das rbp-Register verwenden.  Hierf√ºr gibt es in der virtuellen Maschine ein Flag PreserveFramePointer.  Wenn wir dieses Flag an die virtuelle Maschine √ºbergeben, beginnt die virtuelle Maschine, das rbp-Register f√ºr ihren traditionellen Zweck zu verwenden.  Und dann kann Perf den Stapel drehen.  Und wir bekommen einen echten Call-Stack im Profil.  Die Flagge wurde von dem ber√ºchtigten Brendan Gregg in nur JDK8u60 beigesteuert. <br><br>  Wir starten die virtuelle Maschine mit einem neuen Flag.  F√ºhren Sie <code>create-java-perf-map</code> und anschlie√üend <code>perf record</code> und <code>perf script</code> .  Jetzt k√∂nnen wir mit Call Stacks ein genaues Profil erstellen: <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">18657</span></span> <span class="hljs-number"><span class="hljs-number">1901247.601878</span></span>: <span class="hljs-number"><span class="hljs-number">979583</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>f285d007b10 Interpreter (...) <span class="hljs-number"><span class="hljs-number">7</span></span>f285d0004e7 call_stub (...) <span class="hljs-number"><span class="hljs-number">67</span></span>d0db [unknown] (... libjvm.so) ... <span class="hljs-number"><span class="hljs-number">708</span></span>c start_thread (... libpthread<span class="hljs-number"><span class="hljs-number">-2.26</span></span>.so)</code> </pre><br>  Wir haben dem Perf Profiler, der in den meisten Linux-Distributionen enthalten ist, beigebracht, mit Java-Anwendungen zu arbeiten.  Daher k√∂nnen wir jetzt nicht nur die Hot-Abschnitte des Codes sehen, sondern auch die Reihenfolge der Aufrufe, die zum aktuellen Hotspot gef√ºhrt haben.  Eine gro√üartige Leistung, da der Perf Profiler nichts √ºber Java wei√ü.  Wir haben das alles einfach gelehrt! <br><br><a name="7"></a><h3>  Erh√∂hen Sie die Perf-Abtastrate </h3><br>  Versuchen wir, die Leistung auf 10 Millionen Samples pro Sekunde zu √ºbertakten.  Jetzt haben wir eine deutlich niedrigere Frequenz. <br><br>  Um alle Aufgaben zu automatisieren, die wir gerade ausgef√ºhrt haben, k√∂nnen Sie das Skript <code>perf-java-record-stack</code> aus dem Projekt perf-map-agent verwenden.  Er hat einen wunderbaren Stift - die Umgebungsvariable <code>perf_record-freq</code> , mit der Sie die Abtastfrequenz einstellen k√∂nnen.  Lassen Sie uns zun√§chst 100.000 Samples pro Sekunde einstellen und versuchen, sie auszuf√ºhren.  In der Konsole wird eine schreckliche Meldung angezeigt, dass wir die maximal zul√§ssige Abtastfrequenz √ºberschritten haben: <br><br><pre> <code class="javascript hljs">$ PERF_RECORD_FREQ=<span class="hljs-number"><span class="hljs-number">100000</span></span> ./bin/perf-java-record-stack PID ... Maximum frequency rate (<span class="hljs-number"><span class="hljs-number">30000</span></span>) reached. Please use -F freq option <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> lower value or consider tweaking /proc/sys/kernel/perf_event_max_sample_rate. ...</code> </pre><br>  In meinem Fall lag die Grenze bei 30.000 Proben pro Sekunde.  Perf sagt sofort, welches Kernel-Argument behoben werden muss, was wir entweder mit echo sudo tee f√ºr die gew√ºnschte Datei oder direkt √ºber <code>sysctl</code> tun werden.  Also: <br><br><pre> <code class="javascript hljs">$ echo <span class="hljs-string"><span class="hljs-string">'1000000'</span></span> | sudo tee /proc/sys/kernel/perf_event_max_sample_rate</code> </pre> <br>  oder so: <br><br><pre> <code class="javascript hljs">$ sudo sysctl kernel.perf_event_max_sample_rate=<span class="hljs-number"><span class="hljs-number">1000000</span></span></code> </pre><br>  Jetzt teilen wir dem Kernel mit, dass die Obergrenze der Frequenz jetzt 1 Million Samples pro Sekunde betr√§gt.  Wir starten den Profiler erneut und geben die H√§ufigkeit von 200.000 Abtastungen pro Sekunde an.  Der Profiler arbeitet 15 Sekunden lang und gibt uns 1 Million Proben.  Alles scheint in Ordnung zu sein.  Zumindest keine gewaltigen Fehlermeldungen.  Aber welche Frequenz haben wir tats√§chlich bekommen?  Es stellt sich heraus, dass nur 70.000 Proben pro Sekunde.  Was ist schief gelaufen? <br><br>  Sehen wir uns die Ausgabe des <code>dmesg</code> : <br><br><pre> <code class="javascript hljs">[<span class="hljs-number"><span class="hljs-number">84430.412898</span></span>] perf: interrupt took too long (<span class="hljs-number"><span class="hljs-number">1783</span></span> &gt; <span class="hljs-number"><span class="hljs-number">200</span></span>), lowering kernel.perf_event_max_sample_rate to <span class="hljs-number"><span class="hljs-number">89700</span></span> ... [<span class="hljs-number"><span class="hljs-number">84431.618452</span></span>] perf: interrupt took too long (<span class="hljs-number"><span class="hljs-number">2229</span></span> &gt; <span class="hljs-number"><span class="hljs-number">2228</span></span>), lowering kernel.perf_event_max_sample_rate to <span class="hljs-number"><span class="hljs-number">71700</span></span></code> </pre><br>  Dies ist die Ausgabe des Linux-Kernels.  Es wurde festgestellt, dass wir zu oft abtasten und es zu lange dauert, sodass der Kernel die Frequenz senkt.  Es stellt sich heraus, dass wir ein anderes Handle im Kernel abschrauben m√ºssen - es hei√üt <code>kernel.perf_cpu_time_max_percent</code> und steuert die Zeit, die der Kernel f√ºr Interrupts von perf <code>kernel.perf_cpu_time_max_percent</code> kann. <br><br>  Wir werden eine Abtastfrequenz von 200.000 Abtastungen pro Sekunde bestellen.  Und nach 15 Sekunden erhalten wir 3 Millionen Proben - 200.000 Proben pro Sekunde. <br><br><pre> <code class="javascript hljs">$ PERF_RECORD_FREQ=<span class="hljs-number"><span class="hljs-number">200000</span></span> ./bin/perf-java-record-stack PID Recording events <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span> seconds ... ... [ perf record: Captured ... (<span class="hljs-number"><span class="hljs-number">2.961</span></span><span class="hljs-number"><span class="hljs-number">.252</span></span> samples) ]</code> </pre><br>  Nun sehen wir uns das Profil an.  F√ºhren Sie das <code>perf script</code> : <br><br><pre> <code class="javascript hljs">$ perf script ... java ... native_write_msr (<span class="hljs-regexp"><span class="hljs-regexp">/.../</span></span>vmlinux) java ... Loop2.main (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-29621.</span></span>map) java ... native_write_msr (<span class="hljs-regexp"><span class="hljs-regexp">/.../</span></span>vmlinux) ...</code> </pre><br>  Wir sehen seltsame Funktionen und das ausf√ºhrbare vmlinux-Modul - den Linux-Kernel.  Dies ist definitiv nicht unser Code.  Was ist passiert?  Die Frequenz war so hoch, dass der Kernel-Code in die Samples fiel.  Das hei√üt, je h√∂her wir die Frequenz erh√∂hen, desto mehr Beispiele gibt es, die sich nicht auf unseren Code, sondern auf den Linux-Kernel beziehen. <br><br>  Sackgasse. <br><br><a name="8"></a><h3>  Wir verwenden (explizit) Hardware-PMU / PEBS-Ereignisse </h3><br>  Dann entschied ich mich f√ºr die Verwendung der PMU / PEBS-Hardwaretechnologie - Performance Monitoring Unit, Precise Event Based Sampling.  Sie k√∂nnen Benachrichtigungen erhalten, dass ein Ereignis eine bestimmte Anzahl von Malen aufgetreten ist.  Dies wird als "Periode" bezeichnet.  Beispielsweise k√∂nnen wir Benachrichtigungen √ºber die Ausf√ºhrung jeder 20. Anweisung durch den Prozessor erhalten.  Schauen wir uns ein Beispiel an.  Lassen Sie den xor-Befehl jetzt ausgef√ºhrt werden, und der PMU-Z√§hler erh√§lt den Wert 18;  dann kommt die mov-Anweisung - der Z√§hler ist 19;  und die n√§chste Anweisung, <b>% r14,% r13 hinzuf√ºgen</b> , PMU wird als "hei√ü" <b>angezeigt</b> . <br><br>  Dann beginnt ein neuer Zyklus: <code>inc</code> wird ausgef√ºhrt - die PMU wird auf 1 zur√ºckgesetzt. Einige weitere Iterationen des Zyklus werden durchlaufen.  Am Ende halten wir bei der <code>mov</code> Anweisung an, die PMU schnappt 19. Die n√§chste add-Anweisung, und wieder markieren wir sie als hei√ü.  Siehe die Auflistung: <br><br><pre> <code class="plaintext hljs">mov aaa, bbbb xor %rdx, %rdx L_START: mov $0x0(%rbx, %rdx),%r14 add %r14, %r13 ; (PMU       "") cmp %rdx,100000000 jne L_START</code> </pre> <br>  Bemerken Sie nicht die Kuriosit√§ten?  Ein Zyklus von f√ºnf Anweisungen, aber jedes Mal markieren wir dieselbe Anweisung als hei√ü.  Offensichtlich ist dies nicht wahr: Alle Anweisungen sind "hei√ü".  Sie verbringen auch Zeit, und wir markieren nur eine.  Tatsache ist, dass wir zwischen der Periode und dem Z√§hler der Anzahl der Anweisungen in der Iteration einen gemeinsamen Faktor 4 haben. Es stellt sich heraus, dass wir bei jeder vierten Iteration dieselbe Anweisung als "hei√ü" markieren.  Um dieses Verhalten zu vermeiden, m√ºssen Sie eine Zahl als Zeitraum ausw√§hlen, in dem die Wahrscheinlichkeit eines gemeinsamen Teilers zwischen der Anzahl der Iterationen in der Schleife und dem Z√§hler selbst minimiert wird.  Idealerweise sollte die Periode eine Primzahl sein, d.h.  Teilen Sie nur auf sich selbst und auf dem Ger√§t.  F√ºr das obige Beispiel: Sie sollten einen Zeitraum von 23 w√§hlen. Dann w√ºrden wir alle Anweisungen in diesem Zyklus gleichm√§√üig als ‚Äûhei√ü‚Äú markieren. <br><br>  Die PMU / PEBS-Technologie wird seit mindestens 2009 in ihrer modernen Form unterst√ºtzt, dh auf fast jedem Computer.  Um es explizit anzuwenden, √§ndern wir das Skript <code>perf-java-record-stack</code> .  Ersetzen Sie das <code>-F</code> Flag durch <code>-e</code> , das die Verwendung von PMU / PEBS explizit angibt. <br><br><pre> <code class="javascript hljs">... sudo perf record -F $PERF_RECORD_FREQ ... ...</code> </pre> <br>  Das Skript transformieren: <br><br><pre> <code class="javascript hljs">... sudo perf record -e cycles ‚Äìc <span class="hljs-number"><span class="hljs-number">10007</span></span> ... ...</code> </pre> <br>  Sie wissen bereits, welche Eigenschaften eine Periode haben sollte - wir brauchen eine Primzahl.  In unserem Fall wird es der Zeitraum 10007 sein. <br><br>  Wir haben das modifizierte Perf-Java-Record-Stack-Skript gestartet und in 15 Sekunden 4,5 Millionen Samples empfangen - das sind fast 300.000 pro Sekunde, ein Sample alle 3 Œºs.  Das hei√üt, f√ºr eine Ausf√ºhrung unseres Profilcodes werden f√ºr 100 Œºs 33 Proben gesammelt.  Bei dieser Frequenz betr√§gt die gesamte Profilerfassungszeit nur 30 Sekunden.  Trinken Sie nicht einmal eine Tasse Kaffee!  In Wirklichkeit ist alles etwas komplizierter.  Was passiert, wenn unser Code nicht einmal pro Sekunde, sondern alle 5 Sekunden ausgef√ºhrt wird?  Dann wird die Dauer der Profilerstellung auf 2,5 Minuten anwachsen, was ebenfalls ein anst√§ndiges Ergebnis ist. <br><br>  So erhalten Sie in 30 Sekunden ein Profil, das alle unsere Forschungsbed√ºrfnisse vollst√§ndig abdeckt.  Sieg <br><br>  Aber das Gef√ºhl eines schmutzigen Tricks lie√ü mich nicht los.  Kehren wir zu der Situation zur√ºck, in der unser Code alle 5 Sekunden ausgef√ºhrt wird.  Die Profilerstellung dauert dann 150 Sekunden. In dieser Zeit werden etwa 45 Millionen Proben gesammelt.  Von diesen ben√∂tigen wir nur 1000, dh 0,002% der gesammelten Daten.  Alles andere ist M√ºll, der die Arbeit anderer Werkzeuge verlangsamt und zus√§tzlichen Aufwand verursacht.  Ja, das Problem ist gel√∂st, aber es ist in der Stirn gel√∂st, schmutzige, stumpfe Kraft. <br><br>  Und an diesem Abend, als ich mit Hilfe von Perf zum ersten Mal ein so detailliertes Profil bekam, hatte ich einen Traum.  Ich ging von der Arbeit nach Hause und dachte nach, aber es w√§re sch√∂n, wenn das Eisen das Profil selbst und sogar die Genauigkeit von Mikrostrukturen und Mikrosekunden zusammensetzen k√∂nnte, und wir w√ºrden nur die Ergebnisse analysieren.  Wird mein Traum wahr?  Was meinen Sie? <br><br><a name="9"></a><h3>  Kurze Zusammenfassung: </h3><br><ul><li>  Um ein Profil einer Java-Anwendung mit perf zu erstellen, m√ºssen Sie mithilfe von Skripten aus dem perf-map-agent-Projekt eine Datei mit Informationen zu Zeichen generieren </li><li>  Um Informationen nicht nur √ºber wichtige Codeabschnitte, sondern auch √ºber Stapel zu sammeln, m√ºssen Sie eine virtuelle Maschine mit dem Flag -XX: + PreserveFramePointer ausf√ºhren </li><li>  Wenn Sie die Abtastfrequenz erh√∂hen m√∂chten, sollten Sie auf sysctl'i und kernel.perf_cpu_time_max_percent und kernel.perf_event_max_sample_rate achten. </li><li>  Wenn Beispiele aus dem Kernel, die sich nicht auf die Anwendung beziehen, in das Profil aufgenommen werden, sollten Sie √ºberlegen, den PMU / PEBS-Zeitraum explizit anzugeben. </li></ul><br>  Dieser Artikel (und seine nachfolgenden Teile) ist eine Abschrift des Berichts, die in Textform angepasst wurde.  Wenn Sie nicht nur lesen, sondern auch √ºber die Profilerstellung h√∂ren m√∂chten, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verweisen Sie</a> auf die Pr√§sentation. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466719/">https://habr.com/ru/post/de466719/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466701/index.html">Let's Encrypt bedient fast 30% der Domains</a></li>
<li><a href="../de466705/index.html">Vivaldi Beta f√ºr Android - Echter Browser</a></li>
<li><a href="../de466709/index.html">Entwicklung einer monolithischen Unix-√§hnlichen OS-C-Bibliothek (2)</a></li>
<li><a href="../de466711/index.html">Sicherheitsl√ºcke DaOffice darf jeden Benutzer aus dem sozialen Netzwerk entfernen</a></li>
<li><a href="../de466713/index.html">Ist es in 1C m√∂glich, die Technologie externer Komponenten nicht zu beobachten? Oder wie man Kollegen mit 1C gratuliert?</a></li>
<li><a href="../de466721/index.html">[Ekaterinburg, Ank√ºndigung] java.ural.Meetup @ 3 - Ank√ºndigung der dritten Java Mitap + Video-Berichte von java.ural.Meetup @ 2</a></li>
<li><a href="../de466723/index.html">Apple Text Broadcast - 10. September 2019</a></li>
<li><a href="../de466725/index.html">Dolch 2 ist elementar (Teil 1)</a></li>
<li><a href="../de466727/index.html">Lazy Upgrade: Wie PostgreSQL 12 die Leistung verbessert</a></li>
<li><a href="../de466729/index.html">Das Buch "Data Mining. Informationen von Facebook, Twitter, LinkedIn, Instagram, GitHub abrufen ¬ª</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸŒ¨ï¸ ğŸ¤µğŸ¾ ğŸŒ‘ Comment accÃ©lÃ©rer le dÃ©chargement de LZ4 dans ClickHouse ğŸ‘Œ ğŸ’‚ğŸ¼ ğŸ‘¨ğŸ¾â€ğŸ”¬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lors de l'exÃ©cution de requÃªtes dans ClickHouse, vous pouvez remarquer que dans le profileur, Ã  l'un des premiers endroits, la fonction LZ_decompress_...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment accÃ©lÃ©rer le dÃ©chargement de LZ4 dans ClickHouse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/452778/"> Lors de l'exÃ©cution de requÃªtes dans ClickHouse, vous pouvez remarquer que dans le profileur, Ã  l'un des premiers endroits, la fonction LZ_decompress_fast est souvent visible.  Pourquoi cela se produit-il?  Cette question est devenue la raison de toute l'Ã©tude sur le choix du meilleur algorithme de dÃ©compression.  Ici, je publie l'Ã©tude entiÃ¨re, et la version courte peut Ãªtre trouvÃ©e dans mon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport</a> sur HighLoad ++ Siberia. <br><br>  Les donnÃ©es ClickHouse sont stockÃ©es sous forme compressÃ©e.  Et pendant l'exÃ©cution des requÃªtes, ClickHouse essaie de ne rien faire - utiliser un minimum de ressources CPU.  Il arrive que tous les calculs qui pourraient prendre un certain temps soient dÃ©jÃ  bien optimisÃ©s, et la requÃªte est bien Ã©crite par l'utilisateur.  Reste alors Ã  effectuer la libÃ©ration. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/302/aba/057302aba5041790af404c2c781c4dd3.png"><br><br>  La question est, pourquoi la version LZ4 peut-elle Ãªtre un goulot d'Ã©tranglement?  Il semblerait que LZ4 soit un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">algorithme trÃ¨s lÃ©ger</a> : le taux de compression, selon les donnÃ©es, varie gÃ©nÃ©ralement de 1 Ã  3 Go / s par cÅ“ur de processeur.  C'est bien plus que la vitesse du sous-systÃ¨me de disque.  De plus, nous utilisons tous les noyaux disponibles et l'expansion Ã©volue linÃ©airement sur tous les noyaux physiques. <br><a name="habracut"></a><br>  Mais il y a deux points Ã  garder Ã  l'esprit.  PremiÃ¨rement, les donnÃ©es compressÃ©es sont lues Ã  partir du disque et le taux de compression est donnÃ© en quantitÃ© de donnÃ©es non compressÃ©es.  Si le taux de compression est suffisamment grand, alors presque rien ne doit Ãªtre lu sur les disques.  Mais en mÃªme temps, beaucoup de donnÃ©es compressÃ©es sont gÃ©nÃ©rÃ©es, et bien sÃ»r, cela affecte la consommation du processeur: la quantitÃ© de travail de compression de donnÃ©es dans le cas de LZ4 est presque proportionnelle au volume des donnÃ©es compressÃ©es lui-mÃªme. <br><br>  DeuxiÃ¨mement, la lecture des donnÃ©es Ã  partir des disques peut ne pas Ãªtre nÃ©cessaire du tout si les donnÃ©es sont dans le cache.  Pour ce faire, vous pouvez compter sur le cache de pages ou utiliser votre propre cache.  Dans une base de donnÃ©es de colonnes, l'utilisation du cache est plus efficace car toutes les colonnes n'y entrent pas, mais seulement celles frÃ©quemment utilisÃ©es.  C'est pourquoi LZ4, en termes de charge CPU, est souvent un goulot d'Ã©tranglement. <br><br>  D'oÃ¹ deux autres questions.  Si la compression des donnÃ©es "ralentit", alors peut-Ãªtre qu'elles ne devraient pas du tout Ãªtre compressÃ©es?  Mais en pratique, cette hypothÃ¨se n'a pas de sens.  RÃ©cemment, dans ClickHouse, il n'a Ã©tÃ© possible de configurer que deux options de compression de donnÃ©es - LZ4 et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zstandard</a> .  La valeur par dÃ©faut est LZ4.  En passant Ã  Zstandard, vous pouvez rendre la compression plus forte et plus lente.  Mais il Ã©tait impossible de dÃ©sactiver complÃ¨tement la compression jusqu'Ã  rÃ©cemment - LZ4 est considÃ©rÃ© comme un minimum raisonnable, qui peut toujours Ãªtre utilisÃ©.  C'est pourquoi j'aime vraiment le LZ4.  :) <br><br>  Mais rÃ©cemment, un mystÃ©rieux inconnu est apparu dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chat de discussion</a> anglophone ClickHouse, qui a dit qu'il avait un sous-systÃ¨me de disque trÃ¨s rapide (NVMe SSD) et que tout dÃ©pend de la compression - ce serait bien de pouvoir le dÃ©sactiver.  J'ai rÃ©pondu qu'il n'y a pas une telle possibilitÃ©, mais c'est facile Ã  ajouter.  Quelques jours plus tard, nous avons reÃ§u une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">demande de pool</a> , qui implÃ©mente la mÃ©thode de compression <code>none</code> .  J'ai demandÃ© les rÃ©sultats - combien cela a aidÃ©, la rapiditÃ© des demandes.  La personne a dÃ©clarÃ© que cette nouvelle fonctionnalitÃ© s'est avÃ©rÃ©e inutile dans la pratique, car les donnÃ©es sans compression ont commencÃ© Ã  prendre trop de place. <br><br>  La deuxiÃ¨me question qui se pose est: s'il y a un cache, pourquoi ne pas y stocker les donnÃ©es dÃ©jÃ  non compressÃ©es?  Ceci est autorisÃ© - dans de nombreux cas, il sera possible de se dÃ©barrasser du besoin de dÃ©compression.  Et dans ClickHouse, il existe un tel cache - un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cache de blocs Ã©tendus</a> .  Mais c'est dommage d'y consacrer beaucoup de RAM Ã  cause de sa faible efficacitÃ©.  Il ne se justifie que sur de petites requÃªtes consÃ©cutives qui utilisent presque les mÃªmes donnÃ©es. <br><br>  ConsidÃ©ration gÃ©nÃ©rale: les donnÃ©es doivent Ãªtre compressÃ©es, de prÃ©fÃ©rence toujours.  Gravez-les toujours sur un disque compressÃ©.  Transmettez sur le rÃ©seau Ã©galement avec compression.  Ã€ mon avis, la compression par dÃ©faut doit Ãªtre considÃ©rÃ©e comme justifiÃ©e mÃªme lors du transfert vers un rÃ©seau de 10 gigabits sans surabonnement dans le centre de donnÃ©es, et le transfert de donnÃ©es sans compression entre les centres de donnÃ©es est gÃ©nÃ©ralement inacceptable. <br><br><h3>  Pourquoi LZ4? </h3><br>  Pourquoi LZ4 est-il utilisÃ©?  Est-il possible de choisir quelque chose de plus simple encore?  En principe, c'est possible, c'est juste et utile.  Mais regardons d'abord Ã  quelle classe d'algorithmes appartient LZ4. <br><br>  PremiÃ¨rement, cela ne dÃ©pend pas du type de donnÃ©es.  Par exemple, si vous savez Ã  l'avance que vous disposerez d'un tableau d'entiers, vous pouvez utiliser l'une des nombreuses variantes de l'algorithme VarInt - il sera plus efficace sur le CPU.  DeuxiÃ¨mement, LZ4 ne dÃ©pend pas trop des hypothÃ¨ses requises sur le modÃ¨le de donnÃ©es.  Supposons que vous ayez une sÃ©rie chronologique ordonnÃ©e de lectures de capteur - un tableau avec des nombres de type float.  Ensuite, vous pouvez calculer les deltas, puis compresser davantage, ce qui sera plus efficace en termes de taux de compression. <br><br>  Autrement dit, LZ4 peut Ãªtre utilisÃ© sans problÃ¨me pour tous les tableaux d'octets - pour tous les fichiers.  Bien sÃ»r, il a sa propre spÃ©cialisation (plus de dÃ©tails ci-dessous), et dans certains cas, son utilisation n'a pas de sens.  Mais si vous l'appelez un algorithme Ã  usage gÃ©nÃ©ral, ce sera une petite erreur.  Et notez que, grÃ¢ce au dispositif interne, LZ4 implÃ©mente automatiquement l'algorithme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RLE</a> comme cas particulier. <br><br>  Autre question: LZ4 est-il l'algorithme le plus optimal de cette classe pour la combinaison de la vitesse et de la force de compression?  De tels algorithmes sont appelÃ©s pareto frontier - cela signifie qu'aucun autre algorithme n'est strictement meilleur dans un indicateur et pas pire dans d'autres (et mÃªme sur une grande variÃ©tÃ© de jeux de donnÃ©es).  Il existe des algorithmes plus rapides, mais qui donnent un taux de compression plus faible, et d'autres qui compressent plus, mais en mÃªme temps, compressent ou dÃ©compressent plus lentement. <br><br>  En fait, le LZ4 n'est pas une frontiÃ¨re pareto.  Il existe des options lÃ©gÃ¨rement meilleures.  Par exemple, c'est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LZTURBO</a> d'un certain <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">powturbo</a> .  Il n'y a aucun doute sur la fiabilitÃ© des rÃ©sultats grÃ¢ce Ã  la communautÃ© sur encode.ru (le plus grand et approximativement le seul forum de compression de donnÃ©es).  Mais le dÃ©veloppeur ne distribue pas le code source ou les binaires, mais ne les donne qu'Ã  un cercle restreint de personnes pour des tests ou pour beaucoup d'argent (comme personne n'a payÃ© jusqu'Ã  prÃ©sent).  Il convient Ã©galement de prÃªter attention au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lÃ©zard</a> (anciennement LZ5) et Ã  la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">densitÃ©</a> .  Ils peuvent fonctionner un peu mieux que LZ4 lors du choix d'un niveau de compression.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Faites</a> Ã©galement attention Ã  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LZSSE</a> - une chose extrÃªmement intÃ©ressante.  Cependant, il vaut mieux le regarder aprÃ¨s avoir lu cet article. <br><br><h3>  Comment fonctionne LZ4? </h3><br>  Voyons comment fonctionne LZ4 en gÃ©nÃ©ral.  C'est l'une des implÃ©mentations de l'algorithme LZ77: L et Z indiquent les noms des auteurs (Lempel et Ziv), et 77 - en 1977, lorsque l'algorithme a Ã©tÃ© publiÃ©.  Il a de nombreuses autres implÃ©mentations: QuickLZ, FastLZ, BriefLZ, LZF, LZO, ainsi que gzip et zip lors de l'utilisation de faibles niveaux de compression. <br><br>  Un bloc de donnÃ©es compressÃ© Ã  l'aide de LZ4 contient une sÃ©quence d'enregistrements (commandes, instructions) de deux types: <br><br><ol><li>  LittÃ©ral: "prenez les N octets suivants tels quels et copiez-les dans le rÃ©sultat." </li><li>  Match (match): "prendre N octets qui ont dÃ©jÃ  Ã©tÃ© dÃ©compressÃ©s par le dÃ©calage de dÃ©calage par rapport Ã  la position actuelle." </li></ol><br>  Un exemple.  Avant la compression: <br> <code>Hello world Hello</code> <br> <br>  AprÃ¨s compression: <br> <code>literals 12 "Hello world " match 5 12</code> <br> <br>  Si nous prenons un bloc compressÃ© et le parcourons avec le curseur, en exÃ©cutant ces commandes, nous obtiendrons les donnÃ©es initiales non compressÃ©es en consÃ©quence. <br><br>  Nous avons examinÃ© en gros comment les donnÃ©es sont dÃ©compressÃ©es.  Le point est Ã©galement clair: pour effectuer la compression, l'algorithme code des sÃ©quences d'octets rÃ©pÃ©titives Ã  l'aide de correspondances. <br><br>  Clair et quelques propriÃ©tÃ©s.  Cet algorithme est orientÃ© octet - il ne dissÃ¨que pas les octets individuels, mais les copie uniquement dans son intÃ©gralitÃ©.  C'est lÃ  que rÃ©side, par exemple, la diffÃ©rence avec le codage entropique.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">zstd</a> est une composition de LZ77 et de codage entropique. <br><br>  Notez que la taille du bloc compressÃ© n'est pas choisie trop grande pour ne pas dÃ©penser beaucoup de RAM lors du dÃ©chargement;  afin de ne pas ralentir l'accÃ¨s alÃ©atoire dans un fichier compressÃ© (composÃ© de nombreux blocs compressÃ©s);  et parfois pour que le bloc tienne dans un cache CPU.  Par exemple, vous pouvez choisir 64 Ko - de sorte que les tampons pour les donnÃ©es compressÃ©es et non compressÃ©es tiendront dans le cache L2 et la moitiÃ© restera. <br><br>  Si nous devons compresser un fichier plus volumineux, nous allons simplement concatÃ©ner les blocs compressÃ©s.  En mÃªme temps, Ã  cÃ´tÃ© de chaque bloc compressÃ©, il est pratique de placer des donnÃ©es supplÃ©mentaires - tailles, somme de contrÃ´le. <br><br>  Le dÃ©calage maximum pour la correspondance est limitÃ©, en LZ4 - 64 kilo-octets.  Cette valeur est appelÃ©e une fenÃªtre coulissante.  En effet, cela signifie qu'au fur et Ã  mesure que le curseur avance, les correspondances peuvent se trouver dans une fenÃªtre de 64 kilo-octets par rapport au curseur, qui se dÃ©place avec le curseur. <br><br>  Voyons maintenant comment compresser les donnÃ©es - en d'autres termes, comment trouver les sÃ©quences correspondantes dans un fichier.  Bien sÃ»r, vous pouvez utiliser le suffixe trie (idÃ©al si vous en avez entendu parler).  Il existe des options dans lesquelles la sÃ©quence de correspondance la plus longue est garantie d'Ãªtre parmi les octets prÃ©cÃ©dents dans le processus de compression.  C'est ce qu'on appelle l'analyse optimale et donne un taux de compression <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">presque</a> meilleur pour un format de bloc compressÃ© fixe.  Mais il existe des options plus efficaces - lorsque nous trouvons une correspondance suffisamment bonne dans les donnÃ©es, mais pas nÃ©cessairement la plus longue.  Le moyen le plus efficace de le trouver est d'utiliser une table de hachage. <br><br>  Pour ce faire, nous parcourons le bloc de donnÃ©es source avec le curseur et prenons quelques octets aprÃ¨s le curseur.  Par exemple, 4 octets.  Les hacher et mettre dans la table de hachage le dÃ©calage depuis le dÃ©but du bloc - oÃ¹ ces 4 octets se sont rencontrÃ©s.  La valeur 4 est appelÃ©e min-match - Ã  l'aide d'une telle table de hachage, nous pouvons trouver des correspondances d'au moins 4 octets. <br><br>  Si nous avons regardÃ© la table de hachage, et qu'il y a dÃ©jÃ  un enregistrement lÃ -bas, et si l'offset ne dÃ©passe pas la fenÃªtre glissante, alors nous vÃ©rifions combien d'octets supplÃ©mentaires correspondent aprÃ¨s ces quatre octets.  Il y a peut-Ãªtre beaucoup plus qui coÃ¯ncident.  Il est Ã©galement possible qu'une collision se soit produite dans la table de hachage et que rien ne corresponde.  C'est normal - vous pouvez simplement remplacer la valeur de la table de hachage par une nouvelle.  Les collisions dans la table de hachage entraÃ®neront simplement un taux de compression plus faible car il y a moins de correspondances.  Soit dit en passant, ce type de table de hachage (de taille fixe et sans rÃ©solution de collision) est appelÃ© table de cache, une table de cache.  Cela est Ã©galement logique - en cas de collision, la table de cache oublie simplement l'ancien enregistrement. <br><blockquote>  La tÃ¢che du lecteur attentif.  Soit les donnÃ©es un tableau de nombres comme UInt32 en petit format endian, qui fait partie d'une sÃ©quence de nombres naturels: 0, 1, 2 ... Expliquez pourquoi lorsque vous utilisez LZ4 ces donnÃ©es ne sont pas compressÃ©es (la quantitÃ© de donnÃ©es compressÃ©es n'est pas infÃ©rieure Ã  la quantitÃ© de donnÃ©es non compressÃ©es). </blockquote><h3>  Comment accÃ©lÃ©rer les choses </h3><br>  Donc, je veux accÃ©lÃ©rer le dÃ©chargement de LZ4.  Voyons Ã  quoi ressemble le cycle de dÃ©chargement.  Voici la boucle en pseudocode: <br><br><pre>  tandis que (...)
 {
     lire (input_pos, literal_length, match_length);<font></font>
<font></font>
     copie (output_pos, input_pos, literal_length);
     output_pos + = literal_length;<font></font>
<font></font>
     lecture (input_pos, match_offset);<font></font>
<font></font>
     copy (output_pos, output_pos - match_offset,
         match_length);
     output_pos + = match_length;
 } </pre><br>  Le format LZ4 est conÃ§u pour que les littÃ©raux et les correspondances alternent dans un fichier compressÃ©.  Et Ã©videmment, le littÃ©ral vient toujours en premier (car depuis le tout dÃ©but, le match n'a nulle part oÃ¹ aller).  Par consÃ©quent, leurs longueurs sont codÃ©es ensemble. <br><br>  En fait, tout est un peu plus compliquÃ©.  Un octet est lu dans le fichier et deux quartets sont extraits de celui-ci, dans lesquels les nombres de 0 Ã  15. sont codÃ©s. Si le nombre correspondant n'est pas Ã©gal Ã  15, alors il est considÃ©rÃ© comme la longueur du littÃ©ral et de la correspondance, respectivement.  Et si c'est 15, alors la longueur est plus longue et elle est codÃ©e dans les octets suivants.  Ensuite, l'octet suivant est lu et sa valeur est ajoutÃ©e Ã  la longueur.  De plus, s'il est Ã©gal Ã  255, alors nous continuons - nous lisons l'octet suivant de la mÃªme maniÃ¨re. <br><br>  Notez que le taux de compression maximum pour le format LZ4 n'atteint pas 255. Et la deuxiÃ¨me observation (inutile): si vos donnÃ©es sont trÃ¨s redondantes, alors l'utilisation de LZ4 augmentera le taux de compression doubler. <br><br>  Lorsque nous lisons la longueur du littÃ©ral (puis aussi la longueur de la correspondance et le dÃ©calage de la correspondance), pour desserrer il suffit de copier simplement deux morceaux de mÃ©moire. <br><br><h3>  Comment copier un morceau de mÃ©moire </h3><br>  Il semblerait que vous pouvez utiliser la fonction <code>memcpy</code> , qui est juste conÃ§ue pour copier des morceaux de mÃ©moire.  Mais ce n'est pas optimal et toujours incorrect. <br><br>  Pourquoi l'utilisation de la fonction memcpy n'est-elle pas optimale?  Parce qu'elle: <br><br><ol><li>  gÃ©nÃ©ralement situÃ© dans la bibliothÃ¨que libc (et la bibliothÃ¨que libc est gÃ©nÃ©ralement liÃ©e dynamiquement, et l'appel memcpy ira indirectement, via PLT), </li><li>  pas en ligne avec l'argument taille inconnu au moment de la compilation, </li><li>  fait beaucoup d'efforts pour traiter correctement les Â«queuesÂ» d'un fragment de mÃ©moire qui ne sont pas multiples de la taille d'un mot machine ou d'un registre. </li></ol><br>  Le dernier point est le plus important.  Supposons que nous ayons demandÃ© Ã  la fonction memcpy de copier exactement 5 octets.  Il serait trÃ¨s bien de copier 8 octets Ã  la fois, en utilisant deux instructions movq pour cela. <br><br> <code>Hello world <font color="#0fc000">Hello</font> <font color="#ff0000">wo</font> ... <br> ^^^^^ <font color="#ff0000">^^^</font> - src <br> ^^^^^ <font color="#ff0000">^^^</font> - dst</code> <br> <br>  Mais ensuite, nous allons copier trois octets supplÃ©mentaires - c'est-Ã -dire que nous allons Ã©crire Ã  l'Ã©tranger le tampon transfÃ©rÃ©.  La fonction <code>memcpy</code> n'a pas le droit de le faire - en effet, parce que nous allons Ã©craser certaines donnÃ©es dans notre programme, il y aura un Â«passageÂ» de la mÃ©moire.  Et si nous avons Ã©crit Ã  une adresse non alignÃ©e, ces octets supplÃ©mentaires peuvent Ãªtre situÃ©s sur une page de mÃ©moire virtuelle non allouÃ©e ou sur une page sans accÃ¨s en Ã©criture.  Ensuite, nous obtenons un dÃ©faut de segmentation (c'est bien). <br><br>  Mais dans notre cas, nous pouvons presque toujours Ã©crire des octets supplÃ©mentaires.  Nous pouvons lire des octets supplÃ©mentaires dans le tampon d'entrÃ©e tant que les octets supplÃ©mentaires s'y trouvent entiÃ¨rement.  Dans les mÃªmes conditions, nous pouvons Ã©crire des octets supplÃ©mentaires dans le tampon de sortie - car Ã  la prochaine itÃ©ration, nous les remplacerons de toute faÃ§on. <br><br>  Cette optimisation est dÃ©jÃ  dans l'implÃ©mentation LZ4 d'origine: <br><br><pre>  inline void copy8 (UInt8 * dst, const UInt8 * src)
 {
     memcpy (dst, src, 8);  /// En fait, memcpy n'est pas appelÃ© ici.
 }<font></font>
<font></font>
 inline void wildCopy8 (UInt8 * dst, const UInt8 * src, UInt8 * dst_end)
 {
     faire
     {
         copy8 (dst, src);
         dst + = 8;
         src + = 8;
     } while (dst &lt;dst_end);
 } </pre><br>  Pour profiter de cette optimisation, il suffit de vÃ©rifier que l'on est assez loin de la frontiÃ¨re du buffer.  Cela devrait Ãªtre gratuit, car nous vÃ©rifions dÃ©jÃ  que les limites de tampon sont dÃ©passÃ©es.  Et le traitement des derniers octets - la "queue" des donnÃ©es - peut se faire aprÃ¨s la boucle principale. <br><br>  Cependant, il y a encore quelques subtilitÃ©s.  Il y a deux exemplaires dans le cycle - littÃ©ral et match.  Mais lorsque vous utilisez la fonction LZ4_decompress_fast (au lieu de LZ4_decompress_safe), la vÃ©rification est effectuÃ©e une fois - lorsque nous devons copier le littÃ©ral.  Lors de la copie d'une correspondance, la vÃ©rification n'est pas effectuÃ©e, mais dans la <a href="">spÃ©cification du format LZ4,</a> il existe des conditions qui permettent de l'Ã©viter: <br><br><blockquote>  Les 5 derniers octets sont toujours des littÃ©raux <br>  La derniÃ¨re correspondance doit commencer au moins 12 octets avant la fin du bloc. <br>  Par consÃ©quent, un bloc de moins de 13 octets ne peut pas Ãªtre compressÃ©. </blockquote><br>  Des donnÃ©es d'entrÃ©e spÃ©cialement sÃ©lectionnÃ©es peuvent provoquer un lecteur de mÃ©moire.  Si vous utilisez la fonction LZ4_decompress_fast, vous avez besoin d'une protection contre les donnÃ©es incorrectes.  Les donnÃ©es compressÃ©es doivent Ãªtre au moins une somme de contrÃ´le.  Et si vous avez besoin d'une protection contre un attaquant, utilisez la fonction LZ4_decompress_safe.  Autres options: prenez une fonction de hachage cryptographique comme somme de contrÃ´le, mais cela tuera presque certainement toutes les performances;  soit allouer plus de mÃ©moire aux tampons;  allouez de la mÃ©moire aux tampons avec un appel distinct Ã  mmap et crÃ©ez une page de garde. <br><br>  Quand je vois un code qui copie des donnÃ©es de 8 octets, je demande immÃ©diatement - pourquoi exactement 8 octets?  Vous pouvez copier 16 octets Ã  l'aide des registres SSE: <br><br><pre>  inline void copy16 (UInt8 * dst, const UInt8 * src)
 {
 #if __SSE2__
     _mm_storeu_si128 (reinterpret_cast &lt;__ m128i *&gt; (dst),
         _mm_loadu_si128 (reinterpret_cast &lt;const __m128i *&gt; (src)));
 #else
     memcpy (dst, src, 16);
 #endif
 }<font></font>
<font></font>
 inline void wildCopy16 (UInt8 * dst, const UInt8 * src, UInt8 * dst_end)
 {
     faire
     {
         copy16 (dst, src);
         dst + = 16;
         src + = 16;
     } while (dst &lt;dst_end);
 } </pre><br>  La copie de 32 octets pour AVX et de 64 octets pour AVX-512 fonctionne de maniÃ¨re similaire.  De plus, vous pouvez Ã©tendre le cycle plusieurs fois.  Si vous avez dÃ©jÃ  regardÃ© comment <code>memcpy</code> , c'est exactement l'approche.  (Soit dit en passant, le compilateur dans ce cas ne dÃ©veloppera ni ne vectorisera la boucle: cela nÃ©cessitera l'insertion de vÃ©rifications lourdes.) <br><br>  Pourquoi cela n'est-il pas fait dans l'implÃ©mentation LZ4 d'origine?  PremiÃ¨rement, il n'est pas Ã©vident que ce soit meilleur ou pire.  Le rÃ©sultat dÃ©pend de la taille des fragments qui doivent Ãªtre copiÃ©s.  Soudain, ils sont tous courts et le travail supplÃ©mentaire sera inutile?  Et deuxiÃ¨mement, il dÃ©truit ces conditions au format LZ4 qui vous permettent d'Ã©viter les brunchs inutiles dans la boucle intÃ©rieure. <br><br>  NÃ©anmoins, nous garderons cette option Ã  l'esprit pour l'instant. <br><br><h3>  Copie dÃ©licate </h3><br>  Retour Ã  la question - est-il toujours possible de copier des donnÃ©es de cette faÃ§on?  Supposons que nous ayons besoin de copier une correspondance, c'est-Ã -dire de copier un morceau de mÃ©moire du tampon de sortie qui est Ã  un certain dÃ©calage derriÃ¨re le curseur Ã  la position de ce curseur. <br><br>  Imaginez un cas simple - vous devez copier 5 octets Ã  l'offset 12: <br><br> <code><font color="#0fc000">Hello</font> world ........... <br> ^^^^^ - src <br> ^^^^^ - dst <br> <br> Hello world <font color="#0fc000">Hello</font> <font color="#a8a8a8">wo</font> ... <br> ^^^^^ - src <br> ^^^^^ - dst</code> <br> <br>  Mais il y a un cas plus compliquÃ© - quand nous devons copier un morceau de mÃ©moire dont la longueur est supÃ©rieure au dÃ©calage.  C'est-Ã -dire qu'il indique partiellement des donnÃ©es qui n'ont pas encore Ã©tÃ© Ã©crites dans le tampon de sortie. <br><br>  Copiez 10 octets Ã  l'offset 3: <br><br> <code><font color="#0fc000">abc</font> ............. <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst <br> <br> abc <font color="#0fc000">abcabcabca</font> ... <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst</code> <br> <br>  Dans le processus de compression, nous avons toutes les donnÃ©es, et une telle correspondance peut trÃ¨s bien Ãªtre trouvÃ©e.  La fonction <code>memcpy</code> ne convient pas pour la copier: elle ne prend pas en charge le cas oÃ¹ les plages de fragments de mÃ©moire se croisent.  Soit dit en passant, la fonction <code>memmove</code> ne convient pas non plus, car le fragment de mÃ©moire d'oÃ¹ obtenir les donnÃ©es n'est pas encore complÃ¨tement initialisÃ©.  Vous devez copier comme si nous copions par octet. <br><br><pre>  op [0] = correspond Ã  [0];
 op [1] = correspond Ã  [1];
 op [2] = correspond Ã  [2];
 op [3] = correspond Ã  [3];
 ... </pre><br><br>  Voici comment cela fonctionne: <br><br> <code><font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ............ <br> ^ - src <br> ^ - dst <br> <br> a <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........... <br> ^ - src <br> ^ - dst <br> <br> ab <font color="#0fc000">c</font> ab <font color="#0fc000">c</font> .......... <br> ^ - src <br> ^ - dst <br> <br> abc <font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ......... <br> ^ - src <br> ^ - dst <br> <br> abca <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........ <br> ^ - src <br> ^ - dst</code> <br> <br>  Autrement dit, nous devons crÃ©er une sÃ©quence rÃ©pÃ©titive.  Dans l'implÃ©mentation LZ4 d'origine, un code Ã©tonnamment incomprÃ©hensible a Ã©tÃ© Ã©crit pour cela: <br><br><pre>  const unsigned dec32table [] = {0, 1, 2, 1, 4, 4, 4, 4};
 const int dec64table [] = {0, 0, 0, -1, 0, 1, 2, 3};<font></font>
<font></font>
 const int dec64 = dec64table [offset];
 op [0] = correspond Ã  [0];
 op [1] = correspond Ã  [1];
 op [2] = correspond Ã  [2];
 op [3] = correspond Ã  [3];
 match + = dec32table [offset];
 memcpy (op + 4, match, 4);
 match - = dec64; </pre><br>  Nous copions les 4 premiers octets octet par bit, dÃ©calons d'un certain nombre magique, copions les 4 octets suivants dans leur ensemble, dÃ©calons le pointeur pour qu'il corresponde Ã  un autre nombre magique.  L'auteur du code ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Jan Collet</a> ), pour une raison ridicule, a oubliÃ© de laisser un commentaire sur ce que cela signifie.  De plus, les noms de variables prÃªtent Ã  confusion.  Les deux s'appellent dec ... table, mais nous ajoutons l'un d'eux et soustrayons l'autre.  De plus, un autre n'est pas signÃ© et l'autre est int.  Cependant, il vaut la peine de rendre hommage: tout rÃ©cemment, l'auteur a amÃ©liorÃ© cette place dans le code. <br><br>  Voici comment cela fonctionne rÃ©ellement.  Copiez les 4 premiers octets: <br><br> <code>abc <font color="#0fc000">abca</font> ......... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Vous pouvez maintenant copier 4 octets Ã  la fois: <br><br> <code>abcabca <font color="#0fc000">bcab</font> ..... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Vous pouvez continuer comme d'habitude en copiant 8 octets Ã  la fois: <br><br> <code>abcabcabcab <font color="#0fc000">cabcabca</font> ..... <br> ^^^^^^^^ - src <br> ^^^^^^^^ - dst</code> <br> <br>     ,      â€”   .   : <br><br><pre> inline void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset)<font></font>
{<font></font>
    /// 4 % n.<font></font>
    /// Or if 4 % n is zero, we use n.<font></font>
    /// It gives equivalent result, but is better CPU friendly for unknown reason.<font></font>
    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };<font></font>
<font></font>
    /// 8 % n - 4 % n<font></font>
    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };<font></font>
<font></font>
    op[0] = match[0];<font></font>
    op[1] = match[1];<font></font>
    op[2] = match[2];<font></font>
    op[3] = match[3];<font></font>
<font></font>
    match += shift1[offset];<font></font>
    memcpy(op + 4, match, 4);<font></font>
    match += shift2[offset];<font></font>
 } </pre><br> ,  ,   . ,     ,     â€”   16 . <br><br>    Â« Â»    ,     ( <code>offset &lt; 16</code>   ,  <code>offset &lt; 8</code> ).  ()     16-   : <br><br><pre> inline void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset)<font></font>
{<font></font>
    /// 4 % n.<font></font>
    static constexpr int shift1[]<font></font>
        = { 0, 1, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };<font></font>
<font></font>
    /// 8 % n - 4 % n<font></font>
    static constexpr int shift2[]<font></font>
        = { 0, 0, 0, 1, 0, -1, -2, -3, -4, 4, 4, 4, 4, 4, 4, 4 };<font></font>
<font></font>
    /// 16 % n - 8 % n<font></font>
    static constexpr int shift3[]<font></font>
        = { 0, 0, 0, -1, 0, -2, 2, 1, 8, -1, -2, -3, -4, -5, -6, -7 };<font></font>
<font></font>
    op[0] = match[0];<font></font>
    op[1] = match[1];<font></font>
    op[2] = match[2];<font></font>
    op[3] = match[3];<font></font>
<font></font>
    match += shift1[offset];<font></font>
    memcpy(op + 4, match, 4);<font></font>
    match += shift2[offset];<font></font>
    memcpy(op + 8, match, 8);<font></font>
    match += shift3[offset];<font></font>
 } </pre><br>       ?  ,        SIMD-,       16 ,         ( 1  15). ,   ,      . <br><br>    â€”   <code>pshufb</code> (  packed shuffle bytes)    SSSE3 (  S).    16- .      .   â€” Â«Â»:       0  15 â€”    ,       . ,      127 â€”     . <br><br>  Voici un exemple: <br><br><pre> xmm0: abc.............<font></font>
xmm1: 0120120120120120<font></font>
<font></font>
pshufb %xmm1, %xmm0<font></font>
<font></font>
xmm0: abcabcabcabcabca </pre><br>           â€”      !      : <br><br><pre> inline void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset)<font></font>
{<font></font>
#ifdef __SSSE3__<font></font>
<font></font>
    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =<font></font>
    {<font></font>
        0, 1, 2, 1, 4, 1, 4, 2, 8, 7, 6, 5, 4, 3, 2, 1, /* offset = 0, not used as mask, but for shift amount instead */<font></font>
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, /* offset = 1 */<font></font>
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,<font></font>
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,<font></font>
        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,<font></font>
        0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,<font></font>
        0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3,<font></font>
        0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1,<font></font>
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0,<font></font>
     };<font></font>
<font></font>
    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(op),<font></font>
        _mm_shuffle_epi8(<font></font>
            _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(match)),<font></font>
            _mm_load_si128(reinterpret_cast&lt;const __m128i *&gt;(masks) + offset)));<font></font>
<font></font>
    match += masks[offset];<font></font>
<font></font>
#else<font></font>
    copyOverlap16(op, match, offset);<font></font>
#endif<font></font>
 } </pre><br>  <code>_mm_shuffle_epi8</code> â€”  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">intrinsic</a> ,    <code>pshufb</code> . <br><br>          ,    ?  SSSE3 â€”    ,   2006 .  AVX2  ,      32 ,      16- .     packed shuffle bytes,  vector permute bytes â€”  ,    .  AVX-512 VBMI    ,    64 ,        .      ARM NEON â€”   vtbl (vector table lookup),     8 . <br><br>  ,    <code>pshufb</code>  64- MMX-,   8 .         . ,        ,   16  (  ). <br><br>   Highload++ Siberia         ,    8          (  ) â€”       ! <br><br><h3>    if </h3><br> ,    ,   16 .         ? <br><br>  ,       .      ,           ,  ,         .    ,     . <br><br> ,    . , ,    ,      65 536 .        65 536    .           , ,  65 551 .  ,  ,       96   128  â€”     .     ,           Â«Â»      mmap    (     madvice).      - page faults.         ,    . <br><br><h3>   ? </h3><br> ,    ,     : <br><br><ol><li>   16   8. </li><li>  shuffle-   <code>offset &lt; 16</code> . </li><li>    if. </li></ol><br>              . <br><br>  Exemple 1: <br> Xeon E2650v2,  .,  AppVersion. <br> reference: 1.67 GB/sec. <br> 16 bytes, shuffle: 2.94 GB/sec ( 76% ). <br><br>  Exemple 2: <br> Xeon E2650v2,  .,  ShowsSumPosition. <br> reference: 2.30 GB/sec. <br> 16 bytes, shuffle: 1.91 GB/sec ( 20% ). <br><br>   ,         .     ,    .   - ,   .   ,      .     â€”       16 .  :    ,     ,   . <br><br>   ,     C++      :  8-  16-  ;     shuffle-. <br><br><pre> template &lt;size_t copy_amount, bool use_shuffle&gt;<font></font>
void NO_INLINE decompressImpl(<font></font>
     const char * const source,<font></font>
     char * const dest,<font></font>
     size_t dest_size) </pre><br>        ,         shuffle  .     ,   : <br><br><pre> sudo echo 'performance' | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor<font></font>
kill -STOP $(pidof firefox) $(pidof chromium) </pre><br>        Â«Â»  (c  Xeon E5645),           ,    . ,         ,    .    ,    shuffle-,   ,      16- . <br><br>         : <br><br><pre> sudo kill -STOP $(pidof python) $(pidof perl) $(pgrep -u skynet) $(pidof cqudp-client) </pre><br>    .    thermal throttling  power capping. <br><br><h3>     </h3><br> ,      ,        .         ,         ,    .       .       , ,     .   : ClickHouse      ,       ,         .       ,             (       â€”  ?).      . <br><br>      ,    ,      .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Â« Â»</a> .   ,      ,           ,    . <br><br>      ,   .        .       -        .             â€”   ClickHouse      64 . ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>   .) <br><br>  ,     Â« Â», ,    .      ,     ,   ,   -   .           .            ,          ,    .      . <br><br>         ,          ,       .    Â«Â»     ,    .     ,        .    Thompson Sampling. <br><br> ,   ,    .  â€”      :  ,  .          .     ,     .       ,           C++.     â€” ,     -   ,   ;     . <br><br>     ?      ,       .    . -,      ,         . -,  ,   ,   Â«Â» . <br><br> ,  ,           Thompson Sampling â€”   (   ,        ).   ,         ,         - ,     ,      .           ,     . <br><br>   ,   Â«Â» .   ,     ,        Â«Â»,     .      â€” <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> .    ,     ,       . <br><br>       ,   ,    ,    ,   Â«Â»: <br><br><pre> /// For better convergence, we don't use proper estimate of stddev.<font></font>
/// We want to eventually separate between two algorithms even in case<font></font>
/// when there is no statistical significant difference between them.<font></font>
double sigma() const<font></font>
{<font></font>
    return mean() / sqrt(adjustedCount());<font></font>
 }<font></font>
<font></font>
double sample(pcg64 &amp; rng) const<font></font>
{<font></font>
     ...<font></font>
    return std::normal_distribution&lt;&gt;(mean(), sigma())(rng);<font></font>
 } </pre><br>    ,       â€”    memory latencies. <br><br>   ,         ,       â€”    LZ4    . <br><br>  ,    : <br> â€” reference (baseline):  LZ4   ; <br> â€” variant 0:   8 ,   shuffle; <br> â€” variant 1:   8 ,  shuffle; <br> â€” variant 2:   16 ,   shuffle; <br> â€” variant 3:   16 ,  shuffle; <br> â€” Â«Â» ,            . <br><br><h3>    CPU </h3><br>       CPU,    ,  .  ,   CPU   ? <br><br>         ClickHouse   ,  256    100    ( 256  ).  ,  CPU  ,      .      CPU: <br> â€” IntelÂ® XeonÂ® CPU E5-2650 v2 @ 2.60GHz <br> â€” IntelÂ® XeonÂ® CPU E5-2660 v4 @ 2.00GHz <br> â€” IntelÂ® XeonÂ® CPU E5-2660 0 @ 2.20GHz <br> â€” IntelÂ® XeonÂ® CPU E5645 @ 2.40GHz <br> â€” Intel Xeon E312xx (Sandy Bridge) <br> â€” AMD Opteron(TM) Processor 6274 <br> â€” AMD Opteron(tm) Processor 6380 <br> â€” IntelÂ® XeonÂ® CPU E5-2683 v4 @ 2.10GHz <br> â€” IntelÂ® XeonÂ® CPU E5530 @ 2.40GHz <br> â€” IntelÂ® XeonÂ® CPU E5440 @ 2.83GHz <br> â€” IntelÂ® XeonÂ® CPU E5-2667 v2 @ 3.30GHz <br><br>    â€” ,   R&amp;D: <br> â€” AMD EPYC 7351 16-Core Processor â€”    AMD. <br> â€” Cavium ThunderX2 â€”     x86,  AArch64.    SIMD-   .    224   56  . <br><br>  13 ,        256   6  (reference, 0, 1, 2, 3, adaptive),    10 ,   .  199 680 ,    . <br><br> ,    CPU  .         :      LZ4    (   â€”  ).  ,  Cavium   .       ClickHouse,   Â«Â» Xeon E5-2650 v2         ,      ,   ClickHouse    x86. <br><br><pre> â”Œâ”€cpuâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€refâ”€â”¬â”€adaptâ”€â”¬â”€â”€maxâ”€â”¬â”€bestâ”€â”¬â”€adapt_boostâ”€â”¬â”€max_boostâ”€â”¬â”€adapt_over_maxâ”€â”<font></font>
â”‚ E5-2667 v2 @ 3.30GHz â”‚ 2.81 â”‚ 3.19 â”‚ 3.15 â”‚ 3 â”‚ 1.14 â”‚ 1.12 â”‚ 1.01 â”‚<font></font>
â”‚ E5-2650 v2 @ 2.60GHz â”‚ 2.5 â”‚ 2.84 â”‚ 2.81 â”‚ 3 â”‚ 1.14 â”‚ 1.12 â”‚ 1.01 â”‚<font></font>
â”‚ E5-2683 v4 @ 2.10GHz â”‚ 2.26 â”‚ 2.63 â”‚ 2.59 â”‚ 3 â”‚ 1.16 â”‚ 1.15 â”‚ 1.02 â”‚<font></font>
â”‚ E5-2660 v4 @ 2.00GHz â”‚ 2.15 â”‚ 2.49 â”‚ 2.46 â”‚ 3 â”‚ 1.16 â”‚ 1.14 â”‚ 1.01 â”‚<font></font>
â”‚ AMD EPYC 7351 â”‚ 2.03 â”‚ 2.44 â”‚ 2.35 â”‚ 3 â”‚ 1.20 â”‚ 1.16 â”‚ 1.04 â”‚<font></font>
â”‚ E5-2660 0 @ 2.20GHz â”‚ 2.13 â”‚ 2.39 â”‚ 2.37 â”‚ 3 â”‚ 1.12 â”‚ 1.11 â”‚ 1.01 â”‚<font></font>
â”‚ E312xx (Sandy Bridge) â”‚ 1.97 â”‚ 2.2 â”‚ 2.18 â”‚ 3 â”‚ 1.12 â”‚ 1.11 â”‚ 1.01 â”‚<font></font>
â”‚ E5530 @ 2.40GHz â”‚ 1.65 â”‚ 1.93 â”‚ 1.94 â”‚ 3 â”‚ 1.17 â”‚ 1.18 â”‚ 0.99 â”‚<font></font>
â”‚ E5645 @ 2.40GHz â”‚ 1.65 â”‚ 1.92 â”‚ 1.94 â”‚ 3 â”‚ 1.16 â”‚ 1.18 â”‚ 0.99 â”‚<font></font>
â”‚ AMD Opteron 6380 â”‚ 1.47 â”‚ 1.58 â”‚ 1.56 â”‚ 1 â”‚ 1.07 â”‚ 1.06 â”‚ 1.01 â”‚<font></font>
â”‚ AMD Opteron 6274 â”‚ 1.15 â”‚ 1.35 â”‚ 1.35 â”‚ 1 â”‚ 1.17 â”‚ 1.17 â”‚ 1 â”‚<font></font>
â”‚ E5440 @ 2.83GHz â”‚ 1.35 â”‚ 1.33 â”‚ 1.42 â”‚ 1 â”‚ 0.99 â”‚ 1.05 â”‚ 0.94 â”‚<font></font>
â”‚ Cavium ThunderX2 â”‚ 0.84 â”‚ 0.87 â”‚ 0.87 â”‚ 0 â”‚ 1.04 â”‚ 1.04 â”‚ 1 â”‚<font></font>
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ </pre><br> ref, adapt, max â€”       (,            ). best â€”      ,  0  3. adapt_boost â€”        baseline. max_boost â€”          baseline. adapt_over_max â€”         . <br><br>  ,    x86      12â€“20%.   ARM    4%,   ,         .  ,        Â«Â»              Intel. <br><br><h3>  </h3><br>       . ,   LZ4     12â€“20%,            .           .      ,         . <br><br>    ,     ,    Â«Â» ,    ZStandard level 1  LZ4:      IO    . <br><br>           â€” ,      .          ,       . <br><br>    :         . LZ4    ,   Lizard, Density  LZSSE  ,    . ,    LZ4      LZSSE  ClickHouse. <br><br>       LZ4 :         .          :      ,   .             . ,   inc-  dec-   <a href=""></a> .  ,           12â€“15%     32 ,    16,   .       32  â€”     ,     <a href=""> </a> . <br><br>       ,  ,          page cache  userspace (   mmap,    O_DIRECT  userspace page cache â€”     ),      - (  CityHash128  CRC32-C,    HighwayHash, FARSH  XXH3).         ,       . <br><br>   ,     master,            .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>  HighLoad++ Siberia,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr452778/">https://habr.com/ru/post/fr452778/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr452766/index.html">La technologie de streaming progressif, ou comment regarder des vidÃ©os 4k sur le rÃ©seau, sans frises</a></li>
<li><a href="../fr452768/index.html">Comment concevoir un produit si vous dÃ©cidez d'entrer sur le marchÃ© Ã©tranger</a></li>
<li><a href="../fr452772/index.html">5 techniques avancÃ©es de test Go</a></li>
<li><a href="../fr452774/index.html">Dell XPS 13 9380: un ordinateur portable fiable et trÃ¨s compact pour les affaires sÃ©rieuses</a></li>
<li><a href="../fr452776/index.html">N.M.D. (Pas mon entreprise)</a></li>
<li><a href="../fr452780/index.html">Mobius 2019 Piter: Streaming en direct gratuit et tout le reste</a></li>
<li><a href="../fr452788/index.html">La lutte pour la qualitÃ© dans les applications Web, la dÃ©pression, les dragons et Westeros</a></li>
<li><a href="../fr452790/index.html">OpenCV 4.0 et 4.1 - quoi de neuf?</a></li>
<li><a href="../fr452792/index.html">Examen SSD SSD pour les utilisateurs d'entreprise Kingston DC500R</a></li>
<li><a href="../fr452794/index.html">A propos de la localisation des produits. PremiÃ¨re partie: par oÃ¹ commencer?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêó üåî üéì Identifizieren Sie Betrug mithilfe des Enron-Datensatzes. Teil 1, Datenaufbereitung und Auswahl der Zulassungen üî∞ üç† üëáüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Enron Corporation ist eine der bekanntesten Pers√∂nlichkeiten der amerikanischen Wirtschaft in den 2000er Jahren. Dies wurde nicht durch ihren T√§ti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifizieren Sie Betrug mithilfe des Enron-Datensatzes. Teil 1, Datenaufbereitung und Auswahl der Zulassungen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424891/"><p> Die Enron Corporation ist eine der bekanntesten Pers√∂nlichkeiten der amerikanischen Wirtschaft in den 2000er Jahren.  Dies wurde nicht durch ihren T√§tigkeitsbereich (Elektrizit√§t und Vertr√§ge f√ºr seine Lieferung) erleichtert, sondern durch die Resonanz aufgrund von Betrug.  Seit 15 Jahren ist das Unternehmenseinkommen schnell gewachsen, und die Arbeit darin versprach ein gutes Gehalt.  Aber alles endete genauso fl√ºchtig: im Zeitraum 2000-2001.  Der Aktienkurs fiel von 90 USD / St√ºck auf fast Null, was auf aufgedeckten Betrug mit deklariertem Einkommen zur√ºckzuf√ºhren war.  Seitdem ist das Wort "Enron" ein Begriff im Haushalt und dient als Bezeichnung f√ºr Unternehmen, die nach einem √§hnlichen Muster arbeiten. </p><br><p>  W√§hrend des Prozesses wurden 18 Personen (einschlie√ülich der gr√∂√üten Angeklagten in diesem Fall: Andrew Fastov, Jeff Skilling und Kenneth Lay) verurteilt. </p><br><p><img src="https://habrastorage.org/webt/te/rh/1l/terh1lsenbtg26n8nhjbhv3opfi.jpeg" alt="Bild! [Bild] (http: // https: //habrastorage.org/webt/te/rh/1l/terh1lsenbtg26n8nhjbhv3opfi.jpeg)"></p><br><p>  Gleichzeitig wurden ein Archiv der elektronischen Korrespondenz zwischen Mitarbeitern des Unternehmens, besser bekannt als Enron Email Dataset, und Insiderinformationen √ºber das Einkommen der Mitarbeiter dieses Unternehmens ver√∂ffentlicht. </p><br><p>  In dem Artikel werden die Quellen dieser Daten untersucht und ein darauf basierendes Modell erstellt, um festzustellen, ob eine Person des Betrugs verd√§chtigt wird.  Klingt interessant?  Dann willkommen im Habrakat. <a name="habracut"></a></p><br><h1 id="opisanie-dataseta">  Beschreibung des Datensatzes </h1><br><p>  Enron-Datensatz (Datensatz) ist ein zusammengesetzter Satz offener Daten, der Aufzeichnungen von Personen enth√§lt, die in einem denkw√ºrdigen Unternehmen mit dem entsprechenden Namen arbeiten. <br>  Es kann 3 Teile unterscheiden: </p><br><ul><li>  Zahlungen_Funktionen - eine Gruppe, die finanzielle Bewegungen charakterisiert; </li><li>  stock_features - eine Gruppe, die die mit Aktien verbundenen Zeichen widerspiegelt; </li><li>  email_features - Eine Gruppe, die Informationen √ºber die E-Mails einer bestimmten Person in aggregierter Form wiedergibt. </li></ul><br><p>  Nat√ºrlich gibt es auch eine Zielvariable, die angibt, ob die Person des Betrugs verd√§chtigt wird (das Zeichen <abbr title="Person von Interesse">‚ÄûPoi‚Äú <abbr>).</abbr></abbr> <abbr title="Person von Interesse"><br></abbr> </p><p>  Laden Sie unsere Daten herunter und beginnen Sie mit ihnen zu arbeiten: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">open</span></span>("final_project/enron_dataset.pkl", "rb") <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> data_file: data_dict = pickle.<span class="hljs-keyword"><span class="hljs-keyword">load</span></span>(data_file)</code> </pre> <br><p>  Danach verwandeln wir den <strong>Datensatz data_dict</strong> in einen Pandas-Datenrahmen, um das Arbeiten mit Daten zu vereinfachen: </p><br><pre> <code class="hljs haskell"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings warnings.filterwarnings('<span class="hljs-title"><span class="hljs-title">ignore'</span></span>) source_df = pd.DataFrame.from_dict(<span class="hljs-title"><span class="hljs-title">data_dict</span></span>, <span class="hljs-title"><span class="hljs-title">orient</span></span> = '<span class="hljs-title"><span class="hljs-title">index'</span></span>) source_df.drop('<span class="hljs-type"><span class="hljs-type">TOTAL</span></span>',<span class="hljs-title"><span class="hljs-title">inplace</span></span>=<span class="hljs-type"><span class="hljs-type">True</span></span>)</code> </pre> <br><p>  Wir gruppieren die Zeichen gem√§√ü den zuvor angegebenen Typen.  Dies sollte die Arbeit mit Daten danach erleichtern: </p><br><pre> <code class="hljs powershell">payments_features = [<span class="hljs-string"><span class="hljs-string">'salary'</span></span>, <span class="hljs-string"><span class="hljs-string">'bonus'</span></span>, <span class="hljs-string"><span class="hljs-string">'long_term_incentive'</span></span>, <span class="hljs-string"><span class="hljs-string">'deferred_income'</span></span>, <span class="hljs-string"><span class="hljs-string">'deferral_payments'</span></span>, <span class="hljs-string"><span class="hljs-string">'loan_advances'</span></span>, <span class="hljs-string"><span class="hljs-string">'other'</span></span>, <span class="hljs-string"><span class="hljs-string">'expenses'</span></span>, <span class="hljs-string"><span class="hljs-string">'director_fees'</span></span>, <span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>] stock_features = [<span class="hljs-string"><span class="hljs-string">'exercised_stock_options'</span></span>, <span class="hljs-string"><span class="hljs-string">'restricted_stock'</span></span>, <span class="hljs-string"><span class="hljs-string">'restricted_stock_deferred'</span></span>,<span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>] email_features = [<span class="hljs-string"><span class="hljs-string">'to_messages'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_poi_to_this_person'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_messages'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_this_person_to_poi'</span></span>, <span class="hljs-string"><span class="hljs-string">'shared_receipt_with_poi'</span></span>] target_field = <span class="hljs-string"><span class="hljs-string">'poi'</span></span></code> </pre> <br><h2 id="finansovye-dannye">  Finanzdaten </h2><br><p>  In diesem Datensatz ist vielen ein NaN bekannt, der die √ºbliche L√ºcke in den Daten ausdr√ºckt.  Mit anderen Worten, der Autor des Datensatzes konnte keine Informationen zu einem bestimmten Attribut finden, das einer bestimmten Zeile im Datenrahmen zugeordnet ist.  Infolgedessen k√∂nnen wir annehmen, dass NaN 0 ist, da es keine Informationen √ºber ein bestimmtes Merkmal gibt. </p><br><pre> <code class="hljs powershell">payments = source_df[<span class="hljs-type"><span class="hljs-type">payments_features</span></span>] payments = payments.replace(<span class="hljs-string"><span class="hljs-string">'NaN'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h3 id="proverka-dannyh">  Daten√ºberpr√ºfung </h3><br><p>  Beim Vergleich mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original-PDF</a> , das dem Datensatz zugrunde liegt, stellte sich heraus, dass die Daten leicht verzerrt sind, da <em>das</em> Feld <em>total_payments</em> nicht f√ºr alle Zeilen im <strong>Zahlungsdatenrahmen</strong> die Summe aller Finanztransaktionen einer bestimmten Person ist.  Sie k√∂nnen dies wie folgt √ºberpr√ºfen: </p><br><pre> <code class="hljs powershell">errors = payments[<span class="hljs-type"><span class="hljs-type">payments</span></span>[<span class="hljs-type"><span class="hljs-type">payments_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]]<span class="hljs-type"><span class="hljs-type">.sum</span></span>(<span class="hljs-type"><span class="hljs-type">axis</span></span>=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) != <span class="hljs-type"><span class="hljs-type">payments</span></span>[<span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>]] errors.head()</code> </pre> <br><p><img src="https://habrastorage.org/webt/eo/79/ye/eo79ye27iirsiwcuickrxz4on30.png" alt="2 ung√ºltige Zeilen"><br>  Wir sehen, dass BELFER ROBERT und BHATNAGAR SANJAY falsche Zahlungsbetr√§ge haben. </p><br><p>  Sie k√∂nnen diesen Fehler beheben, indem Sie die Daten in den Fehlerzeilen nach links oder rechts verschieben und die Summe aller Zahlungen erneut z√§hlen: </p><br><pre> <code class="hljs powershell">import numpy as np shifted_values = payments.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>:]].values expected_payments = shifted_values.sum() shifted_values = np.append(shifted_values, expected_payments) payments.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>] = shifted_values shifted_values = payments.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]].values payments.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>] = np.insert(shifted_values, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h2 id="dannye-po-akciyam">  Bestandsdaten </h2><br><pre> <code class="hljs powershell">stocks = source_df[<span class="hljs-type"><span class="hljs-type">stock_features</span></span>] stocks = stocks.replace(<span class="hljs-string"><span class="hljs-string">'NaN'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  F√ºhren Sie auch in diesem Fall eine Validierungspr√ºfung durch: </p><br><pre> <code class="hljs powershell">errors = stocks[<span class="hljs-type"><span class="hljs-type">stocks</span></span>[<span class="hljs-type"><span class="hljs-type">stock_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]]<span class="hljs-type"><span class="hljs-type">.sum</span></span>(<span class="hljs-type"><span class="hljs-type">axis</span></span>=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) != <span class="hljs-type"><span class="hljs-type">stocks</span></span>[<span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>]] errors.head()</code> </pre> <br><p><img src="https://habrastorage.org/webt/sd/28/mz/sd28mzikmhurh_b0mqwibnje8fa.png" alt="Bild"></p><br><p>  Wir werden den Fehler in den Best√§nden auf √§hnliche Weise beheben: </p><br><pre> <code class="hljs powershell">shifted_values = stocks.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>:]].values expected_payments = shifted_values.sum() shifted_values = np.append(shifted_values, expected_payments) stocks.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>] = shifted_values shifted_values = stocks.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]].values stocks.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>] = np.insert(shifted_values, <span class="hljs-number"><span class="hljs-number">0</span></span>, shifted_values[-<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2 id="svodnye-dannye-po-elektronnoy-perepiske">  E-Mail-Korrespondenz </h2><br><p>  Wenn f√ºr diese Finanzen oder Aktien NaN gleich 0 war und dies in das Endergebnis f√ºr jede dieser Gruppen passt, ist es im Fall von E-Mail sinnvoller, NaN durch einen Standardwert zu ersetzen.  Dazu k√∂nnen Sie Imputer verwenden: </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.impute <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleImputer imp = SimpleImputer()</code> </pre> <br><p>  Gleichzeitig werden wir den Standardwert f√ºr jede Kategorie (unabh√§ngig davon, ob wir eine Person des Betrugs vermuten) separat betrachten: </p><br><pre> <code class="hljs markdown">target = source<span class="hljs-emphasis"><span class="hljs-emphasis">_df[target_</span></span>field] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data = source_</span></span>df[<span class="hljs-string"><span class="hljs-string">email_features</span></span>] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data = pd.concat([email_</span></span>data, target], axis=1) email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>poi = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data[email_</span></span>data[<span class="hljs-string"><span class="hljs-string">target_field</span></span>]][<span class="hljs-string"><span class="hljs-string">email_features</span></span>] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>nonpoi = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data[email_</span></span>data[<span class="hljs-string"><span class="hljs-string">target_field</span></span>] == False][email<span class="hljs-emphasis"><span class="hljs-emphasis">_features] email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_poi[email_</span></span>features] = imp.fit<span class="hljs-emphasis"><span class="hljs-emphasis">_transform(email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_poi) email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_nonpoi[email_</span></span>features] = imp.fit<span class="hljs-emphasis"><span class="hljs-emphasis">_transform(email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_nonpoi) email_</span></span>data = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>poi.append(email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>nonpoi)</code> </pre> <br><p>  Endg√ºltiger Datensatz nach Korrektur: </p><br><pre> <code class="hljs cs">df = payments.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(stocks) df = df.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(email_data) df = df.astype(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)</code> </pre> <br><h2 id="vybrosy">  Emissionen </h2><br><p>  Im letzten Schritt dieser Phase werden alle Ausrei√üer entfernt, die das Training verzerren k√∂nnen.  Gleichzeitig stellt sich immer die Frage: Wie viele Daten k√∂nnen wir aus der Stichprobe entfernen und trotzdem als trainiertes Modell nicht verlieren?  Ich folgte dem Rat eines der Dozenten des ML-Kurses (Maschinelles Lernen) zu Udacity - ‚Äû10 entfernen und erneut auf Emissionen pr√ºfen.‚Äú </p><br><pre> <code class="hljs powershell">first_quartile = df.quantile(q=<span class="hljs-number"><span class="hljs-number">0.25</span></span>) third_quartile = df.quantile(q=<span class="hljs-number"><span class="hljs-number">0.75</span></span>) IQR = third_quartile - first_quartile outliers = df[(<span class="hljs-type"><span class="hljs-type">df</span></span> &gt; (<span class="hljs-type"><span class="hljs-type">third_quartile</span></span> + <span class="hljs-number"><span class="hljs-number">1.5</span></span> * <span class="hljs-type"><span class="hljs-type">IQR</span></span>)) | (<span class="hljs-type"><span class="hljs-type">df</span></span> &lt; (<span class="hljs-type"><span class="hljs-type">first_quartile</span></span> - <span class="hljs-number"><span class="hljs-number">1.5</span></span> * <span class="hljs-type"><span class="hljs-type">IQR</span></span>))].count(axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) outliers.sort_values(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>, ascending=False, inplace=True) outliers = outliers.head(<span class="hljs-number"><span class="hljs-number">10</span></span>) outliers</code> </pre> <br><p>  Gleichzeitig werden keine Datens√§tze gel√∂scht, die Ausrei√üer sind und des Betrugs verd√§chtigt werden.  Der Grund ist, dass es nur 18 Zeilen mit solchen Daten gibt, und wir k√∂nnen sie nicht opfern, da dies zu einem Mangel an Trainingsbeispielen f√ºhren kann.  Infolgedessen entfernen wir nur diejenigen, die nicht des Betrugs verd√§chtigt werden, aber gleichzeitig eine Vielzahl von Anzeichen haben, anhand derer Emissionen beobachtet werden: </p><br><pre> <code class="hljs powershell">target_for_outliers = target.loc[<span class="hljs-type"><span class="hljs-type">outliers.index</span></span>] outliers = pd.concat([<span class="hljs-type"><span class="hljs-type">outliers</span></span>, <span class="hljs-type"><span class="hljs-type">target_for_outliers</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) non_poi_outliers = outliers[<span class="hljs-type"><span class="hljs-type">np.logical_not</span></span>(<span class="hljs-type"><span class="hljs-type">outliers.poi</span></span>)] df.drop(non_poi_outliers.index, inplace=True)</code> </pre> <br><h2 id="privedenie-k-itogovom-vidu">  Finalisieren </h2><br><p>  Wir normalisieren unsere Daten: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scale df[df.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>] = scale(df)</code> </pre> <br><p>  L√§sst die Zielvariable auf eine kompatible Ansicht abzielen: </p><br><pre> <code class="hljs cmake"><span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.drop(non_poi_outliers.index, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">target</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.map({<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>}) <span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.value_counts()</code> </pre> <br><p><img src="https://habrastorage.org/webt/nr/mn/fi/nrmnfi0bdldw36fg9uy-tcxinsa.png" alt="Bild"><br>  Infolgedessen 18 Verd√§chtige und 121 diejenigen, die nicht verd√§chtigt wurden. </p><br><h1 id="otbor-priznakov">  Funktionsauswahl </h1><br><p>  Vielleicht ist einer der wichtigsten Punkte vor dem Erlernen eines Modells die Auswahl der wichtigsten Merkmale. </p><br><h2 id="proverka-na-multikollinearnost">  Multikollinearit√§tstest </h2><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib <span class="hljs-keyword"><span class="hljs-keyword">inline</span></span> sns.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(style="whitegrid") corr = df.corr() * <span class="hljs-number"><span class="hljs-number">100</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> upper triangle <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> correlation matrix mask = np.zeros_like(corr, dtype=np.bool) mask[np.triu_indices_from(mask)] = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">Set</span></span> up the matplotlib figure f, ax = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>)) # Generate a custom diverging colormap cmap = sns.diverging_palette(<span class="hljs-number"><span class="hljs-number">220</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) # Draw the heatmap <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> the mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> correct aspect ratio sns.heatmap(corr, mask=mask, cmap=cmap, center=<span class="hljs-number"><span class="hljs-number">0</span></span>, linewidths=<span class="hljs-number"><span class="hljs-number">1</span></span>, cbar_kws={"shrink": <span class="hljs-number"><span class="hljs-number">.7</span></span>}, annot=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fmt=".2f")</code> </pre> <br><p><img src="https://habrastorage.org/webt/kw/66/ta/kw66tahpopi7zjc6tvaj1uzq9qe.png" alt="Bild"><br>  Wie Sie auf dem Bild sehen k√∂nnen, besteht eine ausgepr√§gte Beziehung zwischen 'credit_advanced' und 'total_payments' sowie zwischen 'total_stock_value' und 'beschr√§nkter_stock'.  Wie bereits erw√§hnt, sind 'total_payments' und 'total_stock_value' nur das Ergebnis der Addition aller Indikatoren in einer bestimmten Gruppe.  Daher k√∂nnen sie gel√∂scht werden: </p><br><pre> <code class="hljs pgsql">df.<span class="hljs-keyword"><span class="hljs-keyword">drop</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>=[<span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>, <span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>], inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h2 id="sozdanie-novyh-priznakov">  Neue Eigenschaften schaffen </h2><br><p>  Es besteht auch die Annahme, dass die Verd√§chtigen h√§ufiger an Komplizen als an Mitarbeiter geschrieben haben, die daran nicht beteiligt waren.  Infolgedessen sollte der Anteil solcher Nachrichten gr√∂√üer sein als der Anteil der Nachrichten an normale Mitarbeiter.  Basierend auf dieser Aussage k√∂nnen Sie neue Zeichen erstellen, die den Prozentsatz der eingehenden / ausgehenden Personen im Zusammenhang mit Verd√§chtigen widerspiegeln: </p><br><pre> <code class="hljs powershell">df[<span class="hljs-string"><span class="hljs-string">'ratio_of_poi_mail'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'from_poi_to_this_person'</span></span>]/df[<span class="hljs-string"><span class="hljs-string">'to_messages'</span></span>] df[<span class="hljs-string"><span class="hljs-string">'ratio_of_mail_to_poi'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'from_this_person_to_poi'</span></span>]/df[<span class="hljs-string"><span class="hljs-string">'from_messages'</span></span>]</code> </pre> <br><h2 id="otsev-lishnih-priznakov">  Unn√∂tige Zeichen herausfiltern </h2><br><p>  Im Toolkit der mit ML verbundenen Personen gibt es viele hervorragende Tools zur Auswahl der wichtigsten Funktionen (SelectKBest, SelectPercentile, VarianceThreshold usw.).  In diesem Fall wird RFECV verwendet, da es eine Kreuzvalidierung enth√§lt, mit der Sie die wichtigsten Merkmale berechnen und in allen Teilmengen der Stichprobe √ºberpr√ºfen k√∂nnen: </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split X_train, X_test, y_train, y_test = train_test_split(<span class="hljs-title"><span class="hljs-title">df</span></span>, <span class="hljs-title"><span class="hljs-title">target</span></span>, <span class="hljs-title"><span class="hljs-title">test_size</span></span>=0.2, <span class="hljs-title"><span class="hljs-title">random_state</span></span>=42)</code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RFECV <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier forest = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>) rfecv = RFECV(estimator=forest, cv=<span class="hljs-number"><span class="hljs-number">5</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>) rfecv = rfecv.fit(X_train, y_train) plt.figure() plt.xlabel("Number of features selected") plt.ylabel("Cross validation score of number of selected features") plt.plot(range(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(rfecv.grid_scores_) + <span class="hljs-number"><span class="hljs-number">1</span></span>), rfecv.grid_scores_, <span class="hljs-string"><span class="hljs-string">'--o'</span></span>) indices = rfecv.get_support() <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> = X_train.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>[indices] print(<span class="hljs-string"><span class="hljs-string">'The most important columns are {}'</span></span>.format(<span class="hljs-string"><span class="hljs-string">','</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>)))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fm/-7/oo/fm-7oo9gnbxhmpiw_vwldkgpwpi.png" alt="Bild"><br>  Wie Sie sehen k√∂nnen, hat RandomForestClassifier berechnet, dass nur 7 der 18 Attribute von Bedeutung sind.  Die Verwendung des Restes verringert die Genauigkeit des Modells. </p><br><pre> <code class="hljs pgsql">The most important <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> are bonus, deferred_income, other, exercised_stock_options, shared_receipt_with_poi, ratio_of_poi_mail, ratio_of_mail_to_poi</code> </pre> <br><p>  Diese 7 Funktionen werden in Zukunft verwendet, um das Modell zu vereinfachen und das Risiko einer Umschulung zu verringern: </p><br><ul><li>  Bonus </li><li>  deferred_income </li><li>  andere </li><li>  ausge√ºbte_Stock_Optionen </li><li>  shared_receipt_with_poi </li><li>  ratio_of_poi_mail </li><li>  ratio_of_mail_to_poi </li></ul><br><p>  √Ñndern Sie die Struktur der Trainings- und Testmuster f√ºr das zuk√ºnftige Modelltraining: </p><br><pre> <code class="hljs powershell">X_train = X_train[<span class="hljs-type"><span class="hljs-type">columns</span></span>] X_test = X_test[<span class="hljs-type"><span class="hljs-type">columns</span></span>]</code> </pre> <br><p>  Dies ist das Ende des ersten Teils, in dem die Verwendung des Enron-Datensatzes als Beispiel f√ºr eine Klassifizierungsaufgabe in ML beschrieben wird.  Basierend auf den Materialien aus dem Kurs Einf√ºhrung in maschinelles Lernen √ºber Udacity.  Es gibt auch ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Python-Notizbuch</a> , das die gesamte Abfolge der Aktionen widerspiegelt. </p><br><blockquote>  Der zweite Teil ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> <br></blockquote><p></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424891/">https://habr.com/ru/post/de424891/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424877/index.html">K√ºhlsystem f√ºr fl√ºssige Bremsen</a></li>
<li><a href="../de424879/index.html">Schnittstellenverf√ºgbarkeit Yandex Vortrag</a></li>
<li><a href="../de424881/index.html">Newtoo - 2018 eine vollwertige Browser-Engine von Grund auf neu entwickeln?</a></li>
<li><a href="../de424887/index.html">Wor√ºber Lida schweigt: Der Beginn der Karriere eines Entwicklers. Prinzipien oder wie man ein Middl wird</a></li>
<li><a href="../de424889/index.html">Blick in den Intel 8087 Coprozessor</a></li>
<li><a href="../de424893/index.html">Der Handwerker erstellte ein WiFi-Modul f√ºr den Macintosh SE / 30, ein Modell von 1989</a></li>
<li><a href="../de424895/index.html">Tippen: Ung√ºltige Zust√§nde unaussprechlich machen</a></li>
<li><a href="../de424897/index.html">Ein unerwartetes Treffen. Kapitel 18</a></li>
<li><a href="../de424899/index.html">Was Sie √ºber Audio h√∂ren sollten: 15 Podcasts</a></li>
<li><a href="../de424901/index.html">Die Zusammenfassung interessanter Materialien f√ºr den mobilen Entwickler # 272 (24. September - 30. September)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
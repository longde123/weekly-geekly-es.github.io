<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸŒ ğŸ’Ÿ ğŸ‘©ğŸ¾â€âš–ï¸ Keterbatasan algoritma pengenalan gambar ğŸ‘©ğŸ¾â€âš–ï¸ ğŸ ğŸ¤¦ğŸ¿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tidak, ini bukan tentang algoritme pengenalan gambar - ini tentang batasan penggunaannya, khususnya saat membuat AI. 

 Menurut pendapat saya, pengena...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Keterbatasan algoritma pengenalan gambar</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450422/"><img src="https://habrastorage.org/webt/wv/6j/k6/wv6jk6e24vdagqflmeorpmhjg-0.jpeg"><br><br>  Tidak, ini bukan tentang algoritme pengenalan gambar - ini tentang batasan penggunaannya, khususnya saat membuat AI. <br><br>  Menurut pendapat saya, pengenalan gambar visual oleh seseorang dan sistem komputer sangat berbeda - begitu banyak sehingga memiliki sedikit kesamaan.  Ketika seseorang berkata "Aku mengerti," dia benar-benar berpikir lebih dari yang dia lihat, yang tidak dapat dikatakan tentang sistem komputer yang dilengkapi dengan peralatan untuk pengenalan gambar. <br><br>  Saya tahu bahwa ide itu tidak baru, tetapi saya mengusulkan sekali lagi untuk memastikan validitasnya dengan contoh robot yang mengklaim memiliki kecerdasan.  Pertanyaan pengujiannya adalah: robot seperti apa yang harus dilihat dunia sekitarnya agar sepenuhnya menjadi seperti manusia? <br><a name="habracut"></a><br>  Tentu saja, robot harus mengenali benda.  Oh ya, algoritma mengatasi ini - melalui pelatihan pada sampel asli, seperti yang saya mengerti.  Tapi ini sangat kecil! <br><br>  <b>Saya</b> <br>  Pertama, setiap objek dari dunia sekitarnya terdiri dari banyak objek dan, pada gilirannya, adalah bagian dari objek lain.  Saya menyebut properti ini bersarang.  Tetapi bagaimana jika subjek tidak memiliki nama, sehingga tidak ada di dasar sampel asli yang digunakan untuk mempelajari algoritma - apa yang harus dikenali robot dalam kasus ini? <br><br>  Awan yang saya amati di jendela tidak memiliki nama bagian, meskipun jelas terdiri dari tepi dan tengah.  Namun, tidak ada istilah khusus untuk tepi dan tengah awan, tidak diciptakan.  Untuk menunjukkan objek yang tidak disebutkan namanya, saya menggunakan kata-kata verbal ("cloud" - jenis objek, "cloud edge" - kata-kata verbal), yang tidak termasuk dalam kemampuan algoritma pengenalan gambar. <br><br>  Ternyata algoritma tanpa blok logis tidak banyak berguna.  Jika algoritma mendeteksi bagian dari keseluruhan objek, itu tidak akan selalu dapat mencari tahu - sesuai, robot tidak akan dapat mengetahui - apa itu. <br><br>  <b>II</b> <br>  Kedua, daftar objek yang membentuk dunia tidak tertutup: itu terus diperbarui. <br><br>  Seseorang memiliki kemampuan untuk membangun objek-objek realitas, memberikan nama-nama pada objek-objek baru yang ditemukan, misalnya, spesies fauna.  Dia akan menyebut seekor kuda dengan kepala manusia dan batang tubuh sebagai centaur, tetapi untuk ini, dia pertama-tama akan menyadari bahwa makhluk itu memiliki kepala dan batang tubuh manusia, dan segala sesuatu yang lain adalah kuda, sehingga mengenali objek yang dilihat sebagai yang baru.  Inilah yang dilakukan otak manusia.  Dan algoritme, jika tidak ada input data, akan menentukan makhluk seperti itu sebagai orang atau kuda: tanpa beroperasi dengan karakteristik tipe, ia tidak akan dapat membuat kombinasinya. <br><br>  Agar robot menjadi seperti manusia, ia harus dapat mendefinisikan jenis objek baru untuknya dan menetapkan nama untuk jenis ini.  Dalam deskripsi tipe baru, karakteristik tipe yang diketahui akan muncul.  Dan jika robot tidak tahu caranya, mengapa kita membutuhkannya, begitu indah? <br><br>  Katakanlah kita mengirim robot pengintai ke Mars.  Robot melihat sesuatu yang tidak biasa, tetapi mampu mengidentifikasi objek secara eksklusif dalam istilah duniawi yang diketahui.  Apa yang akan memberi orang mendengarkan pesan verbal yang datang dari robot?  Kadang-kadang itu akan memberikan sesuatu, tentu saja (jika benda-benda Bumi ditemukan di Mars), dan dalam kasus lain, tidak ada (jika benda-benda Mars tidak mirip dengan benda-benda Bumi). <br><br>  Citra adalah masalah lain: seseorang sendiri akan dapat melihat segalanya, mengevaluasi dengan benar dan menamainya.  Hanya melalui bukan algoritma pengenalan gambar pra-terlatih, tetapi otak manusia Anda lebih licik. <br><br>  <b>III.</b> <br>  Ketiga, ada beberapa masalah dengan individualisasi objek. <br><br>  Dunia sekitar terdiri dari objek-objek tertentu.  Sebenarnya, Anda hanya dapat melihat objek tertentu.  Tetapi dalam beberapa kasus mereka perlu individual secara verbal, di mana salah satu nama pribadi digunakan ("Vasya Petrov"), atau indikasi sederhana dari objek tertentu, diucapkan atau tersirat ("tabel ini").  Apa yang saya sebut jenis objek ("orang", "tabel") hanyalah nama kolektif dari objek yang memiliki karakteristik umum tertentu. <br><br>  Algoritma pengenalan gambar, jika dilatih tentang sampel asli, akan dapat mengenali objek individual dan non-individual - ini bagus.  Pengenalan wajah di tempat-tempat ramai dan semua itu.  Yang buruk adalah bahwa algoritma seperti itu tidak akan mengerti objek mana yang harus diakui sebagai memiliki individualitas dan mana yang sama sekali tidak sepadan. <br><br>  Robot, sebagai pemilik AI, sesekali harus masuk ke pesan seperti: <br>  <i>- Oh, dan saya melihat wanita tua ini seminggu yang lalu!</i> <br><br>  Tetapi tidak ada gunanya menyalahgunakan replika semacam itu tentang bilah rumput, terutama karena ada kekhawatiran yang cukup kuat tentang kecukupan daya komputasi untuk melakukan tugas seperti itu. <br><br>  Tidak jelas bagi saya di mana garis tipis ditarik antara seorang wanita tua yang individual dan bilah-bilah rumput yang tak terhitung banyaknya, yang diindividuasikan oleh tidak kurang dari seorang wanita tua, tetapi tidak menarik bagi seseorang dari sudut pandang individualisasi.  Apa gambar yang dikenal dalam pengertian ini?  Nyaris tidak ada apa-apa - awal dari persepsi yang sulit dan menyakitkan tentang realitas di sekitarnya. <br><br>  <b>IV.</b> <br>  Keempat, dinamika objek, ditentukan oleh penataan ruang bersama mereka.  Ini, saya katakan, adalah sesuatu! <br><br>  Saya duduk di depan perapian di kursi berlengan yang dalam dan sekarang saya mencoba untuk bangun. <br>  <i>"Apa yang kamu lihat, robot?"</i> <br><br>  Dari sudut pandang kami sehari-hari, robot melihat saya bangkit dari kursi.  Apa yang harus dia jawab?  Mungkin jawaban yang relevan adalah: <br>  <i>"Aku melihatmu bangkit dari kursimu."</i> <br><br>  Untuk melakukan ini, robot harus tahu siapa saya, apa kursi itu dan apa artinya naik ... <br><br>  Algoritma pengenalan gambar setelah pengaturan yang sesuai akan dapat mengenali saya dan kursi, kemudian dengan membandingkan frame kita dapat menentukan fakta saling menghilangkan saya dari kursi, tetapi apa artinya "bangkit"?  Bagaimana "peningkatan" terjadi dalam realitas fisik? <br><br>  Jika saya sudah bangun dan berjalan pergi, semuanya cukup sederhana.  Setelah saya menjauh dari kursi, semua benda di kantor tidak mengubah posisi spasial satu sama lain, kecuali saya, yang semula duduk di kursi, dan setelah beberapa waktu jauh dari kursi.  Diijinkan untuk menyimpulkan bahwa saya meninggalkan kursi. <br><br>  Jika saya masih dalam proses bangun dari kursi, semuanya agak lebih rumit.  Saya masih di sebelah kursi, namun, posisi spasial relatif dari bagian tubuh saya telah berubah: <br><br><ul><li>  awalnya tibia dan trunk berada dalam posisi tegak, dan paha dalam posisi horizontal (saya sedang duduk), </li><li>  saat berikutnya, semua bagian tubuh berada dalam posisi tegak (saya berdiri). </li></ul><br>  Perhatikan perilaku saya sebagai pribadi, dia akan langsung menyimpulkan bahwa saya bangkit dari kursi.  Bagi seseorang, ini bukan kesimpulan logis sebagai persepsi visual: dia benar-benar akan melihat saya bangkit dari kursi saya, meskipun pada kenyataannya dia akan melihat perubahan posisi relatif dari bagian-bagian tubuh saya.  Namun, pada kenyataannya itu akan menjadi kesimpulan logis bahwa seseorang harus menjelaskan kepada robot, atau robot harus mengerjakan kesimpulan logis ini sendiri. <br><br>  Keduanya sama-sama sulit: <br><br><ul><li>  untuk memasuki informasi basis pengetahuan awal bahwa berdiri adalah perubahan berurutan dalam posisi spasial timbal balik dari bagian-bagian tertentu dari tubuh yang entah bagaimana tidak menginspirasi; </li><li>  tidak kurang bodoh untuk berharap bahwa robot, sebagai makhluk berpikir buatan, itu sendiri akan dengan cepat menebak bahwa perubahan posisi spasial timbal balik dari bagian-bagian tertentu dari tubuh yang dijelaskan di atas disebut berdiri.  Pada manusia, proses ini memakan waktu bertahun-tahun, berapa banyak yang dibutuhkan untuk robot? </li></ul><br>  Dan apa hubungannya dengan algoritma pengenalan gambar?  Mereka tidak akan pernah dapat menentukan bahwa saya bangkit dari kursi. <br><br>  <b>V.</b> <br>  "Berdiri" adalah konsep abstrak, ditentukan oleh perubahan karakteristik objek material, dalam hal ini, perubahan posisi spasial timbal balik mereka.  Dalam kasus umum, ini berlaku untuk konsep abstrak mana pun, karena konsep abstrak itu sendiri tidak ada di dunia material, tetapi sepenuhnya bergantung pada objek material.  Meskipun sering kita melihatnya sebagai diamati secara pribadi. <br><br>  Untuk menggerakkan rahang ke kanan atau kiri, tanpa membuka mulut - apa tindakan ini?  Tapi tidak mungkin.  Tidak diragukan lagi, dengan alasan bahwa gerakan seperti itu umumnya tidak seperti biasanya bagi seseorang.  Menggunakan algoritma yang dibahas, robot akan melihat sesuatu, tetapi apa gunanya?  Di dasar sampel awal, nama yang diinginkan akan tidak ada, dan akan sulit untuk menyebutkan aksi rekaman robot.  Dan untuk memberikan formulasi verbal terperinci untuk tindakan yang tidak disebutkan namanya, serta konsep-konsep abstrak lainnya, algoritma pengenalan gambar tidak dilatih. <br><br>  Bahkan, kami memiliki duplikat paragraf pertama, tidak hanya berkenaan dengan objek, tetapi untuk konsep-konsep abstrak.  Namun, sisa paragraf, sebelum dan sesudahnya, juga dapat dikaitkan dengan konsep abstrak - Saya hanya memperhatikan peningkatan tingkat kompleksitas ketika bekerja dengan abstraksi. <br><br>  <b>VI.</b> <br>  Keenam, hubungan kausal. <br><br>  Bayangkan Anda sedang menonton truk pikap yang melayang di jalan dan menghancurkan pagar.  Alasan bahwa pagar dihancurkan adalah gerakan pikap, dan pada gilirannya gerakan pikap menghasilkan penghancuran pagar. <br><br>  <i>- Aku melihatnya dengan mataku sendiri!</i> <br>  Ini adalah jawaban untuk pertanyaan apakah Anda melihat apa yang terjadi atau memikirkannya.  Dan apa yang sebenarnya Anda lihat? <br><br>  Beberapa item dalam dinamika tersebut: <br><br><ul><li>  sebuah truk pickup melaju di jalan </li><li>  pickup mendekati pagar, </li><li>  pagar telah berubah bentuk dan lokasi. </li></ul><br>  Berdasarkan persepsi visual, robot harus menyadari bahwa dalam kasus biasa, pagar tidak berubah bentuk dan lokasi: di sini ini terjadi sebagai akibat dari kontak dengan pickup.  Penyebab-subjek dan efek-subjek harus bersentuhan satu sama lain, jika tidak, kausalitas tidak ada dalam hubungan mereka. <br><br>  Meskipun di sini kita jatuh ke dalam perangkap logis, karena objek lain dapat bersentuhan dengan subjek-konsekuensi, bukan hanya subjek-alasan. <br><br>  Misalkan, pada saat pikap menabrak gagak di pagar.  Sebuah truk pickup dan gagak bersentuhan dengan pagar pada saat yang sama: bagaimana menentukan hasil kontak mana yang dihancurkan pagar? <br><br>  Mungkin menggunakan pengulangan: <br><br><ul><li>  jika dalam setiap kasus, ketika gagak duduk di pagar, pagar dihancurkan, gagak yang harus disalahkan; </li><li>  jika dalam setiap kasus ketika sebuah pickup menabrak pagar, pickup itu yang harus disalahkan. </li></ul><br>  Dengan demikian, kesimpulan bahwa pagar itu dihancurkan oleh sebuah pickup bukanlah pengamatan, tetapi hasil analisis berdasarkan pengamatan objek yang bersentuhan. <br><br>  Di sisi lain, aksi dapat dilakukan pada jarak jauh, misalnya aksi magnet pada benda besi.  Bagaimana robot menebak bahwa memindahkan magnet lebih dekat ke paku menyebabkan paku bergegas ke arah magnet?  Gambar visual tidak seperti ini: <br><br><ul><li>  magnet mendekat, tetapi tidak bersentuhan dengan kuku, </li><li>  pada saat yang sama, paku bergegas ke magnet atas inisiatifnya sendiri dan melakukan kontak dengannya. </li></ul><br>  Seperti yang Anda lihat, sangat sulit untuk melacak hubungan sebab-akibat, bahkan dalam kasus-kasus di mana saksi menyatakan dengan keyakinan besi bahwa ia melihatnya dengan matanya sendiri.  Algoritma pengenalan gambar tidak berdaya di sini. <br><br>  <b>VII.</b> <br>  Ketujuh dan terakhir, ini adalah pilihan tujuan persepsi visual. <br><br>  Gambar visual di sekitarnya dapat terdiri dari ratusan dan ribuan objek yang bersarang satu sama lain, banyak di antaranya secara konstan mengubah posisi spasial mereka dan karakteristik lainnya.  Jelas, robot tidak perlu melihat setiap helai rumput di lapangan, namun, seperti setiap wajah di jalan kota: Anda hanya perlu melihat yang penting, tergantung pada tugas yang dilakukan. <br><br>  Jelas, menyesuaikan algoritme pengenalan gambar dengan persepsi beberapa objek dan mengabaikan yang lain tidak akan berhasil, karena mungkin tidak diketahui sebelumnya apa yang harus diperhatikan dan apa yang harus diabaikan, terutama karena tujuan saat ini dapat berubah sepanjang jalan.  Suatu situasi mungkin muncul ketika Anda pertama kali perlu melihat ribuan objek bersarang satu sama lain - masing-masing secara harfiah - untuk menganalisis dan hanya kemudian mengeluarkan vonis objek mana yang penting untuk menyelesaikan masalah saat ini dan yang tidak menarik.  Beginilah cara orang memandang dunia di sekitarnya: ia hanya melihat yang penting, tidak memperhatikan peristiwa latar belakang yang tidak menarik.  Bagaimana dia berhasil adalah rahasia. <br><br>  Dan robot itu, bahkan dilengkapi dengan algoritme pengenalan gambar yang paling modern dan cerdik? ... Jika, selama serangan oleh alien Mars, dia memulai laporan dengan laporan cuaca dan melanjutkan dengan deskripsi lanskap baru yang tersebar di depannya, dia mungkin tidak punya waktu untuk melaporkan serangan itu sendiri. <br><br>  <b>Kesimpulan</b> <br><br><ol><li>  Pengenalan sederhana gambar visual tidak akan menggantikan mata manusia. </li><li>  Algoritma pengenalan gambar adalah alat bantu dengan cakupan yang sangat sempit. </li><li>  Agar robot dapat mulai tidak hanya berpikir, tetapi setidaknya melihatnya secara manusiawi, algoritma diperlukan tidak hanya untuk pengenalan pola, tetapi juga untuk pemikiran manusia yang sama tetapi juga tidak terjangkau. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id450422/">https://habr.com/ru/post/id450422/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id450398/index.html">Racun paling tak kenal takut</a></li>
<li><a href="../id450410/index.html">Terraformer - Infrastruktur Untuk Kode</a></li>
<li><a href="../id450416/index.html">Bagaimana penyedia VPN shareware menjual data Anda</a></li>
<li><a href="../id450418/index.html">Seni Membuat Model 3D Organik: Subdermal Shaders</a></li>
<li><a href="../id450420/index.html">Mengapa Tim Ilmu Pengetahuan Data Perlu Universal, Bukan Spesialis</a></li>
<li><a href="../id450426/index.html">2011 vs AM4. Dinosaurus vs Mamalia</a></li>
<li><a href="../id450428/index.html">Pengindeks dalam C # di bawah tenda: pengindeksan lebih baik dari Dow Jones</a></li>
<li><a href="../id450430/index.html">Apa itu Serangan Debu?</a></li>
<li><a href="../id450432/index.html">Nah, dimana dia?</a></li>
<li><a href="../id450436/index.html">Apa itu bootcamp pengkodean?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
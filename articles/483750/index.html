<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üññüèº üë¶üèΩ üêâ Traducci√≥n del libro de Andrew Un, Pasi√≥n por el aprendizaje autom√°tico, cap√≠tulos 30-32 üå§Ô∏è üôáüèº üçÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="cap√≠tulos anteriores 
 30. Interpretaci√≥n de la curva de aprendizaje: sesgo grande 


 Suponga que su curva de error en una muestra de validaci√≥n se v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traducci√≥n del libro de Andrew Un, Pasi√≥n por el aprendizaje autom√°tico, cap√≠tulos 30-32</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483750/"><p>  <a href="https://habr.com/ru/post/429832/">cap√≠tulos anteriores</a> </p><br><h1 id="30-interpretaciya-krivoy-obucheniya-bolshoe-smeschenie">  30. Interpretaci√≥n de la curva de aprendizaje: sesgo grande </h1><br><p>  Suponga que su curva de error en una muestra de validaci√≥n se ve as√≠: <br><img src="https://habrastorage.org/webt/fi/oy/fz/fioyfz5q4qb98cjga-aesqkuxea.png" alt="imagen"></p><br><p>  Ya hemos dicho que si un error de algoritmo en la muestra de validaci√≥n alcanza una meseta, es poco probable que alcance el nivel de calidad deseado simplemente agregando datos. </p><br><p>  Pero es dif√≠cil imaginar c√≥mo se ver√° la extrapolaci√≥n de la curva de la dependencia de la calidad del algoritmo en la muestra de validaci√≥n (error de desarrollo) al agregar datos.  Y si la muestra de validaci√≥n es peque√±a, entonces responder esta pregunta es a√∫n m√°s dif√≠cil debido al hecho de que la curva puede ser ruidosa (tener una gran extensi√≥n de puntos). </p><br><p>  Supongamos que agregamos a nuestro gr√°fico una curva de la dependencia de la magnitud del error en la cantidad de datos de la muestra de prueba y obtuvimos la siguiente imagen: </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/webt/gf/3e/m-/gf3em-wuh6vtvru1w-pyd2lypog.png" alt="imagen"></p><br><p>  Al observar estas dos curvas, puede estar absolutamente seguro de que agregar datos nuevos por s√≠ solo no dar√° el efecto deseado (no permitir√° aumentar la calidad del algoritmo).  ¬øD√≥nde se puede llegar a esta conclusi√≥n? <br>  Recordemos los siguientes dos puntos: </p><br><ul><li>  Si agregamos m√°s datos al conjunto de entrenamiento, el error del algoritmo en el conjunto de entrenamiento solo puede aumentar.  Por lo tanto, la l√≠nea azul de nuestro gr√°fico no cambiar√° o se arrastrar√° y se alejar√° del nivel de calidad deseado de nuestro algoritmo (l√≠nea verde). </li><li>  La l√≠nea de error roja en la muestra de validaci√≥n suele ser m√°s alta que la l√≠nea de error azul del algoritmo en la muestra de entrenamiento.  Por lo tanto, bajo cualquier circunstancia concebible, agregar datos no conducir√° a una disminuci√≥n adicional en la l√≠nea roja, no lo acercar√° al nivel de error deseado.  Esto es casi imposible, dado que incluso el error en la muestra de entrenamiento es mayor de lo deseado. </li></ul><br><p>  La consideraci√≥n de ambas curvas de la dependencia del error del algoritmo en la cantidad de datos en las muestras de validaci√≥n y entrenamiento en el mismo gr√°fico le permite extrapolar con mayor confianza la curva de error del algoritmo de aprendizaje a partir de la cantidad de datos en la muestra de validaci√≥n. </p><cut></cut><br><p>  Supongamos que tenemos una estimaci√≥n de la calidad deseada del algoritmo en forma de un nivel √≥ptimo de errores en nuestro sistema.  En este caso, los gr√°ficos anteriores son una ilustraci√≥n de un caso est√°ndar de "libro de texto" de c√≥mo se ve la curva de aprendizaje con un alto nivel de sesgo removible.  En el tama√±o de muestra de entrenamiento m√°s grande, presumiblemente correspondiente a todos los datos a nuestra disposici√≥n, existe una gran brecha entre el error del algoritmo en la muestra de entrenamiento y la calidad deseada del algoritmo, lo que indica un alto nivel de sesgo evitado.  Adem√°s, la brecha entre el error en la muestra de entrenamiento y el error en la muestra de validaci√≥n es peque√±a, lo que indica una peque√±a extensi√≥n. </p><br><p>  Anteriormente, discutimos los errores de los algoritmos entrenados en muestras de entrenamiento y validaci√≥n solo en el punto m√°s a la derecha sobre el gr√°fico, que corresponde al uso de todos los datos de entrenamiento que tenemos.  La curva de las dependencias del error en la cantidad de datos de la muestra de entrenamiento, construida para diferentes tama√±os de la muestra utilizada para el entrenamiento, nos da una imagen m√°s completa de la calidad del algoritmo entrenado en diferentes tama√±os de la muestra de entrenamiento. </p><cut></cut><br><h1 id="31-interpretaciya-krivoy-obucheniya-ostalnye-sluchai">  31. Interpretaci√≥n de la curva de aprendizaje: otros casos </h1><br><p>  Considere la curva de aprendizaje: <br><img src="https://habrastorage.org/webt/mh/q1/ws/mhq1wskh19gbk_pu7hifvuhodg4.png" alt="imagen"></p><br><p>  ¬øHay un alto sesgo, un alto an√°lisis, o ambos a la vez? </p><br><p>  La curva de error azul en los datos de entrenamiento es relativamente baja, la curva de error roja en los datos de validaci√≥n es significativamente m√°s alta que el error azul en los datos de entrenamiento.  Por lo tanto, en este caso, el sesgo es peque√±o, pero la propagaci√≥n es grande.  Agregar m√°s datos de entrenamiento puede ayudar a cerrar la brecha entre el error en la muestra de validaci√≥n y el error en la muestra de entrenamiento. </p><cut></cut><br><p>  Ahora considere este cuadro: </p><br><p><img src="https://habrastorage.org/webt/oy/uv/dg/oyuvdgzaf9bj_fvz8ywfpjn4zgq.png" alt="imagen"></p><br><p>  En este caso, el error en la muestra de entrenamiento es grande; es significativamente m√°s alto que el algoritmo correspondiente al nivel de calidad deseado.  El error en la muestra de validaci√≥n tambi√©n es significativamente mayor que el error en la muestra de entrenamiento.  Por lo tanto, estamos lidiando simult√°neamente con un gran sesgo y dispersi√≥n.  Debe buscar formas de reducir, compensar y dispersar su algoritmo. </p><br><h1 id="32-postroenie-krivyh-obucheniya">  32. Construyendo curvas de aprendizaje </h1><br><p>  Supongamos que tiene una muestra de entrenamiento muy peque√±a, que consta de solo 100 ejemplos.  Usted entrena su algoritmo usando un subconjunto de 10 ejemplos seleccionado al azar, luego de 20 ejemplos, luego de 30 y as√≠ sucesivamente a 100, aumentando el n√∫mero de ejemplos con un intervalo de diez ejemplos.  Luego, utilizando estos 10 puntos, construye su curva de aprendizaje.  Puede encontrar que la curva parece ruidosa (valores m√°s altos o m√°s bajos de lo esperado) para muestras de entrenamiento m√°s peque√±as. </p><br><p>  Cuando entrena el algoritmo con solo 10 ejemplos seleccionados al azar, es posible que no tenga suerte y esto resultar√° ser una submuestra de entrenamiento particularmente "mala" con una mayor proporci√≥n de ejemplos ambiguos / incorrectamente marcados.  O, por el contrario, puede encontrar una submuestra de entrenamiento particularmente "buena".  La presencia de una peque√±a muestra de entrenamiento implica que el valor de los errores en las muestras de validaci√≥n y entrenamiento puede estar sujeto a fluctuaciones aleatorias. </p><cut></cut><br><p>  Si los datos utilizados para su aplicaci√≥n que utilizan el aprendizaje autom√°tico est√°n fuertemente sesgados hacia una clase (como con el problema de clasificaci√≥n de gatos, en el que la proporci√≥n de ejemplos negativos es mucho mayor que la proporci√≥n de positivos), o si estamos tratando con una gran cantidad de clases (como reconocimiento de 100 especies diferentes de animales), entonces tambi√©n aumenta la posibilidad de obtener una muestra de entrenamiento particularmente "no representativa" o pobre.  Por ejemplo, si el 80% de sus ejemplos son ejemplos negativos (y = 0), y solo el 20% son ejemplos positivos (y = 1), entonces hay una buena posibilidad de que un subconjunto de entrenamiento de 10 ejemplos contenga solo ejemplos negativos, en este caso muy Es dif√≠cil obtener algo razonable del algoritmo entrenado. </p><br><p>  Si, debido al ruido de la curva de aprendizaje en la muestra de capacitaci√≥n, es dif√≠cil hacer una evaluaci√≥n de las tendencias, se pueden proponer las siguientes dos soluciones: </p><br><ul><li><p>  En lugar de entrenar solo un modelo para 10 ejemplos de entrenamiento, seleccionando con reemplazo varias (digamos 3 a 10) diferentes submuestras de entrenamiento al azar de la muestra inicial que consiste en 100 ejemplos.  Entrene el modelo en cada uno de ellos y calcule para cada uno de estos modelos el error en la muestra de validaci√≥n y entrenamiento.  Cuente y trace el error promedio en las muestras de capacitaci√≥n y validaci√≥n. </p><cut></cut><br><p>  <u><em>Comentario del autor:</em></u> <em>una muestra con un reemplazo significa lo siguiente: seleccione aleatoriamente los primeros 10 ejemplos diferentes de 100 para formar la primera submuestra de capacitaci√≥n.</em>  <em>Luego, para formar la segunda submuestra de entrenamiento, nuevamente tomamos 10 ejemplos, pero sin tener en cuenta los seleccionados en la primera submuestra (nuevamente de los cien ejemplos completos).</em>  <em>Por lo tanto, un ejemplo espec√≠fico puede aparecer en ambas submuestras.</em>  <em>Esto distingue una muestra con un reemplazo de una muestra sin reemplazo; en el caso de una muestra sin reemplazo, la segunda submuestra de entrenamiento se seleccionar√≠a de solo 90 ejemplos que no caen en la primera submuestra.</em>  <em>En la pr√°ctica, el m√©todo de selecci√≥n de ejemplos con o sin sustituci√≥n no deber√≠a ser de gran importancia, pero la selecci√≥n de ejemplos con sustituci√≥n es una pr√°ctica com√∫n.</em> </p><br></li><li><p>  Si su muestra de entrenamiento est√° sesgada hacia una de las clases, o si incluye muchas clases, elija una submuestra "equilibrada" que consta de 10 ejemplos de entrenamiento, seleccionados al azar de 100 muestras de muestra.  Por ejemplo, puede estar seguro de que 2/10 ejemplos son positivos y 8/10 negativos.  Para resumir, puede estar seguro de que la proporci√≥n de ejemplos de cada clase en el conjunto de datos observados es lo m√°s cercana posible a su participaci√≥n en la muestra de entrenamiento inicial. </p><cut></cut><br><p>  No me molestar√≠a con ninguno de estos m√©todos hasta que la representaci√≥n gr√°fica de las curvas de error lleve a la conclusi√≥n de que estas curvas son excesivamente ruidosas, lo que no nos permite ver tendencias comprensibles.  Si tiene una muestra de entrenamiento grande, digamos unos 10,000 ejemplos y la distribuci√≥n de sus clases no es muy sesgada, es posible que no necesite estos m√©todos. </p><br></li></ul><br><p>  Finalmente, construir una curva de aprendizaje puede ser costoso desde un punto de vista computacional: por ejemplo, necesita entrenar diez modelos, en los primeros 1000 ejemplos, en el segundo 2000, y as√≠ sucesivamente hasta que el √∫ltimo contenga 10,000 ejemplos.  El entrenamiento modelo en peque√±as cantidades de datos es mucho m√°s r√°pido que el entrenamiento modelo en muestras grandes.  Por lo tanto, en lugar de distribuir uniformemente los tama√±os de las submuestras de entrenamiento a lo largo de una escala lineal, como se describi√≥ anteriormente (1000, 2000, 3000, ..., 10000), puede entrenar modelos con un aumento no lineal en el n√∫mero de ejemplos, por ejemplo, 1000, 2000, 4000, 6000 y 10,000 ejemplos.  De todos modos, deber√≠a darle una comprensi√≥n clara de la tendencia de la dependencia de la calidad del modelo en la cantidad de ejemplos de capacitaci√≥n en las curvas de aprendizaje.  Por supuesto, esta t√©cnica es relevante solo si el costo computacional de la capacitaci√≥n de modelos adicionales es alto. </p><cut></cut><br><p>  <a href="https://habr.com/ru/post/484680/"><em>continuaci√≥n</em></a> </p></div></div><p>Source: <a href="https://habr.com/ru/post/483750/">https://habr.com/ru/post/483750/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../483736/index.html">B√∫squeda inversa de im√°genes: una gu√≠a de la agencia de detectives Bellingcat</a></li>
<li><a href="../483742/index.html">Busca errores como una forma de vida</a></li>
<li><a href="../483744/index.html">Venta de a√±o nuevo antiguo</a></li>
<li><a href="../483746/index.html">Estaci√≥n de puerta de enlace: paso a la l√≠nea lunar, acceso a la estaci√≥n marciana</a></li>
<li><a href="../483748/index.html">El descuido de los usuarios de PayPal que les permite robar su cuenta y dinero [Solucionado]</a></li>
<li><a href="../483752/index.html">D√≥nde ir: los pr√≥ximos eventos gratuitos para especialistas de TI en Mosc√∫ (del 14 al 18 de enero)</a></li>
<li><a href="../483754/index.html">¬øC√≥mo medir la mejora del equipo?</a></li>
<li><a href="../483756/index.html">Hacemos solicitudes HTTP, degradamos con gracia (y no una sola brecha)</a></li>
<li><a href="../483758/index.html">Las 10 nuevas empresas de desarrollo de aplicaciones m√≥viles pueden asociarse en 2020</a></li>
<li><a href="../483762/index.html">GitLab 12.6 lanzado con calificaciones de seguridad del proyecto y materiales de lanzamiento</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
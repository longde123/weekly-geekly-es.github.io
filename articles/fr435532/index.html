<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèº üë©üèº‚Äçüé® üïµüèº Tornado vs Aiohttp: un voyage dans le d√©sert des frameworks asynchrones üìµ üå©Ô∏è üîë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut Je m'appelle Dima et je suis en Python depuis un certain temps maintenant. Aujourd'hui, je veux vous montrer les diff√©rences entre deux cadres a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tornado vs Aiohttp: un voyage dans le d√©sert des frameworks asynchrones</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/435532/">  Salut  Je m'appelle Dima et je suis en Python depuis un certain temps maintenant.  Aujourd'hui, je veux vous montrer les diff√©rences entre deux cadres asynchrones - Tornado et Aiohttp.  Je vais raconter l'histoire du choix entre les cadres de notre projet, en quoi les coroutines de Tornado et d'AsyncIO diff√®rent, je vais montrer des rep√®res et donner quelques conseils utiles sur la fa√ßon d'entrer dans la nature des cadres et d'en sortir avec succ√®s. <br><br><img src="https://habrastorage.org/webt/df/uz/jm/dfuzjmbmzyoqjfd87asllltamtk.png"><br><a name="habracut"></a><br>  Comme vous le savez, Avito est un service publicitaire assez important.  Nous avons beaucoup de donn√©es et de charge, 35 millions d'utilisateurs chaque mois et 45 millions d'annonces actives par jour.  Je travaille en tant que conseiller technique d'un groupe d'√©laboration de recommandations.  Mon √©quipe √©crit des microservices, nous en avons maintenant une vingtaine.  Une charge s'accumule sur tout cela - comme 5k RPS. <br><br><h2>  Choisir un cadre asynchrone </h2><br>  Je vais d'abord vous dire comment nous en sommes arriv√©s l√† o√π nous en sommes maintenant.  En 2015, nous devions choisir un framework asynchrone, car nous savions: <br><br><ul><li>  que vous devez faire beaucoup de demandes √† d'autres microservices: http, json, rpc; </li><li>  dont vous aurez besoin de collecter des donn√©es de diff√©rentes sources tout le temps: Redis, Postgres, MongoDB. </li></ul><br>  Ainsi, nous avons beaucoup de t√¢ches r√©seau, et l'application est principalement occup√©e par les entr√©es / sorties.  La version actuelle de python √† cette √©poque √©tait la 3.4, async et wait n'apparaissaient pas encore.  Aiohttp √©tait √©galement - dans la version 0.x.  Facebook Asynchronous Tornado est apparu en 2010.  Un grand nombre de pilotes de base de donn√©es sont √©crits pour lui dont nous avons besoin.  Tornado a montr√© des r√©sultats stables sur les benchmarks.  Ensuite, nous avons arr√™t√© notre choix sur ce cadre. <br><br>  Trois ans plus tard, nous avons beaucoup compris. <br><br>  Tout d'abord, Python 3.5 est sorti avec des m√©canismes asynchrones / attendent.  Nous avons compris quelle est la diff√©rence entre le rendement et le rendement et comment Tornado est compatible avec l'attente (spoiler: pas tr√®s bon). <br>  Deuxi√®mement, nous avons rencontr√© d'√©tranges probl√®mes de performances avec une grande quantit√© de coroutine dans le planificateur, m√™me lorsque le processeur n'est pas compl√®tement occup√©. <br>  Troisi√®mement, nous avons constat√© que lors de l'ex√©cution d'un grand nombre de demandes http vers d'autres services Tornado, vous devez √™tre particuli√®rement amical avec le r√©solveur DNS asynchrone, il ne respecte pas les d√©lais d'expiration pour √©tablir une connexion et envoyer la demande que nous sp√©cifions.  Et en g√©n√©ral, la meilleure m√©thode pour faire des requ√™tes http dans Tornado est curl, ce qui est plut√¥t √©trange en soi. <br><br>  Dans son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">discours √† PyCon Russie 2018,</a> Andrei Svetlov a d√©clar√©: ¬´Si vous voulez √©crire une sorte d'application Web asynchrone, veuillez simplement √©crire asynchrone, attendez.  Boucle d'√©v√©nement, probablement, vous n'en aurez pas besoin du tout bient√¥t.  N'entrez pas dans la nature des frameworks pour ne pas vous perdre.  N'utilisez pas de primitives de bas niveau et tout ira bien pour vous ... ".  Au cours des trois derni√®res ann√©es, malheureusement, nous avons d√ª monter assez souvent √† l'int√©rieur de Tornado, apprendre beaucoup de choses int√©ressantes √† partir de l√† et voir de gigantesques plateaux pour 30 √† 40 appels. <br><br><h2>  Rendement vs rendement de </h2><br>  L'un des plus gros probl√®mes √† comprendre en python asynchrone est la diff√©rence entre le rendement et le rendement. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Guido Van Rossum a √©crit</a> plus √† ce sujet.  Je joins la traduction avec de l√©g√®res abr√©viations. <br><blockquote>  On m'a demand√© √† plusieurs reprises pourquoi PEP 3156 insiste pour utiliser yield-from au lieu de yield, ce qui exclut la possibilit√© de r√©troportage en Python 3.2 ou m√™me 2.7. <br>  (...) <br>  chaque fois que vous voulez un r√©sultat futur, vous utilisez le rendement. <br>  Ceci est impl√©ment√© comme suit.  La fonction contenant yield est (√©videmment) un g√©n√©rateur, donc il doit y avoir une sorte de code it√©ratif.  Appelons-le un planificateur.  En fait, l'ordonnanceur n'it√®re pas au sens classique (avec for-loop);  au lieu de cela, il prend en charge deux futures collections. <br><br>  J'appellerai la premi√®re collection une s√©quence "ex√©cutable".  Tel est l'avenir, dont les r√©sultats sont disponibles.  Bien que cette liste ne soit pas vide, le planificateur s√©lectionne un √©l√©ment et effectue une √©tape d'it√©ration.  Cette √©tape appelle la m√©thode du g√©n√©rateur .send () avec le r√©sultat du futur (qui peut √™tre des donn√©es qui viennent d'√™tre lues depuis le socket);  dans le g√©n√©rateur, ce r√©sultat appara√Æt comme la valeur de retour de l'expression de rendement.  Lorsque send () renvoie un r√©sultat ou se termine, le planificateur analyse le r√©sultat (qui peut √™tre StopIteration, une autre exception ou une sorte d'objet). <br>  (Si vous √™tes confus, vous devriez probablement lire sur le fonctionnement des g√©n√©rateurs, en particulier la m√©thode .send (). Peut-√™tre que PEP 342 est un bon point de d√©part). <br><br>  (...) <br><br>  la deuxi√®me future collection prise en charge par le planificateur est constitu√©e du futur, qui attend toujours des E / S.  Ils sont en quelque sorte transmis √† select / poll / shell, etc.  qui donne un rappel lorsque le descripteur de fichier est pr√™t pour les E / S.  Le rappel effectue en fait l'op√©ration d'E / S demand√©e par future, d√©finit la valeur future r√©sultante sur le r√©sultat de l'op√©ration d'E / S et d√©place le futur vers la file d'attente d'ex√©cution. <br><br>  (...) <br><br>  Maintenant, nous avons atteint le plus int√©ressant.  Supposons que vous √©crivez un protocole complexe.  Dans votre protocole, vous lisez des octets √† partir d'un socket en utilisant la m√©thode recv ().  Ces octets parviennent au tampon.  La m√©thode recv () est envelopp√©e dans un shell asynchrone, qui d√©finit les E / S et renvoie l'avenir, qui est ex√©cut√© lorsque les E / S sont termin√©es, comme je l'ai expliqu√© ci-dessus.  Supposons maintenant qu'une autre partie de votre code veuille lire les donn√©es du tampon une ligne √† la fois.  Supposons que vous ayez utilis√© la m√©thode readline ().  Si la taille du tampon est sup√©rieure √† la longueur de ligne moyenne, votre m√©thode readline () peut simplement obtenir la ligne suivante du tampon sans bloquer;  mais parfois le tampon ne contient pas une ligne enti√®re, et readline () appelle √† son tour recv () sur le socket. <br><br>  Question: readline () devrait-il retourner dans le futur ou non?  Ce ne serait pas tr√®s bien s'il renvoyait parfois une cha√Æne d'octets, et parfois futur, for√ßant l'appelant √† effectuer une v√©rification de type et un rendement conditionnel.  Donc, la r√©ponse est que readline () devrait toujours retourner √† l'avenir.  Lorsque readline () est appel√©, il v√©rifie le tampon et s'il y trouve au moins une ligne enti√®re, il cr√©e un futur, d√©finit le r√©sultat futur d'une ligne prise dans le tampon et retourne futur.  Si le tampon n'a pas de ligne enti√®re, il lance les E / S et les attend, et lorsque les E / S sont termin√©es, il recommence. <br><br>  (...) <br><br>  Mais maintenant, nous cr√©ons de nombreux futurs qui ne n√©cessitent pas de blocage des E / S, mais qui forcent toujours un appel au planificateur, car readline () renvoie l'avenir, le rendement est requis de l'appelant, ce qui signifie un appel au planificateur. <br>  Le planificateur peut transf√©rer le contr√¥le directement √† la coroutine s'il voit que le futur, qui est d√©j√† termin√©, est affich√©, ou peut retourner le futur √† la file d'attente d'ex√©cution.  Ce dernier ralentira consid√©rablement le travail (√† condition qu'il y ait plus d'une coroutine ex√©cutable), car non seulement l'attente √† la fin de la file d'attente est requise, mais la localit√© de la m√©moire (si elle existe) est probablement √©galement perdue. <br><br>  (...) <br><br>  L'effet net de tout cela est que les auteurs de coroutine doivent conna√Ætre l'avenir de rendement, et donc il y a une plus grande barri√®re psychologique √† la r√©organisation du code complexe en coroutines plus lisibles - beaucoup plus forte que la r√©sistance existante, car les appels de fonction en Python sont assez lents.  Et je me souviens d'une conversation avec Glyph que la vitesse est importante dans une structure d'E / S asynchrone typique. <br>  Comparons maintenant cela avec le rendement de. <br><br>  (...) <br><br>  Vous avez peut-√™tre entendu dire que ¬´rendement de S¬ª est √† peu pr√®s √©quivalent √† ¬´pour i dans S: rendement i¬ª.  Dans le cas le plus simple, c'est vrai, mais cela ne suffit pas pour comprendre la coroutine.  Tenez compte des √©l√©ments suivants (ne pensez pas encore aux E / S asynchrones): <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">driver</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g)</span></span></span><span class="hljs-function">:</span></span> print(next(g)) g.send(<span class="hljs-number"><span class="hljs-number">42</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> val = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-string"><span class="hljs-string">'okay'</span></span> print(val) driver(gen1())</code> </pre> <br>  Ce code imprime deux lignes contenant ¬´okay¬ª et ¬´42¬ª (puis produit une StopIteration non g√©r√©e, que vous pouvez supprimer en ajoutant du rendement √† la fin de gen1).  Vous pouvez voir ce code en action sur pythontutor.com sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> . <br><br>  Consid√©rez maintenant ce qui suit: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gen1() driver(gen2())</code> </pre><br>  Cela fonctionne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exactement de la m√™me mani√®re</a> .  Maintenant, r√©fl√©chis.  Comment √ßa marche?  L'extension yield-from simple dans la boucle for ne peut pas √™tre utilis√©e ici, car dans ce cas, le code retournerait None.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">(Essayez-le)</a> .  Yield-from agit comme un "canal transparent" entre le pilote et gen1.  Autrement dit, lorsque gen1 donne la valeur ¬´okay¬ª, il laisse gen2, via yield-from, au pilote, et lorsque le pilote renvoie 42 √† gen2, cette valeur est renvoy√©e via yield-from √† gen1 (o√π elle devient le r√©sultat du rendement ) <br><br>  La m√™me chose se produirait si le conducteur jetait une erreur dans le g√©n√©rateur: l'erreur passe par le rendement du g√©n√©rateur interne qui la traite.  Par exemple: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">throwing_driver</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g)</span></span></span><span class="hljs-function">:</span></span> print(next(g)) g.throw(RuntimeError(<span class="hljs-string"><span class="hljs-string">'booh'</span></span>)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: val = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-string"><span class="hljs-string">'okay'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> RuntimeError <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> exc: print(exc) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: print(val) <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> throwing_driver(gen1())</code> </pre><br>  Le code donnera "okay" et "bah", ainsi que le code suivant: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gen1() <span class="hljs-comment"><span class="hljs-comment"># unchanged throwing_driver(gen2())</span></span></code> </pre> <br>  (Voir ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">goo.gl/8tnjk</a> ) <br><br>  Maintenant, j'aimerais introduire des graphiques simples (ASCII) afin de pouvoir parler de ce type de code.  J'utilise [f1 -&gt; f2 -&gt; ... -&gt; fN) pour repr√©senter la pile avec f1 en bas (trame d'appel la plus ancienne) et fN en haut (trame d'appel la plus r√©cente), o√π chaque √©l√©ment de la liste est un g√©n√©rateur, et -&gt; sont des rendements de .  Le premier exemple, le pilote (gen1 ()) n'a pas de rendement, mais il a un g√©n√©rateur gen1, il ressemble donc √† ceci: <br><br><pre> <code class="python hljs">[ gen1 )</code> </pre> <br>  Dans le deuxi√®me exemple, gen2 appelle gen1 en utilisant yield-from, il ressemble donc √† ceci: <br><br><pre> <code class="python hljs">[ gen2 -&gt; gen1 )</code> </pre> <br>  J'utilise la notation math√©matique de l'intervalle semi-ouvert [...] pour montrer qu'une autre trame peut √™tre ajout√©e √† droite lorsque le g√©n√©rateur le plus √† droite utilise yield-from pour appeler un autre g√©n√©rateur, tandis que l'extr√©mit√© gauche est plus ou moins fixe.  La fin gauche correspond √† ce que voit le pilote (c'est-√†-dire le planificateur). <br><br>  Je suis maintenant pr√™t √† revenir √† l'exemple readline ().  Nous pouvons r√©√©crire readline () comme un g√©n√©rateur qui appelle read (), un autre g√©n√©rateur utilisant yield-from;  ce dernier, √† son tour, appelle recv (), qui fait les entr√©es / sorties r√©elles de la socket.  √Ä notre gauche se trouve l'application, que nous consid√©rons √©galement comme un g√©n√©rateur qui appelle readline (), utilisant √† nouveau le rendement de.  Le sch√©ma est le suivant: <br><br><pre> <code class="python hljs">[ app -&gt; readline -&gt; read -&gt; recv )</code> </pre> <br>  Maintenant, le g√©n√©rateur recv () d√©finit les E / S, les lie au futur et les transmet au planificateur en utilisant * yield * (et non yield-from!).  future va vers la gauche le long des deux fl√®ches de rendement de l'ordonnanceur (situ√©es √† gauche de "[").  Notez que l'ordonnanceur ne sait pas qu'il contient une pile de g√©n√©rateurs;  tout ce qu'il sait, c'est qu'il contient le g√©n√©rateur le plus √† gauche et qu'il vient d'√©mettre un avenir.  Lorsque les E / S sont termin√©es, le planificateur d√©finit le r√©sultat futur et le renvoie au g√©n√©rateur;  le r√©sultat se d√©place vers la droite le long des deux fl√®ches de d√©part vers le g√©n√©rateur recv, qui re√ßoit les octets qu'il voulait lire depuis le socket comme r√©sultat de rendement. <br><br>  En d'autres termes, le planificateur de cadre de rendement √† partir de g√®re les op√©rations d'E / S tout comme le planificateur de cadre bas√© sur le rendement que j'ai d√©crit pr√©c√©demment.  * Mais: * il n'a pas √† se soucier de l'optimisation lorsque le futur est d√©j√† ex√©cut√©, puisque l'ordonnanceur ne participe pas au transfert de contr√¥le entre readline () et read () ou entre read () et recv (), et vice versa.  Par cons√©quent, le planificateur ne participe pas du tout lorsque app () appelle readline () et readline () peut satisfaire la demande du tampon (sans appeler read ()) - l'interaction entre app () et readline () dans ce cas est compl√®tement trait√©e par l'interpr√©teur de bytecode Python  L'ordonnanceur peut √™tre plus simple et le nombre de futurs cr√©√©s et g√©r√©s par l'ordonnanceur est moindre, car il n'y a pas de futurs cr√©√©s et d√©truits √† chaque appel de coroutine.  Les seuls futurs qui restent n√©cessaires sont ceux qui repr√©sentent les E / S r√©elles, par exemple, cr√©√©es par recv (). <br><br>  Si vous avez lu jusqu'√† ce point, vous m√©ritez une r√©compense.  J'ai omis de nombreux d√©tails d'impl√©mentation, mais l'illustration ci-dessus refl√®te essentiellement correctement l'image. <br><br>  Je voudrais √©galement souligner une autre chose.  * Vous pouvez * faire une partie du code utiliser yield-from, et l'autre partie utiliser yield.  Mais le rendement exige que chaque maillon de la cha√Æne ait un avenir, pas seulement une coroutine.  Puisqu'il y a plusieurs avantages √† utiliser le rendement de, je veux que l'utilisateur n'ait pas √† se rappeler quand utiliser le rendement, et quand le rendement de, il est plus facile de toujours utiliser le rendement de.  Une solution simple permet m√™me √† recv () d'utiliser le rendement de pour transmettre les futures E / S au planificateur: la m√©thode __iter__ est en fait le g√©n√©rateur que le futur √©met. <br><br>  (...) <br><br>  Et encore une chose.  Quelle valeur le rendement de retour?  Il s'av√®re que c'est la valeur de retour du g√©n√©rateur * externe *. <br><br>  (...) <br><br>  Ainsi, bien que les fl√®ches lient les cadres gauche et droit √† la cible * de rendement *, elles transmettent √©galement les valeurs de retour habituelles de la mani√®re habituelle, une image de pile √† la fois.  Les exceptions sont d√©plac√©es de la m√™me mani√®re;  bien s√ªr, √† chaque niveau, essayez / except est n√©cessaire pour les attraper. <br></blockquote>  Il s'av√®re que le rendement est √† peu pr√®s le m√™me que celui attendu. <br><br><h2>  rendement de vs async </h2><br><table><tbody><tr><td><p>  def coro () ^ </p><p>  y = rendement d'un </p></td><td>  async def async_coro (): <p>  y = attendre un </p></td></tr><tr><td>  0 load_global </td><td>  0 load_global </td></tr><tr><td>  2 get_yield_from_iter </td><td><p>  2 get_awaitable </p></td></tr><tr><td>  4 load_const </td><td><p>  4 load_const </p></td></tr><tr><td>  6 yield_from </td><td>  6 yield_from </td></tr><tr><td>  8 store_fast </td><td><p>  8 store_fast </p></td></tr><tr><td>  10 load_const </td><td>  10 load_const <br></td></tr><tr><td>  12 return_value </td><td>  12 return_value </td></tr></tbody></table><br><br>  Les deux coroutines de l'ancienne et de la nouvelle √©cole n'ont qu'une seule diff√©rence mineure: obtenir un rendement de iter vs get attendable. <br><br>  Pourquoi tout cela?  La tornade utilise un rendement simple.  Avant la version 5, il connecte toute cette cha√Æne d'appels via le rendement, ce qui est peu compatible avec le nouveau paradigme cool yield from / wait. <br><br><h2>  La r√©f√©rence asynchrone la plus simple </h2><br>  Il est difficile de trouver un tr√®s bon framework, en le choisissant uniquement selon des tests synth√©tiques.  Dans la vraie vie, beaucoup de choses peuvent mal tourner. <br><br>  J'ai pris Aiohttp version 3.4.4, Tornado 5.1.1, uvloop 0.11, pris le processeur serveur Intel Xeon, CPU E5 v4, 3,6 GHz, et avec Python 3.6.5, j'ai commenc√© √† v√©rifier la comp√©titivit√© des serveurs Web. <br><br>  Le probl√®me typique que nous r√©solvons √† l'aide de microservices, et qui fonctionne en mode asynchrone, ressemble √† ceci.  Nous recevrons des demandes.  Pour chacun d'eux, nous ferons une demande √† un microservice, obtiendrons des donn√©es √† partir de l√†, puis irons √† deux ou trois microservices, √©galement de mani√®re asynchrone, puis √©crireons les donn√©es quelque part dans la base de donn√©es et retournerons le r√©sultat.  Il s'av√®re que de nombreux points nous attendent. <br><br>  Nous effectuons une op√©ration plus simple.  Nous allumons le serveur, le faisons dormir 50 ms.  Cr√©ez une coroutine et compl√©tez-la.  Nous n'aurons pas un tr√®s grand RPS (ce n'est peut-√™tre pas un ordre de grandeur similaire √† ce qui est vu dans les benchmarks enti√®rement synth√©tiques) avec un d√©lai acceptable en raison du fait que beaucoup de coroutine tourneront simultan√©ment sur un serveur comp√©titif. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@tornado.gen.coroutine def old_school_work(): yield tornado.gen.sleep(SLEEP_TIME) async def work(): await tornado.gen.sleep(SLEEP_TIME)</span></span></code> </pre> <br>  Charger - GET requ√™tes HTTP.  Dur√©e - 300s, 1s - √©chauffement, 5 r√©p√©titions de la charge. <br><br><img src="https://habrastorage.org/webt/ep/mq/fw/epmqfwh6bv_vyfu8tymtelvohos.png"><br><br>  <i>R√©sultats sur les centiles du temps de r√©ponse du service.</i> <br><br><div class="spoiler">  <b class="spoiler_title">Que sont les centiles?</b> <div class="spoiler_text">  Vous avez un grand nombre de num√©ros.  Le 95e centile X signifie que 95% des valeurs de cet √©chantillon sont inf√©rieures √† X. Avec une probabilit√© de 5%, votre nombre sera sup√©rieur √† X. <br></div></div><br>  Nous voyons que Aiohttp a fait du bon travail √† 1000 RPS sur un test aussi simple.  Jusqu'√† pr√©sent, sans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">uvloop</a> . <br><br>  Comparez Tornado avec les coroutines des anciennes √©coles (rendement) et nouvelles (asynchrones).  Les auteurs recommandent fortement d'utiliser async.  Nous pouvons nous assurer qu'ils sont vraiment beaucoup plus rapides. <br><br>  √Ä 1200 RPS, Tornado, m√™me avec les nouvelles coroutines scolaires, commence d√©j√† √† abandonner, et Tornado avec les anciennes coroutines scolaires est compl√®tement emport√©.  Si nous dormons pendant 50 ms et que le microservice est responsable de 80 ms, cela n'entre dans aucune porte. <br><br>  La nouvelle √©cole de Tornado √† 1 500 RPS a compl√®tement abandonn√©, tandis que Aiohttp est encore loin de la limite de 3 000 RPS.  Le plus int√©ressant reste √† venir. <br><br><h2>  Pyflame, profilant un microservice fonctionnel </h2><br>  Voyons ce qui se passe en ce moment avec le processeur. <br><br><img src="https://habrastorage.org/webt/mw/-6/c-/mw-6c-vzw_kk-flygqeig93qohe.png"><br><br>  Lorsque nous avons compris comment les microservices asynchrones Python fonctionnent en production, nous avons essay√© de comprendre dans quoi tout cela s'est heurt√©.  Dans la plupart des cas, le probl√®me venait du processeur ou des descripteurs.  Il existe un excellent outil de profilage cr√©√© dans Uber, le profileur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pyflame</a> , qui est bas√© sur l'appel syst√®me ptrace. <br><br>  Nous commen√ßons un service dans le conteneur et commen√ßons √† lancer une charge de combat dessus.  Souvent, ce n'est pas une t√¢che tr√®s triviale - pour cr√©er exactement une telle charge qui est au combat, car il arrive souvent que vous ex√©cutiez des tests synth√©tiques sur les tests de charge, l'apparence et tout fonctionne bien.  Vous poussez la charge de combat sur lui, et ici le microservice commence √† √©mousser. <br><br>  Pendant le fonctionnement, ce profileur fait pour nous des instantan√©s de la pile d'appels.  Vous ne pouvez pas changer le service du tout, lancez pyflame √† proximit√©.  Il collectera une trace de pile une fois dans une certaine p√©riode de temps, puis effectuera une visualisation cool.  Ce profileur donne tr√®s peu de frais g√©n√©raux, en particulier par rapport √† cProfile.  Pyflame prend √©galement en charge les programmes multithread.  Nous avons lanc√© cette chose directement dans la prod, et les performances ne se sont pas beaucoup d√©grad√©es. <br><br><img src="https://habrastorage.org/webt/pk/2s/lu/pk2slutzgqe-szo4mbefnk_zoqe.png"><br><br>  Ici, l'axe X est la quantit√© de temps, le nombre d'appels, lorsque le cadre de pile √©tait sur la liste de tous les cadres de pile Python.  Il s'agit du temps approximatif du processeur que nous avons pass√© dans ce cadre particulier de la pile. <br><br>  Comme vous pouvez le voir, ici la plupart du temps dans aiohttp passe au ralenti.  Tr√®s bien: c'est ce que nous voulons d'un service asynchrone pour qu'il traite la plupart du temps les appels r√©seau.  La profondeur de la pile dans ce cas est d'environ 15 images. <br><br>  Dans Tornado (deuxi√®me image) avec la m√™me charge, beaucoup moins de temps est consacr√© au repos et la profondeur de pile dans ce cas est d'environ 30 images. <br><br>  Voici un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien vers svg</a> , vous pouvez vous tordre. <br><br><h2>  Benchmark asynchrone plus complexe </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">work</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     await asyncio.sleep(SLEEP_TIME) class HardWorkHandler(tornado.web.RequestHandler): timeout_time = datetime.timedelta(seconds=SLEEP_TIME / 2) async def get(self): await work() #     await tornado.gen.multi([work(), work()]) #     try: await tornado.gen.with_timeout(self.timeout_time, work()) except tornado.util.TimeoutError: #     pass</span></span></code> </pre><br>  Attendez-vous √† un temps d'ex√©cution de 125 ms. <br><br><img src="https://habrastorage.org/webt/i2/u5/3d/i2u53d-v1qhpmgkqiifa6q8rita.png"><br><br>  La tornade avec uvloop r√©siste mieux.  Mais Aiohttp uvloop aide beaucoup plus.  Aiohttp commence √† mal se comporter sur 2300-2400 RPS, et avec uvloop, il √©tend consid√©rablement la plage de charge.  Une ligne d'importation, et maintenant vous avez un service beaucoup plus productif. <br><br><h2>  R√©sum√© </h2><br>  Je vais r√©sumer ce que je voulais vous transmettre aujourd'hui. <br><br><ul><li>  Tout d'abord, j'ai lanc√© une certaine r√©f√©rence artificielle, o√π il y avait une bonne quantit√© de coroutine longue.  Dans notre test, Aiohttp a fait mieux 2,5 fois que Tornado. </li><li>  Le deuxi√®me fait.  Uvloop aide tr√®s bien √† am√©liorer les performances d'Aiohttp (mieux que Tornado). </li><li>  Je vous ai parl√© de Pyflame, avec lequel nous profilons souvent l'application directement en production. </li><li>  Et nous avons √©galement parl√© du rendement de (attendre) par rapport au rendement. </li></ul><br>  √Ä la suite de ces benchmarks, notre √©quipe de recommandations (et quelques autres) est presque compl√®tement pass√©e √† Aiohttp avec Tornado pour les microservices en Python en production. <br><br><ul><li>  Pour les services de combat, la consommation du processeur a diminu√© de plus de 2 fois. </li><li>  Nous avons commenc√© √† respecter les d√©lais d'expiration des requ√™tes http. </li><li>  Les services de latence ont chut√© de 2 √† 5 fois. </li></ul><br>  Voici un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien vers le benchmark</a> .  Si vous √™tes int√©ress√©, vous pouvez le r√©p√©ter.  Merci √† tous pour votre attention.  Posez des questions, je vais essayer d'y r√©pondre. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr435532/">https://habr.com/ru/post/fr435532/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr435520/index.html">Nous √©crivons notre langage de programmation, partie 3: Architecture du traducteur. Analyse des structures du langage et des expressions math√©matiques</a></li>
<li><a href="../fr435522/index.html">Instantan√©s d'√©v√©nements dans Axonframework 3, am√©liorant les performances</a></li>
<li><a href="../fr435526/index.html">Aventures avec un cluster Home Kubernetes</a></li>
<li><a href="../fr435528/index.html">5 raisons de r√©ussir: pourquoi Amazon est devenu l'entreprise la plus ch√®re au monde</a></li>
<li><a href="../fr435530/index.html">Abonnements payants - D√©pendance de la connexion automatique √† un appareil mobile</a></li>
<li><a href="../fr435534/index.html">Science des donn√©es: livres d'entr√©e de gamme</a></li>
<li><a href="../fr435536/index.html">Robots humano√Ødes: avantages et probl√®mes des m√©canismes anthropomorphes</a></li>
<li><a href="../fr435538/index.html">En 2018, plus d'√©nergie ¬´verte¬ª a √©t√© re√ßue en Allemagne que l'√©lectricit√© issue de la combustion du charbon</a></li>
<li><a href="../fr435540/index.html">Nouveaux mots cl√©s en Java</a></li>
<li><a href="../fr435542/index.html">D√©veloppement du jeu et d√©fense d'un dipl√¥me ou "Comment j'ai tu√© deux oiseaux avec une premi√®re galette de pierre"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôä üë®üèø‚Äçüîß üë®üèΩ‚Äçü§ù‚Äçüë®üèª Criando um modelo de fluxo de dados para transmitir dados do Pub / Sub para o BigQuery com base no GCP usando o Apache Beam SDK e Python ‚è∫Ô∏è üêÑ ü§ú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No momento, estou envolvido na tarefa de transmitir (e converter) dados. Em alguns c√≠rculos 
 esse processo √© conhecido como ETL , ou seja, extra√ß√£o, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Criando um modelo de fluxo de dados para transmitir dados do Pub / Sub para o BigQuery com base no GCP usando o Apache Beam SDK e Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441892/"><p><img src="https://habrastorage.org/webt/is/qf/7j/isqf7j7patfl6lgirlqfrfbz-k8.png" alt="imagem"></p><br><p>  No momento, estou envolvido na tarefa de transmitir (e converter) dados.  Em alguns c√≠rculos <br>  esse processo √© conhecido como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ETL</a> , ou seja,  extra√ß√£o, convers√£o e carregamento de informa√ß√µes. </p><br><p>  Todo o processo inclui a participa√ß√£o dos seguintes servi√ßos do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Google Cloud Platform</a> : </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pub / Sub</a> - servi√ßo para streaming de dados em tempo real </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Dataflow</a> - um servi√ßo de convers√£o de dados (pode <br>  trabalhar tanto em tempo real quanto em lote) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">BigQuery</a> - um servi√ßo para armazenar dados na forma de tabelas <br>  (suporta SQL) </li></ul><a name="habracut"></a><br><h5 id="0-tekuschee-polozhenie-del">  0. Status atual </h5><br><p>  No momento, h√° uma vers√£o funcional do streaming nos servi√ßos acima, no entanto, <br>  Como modelo, um dos <a href="">padr√µes √© usado</a> . </p><br><p> O problema √© que esse modelo fornece transfer√™ncia de 1 para 1, ou seja,  em <br>  na entrada de Pub / Sub, temos uma string no formato JSON; na sa√≠da, temos uma tabela BigQuery com campos, <br>  que correspondem √†s chaves dos objetos no n√≠vel superior do JSON de entrada. </p><br><h5 id="1-postanovka-zadachi">  1. Declara√ß√£o do problema </h5><br><p> Crie um modelo de fluxo de dados que permita obter uma tabela ou tabelas na sa√≠da <br>  de acordo com as condi√ß√µes dadas.  Por exemplo, queremos criar uma tabela separada para cada <br>  valores de uma chave JSON de entrada espec√≠fica.  √â necess√°rio levar em conta o fato de que algumas <br>  Os objetos JSON de entrada podem conter JSON aninhado como um valor, ou seja,  √© necess√°rio <br>  ser capaz de criar tabelas do BigQuery com campos do tipo <code>RECORD</code> para armazenar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aninhados</a> <br>  dados. </p><br><h5 id="2-podgotovka-k-resheniyu">  2. Prepara√ß√£o para a decis√£o </h5><br><p>  Para criar um modelo de fluxo de dados, use o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Beam</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SDK</a> , que, por sua vez, <br>  suporta Java e Python como uma linguagem de programa√ß√£o.  Devo dizer que <br>  apenas a vers√£o Python 2.7.x √© suportada, o que me surpreendeu um pouco.  Al√©m disso, o apoio <br>  Java √© um pouco mais amplo, porque  para Python, por exemplo, algumas funcionalidades n√£o est√£o dispon√≠veis e mais <br>  Uma lista modesta de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conectores internos</a> .  A prop√≥sito, voc√™ pode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">escrever</a> seus pr√≥prios conectores. </p><br><p>  No entanto, devido ao fato de eu n√£o estar familiarizado com Java, usei o Python. </p><br><p>  Antes de come√ßar a criar um modelo, voc√™ deve ter o seguinte: </p><br><ol><li>  formato JSON de entrada e n√£o deve mudar com o tempo </li><li>  esquema ou esquemas de tabelas do BigQuery para as quais os dados ser√£o transmitidos </li><li>  o n√∫mero de tabelas nas quais o fluxo de dados de sa√≠da ser√° transmitido </li></ol><br><p>  Observe que, ap√≥s criar um modelo e iniciar o Trabalho de fluxo de dados com base nele, esses par√¢metros podem ser <br>  alterar apenas criando um novo modelo. </p><br><p>  Digamos algumas palavras sobre essas restri√ß√µes.  Todos eles v√™m do fato de que n√£o h√° possibilidade <br>  crie um modelo din√¢mico que possa receber qualquer string como entrada, analise-o <br>  de acordo com a l√≥gica interna e, em seguida, preencha tabelas criadas dinamicamente com <br>  criado pelo circuito.  √â muito prov√°vel que essa possibilidade exista, mas dentro dos dados <br>  N√£o consegui implementar esse esquema.  Tanto quanto eu entendo o todo <br>  o pipeline √© constru√≠do antes de execut√°-lo em tempo de execu√ß√£o e, portanto, n√£o h√° como alter√°-lo para <br>  voar.  Talvez algu√©m compartilhe sua decis√£o. </p><br><h5 id="3-reshenie">  3. Decis√£o </h5><br><p>  Para uma compreens√£o mais completa do processo, vale a pena trazer um diagrama do chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pipeline</a> <br>  da documenta√ß√£o do Apache Beam. </p><br><p><img src="https://habrastorage.org/webt/yq/yi/3z/yqyi3zjiwpmjf4i6qp7x4znqv2c.png" alt="imagem"></p><br><p>  No nosso caso (usaremos a divis√£o em v√°rias tabelas): </p><br><ul><li>  input - os dados v√™m do PubSub no Dataflow Job </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Transform</a> # 1 - os dados s√£o convertidos de uma string para um dicion√°rio Python, obtemos sa√≠da <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PCollection</a> # 1 </li><li>  Transforma√ß√£o n¬∫ 2 - os dados s√£o marcados, para posterior separa√ß√£o de acordo com tabelas separadas, em <br>  a sa√≠da √© PCollection # 2 (na verdade, uma tupla de PCollection) </li><li>  Transforma√ß√£o n¬∫ 3 - os dados do PCollection n¬∫ 2 s√£o gravados em tabelas usando esquemas <br>  mesas </li></ul><br><p>  No processo de escrever meu pr√≥prio modelo, fui ativamente inspirado por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esses</a> exemplos. </p><br><div class="spoiler">  <b class="spoiler_title">C√≥digo do modelo com coment√°rios (coment√°rios √† esquerda da mesma maneira dos autores anteriores):</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># coding=utf-8 from __future__ import absolute_import import logging import json import os import apache_beam as beam from apache_beam.pvalue import TaggedOutput from apache_beam.options.pipeline_options import PipelineOptions from apache_beam.options.pipeline_options import SetupOptions from apache_beam.options.pipeline_options import StandardOptions from apache_beam.io.gcp.bigquery import parse_table_schema_from_json #  GCP  gcp_project = '' #  Pub/Sub  topic_name = '' # Pub/Sub    'projects/_GCP_/topics/_' input_topic = 'projects/%s/topics/%s' % (gcp_project, topic_name) #  BigQuery  bq_dataset = 'segment_eu_test' #       schema_dir = './' class TransformToBigQuery(beam.DoFn): #          ,   # BigQuery IO     python dict def process(self, element, *args, **kwargs): body = json.loads(element) #       ,      # python dict       ,     #   yield body class TagDataWithReqType(beam.DoFn): #      , ..      #     ,       #  with_outputs + default def process(self, element, *args, **kwargs): req_type = element.get('_') types = ( 'type1', 'type2', 'type3', ) if req_type in types: yield TaggedOutput(req_type, element) else: yield element def run(): #       _.json   schema_dir,  #         ()  schema_dct = {} for schema_file in os.listdir(schema_dir): filename_list = schema_file.split('.') if filename_list[-1] == 'json': with open('%s/%s' % (schema_dir, schema_file)) as f: schema_json = f.read() schema_dct[filename_list[0]] = json.dumps({'fields': json.loads(schema_json)}) # We use the save_main_session option because one or more DoFn's in this # workflow rely on global context (eg, a module imported at module level). pipeline_options = PipelineOptions() p = beam.Pipeline(options=pipeline_options) pipeline_options.view_as(SetupOptions).save_main_session = True pipeline_options.view_as(StandardOptions).streaming = True # Read from PubSub into a PCollection. input_stream = p | beam.io.ReadFromPubSub(input_topic) # Transform stream to BigQuery IO format stream_bq = input_stream | 'transform to BigQuery' &gt;&gt; beam.ParDo(TransformToBigQuery()) # Tag stream by schema name tagged_stream = \ stream_bq \ | 'tag data by type' &gt;&gt; beam.ParDo(TagDataWithReqType()). with_outputs(*schema_dct.keys(), main='default') # Stream unidentified data to default table tagged_stream.default | 'push to default table' &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.default' % ( gcp_project, bq_dataset, ), schema=parse_table_schema_from_json(schema_dct.get('default')), ) # Stream data to BigQuery tables by number of schema names for name, schema in schema_dct.iteritems(): tagged_stream[name] | 'push to table %s' % name &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.%s' % ( gcp_project, bq_dataset, name), schema=parse_table_schema_from_json(schema), ) result = p.run() result.wait_until_finish() if __name__ == '__main__': logging.getLogger().setLevel(logging.INFO) logger = logging.getLogger(__name__) run()</span></span></code> </pre> </div></div><br><p>  Agora vamos analisar o c√≥digo e dar explica√ß√µes, mas primeiro vale a pena dizer que os principais <br>  a dificuldade em escrever este modelo √© pensar em termos do "fluxo de dados" e <br>  n√£o √© uma mensagem espec√≠fica.  Tamb√©m √© necess√°rio entender que o Pub / Sub opera com mensagens e <br>  √© com eles que receberemos informa√ß√µes para marcar o fluxo. </p><br><pre> <code class="python hljs">pipeline_options = PipelineOptions() p = beam.Pipeline(options=pipeline_options) pipeline_options.view_as(SetupOptions).save_main_session = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> pipeline_options.view_as(StandardOptions).streaming = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre> <br><p>  Porque  O conector Apache Beam Pub / Sub IO √© usado apenas no modo de streaming necess√°rio <br>  adicione PipelineOptions () (embora de fato as op√ß√µes n√£o sejam usadas); caso contr√°rio, crie um modelo <br>  cai com a exce√ß√£o.  Deve-se dizer sobre as op√ß√µes para iniciar o modelo.  Eles podem ser <br>  est√°tico e chamado "tempo de execu√ß√£o".  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui est√° um</a> link para a documenta√ß√£o sobre este t√≥pico.  As op√ß√µes permitem criar um modelo sem especificar par√¢metros antecipadamente, mas transmiti-los ao iniciar o Trabalho de fluxo de dados a partir do modelo, mas ainda n√£o consegui implement√°-lo, provavelmente devido ao fato de este conector n√£o suportar <code>RuntimeValueProvider</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Read from PubSub into a PCollection. input_stream = p | beam.io.ReadFromPubSub(input_topic)</span></span></code> </pre> <br><p>  Tudo est√° claro a partir do coment√°rio, lemos a discuss√£o do t√≥pico.  Vale acrescentar que voc√™ pode aproveitar o fluxo <br>  do t√≥pico e da assinatura (assinatura).  Se o t√≥pico for especificado como uma entrada, ent√£o <br>  uma assinatura tempor√°ria para este t√≥pico ser√° criada automaticamente.  A sintaxe tamb√©m √© bonita <br>  claro, o fluxo de dados de entrada <code>beam.io.ReadFromPubSub(input_topic)</code> enviado ao nosso <br>  gasoduto <code>p</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Transform stream to BigQuery IO format stream_bq = input_stream | 'transform to BigQuery' &gt;&gt; beam.ParDo(TransformToBigQuery())</span></span></code> </pre> <br><p>  √â aqui que a transforma√ß√£o n¬∫ 1 acontece e nossa entrada √© convertida de uma string python para <br>  python dict, e na sa√≠da temos o PCollection # 1.  <code>&gt;&gt;</code> aparece na sintaxe.  Ativado <br>  de fato, o texto entre aspas √© o nome do fluxo (deve ser exclusivo), al√©m de um coment√°rio, <br>  que ser√° adicionado ao bloco no gr√°fico na interface da web do GCP Dataflow.  Vamos considerar em mais detalhes <br>  classe substitu√≠da <code>TransformToBigQuery</code> . </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TransformToBigQuery</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#          ,   # BigQuery IO     python dict def process(self, element, *args, **kwargs): body = json.loads(element) #       ,      # python dict       ,     #  ,      python dict yield body</span></span></code> </pre> <br><p>  A vari√°vel do <code>element</code> conter√° uma mensagem da assinatura do PubSub.  Como visto de <br>  c√≥digo, no nosso caso, deve ser JSON v√°lido.  Na sala de aula deve ser <br>  o m√©todo do <code>process</code> √© redefinido, no qual as transforma√ß√µes necess√°rias devem ser feitas <br>  linha de entrada para obter uma sa√≠da que corresponda ao circuito <br>  a tabela na qual esses dados ser√£o carregados.  Porque  nosso fluxo neste caso √© <br>  cont√≠nuo, <code>unbounded</code> em termos de Apache Beam, voc√™ deve devolv√™-lo usando <br>  <code>yield</code> , n√£o <code>return</code> , como no fluxo de dados final.  No caso de um fluxo final, voc√™ pode <br>  (e necess√°rio) configurar adicionalmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><code>windowing</code></a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><code>triggers</code></a> </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Tag stream by schema name tagged_stream = \ stream_bq \ | 'tag data by type' &gt;&gt; beam.ParDo(TagDataWithReqType()).with_outputs(*schema_dct.keys(), main='default')</span></span></code> </pre> <br><p>  Esse c√≥digo direciona a PCollection # 1 √† Transform # 2, onde a marca√ß√£o ocorrer√° <br>  (separa√ß√£o) do fluxo de dados.  Na vari√°vel <code>schema_dct</code> neste caso, um dicion√°rio, em que a chave √© o nome do arquivo do esquema sem a extens√£o, essa ser√° a tag e o valor √© o JSON v√°lido do esquema <br>  Tabelas do BigQuery para esta tag.  Note-se que o esquema deve ser transmitido exatamente para <br>  visualize <code>{'fields': }</code> que <code></code> √© o esquema da tabela do BigQuery no formato JSON (voc√™ pode <br>  exportar da interface da web). </p><br><p>  <code>main='default'</code> √© o nome da tag do segmento para a qual eles ir√£o <br>  Todas as mensagens que n√£o est√£o sujeitas √†s condi√ß√µes de marca√ß√£o.  Considere a classe <br>  <code>TagDataWithReqType</code> . </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TagDataWithReqType</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      , ..      #     ,       #  with_outputs + default def process(self, element, *args, **kwargs): req_type = element.get('_') types = ( 'type1', 'type2', 'type3', ) if req_type in types: yield TaggedOutput(req_type, element) else: yield element</span></span></code> </pre> <br><p>  Como voc√™ pode ver, a classe de <code>process</code> tamb√©m √© redefinida aqui.  A vari√°vel <code>types</code> cont√©m nomes <br>  tags e devem corresponder ao n√∫mero e nome com o n√∫mero e os nomes das chaves do dicion√°rio <br>  <code>schema_dct</code> .  Embora o m√©todo do <code>process</code> possa aceitar argumentos, eu nunca <br>  Eu fui capaz de passar por eles.  Ainda n√£o descobri o motivo. </p><br><p>  Na sa√≠da, obtemos uma tupla de threads no n√∫mero de tags, ou seja, o n√∫mero de nossos <br>  tags predefinidas + segmento padr√£o que n√£o foram identificados. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Stream unidentified data to default table tagged_stream.default | 'push to default table' &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.default' % ( gcp_project, bq_dataset, ), schema=parse_table_schema_from_json(schema_dct.get('default')), )</span></span></code> </pre> <br><p>  Transforma√ß√£o # ... (na verdade, n√£o est√° no diagrama, √© um "ramo") - escrevemos o fluxo padr√£o <br>  para a tabela padr√£o. </p><br><p>  <code>tagged_stream.default</code> - um fluxo com a tag <code>default</code> √© obtido, uma sintaxe alternativa √© <code>tagged_stream['default']</code> </p><br><p>  <code>schema=parse_table_schema_from_json(schema_dct.get('default'))</code> - aqui o esquema √© definido <br>  mesas.  Observe que o arquivo <code>default.json</code> com o esquema de tabela v√°lido do BigQuery <br>  deve estar no <code>schema_dir = './'</code> atual. </p><br><p>  O fluxo ir√° para uma tabela chamada <code>default</code> . </p><br><p>  Se uma tabela com este nome (no conjunto de dados fornecido deste projeto) n√£o existir, ela ser√° <br>  ser√° criado automaticamente a partir do esquema, gra√ßas √† configura√ß√£o padr√£o <br> <code>create_disposition=BigQueryDisposition.CREATE_IF_NEEDED</code> </p> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Stream data to BigQuery tables by number of schema names for name, schema in schema_dct.iteritems(): tagged_stream[name] | 'push to table %s' % name &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.%s' % ( gcp_project, bq_dataset, name), schema=parse_table_schema_from_json(schema), )</span></span></code> </pre> <br><p>  Na transforma√ß√£o n¬∫ 3, tudo deve ficar claro para quem l√™ o artigo desde o in√≠cio e possui <br>  sintaxe python.  Separamos a tupla de fluxo com um loop e escrevemos cada fluxo em sua pr√≥pria tabela com <br>  o esquema dele.  Deve-se lembrar que o nome do fluxo deve ser exclusivo - <code>'%s:%s.%s' % (gcp_project, bq_dataset, name)</code> . </p><br><p>  Agora deve ficar claro como isso funciona e voc√™ pode criar um modelo.  Para isso voc√™ precisa <br>  execute no console (n√£o esque√ßa de ativar o venv, se dispon√≠vel) ou no IDE: </p><br><pre> <code class="bash hljs">python _.py / --runner DataflowRunner / --project dreamdata-test / --staging_location gs://STORAGE_NAME/STAGING_DIR / --temp_location gs://STORAGE_NAME/TEMP_DIR / --template_location gs://STORAGE_NAME/TEMPLATES_DIR/TEMPLATE_NAME</code> </pre> <br><p>  Ao mesmo tempo, o acesso √† Conta do Google deve ser organizado, por exemplo, atrav√©s da exporta√ß√£o <br>  a <code>GOOGLE_APPLICATION_CREDENTIALS</code> ambiente <code>GOOGLE_APPLICATION_CREDENTIALS</code> ou de outra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">maneira</a> . </p><br><p>  Algumas palavras sobre <code>--runner</code> .  Nesse caso, o <code>DataflowRunner</code> diz que esse c√≥digo <br>  ser√° executado como um modelo para o trabalho de fluxo de dados.  Ainda √© poss√≠vel especificar <br>  <code>DirectRunner</code> , ser√° usado por padr√£o se n√£o houver op√ß√£o <code>--runner</code> e c√≥digo <br>  funcionar√° como um trabalho de fluxo de dados, mas localmente, o que √© muito conveniente para depura√ß√£o. </p><br><p>  Se nenhum erro ocorreu, <code>gs://STORAGE_NAME/TEMPLATES_DIR/TEMPLATE_NAME</code> ser√° <br>  modelo criado.  Vale dizer que em <code>gs://STORAGE_NAME/STAGING_DIR</code> tamb√©m ser√° gravado <br>  arquivos de servi√ßo necess√°rios para a opera√ß√£o bem-sucedida do Datafow Job criado com base em <br>  modelo e voc√™ n√£o precisa exclu√≠-los. </p><br><p>  Em seguida, voc√™ precisa criar um trabalho de fluxo de dados usando este modelo, manualmente ou por qualquer <br>  de outra maneira (IC por exemplo). </p><br><h5 id="4-vyvody">  4. Conclus√µes </h5><br><p>  Assim, conseguimos transmitir o fluxo do PubSub para o BigQuery usando <br>  transforma√ß√µes de dados necess√°rias para fins de armazenamento, transforma√ß√£o e <br>  uso de dados. </p><br><h2 id="osnovnye-ssylki">  Links principais </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Beam SDK</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.google.com/url%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26cad%3Drja%26uact%3D8%26ved%3D2ahUKEwjHvcGT5svgAhV7wsQBHSDWDEoQFjAAegQIABAC%26url%3D">Fluxo de dados do Google</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bigquery do Google</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo de James Moore sobre m√≠dia</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Exemplos de c√≥digo Python para Apache Beam</a> </li></ul><br><p>  Neste artigo, imprecis√µes e at√© erros s√£o poss√≠veis, serei grato pelo construtivo <br>  cr√≠tica.  No final, quero acrescentar que, de fato, nem todos s√£o usados ‚Äã‚Äãaqui <br>  recursos do SDK do Apache Beam, mas esse n√£o era o objetivo. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt441892/">https://habr.com/ru/post/pt441892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt441878/index.html">Voc√™ como voc√™ quer, mas eu fiz</a></li>
<li><a href="../pt441882/index.html">VMware NSX para o menor. Parte 3. Configurando o DHCP</a></li>
<li><a href="../pt441886/index.html">Nos √∫ltimos 12 anos, nunca mostrei um curr√≠culo</a></li>
<li><a href="../pt441888/index.html">SIP do megafone em casa</a></li>
<li><a href="../pt441890/index.html">Tudo o que voc√™ precisa saber sobre as extens√µes de aplicativos para iOS</a></li>
<li><a href="../pt441896/index.html">Aprenda t√°ticas, t√©cnicas e conhecimentos comuns do advers√°rio (ATT @ CK). T√°ticas corporativas. Parte 9</a></li>
<li><a href="../pt441898/index.html">Sketch + Node.js: gerando √≠cones para muitas plataformas e marcas</a></li>
<li><a href="../pt441900/index.html">Satya Nadella falou sobre coopera√ß√£o com o Pent√°gono</a></li>
<li><a href="../pt441902/index.html">Como a tecnologia cria novas realidades</a></li>
<li><a href="../pt441904/index.html">Instalando uma Tela IPS no Thinkpad T430S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
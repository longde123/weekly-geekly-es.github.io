<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👊🏾 🚪 👩🏻‍🚒 Réseau de neurones qui vous aidera à choisir un film - «vos goûts sont spécifiques» 🙅🏾 🤙 🍔</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut 

 Il arrive que vous regardiez un film, et dans votre tête il n'y a qu'une seule question - "Suis-je de nouveau en train de recevoir des appâts...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Réseau de neurones qui vous aidera à choisir un film - «vos goûts sont spécifiques»</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/477630/">  Salut <br><br>  Il arrive que vous regardiez un film, et dans votre tête il n'y a qu'une seule question - "Suis-je de nouveau en train de recevoir des appâts?"  Nous allons résoudre ce problème et nous ne regarderons que des films appropriés.  Je suggère d'expérimenter un peu les données et d'écrire un réseau neuronal simple pour évaluer le film. <br><br>  Notre expérience est basée sur la technologie d'analyse des sentiments pour déterminer l'humeur du public pour un produit.  En tant que données, nous prenons un ensemble de données d'avis d'utilisateurs sur les films IMDb.  L'environnement de développement de Google Colab vous permettra de former rapidement votre réseau de neurones grâce à un accès gratuit au GPU (NVidia Tesla K80). <br><br>  J'utilise la bibliothèque Keras, à l'aide de laquelle je vais construire un modèle universel pour résoudre des problèmes similaires d'apprentissage automatique.  J'aurai besoin du backend TensorFlow, la version par défaut de Colab 1.15.0, il suffit donc de passer à 2.0.0. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf !tf_upgrade_v2 -h</code> </pre> <br>  Ensuite, nous importons tous les modules nécessaires pour le prétraitement des données et la construction de modèles.  Dans les articles précédents, l'accent est mis sur les bibliothèques, vous pouvez y regarder. <br><a name="habracut"></a><br><pre> <code class="python hljs">%matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> to_categorical <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> models <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> imdb</code> </pre> <br><h2>  Analyse des données IMDb </h2><br><img src="https://habrastorage.org/webt/4m/gg/mj/4mggmjh34w_zrwpseprbnv8gpwy.png"><br><br>  L'ensemble de données IMDb comprend 50 000 critiques de films d'utilisateurs notés positif (1) et négatif (0). <br><br><ul><li>  Les avis sont prétraités et chacun d'eux est codé par une séquence d'indices de mots sous forme d'entiers </li></ul><br><ul><li>  Les mots dans les revues sont indexés par leur fréquence totale dans l'ensemble de données.  Par exemple, l'entier «2» code le deuxième mot le plus utilisé </li></ul><br><ul><li>  50 000 avis sont divisés en deux ensembles: 25 000 pour la formation et 25 000 pour les tests. </li></ul><br>  Téléchargez l'ensemble de données intégré à Keras.  Étant donné que les données sont divisées en formation et test dans un rapport de 50-50, je les combinerai pour que plus tard je puisse les diviser par 80-20. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> imdb (training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=<span class="hljs-number"><span class="hljs-number">10000</span></span>) data = np.concatenate((training_data, testing_data), axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) targets = np.concatenate((training_targets, testing_targets), axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h2>  Exploration des données </h2><br>  Voyons ce avec quoi nous travaillons. <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Categories:"</span></span>, np.unique(targets)) print(<span class="hljs-string"><span class="hljs-string">"Number of unique words:"</span></span>, len(np.unique(np.hstack(data))))</code> </pre> <br><img src="https://habrastorage.org/webt/i4/iv/gq/i4ivgqp7pzmudiozqn5ollfffcu.png"><br><br><pre> <code class="python hljs">length = [len(i) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data] print(<span class="hljs-string"><span class="hljs-string">"Average Review length:"</span></span>, np.mean(length)) print(<span class="hljs-string"><span class="hljs-string">"Standard Deviation:"</span></span>, round(np.std(length)))</code> </pre> <br><img src="https://habrastorage.org/webt/_l/3z/td/_l3ztdm6ma6lanax8rzewdm_nk4.png"><br><br>  Vous pouvez voir que toutes les données appartiennent à deux catégories: 0 ou 1, ce qui représente l'ambiance de la revue.  L'ensemble de données contient 9998 mots uniques, la taille moyenne des avis est de 234 mots avec un écart-type de 173. <br><br>  Regardons le premier examen de cet ensemble de données, qui est marqué comme positif. <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Label:"</span></span>, targets[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(data[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/c0/fg/et/c0fgeth2sdc9d0ycekevqesuqwy.png"><br><br><pre> <code class="python hljs">index = imdb.get_word_index() reverse_index = dict([(value, key) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (key, value) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> index.items()]) decoded = <span class="hljs-string"><span class="hljs-string">" "</span></span>.join( [reverse_index.get(i - <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"#"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[<span class="hljs-number"><span class="hljs-number">0</span></span>]] ) print(decoded)</code> </pre> <br><img src="https://habrastorage.org/webt/gl/mj/kd/glmjkdqcbp0mha-udlo2g_qgni4.png"><br><br><h2>  Préparation des données </h2><br>  Il est temps de préparer les données.  Nous devons vectoriser chaque enquête et la remplir de zéros pour que le vecteur contienne exactement 10 000 nombres.  Cela signifie que chaque avis de moins de 10 000 mots est rempli de zéros.  Je le fais parce que la plus grande vue d'ensemble est presque de la même taille, et chaque élément d'entrée de notre réseau neuronal devrait avoir la même taille.  Vous devez également convertir les variables en type flottant. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vectorize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sequences, dimension = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10000</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> results = np.zeros((len(sequences), dimension)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, sequence <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(sequences): results[i, sequence] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> results data = vectorize(data) targets = np.array(targets).astype(<span class="hljs-string"><span class="hljs-string">"float32"</span></span>)</code> </pre> <br>  Ensuite, je divise l'ensemble de données en données de formation et de test comme convenu 4: 1. <br><br><pre> <code class="python hljs">test_x = data[:<span class="hljs-number"><span class="hljs-number">10000</span></span>] test_y = targets[:<span class="hljs-number"><span class="hljs-number">10000</span></span>] train_x = data[<span class="hljs-number"><span class="hljs-number">10000</span></span>:] train_y = targets[<span class="hljs-number"><span class="hljs-number">10000</span></span>:]</code> </pre> <br><br><h2>  Créer et former un modèle </h2><br>  La chose est petite, il ne reste plus qu'à écrire un modèle et à le former.  Commencez par choisir un type.  Deux types de modèles sont disponibles dans Keras: séquentiels et avec une API fonctionnelle.  Ensuite, vous devez ajouter des couches d'entrée, cachées et de sortie. <br><br>  Pour éviter le sur-ajustement, nous utiliserons un "dropout" entre eux. Sur chaque couche, la fonction "dense" est utilisée pour relier complètement les couches entre elles.  Dans les couches cachées, nous utiliserons la fonction d'activation «relu», ce qui conduit presque toujours à des résultats satisfaisants.  Sur la couche de sortie, nous utilisons une fonction sigmoïde qui renormalise les valeurs dans la plage de 0 à 1. <br><br>  J'utilise l'optimiseur adam, il changera de poids pendant la formation. <br><br>  Nous utilisons l'entropie croisée binaire comme fonction de perte et la précision comme mesure métrique. <br><br>  Vous pouvez maintenant former notre modèle.  Nous le ferons avec une taille de lot de 500 et seulement trois époques, car il a été révélé que le modèle commence à se recycler s'il est entraîné plus longtemps. <br><br><pre> <code class="python hljs">model = models.Sequential() <span class="hljs-comment"><span class="hljs-comment"># Input - Layer model.add(layers.Dense(50, activation = "relu", input_shape=(10000, ))) # Hidden - Layers model.add(layers.Dropout(0.3, noise_shape=None, seed=None)) model.add(layers.Dense(50, activation = "relu")) model.add(layers.Dropout(0.2, noise_shape=None, seed=None)) model.add(layers.Dense(50, activation = "relu")) # Output- Layer model.add(layers.Dense(1, activation = "sigmoid")) model.summary() # compiling the model model.compile( optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"] ) results = model.fit( train_x, train_y, epochs= 3, batch_size = 500, validation_data = (test_x, test_y) ) print("Test-Accuracy:", np.mean(results.history["val_acc"]))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fc/ay/fd/fcayfd-sr1jv_ur91nve_ecqm-4.png"><br><br><h2>  Conclusion </h2><br>  Nous avons créé un réseau neuronal simple à six couches qui peut calculer l'humeur des cinéastes avec une précision de 0,89.  Bien sûr, pour regarder des films sympas, il n'est pas du tout nécessaire d'écrire un réseau de neurones, mais ce n'était qu'un autre exemple de la façon dont vous pouvez utiliser les données, en bénéficier, car vous en avez besoin pour cela.  Le réseau de neurones est universel en raison de la simplicité de sa structure, en modifiant certains paramètres, vous pouvez l'adapter à des tâches complètement différentes. <br><br>  N'hésitez pas à écrire vos idées dans les commentaires. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr477630/">https://habr.com/ru/post/fr477630/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr477616/index.html">Comment entrer dans l'Apple Arcade? Entretien avec les fondateurs du studio Tortuga Team</a></li>
<li><a href="../fr477618/index.html">Localisation de l'application React</a></li>
<li><a href="../fr477622/index.html">Fissuration Réduire le concept en seulement 10 minutes</a></li>
<li><a href="../fr477624/index.html">De quoi EXPLAIN est muet et comment en parler</a></li>
<li><a href="../fr477628/index.html">Informatique sans serveur basée sur OpenWhisk, partie 2</a></li>
<li><a href="../fr477634/index.html">Microservices et structure organisationnelle. Quels types d'équipes assureront le succès?</a></li>
<li><a href="../fr477638/index.html">Acheté! = Le vôtre: John Deere prive les agriculteurs du droit de réparer leurs propres tracteurs</a></li>
<li><a href="../fr477642/index.html">La vision (radio) de la machine voit à travers les murs</a></li>
<li><a href="../fr477644/index.html">Restauration d'UNIX v0 sur PDP-7: Détails de l'arrière-boutique</a></li>
<li><a href="../fr477646/index.html">Les mathématiciens coupent des formes à la recherche de parties d'équations</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
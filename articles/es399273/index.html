<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👸🏽 🌵 ☹️ Métodos neurobiológicos y cosas geniales que puedes hacer con ellos: Parte 1 💷 ⚙️ 🌳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los métodos neurobiológicos son similares a los héroes anónimos del periodismo científico. Periódicamente, los medios se iluminan con frases como "máq...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Métodos neurobiológicos y cosas geniales que puedes hacer con ellos: Parte 1</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/399273/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los métodos neurobiológicos son similares a los héroes anónimos del periodismo científico. </font><font style="vertical-align: inherit;">Periódicamente, los medios se iluminan con frases como "máquinas impulsadas por el cerebro" y "lectura de pensamientos" ("los científicos finalmente aprendieron a leer sus PENSAMIENTOS SUCIOS !!! 11"). </font><font style="vertical-align: inherit;">¿Pero cómo se hace esto? </font><font style="vertical-align: inherit;">Y desde que comenzamos a hablar de ello, ¿qué métodos se utilizan para implementar proyectos futuristas como administrar la realidad virtual con los ojos o determinar si el sospechoso estuvo presente en la escena del crimen? </font><font style="vertical-align: inherit;">Preguntas, algunas preguntas. </font><font style="vertical-align: inherit;">Las respuestas están en esta publicación.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seguimiento ocular y realidad virtual</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por definición, el seguimiento del movimiento ocular (ODG) mide la actividad de sus ojos. ¿Cuándo y con qué frecuencia parpadea? ¿Por qué se están estrechando las pupilas? ¿Tu mirada se queda más tiempo en su elegante pecho o sus hermosos ojos? Respondiendo a tales preguntas, el seguimiento de los movimientos oculares le permite saber si una persona está concentrada o relajada y cansada, si su sitio web es conveniente para los usuarios, si el paciente tiene autismo: esta tecnología es aplicable en varias áreas, cuyo número continúa aumentando.</font></font><br>
<a name="habracut"></a><br>
<a href=""><img src="https://habrastorage.org/files/308/d74/1b6/308d741b66e14941a895bed1dc0dcaba.jpg" align="left" title="Cómo funciona el seguimiento ocular"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A diferencia de la década de 1890, la tecnología actual no requiere la inmovilización ocular con cocaína. Hoy en día, el método generalmente aceptado para medir el comportamiento del ojo es la iluminación de la parte infrarroja cercana del espectro en el centro del ojo y comparar la posición de su reflejo con la posición de la pupila (la posición de la luz reflejada permanece en su lugar y la pupila se mueve con respecto a ella). Al combinar datos con la posición de la cabeza, puede extrapolarlos para obtener la dirección de su mirada y calcular qué puntos está mirando la persona. Las medidas típicas incluyen fijaciones (donde la mirada se detuvo en algo que llamó su atención), su duración y el tiempo que lleva traducir la mirada en ellas; saccades (movimiento secuencial de los ojos de una parte del sujeto en cuestión a otra); La forma final de mirar (lo que miraste, en qué orden y por cuánto tiempo).Todo esto se puede medir de dos maneras: dispositivos remotos y dispositivos montados en la cabeza. Los primeros generalmente se unen a la pantalla de la computadora. Estos últimos están montados en la cabeza de una persona y se parecen al atuendo futurista de Lady Gaga. Dichos dispositivos permiten que una persona se mueva libremente.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seguimiento ocular: la tecnología es universal. Sus áreas de aplicación abarcan desde la investigación de mercado (desarrollo de productos, colocación de productos, empaques) hasta neurobiología (diagnóstico temprano de la enfermedad de Alzheimer, investigación de atención y memoria, etc.). Pero hay una idea realmente futurista que debería hacerle cosquillas a su mente geek: la realidad virtual (VR). EDG se está volviendo cada vez más popular en la comunidad de realidad virtual, ya que puede ayudar a crear VR de inmersión profunda en dispositivos menos potentes, así como permitir que el jugador influya en el mundo virtual con un solo ojo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Veamos cómo BP y EDG conducen a una mejora en la experiencia del usuario. El ojo tiene una fóvea: una pequeña depresión en el centro de la pupila, responsable de la visión aguda. Cuando miramos algo, vemos solo una pequeña parte de nuestro entorno en detalle (el que está en el campo de visión foveal). Nuestra visión periférica solo ve color y movimiento, pero en una forma bastante borrosa y no detallada. Para crear la impresión de que vemos muchos más detalles de nuestro entorno, el cerebro simplemente usa nuestra experiencia y memoria para llenar los vacíos. Si una sandía borrosa está en el campo de su visión periférica, su cerebro simplemente sustituirá una imagen enfocada en su lugar, tomándola de la memoria, y ahora está más clara. Y así, los desarrolladores de BP están trabajando en la creación de la tecnología de "representación foveal" [representación foveada],diseñado para reducir significativamente la carga informática de la computadora. Ella debe usar nuestro conocimiento del funcionamiento del cerebro y su interpretación del mundo. Primero, el EDG le dice al programa exactamente dónde está mirando la persona. El renderizado foveal, utilizando esta información, genera una imagen ubicada a los lados del campo de visión con una resolución y detalles mucho más bajos, y dirige toda la potencia informática para aumentar la claridad y el realismo al renderizar la región foveal. La virtualidad se actualiza de acuerdo con los movimientos de sus ojos para que su área de visión esté siempre clara. Similar a la visión en el mundo real, su cerebro creará la ilusión de una visión universalmente clara basada en su experiencia. Y aunque todo esto se ve muy bien, esta tecnología está al comienzo del desarrollo,ya que es bastante difícil crear un dispositivo económico y pequeño para ODG.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qq09BTmjzRs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cómo funciona Los</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
tecno-gigantes no pospusieron su implementación de un nuevo enfoque: más recientemente, Google adquirió una de las principales startups de ODG. </font><font style="vertical-align: inherit;">Dicen que están trabajando en gafas VR inalámbricas que combinan realidad aumentada y realidad virtual. </font><font style="vertical-align: inherit;">¡Seleccione un elemento del menú, echándole un vistazo! </font><font style="vertical-align: inherit;">¡Mira algo más largo y haz zoom! </font><font style="vertical-align: inherit;">Dé un paseo por el Louvre y obtenga información sobre la imagen, ¡bateo 4 veces! </font><font style="vertical-align: inherit;">¡Usa los ojos en lugar de un ratón! </font><font style="vertical-align: inherit;">¡Gloria a nuestro nuevo señor supremo y salvador, seguimiento ocular! </font><font style="vertical-align: inherit;">Lo que comenzó en 1879 como seguimiento ocular durante la lectura ha recorrido un largo camino para cambiar nuestra comprensión de la realidad.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Imagen de resonancia magnética funcional (fMRI) y lectura de la mente</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
fMRI es similar al arte contemporáneo. Todos escucharon acerca de él, pero nadie entiende lo que debería ser. No tengas miedo, pronto todo se aclarará. De hecho, la resonancia magnética funcional se basa en el hecho de que la sangre con un alto contenido de oxígeno se comporta de manera diferente en un campo magnético que la sangre con un bajo contenido de oxígeno. Al mismo tiempo, cuanto más activamente se comporta el área del cerebro, más oxígeno consume. Y cuanto más oxígeno se necesita, más sangre ingresa a esta área. La resonancia magnética funcional puede rastrear un aumento en el flujo sanguíneo y el consumo de oxígeno para encontrar la región activa del cerebro. Este tipo de imagen se llama imagen en función del </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">nivel de oxigenación de</font></a><font style="vertical-align: inherit;"> la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sangre dependiente.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, Negrita). El método no es invasivo, solo necesita acostarse en un tubo de escáner muy ruidoso y dar una buena resolución espacial de las imágenes (la resolución temporal es peor porque hay un retraso de 3-6 segundos entre la activación del área del cerebro y la demanda de oxígeno). Esta herramienta se utiliza en una gran variedad de estudios.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La resonancia magnética funcional puede usarse de dos maneras: ayuda a ver la activación cerebral durante una tarea simple (por ejemplo, en los períodos de experimento de cambio de inactividad con períodos de tareas de memoria / reconocimiento visual / juicios morales, en general, tareas como "erótica o helado"), o se utiliza para analizar el trabajo del cerebro en un momento en que no estamos ocupados con ninguna tarea específica (por ejemplo, cuando soñamos, mirando distraídamente desde la ventana del autobús, o sonreímos y saludamos a los colegas, fingiendo escuchar sus conversaciones sobre los niños). La primera opción, llamada fMRI en estado de reposo, mostró que están sucediendo muchas cosas en el cerebro incluso cuando no estamos haciendo nada: identificó varias redes que controlan el cerebro y nos permitió vercómo cambian las conexiones entre regiones del cerebro en enfermedades psiquiátricas o en diferentes estados de conciencia.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/adb/57c/1f4/adb57c1f42e87569be78996c2582dec3.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nuestro estudio de fMRI mostró que los sujetos realizaban actividad en partes del cerebro asociadas con sonidos fuertes, claustrofobia y pérdida de joyas </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
al </font><font style="vertical-align: inherit;">realizar tareas simples de memorización. </font><font style="vertical-align: inherit;">Cuando tuvimos una idea de cómo funciona [1], qué se puede hacer al respecto ? Lucho con la tentación de declarar "leer pensamientos" (y pasarle una tapa de aluminio), por lo que preferiría usar el término más científico, "decodificar pensamientos basados ​​en la actividad cerebral".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La tecnología de decodificación no solo busca un área que responda, digamos, a una persona. Reconocen todo el patrón de activación cerebral correspondiente al reconocimiento de una cara en particular. Luego, habiendo establecido esquemas de activación para imágenes dofigiliard, el algoritmo de "esquemas de clasificación" las procesa junto con imágenes relacionadas. Como resultado, el clasificador aprende sobre la relación entre las imágenes y la actividad cerebral en el momento de su reconocimiento y comprende qué patrón de activación puede desencadenar una imagen en particular, por ejemplo, una fotografía de un gato o un bebé. El programa, habiendo procesado suficientes ejemplos, puede comenzar a estudiar los escáneres fMRI y tratar de decodificar qué es exactamente en el momento del escaneo que la persona estaba mirando o en qué estaba pensando. Los primeros experimentos fueron simples: en los primeros trabajos, los científicos solo podían reconocer una categoría de objetos,que los sujetos estaban mirando en ese momento (zapatos, botas, tijeras, etc.) [2].</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Poco después, los mecanismos de decodificación dieron un largo paso adelante. Al principio, se usaron para determinar cuál de las 120 imágenes está mirando la gente [3]; la tarea es mucho más complicada que definir una amplia categoría de objetos. Luego, los investigadores desarrollaron un clasificador que puede producir películas primitivas basadas en la película vista por el sujeto [4]. Desde entonces, la tecnología ya se ha utilizado para cualquier cosa: construir escenas visuales [5], memoria de trabajo (¿qué estoy pensando?) [6] y reconocer intenciones [7] (¿en qué botón quiero hacer clic?). Pero la clasificación de intenciones es una tarea más complicada que el reconocimiento de imágenes. Los objetos se agrupan por color o forma, pero ¿cómo asigno categorías a las intenciones? Otro problema es la posibilidad de generalización. Hasta ahora, todos los decodificadores funcionan con cerebros seleccionados,y el desarrollo de un dispositivo estándar para leer pensamientos, que pueda usarse para combatir el crimen, no vale la pena esperar en los próximos años. En la etapa actual, como John-Dylan Haynes (una persona que trabaja duro en la investigación de clasificadores, así como mi profesor (me jacto)) dice: "La mejor manera de averiguar la intención de alguien es preguntar".</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/2e8/915/53d/2e891553d0cf9f6b2d3c23f5d5bf1cfa.jpg" alt="imagen"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cómo funciona la decodificación</font></font></i><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fuentes</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">www.psy.vanderbilt.edu/tonglab/sonia/Personal/fMRI_Basics.html</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
2. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dx.doi.org/10.1016/S1053-8119</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (03) 00049-1 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gallantlab.org/_downloads/2008a.Kay. etal.pdf</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
4. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">www.ncbi.nlm.nih.gov/pubmed/21945275?dopt=Abstract&amp;holding=npg</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
5. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">journal.frontiersin.org/article/10.3389/fnhum.2014.00059/full</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
6. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">www.jneurosci.org/content / 32/38/12983? Ijkey = 3b948eedde2b0698790b3d2f0d7ea14f66079dee &amp; keytype2 = tf_ipsecsha</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
7. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">www.ncbi.nlm.nih.gov/pubmed/21486293</font></font></a></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es399273/">https://habr.com/ru/post/es399273/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es399263/index.html">Calculadora para camarada Kosygina</a></li>
<li><a href="../es399265/index.html">Cómo conectar un láser semiconductor con una potencia de más de 1 W (1000 mW) a una impresora 3D, máquina CNC, mesa de coordenadas</a></li>
<li><a href="../es399267/index.html">Benchmark Premium de Corea del Sur: revisión de la nueva línea de DVR de BlackVue</a></li>
<li><a href="../es399269/index.html">Billetes de todo el mundo: una selección de monedas interesantes de todo el mundo</a></li>
<li><a href="../es399271/index.html">Impresión 3D en odontología utilizando NextDent como ejemplo</a></li>
<li><a href="../es399275/index.html">PocketBook 840-2 Ink Pad 2 revisión: el nuevo lector de tinta E de gran formato con una pantalla de resolución ultra alta</a></li>
<li><a href="../es399277/index.html">Un amante de las consolas de juegos de la vieja escuela crea un juego para Sega Mega Drive</a></li>
<li><a href="../es399279/index.html">La gran cadena de confianza: cómo blockchain y la confianza están cambiando el mundo</a></li>
<li><a href="../es399281/index.html">¿De qué están hechos los japoneses?</a></li>
<li><a href="../es399285/index.html">Post-horror: cómo la tecnología hace cosquillas a los nervios</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§±üèº üíä üë®‚Äçüç≥ AlphaStar: un nuevo sistema de inteligencia artificial para StarCraft II de DeepMind (traducci√≥n completa) ‚ú≥Ô∏è üïû ü§±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los juegos se han utilizado durante d√©cadas como una de las principales formas de probar y evaluar el √©xito de los sistemas de inteligencia artificial...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AlphaStar: un nuevo sistema de inteligencia artificial para StarCraft II de DeepMind (traducci√≥n completa)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437486/"><img src="https://habrastorage.org/webt/nk/ws/dw/nkwsdwhpu2x7d_mzzxswejvrywu.png"><br><br>  Los juegos se han utilizado durante d√©cadas como una de las principales formas de probar y evaluar el √©xito de los sistemas de inteligencia artificial.  A medida que crec√≠an las oportunidades, los investigadores buscaron juegos con una complejidad cada vez mayor, que reflejaran los diversos elementos de pensamiento necesarios para resolver problemas cient√≠ficos o aplicados del mundo real.  En los √∫ltimos a√±os, StarCraft se considera una de las estrategias en tiempo real m√°s vers√°tiles y complejas y una de las m√°s populares en la escena de los deportes electr√≥nicos en la historia, y ahora StarCraft tambi√©n se ha convertido en el principal desaf√≠o para la investigaci√≥n de IA. <a name="habracut"></a><br><br>  AlphaStar es el primer sistema de inteligencia artificial capaz de derrotar a los mejores jugadores profesionales.  En una serie de partidos que tuvieron lugar el 19 de diciembre, AlphaStar obtuvo una victoria aplastante sobre Grzegorz Komincz (MaNa) de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Liquid</a> , uno de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">jugadores m√°s fuertes del mundo</a> , con un puntaje de 5: 0.  Antes de eso, tambi√©n se jug√≥ un exitoso partido de demostraci√≥n contra su compa√±ero de equipo Dario W√ºnsch ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TLO</a> ).  Los partidos se llevaron a cabo de acuerdo con todas las reglas profesionales en una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tarjeta de torneo</a> especial y sin restricciones. <br><br>  A pesar de los √©xitos significativos en juegos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Atari</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mario</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Quake III Arena</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dota 2</a> , los t√©cnicos de IA lucharon sin √©xito contra la complejidad de StarCraft.  Los mejores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">resultados se</a> lograron al construir manualmente los elementos b√°sicos del sistema, al imponer varias restricciones a las reglas del juego, al proporcionar al sistema habilidades sobrehumanas o al jugar en mapas simplificados.  Pero incluso estos matices hicieron imposible acercarse al nivel de los jugadores profesionales.  Contrariamente a esto, AlphaStar juega un juego completo utilizando redes neuronales profundas, que se entrenan sobre la base de datos sin procesar del juego, utilizando m√©todos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ense√±anza con un maestro</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aprendizaje con refuerzo</a> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/cUTMhmVh1qs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Desaf√≠o principal </h2><br>  StarCraft II es un universo de fantas√≠a ficticio con un juego rico y de varios niveles.  Junto con la edici√≥n original, este es el juego m√°s grande y exitoso de todos los tiempos, que ha estado luchando en torneos durante m√°s de 20 a√±os. <br><br><img src="https://habrastorage.org/webt/ms/84/q6/ms84q6h5-66lmbjwtgj9w5csknw.png"><br><br>  Hay muchas formas de jugar, pero la m√°s com√∫n en los deportes electr√≥nicos son los torneos uno a uno que consisten en 5 partidos.  Para comenzar, el jugador debe elegir una de las tres razas: zergs, protoss o terrans, cada una de las cuales tiene sus propias caracter√≠sticas y capacidades.  Por lo tanto, los jugadores profesionales se especializan con mayor frecuencia en una carrera.  Cada jugador comienza con varias unidades de trabajo que extraen recursos para construir edificios, otras unidades o desarrollar tecnolog√≠a.  Esto permite al jugador aprovechar otros recursos, construir bases m√°s sofisticadas y desarrollar nuevas habilidades para burlar al oponente.  Para ganar, el jugador debe equilibrar muy delicadamente la imagen de la econom√≠a general, llamada "macro", y el control de bajo nivel de las unidades individuales, llamado "micro". <br><br>  La necesidad de equilibrar los objetivos a corto y largo plazo y adaptarse a situaciones imprevistas plantea un gran desaf√≠o para los sistemas que, de hecho, a menudo resultan ser completamente inflexibles.  Resolver este problema requiere un gran avance en varias √°reas de la IA: <br><br>  <b>Teor√≠a del juego</b> : StarCraft es un juego en el que, como en "Piedra, tijera, papel", no existe una estrategia ganadora √∫nica.  Por lo tanto, en el proceso de aprendizaje, la IA debe explorar y expandir constantemente los horizontes de su conocimiento estrat√©gico. <br><br>  <b>Informaci√≥n incompleta</b> : a diferencia del ajedrez o ir, donde los jugadores ven todo lo que sucede, en StarCraft la informaci√≥n importante a menudo se oculta y debe extraerse activamente a trav√©s de la inteligencia. <br><br>  <b>Planificaci√≥n a largo plazo</b> : como en las tareas del mundo real, las relaciones causa-efecto pueden no ser instant√°neas.  Un juego tambi√©n puede durar una hora o m√°s, por lo tanto, las acciones realizadas al comienzo de un juego pueden no tener absolutamente ning√∫n significado a largo plazo. <br><br>  <b>Tiempo real</b> : a diferencia de los juegos de mesa tradicionales, donde los participantes se turnan por turnos, en StarCraft, los jugadores realizan acciones continuamente, junto con el paso del tiempo. <br><br>  <b>Gran espacio de acci√≥n</b> : Cientos de diferentes unidades y edificios deben ser monitoreados simult√°neamente, en tiempo real, lo que brinda un enorme espacio combinatorio de oportunidades.  Adem√°s de esto, muchas acciones son jer√°rquicas y pueden cambiar y complementarse en el camino.  Nuestra parametrizaci√≥n del juego proporciona un promedio de aproximadamente 10 a 26 acciones por unidad de tiempo. <br><br>  En vista de estos desaf√≠os, StarCraft se ha convertido en un gran desaf√≠o para los investigadores de IA.  Las competencias actuales de StarCraft y StarCraft II tienen sus ra√≠ces en el lanzamiento de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">BroodWar API</a> en 2009.  Entre ellos se encuentran <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AIIDE StarCraft AI Competition</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CIG StarCraft Competition</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Student StarCraft AI Tournament</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Starcraft II AI Ladder</a> . <br><br>  <font color="gray"><b>Nota</b> : En 2017, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">PatientZero</a> public√≥ en Habr√© una excelente traducci√≥n de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La historia de las competiciones de IA en Starcraft</a> ".</font> <br><br>  Para ayudar a la comunidad a explorar m√°s estos problemas, nosotros, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajando con Blizzard</a> en 2016 y 2017, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicamos el kit de herramientas PySC2</a> , que incluye la mayor variedad de repeticiones anonimizadas que se haya publicado.  En base a este trabajo, combinamos nuestros logros de ingenier√≠a y algoritmos para crear AlphaStar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/822/758/c32/822758c324e93f521b27b56735ec4b83.gif"><br><br>  <font color="gray">La visualizaci√≥n de AlphaStar durante la lucha contra MaNa demuestra el juego en nombre del agente: los datos iniciales observados, la actividad de la red neuronal, algunas de las acciones propuestas y las coordenadas requeridas, as√≠ como el resultado estimado del partido.</font>  <font color="gray">Tambi√©n se muestra la vista del reproductor MaNa, pero, por supuesto, el agente no puede acceder a ella.</font> <br><br><h2>  Como es el entrenamiento </h2><br>  El comportamiento AlphaStar es generado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">por una red neuronal de</a> aprendizaje profundo, que recibe datos sin procesar a trav√©s de la interfaz (una lista de unidades y sus propiedades) y proporciona una secuencia de instrucciones que son acciones en el juego.  M√°s espec√≠ficamente, la arquitectura de la red neuronal adopta el enfoque de "torso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transformador</a> para las unidades, combinado con un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">n√∫cleo LSTM profundo</a> , un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">jefe de pol√≠tica autorregresivo</a> con una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">red de puntero</a> y una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">l√≠nea de base de valor centralizada</a> " <i>(</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">no traducida</a> <i>)</i> .  Creemos que estos modelos ayudar√°n a√∫n m√°s a hacer frente a otras tareas importantes de aprendizaje autom√°tico, incluido el modelado de secuencias a largo plazo y los grandes espacios de salida, como la traducci√≥n, el modelado del lenguaje y las representaciones visuales. <br><br>  AlphaStar tambi√©n utiliza el nuevo algoritmo de aprendizaje multiagente.  Esta red neuronal se entren√≥ originalmente utilizando un m√©todo de aprendizaje basado en el maestro basado en repeticiones an√≥nimas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">disponibles a</a> trav√©s de Blizzard.  Esto permiti√≥ a AlphaStar estudiar y simular las micro y macro estrategias b√°sicas utilizadas por los jugadores en los torneos.  Este agente derrot√≥ el nivel de inteligencia artificial incorporado "Elite", que es equivalente al nivel de un jugador en la liga de oro en el 95% de los juegos de prueba. <br><br><img src="https://habrastorage.org/webt/s1/gd/ll/s1gdll65axq9s7kgbbgap2ublzq.png"><br><br>  <font color="gray">League AlphaStar.</font>  <font color="gray">Los agentes fueron entrenados inicialmente sobre la base de repeticiones de partidos humanos, y luego sobre la base de partidos competitivos entre ellos.</font>  <font color="gray">En cada iteraci√≥n, los nuevos oponentes se ramifican y los originales se congelan.</font>  <font color="gray">La probabilidad de encontrarse con otros oponentes e hiperpar√°metros determina los objetivos de aprendizaje para cada agente, lo que aumenta la complejidad y conserva la diversidad.</font>  <font color="gray">Los par√°metros del agente se actualizan con entrenamiento de refuerzo basado en el resultado del juego contra oponentes.</font>  <font color="gray">El agente final se selecciona (sin reemplazo) en funci√≥n de la distribuci√≥n de Nash.</font> <br><br>  Estos resultados se utilizan para iniciar un proceso de aprendizaje de refuerzo de m√∫ltiples agentes.  Para esto, se cre√≥ una liga donde los agentes oponentes juegan unos contra otros, al igual que las personas ganan experiencia jugando torneos.  Se agregaron nuevos rivales a la liga, por duplicaci√≥n de los agentes actuales.  Esta nueva forma de aprendizaje, que toma prestadas algunas ideas del m√©todo de aprendizaje por refuerzo con elementos de algoritmos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">basados ‚Äã‚Äãen la poblaci√≥n</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">basados ‚Äã‚Äãen la poblaci√≥n</a> ), le permite crear un proceso continuo de exploraci√≥n del vasto espacio estrat√©gico del juego de StarCraft y asegurarse de que los agentes puedan resistir las estrategias m√°s poderosas, no olvidando los viejos. <br><br><img src="https://habrastorage.org/webt/ez/e2/lk/eze2lk_d4mka5wlf4q0ir5brgyg.png"><br><br>  <font color="gray">Score MMR (Match Making Rating): un indicador aproximado de la habilidad del jugador.</font>  <font color="gray">Para los rivales en la liga AlphaStar durante el entrenamiento, en comparaci√≥n con las ligas en l√≠nea de Blizzard.</font> <br><br>  A medida que la liga se desarroll√≥ y se crearon nuevos agentes, aparecieron estrategias contrarias que pudieron derrotar a las anteriores.  Mientras que algunos agentes solo mejoraron las estrategias que hab√≠an encontrado anteriormente, otros agentes crearon estrategias completamente nuevas, incluidas nuevas √≥rdenes de construcci√≥n inusuales, composici√≥n de unidades y administraci√≥n de macros.  Por ejemplo, desde el principio, los "quesos" florecieron: una carrera r√°pida con la ayuda de pistolas de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ca√±ones</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fotones</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">templarios oscuros</a> .  Pero a medida que avanzaba el proceso de aprendizaje, estas estrategias arriesgadas fueron descartadas, dando paso a otras.  Por ejemplo, la producci√≥n de un n√∫mero excesivo de trabajadores para obtener una afluencia adicional de recursos o la donaci√≥n de dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Or√°culos</a> para atacar a los trabajadores del enemigo y socavar su econom√≠a.  Este proceso es similar a c√≥mo los jugadores regulares descubrieron nuevas estrategias y derrotaron viejos enfoques populares, durante los muchos a√±os transcurridos desde el lanzamiento de StarCraft. <br><br><img src="https://habrastorage.org/webt/zk/af/qb/zkafqb5szegbqxsj0khe16mi4ps.png"><br><br>  <font color="gray">A medida que avanzaba el entrenamiento, se not√≥ c√≥mo estaba cambiando la composici√≥n de las unidades utilizadas por los agentes.</font> <br><br>  Para garantizar la diversidad, cada agente estaba dotado de su propio objetivo de aprendizaje.  Por ejemplo, a qu√© oponentes deber√≠a vencer este agente, o cualquier otra motivaci√≥n intr√≠nseca que determine el juego del agente.  Un determinado agente puede tener el objetivo de derrotar a un oponente espec√≠fico y al otro una selecci√≥n completa de oponentes, pero solo unidades espec√≠ficas.  Estas metas han cambiado a lo largo del proceso de aprendizaje. <br><br><img src="https://habrastorage.org/webt/t0/ik/9p/t0ik9pbfntlif0ogbysdsla9jmm.png"><br><br>  <font color="gray">Visualizaci√≥n interactiva (las caracter√≠sticas interactivas est√°n disponibles en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo original</a> ), que muestra rivales con la Liga AlphaStar.</font>  <font color="gray">El agente que jug√≥ contra TLO y MaNa se marca por separado.</font> <br><br>  Los coeficientes (pesos) de la red neuronal de cada agente se actualizaron mediante el entrenamiento de refuerzo basado en juegos con oponentes para optimizar sus objetivos de aprendizaje espec√≠ficos.  La regla para actualizar el peso es un nuevo algoritmo de aprendizaje eficaz "algoritmo de aprendizaje de refuerzo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">actor-cr√≠tico fuera de pol√≠tica</a> con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">repetici√≥n de experiencia</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aprendizaje de imitaci√≥n propia</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">destilaci√≥n de pol√≠ticas</a> " <i>(para la precisi√≥n de los t√©rminos que quedan sin traducci√≥n)</i> . <br><br><img src="https://habrastorage.org/webt/ul/xa/lz/ulxalzh3tlrs7xp5g38pieesd2q.gif"><br><br>  <font color="gray">La imagen muestra c√≥mo un agente (punto negro), que fue seleccionado como resultado del juego contra MaNa, desarroll√≥ su estrategia en comparaci√≥n con los oponentes (puntos de colores) en el proceso de entrenamiento.</font>  <font color="gray">Cada punto representa un oponente en la liga.</font>  <font color="gray">La posici√≥n del punto muestra la estrategia y el tama√±o: la frecuencia con la que se elige como oponente del agente MaNa en el proceso de aprendizaje.</font> <br><br>  Para capacitar a AlphaStar, creamos un sistema distribuido escalable basado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google TPU</a> 3, que proporciona el proceso de capacitaci√≥n paralela de toda una poblaci√≥n de agentes con miles de copias de StarCraft II.  AlphaStar League dur√≥ 14 d√≠as con 16 TPU para cada agente.  Durante el entrenamiento, cada agente experiment√≥ hasta 200 a√±os de experiencia jugando StarCraft en tiempo real.  La versi√≥n final de AlphaStar Agent contiene todos los componentes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">distribuci√≥n de la</a> Liga <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nash</a> .  En otras palabras, la combinaci√≥n m√°s efectiva de estrategias que se descubrieron durante los juegos.  Y esta configuraci√≥n se puede ejecutar en una GPU de escritorio est√°ndar.  Se est√° preparando una descripci√≥n t√©cnica completa para su publicaci√≥n en una revista cient√≠fica revisada por pares. <br><br><img src="https://habrastorage.org/webt/bu/av/df/buavdfbrbivhdaeyemafanmwfxs.png"><br><br>  <font color="gray">Distribuci√≥n de Nash entre rivales durante el desarrollo de la liga y la creaci√≥n de nuevos oponentes.</font>  <font color="gray">La distribuci√≥n de Nash, que es el conjunto de competidores complementarios menos explotable, aprecia a los nuevos jugadores, lo que demuestra un progreso continuo sobre todos los competidores anteriores.</font> <br><br><h2>  C√≥mo act√∫a AlphaStar y ve el juego </h2><br>  Los jugadores profesionales como TLO o MaNa pueden realizar cientos de acciones por minuto ( <a href="">APM</a> ).  Pero esto es mucho menos que la mayor√≠a de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los bots existentes</a> que controlan de forma independiente cada unidad y generan miles, si no decenas de miles de acciones. <br><br>  En nuestros juegos contra TLO y MaNa, AlphaStar mantuvo el APM en un promedio de 280, que es mucho menor que el de los jugadores profesionales, aunque sus acciones pueden ser m√°s precisas.  Un APM tan bajo se debe en particular al hecho de que AlphaStar comenz√≥ a estudiar sobre la base de repeticiones de jugadores comunes y trat√≥ de imitar la forma del juego humano.  Adem√°s de esto, AlphaStar reacciona con un retraso entre la observaci√≥n y la acci√≥n de un promedio de aproximadamente 350 ms. <br><br><img src="https://habrastorage.org/webt/xu/zz/zq/xuzzzqqpxxmw-dep-8zpocumjho.png"><br><br>  <font color="gray">Distribuci√≥n de APM AlphaStar en partidos contra MaNa y TLO, y el retraso general entre observaci√≥n y acci√≥n.</font> <br><br>  Durante los partidos contra TLO y MaNa, AlphaStar interactu√≥ con el motor del juego StarCraft a trav√©s de la interfaz en bruto, es decir, pod√≠a ver los atributos de sus unidades enemigas visibles en el mapa directamente, sin tener que mover la c√°mara: juega de manera efectiva con una vista reducida de todo el territorio .  Contrariamente a esto, las personas vivas deben gestionar claramente la "econom√≠a de la atenci√≥n" para decidir constantemente d√≥nde enfocar la c√°mara.  Sin embargo, un an√°lisis de los juegos AlphaStar revela que controla impl√≠citamente el enfoque.  En promedio, un agente cambia su contexto de atenci√≥n aproximadamente 30 veces por minuto, como MaNa y TLO. <br><br>  Adem√°s, desarrollamos la segunda versi√≥n de AlphaStar.  Como jugadores humanos, esta versi√≥n de AlphaStar elige claramente cu√°ndo y d√≥nde mover la c√°mara.  En esta realizaci√≥n, su percepci√≥n se limita a la informaci√≥n en la pantalla, y las acciones tambi√©n se permiten solo en el √°rea visible de la pantalla. <br><br><img src="https://habrastorage.org/webt/3d/mt/js/3dmtjsjiqiqkc1izsc6-jsentog.png"><br><br>  <font color="gray">Rendimiento de AlphaStar cuando se usa la interfaz base y la interfaz de la c√°mara.</font>  <font color="gray">El gr√°fico muestra que el nuevo agente que trabaja con la c√°mara est√° alcanzando r√°pidamente un rendimiento comparable para el agente que utiliza la interfaz base.</font> <br><br>  Entrenamos a dos agentes nuevos, uno usando la interfaz base y otro que deb√≠a aprender a controlar la c√°mara, jugando contra la liga AlphaStar.  Cada agente al principio fue entrenado con un maestro basado en partidos humanos, seguido de entrenamiento con el refuerzo descrito anteriormente.  La versi√≥n AlphaStar, que utiliza la interfaz de la c√°mara, logr√≥ casi los mismos resultados que la versi√≥n con la interfaz base, superando la marca de 7000 MMR en nuestra tabla de clasificaci√≥n interna.  En una partida de demostraci√≥n, MaNa derrot√≥ al prototipo AlphaStar con una c√°mara.  Entrenamos esta versi√≥n solo 7 d√≠as.  Esperamos poder evaluar una versi√≥n totalmente entrenada con una c√°mara en el futuro cercano. <br><br>  Estos resultados muestran que el √©xito de AlphaStar en los partidos contra MaNa y TLO es principalmente el resultado de una buena gesti√≥n de macro y micro, y no solo una gran tasa de clics, reacci√≥n r√°pida o acceso a la informaci√≥n en la interfaz b√°sica. <br><br><h2>  Resultados del juego AlphaStar vs jugadores profesionales </h2><br>  StarCraft permite a los jugadores elegir una de las tres razas: terranos, zerg o protoss.  Decidimos que AlphaStar se especializar√≠a actualmente en una carrera en particular, los protoss, para reducir el tiempo de entrenamiento y las variaciones en la evaluaci√≥n de los resultados de nuestra liga nacional.  Pero debe tenerse en cuenta que un proceso de aprendizaje similar se puede aplicar a cualquier raza.  Nuestros agentes fueron entrenados para jugar StarCraft II versi√≥n 4.6.2 en modo protoss versus protoss en el mapa CatalystLE.  Para evaluar el rendimiento de AlphaStar, inicialmente probamos a nuestros agentes en partidos contra TLO, un jugador profesional para zerg y un jugador para el nivel protoss "GrandMaster".  AlphaStar gan√≥ partidos con un puntaje de 5: 0, utilizando una amplia gama de unidades y √≥rdenes de construcci√≥n.  "Me sorprendi√≥ lo fuerte que era el agente", dijo.  ‚ÄúAlphaStar toma estrategias bien conocidas y las pone patas arriba.  El agente mostr√≥ estrategias en las que nunca pens√©.  Y esto muestra que todav√≠a puede haber formas de jugar que todav√≠a no se comprenden completamente ". <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UuhECwm31dM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Despu√©s de una semana adicional de entrenamiento, jugamos contra MaNa, uno de los jugadores de StarCraft II m√°s poderosos del mundo, y uno de los 10 mejores jugadores protoss.  AlphaStar esta vez gan√≥ 5-0, demostrando fuertes habilidades de microgesti√≥n y macroestrategia.  "Me sorprendi√≥ ver a AlphaStar usando los enfoques m√°s avanzados y las diferentes estrategias en cada juego, mostrando un estilo de juego muy humano que nunca esper√© ver", dijo.  ‚ÄúMe di cuenta de cu√°n fuerte depende mi estilo de juego del uso de errores basados ‚Äã‚Äãen reacciones humanas.  Y eso pone el juego en un nivel completamente nuevo.  Todos esperamos con entusiasmo ver qu√© pasa despu√©s ". <br><br><h2>  AlphaStar y otros problemas dif√≠ciles </h2><br>  A pesar de que StarCraft es solo un juego, incluso si es muy dif√≠cil, creemos que las t√©cnicas subyacentes de AlphaStar pueden ser √∫tiles para resolver otros problemas.  Por ejemplo, este tipo de arquitectura de red neuronal es capaz de simular secuencias muy largas de acciones probables, en juegos que a menudo duran hasta una hora y contienen decenas de miles de acciones basadas en informaci√≥n incompleta.  Cada cuadro en StarCraft se usa como un paso de entrada.  En este caso, la red neuronal en cada paso predice la secuencia de acciones esperada para todo el juego restante.  La tarea fundamental de hacer pron√≥sticos complejos para secuencias de datos muy largas se encuentra en muchos problemas del mundo real, como el pron√≥stico del tiempo, el modelado del clima, la comprensi√≥n del idioma, etc. Nos complace reconocer el enorme potencial que se puede aplicar en estas √°reas, utilizando la experiencia que hemos adquirido. en el proyecto AlphaStar. <br><br>  Tambi√©n creemos que algunos de nuestros m√©todos de ense√±anza pueden ser √∫tiles para estudiar la seguridad y la fiabilidad de la IA.  Uno de los problemas m√°s dif√≠ciles en el campo de la IA es la cantidad de opciones en las que el sistema puede estar equivocado.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y los jugadores profesionales en el pasado r√°pidamente encontraron formas de evitar la IA, usando sus errores de la manera original. El innovador enfoque AlphaStar, basado en el entrenamiento en la liga, encuentra dichos enfoques y hace que el proceso general sea m√°s confiable y est√© protegido contra tales errores. Nos complace que el potencial de este enfoque pueda ayudar a mejorar la seguridad y la confiabilidad de los sistemas de IA en general. Especialmente en √°reas cr√≠ticas como la energ√≠a, donde es extremadamente importante reaccionar correctamente en situaciones dif√≠ciles. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lograr un nivel de juego tan alto en StarCraft representa un gran avance en uno de los videojuegos m√°s desafiantes jam√°s creados. Creemos que estos logros, junto con los √©xitos en otros proyectos, ya sea </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaZero</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaFold</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , representan un paso adelante en la implementaci√≥n de nuestra misi√≥n de crear sistemas inteligentes que alg√∫n d√≠a nos ayudar√°n a encontrar soluciones a los problemas cient√≠ficos m√°s complejos y fundamentales. </font></font><br><br><hr><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">11 repeticiones de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> todos los partidos </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video del partido de demostraci√≥n</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> contra MaNa </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video con visualizaci√≥n AlphaStar del</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> segundo partido completo contra MaNa</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437486/">https://habr.com/ru/post/437486/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437476/index.html">Ok Yandex! ¬øD√≥nde est√°n nuestros objetivos de alcance?</a></li>
<li><a href="../437478/index.html">Que debemos construir un camino. Parte 1</a></li>
<li><a href="../437480/index.html">4 novelas visuales para aprender ingl√©s</a></li>
<li><a href="../437482/index.html">Preg√∫ntele a Ethan: si la luz se contrae y se expande con el espacio, ¬øc√≥mo podemos detectar ondas gravitacionales?</a></li>
<li><a href="../437484/index.html">C√≥mo realic√© con √©xito seis entrevistas en Silicon Valley</a></li>
<li><a href="../437488/index.html">Cloud Key: C√≥mo construir sus aplicaciones nativas de la nube</a></li>
<li><a href="../437492/index.html">Conferencia Lua en Mosc√∫ 2019</a></li>
<li><a href="../437494/index.html">Conferencia Lua en Mosc√∫ 2019</a></li>
<li><a href="../437496/index.html">Sobre variables en programaci√≥n</a></li>
<li><a href="../437500/index.html">Acerca de cosas "invisibles" importantes: confianza, cultura y valores</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë±üèø ‚õÖÔ∏è üö£ Migration vers Google Cloud Platform (Google Cloud Platform - GCP) üë©üèº‚Äçüç≥ üïü üîî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="[partie 2 de 2] 


 [partie 1 de 2] 





 Comment l'avons-nous fait 


 Nous avons d√©cid√© de passer √† GCP pour am√©liorer les performances des applica...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migration vers Google Cloud Platform (Google Cloud Platform - GCP)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/430874/"><h3 id="chast-2-iz-2">  [partie 2 de 2] </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">[partie 1 de 2]</a> </p><br><img src="https://habrastorage.org/webt/6m/2c/sx/6m2csxdumpxfx00xrft85x4vdng.png"><br><p><br></p><br><h2 id="kak-nam-eto-udalos">  Comment l'avons-nous fait </h2><br><p>  Nous avons d√©cid√© de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">passer √† GCP</a> pour am√©liorer les performances des applications - tout en augmentant l'√©chelle, mais sans co√ªts importants.  L'ensemble du processus a pris plus de 2 mois.  Pour r√©soudre ce probl√®me, nous avons form√© un groupe sp√©cial d'ing√©nieurs. </p><br><p>  Dans cette publication, nous parlerons de l'approche choisie et de sa mise en ≈ìuvre, ainsi que de la mani√®re dont nous avons r√©ussi √† atteindre l'objectif principal - mener √† bien ce processus le plus harmonieusement possible et transf√©rer l'int√©gralit√© de l'infrastructure vers la plateforme Google Cloud, sans compromettre la qualit√© du service aux utilisateurs. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ee6/5d3/693/ee65d3693b51048de4322274109bd23d.png" alt="image"></p><a name="habracut"></a><br><h2 id="planirovanie">  Planification </h2><br><ol><li>  Une liste de contr√¥le d√©taill√©e a √©t√© pr√©par√©e pour identifier chaque √©tape possible.  Un organigramme a √©t√© cr√©√© pour d√©crire la s√©quence. </li><li>  Un plan de r√©initialisation a √©t√© √©labor√© que nous pourrions √©ventuellement utiliser. </li></ol><br><p> Quelques s√©ances de brainstorming - et nous avons identifi√© l'approche la plus compr√©hensible et la plus simple pour mettre en ≈ìuvre le sch√©ma actif-actif.  Elle consiste dans le fait qu'un petit ensemble d'utilisateurs est h√©berg√© sur un cloud, et le reste sur un autre.  Cependant, cette approche a caus√© des probl√®mes, en particulier du c√¥t√© client (li√©s √† la gestion DNS), et a entra√Æn√© des retards dans la r√©plication de la base de donn√©es.  Pour cette raison, il √©tait presque impossible de le mettre en ≈ìuvre en toute s√©curit√©.  La m√©thode √©vidente n'a pas apport√© la solution n√©cessaire et nous avons d√ª d√©velopper une strat√©gie sp√©cialis√©e. </p><br><p>  Sur la base du diagramme de d√©pendance et des exigences de s√©curit√© op√©rationnelle, nous avons divis√© les services d'infrastructure en 9 modules. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/290/5eb/c21/2905ebc2190ea9f8d480e5532a196a1f.jpg" alt="image"></p><br><p>  <em>(Modules de base pour d√©ployer l'infrastructure d'h√©bergement)</em> </p><br><p>  Chaque groupe d'infrastructure g√©rait des services internes et externes communs. </p><br><p>  ‚äπ <strong>Service de messagerie d'infrastructure</strong> : MQTT, HTTPs, Thrift, serveur Gunicorn, module de mise en file d'attente, client Async, serveur Jetty, cluster Kafka. <br>  ‚äπ <strong>Services d'entrep√¥t de donn√©es</strong> : cluster distribu√© MongoDB, Redis, Cassandra, Hbase, MySQL et MongoDB. <br>  ‚äπ <strong>Service d'analyse d'infrastructure</strong> : cluster Kafka, cluster d'entrep√¥t de donn√©es (HDFS, HIVE). </p><br><h2 id="podgotovka-k-znamenatelnomu-dnyu">  Se pr√©parer pour une journ√©e importante: </h2><br><p>  ‚úì Un plan d√©taill√© pour passer au GCP pour chaque service: s√©quence, entrep√¥t de donn√©es, plan de r√©initialisation. <br>  ‚úì Interactions r√©seau entre projets (VPC cloud priv√© virtuel partag√© [XPN]) dans GCP pour isoler diff√©rentes parties de l'infrastructure, optimiser la gestion, am√©liorer la s√©curit√© et la connectivit√©. <br>  ‚úì Plusieurs tunnels VPN entre le GCP et le cloud priv√© virtuel (VPC) en cours d'ex√©cution pour simplifier le transfert de grandes quantit√©s de donn√©es sur le r√©seau pendant la r√©plication, ainsi que pour le d√©ploiement ult√©rieur possible d'un syst√®me parall√®le. <br>  ‚úì Automatisez l'installation et la configuration de la pile enti√®re √† l'aide du syst√®me Chef. <br>  ‚úì Scripts et outils d'automatisation pour le d√©ploiement, la surveillance, la journalisation, etc. <br>  ‚úì Configurez tous les sous-r√©seaux requis et les r√®gles de pare-feu g√©r√©es pour le flux syst√®me. <br>  ‚úì R√©plication dans plusieurs centres de donn√©es (Multi-DC) pour tous les syst√®mes de stockage. <br>  ‚úì Configurer des √©quilibreurs de charge (GLB / ILB) et des groupes d'instances g√©r√©s (MIG). <br>  ‚úì Scripts et code pour transf√©rer le conteneur de stockage d'objets vers GCP Cloud Storage avec des points de contr√¥le. </p><br><p>  Bient√¥t, nous avons rencontr√© tous les pr√©requis n√©cessaires et pr√©par√© une liste de contr√¥le des √©l√©ments pour d√©placer l'infrastructure vers la plateforme GCP.  Apr√®s de nombreuses discussions, ainsi que le nombre de services et leurs diagrammes de d√©pendance, nous avons d√©cid√© de transf√©rer l'infrastructure cloud vers GCP en trois nuits pour couvrir tous les services c√¥t√© serveur et de stockage de donn√©es. </p><br><h2 id="perehod">  Transition </h2><br><h3 id="strategiya-perenosa-balansirovschika-nagruzki">  Strat√©gie de transfert d'√©quilibrage de charge: </h3><br><p>  Nous avons remplac√© le cluster g√©r√© HAProxy pr√©c√©demment utilis√© par un √©quilibreur de charge global pour traiter quotidiennement des dizaines de millions de connexions utilisateur actives. </p><br><p>  ‚äπ <strong>√âtape 1:</strong> </p><br><ul><li>  Les MIG sont cr√©√©s avec des r√®gles de transfert de paquets pour transf√©rer tout le trafic vers les adresses IP MQTT dans le cloud existant. </li><li>  Un √©quilibreur de proxy SSL et TCP a √©t√© cr√©√© avec MIG comme partie serveur. </li><li>  Pour MIG, HAProxy est lanc√© avec des serveurs MQTT comme partie serveur. </li><li>  Dans DNS, une strat√©gie de routage bas√©e sur le poids a ajout√© une adresse IP GLB externe. </li></ul><br><p>  Les connexions utilisateurs sont progressivement d√©ploy√©es tout en suivant leurs performances. </p><br><p>  ‚äπ <strong>√âtape 2:</strong> transition jalon, commencez √† d√©ployer des services dans GCP. <br>  ‚äπ <strong>√âtape 3:</strong> √©tape finale de la transition, tous les services sont transf√©r√©s au GCP. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ebb/fcb/614/ebbfcb614345c40b20de5c9e8edd9a8e.png" alt="image"></p><br><p>  <em>(√âtapes de transfert de l'√©quilibreur de charge)</em> </p><br><p>  √Ä ce stade, tout a fonctionn√© comme pr√©vu.  Bient√¥t, il √©tait temps de d√©ployer plusieurs services HTTP internes dans GCP avec routage - √©tant donn√© le poids des coefficients.  Nous avons suivi de pr√®s tous les indicateurs.  Lorsque nous avons commenc√© √† augmenter progressivement le trafic, la veille de la transition pr√©vue, les retards d'interaction VPC via VPN (des retards de 40 ms √† 100 ms ont √©t√© enregistr√©s, m√™me s'ils √©taient auparavant inf√©rieurs √† 10 ms) ont augment√©. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b6c/af5/3bc/b6caf53bc304c2fd42c9342dd11faf82.png" alt="image"></p><br><p>  <em>(Instantan√© de la v√©rification du retard du r√©seau lorsque deux VPC interagissent)</em> </p><br><p>  La surveillance a clairement montr√©: quelque chose n'allait pas avec les deux canaux du r√©seau cloud utilisant des tunnels VPN.  M√™me le d√©bit du tunnel VPN n'a pas atteint la marque optimale.  Cette situation a commenc√© √† affecter n√©gativement certains de nos services aux utilisateurs.  Nous avons imm√©diatement renvoy√© tous les services HTTP pr√©c√©demment migr√©s √† leur √©tat d'origine.  Nous avons contact√© les √©quipes de support des services cloud et TAM, fourni les donn√©es initiales n√©cessaires et commenc√© √† comprendre pourquoi les retards augmentaient.  Les sp√©cialistes du support sont parvenus √† la conclusion que la bande passante r√©seau maximale dans le canal cloud entre deux fournisseurs de services cloud √©tait atteinte.  D'o√π l'augmentation des retards du r√©seau lors du transfert des syst√®mes internes. </p><br><p>  Cet incident a oblig√© √† suspendre la transition vers le cloud.  Les fournisseurs de services cloud ne pouvaient pas doubler la bande passante assez rapidement.  Par cons√©quent, nous sommes revenus √† l'√©tape de la planification et avons r√©vis√© la strat√©gie.  Nous avons d√©cid√© de transf√©rer l'infrastructure cloud vers GCP en une nuit au lieu de trois et avons inclus dans le plan tous les services de la partie serveur et du stockage des donn√©es.  Lorsque l'heure ¬´X¬ª est arriv√©e, tout s'est bien pass√©: les charges de travail ont √©t√© transf√©r√©es avec succ√®s vers Google Cloud sans √™tre remarqu√©es par nos utilisateurs! </p><br><h2 id="strategiya-perenosa-bazy-dannyh">  Strat√©gie de migration de la base de donn√©es: </h2><br><p>  Il √©tait n√©cessaire de transf√©rer plus de 50 points de terminaison de base de donn√©es pour un SGBD relationnel, un stockage en m√©moire, ainsi que NoSQL et des clusters distribu√©s et √©volutifs √† faible latence.  Nous avons plac√© des r√©pliques de toutes les bases de donn√©es dans GCP.  Cela a √©t√© fait pour tous les d√©ploiements sauf HBase. </p><br><p>  ‚äπ R√©plication <strong>ma√Ætre-esclave:</strong> impl√©ment√©e pour les clusters MySQL, Redis, MongoDB et MongoS. <br>  <strong>R√©plication Multi Multi-DC:</strong> impl√©ment√©e pour les clusters Cassandra. <br>  ‚äπ <strong>Clusters doubles: un</strong> cluster parall√®le a √©t√© configur√© pour Gbase dans GCP.  Les donn√©es existantes ont √©t√© migr√©es, la double entr√©e a √©t√© configur√©e conform√©ment √† la strat√©gie de maintien de la coh√©rence des donn√©es dans les deux clusters. </p><br><p>  Dans le cas de HBase, le probl√®me se posait avec Ambari.  Nous avons rencontr√© quelques difficult√©s lors du placement de clusters dans plusieurs centres de donn√©es, par exemple, il y avait des probl√®mes avec DNS, un script de reconnaissance de rack, etc. </p><br><p>  Les derni√®res √©tapes (apr√®s le d√©placement des serveurs) comprenaient le d√©placement des r√©pliques vers les serveurs principaux et la fermeture des anciennes bases de donn√©es.  Comme pr√©vu, d√©terminant la priorit√© du transfert de la base de donn√©es, nous avons utilis√© Zookeeper pour la configuration n√©cessaire des clusters d'applications. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/550/4e6/6d3/5504e66d3db5f8e35db7eccbfb1cfa6e.png" alt="image"></p><br><h2 id="strategiya-perenosa-sluzhb-prilozheniy">  Strat√©gie de migration des services d'application </h2><br><p>  Pour transf√©rer les charges de travail des services d'application de l'h√©bergement actuel vers le cloud GCP, nous avons utilis√© l'approche lift-and-shift.  Pour chaque service d'application, nous avons cr√©√© un groupe d'instances g√©r√©es (MIG) avec mise √† l'√©chelle automatique. </p><br><p>  Conform√©ment √† un plan d√©taill√©, nous avons commenc√© √† migrer les services vers GCP, en tenant compte de la s√©quence et des d√©pendances des entrep√¥ts de donn√©es.  Tous les services de pile de messagerie ont √©t√© migr√©s vers GCP sans aucun temps d'arr√™t.  Oui, il y a eu quelques probl√®mes mineurs, mais nous les avons trait√©s imm√©diatement. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b1b/70f/159/b1b70f159f2698731b5b6e166afa1079.png" alt="image"></p><br><p>  Le matin, alors que l'activit√© des utilisateurs augmentait, nous avons suivi attentivement tous les tableaux de bord et indicateurs pour identifier rapidement les probl√®mes.  Certaines difficult√©s ont vraiment surgi, mais nous avons pu les √©liminer rapidement.  L'un des probl√®mes √©tait d√ª aux limites de l'√©quilibreur de charge interne (ILB), qui ne peut pas g√©rer plus de 20 000 connexions simultan√©es.  Et il nous en fallait 8 fois plus!  Par cons√©quent, nous avons ajout√© des ILB suppl√©mentaires √† notre couche de gestion des connexions. </p><br><p>  Au cours des premi√®res heures de pointe de charge apr√®s la transition, nous avons contr√¥l√© tous les param√®tres avec beaucoup de soin, car la totalit√© de la charge de la pile de messagerie a √©t√© transf√©r√©e vers GCP.  Il y a eu quelques probl√®mes mineurs que nous avons trait√©s tr√®s rapidement.  Lors de la migration d'autres services, nous avons adopt√© la m√™me approche. </p><br><h2 id="perenos-hranilischa-obektov">  Migration du stockage d'objets: </h2><br><p>  Nous utilisons le service de stockage d'objets principalement de trois mani√®res. </p><br><p>  ‚äπ Stockage de fichiers multim√©dias envoy√©s √† un chat personnel ou de groupe.  La p√©riode de conservation est d√©termin√©e par la politique de gestion du cycle de vie. <br>  ‚äπ Stockage d'images et de vignettes du profil utilisateur. <br>  ‚äπ Stockage des fichiers multim√©dias des sections "Historique" et "Chronologie" et les vignettes correspondantes. </p><br><p>  Nous avons utilis√© l'outil de transfert de stockage de Google pour copier les anciens objets de S3 vers GCS.  Nous avons √©galement utilis√© un MIG bas√© sur Kafka personnalis√© pour transf√©rer des objets de S3 vers GCS lorsqu'une logique sp√©ciale √©tait requise. </p><br><h3 id="perehod-s-s3-na-gcs-vklyuchal-sleduyuschie-shagi">  La transition de S3 √† GCS comprenait les √©tapes suivantes: </h3><br><p>  ‚óè Pour le premier cas d'utilisation du magasin d'objets, nous avons commenc√© √† √©crire de nouvelles donn√©es √† la fois sur S3 et GCS, et apr√®s l'expiration, nous avons commenc√© √† lire les donn√©es de GCS en utilisant la logique c√¥t√© application.  Le transfert d'anciennes donn√©es n'a pas de sens et cette approche est rentable. <br>  ‚óè Pour les deuxi√®me et troisi√®me cas d'utilisation, nous avons commenc√© √† √©crire de nouveaux objets dans GCS et modifi√© le chemin de lecture des donn√©es afin que la recherche soit d'abord effectu√©e dans GCS et ensuite, si l'objet n'est pas trouv√©, dans S3. <br>  Il a fallu des <strong>mois pour</strong> planifier, v√©rifier l'exactitude du concept, pr√©parer et prototyper, mais nous avons ensuite d√©cid√© de la transition et l'avons mise en ≈ìuvre tr√®s rapidement.  Nous avons √©valu√© les risques et r√©alis√© que la migration rapide est pr√©f√©rable et presque imperceptible. <br>  Ce projet √† grande √©chelle nous a aid√©s √† acqu√©rir une position forte et √† augmenter la productivit√© de l'√©quipe dans de nombreux domaines, car la plupart des op√©rations manuelles sur la gestion de l'infrastructure cloud sont d√©sormais du pass√©. <br>  ‚óè Quant aux utilisateurs, nous avons maintenant re√ßu tout le n√©cessaire pour assurer la meilleure qualit√© de service.  Les temps d'arr√™t ont presque disparu et les nouvelles fonctionnalit√©s sont mises en ≈ìuvre plus rapidement. <br>  ‚óè Notre √©quipe consacre moins de temps aux t√¢ches de maintenance et peut se concentrer sur les projets d'automatisation et la cr√©ation de nouveaux outils. <br>  ‚óè Nous avons eu acc√®s √† un ensemble d'outils sans pr√©c√©dent pour travailler avec les m√©gadonn√©es, ainsi qu'√† des fonctionnalit√©s pr√™tes √† l'emploi pour l'apprentissage et l'analyse automatiques.  Voir les d√©tails <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici.</a> <br>  ‚óè L'engagement de Google Cloud √† travailler avec le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet</a> open source <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes est</a> √©galement conforme √† notre plan de d√©veloppement pour cette ann√©e. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr430874/">https://habr.com/ru/post/fr430874/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr430864/index.html">Les matchs ne sont pas un jouet?</a></li>
<li><a href="../fr430866/index.html">P√©kin introduira une notation sociale pour les r√©sidents en 2020</a></li>
<li><a href="../fr430868/index.html">Que retenir lors de l'achat de NGFW? Liste de contr√¥le</a></li>
<li><a href="../fr430870/index.html">Installez BigBlueButton sur Ubuntu 16.04</a></li>
<li><a href="../fr430872/index.html">Qui gagnera le d√©bat sur le mesh contre ESB</a></li>
<li><a href="../fr430876/index.html">D√©veloppement par le test: am√©liorer les comp√©tences</a></li>
<li><a href="../fr430878/index.html">PhpStorm disponible 2018.3</a></li>
<li><a href="../fr430880/index.html">Une autre impl√©mentation du traitement des donn√©es</a></li>
<li><a href="../fr430882/index.html">Xiaomi Aqara Switch refaire de ZigBee √† Z-Wave</a></li>
<li><a href="../fr430884/index.html">Imprimerie: pourquoi "LANIT-Integration" a ouvert sa propre "imprimerie"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
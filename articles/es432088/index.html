<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚öõÔ∏è üàöÔ∏è ü§¥üèæ Alta disponibilidad de MySQL en GitHub üéöÔ∏è üç∂ üë©üèº‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub usa MySQL como su almac√©n de datos primario para todo lo que no est√° relacionado con git , por lo que la disponibilidad de MySQL es clave para ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Alta disponibilidad de MySQL en GitHub</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/432088/"><p> GitHub usa MySQL como su almac√©n de datos primario para todo lo que no est√° relacionado con <code>git</code> , por lo que la disponibilidad de MySQL es clave para el funcionamiento normal de GitHub.  El sitio en s√≠, la API de GitHub, el sistema de autenticaci√≥n y muchas otras caracter√≠sticas requieren acceso a bases de datos.  Utilizamos varios cl√∫steres de MySQL para manejar diversos servicios y tareas.  Se configuran seg√∫n el esquema cl√°sico con un nodo <em>principal</em> disponible para grabaci√≥n y sus r√©plicas.  <em>Las r√©plicas</em> (otros nodos del cl√∫ster) reproducen asincr√≥nicamente los cambios en el nodo principal y proporcionan acceso de lectura. </p><br><p>  La disponibilidad de los sitios host es cr√≠tica.  Sin el nodo principal, el cl√∫ster no admite grabaci√≥n, lo que significa que no puede guardar los cambios necesarios.  Arreglar transacciones, registrar problemas, crear nuevos usuarios, repositorios, revisiones y mucho m√°s ser√° simplemente imposible. </p><br><p>  Para admitir la grabaci√≥n, se requiere un nodo accesible correspondiente: el nodo principal en el cl√∫ster.  Sin embargo, la capacidad de identificar o <em>detectar</em> dicho nodo es igualmente importante. </p><br><p>  En caso de falla del nodo principal actual, es importante asegurar la aparici√≥n inmediata de un nuevo servidor para reemplazarlo, as√≠ como para poder notificar r√°pidamente a todos los servicios sobre este cambio.  El tiempo de inactividad total consiste en el tiempo necesario para detectar una falla, conmutar por error y notificar sobre un nuevo nodo principal. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  Esta publicaci√≥n describe una soluci√≥n para garantizar la alta disponibilidad de MySQL en GitHub y descubrir el servicio principal, que nos permite realizar operaciones de manera confiable que abarcan varios centros de datos, mantener la operatividad cuando algunos de estos centros no est√°n disponibles y garantizar un tiempo de inactividad m√≠nimo en caso de falla. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Objetivos de alta disponibilidad </h3><br><p>  La soluci√≥n descrita en este art√≠culo es una versi√≥n nueva y mejorada de soluciones anteriores de alta disponibilidad (HA) implementadas en GitHub.  A medida que crecemos, necesitamos adaptar la estrategia de MySQL HA para cambiar.  Nos esforzamos por seguir enfoques similares para MySQL y otros servicios en GitHub. </p><br><p>  Para encontrar la soluci√≥n adecuada para la alta disponibilidad y el descubrimiento de servicios, primero debe responder algunas preguntas espec√≠ficas.  Aqu√≠ hay una lista de muestra de ellos: </p><br><ul><li>  ¬øQu√© tiempo de inactividad m√°ximo no es cr√≠tico para usted? </li><li>  ¬øQu√© tan confiables son las herramientas de detecci√≥n de fallas?  ¬øSon cr√≠ticos para usted los falsos positivos (procesamiento de falla prematura)? </li><li>  ¬øQu√© tan confiable es el sistema de failover?  ¬øD√≥nde puede ocurrir una falla? </li><li>  ¬øQu√© tan efectiva es la soluci√≥n en m√∫ltiples centros de datos?  ¬øQu√© tan efectiva es la soluci√≥n en redes de baja y alta latencia? </li><li>  ¬øLa soluci√≥n continuar√° funcionando en caso de falla completa del centro de datos (DPC) o aislamiento de la red? </li><li>  ¬øQu√© mecanismo (si lo hay) previene o mitiga las consecuencias de la aparici√≥n de dos servidores principales en el cl√∫ster que graban de forma independiente? </li><li>  ¬øLa p√©rdida de datos es cr√≠tica para usted?  Si es as√≠, ¬øen qu√© medida? </li></ul><br><p>  Para demostrarlo, consideremos primero la soluci√≥n anterior y discutamos por qu√© decidimos abandonarla. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Negativa a usar VIP y DNS para el descubrimiento </h3><br><p>  Como parte de la soluci√≥n anterior, utilizamos: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">orquestador</a> para detecci√≥n de fallas y failover; </li><li>  VIP y DNS para descubrimiento de host. </li></ul><br><p>  En ese caso, los clientes descubrieron un nodo de grabaci√≥n por su nombre, por ejemplo, <code>mysql-writer-1.github.net</code> .  El nombre se us√≥ para determinar la direcci√≥n IP virtual (VIP) del nodo principal. </p><br><p>  Por lo tanto, en una situaci√≥n normal, los clientes simplemente ten√≠an que resolver el nombre y conectarse a la direcci√≥n IP recibida, donde el nodo principal ya los estaba esperando. </p><br><p>  Considere la siguiente topolog√≠a de replicaci√≥n que abarca tres centros de datos diferentes: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="imagen"></p><br><p>  En el caso de una falla del nodo principal, se debe asignar un nuevo servidor a su lugar (una de las r√©plicas). </p><br><p>  <code>orchestrator</code> detecta una falla, selecciona un nuevo nodo maestro y luego asigna el nombre / VIP.  Los clientes en realidad no conocen la identidad del nodo principal, solo conocen el nombre, que ahora deber√≠a apuntar al nuevo nodo.  Sin embargo, presta atenci√≥n a esto. </p><br><p>  Las direcciones VIP son compartidas, los servidores de bases de datos las solicitan y poseen.  Para recibir o liberar un VIP, el servidor debe enviar una solicitud ARP.  El servidor que posee el VIP primero debe liberarlo antes de que el nuevo maestro pueda acceder a esta direcci√≥n.  Este enfoque lleva a algunas consecuencias indeseables: </p><br><ul><li>  En modo normal, el sistema de conmutaci√≥n por error primero se pondr√° en contacto con el nodo principal fallido y le solicitar√° que libere el VIP, y luego recurrir√° al nuevo servidor principal con una solicitud de asignaci√≥n de VIP.  Pero, ¬øqu√© hacer si el primer nodo principal no est√° disponible o rechaza una solicitud para liberar la direcci√≥n VIP?  Dado que el servidor se encuentra actualmente en un estado de falla, es poco probable que pueda responder a una solicitud a tiempo o responderla en absoluto. <br><ol><li>  Como resultado, puede surgir una situaci√≥n cuando dos anfitriones reclaman sus derechos al mismo VIP.  Diferentes clientes pueden conectarse a cualquiera de estos servidores dependiendo de la ruta de red m√°s corta. </li><li>  El funcionamiento correcto en esta situaci√≥n depende de la interacci√≥n de dos servidores independientes, y dicha configuraci√≥n no es confiable. </li></ol></li><li>  Incluso si el primer nodo principal responde a las solicitudes, desperdiciamos un tiempo valioso: el cambio al nuevo servidor principal no ocurre mientras contactamos con el anterior. </li><li>  Adem√°s, incluso en el caso de la reasignaci√≥n de VIP, no hay garant√≠a de que las conexiones de clientes existentes en el servidor anterior se desconecten.  Nuevamente, corremos el riesgo de estar en una situaci√≥n con dos nodos principales independientes. </li></ul><br><p>  Aqu√≠ y all√°, dentro de nuestro entorno, las direcciones VIP est√°n asociadas con una ubicaci√≥n f√≠sica.  Se asignan a un conmutador o enrutador.  Por lo tanto, podemos reasignar una direcci√≥n VIP solo a un servidor ubicado en el mismo entorno que el host original.  En particular, en algunos casos, no podremos asignar un servidor VIP en otro centro de datos y necesitaremos realizar cambios en el DNS. </p><br><ul><li>  La distribuci√≥n de cambios al DNS lleva m√°s tiempo.  Los clientes almacenan nombres DNS por un per√≠odo de tiempo predefinido.  La conmutaci√≥n por error que involucra m√∫ltiples centros de datos implica un mayor tiempo de inactividad, ya que lleva m√°s tiempo proporcionar a todos los clientes informaci√≥n sobre el nuevo nodo principal. </li></ul><br><p>  Estas restricciones fueron suficientes para obligarnos a comenzar la b√∫squeda de una nueva soluci√≥n, pero tambi√©n tuvimos que tener en cuenta lo siguiente: </p><br><ul><li>  Los nodos principales transmitieron independientemente paquetes de pulsos a trav√©s del servicio <code>pt-heartbeat</code> para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">medir el retraso y la regulaci√≥n de la carga</a> .  El servicio tuvo que ser transferido al nodo principal reci√©n designado.  Si es posible, deber√≠a haberse desactivado en el servidor anterior. </li><li>  Del mismo modo, los nodos principales controlaban independientemente el funcionamiento del <a href="">Pseudo-GTID</a> .  Era necesario comenzar este proceso en el nuevo nodo principal y preferiblemente detenerse en el antiguo. </li><li>  El nuevo nodo maestro se puede escribir.  El nodo anterior (si es posible) deber√≠a tener <code>read_only</code> (solo lectura). </li></ul><br><p>  Estos pasos adicionales llevaron a un aumento en el tiempo de inactividad general y agregaron sus propios puntos de falla y problemas. </p><br><p>  La soluci√≥n funcion√≥ y GitHub manej√≥ con √©xito las fallas de MySQL en segundo plano, pero quer√≠amos mejorar nuestro enfoque de HA de la siguiente manera: </p><br><ul><li>  garantizar la independencia de centros de datos espec√≠ficos; </li><li>  garantizar la operatividad en caso de fallas del centro de datos; </li><li>  Abandonar flujos de trabajo colaborativos poco confiables </li><li>  reducir el tiempo de inactividad total; </li><li>  Realice, en la medida de lo posible, la conmutaci√≥n por error sin p√©rdida. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  Soluci√≥n GitHub HA: orquestador, c√≥nsul, GLB </h3><br><p>  Nuestra nueva estrategia, junto con las mejoras que la acompa√±an, elimina la mayor√≠a de los problemas mencionados anteriormente o mitiga sus consecuencias.  Nuestro sistema HA actual consta de los siguientes elementos: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">orquestador</a> para detecci√≥n de fallas y failover.  Utilizamos el esquema <a href="">orquestador / balsa</a> con varios centros de datos, como se muestra en la figura siguiente; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥nsul</a> Hashicorp para descubrimiento de servicio; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GLB / HAProxy</a> como capa proxy entre clientes y nodos de grabaci√≥n.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El c√≥digo fuente</a> para el Director GLB est√° abierto; </li><li>  Tecnolog√≠a <code>anycast</code> para enrutamiento de red. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="imagen"></p><br><p>  El nuevo esquema permiti√≥ abandonar por completo la realizaci√≥n de cambios en el VIP y DNS.  Ahora, al introducir nuevos componentes, podemos separarlos y simplificar la tarea.  Adem√°s, tuvimos la oportunidad de utilizar soluciones confiables y estables.  A continuaci√≥n se ofrece un an√°lisis detallado de la nueva soluci√≥n. </p><br><h3 id="normalnyy-potok">  Flujo normal </h3><br><p>  En una situaci√≥n normal, las aplicaciones se conectan a los nodos de grabaci√≥n a trav√©s de GLB / HAProxy. </p><br><p>  Las aplicaciones no reciben la identidad del servidor principal.  Como antes, usan solo el nombre.  Por ejemplo, el nodo principal para <code>mysql-writer-1.github.net</code> ser√≠a <code>mysql-writer-1.github.net</code> .  Sin embargo, en nuestra configuraci√≥n actual, este nombre se resuelve en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">direcci√≥n</a> IP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">anycast</a> . </p><br><p>  Gracias a la tecnolog√≠a <code>anycast</code> , el nombre se resuelve en la misma direcci√≥n IP en cualquier lugar, pero el tr√°fico se dirige de manera diferente, dada la ubicaci√≥n del cliente.  En particular, varias instancias de GLB, nuestro equilibrador de carga altamente disponible, se implementan en cada uno de nuestros centros de datos.  El tr√°fico en <code>mysql-writer-1.github.net</code> siempre se enruta al cl√∫ster GLB del centro de datos local.  Debido a esto, todos los clientes son atendidos por representantes locales. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ejecutamos</a> GLB sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HAProxy</a> .  Nuestro servidor HAProxy proporciona <em>grupos de escritura</em> : uno para cada cl√∫ster MySQL.  Adem√°s, cada grupo tiene solo un servidor (el nodo <em>principal</em> del cl√∫ster).  Todas las instancias GLB / HAProxy en todos los centros de datos tienen los mismos grupos, y todas apuntan a los mismos servidores en estos grupos.  Por lo tanto, si la aplicaci√≥n desea escribir datos en la base de datos en <code>mysql-writer-1.github.net</code> , no importa a qu√© servidor GLB se conecte.  En cualquier caso, se realizar√° una redirecci√≥n al nodo de cl√∫ster principal real <code>cluster1</code> . </p><br><p>  Para las aplicaciones, el descubrimiento finaliza en GLB, y el redescubrimiento no es necesario.  Ese GLB redirige el tr√°fico al lugar correcto. </p><br><p>  ¬øDe d√≥nde obtiene el GLB informaci√≥n sobre qu√© servidores enumerar?  ¬øC√≥mo hacemos cambios al GLB? </p><br><h3 id="obnaruzhenie-cherez-consul">  Descubrimiento a trav√©s del c√≥nsul </h3><br><p>  El servicio C√≥nsul es ampliamente conocido como una soluci√≥n de descubrimiento de servicios, y tambi√©n asume funciones de DNS.  Sin embargo, en nuestro caso, lo usamos como un almacenamiento altamente accesible de valores clave (KV). </p><br><p>  En el repositorio de KV en Consul, registramos la identidad de los nodos principales del cl√∫ster.  Para cada cl√∫ster, hay un conjunto de registros KV que apuntan a los datos del nodo principal correspondiente: sus <code>fqdn</code> , port, ipv4 e ipv6. </p><br><p>  Cada nodo GLB / HAProxy lanza una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">plantilla de c√≥nsul</a> , un servicio que rastrea los cambios en los datos de Consul (en nuestro caso, cambios en los datos de los nodos principales).  El servicio de <code>consul-template</code> crea un archivo de configuraci√≥n y puede volver a cargar HAProxy al cambiar la configuraci√≥n. </p><br><p>  Debido a esto, la informaci√≥n sobre c√≥mo cambiar la identidad del nodo principal en Consul est√° disponible para cada instancia de GLB / HAProxy.  En funci√≥n de esta informaci√≥n, se realiza la configuraci√≥n de las instancias, los nuevos nodos principales se indican como la √∫nica entidad en el grupo de servidores del cl√∫ster.  Despu√©s de eso, las instancias se vuelven a cargar para que los cambios surtan efecto. </p><br><p>  Hemos implementado instancias de Consul en cada centro de datos, y cada instancia proporciona alta disponibilidad.  Sin embargo, estas instancias son independientes entre s√≠.  No se replican ni intercambian ning√∫n dato. </p><br><p>  ¬øD√≥nde obtiene Consul informaci√≥n sobre los cambios y c√≥mo se distribuye entre los centros de datos? </p><br><h3 id="orchestratorraft">  orquestador / balsa </h3><br><p>  Utilizamos el esquema <code>orchestrator/raft</code> : los nodos del <code>orchestrator</code> comunican entre s√≠ a trav√©s del consenso de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">balsa</a> .  En cada centro de datos, tenemos uno o dos nodos de <code>orchestrator</code> . </p><br><p>  <code>orchestrator</code> es responsable de detectar fallas, conmutaci√≥n por error de MySQL y transferir los datos del nodo maestro modificado a Consul.  La conmutaci√≥n por error es administrada por un √∫nico <code>orchestrator/raft</code> host de <code>orchestrator/raft</code> , pero los <em>cambios</em> , noticias de que el cl√∫ster ahora es un nuevo maestro, se propagan a todos los nodos del <code>orchestrator</code> utilizando el mecanismo de <code>raft</code> . </p><br><p>  Cuando los nodos del <code>orchestrator</code> reciben noticias sobre un cambio en los datos del nodo principal, cada uno de ellos contacta con su propia instancia local de C√≥nsul e inicia una grabaci√≥n KV.  Los centros de datos con m√∫ltiples instancias de <code>orchestrator</code> recibir√°n varios registros (id√©nticos) en el C√≥nsul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  Vista generalizada de toda la transmisi√≥n. </h3><br><p>  Si el nodo maestro falla: </p><br><ul><li>  <code>orchestrator</code> nodos del <code>orchestrator</code> detectan fallas; </li><li>  <code>orchestrator/raft</code> maestro de <code>orchestrator/raft</code> inicia la recuperaci√≥n.  Se asigna un nuevo nodo maestro; </li><li>  el esquema de <code>orchestrator/raft</code> transfiere los datos sobre el cambio del nodo principal a todos los nodos del grupo de <code>raft</code> </li><li>  cada instancia de <code>orchestrator/raft</code> recibe una notificaci√≥n sobre un cambio de nodo y escribe la identidad de un nuevo nodo maestro en el almacenamiento KV local en Consul; </li><li>  en cada instancia de GLB / HAProxy, se inicia el servicio de <code>consul-template</code> , que monitorea los cambios en el repositorio de KV en Consul, reconfigura y reinicia HAProxy; </li><li>  El tr√°fico del cliente se redirige al nuevo nodo maestro. </li></ul><br><p>  Para cada componente, las responsabilidades est√°n claramente distribuidas y toda la estructura est√° diversificada y simplificada.  <code>orchestrator</code> no interact√∫a con los equilibradores de carga.  El c√≥nsul no requiere informaci√≥n sobre el origen de la informaci√≥n.  Los servidores proxy solo funcionan con Consul.  Los clientes solo trabajan con servidores proxy. </p><br><p>  Por otra parte: </p><br><ul><li>  No es necesario realizar cambios en el DNS y difundir informaci√≥n sobre ellos; </li><li>  TTL no se utiliza; </li><li>  el hilo no espera respuestas del host en un estado de error.  En general, se ignora. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Informaci√≥n adicional </h3><br><p>  Para estabilizar el flujo, tambi√©n aplicamos los siguientes m√©todos: </p><br><ul><li>  El par√°metro HAProxy <code>hard-stop-after</code> se establece en un valor muy peque√±o.  Cuando HAProxy se reinicia con el nuevo servidor en el grupo de escritura, el servidor termina autom√°ticamente todas las conexiones existentes al antiguo nodo maestro. <br><ol><li>  Establecer el par√°metro <code>hard-stop-after</code> permite no esperar ninguna acci√≥n de los clientes, adem√°s, las consecuencias negativas de la posible aparici√≥n de dos nodos principales en el cl√∫ster se minimizan.  Es importante entender que no hay magia aqu√≠, y en cualquier caso, pasa <em>alg√∫n tiempo</em> antes de que se rompan los viejos lazos.  Pero hay un punto en el tiempo despu√©s del cual podemos dejar de esperar sorpresas desagradables. </li></ol></li><li>  No requerimos la disponibilidad continua del servicio de C√≥nsul.  De hecho, necesitamos que est√© disponible solo durante la conmutaci√≥n por error.  Si el servicio de C√≥nsul no responde, GLB contin√∫a trabajando con los √∫ltimos valores conocidos y no toma medidas dr√°sticas. </li><li>  El GLB est√° configurado para verificar la identidad del nodo maestro reci√©n asignado.  Al igual que con nuestros <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">grupos de MySQL sensibles al contexto</a> , se realiza una verificaci√≥n para confirmar que el servidor se puede escribir.  Si eliminamos accidentalmente la identidad del nodo principal en Consul, entonces no habr√° problemas, se ignorar√° un registro vac√≠o.  Si escribimos por error el nombre de otro servidor (no el principal) al C√≥nsul, entonces en este caso est√° bien: GLB no lo actualizar√° y continuar√° trabajando con el √∫ltimo estado v√°lido. </li></ul><br><p>  En las siguientes secciones, analizamos los problemas y analizamos los objetivos de alta disponibilidad. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Detecci√≥n de choque con orquestador / balsa </h3><br><p>  <code>orchestrator</code> adopta un <a href="">enfoque integral</a> para la detecci√≥n de fallas, lo que garantiza una alta confiabilidad de la herramienta.  No encontramos resultados falsos positivos, no se realizan fallas prematuras, lo que significa que se excluye el tiempo de inactividad innecesario. </p><br><p>  El circuito del <code>orchestrator/raft</code> tambi√©n hace frente a situaciones de aislamiento completo de la red del centro de datos (cercado del centro de datos).  El aislamiento de la red del centro de datos puede causar confusi√≥n: los servidores dentro del centro de datos pueden comunicarse entre s√≠.  ¬øC√≥mo entender qui√©n est√° realmente aislado: servidores <em>dentro de un</em> centro de datos <em>dado</em> o todos los <em>dem√°s</em> centros de datos? </p><br><p>  En el esquema de <code>orchestrator/raft</code> , el maestro de <code>orchestrator/raft</code> es conmutaci√≥n por error.  El nodo se convierte en el l√≠der, que recibe el apoyo de la mayor√≠a del grupo (qu√≥rum).  Hemos implementado el nodo del <code>orchestrator</code> de tal manera que ning√∫n centro de datos √∫nico puede proporcionar la mayor√≠a, mientras que cualquier centro de datos <code>n-1</code> puede proporcionarlo. </p><br><p>  En el caso del aislamiento completo de la red del centro de datos, los nodos del <code>orchestrator</code> en este centro est√°n desconectados de nodos similares en otros centros de datos.  Como resultado, los nodos del <code>orchestrator</code> en un centro de datos aislado no pueden convertirse en l√≠deres en un grupo de <code>raft</code> .  Si tal nodo era el maestro, entonces pierde este estado.  A un nuevo host se le asignar√° uno de los nodos de los otros centros de datos.  Este l√≠der tendr√° el apoyo de todos los dem√°s centros de datos que pueden interactuar entre s√≠. </p><br><p>  De esta manera, el maestro del <code>orchestrator</code> siempre estar√° fuera del centro de datos aislado de la red.  Si el nodo maestro estaba ubicado en un centro de datos aislado, el <code>orchestrator</code> inicia una conmutaci√≥n por error para reemplazarlo con el servidor de uno de los centros de datos disponibles.  Mitigamos el impacto del aislamiento del centro de datos delegando decisiones al qu√≥rum de centros de datos disponibles. </p><br><h3 id="uskorennoe-opoveschenie">  Notificaci√≥n m√°s r√°pida </h3><br><p>  El tiempo de inactividad total se puede reducir a√∫n m√°s acelerando la notificaci√≥n de un cambio en el nodo principal.  ¬øC√≥mo lograr esto? </p><br><p>  Cuando el <code>orchestrator</code> inicia la conmutaci√≥n por error, considera un grupo de servidores, uno de los cuales puede asignarse como el principal.  Dadas las reglas de replicaci√≥n, las recomendaciones y las limitaciones, puede tomar una decisi√≥n informada sobre el mejor curso de acci√≥n. </p><br><p>  De acuerdo con los siguientes signos, tambi√©n puede entender que un servidor accesible es <em>un candidato ideal</em> para ser nombrado como el principal: </p><br><ul><li>  nada impide que el servidor se eleve (y tal vez el usuario recomienda este servidor); </li><li>  se espera que el servidor pueda usar todos los dem√°s servidores como r√©plicas. </li></ul><br><p>  En este caso, el <code>orchestrator</code> primero configura el servidor como grabable e inmediatamente anuncia un aumento en su estado (en nuestro caso, escribe el registro en el repositorio KV en Consul).   orchestrator     ,     . </p><br><p>  ,    ,    GLB   ,     ,     .   :    ! </p><br><h3 id="polusinhronnaya-replikaciya">   </h3><br><p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> MySQL         ,           .       :  ,    ,   ,        . </p><br><p>     ,      .        ,    ,   .  ,    ,           ,    . </p><br><p>       : <code>500 </code> .                    .          (    ),          . </p><br><p>                   (   )    .           ,      . </p><br><p>       ,        <em> </em>     .            <em></em> ,      ,  <em></em>    .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> ,       <em> </em> , ,       . </p><br><h3 id="peredacha-paketov-pulsa">    </h3><br><p>  ,   /  <code>pt-heartbeat</code>  /  ,       .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> ,   <code>pt-heartbeat</code>     ,       <code>read_only</code> ,    . </p><br><p>      <code>pt-heartbeat</code>     ,     .       .               .     ,  <code>pt-heartbeat</code>              . </p><br><h3 id="delegirovanie-zadach-orchestrator">   orchestrator </h3><br><p>    orchestrator  : </p><br><ul><li>  Pseudo-GTID; </li><li>       ,    ; </li><li>         ( <code>read_only</code> ),   . </li></ul><br><p>    ,     . ,      ,      ,      .     <code>orchestrator</code>         . </p><br><h3 id="ogranicheniya-i-nedostatki">    </h3><br><p>  -   ,        ,         .     ,   -,         . </p><br><p>     ,       . </p><br><p> ,      ,     ,     -      .         .               <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">STONITH</a>    .    ,  <em> </em> ,       ,    ¬´¬ª -   .  ,       ,  . </p><br><p>    :  Consul    ,     . .  , ,      ,    ,      . </p><br><h3 id="rezultaty">  </h3><br><p>   orchestrator/GLB/Consul   : </p><br><ul><li>   ; </li><li>      ; </li><li>       ; </li><li>    ; </li><li>  ,      (    ); </li><li>    ; </li><li>    <code>10-13 </code>   . <br><ol><li>        <code>20 </code> ,      ‚Äî <code>25 </code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Conclusi√≥n </h3><br><p>  ¬´// ¬ª         ,   ,   .       .     ,    . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es432088/">https://habr.com/ru/post/es432088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es432078/index.html">Tr√°fico al final del t√∫nel o DNS en el pentest</a></li>
<li><a href="../es432080/index.html">Las ideas err√≥neas de los jugadores al evaluar los riesgos. Control del generador de n√∫meros aleatorios en desarrollo.</a></li>
<li><a href="../es432082/index.html">Microsoft AI Chatbot lanza la colecci√≥n de ropa de China</a></li>
<li><a href="../es432084/index.html">C√≥mo organizamos una competencia por turnos entre los trabajadores de producci√≥n (como en la URSS)</a></li>
<li><a href="../es432086/index.html">Impresi√≥n 3D en la escuela internacional que lleva el nombre de M.V. Lomonosov</a></li>
<li><a href="../es432090/index.html">Magento Meetup Kharkiv No. 4 - informes en video</a></li>
<li><a href="../es432092/index.html">Errores desagradables al escribir pruebas unitarias</a></li>
<li><a href="../es432094/index.html">Hackathon en l√≠nea conjunto de OpenGift y Credits Blockchain Platform</a></li>
<li><a href="../es432096/index.html">Gu√≠a completa de CMake. Segunda parte: sistema de compilaci√≥n</a></li>
<li><a href="../es432098/index.html">Pilotos autom√°ticos en el transporte por carretera, c√≥mo interactuar con especiales. en transporte?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚å®Ô∏è üîπ üßëüèº‚Äçü§ù‚Äçüßëüèª 12 neue k√ºnstliche Intelligenz f√ºr Azure Media Services üßúüèº üñ•Ô∏è üßü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Mission von Microsoft ist es, jeder Person und Organisation auf dem Planeten die M√∂glichkeit zu geben, mehr zu erreichen. Die Medienbranche ist ei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>12 neue k√ºnstliche Intelligenz f√ºr Azure Media Services</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/469031/">  Die Mission von Microsoft ist es, jeder Person und Organisation auf dem Planeten die M√∂glichkeit zu geben, mehr zu erreichen.  Die Medienbranche ist ein hervorragendes Beispiel f√ºr die Umsetzung dieser Mission in die Realit√§t.  Wir leben in einer Zeit, in der immer mehr Inhalte erstellt und konsumiert werden, alles auf gro√üartige Weise und auf mehr Ger√§ten.  Auf der IBC 2019 haben wir die neuesten Innovationen vorgestellt, an denen wir gerade arbeiten, und dar√ºber gesprochen, wie sie zur Transformation Ihres Medienprozesses beitragen k√∂nnen. <br><img src="https://habrastorage.org/getpro/habr/post_images/d33/662/fc1/d33662fc1b9cb7b3a7310711f087a51d.jpg"><br>  Details unter dem Schnitt! <a name="habracut"></a><br><br>  Diese Seite befindet sich auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserer Website.</a> <br><br><h2>  Video Indexer bietet Unterst√ºtzung f√ºr Animationen und mehrsprachige Inhalte </h2><br>  Letztes Jahr haben wir auf der IBC unseren preisgekr√∂nten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Azure Media Services-Videoindexer ver√∂ffentlicht</a> , und dieses Jahr wurde er noch besser.  Der Video-Indexer extrahiert automatisch Informationen und Metadaten aus Mediendateien wie gesprochenen W√∂rtern, Gesichtern, Emotionen, Themen und Marken, und Sie m√ºssen kein Experte f√ºr maschinelles Lernen sein, um sie zu verwenden. <br><br>  Unsere neuesten Angebote umfassen vorl√§ufige Versionen von zwei sehr beliebten und differenzierten Funktionen - Erkennung von animierten Zeichen und Transkription mehrsprachiger Sprache sowie mehrere Erg√§nzungen zu bestehenden Modellen, die heute im Video Indexer verf√ºgbar sind. <br><br><h2>  Erkennung von animierten Charakteren </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/01f/1ab/900/01f1ab900cce076468f55a62bc103b2f.png"><br>  Zeichentrickfilme sind eine der beliebtesten Arten von Inhalten, aber Standard-Bildverarbeitungsmodelle, die zum Erkennen menschlicher Gesichter erstellt wurden, funktionieren nicht sehr gut damit, insbesondere wenn der Inhalt Zeichen ohne menschliche Merkmale enth√§lt.  In der neuen Vorschau-Version ist Video Indexer in den Azure Custom Vision-Dienst von Microsoft integriert. Dadurch werden neue Modelle erstellt, die animierte Zeichen automatisch erkennen und gruppieren und das Kennzeichnen und Erkennen mithilfe integrierter benutzerdefinierter Bildverarbeitungsmodelle vereinfachen. <br><br>  Die Modelle sind in einem einzigen F√∂rderband integriert, sodass jeder diesen Service ohne Kenntnisse im Bereich des maschinellen Lernens nutzen kann.  Die Ergebnisse sind √ºber das Video Indexer-Portal verf√ºgbar, f√ºr das kein Code erforderlich ist, oder √ºber die REST-API f√ºr die schnelle Integration in Ihre eigenen Anwendungen. <br><br>  Wir haben diese Modelle f√ºr die Arbeit mit animierten Charakteren zusammen mit einigen Verbrauchern erstellt, die echte animierte Inhalte f√ºr Schulungen und Tests bereitgestellt haben.  Der Wert der neuen Funktionalit√§t wurde von Andy Gutteridge, Senior Director f√ºr Studiotechnologie und Postproduktion von Viacom International Media Networks, der einer der Datenanbieter war, gut beschrieben: ‚ÄûDurch Hinzuf√ºgen einer robusten AI-basierten Funktion zur Erkennung animierter Inhalte k√∂nnen wir schnell und effizient Zeichenmetadaten aus unserer Bibliothek finden und katalogisieren Inhalt. <br><br>  Vor allem wird es unseren Kreativteams die M√∂glichkeit geben, sofort die richtigen Inhalte zu finden, den Zeitaufwand f√ºr die Verwaltung der Medien zu minimieren und uns auf die Kreativit√§t zu konzentrieren. ‚Äú <br><br>  Sie k√∂nnen die Erkennung animierter Zeichen auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentationsseite untersuchen</a> . <br><br><h2>  Identifizierung und Transkription von Inhalten in mehreren Sprachen </h2><br>  Einige Medienressourcen wie Nachrichten, Ereignischroniken und Interviews enthalten Aufzeichnungen von Personen, die verschiedene Sprachen sprechen.  Die meisten der vorhandenen Optionen zum √úbersetzen von Sprache in Text erfordern eine vorl√§ufige Angabe der Tonerkennungssprache, was das Transkribieren mehrsprachiger Videos erschwert. <br><br>  Unsere neue Funktion zur automatischen Identifizierung einer gesprochenen Sprache f√ºr verschiedene Arten von Inhalten verwendet die Technologie des maschinellen Lernens, um Sprachen in Medienressourcen zu identifizieren.  Nach der Erkennung durchl√§uft jedes Sprachsegment automatisch den Transkriptionsprozess in der entsprechenden Sprache. Anschlie√üend werden alle Segmente zu einer einzigen Transkriptionsdatei zusammengefasst, die aus mehreren Sprachen besteht. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/593/b6c/37c/593b6c37c928baa329de15eb80f0a8af.png"><br><br>  Die resultierende Entschl√ºsselung ist als Teil der Ausgabe des JSON Video Indexer und in Form von Dateien mit Untertiteln verf√ºgbar.  Die Ausgabeentschl√ºsselung ist auch in Azure Search integriert, sodass Sie sofort nach verschiedenen Sprachsegmenten in Videos suchen k√∂nnen.  Dar√ºber hinaus ist bei der Arbeit mit dem Video Indexer-Portal eine mehrsprachige Transkription verf√ºgbar, sodass Sie das Transkript und die identifizierte Sprache nach Zeit anzeigen oder f√ºr jede Sprache zu bestimmten Stellen im Video gehen und w√§hrend der Videowiedergabe eine mehrsprachige Transkription in Form von Signaturen anzeigen k√∂nnen.  Sie k√∂nnen den resultierenden Text auch √ºber das Portal und die API in eine der 54 verf√ºgbaren Sprachen √ºbersetzen. <br><br>  Weitere Informationen zur neuen Funktion zur Erkennung mehrsprachiger Inhalte und ihrer Verwendung im Video-Indexer finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der Dokumentation</a> . <br><br><h2>  Zus√§tzliche aktualisierte und verbesserte Modelle </h2><br>  Wir f√ºgen dem Video-Indexer auch neue Modelle hinzu und verbessern vorhandene, einschlie√ülich der unten beschriebenen. <br><br><h4>  Abrufen von mit Personen und Orten verkn√ºpften Entit√§ten </h4><br>  Wir haben unsere bestehenden M√∂glichkeiten zur Markenentdeckung um bekannte Namen und Standorte wie den Eiffelturm in Paris und den Big Ben in London erweitert.  Wenn sie in der generierten Entschl√ºsselung oder mithilfe der optischen Zeichenerkennung (OCR) auf dem Bildschirm angezeigt werden, werden die entsprechenden Informationen hinzugef√ºgt.  Mit dieser neuen Funktion k√∂nnen Sie alle Personen, Orte und Marken durchsuchen, die im Video angezeigt werden, und Informationen zu diesen anzeigen, einschlie√ülich Zeitintervallen, Beschreibungen und Links zur Bing-Suchmaschine, um weitere Informationen zu erhalten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/750/c43/023/750c43023844290c35eefa61f2867890.png"><br><br><h4>  Editor-Erkennungsmodell </h4><br>  Diese neue Funktion f√ºgt den Metadaten, die einzelnen Frames in den JSON-Details zugeordnet sind, eine Reihe von ‚ÄûTags‚Äú hinzu, um deren redaktionellen Typ darzustellen (z. B. Weitwinkel, mittlerer Frame, Nahaufnahme, sehr Nahaufnahme, zwei Aufnahmen, mehrere Personen, im Freien, drinnen usw.).  Diese Rahmentypmerkmale sind n√ºtzlich, wenn Sie Videos f√ºr Clips und Trailer bearbeiten oder nach einem bestimmten Bildstil f√ºr k√ºnstlerische Zwecke suchen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2e8/634/2b4/2e86342b4eb18285316689503e59ac63.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Weitere</a> Informationen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zur</a> Frame-Typ-Erkennung finden Sie im Video-Indexer. <br><br><h4>  Erweiterte IPTC-Zuordnungsdetails </h4><br>  Unser Themenerkennungsmodell identifiziert ein Videothema basierend auf Transkription, optischer Zeichenerkennung (OCR) und entdeckten Prominenten, auch wenn das Thema nicht explizit angegeben ist.  Wir ordnen diese entdeckten Themen vier Klassifizierungsbereichen zu: Wikipedia, Bing, IPTC und IAB.  Diese Verbesserung erm√∂glicht es uns, eine IPTC-Klassifizierung der zweiten Ebene aufzunehmen. <br>  Die Nutzung dieser Verbesserungen ist so einfach wie die Neuindizierung Ihrer aktuellen Video Indexer-Bibliothek. <br><br><h4>  Neue Live-Streaming-Funktionalit√§t </h4><br>  In der Vorschau-Version von Azure Media Services bieten wir au√üerdem zwei neue Funktionen f√ºr das Live-Streaming. <br><br><h4>  Die Echtzeit-Transkription von KI bringt Live-√úbertragungen auf die n√§chste Stufe </h4><br>  Wenn Sie Azure Media Services f√ºr das Live-Streaming verwenden, k√∂nnen Sie jetzt einen Ausgabestream abrufen, der neben Audio- und Videoinhalten auch eine automatisch generierte Textspur enth√§lt.  Text wird durch Transkribieren von Echtzeit-Audio basierend auf k√ºnstlicher Intelligenz erstellt.  Benutzerdefinierte Methoden werden vor und nach der Konvertierung von Sprache in Text angewendet, um die Ergebnisse zu verbessern.  Die Textspur ist in IMSC1, TTML oder WebVTT gepackt, je nachdem, ob sie in DASH, HLS CMAF oder HLS TS vorliegt. <br><br><h4>  Lineare Echtzeitcodierung f√ºr 24/7-OTT-Kan√§le </h4><br>  Mit unserer API v3 k√∂nnen Sie Kan√§le mithilfe der OTT-Technologie (Over-the-Top) erstellen, Live-√úbertragungen verwalten und verwalten sowie alle anderen Azure Media Services-Funktionen wie Live-Video-on-Demand (VOD) verwenden. Video on Demand), Verpackung und Digital Rights Management (DRM). <br>  Eine Vorschau dieser Funktionen finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Community-</a> Seite von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Azure Media Services</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/176/eab/e8a/176eabe8a1e9c0cf847b80d0a122f3a5.png"><br><br><h4>  Neue Funktionen zur Paketgenerierung </h4><br><h4>  Sound Track Beschreibung Unterst√ºtzung </h4><br>  Inhalte, die auf Sendekan√§len ausgestrahlt werden, enthalten h√§ufig eine Audiospur mit verbalen Erkl√§rungen dar√ºber, was zus√§tzlich zum normalen Audiosignal auf dem Bildschirm geschieht.  Dies macht Programme f√ºr sehbehinderte Zuschauer zug√§nglicher, insbesondere wenn der Inhalt haupts√§chlich visuell ist.  Mit der neuen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Audiobeschreibungsfunktion</a> k√∂nnen Sie eine der Audiospuren als Audiobeschreibungsspur (AD, Audiobeschreibung) mit Anmerkungen versehen, damit die Spieler die AD-Spur f√ºr die Zuschauer zug√§nglich machen k√∂nnen. <br><br><h4>  F√ºgen Sie ID3-Metadaten ein </h4><br>  Rundfunkunternehmen verwenden h√§ufig im Video eingebettete zeitbasierte Metadaten, um ein Signal √ºber das Einf√ºgen von Werbung oder benutzergenerierten Metadatenereignissen auf den Player des Kunden zu √ºbertragen.  Zus√§tzlich zu den SCTE-35-Signalisierungsmodi unterst√ºtzen wir jetzt auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ID3v2 und andere</a> vom Anwendungsentwickler definierte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benutzerschemata</a> zur Verwendung durch die Clientanwendung. <br><br><h2>  Microsoft Azure-Partner pr√§sentieren End-to-End-L√∂sungen </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bitmovin</a> f√ºhrt die Bitmovin-Videokodierung und den Bitmovin-Video-Player f√ºr Microsoft Azure ein.  Kunden k√∂nnen diese Codierungs- und Wiedergabel√∂sungen jetzt in Azure verwenden und erweiterte Funktionen wie dreistufige Codierung, Unterst√ºtzung f√ºr AV1 / VC-Codecs, mehrsprachige Untertitel und vorintegrierte Videoanalysen f√ºr QoS, Werbung und Video-Tracking verwenden. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Evergent</a> pr√§sentiert seine User Lifecycle Management Platform in Azure.  Als f√ºhrender Anbieter von Managementl√∂sungen f√ºr Umsatz und Kundenlebenszyklus nutzt Evergent Azure AI, um Premium-Unterhaltungsanbietern dabei zu helfen, die Kundenbindung und -bindung zu verbessern, indem gezielte Servicepakete und Angebote zu kritischen Zeiten in ihrem Lebenszyklus erstellt werden. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Haivision</a> wird seinen intelligenten Cloud-basierten Multimedia-Routing-Service SRT Hub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorstellen</a> , mit dem Kunden Workflows mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Azure Data Box Edge</a> von Anfang bis Ende transformieren und Workflows mithilfe von Hublets von Avid, Telestream, Wowza, Cinegy und Make.tv transformieren k√∂nnen. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SES hat</a> die Azure-basierte Broadcast Class Media Services Suite f√ºr seine satellitenbasierten und verwalteten Mediendienstkunden entwickelt.  SES zeigt L√∂sungen f√ºr vollst√§ndig verwaltete Wiedergabedienste, einschlie√ülich Master-Wiedergabe, lokalisierter Wiedergabe, Anzeigenerkennung und -ersetzung sowie hochwertiger 24-Stunden-Echtzeit-Mehrkanalcodierung in Azure. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SyncWords</a> stellt in Azure praktische Cloud-Tools und -Technologien zum Erstellen von Signaturen zur Verf√ºgung.  Diese Angebote erleichtern Medienunternehmen das automatische Hinzuf√ºgen von Untertiteln, auch in einer Fremdsprache, zu den Workflows der Videoverarbeitung in Echtzeit und offline in Azure. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tata Elxsi</a> , ein internationales Technologiedienstleistungsunternehmen, hat seine OTT SaaS TEPlay-Plattform in Azure Media Services integriert, um OTT-Inhalte aus der Cloud bereitzustellen.  Tata Elxsi hat auch die QoE-L√∂sung von Falcon Eye, die Analyse- und Entscheidungsmetriken bereitstellt, auf Microsoft Azure migriert. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verizon Media</a> stellt seine Streaming-Plattform als Beta auf Azure zur Verf√ºgung.  Verizon Media Platform ist eine OTT-L√∂sung f√ºr Unternehmen, die DRM, Anzeigeneinf√ºgung, personalisierte personalisierte Sitzungen, dynamischen Inhaltsaustausch und Videobereitstellung umfasst.  Die Integration vereinfacht Workflows, globale Unterst√ºtzung und Skalierbarkeit und bietet Ihnen Zugriff auf eine Reihe einzigartiger Funktionen in Azure. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de469031/">https://habr.com/ru/post/de469031/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de469019/index.html">SPA Meetup 5: Jest-Integration mit QA, leistungsstarkes UIKit, Komponentenbibliotheken, DI f√ºr die Skalierung, Plattformbefehle</a></li>
<li><a href="../de469021/index.html">Entwicklung in einem Monorepository. Yandex-Bericht</a></li>
<li><a href="../de469023/index.html">So finden Sie einen Job mit Umzug nach Europa: ein praktischer Leitfaden f√ºr IT-Experten</a></li>
<li><a href="../de469025/index.html">K√ºhlen Sie den Wein schnell ab! Russische Erfindung</a></li>
<li><a href="../de469027/index.html">Ivanovo! Mitap: Wie baue ich eine Karriere in Digital auf?</a></li>
<li><a href="../de469033/index.html">Starten der Elbrus-Plattform f√ºr neuronale PuzzleLib-Netzwerke</a></li>
<li><a href="../de469035/index.html">Die neuen AI-basierten Innovationen von Azure Media Services</a></li>
<li><a href="../de469037/index.html">Industrielle Steuerung. Datenerfassungssystem. ACS</a></li>
<li><a href="../de469039/index.html">Mehr als ein Spiel: Mahjong mit KI und maschinellem Lernen meistern</a></li>
<li><a href="../de469041/index.html">Wie sch√ºtzen Sie Ihr ERP-System?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
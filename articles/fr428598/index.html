<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüè≠ ü•Ñ üíÖüèº R√©seaux de neurones profonds pour l'√©valuation automatique des appels üôèüèª üò≤ üë©üèø‚Äçü§ù‚Äçüë©üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'√©valuation des appels est un √©l√©ment cl√© du contr√¥le qualit√© des centres d'appels. Il permet aux organisations d'affiner leur flux de travail afin q...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>R√©seaux de neurones profonds pour l'√©valuation automatique des appels</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/428598/">  L'√©valuation des appels est un √©l√©ment cl√© du contr√¥le qualit√© des centres d'appels.  Il permet aux organisations d'affiner leur flux de travail afin que les op√©rateurs puissent travailler plus rapidement et plus efficacement et √©galement √©viter une routine vide de sens. <br><br>  Conscient que le centre d'appels doit √™tre efficace, nous avons travaill√© sur l'automatisation des scores d'appels.  En cons√©quence, nous avons trouv√© un algorithme qui traite les appels et les r√©partit en deux groupes: suspects et neutres.  Tous les appels suspects ont √©t√© imm√©diatement envoy√©s √† l'√©quipe d'√©valuation de la qualit√©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yj/0t/yq/yj0tyqtftcw-e0m_wcxkh_ls7l0.jpeg"></div><br><a name="habracut"></a><br>
<h2>  Comment nous avons form√© un r√©seau neuronal profond </h2><br>  Pour les √©chantillons, nous avons pris 1700 fichiers audio, sur lesquels nous avons form√© le r√©seau.  Comme le neurone ne savait pas au d√©part ce qu'il fallait consid√©rer comme suspect et ce qui √©tait neutre, nous avons marqu√© manuellement tous les fichiers en cons√©quence. <br><br>  Dans les √©chantillons neutres, les op√©rateurs: <br><br><ul><li>  n'ont pas √©lev√© la voix; </li><li>  Fournir aux clients toutes les informations demand√©es; </li><li>  n'a pas r√©pondu aux provocations du client. </li></ul><br>  Dans les sch√©mas suspects, les op√©rateurs faisaient souvent ce qui suit: <br><br><ul><li>  utilis√© un langage obsc√®ne; </li><li>  √©lever la voix ou crier aux clients; </li><li>  est all√© √† la personne; </li><li>  a refus√© de conseiller sur les questions. </li></ul><br>  Lorsque l'algorithme a fini de traiter les fichiers, il a marqu√© 200 fichiers comme non valides.  Ces fichiers ne contiennent aucun signe suspect ou neutre.  Nous avons d√©couvert ce qu'il y avait dans ces 200 fichiers: <br><br><ul><li>  le client a raccroch√© imm√©diatement apr√®s que l'op√©rateur lui a r√©pondu; </li><li>  le client n'a rien dit apr√®s avoir re√ßu une r√©ponse; </li><li>  il y avait trop de bruit c√¥t√© client ou op√©rateur. </li></ul><br>  Lorsque nous avons supprim√© ces fichiers, nous avons divis√© les 1 500 restants en cas de formation et de test.  √Ä l'avenir, nous avons utilis√© ces ensembles de donn√©es pour former et tester un r√©seau neuronal profond. <br><br><h2>  √âtape 1: Extraire les fonctionnalit√©s </h2><br>  L'extraction de fonctionnalit√©s de haut niveau joue un r√¥le important dans l'apprentissage automatique, car  cela affecte directement l'efficacit√© de l'algorithme.  Apr√®s avoir analys√© toutes les sources possibles, nous avons s√©lectionn√© les sympt√¥mes suivants: <br><br><h3>  Statistiques de temps </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Taux de passage √† z√©ro</a> : vitesse √† laquelle le signal passe de plus √† moins et vice versa. </li><li>  <b>√ânergie m√©diane de la trame</b> : somme des signaux au carr√© et normalis√©e √† la longueur de trame correspondante. </li><li>  <b>Entropie d'√©nergie de sous-trame</b> : l'entropie de l'√©nergie de sous-trame normalis√©e.  Il peut √™tre interpr√©t√© comme une mesure de changements drastiques. </li><li>  <b>L'√©cart moyen / m√©dian / standard du cadre</b> . </li></ul><br><h3>  Statistiques spectrales (avec intervalles de fr√©quence) </h3><br><ol><li>  Spectral Centroid. </li><li>  Distribution spectrale. </li><li>  Entropie spectrale. </li><li>  Rayonnement spectral. </li><li>  Att√©nuation spectrale. </li></ol><br>  Les coefficients cepstraux de la fr√©quence tonale et du vecteur de saturation sont sensibles √† la longueur du signal d'entr√©e.  Nous pourrions les extraire de l'ensemble du fichier √† la fois, mais ce faisant, nous manquerions le d√©veloppement du trait √† temps.  Cette m√©thode ne nous convenant pas, nous avons d√©cid√© de diviser le signal en ¬´fen√™tres¬ª (blocs de temps). <br><br>  Pour am√©liorer la qualit√© du signe, nous avons divis√© le signal en morceaux, qui se chevauchaient partiellement.  Ensuite, nous avons extrait la balise s√©quentiellement pour chaque morceau;  par cons√©quent, la matrice d'attributs a √©t√© calcul√©e pour chaque fichier audio. <br><br>  Taille de la fen√™tre - 0,2 s;  pas de fen√™tre - 0,1 s. <br><br><h2>  √âtape 2: d√©finir le ton de la voix dans des phrases distinctes </h2><br>  Notre premi√®re approche pour r√©soudre le probl√®me consiste √† d√©finir et √† traiter chaque phrase dans le flux s√©par√©ment. <br><br>  Tout d'abord, nous avons fait la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">diarisation</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">isol√©</a> toutes les phrases en utilisant la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LIUM</a> .  Les fichiers d'entr√©e √©taient de mauvaise qualit√©, donc √† la sortie, nous avons √©galement appliqu√© un lissage et un seuillage adaptatif pour chaque fichier. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ri/8t/me/ri8tmehn045h1dbiztmtq4ixb-o.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/c9/_t/z3c9_tkardcnk9irbxxokxxso44.png"></div><br><h3>  Traitement des interruptions et long silence </h3><br>  Lorsque nous avons d√©termin√© les limites de temps pour chaque phrase (√† la fois le client et l'op√©rateur), nous les avons superpos√©es et avons r√©v√©l√© des cas o√π les deux personnes parlent en m√™me temps, ainsi que des cas o√π les deux sont silencieux.  Il ne restait plus qu'√† d√©terminer la valeur seuil.  Nous avons convenu que si 3 secondes ou plus les participants parlent en m√™me temps, cela est consid√©r√© comme une interruption.  Pour le silence, un seuil de 3 secondes a √©t√© d√©fini exactement. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ke/md/dh/kemddhguibgoz6kug0imtvphl84.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ti/_o/dlti_okejnlhqdwlnpihys0d0vi.png"></div><br>  Le fait est que chaque phrase a sa propre longueur.  Par cons√©quent, le nombre d'entit√©s extraites pour chaque phrase est diff√©rent. <br><br>  Le r√©seau neuronal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSTM</a> pourrait g√©rer ce probl√®me.  Les r√©seaux de ce type peuvent non seulement traiter des s√©quences de diff√©rentes longueurs, mais ils peuvent √©galement contenir des commentaires, ce qui vous donne la possibilit√© d'enregistrer des informations.  Ces fonctionnalit√©s sont tr√®s importantes car les phrases prononc√©es plus t√¥t contiennent des informations qui affectent les phrases prononc√©es apr√®s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/s1/fa/sr/s1fasrlj1hby2a67opppjka_n5m.png"></div><br>  Ensuite, nous avons form√© notre r√©seau LSTM pour d√©terminer l'intonation de chaque phrase. <br><br>  En tant qu'ensemble de formation, nous avons pris 70 fichiers avec 30 phrases en moyenne (15 phrases de chaque c√¥t√©). <br><br>  L'objectif principal √©tait d'√©valuer les phrases de l'op√©rateur du centre d'appels, nous n'avons donc pas utilis√© la parole du client pour la formation.  Nous avons utilis√© 750 phrases comme un ensemble de donn√©es de formation et 250 phrases comme un test.  En cons√©quence, le neurone a appris √† classer la parole avec une pr√©cision de 72%. <br><br>  Mais au final, nous n'avons pas √©t√© satisfaits des performances du r√©seau LSTM: travailler avec lui a pris trop de temps, alors que les r√©sultats sont loin d'√™tre parfaits.  Par cons√©quent, il a √©t√© d√©cid√© d'utiliser une approche diff√©rente. <br><br>  Il est temps de dire comment nous avons d√©termin√© le ton de la voix √† l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">XGBoost</a> plus une combinaison de LSTM et XGB. <br><br><h2>  D√©terminer la tonalit√© vocale de l'ensemble du fichier </h2><br>  Nous avons marqu√© les fichiers comme suspects s'ils contenaient au moins une phrase qui violait les r√®gles.  Nous avons donc tagu√© 2500 fichiers. <br><br>  Pour extraire les attributs, nous avons utilis√© la m√™me m√©thode et la m√™me architecture <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ANN</a> , mais avec une diff√©rence: nous avons dimensionn√© l'architecture pour qu'elle s'adapte aux nouvelles dimensions des attributs. <br><br>  Avec des param√®tres optimaux, le r√©seau neuronal a produit une pr√©cision de 85%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pu/1f/q3/pu1fq3pnbx828w78lppbfkcdrla.png" width="650"></div><br><h3>  XGBoost </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le mod√®le XGBoost</a> n√©cessite un nombre fixe d'attributs pour chaque fichier.  Pour satisfaire cette exigence, nous avons cr√©√© plusieurs signaux et param√®tres. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lh/n0/ec/lhn0ecwl46_pfqmzgq-nelhxagu.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/kl/xh/6vklxhkhif4zlv_haaqhk71pmgy.jpeg"></div><br>  Les statistiques suivantes ont √©t√© utilis√©es: <br><br><ol><li>  La valeur moyenne du signal. </li><li>  La valeur moyenne des 10 premi√®res secondes du signal. </li><li>  La valeur moyenne des 3 derni√®res secondes du signal. </li><li>  La valeur moyenne des maxima locaux dans le signal. </li><li>  La valeur moyenne des maxima locaux dans les 10 premi√®res secondes du signal. </li><li>  La valeur moyenne des maxima locaux au cours des 3 derni√®res secondes du signal. </li></ol><br>  Tous les indicateurs ont √©t√© calcul√©s s√©par√©ment pour chaque signal.  Le nombre total d'attributs est de 36, √† l'exception de la longueur de l'enregistrement.  En cons√©quence, nous avions 37 signes num√©riques pour chaque enregistrement. <br><br>  La pr√©cision de pr√©diction de cet algorithme est de 0,869. <br><br><h3>  Combinaison de LSTM et XGB </h3><br>  Pour combiner les classificateurs, nous avons crois√© ces deux mod√®les.  En sortie, cette pr√©cision augmentait de 2%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e9/wi/21/e9wi21ggxfrlo6tj_shuo6b3pve.png"></div><br>  Autrement dit, nous avons pu augmenter la pr√©cision de la pr√©diction √† 0,9 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ROC</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AUC</a> (Area Under Curve). <br><br><h2>  R√©sultat </h2><br>  Nous avons test√© notre r√©seau de neurones profonds sur 205 fichiers (177 neutres, 28 suspects).  Le r√©seau devait traiter chaque fichier et d√©cider √† quel groupe il appartenait.  Voici les r√©sultats: <br><br><ul><li>  170 fichiers neutres ont √©t√© identifi√©s correctement; </li><li>  7 fichiers neutres ont √©t√© identifi√©s comme suspects; </li><li>  13 fichiers suspects ont √©t√© identifi√©s correctement; </li><li>  15 fichiers suspects ont √©t√© identifi√©s comme neutres. </li></ul><br>  Pour estimer le pourcentage de r√©sultats corrects / faux, nous avons utilis√© la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">matrice d'erreur</a> sous la forme d'un tableau 2x2. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mh/iu/4g/mhiu4g2975opf6esqhuiflvphsm.jpeg"></div><br><h2>  Trouver une phrase sp√©cifique dans une conversation </h2><br>  Nous √©tions impatients d'essayer cette approche pour reconna√Ætre les mots et les phrases dans les fichiers audio.  L'objectif √©tait de trouver des fichiers dans lesquels l'op√©rateur du centre d'appels n'√©tait pas pr√©sent√© aux clients dans les 10 premi√®res secondes de la conversation. <br><br>  Nous avons pris 200 phrases d'une dur√©e moyenne de 1,5 seconde, dans lesquelles les op√©rateurs appellent leur nom et le nom de l'entreprise. <br><br>  La recherche manuelle de ces fichiers a pris beaucoup de temps, car  J'ai d√ª √©couter chaque fichier pour v√©rifier s'il contenait les phrases n√©cessaires.  Pour acc√©l√©rer la formation, nous avons augment√© ¬´artificiellement¬ª l'ensemble de donn√©es: nous avons modifi√© chaque fichier 6 fois au hasard - ajout de bruit, modification de la fr√©quence et / ou du volume.  Nous avons donc obtenu un ensemble de donn√©es de 1 500 fichiers. <br><br><h3>  R√©sum√© </h3><br>  Nous avons utilis√© les 10 premi√®res secondes de la r√©ponse de l'op√©rateur pour former le classificateur, car c'est dans cet intervalle que la phrase souhait√©e a √©t√© prononc√©e.  Chacun de ces passages a √©t√© divis√© en fen√™tres (longueur de fen√™tre de 1,5 s, pas de fen√™tre de 1 s) et trait√© par le r√©seau neuronal en tant que fichier d'entr√©e.  En tant que fichier de sortie, nous avons re√ßu la probabilit√© de prononcer chaque phrase dans la fen√™tre s√©lectionn√©e. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cr/md/4-/crmd4-kcd7c-_qfd5h_arxpa6ei.jpeg"></div><br>  Nous avons ex√©cut√© 300 autres fichiers sur le r√©seau pour savoir si la phrase souhait√©e a √©t√© prononc√©e dans les 10 premi√®res secondes.  Pour ces fichiers, la pr√©cision √©tait de 87%. <br><br><h2>  En fait, √† quoi √ßa sert? </h2><br>  L'√©valuation automatique des appels permet de d√©terminer des KPI clairs pour les op√©rateurs de centres d'appels, de mettre en √©vidence et de suivre les meilleures pratiques et d'augmenter les performances des centres d'appels.  Mais il convient de noter que les logiciels de reconnaissance vocale peuvent √™tre utilis√©s pour un plus large √©ventail de t√¢ches. <br><br>  Voici quelques exemples de la fa√ßon dont la reconnaissance vocale peut aider les organisations: <br><br><ul><li>  collecter et analyser des donn√©es pour am√©liorer l'exp√©rience utilisateur vocale; </li><li>  analyser les enregistrements d'appels pour identifier les relations et les tendances; </li><li>  reconna√Ætre les gens par la voix; </li><li>  Trouvez et identifiez les √©motions des clients pour am√©liorer la satisfaction des utilisateurs </li><li>  augmenter le revenu moyen par appel; </li><li>  r√©duire les sorties; </li><li>  et bien plus! </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428598/">https://habr.com/ru/post/fr428598/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428582/index.html">Histoire oubli√©e de la POO</a></li>
<li><a href="../fr428588/index.html">R√©sum√© des √©v√©nements informatiques en novembre (deuxi√®me partie)</a></li>
<li><a href="../fr428590/index.html">Microinteractions et micro invites dans l'interface</a></li>
<li><a href="../fr428592/index.html">Arr√™tez d'embaucher des ¬´gestionnaires efficaces¬ª. Ils sont non seulement inutiles, mais nocifs</a></li>
<li><a href="../fr428596/index.html">Elon Musk a licenci√© des chefs de projet Internet par satellite Starlink en raison du non-respect des d√©lais</a></li>
<li><a href="../fr428600/index.html">SSD d'effets sp√©ciaux ou ce qui manquait pour le modding - Examen du lecteur HyperX FURY RGB</a></li>
<li><a href="../fr428602/index.html">Apprenez les tactiques, techniques et connaissances communes contradictoires (ATT @ CK). Tactiques d'entreprise. Partie 4</a></li>
<li><a href="../fr428604/index.html">Championnat de science des donn√©es en ligne</a></li>
<li><a href="../fr428606/index.html">¬´Comprendre le fonctionnement du syst√®me a permis beaucoup de piratage¬ª: Roy Beniosef sur le d√©veloppement Android</a></li>
<li><a href="../fr428608/index.html">Les m√©dias d√©tiennent un accord avec Yandex pour retirer les documents pirat√©s</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍🏭 🥄 💅🏼 Réseaux de neurones profonds pour l'évaluation automatique des appels 🙏🏻 😲 👩🏿‍🤝‍👩🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'évaluation des appels est un élément clé du contrôle qualité des centres d'appels. Il permet aux organisations d'affiner leur flux de travail afin q...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Réseaux de neurones profonds pour l'évaluation automatique des appels</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/428598/">  L'évaluation des appels est un élément clé du contrôle qualité des centres d'appels.  Il permet aux organisations d'affiner leur flux de travail afin que les opérateurs puissent travailler plus rapidement et plus efficacement et également éviter une routine vide de sens. <br><br>  Conscient que le centre d'appels doit être efficace, nous avons travaillé sur l'automatisation des scores d'appels.  En conséquence, nous avons trouvé un algorithme qui traite les appels et les répartit en deux groupes: suspects et neutres.  Tous les appels suspects ont été immédiatement envoyés à l'équipe d'évaluation de la qualité. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yj/0t/yq/yj0tyqtftcw-e0m_wcxkh_ls7l0.jpeg"></div><br><a name="habracut"></a><br>
<h2>  Comment nous avons formé un réseau neuronal profond </h2><br>  Pour les échantillons, nous avons pris 1700 fichiers audio, sur lesquels nous avons formé le réseau.  Comme le neurone ne savait pas au départ ce qu'il fallait considérer comme suspect et ce qui était neutre, nous avons marqué manuellement tous les fichiers en conséquence. <br><br>  Dans les échantillons neutres, les opérateurs: <br><br><ul><li>  n'ont pas élevé la voix; </li><li>  Fournir aux clients toutes les informations demandées; </li><li>  n'a pas répondu aux provocations du client. </li></ul><br>  Dans les schémas suspects, les opérateurs faisaient souvent ce qui suit: <br><br><ul><li>  utilisé un langage obscène; </li><li>  élever la voix ou crier aux clients; </li><li>  est allé à la personne; </li><li>  a refusé de conseiller sur les questions. </li></ul><br>  Lorsque l'algorithme a fini de traiter les fichiers, il a marqué 200 fichiers comme non valides.  Ces fichiers ne contiennent aucun signe suspect ou neutre.  Nous avons découvert ce qu'il y avait dans ces 200 fichiers: <br><br><ul><li>  le client a raccroché immédiatement après que l'opérateur lui a répondu; </li><li>  le client n'a rien dit après avoir reçu une réponse; </li><li>  il y avait trop de bruit côté client ou opérateur. </li></ul><br>  Lorsque nous avons supprimé ces fichiers, nous avons divisé les 1 500 restants en cas de formation et de test.  À l'avenir, nous avons utilisé ces ensembles de données pour former et tester un réseau neuronal profond. <br><br><h2>  Étape 1: Extraire les fonctionnalités </h2><br>  L'extraction de fonctionnalités de haut niveau joue un rôle important dans l'apprentissage automatique, car  cela affecte directement l'efficacité de l'algorithme.  Après avoir analysé toutes les sources possibles, nous avons sélectionné les symptômes suivants: <br><br><h3>  Statistiques de temps </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Taux de passage à zéro</a> : vitesse à laquelle le signal passe de plus à moins et vice versa. </li><li>  <b>Énergie médiane de la trame</b> : somme des signaux au carré et normalisée à la longueur de trame correspondante. </li><li>  <b>Entropie d'énergie de sous-trame</b> : l'entropie de l'énergie de sous-trame normalisée.  Il peut être interprété comme une mesure de changements drastiques. </li><li>  <b>L'écart moyen / médian / standard du cadre</b> . </li></ul><br><h3>  Statistiques spectrales (avec intervalles de fréquence) </h3><br><ol><li>  Spectral Centroid. </li><li>  Distribution spectrale. </li><li>  Entropie spectrale. </li><li>  Rayonnement spectral. </li><li>  Atténuation spectrale. </li></ol><br>  Les coefficients cepstraux de la fréquence tonale et du vecteur de saturation sont sensibles à la longueur du signal d'entrée.  Nous pourrions les extraire de l'ensemble du fichier à la fois, mais ce faisant, nous manquerions le développement du trait à temps.  Cette méthode ne nous convenant pas, nous avons décidé de diviser le signal en «fenêtres» (blocs de temps). <br><br>  Pour améliorer la qualité du signe, nous avons divisé le signal en morceaux, qui se chevauchaient partiellement.  Ensuite, nous avons extrait la balise séquentiellement pour chaque morceau;  par conséquent, la matrice d'attributs a été calculée pour chaque fichier audio. <br><br>  Taille de la fenêtre - 0,2 s;  pas de fenêtre - 0,1 s. <br><br><h2>  Étape 2: définir le ton de la voix dans des phrases distinctes </h2><br>  Notre première approche pour résoudre le problème consiste à définir et à traiter chaque phrase dans le flux séparément. <br><br>  Tout d'abord, nous avons fait la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">diarisation</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">isolé</a> toutes les phrases en utilisant la bibliothèque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LIUM</a> .  Les fichiers d'entrée étaient de mauvaise qualité, donc à la sortie, nous avons également appliqué un lissage et un seuillage adaptatif pour chaque fichier. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ri/8t/me/ri8tmehn045h1dbiztmtq4ixb-o.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/c9/_t/z3c9_tkardcnk9irbxxokxxso44.png"></div><br><h3>  Traitement des interruptions et long silence </h3><br>  Lorsque nous avons déterminé les limites de temps pour chaque phrase (à la fois le client et l'opérateur), nous les avons superposées et avons révélé des cas où les deux personnes parlent en même temps, ainsi que des cas où les deux sont silencieux.  Il ne restait plus qu'à déterminer la valeur seuil.  Nous avons convenu que si 3 secondes ou plus les participants parlent en même temps, cela est considéré comme une interruption.  Pour le silence, un seuil de 3 secondes a été défini exactement. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ke/md/dh/kemddhguibgoz6kug0imtvphl84.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ti/_o/dlti_okejnlhqdwlnpihys0d0vi.png"></div><br>  Le fait est que chaque phrase a sa propre longueur.  Par conséquent, le nombre d'entités extraites pour chaque phrase est différent. <br><br>  Le réseau neuronal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSTM</a> pourrait gérer ce problème.  Les réseaux de ce type peuvent non seulement traiter des séquences de différentes longueurs, mais ils peuvent également contenir des commentaires, ce qui vous donne la possibilité d'enregistrer des informations.  Ces fonctionnalités sont très importantes car les phrases prononcées plus tôt contiennent des informations qui affectent les phrases prononcées après. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/s1/fa/sr/s1fasrlj1hby2a67opppjka_n5m.png"></div><br>  Ensuite, nous avons formé notre réseau LSTM pour déterminer l'intonation de chaque phrase. <br><br>  En tant qu'ensemble de formation, nous avons pris 70 fichiers avec 30 phrases en moyenne (15 phrases de chaque côté). <br><br>  L'objectif principal était d'évaluer les phrases de l'opérateur du centre d'appels, nous n'avons donc pas utilisé la parole du client pour la formation.  Nous avons utilisé 750 phrases comme un ensemble de données de formation et 250 phrases comme un test.  En conséquence, le neurone a appris à classer la parole avec une précision de 72%. <br><br>  Mais au final, nous n'avons pas été satisfaits des performances du réseau LSTM: travailler avec lui a pris trop de temps, alors que les résultats sont loin d'être parfaits.  Par conséquent, il a été décidé d'utiliser une approche différente. <br><br>  Il est temps de dire comment nous avons déterminé le ton de la voix à l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">XGBoost</a> plus une combinaison de LSTM et XGB. <br><br><h2>  Déterminer la tonalité vocale de l'ensemble du fichier </h2><br>  Nous avons marqué les fichiers comme suspects s'ils contenaient au moins une phrase qui violait les règles.  Nous avons donc tagué 2500 fichiers. <br><br>  Pour extraire les attributs, nous avons utilisé la même méthode et la même architecture <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ANN</a> , mais avec une différence: nous avons dimensionné l'architecture pour qu'elle s'adapte aux nouvelles dimensions des attributs. <br><br>  Avec des paramètres optimaux, le réseau neuronal a produit une précision de 85%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pu/1f/q3/pu1fq3pnbx828w78lppbfkcdrla.png" width="650"></div><br><h3>  XGBoost </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le modèle XGBoost</a> nécessite un nombre fixe d'attributs pour chaque fichier.  Pour satisfaire cette exigence, nous avons créé plusieurs signaux et paramètres. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lh/n0/ec/lhn0ecwl46_pfqmzgq-nelhxagu.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/kl/xh/6vklxhkhif4zlv_haaqhk71pmgy.jpeg"></div><br>  Les statistiques suivantes ont été utilisées: <br><br><ol><li>  La valeur moyenne du signal. </li><li>  La valeur moyenne des 10 premières secondes du signal. </li><li>  La valeur moyenne des 3 dernières secondes du signal. </li><li>  La valeur moyenne des maxima locaux dans le signal. </li><li>  La valeur moyenne des maxima locaux dans les 10 premières secondes du signal. </li><li>  La valeur moyenne des maxima locaux au cours des 3 dernières secondes du signal. </li></ol><br>  Tous les indicateurs ont été calculés séparément pour chaque signal.  Le nombre total d'attributs est de 36, à l'exception de la longueur de l'enregistrement.  En conséquence, nous avions 37 signes numériques pour chaque enregistrement. <br><br>  La précision de prédiction de cet algorithme est de 0,869. <br><br><h3>  Combinaison de LSTM et XGB </h3><br>  Pour combiner les classificateurs, nous avons croisé ces deux modèles.  En sortie, cette précision augmentait de 2%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e9/wi/21/e9wi21ggxfrlo6tj_shuo6b3pve.png"></div><br>  Autrement dit, nous avons pu augmenter la précision de la prédiction à 0,9 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ROC</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AUC</a> (Area Under Curve). <br><br><h2>  Résultat </h2><br>  Nous avons testé notre réseau de neurones profonds sur 205 fichiers (177 neutres, 28 suspects).  Le réseau devait traiter chaque fichier et décider à quel groupe il appartenait.  Voici les résultats: <br><br><ul><li>  170 fichiers neutres ont été identifiés correctement; </li><li>  7 fichiers neutres ont été identifiés comme suspects; </li><li>  13 fichiers suspects ont été identifiés correctement; </li><li>  15 fichiers suspects ont été identifiés comme neutres. </li></ul><br>  Pour estimer le pourcentage de résultats corrects / faux, nous avons utilisé la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">matrice d'erreur</a> sous la forme d'un tableau 2x2. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mh/iu/4g/mhiu4g2975opf6esqhuiflvphsm.jpeg"></div><br><h2>  Trouver une phrase spécifique dans une conversation </h2><br>  Nous étions impatients d'essayer cette approche pour reconnaître les mots et les phrases dans les fichiers audio.  L'objectif était de trouver des fichiers dans lesquels l'opérateur du centre d'appels n'était pas présenté aux clients dans les 10 premières secondes de la conversation. <br><br>  Nous avons pris 200 phrases d'une durée moyenne de 1,5 seconde, dans lesquelles les opérateurs appellent leur nom et le nom de l'entreprise. <br><br>  La recherche manuelle de ces fichiers a pris beaucoup de temps, car  J'ai dû écouter chaque fichier pour vérifier s'il contenait les phrases nécessaires.  Pour accélérer la formation, nous avons augmenté «artificiellement» l'ensemble de données: nous avons modifié chaque fichier 6 fois au hasard - ajout de bruit, modification de la fréquence et / ou du volume.  Nous avons donc obtenu un ensemble de données de 1 500 fichiers. <br><br><h3>  Résumé </h3><br>  Nous avons utilisé les 10 premières secondes de la réponse de l'opérateur pour former le classificateur, car c'est dans cet intervalle que la phrase souhaitée a été prononcée.  Chacun de ces passages a été divisé en fenêtres (longueur de fenêtre de 1,5 s, pas de fenêtre de 1 s) et traité par le réseau neuronal en tant que fichier d'entrée.  En tant que fichier de sortie, nous avons reçu la probabilité de prononcer chaque phrase dans la fenêtre sélectionnée. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cr/md/4-/crmd4-kcd7c-_qfd5h_arxpa6ei.jpeg"></div><br>  Nous avons exécuté 300 autres fichiers sur le réseau pour savoir si la phrase souhaitée a été prononcée dans les 10 premières secondes.  Pour ces fichiers, la précision était de 87%. <br><br><h2>  En fait, à quoi ça sert? </h2><br>  L'évaluation automatique des appels permet de déterminer des KPI clairs pour les opérateurs de centres d'appels, de mettre en évidence et de suivre les meilleures pratiques et d'augmenter les performances des centres d'appels.  Mais il convient de noter que les logiciels de reconnaissance vocale peuvent être utilisés pour un plus large éventail de tâches. <br><br>  Voici quelques exemples de la façon dont la reconnaissance vocale peut aider les organisations: <br><br><ul><li>  collecter et analyser des données pour améliorer l'expérience utilisateur vocale; </li><li>  analyser les enregistrements d'appels pour identifier les relations et les tendances; </li><li>  reconnaître les gens par la voix; </li><li>  Trouvez et identifiez les émotions des clients pour améliorer la satisfaction des utilisateurs </li><li>  augmenter le revenu moyen par appel; </li><li>  réduire les sorties; </li><li>  et bien plus! </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428598/">https://habr.com/ru/post/fr428598/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428582/index.html">Histoire oubliée de la POO</a></li>
<li><a href="../fr428588/index.html">Résumé des événements informatiques en novembre (deuxième partie)</a></li>
<li><a href="../fr428590/index.html">Microinteractions et micro invites dans l'interface</a></li>
<li><a href="../fr428592/index.html">Arrêtez d'embaucher des «gestionnaires efficaces». Ils sont non seulement inutiles, mais nocifs</a></li>
<li><a href="../fr428596/index.html">Elon Musk a licencié des chefs de projet Internet par satellite Starlink en raison du non-respect des délais</a></li>
<li><a href="../fr428600/index.html">SSD d'effets spéciaux ou ce qui manquait pour le modding - Examen du lecteur HyperX FURY RGB</a></li>
<li><a href="../fr428602/index.html">Apprenez les tactiques, techniques et connaissances communes contradictoires (ATT @ CK). Tactiques d'entreprise. Partie 4</a></li>
<li><a href="../fr428604/index.html">Championnat de science des données en ligne</a></li>
<li><a href="../fr428606/index.html">«Comprendre le fonctionnement du système a permis beaucoup de piratage»: Roy Beniosef sur le développement Android</a></li>
<li><a href="../fr428608/index.html">Les médias détiennent un accord avec Yandex pour retirer les documents piratés</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
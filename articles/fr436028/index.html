<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú¥Ô∏è üë®üèæ‚Äçüî¨ ‚ôäÔ∏è Une introduction √† Kubernetes pour les utilisateurs de VMware. Partie 1. Th√©orie üë≤üèæ üõê üïî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ceci est la deuxi√®me partie de mes Kubernetes dans la s√©rie de publications Enterprise . Comme je l'ai mentionn√© dans mon dernier article, il est tr√®s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Une introduction √† Kubernetes pour les utilisateurs de VMware. Partie 1. Th√©orie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/436028/">  Ceci est la deuxi√®me partie de mes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes dans la</a> s√©rie de publications <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Enterprise</a> .  Comme je l'ai mentionn√© dans mon dernier article, il est tr√®s important de passer aux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Guides de conception et d'impl√©mentation¬ª que</a> tout le monde soit au m√™me niveau de compr√©hension de Kubernetes (K8). <br><br>  Je ne veux pas utiliser l'approche traditionnelle ici pour expliquer l'architecture et les technologies de Kubernetes, mais je vais tout expliquer √† travers une comparaison avec la plate-forme vSphere, que vous, en tant qu'utilisateurs VMware, connaissez.  Cela vous permettra de surmonter l'apparente confusion et la gravit√© de la compr√©hension de Kubernetes.  J'ai utilis√© cette approche dans VMware pour pr√©senter Kubernetes √† diff√©rents publics d'auditeurs, et cela a prouv√© que cela fonctionne tr√®s bien et aide les gens √† s'habituer plus rapidement aux concepts cl√©s. <br><br>  Remarque importante avant de commencer.  Je n'utilise pas cette comparaison pour prouver des similitudes ou des diff√©rences entre vSphere et Kubernetes.  Cela et un autre, en substance, sont des syst√®mes distribu√©s et, par cons√©quent, devraient avoir des similitudes avec tout autre syst√®me similaire.  Par cons√©quent, au final, j'essaie de pr√©senter une technologie aussi merveilleuse que Kubernetes √† une large communaut√© d'utilisateurs. <br><img src="https://habrastorage.org/webt/2x/8j/gn/2x8jgnlfylvf_sfzkylizlg3huk.png"><a name="habracut"></a><br><br><h3>  Un peu d'histoire </h3><br>  La lecture de cet article implique d'apprendre √† conna√Ætre les conteneurs.  Je ne d√©crirai pas les concepts de base des conteneurs, car il existe de nombreuses ressources qui en parlent.  En discutant tr√®s souvent avec les clients, je constate qu'ils ne peuvent pas comprendre pourquoi les conteneurs ont saisi notre industrie et sont devenus tr√®s populaires en un temps record.  Pour r√©pondre √† cette question, je vais vous parler de mon exp√©rience pratique dans la compr√©hension des changements qui se produisent dans notre industrie. <br><br>  Avant d'explorer le monde des t√©l√©communications, j'√©tais d√©veloppeur Web (2003). <br><br>  C'√©tait mon deuxi√®me emploi r√©mun√©r√© apr√®s avoir travaill√© comme ing√©nieur / administrateur de r√©seau (je sais que j'√©tais un cric de tous les m√©tiers).  J'ai d√©velopp√© en PHP.  J'ai d√©velopp√© toutes sortes d'applications, en commen√ßant par les petites que mon employeur utilisait, pour finir par une application de vote professionnelle pour les programmes de t√©l√©vision, et m√™me des applications de t√©l√©communication qui interagissent avec les concentrateurs VSAT et les syst√®mes satellites.  La vie √©tait belle, √† l'exception d'un obstacle majeur que chaque d√©veloppeur conna√Æt, ce sont les d√©pendances. <br><br>  Au d√©but, j'ai d√©velopp√© l'application sur mon ordinateur portable, en utilisant quelque chose comme la pile LAMP, quand cela fonctionnait bien sur mon ordinateur portable, j'ai t√©l√©charg√© le code source sur les serveurs h√¥tes (tout le monde se souvient de RackShack?) Ou sur les serveurs priv√©s du client.  Vous pouvez imaginer que d√®s que j'ai fait cela, l'application s'est bloqu√©e et n'a pas fonctionn√© sur ces serveurs.  La raison en est la d√©pendance.  Les serveurs avaient d'autres versions du logiciel (Apache, PHP, MySQL, etc.) que celles que j'utilisais sur l'ordinateur portable.  J'ai donc d√ª trouver un moyen de mettre √† jour les versions du logiciel sur les serveurs distants (mauvaise id√©e) ou de r√©√©crire le code sur mon ordinateur portable pour correspondre aux versions sur les serveurs distants (pire id√©e).  C'√©tait un cauchemar, parfois je me d√©testais et je me demandais pourquoi c'est ainsi que je gagne ma vie. <br><br>  10 ans se sont √©coul√©s, la soci√©t√© Docker est apparue.  En tant que consultant VMware chez Professional Services (2013), j'ai entendu parler de Docker, et permettez-moi de dire que je ne pouvais pas comprendre cette technologie √† l'√©poque.  J'ai continu√© √† dire quelque chose comme: pourquoi utiliser des conteneurs s'il y a des machines virtuelles.  Pourquoi abandonner des technologies importantes comme vSphere HA, DRS ou vMotion en raison d'avantages √©tranges tels que le lancement instantan√© de conteneurs ou l'√©limination de la surcharge d'hyperviseur.  Apr√®s tout, tout le monde travaille avec des machines virtuelles et fonctionne parfaitement.  Bref, je l'ai envisag√© en termes d'infrastructure. <br><br>  Mais alors j'ai commenc√© √† regarder de pr√®s et cela m'est apparu.  Tout ce qui concerne Docker est li√© aux d√©veloppeurs.  En commen√ßant √† penser en tant que d√©veloppeur, j'ai imm√©diatement r√©alis√© que si j'avais cette technologie en 2003, je pourrais emballer toutes mes d√©pendances.  Mes applications Web peuvent fonctionner quel que soit le serveur utilis√©.  De plus, il ne serait pas n√©cessaire de t√©l√©charger le code source ou de configurer quelque chose.  Vous pouvez simplement ¬´compresser¬ª mon application dans une image et demander aux clients de t√©l√©charger et d'ex√©cuter cette image.  C'est le r√™ve de tout d√©veloppeur Web! <br><br>  Tout cela est super.  Docker a r√©solu l'√©norme probl√®me d'interaction et d'emballage, mais que faire ensuite?  Puis-je, en tant que client d'entreprise, g√©rer ces applications tout en √©voluant?  Je veux toujours utiliser HA, DRS, vMotion et DR.  Docker a r√©solu les probl√®mes de mes d√©veloppeurs et cr√©√© tout un tas de probl√®mes pour mes administrateurs (√©quipe DevOps).  Ils ont besoin d'une plate-forme pour lancer des conteneurs, la m√™me que celle pour lancer des machines virtuelles.  Et nous sommes revenus au d√©but. <br><br>  Mais ensuite Google est apparu, expliquant au monde entier l'utilisation de conteneurs pendant de nombreuses ann√©es (en fait, les conteneurs ont √©t√© invent√©s par Google: cgroups) et la bonne m√©thode pour les utiliser, via une plateforme qu'ils appelaient Kubernetes.  Ils ont ensuite ouvert le code source de Kubernetes.  Pr√©sent√© √† la communaut√© Kubernetes.  Et cela a encore tout chang√©. <br><br><h3>  Comprendre Kubernetes et vSphere </h3><br>  Alors qu'est-ce que Kubernetes?  En termes simples, Kubernetes pour les conteneurs est identique √† vSphere pour les machines virtuelles dans un centre de donn√©es moderne.  Si vous avez utilis√© VMware Workstation au d√©but des ann√©es 2000, vous savez que cette solution a √©t√© s√©rieusement consid√©r√©e comme une solution pour les centres de donn√©es.  Lorsque VI / vSphere avec vCenter et h√¥tes ESXi est apparu, le monde des machines virtuelles a radicalement chang√©.  Kubernetes fait la m√™me chose aujourd'hui avec le monde des conteneurs, offrant la possibilit√© de lancer et de g√©rer des conteneurs en production.  Et c'est pourquoi nous allons commencer √† comparer vSphere c√¥te √† c√¥te avec Kubernetes pour expliquer les d√©tails de ce syst√®me distribu√© pour comprendre ses fonctions et technologies. <br><img src="https://habrastorage.org/webt/2l/ke/vg/2lkevgzxfllfuhfd29vtofvm4ii.png"><br><br><h3>  Pr√©sentation du syst√®me </h3><br>  Comme dans vSphere, il existe des h√¥tes vCenter et ESXi dans le concept de Kubernetes, il y a des ma√Ætres et des n≈ìuds.  Dans ce contexte, Master in K8s est l'√©quivalent de vCenter, en ce sens qu'il s'agit du plan de gestion d'un syst√®me distribu√©.  C'est √©galement le point d'entr√©e de l'API avec laquelle vous interagissez lors de la gestion de votre charge de travail.  De la m√™me mani√®re, les n≈ìuds K8 fonctionnent comme des ressources informatiques, similaires aux h√¥tes ESXi.  C'est sur eux que vous ex√©cutez les charges de travail (dans le cas des K8, nous les appelons Pods).  Les n≈ìuds peuvent √™tre des machines virtuelles ou des serveurs physiques.  Bien s√ªr, avec vSphere ESXi, les h√¥tes doivent toujours √™tre physiques. <br><img src="https://habrastorage.org/webt/to/va/hq/tovahqozye9ym14sljwpbilywto.png"><br><br>  Vous pouvez voir que K8s a un magasin de valeurs-cl√©s appel√© "etcd".  Ce stockage est similaire √† la base de donn√©es vCenter, o√π vous enregistrez la configuration de cluster souhait√©e √† laquelle vous souhaitez adh√©rer. <br><br>  En ce qui concerne les diff√©rences: sur les Master K8, vous pouvez √©galement ex√©cuter des charges de travail, mais sur vCenter, vous ne pouvez pas.  vCenter est une appliance virtuelle d√©di√©e √† la gestion uniquement.  Dans le cas des K8, Master est consid√©r√© comme une ressource informatique, mais ex√©cuter des applications d'entreprise dessus n'est pas une bonne id√©e. <br><br>  Alors, √† quoi cela ressemblera-t-il en r√©alit√©?  Vous utiliserez principalement la CLI pour interagir avec Kubernetes (mais l'interface graphique est toujours une option tr√®s viable).  La capture d'√©cran ci-dessous montre que j'utilise une machine Windows pour me connecter √† mon cluster Kubernetes via la ligne de commande (j'utilise cmder si vous √™tes int√©ress√©).  Dans la capture d'√©cran, j'ai un n≈ìud ma√Ætre et 4 n≈ìuds.  Ils fonctionnent sous le contr√¥le de K8s v1.6.5, et le syst√®me d'exploitation (OS) Ubuntu 16.04 est install√© sur les n≈ìuds.  Au moment de la r√©daction de cet article, nous vivons principalement dans le monde Linux, o√π Master et Node ex√©cutent toujours une distribution Linux. <br><br><img src="https://habrastorage.org/webt/gm/qn/gj/gmqngjq1mraqces6uo1sectxm6i.png"><br>  <i>Gestion de cluster K8s via CLI et GUI.</i> <br><br><h3>  Facteur de forme de charge de travail </h3><br>  Dans vSphere, la machine virtuelle est la limite logique du syst√®me d'exploitation.  Dans Kubernetes, les pods sont des limites de conteneur, tout comme l'h√¥te ESXi, qui peut ex√©cuter plusieurs machines virtuelles simultan√©ment.  Chaque n≈ìud peut ex√©cuter plusieurs pods.  Chaque pod re√ßoit une adresse IP routable, comme les machines virtuelles, pour que les pods communiquent entre eux. <br><br>  Dans vSphere, les applications s'ex√©cutent √† l'int√©rieur du syst√®me d'exploitation et dans Kubernetes, les applications s'ex√©cutent √† l'int√©rieur des conteneurs.  Une machine virtuelle ne peut fonctionner qu'avec un seul syst√®me d'exploitation √† la fois, et un pod peut ex√©cuter plusieurs conteneurs. <br><img src="https://habrastorage.org/webt/hv/cv/9b/hvcv9bj4gw6wsunhhqeqvvfx5d4.png"><br><br>  C'est ainsi que vous pouvez lister les pods √† l'int√©rieur du cluster K8 en utilisant l'outil kubectl via la CLI, v√©rifier la capacit√© de travail des pods, leur √¢ge, leur adresse IP et les n≈ìuds sur lesquels ils travaillent actuellement. <br><img src="https://habrastorage.org/webt/0u/qj/_0/0uqj_0gl0qmxiqbby9gd8ln98nc.png"><br><br><h3>  La gestion </h3><br>  Alors, comment g√©rons-nous nos ma√Ætres, n≈ìuds et pods?  Chez vSphere, nous utilisons le client Web pour g√©rer la plupart (sinon la totalit√©) des composants de notre infrastructure virtuelle.  Pour Kubernetes, de m√™me, en utilisant Dashboard.  Il s'agit d'un bon portail Web bas√© sur une interface graphique auquel vous pouvez acc√©der via votre navigateur de la m√™me mani√®re qu'avec le client Web vSphere.  Dans les sections pr√©c√©dentes, vous pouvez voir que vous pouvez g√©rer votre cluster K8s √† l'aide de la commande kubeclt de la CLI.  Il est toujours discutable o√π vous passerez la plupart de votre temps dans la CLI ou dans le tableau de bord graphique.  Depuis ce dernier devient chaque jour un outil de plus en plus puissant (vous pouvez voir cette vid√©o pour en √™tre s√ªr).  Personnellement, je pense que le tableau de bord est tr√®s pratique pour surveiller rapidement l'√©tat ou afficher les d√©tails des diff√©rents composants des K8, sans avoir √† entrer de longues commandes dans la CLI.  Vous trouverez un √©quilibre entre eux de mani√®re naturelle. <br><br><img src="https://habrastorage.org/webt/hi/hu/cj/hihucj_bhrydsrgy0ad5xifupuc.png"><br><br><h3>  Configurations </h3><br>  L'un des concepts tr√®s importants de Kubernetes est l'√©tat souhait√© des configurations.  Vous d√©clarez que vous voulez pour presque n'importe quel composant Kubernetes via un fichier YAML, et vous cr√©ez tout cela en utilisant kubectl (ou via un tableau de bord graphique) comme √©tat souhait√©.  D√©sormais, Kubernetes s'efforcera toujours de maintenir votre environnement dans un √©tat op√©rationnel donn√©.  Par exemple, si vous souhaitez avoir 4 r√©pliques d'un pod, les K8 continueront de surveiller ces pods, et si l'un d'eux est mort ou si le n≈ìud sur lequel il a travaill√© a eu des probl√®mes, les K8 se r√©cup√®rent automatiquement et le cr√©ent automatiquement Pod ailleurs. <br><br>  En revenant √† nos fichiers de configuration YAML, vous pouvez les consid√©rer comme un fichier .VMX pour une machine virtuelle ou un descripteur .OVF pour une appliance virtuelle que vous souhaitez d√©ployer sur vSphere.  Ces fichiers d√©finissent la configuration de la charge de travail / composant que vous souhaitez ex√©cuter.  Contrairement aux fichiers VMX / OVF, qui sont exclusifs aux VM / Appliances virtuelles, les fichiers de configuration YAML sont utilis√©s pour d√©finir n'importe quel composant K8, tels que ReplicaSets, Services, Deployments, etc.  Consid√©rez ceci dans les sections suivantes. <br><img src="https://habrastorage.org/webt/qg/2w/np/qg2wnppfqeu9ksyev67haaiz19m.png"><br><br><h3>  Clusters virtuels </h3><br>  Dans vSphere, nous avons des h√¥tes ESXi physiques qui sont logiquement regroup√©s en clusters.  Ces clusters peuvent √™tre divis√©s en d'autres clusters virtuels appel√©s ¬´Pools de ressources¬ª.  Ces ¬´pools¬ª sont principalement utilis√©s pour limiter les ressources.  Chez Kubernetes, nous avons quelque chose de tr√®s similaire.  Nous les appelons ¬´espaces de noms¬ª, ils peuvent √©galement √™tre utilis√©s pour fournir des limites de ressources, qui seront refl√©t√©es dans la section suivante.  Cependant, le plus souvent, les ¬´espaces de noms¬ª sont utilis√©s comme un outil d'h√©bergement multiclient pour les applications (ou les utilisateurs, si vous utilisez des clusters K8 courants).  C'est √©galement l'une des options avec lesquelles vous pouvez effectuer la segmentation du r√©seau √† l'aide de NSX-T.  Consid√©rez ceci dans les publications suivantes. <br><img src="https://habrastorage.org/webt/n6/ve/kr/n6vekro9uz1bx9i_0kqgxquyduw.png"><br><br><h3>  Gestion des ressources </h3><br>  Comme je l'ai mentionn√© dans la section pr√©c√©dente, les espaces de noms dans Kubernetes sont couramment utilis√©s comme moyen de segmentation.  Une autre utilisation des espaces de noms est l'allocation des ressources.  Cette option est appel√©e ¬´Quotas de ressources¬ª.  Comme indiqu√© dans les sections pr√©c√©dentes, la d√©finition de cela se produit dans les fichiers de configuration YAML, dans lesquels l'√©tat souhait√© est d√©clar√©.  Dans vSphere, comme le montre la capture d'√©cran ci-dessous, nous le d√©terminons √† partir des param√®tres des pools de ressources. <br><img src="https://habrastorage.org/webt/jq/oy/nl/jqoynlerkguited5ozdgsndtj4w.png"><br><br><h3>  Identification de la charge de travail </h3><br>  C'est assez simple et presque le m√™me pour vSphere et Kubernetes.  Dans le premier cas, nous utilisons les concepts de balises pour d√©finir (ou grouper) des charges de travail similaires, et dans le second, nous utilisons le terme ¬´√©tiquettes¬ª.  Dans le cas de Kubernetes, l'identification de la charge de travail est obligatoire. <br><img src="https://habrastorage.org/webt/j_/2s/go/j_2sgoekii7mwswdmhspterznoq.png"><br><br><h3>  R√©servation </h3><br>  Maintenant pour le vrai plaisir.  Si vous √©tiez ou √™tes un grand fan de vSphere FT, comme moi, vous allez adorer cette fonctionnalit√© dans Kubernetes, malgr√© quelques diff√©rences dans les deux technologies.  Dans vSphere, il s'agit d'une machine virtuelle avec une instance fant√¥me en cours d'ex√©cution ex√©cut√©e sur un h√¥te diff√©rent.  Nous enregistrons les instructions sur la machine virtuelle principale et les rejouons sur la machine virtuelle fant√¥me.  Si la machine principale cesse de fonctionner, la machine virtuelle fant√¥me s'active imm√©diatement.  Ensuite, vSphere essaie de trouver un autre h√¥te ESXi pour cr√©er une nouvelle instance fant√¥me de la machine virtuelle pour maintenir la m√™me redondance.  Chez Kubernetes, nous avons quelque chose de tr√®s similaire.  ReplicaSets est le montant que vous sp√©cifiez pour ex√©cuter plusieurs instances de pods.  Si un pod √©choue, d'autres instances sont disponibles pour traiter le trafic.  Dans le m√™me temps, les K8 essaieront de lancer un nouveau pod sur n'importe quel n≈ìud disponible afin de maintenir l'√©tat de configuration souhait√©.  La principale diff√©rence, comme vous l'avez peut-√™tre d√©j√† remarqu√©, est que dans le cas des K8, les pods fonctionnent et servent toujours le trafic.  Ce ne sont pas des charges de travail fant√¥mes. <br><img src="https://habrastorage.org/webt/29/u-/sd/29u-sdyxbg1n0qdzwpkwjmcyuxe.png"><br><br><h3>  √âquilibrage de charge </h3><br>  Bien que cela ne soit pas une fonction int√©gr√©e dans vSphere, il est tr√®s, tr√®s souvent n√©cessaire d'ex√©cuter des √©quilibreurs de charge sur la plate-forme.  Dans le monde vSphere, il existe des √©quilibreurs de charge virtuels ou physiques pour distribuer le trafic r√©seau entre plusieurs machines virtuelles.  Il peut y avoir de nombreux modes de configuration diff√©rents, mais supposons que nous entendons une configuration √† un bras.  Dans ce cas, vous √©quilibrez la charge du trafic Est-Ouest sur vos machines virtuelles. <br><br>  De m√™me, Kubernetes a le concept de ¬´Services¬ª.  Le service dans les K8 peut √©galement √™tre utilis√© dans diff√©rents modes de configuration.  Choisissons la configuration ¬´ClusterIP¬ª pour la comparer avec l'√©quilibreur de charge √† un bras.  Dans ce cas, le service dans les K8 aura une adresse IP virtuelle (VIP), qui est toujours statique et ne change pas.  Ce VIP r√©partira le trafic entre plusieurs pods.  Ceci est particuli√®rement important dans le monde Kubernetes, o√π par nature les pods sont √©ph√©m√®res, vous perdez l'adresse IP du pod au moment o√π il meurt ou est supprim√©.  Par cons√©quent, vous devez toujours fournir un VIP statique. <br><br>  Comme je l'ai d√©j√† mentionn√©, le service a de nombreuses autres configurations, par exemple, ¬´NodePort¬ª, o√π vous attribuez un port au niveau du n≈ìud, puis effectuez la traduction de la traduction d'adresse de port pour les pods.  Il existe √©galement un ¬´LoadBalancer¬ª dans lequel vous ex√©cutez une instance de Load Balancer √† partir d'un fournisseur tiers ou cloud. <br><img src="https://habrastorage.org/webt/s9/4g/my/s94gmy5frfcjkyxeywlp3gcwtkm.png"><br><br>  Kuberentes dispose d'un autre m√©canisme d'√©quilibrage de charge tr√®s important appel√© ¬´contr√¥leur d'entr√©e¬ª.  Vous pouvez le consid√©rer comme un √©quilibreur de charge d'application en ligne.  L'id√©e principale est que le contr√¥leur d'entr√©e (sous la forme d'un pod) sera lanc√© avec une adresse IP visible de l'ext√©rieur.  Cette adresse IP peut avoir quelque chose comme des enregistrements DNS g√©n√©riques.  Lorsque le trafic arrive au contr√¥leur d'entr√©e √† l'aide d'une adresse IP externe, il v√©rifie les en-t√™tes et d√©termine √† l'aide de l'ensemble de r√®gles que vous avez pr√©c√©demment d√©fini √† quel pod ce nom appartient.  Par exemple: sphinx-v1.esxcloud.net sera dirig√© vers le service sphinx-svc-1, et sphinx-v2.esxcloud.net sera dirig√© vers le service sphinx-svc2, etc. <br><img src="https://habrastorage.org/webt/fk/jr/t_/fkjrt_3ho51djc-euoshgcjccas.png"><br><br><h3>  Stockage et r√©seau </h3><br>  Le stockage et la mise en r√©seau sont des sujets tr√®s, tr√®s larges quand il s'agit de Kubernetes.  Il est presque impossible de parler bri√®vement de ces deux sujets dans un billet d'introduction, mais je parlerai bient√¥t en d√©tail des diff√©rents concepts et options pour chacun de ces sujets.  En attendant, regardons rapidement comment fonctionne la pile r√©seau dans Kubernetes, car nous en aurons besoin dans la section suivante. <br><br>  Kubernetes propose diff√©rents ¬´plugins¬ª r√©seau que vous pouvez utiliser pour configurer le r√©seau de vos n≈ìuds et pods.  Un plugin commun est ¬´kubenet¬ª, qui est actuellement utilis√© dans les m√©ga-nuages ‚Äã‚Äãtels que GCP et AWS.  Ici, je vais parler bri√®vement de la mise en ≈ìuvre de GCP, puis montrer un exemple pratique de mise en ≈ìuvre dans GKE. <br><img src="https://habrastorage.org/webt/vc/vh/n6/vcvhn6ll9s46qdbwvurxheaykg8.png"><br><br>  √Ä premi√®re vue, cela peut sembler trop compliqu√©, mais j'esp√®re que vous comprendrez tout cela d'ici la fin de ce post.  Tout d'abord, nous voyons que nous avons deux n≈ìuds Kubernetes: le n≈ìud 1 et le n≈ìud (m).  Chaque n≈ìud a une interface eth0, comme n'importe quelle machine Linux.  Cette interface a une adresse IP pour le monde ext√©rieur, dans notre cas, sur le sous-r√©seau 10.140.0.0/24.  Le p√©riph√©rique Upstream L3 sert de passerelle par d√©faut pour acheminer notre trafic.  Il peut s'agir d'un commutateur L3 dans votre centre de donn√©es ou d'un routeur VPC dans le cloud, tel que GCP, comme nous le verrons plus tard.  Tout va bien? <br><br>  De plus, nous voyons que nous avons l'interface Bridge cbr0 √† l'int√©rieur du n≈ìud.  Cette interface est la passerelle par d√©faut pour le sous-r√©seau IP 10.40.1.0/24 dans le cas du n≈ìud 1. Ce sous-r√©seau est attribu√© par Kubernetes √† chaque n≈ìud.  Les n≈ìuds obtiennent g√©n√©ralement un sous-r√©seau / 24, mais vous pouvez le changer en utilisant NSX-T (nous couvrirons cela dans les articles suivants).  Pour le moment, ce sous-r√©seau est celui √† partir duquel nous √©mettrons des adresses IP pour les pods.  De cette fa√ßon, tout pod √† l'int√©rieur du n≈ìud 1 obtiendra une adresse IP de ce sous-r√©seau.  Dans notre cas, le Pod 1 a une adresse IP de 10.40.1.10.  Cependant, vous remarquez qu'il existe deux conteneurs imbriqu√©s dans ce pod.  Nous avons d√©j√† dit qu'au sein d'un Pod, un ou plusieurs conteneurs peuvent √™tre lanc√©s, qui sont √©troitement li√©s les uns aux autres en termes de fonctionnalit√©.  C'est ce que nous voyons sur la figure.  Le conteneur 1 √©coute sur le port 80 et le conteneur 2 √©coute sur le port 90. Les deux conteneurs ont la m√™me adresse IP 10.40.1.10, mais ils ne poss√®dent pas l'espace de noms de mise en r√©seau.  OK, alors √† qui appartient cette pile r√©seau?  En fait, il existe un conteneur sp√©cial appel√© ¬´Pause Container¬ª.  Le diagramme montre que son adresse IP est l'adresse IP de Pod pour la communication avec le monde ext√©rieur.  Ainsi, Pause Container poss√®de cette pile r√©seau, y compris l'adresse IP 10.40.1.10 elle-m√™me, et, bien s√ªr, il redirige le trafic vers le conteneur 1 vers le port 80, et redirige √©galement le trafic vers le conteneur 2 vers le port 90. <br><br>  Vous devez maintenant vous demander comment le trafic est redirig√© vers le monde ext√©rieur?  Nous avons le transfert IP Linux standard activ√© pour transf√©rer le trafic de cbr0 vers eth0.  C'est tr√®s bien, mais alors on ne sait pas comment l'appareil L3 peut apprendre √† transf√©rer du trafic vers sa destination?  Dans cet exemple sp√©cifique, nous n'avons pas de routage dynamique pour l'annonce de ce r√©seau.  Par cons√©quent, nous devons avoir une sorte de routes statiques sur le p√©riph√©rique L3.  Afin d'atteindre le sous-r√©seau 10.40.1.0/24, vous devez transf√©rer le trafic vers l'adresse IP du n≈ìud 1 (10.140.0.11) et pour atteindre le sous-r√©seau 10.40.2.0/24, le prochain espoir - Node (m) avec l'adresse IP 10.140.0.12. <br><br>  Tout cela est g√©nial, mais c'est une fa√ßon tr√®s peu pratique de g√©rer vos r√©seaux.  La prise en charge de toutes ces routes lors de la mise √† l'√©chelle de votre cluster sera un cauchemar absolu pour les administrateurs r√©seau.  C'est pourquoi certaines solutions, telles que CNI (Container Network Interface) √† Kuberentes, sont n√©cessaires pour g√©rer la connectivit√© r√©seau.  NSX-T est l'une de ces solutions avec une tr√®s large fonctionnalit√© pour l'interaction r√©seau et la s√©curit√©. <br><br>  N'oubliez pas que nous avons regard√© le plugin kubenet, pas CNI.  Le plugin kubenet est ce que le Google Container Engine (GKE) utilise, et la fa√ßon dont ils le font est assez amusant car il est enti√®rement d√©fini et automatis√© par logiciel dans leur cloud.  ,            GCP.     . <br><br><h3>  Et ensuite? </h3><br>     Kuberentes.        ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">   </a> . <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La deuxi√®me partie.</a> <br><br>     .    . <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr436028/">https://habr.com/ru/post/fr436028/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr436016/index.html">Asterisk Voice Recognition IVR - Rapide, facile et gratuit</a></li>
<li><a href="../fr436020/index.html">Magento 2: importation de produits √† partir de sources externes</a></li>
<li><a href="../fr436022/index.html">Comment nous avons d√©velopp√© Librem 5 DevKit enti√®rement en logiciel libre</a></li>
<li><a href="../fr436024/index.html">Comment ne pas jeter dans Java</a></li>
<li><a href="../fr436026/index.html">Info Desk: ¬´Internet Archive¬ª - histoire, mission et projets subsidiaires</a></li>
<li><a href="../fr436032/index.html">Tutoriel React, partie 9: Propri√©t√©s des composants</a></li>
<li><a href="../fr436036/index.html">Les chercheurs en intelligence artificielle peuvent-ils lui confier un test de leurs travaux?</a></li>
<li><a href="../fr436038/index.html">Le bruit du silence: combien de gadgets fous sont n√©cessaires pour obtenir un environnement optimal pour le sommeil?</a></li>
<li><a href="../fr436040/index.html">Optimisation graphique. Coque concave int√©ressante</a></li>
<li><a href="../fr436042/index.html">Panneau d'outils suppl√©mentaires pour le d√©veloppeur sur InterSystems IRIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
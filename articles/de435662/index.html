<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÜ üí™üèæ üë©üèΩ‚Äçüåæ "Zuverl√§ssigkeit und Zuverl√§ssigkeit wie bei Google" - und nicht nur: √úbersetzung des Artikels "Berechnung der Servicezuverl√§ssigkeit" ü•ë üßö üë©‚Äçüë©‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Hauptaufgabe von kommerziellen (und auch nichtkommerziellen) Diensten besteht darin, dem Benutzer immer zur Verf√ºgung zu stehen. Obwohl alle abst√º...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>"Zuverl√§ssigkeit und Zuverl√§ssigkeit wie bei Google" - und nicht nur: √úbersetzung des Artikels "Berechnung der Servicezuverl√§ssigkeit"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/435662/"><img src="https://habrastorage.org/webt/4y/cb/hg/4ycbhgnlttaomlm6vkgjdlorwgi.png" alt="Bild"><br><br>  Die Hauptaufgabe von kommerziellen (und auch nichtkommerziellen) Diensten besteht darin, dem Benutzer immer zur Verf√ºgung zu stehen.  Obwohl alle abst√ºrzen, stellt sich die Frage, was das IT-Team unternimmt, um sie zu minimieren.  Wir haben einen Artikel von Ben Treynor, Mike Dahlin, Vivek Rau und Betsy Beyer ‚ÄûBerechnung der Servicezuverl√§ssigkeit‚Äú √ºbersetzt, in dem beispielsweise Google erkl√§rt, warum 100% ein falscher Bezugspunkt f√ºr den Zuverl√§ssigkeitsindikator ist, was die ‚ÄûRegel der vier Neunen‚Äú ist und Wie kann in der Praxis die Machbarkeit gro√üer und kleiner Ausf√§lle des Dienstes und / oder seiner kritischen Komponenten mathematisch vorhergesagt werden - die erwartete Ausfallzeit, die Zeit, die zum Erkennen eines Fehlers ben√∂tigt wird, und die Zeit zum Wiederherstellen des Dienstes. <a name="habracut"></a><br><br><h2 id="raschet-nadezhnosti-servisa">  Berechnung der Servicezuverl√§ssigkeit </h2><br><h3 id="vasha-sistema-nadezhna-nastolko-naskolko-nadezhny-eyokomponenty">  <em>Ihr System ist so zuverl√§ssig wie seine Komponenten</em> </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ben Trainor, Mike Dalin, Vivec Rau und Betsy Beyer</a> </p><br><p>  Wie im Buch ‚Äû <em>Site Reliability Engineering: Zuverl√§ssigkeit und Zuverl√§ssigkeit wie bei Google</em> ‚Äú (im Folgenden als SRE-Buch bezeichnet) beschrieben, kann durch die Entwicklung von Google-Produkten und -Diensten eine hohe Geschwindigkeit der Freigabe neuer Funktionen erreicht werden, w√§hrend aggressive SLO (Service-Level-Ziele, Service-Level-Ziele) beibehalten werden. ) um eine hohe Zuverl√§ssigkeit und schnelle Reaktion zu gew√§hrleisten.  SLOs erfordern, dass der Service fast immer in gutem Zustand und fast immer schnell ist.  Dar√ºber hinaus geben SLOs auch die genauen Werte dieses ‚Äûfast immer‚Äú f√ºr einen bestimmten Dienst an.  SLOs basieren auf folgenden Beobachtungen: </p><br><p>  <em>Im allgemeinen Fall ist f√ºr jeden Softwaredienst oder jedes System 100% der falsche Bezugspunkt f√ºr den Zuverl√§ssigkeitsindikator, da kein Benutzer den Unterschied zwischen 100% und 99.999% Verf√ºgbarkeit feststellen kann.</em>  <em>Zwischen dem Benutzer und dem Dienst gibt es viele andere Systeme (sein Laptop, WLAN zu Hause, Anbieter, Netzteil ...), und alle diese Systeme sind in 99,999% der F√§lle nicht verf√ºgbar, aber viel seltener.</em>  <em>Daher geht die Differenz zwischen 99,999% und 100% aufgrund zuf√§lliger Faktoren verloren, die durch die Unzug√§nglichkeit anderer Systeme verursacht werden, und der Benutzer profitiert nicht davon, dass wir uns viel M√ºhe gegeben haben, um diesen letzten Bruchteil des Prozentsatzes der Systemverf√ºgbarkeit zu erreichen.</em>  <em>Schwerwiegende Ausnahmen von dieser Regel sind Antiblockiersysteme und Herzschrittmacher!</em> </p><br><p> Eine ausf√ºhrliche Beschreibung der Beziehung zwischen SLOs und SLIs (Service Level Indicators) und SLAs (Service Level Agreements) finden Sie im Kapitel SRE Target Level of Service.  In diesem Kapitel wird auch ausf√ºhrlich beschrieben, wie Metriken ausgew√§hlt werden, die f√ºr einen bestimmten Dienst oder ein bestimmtes System relevant sind. Dies bestimmt wiederum die Auswahl des geeigneten SLO f√ºr diesen Dienst oder dieses System. </p><br><p>  Dieser Artikel erweitert das SLO-Thema, um sich auf Servicekomponenten zu konzentrieren.  Insbesondere werden wir untersuchen, wie sich die Zuverl√§ssigkeit kritischer Komponenten auf die Zuverl√§ssigkeit eines Dienstes auswirkt und wie Systeme entworfen werden, um die Auswirkungen zu verringern oder die Anzahl kritischer Komponenten zu verringern. </p><br><p>  Die meisten von Google angebotenen Dienste zielen darauf ab, Nutzern eine Zug√§nglichkeit von 99,99 Prozent (manchmal als "vier Neunen" bezeichnet) zu bieten.  F√ºr einige Dienste ist in der Benutzervereinbarung eine niedrigere Anzahl angegeben, das Ziel von 99,99% ist jedoch im Unternehmen gespeichert.  Diese h√∂here Leiste bietet einen Vorteil in Situationen, in denen sich Benutzer lange vor dem Versto√ü gegen die Vertragsbedingungen √ºber die Leistung des Dienstes beschweren, da das Ziel Nummer 1 des SRE-Teams darin besteht, Benutzer mit den Diensten zufrieden zu stellen.  F√ºr viele Dienste stellt ein internes Ziel von 99,99% den Mittelweg dar, der Kosten, Komplexit√§t und Zuverl√§ssigkeit in Einklang bringt.  F√ºr einige andere, insbesondere globale Cloud-Dienste, liegt das interne Ziel bei 99,999%. </p><br><h2 id="nadezhnost-9999-nablyudeniya-i-vyvody">  Zuverl√§ssigkeit 99,99%: Beobachtungen und Schlussfolgerungen </h2><br><p>  Schauen wir uns einige wichtige Beobachtungen und Schlussfolgerungen zum Design und Betrieb des Dienstes mit einer Zuverl√§ssigkeit von 99,99% an und fahren wir dann mit der Praxis fort. </p><br><h4 id="nablyudenie-1-prichiny-sboev">  Beobachtung Nr. 1: Fehlerursachen </h4><br><p>  Fehler treten aus zwei Hauptgr√ºnden auf: Probleme mit dem Dienst selbst und Probleme mit kritischen Komponenten des Dienstes.  Eine kritische Komponente ist eine Komponente, die im Falle eines Fehlers einen entsprechenden Fehler im Betrieb des gesamten Dienstes verursacht. </p><br><h4 id="nablyudenie-2-matematika-nadezhnosti">  Beobachtung Nr. 2: Mathematik der Zuverl√§ssigkeit </h4><br><p>  Die Zuverl√§ssigkeit h√§ngt von der H√§ufigkeit und Dauer der Ausfallzeiten ab.  Es wird gemessen durch: </p><br><ul><li>  Leerlauffrequenz oder umgekehrt: MTTF (mittlere Zeit bis zum Ausfall). </li><li>  Ausfallzeit, MTTR (mittlere Reparaturzeit).  Die Ausfallzeit wird durch die Zeit des Benutzers bestimmt: vom Beginn der Fehlfunktion bis zur Wiederaufnahme des normalen Betriebs des Dienstes. <br>  Somit wird Zuverl√§ssigkeit mathematisch als MTTF / (MTTF + MTTR) unter Verwendung der entsprechenden Einheiten definiert. </li></ul><br><h4 id="vyvod-1-pravilo-dopolnitelnyh-devyatok">  Schlussfolgerung Nr. 1: Regel der zus√§tzlichen Neunen </h4><br><p>  Ein Service kann nicht zuverl√§ssiger sein als alle seine kritischen Komponenten zusammen.  Wenn Ihr Service eine Verf√ºgbarkeit von 99,99% sicherstellen m√∂chte, sollten alle kritischen Komponenten in deutlich mehr als 99,99% der F√§lle verf√ºgbar sein. <br>  In Google verwenden wir die folgende Faustregel: Kritische Komponenten m√ºssen im Vergleich zur deklarierten Zuverl√§ssigkeit Ihres Dienstes zus√§tzliche Neunen bereitstellen - im obigen Beispiel 99,999 Prozent Verf√ºgbarkeit -, da jeder Dienst mehrere kritische Komponenten sowie seine eigenen spezifischen Probleme aufweist.  Dies wird als "Regel der zus√§tzlichen Neunen" bezeichnet. <br>  Wenn Sie eine kritische Komponente haben, die nicht gen√ºgend Neunen liefert (ein relativ h√§ufiges Problem!), Sollten Sie die negativen Folgen minimieren. </p><br><h4 id="vyvod-2-matematika-chastoty-vremeni-obnaruzheniya-ivremeni-vosstanovleniya">  Schlussfolgerung Nr. 2: Mathematik der Frequenz, Erkennungszeit und Erholungszeit </h4><br><p>  Ein Service kann nicht zuverl√§ssiger sein als das Produkt aus der H√§ufigkeit von Vorf√§llen und dem Zeitpunkt der Erkennung und Wiederherstellung.  Beispielsweise f√ºhren drei Abschaltungen pro Jahr von jeweils 20 Minuten zu einer Ausfallzeit von insgesamt 60 Minuten.  Selbst wenn der Service den Rest des Jahres einwandfrei funktioniert h√§tte, w√§re eine Zuverl√§ssigkeit von 99,99 Prozent (nicht mehr als 53 Minuten Ausfallzeit pro Jahr) unm√∂glich. <br>  Dies ist eine einfache mathematische Beobachtung, die jedoch h√§ufig √ºbersehen wird. </p><br><h4 id="zaklyuchenie-izvyvodov-1i-2">  Schlussfolgerung aus den Schlussfolgerungen Nr. 1 und Nr. 2 </h4><br><p>  Wenn das Ma√ü an Zuverl√§ssigkeit, auf das sich Ihr Service st√ºtzt, nicht erreicht werden kann, m√ºssen Anstrengungen unternommen werden, um die Situation zu korrigieren - entweder durch Erh√∂hen der Verf√ºgbarkeit des Service oder durch Minimieren der oben beschriebenen negativen Folgen.  Das Verringern der Erwartungen (d. H. Der deklarierten Zuverl√§ssigkeit) ist ebenfalls eine Option und h√§ufig die zutreffendste: Machen Sie dem von Ihnen abh√§ngigen Dienst klar, dass er entweder sein System neu erstellen muss, um den Fehler in der Zuverl√§ssigkeit Ihres Dienstes zu kompensieren, oder seine eigenen Service-Level-Ziele zu reduzieren .  Wenn Sie die Diskrepanz nicht selbst beseitigen, erfordert ein ausreichend langer Ausfall des Systems zwangsl√§ufig Anpassungen. </p><br><h2 id="prakticheskoe-primenenie">  Praktische Anwendung </h2><br><p>  Schauen wir uns ein Beispiel f√ºr einen Service mit einer Zielzuverl√§ssigkeit von 99,99% an und erarbeiten die Anforderungen f√ºr seine Komponenten und arbeiten mit seinen Fehlern. </p><br><h4 id="cifry">  Zahlen </h4><br><p>  Angenommen, Ihr 99,99-Prozent-Service ist mit den folgenden Merkmalen verf√ºgbar: </p><br><ul><li>  Ein gr√∂√üerer Ausfall und drei kleinere Ausf√§lle pro Jahr.  Das klingt be√§ngstigend, aber beachten Sie, dass ein Vertrauensniveau von 99,99% eine gro√üe Ausfallzeit von 20 bis 30 Minuten und einige kurze teilweise Abschaltungen pro Jahr impliziert.  (Aus der Mathematik geht Folgendes hervor: a) Der Ausfall eines Segments wird aus Sicht von SLO nicht als Ausfall des gesamten Systems angesehen, und b) die Gesamtzuverl√§ssigkeit wird aus der Summe der Zuverl√§ssigkeit der Segmente berechnet.) </li><li>  F√ºnf kritische Komponenten in Form anderer unabh√§ngiger Dienste mit einer Zuverl√§ssigkeit von 99,999%. </li><li>  F√ºnf unabh√§ngige Segmente, die nicht nacheinander ausfallen k√∂nnen. </li><li>  Alle √Ñnderungen werden schrittweise segmentweise durchgef√ºhrt. </li></ul><br><p>  Die mathematische Berechnung der Zuverl√§ssigkeit lautet wie folgt: </p><br><h4 id="trebovaniya-kkomponentam">  Komponentenanforderungen </h4><br><ul><li>  Die Gesamtfehlergrenze f√ºr das Jahr betr√§gt 0,01 Prozent von 525.600 Minuten pro Jahr oder 53 Minuten (basierend auf dem 365-Tage-Jahr im schlimmsten Fall). </li><li>  Die f√ºr das Herunterfahren kritischer Komponenten zugewiesene Grenze betr√§gt f√ºnf unabh√§ngige kritische Komponenten mit einer Grenze von jeweils 0,001% = 0,005%;  0,005% von 525.600 Minuten pro Jahr oder 26 Minuten. </li><li>  Die verbleibende Fehlergrenze Ihres Dienstes betr√§gt 53-26 = 27 Minuten. </li></ul><br><h4 id="trebovaniya-kreagirovaniyu-naotklyucheniya">  Antwortanforderungen f√ºr das Herunterfahren </h4><br><ul><li>  Erwartete Ausfallzeit: 4 (1 vollst√§ndige Abschaltung und 3 Abschaltungen, die nur ein Segment betreffen) </li><li>  Der kumulative Effekt der erwarteten Ausf√§lle: (1 √ó 100%) + (3 √ó 20%) = 1,6 </li><li>  Fehlererkennung und -behebung danach: 27 / 1,6 = 17 Minuten </li><li>  Zeit f√ºr die √úberwachung, um einen Fehler zu erkennen und dar√ºber zu informieren: 2 Minuten </li><li>  Zeit, die dem diensthabenden Spezialisten zur Analyse des Alarms einger√§umt wird: 5 Minuten.  (Das √úberwachungssystem sollte SLO-Verst√∂√üe verfolgen und bei jedem Systemausfall ein Signal an den diensthabenden Pager senden. Viele Google-Dienste werden von diensthabenden Schicht-SR-Ingenieuren unterst√ºtzt, die auf dringende Fragen antworten.) </li><li>  Verbleibende Zeit zur wirksamen Minimierung von Nebenwirkungen: 10 Minuten </li></ul><br><h2 id="vyvod-rychagi-dlya-uvelicheniya-nadezhnosti-servisa">  Fazit: Hebelwirkung zur Erh√∂hung der Servicezuverl√§ssigkeit </h2><br><p>  Es lohnt sich, die vorgestellten Zahlen sorgf√§ltig zu betrachten, da sie den grundlegenden Punkt betonen: Es gibt drei Haupthebel zur Erh√∂hung der Zuverl√§ssigkeit des Dienstes. </p><br><ul><li>  Reduzieren Sie die H√§ufigkeit von Ausf√§llen - durch Freigaberichtlinien, Tests, regelm√§√üige Bewertungen der Projektstruktur usw. </li><li>  Reduzieren Sie Ihre durchschnittliche Ausfallzeit durch Segmentierung, geografische Isolation, allm√§hliche Verschlechterung oder Kundenisolation. </li><li>  Reduzieren Sie die Wiederherstellungszeit - durch √úberwachung, Ein-Knopf-Rettungsvorg√§nge (z. B. Zur√ºcksetzen auf einen fr√ºheren Status oder Hinzuf√ºgen von Standby-Strom), Betriebsbereitschaftspraktiken usw. <br>  Sie k√∂nnen zwischen diesen drei Methoden abw√§gen, um die Implementierung der Fehlertoleranz zu vereinfachen.  Wenn es beispielsweise schwierig ist, eine 17-min√ºtige MTTR zu erreichen, konzentrieren Sie sich auf die Reduzierung der durchschnittlichen Ausfallzeiten.  Strategien zur Minimierung nachteiliger Auswirkungen und zur Abschw√§chung der Auswirkungen kritischer Komponenten werden sp√§ter in diesem Artikel ausf√ºhrlicher erl√§utert. </li></ul><br><h2 id="utochnenie-pravila-dopolnitelnyh-devyatok-dlya-vlozhennyh-komponentov">  Erl√§uterung ‚ÄûRegeln f√ºr zus√§tzliche Neunen‚Äú f√ºr verschachtelte Komponenten </h2><br><p>  Ein zuf√§lliger Leser kann daraus schlie√üen, dass jedes zus√§tzliche Glied in der Abh√§ngigkeitskette zus√§tzliche neun erfordert, so dass zwei zus√§tzliche neun f√ºr Abh√§ngigkeiten zweiter Ordnung, drei zus√§tzliche neun f√ºr Abh√§ngigkeiten dritter Ordnung usw. erforderlich sind. </p><br><p>  Dies ist die falsche Schlussfolgerung.  Es basiert auf einem naiven Modell einer Hierarchie von Komponenten in Form eines Baumes mit einer konstanten Verzweigung auf jeder Ebene.  In einem solchen Modell, wie in Abb.  In 1 gibt es 10 eindeutige Komponenten erster Ordnung, 100 eindeutige Komponenten zweiter Ordnung, 1.000 eindeutige Komponenten dritter Ordnung usw., was zu insgesamt 1.111 eindeutigen Diensten f√ºhrt, selbst wenn die Architektur auf vier Schichten beschr√§nkt ist.  Ein √ñkosystem hochzuverl√§ssiger Dienste mit so vielen unabh√§ngigen kritischen Komponenten ist eindeutig unrealistisch. </p><br><img src="https://habrastorage.org/webt/u6/lt/p3/u6ltp33ofzyn8qgmvvgtnlfi90u.png" alt="Bild"><br><p>  <i>Abb.</i>  <i>1 - Komponentenhierarchie: Ung√ºltiges Modell</i> </p><br><p>  Eine kritische Komponente an sich kann den Ausfall des gesamten Dienstes (oder Dienstsegments) verursachen, unabh√§ngig davon, wo sie sich im Abh√§ngigkeitsbaum befindet.  Wenn eine bestimmte Komponente von X als Abh√§ngigkeit von mehreren Komponenten erster Ordnung angezeigt wird, sollte X daher nur einmal gez√§hlt werden, da ihr Ausfall letztendlich zu einem Dienstausfall f√ºhrt, unabh√§ngig davon, wie viele Zwischendienste ebenfalls betroffen sind. </p><br><p>  Eine korrekte Lesart der Regel lautet wie folgt: </p><br><ul><li>  Wenn ein Dienst N eindeutige kritische Komponenten enth√§lt, tr√§gt jede von ihnen 1 / N zur Unzuverl√§ssigkeit des gesamten durch diese Komponente verursachten Dienstes bei, unabh√§ngig davon, wie niedrig sie in der Hierarchie der Komponenten ist. </li><li>  Jede Komponente sollte nur einmal gez√§hlt werden, auch wenn sie mehrmals in der Komponentenhierarchie vorkommt (mit anderen Worten, es werden nur eindeutige Komponenten gez√§hlt).  Zum Beispiel bei der Berechnung der Komponenten von Service A in Abb.  2, Service B sollte nur einmal ber√ºcksichtigt werden. </li></ul><br><img src="https://habrastorage.org/webt/ng/_y/8h/ng_y8hcswjcctczza1mkhzaejb0.png" alt="Bild"><br><p>  <i>Abb.</i>  <i>2 - Komponenten in der Hierarchie</i> </p><br><p>  Betrachten Sie beispielsweise einen hypothetischen Dienst A mit einer Fehlergrenze von 0,01 Prozent.  Servicebesitzer sind bereit, die H√§lfte dieses Limits f√ºr ihre eigenen Fehler und Verluste und die H√§lfte f√ºr kritische Komponenten auszugeben.  Wenn der Dienst N solche Komponenten hat, erh√§lt jede von ihnen 1 / N der verbleibenden Fehlergrenze.  Typische Dienste haben h√§ufig 5 bis 10 kritische Komponenten, und daher kann jeder von ihnen nur einen zehnten oder einen zwanzigsten Grad der Fehlergrenze von Dienst A ablehnen. Daher sollten kritische Teile des Dienstes in der Regel eine zus√§tzliche Zuverl√§ssigkeit von neun aufweisen. </p><br><h2 id="limity-oshibok">  Fehlergrenzen </h2><br><p>  Das Konzept der Fehlergrenzen wird im Buch SRE ausf√ºhrlich behandelt, hier sollte es jedoch erw√§hnt werden.  Google SR-Ingenieure verwenden Fehlergrenzen, um die Zuverl√§ssigkeit und das Tempo von Updates auszugleichen.  Diese Grenze bestimmt den akzeptablen Ausfallgrad f√ºr den Dienst f√ºr einen bestimmten Zeitraum (normalerweise einen Monat).  Das Fehlerlimit betr√§gt nur 1 abz√ºglich des SLO des Dienstes, sodass der zuvor diskutierte 99,99-prozentige verf√ºgbare Dienst ein 0,01-prozentiges ‚ÄûLimit‚Äú f√ºr die Unzuverl√§ssigkeit aufweist.  Bis der Dienst sein Fehlerlimit innerhalb eines Monats aufgebraucht hat, kann das Entwicklungsteam (innerhalb eines angemessenen Rahmens) neue Funktionen, Updates usw. starten. </p><br><p>  Wenn das Fehlerlimit aufgebraucht ist, werden √Ñnderungen am Dienst ausgesetzt (mit Ausnahme dringender Sicherheitskorrekturen und √Ñnderungen, die den Versto√ü √ºberhaupt verursachen sollen), bis der Dienst die Reserve im Fehlerlimit wieder auff√ºllt oder bis sich der Monat √§ndert.  Viele Dienste bei Google verwenden eine Schiebefenstermethode f√ºr SLO, damit die Fehlergrenze schrittweise wiederhergestellt wird.  Bei seri√∂sen Diensten mit einem SLO von mehr als 99,99% ist es ratsam, das Limit viertelj√§hrlich und nicht monatlich auf Null zu setzen, da die Anzahl der zul√§ssigen Ausfallzeiten gering ist. </p><br><p>  Fehlergrenzen beseitigen Spannungen zwischen Abteilungen, die andernfalls zwischen SR-Ingenieuren und Produktentwicklern auftreten k√∂nnten, und bieten ihnen ein gemeinsames, datenbasiertes Tool zur Risikobewertung f√ºr die Produkteinf√ºhrung.  Sie geben den SR-Ingenieuren und Entwicklungsteams auch das gemeinsame Ziel, Methoden und Technologien zu entwickeln, mit denen sie schneller innovieren und Produkte ohne ‚Äûaufgebl√§htes Budget‚Äú auf den Markt bringen k√∂nnen. </p><br><h2 id="strategii-sokrascheniya-i-smyagcheniya-vliyaniya-kriticheskih-komponentov">  Strategien zur Reduzierung und Reduzierung kritischer Komponenten </h2><br><p>  An dieser Stelle haben wir in diesem Artikel die sogenannte <strong>"Goldene Regel f√ºr die Zuverl√§ssigkeit von Komponenten" festgelegt.</strong>  Dies bedeutet, dass die Zuverl√§ssigkeit einer kritischen Komponente zehnmal h√∂her sein sollte als die angestrebte Zuverl√§ssigkeitsstufe des gesamten Systems, damit ihr Beitrag zur Unzuverl√§ssigkeit des Systems auf der Fehlerstufe bleibt.  Daraus folgt, dass es im Idealfall die Aufgabe ist, m√∂glichst viele Komponenten unkritisch zu machen.  Dies bedeutet, dass Komponenten ein geringeres Ma√ü an Zuverl√§ssigkeit aufweisen k√∂nnen, sodass Entwickler die M√∂glichkeit haben, Innovationen vorzunehmen und Risiken einzugehen. </p><br><p>  Die einfachste und naheliegendste Strategie zur Reduzierung kritischer Abh√§ngigkeiten besteht darin, einzelne Fehlerquellen nach M√∂glichkeit zu beseitigen.  Ein gr√∂√üeres System sollte in der Lage sein, ohne eine bestimmte Komponente, die keine kritische Abh√§ngigkeit oder SPOF darstellt, akzeptabel zu arbeiten. <br>  Tats√§chlich k√∂nnen Sie h√∂chstwahrscheinlich nicht alle kritischen Abh√§ngigkeiten beseitigen.  Sie k√∂nnen jedoch einige Richtlinien f√ºr das Systemdesign befolgen, um die Zuverl√§ssigkeit zu optimieren.  Obwohl dies nicht immer m√∂glich ist, ist es einfacher und effizienter, eine hohe Systemzuverl√§ssigkeit zu erreichen, wenn Sie die Zuverl√§ssigkeit in der Entwurfs- und Planungsphase festlegen und nicht, nachdem das System funktioniert und die tats√§chlichen Benutzer betrifft. </p><br><h4 id="ocenka-struktury-proekta">  Bewertung der Projektstruktur </h4><br><p>  Bei der Planung eines neuen Systems oder Dienstes oder bei der Neugestaltung oder Verbesserung eines vorhandenen Systems oder Dienstes kann eine √úberpr√ºfung der Architektur oder des Projekts eine gemeinsame Infrastruktur sowie interne und externe Abh√§ngigkeiten aufzeigen. </p><br><h4 id="razdelyaemaya-infrastruktura">  Gemeinsame Infrastruktur </h4><br><p>  Wenn Ihr Dienst eine gemeinsam genutzte Infrastruktur verwendet (z. B. den Hauptdatenbankdienst, der von mehreren Produkten verwendet wird, die Benutzern zur Verf√ºgung stehen), pr√ºfen Sie, ob diese Infrastruktur ordnungsgem√§√ü verwendet wird.  Identifizieren Sie die Eigent√ºmer der gemeinsam genutzten Infrastruktur eindeutig als zus√§tzliche Projektteilnehmer.  Achten Sie auch auf Komponenten√ºberlastungen. Koordinieren Sie dazu den Startvorgang sorgf√§ltig mit den Eigent√ºmern dieser Komponenten. </p><br><h4 id="vnutrennie-ivneshnie-zavisimosti">  Interne und externe Abh√§ngigkeiten </h4><br><p>  Manchmal h√§ngt ein Produkt oder eine Dienstleistung von Faktoren ab, die au√üerhalb der Kontrolle Ihres Unternehmens liegen - beispielsweise von Softwarebibliotheken oder Diensten und Daten von Dritten.  Die Identifizierung dieser Faktoren minimiert die unvorhersehbaren Folgen ihrer Verwendung. </p><br><p>  <strong>Planen und entwerfen Sie Systeme sorgf√§ltig</strong> <br>  Beachten Sie beim Entwurf Ihres Systems die folgenden Grunds√§tze: </p><br><h4 id="rezervirovanie-iizolyaciya">  Redundanz und Isolation </h4><br><p>  Sie k√∂nnen versuchen, die Auswirkungen der kritischen Komponente zu verringern, indem Sie mehrere unabh√§ngige Instanzen davon erstellen.  Wenn das Speichern von Daten in einer Instanz beispielsweise eine Verf√ºgbarkeit dieser Daten von 99,9 Prozent sicherstellt, ergibt das Speichern von drei Kopien in drei weit verbreiteten Kopien theoretisch eine Verf√ºgbarkeitsstufe von 1 bis 0,013 oder neun Neunen, wenn der Ausfall der Instanz bei einer Korrelation von Null unabh√§ngig ist. </p><br><p>  In der realen Welt ist die Korrelation niemals Null (ber√ºcksichtigen Sie die Ausf√§lle des Backbone-Netzwerks, die viele Zellen gleichzeitig betreffen), sodass die tats√§chliche Zuverl√§ssigkeit niemals nahe an neun Neunen heranreicht, sondern drei Neunen bei weitem √ºberschreitet. </p><br><p>  In √§hnlicher Weise kann das Senden eines RPC (Remote Procedure Call) an einen Serverpool im selben Cluster eine 99-prozentige Verf√ºgbarkeit der Ergebnisse gew√§hrleisten, w√§hrend das gleichzeitige Senden von drei RPCs an drei verschiedene Serverpools und das Akzeptieren der ersten Antwort zum Erreichen der Verf√ºgbarkeitsstufe beitragen h√∂her als drei Neunen (siehe oben).  Diese Strategie kann auch die Verz√∂gerung der Antwortzeit verk√ºrzen, wenn die Serverpools gleich weit vom RPC-Absender entfernt sind.  (Da die Kosten f√ºr das gleichzeitige Senden von drei RPCs hoch sind, teilt Google die Zeit f√ºr diese Anrufe h√§ufig strategisch zu: Die meisten unserer Systeme erwarten einen Teil der zugewiesenen Zeit vor dem Senden des zweiten RPC und etwas mehr Zeit vor dem Senden des dritten RPC.) </p><br><h4 id="rezerv-iego-primenenie">  Reserve und ihre Anwendung </h4><br><p>  Richten Sie den Start und die Portierung der Software so ein, dass die Systeme weiterhin funktionieren, wenn einzelne Teile ausfallen (ausfallsicher) und sich bei Problemen isolieren.  Das Grundprinzip hierbei ist, dass Sie wahrscheinlich Ihre Fehlergrenze √ºberschreiten, wenn Sie die Person zum Einschalten der Reserve verbinden. </p><br><h4 id="asinhronnost">  Asynchronit√§t </h4><br><p>  Entwerfen Sie Komponenten nach M√∂glichkeit asynchron, um zu verhindern, dass sie kritisch werden.  Wenn ein Dienst eine RPC-Antwort von einem seiner unkritischen Teile erwartet, die eine starke Verlangsamung der Antwortzeit anzeigt, wird durch diese Verlangsamung die Leistung des √ºbergeordneten Dienstes unn√∂tig beeintr√§chtigt.  Wenn Sie den RPC f√ºr eine nicht kritische Komponente auf den asynchronen Modus einstellen, wird die Antwortzeit des √ºbergeordneten Dienstes nicht an die Leistung dieser Komponente gebunden.  Und obwohl Asynchronit√§t den Code und die Infrastruktur des Dienstes komplizieren kann, lohnt sich dieser Kompromiss dennoch. </p><br><h4 id="planirovanie-resursov">  Ressourcenplanung </h4><br><p>  Stellen Sie sicher, dass alle Komponenten mit allem ausgestattet sind, was Sie ben√∂tigen.  ,     ‚Äî    . </p><br><h4 id="konfiguraciya">  </h4><br><p>     ,           \  . </p><br><h4 id="obnaruzhenie-iustranenie-nepoladok">     </h4><br><p>   ,       .        .        .       ,      . </p><br><h4 id="bystryy-inadezhnyy-otkat-vpredyduschee-sostoyanie">        </h4><br><p>                 SLO.  ,   ,       .   ,    ,       ,    MTTR      . </p><br><h4 id="sistematicheski-proveryayte-vse-vozmozhnye-rezhimy-otkaza">       </h4><br><p>     ,          .    : </p><br><ul><li>               ?  ,    . </li><li>         ?   ?    ? </li></ul><br><h4 id="provedite-tschatelnoe-testirovanie">    </h4><br><p>      ,   ,     ,           .       : </p><br><ul><li>        -,         . </li><li>         / .       . </li><li>    .   ,  ,    .   ,       ;       ,     . </li></ul><br><h4 id="plan-nabuduschee">    </h4><br><p>  ,   : ,         ,            .        ‚Äî     ,     . ,  ,        ,   . <br>    ,             .     ,   Google    ,     10          . </p><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>     , ,      ,    ,               .   ,   .   Google             ,        ,      (.  SRE,  B:       ). </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de435662/">https://habr.com/ru/post/de435662/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de435648/index.html">Bot generiert Tutorials aus Wikipedia-Artikeln</a></li>
<li><a href="../de435650/index.html">So binden Sie eine C-Bibliothek in ein Swift-Framework ein</a></li>
<li><a href="../de435652/index.html">Wie man keine Passw√∂rter in Python-Skripten verwendet</a></li>
<li><a href="../de435654/index.html">Fallstricke von benutzerdefinierten CSS-Eigenschaften</a></li>
<li><a href="../de435656/index.html">Roller Rolls Royce - Ninebot KickScooter ES4 von Segway</a></li>
<li><a href="../de435664/index.html">Google-Suchmaschinen-Spoofing</a></li>
<li><a href="../de435666/index.html">Asynchrone Desynchronisation: Antimuster bei der Arbeit mit async / await in .NET</a></li>
<li><a href="../de435668/index.html">Ein weiteres Gesetz des Fr√ºhlings: Der Abgeordnete schlug vor, der Polizei zu erm√∂glichen, den Standort von Kindern mithilfe der Geolokalisierung zu verfolgen</a></li>
<li><a href="../de435670/index.html">Oberster Algorithmus - Verteilung der Algorithmen nach Schwierigkeitsgrad</a></li>
<li><a href="../de435672/index.html">Umschulung in Business Intelligence</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👃🏽 👩🏾‍🤝‍👩🏽 🤙🏾 Wahrsagerei in neuronalen Netzen: ob der Autor selbst in den Kommentaren zum Beitrag vermerkt hat 🤚🏿 🖇️ 🌚</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich werde eine Geschichte über ein kleines Projekt erzählen: Wie finde ich die Antworten des Autors in den Kommentaren, ohne zu wissen, wer der Autor ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wahrsagerei in neuronalen Netzen: ob der Autor selbst in den Kommentaren zum Beitrag vermerkt hat</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441850/"><img src="https://habrastorage.org/webt/dg/5l/lw/dg5llwwkakl3ndxtcjjwlwudupk.jpeg"><br><br>  Ich werde eine Geschichte über ein kleines Projekt erzählen: Wie finde ich die Antworten des Autors in den Kommentaren, ohne zu wissen, wer der Autor des Beitrags ist? <br><br>  Ich habe mein Projekt mit minimalen Kenntnissen über maschinelles Lernen begonnen und ich denke, dass es hier nichts Neues für Spezialisten geben wird.  Dieses Material ist in gewisser Weise eine Zusammenstellung verschiedener Artikel. Darin werde ich erläutern, wie es sich der Aufgabe näherte. Im Code finden Sie nützliche Kleinigkeiten und Tricks zur Verarbeitung natürlicher Sprache. <br><a name="habracut"></a><br>  Meine anfänglichen Daten waren wie folgt: Eine Datenbank mit 2,5 Millionen Medienmaterialien und 39,5 Millionen Kommentaren dazu.  Für 1M-Posts war auf die eine oder andere Weise der Autor des Materials bekannt (diese Informationen waren entweder in der Datenbank vorhanden oder wurden durch Analyse von Daten aus indirekten Gründen erhalten).  Auf dieser Basis wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein</a> Datensatz aus 215.000 markierten Datensätzen erstellt. <br><br>  Anfangs habe ich einen heuristischen Ansatz verwendet, der von der natürlichen Intelligenz ausgegeben und in SQL-Abfragen mit Volltextsuche oder regulären Ausdrücken übersetzt wurde.  Die einfachsten Beispiele für zu analysierende Texte: "Danke für den Kommentar" oder "Danke für die guten Bewertungen". Dies ist in 99,99% der Fälle der Autor und "Danke für die Arbeit" oder "Danke!".  Senden Sie Material per Post.  Vielen Dank!"  - gewöhnliche Überprüfung.  Mit einem solchen Ansatz konnten nur offensichtliche Zufälle herausgefiltert werden, außer in Fällen banaler Tippfehler oder wenn der Autor mit Kommentatoren im Dialog steht.  Daher wurde beschlossen, neuronale Netze zu verwenden, diese Idee kam nicht ohne die Hilfe eines Freundes. <br><br>  Eine typische Folge von Kommentaren, welcher von ihnen ist der Autor? <br><br><img src="https://habrastorage.org/webt/vv/sy/st/vvsystg0cv8nbrkntqqcrkbt45g.png"><br><br><div class="spoiler">  <b class="spoiler_title">Die Antwort</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/nx/jd/dq/nxjddq9-3dckcrg_26r81hvufgy.png"><br></div></div><br>  Die Methode zur Bestimmung der Tonalität des Textes wurde als Grundlage genommen. Die Aufgabe ist für uns in zwei Klassen einfach: der Autor und nicht der Autor.  Zum Trainieren von Modellen habe ich einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dienst</a> von Google verwendet, der virtuellen Maschinen eine GPU und eine Jupiter-Notebook-Oberfläche zur Verfügung stellt. <br><br>  Beispiele für Netzwerke im Internet: <br><br><pre><code class="python hljs">embed_dim = <span class="hljs-number"><span class="hljs-number">128</span></span> model = Sequential() model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>])) model.add(SpatialDropout1D(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">196</span></span>, dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, recurrent_dropout=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>,activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss = <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>,metrics = [<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br>  In den Zeilen, die von HTML-Tags und Sonderzeichen befreit waren, ergaben sie eine Genauigkeit von 65 bis 74 Prozent, was sich nicht wesentlich vom Werfen einer Münze unterschied. <br><br>  Ein interessanter Punkt ist, dass die Ausrichtung von Eingabesequenzen durch <code>pad_sequences(x_train, maxlen=max_len, padding='pre')</code> einen signifikanten Unterschied in den Ergebnissen ergab.  In meinem Fall war das beste Ergebnis mit padding = 'post'. <br><br>  Der nächste Schritt war die Verwendung der Lemmatisierung, die sofort eine Erhöhung der Genauigkeit um bis zu 80% ergab und an der weiter gearbeitet werden konnte.  Das Hauptproblem ist nun das korrekte Löschen des Textes.  Beispielsweise wurden Tippfehler im Wort "Danke" in einen solchen regulären Ausdruck umgewandelt (Tippfehler wurden nach Verwendungshäufigkeit ausgewählt) (solche Ausdrücke haben ein halbes bis zwei Dutzend angesammelt). <br><br><pre> <code class="python hljs">re16 = re.compile(<span class="hljs-string"><span class="hljs-string">ur"(?:\b:(?:1|c(?:|)|(?:|)|(?:(?:|(?:(?:(?:|(?:)?|))?|(?:)?))|)|(?:(?:(?:|)|)||||(?:(?:||(?:|)|(?:|(?:(?:(?:||(?:(?:||(?:[]|)|[]))?|[і]))?|||1)||)|)|||[]|(?:|)|(?:(?:(?:[]|)|?|(?:(?:(?:|(?:)?))?|)|(?:|)))?)||)|(?:|x))\b)"</span></span>, re.UNICODE)</code> </pre> <br>  An dieser Stelle möchte ich mich ganz besonders bei übermäßig höflichen Menschen bedanken, die es für notwendig halten, dieses Wort jedem ihrer Sätze hinzuzufügen. <br><br>  Eine Reduzierung des Anteils an Tippfehlern war notwendig, weil  Am Ausgang des Lemmatisators geben sie seltsame Worte und wir verlieren nützliche Informationen. <br><br>  Aber es gibt einen Silberstreifen, wir haben es satt, uns mit Tippfehlern und komplexer Textbereinigung zu befassen. Ich habe die Vektordarstellung von Wörtern verwendet - word2vec.  Die Methode erlaubte es, alle Tippfehler, Tippfehler und Synonyme in eng beieinander liegende Vektoren zu übersetzen. <br><br><img src="https://habrastorage.org/webt/54/r5/r9/54r5r9mqktawmbwxstrjaeyckvo.png"><br><br>  Wörter und ihre Beziehungen im Vektorraum. <br><br>  Die Reinigungsregeln wurden erheblich vereinfacht (Aha, Geschichtenerzähler), alle Nachrichten und Benutzernamen wurden in Sätze unterteilt und in eine Datei hochgeladen.  Ein wichtiger Punkt: Aufgrund der Kürze unserer Kommentatoren benötigen Wörter zusätzliche Kontextinformationen, beispielsweise aus dem Forum und Wikipedia, um qualitativ hochwertige Vektoren zu erstellen.  An der resultierenden Datei wurden drei Modelle trainiert: klassisches word2vec, Glove und FastText.  Nach vielen Experimenten entschied er sich schließlich für FastText, das in meinem Fall qualitativ am besten unterscheidende Wortcluster. <br><br><img src="https://habrastorage.org/webt/t6/lu/t6/t6lut6wyvpf8b2lba8l2bgjjbd8.png"><br><br>  Alle diese Änderungen brachten eine stabile Genauigkeit von 84 bis 85 Prozent. <br><br><div class="spoiler">  <b class="spoiler_title">Modellbeispiele</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model_conv_core</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model_input, embd_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">128</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> num_filters = <span class="hljs-number"><span class="hljs-number">128</span></span> X = Embedding(total_unique_words, DIM, input_length=max_words, weights=[embedding_matrix], trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, name=<span class="hljs-string"><span class="hljs-string">'Word2Vec'</span></span>)(model_input) X = Conv1D(num_filters, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(X) X = Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)(X) X = MaxPooling1D(<span class="hljs-number"><span class="hljs-number">2</span></span>)(X) X = Conv1D(num_filters, <span class="hljs-number"><span class="hljs-number">5</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(X) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model_conv1d</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model_input, embd_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">128</span></span></span></span><span class="hljs-function"><span class="hljs-params">, num_filters = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">64</span></span></span></span><span class="hljs-function"><span class="hljs-params">, kernel_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> X = Embedding(total_unique_words, DIM, input_length=max_words, weights=[embedding_matrix], trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, name=<span class="hljs-string"><span class="hljs-string">'Word2Vec'</span></span>)(model_input) X = Conv1D(num_filters, kernel_size, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, strides=<span class="hljs-number"><span class="hljs-number">1</span></span>)(X) <span class="hljs-comment"><span class="hljs-comment"># X = Dropout(0.1)(X) X = MaxPooling1D(pool_size=2)(X) X = LSTM(256, kernel_regularizer=regularizers.l2(0.004))(X) X = Dropout(0.3)(X) X = Dense(128, kernel_regularizer=regularizers.l2(0.0004))(X) X = LeakyReLU()(X) X = BatchNormalization()(X) X = Dense(1, activation="sigmoid")(X) model = Model(model_input, X, name='w2v_conv1d') return model def model_gru(model_input, embd_size = 128): X = model_conv_core(model_input, embd_size) X = MaxPooling1D(2)(X) X = Dropout(0.2)(X) X = GRU(256, activation='relu', return_sequences=True, kernel_regularizer=regularizers.l2(0.004))(X) X = Dropout(0.5)(X) X = GRU(128, activation='relu', kernel_regularizer=regularizers.l2(0.0004))(X) X = Dropout(0.5)(X) X = BatchNormalization()(X) X = Dense(1, activation="sigmoid")(X) model = Model(model_input, X, name='w2v_gru') return model def model_conv2d(model_input, embd_size = 128): from keras.layers import MaxPool2D, Conv2D, Reshape num_filters = 256 filter_sizes = [3, 5, 7] X = Embedding(total_unique_words, DIM, input_length=max_words, weights=[embedding_matrix], trainable=False, name='Word2Vec')(model_input) reshape = Reshape((maxSequenceLength, embd_size, 1))(X) conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embd_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape) conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embd_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape) conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embd_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape) maxpool_0 = MaxPool2D(pool_size=(maxSequenceLength - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0) maxpool_1 = MaxPool2D(pool_size=(maxSequenceLength - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1) maxpool_2 = MaxPool2D(pool_size=(maxSequenceLength - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2) X = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1) X = Dropout(0.2)(X) X = Flatten()(X) X = Dense(int(embd_size / 2.0), activation='relu', kernel_regularizer=regularizers.l2(0.004))(X) X = Dropout(0.5)(X) X = BatchNormalization()(X) X = Dense(1, activation="sigmoid")(X) model = Model(model_input, X, name='w2v_conv2d') return model</span></span></code> </pre><br></div></div><br>  und 6 weitere Modelle im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> .  Einige der Modelle stammen aus dem Netzwerk, andere werden unabhängig voneinander erfunden. <br><br>  Es wurde festgestellt, dass unterschiedliche Kommentare zu unterschiedlichen Modellen auffielen. Dies veranlasste die Idee, Ensembles von Modellen zu verwenden.  Zuerst habe ich das Ensemble manuell zusammengestellt, die besten Modellpaare ausgewählt und dann einen Generator hergestellt.  Um die umfassende Suche zu optimieren, habe ich den Gray-Code zugrunde gelegt. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gray_code</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gray_code_recurse</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g,n)</span></span></span><span class="hljs-function">:</span></span> k = len(g) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range (k<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>): char=<span class="hljs-string"><span class="hljs-string">'1'</span></span> + g[i] g.append(char) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range (k<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>): g[i]=<span class="hljs-string"><span class="hljs-string">'0'</span></span> + g[i] gray_code_recurse (g, n<span class="hljs-number"><span class="hljs-number">-1</span></span>) g = [<span class="hljs-string"><span class="hljs-string">'0'</span></span>,<span class="hljs-string"><span class="hljs-string">'1'</span></span>] gray_code_recurse(g, n<span class="hljs-number"><span class="hljs-number">-1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> g <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen_list</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(m)</span></span></span><span class="hljs-function">:</span></span> out = [] g = gray_code(len(m)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range (len(g)): mask_str = g[i] idx = <span class="hljs-number"><span class="hljs-number">0</span></span> v = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> list(mask_str): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> c == <span class="hljs-string"><span class="hljs-string">'1'</span></span>: v.append(m[idx]) idx += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(v) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>: out.append(v) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out</code> </pre> <br>  Mit dem Ensemble „hat das Leben mehr Spaß gemacht“ und der aktuelle Prozentsatz der Modellgenauigkeit wird bei 86-87% gehalten, was hauptsächlich mit einer minderwertigen Klassifizierung einiger Autoren im Datensatz zusammenhängt. <br><br><img src="https://habrastorage.org/webt/q8/8s/zt/q88sztzfnzspm90oanbhll4bz8c.png"><br><br>  Die Probleme, die ich getroffen habe: <br><br><ol><li>  Unausgeglichener Datensatz.  Die Anzahl der Kommentare der Autoren war deutlich geringer als bei anderen Kommentatoren. <br></li><li>  Die Klassen in der Stichprobe sind streng geordnet.  Das Fazit ist, dass sich Anfang, Mitte und Ende in der Qualität der Klassifizierung erheblich unterscheiden.  Dies ist im Lernprozess im Zeitplan der f1-Maßnahme deutlich sichtbar. <img src="https://habrastorage.org/webt/-f/mx/5e/-fmx5evtj0tsfch0y35sedqqezu.png"><br></li></ol><br>  Für die Lösung wurde ein Fahrrad zur Trennung in Trainings- und Validierungsproben hergestellt.  Obwohl in der Praxis in den meisten Fällen die Prozedur train_test_split aus der sklearn-Bibliothek ausreicht. <br><br>  Grafik des aktuellen Arbeitsmodells: <br><br><img src="https://habrastorage.org/webt/cc/8q/zl/cc8qzlyein_kblslui7tgnq5qpg.png"><br><br>  Als Ergebnis erhielt ich aus kurzen Kommentaren ein Modell mit einer sicheren Definition der Autoren.  Weitere Verbesserungen werden mit der Bereinigung und Übertragung der Ergebnisse der Klassifizierung realer Daten in den Trainingsdatensatz verbunden sein. <br><br>  Der gesamte Code mit zusätzlichen Erklärungen befindet sich im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository</a> . <br><br>  Als Postskriptum: Wenn Sie große Textmengen klassifizieren müssen, schauen Sie sich das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VDCNN-Modell</a> „Very Deep Convolutional Neural Network“ ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung</a> auf Keras) an. Dies ist ein Analogon von ResNet für Texte. <br><br>  Verwendete Materialien: <br><br>  • <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Übersicht über maschinelle Lernkurse</a> <br>  • <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Faltungsanalyse mit Faltung</a> <br>  • <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Faltungsnetzwerke in NLP</a> <br>  • <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Metriken beim maschinellen Lernen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://ld86.github.io/ml-slides/unbalanced.html</a> <br>  • <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein Blick in das Modell</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441850/">https://habr.com/ru/post/de441850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441834/index.html">Nicht zur Arbeit nehmen. Aber was ist, wenn die Sache in dir liegt?</a></li>
<li><a href="../de441836/index.html">Eine Cloud-Geschichte: Huawei + 3data = Cloud</a></li>
<li><a href="../de441842/index.html">Practical Go: Tipps zum Schreiben unterstützter Programme in der realen Welt</a></li>
<li><a href="../de441844/index.html">iRobot Scooba: Erfahrung und Lösungen für häufig auftretende Probleme eines Waschroboterreinigers</a></li>
<li><a href="../de441848/index.html">Praktika für Entwickler in Avito: Kämpfe gegen Missionen und arbeite mit erfahrenen Mentoren</a></li>
<li><a href="../de441852/index.html">42 Silicon Valley: So werden Sie ausgewählt</a></li>
<li><a href="../de441854/index.html">RUHE? Nimm einen dummen JSON-RPC</a></li>
<li><a href="../de441858/index.html">Vereinfachter Datenzugriff internes FAT12 für STM32</a></li>
<li><a href="../de441862/index.html">Ein bisschen über Phong-Schattierung</a></li>
<li><a href="../de441864/index.html">Monowheels Marktübersicht 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßô üö¥ üë©üèø‚Äçüíª Neujahrsdatensatz 2018: Offene Semantik der russischen Sprache üßóüèΩ üå† üìó</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die offene Semantik der russischen Sprache, √ºber deren Geschichte Sie hier und hier lesen k√∂nnen, erhielt ein gro√ües Update. Wir haben gen√ºgend Daten ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neujahrsdatensatz 2018: Offene Semantik der russischen Sprache</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434154/">  Die offene Semantik der russischen Sprache, √ºber deren Geschichte Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> lesen k√∂nnen, erhielt ein gro√ües Update.  Wir haben gen√ºgend Daten gesammelt, um maschinelles Lernen zus√§tzlich zu dem gesammelten Markup anzuwenden und ein semantisches Sprachmodell zu erstellen.  Was dabei herauskam, sehen Sie unter dem Schnitt. <br><br><img src="https://habrastorage.org/webt/o-/zn/pr/o-znprf5c6sv6xso7v8r4dmrlwo.png"><br><a name="habracut"></a><br><h2>  Was machen wir </h2><br>  Nehmen Sie zwei Wortgruppen: <br><br><ul><li>  Laufen, Schie√üen, Plotten, Wandern, Gehen; </li><li>  L√§ufer, Fotograf, Ingenieur, Tourist, Sportler. </li></ul><br>  Es ist f√ºr eine Person nicht schwierig festzustellen, dass die erste Gruppe Substantive enth√§lt, die <i>Aktionen oder Ereignisse</i> benennen.  in der zweiten - <i>Menschen</i> anrufen.  Unser Ziel ist es, eine Maschine zu lehren, um solche Probleme zu l√∂sen. <br><br>  Dazu m√ºssen Sie: <br><br><ol><li>  Finden Sie heraus, welche nat√ºrlichen Klassen in der Sprache existieren. </li><li>  Markieren Sie eine ausreichende Anzahl von W√∂rtern zum Thema Zugeh√∂rigkeit zu den Klassen in <i>Absatz 1</i> . </li><li>  Erstellen Sie einen Algorithmus, der anhand des Markups aus <i>Element 2</i> lernt und die Klassifizierung in unbekannten W√∂rtern wiedergibt. </li></ol><br><div class="spoiler">  <b class="spoiler_title">Ist es m√∂glich, dieses Problem mit Hilfe der Verteilungssemantik zu l√∂sen?</b> <div class="spoiler_text">  <i>word2vec</i> ist ein ausgezeichnetes Werkzeug, bevorzugt jedoch die thematische N√§he von W√∂rtern und nicht die √Ñhnlichkeit ihrer semantischen Klassen.  Um diese Tatsache zu demonstrieren, f√ºhren Sie den Algorithmus in Worten aus dem Beispiel aus: <br><br><pre><code class="plaintext hljs">w1 | w2 | cosine_sim | | | |  |  | 1.0000 |  |  | 0.6618 |  |  | 0.5410 |  |  | 0.3389 |  |  | 0.1531 |  |  | 0.1342 |  |  | 0.1067 |  |  | 0.0681 |  |  | 0.0458 |  |  | 0.0373 | | | |  |  | 1.0000 |  |  | 0.5782 |  |  | 0.2525 |  |  | 0.2116 |  |  | 0.1644 |  |  | 0.1579 |  |  | 0.1342 |  |  | 0.1275 |  |  | 0.1100 |  |  | 0.0975 | | | |  |  | 1.0000 |  |  | 0.3575 |  |  | 0.2116 |  |  | 0.1587 |  |  | 0.1207 |  |  | 0.1067 |  |  | 0.0889 |  |  | 0.0794 |  |  | 0.0705 |  |  | 0.0430 | | | |  |  | 1.0000 |  |  | 0.1896 |  |  | 0.1753 |  |  | 0.1644 |  |  | 0.1548 |  |  | 0.1531 |  |  | 0.0889 |  |  | 0.0794 |  |  | 0.0568 |  |  | -0.0013 | | | |  |  | 1.0000 |  |  | 0.5410 |  |  | 0.3442 |  |  | 0.2469 |  |  | 0.1753 |  |  | 0.1650 |  |  | 0.1207 |  |  | 0.1100 |  |  | 0.0673 |  |  | 0.0642 | | | |  |  | 1.0000 |  |  | 0.6618 |  |  | 0.4909 |  |  | 0.3442 |  |  | 0.1548 |  |  | 0.1427 |  |  | 0.1422 |  |  | 0.1275 |  |  | 0.1209 |  |  | 0.0705 | | | |  |  | 1.0000 |  |  | 0.5782 |  |  | 0.3687 |  |  | 0.2334 |  |  | 0.1911 |  |  | 0.1587 |  |  | 0.1209 |  |  | 0.0642 |  |  | 0.0373 |  |  | -0.0013 | | | |  |  | 1.0000 |  |  | 0.3575 |  |  | 0.2334 |  |  | 0.1579 |  |  | 0.1503 |  |  | 0.1447 |  |  | 0.1422 |  |  | 0.0673 |  |  | 0.0568 |  |  | 0.0458 | | | |  |  | 1.0000 |  |  | 0.3687 |  |  | 0.2525 |  |  | 0.1896 |  |  | 0.1650 |  |  | 0.1503 |  |  | 0.1495 |  |  | 0.1427 |  |  | 0.0681 |  |  | 0.0430 | | | |  |  | 1.0000 |  |  | 0.4909 |  |  | 0.3389 |  |  | 0.2469 |  |  | 0.1911 |  |  | 0.1495 |  |  | 0.1447 |  |  | 0.0975 |  |  | 0.0889 |  |  | 0.0889 |</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Wie offene Semantik dieses Problem l√∂st</b> <div class="spoiler_text">  Eine Suche im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">semantischen W√∂rterbuch</a> ergibt folgendes Ergebnis: <br><br><pre> <code class="plaintext hljs">  |   | | |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | ABSTRACT:ACTION |  | HUMAN |  | HUMAN |  | HUMAN |  | HUMAN |  | HUMAN |</code> </pre> <br></div></div><br><h2>  Was wurde getan und wo kann ich herunterladen? </h2><br>  Das Ergebnis der im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository auf dem GC ver√∂ffentlichten</a> und zum Download verf√ºgbaren Arbeit ist eine Beschreibung der Klassenhierarchie und des Markups (manuell und automatisch) der Substantive f√ºr diese Klassen. <br><br>  Um sich mit dem Datensatz vertraut zu machen, k√∂nnen Sie den interaktiven Navigator (Link im Repository) verwenden.  Es gibt auch eine vereinfachte Version des Satzes, in der wir die gesamte Hierarchie entfernt und jedem Wort ein einziges gro√ües semantisches Tag zugewiesen haben: "Menschen", "Tiere", "Orte", "Dinge", "Aktionen" usw. <br><br>  <i>Link zu Github:</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offene Semantik der russischen Sprache (Datensatz)</a> . <br><br><h2>  √úber Wortklassen </h2><br>  Bei Klassifizierungsproblemen werden die Klassen selbst h√§ufig durch das zu l√∂sende Problem bestimmt, und die Arbeit des Dateningenieurs besteht darin, einen erfolgreichen Satz von Attributen zu finden, auf denen Sie ein Arbeitsmodell erstellen k√∂nnen. <br><br>  In unserem Problem sind Wortklassen streng genommen nicht im Voraus bekannt.  Hier hilft eine gro√üe Schicht semantischer Forschung, die von in- und ausl√§ndischen Linguisten durchgef√ºhrt wird, die Vertrautheit mit vorhandenen semantischen W√∂rterb√ºchern und WordNets. <br><br>  Dies ist eine gute Hilfe, aber die endg√ºltige Entscheidung wird bereits in unserer eigenen Forschung getroffen.  Hier ist das Ding.  Viele semantische Ressourcen wurden im Zeitalter vor dem Computer geschaffen (zumindest im modernen Verst√§ndnis des Computers), und die Wahl der Klassen wurde weitgehend von der Sprachintuition ihrer Sch√∂pfer bestimmt.  Ende des vorigen Jahrhunderts wurde WordNet aktiv f√ºr die automatische Textanalyse eingesetzt, und viele neu erstellte Ressourcen wurden f√ºr bestimmte praktische Anwendungen gesch√§rft. <br><br>  Das Ergebnis war, dass diese Sprachressourcen gleichzeitig sowohl sprachliche als auch extralinguistische, enzyklop√§dische Informationen √ºber die Einheiten der Sprache enthalten.  Es ist logisch anzunehmen, dass es unm√∂glich ist, ein Modell zu erstellen, das extralinguistische Informationen √ºberpr√ºft und sich ausschlie√ülich auf die statistische Analyse von Texten st√ºtzt, da die Datenquelle einfach nicht die erforderlichen Informationen enth√§lt. <br><br>  Basierend auf dieser Annahme suchen wir nur nach nat√ºrlichen Klassen, die anhand eines rein sprachlichen Modells erkannt und automatisch verifiziert werden k√∂nnen.  Gleichzeitig erm√∂glicht die Systemarchitektur das Hinzuf√ºgen einer beliebig gro√üen Anzahl zus√§tzlicher Informationsebenen √ºber Spracheinheiten, was in praktischen Anwendungen n√ºtzlich sein kann. <br><br>  Wir werden das Obige anhand eines konkreten Beispiels demonstrieren, indem wir das Wort ‚ÄûK√ºhlschrank‚Äú analysieren.  Aus dem Sprachmodell k√∂nnen wir herausfinden, dass ein "K√ºhlschrank" ein materielles Objekt, ein Design, ein Beh√§lter vom Typ "Kiste oder Beutel" ist, d. H.  Nicht f√ºr die Lagerung von Fl√ºssigkeiten oder Feststoffen ohne zus√§tzlichen Beh√§lter vorgesehen.  Dar√ºber hinaus ist aus diesem Modell nicht klar, dass der "K√ºhlschrank" eine Ware ist, au√üerdem ein haltbares Produkt, und es ist auch nicht klar, dass dies ein Artefakt ist, d.h.  menschlich gemachtes Objekt.  Dies sind nichtsprachliche Informationen, die separat angegeben werden m√ºssen. <br><br><div class="spoiler">  <b class="spoiler_title">Das Ergebnis des Modells f√ºr das Wort "K√ºhlschrank"</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/fk/jc/eh/fkjcehbnahnisns7mtsl18z3khg.png"><br></div></div><br><h2>  Warum das alles gebraucht wird </h2><br>  Wie dem auch sei, w√§hrend des Lernens und Erkennens der Realit√§t reiht eine Person zus√§tzliche Informationen √ºber die sie umgebenden Objekte und Ph√§nomene auf den nat√ºrlichen Rahmen, den sie in ihrer Kindheit gelernt hat.  Einige Konzepte sind jedoch universell, unabh√§ngig vom Themenbereich und k√∂nnen erfolgreich wiederverwendet werden. <br><br>  Sagen wir "Verk√§ufer" ist eine <i>Person</i> + eine <i>funktionale Rolle</i> .  In einigen F√§llen kann der Verk√§ufer eine Gruppe von Personen oder eine Organisation sein, die Subjektivit√§t bleibt jedoch immer erhalten. Andernfalls ist die Zielaktion nicht m√∂glich.  Die W√∂rter "Austausch" oder "Training" beziehen sich auf Aktionen, d.h.  Sie haben Teilnehmer, Dauer und Ergebnis.  Der genaue Inhalt dieser Aktionen kann je nach Situation und Themenbereich erheblich variieren, bestimmte Aspekte sind jedoch unver√§nderlich.  Dies ist der Sprachrahmen, auf dem variables extralinguistisches Wissen basiert. <br><br>  Unser Ziel ist es, die maximal verf√ºgbaren intralinguistischen Informationen zu finden und zu erforschen und auf dieser Grundlage ein Erkl√§rungsmodell der Sprache aufzubauen.  Dies wird die vorhandenen Algorithmen f√ºr die automatische Textverarbeitung verbessern, einschlie√ülich  so komplexe wie das Aufl√∂sen von lexikalischen Mehrdeutigkeiten, das Aufl√∂sen von Anaphoren, komplizierte F√§lle von morphologischer Markierung.  Dabei werden wir uns notwendigerweise irgendwo gegen die Notwendigkeit ausruhen, au√üersprachliches Wissen anzuziehen, aber zumindest werden wir wissen, wo die Grenze liegt, wenn interne Sprachkenntnisse nicht mehr ausreichen. <br><br><h2>  Klassifizierung und Schulung, Satz von Attributen </h2><br>  Derzeit arbeiten wir nur mit Substantiven. Wenn wir also unten ‚ÄûWort‚Äú sagen, meinen wir Zeichen, die sich nur auf diesen Teil der Sprache beziehen.  Da wir uns entschieden haben, nur intralinguistische Informationen zu verwenden, werden wir mit Texten arbeiten, die mit morphologischen Markups ausgestattet sind. <br><br>  Als Zeichen nehmen wir alle m√∂glichen Mikrokontexte, in denen dieses Wort vorkommt.  F√ºr Substantive sind dies: <br><br><ul><li>  APP + X <i>(sch√∂nes X: Augen)</i> </li><li>  GLAG + X <i>(vdite X: Thread)</i> </li><li>  VL + PRED + X <i>(X eingeben: T√ºr)</i> </li><li>  X + SUSCH_ROD <i>(X: Tabellenkante)</i> </li><li>  SUSHCH + X_ROD <i>(Griff X: S√§bel)</i> </li><li>  X_ SUBJECT + GL <i>(X: Die Handlung entwickelt sich)</i> </li></ul><br>  Es gibt mehr Arten von Mikrokontexten, aber die oben genannten sind die h√§ufigsten und liefern bereits beim Lernen ein gutes Ergebnis. <br><br>  Alle Mikrokontexte werden auf die Grundform reduziert und wir setzen daraus eine Reihe von Merkmalen zusammen.  Als n√§chstes setzen wir f√ºr jedes Wort einen Vektor zusammen, dessen <i>i-te</i> Koordinate mit dem Auftreten eines gegebenen Wortes im <i>i-ten</i> Mikrokontext korreliert. <br><br><div class="spoiler">  <b class="spoiler_title">Mikrokontexttabelle f√ºr das Wort "Rucksack"</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">  |  |  |  | | | | |   | VBP_ | 3043 | 1.0000 |  | ADJ | 2426 | 0.9717 |  | NX_NG | 1438 | 0.9065 |   | VBP_ | 1415 | 0.9045 |   | VBP__ | 1300 | 0.8940 |  | NX_NG | 1292 | 0.8932 |  | NX_NG | 1259 | 0.8900 |  | ADJ | 1230 | 0.8871 |  | ADJ | 1116 | 0.8749 |  | ADJ | 903 | 0.8485 |  | ADJ | 849 | 0.8408 |  | NX_NG | 814 | 0.8356 |  | ADJ | 795 | 0.8326 |  | ADJ | 794 | 0.8325 |   | VBP_ | 728 | 0.8217 |  | ADJ | 587 | 0.7948 |  | ADJ | 587 | 0.7948 |   | VBP__ | 567 | 0.7905 |   | VBP_ | 549 | 0.7865 |   | VBP__ | 538 | 0.7840 |   | VBP_ | 495 | 0.7736 |   | VBP_ | 484 | 0.7708 |  | NX_NG | 476 | 0.7687 |  | ADJ | 463 | 0.7652 |  | NX_NG | 459 | 0.7642 |</code> </pre> <br></div></div><br><h2>  Zielwert, semantische Slicing-Hierarchie </h2><br>  Die Sprache verf√ºgt √ºber nat√ºrliche Mechanismen f√ºr die Wiederverwendung von W√∂rtern, wodurch ein Ph√§nomen wie die Polysemie entsteht.  Dar√ºber hinaus werden manchmal nicht nur einzelne W√∂rter wiederverwendet, sondern es wird eine metaphorische √úbertragung ganzer Konzepte vorgenommen.  Dies macht sich insbesondere beim √úbergang von materiellen zu abstrakten Konzepten bemerkbar. <br><br>  Diese Tatsache diktiert die Notwendigkeit einer hierarchischen Klassifizierung, bei der semantische Abschnitte in einer Baumstruktur angeordnet sind und die Partition in jedem internen Knoten auftritt.  Auf diese Weise k√∂nnen Sie vieldeutiger mit Mehrdeutigkeiten in Mikrokontexten umgehen. <br><br><div class="spoiler">  <b class="spoiler_title">Beispiele f√ºr metaphorische Konzept√ºbertragung</b> <div class="spoiler_text">  Neben der L√∂sung dringender praktischer Probleme der Computerlinguistik sollen in unserer Arbeit das Wort und verschiedene sprachliche Ph√§nomene untersucht werden.  Die metaphorische √úbertragung von Konzepten von der realen Ebene auf die abstrakte Ebene ist ein Ph√§nomen, das kognitiven Linguisten bekannt ist.  So ist beispielsweise eines der hellsten Konzepte in der materiellen Welt die Klasse "Container" (in der russischsprachigen Literatur wird sie oft als "Container" bezeichnet). <br><br><blockquote>  Eine andere allgegenw√§rtige ontologische Metapher ist die Metapher des Containers oder Containers, die impliziert, Grenzen im Kontinuum unserer Erfahrung zu ziehen und sie durch r√§umliche Kategorien zu verstehen.  Den Autoren zufolge wird die Art und Weise, wie ein Mensch die Welt um sich herum wahrnimmt, durch seine Erfahrung im Umgang mit diskreten materiellen Objekten und insbesondere durch seine Wahrnehmung von sich selbst und seinem K√∂rper bestimmt.  Der Mensch ist eine Kreatur, die durch die Haut vom Rest der Welt abgegrenzt ist.  Er ist ein Container, und deshalb ist es f√ºr ihn √ºblich, andere Wesenheiten als Container mit einem inneren Teil und einer √§u√üeren Oberfl√§che wahrzunehmen. <br><br>  <i>Skrebtsova T. G. Kognitive Linguistik: Klassische Theorien, Neu</i> <i><br></i>  <i>Ans√§tze</i> </blockquote><br>  Das von uns konstruierte Modell arbeitet in einem einzigen Raum von Attributen und erm√∂glicht es uns, aus realen Beispielen zu lernen und Vorhersagen im Bereich der Zusammenfassung zu treffen.  Auf diese Weise k√∂nnen Sie die oben beschriebene √úbertragung durchf√ºhren.  So sind beispielsweise die folgenden W√∂rter abstrakte Container, was mit der intuitiven Idee √ºbereinstimmt: <br><br><img src="https://habrastorage.org/webt/pl/cg/pm/plcgpmsr_v-ehtfgijakgx1mfz4.png"><br><br>  Ein weiteres interessantes Beispiel ist die √úbertragung des Begriffs "Fl√ºssigkeit" in die Sph√§re des Immateriellen: <br><br><img src="https://habrastorage.org/webt/4q/vg/zg/4qvgzgx0lnlcoifaz-avsokq9us.png"><br></div></div><br><h2>  Algorithmusauswahl </h2><br>  Als Algorithmus verwendeten wir die logistische Regression.  Dies ist auf mehrere Faktoren zur√ºckzuf√ºhren: <br><br><ol><li>  Auf die eine oder andere Weise enth√§lt das anf√§ngliche Markup eine bestimmte Anzahl von Fehlern und Rauschen. </li><li>  Zeichen k√∂nnen unausgeglichen sein und auch Fehler enthalten - Polysemie und metaphorische (bildliche) Verwendung des Wortes. </li><li>  Die vorl√§ufige Analyse legt nahe, dass eine ausreichend ausgew√§hlte Schnittstelle mit einem relativ einfachen Algorithmus repariert werden sollte. </li><li>  Eine gute Interpretierbarkeit des Algorithmus ist wichtig. </li></ol><br>  Der Algorithmus zeigte eine recht gute Genauigkeit: <br><br><div class="spoiler">  <b class="spoiler_title">Protokolle des Markup-Algorithmus</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">== ENTITY == slice | label | count | correctCount | accuracy | | | | | | ENTITY | PHYSICAL | 12249 | 11777 | 0.9615 | ENTITY | ABSTRACT | 9854 | 9298 | 0.9436 | | | | | | | | | | 0.9535 | == PHYSICAL:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:ROLE | ORGANIC | 7001 | 6525 | 0.9320 | PHYSICAL:ROLE | INORGANIC | 3805 | 3496 | 0.9188 | | | | | | | | | | 0.9274 | == PHYSICAL:ORGANIC:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:ORGANIC:ROLE | HUMAN | 4879 | 4759 | 0.9754 | PHYSICAL:ORGANIC:ROLE | ANIMAL | 675 | 629 | 0.9319 | PHYSICAL:ORGANIC:ROLE | FOOD | 488 | 411 | 0.8422 | PHYSICAL:ORGANIC:ROLE | ANATOMY | 190 | 154 | 0.8105 | PHYSICAL:ORGANIC:ROLE | PLANT | 285 | 221 | 0.7754 | | | | | | | | | | 0.9474 | == PHYSICAL:INORGANIC:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:INORGANIC:ROLE | CONSTRUCTION | 1045 | 933 | 0.8928 | PHYSICAL:INORGANIC:ROLE | THING | 2385 | 2123 | 0.8901 | PHYSICAL:INORGANIC:ROLE | SUBSTANCE | 399 | 336 | 0.8421 | | | | | | | | | | 0.8859 | == PHYSICAL:CONSTRUCTION:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:CONSTRUCTION:ROLE | TRANSPORT | 188 | 178 | 0.9468 | PHYSICAL:CONSTRUCTION:ROLE | APARTMENT | 270 | 241 | 0.8926 | PHYSICAL:CONSTRUCTION:ROLE | TERRAIN | 285 | 253 | 0.8877 | | | | | | | | | | 0.9044 | == PHYSICAL:THING:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:THING:ROLE | WEARABLE | 386 | 357 | 0.9249 | PHYSICAL:THING:ROLE | TOOLS | 792 | 701 | 0.8851 | PHYSICAL:THING:ROLE | DISHES | 199 | 174 | 0.8744 | PHYSICAL:THING:ROLE | MUSIC_INSTRUMENTS | 63 | 51 | 0.8095 | PHYSICAL:THING:ROLE | WEAPONS | 107 | 69 | 0.6449 | | | | | | | | | | 0.8739 | == PHYSICAL:TOOLS:ROLE == slice | label | count | correctCount | accuracy | | | | | | PHYSICAL:TOOLS:ROLE | PHY_INTERACTION | 213 | 190 | 0.8920 | PHYSICAL:TOOLS:ROLE | INFORMATION | 101 | 71 | 0.7030 | PHYSICAL:TOOLS:ROLE | EM_ENERGY | 72 | 49 | 0.6806 | | | | | | | | | | 0.8031 | == ATTR:INORGANIC:WEARABLE == slice | label | count | correctCount | accuracy | | | | | | ATTR:INORGANIC:WEARABLE | NON_WEARABLE | 538 | 526 | 0.9777 | ATTR:INORGANIC:WEARABLE | WEARABLE | 282 | 269 | 0.9539 | | | | | | | | | | 0.9695 | == ATTR:PHYSICAL:CONTAINER == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:CONTAINER | CONTAINER | 636 | 627 | 0.9858 | ATTR:PHYSICAL:CONTAINER | NOT_A_CONTAINER | 1225 | 1116 | 0.9110 | | | | | | | | | | 0.9366 | == ATTR:PHYSICAL:CONTAINER:TYPE == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:CONTAINER:TYPE | CONFINED_SPACE | 291 | 287 | 0.9863 | ATTR:PHYSICAL:CONTAINER:TYPE | CONTAINER | 140 | 131 | 0.9357 | ATTR:PHYSICAL:CONTAINER:TYPE | OPEN_AIR | 72 | 64 | 0.8889 | ATTR:PHYSICAL:CONTAINER:TYPE | BAG_OR_BOX | 43 | 31 | 0.7209 | ATTR:PHYSICAL:CONTAINER:TYPE | CAVITY | 30 | 20 | 0.6667 | | | | | | | | | | 0.9253 | == ATTR:PHYSICAL:PHY_STATE == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:PHY_STATE | SOLID | 308 | 274 | 0.8896 | ATTR:PHYSICAL:PHY_STATE | FLUID | 250 | 213 | 0.8520 | ATTR:PHYSICAL:PHY_STATE | FABRIC | 72 | 51 | 0.7083 | ATTR:PHYSICAL:PHY_STATE | PLASTIC | 78 | 42 | 0.5385 | ATTR:PHYSICAL:PHY_STATE | SAND | 70 | 31 | 0.4429 | | | | | | | | | | 0.7853 | == ATTR:PHYSICAL:PLACE == slice | label | count | correctCount | accuracy | | | | | | ATTR:PHYSICAL:PLACE | NOT_A_PLACE | 855 | 821 | 0.9602 | ATTR:PHYSICAL:PLACE | PLACE | 954 | 914 | 0.9581 | | | | | | | | | | 0.9591 | == ABSTRACT:ROLE == slice | label | count | correctCount | accuracy | | | | | | ABSTRACT:ROLE | ACTION | 1497 | 1330 | 0.8884 | ABSTRACT:ROLE | HUMAN | 473 | 327 | 0.6913 | ABSTRACT:ROLE | PHYSICS | 257 | 171 | 0.6654 | ABSTRACT:ROLE | INFORMATION | 222 | 146 | 0.6577 | ABSTRACT:ROLE | ABSTRACT | 70 | 15 | 0.2143 | | | | | | | | | | 0.7896 |</code> </pre> <br></div></div><br><h2>  Fehleranalyse </h2><br>  Fehler, die sich aus der automatischen Klassifizierung ergeben, werden durch drei Hauptfaktoren verursacht: <br><br><ol><li>  Homonymie und Polysemie: W√∂rter, die den gleichen Typ haben, k√∂nnen unterschiedliche Bedeutungen haben (qu√§len Sie <b>a</b> und m <b>u</b> ka, stoppen Sie <i>als Prozess</i> und stoppen Sie <i>als Ort</i> ).  Dies kann auch die metaphorische Verwendung von W√∂rtern und Metonymien umfassen (z. B. wird eine T√ºr als geschlossener Raum klassifiziert - dies ist ein erwartetes Merkmal der Sprache). </li><li>  Ungleichgewicht im Zusammenhang mit der Verwendung des Wortes.  Einige organische Verwendungen sind m√∂glicherweise nicht in der Originalverpackung enthalten, was zu Klassifizierungsfehlern f√ºhrt. </li><li>  Ung√ºltige Klassengrenze.  Sie k√∂nnen Grenzen ziehen, die nicht aus Kontexten berechenbar sind und die die Einbeziehung von au√üersprachlichem Wissen erfordern.  Hier wird der Algorithmus machtlos sein. </li></ol><br>  In dieser Phase achten wir nur auf Fehler des dritten Typs und passen die ausgew√§hlte Grenze zwischen den Klassen an.  Fehler der ersten beiden Typen in einer bestimmten Konfiguration des Systems k√∂nnen nicht beseitigt werden, aber bei einer ausreichenden Menge beschrifteter Daten stellen sie kein gro√ües Problem dar - dies l√§sst sich an der Genauigkeit des Markups der oberen Projektionen ablesen. <br><br><h2>  Was weiter </h2><br>  Derzeit deckt der Datensatz die meisten Substantive ab, die in der russischen Sprache existieren und im Korpus in einer ausreichenden Vielfalt von Kontexten vertreten sind.  Das Hauptaugenmerk lag auf materiellen Objekten - als die verst√§ndlichsten und in wissenschaftlichen Arbeiten ausgearbeiteten.  Es bleibt die Aufgabe, das vorhandene Markup unter Ber√ºcksichtigung der vom Algorithmus empfangenen Daten zu verfeinern und mit Klassen auf den unteren Ebenen zu arbeiten, bei denen eine Verringerung der Vorhersagegenauigkeit aufgrund einer Verwischung der Grenzen zwischen den Kategorien beobachtet wird. <br><br>  Aber das ist eine Art Routinearbeit, die immer da ist.  Eine qualitativ neue Forschungsebene wird die M√∂glichkeit betreffen, ein bestimmtes Wort in einen bestimmten Kontext oder Satz zu klassifizieren, wodurch die Ph√§nomene der Homonymie und Polysemie einschlie√ülich der Metapher (bildliche Bedeutungen) ber√ºcksichtigt werden k√∂nnen. <br><br>  Au√üerdem arbeiten wir derzeit an mehreren verwandten Projekten: <br><br><ul><li>  <b>W√∂rterbuch der Erkennbarkeit der W√∂rter RY: Eine</b> Variation des Frequenzw√∂rterbuchs, bei der die Verst√§ndlichkeit und Vertrautheit des Wortes als Ergebnis eines Crowdsourcing-Markups bewertet und nicht anhand des Textk√∂rpers berechnet wird. </li><li>  <b>Offener Korpus zur L√∂sung lexikalischer Mehrdeutigkeiten:</b> Basierend auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RUSSE 2018 WSI &amp; D Shared Task-</a> Wettbewerb, der im Rahmen der Konferenz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dialogue 2018 durchgef√ºhrt wurde</a> , wurde die N√ºtzlichkeit des Korpus mit entfernter lexikalischer Mehrdeutigkeit zum Testen automatischer Algorithmen zur Begriffskl√§rung und Clusterbildung von Wortbedeutungen deutlich.  Wir werden dieses Gremium auch brauchen, um zur im vorherigen Absatz beschriebenen Phase der Arbeit an offener Semantik √ºberzugehen. </li></ul><br><h2>  Tonw√∂rterbuch der russischen Sprache </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Tonw√∂rterbuch</a> sind die W√∂rter und Ausdr√ºcke des ABl., Die durch die Tonalit√§t und St√§rke der Schwere der emotional-bewertenden Ladung gekennzeichnet sind.  Einfach ausgedr√ºckt, wie viel ein bestimmtes Wort "schlecht" oder "gut" ist. <br><br>  Derzeit sind 67.392 Zeichen markiert (davon 55.532 W√∂rter und 11.860 Ausdr√ºcke). <br><br><h2>  Feedback und Verteilung </h2><br>  Wir freuen uns √ºber jegliches Feedback in den Kommentaren - von Kritik an der Arbeit und unseren Ans√§tzen bis hin zu Links zu interessanten Studien und verwandten Artikeln. <br><br>  Wenn Sie Bekannte oder Kollegen haben, die an dem ver√∂ffentlichten Datensatz interessiert sein k√∂nnten, senden Sie ihnen einen Link zum Artikel oder Repository, um die Verbreitung offener Daten zu unterst√ºtzen. <br><br><h2>  Download-Link und Lizenz </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datensatz: offene Semantik der russischen Sprache</a> <br><br>  Der Datensatz ist unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CC BY-NC-SA 4.0</a> lizenziert. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de434154/">https://habr.com/ru/post/de434154/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de434138/index.html">Wir schreiben unsere eigene virtuelle Maschine</a></li>
<li><a href="../de434140/index.html">Eine kurze Geschichte der asynchronen Javascript-Funktionen</a></li>
<li><a href="../de434142/index.html">Das QRL-Team hat eine enge Frist f√ºr die Token-Migration festgelegt</a></li>
<li><a href="../de434146/index.html">Top 10 IT-Filme</a></li>
<li><a href="../de434150/index.html">Merkmale der Arbeitssuche in Europa</a></li>
<li><a href="../de434156/index.html">Fraktal von Gerasimov. Ein Muster gefunden. Schwarzer Tisch</a></li>
<li><a href="../de434158/index.html">OZON Inside: f√ºhlt sich an wie ein Startup</a></li>
<li><a href="../de434160/index.html">Einf√ºhrung in die Kubedog-Bibliothek f√ºr die Ressourcenverfolgung von Kubernetes</a></li>
<li><a href="../de434162/index.html">Gesichtserkennung Ivideon: Das kosteng√ºnstigste Gesichtserkennungssystem f√ºr Unternehmen</a></li>
<li><a href="../de434164/index.html">Migration von IBM Notes / Domino zu Zimbra Collaboration Suite</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
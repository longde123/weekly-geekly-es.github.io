<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÇ üêä üíü NVIDIA Jetson Nano: Tests und erste Eindr√ºcke - Teil 2, AI-Tests üö¢ üíÉüèæ üëµüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr. 

 Im ersten Teil wurde NVIDIA Jetson Nano in Betracht gezogen - ein Board im Raspberry Pi-Formfaktor, das sich auf Performance Computing ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA Jetson Nano: Tests und erste Eindr√ºcke - Teil 2, AI-Tests</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460971/">  Hallo Habr. <br><br>  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Teil</a> wurde NVIDIA Jetson Nano in Betracht gezogen - ein Board im Raspberry Pi-Formfaktor, das sich auf Performance Computing mit der GPU konzentriert.  Es ist Zeit, das Board so zu testen, wie es erstellt wurde - f√ºr AI-orientierte Berechnungen. <br><br><img src="https://habrastorage.org/webt/91/1a/7i/911a7i0fv9k20_edm9oftroelpq.png"><br><br>  √úberlegen Sie, wie unterschiedliche Aufgaben auf der Tafel ablaufen, z. B. das Klassifizieren von Bildern oder das Erkennen von Fu√üg√§ngern oder Robben (wo ohne sie).  F√ºr alle Tests kann der Quellcode auf dem Desktop, Jetson Nano oder Raspberry Pi ausgef√ºhrt werden.  F√ºr diejenigen, die interessiert sind, weiter unter dem Schnitt. <br><a name="habracut"></a><br>  Es gibt zwei M√∂glichkeiten, dieses Board zu verwenden.  Das erste besteht darin, Standard-Frameworks wie Keras und Tensorflow auszuf√ºhren.  Es wird im Prinzip funktionieren, aber wie bereits im ersten Teil zu sehen ist, ist Jetson Nano nat√ºrlich einer vollwertigen Desktop- oder Laptop-Grafikkarte unterlegen.  Der Benutzer muss die Optimierung des Modells √ºbernehmen.  Der zweite Weg besteht darin, vorgefertigte Kurse zu belegen, die mit dem Board geliefert werden.  Es ist einfacher und funktioniert "out of the box". Das Minus ist, dass alle Implementierungsdetails in viel gr√∂√üerem Ma√üe verborgen sind. Au√üerdem m√ºssen Sie custom-sdk studieren und verwenden, was neben diesen Boards nirgendwo anders n√ºtzlich sein wird.  Wir werden jedoch beide Wege betrachten, beginnend mit dem ersten. <br><br><h2>  Bildklassifizierung </h2><br>  Betrachten Sie das Problem der Bilderkennung.  Dazu verwenden wir das mit Keras gelieferte ResNet50-Modell (dieses Modell war der Gewinner der ImageNet Challenge im Jahr 2015).  Um es zu verwenden, reichen ein paar Codezeilen aus. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">224</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) resnet = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE) img = tf.contrib.keras.preprocessing.image.load_img(<span class="hljs-string"><span class="hljs-string">'cat.png'</span></span>, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_data = tf.contrib.keras.preprocessing.image.img_to_array(img) x = tf.contrib.keras.applications.resnet50.preprocess_input(np.expand_dims(img_data, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)) probabilities = resnet.predict(x) print(tf.contrib.keras.applications.resnet50.decode_predictions(probabilities, top=<span class="hljs-number"><span class="hljs-number">5</span></span>)) print(<span class="hljs-string"><span class="hljs-string">"dT"</span></span>, time.time() - t_start)</code> </pre> <br>  Ich habe nicht einmal angefangen, den Code unter dem Spoiler zu entfernen, weil  Er ist sehr klein.  Wie Sie sehen k√∂nnen, wird die Bildgr√∂√üe zun√§chst auf 224 x 224 ge√§ndert (dies ist das Eingangsnetzwerkformat). Am Ende erledigt die Vorhersagefunktion die gesamte Arbeit. <br><br>  Wir machen ein Foto von der Katze und f√ºhren das Programm aus. <br><br><img src="https://habrastorage.org/webt/_q/e8/ln/_qe8ln2w3hsmbw4dqcy7kdnuft0.png"><br><br>  Ergebnisse: <br><br><pre> <code class="python hljs">[[(<span class="hljs-string"><span class="hljs-string">'n02123045'</span></span>, <span class="hljs-string"><span class="hljs-string">'tabby'</span></span>, <span class="hljs-number"><span class="hljs-number">0.765179</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02123159'</span></span>, <span class="hljs-string"><span class="hljs-string">'tiger_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.19059166</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02124075'</span></span>, <span class="hljs-string"><span class="hljs-string">'Egyptian_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.013605555</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04493381'</span></span>, <span class="hljs-string"><span class="hljs-string">'tub'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0025916891</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04553703'</span></span>, <span class="hljs-string"><span class="hljs-string">'washbasin'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0021566998</span></span>)]]</code> </pre> <br>  Noch einmal, ver√§rgert √ºber seine Englischkenntnisse (ich frage mich, wie viele Nicht-Muttersprachler wissen, was ‚ÄûTabby‚Äú ist?), √úberpr√ºfte ich die Ausgabe mit dem W√∂rterbuch. Ja, alles funktioniert. <br><br>  Die Ausf√ºhrungszeit des PC-Codes betrug <b>0,5 s</b> f√ºr Berechnungen auf der CPU und 2 s (!) F√ºr Berechnungen auf der GPU.  Dem Protokoll nach zu urteilen, liegt das Problem entweder im Modell oder in Tensorflow, aber beim Start versucht der Code, viel Speicher zuzuweisen, und es werden mehrere Warnungen der Form "Allocator (GPU_0_bfc) hat nicht gen√ºgend Speicher, um 2.13GiB mit freed_by_count = 0 zuzuweisen" angezeigt. .  Dies ist eine Warnung und kein Fehler, der Code funktioniert, aber viel langsamer als er sollte. <br><br>  Auf Jetson Nano ist es immer noch langsamer: <b>2,8 c</b> auf der CPU und <b>18,8 c</b> auf der GPU, w√§hrend die Ausgabe folgenderma√üen aussieht: <br><br><img src="https://habrastorage.org/webt/t6/ok/ja/t6okja2fzqx_tjvmd6evens5dn8.png"><br><br>  Im Allgemeinen ist dies sogar 3s pro Bild noch nicht in Echtzeit.  Das Festlegen der Option gpu_options.allow_growth, die f√ºr den Stapel√ºberlauf empfohlen wird, hilft nicht. Wenn jemand einen anderen Weg kennt, schreiben Sie in die Kommentare. <br><br>  <b>Bearbeiten</b> : Wie in den Kommentaren angegeben, dauert der erste Start des Tensorflusses immer lange und es ist falsch, die Zeit damit zu messen.  In der Tat sind die Ergebnisse bei der Verarbeitung der zweiten und der nachfolgenden Dateien viel besser - 0,6 Sekunden ohne GPU und 0,2 Sekunden mit einer GPU.  Auf dem Desktop betr√§gt die Geschwindigkeit jedoch 2,0 s bzw. 0,05 s. <br><br>  Eine praktische Funktion von ResNet50 ist, dass beim ersten Start das gesamte Modell auf die Festplatte (ca. 100 MB) gepumpt wird und der Code dann v√∂llig autonom ohne Registrierung und SMS arbeitet.  Das ist besonders sch√∂n, da die meisten modernen KI-Dienste nur auf dem Server funktionieren und das Ger√§t ohne Internet zu einem "K√ºrbis" wird. <br><br><h2>  Katzen gegen Hunde </h2><br>  Betrachten Sie das folgende Problem.  Mit Keras erstellen wir ein neuronales Netzwerk, das zwischen Katzen und Hunden unterscheiden kann.  Es wird ein Faltungs-Neuronales Netzwerk (CNN - Convolutional Neural Network) sein, wir werden das Netzwerkdesign aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser</a> Ver√∂ffentlichung √ºbernehmen.  Das Paket tensorflow_datasets enth√§lt bereits einen Trainingssatz mit Bildern von Katzen und Hunden, sodass Sie sie nicht selbst fotografieren m√ºssen. <br><br>  Wir laden eine Reihe von Bildern und teilen sie in drei Bl√∂cke auf - Training, Verifikation und Test.  Wir "normalisieren" jedes Bild und bringen die Farben in den Bereich 0..1. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_datasets <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tfds <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">64</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) splits = tfds.Split.TRAIN.subsplit(weighted=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) (cat_train, cat_valid, cat_test), info = tfds.load(<span class="hljs-string"><span class="hljs-string">'cats_vs_dogs'</span></span>, split=list(splits), with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) label_names = info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].int2str <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pre_process_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, label)</span></span></span><span class="hljs-function">:</span></span> image = tf.cast(image, tf.float32) image = image / <span class="hljs-number"><span class="hljs-number">255.0</span></span> <span class="hljs-comment"><span class="hljs-comment"># Normalize image: 0..255 -&gt; 0..1 image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) return image, label BATCH_SIZE = 32 SHUFFLE_BUFFER_SIZE = 1000 train_batch = cat_train.map(pre_process_image).shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(BATCH_SIZE) validation_batch = cat_valid.map(pre_process_image).repeat().batch(BATCH_SIZE)</span></span></code> </pre><br>  Wir schreiben die Funktion der Erzeugung eines Faltungsnetzwerks. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Source: https://medium.com/@ferhat00/deep-learning-with-keras-classifying-cats-and-dogs-part-1-982067594856 classifier = tf.keras.Sequential() # Step 1 ‚Äî Convolution classifier.add(layers.Conv2D(32, (3, 3), input_shape=IMG_SHAPE, activation='relu')) # Step 2 ‚Äî Pooling classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Adding a second convolutional layer classifier.add(layers.Conv2D(32, (3, 3), activation='relu')) classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Step 3 ‚Äî Flattening classifier.add(layers.Flatten()) # Step 4 ‚Äî Full connection classifier.add(layers.Dense(units=128, activation='relu')) classifier.add(layers.Dense(units=1, activation='sigmoid')) # Compiling the CNN we shall use the Adam stochastic optimisation method, binary cross entropy loss function classifier.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy']) return classifier</span></span></code> </pre><br>  Jetzt k√∂nnen wir mit unserem ‚ÄûCat-Dog‚Äú -Kit ein Netzwerktraining durchf√ºhren.  Das Training dauert lange (20 Minuten auf der GPU und 1-2 Stunden auf der CPU), daher speichern wir das Modell am Ende in einer Datei. <br><br><pre> <code class="python hljs">tl_model = custom_model() t_start = time.time() tl_model.fit(train_batch, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">8000</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">2</span></span>, validation_data=validation_batch, validation_steps=<span class="hljs-number"><span class="hljs-number">10</span></span>, callbacks=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) print(<span class="hljs-string"><span class="hljs-string">"Training done, dT:"</span></span>, time.time() - t_start) print(tl_model.summary()) validation_steps = <span class="hljs-number"><span class="hljs-number">20</span></span> loss0, accuracy0 = tl_model.evaluate(validation_batch, steps=validation_steps) print(<span class="hljs-string"><span class="hljs-string">"Loss: {:.2f}"</span></span>.format(loss0)) print(<span class="hljs-string"><span class="hljs-string">"Accuracy: {:.2f}"</span></span>.format(accuracy0)) tl_model.save(<span class="hljs-string"><span class="hljs-string">"dog_cat_model.h5"</span></span>)</code> </pre><br>  Der Versuch, das Training direkt auf dem Jetson Nano zu starten, schlug √ºbrigens fehl - nach 5 Minuten war das Board √ºberhitzt und hing.  F√ºr ressourcenintensive Berechnungen ist ein K√ºhler f√ºr das Board erforderlich, obwohl es im Gro√üen und Ganzen keinen Sinn macht, solche Aufgaben direkt auf Jetson Nano auszuf√ºhren - das Modell kann auf einem PC trainiert werden und die fertig gespeicherte Datei kann auf Nano verwendet werden. <br><br>  Hier kam eine weitere Gefahr heraus: Die Tensowflow-Bibliothek der Version 14 wurde auf dem PC installiert, und die neueste Version f√ºr Jetson Nano ist bisher 13. Und das in der 14. Version gespeicherte Modell wurde in der 13. Version nicht gelesen. Ich musste dieselben Versionen mit pip installieren. <br><br>  Schlie√ülich k√∂nnen wir das Modell aus einer Datei laden und damit Bilder erkennen. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, image_file)</span></span></span><span class="hljs-function">:</span></span> img = image.load_img(image_file, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) result = model.predict_classes(img_arr) print(<span class="hljs-string"><span class="hljs-string">"Result: {}, dT: {}"</span></span>.format(label_names(result[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]), time.time() - t_start)) model = tf.keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'dog_cat_model.h5'</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"cat.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog1.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog2.png"</span></span>)</code> </pre><br>  Das Foto der Katze wurde genauso verwendet, aber f√ºr den "Hund" -Test wurden 2 Bilder verwendet: <br><br><img src="https://habrastorage.org/webt/2m/0m/6f/2m0m6fvejlzvcdfuewdq2m9b5ug.png"><br><br>  Der erste hat richtig geraten, und der zweite hatte zuerst Fehler und das neuronale Netzwerk dachte, es sei eine Katze. Ich musste die Anzahl der Trainingsiterationen erh√∂hen.  Allerdings h√§tte ich wahrscheinlich beim ersten Mal einen Fehler gemacht;) <br><br>  Die Ausf√ºhrungszeit auf Jetson Nano erwies sich als recht kurz - das allererste Foto wurde in 0,3 Sekunden verarbeitet, aber alle nachfolgenden Fotos waren viel schneller, anscheinend werden die Daten im Speicher zwischengespeichert. <br><br><img src="https://habrastorage.org/webt/hx/w1/vg/hxw1vgfb217p1usxaftimpmkybo.png"><br><br>  Im Allgemeinen k√∂nnen wir davon ausgehen, dass in solch einfachen neuronalen Netzen die Geschwindigkeit der Karte auch ohne Optimierungen v√∂llig ausreicht. 100 fps sind ein Wert, der selbst f√ºr Videos in Echtzeit ausreicht. <br><br><h2>  Fazit </h2><br>  Wie Sie sehen, k√∂nnen sogar Standardmodelle von Keras und Tensorflow auf Nano verwendet werden, wenn auch mit unterschiedlichem Erfolg - etwas funktioniert, etwas nicht.  Die Ergebnisse k√∂nnen jedoch verbessert werden, Anweisungen zur Optimierung des Modells und zur Reduzierung der Speichergr√∂√üe k√∂nnen hier gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . <br><br>  Aber zum Gl√ºck haben die Hersteller dies bereits f√ºr uns getan.  Wenn die Leser immer noch Interesse haben, wird der letzte Teil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigten Bibliotheken gewidmet sein,</a> die f√ºr die Arbeit mit Jetson Nano optimiert sind. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460971/">https://habr.com/ru/post/de460971/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460959/index.html">Mit der neuen Technologie von Microsoft k√∂nnen 3D-Kopien einer realen Person jede Sprache sprechen</a></li>
<li><a href="../de460961/index.html">Einrichten von Unit-Tests in gemischten Swift + Objective-C-Projekten</a></li>
<li><a href="../de460965/index.html">Split Controller ohne diese Ihre Storyboards</a></li>
<li><a href="../de460967/index.html">Troy Hunt: 10 pers√∂nliche Finanzstunden f√ºr IT-Profis</a></li>
<li><a href="../de460969/index.html">Margaret Hamilton: ‚ÄûSie hatten Angst, dass M√§nner rebellieren k√∂nnten; aber es ist nicht passiert. "</a></li>
<li><a href="../de460973/index.html">Kontaktschwei√üen f√ºr 18650 Batterien</a></li>
<li><a href="../de460979/index.html">Verj√ºngungsbiotechnologien sind real und unvermeidlich</a></li>
<li><a href="../de460981/index.html">MVVM-Implementierung der WPF-Anwendungskonfiguration, die auf dem Catel-Framework basiert</a></li>
<li><a href="../de460983/index.html">Ich bin nicht real</a></li>
<li><a href="../de460985/index.html">14 besten Kanban-Tools im Jahr 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
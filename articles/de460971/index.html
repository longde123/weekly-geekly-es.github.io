<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏂 🐊 💟 NVIDIA Jetson Nano: Tests und erste Eindrücke - Teil 2, AI-Tests 🚢 💃🏾 👵🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr. 

 Im ersten Teil wurde NVIDIA Jetson Nano in Betracht gezogen - ein Board im Raspberry Pi-Formfaktor, das sich auf Performance Computing ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA Jetson Nano: Tests und erste Eindrücke - Teil 2, AI-Tests</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460971/">  Hallo Habr. <br><br>  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Teil</a> wurde NVIDIA Jetson Nano in Betracht gezogen - ein Board im Raspberry Pi-Formfaktor, das sich auf Performance Computing mit der GPU konzentriert.  Es ist Zeit, das Board so zu testen, wie es erstellt wurde - für AI-orientierte Berechnungen. <br><br><img src="https://habrastorage.org/webt/91/1a/7i/911a7i0fv9k20_edm9oftroelpq.png"><br><br>  Überlegen Sie, wie unterschiedliche Aufgaben auf der Tafel ablaufen, z. B. das Klassifizieren von Bildern oder das Erkennen von Fußgängern oder Robben (wo ohne sie).  Für alle Tests kann der Quellcode auf dem Desktop, Jetson Nano oder Raspberry Pi ausgeführt werden.  Für diejenigen, die interessiert sind, weiter unter dem Schnitt. <br><a name="habracut"></a><br>  Es gibt zwei Möglichkeiten, dieses Board zu verwenden.  Das erste besteht darin, Standard-Frameworks wie Keras und Tensorflow auszuführen.  Es wird im Prinzip funktionieren, aber wie bereits im ersten Teil zu sehen ist, ist Jetson Nano natürlich einer vollwertigen Desktop- oder Laptop-Grafikkarte unterlegen.  Der Benutzer muss die Optimierung des Modells übernehmen.  Der zweite Weg besteht darin, vorgefertigte Kurse zu belegen, die mit dem Board geliefert werden.  Es ist einfacher und funktioniert "out of the box". Das Minus ist, dass alle Implementierungsdetails in viel größerem Maße verborgen sind. Außerdem müssen Sie custom-sdk studieren und verwenden, was neben diesen Boards nirgendwo anders nützlich sein wird.  Wir werden jedoch beide Wege betrachten, beginnend mit dem ersten. <br><br><h2>  Bildklassifizierung </h2><br>  Betrachten Sie das Problem der Bilderkennung.  Dazu verwenden wir das mit Keras gelieferte ResNet50-Modell (dieses Modell war der Gewinner der ImageNet Challenge im Jahr 2015).  Um es zu verwenden, reichen ein paar Codezeilen aus. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">224</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) resnet = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE) img = tf.contrib.keras.preprocessing.image.load_img(<span class="hljs-string"><span class="hljs-string">'cat.png'</span></span>, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_data = tf.contrib.keras.preprocessing.image.img_to_array(img) x = tf.contrib.keras.applications.resnet50.preprocess_input(np.expand_dims(img_data, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)) probabilities = resnet.predict(x) print(tf.contrib.keras.applications.resnet50.decode_predictions(probabilities, top=<span class="hljs-number"><span class="hljs-number">5</span></span>)) print(<span class="hljs-string"><span class="hljs-string">"dT"</span></span>, time.time() - t_start)</code> </pre> <br>  Ich habe nicht einmal angefangen, den Code unter dem Spoiler zu entfernen, weil  Er ist sehr klein.  Wie Sie sehen können, wird die Bildgröße zunächst auf 224 x 224 geändert (dies ist das Eingangsnetzwerkformat). Am Ende erledigt die Vorhersagefunktion die gesamte Arbeit. <br><br>  Wir machen ein Foto von der Katze und führen das Programm aus. <br><br><img src="https://habrastorage.org/webt/_q/e8/ln/_qe8ln2w3hsmbw4dqcy7kdnuft0.png"><br><br>  Ergebnisse: <br><br><pre> <code class="python hljs">[[(<span class="hljs-string"><span class="hljs-string">'n02123045'</span></span>, <span class="hljs-string"><span class="hljs-string">'tabby'</span></span>, <span class="hljs-number"><span class="hljs-number">0.765179</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02123159'</span></span>, <span class="hljs-string"><span class="hljs-string">'tiger_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.19059166</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02124075'</span></span>, <span class="hljs-string"><span class="hljs-string">'Egyptian_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.013605555</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04493381'</span></span>, <span class="hljs-string"><span class="hljs-string">'tub'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0025916891</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04553703'</span></span>, <span class="hljs-string"><span class="hljs-string">'washbasin'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0021566998</span></span>)]]</code> </pre> <br>  Noch einmal, verärgert über seine Englischkenntnisse (ich frage mich, wie viele Nicht-Muttersprachler wissen, was „Tabby“ ist?), Überprüfte ich die Ausgabe mit dem Wörterbuch. Ja, alles funktioniert. <br><br>  Die Ausführungszeit des PC-Codes betrug <b>0,5 s</b> für Berechnungen auf der CPU und 2 s (!) Für Berechnungen auf der GPU.  Dem Protokoll nach zu urteilen, liegt das Problem entweder im Modell oder in Tensorflow, aber beim Start versucht der Code, viel Speicher zuzuweisen, und es werden mehrere Warnungen der Form "Allocator (GPU_0_bfc) hat nicht genügend Speicher, um 2.13GiB mit freed_by_count = 0 zuzuweisen" angezeigt. .  Dies ist eine Warnung und kein Fehler, der Code funktioniert, aber viel langsamer als er sollte. <br><br>  Auf Jetson Nano ist es immer noch langsamer: <b>2,8 c</b> auf der CPU und <b>18,8 c</b> auf der GPU, während die Ausgabe folgendermaßen aussieht: <br><br><img src="https://habrastorage.org/webt/t6/ok/ja/t6okja2fzqx_tjvmd6evens5dn8.png"><br><br>  Im Allgemeinen ist dies sogar 3s pro Bild noch nicht in Echtzeit.  Das Festlegen der Option gpu_options.allow_growth, die für den Stapelüberlauf empfohlen wird, hilft nicht. Wenn jemand einen anderen Weg kennt, schreiben Sie in die Kommentare. <br><br>  <b>Bearbeiten</b> : Wie in den Kommentaren angegeben, dauert der erste Start des Tensorflusses immer lange und es ist falsch, die Zeit damit zu messen.  In der Tat sind die Ergebnisse bei der Verarbeitung der zweiten und der nachfolgenden Dateien viel besser - 0,6 Sekunden ohne GPU und 0,2 Sekunden mit einer GPU.  Auf dem Desktop beträgt die Geschwindigkeit jedoch 2,0 s bzw. 0,05 s. <br><br>  Eine praktische Funktion von ResNet50 ist, dass beim ersten Start das gesamte Modell auf die Festplatte (ca. 100 MB) gepumpt wird und der Code dann völlig autonom ohne Registrierung und SMS arbeitet.  Das ist besonders schön, da die meisten modernen KI-Dienste nur auf dem Server funktionieren und das Gerät ohne Internet zu einem "Kürbis" wird. <br><br><h2>  Katzen gegen Hunde </h2><br>  Betrachten Sie das folgende Problem.  Mit Keras erstellen wir ein neuronales Netzwerk, das zwischen Katzen und Hunden unterscheiden kann.  Es wird ein Faltungs-Neuronales Netzwerk (CNN - Convolutional Neural Network) sein, wir werden das Netzwerkdesign aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser</a> Veröffentlichung übernehmen.  Das Paket tensorflow_datasets enthält bereits einen Trainingssatz mit Bildern von Katzen und Hunden, sodass Sie sie nicht selbst fotografieren müssen. <br><br>  Wir laden eine Reihe von Bildern und teilen sie in drei Blöcke auf - Training, Verifikation und Test.  Wir "normalisieren" jedes Bild und bringen die Farben in den Bereich 0..1. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_datasets <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tfds <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">64</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) splits = tfds.Split.TRAIN.subsplit(weighted=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) (cat_train, cat_valid, cat_test), info = tfds.load(<span class="hljs-string"><span class="hljs-string">'cats_vs_dogs'</span></span>, split=list(splits), with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) label_names = info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].int2str <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pre_process_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, label)</span></span></span><span class="hljs-function">:</span></span> image = tf.cast(image, tf.float32) image = image / <span class="hljs-number"><span class="hljs-number">255.0</span></span> <span class="hljs-comment"><span class="hljs-comment"># Normalize image: 0..255 -&gt; 0..1 image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) return image, label BATCH_SIZE = 32 SHUFFLE_BUFFER_SIZE = 1000 train_batch = cat_train.map(pre_process_image).shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(BATCH_SIZE) validation_batch = cat_valid.map(pre_process_image).repeat().batch(BATCH_SIZE)</span></span></code> </pre><br>  Wir schreiben die Funktion der Erzeugung eines Faltungsnetzwerks. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Source: https://medium.com/@ferhat00/deep-learning-with-keras-classifying-cats-and-dogs-part-1-982067594856 classifier = tf.keras.Sequential() # Step 1 — Convolution classifier.add(layers.Conv2D(32, (3, 3), input_shape=IMG_SHAPE, activation='relu')) # Step 2 — Pooling classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Adding a second convolutional layer classifier.add(layers.Conv2D(32, (3, 3), activation='relu')) classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Step 3 — Flattening classifier.add(layers.Flatten()) # Step 4 — Full connection classifier.add(layers.Dense(units=128, activation='relu')) classifier.add(layers.Dense(units=1, activation='sigmoid')) # Compiling the CNN we shall use the Adam stochastic optimisation method, binary cross entropy loss function classifier.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy']) return classifier</span></span></code> </pre><br>  Jetzt können wir mit unserem „Cat-Dog“ -Kit ein Netzwerktraining durchführen.  Das Training dauert lange (20 Minuten auf der GPU und 1-2 Stunden auf der CPU), daher speichern wir das Modell am Ende in einer Datei. <br><br><pre> <code class="python hljs">tl_model = custom_model() t_start = time.time() tl_model.fit(train_batch, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">8000</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">2</span></span>, validation_data=validation_batch, validation_steps=<span class="hljs-number"><span class="hljs-number">10</span></span>, callbacks=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) print(<span class="hljs-string"><span class="hljs-string">"Training done, dT:"</span></span>, time.time() - t_start) print(tl_model.summary()) validation_steps = <span class="hljs-number"><span class="hljs-number">20</span></span> loss0, accuracy0 = tl_model.evaluate(validation_batch, steps=validation_steps) print(<span class="hljs-string"><span class="hljs-string">"Loss: {:.2f}"</span></span>.format(loss0)) print(<span class="hljs-string"><span class="hljs-string">"Accuracy: {:.2f}"</span></span>.format(accuracy0)) tl_model.save(<span class="hljs-string"><span class="hljs-string">"dog_cat_model.h5"</span></span>)</code> </pre><br>  Der Versuch, das Training direkt auf dem Jetson Nano zu starten, schlug übrigens fehl - nach 5 Minuten war das Board überhitzt und hing.  Für ressourcenintensive Berechnungen ist ein Kühler für das Board erforderlich, obwohl es im Großen und Ganzen keinen Sinn macht, solche Aufgaben direkt auf Jetson Nano auszuführen - das Modell kann auf einem PC trainiert werden und die fertig gespeicherte Datei kann auf Nano verwendet werden. <br><br>  Hier kam eine weitere Gefahr heraus: Die Tensowflow-Bibliothek der Version 14 wurde auf dem PC installiert, und die neueste Version für Jetson Nano ist bisher 13. Und das in der 14. Version gespeicherte Modell wurde in der 13. Version nicht gelesen. Ich musste dieselben Versionen mit pip installieren. <br><br>  Schließlich können wir das Modell aus einer Datei laden und damit Bilder erkennen. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, image_file)</span></span></span><span class="hljs-function">:</span></span> img = image.load_img(image_file, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) result = model.predict_classes(img_arr) print(<span class="hljs-string"><span class="hljs-string">"Result: {}, dT: {}"</span></span>.format(label_names(result[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]), time.time() - t_start)) model = tf.keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'dog_cat_model.h5'</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"cat.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog1.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog2.png"</span></span>)</code> </pre><br>  Das Foto der Katze wurde genauso verwendet, aber für den "Hund" -Test wurden 2 Bilder verwendet: <br><br><img src="https://habrastorage.org/webt/2m/0m/6f/2m0m6fvejlzvcdfuewdq2m9b5ug.png"><br><br>  Der erste hat richtig geraten, und der zweite hatte zuerst Fehler und das neuronale Netzwerk dachte, es sei eine Katze. Ich musste die Anzahl der Trainingsiterationen erhöhen.  Allerdings hätte ich wahrscheinlich beim ersten Mal einen Fehler gemacht;) <br><br>  Die Ausführungszeit auf Jetson Nano erwies sich als recht kurz - das allererste Foto wurde in 0,3 Sekunden verarbeitet, aber alle nachfolgenden Fotos waren viel schneller, anscheinend werden die Daten im Speicher zwischengespeichert. <br><br><img src="https://habrastorage.org/webt/hx/w1/vg/hxw1vgfb217p1usxaftimpmkybo.png"><br><br>  Im Allgemeinen können wir davon ausgehen, dass in solch einfachen neuronalen Netzen die Geschwindigkeit der Karte auch ohne Optimierungen völlig ausreicht. 100 fps sind ein Wert, der selbst für Videos in Echtzeit ausreicht. <br><br><h2>  Fazit </h2><br>  Wie Sie sehen, können sogar Standardmodelle von Keras und Tensorflow auf Nano verwendet werden, wenn auch mit unterschiedlichem Erfolg - etwas funktioniert, etwas nicht.  Die Ergebnisse können jedoch verbessert werden, Anweisungen zur Optimierung des Modells und zur Reduzierung der Speichergröße können hier gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . <br><br>  Aber zum Glück haben die Hersteller dies bereits für uns getan.  Wenn die Leser immer noch Interesse haben, wird der letzte Teil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigten Bibliotheken gewidmet sein,</a> die für die Arbeit mit Jetson Nano optimiert sind. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460971/">https://habr.com/ru/post/de460971/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460959/index.html">Mit der neuen Technologie von Microsoft können 3D-Kopien einer realen Person jede Sprache sprechen</a></li>
<li><a href="../de460961/index.html">Einrichten von Unit-Tests in gemischten Swift + Objective-C-Projekten</a></li>
<li><a href="../de460965/index.html">Split Controller ohne diese Ihre Storyboards</a></li>
<li><a href="../de460967/index.html">Troy Hunt: 10 persönliche Finanzstunden für IT-Profis</a></li>
<li><a href="../de460969/index.html">Margaret Hamilton: „Sie hatten Angst, dass Männer rebellieren könnten; aber es ist nicht passiert. "</a></li>
<li><a href="../de460973/index.html">Kontaktschweißen für 18650 Batterien</a></li>
<li><a href="../de460979/index.html">Verjüngungsbiotechnologien sind real und unvermeidlich</a></li>
<li><a href="../de460981/index.html">MVVM-Implementierung der WPF-Anwendungskonfiguration, die auf dem Catel-Framework basiert</a></li>
<li><a href="../de460983/index.html">Ich bin nicht real</a></li>
<li><a href="../de460985/index.html">14 besten Kanban-Tools im Jahr 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
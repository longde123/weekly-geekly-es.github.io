<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÆ üêû üî§ Libro "An√°lisis de datos de texto aplicado en Python" üë®‚Äçüë¶‚Äçüë¶ üï∫üèΩ üëê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La tecnolog√≠a de an√°lisis de texto est√° cambiando r√°pidamente bajo la influencia del aprendizaje autom√°tico. Las redes neuronales de la investigaci√≥n ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Libro "An√°lisis de datos de texto aplicado en Python"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/444384/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/xl/rp/2m/xlrp2mz88qpo576nl7wcvkhpaek.jpeg" align="left" alt="imagen"></a>  La tecnolog√≠a de an√°lisis de texto est√° cambiando r√°pidamente bajo la influencia del aprendizaje autom√°tico.  Las redes neuronales de la investigaci√≥n cient√≠fica te√≥rica han pasado a la vida real, y el an√°lisis de texto se integra activamente en las soluciones de software.  Las redes neuronales son capaces de resolver las tareas m√°s complejas del procesamiento del lenguaje natural, nadie se sorprende con la traducci√≥n autom√°tica, la "conversaci√≥n" con un robot en una tienda en l√≠nea, reformulando, respondiendo preguntas y manteniendo un di√°logo.  ¬øPor qu√©, entonces, Siri, Alexa y Alice no quieren entendernos, Google no encuentra lo que estamos buscando y los traductores autom√°ticos nos divierten con ejemplos de "dificultades de traducci√≥n" del chino al alban√©s?  La respuesta est√° en los detalles: en algoritmos que funcionan correctamente en teor√≠a, pero que son dif√≠ciles de implementar en la pr√°ctica.  Aprenda a utilizar t√©cnicas de aprendizaje autom√°tico para analizar texto en tareas de la vida real utilizando las capacidades y bibliotecas de Python.  Desde la b√∫squeda de modelos y el preprocesamiento de datos, pasar√° a los m√©todos de clasificaci√≥n y agrupaci√≥n de textos, luego proceder√° a la interpretaci√≥n visual, el an√°lisis de gr√°ficos y, despu√©s de familiarizarse con las t√©cnicas de escala, aprender√° a utilizar el aprendizaje profundo para analizar texto. <br><br><a name="habracut"></a><br><h3>  ¬øQu√© se describe en este libro? </h3><br>  Este libro habla sobre el uso de m√©todos de aprendizaje autom√°tico para analizar texto usando las bibliotecas de Python que acabamos de enumerar.  La naturaleza aplicada del libro sugiere que no nos centremos en la ling√º√≠stica acad√©mica o los modelos estad√≠sticos, sino en el despliegue efectivo de modelos formados por texto dentro de la aplicaci√≥n. <br><br>  Nuestro modelo de an√°lisis de texto est√° directamente relacionado con el proceso de aprendizaje autom√°tico: la b√∫squeda de un modelo que consta de atributos, un algoritmo e hiperpar√°metros que dar√≠an los mejores resultados en los datos de entrenamiento para evaluar datos desconocidos.  Este proceso comienza con la creaci√≥n de un conjunto de datos de capacitaci√≥n, que en el campo del an√°lisis de texto se denomina corpus.  Luego examinamos los m√©todos para extraer atributos y preprocesar para representar el texto en forma de datos num√©ricos comprensibles para los m√©todos de aprendizaje autom√°tico.  Adem√°s, despu√©s de conocer algunos de los conceptos b√°sicos, pasaremos a estudiar los m√©todos de clasificaci√≥n y agrupaci√≥n de texto, cuya historia completa los primeros cap√≠tulos del libro. <br><br>  En cap√≠tulos posteriores, el enfoque est√° en expandir modelos con conjuntos de atributos m√°s ricos y crear aplicaciones de an√°lisis de texto.  Primero, veremos c√≥mo es posible presentar e implementar un contexto en forma de signos, luego pasaremos a una interpretaci√≥n visual para controlar el proceso de selecci√≥n del modelo.  Luego veremos c√≥mo analizar relaciones complejas extra√≠das del texto utilizando t√©cnicas de an√°lisis gr√°fico.  Despu√©s de eso, dirigimos nuestra atenci√≥n a los agentes interactivos y profundizamos nuestra comprensi√≥n del an√°lisis sint√°ctico y sem√°ntico del texto.  En conclusi√≥n, el libro presentar√° una discusi√≥n pr√°ctica de las t√©cnicas de escalado para el an√°lisis de texto en sistemas multiprocesador que usan Spark, y finalmente, consideraremos la siguiente etapa del an√°lisis de texto: aprendizaje profundo. <br><br><h3>  ¬øPara qui√©n es este libro? </h3><br>  Este libro est√° escrito para programadores de Python interesados ‚Äã‚Äãen utilizar el procesamiento del lenguaje natural y los m√©todos de aprendizaje autom√°tico en sus productos de software.  No suponemos que nuestros lectores tengan conocimientos acad√©micos o matem√°ticos especiales, sino que se centren en herramientas y t√©cnicas, en lugar de largas explicaciones.  En primer lugar, este libro analiza el an√°lisis de textos en ingl√©s, por lo que los lectores necesitar√°n al menos un conocimiento b√°sico de entidades gramaticales como sustantivos, verbos, adverbios y adjetivos, y c√≥mo se relacionan.  Los lectores sin experiencia en aprendizaje autom√°tico y ling√º√≠stica, pero con habilidades de programaci√≥n en Python, no se sentir√°n perdidos al aprender los conceptos que presentaremos. <br><br><h3>  Extracto  Extraer gr√°ficos del texto </h3><br>  Extraer un gr√°fico del texto es una tarea dif√≠cil.  Su soluci√≥n generalmente depende del √°rea tem√°tica y, en general, la b√∫squeda de elementos estructurados en datos no estructurados o semiestructurados se determina mediante preguntas anal√≠ticas sensibles al contexto. <br><br>  Proponemos dividir esta tarea en pasos m√°s peque√±os organizando un proceso simple de an√°lisis gr√°fico, como se muestra en la Fig.  9.3. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2k/f4/ce/2kf4cel7ri9mnaguprrfabt_qus.png" alt="imagen"></div><br>  En este proceso, primero determinamos las entidades y las relaciones entre ellas, en funci√≥n de la descripci√≥n de la tarea.  Adem√°s, sobre la base de este esquema, determinamos la metodolog√≠a para seleccionar un gr√°fico del corpus utilizando metadatos, documentos en el corpus y frases o tokens en los documentos para extraer datos y las relaciones entre ellos.  La t√©cnica de seleccionar un gr√°fico es un proceso c√≠clico que se puede aplicar al cuerpo, generar un gr√°fico y guardar este gr√°fico en el disco o la memoria para su posterior procesamiento anal√≠tico. <br><br>  En la etapa de an√°lisis, los c√°lculos se realizan en el gr√°fico extra√≠do, por ejemplo, agrupaci√≥n, an√°lisis estructural, filtrado o evaluaci√≥n, y se crea un nuevo gr√°fico, que se utiliza en las aplicaciones.  Con base en los resultados de la etapa de an√°lisis, podemos volver al comienzo del ciclo, refinar la metodolog√≠a y el esquema, extraer o colapsar grupos de nodos o bordes para tratar de lograr resultados m√°s precisos. <br><br><h3>  Crear un gr√°fico social </h3><br>  Considere nuestro cuerpo de art√≠culos de noticias y la tarea de modelar las relaciones entre diferentes entidades en el texto.  Si consideramos el tema de las diferencias en la cobertura entre diferentes agencias de noticias, puede construir un gr√°fico a partir de los elementos que representan los nombres de las publicaciones, los nombres de los autores y las fuentes de informaci√≥n.  Y si el objetivo es combinar referencias a una entidad en muchos art√≠culos, adem√°s de los detalles demogr√°ficos, nuestras redes pueden arreglar la forma de apelaci√≥n (respetuosa y otras).  Las entidades que nos interesan pueden estar en la estructura de los documentos o estar contenidas directamente en el texto. <br><br>  Digamos que nuestro objetivo es encontrar personas, lugares y cualquier otra cosa relacionada entre nosotros en nuestros documentos.  En otras palabras, necesitamos construir una red social realizando una serie de transformaciones, como se muestra en la Fig.  9.4.  Comenzamos la construcci√≥n del gr√°fico usando la clase EntityExtractor creada en el Cap√≠tulo 7. Luego agregamos los transformadores, uno de los cuales busca pares de entidades relacionadas, y el segundo convierte estos pares en un gr√°fico. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1f/uf/m7/1fufm7sghprbu87dmxa-zpllt3k.png" alt="imagen"></div><br>  <b>Buscar pares de entidades</b> <br><br>  Nuestro siguiente paso es crear la clase EntityPairs, que recibe documentos en forma de listas de entidades (creadas por la clase EntityExtractor del Cap√≠tulo 7).  Esta clase debe actuar como un convertidor en la canalizaci√≥n Pipeline de Scikit-Learn y, por lo tanto, heredar las clases BaseEstimator y TransformerMixin, como se describe en el Cap√≠tulo 4. Se supone que las entidades en el mismo documento est√°n relacionadas incondicionalmente entre s√≠, por lo que agregamos el m√©todo de pares usando la funci√≥n itertools .permutaciones para crear todos los pares posibles de entidades en un documento.  Nuestro m√©todo de transformaci√≥n llamar√° pares para cada documento en el cuerpo: <br><br><pre><code class="plaintext hljs">import itertools from sklearn.base import BaseEstimator, TransformerMixin class EntityPairs(BaseEstimator, TransformerMixin): def __init__(self): super(EntityPairs, self).__init__() def pairs(self, document): return list(itertools.permutations(set(document), 2)) def fit(self, documents, labels = None): return self def transform(self, documents): return [self.pairs(document) for document in documents]</code> </pre> <br>  Ahora puede extraer secuencialmente entidades de documentos y emparejarlas.  Pero a√∫n no podemos distinguir pares de entidades que ocurren con frecuencia de pares que ocurren solo una vez.  De alguna manera debemos codificar el peso de la relaci√≥n entre las entidades en cada par, que trataremos en la siguiente secci√≥n. <br><br><h3>  Gr√°ficos de propiedades </h3><br>  El modelo matem√°tico del gr√°fico define solo conjuntos de nodos y aristas y puede representarse como una matriz de adyacencia, que puede usarse en una variedad de c√°lculos.  Pero no admite un mecanismo para modelar la fuerza o los tipos de relaciones.  ¬øAparecen dos entidades en un solo documento o en muchos?  ¬øSe re√∫nen en art√≠culos de un g√©nero en particular?  Para admitir dicho razonamiento, necesitamos alguna forma de guardar propiedades significativas en los nodos y bordes del gr√°fico. <br><br>  El modelo de gr√°fico de propiedad le permite incrustar m√°s informaci√≥n en el gr√°fico, ampliando as√≠ nuestras capacidades.  En el gr√°fico de propiedades, los nodos son objetos con bordes entrantes y salientes y, por regla general, contienen un campo de tipo, parecido a una tabla en una base de datos relacional.  Las costillas son objetos que definen los puntos inicial y final;  estos objetos generalmente contienen un campo de etiqueta que identifica el tipo de conexi√≥n y un campo de peso que define la fuerza de la conexi√≥n.  Al usar gr√°ficos para el an√°lisis de texto, a menudo usamos sustantivos como nodos y verbos como bordes.  Despu√©s de pasar al paso de modelado, esto nos permitir√° describir los tipos de nodos, etiquetas de enlaces y la estructura gr√°fica propuesta. <br><br><h3>  Sobre los autores </h3><br>  Benjamin Bengfort es un especialista en ciencia de datos con sede en Washington, DC, que ignora por completo la pol√≠tica (algo com√∫n para el Distrito de Columbia) y prefiere la tecnolog√≠a.  Actualmente est√° trabajando en su tesis doctoral en la Universidad de Maryland, donde estudia aprendizaje autom√°tico y computaci√≥n distribuida.  Hay robots en su laboratorio (aunque esta no es su √°rea favorita), y para su disgusto, sus asistentes constantemente equipan estos robots con cuchillos y herramientas, probablemente con el objetivo de ganar una competencia culinaria.  Al ver a un robot que intenta picar un tomate, Benjamin prefiere organizar la cocina √©l mismo, donde cocina platos franceses y hawaianos, as√≠ como parrilladas y barbacoas de todo tipo.  Un programador de educaci√≥n profesional, investigador de datos vocacionales, Benjamin a menudo escribe art√≠culos que cubren una amplia gama de temas, desde el procesamiento del lenguaje natural hasta el an√°lisis de datos en Python y el uso de Hadoop y Spark en an√°lisis. <br><br>  Dra. Rebecca Bilbro - especialista en ciencia de datos, programadora de Python, maestra, profesora y autora de art√≠culos;  vive en Washington DC  Se especializa en la evaluaci√≥n visual de los resultados del aprendizaje autom√°tico: desde el an√°lisis de caracter√≠sticas hasta la selecci√≥n de modelos y la configuraci√≥n de hiperpar√°metros.  Realiza investigaciones en el campo del procesamiento del lenguaje natural, construyendo redes sem√°nticas, resolviendo entidades y procesando informaci√≥n con una gran cantidad de dimensiones.  Como participante activo en la comunidad de usuarios y desarrolladores de software de c√≥digo abierto, Rebecca se complace en trabajar con otros desarrolladores en proyectos como Yellowbrick (un paquete de Python que tiene como objetivo el modelado predictivo de caja negra).  En su tiempo libre, a menudo monta bicicletas con su familia o practica tocando el ukelele.  Recibi√≥ su doctorado de la Universidad de Illinois, en Urbana-Champaign, donde estudi√≥ las t√©cnicas pr√°cticas de comunicaci√≥n y visualizaci√≥n en tecnolog√≠a. <br><br>  ¬ªSe puede encontrar m√°s informaci√≥n sobre el libro en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el sitio web del editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Contenidos</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Extracto</a> <br><br>  Cup√≥n de 20% de descuento para vendedores ambulantes - <b>Python</b> <br><br>  Tras el pago de la versi√≥n en papel del libro, se env√≠a una versi√≥n electr√≥nica del libro por correo electr√≥nico. <br><br>  PD: el 7% del costo del libro se destinar√° a la traducci√≥n de nuevos libros de computadora, la lista de libros entregados a la imprenta est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/444384/">https://habr.com/ru/post/444384/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../444372/index.html">Orientaci√≥n a m√°quina a larga distancia utilizando aprendizaje reforzado</a></li>
<li><a href="../444374/index.html">Efecto hipster: por qu√© los inconformistas a menudo se ven iguales</a></li>
<li><a href="../444376/index.html">La econom√≠a de la atenci√≥n est√° casi muerta.</a></li>
<li><a href="../444378/index.html">USPACE - Espacio √∫nico para aeronaves tripuladas y no tripuladas</a></li>
<li><a href="../444382/index.html">C√≥mo visitar la Universidad de Corea con el sistema de archivos de red</a></li>
<li><a href="../444386/index.html">Misi√≥n lunar "Bereshit": la cuarta maniobra se complet√≥ con √©xito, se est√°n preparando para entrar en la √≥rbita lunar</a></li>
<li><a href="../444388/index.html">M√≥dems legendarios del pasado: los mejores titulares de conexi√≥n en las condiciones de los intercambios nacionales</a></li>
<li><a href="../444390/index.html">Sistema DeviceLock 8.3 DLP: ha pasado un a√±o, Billy, pero no has cambiado nada</a></li>
<li><a href="../444392/index.html">Radiaci√≥n: riesgos, seguridad, protecci√≥n.</a></li>
<li><a href="../444394/index.html">Linux Foundation lanza un nuevo proyecto DevOps con Jenkins y Spinnaker</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
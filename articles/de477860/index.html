<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçüè≠ üï¥üèΩ üî£ Wie werden verwaltete Datenbankdienste in Yandex Cloud angeordnet? ‚ôãÔ∏è üë≤üèø üèáüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wenn Sie jemandem das Wertvollste anvertrauen, das Sie haben - die Daten Ihrer Anwendung oder Ihres Dienstes - m√∂chten Sie sich vorstellen, wie dieser...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie werden verwaltete Datenbankdienste in Yandex Cloud angeordnet?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/477860/">  Wenn Sie jemandem das Wertvollste anvertrauen, das Sie haben - die Daten Ihrer Anwendung oder Ihres Dienstes - m√∂chten Sie sich vorstellen, wie dieser jemand mit Ihrem gr√∂√üten Wert umgeht. <br><br>  Mein Name ist Vladimir Borodin, ich bin der Leiter der Yandex.Cloud-Datenplattform.  Heute m√∂chte ich Ihnen sagen, wie alles in den Diensten von Yandex Managed Databases angeordnet ist und funktioniert, warum alles so abl√§uft und welche Vorteile unsere verschiedenen L√∂sungen aus Sicht der Benutzer haben.  Und nat√ºrlich werden Sie bestimmt herausfinden, was wir in naher Zukunft fertigstellen werden, damit der Service f√ºr alle, die ihn ben√∂tigen, besser und bequemer wird. <br><br>  Nun, lass uns gehen! <br><br><img src="https://habrastorage.org/webt/xw/qq/id/xwqqid27hmguyyigukvb2z3o8da.png" alt="Bild"><br><a name="habracut"></a><br>  Verwaltete Datenbanken (Yandex Managed Databases) ist einer der beliebtesten Dienste von Yandex.Cloud.  Genauer gesagt handelt es sich hierbei um eine ganze Gruppe von Diensten, die nach den virtuellen Maschinen von Yandex Compute Cloud an zweiter Stelle steht. <br><br>  Mit Yandex Managed Databases k√∂nnen Sie schnell eine funktionierende Datenbank erstellen und folgende Aufgaben √ºbernehmen: <br><br><ul><li>  Skalierung - von der elementaren F√§higkeit, Rechenressourcen oder Speicherplatz hinzuzuf√ºgen, bis hin zu einer Zunahme der Anzahl von Replikaten und Shards. </li><li>  Installieren Sie kleinere und gr√∂√üere Updates. </li><li>  Sichern und wiederherstellen. </li><li>  Fehlertoleranz gew√§hrleisten. </li><li>  √úberwachung </li><li>  Bereitstellung bequemer Konfigurations- und Verwaltungstools. </li></ul><br><h2>  So werden verwaltete Datenbankdienste angeordnet: Draufsicht </h2><br>  Der Service besteht aus zwei Hauptteilen: Kontrollebene und Datenebene.  Control Plane ist eine Datenbankverwaltungs-API, mit der Sie Datenbanken erstellen, √§ndern oder l√∂schen k√∂nnen.  Datenebene ist die Ebene der direkten Datenspeicherung. <br><br><img src="https://habrastorage.org/webt/vo/4c/o-/vo4co-q4zc3r6xwe0is2pl9hrri.png" alt="Bild"><br><br>  Die Dienstnutzer haben in der Tat zwei Einstiegspunkte: <br><br><ul><li>  In der Kontrollebene.  Tats√§chlich gibt es viele Eingaben - die Webkonsole, das CLI-Dienstprogramm und die Gateway-API, die die √∂ffentliche API (gRPC und REST) ‚Äã‚Äãbereitstellt.  Letztendlich gehen alle zu dem, was wir die interne API nennen, und deshalb werden wir diesen einen Einstiegspunkt in die Steuerebene betrachten.  Dies ist der Punkt, ab dem der Zust√§ndigkeitsbereich des MDB-Dienstes (Managed Databases) beginnt. </li><li> In der Datenebene.  Dies ist eine direkte Verbindung zu einer laufenden Datenbank √ºber Zugriffsprotokolle auf das DBMS.  Wenn es sich beispielsweise um PostgreSQL handelt, handelt es sich um <a href="https://www.postgresql.org/docs/current/libpq.html">die libpq-Schnittstelle</a> . </li></ul><br><img src="https://habrastorage.org/webt/cr/l5/pq/crl5pqrbr2mqqlun6ivgwlvn0u8.png" alt="Bild"><br>  Im Folgenden werden wir detaillierter beschreiben, was in der Datenebene geschieht, und wir werden jede der Komponenten der Steuerebene analysieren. <br><br><h2>  Datenebene </h2><br>  Bevor Sie sich die Komponenten der Steuerebene ansehen, werfen Sie einen Blick auf die Vorg√§nge in der Datenebene. <br><br><h3>  In einer virtuellen Maschine </h3><br>  MDB f√ºhrt Datenbanken auf denselben virtuellen Maschinen aus, die in <a href="https://cloud.yandex.ru/services/compute">Yandex Compute Cloud</a> bereitgestellt werden. <br><br><img src="https://habrastorage.org/webt/-w/gm/qj/-wgmqjlxi30m4jz7dgp4sct86cw.png" alt="Bild"><br><br>  Zun√§chst wird dort eine Datenbank-Engine, beispielsweise PostgreSQL, implementiert.  Parallel k√∂nnen verschiedene Hilfsprogramme gestartet werden.  F√ºr PostgreSQL ist dies <a href="https://github.com/yandex/odyssey">Odyssey</a> , der Datenbankverbindungs-Puller. <br><br>  Auch innerhalb der virtuellen Maschine wird eine bestimmte Standardgruppe von Diensten gestartet, die f√ºr jedes DBMS eine eigene ist: <br><br><ul><li>  Dienst zum Erstellen von Backups.  F√ºr PostgreSQL ist es ein Open-Source <a href="https://github.com/wal-g/wal-g">-</a> Tool f√ºr <a href="https://github.com/wal-g/wal-g">WAL-G.</a>  Es erstellt Backups und speichert sie im <a href="https://cloud.yandex.ru/services/storage">Yandex Object Storage</a> . </li><li>  Salt Minion ist eine Komponente des <a href="https://docs.saltstack.com/en/getstarted/">SaltStack-</a> Systems f√ºr Betriebs- und Konfigurationsmanagement.  Weitere Informationen hierzu finden Sie weiter unten in der Beschreibung der Bereitstellungsinfrastruktur. </li><li>  MDB-Metriken, die f√ºr die √úbertragung von Datenbankmetriken an <a href="https://cloud.yandex.ru/services/monitoring">Yandex Monitoring</a> und an unseren Microservice verantwortlich sind, um den Status von MDB-Integrit√§tsclustern und -Hosts zu √ºberwachen. </li><li>  Der Push-Client, der DBMS-Protokolle und Abrechnungsprotokolle an den Logbroker-Service sendet, ist eine spezielle L√∂sung zum Sammeln und Liefern von Daten. </li><li>  MDB Cron - unser Fahrrad, das sich von dem √ºblichen Cron in der F√§higkeit unterscheidet, periodische Aufgaben mit einer Genauigkeit von einer Sekunde auszuf√ºhren. </li></ul><br><h3>  Netzwerktopologie </h3><br><img src="https://habrastorage.org/webt/x8/_6/ge/x8_6ge0uluxqju22unryyrxxhxw.png" alt="Bild"><br><br>  Jeder Data Plane-Host verf√ºgt √ºber zwei Netzwerkschnittstellen: <br><br><ul><li>  Einer von ihnen steckt im Netzwerk des Benutzers.  Im Allgemeinen ist es erforderlich, die Produktladung zu warten.  Durch sie jagt die Replikation. </li><li>  Der zweite Teil befindet sich in einem unserer verwalteten Netzwerke, √ºber das Hosts zur Steuerungsebene wechseln. </li></ul><br>  Ja, Hosts verschiedener Clients sitzen in einem solchen verwalteten Netzwerk fest, aber das ist nicht be√§ngstigend, da auf der verwalteten Schnittstelle (fast) nichts √ºberwacht wird und ausgehende Netzwerkverbindungen in der Steuerungsebene nur von dort ge√∂ffnet werden.  Fast niemand, da es offene Ports gibt (z. B. SSH), die jedoch von einer lokalen Firewall geschlossen werden, die nur Verbindungen von bestimmten Hosts zul√§sst.  Wenn ein Angreifer Zugriff auf eine virtuelle Maschine mit einer Datenbank erh√§lt, kann er daher nicht auf die Datenbanken anderer Personen zugreifen. <br><br><h3>  Sicherheit der Datenebene </h3><br>  Da es sich um Sicherheit handelt, muss gesagt werden, dass wir den Dienst urspr√ºnglich so konzipiert haben, dass der Angreifer auf der virtuellen Cluster-Maschine root wird. <br><br>  Am Ende haben wir viel M√ºhe darauf verwendet, Folgendes zu tun: <br><br><ul><li>  Lokale und gro√üe Firewall; </li><li>  Verschl√ºsselung aller Verbindungen und Backups; </li><li>  Alle mit Authentifizierung und Autorisierung; </li><li>  AppArmor </li><li>  Selbstgeschriebene IDS. </li></ul><br>  Betrachten Sie nun die Komponenten der Steuerebene. <br><br><h2>  Steuerebene </h2><br><h3>  Interne API </h3><br>  Die interne API ist der erste Einstiegspunkt in die Steuerebene.  Mal sehen, wie alles hier funktioniert. <br><br><img src="https://habrastorage.org/webt/vb/ru/j7/vbruj7qxxu2tmlaplki2dt_74cy.png" alt="Bild"><br><br>  Angenommen, die interne API empf√§ngt eine Anforderung zum Erstellen eines Datenbankclusters. <br><br>  Zun√§chst greift die interne API auf den Cloud-Dienst Access Service zu, der f√ºr die √úberpr√ºfung der Authentifizierung und Autorisierung des Benutzers zust√§ndig ist.  Wenn der Benutzer die √úberpr√ºfung besteht, √ºberpr√ºft die interne API die G√ºltigkeit der Anforderung selbst.  Beispiel: Eine Anforderung zum Erstellen eines Clusters ohne Angabe des Namens oder mit einem bereits belegten Namen besteht den Test nicht. <br><blockquote>  Die interne API kann Anforderungen an die API anderer Dienste senden.  Wenn Sie einen Cluster in einem bestimmten Netzwerk A und einen bestimmten Host in einem bestimmten Subnetz B erstellen m√∂chten, muss die interne API sicherstellen, dass Sie sowohl f√ºr Netzwerk A als auch f√ºr das angegebene Subnetz B Rechte haben. Gleichzeitig wird √ºberpr√ºft, ob Subnetz B zu Netzwerk A geh√∂rt Dies erfordert den Zugriff auf die Infrastruktur-API. </blockquote><br>  Wenn die Anforderung g√ºltig ist, werden Informationen zum erstellten Cluster in der Metabasis gespeichert.  Wir nennen es MetaDB, es ist auf PostgreSQL implementiert.  MetaDB hat eine Tabelle mit einer Warteschlange von Operationen.  Die interne API speichert Informationen zum Vorgang und legt die Aufgabe transaktional fest.  Danach werden Informationen zum Vorgang an den Benutzer zur√ºckgegeben. <br><br>  Im Allgemeinen ist es f√ºr die Verarbeitung der meisten Anforderungen der internen API ausreichend, MetaDB und die API verwandter Dienste zu verwenden.  Es gibt jedoch zwei weitere Komponenten, die von der internen API zur Beantwortung einiger Abfragen verwendet werden: LogsDB, in der sich die Benutzerclusterprotokolle befinden, und MDB Health.  √úber jedes von ihnen wird unten ausf√ºhrlicher beschrieben. <br><br><h3>  Arbeiter </h3><br>  Worker sind einfach eine Reihe von Prozessen, die die Warteschlange von Vorg√§ngen in MetaDB abfragen, abrufen und ausf√ºhren. <br><br><img src="https://habrastorage.org/webt/ez/u7/q8/ezu7q86g82hjjt2nqrdssqhxpn0.png" alt="Bild"><br><br>  Was genau macht ein Worker, wenn ein Cluster erstellt wird?  Zun√§chst wendet er sich an die Infrastruktur-API, um aus unseren Images virtuelle Maschinen zu erstellen (auf diesen sind bereits alle erforderlichen Pakete installiert und die meisten Dinge sind konfiguriert, die Images werden einmal t√§glich aktualisiert).  Wenn die virtuellen Maschinen erstellt werden und das Netzwerk in ihnen startet, wendet sich der Mitarbeiter an die Bereitstellungsinfrastruktur (wir werden sp√§ter mehr dar√ºber erz√§hlen), um bereitzustellen, was der Benutzer f√ºr die virtuellen Maschinen ben√∂tigt. <br><br>  Dar√ºber hinaus greift der Mitarbeiter auf andere Cloud-Dienste zu.  B. an <a href="https://cloud.yandex.ru/services/storage">Yandex Object Storage</a> , um einen Bucket zu erstellen, in dem Clustersicherungen gespeichert werden.  An den <a href="https://cloud.yandex.ru/services/monitoring">Yandex-√úberwachungsdienst</a> , der Datenbankmetriken sammelt und visualisiert.  Der Arbeiter muss dort Cluster-Metainformationen erstellen.  An die DNS-API, wenn der Benutzer den Cluster-Hosts √∂ffentliche IP-Adressen zuweisen m√∂chte. <br><br>  Im Allgemeinen arbeitet der Arbeiter sehr einfach.  Es empf√§ngt die Aufgabe aus der Metabasiswarteschlange und greift auf den gew√ºnschten Dienst zu.  Nach Abschluss jedes Schritts speichert der Worker Informationen zum Fortschritt des Vorgangs in der Metabasis.  Wenn ein Fehler auftritt, wird der Task einfach neu gestartet und an der Stelle ausgef√ºhrt, an der er aufgeh√∂rt hat.  Aber auch ein Neustart von Anfang an ist kein Problem, da fast alle Arten von Aufgaben f√ºr die Mitarbeiter ohne Zutun geschrieben werden.  Dies liegt daran, dass der Worker den einen oder anderen Schritt des Vorgangs ausf√ºhren kann, in MetaDB jedoch keine Informationen dazu vorhanden sind. <br><br><h3>  Infrastruktur bereitstellen </h3><br>  Ganz unten befindet sich <a href="https://docs.saltstack.com/en/getstarted/">SaltStack</a> , ein ziemlich verbreitetes Open-Source-Konfigurationsmanagementsystem, das in Python geschrieben wurde.  Das System ist sehr <a href="https://docs.saltstack.com/en/latest/ref/index.html">erweiterbar</a> , wof√ºr wir es lieben. <br><br>  Die Hauptkomponenten von Salt sind Salt Master, in dem Informationen dar√ºber gespeichert werden, was und wo angewendet werden soll, und Salt Minion, ein Agent, der auf jedem Host installiert ist, interagiert mit dem Master und kann das Salz direkt vom Salt Master auf den Host anwenden.  F√ºr die Zwecke dieses Artikels verf√ºgen wir √ºber ausreichende Kenntnisse. Weitere <a href="https://docs.saltstack.com/en/getstarted/overview.html">Informationen</a> finden Sie in der <a href="https://docs.saltstack.com/en/getstarted/overview.html">SaltStack-Dokumentation</a> . <br><br>  Ein Salzmeister ist nicht fehlertolerant und kann nicht auf Tausende von Dienern skaliert werden. Es werden mehrere Meister ben√∂tigt.  Die direkte Interaktion mit dem Worker ist unpraktisch, und wir haben unsere Bindungen auf Salt geschrieben, das wir das Deploy-Framework nennen. <br><br><img src="https://habrastorage.org/webt/ir/x6/8o/irx68o0wo493tgj6o8xh0xj0x3o.png" alt="Bild"><br><br>  F√ºr den Worker ist der einzige Einstiegspunkt die Deploy-API, die Methoden wie "Anwenden des gesamten Status oder seiner einzelnen Teile auf solche Minions" und "Informieren Sie sich √ºber den Status eines solchen und eines solchen Roll-outs" implementiert.  Die Deploy-API speichert Informationen zu allen Rollouts und ihren spezifischen Schritten in DeployDB, wo wir auch PostgreSQL verwenden.  Dort werden auch Informationen √ºber alle Diener und Meister sowie √ºber die Zugeh√∂rigkeit des Ersten zum Zweiten gespeichert. <br><br>  Zwei zus√§tzliche Komponenten sind auf Salzmastern installiert: <br><br><ul><li>  <a href="https://docs.saltstack.com/en/develop/ref/netapi/all/salt.netapi.rest_cherrypy.html">Salt REST API</a> , mit der Deploy API interagiert, um Rollouts zu starten.  Die REST-API geht an den lokalen Salt-Master und er kommuniziert bereits mit Minions unter Verwendung von ZeroMQ. </li><li>  Das Wesentliche ist, dass es an die Deploy-API geht und die √∂ffentlichen Schl√ºssel aller Minions erh√§lt, die mit diesem Salt-Master verbunden sein m√ºssen.  Ohne einen √∂ffentlichen Schl√ºssel auf dem Master kann sich der Minion einfach nicht mit dem Master verbinden. </li></ul><br>  Neben Salt Minion sind zwei Komponenten in der Datenebene installiert: <br><br><ul><li>  <a href="https://docs.saltstack.com/en/latest/ref/returners/">Returner</a> - ein Modul (einer der erweiterbaren Teile in Salt), das das Ergebnis des Rollouts nicht nur auf den Salt-Master, sondern auch auf die Deploy-API √ºbertr√§gt.  Deploy API (API bereitstellen) leitet die Bereitstellung √ºber die REST-API des Assistenten ein und empf√§ngt das Ergebnis vom Minion √ºber den Returner. </li><li>  Master-Pinger, der regelm√§√üig die Deploy-API abfragt, mit der Master-Minions verbunden werden sollen.  Wenn die Bereitstellungs-API eine neue Adresse des Assistenten zur√ºckgibt (z. B. weil die alte Adresse tot oder √ºberlastet ist), konfiguriert Pinger den Minion neu. </li></ul><br>  Ein weiterer Ort, an dem wir die SaltStack-Erweiterbarkeit verwenden, ist <a href="https://docs.saltstack.com/en/latest/ref/pillar/all/index.html">ext_pillar</a> - die M√∂glichkeit, von au√üen auf die <a href="https://docs.saltstack.com/en/latest/topics/tutorials/pillar.html">S√§ule</a> <a href="https://docs.saltstack.com/en/latest/ref/pillar/all/index.html">zuzugreifen</a> (einige statische Informationen, z. B. die Konfiguration von PostgreSQL, Benutzern, Datenbanken, Erweiterungen usw.).  Wir rufen die interne API unseres Moduls auf, um clusterspezifische Einstellungen abzurufen, da diese in MetaDB gespeichert sind. <br><br>  Unabh√§ngig davon weisen wir darauf hin, dass die S√§ule auch vertrauliche Informationen enth√§lt (Benutzerkennw√∂rter, TLS-Zertifikate, GPG-Schl√ºssel zum Verschl√ºsseln von Sicherungen). Daher wird zum einen die gesamte Interaktion zwischen allen Komponenten verschl√ºsselt (nicht in einer unserer Datenbanken) kommen √ºberall ohne TLS, HTTPS, der Minion und der Master verschl√ºsseln auch den gesamten Verkehr).  Und zweitens werden alle diese Geheimnisse in MetaDB verschl√ºsselt, und wir verwenden die Trennung von Geheimnissen - auf den internen API-Maschinen gibt es einen √∂ffentlichen Schl√ºssel, der alle Geheimnisse verschl√ºsselt, bevor sie in MetaDB gespeichert werden, und der private Teil davon liegt auf Salt Masters und nur sie k√∂nnen erhalten offene Geheimnisse f√ºr die √úbertragung als S√§ule an einen Diener (wiederum √ºber einen verschl√ºsselten Kanal). <br><br><h3>  MDB Gesundheit </h3><br>  Wenn Sie mit Datenbanken arbeiten, ist es hilfreich, deren Status zu kennen.  Daf√ºr haben wir den Microservice MDB Health.  Es empf√§ngt Hoststatusinformationen von der internen Komponente der MDBs der virtuellen Maschine und speichert sie in einer eigenen Datenbank (in diesem Fall Redis).  Wenn in der internen API eine Anforderung zum Status eines bestimmten Clusters eingeht, verwendet die interne API Daten aus MetaDB und MDB Health. <br><br><img width="500" src="https://habrastorage.org/webt/ee/su/qu/eesuquvflpn5k_frgbcqlakkfkc.png" alt="Bild"><br><br>  Informationen zu allen Hosts werden verarbeitet und in der API in verst√§ndlicher Form dargestellt.  Zus√§tzlich zum Status von Hosts und Clustern f√ºr einige DBMS gibt MDB Health zus√§tzlich zur√ºck, ob ein bestimmter Host ein Master oder ein Replikat ist. <br><br><h3>  MDB DNS </h3><br>  Der MDB-DNS-Microservice wird zum Verwalten von CNAME-Eintr√§gen ben√∂tigt.  Wenn der Treiber f√ºr die Verbindung zur Datenbank die √úbertragung mehrerer Hosts in der Verbindungszeichenfolge nicht zul√§sst, k√∂nnen Sie eine Verbindung zu einem speziellen <a href="https://cloud.yandex.ru/docs/managed-mysql/operations/connect">CNAME herstellen</a> , der immer den aktuellen Master im Cluster angibt.  Wenn der Master wechselt, √§ndert sich der CNAME. <br><br><img width="500" src="https://habrastorage.org/webt/2y/g2/sd/2yg2sd8z2cgvuy9spzxo00w3eoy.png" alt="Bild"><br><br>  Wie l√§uft das  Wie bereits erw√§hnt, befindet sich in der virtuellen Maschine ein MDB-Cron, der regelm√§√üig einen Heartbeat mit den folgenden Inhalten an den MDB-DNS sendet: "In diesem Cluster muss der CNAME-Datensatz auf mich verweisen."  MDB DNS akzeptiert solche Nachrichten von allen virtuellen Maschinen und entscheidet, ob CNAME-Eintr√§ge ge√§ndert werden sollen.  Bei Bedarf wird der Eintrag √ºber die DNS-API ge√§ndert. <br><br>  Warum haben wir daf√ºr einen separaten Service gemacht?  Weil die DNS-API nur auf Zonenebene Zugriffskontrolle hat.  Ein potenzieller Angreifer, der Zugriff auf eine separate virtuelle Maschine erh√§lt, kann die CNAME-Eintr√§ge anderer Benutzer √§ndern.  MDB-DNS schlie√üt dieses Szenario aus, da die Autorisierung √ºberpr√ºft wird. <br><br><h3>  Lieferung und Anzeige von Datenbankprotokollen </h3><br>  Wenn die Datenbank auf der virtuellen Maschine in das Protokoll schreibt, liest die spezielle Push-Client-Komponente diesen Datensatz und sendet die soeben angezeigte Zeile an Logbroker ( <a href="https://habr.com/ru/company/yandex/blog/239823/">sie haben bereits</a> in Habr√© dar√ºber geschrieben).  Die Interaktion des Push-Clients mit LogBroker wird mit genau einer Semantik erstellt: Wir werden sie auf jeden Fall senden und dies auf jeden Fall einmal tun. <br><br>  Ein separater Maschinenpool - LogConsumers - entnimmt Protokolle aus der LogBroker-Warteschlange und speichert sie in der LogsDB-Datenbank.  ClickHouse DBMS wird f√ºr die Protokolldatenbank verwendet. <br><br><img width="500" src="https://habrastorage.org/webt/w-/zc/mr/w-zcmrza7z9pg6gacszmpm0kojo.png" alt="Bild"><br><br>  Wenn eine Anforderung an die interne API gesendet wird, um Protokolle f√ºr ein bestimmtes Zeitintervall f√ºr einen bestimmten Cluster anzuzeigen, √ºberpr√ºft die interne API die Autorisierung und sendet die Anforderung an LogsDB.  Somit ist die Protokoll√ºbermittlungsschleife vollst√§ndig unabh√§ngig von der Protokollanzeigeschleife. <br><br><h3>  Abrechnung </h3><br>  Das Abrechnungsschema ist √§hnlich aufgebaut.  Innerhalb der virtuellen Maschine gibt es eine Komponente, die mit einer bestimmten Periodizit√§t pr√ºft, ob in der Datenbank alles in Ordnung ist.  Wenn alles in Ordnung ist, k√∂nnen Sie dieses Zeitintervall ab dem Zeitpunkt des letzten Starts abrechnen.  In diesem Fall wird ein Datensatz im Abrechnungsprotokoll erstellt, und der Push-Client sendet den Datensatz an LogBroker.  Die Daten von Logbroker werden an das Abrechnungssystem √ºbertragen und dort berechnet.  Dies ist ein Abrechnungsschema f√ºr die Ausf√ºhrung von Clustern. <br><br>  Wenn der Cluster deaktiviert ist, wird die Nutzung der Computerressourcen nicht mehr berechnet, der Speicherplatz wird jedoch berechnet.  In diesem Fall ist eine Abrechnung von der virtuellen Maschine nicht m√∂glich, und es handelt sich um die zweite Schaltung - die Offline-Abrechnungsschaltung.  Es gibt einen separaten Pool von Computern, die die Liste der Shutdown-Cluster aus MetaDB abrufen und in Logbroker ein Protokoll im gleichen Format schreiben. <br><br>  Die Offline-Abrechnung kann auch f√ºr die Abrechnung von Rechnungen und eingeschlossenen Clustern verwendet werden. Dann stellen wir Hosts Abrechnungen, auch wenn diese ausgef√ºhrt werden, aber nicht funktionieren.  Wenn Sie beispielsweise einem Cluster einen Host hinzuf√ºgen, wird dieser aus der Sicherung bereitgestellt und die Replikation wird fortgesetzt.  Es ist falsch, dies dem Benutzer in Rechnung zu stellen, da der Host f√ºr diesen Zeitraum inaktiv ist. <br><br><img width="500" src="https://habrastorage.org/webt/fa/gx/hw/fagxhwoaqe0fb5q60chfthefkv8.png" alt="Bild"><br><br><h3>  Backup </h3><br>  Das Sicherungsschema kann sich f√ºr verschiedene DBMS geringf√ºgig unterscheiden, das allgemeine Prinzip ist jedoch immer dasselbe. <br><br>  Jedes Datenbankmodul verwendet ein eigenes Sicherungstool.  F√ºr PostgreSQL und MySQL ist dies <a href="https://github.com/wal-g/wal-g">WAL-G</a> .  Es erstellt Backups, komprimiert sie, verschl√ºsselt sie und legt sie in <a href="https://cloud.yandex.ru/services/storage">Yandex Object Storage ab</a> .  Gleichzeitig wird jeder Cluster in einem separaten Bucket abgelegt (zum einen zur Isolierung und zum anderen, um Speicherplatz f√ºr Sicherungen zu sparen) und mit einem eigenen Verschl√ºsselungsschl√ºssel verschl√ºsselt. <br><br><img width="500" src="https://habrastorage.org/webt/mf/dh/w0/mfdhw0bgyo59pytnhaqkaqghbou.png" alt="Bild"><br><br>  So funktionieren Control Plane und Data Plane.  Daraus wird der verwaltete Datenbankdienst Yandex.Cloud gebildet. <br><br><h2>  Warum ist alles so angeordnet? </h2><br>  Nat√ºrlich k√∂nnte auf globaler Ebene etwas nach einfacheren Schemata implementiert werden.  Aber wir hatten unsere eigenen Gr√ºnde, dem Weg des geringsten Widerstands nicht zu folgen. <br><br>  Zun√§chst wollten wir eine gemeinsame Steuerungsebene f√ºr alle Arten von DBMS.  Es spielt keine Rolle, f√ºr welche Sie sich entscheiden, am Ende wird Ihre Anfrage an dieselbe interne API gesendet, und alle Komponenten darunter sind auch allen DBMS gemeinsam.  Das macht unser Leben technisch etwas komplizierter.  Andererseits ist es viel einfacher, neue Funktionen und F√§higkeiten einzuf√ºhren, die alle DBMS betreffen.  Dies wird einmal gemacht, nicht sechs. <br><br>  Der zweite wichtige Moment f√ºr uns - wir wollten die Unabh√§ngigkeit der Datenebene von der Kontrollebene so weit wie m√∂glich sicherstellen.  Selbst wenn Control Plane heute nicht mehr verf√ºgbar ist, funktionieren alle Datenbanken weiterhin.  Der Service stellt deren Zuverl√§ssigkeit und Verf√ºgbarkeit sicher. <br><br>  Drittens ist die Entwicklung fast aller Dienste immer ein Kompromiss.  Im Allgemeinen ist grob gesagt die Geschwindigkeit der Ver√∂ffentlichung von Ver√∂ffentlichungen und eine zus√§tzliche Zuverl√§ssigkeit von gr√∂√üerer Bedeutung.  Zur gleichen Zeit kann es sich jetzt niemand mehr leisten, ein oder zwei Ver√∂ffentlichungen pro Jahr zu machen, das ist offensichtlich.  Wenn Sie sich Control Plane anschauen, konzentrieren wir uns hier auf die Geschwindigkeit der Entwicklung, auf die schnelle Einf√ºhrung neuer Funktionen und darauf, Updates mehrmals pro Woche einzuf√ºhren.  Und Data Plane ist verantwortlich f√ºr die Sicherheit Ihrer Datenbanken und f√ºr die Fehlertoleranz. Daher gibt es hier einen v√∂llig anderen Release-Zyklus, der in Wochen gemessen wird.  Und diese Flexibilit√§t in Bezug auf die Entwicklung gibt uns auch die gegenseitige Unabh√§ngigkeit. <br><br>  Ein weiteres Beispiel: In der Regel stellen verwaltete Datenbankdienste Benutzern nur Netzlaufwerke zur Verf√ºgung.  Yandex.Cloud bietet auch lokale Laufwerke an.  Der Grund ist einfach: Ihre Geschwindigkeit ist viel h√∂her.  Mit Netzwerklaufwerken ist es beispielsweise einfacher, die virtuelle Maschine zu vergr√∂√üern und zu verkleinern.  Es ist einfacher, Backups in Form von Snapshots des Netzwerkspeichers zu erstellen.  Viele Benutzer ben√∂tigen jedoch eine hohe Geschwindigkeit, weshalb wir die Sicherungswerkzeuge weiterentwickeln. <br><br><h2>  Zukunftspl√§ne </h2><br>  Und ein paar Worte zu Pl√§nen, den Service mittelfristig zu verbessern.  Hierbei handelt es sich um Pl√§ne, die sich auf die gesamte verwaltete Datenbank von Yandex und nicht auf einzelne DBMS auswirken. <br><br>  Zun√§chst m√∂chten wir die H√§ufigkeit der Sicherungserstellung flexibler einstellen.  Es gibt Szenarien, in denen w√§hrend des Tages alle paar Stunden, w√§hrend der Woche, einmal am Tag, w√§hrend des Monats, einmal in der Woche, w√§hrend des Jahres, einmal im Monat Sicherungen durchgef√ºhrt werden m√ºssen.  Zu diesem Zweck entwickeln wir eine separate Komponente zwischen der internen API und <a href="https://cloud.yandex.ru/services/storage">Yandex Object Storage</a> . <br><br>  Ein weiterer wichtiger Punkt, der sowohl f√ºr die Benutzer als auch f√ºr uns wichtig ist, ist die Geschwindigkeit des Betriebs.  Wir haben k√ºrzlich wesentliche √Ñnderungen an der Bereitstellungsinfrastruktur vorgenommen und die Ausf√ºhrungszeit fast aller Vorg√§nge auf einige Sekunden reduziert.  Nicht behandelt wurden nur die Vorg√§nge zum Erstellen eines Clusters und zum Hinzuf√ºgen eines Hosts zum Cluster.  Die Ausf√ºhrungszeit der zweiten Operation h√§ngt von der Datenmenge ab.  Das erste Verfahren werden wir jedoch in naher Zukunft beschleunigen, da Benutzer h√§ufig Cluster in ihren CI / CD-Pipelines erstellen und l√∂schen m√∂chten. <br><br>  Unsere Liste wichtiger F√§lle umfasst die Hinzuf√ºgung der Funktion zum automatischen Erh√∂hen der Festplattengr√∂√üe.  Dies geschieht nun manuell, was nicht sehr praktisch und nicht sehr gut ist. <br><br>  Schlie√ülich bieten wir den Benutzern eine Vielzahl von Grafiken, die zeigen, was mit der Datenbank passiert.  Wir geben Zugriff auf die Protokolle.  Gleichzeitig stellen wir fest, dass die Daten manchmal nicht ausreichen.  Ben√∂tigen Sie andere Grafiken, andere Scheiben.  Hier planen wir auch Verbesserungen. <br><br>  Unsere Geschichte √ºber den verwalteten Datenbankdienst erwies sich als langwierig und wahrscheinlich als ziemlich m√ºhsam.  Besser als alle Worte und Beschreibungen, nur echte Praxis.  Wenn Sie m√∂chten, k√∂nnen Sie daher die Leistungsf√§higkeit unserer Dienstleistungen unabh√§ngig voneinander bewerten: <br><br><ul><li>  <a href="https://cloud.yandex.ru/services/managed-postgresql">Yandex Managed Service f√ºr PostgreSQL</a> </li><li>  <a href="https://cloud.yandex.ru/services/managed-mysql">Yandex Managed Service f√ºr MySQL</a> </li><li>  <a href="https://cloud.yandex.ru/services/managed-mongodb">Yandex Managed Service f√ºr MongoDB</a> </li><li>  <a href="https://cloud.yandex.ru/services/managed-clickhouse">Yandex Managed Service f√ºr ClickHouse</a> </li><li>  <a href="https://cloud.yandex.ru/services/managed-redis">Yandex Managed Service f√ºr Redis</a> </li><li>  <a href="https://cloud.yandex.ru/services/data-proc">Yandex Data Proc</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de477860/">https://habr.com/ru/post/de477860/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de477848/index.html">Das kleine Geheimnis eines gro√üen Herzens: das erste Blauwal-Kardiogramm der Geschichte</a></li>
<li><a href="../de477852/index.html">Ungiftige Heuchelei</a></li>
<li><a href="../de477854/index.html">Was passiert beim Verbinden innerhalb und au√üerhalb eines VPN-Tunnels?</a></li>
<li><a href="../de477856/index.html">PCI-E-Flash-Beschleuniger von 800 GB bis 6,4 TB: von Anfang an ein normaler PC / Server</a></li>
<li><a href="../de477858/index.html">Off-Table-Arbeit: Welche Projekte kamen nach der Vorbeschleunigung wirklich zum Vorschein?</a></li>
<li><a href="../de477862/index.html">Und so war es m√∂glich? Wissenschaft und IT in einer Konferenz</a></li>
<li><a href="../de477866/index.html">Seminar: Hybride IT-L√∂sungen f√ºr Unternehmen. 5. Dezember, St. Petersburg</a></li>
<li><a href="../de477870/index.html">Grafana Armaturenbrett f√ºr BeerTender Biersystem</a></li>
<li><a href="../de477874/index.html">Dynamisches CDN f√ºr WebRTC-Streaming mit geringer Latenz und Transcodierung</a></li>
<li><a href="../de477876/index.html">Dynamisches CDN f√ºr WebRTC-Streaming mit geringer Latenz und Transcodierung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
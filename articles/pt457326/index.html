<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìö üòå ü§òüèΩ Cluster de Failover PostgreSQL + Patroni. Experi√™ncia de implementa√ß√£o üíõ ü§∑üèΩ üçº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, mostrarei como abordamos a quest√£o da toler√¢ncia a falhas do PostgreSQL, por que isso se tornou importante para n√≥s e o que aconteceu no...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cluster de Failover PostgreSQL + Patroni. Experi√™ncia de implementa√ß√£o</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/miro/blog/457326/">  Neste artigo, mostrarei como abordamos a quest√£o da toler√¢ncia a falhas do PostgreSQL, por que isso se tornou importante para n√≥s e o que aconteceu no final. <br><br>  Temos um servi√ßo altamente carregado: 2,5 milh√µes de usu√°rios em todo o mundo, mais de 50 mil usu√°rios ativos todos os dias.  Os servidores est√£o localizados na Amazone em uma regi√£o da Irlanda: existem constantemente mais de 100 servidores diferentes em opera√ß√£o, dos quais quase 50 est√£o com bancos de dados. <br><br>  Todo o back-end √© um grande aplicativo Java com estado monol√≠tico que mant√©m uma conex√£o constante de websocket com o cliente.  Com o trabalho simult√¢neo de v√°rios usu√°rios em um quadro, todos eles veem as altera√ß√µes em tempo real, porque registramos cada altera√ß√£o no banco de dados.  Temos aproximadamente 10 mil consultas por segundo em nossos bancos de dados.  No pico de carga no Redis, escrevemos de 80 a 100 mil consultas por segundo. <br><img src="https://habrastorage.org/webt/ef/pn/er/efpner_0rhtuim1zt0gwrhff3b8.png"><br><a name="habracut"></a><br><br><h2>  Por que mudamos de Redis para PostgreSQL </h2><br>  Inicialmente, nosso servi√ßo trabalhava com o Redis, um reposit√≥rio de valores-chave que armazena todos os dados na RAM do servidor. <br><br>  Pr√≥s da Redis: <br><br><ol><li>  Alta taxa de resposta, como  tudo √© armazenado na mem√≥ria; </li><li>  Conveni√™ncia de backup e replica√ß√£o. </li></ol><br>  Contras Redis for us: <br><br><ol><li>  N√£o h√° transa√ß√µes reais.  Tentamos simul√°-los no n√≠vel do nosso aplicativo.  Infelizmente, isso nem sempre funcionou bem e exigiu a cria√ß√£o de c√≥digo muito complexo. </li><li>  A quantidade de dados √© limitada pela quantidade de mem√≥ria.  √Ä medida que a quantidade de dados aumenta, a mem√≥ria aumenta e, no final, encontraremos as caracter√≠sticas da inst√¢ncia selecionada, que na AWS exige a interrup√ß√£o de nosso servi√ßo para alterar o tipo de inst√¢ncia. </li><li>  √â necess√°rio manter constantemente um baixo n√≠vel de lat√™ncia, pois  Temos um n√∫mero muito grande de solicita√ß√µes.  O n√≠vel de atraso ideal para n√≥s √© de 17 a 20 ms.  No n√≠vel de 30 a 40 ms, obtemos respostas longas para as solicita√ß√µes de nosso aplicativo e a degrada√ß√£o do servi√ßo.  Infelizmente, isso aconteceu conosco em setembro de 2018, quando uma das inst√¢ncias do Redis, por algum motivo, recebeu uma lat√™ncia 2 vezes maior que o normal.  Para resolver o problema, paramos o servi√ßo no meio do dia para manuten√ß√£o n√£o programada e substitu√≠mos a inst√¢ncia problem√°tica do Redis. </li><li>  √â f√°cil obter inconsist√™ncia de dados, mesmo com pequenos erros no c√≥digo, e gastar muito tempo escrevendo c√≥digo para corrigir esses dados. </li></ol><br>  Levamos em conta as desvantagens e percebemos que precisamos mudar para algo mais conveniente, com transa√ß√µes normais e menos depend√™ncia da lat√™ncia.  Realizou um estudo, analisou muitas op√ß√µes e escolheu o PostgreSQL. <br><br>  Estamos mudando para um novo banco de dados h√° 1,5 anos e transferimos apenas uma pequena parte dos dados. Agora, estamos trabalhando simultaneamente com Redis e PostgreSQL.  Mais informa√ß√µes sobre os est√°gios da movimenta√ß√£o e troca de dados entre bancos de dados est√£o escritas em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo do meu colega</a> . <br><br>  Quando come√ßamos a nos mover, nosso aplicativo trabalhava diretamente com o banco de dados e recorria ao assistente Redis e PostgreSQL.  O cluster do PostgreSQL consistia em um mestre e uma r√©plica de r√©plica ass√≠ncrona.  √â assim que o esquema de opera√ß√£o do banco de dados ficou: <br><img src="https://habrastorage.org/webt/wc/wg/ef/wcwgefzqham9mw7hm-5xc37pfp0.png"><br><br><h2>  Implanta√ß√£o do PgBouncer </h2><br>  Enquanto est√°vamos em movimento, o produto tamb√©m se desenvolveu: o n√∫mero de usu√°rios e o n√∫mero de servidores que trabalhavam com o PostgreSQL aumentaram, e come√ßamos a perder conex√µes.  O PostgreSQL cria um processo separado para cada conex√£o e consome recursos.  Voc√™ pode aumentar o n√∫mero de conex√µes at√© um determinado ponto; caso contr√°rio, h√° uma chance de obter uma opera√ß√£o n√£o ideal do banco de dados.  A op√ß√£o ideal nessa situa√ß√£o seria a escolha de um gerenciador de conex√µes que ficar√° na frente da base. <br><br>  T√≠nhamos duas op√ß√µes para o gerenciador de conex√µes: Pgpool e PgBouncer.  Mas o primeiro n√£o suporta o modo transacional de trabalhar com o banco de dados, por isso escolhemos o PgBouncer. <br><br>  Configuramos o seguinte esquema de trabalho: nosso aplicativo acessa um PgBouncer, seguido pelo Masters PostgreSQL e, por tr√°s de cada mestre, uma r√©plica com replica√ß√£o ass√≠ncrona. <br><img src="https://habrastorage.org/webt/ql/uq/vh/qluqvh64yeyzwvow79wc3tt0nm0.png"><br><br>  Ao mesmo tempo, n√£o pod√≠amos armazenar toda a quantidade de dados no PostgreSQL, e a velocidade de trabalho com o banco de dados era importante para n√≥s, por isso come√ßamos a compartilhar o PostgreSQL no n√≠vel do aplicativo.  O esquema descrito acima √© relativamente conveniente para isso: ao adicionar um novo shard PostgreSQL, basta atualizar a configura√ß√£o do PgBouncer e o aplicativo pode trabalhar imediatamente com o novo shard. <br><br><h3>  Toler√¢ncia a falhas do PgBouncer </h3><br>  Esse esquema funcionou at√© a √∫nica inst√¢ncia do PgBouncer morrer.  Estamos localizados na AWS, onde todas as inst√¢ncias s√£o executadas em hardware que morre periodicamente.  Nesses casos, a inst√¢ncia simplesmente muda para o novo hardware e funciona novamente.  Isso aconteceu com o PgBouncer, mas ficou indispon√≠vel.  O resultado dessa queda foi a inacessibilidade de nosso servi√ßo por 25 minutos.  A AWS recomenda o uso de redund√¢ncia no lado do usu√°rio para essas situa√ß√µes, que n√£o foram implementadas conosco naquele momento. <br><br>  Depois disso, pensamos seriamente na toler√¢ncia a falhas dos clusters PgBouncer e PostgreSQL, porque uma situa√ß√£o semelhante poderia acontecer novamente com qualquer inst√¢ncia em nossa conta da AWS. <br><br>  Criamos o esquema de toler√¢ncia a falhas do PgBouncer da seguinte maneira: todos os servidores de aplicativos acessam o Network Load Balancer, atr√°s do qual existem dois PgBouncer.  Cada um dos PgBouncer analisa o mesmo mestre PostgreSQL de cada fragmento.  Se a inst√¢ncia da AWS travar novamente, todo o tr√°fego ser√° redirecionado por outro PgBouncer.  Toler√¢ncia a falhas O Network Load Balancer fornece a AWS. <br><br>  Este esquema permite adicionar facilmente novos servidores PgBouncer. <br><img src="https://habrastorage.org/webt/05/uc/da/05ucdayudomunfsxjc_gggs5abe.png"><br><br><h2>  Criando um cluster de failover do PostgreSQL </h2><br>  Para solucionar esse problema, consideramos diferentes op√ß√µes: failover auto-escrito, repmgr, AWS RDS, Patroni. <br><br><h3>  Scripts auto-escritos </h3><br>  Eles podem monitorar o trabalho do mestre e, em caso de queda, promover a r√©plica para o mestre e atualizar a configura√ß√£o do PgBouncer. <br><br>  As vantagens dessa abordagem s√£o a simplicidade m√°xima, porque voc√™ mesmo escreve scripts e entende exatamente como eles funcionam. <br><br>  Contras: <br><br><ul><li>  O mestre pode n√£o morrer, mas pode ocorrer uma falha na rede.  O failover, sem saber isso, avan√ßar√° a r√©plica para o mestre e o antigo mestre continuar√° funcionando.  Como resultado, temos dois servidores na fun√ß√£o de mestre e n√£o sabemos qual deles possui os dados reais mais recentes.  Essa situa√ß√£o tamb√©m √© chamada de c√©rebro dividido; </li><li>  Ficamos sem uma r√©plica.  Em nossa configura√ß√£o, a r√©plica principal e uma, depois de alternar a r√©plica, ela se move para a principal e n√£o temos mais r√©plicas; portanto, precisamos adicionar manualmente uma nova r√©plica; </li><li>  Precisamos de monitoramento adicional da opera√ß√£o de failover, enquanto temos 12 shards PostgreSQL, o que significa que devemos monitorar 12 clusters.  Se voc√™ aumentar o n√∫mero de shards, ainda dever√° se lembrar de atualizar o failover. </li></ul><br>  O failover auto-escrito parece muito complicado e requer suporte n√£o trivial.  Com um √∫nico cluster do PostgreSQL, essa ser√° a op√ß√£o mais f√°cil, mas n√£o ser√° dimensionada, portanto, n√£o √© adequada para n√≥s. <br><br><h3>  Repmgr </h3><br>  Replication Manager para clusters do PostgreSQL, que podem gerenciar a opera√ß√£o de um cluster do PostgreSQL.  Ao mesmo tempo, n√£o h√° failover autom√°tico "pronto para uso", portanto, para o trabalho, voc√™ precisar√° escrever seu pr√≥prio "inv√≥lucro" sobre a solu√ß√£o finalizada.  Portanto, tudo pode ficar ainda mais complicado do que com scripts auto-escritos, ent√£o nem tentamos o Repmgr. <br><br><h3>  AWS RDS </h3><br>  Ele suporta tudo o que voc√™ precisa para n√≥s, sabe como fazer backup e suporta um pool de conex√µes.  Possui comuta√ß√£o autom√°tica: ap√≥s a morte do mestre, a r√©plica se torna o novo mestre e a AWS altera o registro de DNS para o novo mestre, enquanto as r√©plicas podem estar em AZs diferentes. <br><br>  As desvantagens incluem a falta de configura√ß√µes sutis.  Como um exemplo de ajuste fino: em nossas inst√¢ncias existem restri√ß√µes para conex√µes tcp, que, infelizmente, n√£o podem ser feitas no RDS: <br><br><pre><code class="python hljs">net.ipv4.tcp_keepalive_time=<span class="hljs-number"><span class="hljs-number">10</span></span> net.ipv4.tcp_keepalive_intvl=<span class="hljs-number"><span class="hljs-number">1</span></span> net.ipv4.tcp_keepalive_probes=<span class="hljs-number"><span class="hljs-number">5</span></span> net.ipv4.tcp_retries2=<span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br>  Al√©m disso, o pre√ßo do AWS RDS √© quase duas vezes superior ao pre√ßo da inst√¢ncia regular, que foi o principal motivo para rejeitar essa decis√£o. <br><br><h3>  Patroni </h3><br>  Este √© um modelo python para gerenciar o PostgreSQL com boa documenta√ß√£o, failover autom√°tico e c√≥digo fonte do github. <br><br>  Pr√≥s de Patroni: <br><br><ul><li>  Cada par√¢metro de configura√ß√£o √© pintado, √© claro como funciona; </li><li>  O failover autom√°tico funciona imediatamente; </li><li>  Est√° escrito em python e, como escrevemos muito em python, ser√° mais f√°cil lidar com problemas e, possivelmente, at√© ajudar no desenvolvimento do projeto; </li><li>  Ele controla totalmente o PostgreSQL, permite alterar a configura√ß√£o em todos os n√≥s do cluster de uma s√≥ vez e, se for necess√°ria uma reinicializa√ß√£o do cluster para aplicar a nova configura√ß√£o, isso poder√° ser feito novamente usando o Patroni. </li></ul><br>  Contras: <br><br><ul><li>  Na documenta√ß√£o, n√£o est√° claro como trabalhar com o PgBouncer.  Embora seja dif√≠cil cham√°-lo de menos, porque a tarefa do Patroni √© gerenciar o PostgreSQL, e como ser√£o as conex√µes com o Patroni √© nosso problema; </li><li>  Existem poucos exemplos de implementa√ß√£o do Patroni em grandes volumes, enquanto muitos exemplos de implementa√ß√£o do zero. </li></ul><br>  Como resultado, para criar um cluster de failover, escolhemos o Patroni. <br><br><h2>  Processo de Implementa√ß√£o Patroni </h2><br>  Antes do Patroni, t√≠nhamos 12 shards do PostgreSQL em configura√ß√£o, um mestre e uma r√©plica com replica√ß√£o ass√≠ncrona.  Os servidores de aplicativos acessaram os bancos de dados atrav√©s do Network Load Balancer, atr√°s do qual havia duas inst√¢ncias com o PgBouncer, e atr√°s deles havia todos os servidores PostgreSQL. <br><img src="https://habrastorage.org/webt/05/uc/da/05ucdayudomunfsxjc_gggs5abe.png"><br><br>  Para implementar o Patroni, precisamos selecionar um reposit√≥rio de configura√ß√£o de cluster distribu√≠do.  Patroni trabalha com sistemas de armazenamento de configura√ß√£o distribu√≠da, como etcd, Zookeeper, Consul.  Temos apenas um cluster de c√¥nsul completo em produtos que funciona em conjunto com o Vault e n√£o o usamos mais.  Um √≥timo motivo para come√ßar a usar o Consul para a finalidade a que se destina. <br><br><h3>  Como Patroni trabalha com o Consul </h3><br>  Temos um cluster Consul, que consiste em tr√™s n√≥s, e um cluster Patroni, que consiste em um l√≠der e uma r√©plica (em Patroni, um mestre √© chamado l√≠der de cluster e os escravos s√£o chamados r√©plicas).  Cada inst√¢ncia de um cluster Patroni envia constantemente informa√ß√µes de status do cluster ao Consul.  Portanto, no Consul voc√™ sempre pode descobrir a configura√ß√£o atual do cluster Patroni e quem √© o l√≠der no momento. <br><br><img src="https://habrastorage.org/webt/jx/j5/is/jxj5ispkzoegn8x80dw-qtynw3q.png"><br><br>  Para conectar o Patroni ao Consul, basta estudar a documenta√ß√£o oficial, que diz que voc√™ precisa especificar o host no formato http ou https, dependendo de como trabalhamos com o Consul e o esquema de conex√£o, opcionalmente: <br><br><pre> <code class="plaintext hljs">host: the host:port for the Consul endpoint, in format: http(s)://host:port scheme: (optional) http or https, defaults to http</code> </pre> <br>  Parece simples, mas aqui come√ßam as armadilhas.  Com o Consul, estamos trabalhando em uma conex√£o segura via https e nossa configura√ß√£o de conex√£o ficar√° assim: <br><br><pre> <code class="python hljs">consul: host: https://server.production.consul:<span class="hljs-number"><span class="hljs-number">8080</span></span> verify: true cacert: {{ consul_cacert }} cert: {{ consul_cert }} key: {{ consul_key }}</code> </pre> <br>  Mas isso n√£o funciona.  No in√≠cio, Patroni n√£o pode se conectar ao Consul, porque tenta seguir o http de qualquer maneira. <br><br>  O c√≥digo fonte do Patroni ajudou a lidar com o problema.  Ainda bem que est√° escrito em python.  Acontece que o par√¢metro host n√£o √© analisado e o protocolo deve ser especificado no esquema.  Aqui est√° o bloco de configura√ß√£o de trabalho para trabalhar com a Consul conosco: <br><br><pre> <code class="python hljs">consul: host: server.production.consul:<span class="hljs-number"><span class="hljs-number">8080</span></span> scheme: https verify: true cacert: {{ consul_cacert }} cert: {{ consul_cert }} key: {{ consul_key }}</code> </pre> <br><h3>  Consul-template </h3><br>  Portanto, escolhemos o armazenamento para uma configura√ß√£o.  Agora voc√™ precisa entender como o PgBouncer mudar√° sua configura√ß√£o ao alterar o l√≠der no cluster Patroni.  A documenta√ß√£o n√£o responde a essa pergunta, porque  l√°, em princ√≠pio, o trabalho com o PgBouncer n√£o √© descrito. <br><br>  Em busca de uma solu√ß√£o, encontramos um artigo (infelizmente n√£o lembro o nome), onde estava escrito que o modelo do Consul ajudou bastante na conex√£o do PgBouncer e Patroni.  Isso nos levou a estudar o trabalho do modelo do c√¥nsul. <br><br>  Aconteceu que o Consul-template monitora constantemente a configura√ß√£o do cluster PostgreSQL no Consul.  Quando o l√≠der muda, ele atualiza a configura√ß√£o do PgBouncer e envia um comando para reinici√°-lo. <br><br><img src="https://habrastorage.org/webt/iv/_f/j-/iv_fj-sjbnqtfabqlnmu986sa0o.png"><br><br>  A grande vantagem do modelo √© que ele √© armazenado como c√≥digo; portanto, ao adicionar um novo shard, basta fazer uma nova confirma√ß√£o e atualizar o modelo no modo autom√°tico, suportando o princ√≠pio de Infraestrutura como c√≥digo. <br><br><h3>  Nova arquitetura com Patroni </h3><br>  Como resultado, obtivemos este esquema de trabalho: <br><img src="https://habrastorage.org/webt/7b/-m/-v/7b-m-vyorrbbuognzt2qx2-fymm.png"><br><br>  Todos os servidores de aplicativos recorrem ao balanceador ‚Üí duas inst√¢ncias do PgBouncer est√£o por tr√°s dele ‚Üí em cada inst√¢ncia √© iniciado um onsul-template, que monitora o status de cada cluster Patroni e monitora a relev√¢ncia da configura√ß√£o do PgBouncer, que envia solicita√ß√µes ao l√≠der atual de cada cluster. <br><br><h3>  Teste manual </h3><br>  Antes de iniciar o programa, lan√ßamos esse circuito em um pequeno ambiente de teste e verificamos a opera√ß√£o da comuta√ß√£o autom√°tica.  Eles abriram o quadro, moveram o adesivo e naquele momento "mataram" o l√≠der do grupo.  Na AWS, basta desativar a inst√¢ncia pelo console. <br><br><img src="https://habrastorage.org/webt/ly/yf/aj/lyyfaj6bxodfoaqrsds5j00ycnw.gif"><br><br>  O adesivo retornou de 10 a 20 segundos e come√ßou a se mover normalmente.  Isso significa que o cluster Patroni funcionou corretamente: ele mudou o l√≠der, enviou as informa√ß√µes ao Consul e o modelo do Consul imediatamente pegou essas informa√ß√µes, substituiu a configura√ß√£o do PgBouncer e enviou o comando para recarregar. <br><br><h2>  Como sobreviver sob alta carga e manter um tempo de inatividade m√≠nimo? </h2><br>  Tudo funciona muito bem!  Mas surgem novas quest√µes: como isso funcionar√° sob alta carga?  Como lan√ßar tudo com rapidez e seguran√ßa na produ√ß√£o? <br><br>  O ambiente de teste no qual realizamos o teste de carga nos ajuda a responder √† primeira pergunta.  √â completamente id√™ntico √† produ√ß√£o em arquitetura e gerou dados de teste, que s√£o aproximadamente iguais em volume √† produ√ß√£o.  Decidimos simplesmente "matar" um dos assistentes do PostgreSQL durante o teste e ver o que acontece.  Por√©m, antes disso, √© importante verificar a rolagem autom√°tica, porque nesse ambiente temos v√°rios shards do PostgreSQL, para que possamos realizar excelentes testes de scripts de configura√ß√£o antes da venda. <br><br>  Ambas as tarefas parecem ambiciosas, mas temos o PostgreSQL 9.6.  Talvez possamos atualizar imediatamente para 11.2? <br><br>  Decidimos fazer isso em duas etapas: primeiro atualize para 11.2 e, em seguida, inicie o Patroni. <br><br><h3>  Atualiza√ß√£o do PostgreSQL </h3><br>  Para atualizar rapidamente a vers√£o do PostgreSQL, voc√™ deve usar a op√ß√£o <b>-k</b> , que cria um link f√≠sico no disco e n√£o √© necess√°rio copiar seus dados.  Em bases de 300 a 400 GB, a atualiza√ß√£o leva 1 segundo. <br><br>  Como temos muitos shards, a atualiza√ß√£o precisa ser feita automaticamente.  Para fazer isso, escrevemos o manual do Ansible, que executa todo o processo de atualiza√ß√£o para n√≥s: <br><br><pre> <code class="plaintext hljs">/usr/lib/postgresql/11/bin/pg_upgrade \ &lt;b&gt;--link \&lt;/b&gt; --old-datadir='' --new-datadir='' \ --old-bindir='' --new-bindir='' \ --old-options=' -c config_file=' \ --new-options=' -c config_file='</code> </pre> <br>  √â importante observar aqui que, antes de iniciar a atualiza√ß√£o, √© necess√°rio execut√°-la com o par√¢metro <b>--check</b> para garantir a possibilidade de uma atualiza√ß√£o.  Nosso script tamb√©m faz a substitui√ß√£o de configura√ß√µes pela atualiza√ß√£o.  O script que conclu√≠mos em 30 segundos, √© um excelente resultado. <br><br><h3>  Lan√ßamento Patroni </h3><br>  Para resolver o segundo problema, basta olhar para a configura√ß√£o do Patroni.  No reposit√≥rio oficial, h√° um exemplo de configura√ß√£o com o initdb, respons√°vel por inicializar um novo banco de dados quando o Patroni √© iniciado pela primeira vez.  Mas como temos um banco de dados pronto, exclu√≠mos esta se√ß√£o da configura√ß√£o. <br><br>  Quando come√ßamos a instalar o Patroni em um cluster PostgreSQL pronto e o executamos, enfrentamos um novo problema: os dois servidores come√ßaram como l√≠deres.  Patroni n√£o sabe nada sobre o estado inicial do cluster e tenta iniciar os dois servidores como dois clusters separados com o mesmo nome.  Para resolver esse problema, exclua o diret√≥rio de dados no escravo: <br><br><pre> <code class="plaintext hljs">rm -rf /var/lib/postgresql/</code> </pre> <br>  <b>Isso deve ser feito apenas no escravo!</b> <br><br>  Ao conectar uma r√©plica limpa, Patroni cria um l√≠der de base-backup e a restaura na r√©plica e, em seguida, atualiza o estado atual por wal-logs. <br><br>  Outra dificuldade que encontramos √© que todos os clusters do PostgreSQL s√£o chamados de main por padr√£o.  Quando cada cluster n√£o sabe nada sobre o outro, isso √© normal.  Mas quando voc√™ deseja usar o Patroni, todos os clusters devem ter um nome exclusivo.  A solu√ß√£o √© alterar o nome do cluster na configura√ß√£o do PostgreSQL. <br><br><h3>  Teste de carga </h3><br>  Lan√ßamos um teste que simula o trabalho dos usu√°rios nos pain√©is.  Quando a carga atingiu nosso valor m√©dio di√°rio, repetimos exatamente o mesmo teste, desativamos uma inst√¢ncia com o l√≠der PostgreSQL.  O failover autom√°tico funcionou como esper√°vamos: Patroni mudou de l√≠der, o Consul-template atualizou a configura√ß√£o do PgBouncer e enviou o comando para recarregar.  De acordo com nossos gr√°ficos no Grafana, ficou claro que existem atrasos de 20 a 30 segundos e uma pequena quantidade de erros de servidores relacionados √† conex√£o com o banco de dados.  Essa √© uma situa√ß√£o normal, esses valores s√£o v√°lidos para nosso failover e definitivamente melhores que o tempo de inatividade do servi√ßo. <br><br><h2>  Produ√ß√£o de Patroni para produ√ß√£o </h2><br>  Como resultado, obtivemos o seguinte plano: <br><br><ul><li>  Implante o Consul-template no servidor PgBouncer e inicie; </li><li>  Atualiza√ß√µes do PostgreSQL para a vers√£o 11.2; </li><li>  Mudan√ßa de nome do cluster; </li><li>  Iniciando um cluster Patroni. </li></ul><br>  Ao mesmo tempo, nosso esquema permite que voc√™ fa√ßa o primeiro item quase a qualquer momento, podemos revezar a remo√ß√£o de cada PgBouncer do trabalho e executar uma implanta√ß√£o nele e executar o consul-template.  Ent√£o n√≥s fizemos. <br><br>  Para rolagem r√°pida, usamos o Ansible, pois j√° checamos todo o manual em um ambiente de teste, e o tempo de execu√ß√£o do script completo foi de 1,5 a 2 minutos para cada fragmento.  Poder√≠amos lan√ßar tudo alternadamente para cada shard sem interromper nosso servi√ßo, mas ter√≠amos que desativar todo PostgreSQL por alguns minutos.  Nesse caso, os usu√°rios cujos dados est√£o nesse fragmento n√£o puderam funcionar totalmente no momento, e isso √© inaceit√°vel para n√≥s. <br><br>  A sa√≠da dessa situa√ß√£o foi a manuten√ß√£o planejada, que ocorre a cada 3 meses.  Essa √© uma janela para o trabalho agendado quando desligamos completamente o servi√ßo e atualizamos as inst√¢ncias do banco de dados.  Faltava uma semana para a pr√≥xima janela e decidimos esperar e nos preparar.  Durante a espera, tamb√©m asseguramos: para cada shard do PostgreSQL, criamos uma r√©plica sobressalente em caso de falha para salvar os dados mais recentes e adicionamos uma nova inst√¢ncia para cada shard, que deve se tornar uma nova r√©plica no cluster Patroni para n√£o executar um comando para excluir dados .  Tudo isso ajudou a minimizar o risco de erro. <br><img src="https://habrastorage.org/webt/ps/ge/yh/psgeyhvrazg-zd1nrochwhl1hag.png"><br><br>  Reinici√°mos o servi√ßo, tudo funcionava como deveria, os usu√°rios continuavam trabalhando, mas nos gr√°ficos notamos uma carga anormalmente alta no servidor Consul. <br><img src="https://habrastorage.org/webt/uk/b9/gu/ukb9guaj4wfabq60v262qe098am.png"><br><br>  Por que n√£o o vimos no ambiente de teste?  Esse problema ilustra muito bem que √© necess√°rio seguir o princ√≠pio da infraestrutura como c√≥digo e refinar toda a infraestrutura, iniciando nos ambientes de teste e finalizando na produ√ß√£o.  Caso contr√°rio, √© muito f√°cil obter o tipo de problema que temos.  O que aconteceu  O Consul apareceu pela primeira vez na produ√ß√£o e, em seguida, nos ambientes de teste, como resultado, nos ambientes de teste, a vers√£o do Consul era superior √† produ√ß√£o.  Apenas em uma das vers√µes, um vazamento de CPU foi resolvido ao trabalhar com o consul-template.  Portanto, acabamos de atualizar o Consul, resolvendo o problema. <br><br><h3>  Reinicie o cluster Patroni </h3><br>  No entanto, temos um novo problema que nem conhec√≠amos.  Ao atualizar o Consul, simplesmente removemos o n√≥ Consul do cluster usando o comando consul leave ‚Üí Patroni se conecta a outro servidor Consul ‚Üí tudo funciona.  Mas quando chegamos √† √∫ltima inst√¢ncia do cluster Consul e enviamos o comando consul leave para ele, todos os clusters Patroni simplesmente foram reiniciados e, nos logs, vimos o seguinte erro: <br><br><pre> <code class="plaintext hljs">ERROR: get_cluster Traceback (most recent call last): ... RetryFailedError: 'Exceeded retry deadline' ERROR: Error communicating with DCS &lt;b&gt;LOG: database system is shut down&lt;/b&gt;</code> </pre> <br>  O cluster Patroni n√£o p√¥de obter informa√ß√µes sobre o cluster e foi reiniciado. <br><br>  Para encontrar uma solu√ß√£o, contatamos os autores do Patroni atrav√©s da edi√ß√£o no github.  Eles sugeriram melhorias nos nossos arquivos de configura√ß√£o: <br><br><pre> <code class="python hljs">consul: consul.checks: [] bootstrap: dcs: retry_timeout: <span class="hljs-number"><span class="hljs-number">8</span></span></code> </pre> <br>  Conseguimos repetir o problema em um ambiente de teste e testamos esses par√¢metros l√°, mas, infelizmente, eles n√£o funcionaram. <br><br>  O problema ainda n√£o foi resolvido.  Planejamos tentar as seguintes solu√ß√µes: <br><br><ul><li>  Use o Consul-agent em cada inst√¢ncia do cluster Patroni; </li><li>  Corrija o problema no c√≥digo. </li></ul><br>  Entendemos o local em que o erro ocorreu: o problema provavelmente est√° usando o tempo limite padr√£o, que n√£o √© substitu√≠do pelo arquivo de configura√ß√£o.  Quando o √∫ltimo servidor Consul √© removido do cluster, o cluster Consul inteiro congela por mais de um segundo, por causa disso, o Patroni n√£o pode obter o estado do cluster e reinicia completamente o cluster inteiro. <br><br>  Felizmente, n√£o encontramos mais nenhum erro. <br><br><h2>  Resultados do uso de Patroni </h2><br>  Ap√≥s o lan√ßamento bem-sucedido do Patroni, adicionamos uma r√©plica adicional em cada cluster.  Agora, em cada agrupamento, h√° um quorum: um l√≠der e duas r√©plicas - para garantir o caso do c√©rebro dividido ao mudar. <br><img src="https://habrastorage.org/webt/ef/pn/er/efpner_0rhtuim1zt0gwrhff3b8.png"><br><br>  Patroni trabalha na produ√ß√£o h√° mais de tr√™s meses.  Durante esse per√≠odo, ele j√° conseguiu nos ajudar.  Recentemente, o l√≠der de um dos clusters morreu na AWS, o failover autom√°tico funcionou e os usu√°rios continuaram trabalhando.  Patroni completou sua tarefa principal. <br><br>  <b>Um pequeno resumo do uso do Patroni:</b> <br><br><ul><li>  Conveni√™ncia de modifica√ß√£o de uma configura√ß√£o.  Basta alterar a configura√ß√£o em uma inst√¢ncia e ela ser√° puxada por todo o cluster.  Se for necess√°ria uma reinicializa√ß√£o para aplicar a nova configura√ß√£o, a Patroni reportar√° isso.  O Patroni pode reiniciar todo o cluster com um √∫nico comando, o que tamb√©m √© muito conveniente. </li><li>  O failover autom√°tico funciona e j√° conseguiu nos ajudar. </li><li>  Atualiza√ß√£o do PostgreSQL sem tempo de inatividade do aplicativo.  Voc√™ deve primeiro atualizar as r√©plicas para a nova vers√£o, depois alterar o l√≠der no cluster Patroni e atualizar o l√≠der antigo.  Nesse caso, o teste necess√°rio do failover autom√°tico ocorre. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt457326/">https://habr.com/ru/post/pt457326/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt457308/index.html">No caminho de Sergey Pavlovich Korolev. Projeto tripulado russo moderno. Parte 2. Foguete</a></li>
<li><a href="../pt457310/index.html">Biologia da Depend√™ncia de Informa√ß√£o</a></li>
<li><a href="../pt457312/index.html">Introdu√ß√£o √† Teoria dos Conjuntos</a></li>
<li><a href="../pt457316/index.html">Como o jogo de representa√ß√£o de pap√©is no mundo real √© organizado para os h√≥spedes da Arm√™nia em viagens pela metade do pa√≠s</a></li>
<li><a href="../pt457324/index.html">Eventos digitais em Moscou de 24 a 30 de junho</a></li>
<li><a href="../pt457328/index.html">Categorias em vez de diret√≥rios ou o sistema de arquivos sem√¢ntico para Linux</a></li>
<li><a href="../pt457330/index.html">Como verificar rapidamente avisos interessantes fornecidos pelo analisador PVS-Studio para c√≥digos C e C ++?</a></li>
<li><a href="../pt457332/index.html">Como ver rapidamente avisos interessantes gerados pelo analisador PVS-Studio para c√≥digo C e C ++?</a></li>
<li><a href="../pt457334/index.html">TacacsGUI, Gerenciador de configura√ß√£o</a></li>
<li><a href="../pt457336/index.html">As consequ√™ncias da remo√ß√£o prematura dos dentes do siso</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåò üà∏ üíæ Principes de base de l'API JAVA SOUND üë®üèø‚Äçüîß üßòüèæ üéß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! Je vous pr√©sente la traduction de l'article ¬´Java Sound, Getting Started, Part 1, Playback¬ª . 

 Sound in JAVA, Part One, The Beginning...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Principes de base de l'API JAVA SOUND</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434424/">  Bonjour, Habr!  Je vous pr√©sente la traduction de l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Java Sound, Getting Started, Part 1, Playback¬ª</a> . <br><br><h3>  Sound in JAVA, Part One, The Beginning.  Jouer du son </h3><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1JZnj4eNHXE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  C'est le d√©but d'une s√©rie de huit le√ßons qui vous familiariseront pleinement avec l'API Java Sound. <br><a name="habracut"></a><br>  Qu'est-ce que le son dans la perception humaine?  C'est le sentiment que nous ressentons lorsqu'un changement de pression atmosph√©rique est transmis aux minuscules zones sensorielles √† l'int√©rieur de nos oreilles. <br><br>  Et l'objectif principal de la cr√©ation de l'API Sound est de vous fournir des moyens d'√©crire du code, ce qui aidera √† transf√©rer les ondes de pression aux oreilles du bon sujet au bon moment. <br><br>  Types de sons en Java: <br><br><ol><li>  L'API Java Sound prend en charge deux principaux types d'audio (son). </li><li>  Son num√©ris√© et enregistr√© directement sous forme de fichier </li><li>  Enregistrez en tant que fichier MIDI.  Tr√®s √©loign√©, mais similaire √† la notation musicale, o√π les instruments de musique sont jou√©s dans la s√©quence souhait√©e. </li></ol><br>  Ces types sont tr√®s diff√©rents dans leur essence et nous nous concentrerons sur le premier, car dans la plupart des cas, nous avons affaire √† du son qui doit √™tre num√©ris√© pour enregistrer √† partir d'une source externe dans un fichier ou vice versa pour reproduire le son pr√©c√©demment enregistr√© √† partir d'un tel fichier. <br><br><h3>  Aper√ßu </h3><br>  L'API Java Sound est bas√©e sur le concept de <i>lignes et de m√©langeurs.</i> <br><br>  Suivant: <br>  Nous d√©crirons les caract√©ristiques physiques et √©lectriques de la repr√©sentation analogique du son appliqu√©e √† un <i>m√©langeur audio</i> . <br><br>  Nous allons nous tourner vers le sc√©nario du groupe de rock d√©butant, qui utilise dans ce cas six microphones et deux haut-parleurs st√©r√©o.  Nous en avons besoin pour comprendre le fonctionnement du m√©langeur audio. <br><br>  Ensuite, nous examinons un certain nombre de th√®mes Java Sound pour la programmation, tels que les lignes, les m√©langeurs, les formats de donn√©es audio, etc. <br><br>  Nous allons comprendre les relations existant entre les objets SourceDataLine, Clip, Mixer, AudioFormat et cr√©er un programme simple qui reproduit l'audio. <br><br>  Ci-dessous, nous donnons un exemple de ce programme, que vous pouvez utiliser pour enregistrer puis lire le son enregistr√©. <br><br>  √Ä l'avenir, nous fournirons une explication compl√®te du code de programme utilis√© √† cet effet.  Mais en aucun cas compl√®tement dans cette le√ßon. <br><br><h3>  Exemple de code et consid√©ration </h3><br>  <b>Caract√©ristiques physiques et √©lectriques du son analogique</b> <br><br>  Le but de notre le√ßon est de vous pr√©senter les bases de la programmation Java √† l'aide de l'API Java Sound. <br><br>  L'API Java Sound est bas√©e sur le concept d'une table de mixage audio, qui est un appareil couramment utilis√© pour jouer du son presque partout: des concerts de rock √† l'√©coute de CD √† la maison.  Mais avant de vous lancer dans une explication d√©taill√©e du fonctionnement du m√©langeur audio, il sera utile de vous familiariser avec les caract√©ristiques physiques et √©lectriques du son analogique lui-m√™me. <br><br>  <i>Regardez la Fig.</i>  <i>1</i> <br><br><img src="https://habrastorage.org/webt/ez/tu/sq/eztusq7byax0l9nu-5r6vj3vkxe.gif"><br><br>  Vasya Pupyrkin pousse un discours. <br><br>  Cette figure montre Vasya pronon√ßant un discours en utilisant un syst√®me connu sous le nom de large adresse.  Un tel syst√®me comprend g√©n√©ralement un microphone, un amplificateur et un haut-parleur.  Le but de ce syst√®me est de renforcer la voix de Vasya afin qu'il puisse √™tre entendu m√™me dans une grande foule. <br><br>  <b>Vaciller dans l'air</b> <br><br>  En bref, lorsque Vasya parle, ses cordes vocales font vibrer les particules d'air dans son larynx.  Cela conduit √† l'√©mergence d'ondes sonores qui, √† leur tour, font vibrer la membrane du microphone puis se transforment en vibrations √©lectriques de tr√®s petite amplitude qui simulent exactement les vibrations sonores de l'original de Vasya.  Un amplificateur, comme son nom l'indique, amplifie ces vibrations √©lectriques.  Ensuite, ils atteignent le haut-parleur, qui effectue la transformation inverse des vibrations √©lectriques amplifi√©es en ondes sonores tr√®s amplifi√©es, mais qui r√©p√®tent n√©anmoins exactement les m√™mes ondes g√©n√©r√©es dans les cordes vocales de Vasya Pupyrkin. <br><br>  <b>Microphone dynamique</b> <br><br>  Regardons maintenant la Fig.  2, qui montre un diagramme sch√©matique d'un microphone appel√© dynamique. <br><br><img src="https://habrastorage.org/webt/hz/1v/ui/hz1vui2-yqnq4cg3xdpi5iy-1w0.gif"><br>  <i>Fig.</i>  <i>2 Circuit microphone dynamique</i> <br><br>  <b>Les vibrations sonores affectent la membrane</b> <br><br>  La pression des vibrations sonores agit sur une membrane flexible √† l'int√©rieur du microphone.  Cela fait vibrer la membrane, tandis que les vibrations de la membrane r√©p√®tent les vibrations des ondes sonores. <br><br>  <b>Bobine mobile</b> <br><br>  Une bobine de fil mince est fix√©e √† la membrane du microphone.  Lorsque la membrane oscille, la bobine effectue √©galement des mouvements alternatifs dans le champ magn√©tique du noyau constitu√© d'un aimant permanent puissant.  Et comme Faraday l'a √©galement √©tabli, un courant √©lectrique appara√Æt dans la bobine. <br><br>  <b>Un signal √©lectrique suit la forme des ondes sonores.</b> <br><br>  Ainsi, √† partir d'un tr√®s faible courant induit dans la bobine, un signal √©lectrique alternatif est obtenu, r√©p√©tant la forme d'ondes sonores qui agissent sur la membrane du microphone.  En outre, ce signal sous la forme d'une tension alternative est appliqu√© √† l'entr√©e de l'amplificateur de la Fig.  1. <br><br>  <b>Haut-parleur</b> <br><br>  En fait, le principe de fonctionnement de l'enceinte r√©p√®te l'appareil d'un microphone dynamique, uniquement allum√© en sens inverse.  <i>(Naturellement, dans ce cas, les fils de bobinage sont beaucoup plus √©pais et la membrane est beaucoup plus grande pour assurer un fonctionnement avec un signal amplifi√©)</i> <i><br></i> <br><br><img src="https://habrastorage.org/webt/0e/ec/4x/0eec4xwyiyp2icsx69azgymv78c.gif"><br><br>  Les oscillations de la membrane du haut-parleur affectent les particules d'air et cr√©ent de puissantes ondes sonores.  La forme de ces ondes r√©p√®te exactement la forme des ondes sonores d'intensit√© beaucoup plus faible cr√©√©es par les cordes vocales de Vasya.  Mais l'intensit√© des nouvelles vagues est maintenant suffisante pour garantir que les vibrations sonores de Vasya atteignent les oreilles des personnes debout, m√™me dans les rang√©es arri√®re d'une grande foule. <br><br>  <b>Concert de rock</b> <br><br>  √Ä ce stade, vous vous demandez peut-√™tre ce que tout cela a √† voir avec l'API Java Sound.  Mais attendez un peu plus longtemps, nous ouvrons la voie aux bases du m√©langeur audio. <br><br>  Le circuit d√©crit ci-dessus √©tait assez simple.  Il √©tait compos√© de Vasya Pupyrkin, d'un microphone, d'un amplificateur et d'un haut-parleur.  Consid√©rons maintenant le circuit avec la Fig.  4, qui pr√©sente la sc√®ne pr√©par√©e pour le concert de rock du groupe de musique d√©butant. <br><br><img src="https://habrastorage.org/webt/jh/zh/qo/jhzhqouio0xa25axcr164jch4du.gif"><br><br>  <b>Six microphones et deux haut-parleurs</b> <br><br>  Dans la Fig.  4 six microphones sont situ√©s sur la sc√®ne.  Deux haut-parleurs (haut-parleurs) sont situ√©s sur les c√¥t√©s de la sc√®ne.  Au d√©but du concert, les interpr√®tes chantent ou jouent de la musique dans chacun des six microphones.  En cons√©quence, nous aurons six signaux √©lectriques, qui doivent √™tre amplifi√©s individuellement puis envoy√©s aux deux haut-parleurs.  En plus de cela, les artistes peuvent utiliser divers effets sp√©ciaux sonores, par exemple la r√©verb√©ration, qui devront √©galement √™tre convertis en signaux √©lectriques avant de les appliquer aux haut-parleurs. <br><br>  Deux haut-parleurs sur les c√¥t√©s de la sc√®ne sont con√ßus pour cr√©er l'effet d'un son st√©r√©o.  Autrement dit, le signal √©lectrique provenant du microphone situ√© sur la sc√®ne √† droite doit tomber dans le haut-parleur situ√© √©galement √† droite.  De m√™me, le signal provenant du microphone √† gauche doit √™tre envoy√© au haut-parleur situ√© √† gauche de la sc√®ne.  Mais les signaux √©lectriques provenant d'autres microphones situ√©s plus pr√®s du centre de la sc√®ne doivent d√©j√† √™tre transmis aux deux haut-parleurs dans des proportions appropri√©es.  Et deux microphones en plein centre devraient transmettre leur signal aux deux haut-parleurs de mani√®re √©gale. <br><br>  <b>Mixeur audio</b> <br><br>  La t√¢che discut√©e ci-dessus n'est ex√©cut√©e que par un appareil √©lectronique appel√© m√©langeur audio. <br><br>  <b>Ligne audio (canal)</b> <br><br>  Bien que l'auteur ne soit pas un expert des m√©langeurs audio, √† sa connaissance humble, un m√©langeur audio typique a la capacit√© de recevoir √† l'entr√©e un certain nombre de signaux √©lectriques ind√©pendants les uns des autres, chacun repr√©sentant le signal ou la ligne sonore d'origine <i>(canal).</i> <br><br>  (Le concept de canal audio deviendra tr√®s important lorsque nous commencerons √† comprendre l'API Java Sound en d√©tail. <br><br>  <b>Traitement ind√©pendant de chaque canal audio</b> <br><br>  Dans tous les cas, le m√©langeur audio standard a la capacit√© d'amplifier chaque ligne audio ind√©pendamment des autres autres canaux.  De plus, la table de mixage a g√©n√©ralement la possibilit√© d'imposer des effets sp√©ciaux sonores, tels que, par exemple, la r√©verb√©ration √† l'une des lignes audio.  Au final, la table de mixage, comme son nom l'indique, peut m√©langer tous les signaux √©lectriques individuels dans les canaux de sortie tels qu'ils seront d√©finis, afin de contr√¥ler la contribution de chaque ligne audio aux canaux de sortie (ce contr√¥le est g√©n√©ralement appel√© pan ou pan - distribution dans l'espace). <br><br>  <b>Retour au son st√©r√©o</b> <br><br>  Ainsi, dans le sch√©ma de la Fig.  4, l'ing√©nieur du son de la table de mixage audio a la capacit√© de combiner les signaux de six microphones pour obtenir deux signaux de sortie, chacun √©tant transmis √† son haut-parleur. <br><br>  Pour un fonctionnement r√©ussi, le signal de chaque microphone doit √™tre fourni dans la proportion appropri√©e, en fonction de l'emplacement physique du microphone sur la sc√®ne.  (En modifiant le panoramique, un ing√©nieur du son qualifi√© peut modifier la contribution de chaque microphone si n√©cessaire, si, par exemple, le chanteur principal se d√©place sur la sc√®ne pendant un concert). <br><br>  <b>Il est temps de retourner dans le monde de la programmation</b> <br><br>  Revenons maintenant du monde physique au monde de la programmation.  Selon Sun: <i>¬´Java Sound n'implique aucune configuration mat√©rielle sp√©ciale;</i>  <i>Il est con√ßu pour permettre √† divers composants audio d'√™tre install√©s sur le syst√®me et mis √† la disposition de l'utilisateur via l'API.</i>  <i>Java Sound prend en charge les fonctionnalit√©s d'entr√©e et de sortie standard d'une carte son (par exemple, pour l'enregistrement et la lecture de fichiers audio), ainsi que la possibilit√© de m√©langer plusieurs flux audio ¬ª</i> <br><br>  <b>Mixeurs et canaux</b> <br><br>  Comme d√©j√† mentionn√©, l'API Java Sound est construite sur le concept de m√©langeurs et de canaux.  Si vous passez du monde physique au monde de la programmation, Sun √©crit ce qui suit concernant le m√©langeur: <br><br>  <i>¬´Un m√©langeur est un appareil audio avec un ou plusieurs canaux.</i>  <i>Mais le m√©langeur qui mixe vraiment le signal audio doit avoir plusieurs canaux d'entr√©e de sources sources et au moins un canal cible de sortie. "</i> <br><br>  Les lignes d'entr√©e peuvent √™tre des instances de classes avec des objets SourceDataLine et les lignes de sortie peuvent √™tre des objets TargetDataLine.  Le m√©langeur peut √©galement recevoir un son pr√©enregistr√© et en boucle en entr√©e, d√©finissant ses canaux de source d'entr√©e comme des instances d'objets de classe qui impl√©mentent l'interface Clip. <br><br>  Interface de ligne de canal. <br><br>  Sun rapporte les informations suivantes √† partir de l'interface de ligne: ¬´La <i>ligne est un √©l√©ment d'un pipeline audio num√©rique tel qu'un port audio d'entr√©e ou de sortie, un m√©langeur ou un chemin audio vers ou depuis un m√©langeur.</i>  <i>Les donn√©es audio passant par le canal peuvent √™tre mono ou multicanaux (par exemple, st√©r√©o).</i>  <i>... Un canal peut avoir des contr√¥les, tels que le gain, le panoramique et la r√©verb√©ration. ¬ª</i> <br><br>  <b>Rassembler les termes</b> <br><br>  Ainsi, les citations ci-dessus de Sun d√©notaient les termes suivants <br><br>  Sourcedataline <br>  Targetgetataline <br>  Port <br>  Clip <br>  Contr√¥les <br><br>  <i>Fig.</i>  <i>5 montre un exemple d'utilisation de ces termes pour construire un programme de sortie audio simple.</i> <br><br><img src="https://habrastorage.org/webt/e1/5r/gh/e15rghejgy0b2reeciyvircdvua.gif"><br><br>  <b>Script de programme</b> <br><br>  D'un point de vue logiciel  5 montre un objet Mixer obtenu avec un objet Clip et deux objets SourceDataLine. <br><br>  <b>Qu'est-ce que Clip</b> <br><br>  Clip est un objet √† l'entr√©e du m√©langeur dont le contenu ne change pas avec le temps.  En d'autres termes, vous chargez les donn√©es audio dans l'objet Clip avant de les lire.  Le contenu audio de l'objet Clip peut √™tre lu une ou plusieurs fois.  Vous pouvez boucler le clip, puis le contenu sera lu encore et encore. <br><br>  <b>Flux d'entr√©e</b> <br><br>  L'objet SourceDataLine, d'autre part, est un objet de flux √† l'entr√©e du m√©langeur.  Un objet de ce type peut recevoir un flux de donn√©es audio et l'envoyer au m√©langeur en temps r√©el.  Les donn√©es audio n√©cessaires peuvent √™tre obtenues √† partir de diverses sources, telles que des fichiers audio, une connexion r√©seau ou une m√©moire tampon. <br><br>  <b>Diff√©rents types de canaux</b> <br><br>  Ainsi, les objets Clip et SourceDataLine peuvent √™tre consid√©r√©s comme des canaux d'entr√©e pour l'objet Mixer.  Chacun de ces canaux d'entr√©e peut avoir le sien: panoramique, gain et r√©verb√©ration. <br><br>  <b>Lire du contenu audio</b> <br><br>  Dans un syst√®me aussi simple, Mixer lit les donn√©es des lignes d'entr√©e, utilise le contr√¥le pour m√©langer les signaux d'entr√©e et fournit une sortie √† un ou plusieurs canaux de sortie, tels qu'un haut-parleur, une sortie de ligne, une prise casque, etc. <br><br>  Le listing 11 montre un programme simple qui capture des donn√©es audio √† partir d'un port de microphone, stocke ces donn√©es en m√©moire, puis les lit via le port de haut-parleur. <br><br>  Nous discuterons uniquement de la capture et de la lecture.  La plupart du programme ci-dessus consiste √† cr√©er une fen√™tre et une interface graphique pour l'utilisateur afin qu'il soit possible de contr√¥ler l'enregistrement et la lecture.  Nous ne discuterons pas de cette partie comme allant au-del√† de l'objectif.  Mais ensuite, nous consid√©rerons la capture et la lecture des donn√©es.  Nous discuterons de la perte dans cette le√ßon et de la capture dans la prochaine.  En cours de route, nous illustrerons l'utilisation du canal audio avec l'API Java Sound. <br><br>  Les donn√©es captur√©es sont stock√©es dans un objet ByteArrayOutputStream. <br><br>  Un extrait de code permet de lire des donn√©es audio √† partir d'un microphone et de les stocker en tant qu'objet ByteArrayOutputStream. <br><br>  La m√©thode, appel√©e playAudio, qui commence dans le Listing 1, lit les donn√©es audio qui ont √©t√© captur√©es et stock√©es dans l'objet ByteArrayOutputStream. <br><br><pre><code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">playAudio</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> audioData[] = byteArrayOutputStream. toByteArray(); InputStream byteArrayInputStream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ByteArrayInputStream( audioData);</code> </pre> <br>  <i>Listing 1</i> <br><br>  <b>Nous commen√ßons avec le code standard.</b> <br><br>  L'extrait de programme du Listing 1 n'est en fait pas encore li√© √† Java Sound. <br><br>  Son objectif est de: <br><br><ul><li>  Convertissez les donn√©es pr√©c√©demment enregistr√©es en un tableau d'octets de type. </li><li>  Obtenez le flux d'entr√©e pour un tableau de donn√©es d'octets. </li></ul><br>  Nous en avons besoin pour rendre les donn√©es audio disponibles pour une lecture ult√©rieure. <br><br>  <b>Acc√©dez √† l'API Sound</b> <br><br>  La ligne de code du Listing 2 est d√©j√† li√©e √† l'API Java Sound. <br><br><pre> <code class="java hljs"> AudioFormat audioFormat = getAudioFormat();</code> </pre><br>  <i>Listing 2</i> <br><br>  Ici, nous abordons bri√®vement le sujet, qui sera discut√© en d√©tail dans la prochaine le√ßon. <br><br>  <b>Deux formats ind√©pendants</b> <br><br>  Le plus souvent, nous avons affaire √† deux formats ind√©pendants pour les donn√©es audio. <br><br>  Format de fichier, (tout) qui contient des donn√©es audio (dans notre programme, il ne l'est pas encore, car les donn√©es sont stock√©es en m√©moire) <br><br>  Le format des donn√©es audio soumises est en lui-m√™me. <br><br>  <b>Qu'est-ce qu'un format audio?</b> <br><br>  Voici ce que Sun √©crit √† ce sujet: <br><br>  <i>¬´Chaque canal de donn√©es a son propre format audio associ√© √† son flux de donn√©es.</i>  <i>Le format (une instance d'AudioFormat) d√©termine l'ordre des octets du flux audio.</i>  <i>Les param√®tres de format peuvent √™tre le nombre de canaux, la fr√©quence d'√©chantillonnage, le bit de quantification, la m√©thode de codage, etc. Les m√©thodes de codage habituelles peuvent √™tre la modulation lin√©aire par impulsions cod√©es du PCM et de ses variantes. ¬ª</i> <br><br>  <b>S√©quence d'octets</b> <br><br>  Les donn√©es audio source sont une s√©quence d'octets de donn√©es binaires.  Il existe diff√©rentes options pour organiser et interpr√©ter cette s√©quence.  Nous ne commencerons pas √† traiter toutes ces options en d√©tail, mais nous discuterons un peu du format audio que nous utilisons ici dans notre programme. <br><br>  <b>Petite digression</b> <br><br>  Ici, nous laissons la m√©thode playAudio pour l'instant et regardons la m√©thode getAudioFormat du Listing 2. <br><br>  <i>La m√©thode getAudioFormat compl√®te est pr√©sent√©e dans le Listing 3.</i> <br><br><pre> <code class="java hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> AudioFormat </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getAudioFormat</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> sampleRate = <span class="hljs-number"><span class="hljs-number">8000.0F</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> sampleSizeInBits = <span class="hljs-number"><span class="hljs-number">16</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> channels = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">boolean</span></span> signed = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">boolean</span></span> bigEndian = <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioFormat( sampleRate, sampleSizeInBits, channels, signed, bigEndian); }<span class="hljs-comment"><span class="hljs-comment">//end getAudioFormat</span></span></code> </pre><br>  <i>Listing 3</i> <br><br>  En plus de d√©clarer des variables initialis√©es, le code du Listing 3 contient une expression ex√©cutable. <br><br>  <b>Objet AudioFormat</b> <br><br>  La m√©thode getAudioFormat cr√©e et renvoie une instance d'un objet de la classe AudioFormat.  Voici ce que Sun √©crit sur cette classe: <br><br>  <i>¬´La classe AudioFormat d√©finit l'ordre sp√©cifique des donn√©es dans un flux audio.</i>  <i>En ce qui concerne les champs de l'objet AudioFormat, vous pouvez obtenir des informations sur la fa√ßon d'interpr√©ter correctement les bits dans un flux de donn√©es binaires. ¬ª</i> <br><br>  <b>Nous utilisons le constructeur le plus simple</b> <br><br>  La classe AudioFormat a deux types de constructeurs (nous prendrons le plus trivial).  Les param√®tres suivants sont requis pour ce constructeur: <br><br><ul><li>  Taux d'√©chantillonnage ou taux d'√©chantillonnage par seconde (valeurs disponibles: 8000, 11025, 16000, 22050 et 44100 √©chantillons par seconde) </li><li>  Profondeur de bits des donn√©es (8 et 16 bits par comptage sont disponibles) </li><li>  Nombre de canaux (un canal pour mono et deux pour st√©r√©o) </li><li>  Donn√©es sign√©es ou non sign√©es utilis√©es dans le flux (par exemple, la valeur varie de 0 √† 255 ou de -127 √† +127) </li><li>  L'ordre des octets de Big-endian ou little-endian.  (si vous transmettez un flux d'octets de valeurs 16 bits, il est important de savoir quel octet vient en premier - bas ou haut, car il y a les deux options). </li></ul><br>  Comme vous pouvez le voir dans le Listing 3, dans notre cas, nous avons utilis√© les param√®tres suivants pour une instance de l'objet AudioFormat. <br><br><ul><li>  8000 √©chantillons par seconde </li><li>  16 taille des donn√©es </li><li>  donn√©es importantes </li><li>  Ordre du petit-boutiste </li></ul><br>  Par d√©faut, les donn√©es sont cod√©es par PCM lin√©aire. <br><br>  Le constructeur que nous avons utilis√© cr√©e une instance de l'objet AudioFormat en utilisant la modulation lin√©aire par impulsions cod√©es et les param√®tres indiqu√©s ci-dessus (Nous reviendrons sur PCM lin√©aire et d'autres m√©thodes d'encodage dans les le√ßons suivantes) <br><br>  <b>Retour √† la m√©thode playAudio √† nouveau</b> <br><br>  Maintenant que nous comprenons comment fonctionne le format de donn√©es audio en son Java, revenons √† la m√©thode playAudio.  D√®s que nous voulons lire les donn√©es audio disponibles, nous avons besoin d'un objet de classe AudioInputStream.  Nous en obtenons une instance dans le Listing 4. <br><br><pre> <code class="java hljs"> audioInputStream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioInputStream( byteArrayInputStream, audioFormat, audioData.length/audioFormat. getFrameSize());</code> </pre><br>  <i>Listing 4</i> <br><br>  <b>Param√®tres du constructeur AudioInputStream</b> <br><br><ul><li>  Le constructeur de la classe AudioInputStream requiert les trois param√®tres suivants: </li><li>  Le flux sur lequel l'instance de l'objet AudioInputStream sera bas√©e (comme nous le voyons √† cet effet, nous utilisons l'instance de l'objet ByteArrayInputStream cr√©√© pr√©c√©demment) </li><li>  Le format de donn√©es audio pour ce flux (√† cet effet, nous avons d√©j√† cr√©√© une instance de l'objet AudioFormat) </li><li>  La taille de la trame (trame) pour les donn√©es de ce flux (voir la description ci-dessous) </li><li>  Les deux premiers param√®tres ressortent clairement du code du Listing 4. Cependant, le troisi√®me param√®tre n'est pas si √©vident en soi. </li></ul><br>  <b>Obtenir la taille du cadre</b> <br><br>  Comme nous pouvons le voir dans le Listing 4, la valeur du troisi√®me param√®tre est cr√©√©e √† l'aide de calculs.  Ce n'est qu'un des attributs du format audio que nous n'avons pas mentionn√© auparavant, et il est appel√© une trame. <br><br>  <b>Qu'est-ce qu'un cadre?</b> <br><br>  Pour un PCM lin√©aire simple utilis√© dans notre programme, la trame contient un ensemble d'√©chantillons pour tous les canaux √† un moment donn√©. <br><br>  Ainsi, la taille de trame est √©gale √† la taille du compte en octets multipli√©e par le nombre de canaux. <br><br>  Comme vous l'avez peut-√™tre devin√©, une m√©thode appel√©e getFrameSize renvoie la taille de la trame en octets. <br><br>  <b>Calcul de la taille du cadre</b> <br><br>  Ainsi, la longueur des donn√©es audio dans une trame peut √™tre calcul√©e en divisant le nombre total d'octets dans la s√©quence de donn√©es audio par le nombre d'octets dans une trame.  Ce calcul est utilis√© pour le troisi√®me param√®tre du Listing 4. <br><br>  <b>Obtention d'un objet SourceDataLine</b> <br><br>  La prochaine partie du programme dont nous allons discuter est un simple syst√®me de sortie audio.  Comme nous pouvons le voir sur le diagramme de la figure 5, pour r√©soudre ce probl√®me, nous avons besoin d'un objet SourceDataLine. <br><br>  Il existe plusieurs fa√ßons d'obtenir une instance de l'objet SourceDataLine, toutes tr√®s d√©licates.  Le code du Listing 5 r√©cup√®re et stocke une r√©f√©rence √† une instance de l'objet SourceDataLine. <br><br>  (Notez que ce code n'instancie pas seulement l'objet SourceDataLine. Il l'obtient de mani√®re plut√¥t d√©tourn√©e.) <br><br><pre> <code class="java hljs"> DataLine.Info dataLineInfo = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataLine.Info( SourceDataLine.class, audioFormat); sourceDataLine = (SourceDataLine) AudioSystem.getLine( dataLineInfo);</code> </pre><br>  <i>Listing 5</i> <br><br>  Qu'est-ce qu'un objet SourceDataLine? <br><br>  √Ä ce sujet, Sun √©crit ce qui suit: <br><br>  <i>¬´SourceDataLine est un canal de donn√©es dans lequel les donn√©es peuvent √™tre √©crites.</i>  <i>Il fonctionne comme une entr√©e pour un m√©langeur.</i>  <i>Une application √©crit une s√©quence d'octets dans une SourceDataLine, qui met en m√©moire tampon les donn√©es et les remet √† son m√©langeur.</i>  <i>Le m√©langeur peut transmettre les donn√©es qu'il traite pour l'√©tape suivante, par exemple, au port de sortie.</i> <i><br><br></i>  <i>Notez que la convention de d√©nomination de ce couplage refl√®te la relation entre le canal et son m√©langeur. ¬ª</i> <br><br>  <b>M√©thode GetLine pour la classe AudioSystem</b> <br><br>  Une fa√ßon d'obtenir une instance de l'objet SourceDataLine consiste √† appeler la m√©thode statique getLine √† partir de la classe AudioSystem (nous aurons beaucoup √† dire √† ce sujet dans les prochaines le√ßons). <br><br>  La m√©thode getLine n√©cessite un param√®tre d'entr√©e de type Line.Info et retourne un objet Line qui correspond √† la description de l'objet Line.Info d√©j√† d√©fini. <br><br>  <b>Une autre petite digression</b> <br><br>  Sun rapporte les informations suivantes sur l'objet Line.Info: <br><br>  ¬´Le canal a son propre objet d'information (une instance de Line.Info), qui indique quel m√©langeur (le cas √©ch√©ant) envoie les donn√©es audio mix√©es en sortie directement au canal, et quel m√©langeur (le cas √©ch√©ant) re√ßoit les donn√©es audio en entr√©e directement du canal.  Les vari√©t√©s de Line peuvent correspondre √† des sous-classes de Line.Info, ce qui vous permet de sp√©cifier d'autres types de param√®tres li√©s √† des types de canaux sp√©cifiques ¬ª <br><br>  <b>Objet DataLine.Info</b> <br><br>  La premi√®re expression du Listing 5 cr√©e une nouvelle instance de l'objet DataLine.Info, qui est une forme sp√©ciale (sous-classe) de l'objet Line.Info. <br><br>  Il existe plusieurs constructeurs surcharg√©s pour la classe DataLine.Info.  Nous avons choisi le plus simple √† utiliser.  Ce constructeur n√©cessite deux param√®tres. <br><br>  <b>Objet de classe</b> <br><br>  Le premier param√®tre est Class, qui repr√©sente la classe que nous avons d√©finie comme SourceDataLine.class <br><br>  Le deuxi√®me param√®tre d√©termine le format de donn√©es souhait√© pour le canal.  Nous utilisons pour cela une instance de l'objet AudioFormat, qui a d√©j√† √©t√© d√©finie pr√©c√©demment. <br><br>  <b>O√π en sommes-nous d√©j√†?</b> <br><br>  Malheureusement, nous n'avons toujours pas l'objet SourceDataLine le plus requis.  Jusqu'√† pr√©sent, nous avons un objet qui fournit uniquement des informations sur l'objet SourceDataLine dont nous avons besoin. <br><br>  <b>Obtention d'un objet SourceDataLine</b> <br><br>  La deuxi√®me expression du Listing 5 cr√©e et stocke enfin l'instance de SourceDataLine dont nous avons besoin.  Cela se produit en appelant la m√©thode statique getLine de la classe AudioSystem et en transmettant dataLineInfo en tant que param√®tre.  (Dans la prochaine le√ßon, nous verrons comment obtenir un objet Line, en travaillant directement avec l'objet Mixer). <br><br>  La m√©thode getLine renvoie une r√©f√©rence √† un objet de type Line, qui est le parent de SourceDataLine.  Par cons√©quent, une conversion descendante est requise ici avant que la valeur de retour ne soit enregistr√©e en tant que SourceDataLine. <br><br>  <b>Pr√©parons-nous √† utiliser l'objet SourceDataLine</b> <br><br>  Une fois que nous obtenons une instance de l'objet SourceDataLine, nous devons le pr√©parer pour l'ouverture et l'ex√©cution, comme indiqu√© dans le Listing 6. <br><br><pre> <code class="java hljs"> sourceDataLine.open(audioFormat); sourceDataLine.start();</code> </pre><br>  <i>Listing 6</i> <br><br>  <b>M√©thode d'ouverture</b> <br><br>  Comme vous pouvez le voir dans le Listing 6, nous avons envoy√© l'objet AudioFormat √† la m√©thode d'ouverture de l'objet SourceDataLine. <br><br>  Selon Sun, il s'agit d'une m√©thode: <br><br>  <i>¬´Ouvre une ligne (canal) avec un format pr√©alablement d√©fini, lui permettant de recevoir toutes les ressources syst√®me dont il a besoin et d'√™tre en √©tat de fonctionnement (de travail)¬ª</i> <br><br>  <b>√âtat de d√©couverte</b> <br><br>  Il n'y a pas grand-chose de plus que Sun √©crit sur lui dans ce fil. <br><br>  <i>¬´L'ouverture et la fermeture du canal affectent la distribution des ressources syst√®me.</i>  <i>Une ouverture r√©ussie du canal garantit que toutes les ressources n√©cessaires sont fournies au canal.</i> <i><br><br></i>  <i>L'ouverture du m√©langeur, qui a ses ports d'entr√©e et de sortie pour les donn√©es audio, comprend, entre autres, l'utilisation du mat√©riel de la plate-forme sur laquelle le travail et l'initialisation des composants logiciels n√©cessaires ont lieu.</i> <i><br><br></i>  <i>L'ouverture d'un canal, qui est une route pour les donn√©es audio vers ou depuis une console de mixage, comprend √† la fois l'initialisation et la r√©ception de ressources de mixage nullement illimit√©es.</i>  <i>En d'autres termes, le m√©langeur a un nombre fini de canaux, donc plusieurs applications avec leurs propres besoins en canaux (et parfois m√™me une application) doivent partager correctement les ressources du m√©langeur) ¬ª</i> <br><br>  <b>Appeler la m√©thode de d√©marrage sur un canal</b> <br><br>  Selon Sun, appeler la m√©thode de d√©marrage d'un canal signifie ce qui suit: <br><br>  <i>¬´Le canal est autoris√© √† utiliser des lignes d'E / S.</i>  <i>Si une tentative est faite pour utiliser une ligne d√©j√† op√©rationnelle, la m√©thode ne fait rien.</i>  <i>Mais une fois que le tampon de donn√©es est vide, la ligne reprend le d√©marrage des E / S, en commen√ßant par la premi√®re trame qu'elle n'a pas r√©ussi √† traiter apr√®s le chargement complet du tampon. ¬ª</i> <br><br>  Dans notre cas, bien s√ªr, la cha√Æne ne s'est pas arr√™t√©e.  Depuis que nous l'avons lanc√© pour la premi√®re fois. <br><br>  <b>Maintenant, nous avons presque tout ce dont nous avons besoin</b> <br><br>  √Ä ce stade, nous avons re√ßu toutes les ressources audio dont nous avons besoin pour lire les donn√©es audio que nous avons pr√©c√©demment enregistr√©es et stock√©es dans une instance de l'objet ByteArrayOutputStream.  (Rappelez-vous que cet objet n'existe que dans la RAM de l'ordinateur). <br><br>  <b>Nous commen√ßons les flux</b> <br><br>  Nous allons cr√©er et d√©marrer le flux pour lire l'audio.  Le code du Listing 7 cr√©e et d√©marre ce thread. <br><br>  (Ne confondez pas l'appel √† la m√©thode start dans ce thread avec l'appel √† la m√©thode start dans l'objet SourceDataLine du Listing 6. Ce sont des op√©rations compl√®tement diff√©rentes) <br><br><pre> <code class="java hljs">Thread playThread = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Thread(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> PlayThread()); playThread.start(); } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (Exception e) { System.out.println(e); System.exit(<span class="hljs-number"><span class="hljs-number">0</span></span>); }<span class="hljs-comment"><span class="hljs-comment">//end catch }//end playAudio</span></span></code> </pre><br>  <i>Listing 7</i> <br><br>  <b>Code sans pr√©tention</b> <br><br>  L'extrait du programme du Listing 7, bien que tr√®s simple, montre un exemple de programmation multi-thread en Java.  Si vous ne le comprenez pas, vous devez vous familiariser avec ce sujet dans des sujets sp√©cialis√©s pour apprendre Java. <br><br>  Une fois le flux d√©marr√©, il fonctionnera jusqu'√† ce que toutes les donn√©es audio pr√©enregistr√©es aient √©t√© lues jusqu'√† la fin. <br><br>  <b>Nouvel objet de thread</b> <br><br>  Le code du Listing 7 cr√©e une instance de l'objet Thread de la classe PlayThread.  Cette classe est d√©finie comme une classe interne dans notre programme.  Sa description commence dans l'extrait 8. <br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PlayThread</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Thread</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> tempBuffer[] = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">10000</span></span>];</code> </pre><br>  <i>Listing 8</i> <br><br>  <b>La m√©thode run dans la classe Thread</b> <br><br>  √Ä l'exception de la d√©claration d'une variable tempBuffer (qui fait r√©f√©rence √† un tableau d'octets), une d√©finition compl√®te de cette classe n'est qu'une d√©finition de la m√©thode d'ex√©cution.  Comme vous devez d√©j√† le savoir, l'appel de la m√©thode start sur un objet Thread provoque l'ex√©cution de la m√©thode run de cet objet <br><br>  La m√©thode d'ex√©cution de ce thread commence dans le Listing 9. <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> cnt; <span class="hljs-comment"><span class="hljs-comment">//  //    -1 // while((cnt = audioInputStream. read(tempBuffer, 0, tempBuffer.length)) != -1){ if(cnt &gt; 0){ //   //    //    //   . sourceDataLine.write( tempBuffer, 0, cnt); }//end if }//end while</span></span></code> </pre><br>  <i>Listing 9</i> <br><br>  <b>La premi√®re partie du fragment de programme dans la m√©thode run</b> <br><br>  La m√©thode run contient deux parties importantes, dont la premi√®re est pr√©sent√©e dans le Listing 9. <br><br>  En r√©sum√©, une boucle est utilis√©e ici pour lire les donn√©es audio d'un AudioInputStream et les transmettre √† une SourceDataLine. <br><br>  Les donn√©es envoy√©es √† l'objet SourceDataLine sont automatiquement transf√©r√©es vers la sortie audio par d√©faut.  Il peut s'agir d'un haut-parleur d'ordinateur int√©gr√© ou d'une sortie ligne.  (Nous apprendrons √† d√©terminer les appareils sonores n√©cessaires dans les le√ßons suivantes).  La variable cnt et le tampon de donn√©es tempBuffer sont utilis√©s pour contr√¥ler le flux de donn√©es entre les op√©rations de lecture et d'√©criture. <br><br>  <b>Lecture de donn√©es depuis AudioInputStream</b> <br><br>  Le cycle de lecture de l'objet AudioInputStream lit le nombre maximal sp√©cifi√© d'octets de donn√©es de AudioInputStream et place leur tableau d'octets. <br><br>  <b>Valeur de retour</b> <br><br>  De plus, cette m√©thode renvoie le nombre total d'octets lus, ou -1, si la fin de la s√©quence enregistr√©e a √©t√© atteinte.  Le nombre d'octets lus est stock√© dans la variable cnt. <br><br>  <b>Boucle d'√©criture SourceDataLine</b> <br><br>  Si le nombre d'octets lus est sup√©rieur √† z√©ro, il y a alors une transition vers le cycle d'√©criture des donn√©es dans SourceDataLine.  Dans cette boucle, les donn√©es audio entrent dans la console de mixage.  Les octets sont lus √† partir du tableau d'octets conform√©ment √† leurs indices et √©crits dans le tampon de canal. <br><br>  <b>Lorsque le flux d'entr√©e s√®che</b> <br><br>  Lorsque la boucle de lecture renvoie -1, cela signifie que toutes les donn√©es audio pr√©c√©demment enregistr√©es sont termin√©es et qu'un contr√¥le suppl√©mentaire est transmis au fragment de programme dans le listing 10. <br><br><pre> <code class="java hljs"> sourceDataLine.drain(); sourceDataLine.close(); }<span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (Exception e) { System.out.println(e); System.exit(<span class="hljs-number"><span class="hljs-number">0</span></span>); }<span class="hljs-comment"><span class="hljs-comment">//end catch }//end run }//   PlayThread</span></span></code> </pre><br>  <i>Listing 10</i> <br><br>  <b>Verrouillez et attendez</b> <br><br>  Le code du Listing 10 appelle la m√©thode drain sur l'objet SourceDataLine afin que le programme puisse bloquer et attendre que le tampon interne se vide dans SourceDataLine.  Lorsque le tampon est vide, cela signifie que la totalit√© de la portion suivante est d√©livr√©e √† la sortie audio de l'ordinateur. <br><br>  <b>Fermeture de SourceDataLine</b> <br><br>  Ensuite, le programme appelle la m√©thode close pour fermer le canal, montrant ainsi que toutes les ressources syst√®me utilis√©es par le canal sont d√©sormais libres.  Sun rapporte la fermeture de canal suivante: <br><br>  <i>¬´La fermeture du canal signale que toutes les ressources impliqu√©es pour ce canal peuvent √™tre lib√©r√©es.</i>  <i>Pour lib√©rer des ressources, l'application doit fermer les canaux, qu'ils soient d√©j√† impliqu√©s ou pas d√©j√†, ainsi que la fin de l'application.</i>  <i>On suppose que les m√©langeurs partagent les ressources du syst√®me et peuvent √™tre ferm√©s et ouverts √† plusieurs reprises.</i>  <i>D'autres canaux peuvent ou non prendre en charge la r√©ouverture apr√®s leur fermeture.</i>  <i>En g√©n√©ral, les m√©canismes d'ouverture des lignes varient selon les diff√©rents sous-types. ¬ª</i> <br><br>  <b>Et maintenant la fin de l'histoire</b> <br><br>  Nous avons donc expliqu√© ici comment notre programme utilise l'API Java Sound afin d'assurer la livraison des donn√©es audio de la m√©moire interne de l'ordinateur √† la carte son. <br><br>  <b>Ex√©cutez le programme</b> <br><br>  Vous pouvez maintenant compiler et ex√©cuter le programme √† partir du Listing 11, qui couronne la fin de notre le√ßon. <br><br>  <b>Capturez et lisez des donn√©es audio</b> <br><br>  Le programme d√©montre la capacit√© d'enregistrer des donn√©es √† partir d'un microphone et de les lire via la carte son de votre ordinateur.  Les instructions d'utilisation sont tr√®s simples. <br><br>  Ex√©cutez le programme.  L'interface graphique simple, qui est illustr√©e √† la figure 6, devrait appara√Ætre √† l'√©cran. <br><br><img src="https://habrastorage.org/webt/lf/7l/ew/lf7lew65yqcqstjqvdvmptmhevy.gif"><br><br><ul><li>  Cliquez sur le bouton Capturer et enregistrez tous les sons dans le microphone. </li><li>  Cliquez sur le bouton Arr√™ter pour arr√™ter l'enregistrement. </li><li>  Cliquez sur le bouton Lecture pour lire l'enregistrement via la sortie audio de votre ordinateur. </li></ul><br>  Si vous n‚Äôentendez rien, essayez d‚Äôaugmenter la sensibilit√© du microphone ou le volume du haut-parleur. <br><br>  Le programme enregistre un enregistrement dans la m√©moire de l'ordinateur, alors soyez prudent.  Si vous essayez d'enregistrer trop de donn√©es audio, vous risquez de manquer de RAM. <br><br>  <b>Conclusion</b> <br><br><ul><li>  Nous avons d√©couvert que l'API Java Sound est bas√©e sur le concept de canaux et de m√©langeurs. </li><li>  Nous avons obtenu les informations initiales sur les caract√©ristiques physiques et √©lectriques du son analogique, afin de comprendre ensuite le dispositif du m√©langeur audio. </li><li>  Nous avons utilis√© un sc√©nario de concert de rock amateur utilisant six microphones et deux haut-parleurs st√©r√©o pour d√©crire la possibilit√© d'utiliser un m√©langeur audio. </li><li>  Nous avons discut√© d'un certain nombre de sujets de programmation Java Sound, notamment les m√©langeurs, les canaux, le format des donn√©es, etc. </li><li>  Nous avons expliqu√© la relation g√©n√©rale entre les objets SourceDataLine, Clip, Mixer, AudioFormat et les ports dans un programme simple de sortie de donn√©es audio. </li><li>  Nous nous sommes familiaris√©s avec un programme qui nous permet initialement d'enregistrer puis de lire des donn√©es audio. </li><li>  Nous avons re√ßu une explication d√©taill√©e du code utilis√© pour lire les donn√©es audio enregistr√©es pr√©c√©demment dans la m√©moire de l'ordinateur. </li></ul><br>  <b>Et ensuite?</b> <br><br>  Dans ce didacticiel, nous avons d√©couvert que l'API Java Sound est bas√©e sur le concept de m√©langeurs et de canaux.  Cependant, le code dont nous avons discut√© n'incluait pas explicitement les m√©langeurs.  La classe AudioSystem nous a fourni des m√©thodes statiques qui permettent d'√©crire des programmes de traitement audio sans acc√©der directement aux m√©langeurs.  En d'autres termes, ces m√©thodes statiques nous √©loignent des m√©langeurs. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans la le√ßon suivante, nous pr√©sentons un code de capture de donn√©es modifi√© par rapport √† celui pr√©sent√© dans cette le√ßon. </font><font style="vertical-align: inherit;">La nouvelle version utilisera explicitement des m√©langeurs pour vous montrer comment les utiliser lorsque vous en avez vraiment besoin.</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.swing.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.event.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.sound.sampled.*; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AudioCapture01</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">JFrame</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">boolean</span></span> stopCapture = <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>; ByteArrayOutputStream byteArrayOutputStream; AudioFormat audioFormat; TargetDataLine targetDataLine; AudioInputStream audioInputStream; SourceDataLine sourceDataLine; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( String args[])</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioCapture01(); }<span class="hljs-comment"><span class="hljs-comment">//end main public AudioCapture01(){ final JButton captureBtn = new JButton("Capture"); final JButton stopBtn = new JButton("Stop"); final JButton playBtn = new JButton("Playback"); captureBtn.setEnabled(true); stopBtn.setEnabled(false); playBtn.setEnabled(false); captureBtn.addActionListener( new ActionListener(){ public void actionPerformed( ActionEvent e){ captureBtn.setEnabled(false); stopBtn.setEnabled(true); playBtn.setEnabled(false); //  //   //   Stop captureAudio(); } } ); getContentPane().add(captureBtn); stopBtn.addActionListener( new ActionListener(){ public void actionPerformed( ActionEvent e){ captureBtn.setEnabled(true); stopBtn.setEnabled(false); playBtn.setEnabled(true); //  //    stopCapture = true; } } ); getContentPane().add(stopBtn); playBtn.addActionListener( new ActionListener(){ public void actionPerformed( ActionEvent e){ //  //    playAudio(); } } ); getContentPane().add(playBtn); getContentPane().setLayout( new FlowLayout()); setTitle("Capture/Playback Demo"); setDefaultCloseOperation( EXIT_ON_CLOSE); setSize(250,70); setVisible(true); } //    //     //   ByteArrayOutputStream private void captureAudio(){ try{ //    audioFormat = getAudioFormat(); DataLine.Info dataLineInfo = new DataLine.Info( TargetDataLine.class, audioFormat); targetDataLine = (TargetDataLine) AudioSystem.getLine( dataLineInfo); targetDataLine.open(audioFormat); targetDataLine.start(); //     //    //   //    Thread captureThread = new Thread( new CaptureThread()); captureThread.start(); } catch (Exception e) { System.out.println(e); System.exit(0); } } //    // ,    //  ByteArrayOutputStream private void playAudio() { try{ //  //  byte audioData[] = byteArrayOutputStream. toByteArray(); InputStream byteArrayInputStream = new ByteArrayInputStream( audioData); AudioFormat audioFormat = getAudioFormat(); audioInputStream = new AudioInputStream( byteArrayInputStream, audioFormat, audioData.length/audioFormat. getFrameSize()); DataLine.Info dataLineInfo = new DataLine.Info( SourceDataLine.class, audioFormat); sourceDataLine = (SourceDataLine) AudioSystem.getLine( dataLineInfo); sourceDataLine.open(audioFormat); sourceDataLine.start(); //    //     //     //      Thread playThread = new Thread(new PlayThread()); playThread.start(); } catch (Exception e) { System.out.println(e); System.exit(0); } } //     //  AudioFormat private AudioFormat getAudioFormat(){ float sampleRate = 8000.0F; //8000,11025,16000,22050,44100 int sampleSizeInBits = 16; //8,16 int channels = 1; //1,2 boolean signed = true; //true,false boolean bigEndian = false; //true,false return new AudioFormat( sampleRate, sampleSizeInBits, channels, signed, bigEndian); } //===================================// //    //    class CaptureThread extends Thread{ byte tempBuffer[] = new byte[10000]; public void run(){ byteArrayOutputStream = new ByteArrayOutputStream(); stopCapture = false; try{ while(!stopCapture){ int cnt = targetDataLine.read( tempBuffer, 0, tempBuffer.length); if(cnt &gt; 0){ //     byteArrayOutputStream.write( tempBuffer, 0, cnt); } } byteArrayOutputStream.close(); }catch (Exception e) { System.out.println(e); System.exit(0); } } } //===================================// //   //     class PlayThread extends Thread{ byte tempBuffer[] = new byte[10000]; public void run(){ try{ int cnt; //     -1 while((cnt = audioInputStream. read(tempBuffer, 0, tempBuffer.length)) != -1){ if(cnt &gt; 0){ //    //   //    //    sourceDataLine.write( tempBuffer, 0, cnt); } } sourceDataLine.drain(); sourceDataLine.close(); }catch (Exception e) { System.out.println(e); System.exit(0); } } } //===================================// }//end outer class AudioCapture01.java</span></span></code> </pre><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listing 11</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr434424/">https://habr.com/ru/post/fr434424/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr434412/index.html">Suppression de la fus√©e avant le lancement sur Vostochny</a></li>
<li><a href="../fr434414/index.html">Iceberg</a></li>
<li><a href="../fr434416/index.html">Lire en vacances. Les meilleurs articles sur notre blog pour 2018</a></li>
<li><a href="../fr434418/index.html">Plus rapide, plus fort, plus brillant: la physique de l'accouplement des colibris ¬´dansant¬ª</a></li>
<li><a href="../fr434422/index.html">Choses non rentables</a></li>
<li><a href="../fr434426/index.html">Liste de contr√¥le: comment soumettre des rapports sur le r√©gime fiscal simplifi√© pour 2018</a></li>
<li><a href="../fr434428/index.html">Nous assemblons, r√©parons et portons une montre num√©rique vintage</a></li>
<li><a href="../fr434430/index.html">IBM a montr√© une puce de m√©moire analogique √† changement de phase de 8 bits</a></li>
<li><a href="../fr434440/index.html">[Vid√©o] Navires de guerre, bots et tir d'argent sur des serveurs</a></li>
<li><a href="../fr434442/index.html">Cosmonautique 2018 - r√©sultats de l'ann√©e</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
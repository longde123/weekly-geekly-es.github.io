<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜë üß¶ ‚ò¢Ô∏è Inmersi√≥n en redes neuronales convolucionales. Parte 5/10 - 18 üíØ üèáüèΩ ü•ï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El curso completo en ruso se puede encontrar en este enlace . 
 El curso de ingl√©s original est√° disponible en este enlace . 



 Nuevas conferencias ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inmersi√≥n en redes neuronales convolucionales. Parte 5/10 - 18</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458170/"><p>  El curso completo en ruso se puede encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br>  El curso de ingl√©s original est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . </p><br><p><img src="https://habrastorage.org/webt/1m/hz/qn/1mhzqnwa288uxjmptqhexriiahc.png"><br>  <i>Nuevas conferencias est√°n programadas cada 2-3 d√≠as.</i> </p><a name="habracut"></a><br><h1>  Contenido </h1><br><ol><li>  Entrevista con Sebastian Trun </li><li>  Introduccion </li><li>  Conjunto de datos de perros y gatos </li><li>  Im√°genes de varios tama√±os. </li><li>  Im√°genes a color.  Parte 1 </li><li>  Im√°genes a color.  Parte 2 </li><li>  Operaci√≥n de convoluci√≥n en im√°genes en color </li><li>  La operaci√≥n de submuestreo por el valor m√°ximo en im√°genes en color </li><li>  CoLab: gatos y perros </li><li>  Softmax y sigmoide </li><li>  Cheque </li><li>  Extensi√≥n de imagen </li><li>  Excepci√≥n </li><li>  CoLab: perros y gatos.  Repetici√≥n </li><li>  Otras t√©cnicas para prevenir el reentrenamiento </li><li>  Ejercicio: clasificaci√≥n de im√°genes en color </li><li>  Resumen </li></ol><br><h1>  Softmax y Sigmoide </h1><br><p>  En nuestro √∫ltimo CoLab pr√°ctico, utilizamos la siguiente arquitectura de red neuronal convolucional: </p><br><pre><code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><p>  Tenga en cuenta que nuestra √∫ltima capa (nuestro clasificador) consiste en una capa completamente conectada con dos neuronas de salida y una <code>softmax</code> activaci√≥n <code>softmax</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)</code> </pre> <br><p>  Otro enfoque popular para resolver problemas de clasificaci√≥n binaria es el uso de un clasificador, que consiste en una capa completamente conectada con 1 neurona de salida y <code>sigmoid</code> activaci√≥n <code>sigmoid</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)</code> </pre> <br><p>  Ambas opciones funcionar√°n bien en el problema de clasificaci√≥n binaria.  Sin embargo, lo que debe tener en cuenta si decide usar la <code>sigmoid</code> activaci√≥n <code>sigmoid</code> en su clasificador, tambi√©n deber√° cambiar la funci√≥n de p√©rdida en el m√©todo <code>model.compile()</code> de <code>sparse_categorical_crossentropy</code> a <code>binary_crossentropy</code> como en el ejemplo a continuaci√≥n: </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h1>  Validaci√≥n </h1><br><p>  En clases pasadas, estudiamos la precisi√≥n de nuestras redes neuronales convolucionales utilizando la m√©trica de <code>accuracy</code> en un conjunto de datos de prueba.  Cuando desarrollamos una red neuronal convolucional para clasificar im√°genes del conjunto de datos FASHION MNIST, obtuvimos un 97% de precisi√≥n en el conjunto de datos de entrenamiento y solo un 92% de precisi√≥n en el conjunto de datos de prueba.  Todo esto sucedi√≥ porque nuestro modelo fue reentrenado.  En otras palabras, nuestra red neuronal convolucional estaba empezando a recordar el conjunto de datos de entrenamiento.  Sin embargo, pudimos aprender sobre la reentrenamiento solo <em>despu√©s de</em> entrenar y probar el modelo con los datos disponibles al comparar la precisi√≥n del conjunto de datos de entrenamiento y el conjunto de datos de prueba. </p><br><p>  Para evitar este problema, a menudo utilizamos un conjunto de datos para la validaci√≥n: </p><br><p><img src="https://habrastorage.org/webt/mj/fw/ea/mjfweaqi7ztkkfbmznz1nfnogjq.png"></p><br><p>  Durante el entrenamiento, nuestra red neuronal convolucional "ve" solo el conjunto de datos de entrenamiento y toma decisiones sobre c√≥mo cambiar los valores de los par√°metros internos: pesos y desplazamientos.  Despu√©s de cada iteraci√≥n de entrenamiento, verificamos el estado del modelo calculando el valor de la funci√≥n de p√©rdida en el conjunto de datos de entrenamiento y en el conjunto de datos de validaci√≥n.  Vale la pena se√±alar y prestar especial atenci√≥n al hecho de que el modelo no utiliza los datos del conjunto de validaci√≥n para ajustar los valores de los par√°metros internos.  La verificaci√≥n de la precisi√≥n del modelo en el conjunto de datos de validaci√≥n solo nos dice qu√© tan bien funciona nuestro modelo en este mismo conjunto de datos.  Por lo tanto, los resultados del modelo en el conjunto de datos de validaci√≥n nos dicen qu√© tan bien nuestro modelo ha aprendido a generalizar los datos obtenidos y aplicar esta generalizaci√≥n a un nuevo conjunto de datos. </p><br><p>  La idea es que, dado que no usamos el conjunto de datos de validaci√≥n cuando entrenamos el modelo, probar el modelo en el conjunto de validaci√≥n nos permitir√° comprender si el modelo est√° reentrenado o no. </p><br><p>  Veamos un ejemplo. </p><br><p>  En CoLab, que realizamos algunos puntos arriba, entrenamos nuestra red neuronal durante 15 iteraciones. </p><br><pre> <code class="plaintext hljs">Epoch 15/15 10/10 [===] - loss: 1.0124 - acc: 0.7170 20/20 [===] - loss: 0.0528 - acc: 0.9900 - val_loss: 1.0124 - val_acc: 0.7070</code> </pre> <br><p>  Si observamos la precisi√≥n de las predicciones en los conjuntos de datos de entrenamiento y validaci√≥n en la decimoquinta iteraci√≥n de entrenamiento, podemos ver que hemos logrado una alta precisi√≥n en el conjunto de datos de entrenamiento y un indicador significativamente bajo en el conjunto de datos de validaci√≥n: <code>0.9900</code> versus <code>0.7070</code> . </p><br><p>  Este es un signo obvio de reciclaje.  La red neuronal record√≥ el conjunto de datos de entrenamiento, por lo tanto, funciona con una precisi√≥n incre√≠ble en los datos de entrada.  Sin embargo, tan pronto como se trata de verificar la precisi√≥n en un conjunto de datos de validaci√≥n que el modelo no "vio", los resultados se reducen significativamente. </p><br><p>  Una forma de evitar el reentrenamiento es estudiar cuidadosamente el gr√°fico de los valores de la funci√≥n de p√©rdida en los conjuntos de datos de entrenamiento y validaci√≥n en todas las iteraciones de entrenamiento: </p><br><p><img src="https://habrastorage.org/webt/mo/bb/ml/mobbml4mb5sqt1ugcjjmj69ziau.png"></p><br><p>  En CoLab, creamos un gr√°fico similar y obtuvimos algo similar al gr√°fico anterior de la dependencia de la funci√≥n de p√©rdida en la iteraci√≥n de entrenamiento. </p><br><p>  Puede notar que despu√©s de una determinada iteraci√≥n de entrenamiento, el valor de la funci√≥n de p√©rdida en el conjunto de datos de validaci√≥n comienza a aumentar, mientras que el valor de la funci√≥n de p√©rdida en el conjunto de datos de entrenamiento contin√∫a disminuyendo. </p><br><p>  Al final de la 15¬™ iteraci√≥n de entrenamiento, notamos que el valor de la funci√≥n de p√©rdida en el conjunto de datos de validaci√≥n es extremadamente alto, y el valor de la funci√≥n de p√©rdida en el conjunto de datos de entrenamiento es extremadamente peque√±o.  En realidad, este es el indicador del reentrenamiento de la red neuronal. </p><br><p>  Al observar cuidadosamente el gr√°fico, puede comprender que, literalmente, despu√©s de algunas iteraciones de entrenamiento, nuestra red neuronal comienza a almacenar simplemente datos de entrenamiento, lo que significa que la capacidad del modelo para generalizar se reduce, lo que conduce a un deterioro en la precisi√≥n del conjunto de datos de validaci√≥n. </p><br><p>  Como probablemente ya haya entendido, el conjunto de datos de validaci√≥n nos permite determinar la cantidad de iteraciones de entrenamiento que deben realizarse para que nuestra red neuronal convolucional sea precisa y, al mismo tiempo, no se vuelva a entrenar. </p><br><p>  Tal enfoque puede ser extremadamente √∫til si tenemos la opci√≥n de varias arquitecturas de redes neuronales convolucionales: </p><br><p><img src="https://habrastorage.org/webt/ay/5j/lq/ay5jlqtty3bwks_zdjclydfgumq.png"></p><br><p>  Por ejemplo, si decide el n√∫mero de capas en una red neuronal convolucional, puede crear varias arquitecturas de redes neuronales y luego comparar su precisi√≥n utilizando un conjunto de datos para la validaci√≥n. </p><br><p>  La arquitectura de la red neuronal, que le permite alcanzar el valor m√≠nimo de la funci√≥n de p√©rdida y ser√° la mejor para resolver su tarea. </p><br><p>  La siguiente pregunta que puede tener es ¬øpor qu√© crear un conjunto de datos de validaci√≥n si ya tenemos un conjunto de datos de prueba?  ¬øPodemos usar un conjunto de datos de prueba para la validaci√≥n? </p><br><p>  El problema es que, a pesar del hecho de que no usamos el conjunto de datos de validaci√≥n en el proceso de capacitaci√≥n del modelo, usamos los resultados de trabajar en el conjunto de datos de prueba para mejorar la precisi√≥n del modelo, lo que significa que el conjunto de datos de prueba afecta los pesos y sesgos en los nervios red </p><br><p><img src="https://habrastorage.org/webt/ys/7a/ih/ys7aihyxutwvpilqpnsaczev5eo.png"></p><br><p>  Es por esta raz√≥n que necesitamos un conjunto de datos de validaci√≥n que nuestro modelo nunca haya visto antes para verificar con precisi√≥n su rendimiento. </p><br><p>  Acabamos de descubrir c√≥mo un conjunto de datos validado puede ayudarnos a evitar el reciclaje.  En las siguientes partes, hablaremos sobre la expansi√≥n de datos (el llamado aumento) y la desconexi√≥n (el llamado abandono) de las neuronas, dos t√©cnicas populares que tambi√©n pueden ayudarnos a evitar el reentrenamiento. </p><br><h1>  Extensi√≥n de imagen (aumento) </h1><br><p>  Al entrenar redes neuronales para determinar objetos de una determinada clase, queremos que nuestra red neuronal encuentre estos objetos, independientemente de su ubicaci√≥n y tama√±o en la imagen. </p><br><p>  Por ejemplo, supongamos que queremos entrenar nuestra red neuronal para reconocer perros en im√°genes: </p><br><p><img src="https://habrastorage.org/webt/0y/d2/cu/0yd2cuip0aaef2hi8auegdq6mt8.png"></p><br><p>  Por lo tanto, queremos que nuestra red neuronal determine la presencia de un perro en la imagen, independientemente de qu√© tan grande sea el perro y en qu√© parte de la imagen sea, si parte del perro es visible o todo el perro.  Queremos asegurarnos de que nuestra red neuronal pueda procesar todas estas opciones durante el entrenamiento. </p><br><p>  Si tienes la suerte y tienes un gran conjunto de datos de entrenamiento, entonces podemos decir con confianza que tienes suerte y que es poco probable que tu red neuronal se vuelva a entrenar.  Sin embargo, lo que sucede con bastante frecuencia, tenemos que trabajar con un conjunto limitado de im√°genes (datos de entrenamiento), que, a su vez, conducir√°n a nuestra red neuronal convolucional con una alta probabilidad de reentrenamiento y reducir√°n su capacidad de generalizar y producir el resultado deseado en datos que no "vio" antes. </p><br><p>  Este problema se puede resolver utilizando una t√©cnica llamada "extensi√≥n" (aumento de imagen).  La expansi√≥n de im√°genes (datos) funciona creando (generando) nuevas im√°genes para el entrenamiento mediante la aplicaci√≥n de transformaciones arbitrarias del conjunto original de im√°genes del conjunto de entrenamiento. </p><br><p>  Por ejemplo, podemos tomar una de las im√°genes de origen de nuestro conjunto de datos de entrenamiento y aplicarle varias transformaciones arbitrarias: voltearla en X grados, reflejarla horizontalmente y hacer un aumento arbitrario. </p><br><p><img src="https://habrastorage.org/webt/nd/ps/fv/ndpsfvldpaymeybswwqkmyspr40.png"></p><br><p>  Al agregar las im√°genes generadas a nuestro conjunto de datos de entrenamiento, estamos convencidos de que nuestra red neuronal "ver√°" un n√∫mero suficiente de ejemplos diferentes para el entrenamiento.  Como resultado de tales acciones, nuestra red neuronal convolucional se generalizar√° mejor y trabajar√° en los datos que a√∫n no ha visto y podremos evitar el reentrenamiento. </p><br><p>  En la siguiente parte, aprenderemos qu√© es un abandono (un apagado), otra t√©cnica para evitar sobreajustar un modelo. </p><br><h1>  Excepci√≥n (abandono) </h1><br><p>  En esta parte, aprenderemos una nueva t√©cnica: el abandono, que tambi√©n nos ayudar√° a evitar un entrenamiento excesivo del modelo.  Como ya sabemos desde las primeras partes, la red neuronal optimiza los par√°metros internos (pesos y desplazamientos) para minimizar la funci√≥n de p√©rdida. </p><br><p>  Uno de los problemas que se pueden encontrar al entrenar una red neuronal son los valores enormes en una parte de la red neuronal y los valores peque√±os en la otra parte de la red neuronal. </p><br><p><img src="https://habrastorage.org/webt/op/bb/cf/opbbcfp4z1wl_geilpygynmvdz8.png"></p><br><p>  Como resultado, resulta que las neuronas con mayor peso juegan <strong>un</strong> papel m√°s importante en el proceso de aprendizaje, mientras que las neuronas con menor peso dejan de ser significativas y est√°n cada vez menos sujetas a cambios.  Una forma de evitar esto es usar un abandono arbitrario de neuronas. </p><br><p>  Apagado (abandono): el proceso de apagado selectivo de neuronas en el proceso de aprendizaje. </p><br><p><img src="https://habrastorage.org/webt/8j/7t/0p/8j7t0p91wpjv2qswrxugif3b2e4.png"></p><br><p>  El apagado selectivo de algunas neuronas en el proceso de aprendizaje le permite involucrar activamente a otras neuronas en el aprendizaje.  Durante las iteraciones de entrenamiento, deshabilitamos arbitrariamente algunas neuronas. </p><br><p>  Veamos un ejemplo.  Imagine que en la primera iteraci√≥n de entrenamiento, apagamos dos neuronas resaltadas en negro: </p><br><p><img src="https://habrastorage.org/webt/rv/f7/uv/rvf7uvlolq1t38zvhi50mqw7hgg.png"></p><br><p>  Los procesos de propagaci√≥n directa y propagaci√≥n inversa se producen sin el uso de dos neuronas aisladas. </p><br><p>  En la segunda iteraci√≥n de entrenamiento, decidimos no usar las siguientes tres neuronas: desact√≠velas: </p><br><p><img src="https://habrastorage.org/webt/lq/dq/k2/lqdqk2gkxaagbvcpgwsybs8i2wq.png"></p><br><p>  Como en el caso anterior, en los procesos de propagaci√≥n directa e inversa, no utilizamos estas tres neuronas.  En la √∫ltima iteraci√≥n del tercer entrenamiento, decidimos no usar estas dos neuronas: </p><br><p><img src="https://habrastorage.org/webt/dk/jf/ac/dkjfacty06iu6r6aopxq9by5qs4.png"></p><br><p>  Y en este caso, no usamos neuronas desconectadas en los procesos de propagaci√≥n directa e inversa.  Y as√≠ sucesivamente. </p><br><p>  Al entrenar nuestra red neuronal de esta manera, podemos evitar el reentrenamiento.  Podemos decir que nuestra red neuronal se est√° volviendo m√°s estable, porque con este enfoque, no puede confiar en absolutamente todas las neuronas para resolver el problema.  Por lo tanto, otras neuronas comienzan a tomar una parte m√°s activa en la formaci√≥n del valor de salida requerido y tambi√©n comienzan a hacer frente a la tarea. </p><br><p>  En la pr√°ctica, este enfoque requiere indicar la probabilidad de eliminar cada una de las neuronas en cualquier iteraci√≥n de entrenamiento.  Tenga en cuenta que, al indicar la probabilidad de que nos encontremos en una situaci√≥n en la que algunas neuronas se desconectar√°n con m√°s frecuencia que otras, y algunas no se desconectar√°n en absoluto.  Sin embargo, esto no es un problema, porque este proceso se realiza muchas veces y, en promedio, cada neurona con la misma probabilidad puede desconectarse. </p><br><p>  Ahora apliquemos el conocimiento te√≥rico adquirido en la pr√°ctica y refinemos nuestro clasificador de im√°genes de gatos y perros. </p><br><h1>  CoLab: perros y gatos.  Repetici√≥n </h1><br><p>  CoLab en ingl√©s est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br>  CoLab en ruso est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . </p><br><h2 id="koshki-vs-sobaki-klassifikaciya-izobrazheniy-s-rasshireniem">  Gatos VS Perros: clasificaci√≥n de im√°genes con extensi√≥n </h2><br><p>  En este tutorial, discutiremos c√≥mo clasificar las im√°genes de gatos y perros.  Desarrollaremos un clasificador de im√°genes utilizando el modelo <code>tf.keras.Sequential</code> y usaremos <code>tf.keras.Sequential</code> para cargar los datos. </p><br><h3 id="idei-kotorye-budut-zatronuty-v-etoy-chasti">  Ideas para ser cubiertas en esta parte: </h3><br><p>  Obtendremos experiencia pr√°ctica en el desarrollo de un clasificador y desarrollaremos una comprensi√≥n intuitiva de los siguientes conceptos: </p><br><ol><li>  Construir un modelo de flujo de datos ( <em>tuber√≠as de entrada de datos</em> ) usando la clase <code>tf.keras.preprocessing.image.ImageDataGenerator</code> (¬øC√≥mo trabajar eficientemente con datos en el disco que interact√∫an con el modelo?) </li><li>  Reciclaje: ¬øqu√© es y c√≥mo determinarlo? </li><li>  El aumento de datos y el m√©todo de abandono son t√©cnicas clave en la lucha contra el reciclaje en las tareas de reconocimiento de patrones que implementaremos en nuestro proceso de capacitaci√≥n modelo. </li></ol><br><h4 id="my-budem-sledovat-osnovnomu-podhodu-pri-razrabotke-modeley-mashinnogo-obucheniya">  Seguiremos el enfoque b√°sico en el desarrollo de modelos de aprendizaje autom√°tico: </h4><br><ol><li>  Explore y comprenda datos </li><li>  Configurar flujo de entrada </li><li>  Construir modelo </li><li>  Modelo de tren </li><li>  Modelo de prueba </li><li>  Mejorar modelo / repetir proceso </li></ol><br><p>  <strong>Antes de comenzar ...</strong> </p><br><p>  Antes de comenzar el c√≥digo en el editor, le recomendamos que restablezca todas las configuraciones en <strong>Runtime -&gt; Restablecer todo</strong> en el men√∫ superior.  Tal acci√≥n ayudar√° a evitar problemas con la falta de memoria, si trabaj√≥ en paralelo o trabaj√≥ con varios editores. </p><br><h1 id="importirovanie-paketov">  Importar paquetes </h1><br><p>  Comencemos importando los paquetes que necesita: </p><br><ul><li>  <code>os</code> - leer archivos y estructuras de directorios; </li><li>  <code>numpy</code> : para algunas operaciones matriciales fuera de TensorFlow; </li><li>  <code>matplotlib.pyplot</code> : trazar y mostrar im√°genes de un conjunto de datos de prueba y validaci√≥n. </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><p>  Importar <code>TensorFlow</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging logger = tf.get_logger() logger.setLevel(logging.ERROR)</code> </pre> <br><h1 id="zagruzka-dannyh">  Carga de datos </h1><br><p>  Comenzamos el desarrollo de nuestro clasificador cargando un conjunto de datos.  El conjunto de datos que utilizamos es una versi√≥n filtrada del conjunto de datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dogs vs Cats</a> del servicio Kaggle (al final, Microsoft Research proporciona este conjunto de datos). </p><br><p>  En el pasado, CoLab y yo usamos un conjunto de datos del propio m√≥dulo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow Dataset</a> , que es extremadamente conveniente para el trabajo y las pruebas.  En este CoLab, sin embargo, utilizaremos la clase <code>tf.keras.preprocessing.image.ImageDataGenerator</code> para leer datos del disco.  Por lo tanto, primero debemos descargar el conjunto de datos Dog VS Cats y descomprimirlo. </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span> zip_dir = tf.keras.utils.get_file(<span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filterted.zip'</span></span>, origin=_URL, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  El conjunto de datos que descargamos tiene la siguiente estructura: </p><br><pre> <code class="plaintext hljs">cats_and_dogs_filtered |__ train |______ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...] |______ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...] |__ validation |______ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...] |______ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]</code> </pre> <br><p>  Para obtener la lista completa de directores, puede usar el siguiente comando: </p><br><pre> <code class="python hljs">zip_dir_base = os.path.dirname(zip_dir) !find $zip_dir_base -type d -<span class="hljs-keyword"><span class="hljs-keyword">print</span></span></code> </pre> <br><p>  Salida (al comenzar desde CoLab): </p><br><pre> <code class="plaintext hljs">/root/.keras/datasets /root/.keras/datasets/cats_and_dogs_filtered /root/.keras/datasets/cats_and_dogs_filtered/train /root/.keras/datasets/cats_and_dogs_filtered/train/dogs /root/.keras/datasets/cats_and_dogs_filtered/train/cats /root/.keras/datasets/cats_and_dogs_filtered/validation /root/.keras/datasets/cats_and_dogs_filtered/validation/dogs /root/.keras/datasets/cats_and_dogs_filtered/validation/cats</code> </pre> <br><p>  Ahora asigne las rutas correctas a los directorios con los conjuntos de datos para capacitaci√≥n y validaci√≥n de las variables: </p><br><pre> <code class="python hljs">base_dir = os.path.join(os.path.dirname(zip_dir), <span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filtered'</span></span>) train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) validation_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'validation'</span></span>) train_cats_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) train_dogs_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>) validation_cats_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) validation_dogs_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>)</code> </pre> <br><h4 id="razbiraemsya-s-dannymi-i-ih-strukturoy">  Comprender los datos y su estructura. </h4><br><p>  Veamos cu√°ntas im√°genes de gatos y perros tenemos en los conjuntos de datos de prueba y validaci√≥n (directorios). </p><br><pre> <code class="python hljs">num_cats_tr = len(os.listdir(train_cats_dir)) num_dogs_tr = len(os.listdir(train_dogs_dir)) num_cats_val = len(os.listdir(validation_cats_dir)) num_dogs_val = len(os.listdir(validation_dogs_dir)) total_train = num_cats_tr + num_dogs_tr total_val = num_cats_val + num_dogs_val</code> </pre> <br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_val) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_val) print(<span class="hljs-string"><span class="hljs-string">'--'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_train) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_val)</code> </pre> <br><p>  Conclusi√≥n </p><br><pre> <code class="plaintext hljs">    : 1000     : 1000     : 500     : 500 --      : 2000      : 1000</code> </pre> <br><h1 id="ustanovka-parametrov-modeli">  Establecer par√°metros del modelo </h1><br><p>  Para mayor comodidad, colocaremos la instalaci√≥n de las variables que necesitamos para un mayor procesamiento de datos y capacitaci√≥n de modelos en un anuncio separado: </p><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#          IMG_SHAPE = 150 #       </span></span></code> </pre> <br><h1 id="rasshirenie-dannyh">  Extensi√≥n de datos </h1><br><p>  La reentrenamiento generalmente ocurre cuando hay pocos ejemplos de capacitaci√≥n en nuestro conjunto de datos.  Una forma de eliminar la escasez de datos es expandirlos al n√∫mero correcto de instancias y la variabilidad correcta.  La extensi√≥n de datos es el proceso de generar datos a partir de instancias existentes mediante la aplicaci√≥n de diversas transformaciones al conjunto de datos original.  El prop√≥sito de este m√©todo es aumentar el n√∫mero de instancias de entrada √∫nicas que el modelo nunca volver√° a ver, lo que, a su vez, permitir√° que el modelo generalice mejor los datos de entrada y muestre una mayor precisi√≥n en el conjunto de datos de validaci√≥n. </p><br><p>  Usando <strong><code>tf.keras</code></strong> podemos implementar tales transformaciones aleatorias y generar nuevas im√°genes a trav√©s de la clase <strong><code>ImageDataGenerator</code></strong> .  Ser√° suficiente para nosotros pasar en forma de par√°metros varias transformaciones que nos gustar√≠a aplicar a las im√°genes, y la clase misma se encargar√° del resto durante el entrenamiento del modelo. </p><br><p>  Primero, escriba una funci√≥n que muestre im√°genes obtenidas como resultado de transformaciones aleatorias.  Luego examinaremos con m√°s detalle las transformaciones utilizadas en el proceso de expansi√≥n del conjunto de datos original. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plotImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_arr)</span></span></span><span class="hljs-function">:</span></span> fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> img, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show()</code> </pre> <br><h4 id="perevorachivanie-izobrazheniya-po-gorizontali">  Voltear la imagen horizontalmente </h4><br><p>  Podemos comenzar con una conversi√≥n simple: volteo horizontal de la imagen.  Veamos c√≥mo se ver√° esta transformaci√≥n aplicada a nuestras im√°genes de origen.        <code>horizontal_flip=True</code>   <strong>ImageDataGenerator</strong> . </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, horizontal_flip=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>                    .      (  )   . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2  5 ): </p><br><p><img src="https://habrastorage.org/webt/9k/ss/zk/9ksszkjktuykiawts9xldwp8d6e.png"></p><br><h4 id="povorot-izobrazheniy">   </h4><br><p>            .        45. </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, rotation_range=<span class="hljs-number"><span class="hljs-number">45</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>         ‚Äî          5   .      (  )   . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2   5): </p><br><p><img src="https://habrastorage.org/webt/f4/7a/du/f47adubevummwogquqvplmzvy5k.png"></p><br><h4 id="primenenie-uvelicheniya">   </h4><br><p>             ‚Äî    50%. </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, zoom_range=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>   ,      ‚Äî 5      .   (  )       . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2  5 ): </p><br><p><img src="https://habrastorage.org/webt/i6/75/qx/i675qx7wsf8c4woaxoipll-j8cs.png"></p><br><h4 id="obedinyaem-vsyo-vmeste">    </h4><br><p>       ,   ,   ,          <code>ImageDataGenerator</code> . </p><br><p>       ‚Äî   ,   45 ,   ,   ,    . </p><br><pre> <code class="python hljs">image_gen_train = ImageDataGenerator( rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, rotation_range=<span class="hljs-number"><span class="hljs-number">40</span></span>, width_shift_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, height_shift_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, shear_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, zoom_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, horizontal_flip=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fill_mode=<span class="hljs-string"><span class="hljs-string">'nearest'</span></span> ) train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>   ,           . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2   5): </p><br><p><img src="https://habrastorage.org/webt/8e/nu/xg/8enuxgydgovr7ppmile7k3arbwg.png"></p><br><h4 id="sozdayom-validacionnyy-nabor-dannyh">     </h4><br><p>  ,       ,       ,            .        ,   ,  . </p><br><pre> <code class="python hljs">image_gen_val = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>) val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE, directory=validation_dir, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><h1 id="sozdanie-modeli">   </h1><br><h3 id="opisyvaem-model">   </h3><br><p>    4           . </p><br><p>             0.5.  ,  50%          0.    . </p><br><p>        512     <code>relu</code> .        ‚Äî    ‚Äî  <code>softmax</code> . </p><br><pre> <code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(IMG_SHAPE, IMG_SHAPE, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><h4 id="kompilirovanie-modeli">   </h4><br><p>       <code>adam</code> .      <code>sparse_categorical_crossentropy</code> .            ,    <code>accuracy</code>   <code>metrics</code> : </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h4 id="predstavlenie-modeli">   </h4><br><p>           <strong>summary</strong> : </p><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ dropout (Dropout) (None, 7, 7, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6272) 0 _________________________________________________________________ dense (Dense) (None, 512) 3211776 _________________________________________________________________ dense_1 (Dense) (None, 2) 1026 ================================================================= Total params: 3,453,634 Trainable params: 3,453,634 Non-trainable params: 0 _________________________________________________________________</code> </pre> <br><h4 id="trenirovka-modeli">   </h4><br><p>    ! </p><br><p>         ( <code>ImageDataGenerator</code> )    <code>fit_generator</code>     <code>fit</code> : </p><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">100</span></span> history = model.fit_generator( train_data_gen, steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))), epochs=EPOCHS, validation_data=val_data_gen, validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))) )</code> </pre> <br><h4 id="vizualizaciya-rezultatov-trenirovki">    </h4><br><p>       : </p><br><pre> <code class="plaintext hljs">acc = history.history['acc'] val_acc = history.history['val_acc'] loss = history.history['loss'] val_loss = history.history['val_loss'] epochs_range = range(EPOCHS) plt.figure(figsize=(8,8)) plt.subplot(1, 2, 1) plt.plot(epochs_range, acc, label='  ') plt.plot(epochs_range, val_acc, label='  ') plt.legend(loc='lower right') plt.title('     ') plt.subplot(1, 2, 2) plt.plot(epochs_range, loss, label='  ') plt.plot(epochs_range, val_loss, label='  ') plt.legend(loc='upper right') plt.title('     ') plt.savefig('./foo.png') plt.show()</code> </pre> <br><p> : </p><br><p><img src="https://habrastorage.org/webt/bo/ea/t2/boeat2ibnf3khchazx3lslllj2e.png"></p><br><h1>      </h1><br><p>        ,    : </p><br><ol><li> <strong> </strong> :                      (   ). </li><li> <strong>  (.. augmentation)</strong> :                . </li><li> <strong> /  (.. dropout)</strong> :           (   ,      ). </li></ol><br><p>         ,     .           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . </p><br><h1> :    </h1><br><p>  CoLab      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . <br> CoLab      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . </p><br><p>                .      CoLab        .   CoLab               .   CoLab       ,             . </p><br><p>               CoLab.   CoLab        ,       ,         . </p><br><p> ! </p><br><p>ÔªøÔªø#     tf.keras </p><br><p>   CoLab     .        <code>tf.keras.Sequential</code> ,      <code>ImageDataGenerator</code> . </p><br><h1 id="importirovanie-paketov-1">   </h1><br><p>      . <code>os</code>         , <code>numpy</code>     python-  numpy-     ,  ,   <code>matplotlib.pyplot</code>         . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> glob <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt</code> </pre> <br><h3 id="todo-importiruem-tensorflow-i-keras-sloi"> TODO:  TensorFlow  Keras- </h3><br><p>         TensorFlow  <code>tf</code>  Keras-  ,         .  ,  <code>ImageDataGenerator</code> -  Keras         . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  </span></span></code> </pre> <br><h1 id="zagruzka-dannyh-1">   </h1><br><p>                ‚Äî   .              . </p><br><p>    . </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"</span></span> zip_file = tf.keras.utils.get_file(origin=_URL, fname=<span class="hljs-string"><span class="hljs-string">"flower_photos.tgz"</span></span>, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) base_dir = os.path.join(os.path.dirname(zip_file), <span class="hljs-string"><span class="hljs-string">'flower_photos'</span></span>)</code> </pre> <br><p>  ,    ,  5  : </p><br><ol><li>  </li><li>  </li><li>  </li><li>  </li><li>  </li></ol><br><p>        : </p><br><pre> <code class="python hljs">classes = [<span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]</code> </pre> <br><p>  ,   ,   : </p><br><pre> <code class="plaintext hljs">flower_photos |__ diasy |__ dandelion |__ roses |__ sunflowers |__ tulips</code> </pre> <br><p>                  .            .   ,    . </p><br><p>    2  <code>train</code>  <code>val</code>      5 - (    ).          ,  80%      ,   20%     .      : </p><br><pre> <code class="plaintext hljs">flower_photos |__ diasy |__ dandelion |__ roses |__ sunflowers |__ tulips |__ train |______ daisy: [1.jpg, 2.jpg, 3.jpg ....] |______ dandelion: [1.jpg, 2.jpg, 3.jpg ....] |______ roses: [1.jpg, 2.jpg, 3.jpg ....] |______ sunflowers: [1.jpg, 2.jpg, 3.jpg ....] |______ tulips: [1.jpg, 2.jpg, 3.jpg ....] |__ val |______ daisy: [507.jpg, 508.jpg, 509.jpg ....] |______ dandelion: [719.jpg, 720.jpg, 721.jpg ....] |______ roses: [514.jpg, 515.jpg, 516.jpg ....] |______ sunflowers: [560.jpg, 561.jpg, 562.jpg .....] |______ tulips: [640.jpg, 641.jpg, 642.jpg ....]</code> </pre> <br><p>       ,     ,   .             . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> cl <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classes: img_path = os.path.join(base_dir, cl) images = glob.glob(img_path + <span class="hljs-string"><span class="hljs-string">'/*.jpg'</span></span>) print(<span class="hljs-string"><span class="hljs-string">"{}: {} "</span></span>.format(cl, len(images))) train, val = images[:round(len(images)*<span class="hljs-number"><span class="hljs-number">0.8</span></span>)], images[round(len(images)*<span class="hljs-number"><span class="hljs-number">0.8</span></span>):] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> train: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)): os.makedirs(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)) shutil.move(t, os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> val: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl)): os.makedirs(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl)) shutil.move(v, os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl))</code> </pre> <br><p>            : </p><br><pre> <code class="python hljs">train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) val_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>)</code> </pre> <br><h1 id="rasshirenie-dannyh-1">   </h1><br><p> ,  ,  ,       .       ‚Äî   (.. augmentation)     .                    .    ,    ,         ‚Äî     ,   .          . </p><br><p>  <strong>tf.keras</strong>       ,             ‚Äî <strong>ImageDataGenerator</strong> .                  . </p><br><h2 id="eksperimentiruyte-s-razlichnymi-preobrazovaniyami-izobrazheniy">      </h2><br><p>            .            ‚Äî        ()    <code>batch_size</code> ,            <code>IMG_SHAPE</code> . </p><br><h4 id="todo-ustanovite-kolichestvo-obuchayuschih-blokov-i-razmer-izobrazheniy"> TODO:        </h4><br><p>      100   <code>batch_size</code>   150   <code>IMG_SHAPE</code> : </p><br><pre> <code class="python hljs">batch_size = IMG_SHAPE =</code> </pre> <br><h4 id="todo-primenite-proizvolnyy-gorizontalnyy-perevorot-izobrazheniya"> TODO:      </h4><br><p>      <code>ImageDataGenerator</code>   ,       ,      .     <code>.flow_from_directory</code>          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plotImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_arr)</span></span></span><span class="hljs-function">:</span></span> fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> img, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show() augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-primenite-proizvolnyy-perevorot-izobrazheniya"> TODO:     </h4><br><p>   ,   <code>ImageDataGenerator</code>          45 .     .flow_from_directory          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-primenite-proizvolnoe-uvelichenie-izobrazheniya"> TODO:     </h4><br><p>   ,   ImageDataGenerator          50%.     .flow_from_directory          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-obedinyaem-vse-izmeneniya"> TODO:    </h4><br><p>     ,   <code>ImageDataGenerator</code>          : </p><br><ul><li>   45  </li><li>   50% </li><li>   </li><li>     0.15 </li><li>     0.15 </li></ul><br><p>    <code>flow_from_directory</code>          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen_train = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-sozdayte-generator-izobrazheniy-dlya-validacionnogo-nabora-dannyh"> TODO:        </h4><br><p>         . ,   ,   <code>ImageDataGenerator</code>   ,      .    <code>flow_from_directory</code>          . ,      ,           .      . </p><br><pre> <code class="python hljs">image_gen_val = val_data_gen =</code> </pre> <br><h1 id="todo-sozdayte-svyortochnuyu-neyronnuyu-set"> TODO:     </h1><br><p>       ,     3   ‚Äî        .      16 ,  ‚Äî 32 ,  ‚Äî 64 .      33.          22. </p><br><p>         <code>Flatten</code> ,      512 .           5 ,       <strong>softmax</strong> .        <strong>relu</strong> .  ,   ,       20%. </p><br><pre> <code class="python hljs">model =</code> </pre> <br><h1 id="todo-skompiliruyte-model"> TODO:   </h1><br><p>     ,        <code>adam</code>   <code>sparse_categorical_crossentropy</code>    .                  ,         <code>compile(...)</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  </span></span></code> </pre> <br><h1 id="todo-obuchite-model"> TODO:   </h1><br><p>     ,        <strong>fit_generator</strong>    <strong>fit</strong> ,    .    <strong>fit_generator</strong>       <strong>ImageDataGenerator</strong>          .    80   ,      <strong>fit_generator</strong> -. </p><br><pre> <code class="python hljs">epochs = history =</code> </pre> <br><h1 id="todo-postroyte-grafiki-tochnosti--poter-dlya-obuchayuschego-i-validacionnogo-naborov-dannyh"> TODO:    /        </h1><br><p>     ,            : </p><br><pre> <code class="python hljs">acc = val_acc = loss = val_loss = epochs_range =</code> </pre> <br><h1 id="todo-poeksperimentiruyte-s-razlichnymi-parametrami"> TODO:     </h1><br><p>              (  +  )       512 .             .      . ,            ,       ..        <strong></strong>   ,     <strong>ImageDataGenerator</strong> ‚Äî         .       ,             . </p><br><p>      ? </p><br><h1>  </h1><br><p>                    . </p><br><p>             RGB-  : </p><br><ul><li> <strong> </strong> :      ,                  (   ); </li><li> <strong> </strong> :      3D-; </li><li> <strong>RGB-</strong> :     3  : ,   ; </li><li> <strong></strong> :                  ().               ,          ().         ‚Äî      . </li><li> <strong>   </strong> :                       .            ,          . </li><li> <strong>  </strong> :               .               ,                . </li></ul><br><p>    : </p><br><ul><li> <strong> </strong> :                    ,      . </li><li> <strong> </strong> :                    . </li><li> <strong> ()</strong> :         . </li></ul><br><p>                       .       ,                     .                    . </p><br><p> ‚Ä¶   call-to-action ‚Äî ,     share :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Telegrama</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VKontakte</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458170/">https://habr.com/ru/post/458170/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458146/index.html">Aplicaci√≥n de contabilidad de comunicaci√≥n de c√≥digo abierto en la regi√≥n.</a></li>
<li><a href="../458150/index.html">Microoptimizaci√≥n de mirilla en compiladores C ++ y C #</a></li>
<li><a href="../458156/index.html">Evaluaci√≥n comparativa de PostgreSQL en FreeBSD, CentOS, Ubuntu Debian y openSUSE</a></li>
<li><a href="../458158/index.html">Buscando asteroides - proyecto Hubble Asteroid Hunter</a></li>
<li><a href="../458164/index.html">Inteligencia artificial: se formular√° una pregunta para cada respuesta</a></li>
<li><a href="../458172/index.html">M√©todos para emparejar conexiones el√©ctricas al rastrear pares diferenciales en placas de circuito impreso</a></li>
<li><a href="../458176/index.html">La barrera de exaflops se superar√° en 2021</a></li>
<li><a href="../458180/index.html">Servidor DHCP de conmutaci√≥n por error basado en Kea</a></li>
<li><a href="../458182/index.html">Leemos VKontakte a trav√©s de RSS</a></li>
<li><a href="../458188/index.html">Como hice una red social en 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🆑 🧦 ☢️ Inmersión en redes neuronales convolucionales. Parte 5/10 - 18 💯 🏇🏽 🥕</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El curso completo en ruso se puede encontrar en este enlace . 
 El curso de inglés original está disponible en este enlace . 



 Nuevas conferencias ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inmersión en redes neuronales convolucionales. Parte 5/10 - 18</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458170/"><p>  El curso completo en ruso se puede encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br>  El curso de inglés original está disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . </p><br><p><img src="https://habrastorage.org/webt/1m/hz/qn/1mhzqnwa288uxjmptqhexriiahc.png"><br>  <i>Nuevas conferencias están programadas cada 2-3 días.</i> </p><a name="habracut"></a><br><h1>  Contenido </h1><br><ol><li>  Entrevista con Sebastian Trun </li><li>  Introduccion </li><li>  Conjunto de datos de perros y gatos </li><li>  Imágenes de varios tamaños. </li><li>  Imágenes a color.  Parte 1 </li><li>  Imágenes a color.  Parte 2 </li><li>  Operación de convolución en imágenes en color </li><li>  La operación de submuestreo por el valor máximo en imágenes en color </li><li>  CoLab: gatos y perros </li><li>  Softmax y sigmoide </li><li>  Cheque </li><li>  Extensión de imagen </li><li>  Excepción </li><li>  CoLab: perros y gatos.  Repetición </li><li>  Otras técnicas para prevenir el reentrenamiento </li><li>  Ejercicio: clasificación de imágenes en color </li><li>  Resumen </li></ol><br><h1>  Softmax y Sigmoide </h1><br><p>  En nuestro último CoLab práctico, utilizamos la siguiente arquitectura de red neuronal convolucional: </p><br><pre><code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><p>  Tenga en cuenta que nuestra última capa (nuestro clasificador) consiste en una capa completamente conectada con dos neuronas de salida y una <code>softmax</code> activación <code>softmax</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)</code> </pre> <br><p>  Otro enfoque popular para resolver problemas de clasificación binaria es el uso de un clasificador, que consiste en una capa completamente conectada con 1 neurona de salida y <code>sigmoid</code> activación <code>sigmoid</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)</code> </pre> <br><p>  Ambas opciones funcionarán bien en el problema de clasificación binaria.  Sin embargo, lo que debe tener en cuenta si decide usar la <code>sigmoid</code> activación <code>sigmoid</code> en su clasificador, también deberá cambiar la función de pérdida en el método <code>model.compile()</code> de <code>sparse_categorical_crossentropy</code> a <code>binary_crossentropy</code> como en el ejemplo a continuación: </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h1>  Validación </h1><br><p>  En clases pasadas, estudiamos la precisión de nuestras redes neuronales convolucionales utilizando la métrica de <code>accuracy</code> en un conjunto de datos de prueba.  Cuando desarrollamos una red neuronal convolucional para clasificar imágenes del conjunto de datos FASHION MNIST, obtuvimos un 97% de precisión en el conjunto de datos de entrenamiento y solo un 92% de precisión en el conjunto de datos de prueba.  Todo esto sucedió porque nuestro modelo fue reentrenado.  En otras palabras, nuestra red neuronal convolucional estaba empezando a recordar el conjunto de datos de entrenamiento.  Sin embargo, pudimos aprender sobre la reentrenamiento solo <em>después de</em> entrenar y probar el modelo con los datos disponibles al comparar la precisión del conjunto de datos de entrenamiento y el conjunto de datos de prueba. </p><br><p>  Para evitar este problema, a menudo utilizamos un conjunto de datos para la validación: </p><br><p><img src="https://habrastorage.org/webt/mj/fw/ea/mjfweaqi7ztkkfbmznz1nfnogjq.png"></p><br><p>  Durante el entrenamiento, nuestra red neuronal convolucional "ve" solo el conjunto de datos de entrenamiento y toma decisiones sobre cómo cambiar los valores de los parámetros internos: pesos y desplazamientos.  Después de cada iteración de entrenamiento, verificamos el estado del modelo calculando el valor de la función de pérdida en el conjunto de datos de entrenamiento y en el conjunto de datos de validación.  Vale la pena señalar y prestar especial atención al hecho de que el modelo no utiliza los datos del conjunto de validación para ajustar los valores de los parámetros internos.  La verificación de la precisión del modelo en el conjunto de datos de validación solo nos dice qué tan bien funciona nuestro modelo en este mismo conjunto de datos.  Por lo tanto, los resultados del modelo en el conjunto de datos de validación nos dicen qué tan bien nuestro modelo ha aprendido a generalizar los datos obtenidos y aplicar esta generalización a un nuevo conjunto de datos. </p><br><p>  La idea es que, dado que no usamos el conjunto de datos de validación cuando entrenamos el modelo, probar el modelo en el conjunto de validación nos permitirá comprender si el modelo está reentrenado o no. </p><br><p>  Veamos un ejemplo. </p><br><p>  En CoLab, que realizamos algunos puntos arriba, entrenamos nuestra red neuronal durante 15 iteraciones. </p><br><pre> <code class="plaintext hljs">Epoch 15/15 10/10 [===] - loss: 1.0124 - acc: 0.7170 20/20 [===] - loss: 0.0528 - acc: 0.9900 - val_loss: 1.0124 - val_acc: 0.7070</code> </pre> <br><p>  Si observamos la precisión de las predicciones en los conjuntos de datos de entrenamiento y validación en la decimoquinta iteración de entrenamiento, podemos ver que hemos logrado una alta precisión en el conjunto de datos de entrenamiento y un indicador significativamente bajo en el conjunto de datos de validación: <code>0.9900</code> versus <code>0.7070</code> . </p><br><p>  Este es un signo obvio de reciclaje.  La red neuronal recordó el conjunto de datos de entrenamiento, por lo tanto, funciona con una precisión increíble en los datos de entrada.  Sin embargo, tan pronto como se trata de verificar la precisión en un conjunto de datos de validación que el modelo no "vio", los resultados se reducen significativamente. </p><br><p>  Una forma de evitar el reentrenamiento es estudiar cuidadosamente el gráfico de los valores de la función de pérdida en los conjuntos de datos de entrenamiento y validación en todas las iteraciones de entrenamiento: </p><br><p><img src="https://habrastorage.org/webt/mo/bb/ml/mobbml4mb5sqt1ugcjjmj69ziau.png"></p><br><p>  En CoLab, creamos un gráfico similar y obtuvimos algo similar al gráfico anterior de la dependencia de la función de pérdida en la iteración de entrenamiento. </p><br><p>  Puede notar que después de una determinada iteración de entrenamiento, el valor de la función de pérdida en el conjunto de datos de validación comienza a aumentar, mientras que el valor de la función de pérdida en el conjunto de datos de entrenamiento continúa disminuyendo. </p><br><p>  Al final de la 15ª iteración de entrenamiento, notamos que el valor de la función de pérdida en el conjunto de datos de validación es extremadamente alto, y el valor de la función de pérdida en el conjunto de datos de entrenamiento es extremadamente pequeño.  En realidad, este es el indicador del reentrenamiento de la red neuronal. </p><br><p>  Al observar cuidadosamente el gráfico, puede comprender que, literalmente, después de algunas iteraciones de entrenamiento, nuestra red neuronal comienza a almacenar simplemente datos de entrenamiento, lo que significa que la capacidad del modelo para generalizar se reduce, lo que conduce a un deterioro en la precisión del conjunto de datos de validación. </p><br><p>  Como probablemente ya haya entendido, el conjunto de datos de validación nos permite determinar la cantidad de iteraciones de entrenamiento que deben realizarse para que nuestra red neuronal convolucional sea precisa y, al mismo tiempo, no se vuelva a entrenar. </p><br><p>  Tal enfoque puede ser extremadamente útil si tenemos la opción de varias arquitecturas de redes neuronales convolucionales: </p><br><p><img src="https://habrastorage.org/webt/ay/5j/lq/ay5jlqtty3bwks_zdjclydfgumq.png"></p><br><p>  Por ejemplo, si decide el número de capas en una red neuronal convolucional, puede crear varias arquitecturas de redes neuronales y luego comparar su precisión utilizando un conjunto de datos para la validación. </p><br><p>  La arquitectura de la red neuronal, que le permite alcanzar el valor mínimo de la función de pérdida y será la mejor para resolver su tarea. </p><br><p>  La siguiente pregunta que puede tener es ¿por qué crear un conjunto de datos de validación si ya tenemos un conjunto de datos de prueba?  ¿Podemos usar un conjunto de datos de prueba para la validación? </p><br><p>  El problema es que, a pesar del hecho de que no usamos el conjunto de datos de validación en el proceso de capacitación del modelo, usamos los resultados de trabajar en el conjunto de datos de prueba para mejorar la precisión del modelo, lo que significa que el conjunto de datos de prueba afecta los pesos y sesgos en los nervios red </p><br><p><img src="https://habrastorage.org/webt/ys/7a/ih/ys7aihyxutwvpilqpnsaczev5eo.png"></p><br><p>  Es por esta razón que necesitamos un conjunto de datos de validación que nuestro modelo nunca haya visto antes para verificar con precisión su rendimiento. </p><br><p>  Acabamos de descubrir cómo un conjunto de datos validado puede ayudarnos a evitar el reciclaje.  En las siguientes partes, hablaremos sobre la expansión de datos (el llamado aumento) y la desconexión (el llamado abandono) de las neuronas, dos técnicas populares que también pueden ayudarnos a evitar el reentrenamiento. </p><br><h1>  Extensión de imagen (aumento) </h1><br><p>  Al entrenar redes neuronales para determinar objetos de una determinada clase, queremos que nuestra red neuronal encuentre estos objetos, independientemente de su ubicación y tamaño en la imagen. </p><br><p>  Por ejemplo, supongamos que queremos entrenar nuestra red neuronal para reconocer perros en imágenes: </p><br><p><img src="https://habrastorage.org/webt/0y/d2/cu/0yd2cuip0aaef2hi8auegdq6mt8.png"></p><br><p>  Por lo tanto, queremos que nuestra red neuronal determine la presencia de un perro en la imagen, independientemente de qué tan grande sea el perro y en qué parte de la imagen sea, si parte del perro es visible o todo el perro.  Queremos asegurarnos de que nuestra red neuronal pueda procesar todas estas opciones durante el entrenamiento. </p><br><p>  Si tienes la suerte y tienes un gran conjunto de datos de entrenamiento, entonces podemos decir con confianza que tienes suerte y que es poco probable que tu red neuronal se vuelva a entrenar.  Sin embargo, lo que sucede con bastante frecuencia, tenemos que trabajar con un conjunto limitado de imágenes (datos de entrenamiento), que, a su vez, conducirán a nuestra red neuronal convolucional con una alta probabilidad de reentrenamiento y reducirán su capacidad de generalizar y producir el resultado deseado en datos que no "vio" antes. </p><br><p>  Este problema se puede resolver utilizando una técnica llamada "extensión" (aumento de imagen).  La expansión de imágenes (datos) funciona creando (generando) nuevas imágenes para el entrenamiento mediante la aplicación de transformaciones arbitrarias del conjunto original de imágenes del conjunto de entrenamiento. </p><br><p>  Por ejemplo, podemos tomar una de las imágenes de origen de nuestro conjunto de datos de entrenamiento y aplicarle varias transformaciones arbitrarias: voltearla en X grados, reflejarla horizontalmente y hacer un aumento arbitrario. </p><br><p><img src="https://habrastorage.org/webt/nd/ps/fv/ndpsfvldpaymeybswwqkmyspr40.png"></p><br><p>  Al agregar las imágenes generadas a nuestro conjunto de datos de entrenamiento, estamos convencidos de que nuestra red neuronal "verá" un número suficiente de ejemplos diferentes para el entrenamiento.  Como resultado de tales acciones, nuestra red neuronal convolucional se generalizará mejor y trabajará en los datos que aún no ha visto y podremos evitar el reentrenamiento. </p><br><p>  En la siguiente parte, aprenderemos qué es un abandono (un apagado), otra técnica para evitar sobreajustar un modelo. </p><br><h1>  Excepción (abandono) </h1><br><p>  En esta parte, aprenderemos una nueva técnica: el abandono, que también nos ayudará a evitar un entrenamiento excesivo del modelo.  Como ya sabemos desde las primeras partes, la red neuronal optimiza los parámetros internos (pesos y desplazamientos) para minimizar la función de pérdida. </p><br><p>  Uno de los problemas que se pueden encontrar al entrenar una red neuronal son los valores enormes en una parte de la red neuronal y los valores pequeños en la otra parte de la red neuronal. </p><br><p><img src="https://habrastorage.org/webt/op/bb/cf/opbbcfp4z1wl_geilpygynmvdz8.png"></p><br><p>  Como resultado, resulta que las neuronas con mayor peso juegan <strong>un</strong> papel más importante en el proceso de aprendizaje, mientras que las neuronas con menor peso dejan de ser significativas y están cada vez menos sujetas a cambios.  Una forma de evitar esto es usar un abandono arbitrario de neuronas. </p><br><p>  Apagado (abandono): el proceso de apagado selectivo de neuronas en el proceso de aprendizaje. </p><br><p><img src="https://habrastorage.org/webt/8j/7t/0p/8j7t0p91wpjv2qswrxugif3b2e4.png"></p><br><p>  El apagado selectivo de algunas neuronas en el proceso de aprendizaje le permite involucrar activamente a otras neuronas en el aprendizaje.  Durante las iteraciones de entrenamiento, deshabilitamos arbitrariamente algunas neuronas. </p><br><p>  Veamos un ejemplo.  Imagine que en la primera iteración de entrenamiento, apagamos dos neuronas resaltadas en negro: </p><br><p><img src="https://habrastorage.org/webt/rv/f7/uv/rvf7uvlolq1t38zvhi50mqw7hgg.png"></p><br><p>  Los procesos de propagación directa y propagación inversa se producen sin el uso de dos neuronas aisladas. </p><br><p>  En la segunda iteración de entrenamiento, decidimos no usar las siguientes tres neuronas: desactívelas: </p><br><p><img src="https://habrastorage.org/webt/lq/dq/k2/lqdqk2gkxaagbvcpgwsybs8i2wq.png"></p><br><p>  Como en el caso anterior, en los procesos de propagación directa e inversa, no utilizamos estas tres neuronas.  En la última iteración del tercer entrenamiento, decidimos no usar estas dos neuronas: </p><br><p><img src="https://habrastorage.org/webt/dk/jf/ac/dkjfacty06iu6r6aopxq9by5qs4.png"></p><br><p>  Y en este caso, no usamos neuronas desconectadas en los procesos de propagación directa e inversa.  Y así sucesivamente. </p><br><p>  Al entrenar nuestra red neuronal de esta manera, podemos evitar el reentrenamiento.  Podemos decir que nuestra red neuronal se está volviendo más estable, porque con este enfoque, no puede confiar en absolutamente todas las neuronas para resolver el problema.  Por lo tanto, otras neuronas comienzan a tomar una parte más activa en la formación del valor de salida requerido y también comienzan a hacer frente a la tarea. </p><br><p>  En la práctica, este enfoque requiere indicar la probabilidad de eliminar cada una de las neuronas en cualquier iteración de entrenamiento.  Tenga en cuenta que, al indicar la probabilidad de que nos encontremos en una situación en la que algunas neuronas se desconectarán con más frecuencia que otras, y algunas no se desconectarán en absoluto.  Sin embargo, esto no es un problema, porque este proceso se realiza muchas veces y, en promedio, cada neurona con la misma probabilidad puede desconectarse. </p><br><p>  Ahora apliquemos el conocimiento teórico adquirido en la práctica y refinemos nuestro clasificador de imágenes de gatos y perros. </p><br><h1>  CoLab: perros y gatos.  Repetición </h1><br><p>  CoLab en inglés está disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br>  CoLab en ruso está disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . </p><br><h2 id="koshki-vs-sobaki-klassifikaciya-izobrazheniy-s-rasshireniem">  Gatos VS Perros: clasificación de imágenes con extensión </h2><br><p>  En este tutorial, discutiremos cómo clasificar las imágenes de gatos y perros.  Desarrollaremos un clasificador de imágenes utilizando el modelo <code>tf.keras.Sequential</code> y usaremos <code>tf.keras.Sequential</code> para cargar los datos. </p><br><h3 id="idei-kotorye-budut-zatronuty-v-etoy-chasti">  Ideas para ser cubiertas en esta parte: </h3><br><p>  Obtendremos experiencia práctica en el desarrollo de un clasificador y desarrollaremos una comprensión intuitiva de los siguientes conceptos: </p><br><ol><li>  Construir un modelo de flujo de datos ( <em>tuberías de entrada de datos</em> ) usando la clase <code>tf.keras.preprocessing.image.ImageDataGenerator</code> (¿Cómo trabajar eficientemente con datos en el disco que interactúan con el modelo?) </li><li>  Reciclaje: ¿qué es y cómo determinarlo? </li><li>  El aumento de datos y el método de abandono son técnicas clave en la lucha contra el reciclaje en las tareas de reconocimiento de patrones que implementaremos en nuestro proceso de capacitación modelo. </li></ol><br><h4 id="my-budem-sledovat-osnovnomu-podhodu-pri-razrabotke-modeley-mashinnogo-obucheniya">  Seguiremos el enfoque básico en el desarrollo de modelos de aprendizaje automático: </h4><br><ol><li>  Explore y comprenda datos </li><li>  Configurar flujo de entrada </li><li>  Construir modelo </li><li>  Modelo de tren </li><li>  Modelo de prueba </li><li>  Mejorar modelo / repetir proceso </li></ol><br><p>  <strong>Antes de comenzar ...</strong> </p><br><p>  Antes de comenzar el código en el editor, le recomendamos que restablezca todas las configuraciones en <strong>Runtime -&gt; Restablecer todo</strong> en el menú superior.  Tal acción ayudará a evitar problemas con la falta de memoria, si trabajó en paralelo o trabajó con varios editores. </p><br><h1 id="importirovanie-paketov">  Importar paquetes </h1><br><p>  Comencemos importando los paquetes que necesita: </p><br><ul><li>  <code>os</code> - leer archivos y estructuras de directorios; </li><li>  <code>numpy</code> : para algunas operaciones matriciales fuera de TensorFlow; </li><li>  <code>matplotlib.pyplot</code> : trazar y mostrar imágenes de un conjunto de datos de prueba y validación. </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><p>  Importar <code>TensorFlow</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging logger = tf.get_logger() logger.setLevel(logging.ERROR)</code> </pre> <br><h1 id="zagruzka-dannyh">  Carga de datos </h1><br><p>  Comenzamos el desarrollo de nuestro clasificador cargando un conjunto de datos.  El conjunto de datos que utilizamos es una versión filtrada del conjunto de datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dogs vs Cats</a> del servicio Kaggle (al final, Microsoft Research proporciona este conjunto de datos). </p><br><p>  En el pasado, CoLab y yo usamos un conjunto de datos del propio módulo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow Dataset</a> , que es extremadamente conveniente para el trabajo y las pruebas.  En este CoLab, sin embargo, utilizaremos la clase <code>tf.keras.preprocessing.image.ImageDataGenerator</code> para leer datos del disco.  Por lo tanto, primero debemos descargar el conjunto de datos Dog VS Cats y descomprimirlo. </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span> zip_dir = tf.keras.utils.get_file(<span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filterted.zip'</span></span>, origin=_URL, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  El conjunto de datos que descargamos tiene la siguiente estructura: </p><br><pre> <code class="plaintext hljs">cats_and_dogs_filtered |__ train |______ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...] |______ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...] |__ validation |______ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...] |______ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]</code> </pre> <br><p>  Para obtener la lista completa de directores, puede usar el siguiente comando: </p><br><pre> <code class="python hljs">zip_dir_base = os.path.dirname(zip_dir) !find $zip_dir_base -type d -<span class="hljs-keyword"><span class="hljs-keyword">print</span></span></code> </pre> <br><p>  Salida (al comenzar desde CoLab): </p><br><pre> <code class="plaintext hljs">/root/.keras/datasets /root/.keras/datasets/cats_and_dogs_filtered /root/.keras/datasets/cats_and_dogs_filtered/train /root/.keras/datasets/cats_and_dogs_filtered/train/dogs /root/.keras/datasets/cats_and_dogs_filtered/train/cats /root/.keras/datasets/cats_and_dogs_filtered/validation /root/.keras/datasets/cats_and_dogs_filtered/validation/dogs /root/.keras/datasets/cats_and_dogs_filtered/validation/cats</code> </pre> <br><p>  Ahora asigne las rutas correctas a los directorios con los conjuntos de datos para capacitación y validación de las variables: </p><br><pre> <code class="python hljs">base_dir = os.path.join(os.path.dirname(zip_dir), <span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filtered'</span></span>) train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) validation_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'validation'</span></span>) train_cats_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) train_dogs_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>) validation_cats_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) validation_dogs_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>)</code> </pre> <br><h4 id="razbiraemsya-s-dannymi-i-ih-strukturoy">  Comprender los datos y su estructura. </h4><br><p>  Veamos cuántas imágenes de gatos y perros tenemos en los conjuntos de datos de prueba y validación (directorios). </p><br><pre> <code class="python hljs">num_cats_tr = len(os.listdir(train_cats_dir)) num_dogs_tr = len(os.listdir(train_dogs_dir)) num_cats_val = len(os.listdir(validation_cats_dir)) num_dogs_val = len(os.listdir(validation_dogs_dir)) total_train = num_cats_tr + num_dogs_tr total_val = num_cats_val + num_dogs_val</code> </pre> <br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_val) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_val) print(<span class="hljs-string"><span class="hljs-string">'--'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_train) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_val)</code> </pre> <br><p>  Conclusión </p><br><pre> <code class="plaintext hljs">    : 1000     : 1000     : 500     : 500 --      : 2000      : 1000</code> </pre> <br><h1 id="ustanovka-parametrov-modeli">  Establecer parámetros del modelo </h1><br><p>  Para mayor comodidad, colocaremos la instalación de las variables que necesitamos para un mayor procesamiento de datos y capacitación de modelos en un anuncio separado: </p><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#          IMG_SHAPE = 150 #       </span></span></code> </pre> <br><h1 id="rasshirenie-dannyh">  Extensión de datos </h1><br><p>  La reentrenamiento generalmente ocurre cuando hay pocos ejemplos de capacitación en nuestro conjunto de datos.  Una forma de eliminar la escasez de datos es expandirlos al número correcto de instancias y la variabilidad correcta.  La extensión de datos es el proceso de generar datos a partir de instancias existentes mediante la aplicación de diversas transformaciones al conjunto de datos original.  El propósito de este método es aumentar el número de instancias de entrada únicas que el modelo nunca volverá a ver, lo que, a su vez, permitirá que el modelo generalice mejor los datos de entrada y muestre una mayor precisión en el conjunto de datos de validación. </p><br><p>  Usando <strong><code>tf.keras</code></strong> podemos implementar tales transformaciones aleatorias y generar nuevas imágenes a través de la clase <strong><code>ImageDataGenerator</code></strong> .  Será suficiente para nosotros pasar en forma de parámetros varias transformaciones que nos gustaría aplicar a las imágenes, y la clase misma se encargará del resto durante el entrenamiento del modelo. </p><br><p>  Primero, escriba una función que muestre imágenes obtenidas como resultado de transformaciones aleatorias.  Luego examinaremos con más detalle las transformaciones utilizadas en el proceso de expansión del conjunto de datos original. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plotImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_arr)</span></span></span><span class="hljs-function">:</span></span> fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> img, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show()</code> </pre> <br><h4 id="perevorachivanie-izobrazheniya-po-gorizontali">  Voltear la imagen horizontalmente </h4><br><p>  Podemos comenzar con una conversión simple: volteo horizontal de la imagen.  Veamos cómo se verá esta transformación aplicada a nuestras imágenes de origen.        <code>horizontal_flip=True</code>   <strong>ImageDataGenerator</strong> . </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, horizontal_flip=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>                    .      (  )   . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2  5 ): </p><br><p><img src="https://habrastorage.org/webt/9k/ss/zk/9ksszkjktuykiawts9xldwp8d6e.png"></p><br><h4 id="povorot-izobrazheniy">   </h4><br><p>            .        45. </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, rotation_range=<span class="hljs-number"><span class="hljs-number">45</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>         —          5   .      (  )   . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2   5): </p><br><p><img src="https://habrastorage.org/webt/f4/7a/du/f47adubevummwogquqvplmzvy5k.png"></p><br><h4 id="primenenie-uvelicheniya">   </h4><br><p>             —    50%. </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, zoom_range=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>   ,      — 5      .   (  )       . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2  5 ): </p><br><p><img src="https://habrastorage.org/webt/i6/75/qx/i675qx7wsf8c4woaxoipll-j8cs.png"></p><br><h4 id="obedinyaem-vsyo-vmeste">    </h4><br><p>       ,   ,   ,          <code>ImageDataGenerator</code> . </p><br><p>       —   ,   45 ,   ,   ,    . </p><br><pre> <code class="python hljs">image_gen_train = ImageDataGenerator( rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, rotation_range=<span class="hljs-number"><span class="hljs-number">40</span></span>, width_shift_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, height_shift_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, shear_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, zoom_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, horizontal_flip=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fill_mode=<span class="hljs-string"><span class="hljs-string">'nearest'</span></span> ) train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>   ,           . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2   5): </p><br><p><img src="https://habrastorage.org/webt/8e/nu/xg/8enuxgydgovr7ppmile7k3arbwg.png"></p><br><h4 id="sozdayom-validacionnyy-nabor-dannyh">     </h4><br><p>  ,       ,       ,            .        ,   ,  . </p><br><pre> <code class="python hljs">image_gen_val = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>) val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE, directory=validation_dir, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><h1 id="sozdanie-modeli">   </h1><br><h3 id="opisyvaem-model">   </h3><br><p>    4           . </p><br><p>             0.5.  ,  50%          0.    . </p><br><p>        512     <code>relu</code> .        —    —  <code>softmax</code> . </p><br><pre> <code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(IMG_SHAPE, IMG_SHAPE, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><h4 id="kompilirovanie-modeli">   </h4><br><p>       <code>adam</code> .      <code>sparse_categorical_crossentropy</code> .            ,    <code>accuracy</code>   <code>metrics</code> : </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h4 id="predstavlenie-modeli">   </h4><br><p>           <strong>summary</strong> : </p><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ dropout (Dropout) (None, 7, 7, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6272) 0 _________________________________________________________________ dense (Dense) (None, 512) 3211776 _________________________________________________________________ dense_1 (Dense) (None, 2) 1026 ================================================================= Total params: 3,453,634 Trainable params: 3,453,634 Non-trainable params: 0 _________________________________________________________________</code> </pre> <br><h4 id="trenirovka-modeli">   </h4><br><p>    ! </p><br><p>         ( <code>ImageDataGenerator</code> )    <code>fit_generator</code>     <code>fit</code> : </p><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">100</span></span> history = model.fit_generator( train_data_gen, steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))), epochs=EPOCHS, validation_data=val_data_gen, validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))) )</code> </pre> <br><h4 id="vizualizaciya-rezultatov-trenirovki">    </h4><br><p>       : </p><br><pre> <code class="plaintext hljs">acc = history.history['acc'] val_acc = history.history['val_acc'] loss = history.history['loss'] val_loss = history.history['val_loss'] epochs_range = range(EPOCHS) plt.figure(figsize=(8,8)) plt.subplot(1, 2, 1) plt.plot(epochs_range, acc, label='  ') plt.plot(epochs_range, val_acc, label='  ') plt.legend(loc='lower right') plt.title('     ') plt.subplot(1, 2, 2) plt.plot(epochs_range, loss, label='  ') plt.plot(epochs_range, val_loss, label='  ') plt.legend(loc='upper right') plt.title('     ') plt.savefig('./foo.png') plt.show()</code> </pre> <br><p> : </p><br><p><img src="https://habrastorage.org/webt/bo/ea/t2/boeat2ibnf3khchazx3lslllj2e.png"></p><br><h1>      </h1><br><p>        ,    : </p><br><ol><li> <strong> </strong> :                      (   ). </li><li> <strong>  (.. augmentation)</strong> :                . </li><li> <strong> /  (.. dropout)</strong> :           (   ,      ). </li></ol><br><p>         ,     .           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . </p><br><h1> :    </h1><br><p>  CoLab      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . <br> CoLab      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . </p><br><p>                .      CoLab        .   CoLab               .   CoLab       ,             . </p><br><p>               CoLab.   CoLab        ,       ,         . </p><br><p> ! </p><br><p>﻿﻿#     tf.keras </p><br><p>   CoLab     .        <code>tf.keras.Sequential</code> ,      <code>ImageDataGenerator</code> . </p><br><h1 id="importirovanie-paketov-1">   </h1><br><p>      . <code>os</code>         , <code>numpy</code>     python-  numpy-     ,  ,   <code>matplotlib.pyplot</code>         . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> glob <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt</code> </pre> <br><h3 id="todo-importiruem-tensorflow-i-keras-sloi"> TODO:  TensorFlow  Keras- </h3><br><p>         TensorFlow  <code>tf</code>  Keras-  ,         .  ,  <code>ImageDataGenerator</code> -  Keras         . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  </span></span></code> </pre> <br><h1 id="zagruzka-dannyh-1">   </h1><br><p>                —   .              . </p><br><p>    . </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"</span></span> zip_file = tf.keras.utils.get_file(origin=_URL, fname=<span class="hljs-string"><span class="hljs-string">"flower_photos.tgz"</span></span>, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) base_dir = os.path.join(os.path.dirname(zip_file), <span class="hljs-string"><span class="hljs-string">'flower_photos'</span></span>)</code> </pre> <br><p>  ,    ,  5  : </p><br><ol><li>  </li><li>  </li><li>  </li><li>  </li><li>  </li></ol><br><p>        : </p><br><pre> <code class="python hljs">classes = [<span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]</code> </pre> <br><p>  ,   ,   : </p><br><pre> <code class="plaintext hljs">flower_photos |__ diasy |__ dandelion |__ roses |__ sunflowers |__ tulips</code> </pre> <br><p>                  .            .   ,    . </p><br><p>    2  <code>train</code>  <code>val</code>      5 - (    ).          ,  80%      ,   20%     .      : </p><br><pre> <code class="plaintext hljs">flower_photos |__ diasy |__ dandelion |__ roses |__ sunflowers |__ tulips |__ train |______ daisy: [1.jpg, 2.jpg, 3.jpg ....] |______ dandelion: [1.jpg, 2.jpg, 3.jpg ....] |______ roses: [1.jpg, 2.jpg, 3.jpg ....] |______ sunflowers: [1.jpg, 2.jpg, 3.jpg ....] |______ tulips: [1.jpg, 2.jpg, 3.jpg ....] |__ val |______ daisy: [507.jpg, 508.jpg, 509.jpg ....] |______ dandelion: [719.jpg, 720.jpg, 721.jpg ....] |______ roses: [514.jpg, 515.jpg, 516.jpg ....] |______ sunflowers: [560.jpg, 561.jpg, 562.jpg .....] |______ tulips: [640.jpg, 641.jpg, 642.jpg ....]</code> </pre> <br><p>       ,     ,   .             . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> cl <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classes: img_path = os.path.join(base_dir, cl) images = glob.glob(img_path + <span class="hljs-string"><span class="hljs-string">'/*.jpg'</span></span>) print(<span class="hljs-string"><span class="hljs-string">"{}: {} "</span></span>.format(cl, len(images))) train, val = images[:round(len(images)*<span class="hljs-number"><span class="hljs-number">0.8</span></span>)], images[round(len(images)*<span class="hljs-number"><span class="hljs-number">0.8</span></span>):] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> train: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)): os.makedirs(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)) shutil.move(t, os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> val: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl)): os.makedirs(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl)) shutil.move(v, os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl))</code> </pre> <br><p>            : </p><br><pre> <code class="python hljs">train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) val_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>)</code> </pre> <br><h1 id="rasshirenie-dannyh-1">   </h1><br><p> ,  ,  ,       .       —   (.. augmentation)     .                    .    ,    ,         —     ,   .          . </p><br><p>  <strong>tf.keras</strong>       ,             — <strong>ImageDataGenerator</strong> .                  . </p><br><h2 id="eksperimentiruyte-s-razlichnymi-preobrazovaniyami-izobrazheniy">      </h2><br><p>            .            —        ()    <code>batch_size</code> ,            <code>IMG_SHAPE</code> . </p><br><h4 id="todo-ustanovite-kolichestvo-obuchayuschih-blokov-i-razmer-izobrazheniy"> TODO:        </h4><br><p>      100   <code>batch_size</code>   150   <code>IMG_SHAPE</code> : </p><br><pre> <code class="python hljs">batch_size = IMG_SHAPE =</code> </pre> <br><h4 id="todo-primenite-proizvolnyy-gorizontalnyy-perevorot-izobrazheniya"> TODO:      </h4><br><p>      <code>ImageDataGenerator</code>   ,       ,      .     <code>.flow_from_directory</code>          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plotImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_arr)</span></span></span><span class="hljs-function">:</span></span> fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> img, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show() augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-primenite-proizvolnyy-perevorot-izobrazheniya"> TODO:     </h4><br><p>   ,   <code>ImageDataGenerator</code>          45 .     .flow_from_directory          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-primenite-proizvolnoe-uvelichenie-izobrazheniya"> TODO:     </h4><br><p>   ,   ImageDataGenerator          50%.     .flow_from_directory          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-obedinyaem-vse-izmeneniya"> TODO:    </h4><br><p>     ,   <code>ImageDataGenerator</code>          : </p><br><ul><li>   45  </li><li>   50% </li><li>   </li><li>     0.15 </li><li>     0.15 </li></ul><br><p>    <code>flow_from_directory</code>          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen_train = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-sozdayte-generator-izobrazheniy-dlya-validacionnogo-nabora-dannyh"> TODO:        </h4><br><p>         . ,   ,   <code>ImageDataGenerator</code>   ,      .    <code>flow_from_directory</code>          . ,      ,           .      . </p><br><pre> <code class="python hljs">image_gen_val = val_data_gen =</code> </pre> <br><h1 id="todo-sozdayte-svyortochnuyu-neyronnuyu-set"> TODO:     </h1><br><p>       ,     3   —        .      16 ,  — 32 ,  — 64 .      33.          22. </p><br><p>         <code>Flatten</code> ,      512 .           5 ,       <strong>softmax</strong> .        <strong>relu</strong> .  ,   ,       20%. </p><br><pre> <code class="python hljs">model =</code> </pre> <br><h1 id="todo-skompiliruyte-model"> TODO:   </h1><br><p>     ,        <code>adam</code>   <code>sparse_categorical_crossentropy</code>    .                  ,         <code>compile(...)</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  </span></span></code> </pre> <br><h1 id="todo-obuchite-model"> TODO:   </h1><br><p>     ,        <strong>fit_generator</strong>    <strong>fit</strong> ,    .    <strong>fit_generator</strong>       <strong>ImageDataGenerator</strong>          .    80   ,      <strong>fit_generator</strong> -. </p><br><pre> <code class="python hljs">epochs = history =</code> </pre> <br><h1 id="todo-postroyte-grafiki-tochnosti--poter-dlya-obuchayuschego-i-validacionnogo-naborov-dannyh"> TODO:    /        </h1><br><p>     ,            : </p><br><pre> <code class="python hljs">acc = val_acc = loss = val_loss = epochs_range =</code> </pre> <br><h1 id="todo-poeksperimentiruyte-s-razlichnymi-parametrami"> TODO:     </h1><br><p>              (  +  )       512 .             .      . ,            ,       ..        <strong></strong>   ,     <strong>ImageDataGenerator</strong> —         .       ,             . </p><br><p>      ? </p><br><h1>  </h1><br><p>                    . </p><br><p>             RGB-  : </p><br><ul><li> <strong> </strong> :      ,                  (   ); </li><li> <strong> </strong> :      3D-; </li><li> <strong>RGB-</strong> :     3  : ,   ; </li><li> <strong></strong> :                  ().               ,          ().         —      . </li><li> <strong>   </strong> :                       .            ,          . </li><li> <strong>  </strong> :               .               ,                . </li></ul><br><p>    : </p><br><ul><li> <strong> </strong> :                    ,      . </li><li> <strong> </strong> :                    . </li><li> <strong> ()</strong> :         . </li></ul><br><p>                       .       ,                     .                    . </p><br><p> …   call-to-action — ,     share :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Telegrama</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VKontakte</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458170/">https://habr.com/ru/post/458170/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458146/index.html">Aplicación de contabilidad de comunicación de código abierto en la región.</a></li>
<li><a href="../458150/index.html">Microoptimización de mirilla en compiladores C ++ y C #</a></li>
<li><a href="../458156/index.html">Evaluación comparativa de PostgreSQL en FreeBSD, CentOS, Ubuntu Debian y openSUSE</a></li>
<li><a href="../458158/index.html">Buscando asteroides - proyecto Hubble Asteroid Hunter</a></li>
<li><a href="../458164/index.html">Inteligencia artificial: se formulará una pregunta para cada respuesta</a></li>
<li><a href="../458172/index.html">Métodos para emparejar conexiones eléctricas al rastrear pares diferenciales en placas de circuito impreso</a></li>
<li><a href="../458176/index.html">La barrera de exaflops se superará en 2021</a></li>
<li><a href="../458180/index.html">Servidor DHCP de conmutación por error basado en Kea</a></li>
<li><a href="../458182/index.html">Leemos VKontakte a través de RSS</a></li>
<li><a href="../458188/index.html">Como hice una red social en 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
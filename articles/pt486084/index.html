<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ¼â€âš•ï¸ ğŸ¥„ ğŸš¤ Substituindo discos menores por discos maiores no Linux ğŸ“ˆ âš“ï¸ ğŸ“</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="OlÃ¡ pessoal. Antecipando o inÃ­cio de um novo grupo do curso Linux Administrator, estamos publicando material Ãºtil escrito por nossos alunos, bem como ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Substituindo discos menores por discos maiores no Linux</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/486084/">  <i>OlÃ¡ pessoal.</i>  <i>Antecipando o inÃ­cio de um novo grupo do curso <a href="https://otus.pw/RDsq/">Linux Administrator, estamos</a> publicando material Ãºtil escrito por nossos alunos, bem como pelo mentor do curso, Roman Travin, especialista em suporte tÃ©cnico de produtos corporativos REG.RU.</i> <br><br>  Neste artigo, consideraremos 2 casos de substituiÃ§Ã£o de discos e transferÃªncia de informaÃ§Ãµes para novos discos de maior volume com expansÃ£o adicional da matriz e do sistema de arquivos.  O primeiro caso diz respeito Ã  substituiÃ§Ã£o de discos com a mesma marcaÃ§Ã£o MBR / MBR ou GPT / GPT, o segundo caso refere-se Ã  substituiÃ§Ã£o de discos com marcaÃ§Ã£o MBR em discos com capacidade superior a 2 TB, nos quais serÃ¡ necessÃ¡ria a marcaÃ§Ã£o GPT com a partiÃ§Ã£o biosboot.  Nos dois casos, os discos para os quais transferimos dados jÃ¡ estÃ£o instalados no servidor.  O sistema de arquivos usado para a partiÃ§Ã£o raiz Ã© ext4. <br><br><hr><a name="habracut"></a><br><h3>  Caso 1: Substituindo unidades menores por unidades maiores (atÃ© 2 TB) </h3><br>  <b>Tarefa:</b> Substitua os discos atuais por discos maiores (atÃ© 2 TB) pela transferÃªncia de informaÃ§Ãµes.  Nesse caso, temos 2 discos SSD de 240 GB (RAID-1) com o sistema instalado e 2 discos SATA de 2 TB para os quais vocÃª precisa transferir o sistema. <br><br>  Considere o layout de disco atual. <br><br><pre><code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sda2 8:2 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  Verifique o espaÃ§o atual do sistema de arquivos usado. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 32G 0 32G 0% /dev tmpfs 32G 0 32G 0% /dev/shm tmpfs 32G 9,6M 32G 1% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/vg0-root 204G 1,3G 192G 1% / /dev/md126 1007M 120M 837M 13% /boot tmpfs 6,3G 0 6,3G 0% /run/user/0</span></span></code> </pre> <br>  O tamanho do sistema de arquivos antes da substituiÃ§Ã£o dos discos Ã© 204 GB, sÃ£o utilizadas 2 matrizes de software md126, montadas em <code>/boot</code> e <code>md127</code> , que Ã© usado como <i>volume fÃ­sico</i> para o grupo VG <i>vg0</i> . <br><br><h4>  1. Removendo partiÃ§Ãµes de disco de matrizes </h4><br>  Verifique o estado da matriz <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sda1[0] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sda2[0] sdb2[1] 233206784 blocks super 1.2 [2/2] [UU] bitmap: 0/2 pages [0KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  O sistema usa 2 matrizes: <code>md126</code> (ponto de montagem <code>/boot</code> ) - consiste nas <code>md127</code> <code>/dev/sda1</code> e <code>/dev/sdb1</code> , <code>md127</code> (LVM para <i>troca</i> e raiz do sistema de arquivos) - consiste em <code>/dev/sda2</code> e <code>/dev/sdb2</code> . <br><br>  Marcamos as partiÃ§Ãµes do primeiro disco, usadas em cada matriz, como ruins. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sda1 mdadm /dev/md127 --fail /dev/sda2</code> </pre><br>  Removemos seÃ§Ãµes do dispositivo de bloco / dev / sda das matrizes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sda1 mdadm /dev/md127 --remove /dev/sda2</code> </pre> <br>  Depois de removermos o disco da matriz, as informaÃ§Ãµes sobre os dispositivos de bloco ficarÃ£o assim. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  O estado das matrizes apÃ³s a remoÃ§Ã£o dos discos. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdb1[1] 1047552 blocks super 1.2 [2/1] [_U] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] bitmap: 1/2 pages [4KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br><h4>  2. Copiando a tabela de partiÃ§Ã£o para um novo disco </h4><br>  VocÃª pode verificar a tabela de partiÃ§Ã£o usada no disco com o seguinte comando. <br><br><pre> <code class="bash hljs">fdisk -l /dev/sdb | grep <span class="hljs-string"><span class="hljs-string">'Disk label type'</span></span></code> </pre><br>  A saÃ­da para o MBR serÃ¡: <br><br><pre> <code class="bash hljs">Disk label <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>: dos</code> </pre> <br>  para GPT: <br><br><pre> <code class="bash hljs">Disk label <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>: gpt</code> </pre> <br>  <b>Copie a tabela de marcaÃ§Ã£o para MBR:</b> <b><br></b> <br><pre> <code class="bash hljs">sfdisk -d /dev/sdb | sfdisk /dev/sdc</code> </pre> <br>  Nesse comando, o <b>primeiro</b> Ã© a unidade <b>da</b> <b>qual a</b> marcaÃ§Ã£o <b>Ã©</b> copiada, o <b>segundo Ã© o local para onde</b> copiar. <br><br><blockquote>  <b>ATENÃ‡ÃƒO</b> : Para GPT, a unidade <b>na qual</b> copiar a marcaÃ§Ã£o Ã© a <b>primeira a ser</b> indicada, a unidade <b>na qual</b> copiar a marcaÃ§Ã£o da <b>segunda</b> unidade.  Se vocÃª misturar os discos, a marcaÃ§Ã£o inicial Ã­ntegra serÃ¡ substituÃ­da e destruÃ­da. <br></blockquote><br>  <b>Copiando a tabela de marcaÃ§Ã£o para a GPT:</b> <b><br></b> <br><pre> <code class="bash hljs">sgdisk -R /dev/sd /dev/sdb</code> </pre> <br>  Em seguida, atribua um UUID aleatÃ³rio ao disco (para GPT). <br><br><pre> <code class="bash hljs">sgdisk -G /dev/sdc</code> </pre> <br>  ApÃ³s a execuÃ§Ã£o do comando, as partiÃ§Ãµes devem aparecer no disco <code>/dev/sdc</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â””â”€sdc2 8:34 0 222,5G 0 part sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  Se apÃ³s a aÃ§Ã£o executada as partiÃ§Ãµes no sistema no disco <code>/dev/sdc</code> nÃ£o estiverem definidas, executaremos o comando para reler a tabela de partiÃ§Ã£o. <br><br><pre> <code class="bash hljs">sfdisk -R /dev/sdc</code> </pre> <br>  Se os discos atuais usarem a tabela MBR e as informaÃ§Ãµes precisarem ser transferidas para discos com capacidade superior a 2 TB, os novos discos precisarÃ£o criar manualmente a marcaÃ§Ã£o GPT usando a seÃ§Ã£o biosboot.  Este caso serÃ¡ considerado na parte 2 deste artigo. <br><br><h4>  3. Adicionando partiÃ§Ãµes do novo disco Ã  matriz </h4><br>  Adicione partiÃ§Ãµes de disco Ã s matrizes correspondentes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdc1 mdadm /dev/md127 --add /dev/sdc2</code> </pre> <br>  Verifique se as seÃ§Ãµes foram adicionadas. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  Depois disso, aguardamos a sincronizaÃ§Ã£o das matrizes. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdc1[2] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdc2[2] sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] [==&gt;..................] recovery = 10.6% (24859136/233206784) finish=29.3min speed=118119K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  VocÃª pode monitorar continuamente o processo de sincronizaÃ§Ã£o usando o utilitÃ¡rio <code>watch</code> . <br><br><pre> <code class="bash hljs">watch -n 2 cat /proc/mdstat</code> </pre> <br>  A <code>-n</code> especifica em quais intervalos em segundos o comando deve ser executado para verificar o progresso. <br><br>  <b>Repita as etapas 1 a 3 para a prÃ³xima unidade de substituiÃ§Ã£o.</b> <br><br>  Marcamos as partiÃ§Ãµes do segundo disco, usadas em cada matriz, como ruins. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sdb1 mdadm /dev/md127 --fail /dev/sdb2</code> </pre><br>  Removemos seÃ§Ãµes do dispositivo de bloco <code>/dev/sdb</code> das matrizes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sdb1 mdadm /dev/md127 --remove /dev/sdb2</code> </pre> <br>  Depois de removermos o disco da matriz, as informaÃ§Ãµes sobre os dispositivos de bloco ficarÃ£o assim. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk</span></span></code> </pre><br>  O estado das matrizes apÃ³s a remoÃ§Ã£o dos discos. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdc1[2] 1047552 blocks super 1.2 [2/1] [U_] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdc2[2] 233206784 blocks super 1.2 [2/1] [U_] bitmap: 1/2 pages [4KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Copie a tabela de marcaÃ§Ã£o MBR da unidade <code>/dev/sd</code> para a unidade <code>/dev/sdd</code> . <br><br><pre> <code class="bash hljs">sfdisk -d /dev/sd | sfdisk /dev/sdd</code> </pre> <br>  ApÃ³s a execuÃ§Ã£o do comando, as partiÃ§Ãµes devem aparecer na unidade <code>/dev/sdd</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â””â”€sdd2 8:50 0 222,5G 0 part</span></span></code> </pre> <br>  Adicione partiÃ§Ãµes de disco Ã s matrizes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdd1 mdadm /dev/md127 --add /dev/sdd2</code> </pre> <br>  Verifique se as seÃ§Ãµes foram adicionadas. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Depois disso, aguardamos a sincronizaÃ§Ã£o das matrizes. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdd1[3] sdc1[2] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdd2[3] sdc2[2] 233206784 blocks super 1.2 [2/1] [U_] [&gt;....................] recovery = 0.5% (1200000/233206784) finish=35.4min speed=109090K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre><br><h4>  5. Instale o GRUB em novas unidades </h4><br>  Para o CentOS: <br><br><pre> <code class="bash hljs">grub2-install /dev/sdX</code> </pre> <br>  Para Debian / Ubuntu: <br><br><pre> <code class="bash hljs">grub-install /dev/sdX</code> </pre> <br>  onde <code>X</code> Ã© a letra do dispositivo de bloco.  Nesse caso, instale o GRUB em <code>/dev/sdc</code> e <code>/dev/sdd</code> . <br><br><h4>  6. ExtensÃ£o do sistema de arquivos (ext4) da partiÃ§Ã£o raiz </h4><br>  931,5 GB estÃ£o disponÃ­veis nas novas unidades <code>/dev/sdc</code> e <code>/dev/sdd</code> .  Como a tabela de partiÃ§Ã£o Ã© copiada de discos menores, 222,5 GB estÃ£o disponÃ­veis nas partiÃ§Ãµes <code>/dev/sdc2</code> e <code>/dev/sdd2</code> . <br><br><pre> <code class="bash hljs">sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</code> </pre> <br>  Ã‰ necessÃ¡rio: <br><br><ol><li>  Estenda a seÃ§Ã£o 2 em cada unidade, </li><li>  Estenda a matriz md127, </li><li>  Expanda PV (volume fÃ­sico), </li><li>  Estenda LV (volume lÃ³gico) vg0-root, </li><li>  Estenda o sistema de arquivos. </li></ol><br>  Usando o utilitÃ¡rio <i>partido,</i> expanda a <code>/dev/sdc2</code> para o valor mÃ¡ximo.  <code>parted /dev/sdc</code> comando <code>parted /dev/sdc</code> (1) e visualizamos a tabela de partiÃ§Ã£o atual com o comando <code>p</code> (2). <br><br><img src="https://habrastorage.org/webt/ao/zx/xc/aozxxc_zhq42me4qblnij5bib4y.png"><br><br>  Como vocÃª pode ver, o final da seÃ§Ã£o 2 termina com 240 GB.  Vamos expandir a seÃ§Ã£o com o comando <code>resizepart</code> <code>2</code> , em que 2 Ã© o nÃºmero da seÃ§Ã£o (3).  Indicamos o valor no formato digital, por exemplo, 1000 GB ou usamos a indicaÃ§Ã£o do compartilhamento de disco - 100%.  Novamente, verificamos que a seÃ§Ã£o possui um novo tamanho (4). <br><br>  Repita as etapas acima para a unidade <code>/dev/sdd</code> .  ApÃ³s expandir as partiÃ§Ãµes, <code>/dev/sdc2</code> e <code>/dev/sdd2</code> tornaram-se iguais a 930,5 GB. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 930,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 930,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Depois disso, expandimos a matriz <i>md127</i> ao mÃ¡ximo. <br><br><pre> <code class="bash hljs">mdadm --grow /dev/md127 --size=max</code> </pre> <br>  Verifique se a matriz foi expandida.  Agora, seu tamanho se tornou 930,4 GB. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 930,5G 0 part â””â”€md127 9:127 0 930,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 930,5G 0 part â””â”€md127 9:127 0 930,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Realizamos a expansÃ£o do <i>volume fÃ­sico</i> .  Antes da expansÃ£o, verifique o estado atual do PV. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvscan PV /dev/md127 VG vg0 lvm2 [222,40 GiB / 0 free] Total: 1 [222,40 GiB] / in use: 1 [222,40 GiB] / in no VG: 0 [0 ]</span></span></code> </pre><br>  Como vocÃª pode ver, o PV <code>/dev/md127</code> usa 222,4 GB de espaÃ§o. <br><br>  Expanda PV com o seguinte comando. <br><br><pre> <code class="bash hljs">pvresize /dev/md127</code> </pre> <br>  Verifique o resultado da extensÃ£o fotovoltaica. <br><br>  [ <pre> <code class="bash hljs">root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvscan PV /dev/md127 VG vg0 lvm2 [930,38 GiB / 707,98 GiB free] Total: 1 [930,38 GiB] / in use: 1 [930,38 GiB] / in no VG: 0 [0 ]</span></span></code> </pre> <br>  ExpansÃ£o do <i>volume lÃ³gico</i> .  Antes da extensÃ£o, verifique o status atual de LV (1). <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvscan ACTIVE '/dev/vg0/swap' [&lt;16,00 GiB] inherit ACTIVE '/dev/vg0/root' [&lt;206,41 GiB] inherit</span></span></code> </pre> <br>  O LV <code>/dev/vg0/root</code> usa 206,41 GB. <br><br>  Expandimos LV com o seguinte comando (2). <br><br><pre> <code class="bash hljs">lvextend -l +100%FREE /dev/mapper/vg0-root</code> </pre> <br><br>  Verifique a aÃ§Ã£o executada (3). <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvscan ACTIVE '/dev/vg0/swap' [&lt;16,00 GiB] inherit ACTIVE '/dev/vg0/root' [&lt;914,39 GiB] inherit</span></span></code> </pre><br>  Como vocÃª pode ver, apÃ³s a expansÃ£o do LV, o volume de espaÃ§o em disco ocupado se tornou 914,39 GB. <br><br><img src="https://habrastorage.org/webt/vd/6r/qh/vd6rqhe3wvbukzdfachz7xf4ehk.png"><br><br>  O volume LV aumentou (4), mas o sistema de arquivos ainda ocupa 204 GB (5). <br><br>  <i>1. Execute a extensÃ£o do sistema de arquivos.</i> <br><br><pre> <code class="bash hljs">resize2fs /dev/mapper/vg0-root</code> </pre> <br>  ApÃ³s o comando executado, verificamos o tamanho do sistema de arquivos. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 32G 0 32G 0% /dev tmpfs 32G 0 32G 0% /dev/shm tmpfs 32G 9,5M 32G 1% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/vg0-root 900G 1,3G 860G 1% / /dev/md126 1007M 120M 837M 13% /boot tmpfs 6,3G 0 6,3G 0% /run/user/0</span></span></code> </pre> <br>  O tamanho do sistema de arquivos raiz aumentarÃ¡ para 900 GB.  ApÃ³s concluir as etapas, vocÃª pode remover os discos antigos. <br><br><h3>  Caso 2: Substituindo unidades menores por unidades maiores (mais de 2 TB) </h3><br>  <b>Tarefa:</b> Substitua os discos atuais por discos maiores (2 x 3 TB) por salvar informaÃ§Ãµes.  Nesse caso, temos 2 discos SSD de 240 GB (RAID-1) com o sistema instalado e 2 discos SATA de 2 TB de 3 TB nos quais vocÃª precisa transferir o sistema.  As unidades atuais usam a tabela de partiÃ§Ã£o MBR.  Como os novos discos tÃªm capacidade superior a 2 TB, eles precisam usar a tabela GPT, pois o MBR nÃ£o pode trabalhar com discos maiores que 2 TB. <br><br>  Veja o layout atual do disco. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sda2 8:2 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 2,7T 0 disk sdd 8:48 0 2,7T 0 disk</span></span></code> </pre> <br>  Verifique a tabela de partiÃ§Ã£o usada na unidade <code>/dev/sda</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># fdisk -l /dev/sda | grep 'Disk label type' Disk label type: dos</span></span></code> </pre> <br>  A unidade <code>/dev/sdb</code> usa uma tabela de partiÃ§Ã£o semelhante.  Verifique o espaÃ§o em disco usado no sistema. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 9,5M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/vg0-root 204G 1,3G 192G 1% / /dev/md126 1007M 120M 837M 13% /boot tmpfs 3,2G 0 3,2G 0% /run/user/0</span></span></code> </pre> <br>  Como vocÃª pode ver, a raiz do sistema de arquivos Ã© 204 GB.  Verifique o estado atual do RAID do software. <br><br><h4>  1. Instale a tabela de partiÃ§Ã£o GPT e o particionamento de disco </h4><br>  Verifique o layout do disco por setor. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># parted /dev/sda print : ATA KINGSTON SVP200S (scsi)  /dev/sda: 240GB   (./.): 512B/512B  : msdos Disk Flags:         1 1049kB 1076MB 1075MB primary , raid 2 1076MB 240GB 239GB primary raid</span></span></code> </pre><br>  Na nova unidade de 3 TB, precisaremos criar 3 partiÃ§Ãµes: <br><br><ol><li>  <code>bios_grub</code> seÃ§Ã£o <code>bios_grub</code> para compatibilidade da GPT com o BIOS, </li><li>  A partiÃ§Ã£o para a matriz RAID a ser montada em <code>/boot</code> . </li><li>  A partiÃ§Ã£o para a matriz RAID na qual serÃ£o a <i>raiz</i> <i>LV</i> e a <i>troca LV</i> . </li></ol><br>  Instale o utilitÃ¡rio <i>parted com o</i> comando <code>yum install -y parted</code> (para CentOS), <code>apt install -y parted</code> (para Debian / Ubuntu). <br><br>  Usando <i>parted,</i> execute os seguintes comandos para particionar o disco. <br><br>  <code>parted /dev/sdc</code> comando <code>parted /dev/sdc</code> e mudamos para o modo de ediÃ§Ã£o do layout do disco. <br><br>  Crie uma tabela de partiÃ§Ã£o GPT. <br><br><pre> <code class="bash hljs">(parted) mktable gpt</code> </pre> <br>  Crie uma seÃ§Ã£o <code>bios_grub</code> e defina um sinalizador para ela. <br><br><pre> <code class="bash hljs">(parted) mkpart primary 1MiB 3MiB (parted) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> 1 bios_grub on</code> </pre> <br>  Crie uma seÃ§Ã£o 2 e defina um sinalizador para ela.  A partiÃ§Ã£o serÃ¡ usada como um bloco para a matriz RAID e montada em <code>/boot</code> . <br><br><pre> <code class="bash hljs">(parted) mkpart primary ext2 3MiB 1028MiB (parted) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> 2 boot on</code> </pre> <br>  Crie uma seÃ§Ã£o 3, que tambÃ©m serÃ¡ usada como um bloco de matriz no qual haverÃ¡ LVM. <br><br><pre> <code class="bash hljs">(parted) mkpart primary 1028MiB 100%</code> </pre> <br>  Nesse caso, a configuraÃ§Ã£o do sinalizador nÃ£o Ã© necessÃ¡ria, mas, se necessÃ¡rio, Ã© possÃ­vel configurÃ¡-lo com o seguinte comando. <br><br><pre> <code class="bash hljs">(parted) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> 3 raid on</code> </pre> <br>  Verifique a tabela criada. <br><br><pre> <code class="bash hljs">(parted) p : ATA TOSHIBA DT01ACA3 (scsi)  /dev/sdc: 3001GB   (./.): 512B/4096B  : gpt Disk Flags:         1 1049kB 3146kB 2097kB primary bios_grub 2 3146kB 1077MB 1074MB primary  3 1077MB 3001GB 3000GB primary</code> </pre><br>  Atribua Ã  unidade um novo GUID aleatÃ³rio. <br><br><pre> <code class="bash hljs">sgdisk -G /dev/sdd</code> </pre><br><h4>  2. Removendo partiÃ§Ãµes do primeiro disco das matrizes </h4><br>  Verifique o estado da matriz <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sda1[0] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sda2[0] sdb2[1] 233206784 blocks super 1.2 [2/2] [UU] bitmap: 0/2 pages [0KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  O sistema usa 2 matrizes: md126 (ponto de montagem / inicializaÃ§Ã£o) - consiste em <code>/dev/sda1</code> e <code>/dev/sdb1</code> , <code>md127</code> (LVM para <code>swap</code> e a raiz do sistema de arquivos) - consiste em <code>/dev/sda2</code> e <code>/dev/sdb2</code> . <br><br>  Marcamos as partiÃ§Ãµes do primeiro disco, usadas em cada matriz, como ruins. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sda1 mdadm /dev/md127 --fail /dev/sda2</code> </pre> <br>  Removemos seÃ§Ãµes do dispositivo de bloco <code>/dev/sda</code> das matrizes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sda1 mdadm /dev/md127 --remove /dev/sda2</code> </pre><br>  Verifique o estado da matriz apÃ³s remover o disco. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdb1[1] 1047552 blocks super 1.2 [2/1] [_U] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre><br><h4>  3. Adicionando partiÃ§Ãµes do novo disco Ã  matriz </h4><br>  O prÃ³ximo passo Ã© adicionar as partiÃ§Ãµes do novo disco Ã s matrizes para sincronizaÃ§Ã£o.  Examinamos o estado atual do layout do disco. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â””â”€sdc3 8:35 0 2,7T 0 part sdd 8:48 0 2,7T 0 disk</span></span></code> </pre> <br>  A <code>/dev/sdc1</code> Ã© uma partiÃ§Ã£o <code>bios_grub</code> e nÃ£o estÃ¡ envolvida na criaÃ§Ã£o de matrizes.  <code>/dev/sdc2</code> usarÃ£o apenas <code>/dev/sdc2</code> e <code>/dev/sdc3</code> .  Adicione essas seÃ§Ãµes Ã s matrizes correspondentes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdc2 mdadm /dev/md127 --add /dev/sdc3</code> </pre> <br>  Depois, aguardamos a sincronizaÃ§Ã£o da matriz. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdc2[2] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdc3[2] sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] [&gt;....................] recovery = 0.2% (619904/233206784) finish=31.2min speed=123980K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Particionando discos depois de adicionar partiÃ§Ãµes a uma matriz. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk</span></span></code> </pre> <br><h4>  4. Removendo partiÃ§Ãµes do segundo disco de matrizes </h4><br>  Marcamos as partiÃ§Ãµes do segundo disco, usadas em cada matriz, como ruins. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sdb1 mdadm /dev/md127 --fail /dev/sdb2</code> </pre><br>  Removemos seÃ§Ãµes do dispositivo de bloco <code>/dev/sda</code> das matrizes. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sdb1 mdadm /dev/md127 --remove /dev/sdb2</code> </pre><br><h4>  5. Copie a tabela de marcaÃ§Ã£o GPT e sincronize a matriz </h4><br>  Para copiar a tabela de marcaÃ§Ã£o GPT, usamos o utilitÃ¡rio <code>sgdisk</code> , incluÃ­do no pacote para trabalhar com partiÃ§Ãµes de disco e a tabela GPT - <code>gdisk</code> . <br><br>  Instale o <code>gdisk</code> para o CentOS: <br><br><pre> <code class="bash hljs">yum install -y gdisk</code> </pre> <br>  Instale o <code>gdisk</code> para Debian / Ubuntu: <br><br><pre> <code class="bash hljs">apt install -y gdisk</code> </pre> <br><blockquote>  <b>ATENÃ‡ÃƒO</b> : Para GPT, o disco <b>no qual a</b> marcaÃ§Ã£o Ã© copiada Ã© indicado <b>primeiro</b> , o <b>segundo</b> disco Ã© o disco <b>no qual a</b> marcaÃ§Ã£o <b>Ã©</b> copiada.  Se vocÃª misturar os discos, a marcaÃ§Ã£o inicial Ã­ntegra serÃ¡ substituÃ­da e destruÃ­da. <br></blockquote><br>  Copie a tabela de marcaÃ§Ã£o GPT. <br><br><pre> <code class="bash hljs">sgdisk -R /dev/sdd /dev/sdc</code> </pre> <br>  Particionando discos apÃ³s transferir uma tabela para <code>/dev/sdd</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â””â”€sdd3 8:51 0 2,7T 0 part</span></span></code> </pre> <br>  Em seguida, adicionamos cada uma das partiÃ§Ãµes participantes das matrizes RAID de software. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdd2 mdadm /dev/md127 --add /dev/sdd3</code> </pre> <br>  Estamos aguardando a sincronizaÃ§Ã£o da matriz. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdd2[3] sdc2[2] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 1/1 pages [4KB], 65536KB chunk md127 : active raid1 sdd3[3] sdc3[2] 233206784 blocks super 1.2 [2/1] [U_] [&gt;....................] recovery = 0.0% (148224/233206784) finish=26.2min speed=148224K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Depois de copiar a marcaÃ§Ã£o GPT para um segundo novo disco, a marcaÃ§Ã£o ficarÃ¡ assim. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd3 8:51 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Em seguida, instale o GRUB nas novas unidades. <br><br>  InstalaÃ§Ã£o para o CentOS: <br><br><pre> <code class="bash hljs">grub2-install /dev/sdX</code> </pre> <br>  InstalaÃ§Ã£o para Debian / Ubuntu: <br><br><pre> <code class="bash hljs">grub-install /dev/sdX</code> </pre> <br>  onde <code>X</code> Ã© a letra da unidade, no nosso caso, as unidades <code>/dev/sdc</code> e <code>/dev/sdd</code> . <br><br>  Atualizando as informaÃ§Ãµes sobre a matriz. <br><br>  Para o CentOS: <br><br><pre> <code class="bash hljs">mdadm --detail --scan --verbose &gt; /etc/mdadm.conf</code> </pre> <br>  Para Debian / Ubuntu: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"DEVICE partitions"</span></span> &gt; /etc/mdadm/mdadm.conf mdadm --detail --scan --verbose | awk <span class="hljs-string"><span class="hljs-string">'/ARRAY/ {print}'</span></span> &gt;&gt; /etc/mdadm/mdadm.conf</code> </pre> <br>  Atualizando a imagem <code>initrd</code> : <br>  Para o CentOS: <br><br><pre> <code class="bash hljs">dracut -f -v --regenerate-all</code> </pre> <br>  Para Debian / Ubuntu: <br><br><pre> <code class="bash hljs">update-initramfs -u -k all</code> </pre> <br>  Atualizando a configuraÃ§Ã£o do GRUB. <br><br>  Para o CentOS: <br><br><pre> <code class="bash hljs">grub2-mkconfig -o /boot/grub2/grub.cfg</code> </pre><br>  Para Debian / Ubuntu: <br><br><pre> <code class="bash hljs">update-grub</code> </pre> <br>  ApÃ³s as etapas concluÃ­das, os discos antigos podem ser removidos. <br><br><h4>  6. ExtensÃ£o do sistema de arquivos (ext4) da partiÃ§Ã£o raiz </h4><br>  Particionando discos antes de expandir o sistema de arquivos apÃ³s movÃª-lo para 2 x discos de 3 TB (RAID-1). <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk sdb 8:16 0 223,6G 0 disk sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md126 9:126 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdd3 8:51 0 2,7T 0 part â””â”€md126 9:126 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  As <code>/dev/sdc3</code> e <code>/dev/sdd3</code> ocupam 2,7 TB.  Como criamos um novo particionamento de discos com uma tabela GPT, o tamanho das trÃªs partiÃ§Ãµes foi imediatamente definido para o espaÃ§o em disco mÃ¡ximo possÃ­vel; nesse caso, a expansÃ£o da partiÃ§Ã£o nÃ£o Ã© necessÃ¡ria. <br><br>  Ã‰ necessÃ¡rio: <br><br><ol><li>  Estenda a matriz md126, </li><li>  Expanda PV (volume fÃ­sico), </li><li>  Estenda LV (volume lÃ³gico) vg0-root, </li><li>  Estenda o sistema de arquivos. </li></ol><br>  <i>1. <code>md126</code> matriz <code>md126</code> ao mÃ¡ximo.</i> <br><br><pre> <code class="bash hljs">mdadm --grow /dev/md126 --size=max</code> </pre><br>  ApÃ³s expandir a matriz <code>md126</code> tamanho do espaÃ§o ocupado aumentou para 2,7 TB. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk sdb 8:16 0 223,6G 0 disk sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md126 9:126 0 2,7T 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdd3 8:51 0 2,7T 0 part â””â”€md126 9:126 0 2,7T 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ExpansÃ£o do </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">volume fÃ­sico</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Antes da expansÃ£o, verificamos o valor atual do espaÃ§o ocupado PV / </font></font><code>dev/md126</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvs PV VG Fmt Attr PSize PFree /dev/md126 vg0 lvm2 a-- 222,40g 0</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Expanda PV com o seguinte comando. </font></font><br><br><pre> <code class="bash hljs">pvresize /dev/md126</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verifique a aÃ§Ã£o concluÃ­da. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvs PV VG Fmt Attr PSize PFree /dev/md126 vg0 lvm2 a-- &lt;2,73t 2,51t</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ExpansÃ£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classe volume lÃ³gico vg0-root</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ApÃ³s a expansÃ£o do PV, verificamos o espaÃ§o ocupado do VG.</font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># vgs VG #PV #LV #SN Attr VSize VFree vg0 1 2 0 wz--n- &lt;2,73t 2,51t</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verifique o espaÃ§o ocupado por LV. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root vg0 -wi-ao---- &lt;206,41g swap vg0 -wi-ao---- &lt;16,00g</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O volume raiz-vg0 ocupa 206,41 GB. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Expanda LV para o espaÃ§o mÃ¡ximo em disco.</font></font><br><br><pre> <code class="bash hljs">lvextend -l +100%FREE /dev/mapper/vg0-root</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verificando o espaÃ§o do VE apÃ³s a expansÃ£o. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root vg0 -wi-ao---- 2,71t swap vg0 -wi-ao---- &lt;16,00g</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Estendendo o sistema de arquivos (ext4). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verifique o tamanho atual do sistema de arquivos.</font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 9,6M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/vg0-root 204G 1,4G 192G 1% / /dev/md127 1007M 141M 816M 15% /boot tmpfs 3,2G 0 3,2G 0% /run/user/0</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O volume / dev / mapper / vg0-root ocupa 204 GB apÃ³s a extensÃ£o LV. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Expandindo o sistema de arquivos.</font></font><br><br><pre> <code class="bash hljs">resize2fs /dev/mapper/vg0-root</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verifique o tamanho do sistema de arquivos apÃ³s sua expansÃ£o. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 9,6M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/vg0-root 2,7T 1,4G 2,6T 1% / /dev/md127 1007M 141M 816M 15% /boot tmpfs 3,2G 0 3,2G 0% /run/user/0</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O tamanho do sistema de arquivos Ã© aumentado pelo volume inteiro do volume. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt486084/">https://habr.com/ru/post/pt486084/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt486062/index.html">RenderizaÃ§Ã£o simples de cÃ³pia zero de vÃ­deo acelerado por hardware em QML</a></li>
<li><a href="../pt486064/index.html">Crie uma apresentaÃ§Ã£o de slides animada em CSS puro.</a></li>
<li><a href="../pt486066/index.html">Na Ã¡rea de acesso. Encontre a distÃ¢ncia de um ponto a uma Ã¡rea e reduza as solicitaÃ§Ãµes de geocodificaÃ§Ã£o reversa</a></li>
<li><a href="../pt486070/index.html">A ACL muda em detalhes</a></li>
<li><a href="../pt486080/index.html">Deixe-me apresentar: Veeam Availability Suite v10</a></li>
<li><a href="../pt486094/index.html">Democrata na CÃ¢mara luta contra o Vale do SilÃ­cio</a></li>
<li><a href="../pt486100/index.html">Como criar um aplicativo descentralizado e escalÃ¡vel? Use menos blockchain</a></li>
<li><a href="../pt486106/index.html">Luz de fundo adaptÃ¡vel para TV Raspberry Pi - Ambilight Analog</a></li>
<li><a href="../pt486114/index.html">Os principais cientistas do campo da neurociÃªncia se reunirÃ£o no congresso anual do sindicato da indÃºstria de neuronets</a></li>
<li><a href="../pt486116/index.html">Testes de simplicidade de Fermat e Miller-Rabin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
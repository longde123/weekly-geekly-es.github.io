<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç∂ üë®üèΩ‚ÄçüöÄ üìô F√ºnf Methoden zur Datenbankverschleierung üëÉüèº üÖ∞Ô∏è üïî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ClickHouse-Benutzer wissen bereits, dass der gr√∂√üte Vorteil die schnelle Verarbeitung von analytischen Abfragen ist. Behauptungen wie diese m√ºssen jed...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>F√ºnf Methoden zur Datenbankverschleierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/485096/">  ClickHouse-Benutzer wissen bereits, dass der gr√∂√üte Vorteil die schnelle Verarbeitung von analytischen Abfragen ist.  Behauptungen wie diese m√ºssen jedoch durch zuverl√§ssige Leistungstests best√§tigt werden.  Dar√ºber m√∂chten wir heute sprechen. <br><br> <a href="https://habr.com/en/company/yandex/blog/457354/"><img src="https://habrastorage.org/webt/ds/2m/sd/ds2msd5-4zeahpzlzptlqz8wgs8.png"></a> <br><br>  Wir haben 2013 begonnen, Tests durchzuf√ºhren, lange bevor das Produkt als Open Source verf√ºgbar war.  Unser Hauptanliegen war damals wie heute die Geschwindigkeit der Datenverarbeitung in Yandex.Metrica.  Diese Daten werden seit Januar 2009 in ClickHouse gespeichert. Ein Teil der Daten wurde ab 2012 in eine Datenbank geschrieben und ein Teil von <a href="https://clickhouse.yandex/blog/evolution-of-data-structures-in-yandex-metrica">OLAPServer und Metrage</a> (Datenstrukturen, die zuvor von Yandex.Metrica verwendet wurden) konvertiert.  Zum Testen haben wir die erste Teilmenge zuf√§llig aus Daten f√ºr 1 Milliarde Seitenaufrufe ausgew√§hlt.  Yandex.Metrica hatte zu diesem Zeitpunkt noch keine Abfragen. Daher haben wir Abfragen ausgearbeitet, die uns interessierten. Dabei wurden alle m√∂glichen Methoden zum Filtern, Aggregieren und Sortieren der Daten verwendet. <br><br>  Die Leistung von ClickHouse wurde mit √§hnlichen Systemen wie Vertica und MonetDB verglichen.  Um Verzerrungen zu vermeiden, wurde der Test von einem Mitarbeiter durchgef√ºhrt, der nicht an der ClickHouse-Entwicklung teilgenommen hatte, und Sonderf√§lle im Code wurden erst dann optimiert, wenn alle Ergebnisse erzielt wurden.  Wir haben den gleichen Ansatz verwendet, um einen Datensatz f√ºr Funktionstests zu erhalten. <br><br>  Nachdem ClickHouse 2016 als Open Source ver√∂ffentlicht wurde, begannen die Leute, diese Tests in Frage zu stellen. <br><br><a name="habracut"></a><h2>  M√§ngel bei der Pr√ºfung privater Daten </h2><br>  Unsere Leistungstests: <br><br><ol><li>  Kann nicht unabh√§ngig reproduziert werden, da private Daten verwendet werden, die nicht ver√∂ffentlicht werden k√∂nnen.  Einige der Funktionstests stehen externen Benutzern aus dem gleichen Grund nicht zur Verf√ºgung. </li><li>  Ben√∂tigen Sie weitere Entwicklung.  Die Testreihe muss erheblich erweitert werden, um Leistungs√§nderungen in einzelnen Teilen des Systems einzugrenzen. </li><li>  F√ºhren Sie die Ausf√ºhrung nicht pro Festschreibung oder f√ºr einzelne Pull-Anforderungen aus.  Externe Entwickler k√∂nnen ihren Code nicht auf Leistungsabweichungen √ºberpr√ºfen. </li></ol><br>  Wir k√∂nnten diese Probleme l√∂sen, indem wir die alten Tests verwerfen und neue auf der Grundlage offener Daten schreiben, wie beispielsweise <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/ontime">Flugdaten f√ºr die USA</a> und <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/nyc_taxi">Taxifahrten in New York</a> .  Oder wir k√∂nnten Benchmarks wie TPC-H, TPC-DS und <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/star_schema">Star Schema Benchmark verwenden</a> .  Der Nachteil ist, dass sich diese Daten stark von den Yandex.Metrica-Daten unterscheiden und wir die Testabfragen lieber behalten m√∂chten. <br><br><h2>  Warum es wichtig ist, echte Daten zu verwenden </h2><br>  Die Leistung sollte nur an realen Daten aus einer Produktionsumgebung getestet werden.  Schauen wir uns einige Beispiele an. <br><br>  <strong>Beispiel 1</strong> <br><br>  Angenommen, Sie f√ºllen eine Datenbank mit gleichm√§√üig verteilten Pseudozufallszahlen.  In diesem Fall funktioniert die Datenkomprimierung nicht, obwohl die Datenkomprimierung f√ºr analytische Datenbanken unerl√§sslich ist.  Es gibt keine Patentl√∂sung f√ºr die Herausforderung, den richtigen Komprimierungsalgorithmus auszuw√§hlen und ihn auf die richtige Weise in das System zu integrieren, da die Datenkomprimierung einen Kompromiss zwischen der Geschwindigkeit der Komprimierung und Dekomprimierung und der potenziellen Komprimierungseffizienz erfordert.  Systeme, die keine Daten komprimieren k√∂nnen, sind jedoch garantierte Verlierer.  Wenn Ihre Tests gleichm√§√üig verteilte Pseudozufallszahlen verwenden, wird dieser Faktor ignoriert und die Ergebnisse werden verzerrt. <br><br>  Fazit: Testdaten m√ºssen ein realistisches Kompressionsverh√§ltnis aufweisen. <br><br>  Ich habe in <a href="https://habr.com/en/company/yandex/blog/457612/">einem fr√ºheren Beitrag</a> die Optimierung von ClickHouse-Datenkomprimierungsalgorithmen behandelt. <br><br>  <strong>Beispiel 2</strong> <br><br>  Angenommen, wir interessieren uns f√ºr die Ausf√ºhrungsgeschwindigkeit dieser SQL-Abfrage: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> RegionID, uniq(UserID) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> visitors <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> test.hits <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> RegionID <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> visitors <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span></code> </pre> <br>  Dies ist eine typische Abfrage f√ºr Yandex.Metrica.  Was beeinflusst die Verarbeitungsgeschwindigkeit? <br><br><ul><li>  Wie GROUP BY ausgef√ºhrt wird. </li><li>  Welche Datenstruktur wird zur Berechnung der einheitlichen Aggregatfunktion verwendet? </li><li>  Wie viele verschiedene RegionIDs gibt es und wie viel RAM ben√∂tigt jeder Status der uniq-Funktion. </li></ul><br>  Ein weiterer wichtiger Faktor ist jedoch, dass die Datenmenge zwischen den Regionen ungleich verteilt ist.  (Es folgt wahrscheinlich einem Potenzgesetz. Ich habe die Verteilung in ein Log-Log-Diagramm eingetragen, kann aber nicht sicher sagen.) Wenn dies der Fall ist, ist es wichtig, dass die Zust√§nde der uniq-Aggregatfunktion mit weniger Werten verwendet werden sehr wenig Ged√§chtnis.  Bei vielen verschiedenen Aggregationsschl√ºsseln z√§hlt jedes einzelne Byte.  Wie k√∂nnen wir generierte Daten mit all diesen Eigenschaften erhalten?  Die naheliegende L√∂sung besteht darin, echte Daten zu verwenden. <br><br>  Viele DBMS implementieren die HyperLogLog-Datenstruktur f√ºr eine Ann√§herung von COUNT (DISTINCT), aber keine von ihnen funktioniert sehr gut, da diese Datenstruktur eine feste Speichermenge verwendet.  ClickHouse verf√ºgt √ºber eine Funktion, die abh√§ngig von der Gr√∂√üe des Datensatzes <a href="https://clickhouse.yandex/docs/en/query_language/agg_functions/reference/">eine Kombination aus drei verschiedenen Datenstrukturen verwendet</a> . <br><br>  Fazit: Die Testdaten m√ºssen die Verteilungseigenschaften der realen Daten gut genug wiedergeben, dh die Kardinalit√§t (Anzahl der unterschiedlichen Werte pro Spalte) und die spalten√ºbergreifende Kardinalit√§t (Anzahl der unterschiedlichen Werte, die √ºber mehrere unterschiedliche Spalten hinweg gez√§hlt werden). <br><br>  <strong>Beispiel 3</strong> <br><br>  Anstatt die Leistung des ClickHouse-DBMS zu testen, nehmen wir etwas Einfacheres wie Hash-Tabellen.  F√ºr Hash-Tabellen ist es wichtig, die richtige Hash-Funktion zu w√§hlen.  Dies ist f√ºr std :: unordered_map nicht so wichtig, da es sich um eine auf Verkettung basierende Hash-Tabelle handelt und eine Primzahl als Array-Gr√∂√üe verwendet wird.  Die Standard-Bibliotheksimplementierung in GCC und Clang verwendet eine einfache Hash-Funktion als Standard-Hash-Funktion f√ºr numerische Typen.  Std :: unordered_map ist jedoch nicht die beste Wahl, wenn wir nach maximaler Geschwindigkeit suchen.  Bei einer offenen Adressierungs-Hash-Tabelle k√∂nnen wir nicht nur eine Standard-Hash-Funktion verwenden.  Die Wahl der richtigen Hash-Funktion wird zum entscheidenden Faktor. <br><br>  Es ist einfach, Leistungstests f√ºr Hash-Tabellen mit zuf√§lligen Daten zu finden, die die verwendeten Hash-Funktionen nicht ber√ºcksichtigen.  Es gibt auch viele Hash-Funktionstests, die sich auf die Berechnungsgeschwindigkeit und bestimmte Qualit√§tskriterien konzentrieren, obwohl sie die verwendeten Datenstrukturen ignorieren.  Fakt ist jedoch, dass Hash-Tabellen und HyperLogLog unterschiedliche Qualit√§tskriterien f√ºr Hash-Funktionen erfordern. <br><br><img src="https://habrastorage.org/webt/bp/3h/32/bp3h320eztrirqzhm-lexeuhmbq.png"><br><br>  Weitere <a href="https://www.youtube.com/watch%3Fv%3DEoX82TEz2sQ">Informationen hierzu finden Sie unter "Funktionsweise von Hash-Tabellen in ClickHouse"</a> (Pr√§sentation in Russisch).  Die Informationen sind leicht veraltet, da sie keine <a href="https://abseil.io/blog/20180927-swisstables">Schweizer Tabellen</a> abdecken. <br><br><h2>  Herausforderung </h2><br>  Unser Ziel ist es, Daten zum Testen der Leistung zu erhalten, die dieselbe Struktur wie Yandex.Metrica-Daten haben, mit allen f√ºr Benchmarks wichtigen Eigenschaften, aber so, dass in diesen Daten keine Spuren von echten Website-Nutzern verbleiben.  Mit anderen Worten, die Daten m√ºssen anonymisiert sein und dennoch Folgendes bewahren: <br><br><ul><li>  Kompressionsverh√§ltnis. </li><li>  Kardinalit√§t (die Anzahl der unterschiedlichen Werte). </li><li>  Gegenseitige Kardinalit√§t zwischen mehreren verschiedenen Spalten. </li><li>  Eigenschaften von Wahrscheinlichkeitsverteilungen, die f√ºr die Datenmodellierung verwendet werden k√∂nnen (wenn wir beispielsweise glauben, dass Regionen nach einem Potenzgesetz verteilt sind, sollte der Exponent - der Verteilungsparameter - f√ºr k√ºnstliche Daten und f√ºr reale Daten ungef√§hr gleich sein). </li></ul><br>  Wie k√∂nnen wir eine √§hnliche Komprimierungsrate f√ºr die Daten erhalten?  Wenn LZ4 verwendet wird, m√ºssen Teilzeichenfolgen in Bin√§rdaten in ungef√§hr derselben Entfernung wiederholt werden und die Wiederholungen m√ºssen ungef√§hr dieselbe L√§nge haben.  F√ºr ZSTD muss auch die Entropie pro Byte √ºbereinstimmen. <br><br>  Das ultimative Ziel ist es, ein √∂ffentlich verf√ºgbares Tool zu erstellen, mit dem jeder seine Datens√§tze zur Ver√∂ffentlichung anonymisieren kann.  Dies w√ºrde es uns erm√∂glichen, die Leistung von Daten anderer Leute zu debuggen und zu testen, die unseren Produktionsdaten √§hnlich sind.  Wir m√∂chten auch, dass die generierten Daten interessant sind. <br><br>  Dies sind jedoch sehr lose definierte Anforderungen, und wir planen nicht, eine formale Problembeschreibung oder Spezifikation f√ºr diese Aufgabe zu verfassen. <br><br><h2>  M√∂gliche L√∂sungen </h2><br>  Ich m√∂chte nicht, dass es so klingt, als sei dieses Problem besonders wichtig.  Es wurde nie in die Planung einbezogen und niemand hatte die Absicht, daran zu arbeiten.  Ich hatte nur gehofft, dass eines Tages eine Idee auftauchen w√ºrde, und pl√∂tzlich war ich gut gelaunt und konnte alles andere bis sp√§ter aufschieben. <br><br><h2>  Explizite Wahrscheinlichkeitsmodelle </h2><br>  Die erste Idee besteht darin, f√ºr jede Spalte in der Tabelle eine Familie von Wahrscheinlichkeitsverteilungen zu finden, die diese modellieren, dann die Parameter basierend auf der Datenstatistik anzupassen (Modellanpassung) und die resultierende Verteilung zum Generieren neuer Daten zu verwenden.  Ein Pseudozufallszahlengenerator mit einem vordefinierten Startwert k√∂nnte verwendet werden, um ein reproduzierbares Ergebnis zu erhalten. <br><br>  Markov-Ketten k√∂nnten f√ºr Textfelder verwendet werden.  Dies ist ein bekanntes Modell, das effektiv implementiert werden k√∂nnte. <br><br>  Es w√§ren jedoch einige Tricks erforderlich: <br><br><ul><li>  Wir wollen die Kontinuit√§t von Zeitreihen erhalten.  Dies bedeutet, dass wir f√ºr einige Datentypen die Differenz zwischen benachbarten Werten und nicht den Wert selbst modellieren m√ºssen. </li><li>  Um die "gemeinsame Kardinalit√§t" von Spalten zu modellieren, m√ºssen wir auch die Abh√§ngigkeiten zwischen Spalten explizit ber√ºcksichtigen.  Beispielsweise gibt es normalerweise nur sehr wenige IP-Adressen pro Benutzer-ID. Um eine IP-Adresse zu generieren, w√ºrden wir einen Hash-Wert der Benutzer-ID als Ausgangswert verwenden und auch eine kleine Menge anderer Pseudozufallsdaten hinzuf√ºgen. </li><li>  Wir sind uns nicht sicher, wie wir die Abh√§ngigkeit ausdr√ºcken sollen, dass derselbe Benutzer URLs mit √ºbereinstimmenden Domains ungef√§hr zur selben Zeit besucht. </li></ul><br>  All dies kann in einem C ++ - "Skript" geschrieben werden, wobei die Distributionen und Abh√§ngigkeiten fest codiert sind.  Markov-Modelle werden jedoch aus einer Kombination von Statistiken mit Gl√§tten und Hinzuf√ºgen von Rauschen erhalten.  Ich habe angefangen, ein Skript wie dieses zu schreiben, aber nachdem ich explizite Modelle f√ºr zehn Spalten geschrieben hatte, wurde es unertr√§glich langweilig - und die "Treffer" -Tabelle in Yandex.Metrica hatte 2012 mehr als 100 Spalten. <br><br><pre> <code class="cpp hljs">EventTime.day(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::discrete_distribution&lt;&gt;({ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">13</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">42</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">17</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, ...})(random)); EventTime.hour(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::discrete_distribution&lt;&gt;({ <span class="hljs-number"><span class="hljs-number">13</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">24</span></span>, <span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">18</span></span>, <span class="hljs-number"><span class="hljs-number">19</span></span>, <span class="hljs-number"><span class="hljs-number">19</span></span>, ...})(random)); EventTime.minute(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::uniform_int_distribution&lt;UInt8&gt;(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">59</span></span>)(random)); EventTime.second(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::uniform_int_distribution&lt;UInt8&gt;(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">59</span></span>)(random)); UInt64 UserID = hash(<span class="hljs-number"><span class="hljs-number">4</span></span>, powerLaw(<span class="hljs-number"><span class="hljs-number">5000</span></span>, <span class="hljs-number"><span class="hljs-number">1.1</span></span>)); UserID = UserID / <span class="hljs-number"><span class="hljs-number">10000000000U</span></span>LL * <span class="hljs-number"><span class="hljs-number">10000000000U</span></span>LL + <span class="hljs-keyword"><span class="hljs-keyword">static_cast</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">time_t</span></span>&gt;(EventTime) + UserID % <span class="hljs-number"><span class="hljs-number">1000000</span></span>; random_with_seed.seed(powerLaw(<span class="hljs-number"><span class="hljs-number">5000</span></span>, <span class="hljs-number"><span class="hljs-number">1.1</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> get_random_with_seed = [&amp;]{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> random_with_seed(); };</code> </pre><br>  Dieser Ansatz war ein Misserfolg.  Wenn ich mich mehr angestrengt h√§tte, w√§re das Skript vielleicht schon fertig. <br><br>  Vorteile: <br><br><ul><li>  Konzeptuelle Einfachheit. </li></ul><br>  Nachteile: <br><br><ul><li>  Viel Arbeit erforderlich. </li><li>  Die L√∂sung gilt nur f√ºr einen Datentyp. </li></ul><br>  Und ich w√ºrde eine allgemeinere L√∂sung vorziehen, die sowohl f√ºr Yandex.Metrica-Daten als auch zum Verschleiern anderer Daten verwendet werden kann. <br><br>  In jedem Fall k√∂nnte diese L√∂sung verbessert werden.  Anstatt Modelle manuell auszuw√§hlen, k√∂nnten wir einen Katalog von Modellen implementieren und die besten unter ihnen ausw√§hlen (beste Anpassung plus irgendeine Form der Regularisierung).  Oder wir k√∂nnten Markov-Modelle f√ºr alle Arten von Feldern verwenden, nicht nur f√ºr Text.  Abh√§ngigkeiten zwischen Daten k√∂nnen auch automatisch extrahiert werden.  Dazu m√ºsste die <a href="https://en.wikipedia.org/wiki/Kullback%25E2%2580%2593Leibler_divergence">relative Entropie</a> (relative Informationsmenge) zwischen den Spalten berechnet werden.  Eine einfachere Alternative besteht darin, relative Kardinalit√§ten f√ºr jedes Spaltenpaar zu berechnen (so etwas wie "wie viele verschiedene Werte von A gibt es im Durchschnitt f√ºr einen festen Wert B").  Dies macht beispielsweise deutlich, dass URLDomain vollst√§ndig von der URL abh√§ngt und nicht umgekehrt. <br><br>  Aber ich habe diese Idee auch abgelehnt, weil zu viele Faktoren zu ber√ºcksichtigen sind und das Schreiben zu lange dauern w√ºrde. <br><br><h2>  Neuronale Netze </h2><br>  Wie ich bereits erw√§hnte, stand diese Aufgabe nicht ganz oben auf der Priorit√§tenliste - niemand dachte dar√ºber nach, sie zu l√∂sen.  Aber wie es das Gl√ºck wollte, unterrichtete unser Kollege Ivan Puzirevsky an der Higher School of Economics.  Er fragte mich, ob ich irgendwelche interessanten Probleme h√§tte, die f√ºr seine Studenten als geeignete Abschlussarbeitsthemen geeignet w√§ren.  Als ich ihm dieses anbot, versicherte er mir, dass es Potenzial habe.  Also gab ich diese Herausforderung an einen netten Kerl "von der Stra√üe" Sharif weiter (er musste allerdings eine NDA unterzeichnen, um auf die Daten zugreifen zu k√∂nnen). <br><br>  Ich teilte ihm alle meine Ideen mit, betonte jedoch, dass es keine Einschr√§nkungen f√ºr die L√∂sung des Problems gibt. Eine gute Option w√§re, Ans√§tze auszuprobieren, √ºber die ich nichts wei√ü, wie die Verwendung von LSTM zum Generieren eines Text-Dumps von Daten.  Dies schien vielversprechend, nachdem der Artikel <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Die unzumutbare Wirksamkeit wiederkehrender neuronaler Netze ver√∂ffentlicht wurde</a> . <br><br>  Die erste Herausforderung besteht darin, dass wir strukturierte Daten generieren m√ºssen, nicht nur Text.  Es war jedoch nicht klar, ob ein wiederkehrendes neuronales Netzwerk Daten mit der gew√ºnschten Struktur erzeugen k√∂nnte.  Es gibt zwei M√∂glichkeiten, dies zu l√∂sen.  Die erste L√∂sung besteht darin, separate Modelle zum Erzeugen der Struktur und des "F√ºllers" zu verwenden und nur das neuronale Netzwerk zum Erzeugen von Werten zu verwenden.  Dieser Ansatz wurde jedoch verschoben und nie abgeschlossen.  Die zweite L√∂sung besteht darin, einfach einen TSV-Dump als Text zu generieren.  Erfahrungsgem√§√ü stimmen einige Zeilen im Text nicht mit der Struktur √ºberein, diese Zeilen k√∂nnen jedoch beim Laden der Daten verworfen werden. <br><br>  Die zweite Herausforderung besteht darin, dass das wiederkehrende neuronale Netzwerk eine Folge von Daten erzeugt und daher Abh√§ngigkeiten in Daten in der Reihenfolge der Folge folgen m√ºssen.  In unseren Daten kann sich die Reihenfolge der Spalten m√∂glicherweise umgekehrt zu den Abh√§ngigkeiten zwischen ihnen verhalten. <br>  Wir haben nichts unternommen, um dieses Problem zu beheben. <br><br>  Als der Sommer n√§her r√ºckte, hatten wir das erste funktionierende Python-Skript, das Daten generierte.  Die Datenqualit√§t schien auf den ersten Blick anst√§ndig: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f31/4c0/56f/f314c056f24678ea65fdeec9076991bc.jpg"><br><br>  Wir sind jedoch auf einige Schwierigkeiten gesto√üen: <br><br><ol><li>  Die Gr√∂√üe des Modells betr√§gt etwa ein Gigabyte.  Wir haben versucht, ein Modell f√ºr Daten mit einer Gr√∂√üe von mehreren Gigabyte zu erstellen (zun√§chst).  Die Tatsache, dass das resultierende Modell so gro√ü ist, gibt Anlass zur Sorge.  W√§re es m√∂glich, die realen Daten zu extrahieren, auf die es trainiert wurde?  Unwahrscheinlich  Aber ich wei√ü nicht viel √ºber maschinelles Lernen und neuronale Netze, und ich habe den Python-Code dieses Entwicklers nicht gelesen. Wie kann ich also sicher sein?  Zu der Zeit wurden mehrere Artikel ver√∂ffentlicht, in denen es darum ging, neuronale Netze ohne Qualit√§tsverlust zu komprimieren, die jedoch nicht implementiert wurden.  Einerseits scheint dies kein ernstes Problem zu sein, da wir die Ver√∂ffentlichung des Modells ablehnen und nur die generierten Daten ver√∂ffentlichen k√∂nnen.  Wenn andererseits eine √úberanpassung auftritt, k√∂nnen die generierten Daten einen Teil der Quelldaten enthalten. </li><li>  Auf einem Computer mit einer einzelnen CPU betr√§gt die Datenerzeugungsgeschwindigkeit ungef√§hr 100 Zeilen pro Sekunde.  Unser Ziel war es, mindestens eine Milliarde Zeilen zu generieren.  Berechnungen ergaben, dass dies nicht vor dem Datum der Verteidigung der Dissertation abgeschlossen sein w√ºrde.  Es war nicht sinnvoll, zus√§tzliche Hardware zu verwenden, da das Ziel darin bestand, ein Tool zur Datengenerierung zu entwickeln, das von jedem verwendet werden konnte. </li></ol><br>  Sharif versuchte, die Qualit√§t der Daten durch einen Vergleich der Statistiken zu analysieren.  Er berechnete unter anderem die H√§ufigkeit verschiedener Zeichen, die in den Quelldaten und in den generierten Daten vorkommen.  Das Ergebnis war atemberaubend: Die h√§ufigsten Zeichen waren √ê und √ë. <br><br>  Mach dir keine Sorgen um Sharif.  Er hat seine These erfolgreich verteidigt und dann haben wir das Ganze gl√ºcklicherweise vergessen. <br><br><h2>  Mutation komprimierter Daten </h2><br>  Angenommen, die Problemanweisung wurde auf einen einzigen Punkt reduziert: Wir m√ºssen Daten mit demselben Komprimierungsverh√§ltnis wie die Quelldaten generieren und die Daten m√ºssen mit derselben Geschwindigkeit dekomprimiert werden.  Wie k√∂nnen wir das erreichen?  Wir m√ºssen komprimierte Datenbytes direkt bearbeiten!  Auf diese Weise k√∂nnen wir die Daten √§ndern, ohne die Gr√∂√üe der komprimierten Daten zu √§ndern, und alles wird schnell funktionieren.  Ich wollte diese Idee sofort ausprobieren, obwohl das Problem, mit dem sie sich befasst, nicht das gleiche ist, mit dem wir begonnen haben.  Aber so ist es immer. <br><br>  Wie bearbeiten wir eine komprimierte Datei?  Nehmen wir an, wir interessieren uns nur f√ºr LZ4.  LZ4-komprimierte Daten bestehen aus Folgen, die wiederum Zeichenfolgen aus nicht komprimierten Bytes (Literalen) sind, gefolgt von einer √úbereinstimmungskopie: <br><br><ol><li>  Literale (kopieren Sie die folgenden N Bytes so wie sie sind). </li><li>  √úbereinstimmungen mit einer minimalen Wiederholungsl√§nge von 4 (wiederholen Sie N Bytes, die sich in der Datei in einem Abstand von M befanden). </li></ol><br>  Quelldaten: <br>  <code>Hello world Hello</code> . <br><br>  Komprimierte Daten (beliebiges Beispiel): <br>  <code>literals 12 "Hello world " match 5 12</code> . <br><br>  In der komprimierten Datei lassen wir "match" unver√§ndert und √§ndern die Bytewerte in "literals".  Als Ergebnis erhalten wir nach dem Dekomprimieren eine Datei, in der alle sich wiederholenden Sequenzen, die mindestens 4 Bytes lang sind, ebenfalls in der gleichen Entfernung wiederholt werden, aber aus einer anderen Menge von Bytes bestehen (im Grunde enth√§lt die ge√§nderte Datei keine einzige Byte, das aus der Quelldatei entnommen wurde). <br><br>  Aber wie √§ndern wir die Bytes?  Die Antwort ist nicht offensichtlich, da die Daten neben den Spaltentypen auch eine eigene interne, implizite Struktur haben, die wir beibehalten m√∂chten.  Beispielsweise wird Text h√§ufig in UTF-8-Codierung gespeichert, und die generierten Daten sollen auch UTF-8-g√ºltig sein.  Ich habe eine einfache Heuristik entwickelt, bei der mehrere Kriterien erf√ºllt werden: <br><br><ul><li>  Nullbytes und ASCII-Steuerzeichen bleiben unver√§ndert. </li><li>  Einige Satzzeichen bleiben unver√§ndert. </li><li>  ASCII wird in ASCII konvertiert und f√ºr alles andere bleibt das h√∂chstwertige Bit erhalten (oder ein expliziter Satz von "if" -Anweisungen wird f√ºr verschiedene UTF-8-L√§ngen geschrieben).  In einer Byte-Klasse wird ein neuer Wert gleichm√§√üig zuf√§llig ausgew√§hlt. </li><li>  Fragmente wie <code>https://</code> bleiben erhalten, sonst sieht es etwas albern aus. </li></ul><br>  Der einzige Nachteil dieses Ansatzes besteht darin, dass das Datenmodell die Quelldaten selbst sind, das hei√üt, es kann nicht ver√∂ffentlicht werden.  Das Modell eignet sich nur zum Generieren von Datenmengen, die nicht gr√∂√üer als die Quelle sind.  Im Gegenteil, die bisherigen Ans√§tze liefern Modelle, mit denen Daten beliebiger Gr√∂√üe erzeugt werden k√∂nnen. <br><br>  Beispiel f√ºr eine URL: <br><br> <code>http://ljc.she/kdoqdqwpgafe/klwlpm&amp;qw=962788775I0E7bs7OXeAyAx <br> http://ljc.she/kdoqdqwdffhant.am/wcpoyodjit/cbytjgeoocvdtclac <br> http://ljc.she/kdoqdqwpgafe/klwlpm&amp;qw=962788775I0E7bs7OXe <br> http://ljc.she/kdoqdqwdffhant.am/wcpoyodjit/cbytjgeoocvdtclac <br> http://ljc.she/kdoqdqwdbknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqw-bknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqwpdtu-Unu-Rjanjna-bbcohu_qxht <br> http://ljc.she/kdoqdqw-bknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqwpdtu-Unu-Rjanjna-bbcohu_qxht <br> http://ljc.she/kdoqdqw-bknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqwpdtu-Unu-Rjanjna-bbcohu-702130 <br></code> <br>  Die Ergebnisse waren positiv und die Daten waren interessant, aber etwas stimmte nicht.  Die URLs behielten die gleiche Struktur, aber in einigen von ihnen war es zu einfach, "yandex" oder "avito" (ein beliebter Marktplatz in Russland) zu erkennen, sodass ich eine Heuristik erstellt habe, die einige der Bytes vertauscht. <br><br>  Es gab auch andere Bedenken.  Beispielsweise k√∂nnen vertrauliche Informationen m√∂glicherweise in einer FixedString-Spalte in Bin√§rdarstellung gespeichert sein und m√∂glicherweise aus ASCII-Steuerzeichen und Satzzeichen bestehen, die ich beibehalten m√∂chte.  Datentypen habe ich jedoch nicht ber√ºcksichtigt. <br><br>  Ein weiteres Problem ist, dass wenn eine Spalte Daten im Format "L√§nge, Wert" speichert (so werden Zeichenfolgenspalten gespeichert), wie kann ich sicherstellen, dass die L√§nge nach der Mutation korrekt bleibt?  Als ich versuchte, das zu beheben, verlor ich sofort das Interesse. <br><br><h2>  Zuf√§llige Permutationen </h2><br>  Leider wurde das Problem nicht gel√∂st.  Wir haben ein paar Experimente durchgef√ºhrt, und es wurde noch schlimmer.  Das einzige, was noch √ºbrig war, war herumzusitzen, nichts zu tun und willk√ºrlich im Internet zu surfen, da die Magie verschwunden war.  Zum Gl√ºck bin ich auf eine Seite <a href="http://fabiensanglard.net/fizzlefade/index.php">gesto√üen, die den Algorithmus</a> zum Rendern des Todes der Hauptfigur im Spiel Wolfenstein 3D erkl√§rt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d4/974/bc8/6d4974bc880538a894617dfb0c77eb3d.gif" width="640" height="480"><br><br>  Die Animation ist wirklich gut gemacht - der Bildschirm f√ºllt sich mit Blut.  Der Artikel erkl√§rt, dass dies tats√§chlich eine pseudozuf√§llige Permutation ist.  Eine zuf√§llige Permutation eines Satzes von Elementen ist eine zuf√§llig ausgew√§hlte bijektive (Eins-zu-Eins) Transformation des Satzes oder eine Abbildung, bei der jedes abgeleitete Element genau einem urspr√ºnglichen Element entspricht (und umgekehrt).  Mit anderen Worten, es ist eine M√∂glichkeit, alle Elemente eines Datensatzes nach dem Zufallsprinzip zu durchlaufen.  Und genau das ist der im Bild gezeigte Vorgang: Jedes Pixel wird ohne Wiederholung in zuf√§lliger Reihenfolge ausgef√ºllt.  Wenn wir bei jedem Schritt nur ein zuf√§lliges Pixel ausw√§hlen w√ºrden, w√ºrde es lange dauern, bis wir zum letzten Pixel gelangen. <br><br>  Das Spiel verwendet einen sehr einfachen Algorithmus f√ºr die Pseudozufalls-Permutation, der als Linear Feedback Shift Register ( <a href="https://en.wikipedia.org/wiki/Linear-feedback_shift_register">LFSR</a> ) bezeichnet wird.  √Ñhnlich wie Pseudozufallszahlengeneratoren k√∂nnen zuf√§llige Permutationen oder vielmehr deren Familien kryptografisch stark sein, wenn sie durch einen Schl√ºssel parametrisiert werden.  Genau das brauchen wir f√ºr die Datentransformation.  Die Details k√∂nnten jedoch kniffliger sein.  Beispielsweise scheint eine kryptografisch starke Verschl√ºsselung von N Bytes zu N Bytes mit einem vorbestimmten Schl√ºssel und einem Initialisierungsvektor f√ºr eine pseudozuf√§llige Permutation eines Satzes von N-Byte-Zeichenfolgen zu funktionieren.  In der Tat ist dies eine Eins-zu-Eins-Transformation und es scheint zuf√§llig zu sein.  Wenn wir jedoch f√ºr alle unsere Daten dieselbe Transformation verwenden, ist das Ergebnis m√∂glicherweise f√ºr die Kryptoanalyse anf√§llig, da derselbe Initialisierungsvektor und derselbe Schl√ºsselwert mehrmals verwendet werden.  Dies √§hnelt der Funktionsweise des <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">elektronischen Codebuchs</a> f√ºr eine Blockchiffre. <br><br>  Was sind die m√∂glichen Wege, um eine Pseudozufalls-Permutation zu erhalten?  Wir k√∂nnen einfache Eins-zu-Eins-Transformationen durchf√ºhren und eine komplexe Funktion erstellen, die zuf√§llig aussieht.  Hier sind einige meiner Lieblings-Eins-zu-Eins-Transformationen: <br><br><ul><li>  Multiplikation mit einer ungeraden Zahl (wie eine gro√üe Primzahl) in Zweierkomplementarithmetik. </li><li>  Xorshift: <code>x ^= x &gt;&gt; N</code> </li><li>  CRC-N, wobei N die Anzahl der Bits im Argument ist. </li></ul><br>  Beispielsweise werden drei Multiplikationen und zwei Xorshift-Operationen f√ºr den <a href="">Murmelhash-</a> Finalizer verwendet.  Diese Operation ist eine Pseudozufalls-Permutation.  Ich sollte jedoch darauf hinweisen, dass Hash-Funktionen nicht eins zu eins sein m√ºssen (sogar Hashes von N Bits zu N Bits). <br><br>  Oder hier ist ein weiteres interessantes <a href="https://preshing.com/20121224/how-to-generate-a-sequence-of-unique-random-integers/">Beispiel aus der elementaren Zahlentheorie</a> von Jeff Preshings Website. <br><br>  Wie k√∂nnen wir Pseudozufalls-Permutationen verwenden, um unser Problem zu l√∂sen?  Wir k√∂nnen sie verwenden, um alle numerischen Felder zu transformieren, damit wir die Kardinalit√§ten und gegenseitigen Kardinalit√§ten aller Feldkombinationen beibehalten k√∂nnen.  Mit anderen Worten, COUNT (DISTINCT) gibt den gleichen Wert wie vor der Transformation zur√ºck und au√üerdem mit jedem GROUP BY. <br><br>  Es ist anzumerken, dass die Wahrung aller Kardinalit√§ten in gewisser Weise unserem Ziel der Datenanonymisierung widerspricht.  Angenommen, jemand wei√ü, dass die Quelldaten f√ºr Websitesitzungen einen Benutzer enthalten, der Websites aus 10 verschiedenen L√§ndern besucht hat, und er m√∂chte diesen Benutzer in den transformierten Daten finden.  Die transformierten Daten zeigen auch, dass der Benutzer Websites aus 10 verschiedenen L√§ndern besucht hat, wodurch die Suche einfacher eingegrenzt werden kann.  Selbst wenn sie herausfinden, in was der Benutzer umgewandelt wurde, ist dies nicht sehr n√ºtzlich, da alle anderen Daten ebenfalls umgewandelt wurden, sodass sie nicht herausfinden k√∂nnen, welche Websites der Benutzer besucht hat oder sonst etwas.  Diese Regeln k√∂nnen jedoch in einer Kette angewendet werden.  Wenn jemand beispielsweise wei√ü, dass die in unseren Daten am h√§ufigsten vorkommende Website Yandex ist und Google an zweiter Stelle steht, kann er anhand des Rankings ermitteln, welche umgewandelten Website-IDs tats√§chlich Yandex und Google bedeuten.  Dies ist nicht √ºberraschend, da wir mit einer informellen Problemstellung arbeiten und nur versuchen, ein Gleichgewicht zwischen Anonymisierung von Daten (Verbergen von Informationen) und Erhalt von Dateneigenschaften (Offenlegung von Informationen) zu finden.  In diesem <a href="https://medium.com/georgian-impact-blog/a-brief-introduction-to-differential-privacy-eacf8722283b">Artikel</a> erfahren Sie, wie Sie das Problem der Datenanonymisierung zuverl√§ssiger angehen k√∂nnen. <br><br>  Zus√§tzlich zur Beibehaltung der urspr√ºnglichen Kardinalit√§t der Werte m√∂chte ich auch die Gr√∂√üenordnung der Werte beibehalten.  Was ich meine ist, dass, wenn die Quelldaten Zahlen unter 10 enthielten, ich m√∂chte, dass die transformierten Zahlen auch klein sind.  Wie k√∂nnen wir das erreichen? <br><br>  Beispielsweise k√∂nnen wir eine Reihe m√∂glicher Werte in Gr√∂√üenklassen unterteilen und Permutationen innerhalb jeder Klasse separat durchf√ºhren (wobei die Gr√∂√üenklassen beibehalten werden).  Der einfachste Weg, dies zu tun, besteht darin, die n√§chste Zweierpotenz oder die Position des h√∂chstwertigen Bits in der Zahl als Gr√∂√üenklasse zu nehmen (dies sind die gleichen Werte).  Die Zahlen 0 und 1 bleiben immer unver√§ndert.  Die Zahlen 2 und 3 bleiben manchmal unver√§ndert (mit einer Wahrscheinlichkeit von 1/2) und werden manchmal ausgetauscht (mit einer Wahrscheinlichkeit von 1/2).  Die Menge der Zahlen 1024. 2047 wird einer von 1024 zugeordnet!  (Fakult√§ts-) Varianten und so weiter.  F√ºr signierte Nummern behalten wir das Schild. <br><br>  Es ist auch zweifelhaft, ob wir eine Eins-zu-Eins-Funktion ben√∂tigen.  Wir k√∂nnen wahrscheinlich nur eine kryptografisch starke Hash-Funktion verwenden.  Die Transformation wird nicht eins zu eins sein, aber die Kardinalit√§t wird in etwa gleich sein. <br><br>  Wir ben√∂tigen jedoch eine kryptografisch starke zuf√§llige Permutation, damit es schwierig ist, die urspr√ºnglichen Daten aus den neu angeordneten Daten wiederherzustellen, ohne den Schl√ºssel zu kennen, wenn wir einen Schl√ºssel definieren und eine Permutation mit diesem Schl√ºssel ableiten. <br><br>  Es gibt ein Problem: Ich wei√ü nicht nur nichts √ºber neuronale Netze und maschinelles Lernen, sondern wei√ü auch nichts √ºber Kryptographie.  Das ist nur mein Mut.  Ich las immer noch zuf√§llige Webseiten und fand in <a href="https://news.ycombinator.com/item%3Fid%3D15122540">Hackers News</a> einen Link zu einer Diskussion auf Fabien Sanglards Seite.  Es gab einen Link zu einem <a href="http://antirez.com/news/113">Blogbeitrag</a> von Redis-Entwickler Salvatore Sanfilippo, in dem es darum ging, auf wunderbare Weise zuf√§llige Permutationen zu erhalten, das sogenannte <a href="https://en.wikipedia.org/wiki/Feistel_cipher">Feistel-Netzwerk</a> . <br><br>  Das Feistel-Netzwerk ist iterativ und besteht aus Runden.  Jede Runde ist eine bemerkenswerte Transformation, mit der Sie von jeder Funktion eine Eins-zu-Eins-Funktion erhalten.  Schauen wir uns an, wie es funktioniert. <br><br><ol><li>  Die Bits des Arguments sind in zwei H√§lften unterteilt: <br> <code>arg: xxxxyyyy <br> <font color="#0fc000">arg_l</font> : xxxx <br> <font color="#0000ff">arg_r</font> : yyyy</code> </li> <li>  Die rechte H√§lfte ersetzt die linke.  An seine Stelle setzen wir das Ergebnis von XOR auf den Anfangswert der linken H√§lfte und das Ergebnis der Funktion, die auf den Anfangswert der rechten H√§lfte angewendet wird, wie folgt: <br> <code>res: yyyyzzzz <br> <font color="#0000ff">res_l</font> = yyyy = <font color="#0000ff">arg_r</font> <br> <font color="#FF6600">res_r</font> = zzzz = <font color="#0fc000">arg_l</font> ^ F( <font color="#0000ff">arg_r</font> )</code> </li> </ol><br>  Es gibt auch die Behauptung, dass wir eine kryptografisch starke Pseudozufallsfunktion f√ºr F verwenden und mindestens viermal eine Feistel-Runde anwenden, um eine kryptografisch starke Pseudozufallspermutation zu erhalten. <br><br>  Das ist wie ein Wunder: Wir nehmen eine Funktion, die zuf√§lligen M√ºll basierend auf Daten erzeugt, f√ºgen ihn in das Feistel-Netzwerk ein und wir haben jetzt eine Funktion, die zuf√§lligen M√ºll basierend auf Daten erzeugt, aber dennoch umkehrbar ist! <br><br>  Das Feistel-Netzwerk ist das Herzst√ºck mehrerer Datenverschl√ºsselungsalgorithmen.  Was wir tun werden, ist so etwas wie Verschl√ºsselung, nur dass es wirklich schlecht ist.  Daf√ºr gibt es zwei Gr√ºnde: <br><br><ul><li>  Wir verschl√ºsseln einzelne Werte unabh√§ngig und auf die gleiche Weise, √§hnlich der Funktionsweise des elektronischen Codebuchs. </li><li>  Wir speichern Informationen √ºber die Gr√∂√üenordnung (die n√§chste Potenz von zwei) und das Vorzeichen des Werts, was bedeutet, dass sich einige Werte √ºberhaupt nicht √§ndern. </li></ul><br>  Auf diese Weise k√∂nnen wir numerische Felder verschleiern und dabei die Eigenschaften beibehalten, die wir ben√∂tigen.  Beispielsweise sollte nach Verwendung von LZ4 das Komprimierungsverh√§ltnis ungef√§hr gleich bleiben, da die doppelten Werte in den Quelldaten in den konvertierten Daten und in gleichen Abst√§nden voneinander wiederholt werden. <br><br><h2>  Markov-Modelle </h2><br>  Textmodelle werden f√ºr die Datenkomprimierung, die Vorhersageeingabe, die Spracherkennung und die Erzeugung von Zufallszeichenfolgen verwendet.  Ein Textmodell ist eine Wahrscheinlichkeitsverteilung aller m√∂glichen Zeichenfolgen.  Nehmen wir an, wir haben eine imagin√§re Wahrscheinlichkeitsverteilung der Texte aller B√ºcher, die die Menschheit jemals schreiben k√∂nnte.  Um eine Zeichenfolge zu generieren, nehmen wir einfach einen zuf√§lligen Wert mit dieser Verteilung und geben die resultierende Zeichenfolge zur√ºck (ein zuf√§lliges Buch, das die Menschheit schreiben k√∂nnte).  Aber wie ermitteln wir die Wahrscheinlichkeitsverteilung aller m√∂glichen Zeichenketten? <br><br>  Erstens w√ºrde dies zu viele Informationen erfordern.  Es gibt 256 ^ 10 m√∂gliche Zeichenfolgen mit einer L√§nge von 10 Byte, und das explizite Schreiben einer Tabelle mit der Wahrscheinlichkeit jeder Zeichenfolge w√ºrde sehr viel Speicherplatz erfordern.  Zweitens haben wir nicht gen√ºgend Statistiken, um die Verteilung genau zu bewerten. <br><br>  Aus diesem Grund verwenden wir als Textmodell eine Wahrscheinlichkeitsverteilung aus groben Statistiken.  Zum Beispiel k√∂nnten wir die Wahrscheinlichkeit berechnen, dass jeder Buchstabe im Text vorkommt, und dann Zeichenfolgen generieren, indem wir jeden n√§chsten Buchstaben mit der gleichen Wahrscheinlichkeit ausw√§hlen.  Dieses primitive Modell funktioniert, aber die Zeichenfolgen sind immer noch sehr unnat√ºrlich. <br><br>  Um das Modell leicht zu verbessern, k√∂nnen wir auch die bedingte Wahrscheinlichkeit des Auftretens des Buchstabens heranziehen, wenn N spezifischen Buchstaben vorangestellt sind.  N ist eine voreingestellte Konstante.  Nehmen wir an, N = 5 und wir berechnen die Wahrscheinlichkeit, dass der Buchstabe "e" nach den Buchstaben "compr" auftritt.  Dieses Textmodell wird als Order-N-Markov-Modell bezeichnet. <br><br> <code>P(cat <font color="#ff0000">a</font> | cat) = 0.8 <br> P(cat <font color="#ff0000">b</font> | cat) = 0.05 <br> P(cat <font color="#ff0000">c</font> | cat) = 0.1 <br> ...</code> <br> <br>  Schauen wir uns auf der Website <a href="https://projects.haykranen.nl/markov/demo/">von Hay Kranen</a> an, wie Markov-Modelle funktionieren.  Im Gegensatz zu neuronalen LSTM-Netzen verf√ºgen die Modelle nur √ºber gen√ºgend Speicher f√ºr einen kleinen Kontext von N mit fester L√§nge, sodass sie lustige, unsinnige Texte generieren.  Markov-Modelle werden auch in primitiven Methoden zum Generieren von Spam verwendet. Die generierten Texte k√∂nnen leicht von echten unterschieden werden, indem Statistiken gez√§hlt werden, die nicht zum Modell passen.  Es gibt einen Vorteil: Markov-Modelle arbeiten viel schneller als neuronale Netze, genau das, was wir brauchen. <br><br>  Beispiel f√ºr Titel (unsere Beispiele sind aufgrund der verwendeten Daten auf T√ºrkisch): <br><br><blockquote>  Hyunday Butter'dan anket shluha - Politischer Leiter man≈üetleri |  STALKER BOXER √áiftede Buch - Yanudistkarƒ±≈ümanlƒ± Mƒ± Kanal |  League el Digitalika Haberler Haberleri - Haberlerisi - Hotels mit Centry'ler Neden babah.com </blockquote><br>  Wir k√∂nnen Statistiken aus den Quelldaten berechnen, ein Markov-Modell erstellen und damit neue Daten generieren.  Beachten Sie, dass das Modell gegl√§ttet werden muss, um Informationen zu seltenen Kombinationen in den Quelldaten nicht preiszugeben. Dies ist jedoch kein Problem.  Ich verwende eine Kombination von Modellen von 0 bis N. Wenn die Statistiken f√ºr das Modell der Ordnung N nicht ausreichen, wird stattdessen das Modell N - 1 verwendet. <br><br>  Wir m√∂chten jedoch weiterhin die Kardinalit√§t der Daten bewahren.  Mit anderen Worten, wenn die Quelldaten 123456 eindeutige URL-Werte hatten, sollte das Ergebnis ungef√§hr dieselbe Anzahl eindeutiger Werte haben.  Wir k√∂nnen einen deterministisch initialisierten Zufallszahlengenerator verwenden, um dies zu erreichen.  Am einfachsten ist es, eine Hash-Funktion zu verwenden und auf den urspr√ºnglichen Wert anzuwenden.  Mit anderen Worten, wir erhalten ein pseudozuf√§lliges Ergebnis, das explizit durch den urspr√ºnglichen Wert bestimmt wird. <br><br>  Eine weitere Voraussetzung ist, dass die Quelldaten viele verschiedene URLs haben, die mit demselben Pr√§fix beginnen, jedoch nicht identisch sind.  Zum Beispiel: <code>https://www.yandex.ru/images/cats/?id=xxxxxx</code> .  Wir m√∂chten, dass das Ergebnis auch URLs enth√§lt, die alle mit demselben, aber einem anderen Pr√§fix beginnen.  Beispiel: <code>http://ftp.google.kz/cgi-bin/index.phtml?item=xxxxxx</code> .  Als Zufallszahlengenerator zum Generieren des n√§chsten Zeichens unter Verwendung eines Markov-Modells nehmen wir eine Hash-Funktion aus einem sich bewegenden Fenster von 8 Bytes an der angegebenen Position (anstatt es aus der gesamten Zeichenfolge zu nehmen). <br><br> <code>https://www.yandex.ru/ <font color="#0fc000">images/c</font> ats/?id=12345 <br> ^^^^^^^^ <br> <br> distribution: [aaaa][b][cc][dddd][e][ff][g <font color="#ff0000">g</font> ggg][h]... <br> hash(" <font color="#0fc000">images/c</font> ") % total_count:           ^ <br> <br></code> <code>http://ftp.google.kz/c <font color="#ff0000">g</font> ...</code> <br> <br>  Es stellt sich heraus, dass es genau das ist, was wir brauchen.  Hier ist das Beispiel f√ºr Seitentitel: <br><br><blockquote><pre>  PhotoFunia - Haber7 - Jetzt kaufen! Oynamak i√ßinde ≈üa≈üƒ±racak haber, Oyunu Oynanƒ±lmaz ‚Ä¢ apr√≥d.hu k√≠n√°lat√°ban - RT Arabic
 PhotoFunia - Kinobar.Net - apr√≥d: Ingyenes |  Posti
 PhotoFunia - Peg Perfeo - Castika, Sƒ±radƒ±≈üƒ± Deniz Lokoning Ihr Code, Vater Eminema.tv/
 PhotoFunia - TUT.BY - Ihr Ayakkanƒ±n ve Son Dakika Spor,
 PhotoFunia - Gro√üfilm, Del Meireles offilim, Samsung DealeXtreme Deƒüerler NEWSru.com.tv, Smotri.com Mobile yapmak Okey
 PhotoFunia 5 |  Galaxy, gt, dupƒÉce anal bilgi yarak Ceza RE050A V-Stran√ß
 PhotoFunia :: Miami olacaksƒ±nƒ± yerel Haberler Oyun Junges Video
 PhotoFunia Monstelli'nin En ƒ∞yi kisa.com.tr ‚ÄìStar Thunder Ekranƒ±
 PhotoFunia Seks - Politika, Ekonomi, Spor GTA SANAYƒ∞ VE
 PhotoFunia Taker-Rating Star-Fernsehen Resmi S√∂ylenen Yataƒüa ka≈ºdy dzie≈º wierzchnie
 PhotoFunia TourIndex.Marketime Oyna Geldollarƒ± Mynet Spor, Magazin, Haberler und Haberleri ve Solvia, korkusuz Ev SahneTv
 PhotoFunia todo in der Gratis Perky Parti'nin yapƒ±yƒ± bu fotogram
 PhotoFunian D√ºnyasƒ±n takƒ±mƒ±z halles en kullarƒ± - TEZ
</pre></blockquote><br><h2>  Ergebnisse </h2><br>  Nachdem ich vier Methoden ausprobiert hatte, hatte ich dieses Problem so satt, dass es Zeit war, einfach etwas auszuw√§hlen, es zu einem brauchbaren Werkzeug zu machen und die L√∂sung anzuk√ºndigen.  Ich habe die L√∂sung gew√§hlt, die zuf√§llige Permutationen und mit einem Schl√ºssel parametrisierte Markov-Modelle verwendet.  Es ist als <b>Clickhouse-Obfuscator-</b> Programm implementiert, das sehr einfach zu bedienen ist.  Die Eingabe ist ein Tabellen-Dump in einem <a href="https://clickhouse.yandex/docs/en/interfaces/formats/">beliebigen unterst√ºtzten Format</a> (z. B. CSV oder JSONEachRow). Die Befehlszeilenparameter geben die Tabellenstruktur (Spaltennamen und -typen) und den geheimen Schl√ºssel (eine beliebige Zeichenfolge, die Sie unmittelbar nach der Verwendung vergessen k√∂nnen) an.  Die Ausgabe entspricht der gleichen Anzahl von Zeilen mit verschleierten Daten. <br><br>  Das Programm wird mit clickhouse-client installiert, ist unabh√§ngig von Abh√§ngigkeiten und kann auf fast allen Linux-Versionen verwendet werden.  Sie k√∂nnen es auf jeden Datenbank-Dump anwenden, nicht nur auf ClickHouse.  Beispielsweise k√∂nnen Sie Testdaten aus MySQL- oder PostgreSQL-Datenbanken generieren oder Entwicklungsdatenbanken erstellen, die Ihren Produktionsdatenbanken √§hneln. <br><br> <code>clickhouse-obfuscator \ <br> --seed "$(head -c16 /dev/urandom | base64)" \ <br> --input-format TSV --output-format TSV \ <br> --structure 'CounterID UInt32, URLDomain String, \ <br> URL String, SearchPhrase String, Title String' \ <br> &lt; table.tsv &gt; result.tsv <br> <br> clickhouse-obfuscator --help <br></code> <br>  Nat√ºrlich ist nicht alles so geschnitten und getrocknet, weil die mit diesem Programm transformierten Daten fast vollst√§ndig umkehrbar sind.  Die Frage ist, ob es m√∂glich ist, die R√ºcktransformation durchzuf√ºhren, ohne den Schl√ºssel zu kennen.  Wenn f√ºr die Umwandlung ein kryptografischer Algorithmus verwendet w√ºrde, w√§re diese Operation so schwierig wie eine Brute-Force-Suche.  Obwohl bei der Transformation einige kryptografische Grundelemente verwendet werden, werden sie nicht korrekt verwendet, und die Daten k√∂nnen mit bestimmten Analysemethoden analysiert werden.  Um Probleme zu vermeiden, werden diese Probleme in der Dokumentation des Programms behandelt (greifen Sie mit <code>--help</code> ). <br><br>  Am Ende haben wir den Datensatz, den wir <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/metrica/">f√ºr die Funktions- und Leistungstests</a> ben√∂tigen <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/metrica/">,</a> und den von Yandex als Vizepr√§sident der Datenschutzbeh√∂rde genehmigten Ver√∂ffentlichung transformiert. <br><br>  <a href="">clickhouse-datasets.s3.yandex.net/hits/tsv/hits_v1.tsv.xz</a> <br>  <a href="">clickhouse-datasets.s3.yandex.net/visits/tsv/visits_v1.tsv.xz</a> <br><br>  Nicht-Yandex-Entwickler verwenden diese Daten f√ºr echte Leistungstests bei der Optimierung von Algorithmen in ClickHouse.  Drittanbieter k√∂nnen uns ihre verschleierten Daten zur Verf√ºgung stellen, damit wir ClickHouse f√ºr sie noch schneller machen k√∂nnen.  Dar√ºber hinaus haben wir einen unabh√§ngigen offenen Benchmark f√ºr Hardware- und Cloud-Anbieter ver√∂ffentlicht: <a href="https://clickhouse.yandex/benchmark_hardware.html">clickhouse.yandex/benchmark_hardware.html</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de485096/">https://habr.com/ru/post/de485096/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de485084/index.html">B√ºro Plankton - Evolution</a></li>
<li><a href="../de485088/index.html">Retrospektive Rechen. Wie sich herausstellte, dass eine selbst gemachte L√∂sung cooler als bezahlt war</a></li>
<li><a href="../de485090/index.html">Das Geheimnis der Effizienz ist der Qualit√§tscode, kein effektiver Manager</a></li>
<li><a href="../de485092/index.html">Validierung von Daten in iOS-Anwendungen</a></li>
<li><a href="../de485094/index.html">Microservices mit Spring Boot. Teil 3. Erstellen eines Mikrodienstes zur W√§hrungsumrechnung</a></li>
<li><a href="../de485100/index.html">Wohin: Die n√§chsten kostenlosen Veranstaltungen f√ºr Entwickler in Moskau (30. Januar - 15. Februar)</a></li>
<li><a href="../de485102/index.html">Topleaked: Ein Tool zum Auffinden von Speicherlecks</a></li>
<li><a href="../de485104/index.html">Erstellen eines universellen RFID-Schl√ºssels f√ºr Sprechanlagen</a></li>
<li><a href="../de485108/index.html">Statistik der zertifizierten PMI-Spezialisten in Russland am 10.01.2020</a></li>
<li><a href="../de485110/index.html">Meine Erfahrung mit effektiver Fernarbeit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
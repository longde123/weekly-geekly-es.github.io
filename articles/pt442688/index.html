<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõÄüèø üôÖüèª üë∏üèΩ An√°lise de dados Scala - uma necessidade urgente ou uma oportunidade agrad√°vel? üß† üë∑ ‚úåÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As ferramentas tradicionais no campo da ci√™ncia de dados s√£o linguagens como R e Python - sintaxe relaxada e um grande n√∫mero de bibliotecas para apre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>An√°lise de dados Scala - uma necessidade urgente ou uma oportunidade agrad√°vel?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/442688/"><p><img src="https://habrastorage.org/webt/5q/1e/fr/5q1efrbkxbuk_ndqoensinfl80a.jpeg"></p><br><p>  As ferramentas tradicionais no campo da ci√™ncia de dados s√£o linguagens como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">R</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Python</a> - sintaxe relaxada e um grande n√∫mero de bibliotecas para aprendizado de m√°quina e processamento de dados permitem obter rapidamente algumas solu√ß√µes de trabalho.  No entanto, h√° situa√ß√µes em que as limita√ß√µes dessas ferramentas se tornam um obst√°culo significativo - primeiro, se voc√™ precisar obter alto desempenho em termos de velocidade de processamento e / ou trabalhar com conjuntos de dados realmente grandes.  Nesse caso, o especialista precisa recorrer com relut√¢ncia √† ajuda do "lado negro" e conectar ferramentas nas linguagens de programa√ß√£o "industriais": <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scala</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Java</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C ++</a> . </p><br><p> Mas esse lado √© t√£o escuro?  Ao longo dos anos de desenvolvimento, as ferramentas da ci√™ncia de dados "industrial" percorreram um longo caminho e hoje s√£o bastante diferentes de suas pr√≥prias vers√µes h√° 2-3 anos.  Vamos tentar usar o exemplo da tarefa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SNA Hackathon 2019</a> para descobrir o quanto o ecossistema Scala + Spark pode corresponder √† Python Data Science. </p><a name="habracut"></a><br><p>  No √¢mbito do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SNA Hackathon 2019, os</a> participantes resolvem o problema de classificar o feed de not√≠cias de um usu√°rio de uma rede social em uma das tr√™s "disciplinas": usando dados de textos, imagens ou registros de recursos.  Nesta publica√ß√£o, veremos como no Spark √© poss√≠vel resolver um problema com base em um log de sinais usando ferramentas cl√°ssicas de aprendizado de m√°quina. </p><br><p>  Na solu√ß√£o do problema, seguiremos o caminho padr√£o que qualquer especialista em an√°lise de dados seguir√° ao desenvolver um modelo: </p><br><ul><li>  Iremos realizar an√°lises de dados de pesquisa, construir gr√°ficos. </li><li>  Analisamos as propriedades estat√≠sticas dos sinais nos dados, observamos suas diferen√ßas entre os conjuntos de treinamento e teste. </li><li>  Conduziremos uma sele√ß√£o inicial de recursos com base nas propriedades estat√≠sticas. </li><li>  Calculamos as correla√ß√µes entre os sinais e a vari√°vel alvo, bem como a correla√ß√£o cruzada entre os sinais. </li><li>  Vamos formar o conjunto final de recursos, treinar o modelo e verificar sua qualidade. </li><li>  Vamos analisar a estrutura interna do modelo para identificar pontos de crescimento. </li></ul><br><p>  Durante nossa "jornada", conheceremos ferramentas como o notebook interativo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zeppelin</a> , a biblioteca de aprendizado de m√°quina <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Spark ML</a> e sua extens√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> , o pacote de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gr√°ficos</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GraphX</a> , a biblioteca de visualiza√ß√£o de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vegas</a> e, √© claro, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Spark</a> em toda a sua gl√≥ria: )  Todos os resultados de c√≥digo e experimento est√£o dispon√≠veis na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">plataforma de</a> notebook colaborativo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zepl</a> . </p><br><h1 id="zagruzka-dannyh">  Carregamento de dados </h1><br><p>  A peculiaridade dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dados</a> apresentados no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SNA Hackathon 2019</a> √© que √© poss√≠vel process√°-los diretamente usando Python, mas √© dif√≠cil: os dados originais s√£o compactados de maneira bastante eficiente, gra√ßas aos recursos do formato de coluna Apache Parquet e ao ler na mem√≥ria "pela testa", s√£o descompactados em v√°rias dezenas de gigabytes.  Ao trabalhar com o Apache Spark, n√£o h√° necessidade de carregar completamente os dados na mem√≥ria, a arquitetura Spark foi projetada para processar dados em partes, carregando do disco conforme necess√°rio. </p><br><p>  Portanto, a primeira etapa - verificar a distribui√ß√£o dos dados por dia - √© facilmente executada por ferramentas in a box: </p><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = sqlContext.read.parquet(<span class="hljs-string"><span class="hljs-string">"/events/hackatons/SNAHackathon/2019/collabTrain"</span></span>) z.show(train.groupBy($<span class="hljs-string"><span class="hljs-string">"date"</span></span>).agg( functions.count($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"count"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"users"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"objects"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"metadata_ownerId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"owners"</span></span>)) .orderBy(<span class="hljs-string"><span class="hljs-string">"date"</span></span>))</code> </pre> <br><p>  O que o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gr√°fico</a> correspondente exibir√° no Zeppelin: </p><br><p><img src="https://habrastorage.org/webt/jp/lh/pw/jplhpwwz4tfgdtrs1u_u-tqsvzi.png"></p><br><p>  Devo dizer que a sintaxe do Scala √© bastante flex√≠vel, e o mesmo c√≥digo pode parecer, por exemplo, assim: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = sqlContext.read.parquet(<span class="hljs-string"><span class="hljs-string">"/events/hackatons/SNAHackathon/2019/collabTrain"</span></span>) z.show( train groupBy $<span class="hljs-string"><span class="hljs-string">"date"</span></span> agg( count($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"count"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"users"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"objects"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"metadata_ownerId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"owners"</span></span>) orderBy <span class="hljs-string"><span class="hljs-string">"date"</span></span> )</code> </pre> <br><p>  Um aviso importante deve ser feito aqui: ao trabalhar em uma equipe grande, onde todos abordam a escrita do c√≥digo Scala exclusivamente do ponto de vista de seu pr√≥prio gosto, a comunica√ß√£o √© muito mais dif√≠cil.  Portanto, √© melhor desenvolver um conceito unificado de estilo de c√≥digo. </p><br><p>  Mas voltando √† nossa tarefa.  Uma an√°lise simples por dia mostrou a presen√ßa de pontos anormais nos dias 17 e 18 de fevereiro;  provavelmente hoje em dia foram coletados dados incompletos e a distribui√ß√£o de caracter√≠sticas pode ser tendenciosa.  Isso deve ser levado em considera√ß√£o em an√°lises posteriores.  Al√©m disso, √© impressionante que o n√∫mero de usu√°rios √∫nicos esteja muito pr√≥ximo do n√∫mero de objetos; portanto, faz sentido estudar a distribui√ß√£o de usu√°rios com diferentes n√∫meros de objetos: </p><br><pre> <code class="scala hljs">z.show(filteredTrain .groupBy($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).count .groupBy(<span class="hljs-string"><span class="hljs-string">"count"</span></span>).agg(functions.log(functions.count(<span class="hljs-string"><span class="hljs-string">"count"</span></span>)).as(<span class="hljs-string"><span class="hljs-string">"withCount"</span></span>)) .orderBy($<span class="hljs-string"><span class="hljs-string">"withCount"</span></span>.desc) .limit(<span class="hljs-number"><span class="hljs-number">100</span></span>) .orderBy($<span class="hljs-string"><span class="hljs-string">"count"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/dh/i-/pp/dhi-ppdka19zurhimccpq7tij5w.png"></p><br><p>  Espera-se ver uma distribui√ß√£o pr√≥xima ao exponencial, com uma cauda muito longa.  Em tais tarefas, como regra, √© poss√≠vel obter uma melhoria na qualidade do trabalho, segmentando modelos para usu√°rios com diferentes n√≠veis de atividade.  Para verificar se vale a pena fazer isso, compare a distribui√ß√£o do n√∫mero de objetos por usu√°rio no conjunto de testes: </p><br><p><img src="https://habrastorage.org/webt/du/sy/xt/dusyxten5shm24an736n7akolnm.png"></p><br><p>  A compara√ß√£o com o teste mostra que os usu√°rios do teste t√™m pelo menos dois objetos nos logs (como o problema de classifica√ß√£o foi resolvido no hackathon, essa √© uma condi√ß√£o necess√°ria para avaliar a qualidade).  No futuro, recomendo examinar mais de perto os usu√°rios no conjunto de treinamento, para os quais declaramos Fun√ß√£o Definida pelo Usu√°rio com um filtro: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//  ,     "",   , //     val testSimilar = sc.broadcast(filteredTrain.groupBy($"instanceId_userId") .agg( functions.count("feedback").as("count"), functions.sum(functions.expr("IF(array_contains(feedback, 'Liked'), 1.0, 0.0)")).as("sum") ) .where("count &gt; sum AND sum &gt; 0") .select("instanceId_userId").rdd.map(_.getInt(0)).collect.sorted) //           // User Defined Function val isTestSimilar = sqlContext.udf.register("isTestSimilar", (x: Int) =&gt; java.util.Arrays.binarySearch(testSimilar.value, x) &gt;= 0)</span></span></code> </pre> <br><p>  Uma observa√ß√£o importante tamb√©m deve ser feita aqui: √© do ponto de vista da defini√ß√£o de UDF que o uso do Spark no Scala / Java e no Python √© muito diferente.  Enquanto o c√≥digo PySpark usa a funcionalidade b√°sica, tudo funciona quase t√£o r√°pido, mas quando as fun√ß√µes substitu√≠das aparecem, o desempenho do PySpark diminui por uma ordem de magnitude. </p><br><h1 id="pervyy-ml-konveyer">  O primeiro pipeline de ML </h1><br><p>  Na pr√≥xima etapa, tentaremos calcular as estat√≠sticas b√°sicas de a√ß√µes e atributos.  Mas, para isso, precisamos dos recursos do SparkML; primeiro, veremos sua arquitetura geral: </p><br><p><img src="https://habrastorage.org/webt/j7/ev/en/j7evenhyzzfvzouqfkbfq1j9hvu.png"></p><br><p>  O SparkML √© constru√≠do com base nos seguintes conceitos: </p><br><ul><li>  Transformador - pega um conjunto de dados como entrada e retorna um conjunto modificado (transforma√ß√£o).  Como regra, ele √© usado para implementar algoritmos de pr√© e p√≥s-processamento, extra√ß√£o de recursos e tamb√©m pode representar os modelos de ML resultantes. </li><li>  Estimador - pega um conjunto de dados como entrada e retorna o transformador (em forma).  Naturalmente, o Estimator pode representar o algoritmo ML. </li><li>  Pipeline √© um caso especial do Estimator, que consiste em uma cadeia de transformadores e estimadores.  Quando o m√©todo √© chamado, o ajuste passa pela cadeia e, se ele v√™ um transformador, aplica-o aos dados e, se v√™ um estimador, treina o transformador com ele, aplica-o aos dados e vai al√©m. </li><li>  PipelineModel - o resultado do Pipeline tamb√©m cont√©m uma cadeia interna, mas composta exclusivamente por transformadores.  Por conseguinte, o pr√≥prio PipelineModel tamb√©m √© um transformador. </li></ul><br><p>  Essa abordagem para a forma√ß√£o de algoritmos ML ajuda a obter uma estrutura modular clara e boa reprodutibilidade - tanto modelos quanto pipelines podem ser salvos. </p><br><p>  Para come√ßar, criaremos um pipeline simples com o qual calcularemos as estat√≠sticas da distribui√ß√£o de a√ß√µes (campo de feedback) dos usu√°rios no conjunto de treinamento: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> feedbackAggregator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-comment"><span class="hljs-comment">//         (feedback)  one-hot  new MultinominalExtractor().setInputCol("feedback").setOutputCol("feedback"), //       new VectorStatCollector() .setGroupByColumns("date").setInputCol("feedback") .setPercentiles(Array(0.1,0.5,0.9)), //        new VectorExplode().setValueCol("feedback") )).fit(train) z.show(feedbackAggregator .transform(filteredTrain) .orderBy($"date", $"feedback"))</span></span></code> </pre> <br><p>  Nesse pipeline, a funcionalidade do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> √© usada ativamente - bibliotecas com blocos √∫teis estendidos para o SparkML, a saber: </p><br><ul><li>  MultinominalExtractor √© usado para codificar um caractere do tipo "array of strings" em um vetor, de acordo com o princ√≠pio one-hot.  Este √© o √∫nico estimador no pipeline (para criar uma codifica√ß√£o, voc√™ deve coletar linhas exclusivas do conjunto de dados). </li><li>  VectorStatCollector √© usado para calcular estat√≠sticas de vetores. </li><li>  VectorExplode √© usado para converter o resultado em um formato conveniente para visualiza√ß√£o. </li></ul><br><p>  O resultado do trabalho ser√° um gr√°fico mostrando que as classes no conjunto de dados n√£o s√£o balanceadas, no entanto, o desequil√≠brio para a classe Liked de destino n√£o √© extremo: </p><br><p><img src="https://habrastorage.org/webt/aa/db/x4/aadbx4el5s5lhuyput_cj4ns9zo.png"></p><br><p>  A an√°lise de uma distribui√ß√£o semelhante entre usu√°rios semelhantes aos de teste (com "positivo" e "negativo" nos logs) mostra que ela √© enviesada para a classe positiva: </p><br><p><img src="https://habrastorage.org/webt/x5/lu/px/x5lupxmayvvodo7lsb3meob1dou.png"></p><br><h1 id="statisticheskiy-analiz-priznakov">  An√°lise estat√≠stica de sinais </h1><br><p>  Na pr√≥xima etapa, realizaremos uma an√°lise detalhada das propriedades estat√≠sticas dos atributos.  Desta vez, precisamos de um transportador maior: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> statsAggregator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-comment"><span class="hljs-comment">//          new AutoAssembler() .setColumnsToExclude( (Seq("date", "feedback") ++ train.schema.fieldNames.filter(_.endsWith("Id")) : _*)) .setOutputCol("features"), new VectorStatCollector() .setGroupByColumns("date").setInputCol("features") .setPercentiles(Array(0.1,0.5,0.9)), new VectorExplode().setValueCol("features") ))</span></span></code> </pre> <br><p>  Como agora precisamos trabalhar n√£o com um campo separado, mas com todos os atributos de uma s√≥ vez, usaremos mais dois utilit√°rios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> √∫teis: </p><br><ul><li>  NullToDefaultReplacer permite substituir elementos ausentes nos dados por seus valores padr√£o (0 para n√∫meros, falso para vari√°veis ‚Äã‚Äãl√≥gicas etc.).  Se voc√™ n√£o fizer essa convers√£o, os valores de NaN aparecer√£o nos vetores resultantes, o que √© fatal para muitos algoritmos (embora, por exemplo, o XGBoost possa sobreviver a isso).  Uma alternativa para substituir por zeros pode ser substituir por m√©dias, isso √© implementado no NaNToMeanReplacerEstimator. </li><li>  O AutoAssembler √© um utilit√°rio muito poderoso que analisa o layout da tabela e, para cada coluna, seleciona um esquema de vetoriza√ß√£o que corresponde ao tipo de coluna. </li></ul><br><p>  Usando o pipeline resultante, calculamos as estat√≠sticas para tr√™s conjuntos (treinamento, treinamento com filtro e teste do usu√°rio) e salvamos em arquivos separados: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//   (   AutoAssembler  ) val trained = statsAggregator.fit(filteredTrain) //       - ,     . trained .transform(filteredTrain .withColumn("date", //  ,      ,     , //        All   functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(7).write.mode("overwrite").parquet("sna2019/featuresStat") trained .transform(filteredTrain .where(isTestSimilar($"instanceId_userId")) .withColumn("date", functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(7).write.mode("overwrite").parquet("sna2019/filteredFeaturesStat") trained .transform(filteredTest.withColumn("date", functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(3).write.mode("overwrite").parquet("sna2019/testFeaturesStat")</span></span></code> </pre> <br><p>  Ap√≥s receber tr√™s conjuntos de dados com estat√≠sticas de atributos, analisamos o seguinte: </p><br><ul><li>  Temos sinais para os quais existem grandes emiss√µes? <br>  - Esses sinais devem ser limitados ou os registros externos devem ser filtrados. </li><li>  Temos sinais com um grande vi√©s da m√©dia em rela√ß√£o √† mediana. <br>  - Essa mudan√ßa geralmente ocorre na presen√ßa de uma distribui√ß√£o de energia; faz sentido logaritmo esses sinais. </li><li>  H√° uma mudan√ßa nas distribui√ß√µes m√©dias entre os conjuntos de treinamento e teste. </li><li>  Qu√£o bem preenchida nossa matriz de recursos. </li></ul><br><p>  Para esclarecer esses aspectos, essa solicita√ß√£o nos ajudar√°: </p><br><pre> <code class="scala hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compareWithTest</span></span></span></span>(data: <span class="hljs-type"><span class="hljs-type">DataFrame</span></span>) : <span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = { data.where(<span class="hljs-string"><span class="hljs-string">"date = 'All'"</span></span>) .select( $<span class="hljs-string"><span class="hljs-string">"features"</span></span>, <span class="hljs-comment"><span class="hljs-comment">//         // ( ) functions.log($"features_mean" / $"features_p50").as("skewenes"), //    90-      //    90-  ‚Äî    functions.log( ($"features_max" - $"features_p90") / ($"features_p90" - $"features_p50")).as("outlieres"), //       ,  //    ($"features_nonZeros" / $"features_count").as("train_fill"), $"features_mean".as("train_mean")) .join(testStat.where("date = 'All'") .select($"features", $"features_mean".as("test_mean"), ($"features_nonZeros" / $"features_count").as("test_fill")), Seq("features")) //          .withColumn("meanDrift", (($"train_mean" - $"test_mean" ) / ($"train_mean" + $"test_mean"))) //      .withColumn("fillDrift", ($"train_fill" - $"test_fill") / ($"train_fill" + $"test_fill")) } //         val comparison = compareWithTest(trainStat).withColumn("mode", functions.lit("raw")) .unionByName(compareWithTest(filteredStat).withColumn("mode", functions.lit("filtered")))</span></span></code> </pre> <br><p>  Nesse est√°gio, a quest√£o da visualiza√ß√£o √© urgente: √© dif√≠cil exibir todos os aspectos imediatamente usando as ferramentas regulares do Zeppelin, e os notebooks com um grande n√∫mero de gr√°ficos come√ßam a ficar visivelmente mais lentos devido ao DOM inchado.  A biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vegas</a> - DSL no Scala para criar especifica√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vega-lite</a> pode resolver esse problema.  Vegas n√£o apenas fornece recursos de visualiza√ß√£o mais avan√ßados (compar√°veis ‚Äã‚Äãao matplotlib), mas tamb√©m os desenha no Canvas sem inflar o DOM :). </p><br><p>  A especifica√ß√£o do gr√°fico em que estamos interessados ‚Äã‚Äãficar√° assim: </p><br><pre> <code class="scala hljs">vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>(width = <span class="hljs-number"><span class="hljs-number">1024</span></span>, height = <span class="hljs-number"><span class="hljs-number">648</span></span>) <span class="hljs-comment"><span class="hljs-comment">//   .withDataFrame(comparison.na.fill(0.0)) //           .encodeX("meanDrift", Quant, scale = Scale(domainValues = List(-1.0, 1.0), clamp = true)) //   -       .encodeY("train_fill", Quant) //       .encodeColor("outlieres", Quant, scale=Scale( rangeNominals=List("#00FF00", "#FF0000"), domainValues = List(0.0, 5), clamp = true)) //       .encodeSize("skewenes", Quant) //   -   (   ) .encodeShape("mode", Nom) .mark(vegas.Point) .show</span></span></code> </pre> <br><p>  O gr√°fico abaixo deve ser assim: </p><br><ul><li>  O eixo X mostra o deslocamento dos centros de distribui√ß√£o entre os conjuntos de teste e treinamento (quanto mais pr√≥ximo de 0, mais est√°vel o sinal). </li><li>  A porcentagem de elementos diferentes de zero √© plotada ao longo do eixo Y (quanto maior, mais dados existem para o maior n√∫mero de pontos por atributo). </li><li>  O tamanho mostra a mudan√ßa da m√©dia em rela√ß√£o √† mediana (quanto maior o ponto, maior a distribui√ß√£o da lei de energia para ele). </li><li>  Cor indica emiss√µes (quanto mais vermelho, mais emiss√µes). </li><li>  Bem, o formul√°rio √© diferenciado por um modo de compara√ß√£o: com um filtro de usu√°rio no conjunto de treinamento ou sem filtro. </li></ul><br><p><img src="https://habrastorage.org/webt/op/hb/6g/ophb6gi3wa_uvsld9rre6ujzquu.png"></p><br><p>  Assim, podemos tirar as seguintes conclus√µes: </p><br><ul><li>  Alguns sinais precisam de um filtro de emiss√£o - limitaremos os valores m√°ximos para o 90¬∫ percentil. </li><li>  Alguns sinais mostram uma distribui√ß√£o pr√≥xima da exponencial - vamos usar o logaritmo. </li><li>  Alguns recursos n√£o s√£o apresentados no teste - vamos exclu√≠-los do treinamento. </li></ul><br><h1 id="korrelyacionnyy-analiz">  An√°lise de correla√ß√£o </h1><br><p>  Depois de ter uma id√©ia geral de como os atributos s√£o distribu√≠dos e como eles se relacionam entre os conjuntos de treinamento e teste, vamos tentar analisar as correla√ß√µes.  Para fazer isso, configure o extrator de recursos com base em observa√ß√µes anteriores: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//             val expressions = filteredTrain.schema.fieldNames //          .filterNot(x =&gt; x == "date" || x == "audit_experiment" || idsColumns(x) || x.contains("vd_")) .map(x =&gt; if(skewedFeautres(x)) { //      s"log($x) AS $x" } else { //     cappedFeatures.get(x).map(capping =&gt; s"IF($x &lt; $capping, $x, $capping) AS $x").getOrElse(x) }) val rawFeaturesExtractor = new Pipeline().setStages(Array( new SQLTransformer().setStatement(s"SELECT ${expressions.mkString(", ")} FROM __THIS__"), new NullToDefaultReplacer(), new AutoAssembler().setOutputCol("features") )) //       val raw = rawFeaturesExtractor.fit(filteredTrain).transform( filteredTrain.where(isTestSimilar($"instanceId_userId")))</span></span></code> </pre> <br><p>  Das novas m√°quinas desse pipeline, o utilit√°rio SQLTransformer atrai a aten√ß√£o, o que permite transforma√ß√µes arbitr√°rias de SQL da tabela de entrada. </p><br><p>  Ao analisar as correla√ß√µes, √© importante filtrar o ru√≠do criado pela correla√ß√£o natural dos recursos one-hot.  Para fazer isso, eu gostaria de entender quais elementos do vetor correspondem a quais colunas de origem.  Esta tarefa no Spark √© realizada usando metadados da coluna (armazenados com dados) e grupos de atributos.  O seguinte bloco de c√≥digo √© usado para filtrar pares de nomes de atributos provenientes da mesma coluna do tipo String: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> attributes = <span class="hljs-type"><span class="hljs-type">AttributeGroup</span></span>.fromStructField(raw.schema(<span class="hljs-string"><span class="hljs-string">"features"</span></span>)).attributes.get <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> originMap = filteredTrain .schema.filter(_.dataType == <span class="hljs-type"><span class="hljs-type">StringType</span></span>) .flatMap(x =&gt; attributes.map(_.name.get).filter(_.startsWith(x.name + <span class="hljs-string"><span class="hljs-string">"_"</span></span>)).map(_ -&gt; x.name)) .toMap <span class="hljs-comment"><span class="hljs-comment">//   ,          val isNonTrivialCorrelation = sqlContext.udf.register("isNonTrivialCorrelation", (x: String, y : String) =&gt; //    Scala-quiz   Option originMap.get(x).map(_ != originMap.getOrElse(y, "")).getOrElse(true))</span></span></code> </pre> <br><p>  Tendo em m√£os um conjunto de dados com uma coluna de vetor, o c√°lculo de correla√ß√µes cruzadas usando o Spark √© bastante simples, mas o resultado √© uma matriz, cuja implanta√ß√£o voc√™ precisar√° reproduzir um pouco em um conjunto de pares: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> pearsonCorrelation = <span class="hljs-comment"><span class="hljs-comment">//    Pearson  Spearman Correlation.corr(raw, "features", "pearson").rdd.flatMap( //           _.getAs[Matrix](0).rowIter.zipWithIndex.flatMap(x =&gt; { //   ,   (  , //  ) val name = attributes(x._2).name.get //    ,     x._1.toArray.zip(attributes).map(y =&gt; (name, y._2.name.get, y._1)) } //     DataFrame )).toDF("feature1", "feature2", "corr") .na.drop //   .where(isNonTrivialCorrelation($"feature1", $"feature2")) //    . pearsonCorrelation.coalesce(1).write.mode("overwrite") .parquet("sna2019/pearsonCorrelation")</span></span></code> </pre> <br><p>  E, √© claro, visualiza√ß√£o: precisaremos novamente da ajuda de Vegas para desenhar um mapa de calor: </p><br><pre> <code class="scala hljs">vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>(<span class="hljs-string"><span class="hljs-string">"Pearson correlation heatmap"</span></span>) .withDataFrame(pearsonCorrelation .withColumn(<span class="hljs-string"><span class="hljs-string">"isPositive"</span></span>, $<span class="hljs-string"><span class="hljs-string">"corr"</span></span> &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) .withColumn(<span class="hljs-string"><span class="hljs-string">"abs_corr"</span></span>, functions.abs($<span class="hljs-string"><span class="hljs-string">"corr"</span></span>)) .where(<span class="hljs-string"><span class="hljs-string">"feature1 &lt; feature2 AND abs_corr &gt; 0.05"</span></span>) .orderBy(<span class="hljs-string"><span class="hljs-string">"feature1"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature2"</span></span>)) .encodeX(<span class="hljs-string"><span class="hljs-string">"feature1"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .encodeY(<span class="hljs-string"><span class="hljs-string">"feature2"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .encodeColor(<span class="hljs-string"><span class="hljs-string">"abs_corr"</span></span>, <span class="hljs-type"><span class="hljs-type">Quant</span></span>, scale=<span class="hljs-type"><span class="hljs-type">Scale</span></span>(rangeNominals=<span class="hljs-type"><span class="hljs-type">List</span></span>(<span class="hljs-string"><span class="hljs-string">"#FFFFFF"</span></span>, <span class="hljs-string"><span class="hljs-string">"#FF0000"</span></span>))) .encodeShape(<span class="hljs-string"><span class="hljs-string">"isPositive"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .mark(vegas.<span class="hljs-type"><span class="hljs-type">Point</span></span>) .show</code> </pre> <br><p>  O resultado √© melhor procurar no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zepl-e</a> .  Para uma compreens√£o geral: </p><br><p><img src="https://habrastorage.org/webt/nm/d9/bm/nmd9bmrion4goaov9_vgx5vbjoy.png"></p><br><p>  O mapa de calor mostra que algumas correla√ß√µes est√£o claramente l√°.  Vamos tentar selecionar os blocos dos recursos mais fortemente correlacionados, para isso usamos a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GraphX</a> : transformamos a matriz de correla√ß√£o em um gr√°fico, filtramos as arestas por peso, ap√≥s o qual encontramos os componentes conectados e deixamos apenas os n√£o degenerados (de mais de um elemento).  Esse procedimento √© essencialmente semelhante √† aplica√ß√£o do algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DBSCAN</a> e √© o seguinte: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//   (GrpahX   ID) val featureIndexMap = spearmanCorrelation.select("feature1").distinct.rdd.map( _.getString(0)).collect.zipWithIndex.toMap val featureIndex = sqlContext.udf.register("featureIndex", (x: String) =&gt; featureIndexMap(x)) //    val vertices = sc.parallelize(featureIndexMap.map(x =&gt; x._2.toLong -&gt; x._1).toSeq, 1) //    val edges = spearmanCorrelation.select(featureIndex($"feature1"), featureIndex($"feature2"), $"corr") //     .where("ABS(corr) &gt; 0.7") .rdd.map(r =&gt; Edge(r.getInt(0), r.getInt(1), r.getDouble(2))) //       val components = Graph(vertices, edges).connectedComponents() val reversedMap = featureIndexMap.map(_.swap) //    ,    ,   //   val clusters = components .vertices.map(x =&gt; reversedMap(x._2.toInt) -&gt; reversedMap(x._1.toInt)) .groupByKey().map(x =&gt; x._2.toSeq) .filter(_.size &gt; 1) .sortBy(-_.size) .collect</span></span></code> </pre> <br><p>  O resultado √© apresentado na forma de uma tabela: </p><br><p><img src="https://habrastorage.org/webt/4b/t2/bl/4bt2blcjzmxbzucnm7zynpvpj-q.png"></p><br><p>  Com base nos resultados do clustering, podemos concluir que os grupos mais correlacionados se formaram em torno de sinais associados √† associa√ß√£o de usu√°rios no grupo (Membership_status_A), bem como em torno do tipo de objeto (instanceId_objectType).  Para a melhor modelagem da intera√ß√£o de sinais, faz sentido aplicar a segmenta√ß√£o de modelos - treinar modelos diferentes para diferentes tipos de objetos, separadamente para grupos nos quais o usu√°rio est√° e n√£o est√°. </p><br><h1 id="mashinnoe-obuchenie">  Aprendizado de m√°quina </h1><br><p>  Abordamos a coisa mais interessante - aprendizado de m√°quina.  O pipeline para treinar o modelo mais simples (regress√£o log√≠stica) usando as extens√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SparkML</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> √© o seguinte: </p><br><pre> <code class="scala hljs"> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement( <span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-type"><span class="hljs-type">Scaler</span></span>.scale(<span class="hljs-type"><span class="hljs-type">Interceptor</span></span>.intercept(<span class="hljs-type"><span class="hljs-type">UnwrappedStage</span></span>.repartition( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LogisticRegressionLBFSG</span></span>(), numPartitions = <span class="hljs-number"><span class="hljs-number">127</span></span>)))</code> </pre> <br><p>  Aqui vemos n√£o apenas muitos elementos familiares, mas tamb√©m v√°rios novos: </p><br><ul><li>  LogisticRegressionLBFSG √© um estimador com treinamento distribu√≠do de regress√£o log√≠stica. </li><li>  Para obter o desempenho m√°ximo dos algoritmos ML distribu√≠dos.  os dados devem ser idealmente distribu√≠dos entre parti√ß√µes.  O utilit√°rio UnwrappedStage.repartition ajudar√° nisso, adicionando uma opera√ß√£o de reparti√ß√£o ao pipeline para que seja usada apenas no est√°gio de treinamento (afinal, ao criar previs√µes, n√£o √© mais necess√°rio). </li><li>  Para que o modelo linear possa dar um bom resultado.  os dados devem ser dimensionados, pelos quais o utilit√°rio Scaler.scale √© respons√°vel.  No entanto, a presen√ßa de duas transforma√ß√µes lineares consecutivas (escala e multiplica√ß√£o pelos pesos de regress√£o) leva a gastos desnecess√°rios, e √© desej√°vel recolher essas opera√ß√µes.  Ao usar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML,</a> a sa√≠da ser√° um modelo limpo com uma transforma√ß√£o :). </li><li>  Bem, √© claro, para esses modelos, voc√™ precisa de um membro gratuito, que adicionamos usando a opera√ß√£o Interceptor.intercept. </li></ul><br><p>  O pipeline resultante, aplicado a todos os dados, fornece AUC por usu√°rio 0,6889 (o c√≥digo de valida√ß√£o est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zepl</a> ).  Agora resta aplicar toda a nossa pesquisa: filtrar dados, transformar recursos e modelos de segmento.  O pipeline final ficar√° assim: </p><br><pre> <code class="scala hljs"> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">s"SELECT instanceId_userId, instanceId_objectId, </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${expressions.mkString(", ")}</span></span></span><span class="hljs-string"> FROM __THIS__"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label, concat(IF(membership_status = 'A', 'OwnGroup_', 'NonUser_'), instanceId_objectType) AS type FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>, <span class="hljs-string"><span class="hljs-string">"type"</span></span>,<span class="hljs-string"><span class="hljs-string">"instanceId_objectType"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-type"><span class="hljs-type">CombinedModel</span></span>.perType( <span class="hljs-type"><span class="hljs-type">Scaler</span></span>.scale(<span class="hljs-type"><span class="hljs-type">Interceptor</span></span>.intercept(<span class="hljs-type"><span class="hljs-type">UnwrappedStage</span></span>.repartition( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LogisticRegressionLBFSG</span></span>(), numPartitions = <span class="hljs-number"><span class="hljs-number">127</span></span>))), numThreads = <span class="hljs-number"><span class="hljs-number">6</span></span>) ))</code> </pre> <br><p>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> ‚Äî    CombinedModel.perType.       ,     numThreads = 6.             . </p><br><p> ,   ,  per-user AUC 0.7004.    ?  ,   " "    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">XGBoost</a> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">XGBoostRegressor</span></span>() .setNumRounds(<span class="hljs-number"><span class="hljs-number">100</span></span>) .setMaxDepth(<span class="hljs-number"><span class="hljs-number">15</span></span>) .setObjective(<span class="hljs-string"><span class="hljs-string">"reg:logistic"</span></span>) .setNumWorkers(<span class="hljs-number"><span class="hljs-number">17</span></span>) .setNthread(<span class="hljs-number"><span class="hljs-number">4</span></span>) .setTrackerConf(<span class="hljs-number"><span class="hljs-number">600000</span></span>L, <span class="hljs-string"><span class="hljs-string">"scala"</span></span>) ))</code> </pre> <br><p> ,     ‚Äî XGBoost  Spark !         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DLMC</a> ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> ,       (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> ).  XGboost " "   10     per-user AUC 0.6981. </p><br><h1 id="analiz-rezultatov">   </h1><br><p> ,     ,  ,       .    SparkML     ,      .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a>  :      Parquet            Spark: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//     val perTypeWeights = sqlContext.read.parquet("sna2019/perType/stages/*/weights") //     20    ( //  ) val topFeatures = new TopKTransformer[Double]() .setGroupByColumns("type") .setColumnToOrderGroupsBy("abs_weight") .setTopK(20) .transform(perTypeWeights.withColumn("abs_weight", functions.abs($"unscaled_weight"))) .orderBy("type", "unscaled_weight")</span></span></code> </pre> <br><p>     Parquet,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PravdaML</a> ‚Äî TopKTransformer,           . </p><br><p>      Vegas (   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zepl</a> ): </p><br><p><img src="https://habrastorage.org/webt/q7/_n/fn/q7_nfnto-hw-9nbdgjf3chhm0oc.png"></p><br><p> ,    -   .      XGBoost? </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> significance = sqlContext.read.parquet( <span class="hljs-string"><span class="hljs-string">"sna2019/xgBoost15_100_raw/stages/*/featuresSignificance"</span></span> vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>() .withDataFrame(significance.na.drop.orderBy($<span class="hljs-string"><span class="hljs-string">"significance"</span></span>.desc).limit(<span class="hljs-number"><span class="hljs-number">40</span></span>)) .encodeX(<span class="hljs-string"><span class="hljs-string">"name"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>, sortField = <span class="hljs-type"><span class="hljs-type">Sort</span></span>(<span class="hljs-string"><span class="hljs-string">"significance"</span></span>, <span class="hljs-type"><span class="hljs-type">AggOps</span></span>.<span class="hljs-type"><span class="hljs-type">Mean</span></span>)) .encodeY(<span class="hljs-string"><span class="hljs-string">"significance"</span></span>, <span class="hljs-type"><span class="hljs-type">Quant</span></span>) .mark(vegas.<span class="hljs-type"><span class="hljs-type">Bar</span></span>) .show</code> </pre> <br><p><img src="https://habrastorage.org/webt/i2/oy/zb/i2oyzbrjlo15x7u1uwadmeswocq.png"></p><br><p>  ,   ,   XGBoost,         ,    .           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .   ,  XGBoost     ,    ,   . </p><br><h1 id="vyvody">  Conclus√µes </h1><br><p>  ,       :).     : </p><br><ol><li>    ,     Scala  Spark    ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> . </li><li>    Scala  Spark        Python:    ETL  ML,    ,      ,     . </li><li>  ,   ,   ,    (,  )    ,     ,      . </li><li> ,     ,       .          ,      ,     , -, . </li></ol><br><p> ,       ,    ,        ,    -.        , ,  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">   Scala</a> "  Newprolab. </p><br><p> ,  ,      ‚Äî   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SNA Hackathon 2019</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt442688/">https://habr.com/ru/post/pt442688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt442678/index.html">Maior projeto em litografia est√©reo: esqueleto gigantesco impresso em uma impressora 3D</a></li>
<li><a href="../pt442680/index.html">As tecnologias de substitui√ß√£o sensorial permitir√£o ver o mundo com a ajuda dos sons: como funciona a neuroplasticidade do c√©rebro humano</a></li>
<li><a href="../pt442682/index.html">O que digitar e como montar um projeto C ++</a></li>
<li><a href="../pt442684/index.html">Desempenho equilibrado do site. Parte 3: Conte√∫do</a></li>
<li><a href="../pt442686/index.html">Tutorial do DataPower</a></li>
<li><a href="../pt442690/index.html">Miss√£o lunar "Bereshit" - selfie no fundo da Terra</a></li>
<li><a href="../pt442692/index.html">Blockchain sem intermedi√°rios: como enviamos t√≠tulos para um registro distribu√≠do</a></li>
<li><a href="../pt442694/index.html">Um dos gigantes do streaming lan√ßado na √çndia e atraiu um milh√£o de usu√°rios em uma semana</a></li>
<li><a href="../pt442696/index.html">S for Security: seguran√ßa das coisas na Internet e relat√≥rios no InoThings ++ 2019</a></li>
<li><a href="../pt442698/index.html">Aplicativo de metr√¥ de Moscou para a Windows Store</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
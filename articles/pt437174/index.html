<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§Ωüèø üå≠ üåã .NET, TensorFlow e os moinhos de vento de Kaggle - a jornada come√ßa üë®‚Äçüë®‚Äçüëß ü§¶üèø ü§∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta √© uma s√©rie de artigos sobre minha jornada em andamento na floresta escura das competi√ß√µes do Kaggle como desenvolvedor .NET. 

 Estarei focando ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>.NET, TensorFlow e os moinhos de vento de Kaggle - a jornada come√ßa</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437174/"><img src="https://habrastorage.org/webt/tc/fj/ml/tcfjml8-rk618mttrw9qhvfan_u.png" align="left">  Esta √© uma s√©rie de artigos sobre minha jornada em andamento na floresta escura das competi√ß√µes do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" title="Kaggle">Kaggle</a> como desenvolvedor .NET. <br><br>  Estarei focando em (quase) redes neurais puras neste e nos seguintes artigos.  Isso significa que a maioria das partes chatas da prepara√ß√£o do conjunto de dados, como preencher valores ausentes, sele√ß√£o de recursos, an√°lise de outliers, etc.  ser√° ignorado intencionalmente. <br><br>  A pilha de tecnologia ser√° a API C # + TensorFlow <i>tf.keras</i> .  A partir de hoje, tamb√©m ser√° necess√°rio o Windows.  Modelos maiores nos pr√≥ximos artigos podem precisar de uma GPU adequada para que seu tempo de treinamento permane√ßa saud√°vel. <br><a name="habracut"></a><br><h2>  Vamos prever os pre√ßos dos im√≥veis! </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Os pre√ßos da habita√ß√£o</a> s√£o uma grande competi√ß√£o para iniciantes.  Seu conjunto de dados √© pequeno, n√£o h√° regras especiais, o placar p√∫blico tem muitos participantes e voc√™ pode enviar at√© 4 entradas por dia. <br><br>  Registre-se no Kaggle, se voc√™ ainda n√£o o fez, participe desta competi√ß√£o e fa√ßa o download dos dados.  O objetivo √© prever o pre√ßo de venda (coluna Pre√ßo de venda) para entradas em <i>test.csv</i> .  O arquivo cont√©m <i>train.csv</i> , que possui cerca de 1500 entradas com pre√ßo de venda conhecido para treinamento.  Come√ßaremos com o carregamento desse conjunto de dados e a explora√ß√£o um pouco antes de entrar nas redes neurais. <br><br><h2>  Analisar dados de treinamento </h2><br>  <i>Eu disse que pularemos a prepara√ß√£o do conjunto de dados?</i>  <i>Eu menti!</i>  <i>Voc√™ tem que dar uma olhada pelo menos uma vez.</i> <br><br>  Para minha surpresa, n√£o encontrei uma maneira f√°cil de carregar um arquivo .csv na biblioteca de classes padr√£o do .NET. Instalei um pacote NuGet, chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CsvHelper</a> .  Para simplificar a manipula√ß√£o de dados, tamb√©m recebi meu novo pacote de extens√£o LINQ favorito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MoreLinq</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Carregando dados .csv no DataTable</b> <div class="spoiler_text"><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> DataTable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LoadData</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> csvFilePath</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> result = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataTable(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> reader = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvDataReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamReader(csvFilePath)))) { result.Load(reader); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">ML.NET</b> <div class="spoiler_text">  Usar o <i>DataTable</i> para treinar a manipula√ß√£o de dados √©, na verdade, uma p√©ssima id√©ia. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O ML.NET</a> deve ter o carregamento .csv e muitas opera√ß√µes de compara√ß√£o e explora√ß√£o de dados.  No entanto, ainda n√£o estava pronto para esse fim espec√≠fico, quando entrei na competi√ß√£o de Pre√ßos da habita√ß√£o. <br></div></div><br><br>  Os dados s√£o assim (apenas algumas linhas e colunas): <br><br><table><tbody><tr><td>  Id </td><td>  MSSubClass </td><td>  Msoning </td><td>  LotFrontage </td><td>  Lotarea </td></tr><tr><td>  1 </td><td>  60 </td><td>  RL </td><td>  65 </td><td>  8450 </td></tr><tr><td>  2 </td><td>  20 </td><td>  RL </td><td>  80 </td><td>  9600 </td></tr><tr><td>  3 </td><td>  60 </td><td>  RL </td><td>  68 </td><td>  11250 </td></tr><tr><td>  4 </td><td>  70 </td><td>  RL </td><td>  60 </td><td>  9550 </td></tr></tbody></table><br><br>  Depois de carregar os dados, precisamos remover a coluna <i>Id</i> , pois ela n√£o tem rela√ß√£o com os pre√ßos da habita√ß√£o: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> trainData = LoadData(<span class="hljs-string"><span class="hljs-string">"train.csv"</span></span>); trainData.Columns.Remove(<span class="hljs-string"><span class="hljs-string">"Id"</span></span>);</code> </pre> <br><h3>  Analisando os tipos de dados da coluna </h3><br>  O DataTable n√£o infere automaticamente os tipos de dados das colunas e assume que s√£o todas as strings.  Portanto, o pr√≥ximo passo √© determinar o que realmente temos.  Para cada coluna, calculei as seguintes estat√≠sticas: n√∫mero de valores distintos, quantos deles s√£o n√∫meros inteiros e quantos s√£o n√∫meros de ponto flutuante (um c√≥digo-fonte com todos os m√©todos auxiliares ser√° vinculado no final do artigo): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> values = rows.Select(row =&gt; (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column]); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> ints = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> distincts = values.Distinct().Count();</code> </pre> <br><h3>  Colunas num√©ricas </h3><br>  Acontece que a maioria das colunas √© realmente ints, mas como as redes neurais funcionam principalmente em n√∫meros flutuantes, n√≥s as converteremos em dobras de qualquer maneira. <br><br><h3>  Colunas categ√≥ricas </h3><br>  Outras colunas descrevem as categorias √†s quais a propriedade √† venda pertencia.  Nenhum deles tem muitos valores diferentes, o que √© bom.  Para us√°-los como entrada para nossa futura rede neural, eles tamb√©m precisam ser convertidos em <i>duplicados</i> . <br><br>  Inicialmente, simplesmente atribuai n√∫meros de 0 a distintoValueCount - 1 a eles, mas isso n√£o faz muito sentido, pois na verdade n√£o h√° progress√£o de "Fachada: Azul" por "Fachada: Verde" para "Fachada: Branco".  T√£o cedo mudei isso para o que √© chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">de codifica√ß√£o one-hot</a> , em que cada valor exclusivo recebe uma coluna de entrada separada.  Por exemplo, ‚ÄúFachada: Azul‚Äù se torna [1,0,0] e ‚ÄúFachada: Branco‚Äù se torna [0,0,1]. <br><br><h3>  Reunindo todos eles </h3><br><div class="spoiler">  <b class="spoiler_title">Grande produ√ß√£o de explora√ß√£o de dados</b> <div class="spoiler_text">  CentralAir: 2 valores, ints: 0,00%, flutuadores: 0,00% <br>  Rua: 2 valores, ints: 0,00%, carros aleg√≥ricos: 0,00% <br>  Utilit√°rios: 2 valores, ints: 0,00%, flutuadores: 0,00% <br>  Beco: 3 valores, ints: 0,00%, carros aleg√≥ricos: 0,00% <br>  BsmtHalfBath: 3 valores, ints: 100,00%, flutuadores: 100,00% <br>  HalfBath: 3 valores, ints: 100,00%, flutuadores: 100,00% <br>  LandSlope: 3 valores, ints: 0,00%, flutuadores: 0,00% <br>  Unidade Pavimentada: 3 valores, ints: 0,00%, flutuadores: 0,00% <br>  BsmtFullBath: 4 valores, ints: 100.00%, flutuadores: 100.00% <br>  ExterQual: 4 valores, ints: 0,00%, flutuadores: 0,00% <br>  Lareiras: 4 valores, ints: 100,00%, flutuadores: 100,00% <br>  FullBath: 4 valores, ints: 100,00%, flutuadores: 100,00% <br>  GarageFinish: 4 valores, ints: 0.00%, flutuadores: 0.00% <br>  KitchenAbvGr: 4 valores, ints: 100,00%, flutuadores: 100,00% <br>  CozinhaQual: 4 valores, ints: 0.00%, flutuadores: 0.00% <br>  LandContour: 4 valores, ints: 0,00%, flutuadores: 0,00% <br>  LotShape: 4 valores, ints: 0,00%, flutuadores: 0,00% <br>  PoolQC: 4 valores, ints: 0,00%, flutuadores: 0,00% <br>  BldgType: 5 valores, ints: 0.00%, flutuadores: 0.00% <br>  BsmtCond: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  Exposi√ß√£o: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  BsmtQual: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  ExterCond: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  Cerca: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  GarageCars: 5 valores, ints: 100,00%, carros aleg√≥ricos: 100,00% <br>  AquecimentoQC: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  LotConfig: 5 valores, ints: 0,00%, flutua√ß√µes: 0,00% <br>  MasVnrType: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  Caracter√≠stica: 5 valores, ints: 0,00%, flutuadores: 0,00% <br>  MSZoning: 5 valores, ints: 0.00%, floats: 0.00% <br>  Vendido: 5 valores, ints: 100,00%, flutuadores: 100,00% <br>  El√©trica: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  LareiraQu: 6 valores, ints: 0.00%, flutuadores: 0.00% <br>  Funda√ß√£o: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  GarageCond: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  GarageQual: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  Aquecimento: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  RoofStyle: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  Condi√ß√£o: 6 valores, ints: 0,00%, flutuadores: 0,00% <br>  BsmtFinType1: 7 valores, ints: 0.00%, flutua√ß√µes: 0.00% <br>  BsmtFinType2: 7 valores, ints: 0,00%, flutua√ß√µes: 0,00% <br>  Funcional: 7 valores, ints: 0,00%, flutuadores: 0,00% <br>  GarageType: 7 valores, ints: 0,00%, flutuadores: 0,00% <br>  BedroomAbvGr: 8 valores, ints: 100.00%, flutuadores: 100.00% <br>  Condi√ß√£o2: 8 valores, ints: 0,00%, flutuadores: 0,00% <br>  HouseStyle: 8 valores, ints: 0.00%, flutuadores: 0.00% <br>  PoolArea: 8 valores, ints: 100,00%, flutuadores: 100,00% <br>  RoofMatl: 8 valores, ints: 0,00%, flutuadores: 0,00% <br>  Condi√ß√£o1: 9 valores, ints: 0,00%, flutuadores: 0,00% <br>  GeralCond: 9 valores, ints: 100,00%, flutuadores: 100,00% <br>  Tipo de venda: 9 valores, ints: 0,00%, flutuadores: 0,00% <br>  TotalQual: 10 valores, ints: 100,00%, flutuadores: 100,00% <br>  MoSold: 12 valores, ints: 100,00%, flutuadores: 100,00% <br>  TotRmsAbvGrd: 12 valores, ints: 100,00%, flutua√ß√µes: 100,00% <br>  Exterior1st: 15 valores, ints: 0,00%, flutuadores: 0,00% <br>  MSSubClass: 15 valores, ints: 100,00%, flutuadores: 100,00% <br>  Exterior2¬∫: 16 valores, ints: 0,00%, flutuadores: 0,00% <br>  3SsnPorch: 20 valores, ints: 100,00%, flutuadores: 100,00% <br>  MiscVal: 21 valores, ints: 100,00%, flutuadores: 100,00% <br>  LowQualFinSF: 24 valores, ints: 100,00%, flutuadores: 100,00% <br>  Bairro: 25 valores, ints: 0,00%, flutuadores: 0,00% <br>  YearRemodAdd: 61 valores, ints: 100.00%, flutuadores: 100.00% <br>  ScreenPorch: 76 valores, ints: 100,00%, flutuadores: 100,00% <br>  GarageYrBlt: 98 valores, ints: 94.45%, flutuadores: 94.45% <br>  LotFrontage: 111 valores, ints: 82.26%, flutuadores: 82.26% <br>  Ano de constru√ß√£o: 112 valores, polegadas: 100,00%, flutuadores: 100,00% <br>  Porch fechado: 120 valores, ints: 100,00%, flutuadores: 100,00% <br>  BsmtFinSF2: 144 valores, ints: 100,00%, flutuadores: 100,00% <br>  OpenPorchSF: 202 valores, ints: 100,00%, flutuadores: 100,00% <br>  WoodDeckSF: 274 valores, ints: 100,00%, flutuadores: 100,00% <br>  MasVnrArea: 328 valores, ints: 99.45%, flutua√ß√µes: 99.45% <br>  2ndFlrSF: 417 valores, ints: 100.00%, flutuadores: 100.00% <br>  GarageArea: 441 valores, ints: 100,00%, flutuadores: 100,00% <br>  BsmtFinSF1: 637 valores, ints: 100.00%, flutua√ß√µes: 100.00% <br>  Pre√ßo: 663 valores, ints: 100,00%, flutuadores: 100,00% <br>  TotalBsmtSF: 721 valores, ints: 100,00%, flutua√ß√µes: 100,00% <br>  1stFlrSF: 753 valores, ints: 100.00%, flutuadores: 100.00% <br>  BsmtUnfSF: 780 valores, ints: 100,00%, flutuadores: 100,00% <br>  GrLivArea: 861 valores, ints: 100,00%, flutuadores: 100,00% <br>  LotArea: 1073 valores, ints: 100.00%, flutua√ß√µes: 100.00% <br><br>  Muitas colunas de valor: <br>  Exterior1st: AsbShng, AsphShn, BrkComm, BrkFace, CBlock, CemntBd, HdBoard, ImStucc, MetalSd, Contraplacado, Pedra, Estuque, VinylSd, Wd Sdng, WdShing <br>  Exterior2nd: AsbShng, AsphShn, Brk Cmn, BrkFace, CBlock, CmentBd, HdBoard, ImStucc, MetalSd, Outros, Contraplacado, Pedra, Estuque, VinylSd, Wd Sdng, Wd Shng <br>  Bairro: Blmngtn, Blueste, BrDale, BrkSide, ClearCr, CollgCr, Crawfor, Edwards, Gilbert, IDOTRR, MeadowV, Mitchel, NAmes, NoRidge, NPkVill, NridgHt, NWAmes, OldTown, Sawyer, SawyerW, Somerst, Stone, Stoner Veenker <br><br>  carros aleg√≥ricos n√£o analis√°veis <br>  GarageYrBlt: NA <br>  LotFrontage: NA <br>  MasVnrArea: NA <br><br>  gamas de flutua√ß√£o: <br>  BmmHalfBath: 0 ... 2 <br>  HalfBath: 0 ... 2 <br>  BmmFullBath: 0 ... 3 <br>  Lareiras: 0 ... 3 <br>  FullBath: 0 ... 3 <br>  KitchenAbvGr: 0 ... 3 <br>  Garagem: 0 ... 4 <br>  Ano: 2006 ... 2010 <br>  QuartoAbvGr: 0 ... 8 <br>  PoolArea: 0 ... 738 <br>  GeralCondi√ß√£o: 1 ... 9 <br>  TotalQualidade: 1 ... 10 <br>  MoSold: 1 ... 12 <br>  TotRmsAbvGrd: 2 ... 14 <br>  MSSubClass: 20 ... 190 <br>  3SsnPorch: 0 ... 508 <br>  Valor: 0 ... 15500 <br>  LowQualFinSF: 0 ... 572 <br>  Adicionado: 1950 ... 2010 <br>  Porteiro: 0 ... 480 <br>  GaragemYrBlt: 1900 ... 2010 <br>  Fronteira do lote: 21 ... 313 <br>  Ano de constru√ß√£o: 1872 ... 2010 <br>  Varanda fechada: 0 ... 552 <br>  BsmtFinSF2: 0 ... 1474 <br>  OpenPorchSF: 0 ... 547 <br>  WoodDeckSF: 0 ... 857 <br>  MasVnrArea: 0 ... 1600 <br>  2ndFlrSF: 0 ... 2065 <br>  √Årea de Garagem: 0 ... 1418 <br>  BsmtFinSF1: 0 ... 5644 <br>  Pre√ßo: 34.900 ... 755.000 <br>  TotalBsmtSF: 0 ... 6110 <br>  1stFlrSF: 334 ... 4692 <br>  BsmtUnfSF: 0 ... 2336 <br>  GrLivArea: 334 ... 5642 <br>  √Årea do lote: 1300 ... 215245 <br></div></div><br><br>  Com isso em mente, <i>criei</i> o seguinte <i>ValueNormalizer</i> , que obt√©m algumas informa√ß√µes sobre os valores dentro da coluna e retorna uma fun√ß√£o que transforma um valor (uma <i>string</i> ) em um vetor de recurso num√©rico para a rede neural ( <i>double []</i> ): <br><br><div class="spoiler">  <b class="spoiler_title">ValueNormalizer</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Func&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[]&gt; ValueNormalizer( <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats, IEnumerable&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt; values) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (floats &gt; <span class="hljs-number"><span class="hljs-number">0.01</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> max = values.AsDouble().Max().Value; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span>[] { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(s, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) ? v / max : <span class="hljs-number"><span class="hljs-number">-1</span></span> }; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>[] domain = values.Distinct().OrderBy(v =&gt; v).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[domain.Length+<span class="hljs-number"><span class="hljs-number">1</span></span>] .Set(Array.IndexOf(domain, s)+<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br></div></div><br>  Agora, temos os dados convertidos em um formato adequado para uma rede neural.  √â hora de construir um. <br><br><h2>  Construa uma rede neural </h2><br>  <i>A partir de hoje, voc√™ precisaria usar uma m√°quina Windows para isso.</i> <br><br>  Se voc√™ j√° possui o Python e o TensorFlow 1.1x instalados, tudo o que voc√™ precisa √© <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">PackageReference</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Include</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"Gradient"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Version</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"0.1.10-tech-preview3"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre> <br>  no seu arquivo .csproj moderno.  Caso contr√°rio, consulte o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">manual</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gradiente</a> para fazer a configura√ß√£o inicial. <br><br>  Quando o pacote estiver em funcionamento, podemos criar nossa primeira rede superficial rasa. <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras.layers; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.train; ... <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Sequential(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Layer[] { <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">16</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dropout(rate: <span class="hljs-number"><span class="hljs-number">0.1</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">10</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: tf.nn.relu_fn), }); model.compile(optimizer: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AdamOptimizer(), loss: <span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>);</code> </pre> <br>  Isso criar√° uma rede neural n√£o treinada com 3 camadas de neur√¥nios e uma camada de evas√£o, que ajuda a evitar o super ajuste. <br><br><div class="spoiler">  <b class="spoiler_title">tf.nn.relu_fn</b> <div class="spoiler_text">  <i>tf.nn.relu_fn</i> √© a fun√ß√£o de ativa√ß√£o de nossos neur√¥nios.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sabe-</a> se que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ReLU</a> funciona bem em redes profundas, porque resolve o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">problema de gradiente de fuga</a> : derivadas de fun√ß√µes originais de ativa√ß√£o n√£o linear tendem a se tornar muito pequenas quando o erro √© propagado de volta da camada de sa√≠da em redes profundas.  Isso significava que as camadas mais pr√≥ximas da entrada se ajustariam apenas um pouco, o que atrasava significativamente o treinamento de redes profundas. <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Abandono</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A evas√£o</a> √© uma camada de fun√ß√£o especial nas redes neurais, que na verdade n√£o cont√©m neur√¥nios como tal.  Em vez disso, ele opera tomando cada entrada individual e a substitui aleatoriamente por 0 na sa√≠da autom√°tica (caso contr√°rio, apenas passa o valor original).  Ao fazer isso, ajuda a evitar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ajuste excessivo</a> a recursos menos relevantes em um pequeno conjunto de dados.  Por exemplo, se n√£o removemos a coluna <i>Id</i> , a rede poderia potencialmente memorizar exatamente o &lt;Id&gt; -&gt; &lt;SalePrice&gt; mapeamento, o que nos daria 100% de precis√£o no conjunto de treinamento, mas n√∫meros completamente independentes em qualquer outro dado. <br><br>  Por que precisamos de abandono?  Nossos dados de treinamento t√™m apenas ~ 1.500 exemplos e essa pequena rede neural que constru√≠mos tem&gt; 1800 pesos ajust√°veis.  Se fosse um polin√¥mio simples, poderia corresponder √† fun√ß√£o de pre√ßo que estamos tentando aproximar exatamente.  Mas, ent√£o, ele teria valores enormes em quaisquer entradas fora do conjunto de treinamento original. <br></div></div><br><h2>  Alimente os dados </h2><br>  O TensorFlow espera seus dados em matrizes NumPy ou nos tensores existentes.  Estou convertendo DataRows em matrizes NumPy: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> numpy; ... <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> predict = <span class="hljs-string"><span class="hljs-string">"SalePrice"</span></span>; <span class="hljs-function"><span class="hljs-function">ndarray </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInputs</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">IEnumerable&lt;DataRow&gt; rowSeq</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(rowSeq.Select(row =&gt; np.array( columnTypes .Where(c =&gt; c.column.ColumnName != predict) .SelectMany(column =&gt; column.normalizer( row.Table.Columns.Contains(column.column.ColumnName) ? (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column.column.ColumnName] : <span class="hljs-string"><span class="hljs-string">"-1"</span></span>)) .ToArray())) .ToArray() ); } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> predictColumn = columnTypes.Single(c =&gt; c.column.ColumnName == predict); ndarray trainOutputs = np.array(predictColumn.trainValues .AsDouble() .Select(v =&gt; v ?? <span class="hljs-number"><span class="hljs-number">-1</span></span>) .ToArray()); ndarray trainInputs = GetInputs(trainRows);</code> </pre> <br>  No c√≥digo acima, convertemos cada <i>DataRow</i> em um <i>ndarray</i> , pegando todas as c√©lulas nele e aplicando o <i>ValueNormalizer</i> correspondente √† sua coluna.  Em seguida, colocamos todas as linhas em outro <i>ndarray</i> , obtendo uma matriz de matrizes. <br><br>  Nenhuma transforma√ß√£o √© necess√°ria para sa√≠das, onde apenas convertemos valores de trem em outro <i>ndarray</i> . <br><br><h2>  Hora de descer o gradiente </h2><br>  Com essa configura√ß√£o, tudo o que precisamos fazer para treinar nossa rede √© chamar a fun√ß√£o de <i>ajuste</i> do modelo: <br><br><pre> <code class="cs hljs">model.fit(trainInputs, trainOutputs, epochs: <span class="hljs-number"><span class="hljs-number">2000</span></span>, validation_split: <span class="hljs-number"><span class="hljs-number">0.075</span></span>, verbose: <span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre> <br>  Na verdade, esta chamada anular√° os √∫ltimos 7,5% do treinamento definido para valida√ß√£o e repita as seguintes 2000 vezes: <br><br><ol><li>  dividir o restante do <i>trainInputs</i> em lotes </li><li>  alimentar esses lotes, um por um, na rede neural </li><li>  erro de c√°lculo usando a fun√ß√£o de perda que definimos acima </li><li>  retropropagam o erro atrav√©s dos gradientes de conex√µes individuais de neur√¥nios, ajustando pesos </li></ol><br>  Durante o treinamento, ele emitir√° o erro da rede nos dados reservados para valida√ß√£o como <b>val_loss</b> e o erro nos dados de treinamento em si como apenas <b>perda</b> .  Geralmente, se <b>val_loss</b> se torna muito maior do que a <b>perda</b> , significa que a rede come√ßou a se <b>ajustar</b> demais.  Abordarei isso com mais detalhes nos seguintes artigos. <br><br>  Se voc√™ fez tudo corretamente, uma <u>raiz quadrada</u> de uma de suas perdas deve ser da ordem de 20000. <br><br><img src="https://habrastorage.org/webt/fu/rn/vg/furnvg6dbs8ocijm91_3xcqdxhm.png"><br><br><h2>  Submiss√£o </h2><br>  N√£o falarei muito sobre gerar o arquivo para enviar aqui.  O c√≥digo para calcular resultados √© simples: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> SubmissionInputFile = <span class="hljs-string"><span class="hljs-string">"test.csv"</span></span>; DataTable submissionData = LoadData(SubmissionInputFile); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> submissionRows = submissionData.Rows.Cast&lt;DataRow&gt;(); ndarray submissionInputs = GetInputs(submissionRows); ndarray sumissionOutputs = model.predict(submissionInputs);</code> </pre> <br>  que usa principalmente fun√ß√µes definidas anteriormente. <br><br>  Em seguida, √© necess√°rio grav√°-los em um arquivo .csv, que √© simplesmente uma lista de pares Id, predicted_value. <br><br>  Ao enviar seu resultado, voc√™ deve obter uma pontua√ß√£o na ordem de 0,17, que estaria em algum lugar no √∫ltimo trimestre da tabela de classifica√ß√£o p√∫blica.  Mas, ei, se fosse t√£o simples quanto uma rede de 3 camadas com 27 neur√¥nios, esses irritantes cientistas de dados n√£o receberiam compensa√ß√µes totais de US $ 300k + / a das principais empresas americanas <br><br><h2>  Finalizando </h2><br>  O c√≥digo fonte completo dessa entrada (com todos os ajudantes e algumas das partes comentadas de minhas explora√ß√µes e experi√™ncias anteriores) √© de cerca de 200 linhas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PasteBin</a> . <br><br>  No pr√≥ximo artigo, voc√™ ver√° minhas travessuras tentando entrar no top 50% dessa classifica√ß√£o p√∫blica.  Vai ser uma aventura amadora para viajantes, uma briga com o Windmill of Overfitting com a √∫nica ferramenta que o viajante tem - um modelo maior (por exemplo, NN profundo, lembre-se, n√£o h√° engenharia manual de recursos!).  Ser√° menos um tutorial de codifica√ß√£o e mais uma busca de racioc√≠nio com matem√°tica realmente complicada e uma conclus√£o estranha.  Fique atento! <br><br><h2>  Liga√ß√µes </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Competi√ß√£o de pre√ßos da habita√ß√£o no Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tutorial de regress√£o do TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°gina inicial do TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Refer√™ncia da API do TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gradiente (liga√ß√£o ao TensorFlow)</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt437174/">https://habr.com/ru/post/pt437174/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt437160/index.html">Devops</a></li>
<li><a href="../pt437164/index.html"># 10anos de desafio para programadores</a></li>
<li><a href="../pt437166/index.html">V√¥o de combate no Meteor-e</a></li>
<li><a href="../pt437170/index.html">Facebook sugere o uso de lasers espaciais para comunica√ß√µes globais</a></li>
<li><a href="../pt437172/index.html">IBM MQ e JMeter: primeiro contato</a></li>
<li><a href="../pt437176/index.html">Aplicativo para iOS e Android na interface do usu√°rio Kotlin + Flutter</a></li>
<li><a href="../pt437180/index.html">JVM siberiana severa: √≥tima entrevista sobre o Excelsior JET</a></li>
<li><a href="../pt437182/index.html">Intercepta√ß√£o de chamada do sistema no m√≥dulo Linux-kernel</a></li>
<li><a href="../pt437184/index.html">Nikolay Durov 90% concluiu o desenvolvimento da plataforma Telegram Open Network</a></li>
<li><a href="../pt437186/index.html">Mon√≥lito para microsservi√ßos. Ponto de vista da infraestrutura</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
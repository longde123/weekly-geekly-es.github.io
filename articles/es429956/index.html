<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí∂ üêù üë®üèæ Integraci√≥n continua en Yandex. Parte 2 üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø ‚è≤Ô∏è üêï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En el art√≠culo anterior , hablamos sobre la transferencia del desarrollo a un √∫nico repositorio con un enfoque de desarrollo basado en troncales, con ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Integraci√≥n continua en Yandex. Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/429956/"><p>  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> anterior <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> hablamos sobre la transferencia del desarrollo a un √∫nico repositorio con un enfoque de desarrollo basado en troncales, con sistemas unificados para ensamblaje, prueba, implementaci√≥n y monitoreo, sobre qu√© tareas debe resolver un sistema de integraci√≥n continua para trabajar eficazmente en tales condiciones. </p><br><p>  Hoy le diremos a los lectores de Habr sobre el dispositivo del sistema de integraci√≥n continua. </p><br><p><img src="https://habrastorage.org/webt/wb/mt/xc/wbmtxcvurtd6cdv1aomjrtcyfw8.png" alt="imagen"></p><br><p>  Un sistema de integraci√≥n continua debe funcionar de manera confiable y r√°pida.  El sistema debe responder r√°pidamente a los eventos entrantes y no debe introducir demoras adicionales en el proceso de entrega de resultados de ejecuci√≥n de prueba al usuario.  Los resultados del montaje y las pruebas deben entregarse al usuario en tiempo real. </p><a name="habracut"></a><br><p>  El sistema de integraci√≥n continua es un sistema de procesamiento de datos de transmisi√≥n con retrasos m√≠nimos. </p><br><p>  Despu√©s de enviar todos los resultados en una determinada etapa (configuraci√≥n, compilaci√≥n, estilo, pruebas peque√±as, pruebas medianas, etc.), el sistema de compilaci√≥n indica esto al sistema de integraci√≥n continua ("cierra" la etapa), y el usuario lo ve para esta verificaci√≥n y En esta etapa se conocen todos los resultados.  Cada etapa se cierra de forma independiente.  El usuario recibe una se√±al √∫til m√°s r√°pido.  Despu√©s de cerrar todas las etapas, la verificaci√≥n se considera completa. </p><br><p>  Para implementar el sistema, elegimos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la</a> arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kappa</a> .  El sistema consta de 2 subsistemas: </p><br><ul><li>  El procesamiento de eventos y datos tiene lugar en un circuito en tiempo real.  Cualquier dato de entrada se trata como flujos de datos (flujos).  Primero, los eventos se registran en la transmisi√≥n y solo luego se procesan. </li><li>  Los resultados del procesamiento de datos se escriben continuamente en la base de datos, donde luego van las llamadas a trav√©s de la API.  En la arquitectura Kappa, esto se llama la capa de servicio. </li></ul><br><p>  Todas las solicitudes de modificaci√≥n de datos deben pasar por el circuito en tiempo real, porque siempre debe tener el estado actual del sistema.  Las solicitudes de lectura van solo a la base de datos. </p><br><img src="https://habrastorage.org/webt/fb/bu/ps/fbbups7bcp0zgwvigxv5un9reek.png"><br><br><p>  Siempre que sea posible, seguimos la regla de solo agregar.  Sin modificaciones ni eliminaciones de objetos, con la excepci√≥n de eliminar datos antiguos e innecesarios. </p><br><p>  M√°s de 2 Tb de datos sin procesar pasan por el servicio por d√≠a. </p><br><p>  Ventajas: </p><br><ul><li>  Las transmisiones contienen todos los eventos y mensajes.  Siempre podemos entender qu√© y cu√°ndo sucedi√≥.  Stream puede ser percibido como un gran registro. </li><li>  Alta eficiencia y gastos generales m√≠nimos.  Resulta un sistema totalmente orientado a eventos, sin ninguna p√©rdida en el sondeo.  No hay evento, no estamos haciendo nada extra. </li><li>  El c√≥digo de la aplicaci√≥n pr√°cticamente no trata las primitivas de la sincronizaci√≥n de subprocesos y la memoria compartida entre subprocesos.  Esto hace que el sistema sea m√°s confiable. </li><li>  Los procesadores est√°n bien aislados entre s√≠, porque  no interact√∫es directamente, solo a trav√©s de flujos.  Se puede proporcionar una buena cobertura de prueba. </li></ul><br><p>  Pero el procesamiento de datos de transmisi√≥n no es tan simple: </p><br><ul><li> Se requiere una buena comprensi√≥n del modelo computacional.  Tendr√° que repensar los algoritmos de procesamiento de datos existentes.  No todos los algoritmos entran inmediatamente en el modelo de transmisi√≥n y tienes que aplastarte un poco. </li><li>  Es necesario garantizar que se mantenga el orden de recepci√≥n y procesamiento de eventos. </li><li>  Debe poder manejar eventos interrelacionados, es decir  tener acceso r√°pido a todos los datos necesarios mientras procesa un nuevo mensaje. </li><li>  Tambi√©n debe ser capaz de manejar eventos duplicados. </li></ul><br><h3 id="potokovaya-obrabotka-dannyh-stream-processing">  Procesamiento de flujo </h3><br><p>  Mientras trabajaba en el proyecto, se escribi√≥ la biblioteca Stream Processor, que nos ayud√≥ a implementar y lanzar r√°pidamente algoritmos de procesamiento de datos de transmisi√≥n en producci√≥n. </p><br><p>  Stream Processor es una biblioteca para construir sistemas de procesamiento de datos de transmisi√≥n.  La secuencia es una secuencia de datos (mensajes) potencialmente interminable en la que solo es posible agregar mensajes nuevos; los mensajes ya grabados no se modifican ni se eliminan de la secuencia.  Los convertidores de un flujo a otro (procesadores de flujo) constan funcionalmente de tres partes: un proveedor de mensajes entrantes, que generalmente lee mensajes de uno o m√°s flujos y los coloca en una cola de procesamiento, un procesador de mensajes que convierte los mensajes entrantes en salientes y los coloca en una cola al registro y al escritor, donde los mensajes salientes agrupados dentro de la ventana de tiempo caen en la secuencia de salida.  Los mensajes de datos generados por un procesador de flujo pueden ser utilizados por otros m√°s adelante.  Por lo tanto, las secuencias y los procesadores forman un gr√°fico dirigido en el que los bucles son posibles, en particular, un procesador de secuencias puede incluso generar mensajes en la misma secuencia desde donde recibe datos. </p><br><p>  Se garantiza que cada mensaje de la secuencia de entrada ser√° procesado por cada procesador asociado con √©l al menos una vez (sem√°ntica al menos una vez).  Tambi√©n se garantiza que todos los mensajes se procesar√°n en el orden en que llegaron a esta secuencia.  Para hacer esto, los procesadores de flujo se distribuyen en todos los nodos de servicio en funcionamiento, de modo que al mismo tiempo no funcione m√°s de una instancia de cada procesador registrado. </p><br><p>  El procesamiento de eventos interrelacionados es uno de los principales problemas en la construcci√≥n de sistemas para el procesamiento de datos en streaming.  Como regla general, cuando se transmiten mensajes, los procesadores de flujo crean gradualmente un cierto estado que era v√°lido en el momento en que se proces√≥ el mensaje actual.  Tales objetos de estado generalmente se asocian no con la secuencia completa en su conjunto, sino con un cierto subconjunto de mensajes, que est√° determinado por el valor clave en esta secuencia.  El almacenamiento eficiente de la riqueza es la clave del √©xito.  Al procesar el siguiente mensaje, es importante que el procesador pueda obtener r√°pidamente este estado y, bas√°ndose en √©l y en el mensaje actual, generar mensajes salientes.  Estos objetos de estado son accesibles para los procesadores en L1 (no confunda con el cach√© de la CPU) cach√© LRU, que se encuentra en la memoria.  En el caso de que no haya estado en el cach√© L1, se restaura desde el cach√© L2 ubicado en el mismo almacenamiento donde se almacenan las secuencias y donde se almacena peri√≥dicamente durante el funcionamiento del procesador.  Si no hab√≠a estado en el cach√© L2, se restaura a partir de los mensajes de flujo originales, como si el procesador hubiera procesado todos los mensajes originales asociados con la clave de mensaje actual.  La t√©cnica de almacenamiento en cach√© tambi√©n le permite lidiar con el problema de la alta latencia del almacenamiento, ya que a menudo el procesamiento secuencial no descansa en el rendimiento del servidor, sino en el retraso de las solicitudes y respuestas al comunicarse con el almac√©n de datos. </p><br><img width="400" src="https://habrastorage.org/webt/_o/pk/sj/_opksjvyut5cirxrnbjerswkt78.png"><br><br><p>  Para almacenar datos de manera efectiva en cach√©s L1 y datos de mensajes en la memoria, adem√°s de estructuras eficientes en la memoria, utilizamos grupos de objetos que le permiten tener solo una copia de un objeto (o incluso partes de √©l) en la memoria.  Esta t√©cnica ya se usa en el JDK para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cadenas de pasadas de cadena</a> y se extiende de manera similar a otros tipos de objetos, que deber√≠an ser inmutables. </p><br><p>  Para el almacenamiento compacto de datos en el almacenamiento de flujo, algunos datos se normalizan antes de escribir en el flujo, es decir  Convi√©rtete en n√∫meros.  Los algoritmos de compresi√≥n efectivos se pueden aplicar a los n√∫meros (identificadores de objeto).  Los n√∫meros se ordenan, se cuentan los deltas, luego se codifica con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ZigZag Encoding</a> y luego se comprime con el archivador.  La normalizaci√≥n no es una t√©cnica muy est√°ndar para la transmisi√≥n de sistemas de procesamiento de datos.  Pero esta t√©cnica de compresi√≥n es muy efectiva y la cantidad de datos en la secuencia m√°s cargada se reduce en aproximadamente 1,000 veces. </p><br><img width="600" src="https://habrastorage.org/getpro/habr/post_images/b1b/6f4/fa9/b1b6f4fa9d551a96fd4069b44435354f.png"><br><br><p>  Para cada secuencia y procesador, rastreamos el ciclo de vida del procesamiento de mensajes: la aparici√≥n de nuevos mensajes en la secuencia de entrada, el tama√±o de la cola de mensajes no procesados, el tama√±o de la cola para escribir en la secuencia resultante, el tiempo de procesamiento de mensajes y la distribuci√≥n del tiempo por etapas de procesamiento de mensajes: </p><br><img src="https://habrastorage.org/webt/jg/0q/rp/jg0qrpqbojreaugzrf66cikffwa.png"><br><br><h3 id="hranilische-dannyh">  Almac√©n de datos </h3><br><p>  Los resultados del procesamiento de datos de transmisi√≥n deben estar disponibles para el usuario lo antes posible.  Los datos procesados ‚Äã‚Äãde las transmisiones deben registrarse continuamente en la base de datos, donde puede solicitar datos (por ejemplo, mostrar un informe con los resultados de la prueba, mostrar el historial de la prueba). </p><br><p>  Caracter√≠sticas de los datos almacenados y consultas. <br>  La mayor√≠a de los datos son ejecuciones de prueba.  Durante un mes, se lanzan m√°s de 1.500 millones de compilaciones y pruebas.  Se almacena una cantidad bastante grande de informaci√≥n para cada lanzamiento: el resultado y el tipo de error, una breve descripci√≥n del error (fragmento), varios enlaces a los registros, la duraci√≥n de la prueba, un conjunto de valores num√©ricos, m√©tricas, en el formato nombre = valor, etc.  Algunos de estos datos, por ejemplo, m√©tricas y duraci√≥n, son muy dif√≠ciles de comprimir, ya que de hecho son valores aleatorios.  La otra parte, por ejemplo, el resultado, el tipo de error, los registros, se pueden guardar de manera m√°s eficiente, ya que casi no cambian en la misma prueba de una ejecuci√≥n a otra. </p><br><p>  Anteriormente, us√°bamos MySQL para almacenar datos procesados.  Poco a poco comenzamos a descansar contra las capacidades de la base de datos: </p><br><ul><li>  La cantidad de datos procesados ‚Äã‚Äãse duplica cada seis meses. </li><li>  Solo pudimos almacenar datos durante los √∫ltimos 2 meses, pero quer√≠amos almacenar datos durante al menos un a√±o. </li><li>  Problemas con la velocidad de ejecuci√≥n de algunas consultas pesadas (cercanas a las anal√≠ticas). </li><li>  Esquema de base de datos complicado.  Muchas tablas (normalizaci√≥n), lo que complica la escritura en la base de datos.  El esquema base es muy diferente del esquema de objetos utilizados en el circuito en tiempo real. </li><li>  No experimentar un apagado del servidor.  La falla de un servidor separado o el apagado del centro de datos puede conducir a una falla del sistema. </li><li>  Operaci√≥n bastante complicada. </li></ul><br><p>  Como candidatos para el nuevo almac√©n de datos, consideramos varias opciones: PostgreSQL, MongoDB y varias soluciones internas, incluida <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ClickHouse</a> . </p><br><p>  Algunas soluciones no nos permiten almacenar nuestros datos de manera m√°s eficiente que la antigua soluci√≥n basada en MySQL.  Otros no permiten la implementaci√≥n de consultas r√°pidas y complejas (casi anal√≠ticas).  Por ejemplo, tenemos una solicitud bastante pesada que muestra confirmaciones que afectan a un proyecto espec√≠fico (un conjunto de pruebas).  En todos los casos en que no podamos ejecutar consultas SQL r√°pidas, tendr√≠amos que obligar al usuario a esperar mucho tiempo o hacer algunos c√°lculos por adelantado con una p√©rdida de flexibilidad.  Si cuenta algo por adelantado, debe escribir m√°s c√≥digo y al mismo tiempo perder flexibilidad: no hay forma de cambiar r√°pidamente el comportamiento y contar nada.  Es mucho m√°s conveniente y r√°pido escribir una consulta SQL que devolver√° los datos que el usuario necesita y podr√° modificarlos r√°pidamente si desea cambiar el comportamiento del sistema. </p><br><h3 id="clickhouse">  Clickhouse </h3><br><p>  Optamos por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ClickHouse</a> .  ClickHouse es un sistema de gesti√≥n de bases de datos en columnas (DBMS) para el procesamiento de consultas anal√≠ticas en l√≠nea (OLAP). </p><br><p>  Cambiando a ClickHouse, abandonamos deliberadamente algunas de las oportunidades proporcionadas por otros DBMS, recibiendo una compensaci√≥n m√°s que valiosa por esto en forma de consultas anal√≠ticas muy r√°pidas y un almac√©n de datos compacto. </p><br><p>  En los DBMS relacionales, los valores relacionados con una fila se almacenan f√≠sicamente uno al lado del otro.  En ClickHouse, los valores de diferentes columnas se almacenan por separado, y los datos de una columna se almacenan juntos.  Este orden de almacenamiento de datos le permite proporcionar un alto grado de compresi√≥n de datos con la elecci√≥n correcta de la clave primaria.  Tambi√©n afecta en qu√© escenarios el DBMS funcionar√° bien.  ClickHouse funciona mejor con consultas, donde se lee una peque√±a cantidad de columnas y la consulta usa una tabla grande y el resto de las tablas son peque√±as.  Pero incluso en consultas no anal√≠ticas, ClickHouse puede mostrar buenos resultados. </p><br><p>  Los datos en las tablas se ordenan por clave primaria.  La clasificaci√≥n se realiza en segundo plano.  Esto le permite crear un √≠ndice disperso de un volumen peque√±o, lo que le permite encontrar datos r√°pidamente.  ClickHouse no tiene √≠ndices secundarios.  Hablando estrictamente, hay un √≠ndice secundario: la clave de partici√≥n (ClickHouse corta los datos de partici√≥n donde la clave de partici√≥n se especifica en la solicitud).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">M√°s detalles</a> </p><br><p>  El esquema de datos con normalizaci√≥n no es funcional, por el contrario, es preferible desnormalizar los datos en funci√≥n de las solicitudes.  Es preferible crear tablas "anchas" con una gran cantidad de columnas.  Este elemento tambi√©n est√° relacionado con el anterior, porque la ausencia de √≠ndices secundarios a veces hace copias de las tablas con una clave primaria diferente. </p><br><p>  ClickHouse no tiene UPDATE y DELETE en el sentido cl√°sico, pero existe la posibilidad de emularlos. </p><br><p>  Los datos deben insertarse en bloques grandes y no con demasiada frecuencia (una vez cada pocos segundos).  La carga de datos l√≠nea por l√≠nea es pr√°cticamente inoperante en vol√∫menes de datos reales. </p><br><p>  ClickHouse no admite transacciones; el sistema <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">eventualmente se</a> vuelve <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">consistente</a> . </p><br><p>  Sin embargo, algunas caracter√≠sticas de ClickHouse, similares a otros DBMS, hacen que sea m√°s f√°cil transferirle los sistemas existentes. </p><br><ul><li>  ClickHouse usa SQL, pero con ligeras diferencias, √∫til para consultas t√≠picas de los sistemas OLAP.  Existe un poderoso sistema de funciones agregadas, ALL / ANY JOIN, expresiones lambda en funciones y otras extensiones SQL que le permiten escribir casi cualquier consulta anal√≠tica. </li><li>  ClickHouse admite replicaci√≥n, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">grabaci√≥n de</a> qu√≥rum, lectura de qu√≥rum.  Es necesaria una escritura de qu√≥rum para un almacenamiento de datos confiable: INSERT es exitoso solo si ClickHouse pudo escribir datos en un n√∫mero dado de r√©plicas sin error. </li></ul><br><p>  Puede leer m√°s sobre las caracter√≠sticas de ClickHouse en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> . </p><br><h4 id="osobennosti-raboty-s-clickhouse">  Caracter√≠sticas de trabajar con ClickHouse </h4><br><p>  Elecci√≥n de clave principal y clave de partici√≥n. </p><br><p>  ¬øC√≥mo elegir una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">clave principal</a> y una clave de partici√≥n?  Quiz√°s esta es la primera pregunta que surge al crear una nueva tabla.  La elecci√≥n de la clave principal y la clave de partici√≥n generalmente est√° dictada por las consultas que se realizar√°n en los datos.  Al mismo tiempo, las consultas que usan ambas condiciones resultan ser las m√°s efectivas: tanto por la clave primaria como por la clave de partici√≥n. </p><br><p>  En nuestro caso, las tablas principales son las matrices para ejecutar las pruebas.  Es l√≥gico suponer que con esta estructura de datos, las claves deben seleccionarse de modo que el orden de anulaci√≥n de una de ellas vaya en el orden de aumentar el n√∫mero de fila y el orden de anulaci√≥n de la otra, en el orden de aumentar el n√∫mero de columna. </p><br><p>  Tambi√©n es importante tener en cuenta que la elecci√≥n de la clave primaria puede afectar dr√°sticamente la compacidad del almacenamiento de datos, ya que los valores id√©nticos en la omisi√≥n de la clave primaria en otras columnas casi no ocupan espacio en la tabla.  Entonces, en nuestro caso, por ejemplo, los estados de las pruebas cambian poco de commit a commit.  Este hecho esencialmente predetermin√≥ la elecci√≥n de la clave primaria: un par de identificador de prueba y n√∫mero de confirmaci√≥n.  Adem√°s, en ese orden. </p><br><img width="600" src="https://habrastorage.org/webt/0t/gj/jo/0tgjjoefxhjgbxexx4gevfwte7y.png"><br><br><p>  La clave de partici√≥n tiene dos prop√≥sitos.  Por un lado, permite que las particiones se "archiven" para que puedan eliminarse permanentemente del almacenamiento, ya que los datos en ellas ya est√°n desactualizados.  Por otro lado, la clave de partici√≥n es un √≠ndice secundario, lo que significa que le permite acelerar las consultas si hay una expresi√≥n para ello. </p><br><p>  Para nuestras matrices, elegir el n√∫mero de confirmaci√≥n como clave de partici√≥n parece bastante natural.  Pero si establece el valor de revisi√≥n en la expresi√≥n para la clave de partici√≥n, habr√° una gran cantidad de particiones en dicha tabla, lo que degradar√° el rendimiento de las consultas.  Por lo tanto, en la expresi√≥n para la clave de partici√≥n, el valor de revisi√≥n puede dividirse en un n√∫mero grande para reducir el n√∫mero de particiones, por ejemplo, PARTITION BY intDiv (revisi√≥n, 2000).  Este n√∫mero debe ser lo suficientemente grande como para que el n√∫mero de particiones no exceda los valores recomendados, mientras que debe ser lo suficientemente peque√±o como para que no caigan muchos datos en una partici√≥n y la base de datos no tenga que leer demasiados datos. </p><br><p>  ¬øC√≥mo implementar ACTUALIZAR y ELIMINAR? </p><br><p>  En el sentido habitual, UPDATE y DELETE no son compatibles con ClickHouse.  Sin embargo, en lugar de ACTUALIZAR y ELIMINAR, puede agregar una columna con la versi√≥n a la tabla y usar el motor especial <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ReplacingMergeTree</a> (elimina los registros duplicados con el mismo valor de clave principal).  En algunos casos, la versi√≥n estar√° naturalmente presente en la tabla desde el principio: por ejemplo, si queremos crear una tabla para el estado actual de la prueba, la versi√≥n en esta tabla ser√° el n√∫mero de confirmaci√≥n. </p><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> current_tests ( test_id UInt64, <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> Nullable(<span class="hljs-keyword"><span class="hljs-keyword">String</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">version</span></span> UInt64 ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree(<span class="hljs-keyword"><span class="hljs-keyword">version</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> test_id</code> </pre> <br><p>  En el caso de un cambio de registro, agregamos la versi√≥n con un nuevo valor, en el caso de eliminaci√≥n, con un valor NULL (o alg√∫n otro valor especial que no se puede encontrar en los datos). </p><br><p>  ¬øQu√© lograste con el nuevo almacenamiento? </p><br><p>  Uno de los principales objetivos de cambiar a ClickHouse era la capacidad de almacenar el historial de pruebas durante un largo per√≠odo de tiempo (varios a√±os o al menos un a√±o en el peor de los casos).  Ya en la etapa de prototipo, qued√≥ claro que podemos sortear los SSD existentes en nuestros servidores para almacenar al menos una historia de tres a√±os.  Las consultas anal√≠ticas se han acelerado significativamente, ahora podemos extraer mucha m√°s informaci√≥n √∫til de nuestros datos.  El margen RPS ha aumentado.  Adem√°s, este valor se escala casi linealmente mediante la adici√≥n de nuevos servidores al cl√∫ster ClickHouse.  Crear un nuevo almac√©n de datos para la base de datos ClickHouse es solo un paso apenas perceptible para el usuario final hacia un objetivo m√°s importante: agregar nuevas funciones, acelerar y simplificar el desarrollo, gracias a la capacidad de almacenar y procesar grandes cantidades de datos. </p><br><h4 id="prihodite-k-nam">  Ven a nosotros </h4><br><p>  Nuestro departamento est√° en constante expansi√≥n.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Vis√≠tanos</a> si quieres trabajar en tareas y algoritmos complejos e interesantes.  Si tiene preguntas, puede preguntarme directamente en PM. </p><br><h3 id="poleznye-ssylki">  Enlaces utiles </h3><br><p>  Procesamiento de flujo </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El registro: lo que todo ingeniero de software debe saber sobre la abstracci√≥n unificadora de datos en tiempo real</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El mundo m√°s all√° del lote: Streaming 101</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dise√±o de</a> libros <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aplicaciones intensivas en datos</a> - O'Reilly Media. </li></ul><br><p>  Arquitectura Kappa </p><br><ul><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitectura kappa</a> </li></ul><br><p>  ClickHouse: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Yandex abre ClickHouse</a> . </li><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://clickhouse.yandex</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Documentaci√≥n</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es429956/">https://habr.com/ru/post/es429956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es429946/index.html">Locura y √©xito del c√≥digo de base de datos Oracle</a></li>
<li><a href="../es429948/index.html">Por qu√© se necesitan gerentes de producto en fintech</a></li>
<li><a href="../es429950/index.html">C√≥mo mantener h√°bitos saludables de comunicaci√≥n de equipos remotos</a></li>
<li><a href="../es429952/index.html">El pasado, presente y futuro de Docker y otros tiempos de ejecuci√≥n de contenedores en Kubernetes</a></li>
<li><a href="../es429954/index.html">El programador para los corredores de apuestas irlandeses.</a></li>
<li><a href="../es429958/index.html">Cinco reglas f√°ciles de depuraci√≥n para principiantes</a></li>
<li><a href="../es429960/index.html">10 razones por las que los clientes se dan de baja de un producto</a></li>
<li><a href="../es429964/index.html">U> X> I> P ... o "C√≥mo juegan los nombres de las profesiones salto de rana"</a></li>
<li><a href="../es429966/index.html">Una descripci√≥n general de las t√©cnicas b√°sicas de adaptaci√≥n de dominio profundo (Parte 2)</a></li>
<li><a href="../es429968/index.html">La empresa de mensajer√≠a m√°s grande de China comienza a utilizar "camiones de ma√≠z" no tripulados para el transporte de mercanc√≠as.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
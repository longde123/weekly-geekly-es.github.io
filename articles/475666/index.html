<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌷 😝 🍫 50 consejos UX en realidad virtual 🌁 🔁 📔</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta lista ha sido compilada en base a varios de mis artículos y notas sobre cómo crear una experiencia de usuario en realidad virtual. El material se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>50 consejos UX en realidad virtual</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/475666/"><img src="https://habrastorage.org/webt/tg/su/wi/tgsuwi0exkxt2y9yhckaobodaa4.png"><br><br>  <i>Esta lista ha sido compilada en base a varios de mis artículos y notas sobre cómo crear una experiencia de usuario en realidad virtual.</i>  <i>El material se creó como una especie de conjunto de recomendaciones adicionales para los nuevos especialistas de Modum Lab que se dedican a la creación de sistemas de interacción en proyectos de realidad virtual (principalmente para HTC Vive y soluciones independientes).</i>  <i>En primer lugar, era necesario analizar temas como el uso de controladores, sistemas en movimiento, los aspectos específicos del desarrollo de elementos de interfaz, visualización de avatares y problemas de inmersión en general.</i> <br><a name="habracut"></a><br><h2>  Introduciendo VR </h2><br>  <b>1.</b> Agregue una pausa al comienzo de la simulación: deje que el usuario no haga nada durante unos segundos en la escena.  Esto permitirá que una persona se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">adapte</a> a un nuevo entorno y navegue en el espacio, y luego podrá concentrarse en la tarea.  No es necesario exigir de inmediato al usuario que haga nada: se trata de la falta de notificaciones, voz en off y cualquier animación.  La apariencia misma de la escena se puede mostrar gradualmente.  Por ejemplo, salir del desvanecimiento, ensamblar a partir de fragmentos alrededor del usuario, etc., son opciones cuando el entorno virtual no aparece inmediatamente ante sus ojos. <br><br>  <b>2. Los</b> nuevos usuarios pueden verse en apuros para dar el primer paso real en realidad virtual.  Por lo tanto, junto con la capacitación para trabajar con el sistema de movimiento, por ejemplo, teletransportación, puede agregar la tarea del movimiento físico habitual en la escena. <br><br>  <b>3.</b> Al principio, los usuarios pueden no determinar muy bien la posición de los objetos en profundidad, por lo que al principio es mejor colocar elementos interactivos para que siempre estén a la distancia del brazo o, por el contrario, mucho más lejos que la posición original de la persona, de modo que quede claro que se deben tomar varios pasos al objeto <br><br><h2>  En movimiento </h2><br>  <b>4.</b> En la gran mayoría de los casos, si los usuarios están acunados en un proyecto, entonces el desarrollador tiene la culpa.  Hay muchas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">discusiones</a> sobre este tema, se ha creado una gran cantidad de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">variaciones</a> de los sistemas de movimiento en el espacio virtual, incluidas varias soluciones de nicho, por ejemplo, para que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tecnología</a> y los desarrolladores continúen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">explorando</a> este tema. <br><br>  Preste atención al estudio de este tema, ya que para diferentes tareas puede elegir la forma más adecuada de moverse en el espacio.  En este caso, la opción más común en el momento actual es moverse usando la teletransportación, es decir, mover instantáneamente al usuario en el espacio a través de la indicación de un punto para moverse usando el controlador o la dirección de visión.  La segunda mecánica popular es todo tipo de variaciones de vuelo. <br><br>  Justificación del uso y las opciones de implementación para la teletransportación en varios proyectos: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/DwZt2jRE8PY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/XMFQVYiuExo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <b>5.</b> El uso de la teletransportación en el proyecto puede ser superado narrativamente, así como en general construir el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">juego en</a> torno a tal "limitación". <br><br>  <b>6.</b> En realidad, hay muchos tipos de teletransportación en sí: esta es una teletransportación gratuita dentro de un área determinada de la escena, teletransportación a puntos determinados, efectos instantáneos y directos (a través del sombreado, secuencia de cuadros, movimiento rápido en línea recta a un punto determinado), etc. .  Todo depende del proyecto específico donde se implementa el proceso de movimiento. <br><br>  La teletransportación basada en zonas también <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">funciona</a> y puede percibirse mucho más fácilmente que la teletransportación clásica.  Esto es cuando el usuario no puede moverse a ningún punto en el espacio, sino a un conjunto específico de zonas definidas.  Pero estos no son solo puntos, es decir, áreas de espacio que corresponden a la zona de seguimiento y la posición del usuario en ella (lo que conduce a una serie de dificultades en el diseño de escenas). <br><br>  <b>7.</b> Al crear un sistema de teletransportación, vale la pena limitar la distancia máxima de movimiento utilizando un teletransporte.  Debido al hecho de que al usar gafas VR por primera vez, los usuarios a menudo se confunden con los botones del controlador, pueden moverse accidentalmente largas distancias, lo que causará una desorientación constante en el espacio: "¿dónde estoy y cómo llegué aquí?" <br><br>  <b>8.</b> Si decide implementar un sistema de movimiento libre, la forma clásica de controlar el movimiento de la cámara con los botones del controlador, haga una alternativa para la parte de la audiencia cuyo aparato vestibular no estará listo para esto. <br><br>  <b>9.</b> Con un sistema de movimiento libre, el efecto del mareo puede reducirse construyendo la estructura de la escena o el nivel del juego de modo que el usuario avance principalmente. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/c18R6Sb97nM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Proyecto de muestra usando un sistema de movimiento libre</i> <br><br><h2>  Controladores, manos y mostrar contenido interactivo </h2><br>  <b>10.</b> Si el controlador / mano toca el objeto interactivo, entonces el objeto en este momento se puede resaltar, lo que indica que ya es posible ir al siguiente paso: tómalo. <br><br>  <b>11.</b> Al tomar un objeto interactivo, el controlador / modelo de la mano generalmente está oculto.  No debe visualizar el controlador, que está medio inmerso en la geometría del objeto con el que interactúa el usuario. <br><br><img src="https://habrastorage.org/webt/3r/qs/p0/3rqsp0schoule0mhdek3pb0x18k.gif"><br>  <i>Proyecto de sala de exposición virtual para Pioneer Group of Companies (en adelante)</i> <br><br>  <b>12.</b> Si la interacción ocurre con la ayuda de modelos de manos y cuando tomas un objeto, las manos permanecen visibles, entonces necesitas desarrollar un conjunto único de posiciones de pincel para varios objetos para que cada objeto o categoría de objetos se vea orgánicamente en la mano.  Debe tenerse en cuenta que esto requerirá cierto tiempo y costos financieros con una ventaja no completamente obvia sobre la versión anterior, cuando el controlador o la mano <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desaparece</a> mientras toma el objeto (una situación ligeramente diferente puede ser con Oculus Touch debido a su ergonomía). <br><br><blockquote>  Me gusta la opción con visualización constante de las manos más desde la posición de correlacionarse con una imagen específica de un avatar virtual.  Incluso simplemente a través de la visualización de las manos, puede indicar que se le ofrece un rol, por ejemplo, un robot o un fantasma.  Y si las manos no desaparecen al interactuar con los objetos, entonces esta conexión está constantemente presente.  Pero no estoy seguro de que esto afecte la sensación de nuestras propias manos en la realidad virtual de alguna manera más fuerte que si solo visualizáramos los objetos que sujetamos con nuestras manos.  Aquí hay un ejemplo de lo que piensan los desarrolladores de Job Simulator: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">youtu.be/hjc7AJwZ4DI?t=1795</a> </blockquote><br>  <b>13.</b> Los botones laterales del controlador HTC Vive deben usarse solo cuando sea absolutamente necesario, pero es mejor no usarlo en absoluto.  Estos son controles bastante obvios en este sistema. <br><br>  <b>14. Cuantos</b> menos botones de controlador estén involucrados en el proyecto, mejor.  Por ejemplo, puede usar el método de captura basado en zonas para interactuar con objetos con un solo botón de controlador.  Esto funciona en algunos casos cuando necesita mover objetos en un área limitada (un mouse sobre una alfombra en una mesa que se puede mover dentro de la alfombra en Job Simulator). <br><br>  En otros casos, debe desarrollar casos separados para esta afección.  Por ejemplo, se introduce una entidad en el proyecto: el área de tomar y devolver un objeto.  Cuando hay una zona separada donde se toma el objeto presionando el gatillo y reemplaza el controlador, después de lo cual el uso posterior del gatillo activa la lógica de este objeto.  Al regresar a la zona de retorno con un clic, el objeto permanece en esta área y el controlador se visualiza nuevamente.  Este enfoque reducirá la cantidad de botones utilizados para tipos similares de acciones (activación de objetos - captura y uso).  De lo contrario, es necesario colocar la captura de objetos funcional en un botón y usarla en el otro, lo que generará preguntas sobre cómo lidiar con otras acciones, que también requieren botones, por ejemplo, para teletransportarse. <br><br>  <b>15.</b> Si visualiza sus manos, es mejor superar su finalización: vaya a la transparencia o use el efecto de "guantes vacíos" cuando cree un guante que tome la forma de una mano, pero no hay nada dentro si mira desde el lado del puño. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/mGrYTB39-c4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Un ejemplo de un corte de geometría convencional sin ningún estilo.</i> <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/ua_IR6-wcLs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Usando el desvanecimiento (dejando en transparencia)</i> <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/CSQyTPzzTRk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Ejemplo de guante</i> <br><br>  <b>16.</b> No haga una visualización realista de las manos, casi siempre no se ve muy bien. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/gQXHNzlKxsc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Presta atención al tipo de mano que toma la llave</i> <br><br>  <b>17. La</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transparencia de las manos</a> resuelve el problema de "efímero", cuando el usuario puede pasar a través de la geometría de la escena con la mano.  Además, en el momento de la intersección de la geometría con una mano opaca ordinaria, puede batir el borde de corte utilizando cualquier efecto (holograma, pasar a la transparencia cerca de la línea de corte, etc.), esto también aliviará el problema de retroalimentación. <br><br>  <b>18.</b> La generación actual de controladores de movimiento para VR tiene una ventaja muy poderosa sobre los dispositivos de entrada clásicos: un umbral de entrada bajo debido a la simplicidad de los controladores de dispositivo y la forma en que se utilizan en los proyectos.  Estamos hablando de gestos naturales y movimientos corporales.  Por ejemplo, tomamos una dona del controlador, nos la llevamos a la boca, reproducimos la animación de morder una pieza y llenamos la vida del personaje.  O recargue una pistola cuando necesite sacar una revista e instalar una nueva.  O inicie el juego mediante la instalación de un cassette con guardar en una grabadora y presionando el botón Reproducir.  Además del hecho de que tales acciones son muy comprensibles, ya que se usan en el mundo real, también se convierten en una parte más sustancial del juego y de la experiencia del nuevo usuario en su conjunto. <br><br>  Pero hay un problema interesante de tales soluciones, no tanto en el campo de los juegos en realidad virtual, sino en la dirección no relacionada con los juegos: esta es la velocidad. <br><br><blockquote>  Es necesario correlacionar los pros y los contras de varios enfoques dentro del marco del sistema de interacción del usuario con el entorno interactivo en proyectos específicos. </blockquote><br>  En algunos casos, la velocidad será un factor decisivo (hacer clic en una dona usando un rayo láser proveniente del controlador), en otro, el proceso de interacción física transferido desde el mundo real será importante (acércate, levanta la dona con tu mano y llévala a la cara para que se reproduzca la animación de comer) .  Por ejemplo, la transición a métodos de control más abstractos puede justificarse por la frecuencia de tales interacciones. <br><br>  <b>19.</b> Los usuarios quieren interactuar con todo lo que tengan a su alcance si parece un objeto que parece que puedes tomar o hacer clic.  Es importante cumplir con sus expectativas, teniendo en cuenta esta especificidad al diseñar y llenar objetos con una escena.  Por ejemplo, para colocar solo objetos interactivos en la zona de alcance, no para colocar objetos estáticos e interactivos en un área, etc. <br><br>  Otra forma de resolver este problema es establecer una indicación visual clara para los objetos interactivos (marcadores animados que aparecen en objetos interactivos con el brazo extendido). <br><br><img src="https://habrastorage.org/webt/0g/5s/sd/0g5ssduuyiz5est09et1bfplsx0.gif"><br><br>  <b>20.</b> En el momento en que mantiene presionado el botón de teletransporte, puede hacer visibles varios indicadores de puntos de interés en áreas que el usuario aún no ha visitado. <br><br>  <b>21.</b> La solución al problema de levantar objetos en el piso para que los usuarios no golpeen a los controladores reales en el piso real: si el objeto cayó al piso, entonces se eleva un poco cuando una mano se estira hacia él.  Es importante crear una indicación visual adicional del proceso de "levitación" del objeto, para que esto no desoriente al usuario. <br><br>  Otra opción es hacer posible "magnetizar" los objetos caídos cuando el haz del controlador se cierne sobre ellos. <br><br>  La versión clásica para simulaciones en las que no se supone que se mueva con el objeto es restablecer la posición cuando, al caer al suelo, el objeto aparece en el lugar donde se encontraba originalmente. <br><br><h2>  Consejos </h2><br>  <b>22.</b> Un solo incentivo para enfocar al usuario en el área deseada de la escena puede no ser suficiente, es mejor usar varias herramientas a la vez: animación en el área misma, luz, indicación del área de los caracteres, voz y texto, etc.  También vale la pena considerar que el comportamiento de los objetos (animaciones) en una escena atrae más atención que la voz o el texto. <br><br>  <b>23. Las</b> instrucciones para manipulaciones complejas con controladores son difíciles de percibir si el controlador en sí y los botones a presionar no son visibles.  Por lo tanto, en las primeras etapas del conocimiento de la administración, es mejor mostrarlos de una forma u otra.  Por ejemplo, las manos del usuario aparecen en el modelo, reemplace el pincel, los controladores se visualizan en el espacio al lado de la mano / objeto tomado. <br><br><img src="https://habrastorage.org/webt/hr/sc/hy/hrschyqwyo2ycj2up3efinlsorw.gif"><br><br>  <b>24.</b> Las ventanas emergentes en movimiento funcionan bien cuando una ventana en un lugar para levantar un objeto en su mano se mueve visualmente a otro lugar donde este objeto necesita ser instalado / movido. <br><br><h2>  Colocación de controles, menú principal </h2><br>  <b>25.</b> El menú principal es lo primero que ve un usuario en un proyecto, no se puede colocar en un vacío sobre un fondo negro, es mejor pasar un poco de tiempo en un entorno abstracto, que ya será mejor que la ausencia total de espacio. <br><br><img src="https://habrastorage.org/webt/xz/t2/wd/xzt2wdeq2aassuntlmewm-mf8zi.jpeg"><br>  <i>Simuladores inmersivos Plataforma de carga de escena sin elementos de interfaz</i> <br><br>  Pero esto tampoco es siempre suficiente.  El menú puede reflejar el concepto del proyecto, en el sentido literal del lobby antes de ir directamente a la simulación.  En los juegos, esto se ha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">usado</a> durante mucho tiempo, pero en todo tipo de servicios, este aspecto recibe muy poca atención. <br><br>  <b>26.</b> Si la carga entre escenas dura mucho tiempo, es mejor asignar tiempo para crear una "sala de espera", un espacio que puede asociarse visual y conceptualmente con el menú principal u otras escenas en el proyecto donde el usuario está esperando que se cargue el nivel. <br><br>  <b>27.</b> Asociar la interfaz con el espacio de la escena.  Incluso si este es el panel del menú principal que cuelga en el espacio, justifique su existencia en el entorno: puede ser un proyector que muestre un holograma en la escena, reflejo o luz del holograma en los elementos del entorno, etc. <br><br><blockquote>  El concepto de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">interfaces diegéticas es</a> ideal para la realidad virtual, ya que mejora el efecto de la autenticidad de lo que sucede debido a la ubicación espacial y la justificación narrativa. </blockquote><br>  <b>28.</b> Al crear el espacio de trabajo de un usuario para la interacción a largo plazo con elementos de la interfaz, uno debe olvidarse de los estereotipos de las películas de ciencia ficción como "Minority Opinion"; no coloque elementos interactivos para la interacción con los controladores a nivel de la vista; esto es muy agotador para brazos y hombros.  Divida el espacio en el área de información en el nivel superior del cuerpo y el área de interacción en el nivel del abdomen del usuario, donde en el primer caso se ubicarán todo tipo de pantallas de estado, notificaciones, campos de entrada y, en el segundo, bloques interactivos, teclados, elementos de menú, etc. <br><br>  <b>29. Por</b> si acaso, es mejor aclararlo: evite adjuntar elementos de interfaz a la cámara del usuario.  En este caso, puede colocar dichos elementos a una pequeña distancia frente a la cámara y establecer la posibilidad de moverse detrás de ella con cierta inercia. <br><br>  <b>30. No</b> siempre es apropiado visualizar botones y otras herramientas en forma de objetos reales en el espacio de la escena, como botones físicos tridimensionales, palancas, etc.  En los paneles virtuales, no hay nada de malo si la retroalimentación de alta calidad está configurada en las acciones del usuario: los botones responden a la guía, al presionar, por ejemplo, se resaltan, cambiar en profundidad, responder a la presión, etc. <br><br>  Es conveniente colocar los controles alrededor de los controladores, como se hace en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tilt Brush</a> , la forma de presentar la interfaz en forma de un análogo de una tableta en la mano, donde se encuentra la interfaz 2D habitual, funciona aún más intuitiva y claramente para el usuario. <br><br><blockquote>  La relevancia de una solución depende de los detalles del proyecto. </blockquote><br>  <b>31.</b> A menudo puede encontrar una solución con la colocación de controles en la muñeca en forma de holograma o algún tipo de panel similar a un reloj inteligente.  Aquí es importante no sobrecargar la funcionalidad de una unidad de interfaz de este tipo; es difícil mantener la mano en el peso para interactuar con elementos interactivos.  Esta solución es ideal para todo tipo de notificaciones y conjuntos simples de acciones. <br><br><h2>  Avatares en primera persona </h2><br>  <b>32.</b> Cuando se trata de visualizar el avatar de un usuario en primera persona en cualquier estilo realista, sigue siendo la forma estándar de mostrar parcialmente el avatar cuando solo se muestran las partes del cuerpo que se muestran, es decir,  esencialmente solo se visualizan las manos.  Esto le permite resolver el problema del desajuste de la posición del cuerpo real y virtual del usuario durante el movimiento. <br><br>  <b>33.</b> Hay proyectos en los que el avatar está en una posición estática, por ejemplo, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">carreras</a> y otros simuladores.  En este caso, es posible visualizar todo el cuerpo del avatar sin ninguna dificultad especial: el propio usuario puede ajustarse a la posición del personaje virtual, "sincronizando" los cuerpos real y virtual. <br><br>  <b>34.</b> Sí, hay proyectos sin sistemas de seguimiento del cuerpo adicionales, donde se visualiza todo el cuerpo del avatar.  En algunos de estos proyectos, esto ni siquiera se hace tan terriblemente (a menudo, estos son juegos de acción donde las inconsistencias se suavizan debido a la dinámica del juego).  Sin embargo, si decides visualizar todo el cuerpo del avatar en primera persona, entonces debes pensar en diseñar el avatar en sí mismo: personajes como robots, personajes de dibujos animados pueden suavizar la situación aquí. <br><br><blockquote>  Una narración también ayudará aquí: si el sistema de seguimiento no permite que el avatar virtual repita el movimiento de todo el cuerpo real, como es el caso de las gafas de Oculus, Sony y HTC, entonces puede ir hacia otro lado.  Es decir  No intente demostrarle al usuario que su cuerpo virtual es real, sino designar al avatar, por ejemplo, como parte del sistema de control remoto con el que el usuario interactúa, golpeándolo visual y narrativamente. <br><br>    ,       ,       “”,       .  ,             ,         ,   - ,             . </blockquote><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">35.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mientras personalizas tu avatar, </font><font style="vertical-align: inherit;">nadie ha encontrado una </font><font style="vertical-align: inherit;">solución mejor, como usar un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">espejo virtual</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Pero hay otras alternativas, que van desde el uso de artículos de vestuario o EPP en simulaciones de seguridad en "maniquíes" condicionales durante la selección del conjunto correcto dentro del marco de la regulación, que termina con paneles clásicos con objetos de inventario. </font><font style="vertical-align: inherit;">En cualquier caso, se recomienda agregar soporte de sonido al usar el artículo: el sonido de la tela, guantes protectores, cascos, etc.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Avatares y redes </font></font></h2><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">36.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El usuario en primera persona solo ve sus manos, pero otros usuarios en la escena pueden ver el avatar completamente visualizado de su interlocutor, ya que el desajuste entre el movimiento del cuerpo real y virtual no es tan crítico para el observador como para el propietario del cuerpo virtual. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">37.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Si hablamos del estilo de los avatares para la interacción en red, es mejor </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">abandonar</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> la imagen realista de las personas para suavizar un posible problema con el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Valle Siniestro"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> debido al conflicto del movimiento realista debido al sistema de seguimiento y la falta de seguimiento de las expresiones faciales, los ojos y otras partes del cuerpo. El uso de estilos visuales no fotorrealistas es más apropiado aquí. Pero esto </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no siempre será así</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/dr_04PCSDWE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/PGkF1xM-xo0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><blockquote>      .  (  )   ,      .       ,       .         ,    ,            ,    ,          . </blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un tema separado es la visualización de avatares de red en simulaciones de entrenamiento, pero requiere una discusión sustantiva en cada caso específico. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">38.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Además de la visualización exagerada, los desarrolladores a menudo intentan superar el momento con rostros y expresiones faciales de los avatares de los usuarios, ocultando sus rostros con gafas, máscaras y trajes espaciales. Esto se hace tanto para ahorrar recursos como para compensar la imposibilidad de rastrear las expresiones faciales. Si encaja en el concepto del proyecto, por supuesto. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">39)</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si hay avatares de usuarios con la posibilidad de comunicación por voz, debe haber un lipSink o su análogo para la visualización del habla, cuando el avatar tiene una boca oculta o no se supone que su animación. </font><font style="vertical-align: inherit;">Una de las opciones es resaltar (nuevamente, si el estilo lo permite) o mostrar un indicador adicional como un elemento de la interfaz de usuario, que a menudo se duplica incluso con un enlace de labios. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">40.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Hay muchas maneras de mejorar el efecto de la presencia social trabajando en los avatares de los usuarios:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Agregue animación intermitente a sus avatares: esto animará enormemente a los personajes de la escena. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Las animaciones adicionales de accesorios que responden al movimiento del cuerpo funcionan bien. </font></font></li><li>  ,   —    ,      ,       .    ,       ,       ,             . </li></ul><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">41.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> No puede interrumpir el proceso de movimiento de los avatares de los usuarios. </font><font style="vertical-align: inherit;">Si se utiliza el seguimiento del cuerpo: los usuarios ven cómo se mueven los avatares de otras personas según la posición de los controladores, entonces no puede interceptar movimientos en este proceso para reproducir animaciones adicionales de los cuerpos de los avatares que no están conectados con una persona real, esto funcionará para destruir el efecto de la presencia social. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">42.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Si la funcionalidad principal en un proyecto con interacción de red es la comunicación entre usuarios (chat analógico) y el sistema móvil en su conjunto no se requiere en esta simulación, entonces la opción más efectiva es colocar los avatares en una mesa donde todas las herramientas de comunicación se encuentran a distancia .</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Misceláneo </font></font></h2><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">43.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Si el usuario inicializa la transición de una escena a otra, a menudo se utilizan varias metáforas para esto. </font><font style="vertical-align: inherit;">Por ejemplo, las esferas de niveles que el usuario toma con el controlador y lleva a la cabeza, esencialmente penetrando en su espacio. </font><font style="vertical-align: inherit;">Otro ejemplo son las gafas de realidad virtual dentro de la realidad virtual, que son necesarias para moverse a otro espacio.</font></font><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Sb1efNYhkGI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Esto es, por un lado, una justificación razonablemente clara para la transición y, por otro, una técnica inmersiva. </font></font></blockquote><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">44. El</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> usuario es libre de moverse en el espacio real de su habitación y es más probable que cruce objetos virtuales. </font><font style="vertical-align: inherit;">Una de las opciones para superar esta situación es eliminar la "materialidad" de la geometría intersectada para que no parezca sólida y estilizar el momento de la intersección para que el corte de la geometría no se lea como un error:</font></font><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/At_Zac4Xezw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Esto es similar a la situación con un corte de la geometría del modelo de mano cuando se cruza con objetos en la escena. </font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Opcionalmente, también puede usar estilización, que muestra la estructura interna del objeto. </font><font style="vertical-align: inherit;">No necesariamente realista, posiblemente exagerado y cómico, si la configuración lo permite. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">45.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A veces los usuarios van más allá de los límites de la escena misma, por ejemplo, a través de la pared de una sala virtual. </font><font style="vertical-align: inherit;">En tales casos, la mayoría de las veces la imagen simplemente se desvanece, a veces el usuario se teletransporta automáticamente, y esta puede no ser una muy buena opción debido a la pérdida de orientación en el espacio. </font><font style="vertical-align: inherit;">Para evitar esto, hay una </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">solución</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bastante interesante </font><font style="vertical-align: inherit;">de HUGE ROBOT como parte del proyecto Freedom Locomotion System.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En el momento de la intersección, la cuadrícula del sistema de seguimiento se visualiza en el espacio, mostrando el área física para moverse y resaltando la silueta del objeto dentro del cual se encuentra el usuario. </font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pero ir más allá de los límites de la escena puede ser superado como parte de la narrativa, el escenario o incluso convertirse en parte de la mecánica del juego. </font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por ejemplo, puede colocar geometría de escena adicional detrás de las paredes del nivel del juego, diseñando el nivel como decoración. </font><font style="vertical-align: inherit;">O puede crear el efecto de moverse a otro espacio mientras sale de la escena, o puede castigar a un jugador al salir del espacio virtual después de un tiempo (si no estaba accidentalmente detrás de la pared y tratando de eludir las reglas del juego): la única pregunta es la relevancia de los datos recepciones en un proyecto específico. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">46)</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un caso especial de un tema con un entorno interactivo se refiere al desarrollo de casos para puertas cerradas, ya que existe un acuerdo tácito con el usuario de que si una puerta tiene una manija, puede intentar abrirla. </font><font style="vertical-align: inherit;">Una manija se cae en la puerta, la puerta se abre, pero hay una pared de ladrillos o una cuadrícula estilizada de espacio tridimensional sin detalles, etc. (si tales técnicas son consistentes con el concepto del proyecto).</font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Estas pequeñas cosas son un ejemplo del nivel necesario de atención a la experiencia del usuario que mejora la inmersión. </font></font></blockquote><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">47.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Si decide utilizar la imagen ya clásica de un robot robot volando en el espacio como asistente de usuario acompañante, aquí hay algunos consejos sobre cómo hacerlo más atractivo y animado:</font></font><br><br><ul><li>                ; </li><li>         (,       ); </li></ul><br><img src="https://habrastorage.org/webt/vx/cn/4z/vxcn4zawvwhps_tblvhp4e1f8ja.gif"><br><br><img src="https://habrastorage.org/webt/p2/6l/gy/p26lgym1flwugheztgroaxrtq3y.gif"><br><br><ul><li>      ,     , -        ,   ; </li><li>          ,         ,           . </li></ul><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">48. El</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> usuario en la realidad virtual sigue siendo él mismo, jugar para un personaje es un juego de rol, y en este entorno virtual, puede probar el papel del personaje, para el que necesita estar preparado de antemano, u obtener una explicación razonable de cómo él, siendo él mismo Yo mismo, terminé en el espacio virtual: escribí sobre esto en una nota separada sobre </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">romper la cuarta pared</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> en la realidad virtual. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esta posibilidad de la destrucción completa de la cuarta pared se puede usar en algunos proyectos para mejorar la inmersión en la simulación: crear una conexión entre el mundo real y el entorno virtual, explicar cómo el usuario terminó en este espacio, superar la existencia de gafas VR de forma narrativa y visual. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">49)</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En proyectos en tercera persona en realidad virtual, es conveniente construir un sistema clásico de movimiento y combate durante el movimiento del personaje cuando el jugador es un observador invisible, que está directamente dentro del entorno virtual. Aquí el problema de la cinetosis también desaparece con las acciones activas del personaje en la escena. El cambio a la primera persona en tales proyectos puede ocurrir en casos especiales: en diálogos o al interactuar con el entorno, por ejemplo, resolviendo acertijos, como se hace en exclusiva para Oculus Rift </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chronos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y juegos similares. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otro ejemplo bastante inusual se relaciona con el desarrollo no relacionado con el juego. . Implementamos la transición de la primera persona a la tercera en el proyecto de interacción de red para Vive al teletransportar el avatar del usuario a las sillas en las escenas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Durante la teletransportación a una silla virtual, colocamos un avatar de usuario sobre ella, y la cámara virtual, el punto de vista, se desplazó detrás del modelo de personaje a la misma altura que la cabeza real del usuario, pero girando la cámara para que mire la parte posterior de la cabeza en busca de un avatar. En este modo, el usuario puede moverse por separado de su representación virtual, que no responde a sus movimientos, hasta que el usuario decida teletransportarse desde la silla en algún lugar de la escena, luego se restablecerá la sincronización entre el personaje y la cámara / usuario. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esta forma simple no interrumpe la sincronización de la cámara con la posición real de la cabeza y conserva la funcionalidad existente de la posible ubicación de los personajes virtuales en las sillas.</font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este es un efecto bastante interesante, que no está en proyectos con el control predominante de terceros con el cambio al primero; aquí está, acostumbrándose a percibir una escena virtual directamente desde los ojos del personaje, como si se separara de su cuerpo virtual y comenzara a percibirlo desde un lado, estando detrás en la silla avatar. </font><font style="vertical-align: inherit;">En este caso, no hay desorientación en el espacio, como podría parecer, al instante todo se aclara, quién eres, dónde estás y quién es el personaje frente a ti. </font><font style="vertical-align: inherit;">Aunque, además, aún discutimos un indicador separado sobre el avatar del usuario, que fue él quien, en general, eliminó cualquier riesgo de perder el foco.</font></font><br></blockquote><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">50.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Por separado, sobre el sonido de un pequeño conjunto de recomendaciones en un bloque.</font></font><br><br><ul><li>    ,         —   ,      ,          —        . </li><li>         .          , ,   ,        ,             .       ,    . </li><li>       — . </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El sonido puede trabajar junto con elementos de guía, moviéndose en el espacio de la escena para enfocar al usuario en el área deseada. </font></font></li></ul><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PD: Inicialmente, el artículo fue publicado en un blog corporativo, pero creo que aquí en los centros temáticos también puede ser interesante para aquellos que están familiarizados con el tema del desarrollo de sistemas de interacción para la realidad virtual.</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/475666/">https://habr.com/ru/post/475666/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../475652/index.html">Cómo desarrollamos una aplicación móvil en Aurora OS (Sailfish Mobile OS RUS)</a></li>
<li><a href="../475656/index.html">Una revisión de la actividad de virus para dispositivos móviles en octubre de 2019</a></li>
<li><a href="../475658/index.html">¿Por qué ir a DevOpsDays? ¿Y por qué esta no es otra conferencia de DevOps?</a></li>
<li><a href="../475660/index.html">Una nueva palabra en mochilero: conozca el modelo de pantalla de píxeles: mi experiencia e impresiones LED</a></li>
<li><a href="../475662/index.html">Los errores más vergonzosos en mi carrera como programador (en este momento)</a></li>
<li><a href="../475668/index.html">Quemarse Recuperarse Comienza de nuevo. O no?</a></li>
<li><a href="../475672/index.html">Escribir un chat en Python y Django</a></li>
<li><a href="../475674/index.html">Sobre el mercado del trabajo completamente remoto sin una foto de la playa</a></li>
<li><a href="../475676/index.html">Insight-Driven: análisis avanzado y gestión del ciclo de vida de los modelos de aprendizaje automático</a></li>
<li><a href="../475678/index.html">Cómo enseñamos a los proveedores de leche de alfabetización informática</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
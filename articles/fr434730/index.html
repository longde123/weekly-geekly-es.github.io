<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßü üíÖüèª üêπ Bases de donn√©es en m√©moire: application, mise √† l'√©chelle et ajouts importants üëµüèª ‚õ≥Ô∏è ü•ü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous continuons d'exp√©rimenter avec les formats des mitaps. R√©cemment, dans un ring de boxe, nous sommes entr√©s en collision avec un bus de donn√©es ce...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bases de donn√©es en m√©moire: application, mise √† l'√©chelle et ajouts importants</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/psb/blog/434730/">  Nous continuons d'exp√©rimenter avec les formats des mitaps.  R√©cemment, dans un ring de boxe, nous sommes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">entr√©s en collision avec un</a> bus de donn√©es centralis√© et un maillage de service.  Cette fois, nous avons d√©cid√© d'essayer quelque chose de plus paisible - StandUp, c'est-√†-dire un microphone ouvert.  Le sujet a √©t√© choisi dans la base de donn√©es en m√©moire. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ffd/790/486/ffd790486ff5792ffd1bbebb3cc69be0.png"><br><br>  Dans quels cas dois-je passer en m√©moire?  Comment et pourquoi √©voluer?  Et √† quoi vaut-il attention?  Les r√©ponses se trouvent dans les discours des orateurs, que nous couvrirons dans cet article. <br><a name="habracut"></a><br>  Mais d'abord, imaginez les haut-parleurs: <br><br><ul><li>  Andrey Trushkin, directeur du Centre pour l'innovation et les technologies avanc√©es de Promsvyazbank <br></li><li>  Vladislav Shpileva, d√©veloppeur Tarantool <br></li><li>  Artyom Shitov, architecte de la solution GridGain <br></li></ul><br><h2>  Passer en m√©moire </h2><br>  Les tendances actuelles du march√© financier imposent des exigences beaucoup plus strictes sur le temps de r√©ponse et le fonctionnement de l'automatisation des processus en g√©n√©ral.  De plus, presque toutes les plus grandes institutions financi√®res cherchent aujourd'hui √† construire leurs propres √©cosyst√®mes. <br><br>  √Ä cet √©gard, nous voyons par nous-m√™mes deux applications principales des solutions en m√©moire.  Le premier est la mise en cache des donn√©es d'int√©gration.  Selon le sc√©nario classique, dans les grandes entreprises, il existe plusieurs syst√®mes automatis√©s qui fournissent des donn√©es √† la demande de l'utilisateur.  Ou un syst√®me externe - mais dans ce cas, l'initiateur dans la plupart des cas est l'utilisateur.  Traditionnellement, ces syst√®mes stockaient des donn√©es structur√©es d'une certaine mani√®re dans la base de donn√©es, y acc√©dant √† la demande. <br><br>  Aujourd'hui, de tels syst√®mes ne r√©pondent plus aux exigences en termes de charge.  Ici, nous ne devons pas oublier les appels √† distance de ces syst√®mes par des syst√®mes grand public.  Cela implique la n√©cessit√© de revoir les approches de stockage et de pr√©sentation des donn√©es - aux utilisateurs, aux syst√®mes automatis√©s ou aux services individuels.  Sortie logique - stockage des donn√©es pertinentes utilis√©es par les services au niveau de la couche en m√©moire;  il existe de nombreux cas similaires r√©ussis sur le march√©. <br><br>  Ce fut le premier cas.  La seconde est efficace, d'un point de vue technique, la gestion des processus m√©tiers.  Les syst√®mes BPM traditionnels automatisent l'ex√©cution de certaines op√©rations conform√©ment √† un algorithme pr√©d√©fini.  Et dans de nombreux cas, des questions se posent: pourquoi ces syst√®mes ne sont-ils pas assez efficaces et assez rapides? <br><br>  En r√®gle g√©n√©rale, ces syst√®mes √©crivent chaque √©tape (ou un petit ensemble d'√©tapes, con√ßu comme une transaction commerciale) dans la base de donn√©es.  Ils sont donc li√©s au temps de r√©ponse et √† l'interaction avec ces syst√®mes.  D√©sormais, le nombre d'instances de processus m√©tier s'ex√©cutant simultan√©ment en temps r√©el repr√©sente des ordres de grandeur il y a plus de 10 ans.  Les syst√®mes modernes de gestion des processus m√©tier devraient donc avoir des performances nettement sup√©rieures et garantir l'ex√©cution des applications d√©centralis√©es.  De plus, aujourd'hui, toutes les entreprises s'orientent vers la formation d'un large environnement de microservices.  Le d√©fi est que diff√©rentes instances de processus m√©tier peuvent partager et utiliser efficacement les donn√©es op√©rationnelles.  Dans le cadre de l'orchestration, il est logique de les stocker dans une solution en m√©moire. <br><br><h2>  Probl√®me de r√©conciliation </h2><br>  Supposons que nous ayons un grand nombre de n≈ìuds et de services, qu'un certain nombre de processus m√©tier soient ex√©cut√©s, dont les actions sont mises en ≈ìuvre sous forme de microservices.  Pour am√©liorer les performances, chacun d'eux commence √† √©crire son √©tat dans une instance de m√©moire locale.  Nous obtenons un grand nombre d'instances locales.  Comment garantir la pertinence et la coh√©rence pour tous? <br><br>  Nous utilisons le zonage des zones en m√©moire.  Par exemple, selon le domaine d'activit√©.  Lorsque nous coupons un domaine m√©tier, nous d√©terminons que certains microservices / processus m√©tier ne fonctionnent que dans le cadre de la zone responsable du domaine correspondant.  De cette fa√ßon, nous pouvons acc√©l√©rer la mise √† jour du cache et l'ensemble de la solution en m√©moire. <br><br>  Dans le m√™me temps, le cache responsable du domaine fonctionne en mode de r√©plication compl√®te - le nombre limit√© de n≈ìuds en raison de la distribution entre les domaines garantit la vitesse et l'exactitude de la solution dans ce mode.  Le zonage et la fragmentation maximale aident √† r√©soudre les probl√®mes de synchronisation, de fonctionnement du cluster, etc.  sur un grand nombre total de n≈ìuds. <br><br>  Naturellement, des questions se posent souvent sur la fiabilit√© des solutions en m√©moire.  Oui, tout ne peut pas y √™tre mis.  Afin d'assurer la fiabilit√©, nous avons toujours des bases de donn√©es √† c√¥t√© de la m√©moire.  Par exemple, pour les probl√®mes importants de reporting qui doivent √™tre regroup√©s, ce qui peut √™tre difficile sur un grand nombre de n≈ìuds.  Alors quelle est notre vision aujourd'hui: la <i>synergie des deux approches</i> . <br><br>  Il convient √©galement de noter que ces deux approches ne sont pas non plus enti√®rement correctes uniquement pour le contraste.  Et en m√™me temps, concentrez-vous sur eux.  Les fabricants et contributeurs de syst√®mes de virtualisation conteneuris√©s avanc√©s, tels que Kubernetes, nous offrent d√©j√† des options de stockage fiable √† long terme.  De bons cas industriels pour la mise en ≈ìuvre de solutions sont d√©j√† apparus, dans lesquels le stockage est effectu√© dans un tel format virtualis√©. <br><br>  L'un des plus grands journaux am√©ricains offre √† ses lecteurs la possibilit√© de recevoir en ligne tout num√©ro publi√© depuis le d√©but de la publication de ce journal au XIXe si√®cle.  On peut imaginer le niveau de charge.  Le stockage est mis en ≈ìuvre par eux via la plateforme Apache Kafka, d√©ploy√©e sur Kubernetes.  Voici une autre option pour stocker des informations et leur donner acc√®s sous une charge importante √† un grand nombre de clients.  Lors de la conception de nouvelles solutions, cette option m√©rite √©galement une attention particuli√®re. <br><br><h2>  Mise √† l'√©chelle des bases de donn√©es en m√©moire avec Tarantool </h2><br>  Supposons que nous ayons un serveur.  Il accepte les demandes, stocke les donn√©es.  Soudain, il y a plus de demandes et de donn√©es, le serveur cesse de faire face √† la charge.  Vous pouvez t√©l√©charger plus de mat√©riel sur le serveur et il acceptera plus de demandes.  Mais c'est une impasse pour trois raisons √† la fois: co√ªt √©lev√©, capacit√©s techniques limit√©es et probl√®mes de tol√©rance aux pannes.  Au lieu de cela, il y a une mise √† l'√©chelle horizontale: des ¬´amis¬ª viennent sur le serveur pour l'aider √† accomplir ses t√¢ches.  La r√©plication et le partitionnement sont les deux principaux types de mise √† l'√©chelle horizontale. <br><br>  La r√©plication, c'est quand il y a beaucoup de serveurs, ils stockent tous les m√™mes donn√©es et les demandes des clients sont dispers√©es sur tous ces serveurs.  C'est ainsi que l'informatique, et non les donn√©es, √©volue.  Cela fonctionne lorsque les donn√©es sont plac√©es sur un n≈ìud, mais il y a tellement de demandes de clients qu'un serveur ne peut pas les g√©rer.  De plus, la tol√©rance aux pannes est consid√©rablement am√©lior√©e ici. <br><br>  Le partage est utilis√© pour mettre √† l'√©chelle les donn√©es: de nombreux serveurs sont cr√©√©s et stockent des donn√©es diff√©rentes.  Vous mettez donc √† l'√©chelle les calculs et les donn√©es.  Mais la tol√©rance aux pannes dans ce cas est faible.  Si un serveur tombe en panne, une partie des donn√©es sera perdue. <br><br>  Il existe une troisi√®me approche: les combiner.  Nous divisons le cluster en sous-clusters, appelons-les ensembles de r√©pliques.  Chacun d'entre eux stocke les m√™mes donn√©es et les donn√©es ne se croisent pas entre les jeux de r√©plicas.  Le r√©sultat est la mise √† l'√©chelle des donn√©es, du calcul et de la tol√©rance aux pannes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/afe/63c/657/afe63c657f8ffb83527f4a5b298425a1.png"><br><br><h2>  R√©plication </h2><br>  La r√©plication peut √™tre de deux types: asynchrone et synchrone.  Asynchrone, c'est lorsque les demandes des clients n'attendent pas que les donn√©es soient dispers√©es sur les r√©pliques: l'√©criture sur une r√©plique suffit.  D√®s que les donn√©es sont arriv√©es sur disque, dans le journal, la transaction r√©ussit et un jour en arri√®re-plan ces donn√©es sont r√©pliqu√©es.  Synchrone - lorsqu'une transaction est divis√©e en 2 phases: pr√©paration et validation.  Commit ne renverra pas le succ√®s tant que les donn√©es ne seront pas r√©pliqu√©es vers un quorum de r√©plicas. <br><br>  La r√©plication asynchrone est √©videmment plus rapide car rien ne repose sur le r√©seau.  Les donn√©es seront envoy√©es au r√©seau en arri√®re-plan et la transaction elle-m√™me, telle qu'elle est enregistr√©e dans le journal, est termin√©e.  Mais il y a un probl√®me: les r√©pliques peuvent √™tre en retard l'une par rapport √† l'autre, d√©synchronis√©es. <br>  La r√©plication synchrone est plus fiable, mais beaucoup plus lente et plus difficile √† impl√©menter.  Il existe des protocoles complexes.  Dans Tarantool, vous pouvez choisir l'un de ces types de r√©plications, selon la t√¢che. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/32f/ca3/bd2/32fca3bd2ad0289626e48a5efc6a8e8d.png"><br><br>  Le d√©calage des r√©pliques entra√Æne non seulement la d√©synchronisation, mais aussi le probl√®me d'ignorance du ma√Ætre: il ne sait pas comment transmettre ses modifications √† la r√©plique.  Les modifications sont g√©n√©ralement apport√©es de mani√®re incr√©mentielle - elles sont appliqu√©es et, sous la m√™me forme, elles s'envolent vers la r√©plique.  Mais que faire avec eux si la r√©plique n'est pas disponible?  Par exemple, tout peut √™tre configur√© dans Tarantool, et l'assistant devient tr√®s flexible. <br><br>  Autre d√©fi: comment rendre la topologie complexe?  Mail.ru, par exemple, a une topologie avec des centaines de Tarantool.  Il poss√®de un noyau tarantool auquel les r√©pliques de tarentules pour les sauvegardes sont li√©es en cercle.  Dans Tarantool, vous pouvez cr√©er des topologies compl√®tement arbitraires, la r√©plication avec cela vit parfaitement. <br><br><h2>  Partage </h2><br>  Passons maintenant √† la mise √† l'√©chelle des donn√©es: le sharding.  Il peut √™tre de deux types: plages et hachages.  Le partage de plage est lorsque toutes les donn√©es sont tri√©es par une cl√© de partage, et cette grande s√©quence est divis√©e en plages de sorte que chaque plage a approximativement la m√™me quantit√© de donn√©es.  Et chaque plage est enti√®rement stock√©e sur un seul n≈ìud physique.  Mais g√©n√©ralement, un tel d√©coupage n'est pas n√©cessaire.  De plus, c'est toujours tr√®s compliqu√©. <br><br>  Il y a aussi des fragments avec des hachages.  Il vient d'√™tre pr√©sent√© dans Tarantool.  Il est beaucoup plus facile √† impl√©menter, √† utiliser et presque toujours adapt√© au lieu de plages de partage.  Cela fonctionne comme ceci: nous consid√©rons la fonction de hachage de l'enregistrement et elle renvoie le num√©ro du n≈ìud physique dans lequel stocker.  Il y a des probl√®mes: premi√®rement, il est difficile de terminer rapidement une requ√™te complexe. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dcc/eb9/f36/dcceb9f36f82f045eb0c461f0f934459.png"><br><br>  Deuxi√®mement, il y a le probl√®me du resharding.  Il existe une sorte de fonction de fragment qui renvoie le num√©ro du fragment physique dans lequel la cl√© doit √™tre enregistr√©e.  Et lorsque le nombre de n≈ìuds change, la fonction de partition change √©galement.  Cela signifie que pour toutes les donn√©es qui sont dans le cluster, elles devront √™tre recalcul√©es et v√©rifi√©es √† nouveau.  De plus, dans le partage classique, certaines donn√©es ne seront pas transf√©r√©es vers un nouveau n≈ìud, mais simplement m√©lang√©es entre les anciens n≈ìuds.  Les transferts inutiles ne peuvent pas √™tre r√©duits √† z√©ro dans le partage classique. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/479/b1f/4e4/479b1f4e48b552723c900d49a4104412.png"><br><br>  Tarantool utilise le partage virtuel: les donn√©es sont distribu√©es non pas sur des n≈ìuds physiques, mais sur des n≈ìuds virtuels.  Compartiment virtuel dans un cluster virtuel.  Et les histoires virtuelles sont pr√©sent√©es sur des histoires physiques.  Et d√©j√† l√†, il est garanti que chaque √©tage virtuel se trouve enti√®rement sur un √©tage physique. <br><br>  Comment cela r√©sout-il le probl√®me du resoldage?  Le fait est que le nombre de compartiments est fixe et d√©passe s√©rieusement le nombre de n≈ìuds physiques.  Ainsi, quelle que soit la taille physique de votre cluster, le bucket sera toujours suffisant pour stocker les donn√©es et les r√©partir uniform√©ment.  Et du fait que la fonction de partition n'est pas modifi√©e, vous n'aurez pas √† la recalculer lorsque la composition du cluster change. <br><br>  En cons√©quence, nous obtenons <i>trois types de partage: les plages, les hachages et les compartiments virtuels</i> .  Dans le cas des plages et des compartiments, il existe un probl√®me de recherche physique. <br><br>  Comment le r√©soudre?  La premi√®re fa√ßon: interdire simplement le resharding.  Ensuite, pour le resharding, vous devrez cr√©er un nouveau cluster et y transf√©rer tout.  La deuxi√®me fa√ßon: toujours aller √† tous les n≈ìuds.  Mais cela n'a pas de sens, car vous devez √©voluer, et les calculs ne √©voluent pas comme √ßa.  Troisi√®me option: un module proxy, qui fait office de routeur pour les buckets.  Vous le d√©marrez, vous y envoyez une demande, en indiquant le num√©ro du compartiment, et il envoie votre demande en tant que proxy au n≈ìud physique souhait√©. <br><br><h2>  M√©moire avanc√©e avec l'exemple de plate-forme GridGain </h2><br>  L'entreprise a des exigences de base de donn√©es suppl√©mentaires.  Il veut que tout cela soit tol√©rant aux fautes et catastrophique.  Il veut une haute disponibilit√©: pour que rien ne soit jamais perdu, pour que vous puissiez r√©cup√©rer rapidement.  Une √©volutivit√© facile et bon march√©, un support simple, une confiance dans la plate-forme et des m√©canismes d'acc√®s efficaces sont √©galement n√©cessaires. <br><br>  Toutes ces id√©es ne sont pas nouvelles.  Beaucoup de ces choses sont, √† un degr√© ou √† un autre, impl√©ment√©es dans des SGBD classiques, en particulier, la r√©plication entre les centres de donn√©es. <br><br>  In-Memory n'est plus une technologie de startup, ce sont des produits matures qui sont utilis√©s dans les plus grandes entreprises du monde (Barclays, Citi Group, Microsoft, etc.).  On suppose que toutes ces exigences sont remplies. <br><br>  Donc, si une catastrophe se produisait soudainement, il devrait y avoir une possibilit√© de r√©cup√©rer de la sauvegarde.  Et si nous parlons d'une organisation financi√®re, il est important que cette sauvegarde soit coh√©rente, et pas seulement une copie de tous les disques.  Pour qu'il n'y ait aucune situation o√π, sur certaines parties des n≈ìuds, les donn√©es ont √©t√© restaur√©es au moment X, et sur l'autre partie au moment Y. Il est tr√®s important d'avoir une r√©cup√©ration ponctuelle, de sorte que m√™me en cas de corruption de donn√©es ou d'accident particuli√®rement grave, minimisez la quantit√© de perte. <br><br>  Il est important de pouvoir envoyer des donn√©es sur disque.  Pour que le cluster ne tombe pas en surcharge et continue de fonctionner encore plus lentement.  Et pour sortir rapidement du disque, puis d√©j√† pomp√© les donn√©es en m√©moire. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/042/edc/328/042edc32872f7b8687bf5677818c712e.png"><br>  <i>R√©ponse en m√©moire aux plantages avec et sans composants de tol√©rance aux pannes GridGain</i> <br><br>  Un cluster de basculement doit √©voluer facilement horizontalement et verticalement.  Je n'ai pas envie de payer pour mon serveur et de regarder comment la moiti√© des ressources sont inactives.  Je ne veux pas avoir l'enfer sur des centaines de processus qui doivent √™tre g√©r√©s.  Je veux un syst√®me simple du point de vue du support, avec une entr√©e-sortie facile des n≈ìuds du cluster et un syst√®me de surveillance d√©velopp√© et mature. <br><br>  Consid√©rez MongoDB dans cette perspective.  Tous ceux qui ont travaill√© avec MongoDB connaissent un grand nombre de processus.  Si nous avons un MongoDB ombr√© de 5 fragments, alors chaque fragment aura un jeu de r√©pliques de trois processus (avec un taux de redondance de 3).  Et il s'agit de 15 processus uniquement sur les donn√©es elles-m√™mes.  Le stockage de configuration de cluster est un autre plus 3 processus, au total, il en obtient 18, et cela n'inclut pas les routeurs.  Si vous voulez 20 fragments, bienvenue en enfer sur 63+ (par exemple, 8 autres, 71 au total) processus. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/015/389/b64/015389b641f5babfe44815fd85f258cc.png"><br><br>  Comparez avec Cassandra.  Nous prenons tous les m√™mes 5 fragments - ce sont 5 processus et 5 n≈ìuds avec le m√™me taux de redondance de 3, ce qui est beaucoup plus simple en termes de contr√¥le.  Je veux 20 fragments - ce sont 20 processus.  Je peux adapter mon cluster √† n'importe quel nombre de n≈ìuds, pas n√©cessairement √† un multiple de 3 (ou √† une autre valeur du coefficient de redondance).  Beaucoup plus facile et moins cher √† mettre en ≈ìuvre et √† entretenir que les jeux de r√©pliques. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bcf/70d/4a4/bcf70d4a4883f9fdc951c871b99c57be.png"><br><br>  De plus, vous devez faire confiance au syst√®me pour comprendre ce que les gens soutiennent chaque produit individuel.  Id√©alement, la licence devrait √™tre open source ou open core.  Pour qu'en cas de d√©c√®s du vendeur, quelque chose puisse √™tre fait.  Il est √©galement bon que le code source soit g√©r√© par une communaut√© ind√©pendante - nous nous souvenons tous de la fa√ßon dont MongoDB et Redis ont chang√© de licence √† la demande de la soci√©t√© de gestion.  Comment Aerospike a introduit des restrictions sur l'√©dition communautaire ¬´open source¬ª au d√©but de l'ann√©e. <br><br>  Besoin d'un acc√®s efficace aux donn√©es.  Presque tous ont un langage de requ√™te structur√© sous une forme ou une autre.  Le plus souvent ils utilisent SQL, il faut que l'adaptation avec ce langage soit aussi simple que possible.  Cela aidera √† l'ex√©cution des requ√™tes distribu√©es, lorsque vous n'avez pas besoin d'envoyer une demande s√©par√©ment √† chaque n≈ìud, mais vous pouvez communiquer avec le cluster comme avec une ¬´fen√™tre unique¬ª.  Sans penser du point de vue de l'API, il s'agit d'un ensemble de n≈ìuds (rappelez-vous √† quel point il est difficile de travailler avec Memcache sur de gros volumes m√™me au niveau put / get le plus simple, sans requ√™tes SQL potentiellement complexes), DDL distribu√© et garanties ACID. <br><br>  Et enfin, le soutien.  Si quelque chose ne fonctionne pas soudainement, l'entreprise perd tout simplement de l'argent.  Pour certains domaines, ce n'est pas critique, mais il est souvent important que quelqu'un assume la responsabilit√© du produit et de son travail.  Qu'il √©tait possible √† tout moment de faire une r√©clamation, et cela a √©t√© rapidement r√©solu. <br><br>  Avec ce billet, nous terminons l'ann√©e de Promsvyazbank sur Habr√©.  Nous avons recueilli les v≈ìux du Nouvel An pour les habitants de Khabrovsk dans une courte vid√©o: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yqp6V3Wqniw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr434730/">https://habr.com/ru/post/fr434730/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr434720/index.html">Verso de la connaissance z√©ro: une porte d√©rob√©e dans zk-SNARK qui ne peut pas √™tre d√©tect√©e</a></li>
<li><a href="../fr434722/index.html">Douleur, pilules et deux ambulances, ou comment nous sommes tous mont√©s √† la cinqui√®me place IronStar 226 √† Sotchi</a></li>
<li><a href="../fr434724/index.html">Les agriculteurs chinois font du streaming en direct</a></li>
<li><a href="../fr434726/index.html">Pi√®ges li√©s √† l'identification d'un appareil Android</a></li>
<li><a href="../fr434728/index.html">Personnes et processus: pourquoi ne pas udalenka adapt√© √† chaque entreprise?</a></li>
<li><a href="../fr434732/index.html">La vie √† 6200 DPI. Examen du noyau HyperX Pulsefire</a></li>
<li><a href="../fr434734/index.html">Transformation de Fourier. Le rapide et le furieux</a></li>
<li><a href="../fr434736/index.html">Utilisation de la base de donn√©es des journaux Mikrotik pour supprimer la force brute</a></li>
<li><a href="../fr434738/index.html">Apprentissage par renforcement en Python</a></li>
<li><a href="../fr434740/index.html">Un r√©seau de neurones a appris √† d√©tecter les panneaux solaires dans les images satellites et √† pr√©dire le niveau de leur distribution</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
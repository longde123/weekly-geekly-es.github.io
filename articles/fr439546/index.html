<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ôüèª üè∞ üíÖüèº Les andro√Ødes r√™vent-ils de punk √©lectrique? Comment j'ai appris √† un r√©seau de neurones √† √©crire de la musique üèùÔ∏è ‚õ¥Ô∏è üôè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lors de cours d'apprentissage automatique √† Artezio, j'ai rencontr√© un mod√®le d'apprentissage qui pouvait faire de la musique. La musique est une part...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Les andro√Ødes r√™vent-ils de punk √©lectrique? Comment j'ai appris √† un r√©seau de neurones √† √©crire de la musique</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/439546/">  Lors de cours d'apprentissage automatique √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Artezio,</a> j'ai rencontr√© un mod√®le d'apprentissage qui pouvait faire de la musique.  La musique est une partie essentielle de ma vie, pendant de nombreuses ann√©es j'ai jou√© dans des groupes (punk rock, reggae, hip hop, rock, etc.) et je suis un auditeur fanatique. <br><br>  Malheureusement, de nombreux groupes, dont j'√©tais un grand fan dans ma jeunesse, se sont s√©par√©s pour diverses raisons.  Ou ils n'ont pas rompu, mais ce qu'ils enregistrent maintenant ... en g√©n√©ral, ce serait mieux s'ils se s√©paraient. <br><br>  J'√©tais curieux de savoir s'il existe maintenant un mod√®le pr√™t √† l'emploi qui peut apprendre sur les pistes d'un de mes groupes pr√©f√©r√©s et cr√©er des compositions similaires.  Puisque les musiciens eux-m√™mes ne sont plus tr√®s performants, peut-√™tre que le r√©seau de neurones peut les g√©rer? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/72f/844/01f/72f84401f2af035271021780fc848fe8.png"></div>  <a href="">Source</a> <br><a name="habracut"></a><br>  En √©tudiant les mod√®les finis, je suis rapidement tomb√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un tel article</a> avec un aper√ßu des six options les plus c√©l√®bres.  Il s'agit bien s√ªr des formats de musique num√©rique.  On peut voir dans l'article que deux approches principales de la g√©n√©ration de musique peuvent √™tre distingu√©es: bas√©e sur le flux audio num√©ris√© (le son que nous entendons des haut-parleurs - audio brut, fichiers wav) et bas√© sur le travail avec MIDI (notation musicale). <br><br>  J'ai abandonn√© les options avec du son brut, et c'est pourquoi. <br><br><ul><li>  Les r√©sultats ne sont pas impressionnants - l'utilisation de tels mod√®les pour la musique polyphonique donne un r√©sultat tr√®s sp√©cifique.  C'est inhabituel, vous pouvez cr√©er des peintures int√©ressantes, mais cela ne convient pas √† mes fins: cela semble √©trange, mais je voulais entendre quelque chose de similaire √† l'original. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5d9/229/364/5d9229364d98bee837d9bcf7cb3e1bac.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br>  Un bon exemple avec la musique pour piano: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Et avec la musique orchestrale ou le rock, √ßa sonne beaucoup plus √©trange: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Ici, les gars ont essay√© de traiter le Black Metal et pas seulement en audio brut. <br><br><ul><li>  Dans les compositions de mes groupes pr√©f√©r√©s, divers instruments sonnent - voix, batterie, basse, guitares, synth√©tiseurs.  Chaque instrument sonne avec le reste.  Je recherche un mod√®le qui agirait de la m√™me mani√®re, c'est-√†-dire qui fonctionnerait non seulement avec des instruments individuels, mais prendrait √©galement en compte leur son commun. <br><br>  Lorsqu'un musicien a besoin d'apprendre une partie d'un instrument √† l'oreille, il essaie d'isoler l'instrument dont il a besoin de l'ensemble du flux sonore.  Il r√©p√®te ensuite son son jusqu'√† ce qu'il obtienne un r√©sultat similaire.  La t√¢che n'est pas la plus facile, m√™me pour une personne ayant une bonne audition - la musique peut √™tre difficile, les instruments ¬´fusionnent¬ª. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dcd/5d1/8eb/dcd5d18eb46a6d383ffbc378d3fc7adb.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br>  Je suis tomb√© sur des outils logiciels qui ont essay√© de r√©soudre un probl√®me similaire.  Il existe plusieurs projets bas√©s sur l'apprentissage automatique.  Par exemple, pendant que j'√©crivais ce texte, Magenta a sorti un nouvel instrument, Wave2Midi2Wave, capable de ¬´prendre¬ª des notes de piano et de ¬´les reproduire¬ª de fa√ßon r√©aliste.  Il existe d'autres outils, bien qu'en g√©n√©ral cette t√¢che n'ait pas encore √©t√© r√©solue. <br><br>  Ainsi, afin d'apprendre une partie d'une ≈ìuvre, il est plus facile de prendre des notes toutes faites.  C'est le moyen le plus simple.  Il est logique de supposer qu'il sera plus facile pour les r√©seaux de neurones de travailler avec la repr√©sentation musicale de la musique, o√π chaque instrument est repr√©sent√© par une piste distincte. <br><br><ul><li>  Dans le cas de l'audio brut, le r√©sultat est un m√©lange de tous les instruments, les parties ne peuvent pas √™tre charg√©es individuellement dans le s√©quenceur (√©diteur audio), corrig√©es, modifi√©es le son, etc.  Je suis tr√®s content si le r√©seau de neurones compose un hit, mais fait une erreur dans quelques notes - lorsque je travaille avec des notes, je peux facilement les corriger, avec du son brut, cela est presque impossible. </li></ul><br>  La notation musicale a √©galement ses inconv√©nients.  Il ne prend pas en compte la masse des nuances de performances.  En ce qui concerne le MIDI, on ne sait pas toujours qui √©taient ces fichiers MIDI, √† quel point ils sont proches de l'original.  Peut-√™tre que le compilateur a simplement fait une erreur, car ce n'est pas une t√¢che facile de "supprimer" le jeu. <br><br>  Lorsque vous travaillez avec des notes polyphoniques, vous devez vous assurer que les instruments sont √† tout moment accord√©s.  De plus, il est important que la s√©quence de ces moments soit logique du point de vue humain de la musique. <br><br>  Il s'est av√©r√© qu'il n'y a pas tellement de solutions qui pourraient fonctionner avec des notes, et m√™me pas avec un instrument, mais avec plusieurs sons en m√™me temps.  J'ai d'abord ignor√© le projet Magenta de Google TensorFlow, car il √©tait d√©crit comme "non polyphonique".  A cette √©poque, la biblioth√®que MusicVAE n'√©tait pas encore publi√©e, donc je me suis install√© sur le projet BachBot. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b7/fef/993/2b7fef9935afb9f001bf954dd0fc097b.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br><h2>  Bachbot </h2><br>  Il s'est av√©r√© que la solution √† mon probl√®me existe d√©j√†.  √âcoutez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">joyeux anniversaire</a> accord√© par BachBot et sonnant comme un choral de Bach. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  La chorale est une musique sp√©cifique, elle se compose de quatre voix: soprano, alto, t√©nor et basse.  Chacun des instruments peut produire une note √† la fois.  Ici, vous devez aller un peu plus loin dans la musique.  Nous parlerons de musique dans la dimension des quatre quarts. <br><br>  Dans une notation musicale, une note a deux indicateurs - la hauteur (to, re, mi ...) et la dur√©e (entier, demi, huiti√®me, seizi√®me, trente seconde).  En cons√©quence, une note enti√®re dure un temps entier, deux demi-notes un temps entier, seize seizi√®mes un temps entier. <br><br>  Lors de la pr√©paration des donn√©es pour la formation du r√©seau neuronal, les cr√©ateurs de BachBot ont pris en compte les √©l√©ments suivants: <br><br><ul><li>  afin de ne pas abattre le mod√®le avec des accords de touches diff√©rentes, qui ensemble ne sonneraient pas harmonieusement, tous les chorals ont conduit √† la m√™me touche; </li><li>  le r√©seau neuronal doit √™tre aliment√© en valeurs discr√®tes, et la musique est un processus continu, ce qui signifie qu'une discr√©tisation est n√©cessaire.  Un instrument peut jouer une longue note enti√®re et l'autre en m√™me temps quelques seizi√®mes.  Pour r√©soudre ce probl√®me, toutes les notes ont √©t√© divis√©es en seizi√®mes.  En d'autres termes, si une quatri√®me note appara√Æt dans les notes, elle arrive quatre fois comme la m√™me seizi√®me entr√©e - la premi√®re fois avec le drapeau sur lequel elle a √©t√© press√©e et les trois fois suivantes avec le drapeau qu'elle continue. </li></ul><br>  Le format des donn√©es est le suivant - (hauteur, nouvelle note | continuation du son de l'ancienne note) <br><br>  (56, Vrai) # Soprano <br>  (52, Faux) # Alt <br>  (47, Faux) # T√©nor <br>  (38, Faux) # Basse <br><br>  Apr√®s avoir conduit tous les choraux de l'ensemble de donn√©es musical21 populaire √† travers cette proc√©dure, les auteurs de BachBot ont constat√© qu'il n'y a pas beaucoup de combinaisons de combinaisons de quatre notes dans les chorales (si vous les amenez √† la m√™me tonalit√©), bien qu'il semble qu'il puisse y avoir potentiellement 128 x 128 x 128 x 128 (128 niveaux de hauteur utilis√©s en midi).  La taille d'un dictionnaire conditionnel n'est pas si grande.  C'est une remarque curieuse, nous y reviendrons lorsque nous parlerons de MusicVAE.  Ainsi, nous avons les chorales de Bach enregistr√©s sous la forme de s√©quences de ces quatuors. <br><br>  On dit souvent que la musique est une langue.  Par cons√©quent, il n'est pas surprenant que les cr√©ateurs de BachBot aient appliqu√© la technologie populaire en NLP (Natural Language Processing) √† la musique, √† savoir qu'ils ont form√© le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©seau LSTM</a> sur l'ensemble de donn√©es g√©n√©r√© et ont obtenu un mod√®le qui peut compl√©ter un ou plusieurs instruments ou m√™me cr√©er des chorales √† partir de z√©ro.  Autrement dit, vous d√©finissez l'alt, le t√©nor et la basse, et BachBot ajoute la m√©lodie de soprano pour vous, et ensemble, cela ressemble √† Bach. <br><br>  Voici un autre exemple: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Sonne bien! <br><br>  Vous pouvez regarder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette vid√©o</a> plus en d√©tail.  Il y a l√† une analyse int√©ressante, collect√©e sur la base d'une enqu√™te sur le site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bachbot.com</a> <br><br>  Les utilisateurs sont encourag√©s √† distinguer les chorals originaux de Bach de la musique cr√©√©e par le r√©seau neuronal.  Les r√©sultats mentionnent que si un r√©seau de neurones cr√©e une partie basse pour tous les autres param√®tres, alors seulement la moiti√© des utilisateurs peuvent distinguer les chorales cr√©√©s par un r√©seau de neurones des originaux.  C'est dr√¥le, mais surtout les experts en musique se confondent.  Avec d'autres outils, les choses vont un peu mieux.  Cela me semble insultant en tant que bassiste - le violoniste semble √™tre n√©cessaire pour le moment, mais il est temps pour les bassistes de perfectionner leurs comp√©tences en cloisons s√®ches. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/701/bb9/cc6/701bb9cc6cdff8a20f0ede768324cd81.png"></div><br><h1>  Magenta </h1><br>  En √©tudiant BachBot, j'ai trouv√© qu'il √©tait inclus dans le projet Magenta (Google TensorFlow).  J'ai d√©cid√© de l'examiner de plus pr√®s et j'ai constat√© que dans le cadre de Magenta, plusieurs mod√®les int√©ressants ont √©t√© d√©velopp√©s, dont l'un est juste consacr√© √† travailler avec des compositions polyphoniques.  Magenta a fait ses merveilleux outils et a m√™me d√©j√† lanc√© le plugin pour l'√©diteur audio Ableton, ce qui est particuli√®rement agr√©able en termes d'application pour les musiciens. <br><br>  Mes favoris: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">beat blender</a> (cr√©e des variations sur une partie de batterie donn√©e) et <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">boucles latentes</a> (cr√©e des transitions entre les m√©lodies). <br><br>  L'id√©e principale de l'outil MusicVAE, que j'ai d√©cid√© d'utiliser, est que les cr√©ateurs ont essay√© de combiner le mod√®le et l'encodeur automatique variationnel - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VAE</a> sur le r√©seau LSTM. <br><br>  Si vous vous souvenez, dans une conversation sur Bach Bot, nous avons remarqu√© que le dictionnaire d'accords ne se compose pas d'√©l√©ments de 128x128x128x128, mais beaucoup moins.  Les cr√©ateurs de MusicVAE l'ont √©galement remarqu√© et ont d√©cid√© d'utiliser un espace latent compress√©. <br><br>  Soit dit en passant, ce qui est typique, pour la formation MusicVAE, vous n'avez pas besoin de traduire les sources en une seule cl√©.  La transposition n'est pas n√©cessaire, je suppose, car le code source sera toujours converti par l'auto-encodeur et les informations de tonalit√© dispara√Ætront. <br><br>  VAE est con√ßu de mani√®re √† permettre au d√©codeur de r√©cup√©rer efficacement les donn√©es de l'ensemble de donn√©es d'apprentissage, tandis que l'espace latent est une distribution fluide des caract√©ristiques des donn√©es d'entr√©e. <br><br>  Ceci est un point tr√®s important.  Cela permet de cr√©er des objets similaires et d'effectuer une interpolation logique significative.  Dans l'espace d'origine, nous avons 128x128x128x128 variantes de combinaison du son de quatre notes, mais en r√©alit√©, toutes ne sont pas utilis√©es (elles sonnent agr√©ablement √† l'oreille humaine).  Un encodeur automatique variationnel les transforme en un ensemble beaucoup plus petit dans un espace cach√©, et vous pouvez proposer des op√©rations math√©matiques dans cet espace qui ont une signification significative du point de vue de l'espace d'origine, par exemple, les points voisins seront des fragments musicaux similaires. <br><br>  Un bon exemple est de savoir comment ajouter des lunettes √† une photo √† l'aide d'un encodeur automatique dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> .  Vous pouvez en savoir plus sur le fonctionnement de Muisc VAE sur le site officiel de Magenta dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> , il y a aussi un lien vers arXiv. <br><br>  Donc, l'instrument est s√©lectionn√©, il reste √† l'utiliser avec mon objectif d'origine - cr√©er de la nouvelle musique bas√©e sur des pistes d√©j√† enregistr√©es et √©valuer combien cela sonnera comme le son du groupe d'origine.  Magenta ne fonctionne pas sur mon ordinateur portable Windows et depuis longtemps, il calcule un mod√®le sans GPU.  Apr√®s avoir souffert de machines virtuelles, d'un docker, etc., j'ai d√©cid√© d'utiliser le cloud. <br><br>  Google fournit des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blocs-notes Colab</a> o√π vous pourrez vous adonner aux mod√®les magenta.  Cependant, dans mon cas, il n'a pas √©t√© possible de former le mod√®le, le processus s'est bloqu√© tout le temps en raison de diverses restrictions - la quantit√© de m√©moire disponible, les arr√™ts de temporisation, l'absence d'une ligne de commande normale et les droits root pour installer les biblioth√®ques n√©cessaires.  Hypoth√©tiquement, il est m√™me possible d'utiliser le GPU, mais, je le r√©p√®te, je n'ai pas pu installer le mod√®le et le d√©marrer. <br><br>  Je pensais acheter un serveur et, oh, bonne chance, j'ai trouv√© que Google fournit des services cloud Google Cloud avec un GPU, et m√™me il y a une p√©riode d'essai gratuite.  Certes, il s'est av√©r√© qu'en Russie, ils ne sont officiellement accessibles qu'aux personnes morales, mais ils m'ont laiss√© entrer en mode d'essai gratuit. <br><br>  J'ai donc cr√©√© une machine virtuelle dans GoogleCloud avec un module GPU, trouv√© sur Internet plusieurs fichiers midi de l'un de mes groupes pr√©f√©r√©s et les ai t√©l√©charg√©s dans le dossier midi du cloud. <br><br>  Installez Magenta: <br><br><pre><code class="plaintext hljs">pip install magenta-gpu</code> </pre> <br>  C'est g√©nial que tout cela puisse √™tre install√© avec une seule √©quipe, pensais-je, mais ... des erreurs.  Il semble que vous deviez toucher la ligne de commande, d√©sol√©. <br><br>  Nous regardons les erreurs: la biblioth√®que rtmidi n'est pas install√©e sur la machine cloud, sans laquelle Magenta ne fonctionne pas. <br><br>  Et cela, √† son tour, se bloque en raison de l'absence du paquet libasound2-dev, et je n'ai pas non plus de privil√®ges root. <br><br>  Pas si effrayant: <br><br><pre> <code class="plaintext hljs">sudo su root apt-get install libasound2-dev</code> </pre> <br>  Hourra, maintenant pip install rtmidi fonctionne sans erreur, tout comme pip install magenta-gpu. <br><br>  On le retrouve sur Internet et t√©l√©charge les fichiers sources dans le dossier midi.  Ils sonnent quelque chose <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">comme √ßa</a> . <br><br>  Nous convertissons midi en un format de donn√©es avec lequel le r√©seau peut d√©j√† fonctionner: <br><br><pre> <code class="plaintext hljs">convert_dir_to_note_sequences \ --input_dir=midi\ --hparams=sampling_rate=1000.0\ --output_file=notesequences_R2Midi.tfrecord \ --log=DEBUG \ --recursive</code> </pre> <br>  et commencer la formation <br><br><pre> <code class="plaintext hljs">music_vae_train \ --config=hier-multiperf_vel_1bar_med \ --run_dir=/home/RNCDtrain/ \ --num_steps=1 \ --checkpoints_to_keep=2 \ --hparams=sampling_rate=1000.0 \ --hparams=batch_size=32,learning_rate=0.0005 \ --num_steps=5000 \ --mode=train \ --examples_path=notesequences_R2Midi.tfrecord</code> </pre> <br>  Encore une fois le probl√®me.  Tensorflow se bloque avec une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">erreur</a> - il ne peut pas trouver la biblioth√®que, heureusement, il y a quelques jours, quelqu'un a d√©j√† d√©crit cette erreur, et les sources Python peuvent √™tre corrig√©es. <br><br>  Nous montons dans le dossier <br><br><pre> <code class="plaintext hljs">/usr/local/lib/python2.7/dist-packages/tensorflow_probability/python/distributions#</code> </pre> <br>  et remplacez la ligne d'importation, comme d√©crit dans le bogue sur github. <br><br>  Lancez √† nouveau music_vae_train et ... Hourra!  La formation est partie! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0b5/46c/498/0b546c498699b6d4fbca1b95af41bd51.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br>  hier-multiperf_vel_1bar_med - J'utilise un mod√®le polyphonique (jusqu'√† 8 instruments) qui produit une mesure chacun. <br><br>  Un param√®tre important est checkpoints_to_keep = 2, la capacit√© du disque dans les nuages ‚Äã‚Äãest limit√©e, l'un des probl√®mes est que le processus d'apprentissage a √©t√© interrompu tout le temps en raison d'un d√©bordement de disque, les points de contr√¥le sont assez lourds - 0,6-1 gigaoctets chacun. <br><br>  Quelque part dans les 5000 √©poques, l'erreur commence √† sauter autour de 40 √† 70.  Je ne sais pas si c'est un bon r√©sultat ou non, mais il semble qu'avec un peu de donn√©es de formation, le r√©seau sera recycl√© davantage et cela n'a aucun sens de passer le temps des GPU si gentiment fournis gratuitement dans les centres de donn√©es Google.  Nous passons √† la g√©n√©ration. <br><br>  Pour une raison quelconque, lorsque l'installation de Magenta n'a pas install√© le fichier de g√©n√©ration lui-m√™me, j'ai d√ª le d√©poser de mes mains dans le dossier des autres: <br><br><pre> <code class="plaintext hljs">curl -o music_vae_generate.py https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/models/music_vae/music_vae_generate.py</code> </pre> <br>  Enfin, cr√©ez les fragments: <br><br><pre> <code class="plaintext hljs">music_vae_generate --config=hier-multiperf_vel_1bar_med --checkpoint_file=/home/RNCDtrain/train/ --mode=sample --num_outputs=32 --output_dir=/home/andrey_shagal/  --temperature=0.3</code> </pre> <br>  config - type de g√©n√©ration, exactement le m√™me que pendant la formation - multipiste, 1 horloge <br>  checkpoint_file - dossier o√π obtenir le dernier fichier avec le mod√®le form√© <br>  mode - √©chantillon - cr√©er un √©chantillon (il existe une autre option interpoler - cr√©er une mesure de transition entre deux mesures) <br>  num_outputs - combien de pi√®ces g√©n√©rer <br>  temp√©rature - un param√®tre de randomisation lors de la cr√©ation d'un √©chantillon, de 0 √† 1. √Ä 0, le r√©sultat est plus pr√©visible, plus proche de la source, √† 1 - Je suis un artiste, tel que je le vois. <br><br>  En sortie, j'obtiens 32 fragments par mesure.  Ayant d√©marr√© le g√©n√©rateur plusieurs fois, j'√©coute les fragments et colle le meilleur sur une piste: neurancid.mp3. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Alors "j'ai pass√© cet √©t√©."  Je suis satisfait.  Bien s√ªr, la radio Maximum est peu susceptible de l'emmener dans la liste de lecture, mais si vous √©coutez, cela ressemble vraiment au groupe Rancid original.  Le son, bien s√ªr, est diff√©rent de l'enregistrement en studio, mais nous avons principalement travaill√© avec des notes.  De plus, il y a de la place pour l'action - traitez le midi avec divers plug-ins VST, r√©enregistrez des parties avec des musiciens en direct ou attendez que les gars de Wave2Midi2Wave arrivent aux guitares avec une surcharge. <br><br>  Il n'y a rien √† redire sur les notes.  Id√©alement, j'aimerais que le r√©seau neuronal cr√©e un chef-d'≈ìuvre ou du moins un hit pour le top 100 du Billboard. Mais alors qu'elle a appris √† <s>utiliser l'alcool et les drogues</s> des rockers <s>,</s> √† jouer le rythme entier d'une note en huiti√®mes (en fait, non seulement, mais je suis fier de son p√®re transition de 20 √† 22 secondes).  Il y a des raisons √† cela, et plus √† leur sujet. <br><br><ol><li>  Petite quantit√© de donn√©es. </li><li>  Le mod√®le que j'ai utilis√© produit des fragments de la taille d'une mesure.  Dans le punk rock, en r√®gle g√©n√©rale, peu d'√©v√©nements se d√©roulent au sein d'une m√™me mesure. </li><li>  Les transitions et m√©lodies int√©ressantes fonctionnent juste dans le contexte des riffs de pitch, des transitions d'accord √† accord, et l'auto-encodeur, avec une petite quantit√© de donn√©es, semble avoir perdu la plupart des morceaux, et m√™me r√©duit tous les riffs √† deux accords consonantiques et plusieurs accords atonaux.  Nous devons essayer un mod√®le qui fonctionne avec 16 mesures, c'est dommage que seules trois voix y soient disponibles. </li></ol><br>  J'ai contact√© les d√©veloppeurs, ils ont recommand√© d'essayer de r√©duire la dimension de l'espace latent, car ils ont form√© leur r√©seau sur 200000 pistes, et je me suis entra√Æn√© sur 15. Je n'ai pas pu obtenir l'effet visible de la r√©duction de l'espace z, mais il y a encore quelque chose √† bricoler. <br><br>  Soit dit en passant, la monotonie et la monotonie est loin d'√™tre toujours un inconv√©nient.  Des rituels chamaniques aux soir√©es techno, comme vous le savez, une seule √©tape.  Nous devons essayer de former le mod√®le sur quelque chose comme √ßa - contre, rave, techno, dub, reggae, hip-hop.  Certes, il y a une chance de cr√©er quelque chose d'agr√©ablement zombie.  J'ai trouv√© une vingtaine de chansons de Bob Marley en midi et, voila la, une tr√®s belle boucle: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Les parties ci-dessus sont r√©enregistr√©es avec des basses et des guitares en direct, trait√©es par des synth√©tiseurs VST pour rendre le fragment plus juteux.  Dans l'original, le r√©seau n'a publi√© que des notes.  Si vous les jouez avec un lecteur midi standard, cela ressemble √† ceci: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Certes, si vous cr√©ez un certain nombre de dessins de batterie th√©matiques de base, d√©marrez-les dans Beat Blender + parties de base de basse et synth√©s avec une boucle latente (il y en avait plus √† leur sujet), il est tout √† fait possible d'ex√©cuter un algorithme pour la radio techno qui cr√©era en continu de nouvelles pistes ou m√™me une piste sans fin.  Buzz √©ternel! <br><br>  MusicVAE offre √©galement la possibilit√© de former le r√©seau pour g√©n√©rer des fragments de trio de 16 mesures - batterie, basse et plomb.  Aussi assez int√©ressant.  Donn√©es d'entr√©e - fichiers midi multipistes - le syst√®me se divise en triples dans toutes les combinaisons possibles et plus loin, il forme le mod√®le.  Un tel r√©seau n√©cessite beaucoup plus de ressources, mais le r√©sultat est imm√©diatement 16 cycles!  Impossible de r√©sister.  J'ai essay√© d'imaginer comment un groupe qui joue quelque chose entre Rancid et NOFX pourrait sonner, se chargeant pour la formation sur un nombre √©gal de pistes de chaque groupe: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Il y a aussi des parties midi r√©enregistr√©es sur des guitares live.  Lecteur midi standard comme celui-ci: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Int√©ressant!  C'est d√©finitivement mieux que mon premier groupe!  Et en passant, ce m√™me mod√®le nous donne un free jazz d√©cent: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Les probl√®mes que j'ai rencontr√©s: <br><br><ol><li>  Absence d'un bon support pratique qui r√©duirait le temps d'attente pour la formation.  Le mod√®le ne fonctionne que sous Linux, la formation est longue, sans GPU depuis tr√®s longtemps, et tout le temps je veux essayer de changer les param√®tres et voir ce qui se passe.  Par exemple, un serveur cloud avec un processeur GPU de 100 √©poques pour le mod√®le ¬´trio de 16 cycles¬ª a compt√© 8 heures. </li><li>  Un probl√®me typique d'apprentissage automatique est le manque de donn√©es.  Seulement 15 fichiers midi - c'est tr√®s petit pour comprendre la musique.  Le r√©seau neuronal, contrairement √† moi dans ma jeunesse, n'a pas √©cout√© 6 albums de Rancid avant les trous, je ne suis pas all√© √† des concerts, ce r√©sultat a √©t√© obtenu √† partir de 15 morceaux midi inconnus de quiconque est loin de l'original.  Maintenant, si vous restez autour du guitariste avec des capteurs et prenez chaque son de chaque note ... Voyons comment se d√©veloppe l'id√©e Wave2Midi2Wave.  Peut-√™tre que dans quelques ann√©es, il sera possible de refuser des notes pour r√©soudre un tel probl√®me. </li><li>  Le musicien doit s'inscrire clairement dans le rythme, mais pas parfaitement.  Le week-end midi, il n'y a pas de dynamique dans les notes (par exemple, dans la batterie), elles sont toutes jou√©es au m√™me volume, exactement en un clic (comme disent les musiciens, c'est-√†-dire exactement dans le rythme), m√™me si vous les diversifiez au hasard, la musique commence √† sonner plus vivant et plus agr√©able.  Encore une fois, Wave2Midi2Wave traite d√©j√† ce probl√®me. </li></ol><br>  Vous avez maintenant une id√©e des possibilit√©s de l'IA dans la cr√©ation de musique et de mes pr√©f√©rences musicales.  Quel r√¥le pensez-vous que l'IA attend dans le processus cr√©atif √† l'avenir?  Une machine peut-elle cr√©er de la musique sur un pied d'√©galit√© ou m√™me mieux qu'un √™tre humain pour √™tre un assistant dans le processus cr√©atif?  Ou l'intelligence artificielle ne deviendra c√©l√®bre dans le domaine musical que pour l'artisanat primitif. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439546/">https://habr.com/ru/post/fr439546/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439534/index.html">Programmation des rendements et utilisation de drones dans la production de p√©trole - 10 conf√©rences de la conf√©rence GIS Tech Russia</a></li>
<li><a href="../fr439538/index.html">Programmation de la soci√©t√©</a></li>
<li><a href="../fr439540/index.html">Etherblade.net - projet opensource pour cr√©er un encapsulateur de trafic Ethernet sur FPGA (premi√®re partie)</a></li>
<li><a href="../fr439542/index.html">Nintendo indique clairement que seul le piratage peut sauvegarder l'historique des jeux vid√©o</a></li>
<li><a href="../fr439544/index.html">Colonie. Chapitre 24: D√©part</a></li>
<li><a href="../fr439550/index.html">Hackquest 2018. R√©sultats et √©critures. Jour 1-3</a></li>
<li><a href="../fr439552/index.html">Extensions Chrome malveillantes</a></li>
<li><a href="../fr439556/index.html">TDMS Fairway. M√©thodologies PMBOK et organisations de conception russes</a></li>
<li><a href="../fr439558/index.html">Nouveau vieux t√©l√©phone. R√©inventez le t√©l√©phone PSTN</a></li>
<li><a href="../fr439560/index.html">Adaptateur Ethereum blockchain pour plate-forme de donn√©es InterSystems IRIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
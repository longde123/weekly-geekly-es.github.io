<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèº‚Äçü§ù‚Äçüßëüèº üë©üèº‚Äçüöí üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® Traitons le son sur Go ü•ù üåï üë©üèæ‚Äçüéì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Avertissement: je ne consid√®re aucun algorithme ni API pour travailler avec la reconnaissance du son et de la parole. Cet article concerne les probl√®m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traitons le son sur Go</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424623/"><blockquote>  Avertissement: je ne consid√®re aucun algorithme ni API pour travailler avec la reconnaissance du son et de la parole.  Cet article concerne les probl√®mes audio et comment les r√©soudre avec Go. </blockquote><p><img src="https://habrastorage.org/webt/gg/cf/7i/ggcf7ihwchhcfrbsnrwdpohwczg.png" alt="gopher"></p><br><p> <code>phono</code> est un cadre d'application pour travailler avec le son.  Sa fonction principale est de cr√©er un convoyeur √† partir de diverses technologies qui traitera le son <del>  pour toi </del>  de la mani√®re dont vous avez besoin. </p><br><p>  Qu'est-ce que le convoyeur a √† voir avec cela, en plus de diff√©rentes technologies, et pourquoi un autre cadre?  Voyons maintenant. </p><a name="habracut"></a><br><h2 id="otkuda-zvuk">  D'o√π vient le son? </h2><br><p>  En 2018, le son est devenu la mani√®re standard dont les humains interagissent avec la technologie.  La plupart des g√©ants de l'informatique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ont cr√©√©</a> leur propre assistant vocal ou le font actuellement.  Le contr√¥le vocal est d√©j√† sur la plupart des syst√®mes d'exploitation, et la messagerie vocale est une caract√©ristique typique de tout messager.  Dans le monde, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">environ un millier de</a> startups travaillent sur le traitement du langage naturel et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">environ deux cents</a> sur la reconnaissance vocale. </p><br><p>  Avec la musique, une histoire similaire.  Il joue √† partir de n'importe quel appareil et l'enregistrement sonore est disponible pour tous ceux qui ont un ordinateur.  Le logiciel musical est d√©velopp√© par des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">centaines d'entreprises</a> et des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">milliers de passionn√©s √†</a> travers le monde. </p><br><h2 id="a-nametasksa-obschie-zadachi">  T√¢ches courantes </h2><br><p>  Si vous deviez travailler avec du son, les conditions suivantes devraient vous √™tre famili√®res: </p><br><ul><li>  L'audio doit √™tre <strong>obtenu √†</strong> partir d'un fichier, d'un appareil, d'un r√©seau, etc. </li><li>  L'audio doit √™tre <strong>trait√©</strong> : ajouter des effets, transcoder, analyser, etc. </li><li>  L'audio doit √™tre <strong>transf√©r√©</strong> vers un fichier, un appareil, un r√©seau, etc. </li><li>  Les donn√©es sont transmises dans de petits tampons. </li></ul><br><p>  Il en r√©sulte un pipeline r√©gulier - il existe un flux de donn√©es qui passe par plusieurs √©tapes de traitement. </p><br><h2 id="resheniya">  Des solutions </h2><br><p>  Pour plus de clart√©, prenons une t√¢che de la vie r√©elle.  Par exemple, vous devez convertir une voix en texte: </p><br><ul><li>  Nous enregistrons l'audio de l'appareil </li><li>  Supprimer le bruit </li><li>  √âgaliser </li><li>  Passer le signal √† l'API de reconnaissance vocale </li></ul><br><p>  Comme toute autre t√¢che, celle-ci a plusieurs solutions. </p><br><h3 id="v-lob">  Le front </h3><br><p>  Hardcore uniquement <del>  cyclistes </del>  programmeurs.  Nous enregistrons le son directement via le pilote de la carte son, √©crivons une r√©duction intelligente du bruit et un √©galiseur multibande.  C'est tr√®s int√©ressant, mais vous pouvez oublier votre t√¢che d'origine pendant plusieurs mois. </p><br><p>  Long et tr√®s difficile. </p><br><h3 id="po-normalnomu">  Normal </h3><br><p>  Une alternative consiste √† utiliser les API existantes.  Vous pouvez enregistrer de l'audio en utilisant ASIO, CoreAudio, PortAudio, ALSA et autres.  Il existe √©galement plusieurs types de plugins pour le traitement: AAX, VST2, VST3, AU. </p><br><p>  Un large choix ne signifie pas que vous pouvez tout utiliser √† la fois.  En r√®gle g√©n√©rale, les restrictions suivantes s'appliquent: </p><br><ol><li>  Syst√®me d'exploitation  Toutes les API ne sont pas disponibles sur tous les syst√®mes d'exploitation.  Par exemple, AU est une technologie OS X native et n'est disponible que l√†-bas. </li><li>  Langage de programmation  La plupart des biblioth√®ques audio sont √©crites en C ou C ++.  En 1996, Steinberg a publi√© la premi√®re version du SDK VST, toujours le standard de plugin le plus populaire.  Apr√®s 20 ans, il n'est plus n√©cessaire d'√©crire en C / C ++: pour VST il y a des wrappers en Java, Python, C #, Rust, et qui sait quoi d'autre.  Bien que le langage reste une limitation, d√©sormais m√™me le son est trait√© en JavaScript. </li><li>  Fonctionnel.  Si la t√¢che est simple et directe, il n'est pas n√©cessaire d'√©crire une nouvelle application.  Le m√™me FFmpeg peut faire beaucoup. </li></ol><br><p>  Dans cette situation, la complexit√© d√©pend de votre choix.  Dans le pire des cas, vous devez traiter avec plusieurs biblioth√®ques.  Et si vous n'avez pas de chance, avec des abstractions complexes et des interfaces compl√®tement diff√©rentes. </p><br><h3 id="chto-v-itoge">  Quel est le r√©sultat? </h3><br><p>  Vous devez choisir entre <strong>tr√®s complexe</strong> et <strong>complexe</strong> : </p><br><ul><li>  soit g√©rer plusieurs API de bas niveau pour √©crire vos v√©los </li><li>  soit traiter avec plusieurs API et essayer de se faire des amis avec eux </li></ul><br><p>  Quelle que soit la m√©thode choisie, la t√¢che revient toujours au convoyeur.  Les technologies utilis√©es peuvent varier, mais l'essence est la m√™me.  Le probl√®me est qu'encore une fois, au lieu de r√©soudre un vrai probl√®me, vous devez √©crire <del>  le v√©lo </del>  bande transporteuse. </p><br><p>  Mais il y a une issue. </p><br><h2 id="phono">  phono </h2><br><p><img src="https://habrastorage.org/webt/ym/fw/h6/ymfwh6c8hjwgig8hzksgbut2ifm.jpeg" alt="phono"></p><br><p>  <code>phono</code> cr√©√© pour r√©soudre des probl√®mes courants - ¬´ <strong>recevoir, traiter et transmettre</strong> ¬ª le son.  Pour ce faire, il utilise le pipeline comme l'abstraction la plus naturelle.  Il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le blog officiel</a> Go qui d√©crit le mod√®le de pipeline.  L'id√©e principale du pipeline est qu'il existe plusieurs √©tapes de traitement des donn√©es qui fonctionnent ind√©pendamment les unes des autres et √©changent des donn√©es via des canaux.  Ce dont vous avez besoin. </p><br><p>  Pourquoi partir? </p><br><p>  Premi√®rement, la plupart des programmes et biblioth√®ques audio sont √©crits en C, et Go est souvent d√©sign√© comme son successeur.  En outre, il existe des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cgo</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un bon nombre de classeurs</a> pour les biblioth√®ques audio existantes.  Vous pouvez prendre et utiliser. </p><br><p>  Deuxi√®mement, √† mon avis personnel, Go est une bonne langue.  Je n'irai pas en profondeur, mais je noterai son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">multithreading</a> .  Les canaux et les gorutins simplifient consid√©rablement la mise en ≈ìuvre du convoyeur. </p><br><h3 id="abstrakcii">  Abstraction </h3><br><p>  Le c≈ìur du <code>phono</code> est le type <code>pipe.Pipe</code> .  C'est lui qui met en ≈ìuvre le pipeline.  Comme dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemple du blog</a> , il existe trois types d'√©tapes: </p><br><ol><li>  <code>pipe.Pump</code> (pompe anglaise) - <strong>r√©ception du</strong> son, uniquement les canaux de sortie </li><li>  <code>pipe.Processor</code> (processeur anglais) - <strong>traitement du</strong> son, canaux d'entr√©e et de sortie </li><li>  <code>pipe.Sink</code> (English sink) - <strong>transmission du</strong> son, canaux d'entr√©e uniquement </li></ol><br><p>  √Ä l'int√©rieur du <code>pipe.Pipe</code> donn√©es dans des tampons.  R√®gles de construction d'un pipeline: </p><br><p><img src="https://habrastorage.org/webt/go/ym/ep/goymepjg4pds_picireejjsshnq.png" alt="pipe_diagram"></p><br><ol><li>  Un <code>pipe.Pump</code> </li><li>  Plusieurs <code>pipe.Processor</code> plac√© s√©quentiellement les uns apr√®s les autres </li><li>  Un ou plusieurs <code>pipe.Sink</code> plac√© en parall√®le </li><li>  Tous les composants des <code>pipe.Pipe</code> doivent avoir les m√™mes: <br><ul><li>  Taille de la m√©moire tampon (messages) </li><li>  Taux d'√©chantillonnage </li><li>  Nombre de canaux </li></ul></li></ol><br><p>  La configuration minimale est une pompe et un √©vier, le reste est facultatif. </p><br><p>  Regardons quelques exemples. </p><br><h3 id="prostoy">  Simple </h3><br><p>  <strong>T√¢che:</strong> lire le fichier wav. </p><br><p>  Apportons-le sous la forme " <strong>recevoir, traiter, transf√©rer</strong> ": </p><br><ol><li>  <strong>Obtenez l'</strong> audio d'un fichier wav </li><li>  <strong>Transf√©rer l'</strong> audio vers un appareil portaudio </li></ol><br><p><img src="https://habrastorage.org/webt/qz/5p/qg/qz5pqgxqfydujch359ei8fsp0pg.png"></p><br><p>  L'audio est lu et imm√©diatement lu. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Play it with portaudio func easy() { wavPath := "_testdata/sample1.wav" bufferSize := phono.BufferSize(512) // wav pump wavPump, err := wav.NewPump( wavPath, bufferSize, ) check(err) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // build pipe p := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(paSink), ) defer p.Close() // run pipe err = p.Do(pipe.Run) check(err) }</span></span></code> </pre> </div></div><br><p>  Tout d'abord, nous cr√©ons les √©l√©ments du futur pipeline: <code>wav.Pump</code> et <code>portaudio.Sink</code> et les passons au <code>pipe.New</code> constructeur.  La fonction d' <code>p.Do(pipe.actionFn) error</code> d√©marre le pipeline et attend qu'il se termine. </p><br><h3 id="slozhnee">  Plus dur </h3><br><p>  <strong>T√¢che:</strong> divisez le fichier wav en √©chantillons, composez-en une piste, enregistrez le r√©sultat et jouez-le simultan√©ment. </p><br><p>  Une piste est une s√©quence d'√©chantillons et un √©chantillon est un petit segment d'audio.  Pour couper l'audio, vous devez d'abord le charger en m√©moire.  Pour ce faire, utilisez le type <code>asset.Asset</code> du <code>asset.Asset</code> <code>phono/asset</code> .  Nous divisons la t√¢che en √©tapes standard: </p><br><ol><li>  <strong>Obtenez l'</strong> audio d'un fichier wav </li><li>  <strong>Transf√©rer l'</strong> audio en m√©moire </li></ol><br><p>  Maintenant, nous faisons des √©chantillons avec nos mains, les ajoutons √† la piste et terminons la t√¢che: </p><br><ol><li>  <strong>Obtenez l'</strong> audio d'une piste </li><li>  <strong>Transf√©rer l'</strong> audio vers <br><ul><li>  fichier wav </li><li>  appareil portaudio </li></ul></li></ol><br><p><img src="https://habrastorage.org/webt/r3/q7/yv/r3q7yvccvkpjxbho7s3iwr2zisc.png" alt="exemple_normal"></p><br><p>  Encore une fois, sans √©tape de traitement, mais deux pipelines! </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/asset"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/track"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Split it to samples // Put samples to track // Save track into .wav and play it with portaudio func normal() { bufferSize := phono.BufferSize(512) inPath := "_testdata/sample1.wav" outPath := "_testdata/example4_out.wav" // wav pump wavPump, err := wav.NewPump(inPath, bufferSize) check(err) // asset sink asset := &amp;asset.Asset{ SampleRate: wavPump.WavSampleRate(), } // import pipe importAsset := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(asset), ) defer importAsset.Close() err = importAsset.Do(pipe.Run) check(err) // track pump track := track.New(bufferSize, asset.NumChannels()) // add samples to track track.AddFrame(198450, asset.Frame(0, 44100)) track.AddFrame(66150, asset.Frame(44100, 44100)) track.AddFrame(132300, asset.Frame(0, 44100)) // wav sink wavSink, err := wav.NewSink( outPath, wavPump.WavSampleRate(), wavPump.WavNumChannels(), wavPump.WavBitDepth(), wavPump.WavAudioFormat(), ) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // final pipe p := pipe.New( pipe.WithPump(track), pipe.WithSinks(wavSink, paSink), ) err = p.Do(pipe.Run) }</span></span></code> </pre> </div></div><br><p>  Par rapport √† l'exemple pr√©c√©dent, il existe deux <code>pipe.Pipe</code> .  Le premier transf√®re les donn√©es en m√©moire afin que vous puissiez couper les √©chantillons.  Le second a deux destinataires √† la fin: <code>wav.Sink</code> et <code>portaudio.Sink</code> .  Avec ce sch√©ma, le son est simultan√©ment enregistr√© dans un fichier wav et lu. </p><br><h3 id="esche-slozhnee">  Plus dur </h3><br><p>  <strong>T√¢che:</strong> lire deux fichiers wav, m√©langer, traiter le plugin vst2 et enregistrer dans un nouveau fichier wav. </p><br><p>  Il y a un <code>mixer.Mixer</code> simple. <code>mixer.Mixer</code> dans le <code>mixer.Mixer</code> <code>phono/mixer</code> .  Il peut <strong>transmettre des</strong> signaux de plusieurs sources et en m√©langer une.  Pour ce faire, il impl√©mente simultan√©ment <code>pipe.Pump</code> et <code>pipe.Sink</code> . </p><br><p>  Encore une fois, la t√¢che consiste en deux sous-t√¢ches.  Le premier ressemble √† ceci: </p><br><ol><li>  <strong>Obtenez le</strong> fichier audio wav </li><li>  <strong>Transf√©rez l'</strong> audio vers la console de mixage </li></ol><br><p>  Deuxi√®mement: </p><br><ol><li>  <strong>Obtenez l'</strong> audio de la console de mixage. </li><li>  <strong>Traitement</strong> du plugin audio </li><li>  <strong>Transf√©rer l'</strong> audio vers un fichier wav </li></ol><br><p><img src="https://habrastorage.org/webt/xw/hj/ad/xwhjadlajgapbhjufym72qjgssq.png" alt="example_hard"></p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/mixer"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/vst2"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> vst2sdk <span class="hljs-string"><span class="hljs-string">"github.com/dudk/vst2"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read two .wav files // Mix them // Process with vst2 // Save result into new .wav file // // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">NOTE:</span></span></span><span class="hljs-comment"> For example both wav files have same characteristics ie: sample rate, bit depth and number of channels. // In real life implicit conversion will be needed. func hard() { bs := phono.BufferSize(512) inPath1 := "../_testdata/sample1.wav" inPath2 := "../_testdata/sample2.wav" outPath := "../_testdata/out/example5.wav" // wav pump 1 wavPump1, err := wav.NewPump(inPath1, bs) check(err) // wav pump 2 wavPump2, err := wav.NewPump(inPath2, bs) check(err) // mixer mixer := mixer.New(bs, wavPump1.WavNumChannels()) // track 1 track1 := pipe.New( pipe.WithPump(wavPump1), pipe.WithSinks(mixer), ) defer track1.Close() // track 2 track2 := pipe.New( pipe.WithPump(wavPump2), pipe.WithSinks(mixer), ) defer track2.Close() // vst2 processor vst2path := "../_testdata/Krush.vst" vst2lib, err := vst2sdk.Open(vst2path) check(err) defer vst2lib.Close() vst2plugin, err := vst2lib.Open() check(err) defer vst2plugin.Close() vst2processor := vst2.NewProcessor( vst2plugin, bs, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), ) // wav sink wavSink, err := wav.NewSink( outPath, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), wavPump1.WavBitDepth(), wavPump1.WavAudioFormat(), ) check(err) // out pipe out := pipe.New( pipe.WithPump(mixer), pipe.WithProcessors(vst2processor), pipe.WithSinks(wavSink), ) defer out.Close() // run all track1Done, err := track1.Begin(pipe.Run) check(err) track2Done, err := track2.Begin(pipe.Run) check(err) outDone, err := out.Begin(pipe.Run) check(err) // wait results err = track1.Wait(track1Done) check(err) err = track2.Wait(track2Done) check(err) err = out.Wait(outDone) check(err) }</span></span></code> </pre> </div></div><br><p>  Il y a d√©j√† trois <code>pipe.Pipe</code> , tous reli√©s entre eux par un m√©langeur.  Pour commencer, utilisez la fonction <code>p.Begin(pipe.actionFn) (pipe.State, error)</code> .  Contrairement √† l' <code>p.Do(pipe.actionFn) error</code> , il ne bloque pas l'appel, mais renvoie simplement un √©tat qui peut ensuite √™tre attendu avec l' <code>p.Wait(pipe.State) error</code> . </p><br><h2 id="chto-dalshe">  Et ensuite? </h2><br><p>  Je veux que le <code>phono</code> devienne le cadre d'application le plus pratique.  Si vous avez un probl√®me avec le son, vous n'avez pas besoin de comprendre les API complexes et de passer du temps √† √©tudier les normes.  Il suffit de construire un convoyeur √† partir d'√©l√©ments appropri√©s et de le faire fonctionner. </p><br><p>  Pendant six mois, les packages suivants ont √©t√© film√©s: </p><br><ul><li>  <code>phono/wav</code> - lire / √©crire des fichiers wav </li><li>  <code>phono/vst2</code> - liaisons incompl√®tes du SDK VST2, alors que vous ne pouvez ouvrir que le plugin et appeler ses m√©thodes, mais pas toutes les structures </li><li>  <code>phono/mixer</code> - table de mixage, ajoute N signaux, sans balance ni volume </li><li>  <code>phono/asset</code> - √©chantillonnage tampon </li><li>  <code>phono/track</code> - lecture s√©quentielle des √©chantillons (superposition cass√©e) </li><li>  <code>phono/portaudio</code> - lecture du signal pendant les exp√©riences </li></ul><br><p>  En plus de cette liste, il y a un arri√©r√© sans cesse croissant de nouvelles id√©es et id√©es, notamment: </p><br><ul><li>  Compte √† rebours </li><li>  Variable √† la vol√©e </li><li>  Pompe / √©vier HTTP </li><li>  Automatisation des param√®tres </li><li>  Processeur de r√©√©chantillonnage </li><li>  Balance et volume du mixeur </li><li>  Pompe en temps r√©el </li><li>  Pompe synchronis√©e pour plusieurs pistes </li><li>  Vst2 complet </li></ul><br><p>  Dans les articles suivants, j'analyserai: </p><br><ul><li>  <code>pipe.Pipe</code> vie du <code>pipe.Pipe</code> - en raison de la structure complexe, son √©tat est contr√¥l√© par l'atome final </li><li>  comment √©crire les √©tapes de votre pipeline </li></ul><br><p>  Ceci est mon premier projet open-source, donc je serai reconnaissant pour toute aide et recommandations.  Vous √™tes les bienvenus. </p><br><h2 id="ssylki">  Les r√©f√©rences </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">phono</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®les de concurrence Go: pipelines et annulation</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424623/">https://habr.com/ru/post/fr424623/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424609/index.html">Comment √©tendre Kubernetes</a></li>
<li><a href="../fr424611/index.html">Comment cr√©er un employ√© √† partir d'un pigiste</a></li>
<li><a href="../fr424613/index.html">Exp√©rience de l'utilisation de redux sans r√©ducteurs</a></li>
<li><a href="../fr424615/index.html">Sortie de fonction de courbe pour limiter en douceur les param√®tres, les signaux et pas seulement dans Wolfram Mathematica</a></li>
<li><a href="../fr424621/index.html">Super-h√©ros non-film. Qui et comment prot√®ge le chantier de construction du centre de Lakhta contre les incendies?</a></li>
<li><a href="../fr424625/index.html">Fuite de code source des services Web Aeroflot</a></li>
<li><a href="../fr424627/index.html">Modification des caisses enregistreuses. Partie 1</a></li>
<li><a href="../fr424629/index.html">Comment les startups augmentent-elles leurs chances d'investir lorsqu'elles communiquent avec un investisseur?</a></li>
<li><a href="../fr424633/index.html">Comment STACKLEAK am√©liore la s√©curit√© du noyau Linux</a></li>
<li><a href="../fr424635/index.html">Bienvenue dans Sberbank Data Science Journey 2018 - Course aux algorithmes d'apprentissage automatique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
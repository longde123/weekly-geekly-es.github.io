<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧑🏼‍🤝‍🧑🏼 👩🏼‍🚒 👨‍❤️‍💋‍👨 Traitons le son sur Go 🥝 🌕 👩🏾‍🎓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Avertissement: je ne considère aucun algorithme ni API pour travailler avec la reconnaissance du son et de la parole. Cet article concerne les problèm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traitons le son sur Go</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424623/"><blockquote>  Avertissement: je ne considère aucun algorithme ni API pour travailler avec la reconnaissance du son et de la parole.  Cet article concerne les problèmes audio et comment les résoudre avec Go. </blockquote><p><img src="https://habrastorage.org/webt/gg/cf/7i/ggcf7ihwchhcfrbsnrwdpohwczg.png" alt="gopher"></p><br><p> <code>phono</code> est un cadre d'application pour travailler avec le son.  Sa fonction principale est de créer un convoyeur à partir de diverses technologies qui traitera le son <del>  pour toi </del>  de la manière dont vous avez besoin. </p><br><p>  Qu'est-ce que le convoyeur a à voir avec cela, en plus de différentes technologies, et pourquoi un autre cadre?  Voyons maintenant. </p><a name="habracut"></a><br><h2 id="otkuda-zvuk">  D'où vient le son? </h2><br><p>  En 2018, le son est devenu la manière standard dont les humains interagissent avec la technologie.  La plupart des géants de l'informatique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ont créé</a> leur propre assistant vocal ou le font actuellement.  Le contrôle vocal est déjà sur la plupart des systèmes d'exploitation, et la messagerie vocale est une caractéristique typique de tout messager.  Dans le monde, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">environ un millier de</a> startups travaillent sur le traitement du langage naturel et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">environ deux cents</a> sur la reconnaissance vocale. </p><br><p>  Avec la musique, une histoire similaire.  Il joue à partir de n'importe quel appareil et l'enregistrement sonore est disponible pour tous ceux qui ont un ordinateur.  Le logiciel musical est développé par des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">centaines d'entreprises</a> et des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">milliers de passionnés à</a> travers le monde. </p><br><h2 id="a-nametasksa-obschie-zadachi">  Tâches courantes </h2><br><p>  Si vous deviez travailler avec du son, les conditions suivantes devraient vous être familières: </p><br><ul><li>  L'audio doit être <strong>obtenu à</strong> partir d'un fichier, d'un appareil, d'un réseau, etc. </li><li>  L'audio doit être <strong>traité</strong> : ajouter des effets, transcoder, analyser, etc. </li><li>  L'audio doit être <strong>transféré</strong> vers un fichier, un appareil, un réseau, etc. </li><li>  Les données sont transmises dans de petits tampons. </li></ul><br><p>  Il en résulte un pipeline régulier - il existe un flux de données qui passe par plusieurs étapes de traitement. </p><br><h2 id="resheniya">  Des solutions </h2><br><p>  Pour plus de clarté, prenons une tâche de la vie réelle.  Par exemple, vous devez convertir une voix en texte: </p><br><ul><li>  Nous enregistrons l'audio de l'appareil </li><li>  Supprimer le bruit </li><li>  Égaliser </li><li>  Passer le signal à l'API de reconnaissance vocale </li></ul><br><p>  Comme toute autre tâche, celle-ci a plusieurs solutions. </p><br><h3 id="v-lob">  Le front </h3><br><p>  Hardcore uniquement <del>  cyclistes </del>  programmeurs.  Nous enregistrons le son directement via le pilote de la carte son, écrivons une réduction intelligente du bruit et un égaliseur multibande.  C'est très intéressant, mais vous pouvez oublier votre tâche d'origine pendant plusieurs mois. </p><br><p>  Long et très difficile. </p><br><h3 id="po-normalnomu">  Normal </h3><br><p>  Une alternative consiste à utiliser les API existantes.  Vous pouvez enregistrer de l'audio en utilisant ASIO, CoreAudio, PortAudio, ALSA et autres.  Il existe également plusieurs types de plugins pour le traitement: AAX, VST2, VST3, AU. </p><br><p>  Un large choix ne signifie pas que vous pouvez tout utiliser à la fois.  En règle générale, les restrictions suivantes s'appliquent: </p><br><ol><li>  Système d'exploitation  Toutes les API ne sont pas disponibles sur tous les systèmes d'exploitation.  Par exemple, AU est une technologie OS X native et n'est disponible que là-bas. </li><li>  Langage de programmation  La plupart des bibliothèques audio sont écrites en C ou C ++.  En 1996, Steinberg a publié la première version du SDK VST, toujours le standard de plugin le plus populaire.  Après 20 ans, il n'est plus nécessaire d'écrire en C / C ++: pour VST il y a des wrappers en Java, Python, C #, Rust, et qui sait quoi d'autre.  Bien que le langage reste une limitation, désormais même le son est traité en JavaScript. </li><li>  Fonctionnel.  Si la tâche est simple et directe, il n'est pas nécessaire d'écrire une nouvelle application.  Le même FFmpeg peut faire beaucoup. </li></ol><br><p>  Dans cette situation, la complexité dépend de votre choix.  Dans le pire des cas, vous devez traiter avec plusieurs bibliothèques.  Et si vous n'avez pas de chance, avec des abstractions complexes et des interfaces complètement différentes. </p><br><h3 id="chto-v-itoge">  Quel est le résultat? </h3><br><p>  Vous devez choisir entre <strong>très complexe</strong> et <strong>complexe</strong> : </p><br><ul><li>  soit gérer plusieurs API de bas niveau pour écrire vos vélos </li><li>  soit traiter avec plusieurs API et essayer de se faire des amis avec eux </li></ul><br><p>  Quelle que soit la méthode choisie, la tâche revient toujours au convoyeur.  Les technologies utilisées peuvent varier, mais l'essence est la même.  Le problème est qu'encore une fois, au lieu de résoudre un vrai problème, vous devez écrire <del>  le vélo </del>  bande transporteuse. </p><br><p>  Mais il y a une issue. </p><br><h2 id="phono">  phono </h2><br><p><img src="https://habrastorage.org/webt/ym/fw/h6/ymfwh6c8hjwgig8hzksgbut2ifm.jpeg" alt="phono"></p><br><p>  <code>phono</code> créé pour résoudre des problèmes courants - « <strong>recevoir, traiter et transmettre</strong> » le son.  Pour ce faire, il utilise le pipeline comme l'abstraction la plus naturelle.  Il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le blog officiel</a> Go qui décrit le modèle de pipeline.  L'idée principale du pipeline est qu'il existe plusieurs étapes de traitement des données qui fonctionnent indépendamment les unes des autres et échangent des données via des canaux.  Ce dont vous avez besoin. </p><br><p>  Pourquoi partir? </p><br><p>  Premièrement, la plupart des programmes et bibliothèques audio sont écrits en C, et Go est souvent désigné comme son successeur.  En outre, il existe des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cgo</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un bon nombre de classeurs</a> pour les bibliothèques audio existantes.  Vous pouvez prendre et utiliser. </p><br><p>  Deuxièmement, à mon avis personnel, Go est une bonne langue.  Je n'irai pas en profondeur, mais je noterai son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">multithreading</a> .  Les canaux et les gorutins simplifient considérablement la mise en œuvre du convoyeur. </p><br><h3 id="abstrakcii">  Abstraction </h3><br><p>  Le cœur du <code>phono</code> est le type <code>pipe.Pipe</code> .  C'est lui qui met en œuvre le pipeline.  Comme dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemple du blog</a> , il existe trois types d'étapes: </p><br><ol><li>  <code>pipe.Pump</code> (pompe anglaise) - <strong>réception du</strong> son, uniquement les canaux de sortie </li><li>  <code>pipe.Processor</code> (processeur anglais) - <strong>traitement du</strong> son, canaux d'entrée et de sortie </li><li>  <code>pipe.Sink</code> (English sink) - <strong>transmission du</strong> son, canaux d'entrée uniquement </li></ol><br><p>  À l'intérieur du <code>pipe.Pipe</code> données dans des tampons.  Règles de construction d'un pipeline: </p><br><p><img src="https://habrastorage.org/webt/go/ym/ep/goymepjg4pds_picireejjsshnq.png" alt="pipe_diagram"></p><br><ol><li>  Un <code>pipe.Pump</code> </li><li>  Plusieurs <code>pipe.Processor</code> placé séquentiellement les uns après les autres </li><li>  Un ou plusieurs <code>pipe.Sink</code> placé en parallèle </li><li>  Tous les composants des <code>pipe.Pipe</code> doivent avoir les mêmes: <br><ul><li>  Taille de la mémoire tampon (messages) </li><li>  Taux d'échantillonnage </li><li>  Nombre de canaux </li></ul></li></ol><br><p>  La configuration minimale est une pompe et un évier, le reste est facultatif. </p><br><p>  Regardons quelques exemples. </p><br><h3 id="prostoy">  Simple </h3><br><p>  <strong>Tâche:</strong> lire le fichier wav. </p><br><p>  Apportons-le sous la forme " <strong>recevoir, traiter, transférer</strong> ": </p><br><ol><li>  <strong>Obtenez l'</strong> audio d'un fichier wav </li><li>  <strong>Transférer l'</strong> audio vers un appareil portaudio </li></ol><br><p><img src="https://habrastorage.org/webt/qz/5p/qg/qz5pqgxqfydujch359ei8fsp0pg.png"></p><br><p>  L'audio est lu et immédiatement lu. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Play it with portaudio func easy() { wavPath := "_testdata/sample1.wav" bufferSize := phono.BufferSize(512) // wav pump wavPump, err := wav.NewPump( wavPath, bufferSize, ) check(err) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // build pipe p := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(paSink), ) defer p.Close() // run pipe err = p.Do(pipe.Run) check(err) }</span></span></code> </pre> </div></div><br><p>  Tout d'abord, nous créons les éléments du futur pipeline: <code>wav.Pump</code> et <code>portaudio.Sink</code> et les passons au <code>pipe.New</code> constructeur.  La fonction d' <code>p.Do(pipe.actionFn) error</code> démarre le pipeline et attend qu'il se termine. </p><br><h3 id="slozhnee">  Plus dur </h3><br><p>  <strong>Tâche:</strong> divisez le fichier wav en échantillons, composez-en une piste, enregistrez le résultat et jouez-le simultanément. </p><br><p>  Une piste est une séquence d'échantillons et un échantillon est un petit segment d'audio.  Pour couper l'audio, vous devez d'abord le charger en mémoire.  Pour ce faire, utilisez le type <code>asset.Asset</code> du <code>asset.Asset</code> <code>phono/asset</code> .  Nous divisons la tâche en étapes standard: </p><br><ol><li>  <strong>Obtenez l'</strong> audio d'un fichier wav </li><li>  <strong>Transférer l'</strong> audio en mémoire </li></ol><br><p>  Maintenant, nous faisons des échantillons avec nos mains, les ajoutons à la piste et terminons la tâche: </p><br><ol><li>  <strong>Obtenez l'</strong> audio d'une piste </li><li>  <strong>Transférer l'</strong> audio vers <br><ul><li>  fichier wav </li><li>  appareil portaudio </li></ul></li></ol><br><p><img src="https://habrastorage.org/webt/r3/q7/yv/r3q7yvccvkpjxbho7s3iwr2zisc.png" alt="exemple_normal"></p><br><p>  Encore une fois, sans étape de traitement, mais deux pipelines! </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/asset"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/track"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Split it to samples // Put samples to track // Save track into .wav and play it with portaudio func normal() { bufferSize := phono.BufferSize(512) inPath := "_testdata/sample1.wav" outPath := "_testdata/example4_out.wav" // wav pump wavPump, err := wav.NewPump(inPath, bufferSize) check(err) // asset sink asset := &amp;asset.Asset{ SampleRate: wavPump.WavSampleRate(), } // import pipe importAsset := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(asset), ) defer importAsset.Close() err = importAsset.Do(pipe.Run) check(err) // track pump track := track.New(bufferSize, asset.NumChannels()) // add samples to track track.AddFrame(198450, asset.Frame(0, 44100)) track.AddFrame(66150, asset.Frame(44100, 44100)) track.AddFrame(132300, asset.Frame(0, 44100)) // wav sink wavSink, err := wav.NewSink( outPath, wavPump.WavSampleRate(), wavPump.WavNumChannels(), wavPump.WavBitDepth(), wavPump.WavAudioFormat(), ) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // final pipe p := pipe.New( pipe.WithPump(track), pipe.WithSinks(wavSink, paSink), ) err = p.Do(pipe.Run) }</span></span></code> </pre> </div></div><br><p>  Par rapport à l'exemple précédent, il existe deux <code>pipe.Pipe</code> .  Le premier transfère les données en mémoire afin que vous puissiez couper les échantillons.  Le second a deux destinataires à la fin: <code>wav.Sink</code> et <code>portaudio.Sink</code> .  Avec ce schéma, le son est simultanément enregistré dans un fichier wav et lu. </p><br><h3 id="esche-slozhnee">  Plus dur </h3><br><p>  <strong>Tâche:</strong> lire deux fichiers wav, mélanger, traiter le plugin vst2 et enregistrer dans un nouveau fichier wav. </p><br><p>  Il y a un <code>mixer.Mixer</code> simple. <code>mixer.Mixer</code> dans le <code>mixer.Mixer</code> <code>phono/mixer</code> .  Il peut <strong>transmettre des</strong> signaux de plusieurs sources et en mélanger une.  Pour ce faire, il implémente simultanément <code>pipe.Pump</code> et <code>pipe.Sink</code> . </p><br><p>  Encore une fois, la tâche consiste en deux sous-tâches.  Le premier ressemble à ceci: </p><br><ol><li>  <strong>Obtenez le</strong> fichier audio wav </li><li>  <strong>Transférez l'</strong> audio vers la console de mixage </li></ol><br><p>  Deuxièmement: </p><br><ol><li>  <strong>Obtenez l'</strong> audio de la console de mixage. </li><li>  <strong>Traitement</strong> du plugin audio </li><li>  <strong>Transférer l'</strong> audio vers un fichier wav </li></ol><br><p><img src="https://habrastorage.org/webt/xw/hj/ad/xwhjadlajgapbhjufym72qjgssq.png" alt="example_hard"></p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/mixer"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/vst2"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> vst2sdk <span class="hljs-string"><span class="hljs-string">"github.com/dudk/vst2"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read two .wav files // Mix them // Process with vst2 // Save result into new .wav file // // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">NOTE:</span></span></span><span class="hljs-comment"> For example both wav files have same characteristics ie: sample rate, bit depth and number of channels. // In real life implicit conversion will be needed. func hard() { bs := phono.BufferSize(512) inPath1 := "../_testdata/sample1.wav" inPath2 := "../_testdata/sample2.wav" outPath := "../_testdata/out/example5.wav" // wav pump 1 wavPump1, err := wav.NewPump(inPath1, bs) check(err) // wav pump 2 wavPump2, err := wav.NewPump(inPath2, bs) check(err) // mixer mixer := mixer.New(bs, wavPump1.WavNumChannels()) // track 1 track1 := pipe.New( pipe.WithPump(wavPump1), pipe.WithSinks(mixer), ) defer track1.Close() // track 2 track2 := pipe.New( pipe.WithPump(wavPump2), pipe.WithSinks(mixer), ) defer track2.Close() // vst2 processor vst2path := "../_testdata/Krush.vst" vst2lib, err := vst2sdk.Open(vst2path) check(err) defer vst2lib.Close() vst2plugin, err := vst2lib.Open() check(err) defer vst2plugin.Close() vst2processor := vst2.NewProcessor( vst2plugin, bs, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), ) // wav sink wavSink, err := wav.NewSink( outPath, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), wavPump1.WavBitDepth(), wavPump1.WavAudioFormat(), ) check(err) // out pipe out := pipe.New( pipe.WithPump(mixer), pipe.WithProcessors(vst2processor), pipe.WithSinks(wavSink), ) defer out.Close() // run all track1Done, err := track1.Begin(pipe.Run) check(err) track2Done, err := track2.Begin(pipe.Run) check(err) outDone, err := out.Begin(pipe.Run) check(err) // wait results err = track1.Wait(track1Done) check(err) err = track2.Wait(track2Done) check(err) err = out.Wait(outDone) check(err) }</span></span></code> </pre> </div></div><br><p>  Il y a déjà trois <code>pipe.Pipe</code> , tous reliés entre eux par un mélangeur.  Pour commencer, utilisez la fonction <code>p.Begin(pipe.actionFn) (pipe.State, error)</code> .  Contrairement à l' <code>p.Do(pipe.actionFn) error</code> , il ne bloque pas l'appel, mais renvoie simplement un état qui peut ensuite être attendu avec l' <code>p.Wait(pipe.State) error</code> . </p><br><h2 id="chto-dalshe">  Et ensuite? </h2><br><p>  Je veux que le <code>phono</code> devienne le cadre d'application le plus pratique.  Si vous avez un problème avec le son, vous n'avez pas besoin de comprendre les API complexes et de passer du temps à étudier les normes.  Il suffit de construire un convoyeur à partir d'éléments appropriés et de le faire fonctionner. </p><br><p>  Pendant six mois, les packages suivants ont été filmés: </p><br><ul><li>  <code>phono/wav</code> - lire / écrire des fichiers wav </li><li>  <code>phono/vst2</code> - liaisons incomplètes du SDK VST2, alors que vous ne pouvez ouvrir que le plugin et appeler ses méthodes, mais pas toutes les structures </li><li>  <code>phono/mixer</code> - table de mixage, ajoute N signaux, sans balance ni volume </li><li>  <code>phono/asset</code> - échantillonnage tampon </li><li>  <code>phono/track</code> - lecture séquentielle des échantillons (superposition cassée) </li><li>  <code>phono/portaudio</code> - lecture du signal pendant les expériences </li></ul><br><p>  En plus de cette liste, il y a un arriéré sans cesse croissant de nouvelles idées et idées, notamment: </p><br><ul><li>  Compte à rebours </li><li>  Variable à la volée </li><li>  Pompe / évier HTTP </li><li>  Automatisation des paramètres </li><li>  Processeur de rééchantillonnage </li><li>  Balance et volume du mixeur </li><li>  Pompe en temps réel </li><li>  Pompe synchronisée pour plusieurs pistes </li><li>  Vst2 complet </li></ul><br><p>  Dans les articles suivants, j'analyserai: </p><br><ul><li>  <code>pipe.Pipe</code> vie du <code>pipe.Pipe</code> - en raison de la structure complexe, son état est contrôlé par l'atome final </li><li>  comment écrire les étapes de votre pipeline </li></ul><br><p>  Ceci est mon premier projet open-source, donc je serai reconnaissant pour toute aide et recommandations.  Vous êtes les bienvenus. </p><br><h2 id="ssylki">  Les références </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">phono</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Modèles de concurrence Go: pipelines et annulation</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424623/">https://habr.com/ru/post/fr424623/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424609/index.html">Comment étendre Kubernetes</a></li>
<li><a href="../fr424611/index.html">Comment créer un employé à partir d'un pigiste</a></li>
<li><a href="../fr424613/index.html">Expérience de l'utilisation de redux sans réducteurs</a></li>
<li><a href="../fr424615/index.html">Sortie de fonction de courbe pour limiter en douceur les paramètres, les signaux et pas seulement dans Wolfram Mathematica</a></li>
<li><a href="../fr424621/index.html">Super-héros non-film. Qui et comment protège le chantier de construction du centre de Lakhta contre les incendies?</a></li>
<li><a href="../fr424625/index.html">Fuite de code source des services Web Aeroflot</a></li>
<li><a href="../fr424627/index.html">Modification des caisses enregistreuses. Partie 1</a></li>
<li><a href="../fr424629/index.html">Comment les startups augmentent-elles leurs chances d'investir lorsqu'elles communiquent avec un investisseur?</a></li>
<li><a href="../fr424633/index.html">Comment STACKLEAK améliore la sécurité du noyau Linux</a></li>
<li><a href="../fr424635/index.html">Bienvenue dans Sberbank Data Science Journey 2018 - Course aux algorithmes d'apprentissage automatique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
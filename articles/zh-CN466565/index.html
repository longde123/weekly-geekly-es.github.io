<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¨ğŸ¿â€ğŸ”¬ ğŸ‘‡ğŸ¼ ğŸ› Python + OpenCV + Kerasï¼šåŠå°æ—¶å†…å³å¯è¯†åˆ«æ–‡æœ¬ ğŸ˜ƒ ğŸ‘¨â€ğŸ‘§ ğŸ‘¨ğŸ¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="å“ˆHa 

 åœ¨è¯•éªŒäº†ä»¥60,000ä¸ªä¼—æ‰€å‘¨çŸ¥çš„æ‰‹å†™æ•°å­—ä¸ºåŸºç¡€çš„MNISTä¹‹åï¼Œé€»è¾‘ä¸Šå‡ºç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œå³æ˜¯å¦å­˜åœ¨ç±»ä¼¼çš„ä¸œè¥¿ï¼Œä½†ä¸ä»…æ”¯æŒæ•°å­—ï¼Œè¿˜æ”¯æŒå­—æ¯ã€‚ äº‹å®è¯æ˜ï¼Œæ‚¨å¯èƒ½ä¼šçŒœåˆ°å­˜åœ¨æ‰©å±•åŸºç¡€çŸ¥è¯†ï¼ˆEMNISTï¼‰ï¼Œå¹¶ä¸”è¢«ç§°ä¸ºè¿™æ ·çš„åŸºç¡€ã€‚ 

 å¦‚æœæœ‰äººå¯¹å¦‚ä½•ä½¿ç”¨è¯¥æ•°æ®åº“æ„Ÿå…´è¶£ï¼Œå¯ä»¥è¿›è¡Œç®€å•çš„æ–‡æœ¬è¯†åˆ«ï¼Œæ¬¢...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python + OpenCV + Kerasï¼šåŠå°æ—¶å†…å³å¯è¯†åˆ«æ–‡æœ¬</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466565/"> å“ˆHa <br><br> åœ¨è¯•éªŒäº†ä»¥60,000ä¸ªä¼—æ‰€å‘¨çŸ¥çš„æ‰‹å†™æ•°å­—ä¸ºåŸºç¡€çš„MNISTä¹‹åï¼Œé€»è¾‘ä¸Šå‡ºç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œå³æ˜¯å¦å­˜åœ¨ç±»ä¼¼çš„ä¸œè¥¿ï¼Œä½†ä¸ä»…æ”¯æŒæ•°å­—ï¼Œè¿˜æ”¯æŒå­—æ¯ã€‚ äº‹å®è¯æ˜ï¼Œæ‚¨å¯èƒ½ä¼šçŒœåˆ°å­˜åœ¨æ‰©å±•åŸºç¡€çŸ¥è¯†ï¼ˆEMNISTï¼‰ï¼Œå¹¶ä¸”è¢«ç§°ä¸ºè¿™æ ·çš„åŸºç¡€ã€‚ <br><br> å¦‚æœæœ‰äººå¯¹å¦‚ä½•ä½¿ç”¨è¯¥æ•°æ®åº“æ„Ÿå…´è¶£ï¼Œå¯ä»¥è¿›è¡Œç®€å•çš„æ–‡æœ¬è¯†åˆ«ï¼Œæ¬¢è¿åŠ å…¥ã€‚ <br><br><img src="https://habrastorage.org/webt/kq/bl/4r/kqbl4rtgmtvz1xl50tzbulmdmlw.png"><br><a name="habracut"></a><br>  <i>æ³¨æ„</i> ï¼šè¿™ä¸ªä¾‹å­æ˜¯å®éªŒæ€§çš„å’Œæ•™è‚²æ€§çš„ï¼Œæˆ‘åªæ˜¯æƒ³çœ‹çœ‹å®ƒå¸¦æ¥äº†ä»€ä¹ˆã€‚ æˆ‘æ²¡æœ‰è®¡åˆ’ä¹Ÿæ²¡æœ‰è®¡åˆ’åšç¬¬äºŒä¸ªFineReaderï¼Œæ‰€ä»¥è¿™é‡Œçš„è®¸å¤šäº‹æƒ…å½“ç„¶éƒ½æ²¡æœ‰å®ç°ã€‚ å› æ­¤ï¼Œä¸æ¥å—â€œä¸ºä»€ä¹ˆâ€ï¼Œâ€œå·²ç»æ›´å¥½â€ç­‰æ ·å¼çš„å£°æ˜ã€‚ å¯èƒ½å·²ç»æœ‰é€‚ç”¨äºPythonçš„ç°æˆçš„OCRåº“ï¼Œä½†æ˜¯è‡ªå·±åšæ˜¯å¾ˆæœ‰è¶£çš„ã€‚ é¡ºä¾¿è¯´ä¸€å¥ï¼Œå¯¹äºé‚£äº›æƒ³äº†è§£çœŸæ­£çš„FineReaderçš„åˆ¶ä½œæ–¹å¼çš„äººï¼Œä»–ä»¬åœ¨HabrÃ©åšå®¢ä¸Šæœ‰2014å¹´çš„ä¸¤ç¯‡æ–‡ç« ï¼š <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">1</a>å’Œ<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2</a> ï¼ˆä½†å½“ç„¶æ²¡æœ‰ä»»ä½•å…¬å¸åšå®¢ä¸­çš„æºä»£ç å’Œè¯¦ç»†ä¿¡æ¯ï¼‰ã€‚ å¥½å§ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼Œä¸€åˆ‡éƒ½åœ¨è¿™é‡Œæ‰“å¼€ï¼Œä¸€åˆ‡éƒ½å¼€æºã€‚ <br><br> ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨çº¯æ–‡æœ¬ã€‚ è¿™æ˜¯ä¸€ä¸ªï¼š <br><br><h3> ä½ å¥½ä¸–ç•Œ </h3><br> è®©æˆ‘ä»¬çœ‹çœ‹å¯ä»¥ç”¨å®ƒåšä»€ä¹ˆã€‚ <br><br><h2> å°†æ–‡å­—åˆ†è§£ä¸ºå­—æ¯ </h2><br> ç¬¬ä¸€æ­¥æ˜¯å°†æ–‡æœ¬åˆ†æˆå•ç‹¬çš„å­—æ¯ã€‚  OpenCVä¸ºæ­¤å¾ˆæœ‰ç”¨ï¼Œæ›´ç¡®åˆ‡åœ°è¯´æ˜¯å®ƒçš„findContourså‡½æ•°ã€‚ <br><br> æ‰“å¼€å›¾åƒï¼ˆcv2.imreadï¼‰ï¼Œå°†å…¶è½¬æ¢ä¸ºé»‘ç™½ï¼ˆcv2.cvtColor + cv2.thresholdï¼‰ï¼Œç•¥å¾®å¢å¤§ï¼ˆcv2.erodeï¼‰å¹¶æ‰¾åˆ°è½®å»“ã€‚ <br><br><pre><code class="python hljs">image_file = <span class="hljs-string"><span class="hljs-string">"text.png"</span></span> img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), np.uint8), iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) cv2.imshow("Input", img) cv2.imshow("Enlarged", img_erode) cv2.imshow("Output", output) cv2.waitKey(0)</span></span></code> </pre> <br> æˆ‘ä»¬å¾—åˆ°äº†è½®å»“çš„åˆ†å±‚æ ‘ï¼ˆå‚æ•°cv2.RETR_TREEï¼‰ã€‚ é¦–å…ˆæ˜¯å›¾ç‰‡çš„æ€»ä½“è½®å»“ï¼Œç„¶åæ˜¯å­—æ¯çš„è½®å»“ï¼Œç„¶åæ˜¯å†…éƒ¨è½®å»“ã€‚ æˆ‘ä»¬åªéœ€è¦å­—æ¯çš„è½®å»“ï¼Œå› æ­¤æˆ‘æ£€æŸ¥â€œè½®å»“â€æ˜¯å¦æ˜¯æ•´ä½“è½®å»“ã€‚ è¿™æ˜¯ä¸€ç§ç®€åŒ–çš„æ–¹æ³•ï¼Œå°½ç®¡å¯¹äºè¯†åˆ«å±å¹•æˆªå›¾å¹¶ä¸é‡è¦ï¼Œä½†å¯¹äºå®é™…æ‰«æè€Œè¨€ï¼Œè¿™å¯èƒ½ä¸èµ·ä½œç”¨ã€‚ <br><br> ç»“æœï¼š <br><br><img src="https://habrastorage.org/webt/7j/zi/pg/7jzipgqvc9ebvxgu2j7c_ubr-rw.png"><br><br> ä¸‹ä¸€æ­¥æ˜¯ä¿å­˜æ¯ä¸ªå­—æ¯ï¼Œä¹‹å‰å·²å°†å…¶ç¼©æ”¾ä¸º28x28æ­£æ–¹å½¢ï¼ˆä»¥è¿™ç§æ ¼å¼å­˜å‚¨MNISTæ•°æ®åº“ï¼‰ã€‚  OpenCVåŸºäºnumpyæ„å»ºï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¤„ç†æ•°ç»„çš„åŠŸèƒ½è¿›è¡Œè£å‰ªå’Œç¼©æ”¾ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">letters_extract</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image_file: str, out_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">28</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> -&gt; List[Any]:</span></span> img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), np.uint8), iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() letters = [] for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) letter_crop = gray[y:y + h, x:x + w] # print(letter_crop.shape) # Resize letter canvas to square size_max = max(w, h) letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8) if w &gt; h: # Enlarge image top-bottom # ------ # ====== # ------ y_pos = size_max//2 - h//2 letter_square[y_pos:y_pos + h, 0:w] = letter_crop elif w &lt; h: # Enlarge image left-right # --||-- x_pos = size_max//2 - w//2 letter_square[0:h, x_pos:x_pos + w] = letter_crop else: letter_square = letter_crop # Resize letter to 28x28 and add letter and its X-coordinate letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA))) # Sort array in place by X-coordinate letters.sort(key=lambda x: x[0], reverse=False) return letters</span></span></code> </pre><br> æœ€åï¼Œæˆ‘ä»¬æŒ‰ç…§Xåæ ‡å¯¹å­—æ¯è¿›è¡Œæ’åºï¼Œå¦‚æ‚¨æ‰€è§ï¼Œæˆ‘ä»¬å°†ç»“æœä¿å­˜ä¸ºå…ƒç»„ï¼ˆxï¼Œwï¼Œå­—æ¯ï¼‰çš„å½¢å¼ï¼Œä»¥ä¾¿å¯ä»¥ä»å­—æ¯ä¹‹é—´çš„ç©ºæ ¼ä¸­é€‰æ‹©ç©ºæ ¼ã€‚ <br><br> ç¡®ä¿ä¸€åˆ‡æ­£å¸¸ï¼š <br><br><pre> <code class="python hljs">cv2.imshow(<span class="hljs-string"><span class="hljs-string">"0"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"1"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"2"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">2</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"3"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">3</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"4"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">4</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.waitKey(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/j-/uw/yh/j-uwyhhh8l0yrapth5u6fy9na0u.png"><br><br> å­—æ¯å·²å‡†å¤‡å¥½è¢«è¯†åˆ«ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å·ç§¯ç½‘ç»œæ¥è¯†åˆ«å®ƒä»¬-è¿™ç§ç±»å‹çš„ç½‘ç»œéå¸¸é€‚åˆæ­¤ç±»ä»»åŠ¡ã€‚ <br><br><h2> ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œè¯†åˆ« </h2><br> æºEMNISTæ•°æ®é›†å…·æœ‰62ä¸ªä¸åŒçš„å­—ç¬¦ï¼ˆA..Zï¼Œ0..9ç­‰ï¼‰ï¼š <br><br><pre> <code class="python hljs">emnist_labels = [<span class="hljs-number"><span class="hljs-number">48</span></span>, <span class="hljs-number"><span class="hljs-number">49</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">51</span></span>, <span class="hljs-number"><span class="hljs-number">52</span></span>, <span class="hljs-number"><span class="hljs-number">53</span></span>, <span class="hljs-number"><span class="hljs-number">54</span></span>, <span class="hljs-number"><span class="hljs-number">55</span></span>, <span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">57</span></span>, <span class="hljs-number"><span class="hljs-number">65</span></span>, <span class="hljs-number"><span class="hljs-number">66</span></span>, <span class="hljs-number"><span class="hljs-number">67</span></span>, <span class="hljs-number"><span class="hljs-number">68</span></span>, <span class="hljs-number"><span class="hljs-number">69</span></span>, <span class="hljs-number"><span class="hljs-number">70</span></span>, <span class="hljs-number"><span class="hljs-number">71</span></span>, <span class="hljs-number"><span class="hljs-number">72</span></span>, <span class="hljs-number"><span class="hljs-number">73</span></span>, <span class="hljs-number"><span class="hljs-number">74</span></span>, <span class="hljs-number"><span class="hljs-number">75</span></span>, <span class="hljs-number"><span class="hljs-number">76</span></span>, <span class="hljs-number"><span class="hljs-number">77</span></span>, <span class="hljs-number"><span class="hljs-number">78</span></span>, <span class="hljs-number"><span class="hljs-number">79</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>, <span class="hljs-number"><span class="hljs-number">82</span></span>, <span class="hljs-number"><span class="hljs-number">83</span></span>, <span class="hljs-number"><span class="hljs-number">84</span></span>, <span class="hljs-number"><span class="hljs-number">85</span></span>, <span class="hljs-number"><span class="hljs-number">86</span></span>, <span class="hljs-number"><span class="hljs-number">87</span></span>, <span class="hljs-number"><span class="hljs-number">88</span></span>, <span class="hljs-number"><span class="hljs-number">89</span></span>, <span class="hljs-number"><span class="hljs-number">90</span></span>, <span class="hljs-number"><span class="hljs-number">97</span></span>, <span class="hljs-number"><span class="hljs-number">98</span></span>, <span class="hljs-number"><span class="hljs-number">99</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">101</span></span>, <span class="hljs-number"><span class="hljs-number">102</span></span>, <span class="hljs-number"><span class="hljs-number">103</span></span>, <span class="hljs-number"><span class="hljs-number">104</span></span>, <span class="hljs-number"><span class="hljs-number">105</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">107</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">113</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>, <span class="hljs-number"><span class="hljs-number">116</span></span>, <span class="hljs-number"><span class="hljs-number">117</span></span>, <span class="hljs-number"><span class="hljs-number">118</span></span>, <span class="hljs-number"><span class="hljs-number">119</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">121</span></span>, <span class="hljs-number"><span class="hljs-number">122</span></span>]</code> </pre> <br> å› æ­¤ï¼Œç¥ç»ç½‘ç»œå…·æœ‰62ä¸ªè¾“å‡ºï¼Œåœ¨è¾“å…¥å¤„å®ƒå°†æ¥æ”¶28x28å›¾åƒï¼Œåœ¨è¯†åˆ«â€œ 1â€ä¹‹åå°†åœ¨ç›¸åº”çš„ç½‘ç»œè¾“å‡ºå¤„ã€‚ <br><br> åˆ›å»ºä¸€ä¸ªç½‘ç»œæ¨¡å‹ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> optimizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGD, RMSprop, Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.constraints <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> maxnorm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">emnist_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() model.add(Convolution2D(filters=<span class="hljs-number"><span class="hljs-number">32</span></span>, kernel_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Convolution2D(filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, kernel_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)) model.add(Flatten()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)) model.add(Dense(len(emnist_labels), activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adadelta'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br> å¦‚æ‚¨æ‰€è§ï¼Œè¿™æ˜¯ä¸€ä¸ªç»å…¸çš„å·ç§¯ç½‘ç»œï¼Œçªå‡ºæ˜¾ç¤ºå›¾åƒçš„æŸäº›ç‰¹å¾ï¼ˆæ»¤æ³¢å™¨32å’Œ64çš„æ•°é‡ï¼‰ï¼Œâ€œçº¿æ€§â€ MLPç½‘ç»œè¿æ¥åˆ°è¯¥å›¾åƒçš„â€œè¾“å‡ºâ€ï¼Œå½¢æˆæœ€ç»ˆç»“æœã€‚ <br><br><h2> ç¥ç»ç½‘ç»œè®­ç»ƒ </h2><br> æˆ‘ä»¬è¿›å…¥äº†æœ€é•¿çš„é˜¶æ®µ-ç½‘ç»œåŸ¹è®­ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨EMNISTæ•°æ®åº“ï¼Œè¯¥æ•°æ®åº“å¯ä»¥<a href="">ä»é“¾æ¥</a>ä¸‹è½½ï¼ˆå­˜æ¡£å¤§å°536Mbï¼‰ã€‚ <br><br> è¦è¯»å–æ•°æ®åº“ï¼Œè¯·ä½¿ç”¨idx2numpyåº“ã€‚ æˆ‘ä»¬å°†å‡†å¤‡æ•°æ®è¿›è¡ŒåŸ¹è®­å’ŒéªŒè¯ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> idx2numpy emnist_path = <span class="hljs-string"><span class="hljs-string">'/home/Documents/TestApps/keras/emnist/'</span></span> X_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-train-images-idx3-ubyte'</span></span>) y_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-train-labels-idx1-ubyte'</span></span>) X_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-test-images-idx3-ubyte'</span></span>) y_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-test-labels-idx1-ubyte'</span></span>) X_train = np.reshape(X_train, (X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) X_test = np.reshape(X_test, (X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels)) k = <span class="hljs-number"><span class="hljs-number">10</span></span> X_train = X_train[:X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] y_train = y_train[:y_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] X_test = X_test[:X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] y_test = y_test[:y_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] <span class="hljs-comment"><span class="hljs-comment"># Normalize X_train = X_train.astype(np.float32) X_train /= 255.0 X_test = X_test.astype(np.float32) X_test /= 255.0 x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels)) y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))</span></span></code> </pre><br> æˆ‘ä»¬å‡†å¤‡äº†ä¸¤å¥—è®­ç»ƒå’ŒéªŒè¯å¥—ä»¶ã€‚ å­—ç¬¦æœ¬èº«æ˜¯æ˜“äºæ˜¾ç¤ºçš„æ™®é€šæ•°ç»„ï¼š <br><br><img src="https://habrastorage.org/webt/lb/uj/yt/lbujytoizk2gxviahqxz5emvgay.png"><br><br> æˆ‘ä»¬è¿˜ä»…ä½¿ç”¨æ•°æ®é›†çš„1/10è¿›è¡Œè®­ç»ƒï¼ˆå‚æ•°kï¼‰ï¼Œå¦åˆ™è¯¥è¿‡ç¨‹å°†è‡³å°‘èŠ±è´¹10ä¸ªå°æ—¶ã€‚ <br><br> æˆ‘ä»¬å¼€å§‹ç½‘ç»œè®­ç»ƒï¼Œåœ¨è¿‡ç¨‹ç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†è®­ç»ƒåçš„æ¨¡å‹ä¿å­˜åˆ°ç£ç›˜ä¸­ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Set a learning rate reduction learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) # Required for learning_rate_reduction: keras.backend.get_session().run(tf.global_variables_initializer()) model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30) model.save('emnist_letters.h5')</span></span></code> </pre> <br> å­¦ä¹ è¿‡ç¨‹æœ¬èº«å¤§çº¦éœ€è¦åŠå°æ—¶ï¼š <br><br><img src="https://habrastorage.org/webt/vu/xv/_s/vuxv_s6hsxg1q0gxcqapd0o3bv8.png"><br><br> è¿™ä»…éœ€è¦æ‰§è¡Œä¸€æ¬¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†ä½¿ç”¨å·²ç»ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ã€‚ åŸ¹è®­å®Œæˆåï¼Œä¸€åˆ‡å°±ç»ªï¼Œæ‚¨å¯ä»¥è¯†åˆ«æ–‡æœ¬ã€‚ <br><br><h2> è®¤å¯åº¦ </h2><br> ä¸ºäº†è¯†åˆ«ï¼Œæˆ‘ä»¬åŠ è½½æ¨¡å‹å¹¶è°ƒç”¨predict_classeså‡½æ•°ã€‚ <br><br><pre> <code class="python hljs">model = keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'emnist_letters.h5'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">emnist_predict_img</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, img)</span></span></span><span class="hljs-function">:</span></span> img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) img_arr = <span class="hljs-number"><span class="hljs-number">1</span></span> - img_arr/<span class="hljs-number"><span class="hljs-number">255.0</span></span> img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>] = np.rot90(img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">3</span></span>) img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>] = np.fliplr(img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>]) img_arr = img_arr.reshape((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) result = model.predict_classes([img_arr]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> chr(emnist_labels[result[<span class="hljs-number"><span class="hljs-number">0</span></span>]])</code> </pre> <br> äº‹å®è¯æ˜ï¼Œæ•°æ®é›†ä¸­çš„å›¾åƒæœ€åˆæ˜¯æ—‹è½¬çš„ï¼Œå› æ­¤åœ¨è¯†åˆ«ä¹‹å‰æˆ‘ä»¬å¿…é¡»æ—‹è½¬å›¾åƒã€‚ <br><br> æœ€ç»ˆå‡½æ•°åœ¨è¾“å…¥ç«¯æ¥æ”¶å¸¦æœ‰å›¾åƒçš„æ–‡ä»¶ï¼Œåœ¨è¾“å‡ºç«¯ç»™å‡ºä¸€è¡Œï¼Œè¯¥å‡½æ•°ä»…å ç”¨10è¡Œä»£ç ï¼š <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">img_to_str</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model: Any, image_file: str)</span></span></span><span class="hljs-function">:</span></span> letters = letters_extract(image_file) s_out = <span class="hljs-string"><span class="hljs-string">""</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(letters)): dn = letters[i+<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] - letters[i][<span class="hljs-number"><span class="hljs-number">0</span></span>] - letters[i][<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i &lt; len(letters) - <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> s_out += emnist_predict_img(model, letters[i][<span class="hljs-number"><span class="hljs-number">2</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (dn &gt; letters[i][<span class="hljs-number"><span class="hljs-number">1</span></span>]/<span class="hljs-number"><span class="hljs-number">4</span></span>): s_out += <span class="hljs-string"><span class="hljs-string">' '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s_out</code> </pre> <br> å¦‚æœå­—æ¯ä¹‹é—´çš„é—´è·å¤§äºå­—ç¬¦çš„1/4ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥å‰ä¿å­˜çš„å­—ç¬¦å®½åº¦æ·»åŠ ç©ºæ ¼ã€‚ <br><br> ç”¨æ³•ç¤ºä¾‹ï¼š <br><pre> <code class="python hljs">model = keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'emnist_letters.h5'</span></span>) s_out = img_to_str(model, <span class="hljs-string"><span class="hljs-string">"hello_world.png"</span></span>) print(s_out)</code> </pre><br> ç»“æœï¼š <br><img src="https://habrastorage.org/webt/ck/r5/iq/ckr5iqlfoiokza60cleu3w1x-hg.png"><br><br> ä¸€ä¸ªæœ‰è¶£çš„ç‰¹å¾æ˜¯ç¥ç»ç½‘ç»œâ€œæ··æ·†â€äº†å­—æ¯â€œ Oâ€å’Œæ•°å­—â€œ 0â€ï¼Œä½†è¿™å¹¶ä¸å¥‡æ€ªï¼Œå› ä¸º  EMNISTçš„åŸå§‹é›†åŒ…å«<i>æ‰‹å†™</i>å­—æ¯å’Œæ•°å­—ï¼Œä¸å°åˆ·çš„å­—æ¯å’Œæ•°å­—å¹¶ä¸å®Œå…¨ç›¸åŒã€‚ ç†æƒ³æƒ…å†µä¸‹ï¼Œè¦è¯†åˆ«å±å¹•æ–‡æœ¬ï¼Œæ‚¨éœ€è¦æ ¹æ®å±å¹•å­—ä½“å‡†å¤‡ä¸€ä¸ªå•ç‹¬çš„é›†åˆï¼Œå¹¶å·²ç»åœ¨å…¶ä¸Šè®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œã€‚ <br><br><h2> ç»“è®º </h2><br> å¦‚æ‚¨æ‰€è§ï¼Œä¸æ˜¯ä¼—ç¥åœ¨çƒ§é”…ï¼Œè€Œåœ¨ç°ä»£å›¾ä¹¦é¦†çš„å¸®åŠ©ä¸‹æ›¾ç»çœ‹èµ·æ¥â€œç¥å¥‡â€çš„äº‹æƒ…å˜å¾—éå¸¸ç®€å•ã€‚ <br><br> ç”±äºPythonæ˜¯è·¨å¹³å°çš„ï¼Œå› æ­¤ä»£ç å¯ä»¥åœ¨Windowsï¼ŒLinuxå’ŒOSXä¸Šçš„ä»»ä½•åœ°æ–¹ä½¿ç”¨ã€‚ å°±åƒKerasç§»æ¤åˆ°iOS / Androidä¸Šä¸€æ ·ï¼Œä»ç†è®ºä¸Šè®²ï¼Œç»è¿‡è®­ç»ƒçš„æ¨¡å‹ä¹Ÿå¯ä»¥åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ç§»åŠ¨è®¾å¤‡ä¸Šä½¿ç”¨</a> ã€‚ <br><br> å¯¹äºé‚£äº›æƒ³è‡ªå·±å°è¯•çš„äººï¼Œæºä»£ç ä½äºç ´åè€…çš„ä¸‹é¢ã€‚ <br><br><div class="spoiler">  <b class="spoiler_title">keras_emnist.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Code source: dmitryelj@gmail.com import os # Force CPU # os.environ["CUDA_VISIBLE_DEVICES"] = "-1" # Debug messages # 0 = all messages are logged (default behavior) # 1 = INFO messages are not printed # 2 = INFO and WARNING messages are not printed # 3 = INFO, WARNING, and ERROR messages are not printed os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' import cv2 import imghdr import numpy as np import pathlib from tensorflow import keras from keras.models import Sequential from keras import optimizers from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization from keras.optimizers import SGD, RMSprop, Adam from keras import backend as K from keras.constraints import maxnorm import tensorflow as tf from scipy import io as spio import idx2numpy # sudo pip3 install idx2numpy from matplotlib import pyplot as plt from typing import * import time # Dataset: # https://www.nist.gov/node/1298471/emnist-dataset # https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip def cnn_print_digit(d): print(d.shape) for x in range(28): s = "" for y in range(28): s += "{0:.1f} ".format(d[28*y + x]) print(s) def cnn_print_digit_2d(d): print(d.shape) for y in range(d.shape[0]): s = "" for x in range(d.shape[1]): s += "{0:.1f} ".format(d[x][y]) print(s) emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122] def emnist_model(): model = Sequential() model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(28, 28, 1), activation='relu')) model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) return model def emnist_model2(): model = Sequential() # In Keras there are two options for padding: same or valid. Same means we pad with the number on the edge and valid means no padding. model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Convolution2D(64, (3, 3), activation='relu', padding='same')) model.add(MaxPooling2D((2, 2))) model.add(Convolution2D(128, (3, 3), activation='relu', padding='same')) model.add(MaxPooling2D((2, 2))) # model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) # model.add(MaxPooling2D((2, 2))) ## model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) return model def emnist_model3(): model = Sequential() model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu')) model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')) model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation="relu")) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation="softmax")) model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), metrics=['accuracy']) return model def emnist_train(model): t_start = time.time() emnist_path = 'D:\\Temp\\1\\' X_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-images-idx3-ubyte') y_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-labels-idx1-ubyte') X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-images-idx3-ubyte') y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-labels-idx1-ubyte') X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1)) X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1)) print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels)) # Test: k = 10 X_train = X_train[:X_train.shape[0] // k] y_train = y_train[:y_train.shape[0] // k] X_test = X_test[:X_test.shape[0] // k] y_test = y_test[:y_test.shape[0] // k] # Normalize X_train = X_train.astype(np.float32) X_train /= 255.0 X_test = X_test.astype(np.float32) X_test /= 255.0 x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels)) y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels)) # Set a learning rate reduction learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) # Required for learning_rate_reduction: keras.backend.get_session().run(tf.global_variables_initializer()) model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30) print("Training done, dT:", time.time() - t_start) def emnist_predict(model, image_file): img = keras.preprocessing.image.load_img(image_file, target_size=(28, 28), color_mode='grayscale') emnist_predict_img(model, img) def emnist_predict_img(model, img): img_arr = np.expand_dims(img, axis=0) img_arr = 1 - img_arr/255.0 img_arr[0] = np.rot90(img_arr[0], 3) img_arr[0] = np.fliplr(img_arr[0]) img_arr = img_arr.reshape((1, 28, 28, 1)) result = model.predict_classes([img_arr]) return chr(emnist_labels[result[0]]) def letters_extract(image_file: str, out_size=28): img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1) # Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() letters = [] for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) letter_crop = gray[y:y + h, x:x + w] # print(letter_crop.shape) # Resize letter canvas to square size_max = max(w, h) letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8) if w &gt; h: # Enlarge image top-bottom # ------ # ====== # ------ y_pos = size_max//2 - h//2 letter_square[y_pos:y_pos + h, 0:w] = letter_crop elif w &lt; h: # Enlarge image left-right # --||-- x_pos = size_max//2 - w//2 letter_square[0:h, x_pos:x_pos + w] = letter_crop else: letter_square = letter_crop # Resize letter to 28x28 and add letter and its X-coordinate letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA))) # Sort array in place by X-coordinate letters.sort(key=lambda x: x[0], reverse=False) # cv2.imshow("Input", img) # # cv2.imshow("Gray", thresh) # cv2.imshow("Enlarged", img_erode) # cv2.imshow("Output", output) # cv2.imshow("0", letters[0][2]) # cv2.imshow("1", letters[1][2]) # cv2.imshow("2", letters[2][2]) # cv2.imshow("3", letters[3][2]) # cv2.imshow("4", letters[4][2]) # cv2.waitKey(0) return letters def img_to_str(model: Any, image_file: str): letters = letters_extract(image_file) s_out = "" for i in range(len(letters)): dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i &lt; len(letters) - 1 else 0 s_out += emnist_predict_img(model, letters[i][2]) if (dn &gt; letters[i][1]/4): s_out += ' ' return s_out if __name__ == "__main__": # model = emnist_model() # emnist_train(model) # model.save('emnist_letters.h5') model = keras.models.load_model('emnist_letters.h5') s_out = img_to_str(model, "hello_world.png") print(s_out)</span></span></code> </pre><br></div></div><br> ä¸å¾€å¸¸ä¸€æ ·ï¼Œæ‰€æœ‰æˆåŠŸçš„å®éªŒã€‚ </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN466565/">https://habr.com/ru/post/zh-CN466565/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN466555/index.html">ä»gitlab.comæ‰¾åˆ°è§£å†³å¤§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆä¸­å­¦åˆ°çš„6è¯¾ã€‚ ç¬¬ä¸€éƒ¨åˆ†</a></li>
<li><a href="../zh-CN466557/index.html">å¦‚ä½•ä¸ºç½‘ç«™åˆ›å»ºå¸ƒå±€è€Œä¸æ˜¯ä¿æŒæç«¯</a></li>
<li><a href="../zh-CN466559/index.html">è®©æˆ‘ä»¬æ¥çœ‹çœ‹æ–°çš„Var</a></li>
<li><a href="../zh-CN466561/index.html">éœ€è¦ç»å¯¹é€æ˜çš„é€‰æ‹©ï¼Ÿ -æˆ‘æœ‰</a></li>
<li><a href="../zh-CN466563/index.html">æˆæœ¬ï¼šæ–°æŠ€æœ¯å †æ ˆä¸­åŒ…å«çš„ç”¨äºå¼€å‘äº‘åº”ç”¨ç¨‹åºçš„å†…å®¹</a></li>
<li><a href="../zh-CN466569/index.html">è«æ–¯ç§‘äº¤æ˜“æ‰€çš„é¦–æ¬¡å…¬å¼€å‹Ÿè‚¡ï¼šä¸ºä½•éœ€è¦ï¼Œç”±è°è¿›è¡Œä»¥åŠå¦‚ä½•è´­ä¹°è‚¡ç¥¨</a></li>
<li><a href="../zh-CN466571/index.html">Tesseract OCRæŠ€å·§-åˆ›å»ºè‡ªå·±çš„è¯æ±‡è¡¨ä»¥æé«˜OCRæ€§èƒ½</a></li>
<li><a href="../zh-CN466573/index.html">ç»™æœªæ¥é›‡ä¸»çš„é—®é¢˜</a></li>
<li><a href="../zh-CN466575/index.html">å°†äºŒç»´åˆ—è¡¨ä»pythonä¼ é€’åˆ°DLL</a></li>
<li><a href="../zh-CN466577/index.html">ä¸¤ä¸ªå­¦ç”Ÿå¦‚ä½•åœ¨iOSä¸‹åˆ¶ä½œæ¸¸æˆä»¥åŠä»–ä»¬èµšäº†å¤šå°‘é’±</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍🔬 👇🏼 🛁 Python + OpenCV + Keras：半小时内即可识别文本 😃 👨‍👧 👨🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="哈Ha 

 在试验了以60,000个众所周知的手写数字为基础的MNIST之后，逻辑上出现了一个问题，即是否存在类似的东西，但不仅支持数字，还支持字母。 事实证明，您可能会猜到存在扩展基础知识（EMNIST），并且被称为这样的基础。 

 如果有人对如何使用该数据库感兴趣，可以进行简单的文本识别，欢...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python + OpenCV + Keras：半小时内即可识别文本</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466565/"> 哈Ha <br><br> 在试验了以60,000个众所周知的手写数字为基础的MNIST之后，逻辑上出现了一个问题，即是否存在类似的东西，但不仅支持数字，还支持字母。 事实证明，您可能会猜到存在扩展基础知识（EMNIST），并且被称为这样的基础。 <br><br> 如果有人对如何使用该数据库感兴趣，可以进行简单的文本识别，欢迎加入。 <br><br><img src="https://habrastorage.org/webt/kq/bl/4r/kqbl4rtgmtvz1xl50tzbulmdmlw.png"><br><a name="habracut"></a><br>  <i>注意</i> ：这个例子是实验性的和教育性的，我只是想看看它带来了什么。 我没有计划也没有计划做第二个FineReader，所以这里的许多事情当然都没有实现。 因此，不接受“为什么”，“已经更好”等样式的声明。 可能已经有适用于Python的现成的OCR库，但是自己做是很有趣的。 顺便说一句，对于那些想了解真正的FineReader的制作方式的人，他们在Habré博客上有2014年的两篇文章： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">1</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2</a> （但当然没有任何公司博客中的源代码和详细信息）。 好吧，让我们开始吧，一切都在这里打开，一切都开源。 <br><br> 例如，我们将使用纯文本。 这是一个： <br><br><h3> 你好世界 </h3><br> 让我们看看可以用它做什么。 <br><br><h2> 将文字分解为字母 </h2><br> 第一步是将文本分成单独的字母。  OpenCV为此很有用，更确切地说是它的findContours函数。 <br><br> 打开图像（cv2.imread），将其转换为黑白（cv2.cvtColor + cv2.threshold），略微增大（cv2.erode）并找到轮廓。 <br><br><pre><code class="python hljs">image_file = <span class="hljs-string"><span class="hljs-string">"text.png"</span></span> img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), np.uint8), iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) cv2.imshow("Input", img) cv2.imshow("Enlarged", img_erode) cv2.imshow("Output", output) cv2.waitKey(0)</span></span></code> </pre> <br> 我们得到了轮廓的分层树（参数cv2.RETR_TREE）。 首先是图片的总体轮廓，然后是字母的轮廓，然后是内部轮廓。 我们只需要字母的轮廓，因此我检查“轮廓”是否是整体轮廓。 这是一种简化的方法，尽管对于识别屏幕截图并不重要，但对于实际扫描而言，这可能不起作用。 <br><br> 结果： <br><br><img src="https://habrastorage.org/webt/7j/zi/pg/7jzipgqvc9ebvxgu2j7c_ubr-rw.png"><br><br> 下一步是保存每个字母，之前已将其缩放为28x28正方形（以这种格式存储MNIST数据库）。  OpenCV基于numpy构建，因此我们可以使用处理数组的功能进行裁剪和缩放。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">letters_extract</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image_file: str, out_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">28</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> -&gt; List[Any]:</span></span> img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), np.uint8), iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() letters = [] for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) letter_crop = gray[y:y + h, x:x + w] # print(letter_crop.shape) # Resize letter canvas to square size_max = max(w, h) letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8) if w &gt; h: # Enlarge image top-bottom # ------ # ====== # ------ y_pos = size_max//2 - h//2 letter_square[y_pos:y_pos + h, 0:w] = letter_crop elif w &lt; h: # Enlarge image left-right # --||-- x_pos = size_max//2 - w//2 letter_square[0:h, x_pos:x_pos + w] = letter_crop else: letter_square = letter_crop # Resize letter to 28x28 and add letter and its X-coordinate letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA))) # Sort array in place by X-coordinate letters.sort(key=lambda x: x[0], reverse=False) return letters</span></span></code> </pre><br> 最后，我们按照X坐标对字母进行排序，如您所见，我们将结果保存为元组（x，w，字母）的形式，以便可以从字母之间的空格中选择空格。 <br><br> 确保一切正常： <br><br><pre> <code class="python hljs">cv2.imshow(<span class="hljs-string"><span class="hljs-string">"0"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"1"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"2"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">2</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"3"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">3</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"4"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">4</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.waitKey(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/j-/uw/yh/j-uwyhhh8l0yrapth5u6fy9na0u.png"><br><br> 字母已准备好被识别，我们将使用卷积网络来识别它们-这种类型的网络非常适合此类任务。 <br><br><h2> 神经网络（CNN）进行识别 </h2><br> 源EMNIST数据集具有62个不同的字符（A..Z，0..9等）： <br><br><pre> <code class="python hljs">emnist_labels = [<span class="hljs-number"><span class="hljs-number">48</span></span>, <span class="hljs-number"><span class="hljs-number">49</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">51</span></span>, <span class="hljs-number"><span class="hljs-number">52</span></span>, <span class="hljs-number"><span class="hljs-number">53</span></span>, <span class="hljs-number"><span class="hljs-number">54</span></span>, <span class="hljs-number"><span class="hljs-number">55</span></span>, <span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">57</span></span>, <span class="hljs-number"><span class="hljs-number">65</span></span>, <span class="hljs-number"><span class="hljs-number">66</span></span>, <span class="hljs-number"><span class="hljs-number">67</span></span>, <span class="hljs-number"><span class="hljs-number">68</span></span>, <span class="hljs-number"><span class="hljs-number">69</span></span>, <span class="hljs-number"><span class="hljs-number">70</span></span>, <span class="hljs-number"><span class="hljs-number">71</span></span>, <span class="hljs-number"><span class="hljs-number">72</span></span>, <span class="hljs-number"><span class="hljs-number">73</span></span>, <span class="hljs-number"><span class="hljs-number">74</span></span>, <span class="hljs-number"><span class="hljs-number">75</span></span>, <span class="hljs-number"><span class="hljs-number">76</span></span>, <span class="hljs-number"><span class="hljs-number">77</span></span>, <span class="hljs-number"><span class="hljs-number">78</span></span>, <span class="hljs-number"><span class="hljs-number">79</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>, <span class="hljs-number"><span class="hljs-number">82</span></span>, <span class="hljs-number"><span class="hljs-number">83</span></span>, <span class="hljs-number"><span class="hljs-number">84</span></span>, <span class="hljs-number"><span class="hljs-number">85</span></span>, <span class="hljs-number"><span class="hljs-number">86</span></span>, <span class="hljs-number"><span class="hljs-number">87</span></span>, <span class="hljs-number"><span class="hljs-number">88</span></span>, <span class="hljs-number"><span class="hljs-number">89</span></span>, <span class="hljs-number"><span class="hljs-number">90</span></span>, <span class="hljs-number"><span class="hljs-number">97</span></span>, <span class="hljs-number"><span class="hljs-number">98</span></span>, <span class="hljs-number"><span class="hljs-number">99</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">101</span></span>, <span class="hljs-number"><span class="hljs-number">102</span></span>, <span class="hljs-number"><span class="hljs-number">103</span></span>, <span class="hljs-number"><span class="hljs-number">104</span></span>, <span class="hljs-number"><span class="hljs-number">105</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">107</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">113</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>, <span class="hljs-number"><span class="hljs-number">116</span></span>, <span class="hljs-number"><span class="hljs-number">117</span></span>, <span class="hljs-number"><span class="hljs-number">118</span></span>, <span class="hljs-number"><span class="hljs-number">119</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">121</span></span>, <span class="hljs-number"><span class="hljs-number">122</span></span>]</code> </pre> <br> 因此，神经网络具有62个输出，在输入处它将接收28x28图像，在识别“ 1”之后将在相应的网络输出处。 <br><br> 创建一个网络模型。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> optimizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGD, RMSprop, Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.constraints <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> maxnorm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">emnist_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() model.add(Convolution2D(filters=<span class="hljs-number"><span class="hljs-number">32</span></span>, kernel_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Convolution2D(filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, kernel_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)) model.add(Flatten()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)) model.add(Dense(len(emnist_labels), activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adadelta'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br> 如您所见，这是一个经典的卷积网络，突出显示图像的某些特征（滤波器32和64的数量），“线性” MLP网络连接到该图像的“输出”，形成最终结果。 <br><br><h2> 神经网络训练 </h2><br> 我们进入了最长的阶段-网络培训。 为此，我们使用EMNIST数据库，该数据库可以<a href="">从链接</a>下载（存档大小536Mb）。 <br><br> 要读取数据库，请使用idx2numpy库。 我们将准备数据进行培训和验证。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> idx2numpy emnist_path = <span class="hljs-string"><span class="hljs-string">'/home/Documents/TestApps/keras/emnist/'</span></span> X_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-train-images-idx3-ubyte'</span></span>) y_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-train-labels-idx1-ubyte'</span></span>) X_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-test-images-idx3-ubyte'</span></span>) y_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-test-labels-idx1-ubyte'</span></span>) X_train = np.reshape(X_train, (X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) X_test = np.reshape(X_test, (X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels)) k = <span class="hljs-number"><span class="hljs-number">10</span></span> X_train = X_train[:X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] y_train = y_train[:y_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] X_test = X_test[:X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] y_test = y_test[:y_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] <span class="hljs-comment"><span class="hljs-comment"># Normalize X_train = X_train.astype(np.float32) X_train /= 255.0 X_test = X_test.astype(np.float32) X_test /= 255.0 x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels)) y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))</span></span></code> </pre><br> 我们准备了两套训练和验证套件。 字符本身是易于显示的普通数组： <br><br><img src="https://habrastorage.org/webt/lb/uj/yt/lbujytoizk2gxviahqxz5emvgay.png"><br><br> 我们还仅使用数据集的1/10进行训练（参数k），否则该过程将至少花费10个小时。 <br><br> 我们开始网络训练，在过程结束时，我们将训练后的模型保存到磁盘中。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Set a learning rate reduction learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) # Required for learning_rate_reduction: keras.backend.get_session().run(tf.global_variables_initializer()) model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30) model.save('emnist_letters.h5')</span></span></code> </pre> <br> 学习过程本身大约需要半小时： <br><br><img src="https://habrastorage.org/webt/vu/xv/_s/vuxv_s6hsxg1q0gxcqapd0o3bv8.png"><br><br> 这仅需要执行一次，那么我们将使用已经保存的模型文件。 培训完成后，一切就绪，您可以识别文本。 <br><br><h2> 认可度 </h2><br> 为了识别，我们加载模型并调用predict_classes函数。 <br><br><pre> <code class="python hljs">model = keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'emnist_letters.h5'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">emnist_predict_img</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, img)</span></span></span><span class="hljs-function">:</span></span> img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) img_arr = <span class="hljs-number"><span class="hljs-number">1</span></span> - img_arr/<span class="hljs-number"><span class="hljs-number">255.0</span></span> img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>] = np.rot90(img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">3</span></span>) img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>] = np.fliplr(img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>]) img_arr = img_arr.reshape((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) result = model.predict_classes([img_arr]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> chr(emnist_labels[result[<span class="hljs-number"><span class="hljs-number">0</span></span>]])</code> </pre> <br> 事实证明，数据集中的图像最初是旋转的，因此在识别之前我们必须旋转图像。 <br><br> 最终函数在输入端接收带有图像的文件，在输出端给出一行，该函数仅占用10行代码： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">img_to_str</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model: Any, image_file: str)</span></span></span><span class="hljs-function">:</span></span> letters = letters_extract(image_file) s_out = <span class="hljs-string"><span class="hljs-string">""</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(letters)): dn = letters[i+<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] - letters[i][<span class="hljs-number"><span class="hljs-number">0</span></span>] - letters[i][<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i &lt; len(letters) - <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> s_out += emnist_predict_img(model, letters[i][<span class="hljs-number"><span class="hljs-number">2</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (dn &gt; letters[i][<span class="hljs-number"><span class="hljs-number">1</span></span>]/<span class="hljs-number"><span class="hljs-number">4</span></span>): s_out += <span class="hljs-string"><span class="hljs-string">' '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s_out</code> </pre> <br> 如果字母之间的间距大于字符的1/4，我们将使用以前保存的字符宽度添加空格。 <br><br> 用法示例： <br><pre> <code class="python hljs">model = keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'emnist_letters.h5'</span></span>) s_out = img_to_str(model, <span class="hljs-string"><span class="hljs-string">"hello_world.png"</span></span>) print(s_out)</code> </pre><br> 结果： <br><img src="https://habrastorage.org/webt/ck/r5/iq/ckr5iqlfoiokza60cleu3w1x-hg.png"><br><br> 一个有趣的特征是神经网络“混淆”了字母“ O”和数字“ 0”，但这并不奇怪，因为  EMNIST的原始集包含<i>手写</i>字母和数字，与印刷的字母和数字并不完全相同。 理想情况下，要识别屏幕文本，您需要根据屏幕字体准备一个单独的集合，并已经在其上训练了一个神经网络。 <br><br><h2> 结论 </h2><br> 如您所见，不是众神在烧锅，而在现代图书馆的帮助下曾经看起来“神奇”的事情变得非常简单。 <br><br> 由于Python是跨平台的，因此代码可以在Windows，Linux和OSX上的任何地方使用。 就像Keras移植到iOS / Android上一样，从理论上讲，经过训练的模型也可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">移动设备上使用</a> 。 <br><br> 对于那些想自己尝试的人，源代码位于破坏者的下面。 <br><br><div class="spoiler">  <b class="spoiler_title">keras_emnist.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Code source: dmitryelj@gmail.com import os # Force CPU # os.environ["CUDA_VISIBLE_DEVICES"] = "-1" # Debug messages # 0 = all messages are logged (default behavior) # 1 = INFO messages are not printed # 2 = INFO and WARNING messages are not printed # 3 = INFO, WARNING, and ERROR messages are not printed os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' import cv2 import imghdr import numpy as np import pathlib from tensorflow import keras from keras.models import Sequential from keras import optimizers from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization from keras.optimizers import SGD, RMSprop, Adam from keras import backend as K from keras.constraints import maxnorm import tensorflow as tf from scipy import io as spio import idx2numpy # sudo pip3 install idx2numpy from matplotlib import pyplot as plt from typing import * import time # Dataset: # https://www.nist.gov/node/1298471/emnist-dataset # https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip def cnn_print_digit(d): print(d.shape) for x in range(28): s = "" for y in range(28): s += "{0:.1f} ".format(d[28*y + x]) print(s) def cnn_print_digit_2d(d): print(d.shape) for y in range(d.shape[0]): s = "" for x in range(d.shape[1]): s += "{0:.1f} ".format(d[x][y]) print(s) emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122] def emnist_model(): model = Sequential() model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(28, 28, 1), activation='relu')) model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) return model def emnist_model2(): model = Sequential() # In Keras there are two options for padding: same or valid. Same means we pad with the number on the edge and valid means no padding. model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Convolution2D(64, (3, 3), activation='relu', padding='same')) model.add(MaxPooling2D((2, 2))) model.add(Convolution2D(128, (3, 3), activation='relu', padding='same')) model.add(MaxPooling2D((2, 2))) # model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) # model.add(MaxPooling2D((2, 2))) ## model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) return model def emnist_model3(): model = Sequential() model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu')) model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')) model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation="relu")) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation="softmax")) model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), metrics=['accuracy']) return model def emnist_train(model): t_start = time.time() emnist_path = 'D:\\Temp\\1\\' X_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-images-idx3-ubyte') y_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-labels-idx1-ubyte') X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-images-idx3-ubyte') y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-labels-idx1-ubyte') X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1)) X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1)) print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels)) # Test: k = 10 X_train = X_train[:X_train.shape[0] // k] y_train = y_train[:y_train.shape[0] // k] X_test = X_test[:X_test.shape[0] // k] y_test = y_test[:y_test.shape[0] // k] # Normalize X_train = X_train.astype(np.float32) X_train /= 255.0 X_test = X_test.astype(np.float32) X_test /= 255.0 x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels)) y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels)) # Set a learning rate reduction learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) # Required for learning_rate_reduction: keras.backend.get_session().run(tf.global_variables_initializer()) model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30) print("Training done, dT:", time.time() - t_start) def emnist_predict(model, image_file): img = keras.preprocessing.image.load_img(image_file, target_size=(28, 28), color_mode='grayscale') emnist_predict_img(model, img) def emnist_predict_img(model, img): img_arr = np.expand_dims(img, axis=0) img_arr = 1 - img_arr/255.0 img_arr[0] = np.rot90(img_arr[0], 3) img_arr[0] = np.fliplr(img_arr[0]) img_arr = img_arr.reshape((1, 28, 28, 1)) result = model.predict_classes([img_arr]) return chr(emnist_labels[result[0]]) def letters_extract(image_file: str, out_size=28): img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1) # Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() letters = [] for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) letter_crop = gray[y:y + h, x:x + w] # print(letter_crop.shape) # Resize letter canvas to square size_max = max(w, h) letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8) if w &gt; h: # Enlarge image top-bottom # ------ # ====== # ------ y_pos = size_max//2 - h//2 letter_square[y_pos:y_pos + h, 0:w] = letter_crop elif w &lt; h: # Enlarge image left-right # --||-- x_pos = size_max//2 - w//2 letter_square[0:h, x_pos:x_pos + w] = letter_crop else: letter_square = letter_crop # Resize letter to 28x28 and add letter and its X-coordinate letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA))) # Sort array in place by X-coordinate letters.sort(key=lambda x: x[0], reverse=False) # cv2.imshow("Input", img) # # cv2.imshow("Gray", thresh) # cv2.imshow("Enlarged", img_erode) # cv2.imshow("Output", output) # cv2.imshow("0", letters[0][2]) # cv2.imshow("1", letters[1][2]) # cv2.imshow("2", letters[2][2]) # cv2.imshow("3", letters[3][2]) # cv2.imshow("4", letters[4][2]) # cv2.waitKey(0) return letters def img_to_str(model: Any, image_file: str): letters = letters_extract(image_file) s_out = "" for i in range(len(letters)): dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i &lt; len(letters) - 1 else 0 s_out += emnist_predict_img(model, letters[i][2]) if (dn &gt; letters[i][1]/4): s_out += ' ' return s_out if __name__ == "__main__": # model = emnist_model() # emnist_train(model) # model.save('emnist_letters.h5') model = keras.models.load_model('emnist_letters.h5') s_out = img_to_str(model, "hello_world.png") print(s_out)</span></span></code> </pre><br></div></div><br> 与往常一样，所有成功的实验。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN466565/">https://habr.com/ru/post/zh-CN466565/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN466555/index.html">从gitlab.com找到解决大问题的解决方案中学到的6课。 第一部分</a></li>
<li><a href="../zh-CN466557/index.html">如何为网站创建布局而不是保持极端</a></li>
<li><a href="../zh-CN466559/index.html">让我们来看看新的Var</a></li>
<li><a href="../zh-CN466561/index.html">需要绝对透明的选择？ -我有</a></li>
<li><a href="../zh-CN466563/index.html">成本：新技术堆栈中包含的用于开发云应用程序的内容</a></li>
<li><a href="../zh-CN466569/index.html">莫斯科交易所的首次公开募股：为何需要，由谁进行以及如何购买股票</a></li>
<li><a href="../zh-CN466571/index.html">Tesseract OCR技巧-创建自己的词汇表以提高OCR性能</a></li>
<li><a href="../zh-CN466573/index.html">给未来雇主的问题</a></li>
<li><a href="../zh-CN466575/index.html">将二维列表从python传递到DLL</a></li>
<li><a href="../zh-CN466577/index.html">两个学生如何在iOS下制作游戏以及他们赚了多少钱</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
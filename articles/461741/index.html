<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äçüíº üç∂ üóÉÔ∏è Agrupaci√≥n jer√°rquica de datos categ√≥ricos en R üëéüèº üê© üë©üèø‚Äçüöí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La traducci√≥n fue preparada para los estudiantes del curso "An√°lisis aplicado en R" . 




 Este fue mi primer intento de agrupar clientes basados ‚Äã‚Äãe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Agrupaci√≥n jer√°rquica de datos categ√≥ricos en R</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/461741/">  <i>La traducci√≥n fue preparada para los estudiantes del curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"An√°lisis aplicado en R"</a> .</i> <br><br><img src="https://habrastorage.org/webt/wq/q0/sp/wqq0sphqihtnsg1f8eor15ffkgi.png"><br><hr><br><br>  Este fue mi primer intento de agrupar clientes basados ‚Äã‚Äãen datos reales, y me dio una experiencia valiosa.  Hay muchos art√≠culos en Internet sobre la agrupaci√≥n en cl√∫ster utilizando variables num√©ricas, pero encontrar soluciones para datos categ√≥ricos, que es algo m√°s dif√≠cil, no fue tan simple.  Los m√©todos de agrupamiento para datos categ√≥ricos todav√≠a est√°n en desarrollo, y en otra publicaci√≥n voy a probar con otro. <br><a name="habracut"></a><br>  Por otro lado, muchas personas piensan que agrupar datos categ√≥ricos puede no producir resultados significativos, y esto es en parte cierto (ver la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">excelente discusi√≥n sobre CrossValidated</a> ).  En un momento, pens√©: ‚Äú¬øQu√© estoy haciendo?  Simplemente se pueden dividir en cohortes ".  Sin embargo, el an√°lisis de cohortes tampoco siempre es aconsejable, especialmente con un n√∫mero significativo de variables categ√≥ricas con una gran cantidad de niveles: puede manejar f√°cilmente de 5 a 7 cohortes, pero si tiene 22 variables y cada una tiene 5 niveles (por ejemplo, una encuesta de clientes con estimaciones discretas 1 , 2, 3, 4 y 5), y necesita comprender con qu√© grupos caracter√≠sticos de clientes est√° tratando: obtendr√° cohortes de 22x5.  Nadie quiere molestarse con tal tarea.  Y aqu√≠ la agrupaci√≥n podr√≠a ayudar.  Entonces, en esta publicaci√≥n, hablar√© sobre lo que a m√≠ mismo me gustar√≠a saber tan pronto como comience a agrupar. <br><br>  El proceso de agrupaci√≥n en s√≠ consta de tres pasos: <br><br><ol><li>  Construir una matriz de disimilitud es, sin duda, la decisi√≥n m√°s importante en la agrupaci√≥n.  Todos los pasos posteriores se basar√°n en la matriz de disimilitud que cre√≥. </li><li>  La elecci√≥n del m√©todo de agrupamiento. </li><li>  Evaluaci√≥n de cl√∫ster. </li></ol><br>  Esta publicaci√≥n ser√° una especie de introducci√≥n que describe los principios b√°sicos de la agrupaci√≥n y su implementaci√≥n en el entorno R. <br><br><h2>  Matriz de disimilitud </h2><br>  La base para la agrupaci√≥n ser√° la matriz de disimilitud, que en t√©rminos matem√°ticos describe la diferencia entre los puntos del conjunto de datos.  Le permite combinar a√∫n m√°s en los grupos aquellos puntos que est√°n m√°s cercanos entre s√≠, o separar los m√°s distantes entre s√≠; esta es la idea principal de la agrupaci√≥n. <br><br>  En esta etapa, las diferencias entre los tipos de datos son importantes, ya que la matriz de disimilitud se basa en las distancias entre puntos de datos individuales.  Es f√°cil imaginar las distancias entre los puntos de datos num√©ricos (un ejemplo bien conocido son las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">distancias euclidianas</a> ), pero en el caso de los datos categ√≥ricos (factores en R), no todo es tan obvio. <br><br>  Para construir una matriz de disimilitud en este caso, se debe utilizar la llamada distancia de Gover.  No profundizar√© en la parte matem√°tica de este concepto, simplemente proporcionar√© enlaces: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">all√°</a> .  Para esto, prefiero usar <code>daisy()</code> con la <code>metric = c("gower")</code> del paquete del <code>cluster</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#-----   -----# #    ,       ,     ,   ,    library(dplyr) #     set.seed(40) #     #    ;   data.frame()     #    ,   200   1  200 id.s &lt;- c(1:200) %&gt;% factor() budget.s &lt;- sample(c("small", "med", "large"), 200, replace = T) %&gt;% factor(levels=c("small", "med", "large"), ordered = TRUE) origins.s &lt;- sample(c("x", "y", "z"), 200, replace = T, prob = c(0.7, 0.15, 0.15)) area.s &lt;- sample(c("area1", "area2", "area3", "area4"), 200, replace = T, prob = c(0.3, 0.1, 0.5, 0.2)) source.s &lt;- sample(c("facebook", "email", "link", "app"), 200, replace = T, prob = c(0.1,0.2, 0.3, 0.4)) ##   ‚Äî      dow.s &lt;- sample(c("mon", "tue", "wed", "thu", "fri", "sat", "sun"), 200, replace = T, prob = c(0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2)) %&gt;% factor(levels=c("mon", "tue", "wed", "thu", "fri", "sat", "sun"), ordered = TRUE) #  dish.s &lt;- sample(c("delicious", "the one you don't like", "pizza"), 200, replace = T) #   data.frame()      synthetic.customers &lt;- data.frame(id.s, budget.s, origins.s, area.s, source.s, dow.s, dish.s) #-----   -----# library(cluster) #       #   : daisy(), diana(), clusplot() gower.dist &lt;- daisy(synthetic.customers[ ,2:7], metric = c("gower")) # class(gower.dist) ## , </span></span></code> </pre> <br>  La matriz de disimilitud est√° lista.  Para 200 observaciones, se construye r√°pidamente, pero puede requerir una gran cantidad de c√≥mputo si se trata de un conjunto de datos grande. <br><br>  En la pr√°ctica, es muy probable que primero tenga que limpiar el conjunto de datos, realizar las transformaciones necesarias de las filas en factores y rastrear los valores faltantes.  En mi caso, el conjunto de datos tambi√©n conten√≠a filas de valores perdidos que se agrupaban maravillosamente cada vez, por lo que parec√≠a que era un tesoro, hasta que mir√© los valores (¬°ay!). <br><br><h2>  Algoritmos de agrupamiento </h2><br>  Es posible que ya sepa que la agrupaci√≥n es <i>k-means y jer√°rquica</i> .  En esta publicaci√≥n, me concentro en el segundo m√©todo, ya que es m√°s flexible y permite varios enfoques: puede elegir un algoritmo de agrupamiento <i>aglomerativo</i> (de abajo hacia arriba) o <i>divisional</i> (de arriba hacia abajo). <br><br><img src="https://habrastorage.org/webt/nl/vp/u4/nlvpu4e8ykoh_nd_el_4i6plh8q.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gu√≠a de programaci√≥n de UC Business Analytics R</a></i> <br><br>  La agrupaci√≥n aglomerativa comienza con <code>n</code> agrupaciones, donde <code>n</code> es el n√∫mero de observaciones: se supone que cada una de ellas es una agrupaci√≥n separada.  Luego, el algoritmo intenta encontrar y agrupar los puntos de datos m√°s similares entre ellos; as√≠ es como comienza la formaci√≥n de conglomerados. <br><br>  La agrupaci√≥n divisional se realiza de manera opuesta: inicialmente se supone que todos los n puntos de datos que tenemos son un grupo grande, y luego los menos similares se dividen en grupos separados. <br><br>  Al decidir cu√°l de estos m√©todos elegir, siempre tiene sentido probar todas las opciones, sin embargo, en general, la <i>agrupaci√≥n aglomerativa es mejor para identificar grupos peque√±os y es utilizada por la mayor√≠a de los programas de computadora, y la agrupaci√≥n divisional es m√°s apropiada para identificar grupos grandes</i> . <br><br>  Personalmente, antes de decidir qu√© m√©todo usar, prefiero mirar los dendrogramas, una representaci√≥n gr√°fica de la agrupaci√≥n.  Como ver√° m√°s adelante, algunos dendrogramas est√°n bien equilibrados, mientras que otros son muy ca√≥ticos. <br><br>  # La entrada principal para el siguiente c√≥digo es la disimilitud (matriz de distancia) <br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#             #            ‚Äî         ‚Äî    #------------  ------------# divisive.clust &lt;- diana(as.matrix(gower.dist), diss = TRUE, keep.diss = TRUE) plot(divisive.clust, main = "Divisive")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/54/mp/m1/54mpm19v8jkkpmj6usehxlgr5qk.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#------------   ------------# #      #         ‚Äî     ,      #    (complete linkages) aggl.clust.c &lt;- hclust(gower.dist, method = "complete") plot(aggl.clust.c, main = "Agglomerative, complete linkages")</span></span></code> </pre> <br><h2>  Evaluaci√≥n de calidad de agrupamiento </h2><br>  En esta etapa, es necesario elegir entre diferentes algoritmos de agrupaci√≥n y un n√∫mero diferente de agrupaciones.  Puede usar diferentes m√©todos de evaluaci√≥n, sin olvidar dejarse guiar por <b>el sentido com√∫n</b> .  Destaqu√© estas palabras en negrita y cursiva, porque el significado de la elecci√≥n es <b>muy importante</b> : el n√∫mero de grupos y el m√©todo de dividir datos en grupos deber√≠a ser pr√°ctico desde un punto de vista pr√°ctico.  El n√∫mero de combinaciones de valores de variables categ√≥ricas es finito (ya que son discretas), pero no ser√° significativo ning√∫n desglose basado en ellas.  Es posible que tampoco desee tener muy pocos grupos; en este caso, ser√°n demasiado generalizados.  Al final, todo depende de su objetivo y las tareas del an√°lisis. <br><br>  En general, al crear grupos, le interesa obtener grupos de puntos de datos claramente definidos, de modo que la distancia entre dichos puntos dentro del grupo ( <i>o compacidad</i> ) sea m√≠nima, y ‚Äã‚Äãla distancia entre grupos ( <i>separabilidad</i> ) sea la m√°xima posible.  Esto es f√°cil de entender intuitivamente: la distancia entre puntos es una medida de su disimilitud, obtenida en base a la matriz de disimilitud.  Por lo tanto, la evaluaci√≥n de la calidad de la agrupaci√≥n se basa en la evaluaci√≥n de la compacidad y la separabilidad. <br><br>  A continuaci√≥n, demostrar√© dos enfoques y mostrar√© que uno de ellos puede dar resultados sin sentido. <br><br><ul><li>  <i>M√©todo de codo</i> : comience con √©l si el factor m√°s importante para su an√°lisis es la compacidad de los grupos, es decir, la similitud dentro de los grupos. </li><li>  <i>M√©todo de evaluaci√≥n de siluetas</i> : el gr√°fico de <i>silueta</i> utilizado como una medida de consistencia de datos muestra qu√© tan cerca est√° cada uno de los puntos dentro de un grupo a los puntos en los grupos vecinos. </li></ul><br>  En la pr√°ctica, estos dos m√©todos a menudo dan resultados diferentes, lo que puede generar cierta confusi√≥n: la compactaci√≥n m√°xima y la separaci√≥n m√°s clara se lograr√°n con un n√∫mero diferente de grupos, por lo que el sentido com√∫n y la comprensi√≥n de lo que realmente significan sus datos jugar√°n un papel importante Al tomar una decisi√≥n final. <br><br>  Tambi√©n hay una serie de m√©tricas que puede analizar.  Los agregar√© directamente al c√≥digo. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#      ,        #      ,     ,   ‚Äî   #     ,      ,         ,   ,     library(fpc) cstats.table &lt;- function(dist, tree, k) { clust.assess &lt;- c("cluster.number","n","within.cluster.ss","average.within","average.between", "wb.ratio","dunn2","avg.silwidth") clust.size &lt;- c("cluster.size") stats.names &lt;- c() row.clust &lt;- c() output.stats &lt;- matrix(ncol = k, nrow = length(clust.assess)) cluster.sizes &lt;- matrix(ncol = k, nrow = k) for(i in c(1:k)){ row.clust[i] &lt;- paste("Cluster-", i, " size") } for(i in c(2:k)){ stats.names[i] &lt;- paste("Test", i-1) for(j in seq_along(clust.assess)){ output.stats[j, i] &lt;- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.assess])[j] } for(d in 1:k) { cluster.sizes[d, i] &lt;- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.size])[d] dim(cluster.sizes[d, i]) &lt;- c(length(cluster.sizes[i]), 1) cluster.sizes[d, i] } } output.stats.df &lt;- data.frame(output.stats) cluster.sizes &lt;- data.frame(cluster.sizes) cluster.sizes[is.na(cluster.sizes)] &lt;- 0 rows.all &lt;- c(clust.assess, row.clust) # rownames(output.stats.df) &lt;- clust.assess output &lt;- rbind(output.stats.df, cluster.sizes)[ ,-1] colnames(output) &lt;- stats.names[2:k] rownames(output) &lt;- rows.all is.num &lt;- sapply(output, is.numeric) output[is.num] &lt;- lapply(output[is.num], round, 2) output } #     :      7 #     ,            stats.df.divisive &lt;- cstats.table(gower.dist, divisive.clust, 7) stats.df.divisive</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/r-/g_/ou/r-g_oukwyorhqnsls_cbg4c8spw.png"><br><br>  Entonces, el indicador average.within, que representa la distancia promedio entre las observaciones dentro de los grupos, disminuye, al igual que dentro de.cluster.ss (la suma de los cuadrados de las distancias entre las observaciones en un grupo).  El ancho promedio de la silueta (avg.silwidth) no cambia tan inequ√≠vocamente, sin embargo, todav√≠a se puede notar una relaci√≥n inversa. <br>  Observe cu√°n desproporcionados son los tama√±os de cl√∫ster.  No me apresurar√≠a a trabajar con un n√∫mero incomparable de observaciones dentro de los grupos.  Una de las razones es que el conjunto de datos puede estar desequilibrado, y algunos grupos de observaciones superar√°n a todos los dem√°s en el an√°lisis; esto no es bueno y probablemente conducir√° a errores. <br><br> <code>stats.df.aggl &lt;-cstats.table(gower.dist, aggl.clust.c, 7) #      </code> <br> <br> <code>stats.df.aggl</code> <br> <br><img src="https://habrastorage.org/webt/a_/-u/aa/a_-uaa_nff99nuyobulroyk_hka.png"><br><br>  Observe cu√°nto mejor se equilibra el n√∫mero de observaciones por grupo mediante el agrupamiento jer√°rquico aglomerativo basado en el m√©todo de comunicaci√≥n completo. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># ---------    ---------# #   ¬´¬ª       #    ,     7  library(ggplot2) #  #   ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))), aes(x=cluster.number, y=within.cluster.ss)) + geom_point()+ geom_line()+ ggtitle("Divisive clustering") + labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/kw/kz/xy/kwkzxyuuzwhe0yst9kteg9inias.png"><br><br>  Entonces, hemos creado un gr√°fico del "codo".  Muestra c√≥mo la suma de las distancias al cuadrado entre las observaciones (la usamos como una medida de la proximidad de las observaciones; cuanto m√°s peque√±a es, m√°s cercanas est√°n las mediciones dentro del grupo) var√≠a para un n√∫mero diferente de grupos.  Idealmente, deber√≠amos ver una "curva de codo" distinta en el punto donde la agrupaci√≥n adicional solo da una ligera disminuci√≥n en la suma de cuadrados (SS).  Para el gr√°fico a continuaci√≥n, me detendr√≠a en aproximadamente 7. Aunque en este caso uno de los grupos consistir√° en solo dos observaciones.  Veamos qu√© sucede durante la agrupaci√≥n aglomerativa. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#       ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), aes(x=cluster.number, y=within.cluster.ss)) + geom_point()+ geom_line()+ ggtitle("Agglomerative clustering") + labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/y0/ck/q-/y0ckq-zxtzg0fbjr9gcq1jgorvq.png"><br><br>  El ‚Äúcodo‚Äù aglomerativo es similar al divisional, pero el gr√°fico se ve m√°s suave: las curvas no son tan pronunciadas.  Al igual que con la agrupaci√≥n divisional, me centrar√≠a en 7 agrupaciones, sin embargo, al elegir entre estos dos m√©todos, me gustan m√°s los tama√±os de agrupaci√≥n que se obtienen mediante el m√©todo aglomerativo; es mejor que sean comparables entre s√≠. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#  ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))), aes(x=cluster.number, y=avg.silwidth)) + geom_point()+ geom_line()+ ggtitle("Divisive clustering") + labs(x = "Num.of clusters", y = "Average silhouette width") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/u9/nj/nf/u9njnfcjqbxbzlfgpl5sxqailra.png"><br><br>  Al usar el m√©todo de estimaci√≥n de silueta, debe elegir la cantidad que proporciona el coeficiente de silueta m√°ximo, porque necesita grupos que est√©n lo suficientemente separados como para considerarse separados. <br><br>  El coeficiente de silueta puede variar de ‚Äì1 a 1, con 1 correspondiente a una buena consistencia dentro de los grupos, y ‚Äì1 no muy bueno. <br>  En el caso de la tabla anterior, elegir√≠a 9 en lugar de 5 grupos. <br><br>  A modo de comparaci√≥n: en el caso "simple", el gr√°fico de silueta es similar al siguiente.  No como el nuestro, pero casi. <br><br><img src="https://habrastorage.org/webt/18/yw/uj/18ywujz8uh4q5hhnhtxlzrgs1nm.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Marineros de datos</a></i> <br><br><pre> <code class="sql hljs">ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), aes(x=cluster.number, y=avg.silwidth)) + geom_point()+ geom_line()+ ggtitle("Agglomerative clustering") + labs(x = "Num.of clusters", y = "Average silhouette width") + theme(plot.title = element_text(hjust = 0.5))</code> </pre> <br><img src="https://habrastorage.org/webt/vk/f1/fl/vkf1fln-v-nedwuh6rzbjkxz2pg.png"><br><br>  El gr√°fico de ancho de la silueta nos dice: cuanto m√°s divide el conjunto de datos, m√°s claros se vuelven los grupos.  Sin embargo, al final alcanzar√°s puntos individuales, y no necesitas esto.  Sin embargo, esto es exactamente lo que ver√° si comienza a aumentar el n√∫mero de cl√∫steres <i>k</i> .  Por ejemplo, para <code>k=30</code> obtuve el siguiente gr√°fico: <br><br><img src="https://habrastorage.org/webt/sz/nq/sy/sznqsykdros9uf8clfabfg8yb94.png"><br><br>  Para resumir: cuanto m√°s divida el conjunto de datos, mejores ser√°n los grupos, pero no podremos alcanzar puntos individuales (por ejemplo, en el gr√°fico anterior seleccionamos 30 grupos, y solo tenemos 200 puntos de datos). <br><br>  Entonces, el agrupamiento aglomerativo en nuestro caso me parece mucho m√°s equilibrado: los tama√±os de los conglomerados son m√°s o menos comparables (¬°solo mire un conglomerado de solo dos observaciones al dividir por el m√©todo divisional!), Y me detendr√≠a en 7 conglomerados obtenidos por este m√©todo.  Veamos c√≥mo se ven y de qu√© est√°n hechos. <br><br>  El conjunto de datos consta de 6 variables que deben visualizarse en 2D o 3D, por lo que debe trabajar duro.  La naturaleza de los datos categ√≥ricos tambi√©n impone algunas limitaciones, por lo que las soluciones preparadas pueden no funcionar.  Necesito: a) ver c√≥mo se dividen las observaciones en grupos, b) entender c√≥mo se clasifican las observaciones.  Por lo tanto, cre√© a) un dendrograma de color, b) un mapa de calor del n√∫mero de observaciones por variable dentro de cada grupo. <br><br><pre> <code class="sql hljs">library("ggplot2") library("reshape2") library("purrr") library("dplyr") <span class="hljs-comment"><span class="hljs-comment">#    library("dendextend") dendro &lt;- as.dendrogram(aggl.clust.c) dendro.col &lt;- dendro %&gt;% set("branches_k_color", k = 7, value = c("darkslategray", "darkslategray4", "darkslategray3", "gold3", "darkcyan", "cyan3", "gold3")) %&gt;% set("branches_lwd", 0.6) %&gt;% set("labels_colors", value = c("darkslategray")) %&gt;% set("labels_cex", 0.5) ggd1 &lt;- as.ggdend(dendro.col) ggplot(ggd1, theme = theme_minimal()) + labs(x = "Num. observations", y = "Height", title = "Dendrogram, k = 7")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/iy/hf/jx/iyhfjxt9q7vztvwbaazmqlzzno0.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#     ( ) ggplot(ggd1, labels = T) + scale_y_reverse(expand = c(0.2, 0)) + coord_polar(theta="x")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/if/4g/yv/if4gyv42vtgecjd9n-b_0bb91rs.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#  ‚Äî   #    ‚Äî       #    ,      clust.num &lt;- cutree(aggl.clust.c, k = 7) synthetic.customers.cl &lt;- cbind(synthetic.customers, clust.num) cust.long &lt;- melt(data.frame(lapply(synthetic.customers.cl, as.character), stringsAsFactors=FALSE), id = c("id.s", "clust.num"), factorsAsStrings=T) cust.long.q &lt;- cust.long %&gt;% group_by(clust.num, variable, value) %&gt;% mutate(count = n_distinct(id.s)) %&gt;% distinct(clust.num, variable, value, count) # heatmap.c ,      ‚Äî ,   ,     heatmap.c &lt;- ggplot(cust.long.q, aes(x = clust.num, y = factor(value, levels = c("x","y","z", "mon", "tue", "wed", "thu", "fri","sat","sun", "delicious", "the one you don't like", "pizza", "facebook", "email", "link", "app", "area1", "area2", "area3", "area4", "small", "med", "large"), ordered = T))) + geom_tile(aes(fill = count))+ scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4") #            cust.long.p &lt;- cust.long.q %&gt;% group_by(clust.num, variable) %&gt;% mutate(perc = count / sum(count)) %&gt;% arrange(clust.num) heatmap.p &lt;- ggplot(cust.long.p, aes(x = clust.num, y = factor(value, levels = c("x","y","z", "mon", "tue", "wed", "thu", "fri","sat", "sun", "delicious", "the one you don't like", "pizza", "facebook", "email", "link", "app", "area1", "area2", "area3", "area4", "small", "med", "large"), ordered = T))) + geom_tile(aes(fill = perc), alpha = 0.85)+ labs(title = "Distribution of characteristics across clusters", x = "Cluster number", y = NULL) + geom_hline(yintercept = 3.5) + geom_hline(yintercept = 10.5) + geom_hline(yintercept = 13.5) + geom_hline(yintercept = 17.5) + geom_hline(yintercept = 21.5) + scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4") heatmap.p</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/c5/gg/y5/c5ggy5vih07qcfi4h26mgcvkfgy.png"><br><br>  El mapa de calor muestra gr√°ficamente cu√°ntas observaciones se hacen para cada nivel de factor para los factores iniciales (las variables con las que comenzamos).  El color azul oscuro corresponde a un n√∫mero relativamente grande de observaciones dentro del grupo.  Este mapa de calor tambi√©n muestra que para el d√≠a de la semana (sol, s√°bado ...) y el tama√±o de la canasta (grande, med, peque√±o) el n√∫mero de clientes en cada celda es casi el mismo, esto puede significar que estas categor√≠as no son determinantes para el an√°lisis, y Quiz√°s no necesitan ser tomados en cuenta. <br><br><h2>  Conclusi√≥n </h2><br>  En este art√≠culo, calculamos la matriz de disimilitud, probamos los m√©todos de aglomeraci√≥n y divisi√≥n del agrupamiento jer√°rquico y nos familiarizamos con los m√©todos de codo y silueta para evaluar la calidad de los grupos. <br><br>  La agrupaci√≥n jer√°rquica divisional y aglomerativa es un buen comienzo para estudiar el tema, pero no se detenga all√≠ si realmente desea dominar el an√°lisis de agrupaci√≥n.  Existen muchos otros m√©todos y t√©cnicas.  La principal diferencia de agrupar datos num√©ricos es el c√°lculo de la matriz de disimilitud.  Al evaluar la calidad de la agrupaci√≥n, no todos los m√©todos est√°ndar dar√°n resultados confiables y significativos; es muy probable que el m√©todo de la silueta no sea adecuado. <br><br>  Y finalmente, dado que ya ha pasado un tiempo desde que hice este ejemplo, ahora veo una serie de deficiencias en mi enfoque y me complacer√° recibir cualquier comentario.  Uno de los problemas importantes de mi an√°lisis no estaba relacionado con la agrupaci√≥n como tal: <i>mi conjunto de datos estaba desequilibrado</i> de muchas maneras, y este momento no se tuvo en cuenta.  Esto tuvo un efecto notable en la agrupaci√≥n: el 70% de los clientes pertenec√≠an a un nivel del factor de "ciudadan√≠a", y este grupo domin√≥ la mayor√≠a de los grupos obtenidos, por lo que fue dif√≠cil calcular las diferencias dentro de otros niveles del factor.  La pr√≥xima vez intentar√© equilibrar el conjunto de datos y comparar los resultados de la agrupaci√≥n.  Pero m√°s sobre eso en otra publicaci√≥n. <br><br>  Finalmente, si desea clonar mi c√≥digo, aqu√≠ est√° el enlace a github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/khunreus/cluster-categorical</a> <br>  ¬°Espero que hayas disfrutado este art√≠culo! <br><br><h3>  <i>Fuentes que me ayudaron:</i> </h3><br>  Gu√≠a de agrupaci√≥n jer√°rquica (preparaci√≥n de datos, agrupaci√≥n, visualizaci√≥n): este blog ser√° interesante para quienes est√©n interesados ‚Äã‚Äãen el an√°lisis empresarial en el entorno R: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://uc-r.github.io/hc_clustering</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https: // uc-r. github.io/kmeans_clustering</a> <br><br>  Agrupaci√≥n: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.sthda.com/english/articles/29-cluster-validation-essentials/97-cluster-validation-statistics-must-know-methods/</a> <br><br>    (   k-): <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://eight2late.wordpress.com/2015/07/22/a-gentle-introduction-to-cluster-analysis-using-r/</a> <br><br>    denextend,        : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html#the-set-function</a> <br><br>    ,   : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.r-statistics.com/2010/06/clustergram-visualization-and-diagnostics-for-cluster-analysis-r-code/</a> <br><br>     : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://jcoliver.github.io/learn-r/008-ggplot-dendrograms-and-heatmaps.html</a> <br><br>       ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5025633/</a> (  GitHub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/khunreus/EnsCat</a> ). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/461741/">https://habr.com/ru/post/461741/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../461731/index.html">DPKI: abordando las desventajas de la PKI centralizada mediante blockchain</a></li>
<li><a href="../461733/index.html">Aprendiendo ingl√©s: 9 modismos de estilo americano</a></li>
<li><a href="../461735/index.html">Pr√°ctica de decodificaci√≥n de hardware FFmpeg DXVA2</a></li>
<li><a href="../461737/index.html">Recopilamos el entorno para TDD moderno en c√≥digo JavaScript + VS</a></li>
<li><a href="../461739/index.html">Backend United 4: Okroshka. Incidentes</a></li>
<li><a href="../461743/index.html">Semana de la seguridad 31: vulnerabilidad VLC y tel√©fono roto</a></li>
<li><a href="../461745/index.html">DeviceLock DLP: precios del mercado negro ruso por romper datos personales (m√°s una respuesta a la respuesta de Tinkoff Bank)</a></li>
<li><a href="../461747/index.html">C√≥mo implementamos ML en una aplicaci√≥n con casi 50 millones de usuarios. Experiencia Sberbank</a></li>
<li><a href="../461749/index.html">Belleza en el ojo del espectador</a></li>
<li><a href="../461751/index.html">Contribuci√≥n del dise√±ador al desarrollo de aplicaciones m√≥viles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
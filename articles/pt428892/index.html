<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò∏ üöã üë®üèΩ‚Äçü§ù‚Äçüë®üèº Como criar uma IA de jogo: um guia para iniciantes üñïüèæ üÖ±Ô∏è ‚¨õÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Me deparei com material interessante sobre intelig√™ncia artificial em jogos. Com uma explica√ß√£o das coisas b√°sicas sobre IA usando exemplos simples, e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como criar uma IA de jogo: um guia para iniciantes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/428892/"><img src="https://habrastorage.org/webt/hp/x-/0n/hpx-0n-frdakrflfvlpdt-6hp1e.png"><br><br>  Me deparei com material interessante sobre intelig√™ncia artificial em jogos.  Com uma explica√ß√£o das coisas b√°sicas sobre IA usando exemplos simples, e por dentro existem muitas ferramentas e m√©todos √∫teis para seu desenvolvimento e design convenientes.  Como, onde e quando us√°-los - tamb√©m est√° l√°. <br><br>  A maioria dos exemplos √© escrita em pseudoc√≥digo, portanto, n√£o √© necess√°rio conhecimento aprofundado de programa√ß√£o.  Sob o corte de 35 folhas de texto com fotos e gifs, prepare-se. <br><br>  UPD  Sinto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muito</a> , mas o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PatientZero</a> j√° fez a tradu√ß√£o deste artigo em Habr√©.  Voc√™ pode ler sua vers√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , mas por algum motivo o artigo passou por mim (usei a pesquisa, mas algo deu errado).  E como estou escrevendo um blog de desenvolvedores de jogos, decidi deixar minha op√ß√£o de tradu√ß√£o para assinantes (alguns momentos s√£o diferentes para mim, outros s√£o intencionalmente ignorados pelos conselhos dos desenvolvedores). <br><a name="habracut"></a><br><h2>  O que √© IA? </h2><br>  A IA do jogo se concentra em quais a√ß√µes um objeto deve executar com base nas condi√ß√µes em que est√° localizado.  Isso geralmente √© chamado de gerenciamento de "agentes inteligentes", onde o agente √© um personagem do jogo, ve√≠culo, bot e, √†s vezes, algo mais abstrato: um grupo inteiro de entidades ou mesmo civiliza√ß√£o.  Em cada caso, √© algo que deve ver seu entorno, tomar decis√µes com base e agir de acordo com eles.  Isso √© chamado de ciclo Sense / Think / Act: <br><br><ul><li>  Sentido: o agente encontra ou recebe informa√ß√µes sobre coisas em seu ambiente que podem afetar seu comportamento (amea√ßas pr√≥ximas, itens a coletar, locais interessantes para pesquisar). </li><li>  Pense: o agente decide como reagir (considera se √© seguro coletar itens ou se deve lutar / se esconder primeiro). </li><li>  Ato: o agente executa a√ß√µes para implementar a decis√£o anterior (come√ßa a se mover em dire√ß√£o ao oponente ou objeto). </li><li>  ... agora a situa√ß√£o mudou devido √†s a√ß√µes dos personagens, ent√£o o ciclo se repete com novos dados. </li></ul><br>  A IA tende a se concentrar na parte sensorial do loop.  Por exemplo, carros aut√¥nomos tiram fotos da estrada, combinam-nos com dados de radar e lidar e interpretam.  Geralmente, isso √© feito pelo aprendizado de m√°quina, que processa os dados recebidos e lhes d√° significado, extraindo informa√ß√µes sem√¢nticas como "existe outro carro 20 metros √† sua frente".  Estes s√£o os chamados problemas de classifica√ß√£o. <br><br>  Os jogos n√£o precisam de um sistema complexo para extrair informa√ß√µes, pois a maioria dos dados j√° √© parte integrante deles.  N√£o √© necess√°rio executar algoritmos de reconhecimento de imagem para determinar se h√° um inimigo √† frente - o jogo j√° sabe e transfere informa√ß√µes diretamente no processo de tomada de decis√£o.  Portanto, parte do ciclo do Sentido √© muitas vezes muito mais simples que o Pense e aja. <br><br><h2>  Limita√ß√µes da IA ‚Äã‚Äãdo jogo </h2><br>  A IA possui v√°rias restri√ß√µes que devem ser observadas: <br><br><ul><li>  A IA n√£o precisa ser treinada com anteced√™ncia, como se fosse um algoritmo de aprendizado de m√°quina.  N√£o faz sentido escrever uma rede neural durante o desenvolvimento para assistir a dezenas de milhares de jogadores e aprender a melhor maneira de jogar contra eles.  Porque  Porque o jogo n√£o √© lan√ßado, mas n√£o h√° jogadores. </li><li>  O jogo deve ser divertido e desafiador, portanto, os agentes n√£o devem encontrar a melhor abordagem contra as pessoas. </li><li>  Os agentes precisam parecer realistas para que os jogadores sintam que est√£o jogando contra pessoas reais.  O AlphaGo superou os humanos, mas os passos dados estavam longe do entendimento tradicional do jogo.  Se o jogo imitar um oponente humano, n√£o deve haver esse sentimento.  O algoritmo precisa ser alterado para que tome decis√µes plaus√≠veis, e n√£o ideais. </li><li>  A IA deve funcionar em tempo real.  Isso significa que o algoritmo n√£o pode monopolizar o uso do processador por um longo tempo para a tomada de decis√£o.  At√© 10 milissegundos para isso √© muito longo, porque a maioria dos jogos tem apenas 16 a 33 milissegundos para concluir todo o processamento e passar para o pr√≥ximo quadro do gr√°fico. </li><li>  Idealmente, pelo menos parte do sistema √© orientada por dados, para que n√£o codificadores possam fazer altera√ß√µes e ajustes mais r√°pidos. </li></ul><br>  Considere abordagens de IA que abrangem todo o ciclo Sense / Think / Act. <br><br><h3>  Tomada de decis√£o b√°sica </h3><br>  Vamos come√ßar com o jogo mais simples - Pong.  Objetivo: mover a plataforma (raquete) para que a bola salte fora dela, em vez de passar voando.  √â como o t√™nis, no qual voc√™ perde se n√£o bate na bola.  Aqui, a IA tem uma tarefa relativamente f√°cil - decidir em qual dire√ß√£o mover a plataforma. <br><br><img src="https://habrastorage.org/webt/1l/6g/p8/1l6gp88aolep77ohq7dqwkw8oky.jpeg"><br><br><h3>  Instru√ß√µes condicionais </h3><br>  Para a IA, Pong tem a solu√ß√£o mais √≥bvia - sempre tente posicionar a plataforma embaixo da bola. <br><br>  Um algoritmo simples para isso, escrito em pseudoc√≥digo: <br><br>  <i>cada quadro / atualiza√ß√£o enquanto o jogo est√° em execu√ß√£o:</i> <i><br></i>  <i>se a bola estiver √† esquerda da raquete:</i> <i><br></i>  <i>mover remo para a esquerda</i> <i><br></i>  <i>caso contr√°rio, se a bola estiver √† direita da raquete:</i> <i><br></i>  <i>mover remo para a direita</i> <br><br>  Se a plataforma se mover na velocidade da bola, esse √© o algoritmo perfeito para IA em Pong.  N√£o h√° necessidade de complicar nada se n√£o houver muitos dados e poss√≠veis a√ß√µes para o agente. <br><br>  Essa abordagem √© t√£o simples que quase todo o ciclo Sense / Think / Act √© quase impercept√≠vel.  Mas ele √©: <br><br><ul><li>  A parte Sense est√° em duas instru√ß√µes if.  O jogo sabe onde est√° a bola e onde est√° a plataforma, ent√£o a IA recorre a ela para obter essas informa√ß√µes. </li><li>  A parte Think tamb√©m vem em duas declara√ß√µes if.  Eles incorporam duas solu√ß√µes, que neste caso s√£o mutuamente exclusivas.  Como resultado, uma das tr√™s a√ß√µes √© selecionada - mova a plataforma para a esquerda, mova para a direita ou n√£o fa√ßa nada se j√° estiver posicionada corretamente. </li><li>  A parte Act est√° nas instru√ß√µes Move Paddle Left e Move Paddle Right.  Dependendo do design do jogo, eles podem mover a plataforma instantaneamente ou a uma certa velocidade. </li></ul><br>  Tais abordagens s√£o chamadas de reativas - h√° um conjunto simples de regras (neste caso, se no c√≥digo) que respondem ao estado atual do mundo e agem. <br><br><h3>  √Årvore de decis√£o </h3><br>  O exemplo de Pong √© realmente igual ao conceito formal de IA chamado √°rvore de decis√£o.  O algoritmo o passa para chegar a uma ‚Äúfolha‚Äù - uma decis√£o sobre qual a√ß√£o tomar. <br><br>  Vamos fazer um diagrama de blocos da √°rvore de decis√£o para o algoritmo da nossa plataforma: <br><br><img src="https://habrastorage.org/webt/yu/u8/nd/yuu8ndgkxfb0mj1qyfhht-vhrnw.png"><br><br>  Cada parte da √°rvore √© chamada de n√≥ - a IA usa a teoria dos grafos para descrever essas estruturas.  Existem dois tipos de n√≥s: <br><br><ul><li>  N√≥s de decis√£o: escolha entre duas alternativas com base na verifica√ß√£o de uma determinada condi√ß√£o em que cada alternativa √© apresentada como um n√≥ separado. </li><li>  N√≥s finais: uma a√ß√£o a ser executada que representa a decis√£o final. </li></ul><br>  O algoritmo come√ßa com o primeiro n√≥ (a "raiz" da √°rvore).  Ele decide para qual n√≥ filho acessar ou executa uma a√ß√£o armazenada no n√≥ e √© conclu√≠da. <br><br>  Qual √© a vantagem se a √°rvore de decis√£o faz o mesmo trabalho que as instru√ß√µes if na se√ß√£o anterior?  Aqui existe um sistema comum em que cada solu√ß√£o tem apenas uma condi√ß√£o e dois resultados poss√≠veis.  Isso permite que o desenvolvedor crie AI a partir dos dados que representam as decis√µes na √°rvore, evitando sua codifica√ß√£o.  Imagine na forma de uma tabela: <br><br><img src="https://habrastorage.org/webt/dt/mx/zg/dtmxzgddk1mo585bhzy7-x_espw.png"><br><br>  No lado do c√≥digo, voc√™ obt√©m um sistema para leitura de strings.  Crie um n√≥ para cada um deles, conecte a l√≥gica de decis√£o com base na segunda coluna e os n√≥s filhos com base na terceira e quarta colunas.  Voc√™ ainda precisa programar as condi√ß√µes e a√ß√µes, mas agora a estrutura do jogo ser√° mais complicada.  Nele, voc√™ adiciona decis√µes e a√ß√µes adicionais e, em seguida, configura toda a IA simplesmente editando um arquivo de texto com uma defini√ß√£o de √°rvore.  Em seguida, transfira o arquivo para o designer do jogo, que pode alterar o comportamento sem recompilar o jogo e alterar o c√≥digo. <br><br>  As √°rvores de decis√£o s√£o muito √∫teis quando constru√≠das automaticamente com base em um grande conjunto de exemplos (por exemplo, usando o algoritmo ID3).  Isso os torna uma ferramenta eficaz e de alto desempenho para classificar situa√ß√µes com base nos dados recebidos.  No entanto, vamos al√©m de um sistema simples para os agentes selecionarem a√ß√µes. <br><br><h3>  Cen√°rios </h3><br>  Desmontamos um sistema de √°rvore de decis√£o que usava condi√ß√µes e a√ß√µes pr√©-criadas.  O designer de IA pode organizar a √°rvore da maneira que quiser, mas ainda precisa confiar no codificador que programou tudo.  E se pud√©ssemos fornecer ferramentas de designer para criar nossas pr√≥prias condi√ß√µes ou a√ß√µes? <br><br>  Para impedir que o programador escreva c√≥digo para as condi√ß√µes Is Ball Left Paddle e Is Ball Right Paddle, ele pode criar um sistema no qual o designer registrar√° as condi√ß√µes para verificar esses valores.  Em seguida, os dados da √°rvore de decis√£o ter√£o a seguinte apar√™ncia: <br><br><img src="https://habrastorage.org/webt/o9/nw/pe/o9nwpet07f-6xi7crzt5u34-orm.png"><br><br>  Em ess√™ncia, √© o mesmo que na primeira tabela, mas as solu√ß√µes dentro de si t√™m seu pr√≥prio c√≥digo, um pouco semelhante √† parte condicional da instru√ß√£o if.  No lado do c√≥digo, isso seria lido na segunda coluna para n√≥s de decis√£o, mas, em vez de procurar uma condi√ß√£o espec√≠fica a ser cumprida (Is Ball Left Of Paddle), ele avalia a express√£o condicional e retorna verdadeiro ou falso, respectivamente.  Isso √© feito usando a linguagem de script Lua ou Angelscript.  Utilizando-os, o desenvolvedor pode pegar objetos em seu jogo (bola e raquete) e criar vari√°veis ‚Äã‚Äãque estar√£o dispon√≠veis no script (ball.position).  Al√©m disso, a linguagem de script √© mais simples que o C ++.  Ele n√£o requer um est√°gio completo de compila√ß√£o, portanto, √© ideal para o r√°pido ajuste da l√≥gica do jogo e permite que ‚Äún√£o codificadores‚Äù criem as fun√ß√µes necess√°rias. <br><br>  No exemplo acima, a linguagem de script √© usada apenas para avaliar uma express√£o condicional, mas tamb√©m pode ser usada para a√ß√µes.  Por exemplo, os dados Move Paddle Right podem se tornar uma instru√ß√£o de script (ball.position.x + = 10).  Para que a a√ß√£o tamb√©m seja definida no script, sem a necessidade de programar o Move Paddle Right. <br><br>  Voc√™ pode ir ainda mais longe e escrever uma √°rvore de decis√£o completa em uma linguagem de script.  Este ser√° um c√≥digo na forma de instru√ß√µes condicionais codificadas, mas elas estar√£o localizadas em arquivos de script externos, ou seja, poder√£o ser alteradas sem recompilar o programa inteiro.  Muitas vezes, voc√™ pode alterar o arquivo de script diretamente durante o jogo para testar rapidamente diferentes rea√ß√µes da IA. <br><br><h3>  Resposta do evento </h3><br>  Os exemplos acima s√£o perfeitos para o Pong.  Eles executam continuamente o ciclo Sense / Think / Act e agem com base no estado mais recente do mundo.  Mas em jogos mais complexos, voc√™ precisa responder a eventos individuais e n√£o avaliar tudo de uma vez.  Pong j√° √© um exemplo malsucedido.  Escolha outro. <br><br>  Imagine um atirador em que os inimigos ficam im√≥veis at√© encontrar o jogador, ap√≥s o que agem dependendo da sua "especializa√ß√£o": algu√©m corre para "esmagar", algu√©m ataca de longe.  Este ainda √© o sistema responsivo b√°sico - ‚Äúse o jogador for notado, fa√ßa alguma coisa‚Äù - mas pode ser logicamente dividido no evento Visto pelo Jogador (o jogador √© notado) e a rea√ß√£o (selecione a resposta e execute-a). <br><br>  Isso nos leva de volta ao ciclo Sense / Think / Act.  Podemos codificar a parte Sense, que cada quadro verificar√° se a IA do jogador est√° vis√≠vel.  Caso contr√°rio, nada acontece, mas, se aparecer, o evento Jogador visto √© gerado.  O c√≥digo ter√° uma se√ß√£o separada que diz: "quando o evento Visto pelo Jogador ocorrer, fa√ßa-o", onde est√° a resposta que voc√™ precisa para se referir √†s partes Pensar e Agir.  Assim, voc√™ configurar√° rea√ß√µes ao evento Player Seen: ChargeAndAttack para o personagem "crescente" e HideAndSnipe para o atirador de elite.  Esses relacionamentos podem ser criados no arquivo de dados para edi√ß√£o r√°pida sem precisar recompilar.  E aqui voc√™ tamb√©m pode usar a linguagem de script. <br><br><h2>  Tomar decis√µes dif√≠ceis </h2><br>  Embora sistemas de rea√ß√£o simples sejam muito eficazes, existem muitas situa√ß√µes em que n√£o s√£o suficientes.  √Äs vezes, √© necess√°rio tomar v√°rias decis√µes com base no que o agente est√° fazendo no momento, mas √© dif√≠cil imaginar isso como uma condi√ß√£o.  √Äs vezes, existem muitas condi√ß√µes para represent√°-las efetivamente em uma √°rvore ou script de decis√£o.  √Äs vezes, voc√™ precisa pr√©-avaliar como a situa√ß√£o vai mudar antes de decidir o pr√≥ximo passo.  Resolver esses problemas requer abordagens mais sofisticadas. <br><br><h3>  M√°quina de estado finito </h3><br>  M√°quina de estado finito ou FSM (m√°quina de estado) √© uma maneira de dizer que nosso agente est√° atualmente em um dos v√°rios estados poss√≠veis e que ele pode passar de um estado para outro.  H√° um certo n√∫mero desses estados - da√≠ o nome.  O melhor exemplo de vida √© um sem√°foro.  Em lugares diferentes, sequ√™ncias diferentes de luzes, mas o princ√≠pio √© o mesmo - cada estado representa algo (stand, go, etc.).  Um sem√°foro fica apenas em um estado a qualquer momento e passa de um para outro com base em regras simples. <br><br>  Com NPCs em jogos, uma hist√≥ria semelhante.  Por exemplo, tome um guarda com as seguintes condi√ß√µes: <br><br><ul><li>  Patrulhamento </li><li>  Atacar </li><li>  Fugindo </li></ul><br>  E essas condi√ß√µes para mudar sua condi√ß√£o: <br><br><ul><li>  Se o guarda v√™ o inimigo, ele ataca. </li><li>  Se o guarda ataca, mas n√£o v√™ mais o inimigo, ele volta a patrulhar. </li><li>  Se o guarda atacar, mas estiver gravemente ferido, ele foge. </li></ul><br>  Voc√™ tamb√©m pode escrever declara√ß√µes if com uma vari√°vel de estado de guarda e v√°rias verifica√ß√µes: existe um inimigo por perto, qual √© o n√≠vel de sa√∫de do NPC, etc. Vamos adicionar mais alguns estados: <br><br><ul><li>  Ina√ß√£o (inatividade) - entre patrulhas. </li><li>  Search (Searching) - quando o inimigo notado desapareceu. </li><li>  Pe√ßa ajuda (Finding Help) - quando o inimigo for visto, mas forte demais para lutar com ele sozinho. </li></ul><br>  A escolha para cada um deles √© limitada - por exemplo, um guarda n√£o procurar√° um inimigo escondido se estiver com a sa√∫de debilitada. <br><br>  No final, a enorme lista de "se &lt;x e y, mas n√£o z&gt;, ent√£o &lt;p&gt;" pode se tornar muito complicada; portanto, devemos formalizar um m√©todo que nos permita ter em mente os estados e transi√ß√µes entre estados.  Para fazer isso, levamos em conta todos os estados e, em cada estado, listamos todas as transi√ß√µes para outros estados, juntamente com as condi√ß√µes necess√°rias para eles. <br><br><img src="https://habrastorage.org/webt/ut/25/j2/ut25j2aky0lx_ajk_rf2eeilgei.png"><br><br>  Esta tabela de transi√ß√£o de estado √© uma maneira abrangente de representar o FSM.  Vamos desenhar um diagrama e obter uma vis√£o geral completa de como o comportamento dos NPCs muda. <br><br><img src="https://habrastorage.org/webt/fg/7u/so/fg7uso5gla8wi4-fry0qne_bfvy.png"><br><br>  O gr√°fico reflete a ess√™ncia da tomada de decis√£o para esse agente com base na situa√ß√£o atual.  Al√©m disso, cada seta mostra uma transi√ß√£o entre estados se a condi√ß√£o pr√≥xima a ela for verdadeira. <br><br>  A cada atualiza√ß√£o, verificamos o estado atual do agente, observamos a lista de transi√ß√µes e, se as condi√ß√µes para a transi√ß√£o forem atendidas, ele assumir√° um novo estado.  Por exemplo, cada quadro verifica se o temporizador de 10 segundos expirou e, em caso afirmativo, o guarda muda de Idling para Patrolling.  Da mesma forma, o estado Atacante verifica a sa√∫de do agente - se estiver baixo, entra no estado Fugindo. <br><br>  Isso √© lidar com transi√ß√µes de estado, mas e o comportamento associado aos pr√≥prios estados?  Em rela√ß√£o √† implementa√ß√£o do comportamento real de um estado espec√≠fico, geralmente existem dois tipos de "ganchos" nos quais atribu√≠mos a√ß√µes ao FSM: <br><br><ul><li>  A√ß√µes que realizamos periodicamente para o estado atual. </li><li>  As a√ß√µes que tomamos ao passar de um estado para outro. </li></ul><br>  Exemplos para o primeiro tipo.  Estado de patrulha Cada quadro mover√° o agente ao longo da rota de patrulha.  Estado de ataque Cada quadro tentar√° iniciar um ataque ou entrar em um estado quando poss√≠vel. <br><br>  Para o segundo tipo, considere a transi√ß√£o ‚Äúse o inimigo estiver vis√≠vel e for muito forte, v√° para o estado Procurando ajuda.  O agente deve escolher para onde procurar ajuda e salvar essas informa√ß√µes para que o status Procurando Ajuda saiba para onde ir.  Assim que a ajuda √© encontrada, o agente volta ao estado Atacante.  Nesse momento, ele desejar√° informar o aliado sobre a amea√ßa, para que a a√ß√£o NotifyFriendOfThreat possa ocorrer. <br><br>  E, novamente, podemos olhar para esse sistema atrav√©s do prisma do ciclo Sense / Think / Act.  O Sense se traduz em dados usados ‚Äã‚Äãpela l√≥gica de transi√ß√£o.  Pense - transi√ß√µes dispon√≠veis em cada estado.  E o ato √© realizado por a√ß√µes realizadas periodicamente dentro do estado ou em transi√ß√µes entre estados. <br><br>  √Äs vezes, o polling cont√≠nuo das condi√ß√µes de transi√ß√£o pode ser caro.  Por exemplo, se cada agente executar c√°lculos complexos em cada quadro para determinar se v√™ inimigos e entender se √© poss√≠vel alternar do estado Patrulhamento para Atacar, isso levar√° muito tempo do processador. <br><br>  Mudan√ßas importantes no estado do mundo podem ser consideradas eventos que ser√£o processados ‚Äã‚Äã√† medida que ocorrerem.  Em vez de o FSM verificar a condi√ß√£o de transi√ß√£o "meu agente pode ver o player?" Em cada quadro, voc√™ pode configurar um sistema separado para executar verifica√ß√µes com menos frequ√™ncia (por exemplo, 5 vezes por segundo).  E o resultado √© dar ao jogador visto quando o cheque passa. <br><br>  Isso √© passado para o FSM, que agora precisa entrar na condi√ß√£o de jogador recebido do evento Visto e reagir de acordo.  O comportamento resultante √© o mesmo, exceto por um atraso quase impercept√≠vel antes de responder.  Mas o desempenho ficou melhor como resultado da separa√ß√£o de parte do Sense em uma parte separada do programa. <br><br><h3>  M√°quina hier√°rquica de estados finitos </h3><br>  No entanto, trabalhar com FSMs grandes nem sempre √© conveniente.  Se quisermos expandir o estado do ataque, substituindo-o por MeleeAttacking (corpo a corpo) e RangedAttacking (√† dist√¢ncia), teremos que alterar as transi√ß√µes de todos os outros estados que levam ao estado de ataque (atual e futuro). <br><br>  Certamente voc√™ percebeu que em nosso exemplo existem muitas transi√ß√µes duplicadas.  A maioria das transi√ß√µes no estado inativo √© id√™ntica √†s transi√ß√µes no estado de patrulhamento.  Seria bom n√£o repetir, especialmente se adicionarmos mais estados semelhantes.  Faz sentido agrupar Idling and Patrolling sob o r√≥tulo comum "non-combat", onde existe apenas um conjunto comum de transi√ß√µes para combater estados.  Se apresentarmos essa etiqueta como um estado, a marcha lenta e o patrulhamento se tornar√£o subestados.  Um exemplo de uso de uma tabela de convers√£o separada para um novo subestado que n√£o seja de combate: <br><br>  <i>As principais condi√ß√µes:</i> <br><img src="https://habrastorage.org/webt/jk/6j/u6/jk6ju6k3dtxhbou06sqelhixykm.png"><br><br>  <i>Status fora de combate:</i> <br><img src="https://habrastorage.org/webt/b4/yn/ae/b4ynaedk42xhvikbzqjsbh9itgc.png"><br><br>  E em forma de gr√°fico: <br><br><img src="https://habrastorage.org/webt/ni/li/dv/nilidvj4kqtrime1pgyzv11gh10.png"><br><br>  Este √© o mesmo sistema, mas com um novo estado de n√£o combate, que inclui Idling and Patrolling.  Com cada estado que cont√©m FSMs com subestados (e esses subestados, por sua vez, cont√™m seus pr√≥prios FSMs - e assim por diante, conforme necess√°rio), obtemos uma M√°quina de Estado Finito Hier√°rquico ou HFSM (m√°quina de estado hier√°rquico).  Depois de agrupar um estado de n√£o combate, cortamos v√°rias transi√ß√µes redundantes.  Podemos fazer o mesmo para quaisquer novos estados com transi√ß√µes comuns.  Por exemplo, se no futuro estendermos o estado Ataque aos estados MeleeAttacking e MissileAttacking, eles ser√£o subestados que se cruzam com base na dist√¢ncia do inimigo e na presen√ßa de muni√ß√£o.  Como resultado, modelos complexos de comportamento e submodelos de comportamento podem ser representados com um m√≠nimo de transi√ß√µes duplicadas. <br><br><h3>   </h3><br>  HFSM      .   ,   ,            .        ,  .           .    ,    ,            . ,      25%,  ,      ,     ,    ‚Äî        .            25%  10%,     . <br><br>       ,    ¬´   ¬ª,     ,            .    . <br><br>     ,           :    ¬´¬ª ,     ,   ,  .     : <br><br><ul><li>       : Succeeded (  ), Failed (  )  Running (        ). </li><li>         .    Decorator,      .   Succeed,      . </li><li> ,  ,   Running    . </li></ul><br>             .  HFSM        : <br><br><img src="https://habrastorage.org/webt/1i/e5/4i/1ie54izd-h-ybfpwrb-yowau724.png"><br><br>           Idling/Patrolling   Attacking   .   ,    ,     Fleeing,   ,      ‚Äî Patrolling, Idling, Attacking   . <br><br><img src="https://habrastorage.org/webt/iw/je/uu/iwjeuuax51z5qxgmg5h4zcbm4tg.png"><br><br>    ‚Äî     ,            .     ,     ‚Äî         ,     ?   ,    ‚Äî  ,      Idling   10    ,      ,    ? <br><br>     . ,        .        ,        . <br><br><h3> Utility-based system </h3><br>       . ,          ,        .  ,         ,           . <br><br> Utility-based system (,   )     .  ,      ,      ,     .   ‚Äî   ,         . <br><br>         ,            .    FSM,   ,        ,  .  ,         ( ,    ).       ,      . <br><br>       ‚Äî ,  0 ( )  100 ( ).      ,     .      : <br><br><img src="https://habrastorage.org/webt/ty/an/id/tyanidrfvaoee_ekrdretfmyqhg.png"><br><br>     ‚Äî       .       .   ,    ,    ,   Fleeing,  FindingHelp    .   FindingHelp   .  ,       50,      .          . <br><br>         ,      .          . ,  Fleeing     ,    ,   Attacking   ,    . -   Fleeing    Attacking   ,   ,         .          ,        ,     FSM. <br><br>        .            .  The Sims,     ,     ‚Äî    ¬´¬ª,    .   ,        ,     EatFood     ,     ,   ,    EatFood  . <br><br>         ,  Utility-based system        ,      .             .  ,       Utility    ,  ,    . <br><br><h2>    </h2><br>       ,      ,  ,    .            ?    ,    ,     ,      ,     ?   . <br><br><h3>  Ger√™ncia </h3><br>     ,      ,    ,        .        ,   ,     . .   Sense/Think/Act,   ,   Think  ,   Act     .      ,      ,        .        ‚Äî ,     .  ,    ,          .   : <br><br> <i>desired_travel = destination_position ‚Äì agent_position</i> <br><br>  2D-.     (-2,-2),   -  -   (30, 20),     ,    ‚Äî (32, 22). ,      ‚Äî      5   ,            (4.12, 2.83).            8 . <br><br>      .       ,     ,       5 / (   ),   .      ,         . <br><br>      ‚Äî ,   ,   ,        .        .     steering behaviours,      : Seek (), Flee (), Arrival ()  . .    ,         ,           ,       . <br><br>      . Seek  Arrival ‚Äî       . Obstacle Avoidance ( )  Separation ()   ,       . Alignment ()  Cohesion ()     .    steering behaviours            . ,   Arrival, Separation  Obstacle Avoidance,        .          . <br><br>    ,      ‚Äî  ,      -  Arrival  Obstacle Avoidance.    ,  ,     .  :     ,          . <br><br>        ,    ,   -   . <br><br><h3>   </h3><br> Steering behaviours         (   ),       ‚Äî        .      pathfinding ( ),            . <br><br>   ‚Äî                .  -     ,           ,     .    .         ,          ( ,     ).  ,     Breadth-First Search  BFS (   ).         ( breadth, ¬´¬ª).      ,  ,      ‚Äî         ,       ,       . <br><br><img src="https://habrastorage.org/webt/ik/gg/_n/ikgg_n7oyigrgvo1av12jtsaga4.gif"><br><br>      ,     .     (, pathfinding) ‚Äî  ,   ,    . <br><br> ,        ,   steering behaviours,     ‚Äî   1   2,    2   3   .   ‚Äî     ,    ‚Äî         . -        . <br><br>   BFS    ‚Äî       ¬´¬ª ,   ¬´¬ª.        A* (A star).   ,     - (  ,       ),         ,      ,     .     ,     ‚Äî ¬´¬ª      (    )   ,        (    ). <br><br><img src="https://habrastorage.org/webt/3k/jb/al/3kjbal-iagj4ovxicix2swrbsxq.gif"><br><br>    ,        ,    ,    .    ,    BFS,        ‚Äî        . <br><br><h3>    </h3><br>  Mas a maioria dos jogos n√£o √© apresentada na grade, e muitas vezes isso n√£o pode ser feito sem comprometer o realismo.  S√£o necess√°rios compromissos.  Qual o tamanho dos quadrados?  Grande demais - e eles n√£o conseguir√£o imaginar corretamente corredores ou curvas pequenos demais - haver√° muitos quadrados a serem pesquisados, o que no final levar√° muito tempo. <br><br>  A primeira coisa a entender √© que a grade nos fornece um gr√°fico de n√≥s conectados.  Os algoritmos A * e BFS realmente funcionam em gr√°ficos e n√£o se importam com nossa grade.  Poder√≠amos colocar os n√≥s em qualquer lugar do mundo do jogo: se houver uma conex√£o entre dois n√≥s conectados, bem como entre os pontos inicial e final e pelo menos um dos n√≥s, o algoritmo funcionar√° t√£o bem quanto antes.  Isso costuma ser chamado de sistema de waypoint, j√° que cada n√≥ representa uma posi√ß√£o significativa no mundo, que pode fazer parte de qualquer n√∫mero de caminhos hipot√©ticos. <br><br><img src="https://habrastorage.org/webt/k7/ab/gq/k7abgqdwnx7efuqf8pqw0p6nbqm.png"><br>  <i>Exemplo 1: um n√≥ em cada quadrado.</i>  <i>A pesquisa come√ßa no n√≥ em que o agente est√° localizado e termina no n√≥ do quadrado desejado.</i> <br><br><img src="https://habrastorage.org/webt/m6/lx/5a/m6lx5a5wleqbvxthzcoajeat_us.png"><br>  <i>Exemplo 2: um conjunto menor de n√≥s (pontos de refer√™ncia).</i>  <i>A pesquisa come√ßa ao quadrado com o agente, passa pelo n√∫mero necess√°rio de n√≥s e depois continua para o destino.</i> <br><br>  Este √© um sistema completamente flex√≠vel e poderoso.  Mas voc√™ precisa de cautela ao decidir onde e como posicionar o waypoint; caso contr√°rio, os agentes podem simplesmente n√£o ver o ponto mais pr√≥ximo e n√£o poder√£o iniciar o caminho.  Seria mais f√°cil se pud√©ssemos definir automaticamente waypoints com base na geometria do mundo. <br><br>  Em seguida, uma malha de navega√ß√£o ou navmesh aparece.  Geralmente, √© uma malha 2D de tri√¢ngulos que se sobrep√µe √† geometria do mundo - onde quer que o agente possa andar.  Cada um dos tri√¢ngulos na grade se torna um n√≥ no gr√°fico e tem at√© tr√™s tri√¢ngulos adjacentes que se tornam n√≥s adjacentes no gr√°fico. <br><br>  Esta imagem √© um exemplo do mecanismo do Unity - ele analisou a geometria no mundo e criou a navmesh (azul claro na captura de tela).  Cada pol√≠gono na navmesh √© uma √°rea na qual um agente pode permanecer ou mover-se de um pol√≠gono para outro pol√≠gono.  Neste exemplo, os pol√≠gonos s√£o menores que os pisos em que est√£o localizados - feitos para levar em considera√ß√£o as dimens√µes do agente, que v√£o al√©m da sua posi√ß√£o nominal. <br><br><img src="https://habrastorage.org/webt/-y/ip/ic/-yipico3akqxyv8hhubbe0rzkgk.png"><br><br>  Podemos pesquisar a rota atrav√©s dessa grade, novamente usando o algoritmo A *.  Isso nos dar√° uma rota quase perfeita no mundo, que leva em considera√ß√£o toda a geometria e n√£o requer n√≥s e pontos de refer√™ncia extras. <br><br>  A busca de caminhos √© um t√≥pico muito extenso sobre o qual uma se√ß√£o do artigo n√£o √© suficiente.  Se voc√™ quiser estud√°-lo com mais detalhes, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site de Amit Patel</a> ajudar√° nisso. <br><br><h2>  Planejamento </h2><br>  Asseguramos com a busca de caminhos que, √†s vezes, n√£o basta escolher uma dire√ß√£o e se mover - precisamos escolher uma rota e fazer v√°rias curvas para chegar ao destino desejado.  Podemos resumir esta id√©ia: alcan√ßar o objetivo n√£o √© apenas o pr√≥ximo passo, mas uma sequ√™ncia inteira, onde √†s vezes voc√™ precisa olhar adiante alguns passos para descobrir qual deve ser o primeiro.  Isso √© chamado de planejamento.  A busca de caminhos pode ser considerada uma das v√°rias adi√ß√µes de planejamento.  Da perspectiva do nosso ciclo Sense / Think / Act, √© aqui que a parte Think planeja v√°rias partes do Act para o futuro. <br><br>  Vejamos o exemplo do jogo de tabuleiro Magic: The Gathering.  Vamos primeiro com esse conjunto de cartas em m√£os: <br><br><ul><li>  P√¢ntano - d√° 1 mana preto (mapa da terra). </li><li>  Floresta - d√° 1 mana verde (mapa da terra). </li><li>  Mago Fugitivo - Requer 1 de mana azul para evocar. </li><li>  √âlfico M√≠stico - Requer 1 mana verde para evocar. </li></ul><br>  Ignoramos os tr√™s cart√µes restantes para facilitar.  De acordo com as regras, √© permitido ao jogador jogar 1 carta de terreno por turno, ele pode "tocar" esta carta para extrair mana dela e, em seguida, usar magias (incluindo convocar criaturas) de acordo com a quantidade de mana.  Nesta situa√ß√£o, o jogador humano sabe que voc√™ precisa jogar Forest, "toque" em 1 mana verde e depois chame Elvish Mystic.  Mas como voc√™ adivinha o jogo AI? <br><br><h3>  Planejamento f√°cil </h3><br>  A abordagem trivial √© tentar cada a√ß√£o sucessivamente at√© que existam.  Olhando para as cartas, a IA v√™ o que o Swamp pode jogar.  E toca.  Ainda existem outras a√ß√µes neste turno?  Ele n√£o pode convocar Elfish Mystic ou Fugitive Wizard, j√° que a convoca√ß√£o deles requer mana verde e azul, respectivamente, e Swamp d√° apenas mana negra.  E ele n√£o ser√° capaz de jogar Forest, porque ele j√° jogou Swamp.  Assim, o jogo AI seguiu as regras, mas fez mal.  Pode ser melhorado. <br><br>  O planejamento pode encontrar uma lista de a√ß√µes que levam o jogo ao estado desejado.  Assim como cada quadrado no caminho tinha vizinhos (na busca de caminhos), cada a√ß√£o no plano tamb√©m tem vizinhos ou sucessores.  Podemos procurar essas a√ß√µes e a√ß√µes subseq√ºentes at√© atingirmos o estado desejado. <br><br>  Em nosso exemplo, o resultado desejado √© "convocar uma criatura, se poss√≠vel".  No in√≠cio da jogada, vemos apenas duas a√ß√µes poss√≠veis permitidas pelas regras do jogo: <br><br>  <i>1. Jogue P√¢ntano (resultado: P√¢ntano no jogo)</i> <i><br></i>  <i>2. Jogue Floresta (resultado: Floresta no jogo)</i> <br><br>  Cada a√ß√£o tomada pode levar a outras a√ß√µes e fechar outras, novamente, dependendo das regras do jogo.  Imagine que jogamos Swamp - isso remover√° o Swamp como o pr√≥ximo passo (j√° o jogamos) e tamb√©m excluir√° Forest (porque pelas regras voc√™ pode jogar um mapa do terreno por turno).  Depois disso, a IA √© adicionada como o pr√≥ximo passo - recebendo 1 mana preto, porque n√£o h√° outras op√ß√µes.  Se ele for mais longe e escolher Tap the Swamp, ele receber√° 1 unidade de mana negra e n√£o pode fazer nada com isso. <br><br>  <i>1. Jogue P√¢ntano (resultado: P√¢ntano no jogo)</i> <i><br></i>  <i>1.1 P√¢ntano "Tap" (resultado: "tap" do p√¢ntano, +1 unidade de mana negra)</i> <i><br></i>  <i>Nenhuma a√ß√£o dispon√≠vel - FIM</i> <i><br></i>  <i>2. Jogue Floresta (resultado: Floresta no jogo)</i> <br><br>  A lista de a√ß√µes foi curta, estamos em um impasse.  Repita o processo para a pr√≥xima etapa.  Jogamos Forest, abrimos a a√ß√£o "receba 1 mana verde", que por sua vez abrir√° a terceira a√ß√£o - o chamado de Elvish Mystic. <br><br>  <i>1. Jogue P√¢ntano (resultado: P√¢ntano no jogo)</i> <i><br></i>  <i>1.1 P√¢ntano "Tap" (resultado: "tap" do p√¢ntano, +1 unidade de mana negra)</i> <i><br></i>  <i>Nenhuma a√ß√£o dispon√≠vel - FIM</i> <i><br></i>  <i>2. Jogue Floresta (resultado: Floresta no jogo)</i> <i><br></i>  <i>2.1 Floresta "Tap" (resultado: "tap" da floresta, +1 unidade de mana verde)</i> <i><br></i>  <i>2.1.1 Evocar √âlfico M√≠stico (resultado: √âlfico M√≠stico no jogo, -1 unidade de mana verde)</i> <i><br></i>  <i>Nenhuma a√ß√£o dispon√≠vel - FIM</i> <br><br>  Finalmente, examinamos todas as a√ß√µes poss√≠veis e encontramos um plano chamando a criatura. <br><br>  Este √© um exemplo muito simplificado.  √â aconselh√°vel escolher o melhor plano poss√≠vel, e n√£o um que atenda a alguns crit√©rios.  Como regra, voc√™ pode avaliar poss√≠veis planos com base no resultado final ou nos benef√≠cios totais de sua implementa√ß√£o.  Voc√™ pode adicionar 1 ponto para jogar um mapa da terra e 3 pontos para desafiar uma criatura.  Jogar Swamp seria um plano dando 1 ponto.  E para jogar Forest ‚Üí Tap the Forest ‚Üí chame Elvish Mystic - ele imediatamente dar√° 4 pontos. <br><br>  √â assim que o planejamento funciona em Magic: The Gathering, mas pela mesma l√≥gica que se aplica em outras situa√ß√µes.  Por exemplo, mova um pe√£o para dar espa√ßo para o bispo se mover no xadrez.  Ou se esconda atr√°s de uma parede para atirar com seguran√ßa no XCOM dessa maneira.  Em geral, voc√™ entende o ponto. <br><br><h3>  Planejamento aprimorado </h3><br>  √Äs vezes, existem muitas a√ß√µes em potencial para considerar todas as op√ß√µes poss√≠veis.  Retornando ao exemplo com Magic: The Gathering: digamos que no jogo e em suas m√£os existam v√°rias cartas de terra e criaturas - o n√∫mero de combina√ß√µes poss√≠veis de movimentos pode estar nas dezenas.  Existem v√°rias solu√ß√µes para o problema. <br><br>  A primeira maneira √© encadear para tr√°s.  Em vez de classificar todas as combina√ß√µes, √© melhor come√ßar com o resultado final e tentar encontrar uma rota direta.  Em vez do caminho da raiz da √°rvore para uma folha espec√≠fica, avan√ßamos na dire√ß√£o oposta - da folha para a raiz.  Este m√©todo √© mais simples e r√°pido. <br><br>  Se o oponente tiver 1 unidade de vida, voc√™ pode encontrar um plano para "causar 1 ou mais unidades de dano".  Para conseguir isso, v√°rias condi√ß√µes devem ser atendidas: <br><br>  1. O dano pode ser causado por um feiti√ßo - ele deve estar na m√£o. <br>  2. Para lan√ßar um feiti√ßo, voc√™ precisa de mana. <br>  3. Para obter mana, voc√™ precisa jogar uma carta de terreno. <br>  4. Para jogar uma carta da terra - voc√™ precisa da sua m√£o. <br><br>  Outra maneira √© a melhor pesquisa em primeiro lugar.  Em vez de percorrer todos os caminhos, escolhemos o mais adequado.  Na maioria das vezes, esse m√©todo fornece um plano ideal sem custos desnecess√°rios de pesquisa.  A * √© a forma da melhor primeira pesquisa - explorando as rotas mais promissoras desde o in√≠cio, ele j√° pode encontrar o melhor caminho sem precisar verificar outras op√ß√µes. <br><br>  Uma op√ß√£o interessante e cada vez mais popular para a melhor pesquisa pela primeira vez √© a Pesquisa de √Årvores em Monte Carlo.  Em vez de adivinhar quais planos s√£o melhores que outros ao escolher cada a√ß√£o subsequente, o algoritmo seleciona sucessores aleat√≥rios a cada passo at√© chegar ao fim (quando o plano levou √† vit√≥ria ou derrota).  Em seguida, o resultado final √© usado para aumentar ou diminuir a classifica√ß√£o de peso das op√ß√µes anteriores.  Repetindo esse processo v√°rias vezes seguidas, o algoritmo fornece uma boa estimativa de qual pr√≥ximo passo √© melhor, mesmo que a situa√ß√£o mude (se o oponente tomar medidas para impedir o jogador). <br><br>  A hist√≥ria sobre o planejamento em jogos n√£o ficar√° sem o Planejamento de a√ß√µes orientadas a objetivos ou o GOAP (planejamento de a√ß√µes orientadas a objetivos).  Este √© um m√©todo amplamente utilizado e discutido, mas, al√©m de alguns detalhes distintos, √© essencialmente o m√©todo de encadeamento reverso sobre o qual falamos anteriormente.  Se a tarefa era "destruir o jogador", e o jogador est√° escondido, o plano pode ser o seguinte: destruir com uma granada ‚Üí obter ‚Üí largar. <br><br>  Geralmente, existem v√°rios objetivos, cada um com sua pr√≥pria prioridade.  Se o objetivo com a maior prioridade n√£o puder ser completado (nenhuma combina√ß√£o de a√ß√µes cria um plano para "destruir o jogador" porque o jogador n√£o est√° vis√≠vel), a IA retornar√° aos alvos com uma prioridade mais baixa. <br><br><h2>  Treinamento e adapta√ß√£o </h2><br>  J√° dissemos que a IA de jogos geralmente n√£o usa aprendizado de m√°quina porque n√£o √© adequada para gerenciar agentes em tempo real.  Mas isso n√£o significa que voc√™ n√£o possa emprestar nada dessa √°rea.  Queremos um advers√°rio assim em um jogo de tiro com o qual possamos aprender alguma coisa.  Por exemplo, descubra as melhores posi√ß√µes no mapa.  Ou um advers√°rio em um jogo de luta que bloqueia truques de combina√ß√£o frequentemente usados ‚Äã‚Äãpelo jogador, motivando outros a usar.  Portanto, o aprendizado de m√°quina nessas situa√ß√µes pode ser muito √∫til. <br><br><h3>  Estat√≠stica e Probabilidades </h3><br>  Antes de passarmos a exemplos complexos, estimaremos at√© onde podemos chegar, tomando algumas medidas simples e usando-as para tomar decis√µes.  Por exemplo, uma estrat√©gia em tempo real - como podemos determinar se um jogador pode lan√ßar um ataque nos primeiros minutos de um jogo e que defesa deve ser preparada contra isso?  Podemos estudar a experi√™ncia passada do jogador para entender qual ser√° a rea√ß√£o futura.  Para come√ßar, n√£o temos esses dados iniciais, mas podemos colet√°-los - sempre que a IA √© jogada contra uma pessoa, ele pode registrar a hora do primeiro ataque.  Ap√≥s v√°rias sess√µes, obteremos o tempo m√©dio pelo qual o jogador atacar√° no futuro. <br><br>  Os valores m√©dios t√™m um problema: se um jogador ‚Äúdecide‚Äù 20 vezes e joga lentamente 20 vezes, ent√£o os valores necess√°rios estar√£o em algum lugar no meio, e isso n√£o nos dar√° nada de √∫til.  Uma solu√ß√£o √© limitar a entrada - voc√™ pode considerar as √∫ltimas 20 partes. <br><br>  Uma abordagem semelhante √© usada para avaliar a probabilidade de certas a√ß√µes, assumindo que as prefer√™ncias passadas do jogador ser√£o as mesmas no futuro.  Se um jogador nos atacar cinco vezes com uma bola de fogo, duas vezes com raios e uma vez com combate corpo a corpo, √© √≥bvio que ele prefere uma bola de fogo.  Extrapolamos e vemos a probabilidade de usar v√°rias armas: bola de fogo = 62,5%, raio = 25% e corpo a corpo = 12,5%.  Nosso jogo AI precisa se preparar para prote√ß√£o contra inc√™ndio. <br><br>  Outro m√©todo interessante √© usar o Naive Bayes Classifier (classificador bayesiano ing√™nuo) para estudar grandes volumes de dados de entrada e classificar a situa√ß√£o para que a IA responda da maneira correta.  Os classificadores bayesianos s√£o mais conhecidos por usar filtros de spam de e-mail.  L√°, eles pesquisam palavras, as comparam com o local onde essas palavras apareceram anteriormente (em spam ou n√£o) e tiram conclus√µes sobre as cartas recebidas.  Podemos fazer o mesmo, mesmo com menos entrada.  Com base em todas as informa√ß√µes √∫teis que a IA v√™ (por exemplo, quais unidades inimigas s√£o criadas, ou quais feiti√ßos eles usam, ou que tecnologias exploraram) e o resultado final (guerra ou paz, "esmagar" ou defender etc.) - selecionaremos o comportamento de IA desejado. <br><br>  Todos esses m√©todos de treinamento s√£o suficientes, mas √© aconselh√°vel us√°-los com base nos dados dos testes.  A IA aprender√° como se adaptar √†s v√°rias estrat√©gias usadas pelos testadores de jogo.  Uma IA que se adapta a um jogador ap√≥s um lan√ßamento pode se tornar muito previs√≠vel ou vice-versa, muito complexa para vencer. <br><br><h3>  Adapta√ß√£o Baseada em Valor </h3><br>  Dado o conte√∫do do nosso mundo de jogo e as regras, podemos alterar o conjunto de valores que afetam a tomada de decis√£o, e n√£o apenas usar os dados de entrada.  Fazemos isso: <br><br><ul><li>  Deixe a IA coletar dados sobre o estado do mundo e os principais eventos durante o jogo (como indicado acima). </li><li>  Vamos mudar alguns valores importantes com base nesses dados. </li><li>  Realizamos nossas decis√µes com base no processamento ou avalia√ß√£o desses valores. </li></ul><br>  Por exemplo, um agente tem v√°rias salas para escolher um atirador em primeira pessoa no mapa.  Cada quarto tem seu pr√≥prio valor, que determina o quanto √© desej√°vel visitar.  A IA escolhe aleatoriamente qual o espa√ßo a seguir, com base no valor do valor.  Em seguida, o agente se lembra em qual quarto ele foi morto e reduz seu valor (a probabilidade de ele voltar para l√°).  Da mesma forma para a situa√ß√£o inversa - se o agente destruir muitos oponentes, o valor da sala aumentar√°. <br><br><h3>  Modelo de Markov </h3><br>  E se usarmos os dados coletados para previs√£o?  Se lembrarmos de cada sala em que vemos o jogador por um determinado per√≠odo de tempo, preveremos em qual sala o jogador poder√° entrar.  Ao rastrear e registrar o movimento do jogador nas salas (valores), podemos prever. <br><br>  Vamos pegar tr√™s quartos: vermelho, verde e azul.  Assim como as observa√ß√µes que registramos ao assistir a uma sess√£o de jogo: <br><br><img src="https://habrastorage.org/webt/cz/qm/-k/czqm-khdlmnybf2c4amu6v_yrc0.png"><br><br>  O n√∫mero de observa√ß√µes para cada sala √© quase igual - ainda n√£o sabemos onde fazer um bom lugar para uma emboscada.  A coleta de estat√≠sticas tamb√©m √© complicada pelo reaparecimento de jogadores que aparecem uniformemente ao longo do mapa.  Mas os dados na pr√≥xima sala, que eles inserem ap√≥s aparecerem no mapa, j√° s√£o √∫teis. <br><br>  Pode-se ver que a sala verde combina com os jogadores - a maioria das pessoas de vermelho vai para ela, 50% das quais permanece l√° e al√©m.  A sala azul, pelo contr√°rio, n√£o √© popular, quase nunca √© visitada e, se for, n√£o permanece. <br><br>  Mas os dados nos dizem algo mais importante - quando o jogador est√° na sala azul, a pr√≥xima sala em que provavelmente o veremos ficar√° vermelha, n√£o verde.  Apesar do fato de a sala verde ser mais popular que a vermelha, a situa√ß√£o muda se o jogador estiver em azul.  O pr√≥ximo estado (ou seja, a sala em que o jogador entrar√°) depende do estado anterior (ou seja, a sala em que o jogador est√° agora).  Devido ao estudo das depend√™ncias, faremos previs√µes com mais precis√£o do que se simplesmente calcul√°ssemos as observa√ß√µes independentemente uma da outra. <br><br>  A previs√£o de um estado futuro com base em dados de estados passados ‚Äã‚Äã√© chamada de modelo de Markov, e esses exemplos (com salas) s√£o chamados de cadeias de Markov.  Como os modelos representam a probabilidade de altera√ß√µes entre estados sucessivos, eles s√£o exibidos visualmente como FSMs com uma probabilidade pr√≥xima a cada transi√ß√£o.  Anteriormente, usamos o FSM para representar o estado comportamental em que o agente estava localizado, mas esse conceito se aplica a qualquer estado, independentemente de estar ou n√£o relacionado ao agente.  Nesse caso, os estados representam a sala ocupada pelo agente: <br><br><img src="https://habrastorage.org/webt/xj/jn/zn/xjjnznthergzfs89ixqdghp7bjq.png"><br><br>  Esta √© uma vers√£o simples da representa√ß√£o da probabilidade relativa de altera√ß√µes nos estados, dando √† AI alguma oportunidade de prever o pr√≥ximo estado.  Voc√™ pode prever alguns passos √† frente. <br><br>  Se o jogador estiver na sala verde, h√° 50% de chance de ele permanecer l√° durante a pr√≥xima observa√ß√£o.  Mas qual √© a probabilidade de ele ainda estar l√°, mesmo depois?  N√£o h√° apenas uma chance de o jogador permanecer na sala verde ap√≥s duas observa√ß√µes, mas tamb√©m a chance de ele sair e retornar.  Aqui est√° a nova tabela com os novos dados: <br><br><img src="https://habrastorage.org/webt/te/wc/ya/tewcyajzsv_ys-9bro4mjdhtpte.png"><br><br>  Isso mostra que a chance de ver um jogador na sala verde ap√≥s duas observa√ß√µes ser√° de 51% a 21%, de que ele vir√° da sala vermelha, 5% deles, que o jogador visitar√° a sala azul entre eles e 25%, que o jogador n√£o v√™ vai sair da sala verde. <br><br>  Uma tabela √© apenas uma ferramenta visual - um procedimento requer apenas uma multiplica√ß√£o de probabilidades em cada etapa.  Isso significa que voc√™ pode olhar para o futuro com uma altera√ß√£o: assumimos que a chance de entrar em uma sala depende completamente da sala atual.  Isso √© chamado de Propriedade Markov - o estado futuro depende apenas do presente.  Mas isso n√£o √© completamente preciso.  Os jogadores podem tomar decis√µes dependendo de outros fatores: n√≠vel de sa√∫de ou quantidade de muni√ß√£o.  Como n√£o fixamos esses valores, nossas previs√µes ser√£o menos precisas. <br><br><h3>  N-gramas </h3><br>         - ?   !      ,     ,    -. <br><br>      ‚Äî    (, Kick, Punch  Block)         . ,    Kick, Kick, Punch,    SuperDeathFist,           ,    . <br><br><img src="https://habrastorage.org/webt/2m/ji/l4/2mjil4fdhjrro3em8vde-zcxhak.png"><br> (  ,     SuperDeathFist.) <br><br>    ,    Kick,    Kick,   ,     Punch.     - SuperDeathFist   ,   . <br><br>     N- (N-grams),  N ‚Äî   .      3- (),  :       .   5-        . <br><br>      N-.   N   ,     . , 2- ()   Kick, Kick  Kick, Punch,     Kick, Kick, Punch,       SuperDeathFist. <br><br>   ,          ,       .        Kick, Punch  Block,    10-,    60   . <br><br>       ‚Äî   ¬´ / ¬ª  ,         . 3-    N-      ,    (   N-)    ,    ‚Äî .         Kick  Kick   Kick  Punch.        , ,  ,       .     ,          ,  -  . <br><br><h2>  Conclus√£o </h2><br>            .    ,          . <br><br>           . ,  ,     .   ,     : <br><br><ul><li>   ,    ,      </li><li>   / (minimax  alpha-beta pruning) </li><li>   (,      ) </li><li>        </li><li>     ( ,        ) </li><li>   (   ) </li><li>   ( ,  anytime,  timeslicing) </li></ul><br> -  : <br><br> 1.  GameDev.net  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">      </a> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> . <br> 2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AiGameDev.com</a>             . <br> 3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">The GDC Vault</a>       GDC AI,     . <br> 4.        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Game Programmers Guild</a> . <br> 5.  ,     ,    YouTube- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI and Games</a>        . <br><br>   : <br><br> 1.   Game AI Pro     , ,         . <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=http://go.gamedev.net/%3Fid%3D13722X707581%26xs%3D1%26isjs%3D1%26url%3Dhttps%253A%252F%252Famzn.to%252F2KGoB8n%26xguid%3Df8ad586e5984991508efff4754027dbd%26xuuid%3D305451ecead59d76ca830fded0aab276%26xsessid%3D6ccb8b9fa3f10b478b65f7ed703a447b%26xcreo%3D0%26xed%3D0%26sref%3Dhttps%253A%252F%252Fwww.gamedev.net%252Farticles%252Fprogramming%252Fartificial-intelligence%252Fthe-total-beginners-guide-to-game-ai-r4942%252F%253Fdo%253Dedit%2526d%253D1%2526id%253D4942%2526csrfKey%253D7015c6d2c5c643e87baa74f8e5d2c094%26pref%3D">Game AI Pro: Collected Wisdom of Game AI Professionals</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=http://go.gamedev.net/%3Fid%3D13722X707581%26xs%3D1%26isjs%3D1%26url%3Dhttps%253A%252F%252Famzn.to%252F2KFKyoe%26xguid%3Df8ad586e5984991508efff4754027dbd%26xuuid%3D305451ecead59d76ca830fded0aab276%26xsessid%3D6ccb8b9fa3f10b478b65f7ed703a447b%26xcreo%3D0%26xed%3D0%26sref%3Dhttps%253A%252F%252Fwww.gamedev.net%252Farticles%252Fprogramming%252Fartificial-intelligence%252Fthe-total-beginners-guide-to-game-ai-r4942%252F%253Fdo%253Dedit%2526d%253D1%2526id%253D4942%2526csrfKey%253D7015c6d2c5c643e87baa74f8e5d2c094%26pref%3D">Game AI Pro 2: Collected Wisdom of Game AI Professionals</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Game AI Pro 3: Collected Wisdom of Game AI Professionals</a> <br><br> 2.  AI Game Programming Wisdom ‚Äî   Game AI Pro.     ,      . <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Game Programming Wisdom 1</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Game Programming Wisdom 2</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Game Programming Wisdom 3</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Game Programming Wisdom 4</a> <br><br> 3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artificial Intelligence: A Modern Approach</a> ‚Äî              .       ‚Äî     . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt428892/">https://habr.com/ru/post/pt428892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt428878/index.html">Voo de porco ou otimiza√ß√£o de int√©rpretes de bytecode</a></li>
<li><a href="../pt428880/index.html">Novos m√©todos de autentica√ß√£o - uma amea√ßa √† privacidade?</a></li>
<li><a href="../pt428882/index.html">Mobile Yandex Blitz: analisamos tarefas</a></li>
<li><a href="../pt428888/index.html">qml: poder e simplicidade</a></li>
<li><a href="../pt428890/index.html">Toda a verdade sobre o RTOS. Artigo # 18 Grupos de Sinalizadores de Eventos: Servi√ßos Auxiliares e Estruturas de Dados</a></li>
<li><a href="../pt428894/index.html">IVA nas compras dom√©sticas</a></li>
<li><a href="../pt428896/index.html">Redes neurais de censura hentai</a></li>
<li><a href="../pt428898/index.html">Aspectos problem√°ticos da programa√ß√£o em C ++</a></li>
<li><a href="../pt428900/index.html">Rob√¥s com rodas come√ßam a entregar mercadorias a residentes dos Estados Unidos e da Gr√£-Bretanha</a></li>
<li><a href="../pt428902/index.html">Tags sem fio NFC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
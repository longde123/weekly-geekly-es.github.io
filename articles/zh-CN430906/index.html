<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👆🏿 💬 🚡 妈妈晚上平静地入睡-我们为Raspbian'a收集OpenCV 👩🏽‍💻 🚴🏿 ㊙️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="最近几周对我们的团队来说很艰难。 OpenCV 4已发布 ，并与之一起为Intel的OpenVINO工具包 R4（包括OpenCV）做准备。 您可能认为，我已经分散了一段时间，我会像往常一样关注OpenCV论坛和用户评论，在这里您可以说OpenCV不是物联网，在Raspberry Pi下它足以组装-...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>妈妈晚上平静地入睡-我们为Raspbian'a收集OpenCV</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/430906/"><p>最近几周对我们的团队来说很艰难。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenCV 4已发布</a> ，并与之一起为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Intel的OpenVINO工具包</a> R4（包括OpenCV）做准备。 您可能认为，我已经分散了一段时间，我会像往常一样关注OpenCV论坛和用户评论，在这里您可以说OpenCV不是物联网，在Raspberry Pi下它足以组装-没有足够的焊料可一<code>make -j2</code>地投入<code>make -j2</code>如果您幸运的话，早晨将准备就绪。 </p><br><p> 因此，我建议携手合作，看看如何为一个运行在ARM处理器上的32位操作系统组装OpenCV库，如何使用具有出色CPU架构的64位OS计算机资源。 <del> 巫术 </del> 交叉编译，否则不会！ </p><a name="habracut"></a><br><h2 id="postanovka-zadachi"> 问题陈述 </h2><br><p> 直接在板上进行编译（通常称为本地编译）确实很费力，因此在这里，我们将考虑一种构建项目的方法，该项目可以使功能更强大的计算设备（称为主机）为小亲戚准备二进制文件。 而且，两台机器可以具有不同的CPU架构。 这是交叉编译。 </p><br><p> 因此，要准备塞满OpenCV的树莓派，我们需要： </p><br><ul><li>  Ubuntu 16.04镜像docker尸体 </li><li> 主机比Raspberry Pi更强大（否则，有什么意义，不是吗？） </li><li> 用于ARMhf的交叉编译器以及相应体系结构的库 </li></ul><br><p> 构建OpenCV的整个过程将在主机上进行。 我在家使用Ubuntu。 使用其他版本的Linux，应该不会出现播放问题。 对于Windows用户-我衷心希望不要放弃并尝试自己解决这个问题。 </p><br><h2 id="ustanovka-docker"> 安装Docker </h2><br><p> 大约一周前，我开始与docker结识，因此添加美味的食盐和语法糖。 对您我来说，三个要素就足够了-Dockerfile，映像和容器的概念。 </p><br><p>  Docker本身是一种用于创建和复制具有必需组件集的任何操作系统的配置的工具。  Dockerfile是通常在主机上使用的一组shell命令，但是在这种情况下，它们都适用于所谓的<code>docker</code>映像。 </p><br><p> 为了安装docker，请考虑最简单的方法：通过<code>apt-get</code>交付服务订购软件包： </p><br><pre> <code class="bash hljs">sudo apt-get install -y docker.io</code> </pre> <br><p> 我们将为docker守护程序提供它所要求的一切，并从系统注销（注意相应地登录）。 </p><br><pre> <code class="bash hljs">sudo usermod -a -G docker <span class="hljs-variable"><span class="hljs-variable">$USER</span></span></code> </pre> <br><h2 id="podgotavlivaem-rabochee-prostranstvo"> 准备工作区 </h2><br><p> 最常见的准备工作是Raspberry Pi（在我的情况下为RPI 2 Model B）是带有Raspbian（基于Debian）操作系统的ARMv7 CPU。 我们将基于Ubuntu 16.04创建一个<code>docker</code>映像，在其中我们将报告交叉编译器，军队库并在同一位置收集OpenCV。 </p><br><p> 在我们的<code>Dockerfile</code>所在的位置创建一个爸爸： </p><br><pre> <code class="bash hljs">mkdir ubuntu16_armhf_opencv &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ubuntu16_armhf_opencv touch Dockerfile</code> </pre> <br><p> 添加有关<code>apt-get</code>软件包安装程序的基本操作系统和<code>armhf</code>体系结构的信息： </p><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 USER root RUN dpkg --add-architecture armhf RUN apt-get update</code> </pre> <br><p> 请注意，诸如<code>FROM ...</code> ， <code>RUN ...</code>类的命令是<code>Dockerfile</code>语法，并写入创建的<code>Dockerfile</code>测试文件中。 </p><br><p> 让我们回到父目录<code>ubuntu16_armhf_opencv</code>并尝试创建我们的<code>ubuntu16_armhf_opencv</code>镜像： </p><br><pre> <code class="bash hljs">docker image build ubuntu16_armhf_opencv</code> </pre> <br><p> 在执行<code>apt-get update</code>命令期间，应导致您看到以下类型的<code>Err:[] [url] xenial[-] armhf Packages</code> </p><br><pre> <code class="bash hljs">Ign:30 http://archive.ubuntu.com/ubuntu xenial-backports/main armhf Packages Ign:32 http://archive.ubuntu.com/ubuntu xenial-backports/universe armhf Packages Err:7 http://archive.ubuntu.com/ubuntu xenial/main armhf Packages 404 Not Found Ign:9 http://archive.ubuntu.com/ubuntu xenial/restricted armhf Packages Ign:18 http://archive.ubuntu.com/ubuntu xenial/universe armhf Packages Ign:20 http://archive.ubuntu.com/ubuntu xenial/multiverse armhf Packages Err:22 http://archive.ubuntu.com/ubuntu xenial-updates/main armhf Packages 404 Not Found Ign:24 http://archive.ubuntu.com/ubuntu xenial-updates/restricted armhf Packages Ign:26 http://archive.ubuntu.com/ubuntu xenial-updates/universe armhf Packages Ign:28 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse armhf Packages Err:30 http://archive.ubuntu.com/ubuntu xenial-backports/main armhf Packages 404 Not Found Ign:32 http://archive.ubuntu.com/ubuntu xenial-backports/universe armhf Packages</code> </pre> <br><p> 如果查看文件<code>/etc/apt/sources.list</code>那么每个这样的错误都对应<code>/etc/apt/sources.list</code>行，例如： </p><br><p>  <strong>失误</strong> </p><br><pre> <code class="plaintext hljs">Err:22 http://archive.ubuntu.com/ubuntu xenial-updates/main armhf Packages 404 Not Found</code> </pre> <br><p>  <strong>在/etc/apt/sources.list中的行</strong> ： </p><br><pre> <code class="plaintext hljs">deb http://archive.ubuntu.com/ubuntu/ xenial-updates main restricted</code> </pre> <br><p>  <strong>解决方案</strong> ： <br> 分为两部分： </p><br><pre> <code class="plaintext hljs">deb [arch=amd64] http://archive.ubuntu.com/ubuntu/ xenial-updates main restricted deb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ xenial-updates main restricted</code> </pre> <br><p> 因此，您必须替换几个软件包源。 在我们的泊坞窗中，我们将用一个命令将它们全部替换： </p><br><pre> <code class="plaintext hljs">RUN sed -i -E 's|^deb ([^ ]+) (.*)$|deb [arch=amd64] \1 \2\ndeb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ \2|' /etc/apt/sources.list</code> </pre> <br><p> 现在， <code>apt-get update</code>应该可以正常工作了。 </p><br><h2 id="stavim-neobhodimye-pakety"> 我们把必要的包裹 </h2><br><p> 我们需要提供主机包，例如<code>git</code> ， <code>python-pip</code> ， <code>cmake</code>和<code>pkg-config</code>以及<code>crossbuild-essential-armhf</code> ，这是一组gcc / g ++交叉编译器（ <code>arm-linux-gnueabihf-gcc</code>和<code>arm-linux-gnueabihf-g++</code> ）和相应架构的系统库： </p><br><pre> <code class="plaintext hljs">RUN apt-get install -y git python-pip cmake pkg-config crossbuild-essential-armhf</code> </pre> <br><p> 从不同寻常的地方-我们还下载了GTK（用于在highgui模块中绘制窗口），GStreamer和Python，但明确指出了外部体系结构： </p><br><pre> <code class="plaintext hljs">RUN apt-get install -y --no-install-recommends \ libgtk2.0-dev:armhf \ libpython-dev:armhf \ libgstreamer1.0-dev:armhf \ libgstreamer-plugins-base1.0-dev:armhf \ libgstreamer-plugins-good1.0-dev:armhf \ libgstreamer-plugins-bad1.0-dev:armhf</code> </pre> <br><p> 然后我们克隆并收集，指示必要的标志： </p><br><pre> <code class="plaintext hljs">RUN git clone https://github.com/opencv/opencv --depth 1 RUN mkdir opencv/build &amp;&amp; cd opencv/build &amp;&amp; \ export PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig &amp;&amp; \ cmake -DCMAKE_BUILD_TYPE=Release \ -DOPENCV_CONFIG_INSTALL_PATH="cmake" \ -DCMAKE_TOOLCHAIN_FILE="../opencv/platforms/linux/arm-gnueabi.toolchain.cmake" \ -DWITH_IPP=OFF \ -DBUILD_TESTS=OFF \ -DBUILD_PERF_TESTS=OFF \ -DOPENCV_ENABLE_PKG_CONFIG=ON \ -DPYTHON2_INCLUDE_PATH="/usr/include/python2.7" \ -DPYTHON2_NUMPY_INCLUDE_DIRS="/usr/local/lib/python2.7/dist-packages/numpy/core/include" \ -DENABLE_NEON=ON \ -DCPU_BASELINE="NEON" ..</code> </pre> <br><p> 在哪里 </p><br><ul><li><p>  <code>CMAKE_TOOLCHAIN_FILE</code>定义交叉编译过程的cmake文件的路径（设置所需的编译器，限制使用主机库。 </p><br></li><li><p>  <code>WITH_IPP=OFF</code> ，-禁用大量依赖。 </p><br></li><li><p>  <code>BUILD_TESTS=OFF</code> ， <code>BUILD_PERF_TESTS=OFF</code> ，禁用测试版本。 </p><br></li><li><p>  <code>OPENCV_ENABLE_PKG_CONFIG=ON</code>这样pkg-config可以找到类似GTK的依赖项。  <code>PKG_CONFIG_PATH</code>是<code>pkg-config</code>将在其中查找库的正确路径。 </p><br></li><li><p>  <code>PYTHON2_INCLUDE_PATH</code> ， <code>PYTHON2_NUMPY_INCLUDE_DIRS</code>交叉编译python2包装器所需的路径。 </p><br></li><li><p>  <code>ENABLE_NEON=ON</code> ， <code>CPU_BASELINE="NEON"</code> -启用NEON优化。 </p><br></li><li><p>  <code>OPENCV_CONFIG_INSTALL_PATH</code>调整文件在<code>install</code>目录中的位置。 </p><br></li></ul><br><p>  <code>cmake</code>执行后，您应注意的主要事情是所有必需的模块都已组装（例如python2）： </p><br><pre> <code class="plaintext hljs">-- OpenCV modules: -- To be built: calib3d core dnn features2d flann gapi highgui imgcodecs imgproc java_bindings_generator ml objdetect photo python2 python_bindings_generator stitching ts video videoio -- Disabled: world -- Disabled by dependency: - -- Unavailable: java js python3 -- Applications: tests perf_tests apps -- Documentation: NO -- Non-free algorithms: NO</code> </pre> <br><p> 并找到了必要的依赖项，例如GTK： </p><br><pre> <code class="plaintext hljs">-- GUI: -- GTK+: YES (ver 2.24.30) -- GThread : YES (ver 2.48.2) -- GtkGlExt: NO -- -- Video I/O: -- GStreamer: -- base: YES (ver 1.8.3) -- video: YES (ver 1.8.3) -- app: YES (ver 1.8.3) -- riff: YES (ver 1.8.3) -- pbutils: YES (ver 1.8.3) -- v4l/v4l2: linux/videodev2.h</code> </pre> <br><p> 剩下的就是调用<code>make</code> ， <code>make install</code>并等待构建完成： </p><br><pre> <code class="plaintext hljs">Successfully built 4dae6b1a7d32</code> </pre> <br><p> 使用此图像<code>id</code>标记并创建一个容器： </p><br><pre> <code class="plaintext hljs">docker tag 4dae6b1a7d32 ubuntu16_armhf_opencv:latest docker run ubuntu16_armhf_opencv</code> </pre> <br><p> 我们只需要从容器中抽出组装好的OpenCV。 首先，让我们看一下创建的容器的标识符： </p><br><pre> <code class="plaintext hljs">$ docker container ls --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e94667fe60d2 ubuntu16_armhf_opencv "/bin/bash" 6 seconds ago Exited (0) 5 seconds ago clever_yalow</code> </pre> <br><p> 并复制已安装OpenCV的安装目录： </p><br><pre> <code class="plaintext hljs">docker cp e94667fe60d2:/opencv/build/install/ ./ mv install ocv_install</code> </pre> <br><h2 id="nakryvaem-na-stol"> 摆桌子 </h2><br><p> 将<code>ocv_install</code>复制到Raspberry Pi，设置路径并尝试从python运行OpenCV。 </p><br><pre> <code class="plaintext hljs">export LD_LIBRARY_PATH=/path/to/ocv_install/lib/:$LD_LIBRARY_PATH export PYTHONPATH=/path/to/ocv_install/python/:$PYTHONPATH</code> </pre> <br><p> 使用来自<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://github.com/chuanqi305/MobileNet-SSD</a>的MobileNet-SSD神经网络运行检测示例： </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cv <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> cv.__file__ classes = [<span class="hljs-string"><span class="hljs-string">'backgroud'</span></span>, <span class="hljs-string"><span class="hljs-string">'aeroplane'</span></span>, <span class="hljs-string"><span class="hljs-string">'bicycle'</span></span>, <span class="hljs-string"><span class="hljs-string">'bird'</span></span>, <span class="hljs-string"><span class="hljs-string">'boat'</span></span>, <span class="hljs-string"><span class="hljs-string">'bottle'</span></span>, <span class="hljs-string"><span class="hljs-string">'bus'</span></span>, <span class="hljs-string"><span class="hljs-string">'car'</span></span>, <span class="hljs-string"><span class="hljs-string">'cat'</span></span>, <span class="hljs-string"><span class="hljs-string">'chair'</span></span>, <span class="hljs-string"><span class="hljs-string">'cow'</span></span>, <span class="hljs-string"><span class="hljs-string">'diningtable'</span></span>, <span class="hljs-string"><span class="hljs-string">'dog'</span></span>, <span class="hljs-string"><span class="hljs-string">'horse'</span></span>, <span class="hljs-string"><span class="hljs-string">'motorbike'</span></span>, <span class="hljs-string"><span class="hljs-string">'person'</span></span>, <span class="hljs-string"><span class="hljs-string">'pottedplant'</span></span>, <span class="hljs-string"><span class="hljs-string">'sheep'</span></span>, <span class="hljs-string"><span class="hljs-string">'sofa'</span></span>, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, <span class="hljs-string"><span class="hljs-string">'tvmonitor'</span></span>] cap = cv.VideoCapture(<span class="hljs-number"><span class="hljs-number">0</span></span>) net = cv.dnn.readNet(<span class="hljs-string"><span class="hljs-string">'MobileNetSSD_deploy.caffemodel'</span></span>, <span class="hljs-string"><span class="hljs-string">'MobileNetSSD_deploy.prototxt'</span></span>) cv.namedWindow(<span class="hljs-string"><span class="hljs-string">'Object detection'</span></span>, cv.WINDOW_NORMAL) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> cv.waitKey(<span class="hljs-number"><span class="hljs-number">1</span></span>) != <span class="hljs-number"><span class="hljs-number">27</span></span>: hasFrame, frame = cap.read() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> hasFrame: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> frame_height, frame_width = frame.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], frame.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] blob = cv.dnn.blobFromImage(frame, scalefactor=<span class="hljs-number"><span class="hljs-number">0.007843</span></span>, size=(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>), mean=(<span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>)) net.setInput(blob) out = net.forward() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detection <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> out.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>): classId = int(detection[<span class="hljs-number"><span class="hljs-number">1</span></span>]) confidence = float(detection[<span class="hljs-number"><span class="hljs-number">2</span></span>]) xmin = int(detection[<span class="hljs-number"><span class="hljs-number">3</span></span>] * frame_width) ymin = int(detection[<span class="hljs-number"><span class="hljs-number">4</span></span>] * frame_height) xmax = int(detection[<span class="hljs-number"><span class="hljs-number">5</span></span>] * frame_width) ymax = int(detection[<span class="hljs-number"><span class="hljs-number">6</span></span>] * frame_height) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> confidence &gt; <span class="hljs-number"><span class="hljs-number">0.5</span></span>: cv.rectangle(frame, (xmin, ymin), (xmax, ymax), color=(<span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>), thickness=<span class="hljs-number"><span class="hljs-number">3</span></span>) label = <span class="hljs-string"><span class="hljs-string">'%s: %.2f'</span></span> % (classes[classId], confidence) labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) ymin = max(ymin, labelSize[<span class="hljs-number"><span class="hljs-number">1</span></span>]) cv.rectangle(frame, (xmin, ymin - labelSize[<span class="hljs-number"><span class="hljs-number">1</span></span>]), (xmin + labelSize[<span class="hljs-number"><span class="hljs-number">0</span></span>], ymin + baseLine), (<span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>), cv.FILLED) cv.putText(frame, label, (xmin, ymin), cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, (<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)) cv.imshow(<span class="hljs-string"><span class="hljs-string">'Object detection'</span></span>, frame)</code> </pre> <br><p><img src="https://habrastorage.org/webt/1h/sd/0m/1hsd0mmmse6gslxx169tw4lc2wu.png"></p><br><p> 如此一来，一次完整的组装就不会超过20分钟。 我将<code>Dockerfile</code>的最终版本<code>Dockerfile</code>下面，并借此机会，我建议对曾经使用该库的人进行OpenCV团队的简短调查： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">//opencv.org/survey-2018.html</a> 。 </p><br><p> 是的，恭喜您使用OpenCV 4！ 这不仅是一个单独团队的工作，而且是整个社区的工作-OpenCV 4您。 </p><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 USER root RUN dpkg --add-architecture armhf RUN sed -i -E 's|^deb ([^ ]+) (.*)$|deb [arch=amd64] \1 \2\ndeb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ \2|' /etc/apt/sources.list RUN apt-get update &amp;&amp; \ apt-get install -y --no-install-recommends \ cmake \ pkg-config \ crossbuild-essential-armhf \ git \ python-pip \ libgtk2.0-dev:armhf \ libpython-dev:armhf \ libgstreamer1.0-dev:armhf \ libgstreamer-plugins-base1.0-dev:armhf \ libgstreamer-plugins-good1.0-dev:armhf \ libgstreamer-plugins-bad1.0-dev:armhf RUN pip install numpy==1.12.1 RUN git clone https://github.com/opencv/opencv --depth 1 RUN mkdir opencv/build &amp;&amp; cd opencv/build &amp;&amp; \ export PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig &amp;&amp; \ cmake -DCMAKE_BUILD_TYPE=Release \ -DOPENCV_CONFIG_INSTALL_PATH="cmake" \ -DCMAKE_TOOLCHAIN_FILE="../opencv/platforms/linux/arm-gnueabi.toolchain.cmake" \ -DWITH_IPP=OFF \ -DBUILD_TESTS=OFF \ -DBUILD_PERF_TESTS=OFF \ -DOPENCV_ENABLE_PKG_CONFIG=ON \ -DPYTHON2_INCLUDE_PATH="/usr/include/python2.7" \ -DPYTHON2_NUMPY_INCLUDE_DIRS="/usr/local/lib/python2.7/dist-packages/numpy/core/include" \ -DENABLE_NEON=ON \ -DCPU_BASELINE="NEON" .. &amp;&amp; make -j4 &amp;&amp; make install</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN430906/">https://habr.com/ru/post/zh-CN430906/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN430892/index.html">跨平台和本机方法在移动应用程序开发中的结合</a></li>
<li><a href="../zh-CN430894/index.html">情况：品牌在播客广告上花费越来越多的钱-我们理解为什么</a></li>
<li><a href="../zh-CN430896/index.html">Linux Foundation已为GraphQL和Ceph建立了资金-为什么需要它们，以及对它们的期望</a></li>
<li><a href="../zh-CN430900/index.html">历史上的第一台激光：那是什么</a></li>
<li><a href="../zh-CN430902/index.html">精灵在记忆中。 在Linux RAM中运行ELF</a></li>
<li><a href="../zh-CN430908/index.html">功率转换器控制模块：开发和组装</a></li>
<li><a href="../zh-CN430910/index.html">富布赖特奖学金：如何以及为什么？</a></li>
<li><a href="../zh-CN430912/index.html">我们给骗子带来干净的水：面试不是雇佣关系。 自然地</a></li>
<li><a href="../zh-CN430914/index.html">黑市价格分析的个人数据和突破</a></li>
<li><a href="../zh-CN430916/index.html">二氧化碳检测仪MT8057S。 由非仿真者参与的非审查</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
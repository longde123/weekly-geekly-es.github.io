<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’†ğŸ¿ ğŸ•º ğŸ”¶ NVidia GPU Stress Test pada Live Streaming Transcoding ğŸ§‘ğŸ½â€ğŸ¤â€ğŸ§‘ğŸ½ ğŸ¤¶ğŸ» ğŸ–¥ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Di bawah ini adalah kisah terperinci tentang bagaimana kami memuat kartu dari NVidia dengan tugas transcoding video untuk streamingnya. Mari kita tunj...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVidia GPU Stress Test pada Live Streaming Transcoding</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/401539/"> <i>Di bawah ini adalah kisah terperinci tentang bagaimana kami memuat kartu dari NVidia dengan tugas transcoding video untuk streamingnya.</i>  <i>Mari kita tunjukkan bahwa kami mencoba apa yang terjadi, dan cara terbaik menggunakan kartu video untuk streaming online.</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/files/7ef/cc6/50b/7efcc650b901459bbb5addc4fe8d6bd3.png"></div><a name="habracut"></a>  Selama beberapa tahun, tim kami telah mengembangkan produk untuk memproses dan mendistribusikan konten media online.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Artikel ini</a> baru-baru ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menjelaskan</a> mengapa pemilik konten mungkin membutuhkan solusi seperti itu di usia YouTube kami. <br><br>  Salah satu produk kami adalah server media <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Nimble Streamer</a> , yang merupakan perangkat lunak server yang mengambil streaming langsung dan file ke input dan membuatnya dapat diakses oleh sejumlah besar pemirsa, sementara secara bersamaan memungkinkannya untuk memonetisasi konten.  Ini adalah aplikasi asli yang ditulis dalam C ++ dan porting ke semua OS populer (Linux, Windows, MacOS) dan platform (x64, ARM).  Sejak awal, konsumsi sumber daya yang rendah dan produktivitas yang tinggi adalah persyaratan utama, dan kami berhasil mencapai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hasil yang baik</a> dalam hal ini. <br><br>  Tahun lalu, kami merilis Nimble Streamer add-on - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">live stream transcoder</a> .  Aplikasi ini memungkinkan Anda untuk mengambil aliran input video dan / atau audio dalam berbagai format dan melakukan berbagai konversi dengannya secara real time.  Fungsionalitas termasuk decoding (baik perangkat lunak dan perangkat keras), konversi video dan audio menggunakan filter (ukuran, overlay, dll.) Dan pengkodean (encoding) - baik perangkat lunak dan perangkat keras. <br><br>  Transcoder dikendalikan melalui layanan web WMSPanel, skrip transcoding dibuat melalui antarmuka drag-n-drop, yang memungkinkan Anda untuk melihat proses secara visual.  Berbagai skenario dapat dijalankan bersama - dengan pendekatan ini, nyaman untuk menjalankan kombinasi pengujian, memuat server dalam variasi apa pun. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dalam video ini,</a> Anda dapat melihat contoh cara kerja antarmuka. <br><br>  Penguraian setiap aliran dilakukan hanya sekali sebelum semua konversi lebih lanjut ... Ini memungkinkan Anda untuk menghemat sumber daya pada operasi pengodean yang mahal, ini akan terlihat jelas di sepanjang pengujian. <br><br>  Salah satu mekanisme konversi yang dapat digunakan dalam transcoder kami adalah decoding perangkat keras dan pengkodean video menggunakan GPU dari NVidia.  Kartu grafis generasi terbaru memungkinkan Anda mengambil beberapa tugas khas, yang menghilangkan beban dari CPU.  Transcoder kami dapat bekerja dengan perangkat keras ini, yang secara aktif digunakan oleh pelanggan kami. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/460/a36/96e/460a3696ed2e4f1e8d7491ecc4e7c2ca.png"></div><br>  Dalam proses komunikasi dengan perwakilan kantor Rusia NVidia, kami diminta untuk mencoba mengatur stress test bersama dari transcoder kami dan NVidia GPU untuk memahami apa dampak ekonomi dari tandem semacam itu akan dibandingkan dengan transcoding perangkat lunak eksklusif, tanpa akselerasi perangkat keras.  Selain itu, saya ingin memahami cara menggunakan GPU secara optimal, dan jika mungkin memberikan resep yang baik. <br><br>  Kami perlu segera mendapatkan zat besi yang sesuai dan akses ke sana, untuk siklus percobaan kami.  Kami berencana untuk bertemu beberapa minggu.  Masih mencari tempat untuk mendapatkan peralatan.  Opsi terbaik adalah menemukannya di cloud dan mendapatkan akses jarak jauh.  Setelah mencari opsi, ternyata AWS belum memiliki VM dengan GPU generasi Maxwell, dan di Azure cloud, hanya direncanakan untuk mulai menyediakannya segera. <br><br><h2>  1. Setrika dari NVidia di awan Softlayer, mengatur Nimble Streamer </h2><br>  Dengan bantuan NVidia, IBM memberi kami akses ke cloud-nya, Platform IBM Bluemix Cloud (sebelumnya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Softlayer</a> ).  Ini adalah jaringan besar pusat data modern (sekitar 50 pada saat publikasi) di seluruh dunia, terhubung oleh jaringan pribadi bersama dan menyediakan banyak pilihan layanan infrastruktur cloud.  Semua pusat data disatukan dan memungkinkan Anda untuk menyewa dari satu hingga ratusan server virtual atau fisik dari konfigurasi yang diperlukan selama beberapa jam, serta penyeimbang, sistem penyimpanan, firewall - secara umum, semua yang diperlukan untuk membangun infrastruktur TI yang andal untuk layanan IT yang digunakan. <br><br>  Kantor perwakilan Rusia dari IBM memberi kami akses penuh ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">portal swalayan</a> untuk mengelola layanan cloud dan ke konfigurasi server yang diperlukan, di mana kami dapat bekerja dengan berbagai aliran input dan pengaturan transcoder kami. <br><br><h3>  Besi </h3><br>  Pertama, kami diberi server fisik (bare-metal) dengan 128 GB RAM dan 2xGPU NVidia Tesla M60 dan pra-instal OS Ubuntu 14.04.  Semua parameter server, kata sandi, versi firmware, switching, IP khusus, status komponen perangkat keras, terlihat langsung di akun Anda, memungkinkan Anda untuk melakukan manipulasi yang diperlukan dengan perangkat sewaan, yang meminimalkan kebutuhan untuk interaksi dengan dukungan IBM.  Selama uji coba, ternyata kami tidak dapat memuat konfigurasi ini secara optimal, karena sejumlah keterbatasan dalam pembuatan konteks. <br><br>  Kami ingin mengurangi konfigurasi.  Karena kami menggunakan platform cloud, diperlukan melalui portal swalayan untuk meminta perubahan konfigurasi.  Setelah disetujui, operasi ini memakan waktu sekitar 2 jam ke jendela layanan yang disetujui.  Selama waktu ini, staf teknis di pusat data Amsterdam menghapus komponen tambahan (slot RAM dan 1xGPU) dari server yang diberikan kepada kami sebelumnya dan mengembalikannya ke operasi.  Perlu dicatat bahwa untuk pengembang opsi ini sangat mudah, karena tidak perlu berurusan dengan pengaturan perangkat keras, memperbaikinya, atau bahkan menghabiskan waktu menginstal OS.  Biarkan saya mengingatkan Anda bahwa dalam kasus ini hypervisor tidak digunakan karena kami perlu memeras sumber daya perangkat keras secara maksimal. <br><br>  Berdasarkan hasil penelitian kami, kami menetapkan konfigurasi server berikut: <br><blockquote>  Dual Intel Xeon E5-2690 v3 (2.60GHz) <br>  24 core <br>  RAM 64GB <br>  SATA 1TB <br></blockquote><br>  Kami memiliki 2 prosesor dengan 12 core masing-masing, dan berkat Hyper threading, kami mendapatkan dua kali lipat, yaitu  hampir 48 core. <br><br>  Dalam skenario dengan akselerator grafis, kartu berbasis chip GM204 - Tesla M60 digunakan: <br><blockquote>  NVIDIA Tesla M60 <br>  1xGPU: 2 x Maxwell GM204 <br>  Memori: 16GB GDDR5 <br>  Kecepatan Clock: 2,5 GHz <br>  NVIDIA CUDA Cores: 2 x 2048 <br>  Memory Bandwidth: 2 x 160GB / detik </blockquote><br>  Saya menarik perhatian Anda pada fakta bahwa tidak ada afinitas, chip tuning, overclocking, atau sihir lain yang dilakukan pada perangkat keras yang berkurang - hanya CPU dan GPU yang tidak di-overclock, dan untuk GPU hanya driver resmi yang diambil dari situs web NVidia yang digunakan.  Jika seseorang memiliki pengalaman serupa - bagikan dalam komentar. <br><br>  Jadi, kami mendapat akses.  Seorang kenalan cepat dengan antarmuka web dari panel kontrol (semuanya sederhana dan jelas di sana), kemudian akses ke server melalui SSH - dan di sini kita berada di baris perintah Ubuntu yang biasa, letakkan Nimble Streamer, daftarkan lisensi transcoder baru dan lakukan sedikit pengaturan konfigurasi. <br><br><h3>  Transcoder streamer gesit </h3><br>  Nimble Streamer dikonfigurasikan untuk pra-membuat cache konteks GPU.  Ini disebabkan oleh kenyataan bahwa GPU memiliki batasan jumlah maksimum dari konteks decoding dan encoding yang dibuat, dan di samping itu, menciptakan konteks dengan cepat dapat memakan waktu terlalu banyak. <br>  Rincian lebih lanjut tentang masalah membuat konteks dapat ditemukan di bagian yang sesuai di bawah ini. <br><br>  Pengaturan gesit pada contoh serangkaian tes pertama: <br><blockquote>  nvenc_context_cache_enable = true <br>  nvenc_context_create_lock = true <br>  nvenc_context_cache_init = 0: 30: 15.1: 30: 15 <br>  nvenc_context_reuse_enable = true </blockquote><br>  Rincian lebih lanjut tentang pengaturan ini ditulis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dalam artikel kami</a> . <br><br>  Sebelum memulai setiap rangkaian tes, cache dikonfigurasikan secara terpisah, dengan mempertimbangkan spesifikasi setiap tugas. <br><br><h3>  Buat Skrip Transkode </h3><br>  Pekerjaan lebih lanjut berlangsung di layanan WMSPanel kami, di mana skrip transcoder dikonfigurasi. <br><br>  Seperti yang telah disebutkan, pekerjaan berjalan melalui antarmuka web, semuanya sangat jelas dan nyaman.  Kami menciptakan sejumlah skenario yang menggabungkan berbagai opsi transcoding (CPU / GPU), opsi resolusi yang berbeda, dan parameter enkode yang berbeda (CPU / GPU, profil, bit rate, dll.) <br><br>  Set skenario dapat dijalankan secara bersamaan, yang memungkinkan untuk memperkenalkan berbagai kombinasi pengujian, menambah beban dalam urutan yang berbeda, dan mengubahnya tergantung pada situasinya.  Cukup pilih skenario yang diperlukan dan hentikan atau lanjutkan. <br><br>  Berikut adalah sejumlah skenario: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/cd6/197/b77/cd6197b77e6b4c0697f43f8d1cfaaf07.png"></div><br>  Berikut ini adalah contoh dari salah satu skenario: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e47/1ff/924/e471ff9244f240edb2c092f42d5cf721.png"></div><br>  Dekoder GPU terlihat seperti ini: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/382/0f8/2fd/3820f82fd74e4e0ea106534962e1ba28.png"></div><br>  Kami menerapkan filter ukuran gambar: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9d3/bd0/eab/9d3bd0eab2ac47d4b3183aca91db0d6f.png"></div><br>  Dan inilah encoder untuk varian GPU: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/212/d34/e2e/212d34e2e3cf425a9f94d03194f7c62d.png"></div><br><br>  Secara umum, pengoperasian antarmuka transcoder dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dilihat di video-video ini</a> . <br><br><h2>  2. Transcoding stream FullHD 1080p </h2><br>  Untuk mulai dengan, kami menguji skenario dengan beban tertinggi untuk mengetahui batas kemampuan besi.  Saat ini, resolusi terberat yang digunakan dalam praktek adalah FullHD 1080p. <br><br>  Untuk menghasilkan streaming langsung asli, file diambil dalam <b>FullHD</b> (1920 * 1080) di <b>profil tinggi H.264</b> .  Konten itu sendiri adalah tur video kota, mis.  Ini adalah video dengan tingkat perubahan gambar rata-rata.  Tidak ada bingkai warna tunggal statis yang dapat memfasilitasi pekerjaan transcoder, tetapi tidak ada perubahan jenis dan warna yang terlalu cepat.  Dalam satu kata - memuat yang cukup tipikal. <br><br>  <b>36 stream identik</b> diumpankan ke input Nimble Streamer, yang kemudian digunakan dalam transcoder dalam berbagai skenario. <br><br>  Skenario transcoding digunakan khas - aliran masuk adalah profil tinggi <b>1080p</b> , <b>720p, 480p, profil utama 360p</b> dibuat darinya <b>,</b> dan kemudian aliran <b>profil dasar: 240p, 160p</b> .  Secara total, ada 1 stream di input dan 5. di output. Biasanya, pass-through (transfer tanpa perubahan) dari stream asli juga dilakukan sehingga pemirsa dapat memilih 1080p itu sendiri ketika melihat.  Kami tidak menambahkannya di skrip, karena  tidak menggunakan transcoding - ada transfer data langsung dari input ke output.  Skenario ini dioptimalkan dalam Nimble dan dalam kondisi nyata akan meningkatkan konsumsi memori yang relatif sedikit. <br>  Audio dalam aliran yang dihasilkan - tidak.  Menambahkan audio ke skrip tidak akan menyebabkan beban CPU yang signifikan, tetapi untuk kemurnian percobaan, kami mengecualikan suara. <br><br><h3>  Tes CPU, tidak ada GPU </h3><br>  Untuk memulai, kami meluncurkan skrip transkode tanpa menggunakan GPU, menentukan decoder dan encoder perangkat lunak dalam skrip. <br><br>  Akibatnya, hanya mungkin memproses 16 arus input dengan penerbitan 80 aliran semua izin keluar. <br><br>  Beban CPU - 4600%, mis.  46 core terlibat.  Konsumsi RAM - sekitar 15GB. <br><br><h3>  Tes CPU + GPU </h3><br>  Tembolok konteks pada saat startup dikonfigurasikan sebagai 0: 30: 15.1: 30: 15 - mis.  30 konteks untuk encoding, 15 untuk decoding, masing-masing GPU. <br><br>  Izinkan saya mengingatkan Anda bahwa pada GPU kami memiliki dua core, yang memungkinkan kami untuk melakukan paralelisasi tugas - ini berguna bagi kami. <br><br>  Beban maksimum diperoleh dengan konfigurasi aliran berikut. <br><br>  Input decoder, GPU0 dan GPU1 - 15 stream.  Jadi kita mendapatkan 30 stream yang diterjemahkan, siap untuk digunakan lebih lanjut.  Setiap aliran diterjemahkan hanya sekali, tidak peduli berapa banyak skenario yang digunakan di masa depan. <br><br>  Encoder GPU0 dan GPU1 diberi makan masing-masing 15 aliran untuk mendapatkan 720p, mis.  30 aliran 720p saat keluar ternyata. <br><br>  Juga, encoders GPU0 dan GPU1 masing-masing menyediakan 15 stream untuk 480p - dan 30 stream 480p juga merupakan output. <br><br>  Karena konteks encoder telah habis, pengkodean dari izin yang tersisa ditetapkan pada CPU.  Ternyata yang berikut ini: <br><br><ol><li>  30 stream 360p </li><li>  30 stream 240p </li><li>  30 stream 160p </li></ol><br>  Bebannya ternyata 2600% CPU, 75% decoder, 32% encoder.  Selanjutnya, CPU dimuat dengan 6 stream untuk decoding, untuk masing-masing 5 resolusi yang sama dikonfigurasi, untuk total 30 utas per output. <br><br>  Secara total, <b>36 stream</b> diterima <b>pada input, 180 dikeluarkan pada output</b> .  Beban final ditetapkan sebagai berikut: <b>4400% CPU, decoder kartu 75%, encoder kartu 32%, RAM 30GB</b> . <br><br><h3>  Beberapa detail </h3><br>  Kami memutuskan untuk memeriksa opsi di mana kami memproses tugas-tugas paling sulit pada GPU - decoding 1080 dan encoding 720 dan 480, dan biarkan sisanya diproses melalui CPU. <br><br>  Pertama, kami memeriksa batas dekoder.  Dengan 22 utas, decoding dipengaruhi oleh masalah dengan konteks, mereka tidak bisa dibuat.  Berkurang 21 - konteks diciptakan, tetapi beban menjadi 100% dan artefak mulai diamati di sungai.  Kami berhenti di 20 aliran - kami melakukan decoding dari 20 aliran, penyandian pada 160p - semuanya berfungsi dengan baik. <br><br>  Selain itu, ternyata secara empiris bahwa kartu ini dengan RAM 16GB on board dengan percaya diri dapat bekerja dengan 47 konteks - dan tidak ada perbedaan, ini adalah konteks encoder atau decoder.  Saya ulangi - ini khusus tentang Tesla M60 GPU ini, pada kartu lain nomor ini mungkin berbeda.  Kami percaya bahwa jika kartu memiliki RAM 24GB, jumlah konteks bisa berbeda, tetapi ini perlu diuji. <br><br>  Sebagai hasilnya, kami memilih formula pembuatan cache "15 konteks decoder dan 30 konteks encoder" - yang memberikan 30 stream ke input dan untuk masing-masing memungkinkan Anda membuat 2 izin.  Jadi resolusi atas - 720 dan 480 - diluncurkan pada GPU, dan sisanya - 360, 240 dan 160 - dikirim ke CPU.  Dan karena CPU masih bebas setelah itu, kami â€œmenyelesaikanâ€ core gratis dengan utas baru, meninggalkan 4 core untuk tugas utilitarian. <br><br><h2>  3. Transcoding stream HD 720p </h2><br>  Skenario pemuatan tipikal  Sebagian besar konten sekarang dibuat dalam HD.  Bahkan SuperBowl LI baru-baru ini - acara dengan rating tertinggi di pasar AS - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">disiarkan dalam HD</a> , meninggalkan FullHD untuk masa depan. <br><br>  Untuk menghasilkan stream sumber, file diambil dalam <b>HD</b> (1280 * 720) dalam <b>profil tinggi</b> .  Konten adalah seri "The Good Wife" favorit insinyur kami, yaitu  Ini adalah video dengan tingkat perubahan gambar rata-rata. <br><br>  Di pintu masuk ke Streamer Nimble, 70 aliran identik diumpankan, yang kemudian digunakan dalam transcoder dalam skenario yang berbeda. <br><br>  Skenario transcoding berikut digunakan - aliran masuk adalah profil tinggi <b>720p</b> , <b>480p, profil utama 360p</b> dan kemudian <b>240p,</b> aliran profil <b>dasar 160p</b> dibuat darinya.  Total, pada input 1, pada output 4. Pass-through dari aliran asli, seperti dalam skenario sebelumnya, tidak dilakukan.  Audio dalam aliran yang dihasilkan juga tidak. <br><br><h3>  Tes CPU, tidak ada GPU </h3><br>  Seperti pada bagian sebelumnya, kami mencoba transcoding stream hanya di CPU.  Akibatnya, hanya dimungkinkan untuk memproses 22 arus input dengan penerbitan 88 aliran semua izin keluar.  Beban CPU - 4700%, mis.  47 core terlibat.  Konsumsi RAM - sekitar 20GB. <br><br><h3>  Tes CPU + GPU </h3><br>  Cache konteks saat startup dikonfigurasikan sebagai 0: 23: 23.1: 23: 23 - yaitu.  23 konteks untuk encoding, 23 untuk decoding untuk setiap GPU. <br><br>  Menggunakan GPU, 46 720p stream diterjemahkan.  Di sana, pada GPU, 46 aliran 480p dikodekan.  Selanjutnya, pengkodean 360p, 240p dan 160p dilakukan pada CPU - masing-masing 46 stream. <br>  Memperbaiki beban 2100% CPU, 61% dari decoder, 16% dari encoder. <br><br>  Selain itu, encoding dan decoding dari 24 utas ke CPU diluncurkan, untuk setiap 1 utas - 4 output, seperti untuk GPU. <br><br>  Secara keseluruhan, <b>70 stream adalah input, 280 stream adalah output</b> . <br>  Beban: <b>4600%, 61% dari decoder, 16% dari encoder, 30GB RAM</b> . <br><br>  Adapun tes sebelumnya, mungkin GPU RAM yang lebih besar akan memberikan lebih banyak konteks dan kami bisa menangani lebih banyak utas.  Tapi ini hanya secara teori, perlu diperiksa. <br><br><h2>  4. Masalah dengan membuat konteks dalam NVidia GPU </h2><br>  Beberapa kata tentang masalah yang tidak memungkinkan kami memproses lebih banyak utas pada GPU. <br><br>  Pada akhir tahun lalu, kami melakukan tes dengan tim NVidia, dengan beberapa kartu.  Ketika bekerja dengan banyak GPU, ternyata menciptakan konteks sangat memperlambat server - membuat setiap konteks baru membutuhkan lebih banyak waktu dari peta.  Jika konteks pertama dibuat pada urutan 300ms, maka masing-masing berikutnya menambahkan 200-300ms dan sudah dalam sepuluh konteks ketiga, membuat yang baru membutuhkan 3-4 detik masing-masing.  Ketika seorang pengguna membuat skrip transkoding, diasumsikan bahwa ia mulai bekerja segera dan tanpa penundaan, dan keadaan baru ini meniadakan semua keuntungan dalam kecepatan Nimbl dan memberikan penundaan dalam menciptakan konteks yang menyebabkan keterlambatan dalam memulai pengkodean. <br><br>  Pada awalnya, kecurigaan jatuh pada Nimble, tetapi kemudian kami melakukan tes menggunakan ffmpeg, yang NVidia sendiri berikan kepada pelanggan dan hasilnya ternyata persis sama - GPU menghabiskan lebih banyak waktu menciptakan setiap konteks baru.  Dalam kondisi ketika server sudah melakukan transcoding dan Anda perlu memulai utas baru untuk diproses, ini memengaruhi kinerja keseluruhan dan membuat server tidak bisa digunakan. <br><br>  Masalahnya dijelaskan secara rinci oleh tim NVidia, tetapi sejauh ini tidak ada solusi penuh yang telah disediakan.  Oleh karena itu, kami sejauh ini menerapkan mekanisme caching konteks di server kami, dengan pembuatan konteks awal di server dimulai.  Ini menyelesaikan masalah dari sudut pandang pekerjaan pengguna akhir, tetapi awal dari Nimbl mungkin memerlukan waktu.  Menyiapkan Nimbl untuk pekerjaan yang efektif dengan konteks <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dijelaskan di blog kami</a> . <br><br>  Selain itu, konteksnya tidak mudah dibuat.  Dengan sejumlah besar konteks ketika menyertakan skrip transkoding, API NVENC mulai membuat kesalahan: "Panggilan API gagal karena tidak dapat mengalokasikan cukup memori untuk melakukan operasi yang diminta." <br><br>  Secara empiris, ternyata satu GPU dapat memulai dan bekerja dengan penuh percaya diri dengan 47 konteks - dan tidak ada perbedaan, ini adalah konteks encoder atau decoder.  Ada asumsi bahwa ini disebabkan oleh jumlah memori pada GPU.  Sekarang ada 16 GB, jika Anda meletakkan kartu dengan 24 GB, ada kemungkinan lebih banyak konteks dapat dilakukan.  Tapi ini hanya teori, perlu diperiksa, seperti yang disebutkan sebelumnya.  Data yang diperoleh valid untuk model GPU tertentu, kartu lain harus diuji secara terpisah. <br><br>  Ini adalah pembatasan jumlah konteks yang menempatkan kendala utama saat bekerja dengan beban besar. <br><br><h2>  5. Kesimpulan </h2><br>  Jadi, tujuan pengujian adalah untuk mempelajari efektivitas GPU untuk berbagai tugas yang ditunjukkan dan untuk mengembangkan resep untuk penggunaan yang tepat.  Apa hasilnya? <br><br><h3>  Efek ekonomi </h3><br>  Di atas, kami melihat bagaimana jumlah utas yang dapat diproses pada CPU dan pada tandem CPU + GPU berbeda.  Mari kita lihat apa artinya ini dalam hal uang.  Sebagai dasar kami mengambil semua Softlayer yang sama dan harga sewa peralatan mereka. <br><br><ul><li>  Konfigurasi tanpa GPU akan dikenakan biaya <b>$ 819 per bulan</b> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Di sini Anda dapat mengambil</a> mobil. </li><li>  Konfigurasi dengan GPU akan dikenakan biaya <b>$ 1729 per bulan</b> untuk pusat data di Amsterdam, harga dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ditemukan di sini</a> .  Saat menggunakan GPU, harga sewa server sedikit meningkat, karena faktor bentuk 2U yang lebih besar digunakan.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Efek ekonomi mungkin akan lebih tinggi ketika membeli peralatan (tetapi ini membutuhkan analisis serius dari TCO, dengan mempertimbangkan pembaruan terus-menerus dari garis NVidia GPU). </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekarang mari kita lihat hasil tes: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk FullHD 1080p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU tanpa GPU: 16 utas per input + 80 utas per output </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 36 utas per input + 180 per output </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Manfaat GPU: 2.25x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keuntungan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> menggunakan GPU: $ 819 * 2,25 - $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 113 per bulan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> saat menyewa 1 server dengan GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk HD 720p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU tanpa GPU: 22 utas per input + 88 utas per output </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 70 utas per input + 280 per output </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Manfaat GPU: 3.18x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keuntungan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> menggunakan GPU: $ 819 * 3,18 - $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">$ 875 per bulan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> saat menyewa 1 server dengan GPU </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artinya, dengan opsi sewa, penghematannya cukup mencolok. Ini tidak memperhitungkan diskon akun - di kantor Rusia IBM, mereka menjanjikan diskon untuk menyewa sumber daya di cloud dibandingkan dengan harga yang disajikan di sini. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami tidak masuk ke opsi dengan pembelian, karena di sini TCO sangat tergantung pada pilihan pemasok, biaya layanan di pusat data dan faktor-faktor lain yang akrab bagi mereka yang bekerja dengan logam telanjang. Namun, angka awal juga berbicara mendukung solusi berbasis GPU.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Juga, jangan lupa tentang lalu lintas dan lebar saluran - mereka termasuk dalam jumlah tertentu dalam tarif yang disajikan di atas, tetapi Anda harus memilih opsi untuk tugas Anda berdasarkan jumlah utas, jumlah pengguna yang diharapkan, dll. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Scaling </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Opsi dengan satu kartu grafis per server bagi kami tampaknya lebih hemat biaya daripada opsi dengan dua kartu atau lebih. Seperti yang dapat kita lihat, dekoder GPU selalu memuat lebih dari encoder, tetapi bahkan tetap kurang karena masalah dengan penggunaan konteks. Jika Anda menambahkan kartu kedua, decoder akan digunakan lebih sedikit lagi, pembuat enkode kami tidak akan dapat memuat dengan kapasitas penuh, dan semua pekerjaan pada pengkodean masih harus dialihkan ke CPU, yang akan dibenarkan untuk uang. Kami juga menguji opsi dengan dua GPU berkat dukungan Softlayer, tetapi karena efek ekonomi yang lemah, kami tidak memberikan detail dalam artikel. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dengan demikian, untuk menskalakan beban, lebih baik menambahkan server baru dengan satu kartu grafis daripada menambahkan kartu ke mesin yang ada.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jika jumlah aliran masuk dan keluar untuk proyek Anda relatif kecil - katakanlah, selusin aliran HD dengan sejumlah kecil izin keluaran, dengan sejumlah kecil penyaringan, maka akan lebih bijaksana untuk menggunakan server tanpa GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perlu juga dicatat bahwa jumlah RAM untuk tugas mengubah utas tidak sepenting kekuatan pemrosesan. Jadi dalam beberapa kasus, Anda juga dapat menghemat dengan mengurangi jumlah memori.</font></font><br><br><h3>  Kesimpulan </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Solusi perangkat keras yang disajikan - kombinasi dari Tesla M60 CPU dan GPU - sempurna untuk transcoding streaming langsung di bawah beban yang berat. </font><font style="vertical-align: inherit;">GPU menangani operasi yang paling intensif sumber daya - mendekode stream dan mengkodekannya ke dalam resolusi tertinggi, sementara resolusi menengah dan kecil diproses dengan baik pada CPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jika salah satu pembaca memiliki pengalaman dan mengoptimalkan kinerja kartu grafis untuk siaran langsung, kami akan senang berkenalan dengan pengalaman Anda - tulis di komentar.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id401539/">https://habr.com/ru/post/id401539/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id401527/index.html">Bagaimana drive optik menurun</a></li>
<li><a href="../id401529/index.html">Tanya Ethan: Bisakah Semesta Dianggap Hidup?</a></li>
<li><a href="../id401531/index.html">Dalam kerangka proyek "Sains bukan tepung", sebuah diskusi akan diadakan pada topik: "Seks, narkoba, rock and roll: kecanduan atau kehidupan?"</a></li>
<li><a href="../id401533/index.html">Kesulitan dalam memilih kartu video anggaran pada contoh RX 460</a></li>
<li><a href="../id401535/index.html">Koloni. Bab 4: pangkalan militer lama</a></li>
<li><a href="../id401541/index.html">50 nuansa tunggul * Penerimaan perangkat keras dari sinyal yang dikodekan PWM oleh mikrokontroler Microchip</a></li>
<li><a href="../id401543/index.html">Menggunakan dataset dari portal data terbuka Rusia data.gov.ru</a></li>
<li><a href="../id401545/index.html">Chef, aku melihatmu. Intel Unite - Alat Komunikasi Profesional</a></li>
<li><a href="../id401549/index.html">Keadaan eksotis materi, LCD dan masa depan air</a></li>
<li><a href="../id401551/index.html">Valve mengembangkan tiga game VR secara bersamaan dan berharap untuk pengembangan teknologi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õπüèº üëÇüèª üåÆ Datenextraktion beim maschinellen Lernen üë¨ ü§Ωüèª üßúüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="M√∂chten Sie drei Data Mining-Methoden f√ºr Ihr n√§chstes ML-Projekt kennenlernen? Dann lesen Sie die √úbersetzung des Rebecca Vickery-Artikels, der im To...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Datenextraktion beim maschinellen Lernen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/plarium/blog/460675/">  M√∂chten Sie drei Data Mining-Methoden f√ºr Ihr n√§chstes ML-Projekt kennenlernen?  Dann lesen Sie die √úbersetzung des Rebecca Vickery-Artikels, der im Towards Data Science-Blog auf Medium ver√∂ffentlicht wurde!  Sie wird f√ºr Anf√§nger interessant sein. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/ce/h3/baceh3syebhbwo_3rvemwpfl8l8.jpeg"></div><br>  Das Abrufen von Qualit√§tsdaten ist der erste und wichtigste Schritt in jedem maschinellen Lernprojekt.  Data Science-Spezialisten verwenden h√§ufig verschiedene Methoden, um Datens√§tze zu erhalten.  Sie k√∂nnen √∂ffentlich verf√ºgbare Daten sowie Daten verwenden, die √ºber die API verf√ºgbar sind oder aus verschiedenen Datenbanken stammen, kombinieren diese Methoden jedoch meistens. <br><br>  Der Zweck dieses Artikels besteht darin, einen kurzen √úberblick √ºber drei verschiedene Methoden zum Abrufen von Daten mit Python zu geben.  Ich werde Ihnen sagen, wie das mit dem Jupyter Notebook geht.  In meinem vorherigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel habe</a> ich √ºber die Anwendung einiger Befehle geschrieben, die im Terminal ausgef√ºhrt werden. <a name="habracut"></a><br><br><h3>  SQL </h3><br>  Wenn Sie Daten aus einer relationalen Datenbank abrufen m√ºssen, arbeiten Sie h√∂chstwahrscheinlich mit der SQL-Sprache.  Mit der SQLAlchemy-Bibliothek k√∂nnen Sie Ihren Laptop-Code den g√§ngigsten Datenbanktypen zuordnen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier</a> finden Sie Informationen dar√ºber, welche Datenbanken unterst√ºtzt werden und wie Sie an jeden Typ binden k√∂nnen. <br><br>  Mit der SQLAlchemy-Bibliothek k√∂nnen Sie Tabellen durchsuchen und Daten abfragen oder Rohabfragen schreiben.  Zum Binden an die Datenbank ben√∂tigen Sie eine URL mit Ihren Anmeldeinformationen.  Als N√§chstes m√ºssen Sie die Methode <code>create_engine</code> initialisieren, um die Verbindung herzustellen. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_engine engine = create_engine(<span class="hljs-string"><span class="hljs-string">'dialect+driver://username:password@host:port/database'</span></span>)</code> </pre> <br>  Jetzt k√∂nnen Sie Datenbankabfragen schreiben und Ergebnisse erhalten. <br><br><pre> <code class="python hljs">connection = engine.connect() result = connection.execute(<span class="hljs-string"><span class="hljs-string">"select * from my_table"</span></span>)</code> </pre> <br><h3>  Schaben </h3><br>  Web Scraping wird verwendet, um Daten von Websites herunterzuladen und die erforderlichen Informationen von deren Seiten zu extrahieren.  Daf√ºr stehen viele Python-Bibliotheken zur Verf√ºgung, aber die einfachste ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beautiful Soup</a> . <br><br>  Sie k√∂nnen das Paket √ºber pip installieren. <br><br><pre> <code class="python hljs">pip install BeautifulSoup4</code> </pre> <br>  Schauen wir uns ein einfaches Beispiel f√ºr die Verwendung an.  Wir werden Beautiful Soup und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Urllib-</a> Bibliothek verwenden, um Hotelnamen und Preise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TripAdvisor</a> zu kratzen. <br><br>  Zuerst importieren wir alle Bibliotheken, mit denen wir arbeiten werden. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib.request</code> </pre> <br>  Laden Sie nun den Inhalt der Seite, die wir verschrotten werden.  Ich m√∂chte Daten zu Preisen f√ºr Hotels auf der griechischen Insel Kreta sammeln und die URL-Adresse mit einer Liste der Hotels an diesem Ort verwenden. <br><br><img src="https://habrastorage.org/webt/vt/jj/7i/vtjj7icfxauctiw_juiik0oqgfo.png"><br><br>  Der folgende Code definiert die URL als Variable und verwendet die urllib-Bibliothek zum √ñffnen der Seite und die Beautiful Soup-Bibliothek zum Lesen und Zur√ºckgeben der Ergebnisse in einem einfachen Format.  Ein Teil der Ausgabedaten wird unter dem Code angezeigt. <br><br><pre> <code class="python hljs">URL = <span class="hljs-string"><span class="hljs-string">'https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html'</span></span> page = urllib.request.urlopen(URL) soup = BeautifulSoup(page, <span class="hljs-string"><span class="hljs-string">'html.parser'</span></span>) print(soup.prettify())</code> </pre> <br><img src="https://habrastorage.org/webt/ul/n3/sn/uln3sn1bwjzjeft182k2dgbp7qo.png"><br><br>  Lassen Sie uns nun eine Liste mit den Namen der Hotels auf der Seite erhalten.  Wir werden die Funktion <code>find_all</code> , mit der Teile des f√ºr uns interessanten Dokuments extrahiert werden.  Sie k√∂nnen es mit der Funktion <code>find_all</code> unterschiedlich <code>find_all</code> , um eine einzelne Zeile, einen regul√§ren Ausdruck oder eine Liste zu √ºbergeben.  Sie k√∂nnen auch eines der Tag-Attribute herausfiltern - genau diese Methode werden wir anwenden.  Wenn Sie mit HTML-Tags und -Attributen noch nicht vertraut sind, finden Sie in diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> eine kurze √úbersicht. <br><br>  Um zu verstehen, wie der Zugriff auf die Daten im Tag am besten bereitgestellt werden kann, m√ºssen Sie den Code f√ºr dieses Element auf der Seite √ºberpr√ºfen.  Wir finden den Code f√ºr den Hotelnamen, indem wir mit der rechten Maustaste auf den Namen in der Liste klicken, wie in der folgenden Abbildung gezeigt. <br><br><img src="https://habrastorage.org/webt/uh/k5/zs/uhk5zsci0kajsubpkghjff3qnye.png"><br><br>  Nach dem Klicken auf <code>inspect</code> Elementcode angezeigt und der Abschnitt mit dem Namen des Hotels wird hervorgehoben. <br><br><img src="https://habrastorage.org/webt/pc/fh/ms/pcfhmsrk8knqsjzr2lzsif2d2j4.png"><br><br>  Wir sehen, dass der Name des Hotels der einzige Text in der Klasse mit dem Namen <code>listing_title</code> .  Nach der Klasse kommen der Code und der Name dieses Attributs zur Funktion <code>find_all</code> sowie zum Tag <code>div</code> . <br><br><pre> <code class="python hljs">content_name = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'listing_title'</span></span>}) print(content_name)</code> </pre> <br>  Jeder Abschnitt des Codes mit dem Namen des Hotels wird als Liste zur√ºckgegeben. <br><br><img src="https://habrastorage.org/webt/gi/u2/b1/giu2b1wmq7holjcoeyfqohasg6u.png"><br><br>  Um Hotelnamen aus dem Code zu extrahieren, verwenden wir die Funktion <code>getText</code> der Beautiful Soup-Bibliothek. <br><br><pre> <code class="python hljs">content_name_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_name: content_name_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_name_list)</code> </pre> <br>  Hotelnamen werden als Liste zur√ºckgegeben. <br><br><img src="https://habrastorage.org/webt/z0/bc/t-/z0bct-wezpzc8exsahj_fywmjnq.png"><br><br>  Ebenso erhalten wir Preisdaten.  Die Codestruktur f√ºr den Preis ist unten gezeigt. <br><br><img src="https://habrastorage.org/webt/v0/ok/oy/v0okoymlgmsbc6dtxicxwa_yz38.png"><br><br>  Wie Sie sehen, k√∂nnen wir mit einem Code arbeiten, der dem f√ºr Hotels verwendeten sehr √§hnlich ist. <br><br><pre> <code class="python hljs">content_price = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'price-wrap'</span></span>}) print(content_price)</code> </pre><br>  Im Falle des Preises gibt es wenig Schwierigkeiten.  Sie k√∂nnen es sehen, indem Sie den folgenden Code ausf√ºhren: <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: content_price_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_price_list)</code> </pre> <br>  Das Ergebnis ist unten dargestellt.  Wenn in der Liste der Hotels zus√§tzlich zu einem Text eine Preissenkung angegeben ist, werden sowohl der Anfangspreis als auch der Endpreis zur√ºckgegeben.  Um dieses Problem zu beheben, geben wir einfach den aktuellen Preis f√ºr heute zur√ºck. <br><br><img src="https://habrastorage.org/webt/52/6j/mn/526jmnbmxhchiyee4jr3feptxom.png"><br><br>  Wir k√∂nnen eine einfache Logik verwenden, um den neuesten im Text angegebenen Preis zu erhalten. <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: a_split = a.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(a_split) &gt; <span class="hljs-number"><span class="hljs-number">5</span></span>: content_price_list.append(a_split[<span class="hljs-number"><span class="hljs-number">-4</span></span>:]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: content_price_list.append(a_split) print(content_price_list)</code> </pre> <br>  Dies ergibt folgendes Ergebnis: <br><br><img src="https://habrastorage.org/webt/kx/d0/sn/kxd0snvrauaecf_q4lvpjdu8-z0.png"><br><br><h3>  API </h3><br>  API - Anwendungsprogrammierschnittstelle (von der englischen Anwendungsprogrammierschnittstelle).  Aus Sicht des Data Mining handelt es sich um ein webbasiertes System, das einen Datenendpunkt bereitstellt, mit dem Sie √ºber die Programmierung Kontakt aufnehmen k√∂nnen.  Normalerweise werden Daten im JSON- oder XML-Format zur√ºckgegeben. <br><br>  Diese Methode wird sich wahrscheinlich beim maschinellen Lernen als n√ºtzlich erweisen.  Ich werde ein einfaches Beispiel f√ºr das Abrufen von Wetterdaten von der √∂ffentlichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dark Sky-</a> API geben.  Um eine Verbindung herzustellen, m√ºssen Sie sich registrieren und haben 1000 kostenlose Anrufe pro Tag.  Dies sollte zum Testen ausreichen. <br><br>  Um auf Daten von Dark Sky zuzugreifen, verwende ich die <code>requests</code> .  Zun√§chst muss ich die richtige URL f√ºr die Anfrage erhalten.  Zus√§tzlich zur Vorhersage liefert Dark Sky historische Wetterdaten.  In diesem Beispiel nehme ich sie und erhalte die richtige URL aus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . <br><br>  Die Struktur dieser URL lautet: <br><br><pre> <code class="python hljs">https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]</code> </pre> <br>  Wir werden die <code>requests</code> verwenden, um zu erhalten <br>  Ergebnisse f√ºr einen bestimmten Breiten- und L√§ngengrad sowie Datum und Uhrzeit.  Stellen Sie sich vor, wir haben nach dem Extrahieren der t√§glichen Preisdaten f√ºr Hotels auf Kreta beschlossen, herauszufinden, ob die Preispolitik mit dem Wetter zusammenh√§ngt. <br><br>  Nehmen wir zum Beispiel die Koordinaten eines der Hotels auf der Liste - Mitsis Laguna Resort &amp; Spa. <br><br><img src="https://habrastorage.org/webt/1j/4a/is/1j4aissalsvek5uw2opv3v9hdhw.png"><br><br>  Erstellen Sie zun√§chst eine URL mit den richtigen Koordinaten sowie der gew√ºnschten Uhrzeit und dem gew√ºnschten Datum.  √úber die <code>requests</code> wir Zugriff auf Daten im JSON-Format. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests request_url = <span class="hljs-string"><span class="hljs-string">'https://api.darksky.net/forecast/fd82a22de40c6dca7d1ae392ad83eeb3/35.3378,-25.3741,2019-07-01T12:00:00'</span></span> result = requests.get(request_url).json() result</code> </pre><br>  Um das Lesen und Analysieren der Ergebnisse zu vereinfachen, k√∂nnen wir die Daten in einen Datenrahmen konvertieren. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd df = pd.DataFrame.from_dict(json_normalize(result), orient=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/jw/1w/sv/jw1wsv_9ixycnrfu44l7qhloxb4.png"><br><br>  Es gibt viele weitere Optionen zur Automatisierung der Datenextraktion mit diesen Methoden.  Beim Web-Scraping k√∂nnen Sie verschiedene Funktionen schreiben, um den Prozess zu automatisieren und das Extrahieren von Daten f√ºr mehr Tage und / oder Orte zu vereinfachen.  In diesem Artikel wollte ich gen√ºgend Codebeispiele √ºberpr√ºfen und bereitstellen.  Die folgenden Materialien werden detaillierter beschrieben: Ich werde Ihnen erkl√§ren, wie Sie gro√üe Datens√§tze erstellen und mit den oben beschriebenen Methoden analysieren. <br><br>  Danke f√ºr die Aufmerksamkeit! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460675/">https://habr.com/ru/post/de460675/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460665/index.html">Entwurf einer FAQ: Warum erscheinen alle drei Jahre C ++ - Standards?</a></li>
<li><a href="../de460667/index.html">Automatisierung des Testens kostenpflichtiger Dienste unter iOS</a></li>
<li><a href="../de460669/index.html">So gew√§hrleisten Sie die Sicherheit der Entwicklung, sparen Zeit und Nerven</a></li>
<li><a href="../de460671/index.html">Eigentum und Ausleihe in D.</a></li>
<li><a href="../de460673/index.html">Enth√ºlle die Magie von DiffUtil</a></li>
<li><a href="../de460683/index.html">Laravel Event Projector und Event Generation Concept</a></li>
<li><a href="../de460685/index.html">Wir verteilen Dateien von Google Drive mit nginx</a></li>
<li><a href="../de460687/index.html">Wie Dosen von innen aussehen</a></li>
<li><a href="../de460695/index.html">Was ist DAA und wie hilft dieses System Drohnen?</a></li>
<li><a href="../de460697/index.html">Kleinstm√∂gliche Schriftart</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
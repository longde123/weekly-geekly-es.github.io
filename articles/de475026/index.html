<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöì üë©üèø‚Äçüî¨ ‚öóÔ∏è 3 Kubernetes-Absturzgeschichten in der Produktion: Anti-Affinit√§t, anmutiges Herunterfahren, Webhook ü§∏üèø üôéüèæ üòõ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Wir pr√§sentieren eine kleine Auswahl von Post-Mortem-Projekten zu den schwerwiegenden Problemen, mit denen Ingenieure verschiedener U...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>3 Kubernetes-Absturzgeschichten in der Produktion: Anti-Affinit√§t, anmutiges Herunterfahren, Webhook</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/475026/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/y7/_c/ra/y7_cracjhm0ke_mtazml1fhzprk.jpeg"></div><br>  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Wir pr√§sentieren eine kleine Auswahl von Post-Mortem-Projekten zu den schwerwiegenden Problemen, mit denen Ingenieure verschiedener Unternehmen beim Betrieb der auf Kubernetes basierenden Infrastruktur konfrontiert waren.</i>  <i>In jeder Notiz geht es um das Problem selbst, seine Ursachen und Folgen und nat√ºrlich um eine L√∂sung, mit der √§hnliche Situationen in Zukunft vermieden werden k√∂nnen.</i> <i><br><br></i>  <i>Wie Sie wissen, ist es g√ºnstiger, aus den Erfahrungen anderer zu lernen. Lassen Sie sich daher mit diesen Geschichten auf m√∂gliche √úberraschungen vorbereiten.</i>  <i>√úbrigens wird auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser Site</a> eine gro√üe und regelm√§√üig aktualisierte Auswahl an Links zu solchen ‚ÄûFehlergeschichten‚Äú ver√∂ffentlicht (gem√§√ü Daten aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Git-Repository</a> ).</i> <a name="habracut"></a><br><br><h2>  Nr. 1.  Wie die Kernel-Panik eine Site zum Absturz brachte </h2><br>  <i>Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mondschein</a> .</i> <br><br>  Zwischen dem 18. und 22. Januar kam es auf der Moonlight-Website und der API zu zeitweiligen Fehlfunktionen.  Alles begann mit zuf√§lligen API-Fehlern und endete mit einem vollst√§ndigen Herunterfahren.  Die Probleme wurden behoben und die Anwendung normalisiert. <br><br><h3>  Allgemeine Informationen </h3><br>  Moonlight verwendet Software, die als Kubernetes bekannt ist.  Kubernetes f√ºhrt Anwendungen auf Servergruppen aus.  Diese Server werden als Knoten bezeichnet.  Kopien der auf dem Knoten ausgef√ºhrten Anwendung werden als Pods bezeichnet.  Kubernetes verf√ºgt √ºber einen Scheduler, der dynamisch festlegt, welche Pods auf welchen Knoten funktionieren sollen. <br><br><h3>  Zeitleiste </h3><br>  Die ersten Fehler am Freitag waren auf Verbindungsprobleme mit der Redis-Datenbank zur√ºckzuf√ºhren.  Die Moonlight-API verwendet Redis, um Sitzungen f√ºr jede authentifizierte Anforderung zu √ºberpr√ºfen.  Unser √úberwachungstool Kubernetes hat mitgeteilt, dass einige Knoten und Pods nicht reagieren.  Zur gleichen Zeit meldete Google Cloud eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">St√∂rung der Netzwerkdienste</a> und wir entschieden, dass diese die Ursache f√ºr unsere Probleme sind. <br><br>  Mit abnehmendem Verkehr am Wochenende schienen die Fehler weitgehend behoben zu sein.  Am Dienstagmorgen fiel jedoch die Website von Moonlight, und der externe Datenverkehr erreichte den Cluster √ºberhaupt nicht.  Wir haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf Twitter</a> eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">andere Person</a> mit √§hnlichen Symptomen gefunden und festgestellt, dass beim Hosting von Google ein Netzwerkfehler aufgetreten ist.  Wir haben uns an den Google Cloud-Support gewandt, der das Problem umgehend an das technische Support-Team weiterleitete. <br><br>  Das technische Support-Team von Google hat einige Muster im Verhalten von Knoten in unserem Kubernetes-Cluster festgestellt.  Die CPU-Auslastung der einzelnen Knoten erreichte 100%, woraufhin die Kernel-Panik in der virtuellen Maschine auftrat und sie abst√ºrzte. <br><br><h3>  Gr√ºnde </h3><br>  Der Zyklus, der den Fehler verursachte, war wie folgt: <br><br><ul><li>  Der Kubernetes-Scheduler hostete mehrere Pods mit hohem CPU-Verbrauch auf demselben Knoten. </li><li>  Die Pods haben alle CPU-Ressourcen auf dem Knoten verbraucht. </li><li>  Als n√§chstes kam die Kernel-Panik, die zu einer Ausfallzeit f√ºhrte, in der der Knoten nicht auf den Scheduler reagierte. </li><li>  Der Scheduler verschob alle heruntergefallenen Pods auf einen neuen Knoten, und der Vorgang wurde wiederholt, was die allgemeine Situation versch√§rfte. </li></ul><br>  Anfangs trat der Fehler im Redis-Pod auf, aber am Ende fielen alle mit Verkehr arbeitenden Pods, was zu einem vollst√§ndigen Herunterfahren f√ºhrte.  Exponentielle Verz√∂gerungen w√§hrend der Neuplanung haben zu l√§ngeren Ausfallzeiten gef√ºhrt. <br><br><h3>  L√∂sung </h3><br>  Wir konnten die Site wiederherstellen, indem wir allen wichtigen Bereitstellungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anti-Affinit√§tsregeln</a> hinzuf√ºgten.  Sie verteilen die Pods automatisch auf die Knoten, wodurch Fehlertoleranz und Leistung erh√∂ht werden. <br><br>  Kubernetes selbst ist als fehlertolerantes Hostsystem konzipiert.  Moonlight verwendet drei Knoten auf verschiedenen Servern, um die Stabilit√§t zu gew√§hrleisten. Von jeder Anwendung, die den Datenverkehr bedient, werden drei Kopien ausgef√ºhrt.  Die Idee ist, eine Kopie auf jedem Knoten zu haben.  In diesem Fall f√ºhrt selbst ein Ausfall von zwei Knoten nicht zu Ausfallzeiten.  Kubernetes platzierte jedoch manchmal alle drei Pods mit der Site auf demselben Knoten und verursachte so einen Engpass im System.  Zur gleichen Zeit befanden sich andere Anwendungen, die Prozessorleistung ben√∂tigten (n√§mlich serverseitiges Rendern), auf demselben Knoten und nicht auf einem separaten. <br><br>  Ein ordnungsgem√§√ü konfigurierter und funktionsf√§higer Kubernetes-Cluster ist erforderlich, um lange Zeitr√§ume mit hoher CPU-Auslastung zu bew√§ltigen und die Pods so zu platzieren, dass die verf√ºgbaren Ressourcen optimal genutzt werden.  Wir arbeiten weiterhin mit dem Google Cloud-Support zusammen, um die Hauptursache der Kernel-Panik auf Servern zu identifizieren und zu beheben. <br><br><h3>  Fazit </h3><br>  Mit Anti-Affinit√§tsregeln k√∂nnen Sie Anwendungen, die mit externem Datenverkehr arbeiten, fehlertoleranter machen.  Wenn Sie einen √§hnlichen Service bei Kubernetes haben, sollten Sie ihn hinzuf√ºgen. <br><br>  Wir arbeiten weiterhin mit den Mitarbeitern von Google zusammen, um die Fehlerursache im Betriebssystemkern auf den Knoten zu finden und zu beseitigen. <br><br><h2>  Nr. 2.  Das "schmutzige" Geheimnis von Kubernetes und Ingress Endpoint </h2><br>  <i>Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Phil Pearl von Ravelin</a> .</i> <br><br><h3>  Eleganz wird √ºberbewertet </h3><br>  Wir bei Ravelin sind nach Kubernetes (auf GKE) gewandert.  Der Prozess war sehr erfolgreich.  Unsere Budgets f√ºr Pod-Unterbrechungen sind so voll wie immer, Statefuls sind wirklich stattlich <i>(ein schwer zu √ºbersetzendes Wortspiel: "Unsere Statefulsets sind sehr stattlich" - ungef√§hr √ºbersetzt)</i> , und das gleitende Ersetzen von Knoten funktioniert wie am Schn√ºrchen. <br><br>  Der letzte Teil des Puzzles besteht darin, die API-Ebene von alten virtuellen Maschinen in den Kubernetes-Cluster zu verschieben.  Dazu m√ºssen wir Ingress so konfigurieren, dass die API von au√üen zug√§nglich ist. <br><br>  Anfangs schien die Aufgabe einfach zu sein.  Wir definieren nur den Ingress-Controller, optimieren die Terraform, um eine bestimmte Anzahl von IP-Adressen zu erhalten, und Google k√ºmmert sich um fast alles andere.  Und das alles wird wie von Zauberhand funktionieren.  Klasse! <br><br>  Mit der Zeit bemerkten sie jedoch, dass Integrationstests in regelm√§√üigen Abst√§nden Fehler 502 erhielten. Daraufhin begann unsere Reise.  Ich werde Ihnen jedoch Zeit sparen und gleich zu den Schlussfolgerungen kommen. <br><br><h3>  Anmutiges Herunterfahren </h3><br>  Alle sprechen von einem w√ºrdevollen Herunterfahren ("w√ºrdevolles", schrittweises Herunterfahren).  Aber auf ihn sollte man sich bei Kubernetes wirklich nicht verlassen.  Zumindest sollte es nicht das anmutige Herunterfahren sein, das Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://golang.org/pkg/net/">mit der Milch Ihrer Mutter aufgenommen haben</a> .  In der Welt der Kubernetes ist dieses Ma√ü an "Eleganz" unn√∂tig und droht mit ernsthaften Problemen. <br><br><h3>  Perfekte Welt </h3><br>  In den meisten F√§llen wird der Pod folgenderma√üen aus dem Dienst oder Load Balancer in Kubernetes entfernt: <br><br><ol><li>  Der Replikationscontroller beschlie√üt, den Pod zu entfernen. </li><li>  Der Endpunkt-Pod wird aus dem Dienst oder Load Balancer entfernt.  Es kommt kein neuer Verkehr mehr zum Pod. </li><li>  Ein Pre-Stop-Hook wird aufgerufen oder der Pod empf√§ngt ein SIGTERM-Signal. </li><li>  Pod "anmutig" ist nicht verbunden.  Eingehende Verbindungen werden nicht mehr akzeptiert. </li><li>  Die "ordnungsgem√§√üe" Trennung ist abgeschlossen, und der Pod wird zerst√∂rt, nachdem alle vorhandenen Verbindungen gestoppt oder beendet wurden. </li></ol><br>  Leider sieht die Realit√§t ganz anders aus. <br><br><h3>  Reale Welt </h3><br>  Die meisten Dokumentationen weisen darauf hin, dass alles ein wenig anders abl√§uft, aber sie schreiben nirgendwo explizit dar√ºber.  Das Hauptproblem ist, dass Schritt 3 nicht auf Schritt 2 folgt. Sie treten gleichzeitig auf.  Bei normalen Diensten werden die Endpunkte so schnell entfernt, dass die Wahrscheinlichkeit von Problemen √§u√üerst gering ist.  Bei Ingress ist jedoch alles anders: Sie reagieren in der Regel viel langsamer, sodass das Problem offensichtlich wird.  Der Pod kann SIGTERM erhalten, lange bevor √Ñnderungen an Endpunkten in Ingress eintreten. <br><br>  Infolgedessen ist ein ordnungsgem√§√ües Herunterfahren √ºberhaupt nicht das, was von einem Pod verlangt wird.  Er wird neue Verbindungen erhalten und diese weiter verarbeiten m√ºssen, andernfalls werden die Clients die 500. Fehler erhalten und die ganze wunderbare Geschichte √ºber unkomplizierte Bereitstellungen und Skalierungen wird auseinanderfallen. <br><br>  Folgendes passiert tats√§chlich: <br><br><ol><li>  Der Replikationscontroller beschlie√üt, den Pod zu entfernen. </li><li>  Der Endpunkt-Pod wird aus dem Dienst oder Load Balancer entfernt.  Bei Ingress kann dies einige Zeit dauern, und es flie√üt weiterhin neuer Verkehr in den Pod. </li><li>  Ein Pre-Stop-Hook wird aufgerufen oder der Pod empf√§ngt ein SIGTERM-Signal. </li><li>  Der Pod muss dies weitgehend ignorieren, weiterarbeiten und neue Verbindungen aufrechterhalten.  Wenn m√∂glich, sollte er Kunden darauf hinweisen, dass es sch√∂n w√§re, an einen anderen Ort zu wechseln.  Im Falle von HTTP kann beispielsweise <code>Connection: close</code> in den Antwort-Headern gesendet werden. </li><li>  Der Pod wird nur beendet, wenn die Wartezeit ‚Äûelegant‚Äú abgelaufen ist und er von SIGKILL get√∂tet wird. </li><li>  Stellen Sie sicher, dass dieser Zeitraum l√§nger ist als die Zeit, die f√ºr die Neuprogrammierung des Load Balancers erforderlich ist. </li></ol><br>  Wenn es sich um Code von Drittanbietern handelt und Sie das Verhalten nicht √§ndern k√∂nnen, k√∂nnen Sie am besten einen Pre-Stop-Hook hinzuf√ºgen, der nur f√ºr eine ‚Äûelegante‚Äú Zeitspanne ruht, sodass der Pod weiterhin wie nichts funktioniert passiert ist. <br><br><h2>  Nummer 3.  Wie ein einfacher Webhook einen Clusterausfall verursachte </h2><br>  <i>Im Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jetstack</a> .</i> <br><br>  Jetstack bietet seinen Kunden mandantenf√§hige Plattformen auf Kubernetes an.  Manchmal gibt es spezielle Anforderungen, die wir mit der Standard-Kubernetes-Konfiguration nicht erf√ºllen k√∂nnen.  Um diese zu implementieren, haben wir k√ºrzlich begonnen, den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Open Policy Agent</a> <i>(√ºber das Projekt haben wir in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Test</a> ausf√ºhrlicher berichtet - ca. √ºbersetzt)</i> als Zugriffskontroller f√ºr die Implementierung spezieller Richtlinien zu verwenden. <br><br>  Dieser Artikel beschreibt den Fehler, der durch die nicht ordnungsgem√§√ü konfigurierte Integration verursacht wird. <br><br><h3>  Zwischenfall </h3><br>  Wir haben den Assistenten f√ºr den Entwicklercluster aktualisiert, in dem verschiedene Teams ihre Anwendungen w√§hrend des Arbeitstages getestet haben.  Es war ein regionaler Cluster in der Zone Europa-West1 der Google Kubernetes Engine (GKE). <br><br>  Befehle wurden gewarnt, dass ein Update ausgef√ºhrt wird und keine Ausfallzeiten zu erwarten sind.  Wir haben an diesem Tag bereits ein √§hnliches Update f√ºr eine andere Vorproduktionsumgebung durchgef√ºhrt. <br><br>  Wir haben das Upgrade mit unserer GKE Terraform-Pipeline gestartet.  Das Update des Assistenten wurde erst nach Ablauf des Terraform-Timeouts abgeschlossen, das wir f√ºr 20 Minuten festgelegt haben.  Dies war der erste Weckruf, bei dem ein Fehler aufgetreten ist, obwohl der Cluster in der GKE-Konsole immer noch als "Upgrade" aufgef√ºhrt war. <br><br>  Ein Neustart der Pipeline f√ºhrte zu folgendem Fehler <br><br><pre> <code class="bash hljs">google_container_cluster.cluster: Error waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> updating GKE master version: All cluster resources were brought up, but the cluster API is reporting that: component <span class="hljs-string"><span class="hljs-string">"kube-apiserver"</span></span> from endpoint <span class="hljs-string"><span class="hljs-string">"gke-..."</span></span> is unhealthy</code> </pre> <br>  Diesmal wurde die Verbindung zum API-Server regelm√§√üig unterbrochen und die Teams konnten ihre Anwendungen nicht bereitstellen. <br><br>  W√§hrend wir versuchten zu verstehen, was vor sich ging, wurden alle Knoten in einem endlosen Zyklus zerst√∂rt und neu erstellt.  Dies hat zu einem wahllosen Denial-of-Service f√ºr alle unsere Kunden gef√ºhrt. <br><br><h3>  Wir ermitteln die Fehlerursache </h3><br>  Mit der Unterst√ºtzung von Google konnten wir die Reihenfolge der Ereignisse ermitteln, die zu dem Fehler gef√ºhrt haben: <br><br><ol><li>  GKE schloss das Upgrade auf einer Instanz des Assistenten ab und begann, den gesamten Datenverkehr zum API-Server darauf zu akzeptieren, wenn die n√§chsten Assistenten aktualisiert wurden. </li><li>  W√§hrend des Upgrades der zweiten Instanz des Assistenten konnte der API-Server <a href="">PostStartHook</a> nicht ausf√ºhren, um die <a href="">Zertifizierungsstelle</a> zu <a href="">registrieren.</a> </li><li>  W√§hrend der Ausf√ºhrung dieses Hooks hat der API-Server versucht, ConfigMap mit dem Namen <code>extension-apiserver-authentication</code> in <code>kube-system</code> zu aktualisieren.  Dies war nicht m√∂glich, da das von uns konfigurierte Back-End f√ºr den Open Policy Agent (OPA) -√úberpr√ºfungswebhook nicht reagierte. </li><li>  Damit der Assistent eine Integrit√§tspr√ºfung besteht, muss dieser Vorgang erfolgreich abgeschlossen werden.  Da dies nicht geschah, trat der zweite Master in den Notfallzyklus ein und stoppte das Update. </li></ol><br>  Das Ergebnis waren regelm√§√üige API-Abst√ºrze, aufgrund derer Kubelets nicht in der Lage waren, den Zustand des Knotens zu melden.  Dies f√ºhrte wiederum dazu, dass der Mechanismus zur automatischen Wiederherstellung von GKE-Knoten <i>(Node Auto Repair)</i> begann, die Knoten neu zu starten.  Diese Funktion wird in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> ausf√ºhrlich beschrieben: <br><br><blockquote>  <i>Ein fehlerhafter Status kann bedeuten: Innerhalb einer bestimmten Zeit (ca. 10 Minuten) gibt der Knoten √ºberhaupt keinen Status aus.</i> </blockquote><br><h3>  L√∂sung </h3><br>  Als wir herausfanden, dass die <code>ValidatingAdmissionWebhook</code> Ressource einen zeitweiligen Zugriff auf den API-Server verursachte, l√∂schten wir sie und stellten die Funktionsf√§higkeit des Clusters wieder her. <br><br>  Seitdem wurde <code>ValidatingAdmissionWebhook</code> for OPA so konfiguriert, dass nur die Namespaces √ºberwacht werden, auf die die Richtlinie anwendbar ist und auf die die Entwicklungsteams Zugriff haben.  Wir haben den Webhook auch auf <code>Ingress</code> und <code>Service</code> , die einzigen, mit denen unsere Richtlinie funktioniert. <br><br>  Seit wir das OPA zum ersten Mal bereitgestellt haben, wurde die Dokumentation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aktualisiert</a> , um diese √Ñnderung widerzuspiegeln. <br><br>  Wir haben auch einen Verf√ºgbarkeitstest hinzugef√ºgt, um sicherzustellen, dass der OPA neu gestartet wird, falls er nicht mehr verf√ºgbar ist (und die Dokumentation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">entsprechend ge√§ndert</a> ). <br><br>  Wir haben auch √ºberlegt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den</a> automatischen Wiederherstellungsmechanismus f√ºr GKE-Knoten zu deaktivieren, haben uns aber dennoch entschlossen, diese Idee aufzugeben. <br><br><h3>  Zusammenfassung </h3><br>  Wenn wir die API-Server-Antwortzeitwarnungen aktivieren, k√∂nnen wir nach der Bereitstellung des OPA-Webhooks zun√§chst die globale Erh√∂hung f√ºr alle <code>CREATE</code> und <code>UPDATE</code> Anforderungen feststellen. <br><br>  Dies unterstreicht, wie wichtig es ist, Tests f√ºr alle Workloads einzurichten.  R√ºckblickend k√∂nnen wir sagen, dass der Einsatz von OPA so tr√ºgerisch einfach war, dass wir uns nicht einmal auf das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Helm-Diagramm einlie√üen</a> (obwohl dies so sein sollte).  Die Tabelle enth√§lt eine Reihe von Anpassungen, die √ºber die im Handbuch beschriebenen Grundeinstellungen hinausgehen, einschlie√ülich der Einstellung "livenessProbe" f√ºr Container mit einem Zugangscontroller. <br><br>  Wir waren nicht die Ersten, die auf dieses Problem gesto√üen sind: Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgelagerte Frage</a> bleibt offen.  Die Funktionalit√§t in dieser Angelegenheit kann eindeutig verbessert werden (und wir werden dies weiter verfolgen). <br><br><h2>  PS vom √úbersetzer </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie Pod-Priorit√§ten bei Kubernetes Ausfallzeiten bei Grafana Labs verursachten</a> ." </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aus dem Leben mit Kubernetes: Wie die Spanier sich nicht √ºber den HTTP-Server beschwerten</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">6 unterhaltsame Systemfehler im Betrieb von Kubernetes [und deren L√∂sung]</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">6 praktische Geschichten aus unserem SRE-Alltag</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de475026/">https://habr.com/ru/post/de475026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de475012/index.html">Wie der Browser f√ºr iOS die A / B-Tests verbesserte. Yandex-Bericht</a></li>
<li><a href="../de475016/index.html">QA mitap bei Redmadrobot 22. November</a></li>
<li><a href="../de475018/index.html">√Ñnderung der S√§ulen Radiotehnika S-30</a></li>
<li><a href="../de475022/index.html">Architektonische Schizophrenie Facebook Waage</a></li>
<li><a href="../de475024/index.html">Laufen ist ein idealer Sport f√ºr Fernarbeiter. Teil 1: Der Weg zum ersten Rennen von hundert Kilometern</a></li>
<li><a href="../de475028/index.html">Bemerkungen zur Anwendung von ML im Gesch√§ftsverkehr auf ≈ΩijemeIT-Aktien</a></li>
<li><a href="../de475032/index.html">Gartner Hype Cycle 2019: Nachbesprechung</a></li>
<li><a href="../de475034/index.html">Grafik im Browser f√ºr Arduino und STM32</a></li>
<li><a href="../de475036/index.html">Cassandra-Migration zu Kubernetes: Funktionen und L√∂sungen</a></li>
<li><a href="../de475038/index.html">Der erste Satz "Angewandte Mathematik und Informatik" an der HSE in St. Petersburg: Wer sind sie und wie arbeiten sie mit ihnen?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
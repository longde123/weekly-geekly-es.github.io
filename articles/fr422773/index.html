<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçüè≠ üçô üóÇÔ∏è NVIDIA. R√©v√©ler les secrets de l'architecture GPU Turing de nouvelle g√©n√©ration: double ray tracing, GDDR6, etc. üìà ü§∂üèæ ‚òÅÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lors de la pr√©sentation de NVIDIA SIGGRAPH 2018, le PDG de la soci√©t√©, Jensen Juan, a officiellement d√©voil√© l'architecture GPU Turing tant attendue (...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA. R√©v√©ler les secrets de l'architecture GPU Turing de nouvelle g√©n√©ration: double ray tracing, GDDR6, etc.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/422773/">  Lors de la pr√©sentation de NVIDIA SIGGRAPH 2018, le PDG de la soci√©t√©, Jensen Juan, a officiellement d√©voil√© l'architecture GPU Turing tant attendue (et rumeur et sp√©culation).  La prochaine g√©n√©ration de GPU NVIDIA, Turing, inclura un certain nombre de nouvelles fonctionnalit√©s et verra le monde plus tard cette ann√©e.  Bien que la visualisation professionnelle (ProViz) ait √©t√© au centre des annonces d'aujourd'hui, nous nous attendons √† ce que la nouvelle architecture soit utilis√©e dans d'autres produits NVIDIA √† venir.  La revue d'aujourd'hui n'est pas seulement une liste de toutes les fonctionnalit√©s de Turing. <br><br><img src="https://habrastorage.org/webt/7c/7l/qd/7c7lqd7hpvnms_v0fcexsts94-m.jpeg"><br><a name="habracut"></a><br><h3>  Rendu hybride et r√©seaux de neurones: noyaux RT et tenseur </h3><br>  Alors, quelle est la particularit√© et la nouveaut√© de l'architecture Turing?  Marquee, au moins pour la communaut√© NVIDIA ProViz, est con√ßu pour le rendu hybride, qui combine le lancer de rayons avec la pixellisation traditionnelle. <br><br><img src="https://habrastorage.org/webt/zz/lq/is/zzlqisnubeefbyyqueijnvgumaa.jpeg"><br><br>  Changement majeur: NVIDIA a inclus encore plus d'√©quipements de tra√ßage de rayons dans Turing pour offrir le tra√ßage de rayons acc√©l√©r√© mat√©riel le plus rapide.  Une nouveaut√© pour l'architecture de Turing est l'unit√© informatique sp√©cialis√©e RT Core, comme l'appelle NVIDIA, actuellement il n'y a pas assez d'informations √† ce sujet, on sait seulement que sa fonction est la prise en charge du lancer de rayons.  Ces unit√©s de traitement acc√©l√®rent √† la fois la v√©rification de l'intersection des rayons et des triangles, ainsi que la manipulation des BVH (hi√©rarchies des volumes englobants). <br><br>  NVIDIA affirme que les composants de Turing les plus rapides peuvent compter 10 milliards (Giga) de rayons par seconde, ce qui, compar√© au Pascal non acc√©l√©r√©, repr√©sente une am√©lioration de 25 fois des performances de tra√ßage des rayons. <br><br>  L'architecture de Turing comprend des noyaux de tenseurs Volta qui ont √©t√© renforc√©s.  Les noyaux tenseur sont un aspect important de plusieurs initiatives NVIDIA.  Parall√®lement √† l'acc√©l√©ration du tra√ßage des rayons, un outil important dans le ¬´sac magique¬ª NVIDIA est de r√©duire le nombre de rayons requis dans la sc√®ne en utilisant la r√©duction du bruit AI pour effacer l'image, ici les noyaux tensoriels font mieux.  Bien s√ªr, ce n'est pas le seul domaine o√π ils sont bons - tous les r√©seaux de neurones et les empires d'IA de NVIDIA sont construits sur eux. <br><br>  Turing se caract√©rise par la prise en charge d'une plus grande plage de pr√©cision, ce qui signifie la possibilit√© d'une acc√©l√©ration significative des charges de travail qui n'ont pas d'exigences de pr√©cision √©lev√©es.  En plus du mode de pr√©cision Volta FP16, les noyaux tenseurs de Turing prennent en charge INT8 et m√™me INT4.  Ceci est 2 et 4 fois plus rapide que FP16, respectivement.  Bien que NVIDIA ne veuille pas entrer dans les d√©tails lors de la pr√©sentation, je sugg√®re qu'ils impl√©mentent quelque chose de similaire √† l'empaquetage de donn√©es, qui est utilis√© pour les op√©rations de faible pr√©cision sur les c≈ìurs CUDA.  Malgr√© la pr√©cision r√©duite du r√©seau neuronal (le retour est r√©duit - selon INT4, nous n'obtenons que 16 (!) Valeurs) - certains mod√®les ont vraiment besoin de ce faible niveau de pr√©cision.  En cons√©quence, les modes de pr√©cision r√©duits afficheront un bon d√©bit, en particulier dans les t√¢ches de sortie, ce qui plaira sans aucun doute √† certains utilisateurs. <br><br>  En revenant au rendu hybride en g√©n√©ral, il est int√©ressant de noter que malgr√© ces grandes acc√©l√©rations individuelles, la promesse globale de NVIDIA de gains de performances semble un peu plus modeste.  Bien que l'entreprise promette d'augmenter la productivit√© de 6 fois par rapport √† Pascal, il est temps de demander quelles pi√®ces sont acc√©l√©r√©es, et en comparaison avec lesquelles.  Le temps nous le dira. <br><br>  Parall√®lement, afin de mieux utiliser les noyaux tensoriels en dehors du ray tracing et des t√¢ches d'apprentissage approfondi √©troitement cibl√©es, NVIDIA d√©ploiera un SDK, NVIDIA NGX, qui permettra l'int√©gration de r√©seaux de neurones dans le traitement d'images.  NVIDIA pr√©voit l'utilisation de r√©seaux de neurones et de c≈ìurs tenseurs pour le traitement d'images et de vid√©os suppl√©mentaires, y compris des m√©thodes telles que le prochain Deep-Anti-Aliasing (DLAA). <br><br><h3>  Turing SM: c≈ìurs INT d√©di√©s, cache unique, ombrage √† d√©bit variable </h3><br>  Avec les noyaux RT et tensoriels, l'architecture Turing Streaming Multiprocessor (SM) elle-m√™me introduit de nouvelles astuces.  En particulier, l'un des derniers changements de Volta a √©t√© h√©rit√©, √† la suite duquel les c≈ìurs Integer sont allou√©s dans leurs propres blocs et ne font pas partie des c≈ìurs √† virgule flottante CUDA.  L'avantage est une g√©n√©ration d'adresse plus rapide et des performances Fused Multiply Add (FMA). <br><br>  Quant √† ALU (j'attends toujours la confirmation de Turing) - support pour des op√©rations plus rapides avec une faible pr√©cision (par exemple, FP16 rapide).  √Ä Volta, cela est mis en ≈ìuvre comme des op√©rations de FP16 √† double fr√©quence par rapport √† FP32 et des op√©rations INT8 √† 4x.  Les noyaux tenseur prennent d√©j√† en charge ce concept, il serait donc logique de le transf√©rer vers les noyaux CUDA. <br>  Fast FP16, la technologie Rapid Packed Math et d'autres moyens de regrouper plusieurs petites op√©rations en une seule grande op√©ration sont tous des √©l√©ments cl√©s de l'am√©lioration des performances du GPU √† un moment o√π la loi de Moore ralentit. <br><br>  En utilisant des types de donn√©es volumineux (exacts) uniquement lorsque cela est n√©cessaire, ils peuvent √™tre regroup√©s pour effectuer plus de travail dans la m√™me p√©riode.  Ceci est principalement important pour la sortie des r√©seaux de neurones, ainsi que pour le d√©veloppement de jeux.  Le fait est que tous les programmes de shader n'ont pas besoin de pr√©cision FP32, et la r√©duction de la pr√©cision peut am√©liorer les performances et r√©duire la bande passante m√©moire utile et l'utilisation du fichier de registre. <br><br>  Turing SM inclut quelque chose que NVIDIA appelle ¬´l'architecture de cache unifi√©e¬ª.  Comme j'attends toujours des diagrammes SMID officiels de NVIDIA, il n'est pas clair s'il s'agit de la m√™me unification que nous avons vue avec Volta - o√π le cache L1 a √©t√© combin√© avec la m√©moire partag√©e - ou NVIDIA est all√© plus loin.  Dans tous les cas, NVIDIA pr√©tend avoir maintenant offert deux fois plus de bande passante par rapport √† la ¬´g√©n√©ration pr√©c√©dente¬ª, mais on ne sait pas si cela signifie ¬´Pascal¬ª ou ¬´Volta¬ª (ce dernier est plus probable). <br><br>  Enfin, profond√©ment cach√© dans le communiqu√© de presse de Turing, il a √©t√© fait mention du support de l'ombrage √† taux variable.  Il s'agit d'une technologie de rendu graphique relativement jeune et √©volutive, sur laquelle il existe peu d'informations (en particulier sur la fa√ßon dont elle est impl√©ment√©e par NVIDIA).  Mais √† un niveau d'abstraction tr√®s √©lev√©, cela ressemble √† ¬´la technologie de prochaine g√©n√©ration de NVIDIA qui vous permet d'appliquer un ombrage avec diff√©rentes r√©solutions, ce qui permet aux d√©veloppeurs d'afficher diff√©rentes zones de l'√©cran √† diff√©rentes r√©solutions efficaces pour la qualit√© de concentration (et le temps de rendu) dans les zones o√π cela est le plus n√©cessaire¬ª . <br><br><h3>  Nourrir la b√™te: prise en charge de GDDR6 </h3><br>  La m√©moire utilis√©e par les GPU √©tant d√©velopp√©e par des soci√©t√©s tierces, il n'y a pas de secret.  JEDEC et son grand Samsung √† 3 membres, SK Hynix et Micron d√©veloppent la m√©moire GDDR6 en tant que successeur de GDDR5 et GDDR5X.  NVIDIA a confirm√© que Turing le soutiendrait.  Selon le fabricant, la premi√®re g√©n√©ration de GDDR6 est annonc√©e comme ayant une bande passante m√©moire allant jusqu'√† 16 Gb / s par bus, soit deux fois plus que les cartes NVIDIA GDDR5 de derni√®re g√©n√©ration, et 40% plus rapide que les derni√®res cartes NVIDIA GDDR5X. <br><br><img src="https://habrastorage.org/webt/ts/ln/ty/tslntydaj3sl-jayd7jr8wbg57w.png"><br><br>  Compar√© au GDDR5X, le GDDR6 ne ressemble pas √† une perc√©e majeure, car de nombreuses innovations du GDDR6 ont d√©j√† √©t√© appliqu√©es au GDDR5X.  Les changements fondamentaux incluent ici des tensions de fonctionnement plus faibles (1,35 V), et la m√©moire interne est maintenant divis√©e: deux canaux de m√©moire par microcircuit.  Pour une puce standard de 32 bits - deux canaux de m√©moire de 16 bits, nous avons au total 16 de ces canaux sur une carte de 256 bits.  Bien que cela, √† son tour, indique qu'il existe un tr√®s grand nombre de canaux, les GPU b√©n√©ficieront au maximum de l'innovation, car ils sont historiquement les appareils les plus ¬´parall√®les¬ª. <br><br><img src="https://habrastorage.org/webt/u-/45/om/u-45om2tovq4lcaqzdvb3acmpyw.jpeg"><br><br>  NVIDIA, pour sa part, a confirm√© que les premi√®res cartes Turing Quadro utiliseront la GDDR6 √† 14 Gb / s.  Dans le m√™me temps, NVIDIA a √©galement confirm√© l'utilisation de la m√©moire Samsung, en particulier pour ses appareils avanc√©s de 16 gigaoctets.  Ceci est important car cela signifie qu'un GPU NVIDIA 256 bits typique peut √™tre √©quip√© de 8 modules standard et obtenir 16 Go de capacit√© de m√©moire totale, voire 32 Go s'ils utilisent le mode √† clapet (permet d'adresser 32 Go de m√©moire sur 256 bits standard bus). <br><br><h3>  Toutes sortes de d√©tails: NVLink, VirtualLink et 8K HEVC </h3><br>  Se terminant d√©j√† par un examen de l'architecture Turing, NVIDIA a confirm√© nonchalamment la prise en charge de certaines des nouvelles fonctionnalit√©s d'E / S externes.  Le support NVLink sera pr√©sent dans au moins plusieurs produits Turing.  Rappelons que NVIDIA l'utilise dans les trois nouvelles cartes Quadro.  NVIDIA propose une configuration GPU bidirectionnelle. <br><br>  Un point important (avant qu'une partie de notre public orient√© jeu ne se lance dans la lecture): la pr√©sence de NVLink dans l'√©quipement Turing ne signifie pas qu'il sera utilis√© dans les cartes vid√©o grand public.  Peut-√™tre que tout sera limit√© aux cartes Quadro et Tesla. <br><br><img src="https://habrastorage.org/webt/hz/ug/kh/hzugkh-qnznywnylpygk2f7u1eq.png"><br><br>  Avec l'ajout de la prise en charge de VirtualLink, les lecteurs et utilisateurs ProViz auront ce √† quoi s'attendre de la r√©alit√© virtuelle.  Un autre mode USB Type-C a √©t√© annonc√© le mois dernier et prend en charge une puissance de 15 W +, un transfert de donn√©es de 10 Gb / s gr√¢ce √† l'USB 3.1 Gen 2, 4 bandes DisplayPort HBR3 sur un seul c√¢ble.  En d'autres termes, il s'agit d'une connexion DisplayPort 1.4 avec des donn√©es et une alimentation suppl√©mentaires.  Cela permet √† la carte vid√©o de contr√¥ler directement le casque VR.  La norme est prise en charge par NVIDIA, AMD, Oculus, Valve et Microsoft, de sorte que les produits Turing seront les premiers d'un certain nombre de produits qui prendront en charge la nouvelle norme. <br><br>  Bien que NVIDIA n'ait abord√© que tr√®s peu le sujet, nous savons que le codeur vid√©o NVENC a √©t√© mis √† jour dans Turing.  La derni√®re it√©ration NVENC ajoute un support d'encodage HEKC 8K sp√©cial.  Pendant ce temps, NVIDIA a pu am√©liorer la qualit√© de son encodeur, lui permettant d'atteindre la m√™me qualit√© qu'auparavant, avec un d√©bit vid√©o inf√©rieur de 25%. <br><br><h3>  Indicateurs de performance </h3><br>  Parall√®lement aux sp√©cifications mat√©rielles annonc√©es, NVIDIA pr√©sente plusieurs chiffres de performances des √©quipements Turing.  Il convient de noter que nous en savons tr√®s, tr√®s peu ici.  Les composants sont apparemment bas√©s sur les SKU Turing enti√®rement et partiellement inclus avec 4608 noyaux CUDA et 576 noyaux tensoriels.  Les fr√©quences n'ont pas √©t√© divulgu√©es, cependant, puisque ces chiffres sont profil√©s pour le mat√©riel Quadro, nous verrons probablement des vitesses d'horloge inf√©rieures √† celles de tout √©quipement grand public. <br><br><img src="https://habrastorage.org/webt/x9/10/zm/x910zmkfvkgbmxvjizsumjqjefi.jpeg"><br><br><img src="https://habrastorage.org/webt/65/95/4z/65954zsmzwtbffhmn6boyiioazi.png"><br><br>  Avec les 10 GigaRays / sec susmentionn√©s pour les c≈ìurs RT, les performances des c≈ìurs de tenseurs NVIDIA sont de 500 billions d'op√©rations de tenseur par seconde (500T TOP).  Pour r√©f√©rence, NVIDIA mentionne souvent le GPU GV100 comme capable de fournir un maximum de 120T TOP, mais ce n'est pas la m√™me chose.  En particulier, alors que le GV100 est mentionn√© dans le traitement des op√©rations FP16, les performances de Turing sont cit√©es avec une pr√©cision extr√™mement faible INT4, qui ne repr√©sente qu'un quart de la taille de FP16 et, par cons√©quent, augmente le d√©bit quatre fois.  Si nous normalisons la pr√©cision, les noyaux tensoriels de Turing ne semblent pas avoir le meilleur d√©bit par c≈ìur, mais offrent plut√¥t plus d'options de pr√©cision que Volta.  Dans tous les cas, 576 c≈ìurs tenseurs dans cette puce la mettent presque √† √©galit√© avec le GV100, qui en compte 640. <br><br>  Concernant les c≈ìurs CUDA, NVIDIA affirme que le GPU Turing peut offrir 16 performances TFLOPS.  Ceci est l√©g√®rement en avance sur les performances de 15 TFLOPS avec la pr√©cision simple du Tesla V100, ou encore plus en avance sur les 13,8 TFLOPS de Titan V.Si vous recherchez des informations plus conviviales, c'est environ 32% de plus que le Titan Xp.  Apr√®s avoir esquiss√© quelques calculs approximatifs sur papier, nous pouvons supposer la vitesse d'horloge du GPU d'environ 1730 MHz, √©tant donn√© qu'au niveau SM, il n'y a eu aucun changement suppl√©mentaire qui changerait les formules de performance ALU traditionnelles. <br><br>  Pendant ce temps, NVIDIA a annonc√© que les cartes Quadro seront livr√©es avec une m√©moire GDDR6 fonctionnant √† 14 Gb / s.  Et en regardant les deux meilleures SKU Quadro offrant respectivement 48 Go et 24 Go GDDR6, nous voyons presque le bus m√©moire 384 bits sur ce GPU Turing.  En ce qui concerne les chiffres, cela √©quivaut √† 672 Go / s de bande passante m√©moire pour les deux cartes Quadro haut de gamme. <br><br>  Sinon, avec un changement d'architecture, il est difficile de faire de nombreuses comparaisons de performances utiles, surtout lors de la comparaison avec Pascal.  D'apr√®s ce que nous avons vu avec Volta, les performances globales de NVIDIA se sont am√©lior√©es, en particulier dans les charges de travail informatiques bien con√ßues.  Ainsi, une am√©lioration d'environ 33% des performances du papier par rapport au Quadro P6000 pourrait bien √™tre quelque chose de beaucoup plus important. <br><br>  Je mentionnerai la taille cristalline du nouveau GPU.  Situ√© sur 754 mm2, ce n'est pas seulement grand, c'est √©norme.  Par rapport aux autres GPU, seul le NVIDIA GV100 est le deuxi√®me en taille, qui reste actuellement le fleuron de NVIDIA.  Mais avec 18,6 milliards de transistors, il est facile de voir pourquoi la puce r√©sultante devrait √™tre si grosse.  Apparemment, NVIDIA a de grands projets pour ce GPU, qui √† terme pourra justifier la pr√©sence de deux √©normes processeurs graphiques dans sa pile de produits. <br><br>  NVIDIA, pour sa part, n'a pas indiqu√© de num√©ro de mod√®le sp√©cifique pour ce GPU - qu'il s'agisse d'un GPU traditionnel de classe 102 ou m√™me de classe 100.  Je me demande si nous verrons une modification de ce type de GPU pour un produit de consommation sous une forme ou une autre;  il est si grand que NVIDIA souhaitera peut-√™tre le conserver pour ses GPU Quadro et Tesla plus rentables. <br><br><h3>  Publi√© au quatri√®me trimestre de 2018, sinon plus t√¥t </h3><br>  En conclusion, je dirai qu'avec l'annonce de l'architecture Turing, NVIDIA a annonc√© que les 4 premi√®res cartes Quadro bas√©es sur les GPU Turing - Quadro RTX 8000, RTX 6000 et RTX 5000 commenceront √† √™tre livr√©es au quatri√®me trimestre de cette ann√©e.  √âtant donn√© que la nature m√™me de cette annonce est quelque peu invers√©e - g√©n√©ralement NVIDIA annonce d'abord les composants grand public - je n'appliquerais pas la m√™me chronologie aux cartes grand public qui n'ont pas des exigences de validation aussi strictes.  Nous verrons de l'√©quipement Turing au quatri√®me trimestre de cette ann√©e, sinon plus t√¥t.  Ceux qui veulent acheter Quadro peuvent commencer √† √©conomiser de l'argent d√®s maintenant: le meilleur des nouvelles cartes Quadro RTX 8000 vous co√ªtera environ 10000 $. <br><br>  Enfin, pour les consommateurs avec Tesla de NVIDIA, le lancement du Turing laisse Volta dans les limbes.  NVIDIA ne nous a pas dit si Turing allait √©ventuellement s'√©tendre dans l'espace haut de gamme de Tesla - en remplacement du GV100 - ou si leur meilleur processeur Volta resterait le ma√Ætre de son domaine pendant des si√®cles.  Cependant, puisque les autres cartes Tesla ont jusqu'√† pr√©sent √©t√© bas√©es sur Pascal, elles sont les premi√®res candidates √† l'√©viction de Turing en 2019. <br><br>  Merci de rester avec nous.  Aimez-vous nos articles?  Vous voulez voir des mat√©riaux plus int√©ressants?  Soutenez-nous en passant une commande ou en le recommandant √† vos amis, une <b>r√©duction de 30% pour les utilisateurs Habr sur un analogue unique de serveurs d'entr√©e de gamme que nous avons invent√©s pour vous:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Toute la v√©rit√© sur VPS (KVM) E5-2650 v4 (6 c≈ìurs) 10 Go DDR4 240 Go SSD 1 Gbps √† partir de 20 $ ou comment diviser le serveur?</a>  (les options sont disponibles avec RAID1 et RAID10, jusqu'√† 24 c≈ìurs et jusqu'√† 40 Go de DDR4). <br><br>  <b>VPS (KVM) E5-2650 v4 (6 c≈ìurs) 10 Go DDR4 240 Go SSD 1 Gbit / s jusqu'en d√©cembre gratuitement</b> en payant pour une p√©riode de six mois, vous pouvez commander <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  <b>Dell R730xd 2 fois moins cher?</b>  Nous avons seulement <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2 x Intel Dodeca-Core Xeon E5-2650v4 128 Go DDR4 6x480 Go SSD 1 Gbps 100 TV √† partir de 249 $</a> aux Pays-Bas et aux √âtats-Unis!</b>  Pour en savoir plus sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cr√©ation d'un b√¢timent d'infrastructure.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classe utilisant des serveurs Dell R730xd E5-2650 v4 co√ªtant 9 000 euros pour un sou?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422773/">https://habr.com/ru/post/fr422773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422763/index.html">√âv√©nements num√©riques √† Moscou du 10 au 16 septembre</a></li>
<li><a href="../fr422765/index.html">OpenID Connect 1.0 sur les doigts</a></li>
<li><a href="../fr422767/index.html">Conf√©rence DEFCON 16. Fedor, InSecure.org Hacker. Analyse NMAP en ligne</a></li>
<li><a href="../fr422769/index.html">Les gagnants du Startup Battlefield TechCrunch Disrupt San Francisco 2018</a></li>
<li><a href="../fr422771/index.html">Les r√®gles du design, atteindre un nouveau niveau et la pens√©e design</a></li>
<li><a href="../fr422775/index.html">Conf√©rence DEFCON 22. Andrew "Zoz" Brooks. Ne le g√¢chez pas! Partie 1</a></li>
<li><a href="../fr422777/index.html">Une introduction simple √† l'ALU pour les r√©seaux de neurones: explication, signification physique et mise en ≈ìuvre</a></li>
<li><a href="../fr422781/index.html">Fintech digest: SWIFT continuera √† travailler en F√©d√©ration de Russie, VISA vous permettra de transf√©rer des fonds par num√©ro de t√©l√©phone, biom√©trie on√©reuse</a></li>
<li><a href="../fr422783/index.html">Mieux, plus rapide, plus puissant: les composants de style v4</a></li>
<li><a href="../fr422785/index.html">Num√©risation en usine: un regard sur le devant</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
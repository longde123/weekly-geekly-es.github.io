<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòæ üë®üèº‚Äçüîß üëû Apprentissage automatique renforc√© des r√©seaux de neurones profonds sur tensorflow.js: Astuces üë©üèª üì° ‚õÑÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Former des r√©seaux de neurones profonds √† partir de z√©ro n'est pas une t√¢che facile. 

 Cela prend beaucoup de donn√©es et de temps √† apprendre, mais c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprentissage automatique renforc√© des r√©seaux de neurones profonds sur tensorflow.js: Astuces</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452612/">  Former des r√©seaux de neurones profonds √† partir de z√©ro n'est pas une t√¢che facile. <br><br>  Cela prend beaucoup de donn√©es et de temps √† apprendre, mais certaines astuces peuvent aider √† acc√©l√©rer le processus, dont je parlerai sous la coupe. <br><br>  D√©monstration du passage d'un labyrinthe simple √† l'aide de tours.  Dur√©e de la formation en r√©seau: 1 heure 06 minutes.  Enregistrement acc√©l√©r√© de 8 fois. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/KbuNjZKidpw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  Pour chaque t√¢che, vous devez d√©velopper votre propre ensemble d'astuces pour acc√©l√©rer l'apprentissage en r√©seau.  Je vais partager quelques astuces qui m'ont aid√© √† former le r√©seau beaucoup plus rapidement. <br><br>  Pour les connaissances th√©oriques, je recommande de passer au canal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sim0nsays</a> . <br>  Et je parlerai de mes modestes succ√®s dans la formation des r√©seaux de neurones. <br><br><h2>  √ânonc√© du probl√®me </h2><br>  <i>Pour approximer la fonction de convergence en minimisant la fonction de perte quadratique par la propagation en arri√®re de l'erreur par les r√©seaux de neurones profonds.</i> <br><br>  J'avais un choix strat√©gique sur la fa√ßon de former un r√©seau neuronal. <br>  Encouragez la r√©ussite de la t√¢che ou encouragez-la √† l'approche de la fin de la t√¢che. <br><br>  J'ai choisi la deuxi√®me m√©thode, pour deux raisons: <br><br><ul><li>  La probabilit√© que le r√©seau atteigne lui-m√™me la ligne d'arriv√©e est tr√®s faible, il sera donc condamn√© √† recevoir beaucoup de renforcement n√©gatif.  Cela r√©initialisera les poids de tous les neurones et le r√©seau ne sera pas en mesure de poursuivre la formation. <br></li><li>  Les r√©seaux de neurones profonds sont puissants.  Je n'exclus pas que la premi√®re m√©thode aurait r√©ussi si j'avais une puissance de calcul √©norme et beaucoup de temps pour la formation.  J'ai pris le chemin du moindre co√ªt en d√©veloppant des astuces. <br></li></ul><br><h2>  Architecture de r√©seau neuronal </h2><br>  L'architecture se d√©veloppe exp√©rimentalement, bas√©e sur l'exp√©rience de l'architecte et bonne chance. <br><br>  Architecture pour r√©soudre le probl√®me: <br><br><ul><li>  3 neurones d'entr√©e - les coordonn√©es de l'agent et la valeur de la cellule pass√©e (nous normalisons dans la plage de 0 √† 1). <br></li><li>  2 couches cach√©es de 256 et 128 neurones (on r√©duit la dimension des couches vers la sortie r√©seau). <br></li><li>  1 couche supprimant des neurones al√©atoires pour un r√©seau d'apprentissage durable. <br></li><li>  4 neurones de sortie - la probabilit√© de d√©cider quel c√¥t√© choisir pour l'√©tape suivante. <br></li><li>  Fonction d'activation des neurones: sigmo√Øde.  Optimiseur: adam. <br></li></ul><br>  sigmoid donne 4 probabilit√©s √† la sortie dans la plage de 0 √† 1, en choisissant le maximum, nous obtenons le c√¥t√© pour la prochaine √©tape: [jumpTop, jumpRight, jumpBottom, jumpLeft]. <br><br><h2>  D√©veloppement d'architecture </h2><br>  Le recyclage se produit lors de l'utilisation de mod√®les trop complexes. <br><br>  C'est √† ce moment que le r√©seau a m√©moris√© les donn√©es de formation et pour les nouvelles donn√©es que le r√©seau n'a pas encore vues, cela fonctionnera mal car le r√©seau n'a pas eu besoin de rechercher des g√©n√©ralisations, car il avait suffisamment de m√©moire pour m√©moriser. <br><br>  Manque d'√©ducation - avec des mod√®les insuffisamment complexes.  C'est alors que le r√©seau avait peu de donn√©es d'entra√Ænement pour trouver des g√©n√©ralisations. <br><br>  <b>Conclusion:</b> plus il y a de couches et de neurones, plus il faut de donn√©es pour l'entra√Ænement. <br><br><h2>  Terrain de jeu </h2><br><img src="https://habrastorage.org/webt/3n/we/ck/3nweckh5jsx0-pfebojf_yq3n3k.png"><br><br><h3>  R√®gles du jeu </h3><br>  0 - En entrant dans cette cellule, l'agent est d√©truit. <br>  1..44 - Cellules dont les valeurs augmentent √† chaque √©tape. <br>  Plus l'agent va loin, plus il recevra de r√©compense. <br>  45 - Terminer.  Dans le m√™me temps, la formation ne se produit pas, c'est seulement lorsque tous les agents sont d√©truits, et la ligne d'arriv√©e est une exception qui utilise simplement le r√©seau d√©j√† form√© pour les prochaines pr√©visions d√®s le tout d√©but du labyrinthe. <br><br><h2>  Description des param√®tres </h2><br>  L'agent poss√®de une "antenne" dans quatre directions - elles jouent le r√¥le de l'intelligence environnementale et sont une description des coordonn√©es de l'agent et de la valeur de la cellule sur laquelle il se trouve. <br><br>  La description joue le r√¥le de pr√©dire la prochaine direction pour le mouvement de l'agent.  C'est-√†-dire que l'agent scanne en avant ce qui est suivant et, en cons√©quence, au fil du temps, le r√©seau apprend √† se d√©placer dans le sens d'une augmentation de la valeur de la cellule et √† ne pas d√©passer les limites du mouvement autoris√©. <br><br>  <b>Le but du r√©seau neuronal:</b> obtenir plus de r√©compenses. <br>  <b>Objectif d'apprentissage: pour</b> encourager des actions correctes, plus l'agent est proche de r√©soudre la t√¢che, plus la r√©compense pour le r√©seau neuronal est √©lev√©e. <br><br><h2>  Astuces </h2><br>  Les premi√®res tentatives d'apprentissage sans artifices ont n√©cessit√© plusieurs heures d'entra√Ænement et le r√©sultat √©tait loin d'√™tre complet.  En appliquant certaines techniques, le r√©sultat a √©t√© obtenu en seulement une heure et six minutes! <br><br><h3>  Bouclage d'agent </h3><br>  Pendant la formation, le r√©seau a commenc√© √† prendre des d√©cisions, √† faire des allers-retours - le probl√®me de ¬´l'utilisation¬ª.  Les deux mouvements donnent au r√©seau une r√©compense positive, ce qui a stopp√© le processus d'exploration du labyrinthe et n'a pas permis de sortir du minimum local. <br><br>  La premi√®re tentative de solution a √©t√© de limiter le nombre de mouvements de l'agent, mais ce n'√©tait pas optimal, car l'agent a pass√© beaucoup de temps dans une boucle avant de s'autod√©truire.  La meilleure solution √©tait de d√©truire l'agent s'il se rendait dans la cellule avec une valeur inf√©rieure √† celle sur laquelle il se trouvait - l'interdiction d'aller dans la direction oppos√©e. <br><br><h3>  Recherche ou utilisation </h3><br>  Une simple astuce a √©t√© utilis√©e pour explorer les chemins autour de la position actuelle de l'agent: √† chaque √©tape, 5 agents seront des chercheurs ¬´volontaires¬ª.  Le cours de ces agents sera choisi au hasard et non par la pr√©vision du r√©seau neuronal. <br><br>  Ainsi, nous avons une probabilit√© accrue que l'un des cinq agents avance plus que les autres et aide √† former le r√©seau avec de meilleurs r√©sultats. <br><br><h3>  Algorithme g√©n√©tique </h3><br>  Chaque √©poque, 500 agents participent sur le terrain.  Les pr√©dictions pour tous les agents sont effectu√©es en mode asynchrone pour tous les agents √† la fois, de plus, les calculs sont d√©l√©gu√©s √† gpu.  Ainsi, nous obtenons une utilisation plus efficace de la puissance de calcul de l'ordinateur, ce qui conduit √† une r√©duction du temps pour pr√©dire un r√©seau neuronal pour 500 agents en m√™me temps. <br><br>  La pr√©diction fonctionne plus rapidement que l'entra√Ænement, de sorte que le r√©seau a plus de chances de progresser dans le labyrinthe avec le moins de temps et les meilleurs r√©sultats. <br><br><h3>  Apprendre le meilleur de la g√©n√©ration </h3><br>  Tout au long de l'√®re, pour 500 agents, les r√©sultats de leur progression dans le labyrinthe sont pr√©serv√©s.  Lorsque le dernier agent est d√©truit, les 5 meilleurs agents sur 500 sont s√©lectionn√©s - qui ont atteint le labyrinthe le plus loin. <br><br>  Sur la base des meilleurs r√©sultats de l'√©poque, un r√©seau de neurones sera form√©. <br><br>  Ainsi, nous r√©duirons la quantit√© de m√©moire utilis√©e en ne sauvegardant pas et en ne formant pas le r√©seau sur des agents qui ne font pas avancer le r√©seau. <br><br><h2>  Ach√®vement </h2><br>  N'√©tant pas un sp√©cialiste dans ce domaine, j'ai r√©ussi √† obtenir un certain succ√®s dans la formation du r√©seau neuronal, et vous r√©ussirez - allez-y! <br><br>  Efforcez-vous d'apprendre plus vite que les ordinateurs, pendant que nous faisons mieux. <br><br><h3>  Mat√©riaux </h3><br>  <a href="">R√©f√©rentiel avec code</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lancer la formation sur le navigateur</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La documentation tensorflow.js</a> , o√π vous pouvez √©galement trouver des ressources suppl√©mentaires pour l'apprentissage. <br><br><h3>  Livres </h3><br><ul><li>  Apprentissage profond.  Immersion dans le monde des r√©seaux de neurones <br>  S. Nikolenko, A. Kadurin, E. Arkhangelskaya <br></li><li>  Apprentissage automatique et TensorFlow <br>  N. Shakla <br></li><li>  Syst√®mes d'auto-apprentissage <br>  S. I. Nikolenko, A. L. Tulupyev <br></li><li>  Formation de renforcement <br>  R.S. Sutton, E.G. Barto <br></li><li>  Cartes auto-organis√©es <br>  T. Kohonen <br></li></ul><br><h2>  Merci de votre attention! </h2></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr452612/">https://habr.com/ru/post/fr452612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr452598/index.html">Management d'une √©quipe de programmeurs: comment et comment les motiver correctement? Premi√®re partie</a></li>
<li><a href="../fr452602/index.html">Cisco Hyperflex pour les syst√®mes de gestion de bases de donn√©es √† charge √©lev√©e</a></li>
<li><a href="../fr452606/index.html">UDB. Qu'est-ce que c'est? Partie 8. Adressage UDB</a></li>
<li><a href="../fr452608/index.html">Partie 1. QInst: il vaut mieux perdre une journ√©e, puis voler en cinq minutes (√©crire des instruments est trivial)</a></li>
<li><a href="../fr452610/index.html">Aide et demande pour elle. Article sur la s√©curit√© des informations pour les utilisateurs ordinaires</a></li>
<li><a href="../fr452614/index.html">Comment d√©marrer la programmation dans Adobe Illustrator. Deuxi√®me partie</a></li>
<li><a href="../fr452618/index.html">Ce qui a √©t√© dit sur Google I / O 2019: Android 10, AR-applications et bien plus encore</a></li>
<li><a href="../fr452620/index.html">D√©rivation d'un type d'action √† l'aide de Typescript</a></li>
<li><a href="../fr452622/index.html">Introduction √† la g√©nomique pour les programmeurs</a></li>
<li><a href="../fr452624/index.html">Introduction √† Spring Boot Actuator</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧦 💟 👨🏼‍🔧 O passado, presente e futuro do Docker e outros tempos de execução de contêineres em Kubernetes 🧙🏼 🚏 🈯️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : Já escrevemos mais de uma publicação (consulte os links no final do artigo) sobre tempos de execução do contêiner (tempos de execução do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O passado, presente e futuro do Docker e outros tempos de execução de contêineres em Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/429952/">  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: Já escrevemos mais de uma publicação (consulte os links no final do artigo) sobre tempos de execução do contêiner (tempos de execução do contêiner) - como regra geral, eles são discutidos no contexto do Kubernetes.</i>  <i>No entanto, muitas vezes esses materiais suscitaram perguntas dos leitores, indicando uma falta de entendimento de onde o próximo projeto veio, como ele está conectado com outros e o que está acontecendo em todo esse “zoológico” de contêineres.</i> <br><br><img src="https://habrastorage.org/webt/cy/td/t5/cytdt5jmmufxrtz_b41os56vneg.png"><br><br>  <i>Um artigo recente de Phil Estes, diretor técnico de arquitetura de contêineres e arquitetura Linux da IBM Watson &amp; Cloud Platform, fornece uma excelente retrospectiva sobre como navegar e obter uma compreensão mais ampla de quem perdeu (ou nunca capturou) o encadeamento de eventos.</i>  <i>Sendo um dos mantenedores dos projetos Moby e container, um membro dos comitês técnicos da Open Container Initiative (OCI) e da Moby, e também com o status de Docker Captain, o autor escreve sobre o passado, presente e futuro do novo mundo maravilhoso dos tempos de execução de contêineres.</i>  <i>E para os mais preguiçosos, o material começa com um TL; DR compacto sobre o assunto ...</i> <a name="habracut"></a><br><br><h2>  Principais conclusões </h2><br><ul><li>  Com o tempo, a escolha entre tempos de execução de contêineres aumentou, oferecendo mais opções do que o popular mecanismo Docker. </li><li>  A Open Container Initiative (OCI) padronizou com sucesso o conceito de imagem de contêiner e contêiner para garantir a interoperabilidade <i>(“interoperabilidade” - aprox. Transl.)</i> Entre ambientes de tempo de execução. </li><li>  O Kubernetes adicionou a Interface de Tempo de Execução do Contêiner (CRI), que permite que os contêineres se conectem aos ambientes de tempo de execução com a camada de orquestração subjacente no K8s. </li><li>  As inovações nessa área permitem que os contêineres aproveitem a virtualização leve e outras técnicas exclusivas de isolamento para aumentar os requisitos de segurança. </li><li>  Com o OCI e o CRI, a interoperabilidade e a escolha se tornaram realidade no ecossistema de ambientes de contêiner e orquestração de tempo de execução. </li></ul><br>  A tecnologia de conteinerização existe há algum tempo no mundo dos sistemas operacionais Linux - as primeiras idéias sobre espaços para nome separados para sistemas e processos de arquivos surgiram há mais de uma década.  E em um passado relativamente recente, o LXC apareceu e se tornou a maneira padrão para os usuários do Linux interagirem com a poderosa tecnologia de isolamento escondida no kernel do Linux. <br><br>  No entanto, apesar das tentativas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do LXC de</a> ocultar a complexidade de combinar vários "interiores" tecnológicos do que hoje chamamos de contêiner atualmente, os contêineres continuaram sendo uma espécie de mágica e se tornaram mais fortes apenas no mundo daqueles com conhecimento especial e não obtiveram ampla distribuição entre as massas. <br><br>  Tudo mudou em 2014 com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Docker</a> , quando um novo invólucro de desenvolvedor para a mesma tecnologia de kernel Linux que o LXC tinha em serviço apareceu - afinal, as versões anteriores do Docker “nos bastidores” usavam o LXC e os contêineres se tornaram - um fenômeno de massa real, pois os desenvolvedores estavam imbuídos da simplicidade e das possibilidades de reutilizar imagens de contêineres do Docker e comandos simples para trabalhar com eles. <br><br>  É claro que a Docker não foi a única pessoa que queria ganhar uma participação no mercado de contêineres quando o hype que os acompanhou não pensou em diminuir após o primeiro interesse explosivo em 2014.  Ao longo dos anos, surgiram várias idéias alternativas para ambientes de contêineres executáveis ​​do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CoreOS (rkt)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Intel Clear Containers</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hyper.sh</a> (virtualização leve baseada em contêiner) e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Singularidade</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mudança</a> no mundo da pesquisa em computação de alto desempenho (HPC). <br><br>  O mercado continuou a crescer e amadurecer e, com a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Open Container Initiative (OCI),</a> veio o esforço de padronizar as idéias iniciais promovidas pela Docker.  Atualmente, muitos ambientes executáveis ​​de contêineres já são compatíveis com a OCI ou estão a caminho disso, oferecendo aos fabricantes condições iguais para promover seus recursos e capacidades focados em um aplicativo específico. <br><br><h2>  Popularidade de Kubernetes </h2><br>  O próximo estágio na evolução dos contêineres foi combinar contêineres de computação distribuídos à microsserviços com contêineres - e tudo isso no novo mundo de iterações rápidas de desenvolvimento e implantação (podemos dizer que o DevOps), que estava ganhando impulso ativamente junto com a popularidade do Docker. <br><br>  Embora o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Mesos</a> e outras plataformas de orquestração de software existissem antes do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kubernetes</a> dominar, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">K8s decolou</a> rapidamente de um pequeno projeto de código aberto do Google para o projeto principal da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CNC Native (Cloud Native Computing Foundation)</a> . <br><br>  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: Você sabia que o CNCF <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">apareceu</a> em 2015 por ocasião do lançamento do Kubernetes 1.0?</i>  <i>Ao mesmo tempo, o projeto foi transferido pelo Google para uma nova organização independente que se tornou parte da Linux Foundation.</i> <br><br><img src="https://habrastorage.org/webt/hu/_u/em/hu_uemcx44qdursrnr_nsc04gie.png"><br>  <i>Evento de lançamento do K8s 1.0 patrocinado por, entre outros, Mesosfera, CoreOS, Mirantis, OpenStack, Bitnami</i> <br><img src="https://habrastorage.org/webt/lq/rf/ab/lqrfabydpe9_lbh9zv5x8titb48.png"><br>  <i>Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">notícias</a> sobre o lançamento do Kubernetes 1.0 no ZDNet</i> <br><br>  Mesmo depois que o Docker lançou a plataforma de orquestração rival, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Swarm</a> , incorporada ao Docker e apresentando simplicidade no Docker e foco na configuração padrão de cluster seguro, isso não era mais suficiente para conter o crescente interesse no Kubernetes. <br><br>  No entanto, muitas partes interessadas fora das comunidades nativas da nuvem em rápido crescimento estavam confusas.  Um observador comum não conseguia descobrir o que estava acontecendo: os Kubernetes brigam com o Docker ou com a cooperação deles.  Como o Kubernetes era apenas uma plataforma de orquestração, era necessário um ambiente de contêiner executável que iniciasse diretamente contêineres orquestrados no Kubernetes.  Desde o início, o Kubernetes usou o mecanismo do Docker e, apesar da tensão competitiva entre o Swarm e o Kubernetes, o Docker ainda era o tempo de execução padrão e era necessário para o cluster Kubernetes funcionar. <br><br>  Com um pequeno número de tempos de execução de contêiner além do Docker, parecia claro que o tempo de execução do emparelhamento com o Kubernetes exigiria uma interface especialmente escrita - shim - para cada tempo de execução.  A falta de uma interface clara para implementar os tempos de execução do contêiner dificultava a adição de suporte para novos tempos de execução no Kubernetes. <br><br><h2>  Interface de Tempo de Execução do Contêiner (CRI) </h2><br>  Para resolver a crescente complexidade da implementação de tempos de execução no Kubernetes, a comunidade definiu uma função específica da interface que o tempo de execução do contêiner deveria implementar no Kubernetes - nomeando-a <a href="">Interface de Tempo de Execução do Container (CRI)</a> <i>(que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">apareceu</a> no Kubernetes 1.5 - tradução aproximada).</i> .  Esse evento não apenas ajudou o problema do crescente número de fragmentos da base de código Kubernetes que afetava o uso de tempos de execução do contêiner, mas também ajudou a entender quais funções deveriam ser suportadas por tempos de execução em potencial, se eles quisessem cumprir o CRI. <br><br>  Como você pode imaginar, o CRI espera coisas muito simples do tempo de execução.  Esse ambiente deve poder iniciar e parar pods, manipular todas as operações com contêineres no contexto de pods (iniciar, parar, pausar, eliminar, excluir) e também oferecer suporte ao gerenciamento de imagens de contêineres usando o registro.  Também existem funções auxiliares para coletar logs, métricas etc. <br><br>  Quando novos recursos aparecem no Kubernetes, se eles dependem da camada do tempo de execução do contêiner, essas alterações são feitas na API CRI com versão.  Por sua vez, isso cria uma nova dependência funcional do Kubernetes e requer o lançamento de versões mais recentes dos tempos de execução que suportam novos recursos (um exemplo recente são os espaços de nome de usuário). <br><br><h2>  Cenário atual do CRI </h2><br>  A partir de 2018, existem várias opções para uso como tempos de execução de contêineres no Kubernetes.  Conforme mostrado na ilustração abaixo, uma das opções reais ainda é o Docker, com seu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dockershim</a> que implementa a API do CRI.  De fato, na maioria das instalações do Kubernetes atualmente, é ele, Docker, quem permanece o tempo de execução padrão. <br><br><img src="https://habrastorage.org/webt/p6/9q/0h/p69q0hpabyujabund9bgicx12q4.jpeg"><br><br>  Uma das conseqüências interessantes da tensão entre a estratégia de orquestração do Docker com o Swarm e a comunidade Kubernetes foi um projeto conjunto, que tomou a base do tempo de execução do Docker e reuniu um novo projeto de código aberto desenvolvido em conjunto - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">contemerd</a> .  Com o tempo, o containererd foi transferido para o CNCF, a mesma organização que gerencia e é dona do projeto Kubernetes.  <i>( <b>Nota</b> : traduzimos a aparência de container em mais detalhes em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo separado</a> .)</i> <br><br><img src="https://habrastorage.org/webt/yr/o1/wx/yro1wxcji1jh-xettnzp-jiyiu8.png"><br>  <i>A partir do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">anúncio de</a> containsererd no blog Docker</i> <br><br>  O Containerd, sendo uma implementação simples, básica e <i>independente da</i> empresa <i>(não opinativa)</i> do tempo de execução para o Docker e o Kubernetes (via CRI), começou a ganhar popularidade como um substituto potencial para o Docker em muitas instalações do Kubernetes.  Até o momento, o IBM Cloud e o Google Cloud possuem clusters baseados emerd no modo beta / acesso antecipado.  O Microsoft Azure também prometeu mudar para oerderd no futuro, e a Amazon ainda está considerando várias opções de tempos de execução para suas soluções de contêiner (ECS e EKS), enquanto continua usando o Docker. <br><br>  A Red Hat entrou no espaço de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tempo de execução</a> do contêiner criando uma implementação simples de CRI chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cri-o com</a> base na implementação de referência da OCI, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">runc</a> .  O Docker e oerderd também são baseados em runc, mas os criadores do cri-o afirmam que seus tempos de execução são "apenas o suficiente" para o Kubernetes e não precisam de mais - apenas adicionaram as funções mais necessárias para implementar o Kubernetes CRI sobre o binário básico do runc.  <i>( <b>Observação</b> : escrevemos mais sobre o projeto CRI-O <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste artigo</a> e aqui sobre seu desenvolvimento na forma de podman.)</i> <br><br>  Projetos leves de virtualização: Intel Clear Containers e hyper.sh - apareceram nos bastidores da OpenStack Foundation, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">contêineres Kata</a> e oferecem sua visão de contêineres virtualizados para isolamento adicional usando uma implementação de CRI chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">frakti</a> .  Cri-o e container também funcionam com contêineres Kata, portanto, seu tempo de execução compatível com OCI pode ser selecionado como uma opção conectável. <br><br><h2>  Prevendo o futuro </h2><br>  Dizer que você sabe que o futuro geralmente não é muito sábio, mas podemos pelo menos corrigir algumas tendências emergentes à medida que o ecossistema de contêineres se move do entusiasmo e do hype para um estágio mais maduro da nossa existência. <br><br>  Havia temores iniciais de que o ecossistema de contêineres formaria um ambiente fragmentado, cujos diferentes participantes apresentariam idéias diferentes e incompatíveis sobre o que é um contêiner.  Graças ao trabalho da OCI e às ações responsáveis ​​dos principais fornecedores e participantes, vimos um ambiente saudável no setor entre as ofertas de software que preferiam a compatibilidade com a OCI. <br><br>  Mesmo em ambientes mais recentes, onde o padrão de uso do Docker encontrou menos resistência devido às restrições existentes - por exemplo, no HPC - todas as tentativas de criar ambientes de contêineres não baseados no Docker também chamaram a atenção para o OCI.  Estão em andamento discussões sobre se a OCI pode ser uma solução viável para as necessidades específicas das comunidades de cientistas e pesquisadores. <br><br>  Adicionando a isso a padronização dos tempos de execução do contêiner de plug-in no Kubernetes usando o CRI, podemos imaginar um mundo em que desenvolvedores e administradores podem escolher as ferramentas e pilhas de software certas para suas tarefas, aguardando e observando a interoperabilidade em todo o ecossistema do contêiner. <br><br>  Considere um exemplo específico para entender melhor este mundo: <br><br><ul><li>  Um desenvolvedor com um MacBook usa o Docker para Mac para desenvolver seu aplicativo e até usa o suporte Kubernetes interno (o Docker aqui funciona como tempo de execução CRI) para tentar implantar um novo aplicativo nos pods do K8s. </li><li>  O aplicativo passa pelo CI / CD no software do fornecedor, que usa código runc e especial (gravado pelo fornecedor) para empacotar a imagem OCI e carregá-la no registro corporativo de contêineres para teste. </li><li>  A instalação local do cluster Kubernetes, trabalhando com o container como um tempo de execução CRI, executa um conjunto de testes para o aplicativo. </li><li>  Por alguma razão, essa empresa escolheu os contêineres Kata para determinadas cargas de trabalho na produção; portanto, quando você implanta o aplicativo, ele inicia nos pods com o container configurado para usar os contêineres Kata como tempo de execução em vez de runc. </li></ul><br>  Todo o cenário descrito funciona maravilhosamente devido à compatibilidade com a especificação OCI para ambientes e imagens de tempo de execução e o fato de o CRI fornecer flexibilidade na escolha do tempo de execução. <br><br>  Essa possível flexibilidade e escolha tornam o ecossistema de contêineres verdadeiramente notável e também é uma condição muito importante para a maturidade da indústria, que cresce tão rapidamente desde 2014.  No limiar de 2019 e nos anos seguintes, vejo um futuro brilhante com inovações e flexibilidade contínuas para quem usa e cria plataformas baseadas em contêineres. <br><br>  Mais informações sobre esse tópico podem ser encontradas em uma recente conversa de Phil Estes no QCon NY: “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Mergulho profundo</a> nos tempos de execução do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CRI: quem está executando meu pod de Kubernetes!?</a>  " <br><br><h2>  PS do tradutor </h2><br>  Leia também em nosso blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Red Hat substitui o Docker pelo Podman</a> "; </li><li>  “A <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">integração do container com o Kubernetes, substituindo o Docker, está pronta para produção</a> ”; </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CRI-O - uma alternativa ao Docker para lançamento de contêineres no Kubernetes</a> ”; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O que e por que o Docker está fazendo o Moby para se integrar ao Kubernetes?"</a>  " </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Então, o que é um pod em Kubernetes?</a>  " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt429952/">https://habr.com/ru/post/pt429952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt429940/index.html">Por que as plantas precisam de aprendizado de máquina</a></li>
<li><a href="../pt429942/index.html">Obter música VK através de uma API de terceiros</a></li>
<li><a href="../pt429946/index.html">Loucura e sucesso do código do banco de dados Oracle</a></li>
<li><a href="../pt429948/index.html">Por que os gerentes de produto da fintech são necessários</a></li>
<li><a href="../pt429950/index.html">Como manter hábitos saudáveis ​​de comunicação de equipes remotas</a></li>
<li><a href="../pt429954/index.html">O programador das casas de apostas irlandesas</a></li>
<li><a href="../pt429956/index.html">Integração contínua no Yandex. Parte 2</a></li>
<li><a href="../pt429958/index.html">Cinco regras de depuração fáceis para iniciantes</a></li>
<li><a href="../pt429960/index.html">10 razões pelas quais os clientes estão cancelando a assinatura de um produto</a></li>
<li><a href="../pt429964/index.html">U> X> I> P ... ou "Como os nomes das profissões se destacam"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê£ üë∞üèº üí£ Restauration de photos bas√©e sur l'IA üîü üë∏üèæ üçã</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut tout le monde! Je suis ing√©nieur de recherche au sein de l'√©quipe de vision par ordinateur du groupe Mail.ru. Dans cet article, je vais raconter...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Restauration de photos bas√©e sur l'IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/459696/"><img src="https://habrastorage.org/webt/ya/mt/mm/yamtmmcino7skf3gyqzpsrgqla4.jpeg"><br><br>  Salut tout le monde!  Je suis ing√©nieur de recherche au sein de l'√©quipe de vision par ordinateur du groupe Mail.ru.  Dans cet article, je vais raconter comment nous avons cr√©√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet de restauration de photos bas√© sur l'IA</a> pour de vieilles photos militaires.  Qu'est-ce que la ¬´restauration photo¬ª?  Il se compose de trois √©tapes: <br><br><ul><li>  on retrouve tous les d√©fauts d'image: fractures, √©raflures, trous; <br></li><li>  nous peignons les d√©fauts d√©couverts, sur la base des valeurs de pixels qui les entourent; <br></li><li>  on colorise l'image. <br></li></ul><br>  De plus, je d√©crirai chaque √©tape de la restauration de photos et vous dirai comment nous avons obtenu nos donn√©es, quels r√©seaux nous avons form√©s, ce que nous avons accompli et quelles erreurs nous avons commises. <br><a name="habracut"></a><br><h1>  Recherche de d√©fauts </h1><br>  Nous voulons trouver tous les pixels li√©s aux d√©fauts dans une photo t√©l√©charg√©e.  Tout d'abord, nous devons d√©terminer quel type de photos les gens vont t√©l√©charger.  Nous avons discut√© avec les fondateurs du projet "Immortal Regiment", une organisation non commerciale stockant les anciennes photos de la Seconde Guerre mondiale, qui ont partag√© leurs donn√©es avec nous.  En l'analysant, nous avons remarqu√© que les gens t√©l√©chargent principalement des portraits individuels ou de groupe avec un nombre moyen √† √©lev√© de d√©fauts. <br><br>  Ensuite, nous avons d√ª rassembler un ensemble de formation.  L'ensemble de formation pour une t√¢che de segmentation est une image et un masque o√π tous les d√©fauts sont marqu√©s.  La fa√ßon la plus simple de le faire est de laisser les √©valuateurs cr√©er les masques de segmentation.  Bien s√ªr, les gens savent tr√®s bien comment trouver les d√©fauts, mais cela prendrait trop de temps. <br><br><img src="https://habrastorage.org/webt/yg/6y/iu/yg6yiue75v7msnxyffapttyugs8.jpeg"><br><br>  Cela peut prendre une heure ou toute la journ√©e de travail pour marquer les pixels d√©fectueux sur une photo.  Par cons√©quent, il n'est pas facile de collecter un ensemble de formation de plus de 100 images en quelques semaines.  C'est pourquoi nous avons essay√© d'augmenter nos donn√©es et de cr√©er nos propres d√©fauts: nous prenions une bonne photo, ajoutions des d√©fauts en utilisant des marches al√©atoires sur l'image et nous retrouvions avec un masque montrant les parties de l'image avec les d√©fauts.  Sans augmentations, nous avons 68 photos √©tiquet√©es manuellement dans l'ensemble de formation et 11 photos dans l'ensemble de validation. <br><br>  L'approche de segmentation la plus populaire: prenez Unet avec un encodeur pr√©-form√© et minimisez la somme de BCE ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">entropie crois√©e binaire</a> ) et DICE ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">S√∏rensen - Coefficient de d√©s</a> ). <br><br>  Quels probl√®mes surviennent lorsque nous utilisons cette approche de segmentation pour notre t√¢che? <br><br><ul><li>  M√™me s'il semble qu'il y ait des tonnes de d√©fauts sur la photo, qu'elle soit tr√®s ancienne et minable, la zone avec des d√©fauts est encore beaucoup plus petite que celle en bon √©tat.  Pour r√©soudre ce probl√®me, nous pouvons augmenter le poids de classe positif dans BCE;  un poids optimal serait le rapport des pixels propres aux pixels d√©fectueux. <br></li><li>  Le deuxi√®me probl√®me est que si nous utilisons un Unet pr√™t √† l'emploi avec un encodeur pr√©-form√© (Albunet-18, par exemple), nous perdons beaucoup de donn√©es de position.  La premi√®re couche d'Albunet-18 consiste en une convolution avec un noyau 5 et une foul√©e √©gale √† deux.  Il permet au filet de fonctionner rapidement.  Nous avons √©chang√© le temps de fonctionnement net pour avoir une meilleure localisation des d√©fauts: nous avons supprim√© le regroupement maximal apr√®s la premi√®re couche, diminu√© la foul√©e √† 1 et diminu√© le noyau de convolution √† 3. <br></li><li> Si nous travaillons avec de petites images en les compressant, par exemple, en 256 x 256 ou 512 x 512 pixels, les petits d√©fauts dispara√Ætront en raison de l'interpolation.  Par cons√©quent, nous devons travailler avec des images plus grandes.  Nous segmentons actuellement les d√©fauts en photos 1024 x 1024 en production.  C'est pourquoi nous avons d√ª former le filet aux cultures √† grande image.  Cependant, cela provoque des probl√®mes avec une petite taille de lot sur un seul GPU. <br></li><li>  Pendant la formation, nous pouvons adapter environ 20 images sur un GPU.  Pour cette raison, nous nous retrouvons avec des valeurs moyennes et d'√©cart type inexactes dans les couches BatchNorm.  Nous pouvons r√©soudre ce probl√®me en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BatchNorm sur place</a> , qui, d'une part, √©conomise de l'espace m√©moire, et d'autre part, a une version BatchNorm synchronis√©e, qui synchronise les statistiques sur tous les GPU.  Maintenant, nous calculons les valeurs moyenne et √©cart type non pas pour 20 images sur un seul GPU, mais pour 80 images √† partir de 4 GPU.  Cela am√©liore la convergence nette. <br></li></ul><br>  Enfin, en augmentant le poids de BCE, en changeant d'architecture et en utilisant BatchNorm sur place, nous avons am√©lior√© la segmentation.  Cependant, il ne co√ªterait pas trop cher de faire quelque chose d'encore mieux en ajoutant l'augmentation de la dur√©e du test.  Nous pouvons ex√©cuter le net une fois sur une image d'entr√©e, puis la mettre en miroir et r√©ex√©cuter le net pour trouver tous les petits d√©fauts. <br><br><img src="https://habrastorage.org/webt/3c/vj/g0/3cvjg04qc_nqsl8lop44jvtjfym.jpeg"><br><br>  Le net converge en 18 heures sur quatre GeForce 1080Ti.  L'inf√©rence prend 290 ms.  C'est assez long, mais c'est le prix de nos performances sup√©rieures √† celles par d√©faut.  Validation DICE est √©gal √† 0,35 et ROCAUC - 0,93. <br><br><h1>  Inpainting d'image </h1><br>  M√™me chose avec la t√¢che de segmentation que nous avons utilis√©e Unet.  Pour faire de la peinture, nous t√©l√©chargions une image originale et un masque o√π nous avons marqu√© toute la zone propre avec des uns et avec des z√©ros - tous les pixels que nous voulons peindre.  C'est ainsi que nous collections des donn√©es: pour toute photo d'un jeu de donn√©es d'images open-source, par exemple, OpenImagesV4, nous ajoutons les d√©fauts similaires √† ceux que nous voyons dans la vie r√©elle.  Ensuite, nous avions form√© le filet pour restaurer les pi√®ces manquantes. <br><br>  Comment pouvons-nous modifier Unet pour cette t√¢che? <br><br>  Nous pouvons utiliser une convolution partielle au lieu d'une convolution originale.  L'id√©e est que lorsque nous convolutons une zone avec un noyau, nous ne prenons pas en compte les valeurs des pixels d√©fectueux.  Cela rend la peinture plus pr√©cise.  Nous vous montrons un exemple du r√©cent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article NVIDIA</a> .  Ils ont utilis√© Unet avec une convolution bidimensionnelle par d√©faut dans l'image du milieu et une convolution partielle - dans l'image de droite. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ec1/5ba/bdb/ec15babdbf1cd219be4a5e3ffa4ae50f.jpg"><br><br>  Nous avons form√© le filet pendant cinq jours.  Le dernier jour, nous avons gel√© BatchNorms pour rendre les bords de la partie peinte moins visibles. <br><br>  Il faut 50 ms pour traiter une image 512 x 512.  La validation PSNR est √©gale √† 26,4.  Cependant, vous ne pouvez pas totalement compter sur les m√©triques dans cette t√¢che.  Pour choisir le meilleur mod√®le, nous avons ex√©cut√© plusieurs bons mod√®les sur des images d'√©valuation, anonymis√© les r√©sultats, puis vot√© pour ceux que nous aimions le plus.  C'est ainsi que nous avons choisi notre mod√®le final. <br><br>  J'ai mentionn√© plus t√¥t que nous avons artificiellement ajout√© des d√©fauts aux images propres.  Vous devez toujours suivre la taille maximale des d√©fauts ajout√©s pendant la formation;  dans le cas o√π vous introduisez une image avec un tr√®s gros d√©faut dans le filet qui n'est jamais trait√© au stade de l'entra√Ænement, le filet fonctionnera de mani√®re sauvage et produira un r√©sultat inapplicable.  Par cons√©quent, si vous devez corriger de gros d√©fauts, augmentez votre ensemble d'entra√Ænement avec eux. <br><br>  Voici l'exemple du fonctionnement de notre algorithme: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c48/2cd/253/c482cd253865ee12a834475a2e30d619.jpg"><br><br><h1>  Colorisation </h1><br>  Nous avons segment√© les d√©fauts et les avons peints;  la troisi√®me √©tape - la reconstruction des couleurs.  Comme je l'ai d√©j√† dit, il y a beaucoup de portraits individuels et de groupe parmi les photos du r√©giment immortel.  Nous voulions que notre filet fonctionne bien avec eux.  Nous avons d√©cid√© de proposer notre propre colorisation car aucun des services existants ne pouvait colorer les portraits rapidement et efficacement.  Nous voulons que nos photos coloris√©es soient plus cr√©dibles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cec/b9a/b6c/cecb9ab6c8e1b76b567f49eac1261957.jpg"><br><br>  GitHub a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rentiel</a> populaire pour la colorisation des photos.  Il fait du bon travail mais a encore quelques probl√®mes.  Par exemple, il a tendance √† peindre les v√™tements en bleu.  C'est pourquoi nous l'avons √©galement rejet√©. <br><br>  Nous avons donc d√©cid√© de cr√©er un algorithme de colorisation de l'image.  L'id√©e la plus √©vidente: prendre une image en noir et blanc et pr√©voir trois canaux: rouge, vert et bleu.  Cependant, nous pouvons faciliter notre travail: travailler non pas avec la repr√©sentation des couleurs RVB, mais avec la repr√©sentation des couleurs YCbCr.  La composante Y est la luminosit√© (luma).  Une image t√©l√©charg√©e en noir et blanc est la cha√Æne Y, et nous allons la r√©utiliser.  Maintenant, nous devons pr√©dire Cb et Cr: Cb est la diff√©rence de couleur bleue et de luminosit√© et Cr - la diff√©rence de couleur rouge et de luminosit√©. <br><br><img src="https://habrastorage.org/webt/yo/au/zi/yoauzi06k3bd0uyod2rjnpxgvms.jpeg"><br><br>  Pourquoi avons-nous choisi la repr√©sentation YCbCr?  Un ≈ìil humain est plus sensible aux changements de luminosit√© qu'aux changements de couleur.  C'est pourquoi nous r√©utilisons la composante Y (luminosit√©) avec laquelle l'≈ìil humain est le plus sensible et pr√©disons le Cb et le Cr avec lesquels nous pourrions faire une erreur car nous ne pouvons pas tr√®s bien remarquer la fausset√© des couleurs.  Cette caract√©ristique sp√©cifique a √©t√© largement utilis√©e √† l'aube de la t√©l√©vision couleur lorsque la capacit√© des canaux n'√©tait pas suffisante pour transmettre toutes les couleurs.  L'image a √©t√© transmise en YCbCr, inchang√©e √† la composante Y, et Cb et Cr ont √©t√© r√©duits de moiti√©. <br><br><h1>  Comment cr√©er une ligne de base </h1><br>  Nous pouvons prendre Unet avec un encodeur pr√©-form√© et minimiser la perte L1 entre les valeurs CbCr existantes et celles pr√©dites.  Nous voulons colorer les portraits et, par cons√©quent, en plus des photos OpenImages, nous avons besoin de photos plus sp√©cifiques √† la t√¢che. <br><br>  O√π peut-on obtenir des photos coloris√©es de personnes v√™tues d'un uniforme militaire?  Il y a des gens sur Internet qui colorisent les vieilles photos comme passe-temps ou pour un prix.  Ils le font tr√®s soigneusement, essayant d'√™tre tr√®s pr√©cis.  Lorsqu'ils colorent un uniforme, des √©paulettes et des m√©dailles, ils se r√©f√®rent aux documents d'archives, de sorte que les r√©sultats de leur travail sont dignes de confiance.  Dans l'ensemble, nous avons utilis√© 200 photos coloris√©es manuellement avec des personnes en uniforme militaire. <br><br>  L'autre source de donn√©es utiles est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le</a> site Web de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Arm√©e rouge des travailleurs et des paysans</a> .  L'un de ses fondateurs s'est fait photographier dans presque tous les uniformes sovi√©tiques de la Seconde Guerre mondiale disponibles. <br><br><img src="https://habrastorage.org/webt/yh/b7/u7/yhb7u74fa3feihqo0k-jpqcyxgk.jpeg"><br><br>  Dans certaines photos, il a imit√© les poses de personnes √† partir des c√©l√®bres photos d'archives.  C'est une bonne chose que ses images aient un fond blanc: cela nous a permis d'augmenter tr√®s bien les donn√©es en ajoutant divers objets naturels en arri√®re-plan.  Nous avons √©galement utilis√© des portraits r√©guliers, en les compl√©tant d'insignes et d'autres attributs de guerre. <br><br>  Nous avons form√© AlbuNet-50 - c'est un Unet qui utilise ResNet-50 pr√©-form√© comme encodeur.  Le filet a commenc√© √† donner des r√©sultats satisfaisants: la peau √©tait rose, les yeux - gris-bleu, les planches d'√©paule - jaun√¢tres.  Cependant, le probl√®me est qu'il laisse certaines zones de la photo intactes.  Cela √©tait d√ª au fait que, selon l'erreur L1, trouver un tel optimum o√π il vaut mieux ne rien faire que d'essayer de pr√©dire une certaine couleur. <br><br><img src="https://habrastorage.org/webt/ov/zh/bn/ovzhbnv-6ch0nnoa4fdbh3nygym.jpeg"><br>  <i>Nous comparons notre r√©sultat avec une photo de Ground Truth - une colorisation manuelle r√©alis√©e par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Klimbim</a></i> <br><br>  Comment pouvons-nous r√©soudre ce probl√®me?  Nous avons besoin d'un discriminateur: un r√©seau neuronal qui recevrait une image et nous dirait si elle a l'air r√©aliste ou non.  L'une des images ci-dessous est color√©e manuellement et l'autre - par notre g√©n√©rateur, AlbuNet-50.  Comment l'homme distingue-t-il les photos color√©es manuellement et automatiquement?  En regardant les d√©tails.  Pouvez-vous dire o√π se trouve la photo coloris√©e automatiquement par notre solution de base? <br><br><img src="https://habrastorage.org/webt/fk/er/n_/fkern_az5kgkgr2kwamcoxr_gtg.jpeg"><br><br><div class="spoiler">  <b class="spoiler_title">R√©pondre</b> <div class="spoiler_text">  l'image √† gauche est color√©e manuellement, √† droite - automatiquement. </div></div><br>  Nous utilisons le discriminateur du document <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Self-Attention GAN</a> .  C'est un petit filet de convolution avec soi-disant auto-attention int√©gr√© dans les couches sup√©rieures.  Cela nous permet de "faire plus attention" aux d√©tails de l'image.  Nous utilisons √©galement la normalisation spectrale.  Vous pouvez trouver plus d'informations dans le document susmentionn√©.  Nous avons form√© le filet avec une combinaison de perte L1 et de perte du discriminateur.  Maintenant, le net colore mieux les d√©tails de l'image et l'arri√®re-plan semble plus coh√©rent.  Un autre exemple: √† gauche, le travail par filet entra√Æn√© avec perte L1 uniquement;  √† droite - avec une combinaison de pertes de discriminateur L1. <br><br><img src="https://habrastorage.org/webt/nd/3p/91/nd3p91aw1mzzoidhra1egef3zki.jpeg"><br><br>  Le processus de formation a pris deux jours sur quatre GeForce 1080Ti.  Il faut 30 ms pour traiter une image 512 x 512.  Validation MSE - 34.4.  Tout comme avec l'inpainting, les m√©triques sur lesquelles vous ne voulez pas vous fier.  C'est pourquoi nous avons choisi six mod√®les avec les meilleures m√©triques de validation et vot√© aveugl√©ment pour le meilleur mod√®le. <br><br>  Lorsque nous avons d√©j√† cr√©√© un syst√®me de production et lanc√© un site Web, nous avons poursuivi nos exp√©rimentations et conclu que nous devions mieux minimiser non pas la perte L1 par pixel, mais la perte perceptuelle.  Pour le calculer, nous alimentons les pr√©visions du net et une photo au sol au VGG-16 net, prenons les cartes d'entit√©s sur les couches inf√©rieures et les comparons avec MSE.  Cette approche peint plus de zones et donne des r√©sultats plus color√©s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/676/9c8/b64/6769c8b64fdf00cb66dcd73edcd39e81.jpg"><br><br><h1>  R√©capitulatif </h1><br>  Unet est un mod√®le assez cool.  Lors de la premi√®re t√¢che de segmentation, nous avons rencontr√© un probl√®me pendant la formation et travaillons avec des images haute r√©solution et c'est pourquoi nous utilisons In-Place BatchNorm.  Lors de notre deuxi√®me t√¢che (Inpainting), nous avons utilis√© la convolution partielle au lieu d'une convolution par d√©faut, et cela nous a permis d'obtenir de meilleurs r√©sultats.  Lorsque nous travaillions sur la colorisation, nous avons ajout√© un petit filet de discrimination qui p√©nalisait le g√©n√©rateur pour des images irr√©alistes.  Nous avons √©galement utilis√© une perte de perception. <br><br>  Deuxi√®me conclusion - les √©valuateurs sont essentiels.  Et pas seulement lors de la cr√©ation des masques de segmentation mais aussi pour la validation du r√©sultat final.  En fin de compte, nous donnons √† l'utilisateur trois photos: une image originale avec des d√©fauts peints, une photo coloris√©e avec des d√©fauts peints et une photo simplement coloris√©e au cas o√π l'algorithme de recherche de d√©fauts et de peinture se serait tromp√©. <br><br>  Nous avons pris quelques photos du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet War Album</a> et les avons trait√©es sur ces neuronets.  Voici les r√©sultats que nous avons obtenus: <br><br><img src="https://habrastorage.org/webt/rm/4z/sb/rm4zsbvc0j_h_r2nobp4xj2p4ei.jpeg"><br><br>  De plus, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici,</a> vous pouvez regarder de plus pr√®s les images originales et toutes les √©tapes de traitement. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr459696/">https://habr.com/ru/post/fr459696/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr459682/index.html">Qualit√© des donn√©es en stockage</a></li>
<li><a href="../fr459684/index.html">Carte du m√©tro de Moscou et du monde entier pour Android</a></li>
<li><a href="../fr459688/index.html">L'urbanisme en Chine: moins de hipsters, plus de science et d'informatique</a></li>
<li><a href="../fr459692/index.html">Comment nous avons d√©couvert des modifications mat√©rielles qui contredisent les principes chimiques √©tablis</a></li>
<li><a href="../fr459694/index.html">Museum DataArt. D√©ballez et lancez Radio 86RK</a></li>
<li><a href="../fr459698/index.html">Comment forcer Oracle BI 12c √† cr√©er autant de variables de session qu'un programmeur en a besoin?</a></li>
<li><a href="../fr459704/index.html">LLVM IR and Go</a></li>
<li><a href="../fr459706/index.html">5 raisons pour lesquelles vous devriez oublier Redux dans les applications React</a></li>
<li><a href="../fr459708/index.html">Conception de l'interface de jeu. Brent Fox De quoi parle le livre?</a></li>
<li><a href="../fr459710/index.html">Survivre √† une collision frontale et pourquoi l'amn√©sie n'est pas ce que vous pensez</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
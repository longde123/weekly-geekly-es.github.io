<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üà≥ üëÜüèø üè¶ Comment surmonter l'incompatibilit√© lors de la migration des donn√©es de Greenplum 4 vers Greenplum 5 üôÇ üö¢ üò¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lorsque nous avons choisi un outil pour traiter les m√©gadonn√©es, nous avons envisag√© diff√©rentes options - √† la fois propri√©taires et open source. Nou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment surmonter l'incompatibilit√© lors de la migration des donn√©es de Greenplum 4 vers Greenplum 5</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/439876/">  Lorsque nous avons choisi un outil pour traiter les m√©gadonn√©es, nous avons envisag√© diff√©rentes options - √† la fois propri√©taires et open source.  Nous avons √©valu√© les possibilit√©s d'adaptation rapide, d'accessibilit√© et de flexibilit√© des technologies.  Y compris la migration entre les versions.  En cons√©quence, nous avons choisi la solution open source Greenplum, qui r√©pondait le mieux √† nos exigences, mais n√©cessitait la solution d'un probl√®me important. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ff/69c/0d9/9ff69c0d9031f0afb897244dd0778e9e.png"><br><br>  Le fait est que les versions 4 et 5 des fichiers de base de donn√©es Greenplum ne sont pas compatibles entre elles, et qu'une simple mise √† niveau d'une version √† l'autre est donc impossible.  La migration des donn√©es ne peut se faire que par t√©l√©chargement et t√©l√©chargement de donn√©es.  Dans cet article, je parlerai des options possibles pour cette migration. <br><a name="habracut"></a><br><h2>  √âvaluation des options de migration </h2><br><h3>  pg_dump &amp; psql (ou pg_restore) </h3><br>  C'est trop lent quand il s'agit de dizaines de t√©raoctets, car toutes les donn√©es sont t√©l√©charg√©es et t√©l√©charg√©es via les n≈ìuds ma√Ætres.  Mais assez rapide pour migrer DDL et de petites tables.  Vous pouvez t√©l√©charger les deux dans un fichier et ex√©cuter pg_dump et psql en m√™me temps via un canal sur un cluster source et un cluster de destination.  pg_dump t√©l√©charge simplement vers un fichier unique contenant √† la fois les commandes DDL et les commandes de donn√©es COPY.  Les donn√©es obtenues peuvent √™tre trait√©es de mani√®re pratique, comme indiqu√© ci-dessous. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/482/f47/cd8/482f47cd86df49125689c5360b6d060e.png"><br><br><h3>  gptransfer </h3><br>  N√©cessite la version Greenplum 4.2 ou ult√©rieure.  Il est n√©cessaire que le cluster source et le cluster de destination fonctionnent simultan√©ment.  Le moyen le plus rapide de migrer de grandes tables de donn√©es pour la version open source.  Mais cette m√©thode est tr√®s lente pour transf√©rer des tables vides et petites en raison de la surcharge √©lev√©e. <br><br>  gptransfer utilise pg_dump pour transf√©rer DDL et gpfdist pour transf√©rer des donn√©es.  Le nombre de segments principaux sur le cluster de destination ne doit pas √™tre inf√©rieur au segment h√¥te sur le cluster source.  Il est important de prendre en compte lors de la cr√©ation de clusters ¬´sandbox¬ª, si les donn√©es des clusters principaux leur seront transf√©r√©es et que l'utilisation de l'utilitaire gptransfer est pr√©vue.  M√™me si les h√¥tes de segment sont peu nombreux, vous pouvez d√©ployer le nombre requis de segments sur chacun d'eux.  Le nombre de segments sur le cluster de destination peut √™tre inf√©rieur √† celui sur le cluster source, mais cela <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">affectera n√©gativement</a> la vitesse de transfert des donn√©es.  Entre les clusters, l'authentification ssh sur les certificats doit √™tre configur√©e. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/84b/a0a/f53/84ba0af53e82d2a4e861fe19c6f9be9a.png"><br><br>  Il s'agit du sch√©ma du mode rapide lorsque le nombre de segments sur le cluster de destination est sup√©rieur ou √©gal au nombre sur le cluster source.  Le lancement de l'utilitaire lui-m√™me est illustr√© dans le diagramme sur le n≈ìud ma√Ætre du cluster r√©cepteur.  Dans ce mode, une table d'√©criture externe est cr√©√©e sur le cluster source, qui √©crit des donn√©es sur chaque segment dans le canal nomm√©.  La commande INSERT INTO writable_external_table SELECT * FROM source_table est ex√©cut√©e.  Les donn√©es du canal nomm√© sont lues par gpfdist.  Une table externe est √©galement cr√©√©e sur le cluster de destination, uniquement pour la lecture.  Le tableau indique les donn√©es fournies par gpfdist via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le protocole du m√™me nom</a> .  La commande INSERT INTO target_table SELECT * FROM external_gpfdist_table est ex√©cut√©e.  Les donn√©es sont automatiquement redistribu√©es entre les segments du cluster de destination. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/13f/b61/cfb/13fb61cfba946fbea0649c1df1cbf28c.png"><br><br>  Et c'est le sch√©ma du mode lent, ou, comme le dit gptransfer lui-m√™me, le mode standard.  La principale diff√©rence est que sur chaque segment-h√¥te du cluster source, une paire gpfdist est lanc√©e pour tous les segments de ce segment-h√¥te.  Une table d'enregistrement externe fait r√©f√©rence √† gpfdist agissant comme un r√©cepteur de donn√©es.  De plus, si plusieurs valeurs sont indiqu√©es pour l'√©criture dans le param√®tre LOCATION de la table externe, alors les segments sont distribu√©s uniform√©ment par gpfdist lors de l'√©criture des donn√©es.  Les donn√©es entre gpfdist sur le segment h√¥te sont transmises via le canal nomm√©.  Pour cette raison, la vitesse de transfert de donn√©es est inf√©rieure, mais elle s'av√®re toujours plus rapide que lors du transfert de donn√©es uniquement via le n≈ìud ma√Ætre. <br><br>  Lors de la migration des donn√©es de Greenplum 4 vers Greenplum 5, gptransfer doit √™tre ex√©cut√© sur le n≈ìud ma√Ætre du cluster de destination.  Si nous ex√©cutons gptransfer sur le cluster source, nous obtenons l'erreur de l'absence du champ <code>san_mounts</code> dans la table <code>pg_catalog.gp_segment_configuration</code> : <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Validating options... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190109:12:46:14:010893 gptransfer:gpdb-source-master.local:gpadmin-[CRITICAL]:-gptransfer failed. (Reason='error 'ERROR: column "san_mounts" does not exist LINE 2: ... SELECT dbid, content, status, unnest(san_mounts... ^ ' in ' SELECT dbid, content, status, unnest(san_mounts) FROM pg_catalog.gp_segment_configuration WHERE content &gt;= 0 ORDER BY content, dbid '') exiting...</code> </pre> <br>  Vous devez √©galement v√©rifier les variables GPHOME afin qu'elles correspondent entre le cluster source et le cluster de destination.  Sinon, nous obtenons une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">erreur</a> assez √©trange (l'utilitaire gptransfer √©choue lorsque la source et la cible ont un chemin GPHOME diff√©rent). <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --source-host=gpdb-spurce-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[ERROR]:-gptransfer: error: GPHOME directory does not exist on gpdb-source-master.local</code> </pre> <br>  Vous pouvez simplement cr√©er le lien symbolique correspondant et remplacer la variable GPHOME dans la session dans laquelle gptransfer est d√©marr√©. <br><br>  Lorsque gptransfer est d√©marr√© sur le cluster de destination, l'option ¬´--source-map-file¬ª doit pointer vers un fichier contenant une liste d'h√¥tes et leurs adresses IP avec les segments principaux du cluster source.  Par exemple: <br><br><pre> <code class="plaintext hljs">sdw1,192.0.2.1 sdw2,192.0.2.2 sdw3,192.0.2.3 sdw4,192.0.2.4</code> </pre> <br>  Avec l'option ¬´--full¬ª, il est possible de transf√©rer non seulement des tables, mais la base de donn√©es enti√®re, cependant, les bases de donn√©es utilisateur ne doivent pas √™tre cr√©√©es sur le cluster de destination.  Vous devez √©galement vous rappeler qu'il y a des probl√®mes dus aux changements de syntaxe lors du d√©placement de tables externes. <br><br>  √âvaluons la surcharge suppl√©mentaire, par exemple, en copiant 10 tables vides (tables de big_db.public.test_table_2 √† big_db.public.test_table_11) √† l'aide de gptarnsfer: <br><br><pre> <code class="plaintext hljs">gptransfer -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-ba tch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-batch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190118:06:14:09:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving source tables... 20190118:06:14:12:031521 gptransfer:mdw:gpadmin-[INFO]:-Checking for gptransfer schemas... 20190118:06:14:22:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving list of destination tables... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Reading source host map file... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Building list of source tables to transfer... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Number of tables to transfer: 10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-gptransfer will use "standard" mode for transfer. 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating source host map... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating transfer table set... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-The following tables on the destination system will be truncated: 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_2 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_3 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_4 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_5 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_6 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_7 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_8 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_9 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_11 ‚Ä¶ 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using batch size of 10 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using sub-batch size of 16 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating work directory '/home/gpadmin/gptransfer_31521' 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating schema public in database edw_prod... 20190118:06:14:40:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting transfer of big_db.public.test_table_5 to big_db.public.test_table_5... ‚Ä¶ 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Validation of big_db.public.test_table_4 successful 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Removing work directories... 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Finished.</code> </pre> <br>  En cons√©quence, le transfert de 10 tables vides a pris environ 16 secondes (14: 40-15: 02), c'est-√†-dire une table - 1,6 secondes.  Pendant ce temps, dans notre cas, environ 100 Mo de donn√©es peuvent √™tre t√©l√©charg√©es √† l'aide de pg_dump &amp; psql. <br><br><h3>  gp_dump &amp; gp_restore </h3><br>  En option: utilisez des modules compl√©mentaires sur eux, gpcrondump &amp; gpdbrestore, car gp_dump &amp; gp_restore sont d√©clar√©s obsol√®tes.  Bien que gpcrondump &amp; gpdbrestore utilisent eux-m√™mes gp_dump &amp; gp_restore dans le processus.  C'est le moyen le plus universel, mais pas le plus rapide.  Les fichiers de sauvegarde cr√©√©s avec gp_dump repr√©sentent un ensemble de commandes DDL sur le n≈ìud ma√Ætre et sur les segments principaux, principalement des ensembles de commandes et de donn√©es COPY.  Convient aux cas o√π il n'est pas possible de fournir un fonctionnement simultan√© du cluster de destination et du cluster source.  Il existe √† la fois dans les anciennes versions de Greenplum et dans les nouvelles: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gp_dump</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gp_restore</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/141/1b7/8e8/1411b78e893176ef21de383e78c0b87f.png"><br><br><h3>  Utilitaires gpbackup et gprestore </h3><br>  Cr√©√© en remplacement de gp_dump &amp; gp_restore.  Pour leur travail, la version minimale 4.3.17 de Greenplum est requise ( <a href="">const MINIMUM_GPDB4_VERSION = "4.3.17"</a> ).  Le sch√©ma de travail est similaire √† gpbackup &amp; gprestore, tandis que la vitesse de travail est beaucoup plus rapide.  Le moyen le plus rapide d'obtenir des commandes DDL pour de grandes bases de donn√©es.  Par d√©faut, il transf√®re les objets globaux, pour la r√©cup√©ration, vous devez sp√©cifier "gprestore --with-globals".  Le param√®tre facultatif ¬´--jobs¬ª peut d√©finir le nombre de travaux (et de sessions dans la base de donn√©es) lors de la cr√©ation d'une sauvegarde.  √âtant donn√© que plusieurs sessions sont cr√©√©es, il est important de garantir la coh√©rence des donn√©es jusqu'√† ce que tous les verrous soient re√ßus.  Il existe √©galement une option utile ¬´--with-stats¬ª, qui vous permet de transf√©rer des statistiques sur les objets utilis√©s pour construire des plans d'ex√©cution.  Plus d'informations <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><h3>  Utilitaire Gpcopy </h3><br>  Pour copier des bases de donn√©es, il existe un utilitaire gpcopy - un remplacement de gptansfer.  Mais il n'est inclus que dans la version propri√©taire de Greenplum de Pivotal, √† partir de 4.3.26 - dans la version open source, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet utilitaire ne le fait pas</a> .  Lorsque vous travaillez sur le cluster source, la commande COPIER source_table POUR PROGRAMMER 'gpcopy_helper ...' SUR SEGMENT CSV IGNORE EXTERNAL PARTITIONS est ex√©cut√©e.  Du c√¥t√© du cluster r√©cepteur, une table externe temporaire CREATE EXTERNAL WEB TEMP TABLE external_temp_table (LIKE target_table) EXECUTE '... gpcopy_helper ‚Äìlisten ...' est cr√©√©e et la commande INSERT INTO target_table SELECT * FROM external_temp_table est ex√©cut√©e.  Par cons√©quent, gpcopy_helper avec le param√®tre ‚Äìlisten est lanc√© sur chaque segment du cluster de destination, qui re√ßoit les donn√©es de gpcopy_helper des segments du cluster source.  En raison d'un tel sch√©ma de transmission de donn√©es, ainsi que de la compression, la vitesse de transmission est beaucoup plus √©lev√©e.  Entre les clusters, l'authentification ssh sur les certificats doit √©galement √™tre configur√©e.  Je veux √©galement noter que gpcopy a une option pratique ¬´--truncate-source-after¬ª (et ¬´--validate¬ª) pour les cas o√π les clusters source et de destination sont situ√©s sur les m√™mes serveurs. <br><br><h2>  Strat√©gie de transfert de donn√©es </h2><br>  Pour d√©terminer la strat√©gie de transfert, nous devons d√©terminer ce qui est le plus important pour nous: transf√©rer des donn√©es rapidement, mais avec plus de travail et peut-√™tre moins de mani√®re fiable (gpbackup, gptransfer ou une combinaison de ceux-ci) ou avec moins de travail, mais plus lentement (gpbackup ou gptransfer sans combinaison). <br><br>  Le moyen le plus rapide de transf√©rer des donn√©es - lorsqu'il existe un cluster source et un cluster de destination - est le suivant: <br><br><ul><li>  Obtenez DDL en utilisant gpbackup --metadata-only, convertissez et chargez √† travers le pipeline en utilisant psql <br></li><li>  Supprimer les index <br></li><li>  Transf√©rer des tables d'une taille de 100 Mo ou plus √† l'aide de gptransfer <br></li><li>  Transf√©rer des tables d'une taille inf√©rieure √† 100 Mo √† l'aide de pg_dump |  psql comme dans le premier paragraphe <br></li><li>  Cr√©er des index supprim√©s <br></li></ul><br>  Cette m√©thode s'est av√©r√©e √™tre dans nos mesures au moins 2 fois plus rapide que gp_dump &amp; gp_restore.  M√©thodes alternatives: transfert de toutes les bases de donn√©es √† l'aide de gptransfer ‚Äìfull, gpbackup &amp; gprestore ou gp_dump &amp; gp_restore. <br><br>  Les tailles de table peuvent √™tre obtenues par la requ√™te suivante: <br><br><pre> <code class="plaintext hljs">SELECT nspname AS "schema", coalesce(tablename, relname) AS "name", SUM(pg_total_relation_size(class.oid)) AS "size" FROM pg_class class JOIN pg_namespace namespace ON namespace.oid = class.relnamespace LEFT JOIN pg_partitions parts ON class.relname = parts.partitiontablename AND namespace.nspname = parts.schemaname WHERE nspname NOT IN ('pg_catalog', 'information_schema', 'pg_toast', 'pg_bitmapindex', 'pg_aoseg', 'gp_toolkit') GROUP BY nspname, relkind, coalesce(tablename, relname), pg_get_userbyid(class.relowner) ORDER BY 1,2;</code> </pre><br><br><h3>  Conversions n√©cessaires </h3><br>  Les fichiers de sauvegarde dans les versions 4 et 5 de Greenplum ne sont pas non plus enti√®rement compatibles.  Ainsi, dans Greenplum 5, en raison d'un changement de syntaxe, les commandes CREATE EXTERNAL TABLE et COPY n'ont pas le param√®tre INTO ERROR TABLE, et vous devez d√©finir le param√®tre SET gp_ignore_error_table sur true afin que la restauration de la sauvegarde n'√©choue pas par erreur.  Avec le param√®tre d√©fini, nous obtenons simplement un avertissement. <br><br>  De plus, la cinqui√®me version a introduit un protocole diff√©rent pour interagir avec les tables pxf externes et pour l'utiliser, vous devez modifier le param√®tre LOCATION et configurer le service pxf. <br>  Il convient √©galement de noter que dans les fichiers de sauvegarde gp_dump et gp_restore √† la fois sur le n≈ìud ma√Ætre et sur chaque segment principal, le param√®tre SET gp_strict_xml_parse est d√©fini sur false.  Il n'y a pas un tel param√®tre dans Greenplum 5, et par cons√©quent, nous obtenons un message d'erreur. <br><br>  Si le protocole gphdfs a √©t√© utilis√© pour les tables externes, vous devez archiver dans les fichiers de sauvegarde la liste des sources dans le param√®tre LOCATION pour les tables externes sur la ligne 'gphdfs: //'.  Par exemple, il ne devrait y avoir que 'gphdfs: //hadoop.local: 8020'.  S'il existe d'autres lignes, elles doivent √™tre ajout√©es au script de remplacement sur le n≈ìud ma√Ætre par analogie. <br><br><pre> <code class="plaintext hljs">grep -o gphdfs\:\/\/.*\/ /data1/master/gpseg-1/db_dumps/20181206/gp_dump_-1_1_20181206122002.gz | cut -d/ -f1-3 | sort | uniq gphdfs://hadoop.local:8020</code> </pre> <br>  Nous rempla√ßons le n≈ìud ma√Ætre (en utilisant le fichier de donn√©es gp_dump comme exemple): <br><br><pre> <code class="plaintext hljs">mv /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz gunzip -c /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz | sed "s#'gphdfs://hadoop.local:8020#'pxf:/#g" | sed "s/\(^.*pxf\:\/\/.*'\)/\1\\&amp;\&amp;\?PROFILE=HdfsTextSimple'/" |sed "s#'&amp;#g" | sed 's/SET gp_strict_xml_parse = false;/SET gp_ignore_error_table = true;/g' | gzip -1 &gt; /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz nets</code> </pre> <br>  Dans les versions r√©centes, le nom du profil HdfsTextSimple est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©clar√© obsol√®te</a> , le nouveau nom est hdfs: text. <br><br><h2>  R√©sum√© </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Implicit Text Casting</a> , le nouveau m√©canisme de gestion des ressources du cluster des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">groupes de</a> ressources, rempla√ßant les files d'attente de ressources, l'optimiseur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GPORCA</a> , qui est inclus par d√©faut dans Greenplum 5, les probl√®mes mineurs avec les clients restaient en dehors du champ d'application de l'article. <br><br>  J'attends avec impatience la sortie de la sixi√®me version de Greenplum, pr√©vue pour le printemps 2019: niveau de compatibilit√© avec PostgreSQL 9.4, recherche en texte int√©gral, prise en charge de l'index GIN, types de plage, JSONB, compression zStd.  De plus, les plans pr√©liminaires de Greenplum 7 sont devenus connus: niveau de compatibilit√© avec PostgreSQL 9.6 minimum, Row Level Security, Automated Master Failover.  Les d√©veloppeurs promettent √©galement la disponibilit√© d'utilitaires de mise √† niveau de la base de donn√©es pour la mise √† jour entre les versions principales, ce qui facilitera la vie. <br><br>  <i>Cet article a √©t√© pr√©par√© par l'√©quipe de gestion des donn√©es de Rostelecom</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439876/">https://habr.com/ru/post/fr439876/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439864/index.html">Gestion des connaissances, pourquoi et comment nous l'avons fait</a></li>
<li><a href="../fr439866/index.html">Les principes de conception des r√©pertoires de nomenclature dans 1C Enterprise Management 2 (ERP 2.4.6)</a></li>
<li><a href="../fr439868/index.html">La vie sans Facebook: vues moins radicales, bonne humeur, plus de temps pour les proches. Maintenant prouv√© par la science</a></li>
<li><a href="../fr439870/index.html">La vid√©o comme moteur de progr√®s: l'√©volution des syst√®mes de surveillance</a></li>
<li><a href="../fr439874/index.html">Effets de filtrage SVG. Partie 3. Effet de post√©risation d'image √† l'aide de feComponentTransfer</a></li>
<li><a href="../fr439878/index.html">Cr√©ation d'une architecture pour une nouvelle startup tr√®s charg√©e en 2019</a></li>
<li><a href="../fr439880/index.html">Security Week 07: vuln√©rabilit√©s locales des appareils IoT</a></li>
<li><a href="../fr439882/index.html">Aventure avec ptrace (2)</a></li>
<li><a href="../fr439884/index.html">Comment refuser des newsletters inutiles avec un seul bouton. Exp√©rience de l'√©quipe Yandex.Mail</a></li>
<li><a href="../fr439886/index.html">Comment j'ai enseign√© √† un r√©seau de neurones √† impl√©menter la fonction d'√©valuation de position lors du Russian AI Cup CodeBall 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤷🏾 🔙 🌪️ iBrain est déjà là - et déjà dans votre téléphone 🤽🏾 🛌🏾 🤷🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vue exclusive d'Apple sur l'IA et l'apprentissage automatique
 
 
 30 juillet 2014 La Syrie [Siri] a transplanté le cerveau. 
 
 Trois ans auparavant,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>iBrain est déjà là - et déjà dans votre téléphone</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/397331/"><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vue exclusive d'Apple sur l'IA et l'apprentissage automatique</font></font></h1><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/dff/c2a/04b/dffc2a04b292bd73095c32f32c61aabf.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
30 juillet 2014 La Syrie [Siri] a transplanté le cerveau. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trois ans auparavant, Apple était la première des plus grandes entreprises technologiques à déployer un assistant AI dans le système d'exploitation. Siri est devenu une adaptation d'une application tierce acquise par l'entreprise. Parallèlement à l'application en 2010, la société de développement a été acquise. Les toutes premières critiques de la technologie ont été enthousiastes, mais au cours des mois et des années qui ont suivi, les utilisateurs ont commencé à agacer ses défauts. Trop souvent, elle a mal reconnu les commandes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par conséquent, Apple a transféré le système de reconnaissance vocale de Siri pour fonctionner en utilisant un réseau de neurones pour les utilisateurs des États-Unis le jour de juillet susmentionné (dans le reste du monde, cela s'est produit le 15 août 2014). Certaines des techniques précédentes sont restées opérationnelles - y compris les «modèles de Markov cachés» - mais le système est désormais basé sur des techniques d'apprentissage automatique telles que les réseaux de neurones profonds (DNN), les réseaux de neurones convolutionnels, la mémoire à court terme à long terme, les réseaux récurrents avec passerelles et les n-grammes. Après la mise à niveau, Siri avait la même apparence, mais un apprentissage profond est venu à son secours. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et comme c'est souvent le cas avec les mises à jour cachées, Apple ne l'a pas annoncé. Si les utilisateurs l'ont remarqué, il s'agit d'une réduction du nombre d'erreurs. Apple affirme que les résultats de l'amélioration de la précision sont étonnants.</font></font><br>
<a name="habracut"></a><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e62/bcf/2b6/e62bcf2b65840eca47295610530b42f3.png"><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eddie Kew, vice-président directeur, Logiciels et services Internet</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
«C'était l'une de ces périodes où l'amélioration était si importante que nous avons dû vérifier les résultats pour nous assurer que personne ne mettait le séparateur décimal ailleurs», explique Eddie Kew. Vice-président principal des programmes et services Internet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'histoire de la transformation de Siri, décrite pour la première fois dans cet article, peut surprendre les experts de l'IA. Non pas parce que les réseaux de neurones ont amélioré le système, mais parce qu'Apple a tout fait en silence. Jusqu'à récemment, lorsque la société a augmenté son recrutement d'experts en IA et acquis quelques sociétés spécialisées, les observateurs considéraient qu'Apple était en retard dans la compétition la plus passionnante de notre époque: la course à l'exploitation des riches capacités de l'IA. Comme Apple était toujours réticent à partager des informations sur ce qui se passait à huis clos, les connaisseurs de l'IA ne soupçonnaient pas que l'entreprise était engagée dans l'apprentissage automatique. "Apple ne fait pas partie de la communauté", a déclaré Jerry Kaplan, cours d'histoire de l'IA à Stanford. "Apple est la NSA dans le monde de l'IA." Mais les experts de l'IA pensaient que si Apple avait fait l'IA aussi sérieusement que Google ou Facebook, cela aurait été connu.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Les meilleures personnes sur Google, Facebook et Microsoft sont l'apprentissage automatique», explique Oren Etzioni de l'Allen Institute of AI. - Oui, Apple a engagé quelqu'un. Mais appelez-moi les cinq meilleurs experts de l'IA sur Apple? Ils ont la reconnaissance vocale, mais il n'est pas clair où le machine learning les aide. Montrez-moi où MO est utilisé dans votre produit! ” </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Je suis moi-même avec le Missouri», explique Etzioni, qui est en fait né en Israël. "Montre-moi."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Récemment, Apple a montré où l'apprentissage automatique est utilisé dans ses produits - mais pas pour Etzoni, mais pour moi. J'ai passé la majeure partie de la journée dans la salle de réunion One Infinite Loop à Cupertino, à recevoir des informations de base sur le travail de l'entreprise avec l'IA et le MO des dirigeants d'Apple (Kew, Phil Schiller, vice-président senior du marketing international, et Craig Federigi, vice-président senior du développement logiciel) et deux scientifiques dont les travaux ont été essentiels au développement de la Syrie. Nous nous sommes assis et ils m'ont donné un contenu de deux pages répertoriant les produits et services Apple utilisant la technologie des machines - ceux qui préparaient déjà la sortie, ou qui partaient déjà - comme sujet de discussion. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Message: Nous sommes déjà là. Nous ne sommes inférieurs à personne. Mais nous le faisons à notre façon.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si vous utilisez un iPhone, vous avez rencontré l'IA d'Apple, et pas seulement dans la version améliorée de Siri. </font><font style="vertical-align: inherit;">Vous le rencontrez lorsque le téléphone identifie un appelant qui ne figure pas dans votre liste de contacts (mais qui vous a récemment écrit un e-mail). </font><font style="vertical-align: inherit;">Ou lorsque vous faites glisser votre doigt sur l'écran pour afficher une liste d'applications, parmi lesquelles il y a une forte probabilité que vous souhaitiez ouvrir après cela. </font><font style="vertical-align: inherit;">Ou lorsque vous recevez un rappel de réunion que vous n'avez pas ajouté au calendrier. </font><font style="vertical-align: inherit;">Ou lorsqu'un point apparaît sur la carte avec l'hôtel que vous avez réservé et que vous n'avez pas encore conduit son adresse. </font><font style="vertical-align: inherit;">Ou lorsque le téléphone vous indique l'endroit où vous vous êtes garé, mais que vous ne lui avez pas demandé. </font><font style="vertical-align: inherit;">Toutes ces fonctionnalités sont apparues ou ont été grandement améliorées grâce à l'utilisation de l'apprentissage en profondeur et des réseaux de neurones.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/968/749/a38/968749a386b05f2cd73d2f403018905f.png"><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La reconnaissance faciale fonctionne avec les réseaux de neurones</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme mes orateurs le disent, MO est déjà utilisé dans tous les produits et services de l'entreprise. Apple utilise une formation approfondie pour identifier les fraudeurs dans l'Apple Store, pour augmenter la durée de vie de la batterie, pour éliminer les commentaires les plus utiles des bêta-testeurs. MO aide Apple à choisir les nouvelles pour vous. Détermine si les utilisateurs d'Apple Watch font du sport ou simplement vont et viennent. Il reconnaît les visages et les lieux à partir de photographies. Il détermine s'il est préférable de rompre une connexion Wi-Fi faible et de passer aux communications mobiles. Elle sait même comment faire un film, combinant photos et vidéos en un petit film sur simple pression d'un bouton. Les concurrents de l'entreprise font de même, mais selon ses directeurs, ces capacités d'intelligence artificielle ne peuvent pas fonctionner aussi bien, tout en protégeant la confidentialité des utilisateurs autant qu'elles le font chez Apple.Et bien sûr, aucun d'entre eux ne fabrique des produits comme Apple.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'IA n'est pas nouvelle pour l'entreprise. Déjà dans les années 1990, ils ont utilisé certaines techniques de MO dans des programmes qui reconnaissaient l'écriture manuscrite (vous vous souvenez de Newton?). Les vestiges de ces tentatives se trouvent dans les programmes d'aujourd'hui qui convertissent les caractères chinois manuscrits en texte ou reconnaissent la saisie lettre par texte sur l'Apple Watch. Ces deux opportunités ont été développées par la même équipe de spécialistes du ministère de la Défense. Bien sûr, auparavant, l'apprentissage automatique fonctionnait plus primitivement, et peu de gens connaissaient l'apprentissage profond. Aujourd'hui, ces technologies sont à leur apogée, et Apple se hérisse en réponse aux allégations selon lesquelles leur MO n'est pas trop grave. Et ici, les chefs d'entreprise en parlent plus en détail.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/48c/33f/05b/48c33f05bc21943869dc7ad270c35123.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Au cours des cinq dernières années, nous avons observé la croissance de ce domaine dans l'entreprise», explique Phil Schiller. "Nos appareils deviennent plus intelligents et plus rapides et plus rapides, en particulier avec l'utilisation des puces de la série A que nous avons développées. Le backend devient plus intelligent, plus rapide et tout ce que nous faisons est connecté les uns aux autres." Cela nous permet d'utiliser de plus en plus de techniques MO, car il y a tant à apprendre, mais elles sont déjà à notre disposition. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et bien qu'Apple ait du mal à utiliser pleinement le MO, les administrateurs soulignent que ce processus n'a rien de spécial. Les patrons de Cupertin voient dans le deep learning et MO juste une autre technologie issue d'un flux de technologies révolutionnaires successives. Oui, oui, cela change le monde, mais pas plus que d'autres percées, telles que les écrans tactiles, les écrans plats ou la POO. Du point de vue d'Apple, MO n'est pas la dernière frontière, malgré l'avis d'autres sociétés. «Après tout, on ne peut pas dire qu'au cours des dernières années, il n'y a pas eu d'autres technologies essentielles pour changer les principes de notre interaction avec les appareils», explique Kew. Et personne dans l'entreprise ne veut se rapprocher de discuter de sujets effrayants qui surgissent invariablement lors de la mention de l'IA. Et, comme vous vous en doutez, Apple ne confirme pas s'il fonctionne sur des véhicules robotiques ou sur sa version de Netflix.Mais l'équipe a clairement indiqué qu'Apple ne travaille pas sur Skynet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Nous utilisons ces technologies pour ce que nous voulions depuis longtemps et avec une meilleure qualité qu'auparavant», explique Schiller. - Et pour de nouvelles choses que nous ne pouvions pas faire. Cette technologie deviendra une méthode Apple pour atteindre les objectifs à mesure qu'elle évolue au sein de l'entreprise et en raison de la façon dont nous fabriquons nos produits. » </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais lors du briefing, il devient clair comment l'IA a considérablement changé les méthodes d'utilisation de l'écosystème Apple. Les experts de l'IA estiment qu'Apple est limité en ce qu'il ne dispose pas de son propre moteur de recherche (qui pourrait fournir des données pour la formation des réseaux de neurones) et de sa conviction inflexible de la nécessité de protéger les informations des utilisateurs (données qui pourraient autrement être utilisées). Mais il s'avère qu'Apple a déjà compris comment surmonter ces deux obstacles.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et quelle est la taille de ce cerveau, un cache dynamique qui fournit MO sur iPhone? J'ai été surpris de recevoir une réponse à cette question. Sa taille est d'environ 200 Mo, selon la quantité d'informations personnelles stockées (les anciennes données sont toujours supprimées). Cela comprend des informations sur l'utilisation des applications, l'interaction avec les gens, le traitement des réseaux de neurones, la génération de la voix et la «modélisation des événements du langage naturel». Il contient également des données utilisées pour les réseaux de neurones qui fonctionnent avec la reconnaissance des formes, les visages et la classification des scènes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et, selon Apple, tout cela est fait de manière à ce que vos paramètres, préférences et mouvements restent privés.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et bien qu'ils ne m'aient pas tout expliqué sur l'utilisation de l'IA dans l'entreprise, j'ai pu comprendre comment l'entreprise diffuse l'expérience dans le MO parmi les employés de l'organisation. Le talent de la région de Moscou est partagé dans toute l'entreprise, il est disponible pour tous les développeurs qui sont encouragés à utiliser ces connaissances pour résoudre des problèmes et inventer de nouvelles opportunités pour des produits spécifiques. «Nous n’avons pas d’organisation dédiée, le Temple MO, chez Apple», déclare Craig Federigi. «Nous essayons de garder les informations plus proches des équipes qui les utilisent pour créer la bonne expérience utilisateur.»</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Combien de personnes dans l'entreprise travaillent sur MO? «Beaucoup», dit Federigi après réflexion. (Si vous pensiez qu'il me dirait le montant exact, vous ne connaissez pas Apple). Il est intéressant de noter que les personnes qui n'étaient pas expertes en la matière avant de rejoindre l'entreprise évoluent également chez Apple. «Nous embauchons des gens qui connaissent bien les mathématiques, les statistiques, la programmation, la cryptographie», explique Federigi. - Il s'avère que nombre de ces talents se transforment parfaitement en MO. Bien qu'aujourd'hui, bien sûr, nous embauchions des spécialistes dans la région de Moscou, nous prenons également des personnes ayant les inclinations et les talents nécessaires. » </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/a9f/e97/4d9/a9fe974d9972ac13d4a86f997b61490a.jpg"><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Craig Federigi, vice-président directeur du développement logiciel, écoute Alex Acero, directeur principal de Siri</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien que Federigi ne le dise pas, cette approche peut être nécessaire: la propension de l'entreprise au secret peut la désavantager par rapport aux concurrents qui encouragent leurs meilleurs programmeurs à diffuser les résultats de la recherche. «Nos méthodes augmentent la dispersion de la sélection naturelle - ceux qui ont besoin d'un travail d'équipe et la libération d'excellents produits surtout contre ceux qui ont le plus besoin de publication», explique Federigi. Si les chercheurs font une percée dans le domaine tout en améliorant les produits Apple, tant mieux. «Mais pour nous, le résultat final sera le principal», explique Kew.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Certaines personnes talentueuses entrent dans l'entreprise après le rachat. «Récemment, nous achetons 20 à 30 petites entreprises par an, nous sommes engagés dans l'embauche de main-d'œuvre», explique Kew. Quand Apple achète une entreprise travaillant sur l'IA, elle ne le fait pas parce que «il y a une foule de chercheurs en MO ici, obtenons-en une stable», explique Federigi. «Nous recherchons des personnes talentueuses mais soucieuses de créer une expérience utilisateur exceptionnelle.»</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'acquisition la plus récente est Turi, une société basée à Seattle qu'Apple a achetée pour 200 millions de dollars. Ils ont construit une boîte à outils pour les MO comparable à TensorFlow de Google, et cette acquisition a conduit à des rumeurs selon lesquelles Apple utiliserait cette technologie à des fins similaires, à la fois pour lui-même et pour les développeurs. Les administrateurs ne confirment ni ne nient ces informations. «Certains de leurs résultats se sont très bien combinés avec Apple, à la fois en termes de technologie et de personnes», explique Kew. Dans quelques années, nous saurons probablement ce qui s'est passé, comme c'était le cas lorsque Siri a commencé à démontrer les capacités prédictives de Cue (non lié à Eddie), le produit du démarrage du même nom qu'Apple a acheté en 2013.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Peu importe d'où vient le talent, l'infrastructure d'IA d'Apple lui permet de développer des produits et des capacités qui ne seraient pas possibles autrement. Elle modifie le programme de développement de produits de l'entreprise. «La liste d’idées intéressantes d’Apple n’a pas de fin», explique Schiller. - MO nous permet de nous tourner vers des choses que nous ne touchions pas par le passé. Il se fond dans le processus décisionnel concernant les produits que nous traiterons à l'avenir. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un exemple est l'Apple Pencil, qui fonctionne avec l'Apple Pencil. Pour que ce stylet de haute technologie fonctionne, l'entreprise a dû résoudre le problème: lorsque les gens écrivent sur l'écran, la partie inférieure de la paume court sur l'écran tactile, ce qui entraîne l'apparition de clics parasites. En utilisant le modèle MO pour éliminer ces tapotements, la société a pu apprendre à l'écran à distinguer le défilement, le toucher et la saisie du stylet. «Si cela ne fonctionne pas à 100%, ce papier d'enregistrement ne me convient pas et le crayon est un mauvais produit», explique Federigi. Si vous aimez le crayon, merci MO pour cela.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Peut-être que la meilleure mesure des progrès de MO dans une entreprise serait son achat le plus important, Siri. Il trouve son origine dans l'ambitieux programme DARPA pour le développement d'assistants intelligents, après quoi plusieurs scientifiques ont fondé l'entreprise pour créer une application utilisant cette technologie. Steve Jobs a personnellement convaincu les fondateurs de l'entreprise de vendre Apple en 2010 et a insisté pour que Siri soit intégré au système d'exploitation. Son lancement a été l'un des points forts de la présentation de l'iPhone 4S en octobre 2011. Maintenant, cela ne fonctionne pas seulement lorsque l'utilisateur tient le bouton d'accueil ou marmonne "Hey Siri" (MO lui-même utilise également cette fonctionnalité, permettant à l'iPhone d'écouter éther, ne mettant pas beaucoup de batterie). L'intelligence de Siri est intégrée à Apple Brain et fonctionne même lorsqu'elle ne dit rien.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kew décrit les quatre composants d'un produit de base: reconnaissance vocale, compréhension du langage naturel, exécution de commandes et rappel. «Le MoE a touché très fortement tous ces domaines», dit-il. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/fb3/b23/118/fb3b23118f7bf3c28090e3e09956e5c6.png"><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chef de l'ingénierie avancée Tom Gruber et Siri Guru, Alex Acero</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Siri est engagé dans le chef du département de développement avancé Tom Grubber, entré dans Apple avec l'acquisition principale (les co-fondateurs de la société ont quitté Apple en 2011). Il dit que même avant que les réseaux de neurones soient appliqués à Siri, ils avaient reçu une énorme quantité de données provenant de la base d'utilisateurs. À l'avenir, ces données ont servi de clé à la formation des réseaux de neurones. "Steve a dit que nous passerons d'une application pilote à des centaines de millions de personnes en une nuit, sans test bêta", dit-il. - Soudain, nous aurons des utilisateurs. On nous a dit comment les gens appelleraient les choses liées à notre application. Ce fut la première révolution. Et puis des réseaux de neurones sont apparus. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La transition de Siri vers des réseaux neuronaux qui traitent la reconnaissance vocale a coïncidé avec l'arrivée de plusieurs experts en intelligence artificielle, dont Alex Acero, aujourd'hui à la tête de l'équipe des technologies vocales. Acero a commencé sa carrière dans la reconnaissance vocale chez Apple au début des années 90, puis a passé de nombreuses années chez Microsoft Research. «J'ai vraiment aimé travailler là-bas, j'ai publié beaucoup de travail», dit-il. "Mais quand Siri est sorti, j'ai dit:" C'est une chance de faire des réseaux de neurones profonds une réalité, de les faire passer d'un état où des centaines de personnes lisent à leur sujet, à un état dans lequel des millions de personnes les utilisent. " En d'autres termes, il appartenait exactement au type de scientifiques que Apple recherchait - mettant le produit au-dessus des publications.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque Acero a rejoint la société il y a trois ans, Apple était toujours en train d'obtenir des licences pour la plupart des technologies vocales de Siri auprès de fabricants tiers, et cette situation allait bientôt changer. Federigi note qu'Apple travaille constamment sur ce modèle. «Lorsqu'il devient clair que le domaine technologique est nécessaire pour notre capacité à lancer un nouveau produit au fil du temps, nous augmentons notre capacité interne à produire ce que nous voulons. Pour rendre un produit génial, nous devons être parfaitement compétents en technologie et innover en interne. Le discours est un excellent exemple de la façon dont nous avons utilisé les opportunités disponibles de l'extérieur pour lancer le projet. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'équipe a commencé à former le réseau neuronal pour remplacer le Siri d'origine. «Nous avions la ferme de GPU la plus cool, fonctionnant 24 heures sur 24», explique Acero. "Et nous y avons injecté un tas de données." La version de juillet 2014 a prouvé que tout ce temps processeur n'était pas perdu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Le nombre d'erreurs a diminué de moitié dans toutes les langues, et dans certains cas, encore plus», explique Acero. «Principalement grâce à l'apprentissage en profondeur et à notre optimisation - pas seulement l'algorithme lui-même, mais selon le contexte de son travail dans le produit final.»</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La mention du produit final n'est pas accidentelle. Apple n'est pas le premier à utiliser la formation sur les réseaux de neurones profonds pour la reconnaissance vocale. Mais Apple prétend avoir l'avantage de contrôler l'ensemble du système de développement et de livraison des produits. Depuis qu'Apple fait les puces elle-même, Acero a eu l'opportunité de travailler avec leur équipe de développement et leurs ingénieurs qui ont écrit des micrologiciels pour les appareils afin de maximiser les performances des réseaux de neurones. Les besoins de l'équipe de développement de Siri ont même influencé la conception de l'iPhone. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Ce n'est pas seulement du silicium», ajoute Federigi. - Le nombre de microphones sur l'appareil, où ils se trouvent. Comment configurer le matériel et les microphones, et un ensemble de logiciels qui traitent le son. L'interaction des pièces est importante. C'est un énorme avantage sur ceux qui ont simplement écrit un logiciel et voir ce qu'il fait. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Autre avantage: lorsqu'un réseau de neurones fonctionne dans un seul produit, il peut être adapté comme base technologique à d'autres fins. MO, aidant Siri à vous comprendre, se transforme en un moteur d'enregistrement de dictée. Grâce au travail de Siri, les gens trouvent que leurs e-mails et messages auront plus de sens s'ils abandonnent le clavier à l'écran, cliquent sur l'icône du microphone et parlent à haute voix.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La deuxième composante de Siri, mentionnée par Kew, est la compréhension du langage naturel. Siri a commencé à utiliser MO pour comprendre les intentions de l'utilisateur en novembre 2014 et a publié une version d'apprentissage en profondeur un an plus tard. Et, comme pour la reconnaissance vocale, MO a amélioré l'expérience utilisateur - en particulier en termes d'interprétation plus flexible des commandes. Par exemple, Kew sort un iPhone et appelle Siri. «Envoyez vingt dollars à Jane via Square Cash», dit-il. Un message apparaît à l'écran avec une description de sa demande. Puis il essaie de définir la tâche d'une manière différente: "jeter vingt de ma femme". Le résultat est le même.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apple affirme que sans ces améliorations dans Siri, il serait peu probable que la version actuelle d'Apple TV, dotée d'un contrôle vocal sophistiqué, soit possible. Les versions antérieures de Siri vous faisaient parler clairement et séparément, la version MO chargée offre non seulement des options spécifiques à partir d'un vaste catalogue de films et de chansons, mais comprend également les concepts. "Montrez-moi un bon thriller avec Tom Hanks." (Si Siri était vraiment intelligent, elle aurait exclu le Da Vinci Code). «Une telle opportunité avant l'avènement de cette technologie n'aurait pas pu être offerte», explique Federigi.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
IOS 10 devrait sortir cet automne, et la voix de Siri sera le dernier des quatre composants transformés par MO. Les réseaux de neurones profonds ont remplacé les implémentations précédentes faites sous licence. En fait, les répliques de Siri sont sélectionnées dans la base de données des enregistrements collectés dans le centre vocal et chaque phrase est collectée en plusieurs parties. Selon Grubber, l'apprentissage automatique lisse les coins et fait ressembler Siri à une vraie personne. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Acero effectue une démonstration - la première voix familière de Siri, avec des notes de type robot auxquelles nous sommes habitués. Puis un nouveau, en disant "Bonjour, comment puis-je vous aider?", Avec une fluidité captivante. Quelle est la différence? «Apprentissage profond, bébé», dit-il.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cela semble être un détail fin, mais une voix plus naturelle peut entraîner de grands changements. «Les gens font mieux confiance à une meilleure voix», explique Grubber. - La meilleure voix attire l'utilisateur et l'encourage à l'utiliser plus souvent. L'effet de retour augmente. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le désir d'utiliser Siri, et toutes les améliorations apportées grâce à MO, deviennent encore plus importants, car Apple ouvre enfin Siri aux développeurs tiers - et les critiques de la société pensent qu'il était temps de le faire il y a longtemps. Beaucoup ont noté qu'Apple, dont des dizaines de partenaires Siri, est en retard sur des systèmes comme Alexa d'Amazon, bénéficiant d'un millier de fonctionnalités fournies par des développeurs tiers. Apple dit que les comparer est incorrect car les utilisateurs d'Amazon doivent exprimer leurs souhaits dans une langue spéciale. Siri inclura plus naturellement des choses comme SquareCash ou Uber. (Un autre concurrent, Viv - créé par d'autres co-fondateurs de Siri - promet également une intégration avec des services tiers lorsque la date de sortie n'est pas encore annoncée).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le plus grand défi pour le développement de MO sera peut-être de réussir, si nécessaire, à adhérer aux principes de confidentialité des utilisateurs. La société crypte leurs données, donc personne, même les avocats d'Apple, ne peut les lire (même le FBI, même avec un mandat). Et l'entreprise est fière de ne pas collecter de données utilisateur à des fins publicitaires. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien qu'une telle austérité soit louable du point de vue des utilisateurs, elle n'aide pas à attirer les meilleurs talents de l'IA dans l'entreprise. «Les experts de MO ont besoin de données», a déclaré un ancien employé d'Apple travaillant pour une entreprise spécialisée dans l'IA. "Mais dans une position de confidentialité, Apple vous oblige à travailler d'une seule main." Vous pouvez vous demander si c'est bien ou mal, mais en conséquence, Apple n'a pas la réputation d'experts en IA vraiment cool. »</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a deux problèmes. Le premier est le traitement des informations personnelles dans les systèmes basés sur MO. Lorsque les données personnelles d'un utilisateur passent par une meule de traitement de réseau neuronal, qu'advient-il de ces informations? Le deuxième problème consiste à recueillir les informations nécessaires pour former les réseaux de neurones à reconnaître le comportement. Comment cela peut-il se faire sans collecter les informations personnelles des utilisateurs? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apple pense avoir des solutions. «Certaines personnes pensent que nous ne pouvons pas faire cela avec l'IA parce que nous n'avons pas de données», explique Kew. «Mais nous avons trouvé des moyens d'obtenir les données dont nous avons besoin, tout en préservant la confidentialité.» Comme ça. "</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apple résout le premier problème en tirant parti de la possibilité de contrôler à la fois les logiciels et le matériel. Les informations les plus personnelles restent dans Apple Brain. «Nous stockons les choses les plus sensibles où le MO se produit localement par rapport à l'appareil», explique Federigi. À titre d'exemple, il donne des prédictions d'applications à exécuter, des icônes qui apparaissent lorsque vous faites glisser l'écran vers la droite. Ces prédictions sont basées sur de nombreux facteurs, dont certains ne dépendent que de votre comportement. Et ils fonctionnent - Federigi dit que 90% du temps, les gens trouvent ce dont ils ont besoin dans ces prévisions. Tous les calculs effectués par Apple directement sur le téléphone.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, l'appareil stocke, éventuellement, les informations les plus personnelles reçues par l'entreprise: mots utilisés par les personnes sur le clavier iPhone QuickType. À l'aide d'un système de formation de réseau de neurones qui surveille vos entrées, Apple peut reconnaître les événements et les moments clés, tels que les informations sur les voyages en avion, les contacts, les réunions, mais les informations elles-mêmes restent sur votre téléphone. Même dans les sauvegardes stockées dans le cloud, il est dilué de telle manière que vous ne pouvez pas l'obtenir à partir d'une seule copie de sauvegarde. «Nous ne voulons pas que ces informations soient stockées sur nos serveurs», déclare Federigi. "Apple n'a pas besoin de connaître vos habitudes, ni où et quand vous allez."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apple essaie de minimiser les informations stockées. Federigi a donné un exemple dans lequel vous pouvez avoir une conversation, et quelqu'un dans celui-ci mentionnera un terme approprié pour la recherche. D'autres sociétés pourraient analyser l'intégralité de la conversation dans le cloud pour trouver ces termes, mais l'appareil Apple peut les reconnaître afin que les données ne quittent pas l'utilisateur - car le système recherche constamment des correspondances dans la base de connaissances stockée sur le téléphone (il fait partie de 200 Mo «Cerveau»). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«La base est compacte mais complète, avec des centaines de milliers d'emplacements et d'objets. Nous le localisons, car nous savons où vous vous trouvez », explique Federigi. Toutes les applications Apple accèdent à la base de données, y compris le moteur de recherche Spotlight, Maps et Safari. Il aide à corriger automatiquement les erreurs. «Et cela fonctionne constamment en arrière-plan», dit-il.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À partir d'iOS 10, Apple utilisera la nouvelle technologie de confidentialité différenciée, qui permet le crowdsourcing des informations afin qu'il ne puisse pas identifier les individus. Il peut s'agir de mots qui ont gagné en popularité et qui ne figurent pas dans la base de données, de liens qui offrent des réponses plus pertinentes aux requêtes ou d'une manière d'utiliser certains emojis. «Habituellement, dans l'industrie, il est de coutume d'envoyer tous les mots et symboles que vous saisissez aux serveurs de l'entreprise afin qu'ils y plongent plus tard et remarquent quelque chose d'intéressant», explique Federigi. "Nous chiffrons les informations depuis et vers, donc nous ne le faisons pas." Bien que la confidentialité différenciée soit originaire de la communauté des chercheurs, Apple essaie de la présenter au grand public. "Nous la transférons du département de la recherche à un milliard d'utilisateurs", explique Kew.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et bien qu'il soit clair que MO a changé les produits Apple, il n'est pas encore clair s'il a changé l'entreprise elle-même. Dans un sens, l'approche utilisant MO est en conflit avec l'esprit de l'entreprise. Apple surveille attentivement l'expérience utilisateur, jusqu'aux capteurs qui mesurent la conductivité à l'écran. Tout est planifié à l'avance et encodé avec précision. Mais lorsqu'ils utilisent MO, les ingénieurs doivent prendre du recul et donner au logiciel la possibilité de rechercher des solutions par eux-mêmes. Apple peut-il s'adapter à la réalité moderne, dans laquelle les systèmes avec MO peuvent eux-mêmes participer à la conception des produits?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«C'est la cause de nombreuses controverses au sein de l'entreprise», explique Federigi. - Nous sommes habitués à offrir une expérience très réfléchie et contrôlée dans laquelle nous contrôlons toutes les dimensions de la façon dont le système communique avec l'utilisateur. Lorsque vous commencez à former un système basé sur un grand ensemble de données sur le comportement humain, les résultats obtenus peuvent ne pas coïncider avec l'idée du concepteur. Ils apparaissent sur la base de données. " </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais Apple ne va pas reculer, dit Schiller. «Bien que ces technologies influencent bien sûr le développement de produits, nous les utilisons finalement pour produire de meilleurs produits.» </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par conséquent, Apple ne fera peut-être pas d'annonce de cap sur l'immersion dans le MO, mais il utilisera autant de MO que possible pour améliorer les produits. Le cerveau de votre téléphone le prouve.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Un utilisateur typique fera l'expérience d'un apprentissage approfondi au quotidien, et cela illustre ce que vous aimez des produits Apple», explique Schiller. </font><font style="vertical-align: inherit;">"Les moments les plus cool sont si subtils que vous n'y pensez qu'après une troisième rencontre avec eux, puis vous vous arrêtez et vous exclamez:" Comment est-ce possible? " </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Skynet attendra.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr397331/">https://habr.com/ru/post/fr397331/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr397321/index.html">Présentation officielle du Sony Xperia XZ et Xperia X Compact</a></li>
<li><a href="../fr397323/index.html">Arrête de mettre la diode</a></li>
<li><a href="../fr397325/index.html">Le propriétaire du forum informatique Ru-Board tué</a></li>
<li><a href="../fr397327/index.html">WaveNet: discours de type humain synthétisé par ordinateur</a></li>
<li><a href="../fr397329/index.html">Pourquoi la peau se ride-t-elle dans l'eau</a></li>
<li><a href="../fr397333/index.html">La règle des cinq secondes ne fonctionne toujours pas</a></li>
<li><a href="../fr397335/index.html">Samsung rappelle les smartphones Galaxy Note 7 après des rapports d'explosions de batterie</a></li>
<li><a href="../fr397337/index.html">Entretien avec le fondateur de la startup Petiole Andrei Seleznev</a></li>
<li><a href="../fr397339/index.html">Un microscope électronique a découvert comment la vitamine A pénètre dans les cellules</a></li>
<li><a href="../fr397341/index.html">FAQ du samedi sur l'énergie gratuite et le BTG</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õπÔ∏è üö¥üèæ üíô Con barba, con gafas oscuras y de perfil: situaciones dif√≠ciles para la visi√≥n por computadora. üìÆ ‚§µÔ∏è üéì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Las tecnolog√≠as y modelos para nuestro futuro sistema de visi√≥n por computadora se crearon y mejoraron gradualmente en varios proyectos de nuestra com...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Con barba, con gafas oscuras y de perfil: situaciones dif√≠ciles para la visi√≥n por computadora.</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/449120/"><img src="https://habrastorage.org/getpro/habr/post_images/027/06d/ef1/02706def16ee17a808ab04bef455cb83.jpg"><br><br>  Las tecnolog√≠as y modelos para nuestro futuro sistema de visi√≥n por computadora se crearon y mejoraron gradualmente en varios proyectos de nuestra compa√±√≠a, en Mail, Cloud y Search.  Madurado como buen queso o co√±ac.  Una vez que nos dimos cuenta de que nuestras redes neuronales mostraban excelentes resultados de reconocimiento, y decidimos unirlas en un solo producto b2b, Visi√≥n, que ahora usamos nosotros mismos y ofrecemos para usarlo. <br><br>  Hoy en d√≠a, nuestra tecnolog√≠a de visi√≥n por computadora en la plataforma Mail.Ru Cloud Solutions funciona con √©xito y resuelve problemas pr√°cticos muy complejos.  Se basa en una serie de redes neuronales que est√°n capacitadas en nuestros conjuntos de datos y se especializan en resolver problemas aplicados.  Todos los servicios est√°n girando en las capacidades de nuestro servidor.  Puede integrar la API p√∫blica de Vision en sus aplicaciones, a trav√©s de la cual todas las caracter√≠sticas del servicio est√°n disponibles.  La API es r√°pida: gracias a las GPU del servidor, el tiempo de respuesta promedio dentro de nuestra red es de 100 ms. <br><br>  Ven debajo del corte, hay una historia detallada y muchos ejemplos de Visi√≥n. <br><a name="habracut"></a><br>  Como ejemplo de un servicio en el que nosotros mismos utilizamos las tecnolog√≠as de reconocimiento facial mencionadas anteriormente, podemos citar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Eventos</a> .  Uno de sus componentes son los soportes de fotos Vision, que instalamos en varias conferencias.  Si sube a un puesto de fotos de este tipo, tome una foto con la c√°mara incorporada e ingrese su correo, el sistema encontrar√° inmediatamente entre la variedad de fotos aquellas de las cuales los fot√≥grafos de conferencias regulares lo han capturado y, si lo desea, le enviar√° las fotos encontradas por correo.  Y no se trata de retratos en escena: Vision lo reconoce incluso en el fondo en la multitud de visitantes.  Por supuesto, no son reconocidos por los soportes de fotos, solo son tabletas en hermosos posavasos que simplemente fotograf√≠an a los invitados en sus c√°maras incorporadas y transmiten informaci√≥n a los servidores, donde tiene lugar toda la magia del reconocimiento.  Y hemos observado repetidamente cu√°n sorprendente es la efectividad de la tecnolog√≠a incluso entre los especialistas en reconocimiento de im√°genes.  A continuaci√≥n hablaremos de algunos ejemplos. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3gE-OeSmoKo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h1>  1. Nuestro modelo de reconocimiento facial </h1><br><h3>  1.1.  Red neuronal y velocidad de procesamiento </h3><br>  Para el reconocimiento, utilizamos una modificaci√≥n del modelo de red neuronal ResNet 101. La agrupaci√≥n promedio al final se reemplaza por una capa completamente conectada, similar a como se hizo en ArcFace.  Sin embargo, el tama√±o de las representaciones vectoriales es 128, no 512. Nuestro conjunto de entrenamiento contiene alrededor de 10 millones de fotos de 273,593 personas. <br><br>  El modelo funciona muy r√°pido gracias a una arquitectura de configuraci√≥n de servidor cuidadosamente seleccionada y computaci√≥n GPU.  Se necesitan 100 ms para obtener una respuesta de la API en nuestras redes internas; esto incluye la detecci√≥n de rostros (detecci√≥n de rostros en la foto), el reconocimiento y la devoluci√≥n del PersonID en la respuesta de la API.  Con grandes vol√∫menes de datos entrantes (fotos y videos), llevar√° mucho m√°s tiempo transferir datos al servicio y recibir una respuesta. <br><br><h3>  1.2.  Estimaci√≥n de la eficiencia del modelo. </h3><br>  Pero determinar la eficiencia de las redes neuronales es una tarea muy mixta.  La calidad de su trabajo depende de en qu√© conjuntos de datos se entrenaron los modelos y si fueron optimizados para trabajar con datos espec√≠ficos. <br><br>  Comenzamos a evaluar la precisi√≥n de nuestro modelo con la popular prueba de verificaci√≥n LFW, pero es demasiado peque√±a y simple.  Despu√©s de alcanzar el 99.8% de precisi√≥n, ya no es √∫til.  Hay una buena competencia para evaluar los modelos de reconocimiento: Megaface en √©l alcanzamos gradualmente el 82% rango 1. La prueba de Megaface consta de un mill√≥n de fotos, distractores, y el modelo deber√≠a poder distinguir bien varios miles de fotos de celebridades del conjunto de datos Facescrub de los distractores.  Sin embargo, despu√©s de borrar la prueba de errores de Megaface, descubrimos que en la versi√≥n limpia alcanzamos una precisi√≥n del 98% de rango 1 (las fotos de celebridades generalmente son bastante espec√≠ficas).  Por lo tanto, crearon una prueba de identificaci√≥n separada, similar a Megaface, pero con fotos de personas "comunes".  Mejor√≥ a√∫n m√°s la precisi√≥n de reconocimiento en sus conjuntos de datos y sigui√≥ adelante.  Adem√°s, utilizamos la prueba de calidad de agrupamiento, que consta de varios miles de fotograf√≠as;  Simula el marcado de caras en la nube del usuario.  En este caso, los grupos son grupos de individuos similares, un grupo para cada persona reconocible.  Verificamos la calidad del trabajo en grupos reales (verdadero). <br><br>  Por supuesto, cualquier modelo tiene errores de reconocimiento.  Pero tales situaciones a menudo se resuelven ajustando los umbrales para condiciones espec√≠ficas (para todas las conferencias usamos los mismos umbrales, y, por ejemplo, para los SCA tenemos que aumentar significativamente los umbrales para que haya menos falsos positivos).  La gran mayor√≠a de los asistentes a la conferencia fueron reconocidos por nuestros soportes de fotos Vision correctamente.  A veces alguien miraba la vista previa recortada y dec√≠a: "Tu sistema estaba mal, no soy yo".  Luego abrimos toda la fotograf√≠a, y result√≥ que este visitante realmente estaba en la fotograf√≠a, solo que no la tomaron, pero alguien m√°s, solo un hombre apareci√≥ accidentalmente en el fondo en la zona borrosa.  Adem√°s, la red neuronal a menudo reconoce correctamente incluso cuando una parte de la cara no es visible, o una persona est√° de perfil, o incluso media cara.  El sistema puede reconocer a una persona, incluso si la persona cay√≥ en el campo de la distorsi√≥n √≥ptica, por ejemplo, al disparar con una lente gran angular. <br><br><h3>  1.3.  Ejemplos de pruebas en situaciones dif√≠ciles </h3><br>  A continuaci√≥n se presentan ejemplos del funcionamiento de nuestra red neuronal.  En la entrada, se env√≠an fotos, que debe marcar con PersonID, un identificador √∫nico para la persona.  Si dos o m√°s im√°genes tienen el mismo identificador, entonces, seg√∫n los modelos, estas fotos muestran a una persona. <br><br>  Inmediatamente, notamos que durante las pruebas tenemos acceso a varios par√°metros y umbrales de modelos que podemos configurar para lograr un resultado particular.  La API p√∫blica est√° optimizada para la m√°xima precisi√≥n en casos comunes. <br><br>  Comencemos con lo m√°s simple, con reconocimiento facial en la cara. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21e/973/ba9/21e973ba959f23ab2b8592e795fb8bcb.png"><br><br>  Bueno, eso fue demasiado f√°cil.  Complicamos la tarea, agregamos una barba y un pu√±ado de a√±os. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/24e/a74/347/24ea7434773548d5dc23cdff03887b0f.png"><br><br>  Alguien dir√° que esto no fue demasiado dif√≠cil, porque en ambos casos la cara es visible en su totalidad, el algoritmo tiene mucha informaci√≥n sobre la cara.  De acuerdo, convierte a Tom Hardy en el perfil.  Esta tarea es mucho m√°s complicada, y dedicamos mucho esfuerzo a su soluci√≥n exitosa mientras mantenemos un bajo nivel de errores: seleccionamos una muestra de entrenamiento, pensamos en la arquitectura de la red neuronal, perfeccionamos las funciones de p√©rdida y mejoramos el procesamiento preliminar de las fotos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/df6/191/445/df619144560539d45c09176174349b9d.png"><br><br>  Vamos a ponerle un sombrero: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/40c/2e5/48b/40c2e548b16ea8a2015b0b7f0ff53b62.png"><br><br>  Por cierto, este es un ejemplo de una situaci√≥n particularmente dif√≠cil, ya que la cara est√° muy cubierta aqu√≠, y en la imagen inferior tambi√©n hay una sombra profunda que oculta los ojos.  En la vida real, las personas a menudo cambian su apariencia con la ayuda de lentes oscuros.  Haz lo mismo con Tom. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/27e/792/5db/27e7925dbb402d2ba1957e812279de7c.png"><br><br>  Bueno, intentemos subir fotos de diferentes edades, y esta vez vamos a poner experiencia en otro actor.  Tomemos un ejemplo mucho m√°s complejo cuando los cambios relacionados con la edad son especialmente pronunciados.  La situaci√≥n no es descabellada, sucede todo el tiempo cuando necesita comparar una fotograf√≠a en su pasaporte con la cara del portador.  Despu√©s de todo, la primera foto est√° atrapada en el pasaporte cuando el propietario tiene 20 a√±os y 45 personas pueden cambiar mucho: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/59f/d37/109/59fd37109369ee642fa75ff107be9726.png"><br><br>  ¬øCrees que el especial principal en misiones imposibles no ha cambiado mucho con la edad?  Creo que incluso unas pocas personas combinar√≠an las fotos superior e inferior, el ni√±o ha cambiado mucho a lo largo de los a√±os. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f3c/f57/20c/f3cf5720c2aeced56746035af7687531.png"><br><br>  Las redes neuronales se enfrentan a cambios en la apariencia con mucha m√°s frecuencia.  Por ejemplo, a veces las mujeres pueden cambiar mucho su imagen con la ayuda de los cosm√©ticos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/47e/c03/e0747ec033917573a028028e04a0cf24.png"><br><br>  Ahora vamos a complicar a√∫n m√°s la tarea: dejar que diferentes partes de la cara se cubran con diferentes fotos.  En tales casos, el algoritmo no puede comparar las muestras completas.  Sin embargo, Vision maneja bien tales situaciones. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f99/14b/600/f9914b600d274f8f29ecbd229e937e9e.png"><br><br>  Por cierto, hay muchas caras en las fotograf√≠as, por ejemplo, m√°s de 100 personas pueden caber en una imagen com√∫n de la sala.  Esta es una situaci√≥n dif√≠cil para las redes neuronales, ya que muchas caras se pueden iluminar de manera diferente, alguien fuera de la zona de nitidez.  Sin embargo, si la foto se tom√≥ con suficiente resoluci√≥n y calidad (al menos 75 p√≠xeles por cuadrado que cubre la cara), Vision podr√° identificarla y reconocerla. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/362/3a9/b8e/3623a9b8e23fd68b025f6bc9c81f22d2.png"><br><br>  La peculiaridad de informar fotograf√≠as e im√°genes de c√°maras de vigilancia es que las personas a menudo est√°n borrosas porque estaban fuera del campo de nitidez o se mov√≠an en ese momento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/819/db8/c4e/819db8c4e234677690cfc86c7be73a02.png"><br><br>  Adem√°s, la intensidad de la iluminaci√≥n puede variar mucho de una imagen a otra.  Esto tambi√©n a menudo se convierte en un obst√°culo, muchos algoritmos tienen una gran dificultad para procesar correctamente im√°genes que son demasiado oscuras y claras, sin mencionar la comparaci√≥n exacta.  Perm√≠tame recordarle que para lograr ese resultado, debe establecer umbrales de cierta manera, esta posibilidad a√∫n no est√° disponible p√∫blicamente.  Para todos los clientes, utilizamos la misma red neuronal, tiene umbrales adecuados para la mayor√≠a de las tareas pr√°cticas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db0/423/6a3/db04236a312641cc7ed888bc279cbf66.png"><br><br>  Recientemente, lanzamos una nueva versi√≥n del modelo que reconoce las caras asi√°ticas con alta precisi√≥n.  Anteriormente, este era un gran problema, que incluso se llamaba "racismo de aprendizaje autom√°tico" (o "redes neuronales").  Las redes neuronales europeas y americanas reconocieron bien los rostros europeos, y las cosas fueron mucho peores con los mongoloides y los negroides.  Probablemente en la misma China, la situaci√≥n era exactamente lo contrario.  Se trata de conjuntos de datos de capacitaci√≥n que reflejan los tipos dominantes de personas en un pa√≠s en particular.  Sin embargo, la situaci√≥n est√° cambiando, hoy este problema est√° lejos de ser tan grave.  La visi√≥n no tiene ninguna dificultad con representantes de diferentes razas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/be8/750/da9/be8750da9407b7ca4c2cd11dac314ef3.png"><br><br>  El reconocimiento facial es solo una de las muchas aplicaciones de nuestra tecnolog√≠a. Se puede ense√±ar a Vision a reconocer cualquier cosa.  Por ejemplo, n√∫meros de autom√≥viles, incluso en condiciones dif√≠ciles para algoritmos: en √°ngulos agudos, n√∫meros sucios y dif√≠ciles de leer. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b22/ddb/39d/b22ddb39d2fe119db6eb50db37df829b.png"><br><br><h1>  2. Casos de uso pr√°ctico </h1><br><h3>  2.1.  Control de acceso f√≠sico: cuando dos van en el mismo pase </h3><br>  Con la ayuda de Vision, es posible implementar sistemas de contabilidad para la llegada y salida de los empleados.  Un sistema tradicional basado en pases electr√≥nicos tiene inconvenientes obvios, por ejemplo, puede pasar por dos insignias juntas.  Si el sistema de control de acceso (ACS) se complementa con Vision, honestamente registrar√° qui√©n entr√≥ y cu√°ndo. <br><br><h3>  2.2.  Seguimiento de tiempo </h3><br>  Este caso de uso para Vision est√° estrechamente relacionado con el anterior.  Si complementamos el sistema de control de acceso con nuestro servicio de reconocimiento facial, ser√° capaz de notar no solo violaciones del control de acceso, sino tambi√©n registrar la estad√≠a real de los empleados en el edificio o en las instalaciones.  En otras palabras, Vision ayudar√° a considerar honestamente qui√©n y cu√°nto vino a trabajar y se fue con ella, y qui√©n incluso se salt√≥, incluso si sus colegas lo cubrieron frente a sus superiores. <br><br><h3>  2.3.  An√°lisis de video: seguimiento de personas y seguridad </h3><br>  Al rastrear a las personas que usan Vision, puede evaluar con precisi√≥n la permeabilidad real de las √°reas comerciales, estaciones de tren, cruces, calles y muchos otros lugares p√∫blicos.  Nuestro seguimiento tambi√©n puede ser de gran ayuda para controlar el acceso, por ejemplo, a un almac√©n u otras oficinas importantes.  Y, por supuesto, rastrear personas y rostros ayuda a resolver problemas de seguridad.  ¬øAtrap√≥ a alguien robando de su tienda?  Agr√©guelo al PersonID, que devolvi√≥ Vision, en la lista negra de su software de an√°lisis de video, y la pr√≥xima vez que el sistema alertar√° inmediatamente a la seguridad si este tipo aparece nuevamente. <br><br><h3>  2.4.  En el comercio </h3><br>  Las empresas minoristas y de servicios diversos est√°n interesadas en el reconocimiento de colas.  Con Vision, puede reconocer que no se trata de una multitud aleatoria de personas, sino m√°s bien una cola, y determinar su longitud.  Y luego el sistema informa a las personas responsables sobre la cola para comprender la situaci√≥n: o bien esto es una afluencia de visitantes y se debe llamar a empleados adicionales, o alguien est√° hackeando sus responsabilidades laborales. <br><br>  Otra tarea interesante es la separaci√≥n de los empleados de la empresa en la sala de los visitantes.  Por lo general, el sistema aprende a separar objetos en ciertas prendas (c√≥digo de vestimenta) o con alguna caracter√≠stica distintiva (bufanda de firma, insignia en el cofre, etc.).  Esto ayuda a evaluar con mayor precisi√≥n la asistencia (para que los empleados solos no "terminen" las estad√≠sticas de las personas en el pasillo). <br><br>  Mediante el reconocimiento facial, puede evaluar su audiencia: cu√°l es la lealtad de los visitantes, es decir, cu√°ntas personas regresan a su instituci√≥n y con qu√© frecuencia.  Calcule cu√°ntos visitantes √∫nicos vienen a usted en un mes.  Para optimizar los costos de atraer y retener, puede averiguar el cambio de asistencia seg√∫n el d√≠a de la semana e incluso la hora del d√≠a. <br><br>  Los franquiciadores y las compa√±√≠as de la red pueden solicitar una evaluaci√≥n de la calidad de la marca de varios puntos de venta minorista a partir de fotograf√≠as: la presencia de logotipos, letreros, carteles, pancartas, etc. <br><br><h3>  2.5.  En el transporte </h3><br>  Otro ejemplo de seguridad a trav√©s de la anal√≠tica de video es la identificaci√≥n de elementos que quedan en los pasillos de aeropuertos o estaciones de trenes.  La visi√≥n puede ser entrenada para reconocer objetos de cientos de clases: muebles, bolsos, maletas, sombrillas, varios tipos de ropa, botellas, etc.  Si su sistema de an√°lisis de video detecta un objeto sin propietario y lo reconoce usando Vision, env√≠a una se√±al al servicio de seguridad.  Una tarea similar est√° relacionada con la detecci√≥n autom√°tica de situaciones no est√°ndar en lugares p√∫blicos: alguien se enferm√≥, o alguien fum√≥ en el lugar equivocado, o la persona se cay√≥ sobre los rieles, y as√≠ sucesivamente: todos estos patrones del sistema de an√°lisis de video pueden reconocer a trav√©s de API Vision. <br><br><h3>  2.6.  Flujo de trabajo </h3><br>  Otra aplicaci√≥n futura interesante de Vision que estamos desarrollando actualmente es el reconocimiento de documentos y su an√°lisis autom√°tico en bases de datos.  En lugar de ingresar manualmente (o peor a√∫n, ingresar) series interminables, n√∫meros, fechas de emisi√≥n, n√∫meros de cuenta, detalles bancarios, fechas y lugares de nacimiento y muchos otros datos formalizados, puede escanear documentos y enviarlos autom√°ticamente a trav√©s de un canal seguro a trav√©s de la API en la nube, donde el sistema estar√° sobre la marcha, estos documentos ser√°n reconocidos, analizados y devolver√°n una respuesta con los datos en el formato deseado para la entrada autom√°tica en la base de datos.  Hoy Vision ya sabe c√≥mo clasificar documentos (incluso en PDF): distingue pasaportes, SNILS, TIN, certificados de nacimiento, certificados de matrimonio y otros. <br><br>  Por supuesto, en todas estas situaciones, la red neuronal no es capaz de manejar de forma inmediata.  En cada caso, se construye un nuevo modelo para un cliente en particular, se tienen en cuenta muchos factores, matices y requisitos, se seleccionan los conjuntos de datos, se repiten los ajustes de las pruebas de capacitaci√≥n. <br><br><h1>  3. esquema de trabajo API </h1><br>  La ‚Äúpuerta de entrada‚Äù de Vision para los usuarios es la API REST.  En la entrada, puede tomar fotos, archivos de video y transmisiones desde c√°maras de red (transmisiones RTSP). <br><br>  Para usar Vision, debe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">registrarse</a> en Mail.ru Cloud Solutions y obtener tokens de acceso (client_id + client_secret).  La autenticaci√≥n del usuario se realiza utilizando el protocolo OAuth.  Los datos de origen en los cuerpos de las solicitudes POST se env√≠an a la API.  Y en respuesta, el cliente recibe el resultado de reconocimiento de la API en formato JSON, y la respuesta est√° estructurada: contiene informaci√≥n sobre los objetos encontrados y sus coordenadas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/bc3/859/d8cbc3859777f8f0a40712ef8e8a4e17.png"><br><br><div class="spoiler">  <b class="spoiler_title">Ejemplo de respuesta</b> <div class="spoiler_text"><pre><code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-attr"><span class="hljs-attr">"body"</span></span>:{ <span class="hljs-attr"><span class="hljs-attr">"objects"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_0"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_2"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person9"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">149</span></span>,<span class="hljs-number"><span class="hljs-number">60</span></span>,<span class="hljs-number"><span class="hljs-number">234</span></span>,<span class="hljs-number"><span class="hljs-number">181</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9999</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.45</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person10"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">159</span></span>,<span class="hljs-number"><span class="hljs-number">70</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">171</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9998</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.32</span></span> } ] } { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_3"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person11"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">157</span></span>,<span class="hljs-number"><span class="hljs-number">60</span></span>,<span class="hljs-number"><span class="hljs-number">232</span></span>,<span class="hljs-number"><span class="hljs-number">111</span></span>], <span class="hljs-attr"><span class="hljs-attr">"aliases"</span></span>:[<span class="hljs-string"><span class="hljs-string">"person12"</span></span>, <span class="hljs-string"><span class="hljs-string">"person13"</span></span>] <span class="hljs-string"><span class="hljs-string">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9998</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.32</span></span> } ] }, { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_4"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"undefined"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">147</span></span>,<span class="hljs-number"><span class="hljs-number">50</span></span>,<span class="hljs-number"><span class="hljs-number">222</span></span>,<span class="hljs-number"><span class="hljs-number">121</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9997</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.26</span></span> } ] } ], <span class="hljs-attr"><span class="hljs-attr">"aliases_changed"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"htmlencoded"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-attr"><span class="hljs-attr">"last_modified"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span> }</code> </pre> <br></div></div><br>  La respuesta tiene un par√°metro interesante de genialidad: esta es la "frescura" condicional de la cara en la foto, con ella seleccionamos la mejor toma de la secuencia.  Entrenamos a la red neuronal para predecir la probabilidad de que la imagen sea como en las redes sociales.  Cuanto mejor es la imagen y m√°s suave es la cara, mayor es la asombro. <br><br>  Vision API utiliza un concepto como el espacio.  Esta es una herramienta para crear diferentes conjuntos de caras.  Ejemplos de espacios son listas en blanco y negro, listas de visitantes, empleados, clientes, etc. Para cada token en Vision, puede crear hasta 10 espacios, en cada espacio puede haber hasta 50 mil PersonID, es decir, hasta 500 mil por un token .  Adem√°s, el n√∫mero de tokens por cuenta no est√° limitado. <br><br>  Hoy, la API admite los siguientes m√©todos de detecci√≥n y reconocimiento: <br><br><ul><li>  Reconocer / Establecer: definici√≥n y reconocimiento de caras.  Asigna autom√°ticamente un PersonID a cada cara √∫nica, devuelve el PersonID y las coordenadas de las caras encontradas. <br></li><li>  Eliminar: elimina un PersonID espec√≠fico de la base de datos de personas. <br></li><li>  Truncar: borrar todo el espacio de PersonID, √∫til si se us√≥ como prueba y necesita restablecer la base para la producci√≥n. <br></li><li>  Detectar: ‚Äã‚Äãdefinici√≥n de objetos, escenas, placas, atracciones, colas, etc. Devuelve la clase de objetos encontrados y sus coordenadas <br></li><li>  Detectar documentos: detecta tipos espec√≠ficos de documentos de la Federaci√≥n Rusa (distingue pasaporte, snls, posada, etc.). <br></li></ul><br>  Adem√°s, pronto terminaremos de trabajar en m√©todos para OCR, determinar el sexo, la edad y las emociones, as√≠ como resolver tareas de comercializaci√≥n, es decir, controlar autom√°ticamente la exhibici√≥n de productos en las tiendas.  Puede encontrar la documentaci√≥n completa de la API aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://mcs.mail.ru/help/vision-api</a> <br><br><h1>  4. Conclusi√≥n </h1><br>  Ahora, a trav√©s de la API p√∫blica, puede acceder al reconocimiento facial en fotos y videos, admite la definici√≥n de varios objetos, n√∫meros de autom√≥viles, atracciones, documentos y escenas completas.  Escenarios de aplicaci√≥n - Mar.  Ven, prueba nuestro servicio, establece las tareas m√°s dif√≠ciles para √©l.  Las primeras 5,000 transacciones son gratis.  Puede ser el "ingrediente faltante" para sus proyectos. <br><br>  El acceso a la API se puede obtener instant√°neamente al registrarse y conectarse a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Vision</a> .  Todos los usuarios de Habra: un c√≥digo promocional para transacciones adicionales.  ¬°Escriba una direcci√≥n de correo electr√≥nico personal en la que se registr√≥ la cuenta! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/449120/">https://habr.com/ru/post/449120/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../449108/index.html">UDB Que es esto Parte 7. M√≥dulo de control de temporizaci√≥n y reinicio</a></li>
<li><a href="../449110/index.html">Se corrigi√≥ un error relacionado con la imposibilidad de usar el alfabeto cir√≠lico en los nombres de las carpetas IMAP</a></li>
<li><a href="../449112/index.html">Nos retiramos, hablamos de dispositivos de audio que alguna vez fueron populares y que ya est√°n "desactualizados"</a></li>
<li><a href="../449114/index.html">Reaccionar en Œªambda</a></li>
<li><a href="../449118/index.html">P√≠ldora del demonio del Kremlin</a></li>
<li><a href="../449122/index.html">Lamentando la ausencia en C ++ de una est√°tica completa si o ...</a></li>
<li><a href="../449124/index.html">Tan dif√≠cil de encontrar, f√°cil de perder e imposible de emitir</a></li>
<li><a href="../449128/index.html">Las mejores empresas de desarrollo de juegos del mundo</a></li>
<li><a href="../449132/index.html">Los mejores 17 complementos para Android Studio</a></li>
<li><a href="../449134/index.html">Zoo afl</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
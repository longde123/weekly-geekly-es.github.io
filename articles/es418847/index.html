<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍👦 🧘🏾 👨🏾‍🌾 Red neuronal óptica 🏺 🕡 🌶️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Máscara de fase multicapa entrenada (clasificador de caracteres escrito a mano). A la derecha hay un modelo físico de una red neuronal óptica D²NN imp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Red neuronal óptica</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/418847/"><img src="https://habrastorage.org/webt/m2/xq/tj/m2xqtjhmcoi7hwz757dfzhrhb-o.jpeg"><br>  <i><font color="gray">Máscara de fase multicapa entrenada (clasificador de caracteres escrito a mano).</font></i>  <i><font color="gray">A la derecha hay un modelo físico de una red neuronal óptica D²NN impresa en una impresora 3D: capas de 8 × 8 cm con una distancia de 3 cm entre sí</font></i> <br><br>  Un equipo de investigadores de la Universidad de California en Los Ángeles ha desarrollado un nuevo tipo de red neuronal que utiliza luz en lugar de electricidad para funcionar.  La revista Science publicó <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un artículo que</a> describe una idea, un dispositivo de trabajo, su rendimiento y tipos de aplicaciones que, según los autores, son buenos para la informática en un nuevo tipo de red neuronal. <br><br>  La red neuronal profunda difractiva completamente óptica (D²NN), que se forma físicamente a partir de una variedad de superficies reflectantes o transparentes.  Estas superficies trabajan juntas, realizando una función arbitraria, adquirida como resultado del entrenamiento.  Si bien la obtención del resultado y el pronóstico en la red física se organiza de manera completamente óptica, la parte de capacitación con el diseño de la estructura de las superficies reflectantes se calcula en una computadora. <br><a name="habracut"></a><br>  Entonces, en el modelo físico, D²NN consta de varias capas reflectantes o transparentes.  En estas capas, cada punto transmite o refleja una onda entrante.  Por lo tanto, este punto es una neurona artificial que está conectada a las neuronas de las siguientes capas a través de la difracción óptica.  La estructura de D²NN se muestra en la ilustración. <br><br><img src="https://habrastorage.org/webt/p8/ui/gd/p8uigdcnfuvebalr6mhjxseucxy.png"><br>  <i><font color="gray">Red neuronal profunda difractiva (D²NN).</font></i> <br><br>  En la ilustración A, un diagrama de varias capas transparentes / reflectantes, donde cada punto es una neurona con un coeficiente complejo de transparencia o reflexión.  Estos coeficientes se derivan del aprendizaje profundo.  Después de la fase de entrenamiento, el diseño D²NN es fijo, y las placas correspondientes se imprimen en la impresora 3D, que calcula la función obtenida como resultado del entrenamiento preliminar.  A diferencia de las redes informáticas electrónicas, aquí los cálculos se realizan <b>a la velocidad de la luz</b> . <br><br>  Durante los experimentos, los científicos entrenaron y probaron experimentalmente varios tipos de D²NN.  La Figura B muestra el clasificador de caracteres escritos a mano, y la Figura C muestra la lente de imagen. <br><br>  La parte inferior de la ilustración compara el funcionamiento de la red neuronal óptica difractiva (izquierda) y la red neuronal electrónica (derecha).  Basado en ondas coherentes, D²NN opera con valores de entrada complejos y sesgo multiplicativo.  Los pesos en D²NN se basan en la difracción del espacio libre y determinan la interferencia coherente de las ondas secundarias, que son la fase y / o amplitud modulada por las capas anteriores.  El símbolo "ο" significa la operación del producto de Hadamard, es decir, la multiplicación lógica bit a bit de los miembros correspondientes de dos secuencias de igual longitud. <br><br>  Los investigadores explican que la estructura de la red neuronal óptica está organizada de acuerdo <b>con el principio de Huygens</b> , según el cual cada elemento del frente de onda puede considerarse como el centro de la perturbación secundaria que genera ondas esféricas secundarias, y el campo de luz resultante en cada punto en el espacio estará determinado por la interferencia de estas ondas.  Por lo tanto, la neurona artificial en D²NN está conectada a otras neuronas de la siguiente capa a través de una onda secundaria, que está modulada en amplitud y fase por el patrón de interferencia de entrada creado por las capas anteriores y el coeficiente local de transmisión / reflexión en este punto. <br><br>  Por analogía con las redes neuronales profundas estándar, podemos considerar el coeficiente de transmisión / reflexión de cada punto / neurona como el término multiplicativo “sesgo”, que se corrige iterativamente durante el entrenamiento de la red de difracción utilizando el método de error de propagación inversa.  Después del entrenamiento numérico, el diseño D2NN se fija y se determinan los coeficientes de transmisión / reflexión de las neuronas de todas las capas.  Luego puede hacer las capas calculadas por cualquier método: impresión 3D, litografía, etc. <br><br>  Los científicos enfatizan que la red neuronal óptica realiza una función a la velocidad de la luz y no necesita energía.  Por lo tanto, es una forma efectiva y rápida de implementar tareas de aprendizaje automático. <br><br>  Para probar la idea, los investigadores crearon una red neuronal que puede reconocer números del cero al nueve, e informar el resultado.  Después de entrenar 55,000 imágenes de números, la red neuronal impresa de siete capas mostró una precisión del 93.39%. <br><br><img src="https://habrastorage.org/webt/ci/rf/0t/cirf0t6vh5lgkblbz3-pct4cw4i.png"><br><br>  Al reconocer la ropa y los zapatos de moda, una red neuronal de cinco capas mostró una precisión del 81.13%, una red neuronal de diez capas: 86.60%. <br><br><img src="https://habrastorage.org/webt/yh/2g/qv/yh2gqvdh5et99u1dype75pgfgvm.png"><br><br>  Según los investigadores, la red neuronal de tipo óptico se puede utilizar en dispositivos especializados que requieren alta velocidad, como determinar una persona específica en una multitud de personas en movimiento. <br><br>  El artículo científico fue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicado</a> el 26 de julio de 2018 en la revista <i>Science</i> (doi: 10.1126 / science.aat8084, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pdf</a> ). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es418847/">https://habr.com/ru/post/es418847/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es418837/index.html">La vida en Alemania a través de los ojos de mi esposa.</a></li>
<li><a href="../es418839/index.html">Kivy - Marco de desarrollo multiplataforma n. ° 1</a></li>
<li><a href="../es418841/index.html">20 estados están tratando de detener la distribución de archivos CAD de Internet para imprimir armas</a></li>
<li><a href="../es418843/index.html">Producción Hell STALKER: Shadow of Chernobyl</a></li>
<li><a href="../es418845/index.html">Cómo Roskomnadzor bloquea HideMy.name y qué sucederá después. Una palabra para los fundadores del servicio VPN.</a></li>
<li><a href="../es418849/index.html">El resumen de eventos para profesionales de recursos humanos en el campo de TI para agosto de 2018</a></li>
<li><a href="../es418851/index.html">Cómo comprar la ilusión de seguridad en forma de relojes inteligentes para niños</a></li>
<li><a href="../es418853/index.html">Detalles sobre la actualización de Testigos segregados y las consecuencias de su adopción en Bitcoin</a></li>
<li><a href="../es418855/index.html">Abrir el seminario web "Creación de una aplicación en Webpack + React + Express"</a></li>
<li><a href="../es418857/index.html">Preparación de certificados SSL para la instalación</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
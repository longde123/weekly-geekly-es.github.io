<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõèÔ∏è ü§µüèæ üßòüèª C√°maras de profundidad: revoluci√≥n silenciosa (cuando los robots lo ver√°n) Parte 1 üñïüèΩ ‚ù£Ô∏è üë®‚Äçüë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recientemente, describ√≠, gracias a qu√© robots comenzar√°n ma√±ana MUCHO mejor para pensar (una publicaci√≥n sobre aceleraci√≥n de hardware de redes neuron...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√°maras de profundidad: revoluci√≥n silenciosa (cuando los robots lo ver√°n) Parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457524/"><img src="https://habrastorage.org/getpro/habr/post_images/917/25a/9a4/91725a9a49451111a6d55d1015cc297c.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/f58/7fd/ebe/f587fdebeedd2f17fe6f4122a68dff9f.png"><br><br>  Recientemente, describ√≠, gracias a qu√© robots comenzar√°n ma√±ana MUCHO mejor para pensar (una publicaci√≥n sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aceleraci√≥n de hardware de redes neuronales</a> ).  Hoy veremos por qu√© los robots pronto ser√°n mucho mejores para ver.  En algunas situaciones, mucho mejor que una persona. <br><br>  Hablaremos de c√°maras de profundidad que filman video, en cada p√≠xel de las cuales se almacena no el color, sino la distancia al objeto en este punto.  Estas c√°maras han existido durante m√°s de 20 a√±os, pero en los √∫ltimos a√±os la velocidad de su desarrollo ha crecido muchas veces y ya podemos hablar de la revoluci√≥n.  Y multi-vector.  Se est√° desarrollando r√°pidamente en las siguientes √°reas: <br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Luz estructurada de una c√°mara</a> , o una c√°mara de luz estructural, cuando hay un proyector (a menudo infrarrojo) y una c√°mara que registra la luz estructural del proyector; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√°maras de tiempo de vuelo</a> , o c√°maras basadas en la medici√≥n del retraso en la luz reflejada; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Profundidad de las c√°maras est√©reo</a> : la direcci√≥n cl√°sica y, tal vez, la m√°s famosa, de la profundidad del edificio desde est√©reo; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√°mara de campo de luz</a> : tambi√©n son c√°maras de campo de luz o c√°maras ple√≥pticas, sobre las cuales hab√≠a una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaci√≥n detallada por</a> separado; <br></li><li>  Y finalmente, las c√°maras basadas en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tecnolog√≠a Lidar</a> , especialmente los nuevos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lidars de estado s√≥lido</a> , que funcionan sin fallas aproximadamente 100 veces m√°s que los lidares comunes y producen la imagen rectangular habitual. <br></li></ul><br>  A qui√©n le importa c√≥mo se ver√°, as√≠ como una comparaci√≥n de diferentes enfoques y su aplicaci√≥n actual y de ma√±ana, ¬°bienvenido! <br><a name="habracut"></a><br>  Entonces!  Analizaremos las principales direcciones de desarrollo de c√°maras de profundidad o principios realmente diferentes para medir la profundidad.  Con sus pros y sus contras. <br><br><h1>  M√©todo 1: c√°mara de luz estructurada </h1><br>  Comencemos con uno de los m√©todos m√°s simples, antiguos y relativamente baratos de medir la profundidad: la luz estructurada.  Este m√©todo apareci√≥ esencialmente de inmediato, tan pronto como aparecieron las c√°maras digitales, es decir  Hace m√°s de 40 a√±os y se simplific√≥ enormemente un poco m√°s tarde, con la llegada de los proyectores digitales. <br><br>  La idea b√°sica es extremadamente simple.  Ponemos al lado del proyector, que crea, por ejemplo, rayas horizontales (y luego verticales) y al lado de la c√°mara, que toma una imagen con rayas, como se muestra en esta figura: <br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/416/7c3/ed44167c3f6f9e1af2af2eda53f6ec97.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Autodesk: Escaneo 3D de luz estructurada</a></i> <br><br>  Dado que la c√°mara y el proyector est√°n desplazados entre s√≠, las tiras tambi√©n se desplazar√°n en proporci√≥n a la distancia al sujeto.  Al medir este desplazamiento, podemos calcular la distancia al objeto: <br><img src="https://habrastorage.org/webt/27/oo/xp/27ooxpjh4fgdijfazupjylg1ang.png">  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.vision-systems.com/</a></i> <br><br>  De hecho, con el proyector m√°s barato (y su precio comienza en 3.000 rublos) y un tel√©fono inteligente, puede medir la profundidad de las escenas est√°ticas en una habitaci√≥n oscura: <br><img src="https://habrastorage.org/getpro/habr/post_images/f41/e50/8b8/f41e508b881e7d1f1b36bbc0dfb9c179.png"><img src="https://habrastorage.org/getpro/habr/post_images/464/662/9ee/4646629ee8562fe3a76beaef82e4c284.png"><img src="https://habrastorage.org/getpro/habr/post_images/85a/493/ee0/85a493ee0b020b885518bfcddb2c9b1d.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Autodesk: Escaneo 3D de luz estructurada</a></i> <br><br>  Est√° claro que al hacerlo, habr√° que resolver un mont√≥n de tareas: la calibraci√≥n del proyector, la calibraci√≥n de la c√°mara del tel√©fono, el reconocimiento de cambio de banda, etc., pero todas estas tareas son bastante capaces incluso para los estudiantes de secundaria avanzados que aprenden programaci√≥n. <br><br>  Este principio de medici√≥n de profundidad se hizo m√°s conocido cuando, en 2010, Microsoft lanz√≥ el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sensor de</a> profundidad <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MS Kinect</a> por $ 150, que en ese momento era revolucionario y barato. <br><img src="https://habrastorage.org/getpro/habr/post_images/89c/3d5/8b2/89c3d58b24c16b18593782bd822a5bd2.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reconstrucci√≥n de objetos parcialmente ocluidos utilizando m√∫ltiples sensores Kinect</a></i> <br><br>  A pesar de que, adem√°s de medir realmente la profundidad con un proyector IR y una c√°mara IR, Kinect tambi√©n grab√≥ videos RGB normales, ten√≠a cuatro micr√≥fonos con reducci√≥n de ruido y pod√≠a ajustarse a la altura de una persona, inclinando hacia arriba o hacia abajo autom√°ticamente, se integr√≥ de inmediato en el interior procesamiento de datos, que emiti√≥ a la consola de inmediato un mapa de profundidad listo: <br><img src="https://habrastorage.org/getpro/habr/post_images/a48/49e/1a1/a4849e1a19f745aedb92800debafc6f7.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Implementaci√≥n de botones de interfaz de usuario natural usando Kinect</a></i> <br><br>  En total, se vendieron unos 35 millones de dispositivos, lo que convierte a Kinect en la primera c√°mara de profundidad masiva de la historia.  Y si considera que ciertamente hab√≠a c√°maras de profundidad, pero generalmente vend√≠an un m√°ximo de cientos y costaban al menos un orden de magnitud m√°s caro, esta fue una revoluci√≥n que proporcion√≥ una gran inversi√≥n en esta √°rea. <br><br>  Una raz√≥n importante para el √©xito fue que cuando Microsoft lanz√≥ la Xbox 360, ya hab√≠a algunos juegos que usaban activamente a Kinect como sensor.  El despegue fue r√°pido: <br><img width="75%" src="https://habrastorage.org/getpro/habr/post_images/895/5be/676/8955be6766420326e6fc7c1ab2371385.png"><br><br>  Adem√°s, Kinect incluso logr√≥ ingresar al Libro Guinness de los R√©cords como el dispositivo m√°s vendido en la historia.  Es cierto que Apple pronto expuls√≥ a Microsoft de este lugar, pero no obstante.  Para un nuevo sensor experimental que funciona adem√°s del dispositivo principal para convertirse en el dispositivo electr√≥nico m√°s vendido en la historia, este es simplemente un gran logro: <br><img src="https://habrastorage.org/getpro/habr/post_images/051/f2a/cf2/051f2acf275e677c10252fc38541ff82.png"><br><br>  En las conferencias, me gusta preguntarle a la audiencia de d√≥nde provienen todos estos millones de clientes.  ¬øQui√©nes eran todas estas personas? <br><br>  Como regla general, nadie adivina, pero a veces, especialmente si el p√∫blico es mayor y tiene m√°s experiencia, dan la respuesta correcta: las ventas fueron impulsadas por padres estadounidenses, que vieron con deleite que sus hijos pod√≠an jugar en la consola y no sentarse en el sof√° con un grueso bot√≠n, y saltando frente al televisor.  ¬°Fue un gran avance!  Millones de madres y padres se apresuraron a pedir un dispositivo para sus hijos. <br><br>  En general, cuando se trata de reconocimiento de gestos, las personas generalmente creen ingenuamente que solo los datos de una c√°mara 2D son suficientes.  Despu√©s de todo, ¬°vieron muchas demostraciones hermosas!  La realidad es mucho m√°s severa.  La precisi√≥n del reconocimiento de los gestos de una transmisi√≥n de video 2D desde una c√°mara y la precisi√≥n del reconocimiento de los gestos desde la profundidad de una c√°mara difieren en un orden de magnitud.  Desde una c√°mara de profundidad, o m√°s bien, desde una c√°mara RGB combinada con una c√°mara de profundidad (esta √∫ltima es importante), puede reconocer los gestos con mucha m√°s precisi√≥n y a un costo menor (incluso si la habitaci√≥n est√° oscura) y esto ha tra√≠do el √©xito a la primera c√°mara de profundidad masiva. <br><br>  Sobre Kinect en Habr√© en el momento en que escribieron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mucho</a> , muy brevemente c√≥mo funciona. <br><br>  Un proyector de infrarrojos proporciona un conjunto pseudoaleatorio de puntos en el espacio, cuyo desplazamiento determina la profundidad en un p√≠xel dado: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55f/c46/d72/55fc46d72e36087ac7522312d791af6f.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Estructuras planas de detecci√≥n de profundidad: detecci√≥n de configuraciones de muebles de oficina</a></i> <br><br>  La resoluci√≥n de la c√°mara se declara como 640x480, pero realmente hay un lugar alrededor de 320x240 con un filtrado bastante fuerte y la imagen en ejemplos reales se ve as√≠ (es decir, bastante aterrador): <br><img src="https://habrastorage.org/webt/a9/ni/up/a9niup8_g7i8a1x3n_0oaikpee0.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reconstrucci√≥n de objetos parcialmente ocluidos utilizando m√∫ltiples sensores Kinect</a></i> <br><br>  Las "sombras" de los objetos son claramente visibles, ya que la c√°mara y el proyector est√°n lo suficientemente separados.  Se puede ver que se realizan desplazamientos de varios puntos del proyector para predecir la profundidad.  Adem√°s, hay un filtrado (duro) por vecinos inmediatos, pero a√∫n as√≠ el mapa de profundidad es bastante ruidoso, especialmente en las fronteras.  Esto conduce a un ruido bastante notable en la superficie de los objetos resultantes, que debe suavizarse adicionalmente y de manera no trivial: <br><img src="https://habrastorage.org/webt/ph/e-/dl/phe-dlp6dczaztxgy7q4p-tyxtg.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Biblioteca Java J4K para Kinect SDK de Microsoft</a></i> <br><br>  Sin embargo, solo $ 150 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hoy ya son $ 69</a> , aunque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">es m√°s cercano a $ 200</a> , por supuesto), ¬°y usted "ve" la profundidad!  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Realmente</a> hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">muchos</a> productos en serie. <br><br>  Por cierto, en febrero de este a√±o, se anunci√≥ un nuevo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Azure Kinect</a> : <br><img src="https://habrastorage.org/webt/l6/0y/b2/l60yb2lcfeuufoe6q6jdd0e-jg0.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Microsoft anuncia Azure Kinect, disponible para pre-pedido ahora</a></i> <br><br>  Sus entregas a desarrolladores en los EE. UU. Y China deber√≠an comenzar el 27 de junio, es decir,  literalmente ahora mismo.  De las capacidades, adem√°s de la resoluci√≥n notablemente mejor de RGB y la mejor calidad de las c√°maras de profundidad (prometen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1024x1024</a> a 15 FPS y 512x512 a 30 FPS y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la demostraci√≥n de</a> la c√°mara de ToF es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">claramente visible</a> ), se admite claramente la compatibilidad con la colaboraci√≥n de varios dispositivos listos para usar. el sol, el error es inferior a 1 cm a una distancia de 4 metros y 1-2 mm a una distancia de menos de 1 metro, lo que suena extremadamente interesante, por lo que esperamos, esperamos: <br><img src="https://habrastorage.org/getpro/habr/post_images/0d1/972/90b/0d197290bf6363f157fa9955070c4b5a.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Presentaci√≥n de Azure Kinect DK</a></i> <br><br>  El siguiente producto <b>masivo</b> , donde se realiz√≥ una c√°mara de profundidad con una luz estructurada, no fue una consola de juegos, sino ... (redoble de bater√≠a) correctamente: ¬° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">iPhone X</a> ! <br><br>  Su tecnolog√≠a Face ID es una c√°mara de profundidad t√≠pica con un proyector Dot infrarrojo t√≠pico y una c√°mara infrarroja (por cierto, ahora entiendes por qu√© est√°n en los bordes del flequillo, espaciados lo m√°s posible entre s√≠; esta es una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">base est√©reo</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/755/6e2/6de/7556e26dea5a132b997658d386d74e7f.png"><br><br>  La resoluci√≥n del mapa de profundidad es incluso menor que la de Kinect: aproximadamente 150x200.  Est√° claro que si usted dice: "Nuestra resoluci√≥n es de aproximadamente 150x200 p√≠xeles o 0.03 megap√≠xeles", la gente dir√° breve y sucintamente: "¬°Apesta!"  Y si dices <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Proyector de puntos: se proyectan m√°s de 30,000 puntos invisibles en tu cara"</a> , la gente dice: "¬°Guau, 30 mil puntos invisibles, genial!".  Algunas rubias preguntar√°n si aparecen pecas desde puntos invisibles.  ¬°Y el tema ir√° a las masas!  Por lo tanto, la segunda opci√≥n era la hipermetrop√≠a en la publicidad.  La resoluci√≥n es peque√±a por tres razones: en primer lugar, los requisitos de miniatura, en segundo lugar, el consumo de energ√≠a y, en tercer lugar, los precios. <br><br>  Sin embargo, esta es otra c√°mara de profundidad en una luz estructurada, que se ha incluido en una serie de millones de copias y ya ha sido repetida por otros fabricantes de tel√©fonos inteligentes, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">por ejemplo, (¬°sorpresa-sorpresa!) Huawei</a> (que eludi√≥ a Apple en ventas de tel√©fonos inteligentes el a√±o pasado).  Solo Huawei tiene una c√°mara a la derecha y el proyector a la izquierda, pero tambi√©n, por supuesto, a lo largo de los bordes del ‚Äúflequillo‚Äù: <br><img src="https://habrastorage.org/webt/zt/2h/ab/zt2habvk5zl2pkyvmeerbzacjfq.png"><br>  <i>Fuente: la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">actualizaci√≥n de Huawei Mate 20 Pro permite a los usuarios agregar una segunda cara para el desbloqueo facial</a></i> <br><br>  Al mismo tiempo, se declaran 300,000 puntos, es decir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">, 10 veces m√°s que Apple</a> , y la c√°mara frontal es mejor <s>y la fuente es m√°s grande</s> .  ¬øHay una exageraci√≥n con respecto a 300 mil? Es dif√≠cil de decir, pero Huawei muestra un muy buen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">escaneo 3D de objetos con una c√°mara frontal</a> .  Las pruebas independientes son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s aterradoras</a> , pero este es claramente el comienzo del tema y la infancia de la tecnolog√≠a de las c√°maras de profundidad en miniatura de bajo consumo de energ√≠a y los anuncios de c√°mara a finales de este a√±o ya es notablemente mejor en rendimiento. <br><br>  Al mismo tiempo, es comprensible por qu√© se utiliz√≥ la tecnolog√≠a de identificaci√≥n facial en los tel√©fonos.  En primer lugar, ahora no puedes enga√±ar al detector mostrando una foto de tu cara (o video de la tableta).  En segundo lugar, la cara cambia mucho cuando cambia la iluminaci√≥n, pero su forma no, lo que nos permite identificar con mayor precisi√≥n a la persona junto con los datos de la c√°mara RGB: <br><img src="https://habrastorage.org/getpro/habr/post_images/5c9/12b/e86/5c912be86bf5a47aa02bcce67e48f148.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">foto de TI de la misma persona</a></i> <br><br>  Obviamente, el sensor infrarrojo tiene problemas inherentes.  En primer lugar, nuestro proyector relativamente d√©bil brilla al sol una o dos veces, por lo que estas c√°maras no funcionan en la calle.  Incluso a la sombra, si la pared blanca de un edificio est√° iluminada por el sol, puede tener grandes problemas con Face ID.  El nivel de ruido en Kinect tambi√©n cambia incluso cuando el sol est√° cubierto por nubes: <br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/477/bb5/e5b477bb581588840cb6d1219b7899dd.png"><br>  <i>Fuente: esta y las dos im√°genes siguientes</i> - <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">materiales Basler AG</a></i> <br><br>  Otro gran problema es la reflexi√≥n y la reflexi√≥n.  Dado que la luz infrarroja tambi√©n se refleja, para fotografiar un costoso hervidor de acero inoxidable, una mesa barnizada o una pantalla de vidrio con Kinect ser√° problem√°tico: <br><img src="https://habrastorage.org/getpro/habr/post_images/872/913/e20/872913e207e550f6e7eb609510fd70f6.png"><br><br>  Y finalmente, dos c√°maras que disparan un objeto pueden interferir entre s√≠.  Curiosamente, en el caso de la luz estructurada, puede hacer que el proyector parpadee y comprender d√≥nde est√°n nuestros puntos y d√≥nde no, pero esta es una historia separada y bastante complicada: <br><img src="https://habrastorage.org/getpro/habr/post_images/c9f/427/3e3/c9f4273e3bf9682c1b6869cbfaaf22b5.png"><br><br>  Ahora sabes c√≥mo romper FaceID ... <br><br>  Sin embargo, para dispositivos m√≥viles, la luz estructurada parece el compromiso m√°s razonable hoy en d√≠a: <br><img src="https://habrastorage.org/getpro/habr/post_images/cc8/77f/743/cc877f74308b460ca7cd306856ba637a.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Las empresas de tel√©fonos inteligentes luchan por igualar el rendimiento y el costo de la c√°mara Apple 3D</a></i> <br><br>  Para la luz estructurada, el bajo costo de un sensor convencional es tal que su uso en la mayor√≠a de los casos est√° m√°s que justificado.  Lo que dio vida a una gran cantidad de startups que operan de acuerdo con la f√≥rmula: sensor barato + software complejo = resultado bastante aceptable. <br><br>  Por ejemplo, nuestro antiguo estudiante de posgrado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Maxim Fedyukov</a> , quien ha estado involucrado en la reconstrucci√≥n 3D desde 2004, cre√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Texel</a> , cuyo producto principal es una plataforma con 4 c√°maras Kinect y un software que convierte a una persona en un monumento potencial en 30 segundos.  Bueno, o una figura de escritorio.  Este es quien tiene suficiente dinero.  O puede enviar a sus amigos fotos baratas y alegres de su modelo 3D (por alguna raz√≥n, el caso m√°s popular por alguna raz√≥n).  Ahora env√≠an sus plataformas y software al extranjero desde el Reino Unido a Australia: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/VLaZ_jDuZ30" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">crear un modelo 3D de una persona en 30 segundos</a></i> <br><br>  Como bailarina, no puedo soportar bellamente, as√≠ que solo miro pensativamente la aleta de un tibur√≥n nadando: <br><img src="https://habrastorage.org/getpro/habr/post_images/fca/b59/2b2/fcab592b290ca2a9838748bc3ac82ce2.gif"><br>  <i>Fuente: materiales del autor.</i> <br><br>  En general, un nuevo tipo de sensores gener√≥ nuevos proyectos de arte.  En invierno, vi una pel√≠cula de realidad virtual bastante curiosa rodada con Kinect.  A continuaci√≥n se muestra una interesante visualizaci√≥n del baile, tambi√©n hecha con Kinect (parece que se usaron 4 c√°maras), y a diferencia del ejemplo anterior, no lucharon con el ruido, sino que agregaron detalles divertidos: <br><img src="https://habrastorage.org/getpro/habr/post_images/cd3/072/e7f/cd3072e7ffef9e111604f9d6e83e640e.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un espect√°culo de danza capturado con un sensor Kinect y visualizado con software 3D</a></i> <br><br>  Qu√© tendencias se pueden observar en el √°rea: <br><ul><li>  Como sabe, los sensores digitales de las c√°maras modernas son sensibles a la radiaci√≥n infrarroja, por lo que debe usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtros de bloqueo</a> especiales para que el ruido infrarrojo no estropee la imagen (incluso aparece la direcci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">disparo art√≠stico en el rango infrarrojo</a> , incluso cuando se retira el filtro del sensor).  Esto significa que se invierten enormes cantidades de dinero en miniaturizaci√≥n, mayor resoluci√≥n y sensores m√°s baratos, que pueden usarse como infrarrojos (con un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtro especial</a> ). <br></li><li>  Del mismo modo, los algoritmos para procesar mapas de profundidad ahora est√°n mejorando r√°pidamente, incluidos los m√©todos de filtrado cruzado, cuando los datos de un sensor RGB y los datos ruidosos por profundidad le permiten obtener un muy buen video de profundidad juntos.  Al mismo tiempo, utilizando enfoques de redes neuronales, se hace posible aumentar dr√°sticamente la velocidad para obtener un buen resultado. <br></li><li>  Todas las principales empresas trabajan en esta √°rea, especialmente los fabricantes de tel√©fonos inteligentes. <br></li></ul><br>  Como resultado: <br><ul><li>  Podemos esperar un aumento dram√°tico en la resoluci√≥n y precisi√≥n de disparar c√°maras de profundidad de Luz Estructurada en los pr√≥ximos 5 a√±os. <br></li><li>  Habr√° una reducci√≥n (aunque m√°s lenta) en el consumo de energ√≠a de los sensores m√≥viles, lo que simplificar√° el uso de sensores de pr√≥xima generaci√≥n en tel√©fonos inteligentes, tabletas y otros dispositivos m√≥viles. <br></li></ul><br>  En cualquier caso, lo que estamos viendo ahora es la infancia de la tecnolog√≠a.  Los primeros productos en masa en los que se acaba de lanzar la depuraci√≥n de la producci√≥n y el uso de un nuevo tipo de datos inusual: video con profundidad. <br><br><h1>  M√©todo 2: c√°mara de tiempo de vuelo </h1><br>  La siguiente forma de obtener profundidad es m√°s interesante.  Se basa en la medici√≥n del retraso de la luz de ida y vuelta (ToF - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tiempo de vuelo</a> ).  Como saben, la velocidad de los procesadores modernos es alta, y la velocidad de la luz es peque√±a.  En un ciclo de reloj del procesador a 3 GHz, la luz logra volar solo 10 cent√≠metros.  O 10 medidas por metro.  Mucho tiempo, si alguien se dedicaba a la optimizaci√≥n de bajo nivel.  En consecuencia, instalamos una fuente de luz pulsada y una c√°mara especial: <br><img src="https://habrastorage.org/getpro/habr/post_images/6e0/565/fc8/6e0565fc82326ab1f3487051f20ef58d.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La c√°mara Basler Time-of-Flight (ToF)</a></i> <br><br>  De hecho, necesitamos medir el retraso con el que la luz vuelve a cada punto: <br><img src="https://habrastorage.org/getpro/habr/post_images/26b/fd8/bc8/26bfd8bc85003daa2b45d9dd11dfb31d.png"><img src="https://habrastorage.org/getpro/habr/post_images/4f6/7a5/13d/4f67a513d6cd9fb6e9370d680a28db79.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La c√°mara Basler Time-of-Flight (ToF)</a></i> <br><br>  O, si tenemos varios sensores con diferentes tiempos de acumulaci√≥n de carga, entonces, conociendo el cambio de tiempo relativo a la fuente para cada sensor y el brillo del flash de disparo, podemos calcular el cambio y, en consecuencia, la distancia al objeto, y al aumentar el n√∫mero de sensores, aumentamos la precisi√≥n: <br><img src="https://habrastorage.org/getpro/habr/post_images/e78/c93/d70/e78c93d70d056347e6e963bb191f3016.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/27f/26f/e8d/27f26fe8d30826c317bbc54687fbe169.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√°mara de tiempo de vuelo de Larry Li: una introducci√≥n</a></i> <br><br>  El resultado es un esquema de la c√°mara con iluminaci√≥n LED o, menos com√∫nmente, l√°ser ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VCSEL</a> ) de infrarrojos: <br><img src="https://habrastorage.org/getpro/habr/post_images/1b8/5cf/e74/1b85cfe7436630ed22abf6f9ec4c0555.png"><br>  <i>Fuente: Una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">muy buena descripci√≥n del trabajo de ToF en allaboutcircuits.com</a></i> <br><br>  En este caso, la imagen se obtiene a una resoluci√≥n bastante baja (porque necesitamos colocar varios sensores con diferentes tiempos de sondeo uno al lado del otro), pero potencialmente con un FPS alto.  Y los problemas est√°n principalmente en los l√≠mites de los objetos (lo cual es t√≠pico para todas las c√°maras de profundidad).  Pero sin las "sombras" t√≠picas de la luz estructurada: <br><img src="https://habrastorage.org/getpro/habr/post_images/f25/aac/393/f25aac393d27eab254d2d2062f70aace.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">video de Basler AG</a></i> <br><br>  En particular, fue este tipo de c√°mara (ToF) la que prob√≥ activamente Google en el proyecto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google Tango</a> , que estuvo bien representado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este video</a> .  El significado era simple: combinar los datos del giroscopio, el aceler√≥metro, la c√°mara RGB y la c√°mara de profundidad, creando una escena tridimensional frente al tel√©fono inteligente: <br><img src="https://habrastorage.org/getpro/habr/post_images/0e5/48d/a33/0e548da33324491beed0083067daf629.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Proyecto Tango de Google ahora est√° dise√±ado para tel√©fonos inteligentes</a></i> <br><br>  El proyecto en s√≠ no funcion√≥ (mi opini√≥n es que estaba un poco adelantado a su tiempo), pero cre√≥ requisitos previos importantes para crear una ola de inter√©s en AR (realidad aumentada) y, en consecuencia, desarrollar sensores que puedan funcionar con √©l.  Ahora todos sus logros se vierten en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ARCore</a> de Google. <br><br>  En general, el volumen de mercado de las c√°maras ToF crece aproximadamente un 30% cada 3 a√±os, lo que es un crecimiento bastante exponencial, y pocos mercados crecen tan r√°pido: <br><img src="https://habrastorage.org/getpro/habr/post_images/9ae/e45/a34/9aee45a343486d009e472897358a57c6.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Potencial de c√°maras de tiempo de vuelo y penetraci√≥n en el mercado</a></i> <br><br>  Un motor serio del mercado hoy en d√≠a es el desarrollo r√°pido (y tambi√©n exponencial) de robots industriales, para los cuales las c√°maras ToF son una soluci√≥n ideal.  Por ejemplo, si su robot empaqueta cajas, entonces con una c√°mara 2D ordinaria, determinar que est√° comenzando a atascar el cart√≥n es una tarea extremadamente no trivial.  Y para una c√°mara ToF, es trivial "ver" y procesarla.  Y muy rapido.  Como resultado, vemos un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">auge en las c√°maras industriales ToF</a> : <br><img width="50%" src="https://habrastorage.org/webt/rg/7k/oh/rg7kohuwwuzhwji6zrqr19a54yy.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/843/1a9/ac6/8431a9ac68acfef82b2f9dc5e5579d32.png"><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/c66/2c5/5c1/c662c55c1309b666ef460c5944289fbd.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/5d7/514/fda/5d7514fda4a985c28cbc6695e1a3e27a.png"><br>  Naturalmente, esto tambi√©n lleva a la aparici√≥n de productos caseros que utilizan c√°maras de profundidad.  Por ejemplo, una c√°mara de seguridad con una unidad de video nocturno y una c√°mara de profundidad ToF de German <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PMD Technologies</a> , que ha estado desarrollando c√°maras 3D durante <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s de 20 a√±os</a> : <br><img src="https://habrastorage.org/webt/dj/uz/_m/djuz_mmy6htracd_tgkn_clt698.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La detecci√≥n de profundidad de tiempo de vuelo en 3D aporta magia a la nueva c√°mara inteligente para el hogar Lighthouse</a></i> <br><br>  ¬øRecuerdas la capa de invisibilidad bajo la cual Harry Potter se escond√≠a? <br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/4cc/5ac/d00/4cc5acd002df5032104a965cc01ec109.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La capa de invisibilidad de Harry Potter tiene una historia de origen y puede existir pronto en la vida real</a></i> <br><br>  Me temo que la c√°mara alemana lo detectar√° una o dos veces.  Y ser√° dif√≠cil colocar una pantalla con una imagen frente a dicha c√°mara (esto no es una protecci√≥n que lo distraiga): <br><img src="https://habrastorage.org/getpro/habr/post_images/af4/649/03f/af464903f5fdbda4fca2c1734f476ec5.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fragmento de la pel√≠cula "Misi√≥n imposible: protocolo fantasma"</a></i> <br><br>  Parece que para las nuevas c√°maras de CCTV, se requerir√° la magia no infantil de Hogwarts para enga√±arlas con una c√°mara de profundidad ToF que pueda grabar ese video en completa oscuridad: <br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/b34/f9f/884/b34f9f8844825387a528da8d630a69cb.gif"><br>  Pretender ser una pared, una pantalla y otras formas de protegerse del hecho de que la c√°mara combinada ToF + RGB detectar√° un objeto extra√±o se vuelve t√©cnicamente m√°s dif√≠cil. <br><br>  Otra aplicaci√≥n pac√≠fica masiva para c√°maras de profundidad es el reconocimiento de gestos.  En el futuro cercano, puede esperar televisores, consolas y aspiradoras rob√≥ticas que podr√°n percibir no solo los comandos de voz como altavoces inteligentes, sino tambi√©n el descuidado "¬°l√≠mpielo!"  con un gesto de su mano.  Luego, el control remoto (tambi√©n conocido como vago) del televisor inteligente ser√° completamente innecesario y la ciencia ficci√≥n cobrar√° vida.  Como resultado, lo que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fue fant√°stico en 2002 se</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">convirti√≥ en experimental en 2013</a> y, finalmente, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en serie en 2019</a> (aunque la gente no sabr√° que hay una c√°mara de profundidad en el interior, <s>¬øqu√© diferencia hace, c√≥mo funciona esta magia?</s> ): <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/9e6/bd8/2bd/9e6bd82bda38b0c8bb9cb939afee76a7.png"><img width="44%" src="https://habrastorage.org/getpro/habr/post_images/2a8/dcc/b9c/2a8dccb9cc86e1fe8ad57c613432e146.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">experimentos</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">producto.</a></i> <br><br>  Y la l√≠nea completa de aplicaciones es a√∫n m√°s amplia, por supuesto: <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/66d/fc8/23d/66dfc823dd2619f52003f3dbd92bbf34.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/0c5/819/751/0c5819751f59b53a33f4b0d37efb1caf.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7b0/266/402/7b02664025b9c9c4fbab5b5825822a2b.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">video de sensores de profundidad de Terabee</a></i> <i>(por cierto, ¬øqu√©</i> <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tipo de</a></i> <i><b>ratones</b> corren en el piso por 2 y 3 videos? ¬øLos ven? Es broma, es polvo en el aire, una tarifa por el peque√±o tama√±o del sensor y la proximidad de la fuente de luz al sensor)</i> <br><br>  Por cierto, en las famosas "tiendas sin cajeros" de Amazon Go tambi√©n hay muchas c√°maras debajo del techo: <br><img src="https://habrastorage.org/webt/ca/k9/ds/cak9ds3gc_8-a9n2tgwxdjhvpg0.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dentro de la tienda de conveniencia de Amazon que funciona sin vigilancia</a></i> <br><br>  Adem√°s, como escribe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TechCrunch</a> : <i>"Est√°n aumentados por <b>c√°maras de detecci√≥n de profundidad</b> separadas (usando una <b>t√©cnica de tiempo de vuelo</b> , o eso entend√≠ de Kumar) que se mezclan con el fondo como el resto, todo negro mate".</i>  Es decir, el milagro de determinar de qu√© estante se toma el yogur lo proporcionan, entre otras cosas, las misteriosas c√°maras de ToF negro mate (una buena pregunta, ¬øest√°n en la foto?): <br><img src="https://habrastorage.org/webt/25/qj/g1/25qjg1s8_o5uyjmoyv9r-haadms.png"><br><br>  Desafortunadamente, la informaci√≥n directa es a menudo dif√≠cil de encontrar.  Pero hay uno indirecto.  Por ejemplo, hab√≠a una compa√±√≠a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Softkinetic</a> , que desde 2007 ha estado desarrollando c√°maras ToF.  8 a√±os despu√©s, fueron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">comprados por Sony</a> (que, por cierto, est√° listo para conquistar nuevos mercados bajo la marca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sony Depthsensing</a> ).  Entonces, uno de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mejores empleados de</a> Softkinetic ahora trabaja solo en Amazon Go.  ¬°Qu√© coincidencia!  Dentro de un par de a√±os, cuando se presente la tecnolog√≠a y se presenten las principales patentes, lo m√°s probable es que se revelen los detalles. <br><br>  Bueno, como siempre, los chinos se encienden.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pico Zense</a> , por ejemplo, present√≥ en CES 2019 una l√≠nea muy impresionante de c√°maras ToF, incluso para uso en exteriores: <br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/c1c/545/d8cc1c545595e42cdab55a1a790384c9.png"><br>  Prometen una revoluci√≥n en todas partes.  Los vagones se cargar√°n m√°s densos debido a la carga automatizada, los cajeros autom√°ticos ser√°n m√°s seguros, debido a las c√°maras de profundidad en cada uno, la navegaci√≥n de los robots ser√° m√°s f√°cil y precisa, las personas (y, lo m√°s importante, los ni√±os) se contar√°n un orden de magnitud mejor en la corriente, aparecer√°n nuevos entrenadores de fitness c la capacidad de controlar la correcci√≥n de los ejercicios sin un instructor, y as√≠ sucesivamente.  Naturalmente, las c√°maras chinas baratas de una nueva generaci√≥n de profundidad ya est√°n listas para toda esta magnificencia.  ¬°Toma y construye! <br><br>  Curiosamente, el √∫ltimo Huawei P30 Pro en serie tiene un sensor ToF junto a las c√°maras principales, es decir,  el sufrido Huawei es m√°s capaz de fabricar sensores de luz estructurados de frente de Apple y, al parecer, con m√°s √©xito Google (Proyecto Tango, que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estaba cerrado</a> ) introdujo una c√°mara junto a las principales c√°maras ToF: <br><img width="60%" src="https://habrastorage.org/getpro/habr/post_images/fc9/eaf/763/fc9eaf76396c966eeab065ca641e8543.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Revisi√≥n de nueva tecnolog√≠a de Ars Technica Huawei a fines de marzo de 2019</a></i> <br><br>  Los detalles del uso, por supuesto, no fueron revelados, pero adem√°s de acelerar el enfoque (que es importante para las tres c√°maras principales con lentes diferentes), este sensor se puede usar para aumentar la calidad de desenfocar el fondo de las fotos (simulando peque√±os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DOF</a> ). <br><br>  Tambi√©n es obvio que la pr√≥xima generaci√≥n de sensores de profundidad junto a las c√°maras principales se utilizar√° en aplicaciones de AR, lo que aumentar√° la precisi√≥n del AR desde el actual "fr√≠o, pero a menudo con errores" a un nivel de trabajo en masa.  Y, obviamente, a la luz de los √©xitos chinos, la gran pregunta es cu√°nto querr√° Google apoyar el revolucionario hardware chino en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ARCore</a> .  Las guerras de patentes pueden ralentizar significativamente el mercado tecnol√≥gico.  El desarrollo de esta dram√°tica historia que veremos literalmente en los pr√≥ximos dos a√±os. <br><br><h1>  Subtotales </h1><br>  Hace unos 25 a√±os, cuando aparecieron las primeras puertas autom√°ticas, observ√© personalmente c√≥mo los t√≠os respetables aceleraban peri√≥dicamente frente a esas puertas.  ¬øTiene √©xito para abrir o no tiene tiempo?  Ella es grande, pesada, de cristal!  Casi lo mismo que observ√© durante una gira de profesores bastante respetables en una f√°brica autom√°tica en China recientemente.  Se quedaron un poco atr√°s del grupo para ver qu√© pasar√≠a si te pararas frente al robot, llevando piezas pac√≠ficamente y tocando una melod√≠a tranquila y agradable en el camino.  Yo tambi√©n me arrepiento, no pude resistir ... ¬°Sabes, se detiene!  Quiz√°s sin problemas.  Quiz√°s como hombre muerto.  ¬°Los sensores de profundidad funcionan! <br><img src="https://habrastorage.org/webt/6z/h_/xm/6zh_xmrkvzfljpw0hkymlngojrs.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dentro del nuevo campus de Huawei Technology</a></i> <br><br>  El hotel tambi√©n funcionaba como robots de limpieza, que se ve√≠an as√≠: <br><img src="https://habrastorage.org/webt/di/rm/bc/dirmbceths3wfdn1sbtswf9tduw.png"><br>  Al mismo tiempo, fueron intimidados con m√°s fuerza que los robots en la f√°brica.  No tan duro como en lo <b><i>inhumano</i></b> en todos los sentidos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bosstown Dynamics</a> , por supuesto.  Pero personalmente vi c√≥mo se levantaron en el camino, el robot intent√≥ rodear a una persona, la persona se movi√≥, bloqueando el camino ... Una especie de gato y rat√≥n.  En general, parece que cuando aparecen veh√≠culos no tripulados en las carreteras, la primera vez se cortar√°n con m√°s frecuencia de lo habitual ... Oh, gente-gente ... Hmmm ... Sin embargo, est√°bamos distra√≠dos. <br><br>  Resumiendo los puntos clave: <br><ul><li>  Debido a otro principio de funcionamiento, podemos colocar la fuente de luz en la c√°mara ToF lo m√°s cerca posible del sensor (incluso bajo la misma lente).  Adem√°s, muchos modelos industriales tienen LED ubicados alrededor del sensor.  Como resultado, las "sombras" en el mapa de profundidad se reducen radicalmente, o incluso desaparecen.  Es decir  Trabajo simplificado con objetos de geometr√≠a compleja, lo cual es importante para los robots industriales. <br></li><li>  Como la iluminaci√≥n pulsada, por regla general, permanece infrarroja, se conservan todas las desventajas de la c√°mara infrarroja descrita en la √∫ltima secci√≥n: exposici√≥n al sol, dificultades cuando dos c√°maras trabajan juntas, etc.  Sin embargo, los robots industriales a menudo trabajan en interiores y se est√°n desarrollando c√°maras con iluminaci√≥n l√°ser. <br></li><li>  Por desgracia, los sensores ToF son m√°s dif√≠ciles de "seguir" la mejora general de los sensores de las c√°maras RGB, por lo que su desarrollo es m√°s lento, pero sorprendentemente seguro y las noticias sobre la introducci√≥n de las c√°maras ToF son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MUY mucho y lo que (all√≠) no est√° all√≠</a> (solo en los tel√©fonos inteligentes anunciaron la integraci√≥n de sensores y Samsung, Google Pixel y Sony Xperia ...). <br></li><li>  La nueva Sony promete que 2 c√°maras de 8 c√°maras telef√≥nicas (!!!) ser√°n c√°maras de profundidad ToF (!), Es decir.  Las c√°maras de profundidad estar√°n a ambos lados del tel√©fono: <img src="https://habrastorage.org/getpro/habr/post_images/5cb/319/b6a/5cb319b6ade6cec9232d201201d15a60.png"><br>  <i>Fuente: el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tel√©fono Sony Hexa-cam revela las especificaciones de la c√°mara</a></i> <br></li><li>  Como resultado, <b>¬°encontraremos muchas cosas interesantes en esta √°rea incluso en el pr√≥ximo a√±o!</b>  Y el pr√≥ximo a√±o, hasta el 20% de los tel√©fonos nuevos contar√°n con c√°maras de profundidad (Structured Light + ToF).  Dado que en 2017 solo Apple estaba en el mercado en un espl√©ndido aislamiento con "30 mil puntos", y ahora no est√°n poniendo menos de 300 mil, el tema claramente sali√≥ bien: <br><img src="https://habrastorage.org/getpro/habr/post_images/463/6e5/971/4636e597115004d4a161719cfcafbe9d.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Crecimiento limitado del mercado de sensores 3D para tel√©fonos inteligentes en 2019;</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apple ser√° el promotor clave del crecimiento en 2020</a></i> <br></li></ul><br>  ¬øTodav√≠a dudas de la revoluci√≥n en curso? <br><br>  Esta fue la primera parte!  Una comparaci√≥n general ser√° en el segundo. <br><br>  En la pr√≥xima serie, espera: <br><ul><li>  M√©todo 3, cl√°sico: profundidad de est√©reo; <br></li><li>  M√©todo 4, novedoso: profundidad de los ple√≥pticos; <br></li><li>  M√©todo 5, de r√°pido crecimiento: lidares, incluidos los lidares de estado s√≥lido; <br></li><li>  Algunos problemas al procesar video con profundidad; <br></li><li>  Y finalmente, una breve comparaci√≥n de los 5 m√©todos y conclusiones generales. <br></li></ul><br><br>  <b><s>Cartago debe estar roto ... ¬°</s> Todo el video ser√° tridimensional para fines de siglo!</b> <br><br>  Est√©n atentos!  (Si tengo suficiente tiempo, describir√© nuevas c√°maras, incluidas las pruebas de Kinect reciente, para fin de a√±o). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2</a> <br><br><div class="spoiler">  <b class="spoiler_title">Agradecimientos</b> <div class="spoiler_text">  Me gustar√≠a agradecerle cordialmente: <br><ul><li>  Laboratorio de Computaci√≥n Gr√°fica VMK Universidad Estatal de Mosc√∫  MV Lomonosov por su contribuci√≥n al desarrollo de gr√°ficos por computadora en Rusia en general y su trabajo con c√°maras de profundidad en particular, <br></li><li>  Microsoft, Apple, Huawei y Amazon para productos basados ‚Äã‚Äãen c√°maras de gran profundidad, <br></li><li>  Texel para el desarrollo de productos rusos de alta tecnolog√≠a con c√°maras de profundidad, <br></li><li>  personalmente Konstantin Kozhemyakov, quien hizo mucho para hacer este art√≠culo mejor y m√°s visual, <br></li><li>  y, finalmente, muchas gracias a Roman Kazantsev, Eugene Lyapustin, Egor Sklyarov, Maxim Fedyukov, Nikolai Oplachko e Ivan Molodetsky por una gran cantidad de comentarios y correcciones razonables que hicieron que este texto fuera mucho mejor. <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457524/">https://habr.com/ru/post/457524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457512/index.html">Replicaci√≥n l√≥gica entre versiones de PostgreSQL</a></li>
<li><a href="../457514/index.html">Nevanger</a></li>
<li><a href="../457516/index.html">Escribir un modelo de amenaza</a></li>
<li><a href="../457518/index.html">Plasma Cash Chain como soluci√≥n al trilema de escalabilidad de blockchain</a></li>
<li><a href="../457522/index.html">¬øAumentar el servicio de su lista de correo o usar soluciones preparadas? Lo que aprend√≠ durante 5 a√±os en UniSender</a></li>
<li><a href="../457526/index.html">Medios t√©cnicos como un bazar</a></li>
<li><a href="../457532/index.html">Ya es hora de formar parte de un proyecto de c√≥digo abierto</a></li>
<li><a href="../457534/index.html">Versiones certificadas: el rastrillo que elegimos</a></li>
<li><a href="../457538/index.html">¬øC√≥mo puedo usar m√°quinas virtuales Yandex.Cloud interrumpidas y ahorrar para resolver problemas a gran escala?</a></li>
<li><a href="../457540/index.html">Intel Optane DC Persistent Memory, un a√±o despu√©s</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
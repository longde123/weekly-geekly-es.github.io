<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ»â€ğŸ’¼ ğŸ‘ˆğŸ» ğŸ¤¸ğŸ½ Cassandra untuk menyimpan metadata: keberhasilan dan kegagalan ğŸ¦” ğŸ‘©ğŸ¾â€âš–ï¸ ğŸ—œï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Persyaratan apa yang harus dipenuhi oleh penyimpanan metadata untuk layanan cloud? Ya, bukan yang paling biasa, tetapi untuk perusahaan dengan dukunga...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cassandra untuk menyimpan metadata: keberhasilan dan kegagalan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/417617/"> Persyaratan apa yang harus dipenuhi oleh penyimpanan metadata untuk layanan cloud?  Ya, bukan yang paling biasa, tetapi untuk perusahaan dengan dukungan untuk pusat data yang didistribusikan secara geografis dan Aktif-Aktif.  Jelas, sistem harus berskala baik, <strong>toleran terhadap kesalahan, dan ingin dapat mengimplementasikan konsistensi operasi yang dapat disesuaikan.</strong> <br><br>  Hanya Cassandra yang cocok untuk semua persyaratan ini, dan tidak ada yang cocok.  Perlu dicatat bahwa Cassandra benar-benar keren, tetapi bekerja dengannya menyerupai roller coaster. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  Dalam sebuah laporan di Highload ++ 2017, <strong>Andrei Smirnov</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">smira</a> ) memutuskan bahwa tidak menarik untuk berbicara tentang yang baik, tetapi ia berbicara secara rinci tentang setiap masalah yang harus dihadapi: tentang kehilangan data dan korupsi, tentang zombie dan kehilangan kinerja.  Kisah-kisah ini benar-benar mengingatkan kita pada roller coaster, tetapi untuk semua masalah ada solusinya, di mana Anda dipersilakan untuk melakukannya. <br><br>  <strong><em>Tentang pembicara:</em></strong> Andrey Smirnov bekerja untuk Virtustream, sebuah perusahaan yang mengimplementasikan penyimpanan cloud untuk perusahaan.  Idenya adalah bahwa secara kondisional Amazon melakukan cloud untuk semua orang, dan Virtustream melakukan hal-hal spesifik yang dibutuhkan perusahaan besar. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SAyClLjN6Sk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Beberapa kata tentang Virtustream </h1><br>  Kami bekerja dalam tim kecil yang sepenuhnya terpencil, dan kami terlibat dalam salah satu solusi cloud Virtustream.  Ini adalah awan penyimpanan data. <br><img src="https://habrastorage.org/webt/bo/rc/jh/borcjhczgtiycqzx8dz0bnh9zim.jpeg"><br><br>  Berbicara sangat sederhana, ini adalah API yang kompatibel S3 di mana Anda dapat menyimpan objek.  Bagi mereka yang tidak tahu apa itu S3, itu hanya API HTTP yang dengannya Anda dapat mengunggah objek ke cloud di suatu tempat, mendapatkannya kembali, menghapusnya, mendapatkan daftar objek, dll.  Selanjutnya - fitur yang lebih kompleks berdasarkan pada operasi sederhana ini. <br><br>  Kami memiliki beberapa fitur khas yang tidak dimiliki Amazon.  Salah satunya adalah yang disebut geo-region.  Dalam situasi yang biasa, ketika Anda membuat repositori dan mengatakan bahwa Anda akan menyimpan objek di cloud, Anda harus memilih wilayah.  Suatu wilayah pada dasarnya adalah pusat data, dan objek Anda tidak akan pernah meninggalkan pusat data ini.  Jika sesuatu terjadi padanya, maka objek Anda tidak akan lagi tersedia. <br><br>  Kami menawarkan geo-region di mana data secara bersamaan terletak di beberapa pusat data (DC), setidaknya dalam dua, seperti pada gambar.  Klien dapat menghubungi pusat data apa saja, baginya itu transparan.  Data di antara mereka direplikasi, yaitu, kami bekerja dalam mode Aktif-Aktif, dan terus-menerus.  Ini memberikan klien dengan fitur tambahan, termasuk: <br><br><ol><li>  keandalan penyimpanan, membaca dan menulis yang lebih besar jika terjadi kegagalan DC atau kehilangan konektivitas; <br></li><li>  ketersediaan data bahkan jika salah satu DC gagal; <br></li><li>  mengarahkan operasi ke DC "terdekat". <br></li></ol><br>  Ini adalah peluang yang menarik - bahkan jika DC ini secara geografis berjauhan, maka beberapa dari mereka mungkin lebih dekat dengan klien pada titik waktu yang berbeda.  Dan mengakses data ke DC terdekat hanya lebih cepat. <br><img src="https://habrastorage.org/webt/k-/ry/dl/k-rydl_mt74-eybwakpv1dpqjum.jpeg"><br><br>  Untuk membagi konstruksi yang akan kita bicarakan menjadi beberapa bagian, saya akan menyajikan objek-objek yang disimpan di awan sebagai dua bagian besar: <br><br>  1. Bagian sederhana pertama dari sebuah objek adalah <strong>data</strong> .  Mereka tidak berubah, mereka diunduh sekali dan itu saja.  Satu-satunya hal yang dapat terjadi pada mereka nanti adalah kita dapat menghapusnya jika tidak diperlukan lagi. <br><br>  Proyek kami sebelumnya terkait dengan penyimpanan exabytes data, jadi kami tidak punya masalah dengan penyimpanan data.  Ini sudah merupakan tugas yang diselesaikan bagi kami. <br><br>  2. <strong>Metadata</strong> .  Semua logika bisnis, semua yang paling menarik, terkait dengan kompetisi: akses, catatan, penulisan ulang - di area metadata. <br><br>  Metadata tentang objek dengan sendirinya merupakan kompleksitas terbesar dari proyek, metadata menyimpan pointer ke blok data yang tersimpan dari objek. <br><br>  Dari sudut pandang pengguna, ini adalah satu objek, tetapi kita dapat membaginya menjadi dua bagian.  Hari ini saya <strong>hanya</strong> akan berbicara <strong>tentang metadata</strong> . <br><br><h2>  Tokoh <br></h2><br><ul><li>  <strong>Data</strong> : 4 Pbytes. </li><li>  <strong>Cluster Metadata</strong> : 3. </li><li>  <strong>Objek</strong> : 40 miliar. </li><li>  <strong>Ukuran metadata</strong> : 160 TB (termasuk replikasi). </li><li>  <strong>Tingkat perubahan (metadata):</strong> 3000 objek / s. </li></ul><br>  Jika Anda melihat indikator-indikator ini dengan cermat, hal pertama yang menarik perhatian Anda adalah ukuran rata-rata yang sangat kecil dari objek yang disimpan.  Kami memiliki banyak metadata per unit volume data master.  Bagi kami, itu tidak mengejutkan daripada mungkin untuk Anda sekarang. <br><br>  Kami merencanakan bahwa kami akan memiliki setidaknya satu urutan data, jika tidak 2, lebih dari metadata.  Artinya, setiap objek akan secara signifikan lebih besar, dan jumlah metadata akan lebih sedikit.  Karena data lebih murah untuk disimpan, lebih sedikit operasi dengan mereka, dan metadata jauh lebih mahal baik dalam arti perangkat keras, dan dalam arti melayani dan melakukan berbagai operasi pada mereka. <br><br>  Apalagi data ini berubah dengan kecepatan yang cukup tinggi.  Saya telah memberikan nilai puncak di sini, nilai non-puncak tidak jauh lebih sedikit, tetapi, bagaimanapun, beban yang agak besar dapat diperoleh pada titik waktu tertentu. <br><br>  Angka-angka ini sudah diperoleh dari sistem kerja, tetapi mari kita kembali sedikit, ke waktu merancang penyimpanan cloud. <br><br><h1>  Memilih repositori untuk metadata </h1><br>  Ketika kami menghadapi tantangan bahwa kami ingin memiliki geo-region, Active-Active, dan kami perlu menyimpan metadata di suatu tempat, kami pikir itu bisa terjadi? <br><br>  Jelas, repositori (database) harus memiliki properti berikut: <br><br><ul><li>  <strong>Dukungan Aktif-Aktif</strong> ; </li><li>  <strong>Skalabilitas.</strong> </li></ul><br>  Kami benar-benar ingin produk kami menjadi sangat populer, dan kami tidak tahu bagaimana itu akan tumbuh pada saat yang sama, sehingga sistemnya harus berkembang. <br><br><ul><li>  <strong>Keseimbangan toleransi kesalahan dan keandalan penyimpanan.</strong> </li></ul><br>  Metadata harus disimpan dengan aman, karena jika kita kehilangan mereka, dan ada tautan ke data di dalamnya, maka kita akan kehilangan seluruh objek. <br><br><ul><li>  <strong>Konsistensi operasi yang dapat disesuaikan.</strong> </li></ul><br>  Karena fakta bahwa kami bekerja di beberapa DC dan memungkinkan kemungkinan bahwa DC mungkin tidak tersedia, apalagi, DC jauh dari satu sama lain, kami tidak dapat, selama sebagian besar operasi API, mengharuskan operasi ini dilakukan secara bersamaan di dua DC.  Itu hanya akan terlalu lambat dan tidak mungkin jika DC kedua tidak tersedia.  Oleh karena itu, bagian dari operasi harus bekerja secara lokal dalam satu DC. <br><br>  Tetapi, jelas, semacam konvergensi harus terjadi kapan-kapan, dan setelah menyelesaikan semua konflik, data harus terlihat di kedua pusat data.  Karena itu, konsistensi operasi harus disesuaikan. <br><br>  Dari sudut pandang saya, Cassandra cocok untuk persyaratan ini. <br><br><h1>  Cassandra </h1><br>  Saya akan sangat senang jika kami tidak harus menggunakan Cassandra, karena bagi kami itu adalah semacam pengalaman baru.  Tapi tidak ada yang cocok.  Bagi saya, ini adalah situasi yang paling menyedihkan di pasar untuk sistem penyimpanan semacam itu - tidak ada <strong>alternatif</strong> . <br><br><img src="https://habrastorage.org/webt/ge/l-/xo/gel-xoykdx5yx1-sb36hjinlsas.jpeg"><br><br><h3>  Apa itu Cassandra? <br></h3><br>  Ini adalah basis data nilai kunci yang didistribusikan.  Dari sudut pandang arsitektur dan ide-ide yang tertanam di dalamnya, tampak bagi saya bahwa semuanya keren.  Jika saya melakukannya, saya akan melakukan hal yang sama.  Ketika kami pertama kali mulai, kami berpikir untuk menulis sistem penyimpanan metadata kami sendiri.  Tetapi semakin jauh, semakin kita menyadari bahwa kita harus melakukan sesuatu yang sangat mirip dengan Cassandra, dan upaya yang akan kita keluarkan untuk itu tidak sepadan.  Untuk keseluruhan pengembangan <strong>, kami hanya memiliki satu setengah bulan</strong> .  Akan aneh menghabiskan mereka menulis basis data Anda. <br><br>  Jika Cassandra berlapis seperti kue lapis, saya akan memilih 3 lapisan: <br><br>  1. <strong>Penyimpanan KV lokal pada setiap node.</strong> <br>  Ini adalah sekelompok node, yang masing-masing dapat menyimpan data nilai kunci secara lokal. <br><br>  2. <strong>Sharding data on node (hashing konsisten).</strong> <br>  Cassandra dapat mendistribusikan data di antara node cluster, termasuk replikasi, dan melakukannya sedemikian rupa sehingga cluster dapat tumbuh atau berkurang ukurannya, dan data akan didistribusikan kembali. <br><br>  3. <strong>Koordinator untuk mengalihkan permintaan ke node lain.</strong> <br>  Ketika kita mengakses data untuk beberapa kueri dari aplikasi kita, Cassandra dapat mendistribusikan kueri kita ke dalam node sehingga kita mendapatkan data yang kita inginkan dan dengan tingkat konsistensi yang kita butuhkan - kita hanya ingin membacanya kuorum, atau ingin kuorum dengan dua DC, dll. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  Bagi kami, dua tahun bersama Cassandra - itu roller coaster atau roller coaster - apa pun yang Anda inginkan.  Semuanya dimulai jauh di lubuk hati, kami tidak memiliki pengalaman dengan Cassandra.  Kami takut.  Kami mulai, dan semuanya baik-baik saja.  Tapi kemudian jatuh dan tinggal landas terus-menerus dimulai: masalahnya, semuanya buruk, kami tidak tahu harus berbuat apa, kami mendapatkan kesalahan, lalu kami memecahkan masalah, dll. <br><br>  Roller coaster ini, pada prinsipnya, tidak berakhir sampai hari ini. <br><br><h1>  Bagus </h1><br>  Bab pertama dan terakhir, di mana saya mengatakan bahwa Cassandra itu keren.  Ini benar-benar keren, sistem yang hebat, tetapi jika saya terus mengatakan betapa bagusnya, saya pikir Anda tidak akan tertarik.  Karena itu, kita akan lebih memperhatikan yang buruk, tetapi nanti. <br><br>  Cassandra benar-benar bagus. <br><br><ul><li>  Ini adalah salah satu sistem yang memungkinkan kita untuk memiliki <strong>waktu respons dalam milidetik</strong> , yaitu, jelas kurang dari 10 ms.  Ini bagus untuk kita, karena waktu respons secara umum penting bagi kita.  Operasi dengan metadata bagi kita hanyalah bagian dari operasi apa pun yang terkait dengan penyimpanan suatu objek, baik itu menerima atau merekam. </li><li>  Dari sudut pandang perekaman, <strong>skalabilitas tinggi</strong> tercapai.  Anda dapat menulis di Cassandra dengan kecepatan yang gila, dan dalam beberapa situasi ini diperlukan, misalnya, saat kami memindahkan sejumlah besar data di antara catatan. </li><li>  Cassandra benar-benar <strong>toleran terhadap kesalahan</strong> .  Jatuhnya satu node tidak langsung menyebabkan masalah, meskipun cepat atau lambat mereka akan mulai.  Cassandra menyatakan bahwa ia tidak memiliki satu titik kegagalan, tetapi, pada kenyataannya, ada titik-titik kegagalan di mana-mana.  Bahkan, orang yang bekerja dengan database tahu bahwa bahkan sebuah node crash bukanlah sesuatu yang biasanya diderita sampai pagi hari.  Biasanya, situasi ini perlu diperbaiki lebih cepat. </li><li>  <strong>Kesederhanaan.</strong>  Namun, dibandingkan dengan database relasional Cassandra standar lainnya, lebih mudah untuk memahami apa yang sedang terjadi.  Sangat sering, terjadi kesalahan, dan kita perlu memahami apa yang terjadi.  Cassandra memiliki lebih banyak peluang untuk mengetahuinya, sampai ke sekrup terkecil, mungkin, daripada dengan database lain. </li></ul><br><h1>  Lima Cerita Buruk </h1><br>  Saya ulangi, Cassandra baik, itu bekerja untuk kita, tetapi saya akan menceritakan lima cerita tentang yang buruk.  Saya pikir ini untuk apa Anda membacanya.  Saya akan memberikan cerita dalam urutan kronologis, meskipun mereka tidak saling terhubung. <br><img src="https://habrastorage.org/webt/ao/15/oa/ao15oaiwdhwvl4w4u5pvcgwolrq.jpeg"><br><br>  Kisah ini adalah yang paling menyedihkan bagi kami.  Karena kami menyimpan data pengguna, hal terburuk yang mungkin terjadi adalah kehilangannya, dan <strong>hilang selamanya</strong> , seperti yang terjadi dalam situasi ini.  Kami telah menyediakan cara untuk memulihkan data jika kehilangannya di Cassandra, tetapi kami kehilangannya sehingga kami benar-benar tidak dapat memulihkannya. <br><br>  Untuk menjelaskan bagaimana ini terjadi, saya harus berbicara sedikit tentang bagaimana semuanya diatur dalam diri kita. <br><img src="https://habrastorage.org/webt/6i/vf/gk/6ivfgkdspndo3kzyy153iveq4xq.jpeg"><br><br>  Dari perspektif S3, ada beberapa hal mendasar: <br><br><ul><li>  Bucket - dapat dibayangkan sebagai katalog besar tempat pengguna mengunggah objek (selanjutnya disebut sebagai bucket). </li><li>  Setiap objek memiliki nama (kunci) dan metadata yang terkait dengannya: ukuran, tipe konten, dan penunjuk ke data objek.  Pada saat yang sama, ukuran ember tidak dibatasi oleh apa pun.  Artinya, bisa 10 kunci, mungkin 100 miliar kunci - tidak ada perbedaan. </li><li>  Setiap operasi kompetitif dimungkinkan, yaitu, mungkin ada beberapa isian kompetitif dalam kunci yang sama, mungkin ada penghapusan kompetitif, dll. </li></ul><br>  Dalam situasi kami, aktif-aktif, operasi dapat terjadi, termasuk secara kompetitif di berbagai DC, tidak hanya dalam satu.  Oleh karena itu, kita memerlukan semacam skema konservasi yang memungkinkan kita untuk mengimplementasikan logika tersebut.  Pada akhirnya, kami memilih kebijakan sederhana: versi yang terakhir direkam akan menang.  Terkadang beberapa operasi kompetitif terjadi, tetapi pelanggan tidak perlu melakukan ini dengan sengaja.  Mungkin saja itu permintaan yang dimulai, tetapi klien tidak menunggu jawaban, sesuatu yang lain terjadi, mencoba lagi, dll. <br><br>  Oleh karena itu, kami memiliki dua tabel dasar: <br><br><ol><li>  <strong>Daftar benda</strong> .  Di dalamnya, sepasang - nama ember dan nama kunci - dikaitkan dengan versi saat ini.  Jika objek dihapus, maka tidak ada dalam versi ini.  Jika objek ada, ada versi saat ini.  Bahkan, dalam tabel ini kami hanya mengubah bidang versi saat ini. <br></li><li>  <strong>Tabel versi objek</strong> .  Kami hanya memasukkan versi baru ke dalam tabel ini.  Setiap kali objek baru diunduh, kami menyisipkan versi baru ke dalam tabel versi, memberikan nomor unik, menyimpan semua informasi tentangnya, dan pada akhirnya memperbarui tautannya ke dalam tabel objek. <br></li></ol><br>  Gambar tersebut menunjukkan contoh bagaimana tabel objek dan versi objek saling berhubungan. <br><img src="https://habrastorage.org/webt/rv/jm/3y/rvjm3y1ohf-9yiehp1ajlm4zjik.jpeg"><br><br>  Berikut adalah objek yang memiliki dua versi - satu saat ini dan yang lama, ada objek yang telah dihapus, dan versinya masih ada.  Kita perlu membersihkan versi yang tidak perlu dari waktu ke waktu, yaitu menghapus sesuatu yang tidak dirujuk orang lain.  Selain itu, kami tidak perlu langsung menghapusnya, kami bisa melakukannya dalam mode ditangguhkan.  Ini adalah pembersihan internal kami, kami hanya menghapus apa yang tidak lagi diperlukan. <br><br>  Ada masalah. <br><img src="https://habrastorage.org/webt/md/rc/xy/mdrcxyc9ojwdjuwchg7gsgkspio.jpeg"><br><br>  Masalahnya adalah ini: kami memiliki aktif-aktif, dua DC.  Di setiap DC, metadata disimpan dalam tiga salinan, yaitu, kami memiliki 3 + 3 - hanya 6 replika.  Ketika klien menghubungi kami, kami melakukan operasi dengan konsistensi (dari sudut pandang Cassandra disebut LOCAL_QUORUM).  Artinya, dijamin bahwa catatan (atau baca) terjadi dalam 2 replika di DC lokal.  Ini adalah jaminan - jika tidak operasi akan gagal. <br><br>  Cassandra akan selalu mencoba untuk menulis di semua 6 baris - 99% dari waktu semuanya akan baik-baik saja.  Bahkan, semua 6 replika akan sama, tetapi dijamin kepada kami 2. <br><br>  Kami memiliki situasi yang sulit, meskipun itu bahkan bukan wilayah geografis.  Bahkan untuk wilayah biasa yang berada dalam satu DC, kami masih menyimpan salinan kedua metadata di DC lain.  Ini adalah cerita yang panjang, saya tidak akan memberikan semua detailnya.  Tetapi pada akhirnya, kami memiliki proses pembersihan yang menghapus versi yang tidak perlu. <br><br>  Dan kemudian muncul masalah yang sama.  Proses pembersihan juga bekerja dengan konsistensi kuorum lokal di satu pusat data, karena tidak ada gunanya menjalankannya dalam dua - mereka akan saling bertarung. <br><br>  Semuanya baik-baik saja sampai ternyata pengguna kami terkadang masih menulis ke pusat data lain, yang tidak kami duga.  Semuanya diatur untuk berjaga-jaga untuk feylover, tetapi ternyata mereka sudah menggunakannya. <br><img src="https://habrastorage.org/webt/sa/cs/6q/sacs6qjj7og_ay7jbmkhfkjh9ei.jpeg"><br><br>  Sebagian besar waktu, semuanya baik-baik saja sampai suatu hari muncul situasi di mana entri dalam tabel versi direplikasi di kedua DC, tetapi catatan di tabel objek ternyata hanya dalam satu DC, dan tidak berakhir di yang kedua.  Dengan demikian, prosedur pembersihan, diluncurkan di DC pertama (atas), melihat bahwa ada versi yang tidak ada yang merujuk dan menghapusnya.  Dan saya tidak hanya menghapus versi, tetapi juga, tentu saja, data - semuanya benar-benar, karena itu hanya objek yang tidak perlu.  Dan penghapusan ini tidak dapat dibatalkan. <br><br>  Tentu saja, ada "booming" lebih lanjut, karena kita masih memiliki catatan dalam tabel objek yang merujuk ke versi yang tidak ada lagi. <br><br>  Jadi pertama kali kami kehilangan data, dan kami kehilangan itu benar-benar tidak dapat dibatalkan - bagus, sedikit. <br><br><h3>  Solusi </h3><br>  Apa yang harus dilakukan  Dalam situasi kita, semuanya sederhana. <br><br>  Karena kami memiliki data yang disimpan di dua pusat data, proses pembersihan adalah proses konvergensi dan sinkronisasi.  Kita harus membaca data dari kedua DC.  Proses ini hanya akan berfungsi ketika kedua DC tersedia.  Karena saya katakan bahwa ini adalah proses tertunda yang tidak terjadi selama pemrosesan API, ini tidak menakutkan. <br><br>  <strong>Consistency ALL</strong> adalah fitur Cassandra 2. Dalam Cassandra 3, semuanya sedikit lebih baik - ada tingkat konsistensi, yang disebut kuorum di setiap DC.  Tapi bagaimanapun, ada masalah yang <strong>lambat</strong> , karena, pertama, kita harus beralih ke DC jarak jauh.  Kedua, dalam hal konsistensi semua 6 node, ini berarti bahwa ia bekerja pada kecepatan yang terburuk dari 6 node ini. <br><br>  Tetapi pada saat yang sama, proses <strong>perbaikan-baca</strong> terjadi, ketika tidak semua replika sinkron.  Artinya, ketika rekaman gagal di suatu tempat, proses ini secara bersamaan memperbaikinya.  Begitulah cara kerja Cassandra. <br><br>  Ketika ini terjadi, kami menerima keluhan dari klien bahwa objek tidak tersedia.  Kami menemukan jawabannya, mengerti alasannya, dan hal pertama yang ingin kami lakukan adalah mencari tahu berapa banyak lagi benda yang kita miliki.  Kami menjalankan skrip yang mencoba menemukan konstruksi yang mirip dengan ini ketika ada entri di satu tabel, tetapi tidak ada entri di yang lain. <br><br>  Tiba-tiba kami menemukan bahwa kami memiliki <strong>10% dari catatan tersebut</strong> .  Tidak ada yang lebih buruk, mungkin, tidak akan terjadi jika kita tidak menduga bahwa ini bukan masalahnya.  Masalahnya berbeda. <br><br><img src="https://habrastorage.org/webt/kc/jt/_d/kcjt_dh03wmb-6szvtrgxqz-hme.jpeg"><br><br>  Zombi telah merayap ke dalam basis data kami.  Ini adalah nama semi-resmi untuk masalah ini.  Untuk memahami apa itu, Anda perlu berbicara tentang cara kerja penghapusan di Cassandra. <br><img src="https://habrastorage.org/webt/k2/sd/2j/k2sd2jvngn9ouhiv6b3yre0s8vs.jpeg"><br><br>  Sebagai contoh, kami memiliki beberapa data <strong><em>x</em></strong> yang direkam dan direplikasi dengan sempurna untuk semua 6 replika.  Jika kami ingin menghapusnya, penghapusan, seperti operasi apa pun di Cassandra, mungkin tidak dilakukan pada semua node. <br><br>  Sebagai contoh, kami ingin menjamin konsistensi 2 dari 3 dalam satu DC.  Biarkan operasi penghapusan dilakukan pada lima node, tetapi tetap pada satu catatan, misalnya, karena node tidak tersedia pada saat itu. <br><img src="https://habrastorage.org/webt/lu/d5/ot/lud5otv1dguftzwinkrb2wpeaaq.jpeg"><br><br>  Jika kita menghapus ini dan kemudian mencoba membaca "Saya ingin 2 dari 3" dengan konsistensi yang sama, maka Cassandra, melihat nilai dan ketiadaannya, menafsirkan ini sebagai keberadaan data.  Artinya, ketika membaca kembali, dia akan berkata: "Oh, ada data!", Meskipun kami menghapusnya.  Karenanya, Anda tidak dapat menghapus dengan cara ini. <br><img src="https://habrastorage.org/webt/m6/li/ol/m6liolpvsglhmd_9wjg1gvkascw.jpeg"><br><br>  Cassandra menghapus secara berbeda.  <strong>Penghapusan sebenarnya sebuah catatan</strong> .  Ketika kami menghapus data, Cassandra menulis beberapa penanda kecil yang disebut <strong>Tombstone</strong> (batu nisan).  Itu menandakan bahwa data dihapus.  Jadi, jika kita membaca token penghapusan dan data pada saat yang sama, Cassandra selalu lebih suka token penghapusan dalam situasi ini dan mengatakan bahwa sebenarnya tidak ada data.  Ini yang kamu butuhkan. <br><br>  <strong>Tombstone â€”   </strong> , , ,      , -     ,     .   Tombstone     .   <strong>Tombstone   gc_grace_period </strong> .   ,   ,   . <br><br>   ? <br><br><h2> Repair <br></h2><br>  Cassandra  ,   Repair ().   â€”  ,     .       ,  ,      ,     , / ,  , -  - ,    ..     . Repair  ,    . <br><img src="https://habrastorage.org/webt/hj/td/x0/hjtdx0thzgak5uhzjd_ejn09s1m.jpeg"><br><br>   , -   , -   .  Repair    ,    ,    .  - ,     â€”     .     ,    . <br><img src="https://habrastorage.org/webt/qe/ee/kj/qeeekjf-dzxokqp6c4zi1aylljm.jpeg"><br><br>     Repair,       ,  ,      ,    â€” ,   .   6     .     â€” ,   ,     . <br><img src="https://habrastorage.org/webt/c7/qo/o2/c7qoo2bykcraic_gbj8fxbxrmoo.jpeg"><br><br>     ,      â€” ,  -  .      ,    .        ,  - ,    ,       ,    . <br><br><h3>  Solusi <br></h3><br>   ,   : <br><br><ul><li> <strong>Repair       </strong> . </li></ul><br>    ,      repair.    ,          ,       . <br><br><ul><li> <strong>    ,    Tombstones,   ,   repair.</strong> </li></ul><br>  repair â€”   ,     repair. ,  ,          10-20 , , 3 .    Tombstone     ,     .      ,  ,      -. <br><img src="https://habrastorage.org/webt/18/yp/cc/18ypccovl1xcoxairec6nf3ssx0.jpeg"><br><br>      Cassandra,     .       . <br><br>  S3  .   ,      â€” 10 , 100  .   API,     â€”      .     , ,  , ,   ,         .  ,    ,  ,    â€”     ,    .      . <br><br>    API? <br><img src="https://habrastorage.org/webt/1l/tl/hd/1ltlhdhdtgnwgxezzz8jsnavvky.jpeg"><br><br>   ,     â€” , ,   â€”    ,    ,    .    .              â€” .   ,     ,   .   ,   ,      Cassandra.    ,         â€”  ,  ,    ,      . <br><br>        ,          ,      ,  ,  .          ,      . ,   ,             . ,   - ,           . <br><br> Cassandra ,       .           ,       ,  ,   ,       ,     . <br><img src="https://habrastorage.org/webt/fk/os/a3/fkosa3zozy2gk_dzpgjvxdwm4k8.jpeg"><br><br>    ,   Cassandra  <strong>composite key</strong> .       ,    â€”    ,   - ,      â€”  .    ,   .   ? ,   ,    ! <br><br>      ,    ,  , ,      â€”  ,          . <br><br>     .  Cassandra   ,   <strong>  Cassandra      </strong> .  ,     ,    Cassandra,        :  ,  ,   SQL  ..    ! <br><img src="https://habrastorage.org/webt/8o/_s/ka/8o_ska-swgmzixxiztlblopuze0.jpeg"><br><br>      .     Cassandra  ?    ,     ,   API.  ,   ,     ,   ,     (     )   . <strong>   ,   </strong>   . <br><br>    ,           .        ,   , ,    .   ,     â€”   â€”       . , ,  ,          . <br><br>   Cassandra   ,       .    : Â«  100 Â»,    ,    ,  ,      ,        ,   100,    . <br><br> ,         (   ),    â€”          ,    ,         .         ,   ,   ,   ,     ,   - .     100 ,   - ,     ,  .      ,         SQL    . <br><br> Cassandra       ,     ,     Java,    .  ,  <strong>Large Partition</strong> ,  .    â€” , , ,  ,     â€”  .         ,   , garbage collection    ..     . <br><br>   ,   ,  <strong>    ,   </strong> ,        . <br><br> ,        ,   -  . <br><img src="https://habrastorage.org/webt/qg/o9/oo/qgo9ooa3pgv_zqkv8iyby4ppq9g.jpeg"><br><br>   ,     ,           .      .     ,      Large Partition. <br><br>     : <br><br><ol><li>        ( ,  - ); <br></li><li>   ,    ,       .     ,     . <br></li></ol><br>   ,     ,   ,     key_hash   0.   , <strong>    ,         </strong> .       ,    .       ,      ,      . <br><br>  ,     . <br><img src="https://habrastorage.org/webt/zr/aw/xn/zrawxn-n6hr1huoqkenbqcgpeoo.jpeg"><br><br>    â€” ,    ,    ,      - -      . <br><br>   â€”      ,   N ?    ,  Large Partition,   â€”     .  ,        .   :   .  ,    ,  ,    ,       -  .    ,           .    , ,     . <br><img src="https://habrastorage.org/webt/og/um/4y/ogum4yxqpvbvrdadna7r8adomwm.jpeg"><br><br>     â€”   ,    ,   -  .    -  ,       ,       .    ,    ,    .   ,    ,        .. <br><br>         â€”  ,    ?    ,   .    ? -     md5- â€”      ,   -  30  â€”     ,  - .    .     ,     ,   . <br><img src="https://habrastorage.org/webt/yp/ik/vy/ypikvyolprsxdju5hawmlm6_epq.jpeg"><br><br>      ,    , , ,   .       â€”   ,    .    ,       .   ,    -  -   - ,  -  - â€”  .     ,     .      . <br><br><h2>   </h2><br>    ,    ,     ,    . <br><br><ul><li>   . </li><li>         . </li><li>     Cassandra. </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Redistribusi online (tanpa menghentikan operasi dan kehilangan konsistensi). </font></font></li></ul><br>  Kami memiliki beberapa kondisi bucket sekarang, entah bagaimana dibagi menjadi beberapa partisi.  Kemudian kami memahami bahwa beberapa partisi terlalu besar atau terlalu kecil.  Kita perlu menemukan partisi baru, yang, di satu sisi, akan optimal, yaitu, ukuran setiap partisi akan kurang dari beberapa batas kami, dan mereka akan lebih atau kurang seragam.  Dalam hal ini, transisi dari kondisi saat ini ke yang baru harus memerlukan jumlah tindakan minimum.  Jelas bahwa setiap transisi memerlukan kunci yang bergerak di antara partisi, tetapi semakin sedikit kita memindahkannya, semakin baik. <br><br>  Kami berhasil.  Mungkin, bagian yang berhubungan dengan pemilihan distribusi adalah bagian paling sulit dari seluruh layanan, jika kita berbicara tentang bekerja dengan metadata secara umum.  Kami menulis ulang, mengolahnya, dan masih melakukannya, karena beberapa klien atau pola tertentu membuat kunci selalu ditemukan yang mengenai titik lemah skema ini. <br><br>  Misalnya, kami berasumsi bahwa ember akan tumbuh kurang lebih secara merata.  Yaitu, kami mengambil beberapa jenis distribusi, dan berharap semua partisi akan tumbuh sesuai dengan distribusi ini.  Tetapi kami menemukan klien yang selalu menulis pada akhirnya, dalam arti bahwa kuncinya selalu dalam urutan.  Setiap saat ia berdetak di partisi terakhir, yang tumbuh dengan kecepatan sedemikian rupa sehingga dalam satu menit bisa mencapai 100 ribu kunci.  Dan 100 ribu kira-kira nilai yang cocok menjadi satu partisi. <br><br>  Kami tidak akan punya waktu untuk memproses penambahan kunci dengan algoritma kami, dan kami harus memperkenalkan distribusi pendahuluan khusus untuk klien ini.  Karena kita tahu seperti apa kuncinya, jika kita melihat bahwa itu adalah dia, kita baru mulai membuat partisi kosong terlebih dahulu di akhir, sehingga dia dapat menulis dengan tenang di sana, dan untuk sekarang kita akan memiliki sedikit istirahat hingga iterasi berikutnya, ketika kita lagi harus mendistribusikan kembali semuanya. <br><br>  Semua ini terjadi online dalam arti bahwa kami tidak menghentikan operasi.  Mungkin ada operasi baca, tulis, kapan saja Anda dapat meminta daftar kunci.  Itu akan selalu konsisten, bahkan jika kita sedang dalam proses partisi ulang. <br><br>  Ini cukup menarik, dan ternyata dengan Cassandra.  Di sini Anda dapat bermain dengan trik yang terkait dengan fakta bahwa Cassandra dapat menyelesaikan konflik.  Jika kami menulis dua nilai berbeda pada baris yang sama, maka nilai yang memiliki stempel waktu yang lebih besar akan menang. <br><br>  Biasanya timestamp adalah timestamp saat ini, tetapi dapat dilewati secara manual.  Misalnya, kami ingin menulis nilai ke string, yang dalam hal apa pun harus dihapus jika klien menulis sesuatu sendiri.  Artinya, kami menyalin beberapa data, tetapi kami menginginkan klien, jika dia tiba-tiba menulis bersama kami pada saat yang sama, dapat menimpanya.  Lalu kita bisa menyalin data kita dengan cap waktu sedikit dari masa lalu.  Kemudian rekaman apa pun saat ini akan sengaja dihancurkan, terlepas dari urutan pembuatan rekaman itu. <br><br>  Trik semacam itu memungkinkan Anda melakukan ini secara online. <br><br><h2>  Solusi </h2><br><ul><li>  Jangan, jangan pernah <strong>mengizinkan penampilan partisi yang besar</strong> . </li><li>  <strong>Memecah data dengan kunci utama</strong> tergantung pada tugas. </li></ul><br>  Jika sesuatu yang mirip dengan partisi besar direncanakan dalam skema data, Anda harus segera mencoba melakukan sesuatu tentang hal itu - cari tahu cara memecahnya dan bagaimana cara menghindarinya.  Cepat atau lambat, ini muncul, karena setiap indeks terbalik cepat atau lambat muncul di hampir semua tugas.  Saya sudah memberi tahu Anda tentang cerita seperti itu - kami memiliki kunci ember di objek, dan kami perlu mendapatkan daftar kunci dari ember - sebenarnya, ini adalah indeks. <br><br>  Selain itu, partisi bisa besar tidak hanya dari data, tetapi juga dari Tombstone (penanda penghapusan).  Dari sudut pandang internal Cassandra (kita tidak pernah melihatnya dari luar), spidol penghapusan juga data, dan partisi dapat menjadi besar jika banyak hal dihapus di dalamnya, karena penghapusan adalah sebuah catatan.  Anda seharusnya tidak melupakan ini juga. <br><img src="https://habrastorage.org/webt/-s/tw/la/-stwlarb11mcy5nlqaqrpxfc-ky.jpeg"><br><br>  Kisah lain yang sebenarnya konstan adalah bahwa ada yang tidak beres dari awal hingga akhir.  Misalnya, Anda melihat bahwa waktu respons dari Cassandra telah meningkat, ia merespons dengan lambat.  Bagaimana memahami dan memahami apa masalahnya?  Tidak pernah ada sinyal eksternal bahwa masalahnya ada di sana. <br><img src="https://habrastorage.org/webt/c0/lr/5r/c0lr5rwf9w5zi-nx1ddd5k5blgk.jpeg"><br><br>  Misalnya, saya akan memberikan grafik - ini adalah waktu respons rata-rata dari cluster secara keseluruhan.  Ini menunjukkan bahwa kami memiliki masalah - waktu respons maksimum adalah 12 detik - ini adalah batas waktu internal Cassandra.  Ini berarti dia akan menyendiri.  Jika batas waktu di atas 12 detik, kemungkinan besar ini berarti bahwa pemulung bekerja, dan Cassandra bahkan tidak punya waktu untuk merespons pada waktu yang tepat.  Dia menjawab sendiri dengan batas waktu, tetapi waktu respons untuk sebagian besar permintaan, seperti yang saya katakan, harus rata-rata dalam 10 ms. <br><br>  Pada grafik, rata-rata telah melebihi ratusan milidetik - ada yang salah.  Tetapi melihat gambar ini, tidak mungkin untuk memahami apa alasannya. <br><br><img src="https://habrastorage.org/webt/e6/t6/qk/e6t6qkz3yw6k80sjw7smsycclrc.jpeg"><br><br>  Tetapi jika Anda memperluas statistik yang sama pada node Cassandra, Anda dapat melihat bahwa, pada prinsipnya, semua node lebih atau kurang sama sekali, tetapi waktu respon untuk satu node berbeda berdasarkan urutan besarnya.  Kemungkinan besar, ada beberapa masalah dengannya. <br><br>  Statistik pada node mengubah gambar sepenuhnya.  Statistik ini berasal dari sisi aplikasi.  Tetapi di sini sebenarnya sangat sering sulit untuk memahami apa masalahnya.  Ketika suatu aplikasi mengakses Cassandra, ia mengakses beberapa simpul, menggunakannya sebagai koordinator.  Artinya, aplikasi memberikan permintaan, dan koordinator mengalihkannya ke replika dengan data.  Mereka sudah menjawab, dan koordinator membentuk jawaban akhir. <br><br>  Tetapi mengapa koordinator merespons dengan lambat?  Mungkin masalahnya dengan dia, dengan demikian, yaitu, dia melambat dan menjawab perlahan?  Atau mungkin dia melambat, karena replika meresponsnya dengan lambat?  Jika replika merespons dengan lambat, dari sudut pandang aplikasi itu akan terlihat seperti respons lambat dari koordinator, meskipun tidak ada hubungannya dengan itu. <br><br>  Inilah situasi yang membahagiakan - jelas bahwa hanya satu simpul yang merespons secara lambat, dan kemungkinan besar masalahnya ada di dalamnya. <br><br><h3>  Kompleksitas penafsiran </h3><br><br><ul><li>  Waktu respons koordinator (simpul vs. replika itu sendiri). </li><li>  Tabel spesifik atau seluruh simpul? </li><li>  Jeda GC?  Pool Thread Tidak Memadai? </li><li>  Terlalu banyak SSTable yang tidak dikompilasi? </li></ul><br>  Selalu sulit untuk memahami apa yang salah.  Itu hanya <strong>membutuhkan banyak statistik dan pemantauan</strong> , baik dari sisi aplikasi dan dari Cassandra sendiri, karena jika itu benar-benar buruk, tidak ada yang terlihat dari Cassandra.  Anda bisa melihat tingkat permintaan individu, di tingkat setiap tabel tertentu, di setiap node tertentu. <br><br>  Mungkin ada, misalnya, situasi di mana satu tabel dari apa yang disebut dalam Cassandra SSTables (file terpisah) memiliki terlalu banyak.  Untuk membaca, Cassandra secara kasar telah memilah-milah semua SSTable.  Jika jumlah mereka terlalu banyak, maka proses penyortiran ini memakan waktu terlalu lama, dan membaca mulai melorot. <br><br>  Solusinya adalah pemadatan, yang mengurangi jumlah SSTable ini, tetapi harus dicatat bahwa itu hanya pada satu node untuk satu tabel tertentu.  Karena Cassandra, sayangnya, ditulis di Jawa dan dijalankan pada JVM, mungkin pemulung telah berhenti sehingga tidak punya waktu untuk merespons.  Ketika pengumpul sampah berhenti, tidak hanya permintaan Anda melambat, tetapi <strong>interaksi dalam gugus Cassandra antara node mulai melambat</strong> .  Simpul satu sama lain mulai dianggap telah turun, yaitu, jatuh, mati. <br><br>  Situasi yang lebih menyenangkan dimulai, karena ketika sebuah node menganggap bahwa node lain sedang down, itu, pertama, tidak mengirim permintaan ke sana, dan kedua, itu mulai mencoba untuk menyimpan data yang perlu direplikasi ke node lain di dirinya sendiri secara lokal, jadi dia mulai bunuh diri perlahan, dll. <br><br>  Ada situasi di mana masalah ini dapat diselesaikan hanya dengan menggunakan pengaturan yang benar.  Misalnya, mungkin ada sumber daya yang cukup, semuanya baik-baik saja dan luar biasa, tetapi hanya Thread Pool, yang jumlahnya adalah ukuran tetap, perlu ditingkatkan. <br><br>  Akhirnya, mungkin kita perlu membatasi daya saing di sisi pengemudi.  Kadang-kadang terjadi bahwa terlalu banyak permintaan kompetitif dikirim, dan seperti basis data apa pun, Cassandra tidak dapat menanganinya dan pergi ke klinik ketika waktu respons meningkat secara eksponensial, dan kami berusaha untuk memberikan lebih banyak pekerjaan. <br><br><h3>  Memahami konteksnya </h3><br>  Selalu ada beberapa konteks untuk masalah - apa yang terjadi di gugus, apakah Perbaikan berfungsi sekarang, pada simpul mana, di mana ruang-ruang utama, di tabel mana. <br><br>  Misalnya, kami mengalami masalah yang agak konyol dengan zat besi.  Kami melihat bahwa bagian dari node lambat.  Kemudian ditemukan bahwa alasannya adalah bahwa di BIOS prosesor mereka berada dalam mode hemat energi.  Untuk beberapa alasan, selama pemasangan awal besi, ini terjadi, dan sekitar 50% dari sumber daya prosesor digunakan dibandingkan dengan node lain. <br><br>  Memahami masalah seperti itu bisa sulit, sebenarnya.  Gejalanya adalah ini - tampaknya simpul melakukan pemadatan, tetapi melakukannya perlahan-lahan.  Terkadang terhubung dengan besi, terkadang tidak, tapi ini hanyalah bug Cassandra. <br><br>  Oleh karena itu, pemantauan adalah wajib dan perlu banyak.  Semakin kompleks fitur di Cassandra, semakin jauh dari menulis sederhana dan membaca, semakin banyak masalah dengan itu, dan semakin cepat dapat membunuh database dengan jumlah pertanyaan yang cukup.  Karena itu, jika mungkin, jangan melihat beberapa keripik "enak" dan mencoba menggunakannya, lebih baik hindari keripik sebanyak mungkin.  Tidak selalu mungkin - tentu saja, cepat atau lambat itu perlu. <br><img src="https://habrastorage.org/webt/mx/m8/lx/mxm8lxirhudrxrdlcq26jpstvle.jpeg"><br><br>  Kisah terakhir adalah tentang bagaimana Cassandra mengacaukan data.  Dalam situasi ini, itu terjadi di dalam Cassandra.  Itu menarik. <br><br>  Kami melihat bahwa sekitar sekali seminggu di basis data kami beberapa lusin garis yang rusak muncul - mereka benar-benar tersumbat oleh sampah.  Selain itu, Cassandra memvalidasi data yang masuk ke inputnya.  Sebagai contoh, jika itu adalah string, maka harus dalam utf8.  Tetapi di baris-baris ini adalah sampah, bukan utf8, dan Cassandra bahkan tidak mau berurusan dengan itu.  Ketika saya mencoba untuk menghapus (atau melakukan sesuatu yang lain), saya tidak dapat menghapus nilai yang bukan utf8, karena, khususnya, saya tidak dapat memasukkannya di WHERE, karena kuncinya adalah utf8. <br><br>  Garis manja muncul, seperti lampu kilat, di beberapa titik, dan kemudian hilang lagi selama beberapa hari atau minggu. <br><br>  Kami mulai mencari masalah.  Kami pikir mungkin ada masalah di simpul tertentu yang kami gunakan, melakukan sesuatu dengan data, menyalin SSTables.  Mungkin, semua sama, Anda dapat melihat replika data ini?  Mungkin replika ini memiliki simpul umum, faktor umum terkecil?  Mungkin beberapa node crash?  Tidak, tidak ada yang seperti itu. <br><br>  Mungkin sesuatu dengan disk?  Apakah data rusak pada disk?  Tidak lagi <br><br>  Mungkin ingatan?  Tidak!  Tersebar di sebuah cluster. <br><br>  Mungkin ini semacam masalah replikasi?  Satu simpul merusak segalanya dan selanjutnya mereplikasi nilai buruk?  - Tidak. <br><br>  Akhirnya, mungkin ini adalah masalah aplikasi? <br><br>  Terlebih lagi, di beberapa titik, garis yang rusak mulai muncul dalam dua kelompok Cassandra.  Satu bekerja pada versi 2.1, yang kedua pada yang ketiga.  Tampaknya Cassandra berbeda, tetapi masalahnya sama.  Mungkin layanan kami mengirim data buruk?  Tapi itu sulit dipercaya.  Cassandra memvalidasi input data, tidak bisa menulis sampah.  Tapi tiba-tiba? <br><br>  Tidak ada yang cocok. <br><br><h3>  Jarum ditemukan! </h3><br>  Kami berjuang lama dan keras sampai kami menemukan masalah kecil: mengapa kita memiliki semacam crash dump dari JVM pada node yang tidak kita perhatikan?  Dan entah bagaimana itu terlihat mencurigakan di tumpukan sampah jejak pengumpul ... Dan untuk beberapa alasan beberapa jejak tumpukan juga tersumbat dengan sampah. <br><br>  Pada akhirnya, kami menyadari - oh, <strong>untuk beberapa alasan kami menggunakan JVM versi lama 2015</strong> .  Ini adalah satu-satunya hal umum yang menyatukan cluster Cassandra pada versi Cassandra yang berbeda. <br><br>  Saya masih tidak tahu apa masalahnya, karena tidak ada yang ditulis tentang ini dalam catatan rilis resmi JVM.  Namun setelah pembaruan, semuanya menghilang, masalahnya tidak lagi muncul.  Selain itu, itu tidak terjadi di cluster sejak hari pertama, tetapi dari beberapa titik, meskipun bekerja pada JVM yang sama untuk waktu yang lama. <br><br><h3>  Pemulihan data </h3><br>  Pelajaran apa yang telah kita pelajari dari ini: <br><br>  â— Pencadangan tidak berguna. <br>  Data, seperti yang kami ketahui, rusak saat data itu direkam.  Pada saat data masuk ke koordinator, mereka sudah rusak. <br><br>  â— Pemulihan sebagian kolom yang tidak rusak adalah mungkin. <br>  Beberapa kolom tidak rusak, kita bisa membaca data ini, mengembalikannya sebagian. <br><br>  â— Pada akhirnya, kami harus melakukan pemulihan dari berbagai sumber. <br>  Kami memiliki metadata cadangan di objek, tetapi dalam data itu sendiri.  Untuk menghubungkan kembali dengan objek, kami menggunakan log, dll. <br><br>  â— Log tidak ternilai harganya! <br>  Kami dapat memulihkan semua data yang rusak, tetapi pada akhirnya sangat sulit untuk mempercayai basis data jika kehilangan data Anda bahkan tanpa tindakan apa pun dari pihak Anda. <br><br><h3>  Solusi </h3><br><ul><li>  Perbarui JVM setelah pengujian ekstensif. </li><li>  Pemantauan kecelakaan JVM. </li><li>  Memiliki salinan data Cassandra-independent. </li></ul><br><blockquote>  <strong>Sebagai tip:</strong> Cobalah untuk memiliki semacam salinan data Cassandra-independent yang dapat Anda pulihkan jika perlu.  Ini mungkin solusi tingkat terakhir.  Biarkan mengambil banyak waktu, sumber daya, tetapi harus ada beberapa opsi yang akan memungkinkan Anda untuk mengembalikan data. </blockquote><br><h1>  Bug </h1><br>  â— <strong>Kualitas pengujian rilis yang buruk</strong> <br>  Ketika Anda mulai bekerja dengan Cassandra, ada perasaan konstan (terutama jika Anda bergerak, relatif berbicara, dari database "baik", misalnya, PostgreSQL) bahwa jika Anda memperbaiki bug dalam rilis yang sebelumnya, Anda pasti akan menambahkan yang baru.  Dan bug ini bukan omong kosong, biasanya data rusak atau perilaku salah lainnya. <br><br>  â— <strong>Masalah yang terus-menerus dengan fitur yang kompleks</strong> <br>  Semakin kompleks fitur, semakin banyak masalah, bug, dll. Dengan itu. <br><br>  â— <strong>Jangan gunakan perbaikan bertahap di 2.1</strong> <br>  Perbaikan terkenal, yang saya bicarakan, yang memperbaiki konsistensi data, dalam mode standar, ketika melakukan polling semua node, bekerja dengan baik.  Tetapi tidak dalam mode incremental yang disebut (ketika perbaikan melewatkan data yang tidak berubah sejak perbaikan sebelumnya, yang cukup logis).  Sudah lama diumumkan, secara formal, ketika fitur ada, tetapi semua orang mengatakan: â€œTidak, dalam versi 2.1, tidak pernah menggunakannya!  Dia pasti akan kehilangan sesuatu.  Di 3 kita memperbaikinya. " <br><br>  â— <strong>Tapi jangan gunakan perbaikan bertahap di 3.x</strong> <br>  Ketika versi ketiga keluar, beberapa hari kemudian mereka berkata: â€œTidak, Anda tidak dapat menggunakannya di versi ke-3.  Ada daftar 15 bug, jadi jangan gunakan perbaikan tambahan.  Di kelas 4 kita akan melakukan yang lebih baik! " <br><br>  Saya tidak percaya mereka.  Dan ini adalah masalah besar, terutama dengan bertambahnya ukuran cluster.  Karena itu, Anda harus terus memantau bugtracker mereka dan melihat apa yang terjadi.  Sayangnya, tidak mungkin untuk hidup bersama mereka tanpa itu. <br><br>  â— <strong>Perlu melacak JIRA</strong> <br><img src="https://habrastorage.org/webt/g0/1k/el/g01kela-ibcrrsorr1pjxo-pmdc.jpeg"><br><br><blockquote>  Jika Anda menyebarkan semua database pada spektrum prediktabilitas, bagi saya, Cassandra ada di sebelah kiri di area merah.  Ini tidak berarti bahwa itu buruk, Anda hanya harus siap untuk fakta bahwa Cassandra tidak dapat diprediksi dalam arti kata apa pun: baik dalam cara kerjanya maupun dalam kenyataan bahwa sesuatu dapat terjadi. </blockquote><br><img src="https://habrastorage.org/webt/je/_1/w0/je_1w0808rlhzxo1bakk0zjj9ee.jpeg"><br><br>  Saya berharap Anda menemukan garu lain dan menginjaknya, karena, dari sudut pandang saya, tidak peduli apa, Cassandra baik dan, tentu saja, tidak membosankan.  Ingat saja gundukan di jalan! <br><br><blockquote>  <strong>Buka rapat aktivis HighLoad ++</strong> <br><br>  Pada tanggal 31 Juli di Moskow, pada pukul 19:00, sebuah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertemuan para</a> pembicara, Komite Program dan para aktivis dari konferensi para pengembang sistem beban tinggi HighLoad ++ 2018 akan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diadakan</a> . Kami akan mengadakan brainstorming kecil tentang program tahun ini agar tidak ketinggalan sesuatu yang baru dan penting.  Rapat terbuka, tetapi Anda harus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mendaftar</a> . <br><br>  <strong>Panggilan untuk surat-surat</strong> <br><br>  Secara aktif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menerima aplikasi</a> untuk laporan di Highload ++ 2018. Komite Program sedang menunggu abstrak Anda sampai akhir musim panas. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id417617/">https://habr.com/ru/post/id417617/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id417603/index.html">Pengumuman mitap seluler: Apa yang harus dilakukan ketika aplikasi menjadi besar?</a></li>
<li><a href="../id417605/index.html">Dasar-dasar pemodelan 3D untuk pencetakan 3D</a></li>
<li><a href="../id417607/index.html">Tes A / B tidak berhasil. Periksa apa yang Anda lakukan salah</a></li>
<li><a href="../id417613/index.html">Ceph as pluggable storage: 5 wawasan praktis dari proyek besar</a></li>
<li><a href="../id417615/index.html">Disk Cracker Confessions untuk Apple II: Rahasia 4 pagi</a></li>
<li><a href="../id417619/index.html">Win32 / Glupteba tidak lagi dikaitkan dengan operasi Windigo</a></li>
<li><a href="../id417621/index.html">Apa yang terjadi ketika kami memecahkan pameran?</a></li>
<li><a href="../id417627/index.html">Hyper CRM atau Mini ERP? Bisnis kacau</a></li>
<li><a href="../id417629/index.html">Delphi dan C ++ Builder Community Edition</a></li>
<li><a href="../id417631/index.html">Tutorial Video Kotak CSS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ–ğŸ½ ğŸ‘ˆğŸ¿ ğŸ‘¨â€ğŸ”¬ Trucs et astuces Kubernetes: allocation de nÅ“uds et charges d'applications Web ğŸ¹ ğŸ‘©ğŸ¼â€âš•ï¸ â˜£ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Poursuivant nos articles avec des instructions pratiques sur la faÃ§on de faciliter la vie dans le travail quotidien avec Kubernetes, nous parlons de d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Trucs et astuces Kubernetes: allocation de nÅ“uds et charges d'applications Web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/432748/"><img src="https://habrastorage.org/webt/7r/gv/ix/7rgvixbeoe0vyfkw__obak6ow_y.jpeg"><br><br>  Poursuivant nos articles avec des instructions pratiques sur la faÃ§on de faciliter la vie dans le travail quotidien avec Kubernetes, nous parlons de deux histoires du monde de l'exploitation: l'allocation de nÅ“uds individuels pour des tÃ¢ches spÃ©cifiques et la configuration de php-fpm (ou d'un autre serveur d'applications) pour des charges lourdes.  Comme prÃ©cÃ©demment, les solutions dÃ©crites ici ne prÃ©tendent pas Ãªtre idÃ©ales, mais sont proposÃ©es comme point de dÃ©part pour vos cas spÃ©cifiques et comme base de rÃ©flexion.  Les questions et amÃ©liorations dans les commentaires sont les bienvenues! <a name="habracut"></a><br><br><h2>  1. L'allocation de nÅ“uds individuels pour des tÃ¢ches spÃ©cifiques </h2><br>  Nous Ã©levons un cluster Kubernetes sur des serveurs virtuels, des clouds ou des serveurs bare metal.  Si vous installez tous les logiciels systÃ¨me et applications client sur les mÃªmes nÅ“uds, il est probable que des problÃ¨mes surviennent: <br><br><ul><li>  l'application client commencera soudainement Ã  Â«fuirÂ» de la mÃ©moire, bien que ses limites soient trÃ¨s Ã©levÃ©es; </li><li>  les demandes ponctuelles complexes de loghouse, de PromÃ©thÃ©e ou d'Ingress * mÃ¨nent au MOO, par consÃ©quent, l'application cliente souffre; </li><li>  une fuite de mÃ©moire due Ã  un bogue dans le logiciel systÃ¨me tue l'application cliente, bien que les composants ne soient pas logiquement connectÃ©s entre eux. </li></ul><br>  <i>* Entre autres choses, il Ã©tait pertinent pour les anciennes versions d'Ingress, quand en raison du grand nombre de connexions Websocket et des rechargements constants de nginx, des Â«processus nginx bloquÃ©sÂ» sont apparus, qui se chiffraient Ã  des milliers et consommaient une Ã©norme quantitÃ© de ressources.</i> <br><br>  Le vrai cas est l'installation de Prometheus avec un grand nombre de mÃ©triques, dans lesquelles lors de l'affichage du tableau de bord "lourd", oÃ¹ un grand nombre de conteneurs d'applications sont prÃ©sentÃ©s, Ã  partir de chacun desquels des graphiques sont dessinÃ©s, la consommation de mÃ©moire est rapidement passÃ©e Ã  ~ 15 Go.  En consÃ©quence, le tueur OOM pourrait Â«venirÂ» sur le systÃ¨me hÃ´te et commencer Ã  tuer d'autres services, ce qui Ã  son tour a conduit Ã  Â«un comportement incomprÃ©hensible des applications dans le clusterÂ».  Et en raison de la charge Ã©levÃ©e du processeur sur l'application cliente, il est facile d'obtenir un temps de traitement de requÃªte Ingst instable ... <br><br>  La solution s'est rapidement imposÃ©e: il a fallu allouer des machines individuelles pour diffÃ©rentes tÃ¢ches.  Nous avons identifiÃ© 3 principaux types de groupes de travail: <br><br><ol><li>  <b>Fronts</b> , oÃ¹ nous ne mettons que des entrÃ©es, pour Ãªtre sÃ»r qu'aucun autre service ne peut affecter le temps de traitement des demandes; </li><li>  Noeuds <b>systÃ¨me</b> sur lesquels nous dÃ©ployons des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VPN</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">loghouse</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Prometheus</a> , Dashboard, CoreDNS, etc.; </li><li>  <b>Noeuds pour les applications</b> - en fait, oÃ¹ les applications clientes se dÃ©ploient.  Ils peuvent Ã©galement Ãªtre allouÃ©s pour des environnements ou des fonctionnalitÃ©s: dev, prod, perf, ... </li></ol><br><h3>  Solution </h3><br>  Comment mettons-nous cela en Å“uvre?  TrÃ¨s simple: deux mÃ©canismes natifs de Kubernetes.  Le premier est <b>nodeSelector</b> pour sÃ©lectionner le nÅ“ud souhaitÃ© oÃ¹ l'application doit aller, qui est basÃ© sur les Ã©tiquettes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">installÃ©es</a> sur chaque nÅ“ud. <br><br>  Disons que nous avons un nÅ“ud <code>kube-system-1</code> .  Nous y ajoutons une Ã©tiquette supplÃ©mentaire: <br><br><pre> <code class="bash hljs">$ kubectl label node kube-system-1 node-role/monitoring=</code> </pre> <br>  ... et dans <code>Deployment</code> , qui devrait Ãªtre dÃ©ployÃ© sur ce nÅ“ud, nous Ã©crivons: <br><br><pre> <code class="plaintext hljs">nodeSelector: node-role/monitoring: ""</code> </pre> <br>  Le deuxiÃ¨me mÃ©canisme est les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>souillures et les tolÃ©rances</b></a> .  Avec son aide, nous indiquons explicitement que sur ces machines, seuls les conteneurs pouvant Ãªtre tolÃ©rÃ©s Ã  cette souillure peuvent Ãªtre lancÃ©s. <br><br>  Par exemple, il existe une machine <code>kube-frontend-1</code> sur laquelle nous roulerons uniquement Ingress.  Ajoutez de la souillure Ã  ce nÅ“ud: <br><br><pre> <code class="bash hljs">$ kubectl taint node kube-frontend-1 node-role/frontend=<span class="hljs-string"><span class="hljs-string">""</span></span>:NoExecute</code> </pre> <br>  ... et au <code>Deployment</code> nous crÃ©ons la tolÃ©rance: <br><br><pre> <code class="plaintext hljs">tolerations: - effect: NoExecute key: node-role/frontend</code> </pre> <br>  Dans le cas de kops, des groupes d'instances individuels peuvent Ãªtre crÃ©Ã©s pour les mÃªmes besoins: <br><br><pre> <code class="bash hljs">$ kops create ig --name cluster_name IG_NAME</code> </pre> <br>  ... et vous obtenez quelque chose comme cette configuration de groupe d'instances dans kops: <br><br><pre> <code class="plaintext hljs">apiVersion: kops/v1alpha2 kind: InstanceGroup metadata: creationTimestamp: 2017-12-07T09:24:49Z labels: dedicated: monitoring kops.k8s.io/cluster: k-dev.k8s name: monitoring spec: image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-01-14 machineType: m4.4xlarge maxSize: 2 minSize: 2 nodeLabels: dedicated: monitoring role: Node subnets: - eu-central-1c taints: - dedicated=monitoring:NoSchedule</code> </pre> <br>  Ainsi, les nÅ“uds de ce groupe d'instances ajouteront automatiquement une Ã©tiquette et une coloration supplÃ©mentaires. <br><br><h2>  2. Configuration de php-fpm pour les charges lourdes </h2><br>  Il existe une grande variÃ©tÃ© de serveurs qui sont utilisÃ©s pour exÃ©cuter des applications Web: php-fpm, gunicorn et similaires.  Leur utilisation dans Kubernetes signifie qu'il y a plusieurs choses auxquelles vous devez toujours penser: <br><br><ul><li>  Il est <b>nÃ©cessaire</b> de comprendre approximativement <b>combien de travailleurs</b> nous sommes disposÃ©s Ã  allouer en php-fpm dans chaque conteneur.  Par exemple, nous pouvons allouer 10 employÃ©s pour traiter les demandes entrantes, allouer moins de ressources pour le pod et Ã©voluer en utilisant le nombre de pods - c'est une bonne pratique.  Un autre exemple est d'allouer 500 travailleurs pour chaque pod et d'avoir 2-3 de tels pods en production ... mais c'est une assez mauvaise idÃ©e. </li><li>  <b>Des tests de vivacitÃ© / de prÃ©paration sont</b> nÃ©cessaires pour vÃ©rifier le bon fonctionnement de chaque module et dans le cas oÃ¹ le module est Â«bloquÃ©Â» en raison de problÃ¨mes de rÃ©seau ou en raison de l'accÃ¨s Ã  la base de donnÃ©es (il peut y avoir l'une de vos options et la raison).  Dans de telles situations, vous devez recrÃ©er le module problÃ©matique. </li><li>  Il est important d'enregistrer explicitement la <b>demande et de limiter les ressources</b> pour chaque conteneur afin que l'application ne "coule" pas et ne commence pas Ã  endommager tous les services sur ce serveur. </li></ul><br><h3>  Des solutions </h3><br>  Malheureusement, <b>il n'y a pas de solution miracle</b> qui vous aide Ã  comprendre immÃ©diatement de combien de ressources (CPU, RAM) une application peut avoir besoin.  Une option possible est de surveiller la consommation des ressources et de sÃ©lectionner Ã  chaque fois les valeurs optimales.  Afin d'Ã©viter les kill'ov OOM injustifiÃ©s et la limitation du processeur, qui affectent considÃ©rablement le service, vous pouvez proposer: <br><br><ul><li>  ajoutez les tests de vivacitÃ© / prÃ©paration corrects afin que nous puissions dire avec certitude que ce conteneur fonctionne correctement.  Il s'agit trÃ¨s probablement d'une page de service qui vÃ©rifie la disponibilitÃ© de tous les Ã©lÃ©ments d'infrastructure (nÃ©cessaires pour que l'application fonctionne dans le pod) et renvoie un code de rÃ©ponse 200 OK; </li><li>  sÃ©lectionner correctement le nombre de travailleurs qui traiteront les demandes et les rÃ©partir correctement. </li></ul><br>  Par exemple, nous avons 10 pods qui se composent de deux conteneurs: nginx (pour envoyer des requÃªtes statiques et proxy au backend) et php-fpm (en fait le backend, qui traite les pages dynamiques).  Le pool Php-fpm est configurÃ© pour un nombre statique de travailleurs (10).  Ainsi, dans une unitÃ© de temps, nous pouvons traiter 100 requÃªtes actives vers les backends.  Laissez chaque requÃªte Ãªtre traitÃ©e par PHP en 1 seconde. <br><br>  Que se passe-t-il si 1 demande supplÃ©mentaire arrive dans un module spÃ©cifique, dans lequel 10 demandes sont actuellement activement traitÃ©es?  PHP ne pourra pas le traiter et Ingress l'enverra pour rÃ©essayer vers le pod suivant s'il s'agit d'une requÃªte GET.  S'il y avait une demande POST, il retournera une erreur. <br><br>  Et si nous prenons en compte que lors du traitement des 10 demandes, nous recevrons un chÃ¨que de kubelet (sonde de vivacitÃ©), il Ã©chouera et Kubernetes commencera Ã  penser que quelque chose ne va pas avec ce conteneur, et le tuera.  Dans ce cas, toutes les demandes qui ont Ã©tÃ© traitÃ©es actuellement se termineront par une erreur (!) Et au moment du redÃ©marrage du conteneur, il sera dÃ©sÃ©quilibrÃ©, ce qui entraÃ®nera une augmentation des demandes pour tous les autres backends. <br><br><h4>  Clairement </h4><br>  Supposons que nous ayons 2 pods qui ont chacun 10 travailleurs php-fpm configurÃ©s.  Voici un graphique qui affiche des informations pendant le Â«temps d'arrÃªtÂ», c'est-Ã -dire  lorsque le seul qui demande php-fpm est l'exportateur php-fpm (nous avons chacun un travailleur actif): <br><br><img src="https://habrastorage.org/webt/zo/hw/ea/zohwea7nsfbofpgvhixp7edc-qk.png"><br><br>  Maintenant, dÃ©marrez le dÃ©marrage avec la concurrence 19: <br><br><img src="https://habrastorage.org/webt/my/ba/hp/mybahpcgbfoqzzazbwtzu9dc46a.png"><br><br>  Essayons maintenant de rendre la concurrence supÃ©rieure Ã  ce que nous pouvons gÃ©rer (20) ... disons 23. Ensuite, tous les employÃ©s de php-fpm sont occupÃ©s Ã  traiter les demandes des clients: <br><br><img src="https://habrastorage.org/webt/tq/v6/f1/tqv6f1fopruyz8_zittdan1pkho.png"><br><br>  Les vorkers ne suffisent plus pour traiter un Ã©chantillon de vivacitÃ©, nous voyons donc cette image dans le tableau de bord Kubernetes (ou <code>describe pod</code> ): <br><br><img src="https://habrastorage.org/webt/7z/qo/fw/7zqofwlbjcmxl0qkz2g2rkerece.png"><br><br>  Maintenant, lorsque l'un des pods redÃ©marre, un <b>effet d'avalanche se produit</b> : les demandes commencent Ã  tomber sur le deuxiÃ¨me pod, qui n'est pas non plus en mesure de les traiter, ce qui nous fait recevoir un grand nombre d'erreurs de la part des clients.  Une fois que les piscines de tous les conteneurs sont pleines, l'augmentation du service est problÃ©matique - cela n'est possible que par une forte augmentation du nombre de pods ou de travailleurs. <br><br><h4>  PremiÃ¨re option </h4><br>  Dans un conteneur avec PHP, vous pouvez configurer 2 pools fpm: l'un pour le traitement des demandes des clients, l'autre pour vÃ©rifier la Â«capacitÃ© de survieÂ» du conteneur.  Ensuite, sur le conteneur nginx, vous devrez effectuer une configuration similaire: <br><br><pre> <code class="plaintext hljs"> upstream backend { server 127.0.0.1:9000 max_fails=0; } upstream backend-status { server 127.0.0.1:9001 max_fails=0; }</code> </pre> <br>  Il ne reste plus qu'Ã  envoyer l'Ã©chantillon de vivacitÃ© pour traitement Ã  l'amont appelÃ© <code>backend-status</code> . <br><br>  Maintenant que la sonde de vivacitÃ© est traitÃ©e sÃ©parÃ©ment, des erreurs se produiront toujours pour certains clients, mais au moins aucun problÃ¨me n'est associÃ© au redÃ©marrage du pod et Ã  la dÃ©connexion d'autres clients.  Ainsi, nous rÃ©duirons considÃ©rablement le nombre d'erreurs, mÃªme si nos backends ne peuvent pas faire face Ã  la charge actuelle. <br><br>  Cette option est certainement meilleure que rien, mais elle est Ã©galement mauvaise car quelque chose peut arriver au pool principal, que nous n'apprendrons pas Ã  utiliser le test de vivacitÃ©. <br><br><h4>  DeuxiÃ¨me option </h4><br>  Vous pouvez Ã©galement utiliser le module nginx peu populaire appelÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nginx-limit-upstream</a> .  Ensuite, en PHP, nous spÃ©cifierons 11 travailleurs, et dans le conteneur avec nginx, nous ferons une configuration similaire: <br><br><pre> <code class="plaintext hljs"> limit_upstream_zone limit 32m; upstream backend { server 127.0.0.1:9000 max_fails=0; limit_upstream_conn limit=10 zone=limit backlog=10 timeout=5s; } upstream backend-status { server 127.0.0.1:9000 max_fails=0; }</code> </pre> <br>  Au niveau du frontend, nginx limitera le nombre de requÃªtes qui seront envoyÃ©es au backend (10).  Un point intÃ©ressant est qu'un backlog spÃ©cial est crÃ©Ã©: si le client reÃ§oit la 11Ã¨me requÃªte pour nginx, et nginx voit que le pool php-fpm est occupÃ©, alors cette requÃªte est placÃ©e dans le backlog pendant 5 secondes.  Si, pendant ce temps, php-fpm ne s'est pas libÃ©rÃ©, alors seulement Ingress entrera en action, qui rÃ©essayera la demande vers un autre pod.  Cela lisse l'image, car nous aurons toujours 1 travailleur PHP gratuit pour traiter un Ã©chantillon de vivacitÃ© - nous pouvons Ã©viter l'effet d'avalanche. <br><br><h4>  Autres pensÃ©es </h4><br>  Pour des options plus polyvalentes et plus belles pour rÃ©soudre ce problÃ¨me, il vaut la peine de chercher dans la direction d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Envoy</a> et de ses analogues. <br><br>  En gÃ©nÃ©ral, afin que Prometheus ait un emploi clair des travailleurs, ce qui Ã  son tour aidera Ã  trouver rapidement le problÃ¨me (et Ã  le notifier), je recommande fortement d'obtenir des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exportateurs</a> prÃªts Ã  l'emploi pour convertir les donnÃ©es du logiciel au format Prometheus. <br><br><h2>  PS </h2><br>  Autres du cycle de trucs et astuces de K8: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pages d'erreur personnalisÃ©es dans NGINX Ingress</a> "; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transfert des ressources travaillant dans un cluster vers la gestion de Helm 2</a> Â»; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AccÃ¨s aux sites de dÃ©veloppement</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AccÃ©lÃ©rer le bootstrap des grandes bases de donnÃ©es.</a> " </li></ul><br>  Lisez aussi dans notre blog: <br><br><ul><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comment la haute disponibilitÃ© chez Kubernetes est assurÃ©e</a> Â»; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Monitoring and Kubernetes</a> Â» <i>(revue et reportage vidÃ©o)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Notre expÃ©rience avec Kubernetes dans les petits projets</a> " <i>(reportage vidÃ©o, qui comprend une introduction au dispositif technique Kubernetes)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr432748/">https://habr.com/ru/post/fr432748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr432736/index.html">Devops, JUnit5 et tests de microservices: un regard subjectif sur le Heisenbag de Moscou</a></li>
<li><a href="../fr432740/index.html">"CMS" basÃ© sur Google Spreadsheets pour les sites statiques</a></li>
<li><a href="../fr432742/index.html">Pression du temps de l'entreprise</a></li>
<li><a href="../fr432744/index.html">DWDM: la solution est moins chÃ¨re que l'opÃ©rateur de 30 Ã  50% (classe Entreprise)</a></li>
<li><a href="../fr432746/index.html">Pendant trois jours en soins intensifs ou qu'est-ce qui ne va pas avec la section Ã©quilibre travail-vie personnelle sur Mobius'18?</a></li>
<li><a href="../fr432750/index.html">La joie d'Haxe. Un roman avec un langage de programmation nÃ©gligÃ©</a></li>
<li><a href="../fr432752/index.html">Colline de fourmis ou forteresse? Je construis une maison pour le prix d'un appartement. 3 parties. Alimentation</a></li>
<li><a href="../fr432754/index.html">Le stockage de donnÃ©es en mÃ©moire et sur disque rendra public</a></li>
<li><a href="../fr432756/index.html">Nous implÃ©mentons la prise en charge de l'accessibilitÃ© sans modifier la composante visuelle de l'application mobile</a></li>
<li><a href="../fr432760/index.html">Vues de produit vectorielles ou autre utilisation du modÃ¨le Word2Vec</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
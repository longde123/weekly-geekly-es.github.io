<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖐🏽 👈🏿 👨‍🔬 Trucs et astuces Kubernetes: allocation de nœuds et charges d'applications Web 🏹 👩🏼‍⚕️ ☣️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Poursuivant nos articles avec des instructions pratiques sur la façon de faciliter la vie dans le travail quotidien avec Kubernetes, nous parlons de d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Trucs et astuces Kubernetes: allocation de nœuds et charges d'applications Web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/432748/"><img src="https://habrastorage.org/webt/7r/gv/ix/7rgvixbeoe0vyfkw__obak6ow_y.jpeg"><br><br>  Poursuivant nos articles avec des instructions pratiques sur la façon de faciliter la vie dans le travail quotidien avec Kubernetes, nous parlons de deux histoires du monde de l'exploitation: l'allocation de nœuds individuels pour des tâches spécifiques et la configuration de php-fpm (ou d'un autre serveur d'applications) pour des charges lourdes.  Comme précédemment, les solutions décrites ici ne prétendent pas être idéales, mais sont proposées comme point de départ pour vos cas spécifiques et comme base de réflexion.  Les questions et améliorations dans les commentaires sont les bienvenues! <a name="habracut"></a><br><br><h2>  1. L'allocation de nœuds individuels pour des tâches spécifiques </h2><br>  Nous élevons un cluster Kubernetes sur des serveurs virtuels, des clouds ou des serveurs bare metal.  Si vous installez tous les logiciels système et applications client sur les mêmes nœuds, il est probable que des problèmes surviennent: <br><br><ul><li>  l'application client commencera soudainement à «fuir» de la mémoire, bien que ses limites soient très élevées; </li><li>  les demandes ponctuelles complexes de loghouse, de Prométhée ou d'Ingress * mènent au MOO, par conséquent, l'application cliente souffre; </li><li>  une fuite de mémoire due à un bogue dans le logiciel système tue l'application cliente, bien que les composants ne soient pas logiquement connectés entre eux. </li></ul><br>  <i>* Entre autres choses, il était pertinent pour les anciennes versions d'Ingress, quand en raison du grand nombre de connexions Websocket et des rechargements constants de nginx, des «processus nginx bloqués» sont apparus, qui se chiffraient à des milliers et consommaient une énorme quantité de ressources.</i> <br><br>  Le vrai cas est l'installation de Prometheus avec un grand nombre de métriques, dans lesquelles lors de l'affichage du tableau de bord "lourd", où un grand nombre de conteneurs d'applications sont présentés, à partir de chacun desquels des graphiques sont dessinés, la consommation de mémoire est rapidement passée à ~ 15 Go.  En conséquence, le tueur OOM pourrait «venir» sur le système hôte et commencer à tuer d'autres services, ce qui à son tour a conduit à «un comportement incompréhensible des applications dans le cluster».  Et en raison de la charge élevée du processeur sur l'application cliente, il est facile d'obtenir un temps de traitement de requête Ingst instable ... <br><br>  La solution s'est rapidement imposée: il a fallu allouer des machines individuelles pour différentes tâches.  Nous avons identifié 3 principaux types de groupes de travail: <br><br><ol><li>  <b>Fronts</b> , où nous ne mettons que des entrées, pour être sûr qu'aucun autre service ne peut affecter le temps de traitement des demandes; </li><li>  Noeuds <b>système</b> sur lesquels nous déployons des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VPN</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">loghouse</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Prometheus</a> , Dashboard, CoreDNS, etc.; </li><li>  <b>Noeuds pour les applications</b> - en fait, où les applications clientes se déploient.  Ils peuvent également être alloués pour des environnements ou des fonctionnalités: dev, prod, perf, ... </li></ol><br><h3>  Solution </h3><br>  Comment mettons-nous cela en œuvre?  Très simple: deux mécanismes natifs de Kubernetes.  Le premier est <b>nodeSelector</b> pour sélectionner le nœud souhaité où l'application doit aller, qui est basé sur les étiquettes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">installées</a> sur chaque nœud. <br><br>  Disons que nous avons un nœud <code>kube-system-1</code> .  Nous y ajoutons une étiquette supplémentaire: <br><br><pre> <code class="bash hljs">$ kubectl label node kube-system-1 node-role/monitoring=</code> </pre> <br>  ... et dans <code>Deployment</code> , qui devrait être déployé sur ce nœud, nous écrivons: <br><br><pre> <code class="plaintext hljs">nodeSelector: node-role/monitoring: ""</code> </pre> <br>  Le deuxième mécanisme est les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>souillures et les tolérances</b></a> .  Avec son aide, nous indiquons explicitement que sur ces machines, seuls les conteneurs pouvant être tolérés à cette souillure peuvent être lancés. <br><br>  Par exemple, il existe une machine <code>kube-frontend-1</code> sur laquelle nous roulerons uniquement Ingress.  Ajoutez de la souillure à ce nœud: <br><br><pre> <code class="bash hljs">$ kubectl taint node kube-frontend-1 node-role/frontend=<span class="hljs-string"><span class="hljs-string">""</span></span>:NoExecute</code> </pre> <br>  ... et au <code>Deployment</code> nous créons la tolérance: <br><br><pre> <code class="plaintext hljs">tolerations: - effect: NoExecute key: node-role/frontend</code> </pre> <br>  Dans le cas de kops, des groupes d'instances individuels peuvent être créés pour les mêmes besoins: <br><br><pre> <code class="bash hljs">$ kops create ig --name cluster_name IG_NAME</code> </pre> <br>  ... et vous obtenez quelque chose comme cette configuration de groupe d'instances dans kops: <br><br><pre> <code class="plaintext hljs">apiVersion: kops/v1alpha2 kind: InstanceGroup metadata: creationTimestamp: 2017-12-07T09:24:49Z labels: dedicated: monitoring kops.k8s.io/cluster: k-dev.k8s name: monitoring spec: image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-01-14 machineType: m4.4xlarge maxSize: 2 minSize: 2 nodeLabels: dedicated: monitoring role: Node subnets: - eu-central-1c taints: - dedicated=monitoring:NoSchedule</code> </pre> <br>  Ainsi, les nœuds de ce groupe d'instances ajouteront automatiquement une étiquette et une coloration supplémentaires. <br><br><h2>  2. Configuration de php-fpm pour les charges lourdes </h2><br>  Il existe une grande variété de serveurs qui sont utilisés pour exécuter des applications Web: php-fpm, gunicorn et similaires.  Leur utilisation dans Kubernetes signifie qu'il y a plusieurs choses auxquelles vous devez toujours penser: <br><br><ul><li>  Il est <b>nécessaire</b> de comprendre approximativement <b>combien de travailleurs</b> nous sommes disposés à allouer en php-fpm dans chaque conteneur.  Par exemple, nous pouvons allouer 10 employés pour traiter les demandes entrantes, allouer moins de ressources pour le pod et évoluer en utilisant le nombre de pods - c'est une bonne pratique.  Un autre exemple est d'allouer 500 travailleurs pour chaque pod et d'avoir 2-3 de tels pods en production ... mais c'est une assez mauvaise idée. </li><li>  <b>Des tests de vivacité / de préparation sont</b> nécessaires pour vérifier le bon fonctionnement de chaque module et dans le cas où le module est «bloqué» en raison de problèmes de réseau ou en raison de l'accès à la base de données (il peut y avoir l'une de vos options et la raison).  Dans de telles situations, vous devez recréer le module problématique. </li><li>  Il est important d'enregistrer explicitement la <b>demande et de limiter les ressources</b> pour chaque conteneur afin que l'application ne "coule" pas et ne commence pas à endommager tous les services sur ce serveur. </li></ul><br><h3>  Des solutions </h3><br>  Malheureusement, <b>il n'y a pas de solution miracle</b> qui vous aide à comprendre immédiatement de combien de ressources (CPU, RAM) une application peut avoir besoin.  Une option possible est de surveiller la consommation des ressources et de sélectionner à chaque fois les valeurs optimales.  Afin d'éviter les kill'ov OOM injustifiés et la limitation du processeur, qui affectent considérablement le service, vous pouvez proposer: <br><br><ul><li>  ajoutez les tests de vivacité / préparation corrects afin que nous puissions dire avec certitude que ce conteneur fonctionne correctement.  Il s'agit très probablement d'une page de service qui vérifie la disponibilité de tous les éléments d'infrastructure (nécessaires pour que l'application fonctionne dans le pod) et renvoie un code de réponse 200 OK; </li><li>  sélectionner correctement le nombre de travailleurs qui traiteront les demandes et les répartir correctement. </li></ul><br>  Par exemple, nous avons 10 pods qui se composent de deux conteneurs: nginx (pour envoyer des requêtes statiques et proxy au backend) et php-fpm (en fait le backend, qui traite les pages dynamiques).  Le pool Php-fpm est configuré pour un nombre statique de travailleurs (10).  Ainsi, dans une unité de temps, nous pouvons traiter 100 requêtes actives vers les backends.  Laissez chaque requête être traitée par PHP en 1 seconde. <br><br>  Que se passe-t-il si 1 demande supplémentaire arrive dans un module spécifique, dans lequel 10 demandes sont actuellement activement traitées?  PHP ne pourra pas le traiter et Ingress l'enverra pour réessayer vers le pod suivant s'il s'agit d'une requête GET.  S'il y avait une demande POST, il retournera une erreur. <br><br>  Et si nous prenons en compte que lors du traitement des 10 demandes, nous recevrons un chèque de kubelet (sonde de vivacité), il échouera et Kubernetes commencera à penser que quelque chose ne va pas avec ce conteneur, et le tuera.  Dans ce cas, toutes les demandes qui ont été traitées actuellement se termineront par une erreur (!) Et au moment du redémarrage du conteneur, il sera déséquilibré, ce qui entraînera une augmentation des demandes pour tous les autres backends. <br><br><h4>  Clairement </h4><br>  Supposons que nous ayons 2 pods qui ont chacun 10 travailleurs php-fpm configurés.  Voici un graphique qui affiche des informations pendant le «temps d'arrêt», c'est-à-dire  lorsque le seul qui demande php-fpm est l'exportateur php-fpm (nous avons chacun un travailleur actif): <br><br><img src="https://habrastorage.org/webt/zo/hw/ea/zohwea7nsfbofpgvhixp7edc-qk.png"><br><br>  Maintenant, démarrez le démarrage avec la concurrence 19: <br><br><img src="https://habrastorage.org/webt/my/ba/hp/mybahpcgbfoqzzazbwtzu9dc46a.png"><br><br>  Essayons maintenant de rendre la concurrence supérieure à ce que nous pouvons gérer (20) ... disons 23. Ensuite, tous les employés de php-fpm sont occupés à traiter les demandes des clients: <br><br><img src="https://habrastorage.org/webt/tq/v6/f1/tqv6f1fopruyz8_zittdan1pkho.png"><br><br>  Les vorkers ne suffisent plus pour traiter un échantillon de vivacité, nous voyons donc cette image dans le tableau de bord Kubernetes (ou <code>describe pod</code> ): <br><br><img src="https://habrastorage.org/webt/7z/qo/fw/7zqofwlbjcmxl0qkz2g2rkerece.png"><br><br>  Maintenant, lorsque l'un des pods redémarre, un <b>effet d'avalanche se produit</b> : les demandes commencent à tomber sur le deuxième pod, qui n'est pas non plus en mesure de les traiter, ce qui nous fait recevoir un grand nombre d'erreurs de la part des clients.  Une fois que les piscines de tous les conteneurs sont pleines, l'augmentation du service est problématique - cela n'est possible que par une forte augmentation du nombre de pods ou de travailleurs. <br><br><h4>  Première option </h4><br>  Dans un conteneur avec PHP, vous pouvez configurer 2 pools fpm: l'un pour le traitement des demandes des clients, l'autre pour vérifier la «capacité de survie» du conteneur.  Ensuite, sur le conteneur nginx, vous devrez effectuer une configuration similaire: <br><br><pre> <code class="plaintext hljs"> upstream backend { server 127.0.0.1:9000 max_fails=0; } upstream backend-status { server 127.0.0.1:9001 max_fails=0; }</code> </pre> <br>  Il ne reste plus qu'à envoyer l'échantillon de vivacité pour traitement à l'amont appelé <code>backend-status</code> . <br><br>  Maintenant que la sonde de vivacité est traitée séparément, des erreurs se produiront toujours pour certains clients, mais au moins aucun problème n'est associé au redémarrage du pod et à la déconnexion d'autres clients.  Ainsi, nous réduirons considérablement le nombre d'erreurs, même si nos backends ne peuvent pas faire face à la charge actuelle. <br><br>  Cette option est certainement meilleure que rien, mais elle est également mauvaise car quelque chose peut arriver au pool principal, que nous n'apprendrons pas à utiliser le test de vivacité. <br><br><h4>  Deuxième option </h4><br>  Vous pouvez également utiliser le module nginx peu populaire appelé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nginx-limit-upstream</a> .  Ensuite, en PHP, nous spécifierons 11 travailleurs, et dans le conteneur avec nginx, nous ferons une configuration similaire: <br><br><pre> <code class="plaintext hljs"> limit_upstream_zone limit 32m; upstream backend { server 127.0.0.1:9000 max_fails=0; limit_upstream_conn limit=10 zone=limit backlog=10 timeout=5s; } upstream backend-status { server 127.0.0.1:9000 max_fails=0; }</code> </pre> <br>  Au niveau du frontend, nginx limitera le nombre de requêtes qui seront envoyées au backend (10).  Un point intéressant est qu'un backlog spécial est créé: si le client reçoit la 11ème requête pour nginx, et nginx voit que le pool php-fpm est occupé, alors cette requête est placée dans le backlog pendant 5 secondes.  Si, pendant ce temps, php-fpm ne s'est pas libéré, alors seulement Ingress entrera en action, qui réessayera la demande vers un autre pod.  Cela lisse l'image, car nous aurons toujours 1 travailleur PHP gratuit pour traiter un échantillon de vivacité - nous pouvons éviter l'effet d'avalanche. <br><br><h4>  Autres pensées </h4><br>  Pour des options plus polyvalentes et plus belles pour résoudre ce problème, il vaut la peine de chercher dans la direction d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Envoy</a> et de ses analogues. <br><br>  En général, afin que Prometheus ait un emploi clair des travailleurs, ce qui à son tour aidera à trouver rapidement le problème (et à le notifier), je recommande fortement d'obtenir des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exportateurs</a> prêts à l'emploi pour convertir les données du logiciel au format Prometheus. <br><br><h2>  PS </h2><br>  Autres du cycle de trucs et astuces de K8: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pages d'erreur personnalisées dans NGINX Ingress</a> "; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transfert des ressources travaillant dans un cluster vers la gestion de Helm 2</a> »; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Accès aux sites de développement</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Accélérer le bootstrap des grandes bases de données.</a> " </li></ul><br>  Lisez aussi dans notre blog: <br><br><ul><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comment la haute disponibilité chez Kubernetes est assurée</a> »; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Monitoring and Kubernetes</a> » <i>(revue et reportage vidéo)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Notre expérience avec Kubernetes dans les petits projets</a> " <i>(reportage vidéo, qui comprend une introduction au dispositif technique Kubernetes)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr432748/">https://habr.com/ru/post/fr432748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr432736/index.html">Devops, JUnit5 et tests de microservices: un regard subjectif sur le Heisenbag de Moscou</a></li>
<li><a href="../fr432740/index.html">"CMS" basé sur Google Spreadsheets pour les sites statiques</a></li>
<li><a href="../fr432742/index.html">Pression du temps de l'entreprise</a></li>
<li><a href="../fr432744/index.html">DWDM: la solution est moins chère que l'opérateur de 30 à 50% (classe Entreprise)</a></li>
<li><a href="../fr432746/index.html">Pendant trois jours en soins intensifs ou qu'est-ce qui ne va pas avec la section équilibre travail-vie personnelle sur Mobius'18?</a></li>
<li><a href="../fr432750/index.html">La joie d'Haxe. Un roman avec un langage de programmation négligé</a></li>
<li><a href="../fr432752/index.html">Colline de fourmis ou forteresse? Je construis une maison pour le prix d'un appartement. 3 parties. Alimentation</a></li>
<li><a href="../fr432754/index.html">Le stockage de données en mémoire et sur disque rendra public</a></li>
<li><a href="../fr432756/index.html">Nous implémentons la prise en charge de l'accessibilité sans modifier la composante visuelle de l'application mobile</a></li>
<li><a href="../fr432760/index.html">Vues de produit vectorielles ou autre utilisation du modèle Word2Vec</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
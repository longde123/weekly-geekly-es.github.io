<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔝 🚰 👩🏽‍🚀 Verwendung von Clickhouse als Ersatz für ELK, Big Query und TimescaleDB 🎾 🤞🏼 🍾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clickhouse ist ein von Yandex entwickeltes Open-Source-Open-Source-Datenbankmanagementsystem (OLAP) für analytische Abfragen. Es wird von Yandex, Clou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwendung von Clickhouse als Ersatz für ELK, Big Query und TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/483112/">  <a href="https://clickhouse.yandex/">Clickhouse</a> ist ein von Yandex entwickeltes Open-Source-Open-Source-Datenbankmanagementsystem (OLAP) für analytische Abfragen.  Es wird von Yandex, CloudFlare, VK.com, Badoo und anderen Diensten auf der ganzen Welt verwendet, um wirklich große Datenmengen zu speichern (fügen Sie Tausende von Zeilen pro Sekunde oder Petabyte von Daten ein, die auf der Festplatte gespeichert sind). <br><br>  In einem regulären "String" -DBMS, beispielsweise MySQL, Postgres, MS SQL Server, werden die Daten in dieser Reihenfolge gespeichert: <br><br><img src="https://habrastorage.org/webt/op/as/zd/opaszdhxefzryaitjqttg8sk_to.jpeg"><br><br>  In diesem Fall werden Werte, die sich auf eine Zeile beziehen, physisch nebeneinander gespeichert.  In einem Spalten-DBMS werden Werte aus verschiedenen Spalten separat gespeichert und die Daten einer Spalte werden zusammen gespeichert: <br><br><img src="https://habrastorage.org/webt/oj/17/vg/oj17vgwsilwf8mri4-whzqzm31s.jpeg"><a name="habracut"></a><br><br>  Beispiele für säulenförmige DBMS sind Vertica, Paraccel (Actian Matrix, Amazon Redshift), Sybase IQ, Exasol, Infobright, InfiniDB, MonetDB (VectorWise, Actian Vector), LucidDB, SAP HANA, Google Dremel, Google PowerDrill, Druid, kdb +. <br><br>  Das Mail- <a href="https://qwintry.com/">Weiterleitungsunternehmen Qwintry</a> begann 2018 mit der Verwendung von Clickhouse für die Berichterstellung und war von seiner Einfachheit, Skalierbarkeit, SQL-Unterstützung und Geschwindigkeit sehr beeindruckt.  Die Geschwindigkeit dieses DBMS war von Zauberei begrenzt. <br><br><h3>  Einfachheit </h3><br>  Clickhouse wird auf Ubuntu mit einem einzigen Befehl installiert.  Wenn Sie mit SQL vertraut sind, können Sie Clickhouse sofort für Ihre Anforderungen verwenden.  Dies bedeutet jedoch nicht, dass Sie "show create table" in MySQL ausführen und SQL in Clickhouse kopieren und einfügen können. <br><br>  Im Vergleich zu MySQL gibt es in diesem DBMS wichtige Unterschiede bei den Datentypen bei den Definitionen von Tabellenschemata. Für eine komfortable Arbeit benötigen Sie also noch einige Zeit, um die Definitionen des Tabellenschemas zu ändern und die Tabellenmodule zu untersuchen. <br><br>  Clickhouse funktioniert ohne zusätzliche Software hervorragend. Wenn Sie jedoch die Replikation verwenden möchten, müssen Sie ZooKeeper installieren.  Die Analyse der Abfrageleistung zeigt hervorragende Ergebnisse - Systemtabellen enthalten alle Informationen, und alle Daten können mit dem alten und langweiligen SQL abgerufen werden. <br><br><h3>  Leistung </h3><br><br><ul><li> <a href="https://clickhouse.yandex/benchmark.html">Benchmark-</a> Vergleich von Clickhouse mit Vertica und MySQL auf einem Konfigurationsserver: zwei Intel® Xeon®-CPU-Sockel E5-2650 v2 bei 2,60 GHz;  128 GiB RAM;  md RAID-5 auf 8 SATA-Festplatten mit 6 TB, ext4. </li><li>  <a href="https://www.altinity.com/blog/2017/6/20/clickhouse-vs-redshift">Benchmark-</a> Vergleich von Clickhouse mit dem Cloud-Datenspeicher von Amazon RedShift. </li><li>  Auszüge aus dem <a href="https://blog.cloudflare.com/how-cloudflare-analyzes-1m-dns-queries-per-second/">Cloudflare Clickhouse Performance Blog</a> : </li></ul><br><img src="https://habrastorage.org/webt/oo/2c/0d/oo2c0dfcidwr9fsilydx_b9jilw.jpeg"><br><br>  Die ClickHouse-Datenbank ist sehr einfach aufgebaut - alle Knoten im Cluster haben dieselbe Funktionalität und verwenden nur ZooKeeper für die Koordination.  Wir haben einen kleinen Cluster aus mehreren Knoten erstellt und Tests durchgeführt. Dabei haben wir festgestellt, dass das System eine beeindruckende Leistung aufweist, was den in den Benchmarks für analytische DBMS angegebenen Vorteilen entspricht.  Wir haben uns das Konzept von ClickHouse genauer angesehen.  Das erste Hindernis für die Recherche war der Mangel an Tools und die geringe Größe der ClickHouse-Community. Daher haben wir uns mit dem Design dieses Datenbankverwaltungssystems befasst, um zu verstehen, wie es funktioniert. <br><br>  ClickHouse unterstützt das direkte Empfangen von Daten von Kafka nicht (im Moment weiß es bereits wie), da es sich nur um eine Datenbank handelt. Deshalb haben wir unseren eigenen Adapterservice in Go geschrieben.  Er las Cap'n Proto-codierte Nachrichten von Kafka, konvertierte sie in TSV und fügte sie stapelweise über die HTTP-Schnittstelle in ClickHouse ein.  Später haben wir diesen Service umgeschrieben, um die Go-Bibliothek in Verbindung mit unserer eigenen ClickHouse-Oberfläche zu verwenden und die Leistung zu verbessern.  Bei der Bewertung der Leistung beim Empfang von Paketen haben wir eine wichtige Erkenntnis gewonnen: Es stellte sich heraus, dass diese Leistung bei ClickHouse stark von der Größe des Pakets abhängt, dh von der Anzahl der gleichzeitig eingefügten Zeilen.  Um zu verstehen, warum dies geschieht, haben wir untersucht, wie ClickHouse Daten speichert. <br><br>  Das Hauptmodul bzw. die Familie der von ClickHouse zum Speichern von Daten verwendeten Tabellenmodule ist MergeTree.  Diese Engine ähnelt konzeptionell dem von Google BigTable oder Apache Cassandra verwendeten LSM-Algorithmus, vermeidet jedoch das Erstellen einer Zwischenspeichertabelle und schreibt Daten direkt auf die Festplatte.  Dies ergibt einen ausgezeichneten Schreibdurchsatz, da jedes eingefügte Paket nur nach dem Primärschlüssel sortiert wird, komprimiert und auf die Festplatte geschrieben wird, um ein Segment zu bilden. <br><br>  Das Fehlen einer Speichertabelle oder eines Konzepts der „Aktualität“ von Daten bedeutet auch, dass sie nur hinzugefügt werden können, das System unterstützt das Ändern oder Löschen dieser Daten nicht.  Heutzutage besteht die einzige Möglichkeit, Daten zu löschen, darin, sie nach Kalendermonaten zu löschen, da Segmente niemals die Monatsgrenze überschreiten.  Das ClickHouse-Team arbeitet aktiv daran, diese Funktion anpassbar zu machen.  Auf der anderen Seite werden Segmente nahtlos aufgezeichnet und zusammengeführt, sodass die Empfangsbandbreite linear mit der Anzahl der parallelen Einfügungen skaliert, bis E / A oder Kerne gesättigt sind. <br>  Dies bedeutet jedoch auch, dass das System nicht für kleine Pakete geeignet ist, weshalb Kafka-Services und -Inserts zum Puffern verwendet werden.  Darüber hinaus führt ClickHouse im Hintergrund das Zusammenführen von Segmenten fortwährend durch, sodass viele kleine Informationen mehrmals kombiniert und aufgezeichnet werden, wodurch die Aufzeichnungsintensität erhöht wird.  In diesem Fall verursachen zu viele nicht zusammenhängende Teile eine aggressive Drosselung der Einsätze, solange der Zusammenschluss fortgesetzt wird.  Wir haben festgestellt, dass der beste Kompromiss zwischen Echtzeitdatenempfang und Empfangsleistung darin besteht, eine begrenzte Anzahl von Einfügungen pro Sekunde in die Tabelle zu erhalten. <br><br>  Der Schlüssel zur Leistung beim Lesen von Tabellen ist das Indizieren und Positionieren von Daten auf der Festplatte.  Unabhängig davon, wie schnell die Verarbeitung ist, wenn die Engine Terabytes an Daten von der Festplatte scannen und nur einen Teil davon verwenden muss, dauert es einige Zeit.  ClickHouse ist ein Spaltenspeicher, daher enthält jedes Segment eine Datei für jede Spalte (Spalte) mit sortierten Werten für jede Zeile.  Somit können ganze Spalten, die nicht in der Abfrage enthalten sind, zuerst übersprungen werden, und dann können mehrere Zellen parallel zur vektorisierten Ausführung verarbeitet werden.  Um einen vollständigen Scan zu vermeiden, verfügt jedes Segment über eine kleine Indexdatei. <br><br>  Da alle Spalten nach "Primärschlüssel" sortiert sind, enthält die Indexdatei nur die Bezeichnungen (erfassten Zeilen) jeder N-ten Zeile, um sie auch für sehr große Tabellen im Speicher speichern zu können.  Sie können beispielsweise die Standardeinstellungen "Alle 8192. Zeile markieren" und anschließend die "magere" Indizierung der Tabelle mit 1 Billion festlegen.  Zeilen, die leicht in den Speicher passen, belegen nur 122.070 Zeichen. <br><br><h3>  Systementwicklung </h3><br>  Die Entwicklung und Verbesserung von Clickhouse lässt sich auf das <a href="https://github.com/yandex/ClickHouse/pulse">Github-Repo</a> zurückführen und stellt sicher, dass der Prozess des "Erwachsenwerdens" in beeindruckendem Tempo abläuft. <br><br><img src="https://habrastorage.org/webt/zl/iw/iz/zliwizhn6we2o5easwfkystr5g0.jpeg"><br><br><h3>  Popularität </h3><br>  Clickhouse scheint exponentiell zu wachsen, insbesondere in der russischsprachigen Gemeinschaft.  Die letztjährige Konferenz High Load 2018 (Moskau, 8. bis 9. November 2018) zeigte, dass Monster wie vk.com und Badoo Clickhouse verwenden, mit dem sie Daten (zum Beispiel Protokolle) von Zehntausenden von Servern gleichzeitig einfügen.  In einem 40-minütigen Video <a href="https://www.youtube.com/watch%3Fv%3DpbbcMcrQoXw">spricht Yuri Nasretdinov vom VKontakte-Team darüber, wie das gemacht wird</a> .  In Kürze werden wir das Transkript auf Habr veröffentlichen, um die Arbeit mit dem Material zu erleichtern. <br><br><h3>  Anwendungsgebiete </h3><br>  Nachdem ich einige Zeit recherchiert habe, gibt es Bereiche, in denen ClickHouse nützlich sein oder andere, traditionellere und populärere Lösungen, wie MySQL, PostgreSQL, ELK, Google Big Query, Amazon RedShift, vollständig ersetzen kann. TimescaleDB, Hadoop, MapReduce, Pinot und Druid.  Im Folgenden werden Details zur Verwendung von ClickHouse zum Upgrade oder vollständigen Ersetzen der oben genannten DBMS aufgeführt. <br><br><h3>  Erweiterung von MySQL und PostgreSQL </h3><br>  Zuletzt haben wir MySQL für die <a href="https://www.mautic.org/">Newsletter-</a> Plattform von <a href="https://www.mautic.org/">Mautic</a> teilweise durch ClickHouse ersetzt.  Das Problem war, dass MySQL aufgrund seines schlecht durchdachten Designs jede gesendete E-Mail und jeden Link in dieser E-Mail mit einem base64-Hash protokollierte und so eine riesige MySQL-Tabelle (email_stats) erstellte.  Nachdem nur 10 Millionen Briefe an Service-Abonnenten gesendet worden waren, belegte diese Tabelle 150 GB Dateibereich, und MySQL wurde bei einfachen Abfragen "langweilig".  Um das Dateibereichsproblem zu beheben, haben wir erfolgreich die InnoDB-Tabellenkomprimierung verwendet, die es um das Vierfache reduzierte.  Es ist jedoch immer noch nicht sinnvoll, mehr als 20 bis 30 Millionen E-Mails in MySQL zu speichern, um die Story zu lesen, da jede einfache Anforderung, die aus irgendeinem Grund einen vollständigen Scan durchführen muss, zu einem Austausch und einer hohen Belastung der E / A führt über die wir regelmäßig Warnungen von Zabbix erhielten. <br><br><img src="https://habrastorage.org/webt/t6/h9/3d/t6h93dxzyu7l_ddcmb9g-zhctwk.jpeg"><br><br>  Clickhouse verwendet zwei Komprimierungsalgorithmen, die die Datenmenge um das <a href="https://www.altinity.com/blog/2017/11/21/compression-in-clickhouse">3-4-fache</a> reduzieren. In diesem speziellen Fall waren die Daten jedoch besonders „komprimierbar“. <br><br><img src="https://habrastorage.org/webt/rd/8o/0x/rd8o0xpshmzaqfmbzblzp-cgczm.jpeg"><br><br><h3>  ELK Ersatz </h3><br>  Nach unseren eigenen Erfahrungen erfordert der ELK-Stack (ElasticSearch, Logstash und Kibana, in diesem speziellen Fall ElasticSearch) viel mehr Ressourcen, als zum Speichern von Protokollen erforderlich sind.  ElasticSearch ist eine großartige Suchmaschine, wenn Sie eine gute Volltext-Protokollsuche benötigen (und ich glaube nicht, dass Sie sie wirklich benötigen), aber ich frage mich, warum sie de facto zur Standard-Protokolliermaschine geworden ist.  Die Empfangsleistung in Kombination mit Logstash bereitete uns auch bei relativ geringen Belastungen Probleme und erforderte die Hinzufügung von mehr RAM und Speicherplatz.  Als Datenbank ist Clickhouse aus folgenden Gründen besser als ElasticSearch: <br><br><ul><li>  SQL-Dialekt-Unterstützung; </li><li>  Das beste Komprimierungsverhältnis der gespeicherten Daten; </li><li>  Unterstützung für reguläre reguläre Ausdruckssuchen anstelle von Volltextsuchen; </li><li>  Verbesserte Abfrageplanung und höhere Gesamtleistung. </li></ul><br>  Derzeit ist das größte Problem, das beim Vergleich von ClickHouse mit ELK auftritt, das Fehlen von Lösungen für Versandprotokolle sowie das Fehlen von Dokumentation und Schulungshilfen zu diesem Thema.  Gleichzeitig kann jeder Benutzer ELK mithilfe des Digital Ocean Guide konfigurieren, was für die schnelle Implementierung solcher Technologien sehr wichtig ist.  Es gibt hier eine Datenbank-Engine, aber noch keinen Filebeat für ClickHouse.  Ja, es gibt ein <a href="https://www.fluentd.org/">fließendes</a> und ein System zum Arbeiten mit Protokolldateien. Es gibt ein <a href="https://github.com/Altinity/clicktail">Klick-</a> Tool zum Eingeben von Daten aus Protokolldateien in ClickHouse, aber all dies nimmt mehr Zeit in Anspruch.  Allerdings führt ClickHouse aufgrund seiner Einfachheit immer noch dazu, dass selbst Anfänger es einfach installieren und es in nur 10 Minuten vollständig nutzen können. <br><br>  Ich bevorzuge minimalistische Lösungen und versuche, FluentBit, ein Tool zum Versenden von Protokollen mit sehr wenig Speicher, zusammen mit ClickHouse, zu verwenden, während ich versuche, Kafka zu vermeiden.  Kleinere Inkompatibilitäten, z. B. <a href="https://github.com/fluent/fluent-bit/issues/848">Probleme mit dem Datumsformat</a> , müssen jedoch behoben werden, bevor auf eine Proxy-Ebene verzichtet werden kann, die Daten von FluentBit nach ClickHouse konvertiert. <br><br>  Alternativ zu Kibana können Sie <a href="https://github.com/Vertamedia/clickhouse-grafana">Grafana</a> als ClickHouse- <a href="https://github.com/Vertamedia/clickhouse-grafana">Backend verwenden</a> .  Soweit ich weiß, kann dies zu Leistungsproblemen beim Rendern einer großen Menge von Datenpunkten führen, insbesondere bei älteren Versionen von Grafana.  Bei Qwintry haben wir dies noch nicht ausprobiert, aber Beschwerden darüber erscheinen von Zeit zu Zeit auf dem ClickHouse-Support-Kanal in Telegram. <br><br><h3>  Ersetzen von Google Big Query und Amazon RedShift (Lösung für große Unternehmen) </h3><br>  Der ideale Anwendungsfall für BigQuery ist das Herunterladen von 1 TB JSON-Daten und das Ausführen von analytischen Abfragen.  Big Query ist ein großartiges Produkt, dessen Skalierbarkeit schwer zu überschätzen ist.  Dies ist eine wesentlich komplexere Software als ClickHouse, die auf einem internen Cluster ausgeführt wird. Aus Sicht des Clients hat sie jedoch viele Gemeinsamkeiten mit ClickHouse.  BigQuery kann schnell im Preis steigen, sobald Sie für jedes SELECT bezahlen. Dies ist also eine echte SaaS-Lösung mit all ihren Vor- und Nachteilen. <br><br>  ClickHouse ist die beste Wahl, wenn Sie viele rechenintensive Abfragen durchführen.  Je mehr SELECT-Abfragen Sie täglich ausführen, desto sinnvoller ist es, Big Query durch ClickHouse zu ersetzen, da Sie durch eine solche Ersetzung Tausende von Dollar sparen, wenn es um viele Terabyte verarbeiteter Daten geht.  Dies gilt nicht für gespeicherte Daten, deren Verarbeitung in Big Query recht kostengünstig ist. <br><br>  In dem Artikel von Altinity-Mitbegründer Alexander Zaitsev, <a href="https://www.altinity.com/blog/2017/10/23/migration-to-clickhouse">„Switching to ClickHouse“</a> , werden die Vorteile einer solchen DBMS-Migration <a href="https://www.altinity.com/blog/2017/10/23/migration-to-clickhouse">erläutert</a> . <br><br><h3>  TimescaleDB ersetzen </h3><br>  TimescaleDB ist eine PostgreSQL-Erweiterung, die die Arbeit mit Zeitreihen-Zeitreihen in einer regulären Datenbank optimiert ( <a href="https://docs.timescale.com/v1.0/introduction">https://docs.timescale.com/v1.0/introduction</a> , <a href="https://habr.com/ru/company/zabbix/blog/458530/">https://habr.com/de/company/zabbix/blog/458530) /</a> ). <br><br>  Obwohl ClickHouse kein ernstzunehmender Konkurrent in der Zeitreihennische ist, sondern die Spaltenstruktur und Vektorausführung von Abfragen, ist es in den meisten Fällen bei der Verarbeitung von analytischen Abfragen viel schneller als TimescaleDB.  Gleichzeitig ist die Leistung beim Empfang von ClickHouse-Paketdaten etwa dreimal so hoch. Darüber hinaus wird 20 Mal weniger Speicherplatz benötigt, was für die Verarbeitung großer Mengen historischer Daten wirklich wichtig ist: <a href="https://www.altinity.com/blog/ClickHouse-for-time-series">https://www.altinity.com/blog/ClickHouse-for -Zeit-Serie</a> . <br><br>  Im Gegensatz zu ClickHouse können Sie in TimescaleDB nur mit ZFS oder ähnlichen Dateisystemen Speicherplatz sparen. <br><br>  Bevorstehende ClickHouse-Aktualisierungen führen wahrscheinlich zu einer Delta-Komprimierung, die die Verarbeitung und Speicherung von Zeitreihendaten noch einfacher macht.  In den folgenden Fällen ist TimescaleDB möglicherweise die bessere Wahl als ein nacktes ClickHouse: <br><br><ul><li>  kleine Installationen mit sehr wenig RAM (&lt;3 GB); </li><li>  eine große Anzahl kleiner INSERTs, die nicht in große Fragmente gepuffert werden sollen; </li><li>  bessere Konsistenz-, Homogenitäts- und ACID-Anforderungen; </li><li>  PostGIS-Unterstützung; </li><li>  Zusammenführen mit vorhandenen PostgreSQL-Tabellen, da Timescale DB im Wesentlichen PostgreSQL ist. </li></ul><br><h3>  Wettbewerb mit Hadoop und MapReduce Systems </h3><br>  Hadoop und andere MapReduce-Produkte können viele komplexe Berechnungen durchführen, sind jedoch in der Regel mit großen Verzögerungen verbunden. ClickHouse behebt dieses Problem, indem es Terabytes an Daten verarbeitet und fast sofort Ergebnisse liefert.  Somit ist ClickHouse viel effizienter für die Durchführung schneller, interaktiver Analysen, was für Datenverarbeitungsspezialisten interessant sein dürfte. <br><br><h3>  Konkurrenz mit Pinot und Druide </h3><br>  Die engsten Konkurrenten von ClickHouse sind Pinot und Druid, ein linear skalierbares Open-Source-Produkt.  Ein hervorragender Vergleich dieser Systeme wurde in einem Artikel von <a href="https://medium.com/%40leventov/comparison-of-the-open-source-olap-systems-for-big-data-ClickHouse-druid-and-pinot-8e042a5ed1c7">Roman Leventov</a> vom 1. Februar 2018 veröffentlicht. <br><br><img src="https://habrastorage.org/webt/4c/26/hb/4c26hbndeb9gj0mq86lyfrmpc0e.jpeg"><br><br>  Dieser Artikel muss aktualisiert werden. ClickHouse unterstützt keine UPDATE- und DELETE-Vorgänge, was für die neuesten Versionen nicht vollständig zutrifft. <br><br>  Wir haben nicht genug Erfahrung mit diesen DBMS, aber ich mag die Komplexität der Infrastruktur, die für die Ausführung von Druid und Pinot verwendet wird, nicht - dies ist eine ganze Reihe von "beweglichen Teilen", die von allen Seiten von Java umgeben sind. <br><br>  Druid und Pinot sind Apache-Inkubatorprojekte, über deren Entwicklungsfortschritt Apache auf den Seiten seiner GitHub-Projekte ausführlich berichtet.  Pinot erschien im Oktober 2018 im Inkubator und Druide wurde 8 Monate zuvor geboren - im Februar. <br><br>  Der Mangel an Informationen über die Funktionsweise von AFS wirft einige und vielleicht alberne Fragen auf.  Ich frage mich, ob die Autoren von Pinot bemerkt haben, dass die Apache Foundation Druiden gegenüber eher geneigt ist, und hat diese Haltung gegenüber dem Konkurrenten Neid ausgelöst?  Wird sich die Entwicklung von Druiden verlangsamen und der Pinot beschleunigen, wenn Sponsoren, die die ersteren unterstützen, plötzlich Interesse an den letzteren entwickeln? <br><br><h3>  Nachteile von ClickHouse </h3><br>  Unreife: Offensichtlich ist dies noch keine langweilige Technologie, aber in anderen säulenartigen DBMS wird auf jeden Fall nichts Ähnliches beobachtet. <br><br>  Kleine Beilagen funktionieren bei hoher Geschwindigkeit nicht gut: Beilagen müssen in große Teile geteilt werden, da die Leistung kleiner Beilagen proportional zur Anzahl der Spalten in jeder Zeile abnimmt.  Auf diese Weise speichert ClickHouse Daten auf der Festplatte - jede Spalte bedeutet 1 Datei oder mehr. Um eine Zeile mit 100 Spalten einzufügen, müssen Sie mindestens 100 Dateien öffnen und schreiben.  Aus diesem Grund ist ein Intermediär erforderlich, um Einfügungen zu puffern (es sei denn, der Client stellt selbst die Pufferung bereit). In der Regel handelt es sich hierbei um Kafka oder eine Art Warteschlangenverwaltungssystem.  Sie können auch die Puffertabellen-Engine verwenden, um später große Datenmengen in MergeTree-Tabellen zu kopieren. <br><br>  Tabellenverknüpfungen sind durch den Arbeitsspeicher des Servers begrenzt, aber zumindest sind sie vorhanden!  Zum Beispiel haben Druid und Pinot überhaupt keine derartigen Verbindungen, da sie in verteilten Systemen, die das Verschieben großer Datenmengen zwischen Knoten nicht unterstützen, nur schwer direkt zu implementieren sind. <br><br><h3>  Schlussfolgerungen </h3><br>  In den kommenden Jahren planen wir, ClickHouse in Qwintry umfassend zu nutzen, da dieses DBMS ein hervorragendes Gleichgewicht zwischen Leistung, geringem Overhead, Skalierbarkeit und Einfachheit bietet.  Ich bin mir ziemlich sicher, dass es sich schnell verbreiten wird, sobald die ClickHouse-Community mehr Möglichkeiten für die Verwendung in kleinen und mittleren Installationen findet. <br><br><h3>  Ein bisschen Werbung :) </h3><br>  Vielen Dank für Ihren Aufenthalt bei uns.  Mögen Sie unsere Artikel?  Möchten Sie weitere interessante Materialien sehen?  Unterstützen Sie uns, indem Sie eine Bestellung <a href="https://habr.com/company/ua-hosting/blog/347386/">aufgeben</a> oder Ihren Freunden <a href="https://ua-hosting.company/cloudvps/nl">Cloud-basiertes VPS für Entwickler ab 4,99 US-Dollar</a> empfehlen, ein <b>einzigartiges Analogon zu Einstiegsservern, das wir für Sie erfunden haben:</b> <a href="https://habr.com/company/ua-hosting/blog/347386/">Die ganze Wahrheit über VPS (KVM) E5-2697 v3 (6 Kerne) 10 GB DDR4 480 GB SSD 1 Gbit / s ab 19 Dollar oder wie teilt man den Server?</a>  (Optionen sind mit RAID1 und RAID10, bis zu 24 Kernen und bis zu 40 GB DDR4 verfügbar). <br><br>  <b>Dell R730xd 2-mal billiger im Equinix Tier IV-Rechenzentrum in Amsterdam?</b>  Nur wir haben <b><a href="https://ua-hosting.company/serversnl">2 x Intel TetraDeca-Core Xeon 2 x E5-2697v3 2,6 GHz 14C 64 GB DDR4 4 x 960 GB SSD 1 Gbit / s 100 TV ab 199 US-Dollar</a> in den Niederlanden!</b>  <b><b>Dell R420 - 2x E5-2430 2,2 GHz 6C 128 GB DDR3 2x960 GB SSD 1 Gbit / s 100 TB - ab 99 US-Dollar!</b></b>  Lesen Sie mehr über <a href="https://habr.com/company/ua-hosting/blog/329618/">das Erstellen von Infrastruktur-Bldg.</a>  <a href="https://habr.com/company/ua-hosting/blog/329618/">Klasse mit Dell R730xd E5-2650 v4 Servern für 9.000 Euro für einen Cent?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de483112/">https://habr.com/ru/post/de483112/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de483082/index.html">Vulnerability Hunting ist 7% effektiver</a></li>
<li><a href="../de483084/index.html">Kamera mit Tracking-Funktion</a></li>
<li><a href="../de483086/index.html">Ergebnisse von 2019: Welche Vermögenswerte erwiesen sich für russische Investoren als die rentabelsten</a></li>
<li><a href="../de483094/index.html">Wie ich meinen Traum verwirklichte, als ich das russische Büro von Microsoft besuchte</a></li>
<li><a href="../de483110/index.html">Rostow am Don: IT-Unternehmen, Communities und Veranstaltungen im Jahr 2019</a></li>
<li><a href="../de483114/index.html">Die modalen Fenster, die wir verdienen</a></li>
<li><a href="../de483116/index.html">Zu Hause ein Teleskoprohr bauen</a></li>
<li><a href="../de483118/index.html">Was wird im Jahr 2020 zu JavaScript hinzugefügt</a></li>
<li><a href="../de483120/index.html">Wie verbinde ich Karten in einer Ellipsoidprojektion, wenn dies nicht vorgesehen ist?</a></li>
<li><a href="../de483124/index.html">Das massivste Gadget in naher Zukunft (kein Smartphone)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîù üö∞ üë©üèΩ‚ÄçüöÄ Verwendung von Clickhouse als Ersatz f√ºr ELK, Big Query und TimescaleDB üéæ ü§ûüèº üçæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clickhouse ist ein von Yandex entwickeltes Open-Source-Open-Source-Datenbankmanagementsystem (OLAP) f√ºr analytische Abfragen. Es wird von Yandex, Clou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwendung von Clickhouse als Ersatz f√ºr ELK, Big Query und TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/483112/">  <a href="https://clickhouse.yandex/">Clickhouse</a> ist ein von Yandex entwickeltes Open-Source-Open-Source-Datenbankmanagementsystem (OLAP) f√ºr analytische Abfragen.  Es wird von Yandex, CloudFlare, VK.com, Badoo und anderen Diensten auf der ganzen Welt verwendet, um wirklich gro√üe Datenmengen zu speichern (f√ºgen Sie Tausende von Zeilen pro Sekunde oder Petabyte von Daten ein, die auf der Festplatte gespeichert sind). <br><br>  In einem regul√§ren "String" -DBMS, beispielsweise MySQL, Postgres, MS SQL Server, werden die Daten in dieser Reihenfolge gespeichert: <br><br><img src="https://habrastorage.org/webt/op/as/zd/opaszdhxefzryaitjqttg8sk_to.jpeg"><br><br>  In diesem Fall werden Werte, die sich auf eine Zeile beziehen, physisch nebeneinander gespeichert.  In einem Spalten-DBMS werden Werte aus verschiedenen Spalten separat gespeichert und die Daten einer Spalte werden zusammen gespeichert: <br><br><img src="https://habrastorage.org/webt/oj/17/vg/oj17vgwsilwf8mri4-whzqzm31s.jpeg"><a name="habracut"></a><br><br>  Beispiele f√ºr s√§ulenf√∂rmige DBMS sind Vertica, Paraccel (Actian Matrix, Amazon Redshift), Sybase IQ, Exasol, Infobright, InfiniDB, MonetDB (VectorWise, Actian Vector), LucidDB, SAP HANA, Google Dremel, Google PowerDrill, Druid, kdb +. <br><br>  Das Mail- <a href="https://qwintry.com/">Weiterleitungsunternehmen Qwintry</a> begann 2018 mit der Verwendung von Clickhouse f√ºr die Berichterstellung und war von seiner Einfachheit, Skalierbarkeit, SQL-Unterst√ºtzung und Geschwindigkeit sehr beeindruckt.  Die Geschwindigkeit dieses DBMS war von Zauberei begrenzt. <br><br><h3>  Einfachheit </h3><br>  Clickhouse wird auf Ubuntu mit einem einzigen Befehl installiert.  Wenn Sie mit SQL vertraut sind, k√∂nnen Sie Clickhouse sofort f√ºr Ihre Anforderungen verwenden.  Dies bedeutet jedoch nicht, dass Sie "show create table" in MySQL ausf√ºhren und SQL in Clickhouse kopieren und einf√ºgen k√∂nnen. <br><br>  Im Vergleich zu MySQL gibt es in diesem DBMS wichtige Unterschiede bei den Datentypen bei den Definitionen von Tabellenschemata. F√ºr eine komfortable Arbeit ben√∂tigen Sie also noch einige Zeit, um die Definitionen des Tabellenschemas zu √§ndern und die Tabellenmodule zu untersuchen. <br><br>  Clickhouse funktioniert ohne zus√§tzliche Software hervorragend. Wenn Sie jedoch die Replikation verwenden m√∂chten, m√ºssen Sie ZooKeeper installieren.  Die Analyse der Abfrageleistung zeigt hervorragende Ergebnisse - Systemtabellen enthalten alle Informationen, und alle Daten k√∂nnen mit dem alten und langweiligen SQL abgerufen werden. <br><br><h3>  Leistung </h3><br><br><ul><li> <a href="https://clickhouse.yandex/benchmark.html">Benchmark-</a> Vergleich von Clickhouse mit Vertica und MySQL auf einem Konfigurationsserver: zwei Intel¬Æ Xeon¬Æ-CPU-Sockel E5-2650 v2 bei 2,60 GHz;  128 GiB RAM;  md RAID-5 auf 8 SATA-Festplatten mit 6 TB, ext4. </li><li>  <a href="https://www.altinity.com/blog/2017/6/20/clickhouse-vs-redshift">Benchmark-</a> Vergleich von Clickhouse mit dem Cloud-Datenspeicher von Amazon RedShift. </li><li>  Ausz√ºge aus dem <a href="https://blog.cloudflare.com/how-cloudflare-analyzes-1m-dns-queries-per-second/">Cloudflare Clickhouse Performance Blog</a> : </li></ul><br><img src="https://habrastorage.org/webt/oo/2c/0d/oo2c0dfcidwr9fsilydx_b9jilw.jpeg"><br><br>  Die ClickHouse-Datenbank ist sehr einfach aufgebaut - alle Knoten im Cluster haben dieselbe Funktionalit√§t und verwenden nur ZooKeeper f√ºr die Koordination.  Wir haben einen kleinen Cluster aus mehreren Knoten erstellt und Tests durchgef√ºhrt. Dabei haben wir festgestellt, dass das System eine beeindruckende Leistung aufweist, was den in den Benchmarks f√ºr analytische DBMS angegebenen Vorteilen entspricht.  Wir haben uns das Konzept von ClickHouse genauer angesehen.  Das erste Hindernis f√ºr die Recherche war der Mangel an Tools und die geringe Gr√∂√üe der ClickHouse-Community. Daher haben wir uns mit dem Design dieses Datenbankverwaltungssystems befasst, um zu verstehen, wie es funktioniert. <br><br>  ClickHouse unterst√ºtzt das direkte Empfangen von Daten von Kafka nicht (im Moment wei√ü es bereits wie), da es sich nur um eine Datenbank handelt. Deshalb haben wir unseren eigenen Adapterservice in Go geschrieben.  Er las Cap'n Proto-codierte Nachrichten von Kafka, konvertierte sie in TSV und f√ºgte sie stapelweise √ºber die HTTP-Schnittstelle in ClickHouse ein.  Sp√§ter haben wir diesen Service umgeschrieben, um die Go-Bibliothek in Verbindung mit unserer eigenen ClickHouse-Oberfl√§che zu verwenden und die Leistung zu verbessern.  Bei der Bewertung der Leistung beim Empfang von Paketen haben wir eine wichtige Erkenntnis gewonnen: Es stellte sich heraus, dass diese Leistung bei ClickHouse stark von der Gr√∂√üe des Pakets abh√§ngt, dh von der Anzahl der gleichzeitig eingef√ºgten Zeilen.  Um zu verstehen, warum dies geschieht, haben wir untersucht, wie ClickHouse Daten speichert. <br><br>  Das Hauptmodul bzw. die Familie der von ClickHouse zum Speichern von Daten verwendeten Tabellenmodule ist MergeTree.  Diese Engine √§hnelt konzeptionell dem von Google BigTable oder Apache Cassandra verwendeten LSM-Algorithmus, vermeidet jedoch das Erstellen einer Zwischenspeichertabelle und schreibt Daten direkt auf die Festplatte.  Dies ergibt einen ausgezeichneten Schreibdurchsatz, da jedes eingef√ºgte Paket nur nach dem Prim√§rschl√ºssel sortiert wird, komprimiert und auf die Festplatte geschrieben wird, um ein Segment zu bilden. <br><br>  Das Fehlen einer Speichertabelle oder eines Konzepts der ‚ÄûAktualit√§t‚Äú von Daten bedeutet auch, dass sie nur hinzugef√ºgt werden k√∂nnen, das System unterst√ºtzt das √Ñndern oder L√∂schen dieser Daten nicht.  Heutzutage besteht die einzige M√∂glichkeit, Daten zu l√∂schen, darin, sie nach Kalendermonaten zu l√∂schen, da Segmente niemals die Monatsgrenze √ºberschreiten.  Das ClickHouse-Team arbeitet aktiv daran, diese Funktion anpassbar zu machen.  Auf der anderen Seite werden Segmente nahtlos aufgezeichnet und zusammengef√ºhrt, sodass die Empfangsbandbreite linear mit der Anzahl der parallelen Einf√ºgungen skaliert, bis E / A oder Kerne ges√§ttigt sind. <br>  Dies bedeutet jedoch auch, dass das System nicht f√ºr kleine Pakete geeignet ist, weshalb Kafka-Services und -Inserts zum Puffern verwendet werden.  Dar√ºber hinaus f√ºhrt ClickHouse im Hintergrund das Zusammenf√ºhren von Segmenten fortw√§hrend durch, sodass viele kleine Informationen mehrmals kombiniert und aufgezeichnet werden, wodurch die Aufzeichnungsintensit√§t erh√∂ht wird.  In diesem Fall verursachen zu viele nicht zusammenh√§ngende Teile eine aggressive Drosselung der Eins√§tze, solange der Zusammenschluss fortgesetzt wird.  Wir haben festgestellt, dass der beste Kompromiss zwischen Echtzeitdatenempfang und Empfangsleistung darin besteht, eine begrenzte Anzahl von Einf√ºgungen pro Sekunde in die Tabelle zu erhalten. <br><br>  Der Schl√ºssel zur Leistung beim Lesen von Tabellen ist das Indizieren und Positionieren von Daten auf der Festplatte.  Unabh√§ngig davon, wie schnell die Verarbeitung ist, wenn die Engine Terabytes an Daten von der Festplatte scannen und nur einen Teil davon verwenden muss, dauert es einige Zeit.  ClickHouse ist ein Spaltenspeicher, daher enth√§lt jedes Segment eine Datei f√ºr jede Spalte (Spalte) mit sortierten Werten f√ºr jede Zeile.  Somit k√∂nnen ganze Spalten, die nicht in der Abfrage enthalten sind, zuerst √ºbersprungen werden, und dann k√∂nnen mehrere Zellen parallel zur vektorisierten Ausf√ºhrung verarbeitet werden.  Um einen vollst√§ndigen Scan zu vermeiden, verf√ºgt jedes Segment √ºber eine kleine Indexdatei. <br><br>  Da alle Spalten nach "Prim√§rschl√ºssel" sortiert sind, enth√§lt die Indexdatei nur die Bezeichnungen (erfassten Zeilen) jeder N-ten Zeile, um sie auch f√ºr sehr gro√üe Tabellen im Speicher speichern zu k√∂nnen.  Sie k√∂nnen beispielsweise die Standardeinstellungen "Alle 8192. Zeile markieren" und anschlie√üend die "magere" Indizierung der Tabelle mit 1 Billion festlegen.  Zeilen, die leicht in den Speicher passen, belegen nur 122.070 Zeichen. <br><br><h3>  Systementwicklung </h3><br>  Die Entwicklung und Verbesserung von Clickhouse l√§sst sich auf das <a href="https://github.com/yandex/ClickHouse/pulse">Github-Repo</a> zur√ºckf√ºhren und stellt sicher, dass der Prozess des "Erwachsenwerdens" in beeindruckendem Tempo abl√§uft. <br><br><img src="https://habrastorage.org/webt/zl/iw/iz/zliwizhn6we2o5easwfkystr5g0.jpeg"><br><br><h3>  Popularit√§t </h3><br>  Clickhouse scheint exponentiell zu wachsen, insbesondere in der russischsprachigen Gemeinschaft.  Die letztj√§hrige Konferenz High Load 2018 (Moskau, 8. bis 9. November 2018) zeigte, dass Monster wie vk.com und Badoo Clickhouse verwenden, mit dem sie Daten (zum Beispiel Protokolle) von Zehntausenden von Servern gleichzeitig einf√ºgen.  In einem 40-min√ºtigen Video <a href="https://www.youtube.com/watch%3Fv%3DpbbcMcrQoXw">spricht Yuri Nasretdinov vom VKontakte-Team dar√ºber, wie das gemacht wird</a> .  In K√ºrze werden wir das Transkript auf Habr ver√∂ffentlichen, um die Arbeit mit dem Material zu erleichtern. <br><br><h3>  Anwendungsgebiete </h3><br>  Nachdem ich einige Zeit recherchiert habe, gibt es Bereiche, in denen ClickHouse n√ºtzlich sein oder andere, traditionellere und popul√§rere L√∂sungen, wie MySQL, PostgreSQL, ELK, Google Big Query, Amazon RedShift, vollst√§ndig ersetzen kann. TimescaleDB, Hadoop, MapReduce, Pinot und Druid.  Im Folgenden werden Details zur Verwendung von ClickHouse zum Upgrade oder vollst√§ndigen Ersetzen der oben genannten DBMS aufgef√ºhrt. <br><br><h3>  Erweiterung von MySQL und PostgreSQL </h3><br>  Zuletzt haben wir MySQL f√ºr die <a href="https://www.mautic.org/">Newsletter-</a> Plattform von <a href="https://www.mautic.org/">Mautic</a> teilweise durch ClickHouse ersetzt.  Das Problem war, dass MySQL aufgrund seines schlecht durchdachten Designs jede gesendete E-Mail und jeden Link in dieser E-Mail mit einem base64-Hash protokollierte und so eine riesige MySQL-Tabelle (email_stats) erstellte.  Nachdem nur 10 Millionen Briefe an Service-Abonnenten gesendet worden waren, belegte diese Tabelle 150 GB Dateibereich, und MySQL wurde bei einfachen Abfragen "langweilig".  Um das Dateibereichsproblem zu beheben, haben wir erfolgreich die InnoDB-Tabellenkomprimierung verwendet, die es um das Vierfache reduzierte.  Es ist jedoch immer noch nicht sinnvoll, mehr als 20 bis 30 Millionen E-Mails in MySQL zu speichern, um die Story zu lesen, da jede einfache Anforderung, die aus irgendeinem Grund einen vollst√§ndigen Scan durchf√ºhren muss, zu einem Austausch und einer hohen Belastung der E / A f√ºhrt √ºber die wir regelm√§√üig Warnungen von Zabbix erhielten. <br><br><img src="https://habrastorage.org/webt/t6/h9/3d/t6h93dxzyu7l_ddcmb9g-zhctwk.jpeg"><br><br>  Clickhouse verwendet zwei Komprimierungsalgorithmen, die die Datenmenge um das <a href="https://www.altinity.com/blog/2017/11/21/compression-in-clickhouse">3-4-fache</a> reduzieren. In diesem speziellen Fall waren die Daten jedoch besonders ‚Äûkomprimierbar‚Äú. <br><br><img src="https://habrastorage.org/webt/rd/8o/0x/rd8o0xpshmzaqfmbzblzp-cgczm.jpeg"><br><br><h3>  ELK Ersatz </h3><br>  Nach unseren eigenen Erfahrungen erfordert der ELK-Stack (ElasticSearch, Logstash und Kibana, in diesem speziellen Fall ElasticSearch) viel mehr Ressourcen, als zum Speichern von Protokollen erforderlich sind.  ElasticSearch ist eine gro√üartige Suchmaschine, wenn Sie eine gute Volltext-Protokollsuche ben√∂tigen (und ich glaube nicht, dass Sie sie wirklich ben√∂tigen), aber ich frage mich, warum sie de facto zur Standard-Protokolliermaschine geworden ist.  Die Empfangsleistung in Kombination mit Logstash bereitete uns auch bei relativ geringen Belastungen Probleme und erforderte die Hinzuf√ºgung von mehr RAM und Speicherplatz.  Als Datenbank ist Clickhouse aus folgenden Gr√ºnden besser als ElasticSearch: <br><br><ul><li>  SQL-Dialekt-Unterst√ºtzung; </li><li>  Das beste Komprimierungsverh√§ltnis der gespeicherten Daten; </li><li>  Unterst√ºtzung f√ºr regul√§re regul√§re Ausdruckssuchen anstelle von Volltextsuchen; </li><li>  Verbesserte Abfrageplanung und h√∂here Gesamtleistung. </li></ul><br>  Derzeit ist das gr√∂√üte Problem, das beim Vergleich von ClickHouse mit ELK auftritt, das Fehlen von L√∂sungen f√ºr Versandprotokolle sowie das Fehlen von Dokumentation und Schulungshilfen zu diesem Thema.  Gleichzeitig kann jeder Benutzer ELK mithilfe des Digital Ocean Guide konfigurieren, was f√ºr die schnelle Implementierung solcher Technologien sehr wichtig ist.  Es gibt hier eine Datenbank-Engine, aber noch keinen Filebeat f√ºr ClickHouse.  Ja, es gibt ein <a href="https://www.fluentd.org/">flie√üendes</a> und ein System zum Arbeiten mit Protokolldateien. Es gibt ein <a href="https://github.com/Altinity/clicktail">Klick-</a> Tool zum Eingeben von Daten aus Protokolldateien in ClickHouse, aber all dies nimmt mehr Zeit in Anspruch.  Allerdings f√ºhrt ClickHouse aufgrund seiner Einfachheit immer noch dazu, dass selbst Anf√§nger es einfach installieren und es in nur 10 Minuten vollst√§ndig nutzen k√∂nnen. <br><br>  Ich bevorzuge minimalistische L√∂sungen und versuche, FluentBit, ein Tool zum Versenden von Protokollen mit sehr wenig Speicher, zusammen mit ClickHouse, zu verwenden, w√§hrend ich versuche, Kafka zu vermeiden.  Kleinere Inkompatibilit√§ten, z. B. <a href="https://github.com/fluent/fluent-bit/issues/848">Probleme mit dem Datumsformat</a> , m√ºssen jedoch behoben werden, bevor auf eine Proxy-Ebene verzichtet werden kann, die Daten von FluentBit nach ClickHouse konvertiert. <br><br>  Alternativ zu Kibana k√∂nnen Sie <a href="https://github.com/Vertamedia/clickhouse-grafana">Grafana</a> als ClickHouse- <a href="https://github.com/Vertamedia/clickhouse-grafana">Backend verwenden</a> .  Soweit ich wei√ü, kann dies zu Leistungsproblemen beim Rendern einer gro√üen Menge von Datenpunkten f√ºhren, insbesondere bei √§lteren Versionen von Grafana.  Bei Qwintry haben wir dies noch nicht ausprobiert, aber Beschwerden dar√ºber erscheinen von Zeit zu Zeit auf dem ClickHouse-Support-Kanal in Telegram. <br><br><h3>  Ersetzen von Google Big Query und Amazon RedShift (L√∂sung f√ºr gro√üe Unternehmen) </h3><br>  Der ideale Anwendungsfall f√ºr BigQuery ist das Herunterladen von 1 TB JSON-Daten und das Ausf√ºhren von analytischen Abfragen.  Big Query ist ein gro√üartiges Produkt, dessen Skalierbarkeit schwer zu √ºbersch√§tzen ist.  Dies ist eine wesentlich komplexere Software als ClickHouse, die auf einem internen Cluster ausgef√ºhrt wird. Aus Sicht des Clients hat sie jedoch viele Gemeinsamkeiten mit ClickHouse.  BigQuery kann schnell im Preis steigen, sobald Sie f√ºr jedes SELECT bezahlen. Dies ist also eine echte SaaS-L√∂sung mit all ihren Vor- und Nachteilen. <br><br>  ClickHouse ist die beste Wahl, wenn Sie viele rechenintensive Abfragen durchf√ºhren.  Je mehr SELECT-Abfragen Sie t√§glich ausf√ºhren, desto sinnvoller ist es, Big Query durch ClickHouse zu ersetzen, da Sie durch eine solche Ersetzung Tausende von Dollar sparen, wenn es um viele Terabyte verarbeiteter Daten geht.  Dies gilt nicht f√ºr gespeicherte Daten, deren Verarbeitung in Big Query recht kosteng√ºnstig ist. <br><br>  In dem Artikel von Altinity-Mitbegr√ºnder Alexander Zaitsev, <a href="https://www.altinity.com/blog/2017/10/23/migration-to-clickhouse">‚ÄûSwitching to ClickHouse‚Äú</a> , werden die Vorteile einer solchen DBMS-Migration <a href="https://www.altinity.com/blog/2017/10/23/migration-to-clickhouse">erl√§utert</a> . <br><br><h3>  TimescaleDB ersetzen </h3><br>  TimescaleDB ist eine PostgreSQL-Erweiterung, die die Arbeit mit Zeitreihen-Zeitreihen in einer regul√§ren Datenbank optimiert ( <a href="https://docs.timescale.com/v1.0/introduction">https://docs.timescale.com/v1.0/introduction</a> , <a href="https://habr.com/ru/company/zabbix/blog/458530/">https://habr.com/de/company/zabbix/blog/458530) /</a> ). <br><br>  Obwohl ClickHouse kein ernstzunehmender Konkurrent in der Zeitreihennische ist, sondern die Spaltenstruktur und Vektorausf√ºhrung von Abfragen, ist es in den meisten F√§llen bei der Verarbeitung von analytischen Abfragen viel schneller als TimescaleDB.  Gleichzeitig ist die Leistung beim Empfang von ClickHouse-Paketdaten etwa dreimal so hoch. Dar√ºber hinaus wird 20 Mal weniger Speicherplatz ben√∂tigt, was f√ºr die Verarbeitung gro√üer Mengen historischer Daten wirklich wichtig ist: <a href="https://www.altinity.com/blog/ClickHouse-for-time-series">https://www.altinity.com/blog/ClickHouse-for -Zeit-Serie</a> . <br><br>  Im Gegensatz zu ClickHouse k√∂nnen Sie in TimescaleDB nur mit ZFS oder √§hnlichen Dateisystemen Speicherplatz sparen. <br><br>  Bevorstehende ClickHouse-Aktualisierungen f√ºhren wahrscheinlich zu einer Delta-Komprimierung, die die Verarbeitung und Speicherung von Zeitreihendaten noch einfacher macht.  In den folgenden F√§llen ist TimescaleDB m√∂glicherweise die bessere Wahl als ein nacktes ClickHouse: <br><br><ul><li>  kleine Installationen mit sehr wenig RAM (&lt;3 GB); </li><li>  eine gro√üe Anzahl kleiner INSERTs, die nicht in gro√üe Fragmente gepuffert werden sollen; </li><li>  bessere Konsistenz-, Homogenit√§ts- und ACID-Anforderungen; </li><li>  PostGIS-Unterst√ºtzung; </li><li>  Zusammenf√ºhren mit vorhandenen PostgreSQL-Tabellen, da Timescale DB im Wesentlichen PostgreSQL ist. </li></ul><br><h3>  Wettbewerb mit Hadoop und MapReduce Systems </h3><br>  Hadoop und andere MapReduce-Produkte k√∂nnen viele komplexe Berechnungen durchf√ºhren, sind jedoch in der Regel mit gro√üen Verz√∂gerungen verbunden. ClickHouse behebt dieses Problem, indem es Terabytes an Daten verarbeitet und fast sofort Ergebnisse liefert.  Somit ist ClickHouse viel effizienter f√ºr die Durchf√ºhrung schneller, interaktiver Analysen, was f√ºr Datenverarbeitungsspezialisten interessant sein d√ºrfte. <br><br><h3>  Konkurrenz mit Pinot und Druide </h3><br>  Die engsten Konkurrenten von ClickHouse sind Pinot und Druid, ein linear skalierbares Open-Source-Produkt.  Ein hervorragender Vergleich dieser Systeme wurde in einem Artikel von <a href="https://medium.com/%40leventov/comparison-of-the-open-source-olap-systems-for-big-data-ClickHouse-druid-and-pinot-8e042a5ed1c7">Roman Leventov</a> vom 1. Februar 2018 ver√∂ffentlicht. <br><br><img src="https://habrastorage.org/webt/4c/26/hb/4c26hbndeb9gj0mq86lyfrmpc0e.jpeg"><br><br>  Dieser Artikel muss aktualisiert werden. ClickHouse unterst√ºtzt keine UPDATE- und DELETE-Vorg√§nge, was f√ºr die neuesten Versionen nicht vollst√§ndig zutrifft. <br><br>  Wir haben nicht genug Erfahrung mit diesen DBMS, aber ich mag die Komplexit√§t der Infrastruktur, die f√ºr die Ausf√ºhrung von Druid und Pinot verwendet wird, nicht - dies ist eine ganze Reihe von "beweglichen Teilen", die von allen Seiten von Java umgeben sind. <br><br>  Druid und Pinot sind Apache-Inkubatorprojekte, √ºber deren Entwicklungsfortschritt Apache auf den Seiten seiner GitHub-Projekte ausf√ºhrlich berichtet.  Pinot erschien im Oktober 2018 im Inkubator und Druide wurde 8 Monate zuvor geboren - im Februar. <br><br>  Der Mangel an Informationen √ºber die Funktionsweise von AFS wirft einige und vielleicht alberne Fragen auf.  Ich frage mich, ob die Autoren von Pinot bemerkt haben, dass die Apache Foundation Druiden gegen√ºber eher geneigt ist, und hat diese Haltung gegen√ºber dem Konkurrenten Neid ausgel√∂st?  Wird sich die Entwicklung von Druiden verlangsamen und der Pinot beschleunigen, wenn Sponsoren, die die ersteren unterst√ºtzen, pl√∂tzlich Interesse an den letzteren entwickeln? <br><br><h3>  Nachteile von ClickHouse </h3><br>  Unreife: Offensichtlich ist dies noch keine langweilige Technologie, aber in anderen s√§ulenartigen DBMS wird auf jeden Fall nichts √Ñhnliches beobachtet. <br><br>  Kleine Beilagen funktionieren bei hoher Geschwindigkeit nicht gut: Beilagen m√ºssen in gro√üe Teile geteilt werden, da die Leistung kleiner Beilagen proportional zur Anzahl der Spalten in jeder Zeile abnimmt.  Auf diese Weise speichert ClickHouse Daten auf der Festplatte - jede Spalte bedeutet 1 Datei oder mehr. Um eine Zeile mit 100 Spalten einzuf√ºgen, m√ºssen Sie mindestens 100 Dateien √∂ffnen und schreiben.  Aus diesem Grund ist ein Intermedi√§r erforderlich, um Einf√ºgungen zu puffern (es sei denn, der Client stellt selbst die Pufferung bereit). In der Regel handelt es sich hierbei um Kafka oder eine Art Warteschlangenverwaltungssystem.  Sie k√∂nnen auch die Puffertabellen-Engine verwenden, um sp√§ter gro√üe Datenmengen in MergeTree-Tabellen zu kopieren. <br><br>  Tabellenverkn√ºpfungen sind durch den Arbeitsspeicher des Servers begrenzt, aber zumindest sind sie vorhanden!  Zum Beispiel haben Druid und Pinot √ºberhaupt keine derartigen Verbindungen, da sie in verteilten Systemen, die das Verschieben gro√üer Datenmengen zwischen Knoten nicht unterst√ºtzen, nur schwer direkt zu implementieren sind. <br><br><h3>  Schlussfolgerungen </h3><br>  In den kommenden Jahren planen wir, ClickHouse in Qwintry umfassend zu nutzen, da dieses DBMS ein hervorragendes Gleichgewicht zwischen Leistung, geringem Overhead, Skalierbarkeit und Einfachheit bietet.  Ich bin mir ziemlich sicher, dass es sich schnell verbreiten wird, sobald die ClickHouse-Community mehr M√∂glichkeiten f√ºr die Verwendung in kleinen und mittleren Installationen findet. <br><br><h3>  Ein bisschen Werbung :) </h3><br>  Vielen Dank f√ºr Ihren Aufenthalt bei uns.  M√∂gen Sie unsere Artikel?  M√∂chten Sie weitere interessante Materialien sehen?  Unterst√ºtzen Sie uns, indem Sie eine Bestellung <a href="https://habr.com/company/ua-hosting/blog/347386/">aufgeben</a> oder Ihren Freunden <a href="https://ua-hosting.company/cloudvps/nl">Cloud-basiertes VPS f√ºr Entwickler ab 4,99 US-Dollar</a> empfehlen, ein <b>einzigartiges Analogon zu Einstiegsservern, das wir f√ºr Sie erfunden haben:</b> <a href="https://habr.com/company/ua-hosting/blog/347386/">Die ganze Wahrheit √ºber VPS (KVM) E5-2697 v3 (6 Kerne) 10 GB DDR4 480 GB SSD 1 Gbit / s ab 19 Dollar oder wie teilt man den Server?</a>  (Optionen sind mit RAID1 und RAID10, bis zu 24 Kernen und bis zu 40 GB DDR4 verf√ºgbar). <br><br>  <b>Dell R730xd 2-mal billiger im Equinix Tier IV-Rechenzentrum in Amsterdam?</b>  Nur wir haben <b><a href="https://ua-hosting.company/serversnl">2 x Intel TetraDeca-Core Xeon 2 x E5-2697v3 2,6 GHz 14C 64 GB DDR4 4 x 960 GB SSD 1 Gbit / s 100 TV ab 199 US-Dollar</a> in den Niederlanden!</b>  <b><b>Dell R420 - 2x E5-2430 2,2 GHz 6C 128 GB DDR3 2x960 GB SSD 1 Gbit / s 100 TB - ab 99 US-Dollar!</b></b>  Lesen Sie mehr √ºber <a href="https://habr.com/company/ua-hosting/blog/329618/">das Erstellen von Infrastruktur-Bldg.</a>  <a href="https://habr.com/company/ua-hosting/blog/329618/">Klasse mit Dell R730xd E5-2650 v4 Servern f√ºr 9.000 Euro f√ºr einen Cent?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de483112/">https://habr.com/ru/post/de483112/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de483082/index.html">Vulnerability Hunting ist 7% effektiver</a></li>
<li><a href="../de483084/index.html">Kamera mit Tracking-Funktion</a></li>
<li><a href="../de483086/index.html">Ergebnisse von 2019: Welche Verm√∂genswerte erwiesen sich f√ºr russische Investoren als die rentabelsten</a></li>
<li><a href="../de483094/index.html">Wie ich meinen Traum verwirklichte, als ich das russische B√ºro von Microsoft besuchte</a></li>
<li><a href="../de483110/index.html">Rostow am Don: IT-Unternehmen, Communities und Veranstaltungen im Jahr 2019</a></li>
<li><a href="../de483114/index.html">Die modalen Fenster, die wir verdienen</a></li>
<li><a href="../de483116/index.html">Zu Hause ein Teleskoprohr bauen</a></li>
<li><a href="../de483118/index.html">Was wird im Jahr 2020 zu JavaScript hinzugef√ºgt</a></li>
<li><a href="../de483120/index.html">Wie verbinde ich Karten in einer Ellipsoidprojektion, wenn dies nicht vorgesehen ist?</a></li>
<li><a href="../de483124/index.html">Das massivste Gadget in naher Zukunft (kein Smartphone)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
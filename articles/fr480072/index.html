<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üññüèæ üë©üèæ‚Äç‚úàÔ∏è üîö Kubernetes: pourquoi est-il si important de configurer la gestion des ressources syst√®me? üë®‚Äçüåæ ‚ùé üòé</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En r√®gle g√©n√©rale, il est toujours n√©cessaire de fournir un pool de ressources d√©di√© √† toute application pour son fonctionnement correct et stable. Ma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes: pourquoi est-il si important de configurer la gestion des ressources syst√®me?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nixys/blog/480072/"><p>  En r√®gle g√©n√©rale, il est toujours n√©cessaire de fournir un pool de ressources d√©di√© √† toute application pour son fonctionnement correct et stable.  Mais que se passe-t-il si plusieurs applications fonctionnent sur les m√™mes capacit√©s √† la fois?  Comment fournir le minimum de ressources n√©cessaires pour chacun d'eux?  Comment puis-je limiter la consommation de ressources?  Comment r√©partir correctement la charge entre les n≈ìuds?  Comment assurer le m√©canisme de mise √† l'√©chelle horizontale en cas de charge accrue sur l'application? </p><br><p><img src="https://habrastorage.org/webt/-f/yj/hw/-fyjhwhkhcibnshgzndgd4w4e_c.png"></p><a name="habracut"></a><br><p>  Vous devez commencer par quels types de ressources de base existent dans le syst√®me - bien s√ªr, le temps processeur et la RAM.  Dans les manifestes k8s, ces types de ressources sont mesur√©s dans les unit√©s suivantes: </p><br><ul><li>  CPU - dans les c≈ìurs </li><li>  RAM - en octets </li></ul><br><p>  De plus, pour chaque ressource, il est possible de d√©finir deux types d'exigences: les <strong>demandes</strong> et les <strong>limites</strong> .  Demandes - d√©crit les exigences minimales pour les ressources libres du n≈ìud pour ex√©cuter le conteneur (et l'√¢tre dans son ensemble), tandis que limits d√©finit une limite stricte sur les ressources disponibles pour le conteneur. </p><br><p>  Il est important de comprendre que dans le manifeste, il n'est pas n√©cessaire de d√©finir explicitement les deux types, et le comportement sera le suivant: </p><br><ul><li>  Si seules les limites de la ressource sont d√©finies explicitement, les demandes pour cette ressource prennent automatiquement une valeur √©gale aux limites (cela peut √™tre v√©rifi√© en appelant des entit√©s de description).  C'est-√†-dire  en fait, le fonctionnement du conteneur sera limit√© par la m√™me quantit√© de ressources dont il a besoin pour fonctionner. </li><li>  Si seules les demandes sont explicitement d√©finies pour une ressource, aucune restriction n'est d√©finie au-dessus de cette ressource, c'est-√†-dire  le conteneur n'est limit√© que par les ressources du n≈ìud lui-m√™me. </li></ul><br><p>  Il est √©galement possible de configurer la gestion des ressources non seulement au niveau d'un conteneur sp√©cifique, mais √©galement au niveau de l'espace de noms √† l'aide des entit√©s suivantes: </p><br><ul><li>  <strong>LimitRange</strong> - d√©crit la politique de restriction au niveau du conteneur / foyer en ns et est n√©cessaire pour d√©crire les restrictions par d√©faut sur le conteneur / foyer, ainsi que pour emp√™cher la cr√©ation de conteneurs / foyers manifestement gras (ou vice versa), limiter leur nombre et d√©terminer la diff√©rence possible entre les limites et demandes </li><li>  <strong>ResourceQuotas</strong> - d√©crivent la politique de restriction en g√©n√©ral pour tous les conteneurs en ns et est utilis√©, en r√®gle g√©n√©rale, pour diff√©rencier les ressources entre les environnements (utile lorsque les environnements ne sont pas rigoureusement d√©limit√©s au niveau des n≈ìuds) </li></ul><br><p>  Voici des exemples de manifestes dans lesquels des limites de ressources sont d√©finies: </p><br><ul><li><p>  Au niveau du conteneur sp√©cifique: </p><br><pre><code class="plaintext hljs">containers: - name: app-nginx image: nginx resources: requests: memory: 1Gi limits: cpu: 200m</code> </pre> <br><p>  C'est-√†-dire  dans ce cas, pour d√©marrer un conteneur avec nginx, vous aurez besoin d'au moins la pr√©sence d'OP 1G gratuit et de 0,2 CPU sur le n≈ìud, tandis que le conteneur maximum peut consommer 0,2 CPU et tous les OP disponibles sur le n≈ìud. </p><br></li><li><p>  Au niveau entier ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: ResourceQuota metadata: name: nxs-test spec: hard: requests.cpu: 300m requests.memory: 1Gi limits.cpu: 700m limits.memory: 2Gi</code> </pre> <br><p>  C'est-√†-dire  la somme de tous les conteneurs de demande dans les n par d√©faut ne peut pas d√©passer 300 m pour le CPU et 1 G pour l'OP, et la somme de toutes les limites est de 700 m pour le CPU et 2 G pour l'OP. </p><br></li><li><p>  Restrictions par d√©faut pour les conteneurs en ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-per-container spec: limits: - type: Container defaultRequest: cpu: 100m memory: 1Gi default: cpu: 1 memory: 2Gi min: cpu: 50m memory: 500Mi max: cpu: 2 memory: 4Gi</code> </pre> <br><p>  C'est-√†-dire  dans l'espace de noms par d√©faut pour tous les conteneurs, par d√©faut, la demande sera d√©finie √† 100 m pour le CPU et 1G pour l'OP, limite - 1 CPU et 2G.  Dans le m√™me temps, une restriction a √©galement √©t√© √©tablie sur les valeurs possibles dans la demande / limite pour le CPU (50m &lt;x &lt;2) et la RAM (500M &lt;x &lt;4G). </p><br></li><li><p>  Limitations au niveau du foyer ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-pod spec: limits: - type: Pod max: cpu: 4 memory: 1Gi</code> </pre> <br><p>  C'est-√†-dire  pour chaque foyer dans les ns par d√©faut, une limite de 4 vCPU et 1G sera fix√©e. </p><br></li></ul><br><p>  J'aimerais maintenant vous dire quels avantages l'installation de ces restrictions peut nous apporter. </p><br><h2 id="mehanizm-balansirovki-nagruzki-mezhdu-nodami">  Le m√©canisme d'√©quilibrage de charge entre les n≈ìuds </h2><br><p>  Comme vous le savez, le composant k8s tel que l' <strong>ordonnanceur</strong> , qui fonctionne selon un certain algorithme, est responsable de la r√©partition des foyers par noeuds.  Cet algorithme en train de choisir le n≈ìud optimal √† ex√©cuter passe par deux √©tapes: </p><br><ol><li>  Filtrage </li><li>  Classement </li></ol><br><p>  C'est-√†-dire  selon la politique d√©crite, les n≈ìuds sont initialement s√©lectionn√©s sur lesquels un foyer peut √™tre lanc√© en fonction d'un ensemble de <strong>pr√©dicats</strong> (y compris si le n≈ìud a suffisamment de ressources pour faire fonctionner un foyer - PodFitsResources), puis des points sont attribu√©s pour chacun de ces n≈ìuds, selon des <strong>priorit√©s</strong> (y compris, plus le n≈ìud dispose de ressources libres - plus il lui est attribu√© de points - LeastResourceAllocation / LeastRequestedPriority / BalancedResourceAllocation) et est ex√©cut√© sur le n≈ìud avec le plus de points (si plusieurs n≈ìuds remplissent cette condition √† la fois, un al√©atoire est s√©lectionn√©). </p><br><p>  Dans le m√™me temps, vous devez comprendre que le planificateur, lors de l'√©valuation des ressources disponibles du n≈ìud, se concentre sur les donn√©es stock√©es dans etcd - c'est-√†-dire  par la quantit√© de ressource demand√©e / limite de chaque pod s'ex√©cutant sur ce n≈ìud, mais pas par la consommation r√©elle de ressources.  Ces informations peuvent √™tre obtenues dans la sortie de la commande <code>kubectl describe node $NODE</code> , par exemple: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># kubectl describe nodes nxs-k8s-s1 .. Non-terminated Pods: (9 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits AGE --------- ---- ------------ ---------- --------------- ------------- --- ingress-nginx nginx-ingress-controller-754b85bf44-qkt2t 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-flannel-26bl4 150m (0%) 300m (1%) 64M (0%) 500M (1%) 233d kube-system kube-proxy-exporter-cb629 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-proxy-x9fsc 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system nginx-proxy-k8s-worker-s1 25m (0%) 300m (1%) 32M (0%) 512M (1%) 233d nxs-monitoring alertmanager-main-1 100m (0%) 100m (0%) 425Mi (1%) 25Mi (0%) 233d nxs-logging filebeat-lmsmp 100m (0%) 0 (0%) 100Mi (0%) 200Mi (0%) 233d nxs-monitoring node-exporter-v4gdq 112m (0%) 122m (0%) 200Mi (0%) 220Mi (0%) 233d Allocated resources: (Total limits may be over 100 percent, ie, overcommitted.) Resource Requests Limits -------- -------- ------ cpu 487m (3%) 822m (5%) memory 15856217600 (2%) 749976320 (3%) ephemeral-storage 0 (0%) 0 (0%)</span></span></code> </pre> <br><p>  Ici, nous voyons tous les pods s'ex√©cutant sur un n≈ìud particulier, ainsi que les ressources que chacun des pods demande.  Et voici √† quoi ressemblent les journaux du planificateur lors du d√©marrage du pod cronjob-cron-events-1573793820-xt6q9 (ces informations apparaissent dans le journal du planificateur lors de la d√©finition du 10e niveau de journalisation dans les arguments de la commande de d√©marrage --v = 10): </p><br><div class="spoiler">  <b class="spoiler_title">go√©land large</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">I1115 07:57:21.637791 1 scheduling_queue.go:908] About to try and schedule pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.637804 1 scheduler.go:453] Attempting to schedule pod: nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.638285 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s5 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638300 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s6 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s3 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s4 is allowed, Node is running only 17 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638365 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s12 is allowed, Node is running only 9 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s11 is allowed, Node is running only 11 out of 110 Pods. I1115 07:57:21.638385 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s1 is allowed, Node is running only 19 out of 110 Pods. I1115 07:57:21.638402 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s2 is allowed, Node is running only 21 out of 110 Pods. I1115 07:57:21.638383 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638335 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, Node is running only 18 out of 110 Pods. I1115 07:57:21.638408 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s13 is allowed, Node is running only 8 out of 110 Pods. I1115 07:57:21.638478 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638505 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638577 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638583 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s7 is allowed, Node is running only 25 out of 110 Pods. I1115 07:57:21.638932 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 9 I1115 07:57:21.638946 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 8 I1115 07:57:21.638961 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: BalancedResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 9 I1115 07:57:21.638971 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.638975 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: LeastResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 8 I1115 07:57:21.638990 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.639022 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: TaintTolerationPriority, Score: (10) I1115 07:57:21.639030 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: TaintTolerationPriority, Score: (10) I1115 07:57:21.639034 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: TaintTolerationPriority, Score: (10) I1115 07:57:21.639041 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: NodeAffinityPriority, Score: (0) I1115 07:57:21.639053 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: NodeAffinityPriority, Score: (0) I1115 07:57:21.639059 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: NodeAffinityPriority, Score: (0) I1115 07:57:21.639061 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639063 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639073 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639077 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639085 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639088 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639103 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639109 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639114 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639127 1 generic_scheduler.go:781] Host nxs-k8s-s10 =&gt; Score 100037 I1115 07:57:21.639150 1 generic_scheduler.go:781] Host nxs-k8s-s8 =&gt; Score 100034 I1115 07:57:21.639154 1 generic_scheduler.go:781] Host nxs-k8s-s9 =&gt; Score 100037 I1115 07:57:21.639267 1 scheduler_binder.go:269] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10" I1115 07:57:21.639286 1 scheduler_binder.go:279] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10": all PVCs bound and nothing to do I1115 07:57:21.639333 1 factory.go:733] Attempting to bind cronjob-cron-events-1573793820-xt6q9 to nxs-k8s-s10</code> </pre> </div></div><br><p>  On voit ici qu'initialement le planificateur effectue un filtrage et forme une liste de 3 n≈ìuds sur lesquels il est possible de s'ex√©cuter (nxs-k8s-s8, nxs-k8s-s9, nxs-k8s-s10).  Il calcule ensuite des points selon plusieurs param√®tres (dont BalancedResourceAllocation, LeastResourceAllocation) pour chacun de ces n≈ìuds afin de d√©terminer le n≈ìud le plus adapt√©.  En fin de compte, il est pr√©vu sous le n≈ìud avec le plus de points (ici, deux n≈ìuds ont √† la fois le m√™me nombre de points 100037, donc un al√©atoire est s√©lectionn√© - nxs-k8s-s10). </p><br><p>  <strong>Conclusion</strong> : si les pods fonctionnent sur le n≈ìud pour lequel aucune restriction n'est d√©finie, alors pour les k8 (du point de vue de la consommation des ressources), cela sera √©quivalent √† comme si ces pods √©taient compl√®tement absents sur ce n≈ìud.  Par cons√©quent, si vous avez, par convention, un pod avec un processus vorace (par exemple, wowza) et qu'il n'y a pas de restrictions pour cela, alors une situation peut se produire lorsque en fait celui donn√© a mang√© toutes les ressources du n≈ìud, mais en m√™me temps pour k8, ce n≈ìud est consid√©r√© comme d√©charg√© et il se verra attribuer le m√™me nombre de points lors du classement (√† savoir, en points avec une √©valuation des ressources disponibles), ainsi qu'un n≈ìud qui n'a pas de pas de travail, ce qui peut finalement conduire √† une r√©partition in√©gale de la charge entre les n≈ìuds. </p><br><h2 id="vyselenie-poda">  Expulsion du foyer </h2><br><p>  Comme vous le savez, chacun des pods se voit attribuer l'une des 3 classes QoS: </p><br><ol><li>  <strong>guaranuted</strong> - est attribu√© lorsque la demande et la limite sont d√©finies pour chaque conteneur dans l'√¢tre pour la m√©moire et le processeur, et ces valeurs doivent correspondre </li><li>  <strong>√©clatable</strong> - au moins un conteneur dans le foyer a une demande et une limite, tandis que la demande &lt;limite </li><li>  <strong>meilleur effort</strong> - quand aucun r√©cipient dans le foyer est limit√© en ressources </li></ol><br><p>  Dans le m√™me temps, lorsqu'il y a une p√©nurie de ressources (disque, m√©moire) sur le n≈ìud, kubelet commence √† classer et √† expulser les pods selon un certain algorithme qui prend en compte la priorit√© du pod et de sa classe QoS.  Par exemple, si nous parlons de RAM, alors sur la base de la classe QoS, les points sont attribu√©s selon le principe suivant: </p><br><ul><li>  <strong>Garanti</strong> : -998 </li><li>  <strong>BestEffort</strong> : 1000 </li><li>  <strong>Burstable</strong> : min (max (2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) </li></ul><br><p>  C'est-√†-dire  avec la m√™me priorit√©, kubelet expulsera d'abord les pods avec la classe de QoS avec le meilleur effort du n≈ìud. </p><br><p>  <strong>Conclusion</strong> : si vous souhaitez r√©duire la probabilit√© d'expulsion du pod n√©cessaire du n≈ìud en cas de ressources insuffisantes, alors avec la priorit√©, vous devez √©galement prendre soin de d√©finir la demande / limite pour celui-ci. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-podov-prilozheniya-hpa">  M√©canisme de mise √† l'√©chelle horizontale du foyer d'application (HPA) </h2><br><p>  Lorsque la t√¢che consiste √† augmenter et diminuer automatiquement le nombre de pod en fonction de l'utilisation des ressources (syst√®me - CPU / RAM ou utilisateur - rps), une entit√© k8 comme <strong>HPA</strong> (Horizontal Pod Autoscaler) peut aider dans sa solution.  Dont l'algorithme est le suivant: </p><br><ol><li>  Les lectures actuelles de la ressource observ√©e (currentMetricValue) sont d√©termin√©es </li><li>  Les valeurs souhait√©es pour la ressource (desireMetricValue) sont d√©termin√©es, qui sont d√©finies pour les ressources syst√®me √† l'aide de la demande </li><li>  Le nombre actuel de r√©pliques est d√©termin√© (currentReplicas) </li><li>  La formule suivante calcule le nombre souhait√© de r√©pliques (r√©pliques souhait√©es) <br>  desireReplicas = [currentReplicas * (currentMetricValue / desireMetricValue)] </li></ol><br><p>  Cependant, la mise √† l'√©chelle ne se produira pas lorsque le coefficient (currentMetricValue / desireMetricValue) est proche de 1 (nous pouvons d√©finir l'erreur admissible nous-m√™mes, par d√©faut, il est de 0,1). </p><br><p>  Envisagez hpa en utilisant l'application de test d'application (d√©crite comme D√©ploiement), o√π il est n√©cessaire de modifier le nombre de r√©pliques, en fonction de la consommation du processeur: </p><br><ul><li><p>  Manifeste d'application </p><br><pre> <code class="plaintext hljs">kind: Deployment apiVersion: apps/v1beta2 metadata: name: app-test spec: selector: matchLabels: app: app-test replicas: 2 template: metadata: labels: app: app-test spec: containers: - name: nginx image: registry.nixys.ru/generic-images/nginx imagePullPolicy: Always resources: requests: cpu: 60m ports: - name: http containerPort: 80 - name: nginx-exporter image: nginx/nginx-prometheus-exporter resources: requests: cpu: 30m ports: - name: nginx-exporter containerPort: 9113 args: - -nginx.scrape-uri - http://127.0.0.1:80/nginx-status</code> </pre> <br><p>  C'est-√†-dire  nous voyons que sous l'application, elle est initialement lanc√©e dans deux instances, chacune contenant deux conteneurs nginx et nginx-exporter, pour chacun desquels des <strong>requ√™tes</strong> pour le CPU sont donn√©es. </p><br></li><li><p>  Manifeste HPA </p><br><pre> <code class="plaintext hljs">apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: app-test-hpa spec: maxReplicas: 10 minReplicas: 2 scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: app-test metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 30</code> </pre> <br><p>  C'est-√†-dire  nous avons cr√©√© un hpa qui surveillera le test d'application de d√©ploiement et ajustera le nombre de foyers avec l'application en fonction de l'indicateur cpu (nous nous attendons √† ce que le foyer consomme 30% pour cent du CPU demand√© par lui), tandis que le nombre de r√©pliques est compris entre 2 et 10. </p><br><p>  Maintenant, nous consid√©rerons le m√©canisme de fonctionnement hpa si nous appliquons une charge √† l'un des foyers: </p><br><pre> <code class="bash hljs"> <span class="hljs-comment"><span class="hljs-comment"># kubectl top pod NAME CPU(cores) MEMORY(bytes) app-test-78559f8f44-pgs58 101m 243Mi app-test-78559f8f44-cj4jz 4m 240Mi</span></span></code> </pre> <br></li></ul><br><p>  Au total, nous avons les √©l√©ments suivants: </p><br><ul><li>  Valeur souhait√©e (d√©sir√©MetricValue) - selon les param√®tres hpa, nous avons 30% </li><li>  Valeur actuelle (currentMetricValue) - pour le calcul, le contr√¥leur-gestionnaire calcule la valeur moyenne de la consommation de ressources en%, c'est-√†-dire  fait conditionnellement ce qui suit: <br><ol><li>  Obtient les valeurs absolues des mesures de foyer du serveur de mesures, c.-√†-d.  101m et 4m </li><li>  Calcule la valeur absolue moyenne, c'est-√†-dire  (101m + 4m) / 2 = 53m </li><li>  Obtient la valeur absolue de la consommation de ressources souhait√©e (pour cela, la demande de tous les conteneurs est somm√©e) 60m + 30m = 90m </li><li>  Calcule le pourcentage moyen de la consommation du processeur par rapport au foyer de la demande  53 m / 90 m * 100% = 59% </li></ol></li></ul><br><p>  Maintenant, nous avons tout le n√©cessaire pour d√©terminer s'il est n√©cessaire de changer le nombre de r√©pliques, pour cela nous calculons le coefficient: </p><br><p> <code>ratio = 59% / 30% = 1.96</code> </p> <br><p>  C'est-√†-dire  le nombre de r√©pliques doit √™tre augment√© ~ 2 fois et constituer [2 * 1,96] = 4. </p><br><p>  <strong>Conclusion:</strong> Comme vous pouvez le voir, pour que ce m√©canisme fonctionne, une condition pr√©alable est d'inclure la disponibilit√© des demandes pour tous les conteneurs dans l'√¢tre observ√©. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-nod-cluster-autoscaler">  Le m√©canisme de mise √† l'√©chelle automatique horizontale des n≈ìuds (Cluster Autoscaler) </h2><br><p>  Afin de neutraliser l'impact n√©gatif sur le syst√®me lors d'√©clats de charge, la pr√©sence d'un hpa r√©gl√© n'est pas suffisante.  Par exemple, selon les param√®tres du gestionnaire de contr√¥leur hpa d√©cide que le nombre de r√©pliques doit √™tre augment√© de 2 fois, cependant, il n'y a pas de ressources libres sur les n≈ìuds pour ex√©cuter un tel nombre de pods (c'est-√†-dire que le n≈ìud ne peut pas fournir les ressources demand√©es pour les demandes de pod) et ces pods entrer dans l'√©tat En attente. </p><br><p>  Dans ce cas, si le fournisseur dispose des IaaS / PaaS appropri√©s (par exemple, GKE / GCE, AKS, EKS, etc.), un outil tel que <strong>Node Autoscaler</strong> peut nous aider.  Il vous permet de d√©finir le nombre maximal et minimal de n≈ìuds dans le cluster et d'ajuster automatiquement le nombre actuel de n≈ìuds (en acc√©dant √† l'API du fournisseur de cloud pour commander / supprimer des n≈ìuds) lorsqu'il y a une p√©nurie de ressources dans le cluster et que les pods ne peuvent pas √™tre planifi√©s (dans l'√©tat En attente). </p><br><p>  <strong>Conclusion:</strong> pour pouvoir dimensionner automatiquement les n≈ìuds, il est n√©cessaire de sp√©cifier des requ√™tes dans les conteneurs de foyer afin que les k8 puissent √©valuer correctement la charge des n≈ìuds et signaler en cons√©quence qu'il n'y a pas de ressources dans le cluster pour d√©marrer le foyer suivant. </p><br><hr><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  Il convient de noter que la d√©finition de limites de ressources pour le conteneur n'est pas une condition pr√©alable au lancement r√©ussi de l'application, mais il est toujours pr√©f√©rable de le faire pour les raisons suivantes: </p><br><ol><li>  Pour un fonctionnement plus pr√©cis du planificateur en termes d'√©quilibrage de charge entre les n≈ìuds k8s </li><li>  Pour r√©duire la probabilit√© d'un √©v√©nement d'√©viction du foyer </li><li>  Pour les foyers d'application √† mise √† l'√©chelle horizontale (HPA) </li><li>  Pour une mise √† l'√©chelle automatique horizontale des n≈ìuds (mise √† l'√©chelle automatique de cluster) pour les fournisseurs de cloud </li></ol><br><h2 id="takzhe-chitayte-drugie-stati-v-nashem-bloge">  Lisez √©galement d'autres articles sur notre blog: </h2><br><ul><li>  <a href="https://habr.com/ru/company/nixys/blog/481992/">Tekton Pipeline - Pipelines natifs de Kubernetes</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/473578/">Cr√©ation de modules dynamiques pour Nginx</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/468779/">Quel a √©t√© le r√©sultat de la migration de ClickHouse sans autorisation vers ClickHouse avec autorisation</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/461723/">Comprendre le package de contexte dans Golang</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/437372/">Trois astuces simples pour r√©duire les images de docker</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/424717/">Sauvegarde d'un grand nombre de projets Web h√©t√©rog√®nes</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr480072/">https://habr.com/ru/post/fr480072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr480060/index.html">Classificateur P300 simple sur donn√©es ouvertes</a></li>
<li><a href="../fr480062/index.html">10 syst√®mes de contr√¥le. O√π est-il plus pratique de communiquer sur les t√¢ches et de partager des fichiers?</a></li>
<li><a href="../fr480064/index.html">Mots d'apprentissage regroup√©s par th√®me</a></li>
<li><a href="../fr480068/index.html">[Mise √† jour] Nos gens sont battus et nous nous tairons?</a></li>
<li><a href="../fr480070/index.html">Avantages React: une b√©n√©diction pour les entreprises?</a></li>
<li><a href="../fr480076/index.html">Multitraitement et rapprochement des donn√©es de diverses sources</a></li>
<li><a href="../fr480078/index.html">Nouvelles biblioth√®ques frontales sur les p√©riph√©riques React</a></li>
<li><a href="../fr480080/index.html">De quoi avez-vous besoin pour prendre des notes?</a></li>
<li><a href="../fr480082/index.html">Utilisation du partitionnement dans MySQL pour Zabbix avec un grand nombre d'objets de surveillance</a></li>
<li><a href="../fr480086/index.html">Comment se conformer aux exigences de 152-FZ, prot√©ger les donn√©es personnelles de nos clients et ne pas marcher sur notre r√¢teau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
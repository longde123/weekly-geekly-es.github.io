<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö£üèª üë©üèª üë©üèº‚Äçüé® Lehren und Testen neuronaler Netze auf PyTorch mit Ignite üïê üî≥ üí™üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr, in diesem Artikel werde ich √ºber die Ignite- Bibliothek sprechen, mit der Sie neuronale Netze mithilfe des PyTorch-Frameworks einfach trai...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lehren und Testen neuronaler Netze auf PyTorch mit Ignite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/424781/"><p>  <em>Hallo Habr, in diesem Artikel werde ich √ºber die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite-</a> Bibliothek sprechen, mit der Sie neuronale Netze mithilfe des PyTorch-Frameworks einfach trainieren und testen k√∂nnen.</em> </p><br><p> Mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ignite k√∂nnen</a> Sie Zyklen schreiben, um das Netzwerk in nur wenigen Zeilen zu trainieren, Standardmetrikberechnungen aus der Box hinzuzuf√ºgen, das Modell zu speichern usw.  Nun, f√ºr diejenigen, die von TF zu PyTorch gewechselt sind, k√∂nnen wir sagen, dass die Ignite-Bibliothek Keras f√ºr PyTorch ist. </p><br><p>  Der Artikel wird im Detail ein Beispiel f√ºr das Training eines neuronalen Netzwerks f√ºr eine Klassifizierungsaufgabe unter Verwendung von <em>Ignite untersuchen.</em> </p><br><p><img src="https://habrastorage.org/webt/35/ar/af/35arafc8y9aicrbpz5unazs-y-a.png"></p><a name="habracut"></a><br><h2 id="dobavim-esche-bolshe-ognya-v-pytorch">  F√ºge PyTorch mehr Feuer hinzu </h2><br><p>  Ich werde keine Zeit damit verschwenden, dar√ºber zu sprechen, wie <em>cool das</em> PyTorch-Framework ist.  Jeder, der es bereits benutzt hat, versteht, wor√ºber ich schreibe.  Trotz all seiner Vorteile ist es in Bezug auf Schreibzyklen zum Trainieren, Testen und Testen neuronaler Netze immer noch auf einem niedrigen Niveau. </p><br><p>  Wenn wir uns <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offizielle Beispiele f√ºr die</a> Verwendung des PyTorch-Frameworks ansehen, sehen wir mindestens zwei Iterationszyklen nach Epoche und nach Stapeln des im Grid-Trainingscode festgelegten Trainings: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, epochs + <span class="hljs-number"><span class="hljs-number">1</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(train_loader): <span class="hljs-comment"><span class="hljs-comment"># ...</span></span></code> </pre> <br><p>  Die Hauptidee der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite-</a> Bibliothek besteht darin, diese Schleifen in eine einzige Klasse zu zerlegen, w√§hrend der Benutzer mithilfe von Ereignishandlern mit diesen Schleifen interagieren kann. </p><br><p>  Infolgedessen k√∂nnen wir bei Standard-Deep-Learning-Aufgaben viel an der Anzahl der Codezeilen sparen.  Weniger Zeilen - weniger Fehler! </p><br><p>  Zum Vergleich: Auf der linken Seite befindet sich links der Code f√ºr das Training und die Modellvalidierung mit ignite und auf der rechten Seite reines PyTorch: <br><img src="https://habrastorage.org/getpro/habr/post_images/914/408/b07/914408b07fa093c696e66cb15ae36bfc.png" alt="Bild"></p><br><p>  Also nochmal, wof√ºr ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Z√ºnden</a> gut? </p><br><ul><li>  Sie m√ºssen nicht mehr f√ºr jede <code>for epoch in range(n_epochs)</code> und <code>for batch in data_loader</code> . </li><li>  erm√∂glicht es Ihnen, Code besser zu faktorisieren </li><li>  erm√∂glicht es Ihnen, grundlegende Metriken sofort zu berechnen </li><li>  bietet "Br√∂tchen" vom Typ <br><ul><li>  Speichern der neuesten und besten Modelle (auch Optimierer und Planer der Lernrate) w√§hrend des Trainings, </li><li>  fr√ºh aufh√∂ren zu lernen </li><li>  usw </li></ul></li><li>  l√§sst sich leicht in Visualisierungstools integrieren: tensorboardX, visdom, ... </li></ul><br><p>  In gewisser Weise kann die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite-</a> Bibliothek, wie bereits erw√§hnt, mit allen bekannten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Keras</a> und ihrer API zum Trainieren und Testen von Netzwerken verglichen werden.  Au√üerdem ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite-</a> Bibliothek auf den ersten Blick der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tnt-</a> Bibliothek sehr √§hnlich, da beide Bibliotheken anfangs gemeinsame Ziele hatten und √§hnliche Ideen f√ºr ihre Implementierung hatten. </p><br><p>  Also, leuchten: </p><br><pre> <code class="hljs sql">pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> pytorch-ignite</code> </pre> <br><p>  oder </p><br><pre> <code class="hljs swift">conda install ignite -<span class="hljs-built_in"><span class="hljs-built_in">c</span></span> pytorch</code> </pre> <br><p>  Als n√§chstes werden wir uns <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">anhand</a> eines konkreten Beispiels mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">API f√ºr</a> die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite-</a> Bibliothek vertraut machen. </p><br><h2 id="zadacha-klassifikacii-s-ignitehttpspytorchorgignite">  Klassifizierungsaufgabe mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Z√ºndung</a> </h2><br><p>  In diesem Teil des Artikels werden wir ein <em>Schulbeispiel</em> zum Trainieren eines neuronalen Netzwerks f√ºr das Klassifizierungsproblem unter Verwendung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Z√ºndbibliothek betrachten</a> . </p><br><p>  Nehmen wir also einen einfachen Datensatz mit Bildern von Fr√ºchten mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle</a> .  Die Aufgabe besteht darin, jedem Fruchtbild eine entsprechende Klasse zuzuordnen. </p><br><p>  Bevor Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ignite verwenden</a> , definieren wir die Hauptkomponenten: </p><br><p>  Datenstrom </p><br><ul><li>  Trainingsbeispiel Batcher Loader, <code>train_loader</code> </li><li>  Checkout Batch Downloader, <code>val_loader</code> </li></ul><br><p>  Modell: </p><br><ul><li>  Nimm das kleine SqueezeNet-Gitter von <code>torchvision</code> </li></ul><br><p>  Optimierungsalgorithmus: </p><br><ul><li>  nimm sgd </li></ul><br><p>  Verlustfunktion: </p><br><ul><li>  Kreuzentropie </li></ul><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dataset, DataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data.dataset <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Subset <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageFolder <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ColorJitter, ToTensor, Normalize FRUIT360_PATH = Path(<span class="hljs-string"><span class="hljs-string">"."</span></span>).resolve().parent / <span class="hljs-string"><span class="hljs-string">"input"</span></span> / <span class="hljs-string"><span class="hljs-string">"fruits-360_dataset"</span></span> / <span class="hljs-string"><span class="hljs-string">"fruits-360"</span></span> device = <span class="hljs-string"><span class="hljs-string">"cuda"</span></span> train_transform = Compose([ RandomHorizontalFlip(), RandomResizedCrop(size=<span class="hljs-number"><span class="hljs-number">32</span></span>), ColorJitter(brightness=<span class="hljs-number"><span class="hljs-number">0.12</span></span>), ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>]) ]) val_transform = Compose([ RandomResizedCrop(size=<span class="hljs-number"><span class="hljs-number">32</span></span>), ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>]) ]) batch_size = <span class="hljs-number"><span class="hljs-number">128</span></span> num_workers = <span class="hljs-number"><span class="hljs-number">8</span></span> train_dataset = ImageFolder((FRUIT360_PATH /<span class="hljs-string"><span class="hljs-string">"Training"</span></span>).as_posix(), transform=train_transform, target_transform=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) val_dataset = ImageFolder((FRUIT360_PATH /<span class="hljs-string"><span class="hljs-string">"Test"</span></span>).as_posix(), transform=val_transform, target_transform=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.models.squeezenet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> squeezenet1_1 model = squeezenet1_1(pretrained=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">81</span></span>) model.classifier[<span class="hljs-number"><span class="hljs-number">-1</span></span>] = nn.AdaptiveAvgPool2d(<span class="hljs-number"><span class="hljs-number">1</span></span>) model = model.to(device)</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.optim <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGD optimizer = SGD(model.parameters(), lr=<span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) criterion = nn.CrossEntropyLoss()</code> </pre> </div></div><br><p>  Jetzt ist es Zeit zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">z√ºnden</a> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Engine, _prepare_batch <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.train() optimizer.zero_grad() x, y = _prepare_batch(batch, device=device) y_pred = model(x) loss = criterion(y_pred, y) loss.backward() optimizer.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loss.item() trainer = Engine(process_function)</code> </pre> <br><p>  Mal sehen, was dieser Code bedeutet. </p><br><h3 id="dvizhok-engine">  Motor <code>Engine</code> </h3><br><p>  Die Klasse <code>ignite.engine.Engine</code> ist das Bibliotheksframework, und das Objekt dieser Klasse ist <code>trainer</code> : </p><br><pre> <code class="python hljs">trainer = Engine(process_function)</code> </pre> <br><p>  Sie wird mit der Eingabefunktion <code>process_function</code> f√ºr die Verarbeitung einer Charge definiert und dient zur Implementierung von Durchl√§ufen f√ºr das Trainingsmuster.  In der Klasse <code>ignite.engine.Engine</code> geschieht Folgendes: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> epoch &lt; max_epochs: <span class="hljs-comment"><span class="hljs-comment"># run once on data for batch in data: output = process_function(batch)</span></span></code> </pre> <br><p>  Zur√ºck zur Funktion <code>process_function</code> : </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.train() optimizer.zero_grad() x, y = _prepare_batch(batch, device=device) y_pred = model(x) loss = criterion(y_pred, y) loss.backward() optimizer.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loss.item()</code> </pre> <br><p>  Wir sehen, dass wir innerhalb der Funktion, wie im Fall des Modelltrainings √ºblich, die <code>y_pred</code> Vorhersagen berechnen, die Verlustfunktion, den <code>loss</code> und die Gradienten berechnen.  Mit letzterem k√∂nnen Sie das Modellgewicht aktualisieren: <code>optimizer.step()</code> . </p><br><p>  Im Allgemeinen gibt es keine Einschr√§nkungen f√ºr den Code der Funktion <code>process_function</code> .  Wir stellen nur fest, dass zwei Argumente als Eingabe verwendet werden: das <code>Engine</code> Objekt (in unserem Fall <code>trainer</code> ) und der Stapel vom Datenlader.  Um beispielsweise ein neuronales Netzwerk zu testen, k√∂nnen wir ein anderes Objekt der Klasse <code>ignite.engine.Engine</code> definieren, in dem die Eingabefunktion einfach die Vorhersagen berechnet und einen Durchlauf durch das Testmuster einmal implementiert.  Lesen Sie sp√§ter dar√ºber. </p><br><p>  Der obige Code definiert also nur die erforderlichen Objekte, ohne mit dem Training zu beginnen.  Grunds√§tzlich k√∂nnen Sie in einem minimalen Beispiel die Methode aufrufen: </p><br><pre> <code class="python hljs">trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> <br><p>  und dieser Code reicht aus, um das Modell "leise" (ohne Ableitung von Zwischenergebnissen) zu trainieren. </p><br><div class="spoiler">  <b class="spoiler_title">Eine Notiz</b> <div class="spoiler_text"><p>  Beachten Sie auch, dass die Bibliothek f√ºr Aufgaben dieses Typs eine bequeme Methode zum Erstellen des <code>trainer</code> bietet: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_supervised_trainer trainer = create_supervised_trainer(model, optimizer, criterion, device)</code> </pre> </div></div><br><p>  In der Praxis ist das obige Beispiel nat√ºrlich von geringem Interesse. F√ºgen wir daher die folgenden Optionen f√ºr den ‚ÄûTrainer‚Äú hinzu: </p><br><ul><li>  Anzeige des Verlustfunktionswertes alle 50 Iterationen </li><li>  Beginn der Berechnung der Metriken auf dem Trainingssatz mit einem festen Modell </li><li>  Beginn der Berechnung der Metriken an der Testprobe nach jeder √Ñra </li><li>  Speichern von Modellparametern nach jeder √Ñra </li><li>  Erhaltung der drei besten Modelle </li><li>  √Ñnderung der Lerngeschwindigkeit je nach Epoche (Planung der Lernrate) </li><li>  Fr√ºhstopp-Training (Fr√ºhstopp-Training) </li></ul><br><h3 id="sobytiya-i-obrabotchiki-sobytiy">  Ereignisse und Ereignishandler </h3><br><p>  Um die oben genannten Optionen f√ºr den ‚ÄûTrainer‚Äú hinzuzuf√ºgen, bietet die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite-</a> Bibliothek ein Ereignissystem und den Start von benutzerdefinierten Ereignishandlern.  Somit kann der Benutzer in jeder Phase ein Objekt der <code>Engine</code> Klasse steuern: </p><br><ul><li>  Motor gestartet / Start abgeschlossen </li><li>  √Ñra begann / endete </li><li>  Batch-Iteration gestartet / beendet </li></ul><br><p>  und f√ºhren Sie Ihren Code bei jedem Ereignis aus. </p><br><h4 id="vyvod-na-ekran-znacheniya-funkcii-poter">  Zeigt Verlustfunktionswerte an </h4><br><p>  Dazu m√ºssen Sie nur die Funktion bestimmen, in der die Ausgabe auf dem Bildschirm angezeigt wird, und sie dem "Trainer" hinzuf√ºgen: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Events log_interval = <span class="hljs-number"><span class="hljs-number">50</span></span> @trainer.on(Events.ITERATION_COMPLETED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_training_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> iteration = (engine.state.iteration - <span class="hljs-number"><span class="hljs-number">1</span></span>) % len(train_loader) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> iteration % log_interval == <span class="hljs-number"><span class="hljs-number">0</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}"</span></span> .format(engine.state.epoch, iteration, len(train_loader), engine.state.output))</code> </pre> <br><p>  Es gibt zwei M√∂glichkeiten, einen Ereignishandler hinzuzuf√ºgen: √ºber <code>add_event_handler</code> oder √ºber den <code>on</code> decorator.  Das gleiche wie oben kann folgenderma√üen gemacht werden: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Events log_interval = <span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_training_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># ... trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)</span></span></code> </pre> <br><p>  Beachten Sie, dass alle Argumente an die Ereignisbehandlungsfunktion √ºbergeben werden k√∂nnen.  Im Allgemeinen sieht eine solche Funktion folgenderma√üen aus: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_handler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">pass</span></span> trainer.add_event_handler(Events.ITERATION_COMPLETED, custom_handler, *args, **kwargs) <span class="hljs-comment"><span class="hljs-comment">#  @trainer.on(Events.ITERATION_COMPLETED, *args, **kwargs) def custom_handler(engine, *args, **kwargs): pass</span></span></code> </pre> <br><p>  Beginnen wir also mit dem Training in einer √Ñra und sehen, was passiert: </p><br><pre> <code class="python hljs">output = trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[50/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.3459</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[100/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.2801</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[150/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.2294</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[200/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.1467</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[250/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 3<span class="hljs-selector-class"><span class="hljs-selector-class">.8607</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[300/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 3<span class="hljs-selector-class"><span class="hljs-selector-class">.6688</span></span></code> </pre> <br><p>  Nicht schlecht!  Gehen wir weiter. </p><br><h4 id="zapusk-rascheta-metrik-na-obuchayuschey-i-testovoy-vyborkah">  Starten der Berechnung von Metriken f√ºr Trainings- und Testmuster </h4><br><p>  Berechnen wir die folgenden Metriken: durchschnittliche Genauigkeit, durchschnittliche Vollst√§ndigkeit nach jeder √Ñra seitens des Trainings und der gesamten Testprobe.  Beachten Sie, dass wir die Metriken seitens der Trainingsstichprobe nach jeder Trainings√§ra und nicht w√§hrend des Trainings berechnen.  Somit ist die Messung der Effizienz genauer, da sich das Modell w√§hrend der Berechnung nicht √§ndert. </p><br><p>  Also definieren wir die Metriken: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Loss, CategoricalAccuracy, Precision, Recall metrics = { <span class="hljs-string"><span class="hljs-string">'avg_loss'</span></span>: Loss(criterion), <span class="hljs-string"><span class="hljs-string">'avg_accuracy'</span></span>: CategoricalAccuracy(), <span class="hljs-string"><span class="hljs-string">'avg_precision'</span></span>: Precision(average=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), <span class="hljs-string"><span class="hljs-string">'avg_recall'</span></span>: Recall(average=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) }</code> </pre> <br><p>  Als N√§chstes erstellen wir zwei Engines, um das Modell mit <code>ignite.engine.create_supervised_evaluator</code> zu bewerten: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_supervised_evaluator <span class="hljs-comment"><span class="hljs-comment"># ,  device = ‚Äúcuda‚Äù    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device) val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)</span></span></code> </pre> <br><p>  Wir erstellen zwei Engines, um einem von ihnen zus√§tzliche Ereignishandler <code>val_evaluator</code> ( <code>val_evaluator</code> ), um das Modell zu speichern und das Lernen fr√ºhzeitig zu beenden (dazu weiter unten). </p><br><p>  Schauen wir uns auch genauer an, wie die Engine zur Bewertung des Modells definiert ist, n√§mlich wie die Eingabefunktion <code>process_function</code> definiert ist, um eine Charge zu verarbeiten: </p><br><pre> <code class="hljs python"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_supervised_evaluator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, metrics={}, device=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> device: model.to(device) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_inference</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.eval() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): x, y = _prepare_batch(batch, device=device) y_pred = model(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y_pred, y engine = Engine(_inference) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> name, metric <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> metrics.items(): metric.attach(engine, name) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> engine</code> </pre> <br><p>  Wir gehen weiter.  Lassen Sie uns zuf√§llig den Teil der Trainingsstichprobe ausw√§hlen, f√ºr den wir die Metriken berechnen: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data.dataset <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Subset indices = np.arange(len(train_dataset)) random_indices = np.random.permutation(indices)[:len(val_dataset)] train_subset = Subset(train_dataset, indices=random_indices) train_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre> <br><p>  Als n√§chstes legen wir fest, an welchem ‚Äã‚ÄãPunkt des Trainings wir mit der Berechnung der Metriken beginnen und auf dem Bildschirm ausgeben: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@trainer.on(Events.EPOCH_COMPLETED) def compute_and_display_offline_train_metrics(engine): epoch = engine.state.epoch print("Compute train metrics...") metrics = train_evaluator.run(train_eval_loader).metrics print("Training Results - Epoch: {} Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}" .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall'])) @trainer.on(Events.EPOCH_COMPLETED) def compute_and_display_val_metrics(engine): epoch = engine.state.epoch print("Compute validation metrics...") metrics = val_evaluator.run(val_loader).metrics print("Validation Results - Epoch: {} Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}" .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))</span></span></code> </pre><br><p>  Du kannst rennen! </p><br><pre> <code class="python hljs">output = trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p>  Wir kommen auf den Bildschirm </p><br><pre> <code class="hljs powershell">Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">3.5112</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.9840</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.8807</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.9285</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.5026</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.1944</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">2.1018</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.3699</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.3981</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.3686</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">2.0519</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.3850</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.3578</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.3845</span></span></code> </pre><br><p>  Schon besser ! </p><br><p>  <strong>Einige Details</strong> <br>  Schauen wir uns den vorherigen Code etwas an.  Der Leser hat m√∂glicherweise die folgende Codezeile bemerkt: </p><br><pre> <code class="python hljs">metrics = train_evaluator.run(train_eval_loader).metrics</code> </pre> <br><p>  und wahrscheinlich gab es eine Frage zum Objekttyp, der von <code>train_evaluator.run(train_eval_loader)</code> , der das <code>train_evaluator.run(train_eval_loader)</code> hat. </p><br><p>  Tats√§chlich enth√§lt die <code>Engine</code> Klasse eine Struktur namens <code>state</code> (Typ <code>State</code> ), um Daten zwischen Ereignishandlern √ºbertragen zu k√∂nnen.  Dieses Statusattribut enth√§lt grundlegende Informationen zur aktuellen √Ñra, Iteration, Anzahl der Epochen usw.  Es kann auch zum √úbertragen von Benutzerdaten verwendet werden, einschlie√ülich der Ergebnisse der Berechnung von Metriken. </p><br><pre> <code class="python hljs">state = train_evaluator.run(train_eval_loader) metrics = state.metrics <span class="hljs-comment"><span class="hljs-comment">#   train_evaluator.run(train_eval_loader) metrics = train_evaluator.state.metrics</span></span></code> </pre> <br><h5 id="raschet-metrik-vo-vremya-obucheniya">  Berechnung von Metriken w√§hrend des Trainings </h5><br><p>  Wenn die Aufgabe √ºber ein gro√ües Trainingsbeispiel verf√ºgt und die Berechnung von Metriken nach jeder Trainingsepoche teuer ist, Sie jedoch weiterhin m√∂chten, dass sich einige Metriken w√§hrend des Trainings √§ndern, k√∂nnen Sie den folgenden <code>RunningAverage</code> Ereignishandler aus der Box verwenden.  Zum Beispiel m√∂chten wir die Genauigkeit des Klassifikators berechnen und anzeigen: </p><br><pre> <code class="python hljs">acc_metric = RunningAverage(CategoryAccuracy(...), alpha=<span class="hljs-number"><span class="hljs-number">0.98</span></span>) acc_metric.attach(trainer, <span class="hljs-string"><span class="hljs-string">'running_avg_accuracy'</span></span>) @trainer.on(Events.ITERATION_COMPLETED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_running_avg_metrics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"running avg accuracy:"</span></span>, engine.state.metrics[<span class="hljs-string"><span class="hljs-string">'running_avg_accuracy'</span></span>])</code> </pre> <br><p>  Um die <code>RunningAverage</code> Funktionalit√§t nutzen zu k√∂nnen, m√ºssen Sie <code>RunningAverage</code> aus folgenden Quellen installieren: </p><br><pre> <code class="hljs objectivec">pip install git+https:<span class="hljs-comment"><span class="hljs-comment">//github.com/pytorch/ignite</span></span></code> </pre> <br><h4 id="izmenenie-skorosti-obuchenie-learning-rate-scheduling">  Planung der Lernrate </h4><br><p>  Es gibt verschiedene M√∂glichkeiten, die Lerngeschwindigkeit mithilfe von <em>Ignite</em> zu √§ndern.  Betrachten Sie als N√§chstes die einfachste Methode, indem <code>lr_scheduler.step()</code> zu Beginn jeder √Ñra die Funktion <code>lr_scheduler.step()</code> aufrufen. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.optim.lr_scheduler <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ExponentialLR lr_scheduler = ExponentialLR(optimizer, gamma=<span class="hljs-number"><span class="hljs-number">0.8</span></span>) @trainer.on(Events.EPOCH_STARTED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">update_lr_scheduler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> lr_scheduler.step() <span class="hljs-comment"><span class="hljs-comment">#    : if len(optimizer.param_groups) == 1: lr = float(optimizer.param_groups[0]['lr']) print("Learning rate: {}".format(lr)) else: for i, param_group in enumerate(optimizer.param_groups): lr = float(param_group['lr']) print("Learning rate (group {}): {}".format(i, lr))</span></span></code> </pre> <br><h4 id="sohranenie-luchshih-modeley-i-drugih-parametrov-vo-vremya-obucheniya">  Speichern der besten Modelle und anderer Parameter w√§hrend des Trainings </h4><br><p>  W√§hrend des Trainings w√§re es gro√üartig, die Gewichte des besten Modells auf der Disc aufzuzeichnen und die Modellgewichte, Optimierungsparameter und Parameter zum √Ñndern der Lerngeschwindigkeit regelm√§√üig zu speichern.  Letzteres kann n√ºtzlich sein, um das Lernen aus dem zuletzt gespeicherten Zustand fortzusetzen. </p><br><p>  <em>Ignite</em> hat hierf√ºr eine spezielle <code>ModelCheckpoint</code> Klasse.  Erstellen <code>ModelCheckpoint</code> einen <code>ModelCheckpoint</code> Ereignishandler und speichern das beste Modell hinsichtlich der Genauigkeit im <code>ModelCheckpoint</code> .  In diesem Fall definieren wir eine <code>score_function</code> Funktion, die dem Ereignishandler den Genauigkeitswert gibt und entscheidet, ob das Modell <code>score_function</code> oder nicht: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.handlers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> val_avg_accuracy = engine.state.metrics[<span class="hljs-string"><span class="hljs-string">'avg_accuracy'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> val_avg_accuracy best_model_saver = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"best_models"</span></span>, filename_prefix=<span class="hljs-string"><span class="hljs-string">"model"</span></span>, score_name=<span class="hljs-string"><span class="hljs-string">"val_accuracy"</span></span>, score_function=score_function, n_saved=<span class="hljs-number"><span class="hljs-number">3</span></span>, save_as_state_dict=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, create_dir=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment"># "best_models" -    1     #   -&gt; {filename_prefix}_{name}_{step_number}_{score_name}={abs(score_function_result)}.pth # save_as_state_dict=True, #   `state_dict` val_evaluator.add_event_handler(Events.COMPLETED, best_model_saver, {"best_model": model})</span></span></code> </pre> <br><p>  Erstellen <code>ModelCheckpoint</code> nun einen weiteren <code>ModelCheckpoint</code> Ereignishandler, um den Lernstatus alle 1000 Iterationen beizubehalten: </p><br><pre> <code class="python hljs">training_saver = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"checkpoint"</span></span>, filename_prefix=<span class="hljs-string"><span class="hljs-string">"checkpoint"</span></span>, save_interval=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_saved=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_as_state_dict=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, create_dir=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) to_save = {<span class="hljs-string"><span class="hljs-string">"model"</span></span>: model, <span class="hljs-string"><span class="hljs-string">"optimizer"</span></span>: optimizer, <span class="hljs-string"><span class="hljs-string">"lr_scheduler"</span></span>: lr_scheduler} trainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)</code> </pre> <br><p>  Also, fast alles ist fertig, f√ºgen Sie das letzte Element hinzu: </p><br><h4 id="rannyaya-ostanovka-obucheniya-early-stopping">  Fr√ºhstopp-Training (Fr√ºhstopp) </h4><br><p>  F√ºgen wir einen weiteren Event-Handler hinzu, der das Lernen beendet, wenn sich die Modellqualit√§t √ºber 10 Epochen nicht verbessert.  Wir werden die Qualit√§t des Modells erneut mit der <code>score_function</code> score_function bewerten. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.handlers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EarlyStopping early_stopping = EarlyStopping(patience=<span class="hljs-number"><span class="hljs-number">10</span></span>, score_function=score_function, trainer=trainer) val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)</code> </pre> <br><h3 id="zapusk-obucheniya">  Beginnen Sie mit dem Training </h3><br><p>  Um mit dem Training zu beginnen, reicht es aus, die <code>run()</code> -Methode aufzurufen.  Wir werden das Modell f√ºr 10 Epochen trainieren: </p><br><pre> <code class="python hljs">max_epochs = <span class="hljs-number"><span class="hljs-number">10</span></span> output = trainer.run(train_loader, max_epochs=max_epochs)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Bildschirmausgabe</b> <div class="spoiler_text"><pre> <code class="hljs powershell">Learning rate: <span class="hljs-number"><span class="hljs-number">0.01</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.7984</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.9736</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">4.3419</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.0261</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.1724</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.1599</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">1.5363</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.5177</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.5477</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.5178</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">1.5116</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.5139</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.5400</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.5140</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.008</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.4076</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.4892</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.2485</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.6511</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">3.3376</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.3299</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">2</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">3.2686</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.1977</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.1792</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.1942</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">2</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">3.2772</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.1962</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.1628</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.1918</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.006400000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.9016</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.2006</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8892</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8141</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.4005</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8888</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">3</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.7368</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7554</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.7818</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7554</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">3</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.7177</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7623</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.7863</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7611</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.005120000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8490</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8493</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8100</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.9165</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.9370</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6548</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">4</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.7047</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7713</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8040</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7728</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">4</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.6737</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7778</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.7955</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7806</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.004096000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6965</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6196</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6194</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3986</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6032</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.7152</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">5</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.5049</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8282</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8393</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8314</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">5</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.5084</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8304</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8386</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8328</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.0032768000000000007</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4433</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4764</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5578</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3684</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4847</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3811</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">6</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4383</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8474</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8618</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8495</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">6</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4419</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8446</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8532</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8442</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.002621440000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4447</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4602</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5345</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3973</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5023</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5303</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">7</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4305</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8579</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8691</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8596</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">7</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4262</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8590</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8685</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8606</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.002097152000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4867</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3090</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3721</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4559</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3958</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4222</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">8</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3432</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8818</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8895</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8817</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">8</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3644</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8713</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8784</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8707</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.001677721600000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3557</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3692</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3510</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3446</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3966</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3451</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">9</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3315</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8954</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.9001</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8982</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">9</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3559</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8818</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8876</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8847</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.0013421772800000006</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3340</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3370</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3694</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3409</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4420</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.2770</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">10</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3246</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8921</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8988</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8925</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">10</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3536</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8731</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8785</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8722</span></span></code> </pre> </div></div><br><p>  √úberpr√ºfen Sie nun die auf der Festplatte gespeicherten Modelle und Parameter: </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">ls</span></span> best_models/ model_best_model_10_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8730994</span></span>.pth model_best_model_8_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8712978</span></span>.pth model_best_model_9_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8818188</span></span>.pth</code> </pre> <br><p>  und </p><br><pre> <code class="hljs pgsql">ls <span class="hljs-keyword"><span class="hljs-keyword">checkpoint</span></span>/ checkpoint_lr_scheduler_3000.pth checkpoint_optimizer_3000.pth checkpoint_model_3000.pth</code> </pre> <br><h3 id="predskazaniya-obuchennoy-modelyu">  Vorhersagen eines trainierten Modells </h3><br><p>  Erstellen Sie zun√§chst einen Testdatenlader (z. B. ein Validierungsbeispiel), sodass der Datenstapel aus Bildern und ihren Indizes besteht: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Dataset)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, ds)</span></span></span><span class="hljs-function">:</span></span> self.ds = ds <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__len__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(self.ds) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__getitem__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, index)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.ds[index][<span class="hljs-number"><span class="hljs-number">0</span></span>], index test_dataset = TestDataset(val_dataset) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre> <br><p>  Mit <em>ignite</em> erstellen wir eine neue Vorhersage-Engine f√ºr Testdaten.  Dazu definieren wir die Funktion <code>inference_update</code> , die das Ergebnis der Vorhersage und den Index des Bildes zur√ºckgibt.  Um die Genauigkeit zu erh√∂hen, verwenden wir auch den bekannten Trick ‚ÄûTest Time Augmentation‚Äú (TTA). </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn.functional <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> F <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite._utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> convert_tensor <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_prepare_batch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(batch)</span></span></span><span class="hljs-function">:</span></span> x, index = batch x = convert_tensor(x, device=device) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x, index <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">inference_update</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> x, indices = _prepare_batch(batch) y_pred = model(x) y_pred = F.softmax(y_pred, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">"y_pred"</span></span>: convert_tensor(y_pred, device=<span class="hljs-string"><span class="hljs-string">'cpu'</span></span>), <span class="hljs-string"><span class="hljs-string">"indices"</span></span>: indices} model.eval() inferencer = Engine(inference_update)</code> </pre> <br><p>  Erstellen Sie als N√§chstes Ereignishandler, die √ºber den Stand der Vorhersagen informieren und die Vorhersagen in einem dedizierten Array speichern: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inferencer.on(Events.EPOCH_COMPLETED) def log_tta(engine): print("TTA {} / {}".format(engine.state.epoch, n_tta)) n_tta = 3 num_classes = 81 n_samples = len(val_dataset) #     y_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32) @inferencer.on(Events.ITERATION_COMPLETED) def save_results(engine): output = engine.state.output tta_index = engine.state.epoch - 1 start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size end_index = min(start_index + batch_size, n_samples) batch_y_probas = output['y_pred'].detach().numpy() y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas</span></span></code> </pre> <br><p>  Laden Sie vor dem Start das beste Modell herunter: </p><br><pre> <code class="python hljs">model = squeezenet1_1(pretrained=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">64</span></span>) model.classifier[<span class="hljs-number"><span class="hljs-number">-1</span></span>] = nn.AdaptiveAvgPool2d(<span class="hljs-number"><span class="hljs-number">1</span></span>) model = model.to(device) model_state_dict = torch.load(<span class="hljs-string"><span class="hljs-string">"best_models/model_best_model_10_val_accuracy=0.8730994.pth"</span></span>) model.load_state_dict(model_state_dict)</code> </pre> <br><p>  Wir starten: </p><br><pre> <code class="python hljs">inferencer.run(test_loader, max_epochs=n_tta) &gt; TTA <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; TTA <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; TTA <span class="hljs-number"><span class="hljs-number">3</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><p>  Als n√§chstes nehmen wir standardm√§√üig den Durchschnitt der TTA-Vorhersagen und berechnen den Klassenindex mit der h√∂chsten Wahrscheinlichkeit: </p><br><pre> <code class="python hljs">y_probas = np.mean(y_probas_tta, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>) y_preds = np.argmax(y_probas, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)</code> </pre> <br><p>  Und jetzt k√∂nnen wir die Genauigkeit des Modells noch einmal anhand der Vorhersagen berechnen: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score y_test_true = [y <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _, y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> val_dataset] accuracy_score(y_test_true, y_preds) &gt; <span class="hljs-number"><span class="hljs-number">0.9310369676443035</span></span></code> </pre> <br><p> ,     ,          .   ,   ,      ,    <em>ignite</em>      . </p><br><h2 id="drugie-primery-s-ignitehttpspytorchorgignite">    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ignite</a> </h2><br><p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . </p><br><p>  github      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>       </p><br><ul><li> fast neural transfer </li><li> reinforcement learning </li><li> dcgan </li></ul><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>    ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ignite</a>      Facebook           (.   ).        0.1.0,   API (Engine, State, Events, Metric, ...)           .       ,      ,     ,     pull request-  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> github</a> . </p><br><p>  Vielen Dank f√ºr Ihre Aufmerksamkeit! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424781/">https://habr.com/ru/post/de424781/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424767/index.html">Wir machen einen Kuchen aus Habr. Wieder</a></li>
<li><a href="../de424771/index.html">Pers√∂nliche Erfahrung: von einer Idee und einem leeren Blatt bis zu einer Entwurfsversion einer Website</a></li>
<li><a href="../de424773/index.html">Biopharma und numerische Modellierung: Amgen Erfahrung und Praxis</a></li>
<li><a href="../de424777/index.html">Verwenden von Consul zum Skalieren von Stateful Services</a></li>
<li><a href="../de424779/index.html">Mehrseitiges SPA in Python</a></li>
<li><a href="../de424787/index.html">Interview mit Aaron Patterson, Sprecher der RubyRussia-Konferenz 2018</a></li>
<li><a href="../de424789/index.html">So stellen Sie eine Ruby on Rails-Anwendung mit HAProxy Ingress, Unicorn / Puma und Web-Sockets bereit</a></li>
<li><a href="../de424791/index.html">Erweitern der Netzwerkfunktionen eines programmierbaren Relais mithilfe von WI-FI</a></li>
<li><a href="../de424793/index.html">So drucken Sie einen Elektromotor</a></li>
<li><a href="../de424795/index.html">Wie gro√ü kann eine solarbetriebene Drohne sein?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
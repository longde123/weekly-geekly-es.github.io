<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧕🏿 👒 👨🏿‍🚒 两个Yakozun之战，或Cassandra与HBase。 Sberbank团队经验 🥠 🌷 ✍🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="这甚至不是在开玩笑，似乎这张特定的图片最准确地反映了这些数据库的本质，最后将清楚为什么： 



 根据DB-Engines排名，两个最受欢迎的NoSQL列基础是Cassandra（以下简称CS）和HBase（HB）。 



 依照命运的意愿，我们位于Sberbank的数据加载管理团队与HB 长期...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>两个Yakozun之战，或Cassandra与HBase。 Sberbank团队经验</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/484096/"> 这甚至不是在开玩笑，似乎这张特定的图片最准确地反映了这些数据库的本质，最后将清楚为什么： <br><br><img src="https://habrastorage.org/webt/i2/lk/zo/i2lkzo9tq7zpeprcbtgm3-mufk4.png"><br><br> 根据DB-Engines排名，两个最受欢迎的NoSQL列基础是Cassandra（以下简称CS）和HBase（HB）。 <br><br><img src="https://habrastorage.org/webt/su/rd/39/surd39n7bmrbnxgpn0512tnxamm.png"><br><br> 依照命运的意愿，我们位于Sberbank的数据加载管理团队与HB <a href="https://habr.com/ru/company/sberbank/blog/420425/">长期</a>合作密切。 在这段时间里，我们很好地研究了它的优缺点，并学会了如何烹饪。 但是，一直以来，以CS形式出现的替代方案使我感到疑惑：我们是否做出了正确的选择？ 此外，DataStax进行的<a href="https://www.datastax.com/products/compare/nosql-performance-benchmarks">比较</a>结果表明，CS几乎可以击碎得分，轻松击败HB。 另一方面，DataStax是一个有兴趣的人，您不要在这里说什么。 而且，关于测试条件的相当少的信息令人尴尬，因此我们决定独立找出谁是BigData NoSql的王者，结果非常有趣。 <br><a name="habracut"></a><br> 但是，在继续进行测试的结果之前，有必要描述环境配置的基本方面。 事实是CS可以在数据丢失容忍模式下使用。 即 这是当只有一个服务器（节点）负责某个键的数据时，如果由于某种原因它掉线了，则该键的值将丢失。 对于许多任务而言，这并不重要，但对于银行业而言，这是例外而不是规则。 在我们的案例中，重要的是要拥有多个数据副本以进行可靠的存储。 <br><br> 因此，仅考虑三重复制的CS模式，即。 用以下参数创建案例： <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> KEYSPACE ks <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> <span class="hljs-keyword"><span class="hljs-keyword">REPLICATION</span></span> = {<span class="hljs-string"><span class="hljs-string">'class'</span></span> : <span class="hljs-string"><span class="hljs-string">'NetworkTopologyStrategy'</span></span>, <span class="hljs-string"><span class="hljs-string">'datacenter1'</span></span> : <span class="hljs-number"><span class="hljs-number">3</span></span>};</code> </pre> <br> 此外，有两种方法可以确保所需的一致性。 一般规则： <br>  NW + NR&gt;射频 <br><br> 这意味着写入时来自节点的确认数（NW）加上读取时来自节点的确认数（NR）必须大于复制因子。 在我们的情况下，RF = 3，因此以下选项适用： <br>  2 + 2&gt; 3 <br>  3 +1&gt; 3 <br><br> 由于对我们而言，保持数据尽可能可靠至关重要，因此选择了3 + 1方案。 此外，HB在类似的基础上工作，即 这样的比较会更诚实。 <br><br> 应当指出，DataStax在他们的研究中做的是相反的，他们为CS和HB都设置了RF = 1（对于后者，通过更改HDFS设置）。 这是一个非常重要的方面，因为在这种情况下，对CS性能的影响很大。 例如，下图显示了将数据加载到CS中所需的时间增加： <br><br><img src="https://habrastorage.org/webt/fw/az/r9/fwazr9muypegpgjpyaq4rnagg8u.png"><br><br> 在这里，我们看到以下内容，竞争越多的线程写入数据，花费的时间越长。 这是自然的，但重要的是RF = 3的性能下降要高得多。 换句话说，如果我们在5个流中的每个流中写入4个表（总计20个），则RF = 3损失大约2倍（150秒RF = 3，而RF = 1则为75）。 但是，如果我们通过将数据加载到5个流中的每个流中的8个表中来增加负载（总计40个），那么丢失RF = 3已经是2.7倍（375秒对138秒）。 <br><br> 这也许部分是成功进行CS负载测试的DataStax测试的秘密，因为对于我们公司的HB而言，将复制因子从2更改为3无效。 即 对于我们的配置，光盘不是HB的瓶颈。 但是，还有许多其他陷阱，因为应该注意，我们的HB版本​​略有打补丁和模糊不清，环境完全不同，等等。 还要指出的是，也许我只是不知道如何正确准备CS，并且有一些更有效的处理方式，希望我能在评论中找到答案。 但是首先是第一件事。 <br><br> 所有测试都是在由4个服务器组成的铁群集上执行的，每个服务器都具有以下配置： <br><br>  <i>CPU：Xeon E5-2680 v4 @ 2.40GHz 64线程</i> <i><br></i>  <i>磁盘：12个SATA HDD</i> <i><br></i>  <i>Java版本：1.8.0_111</i> <i><br></i> <br><br>  CS版本：3.11.5 <br><br><div class="spoiler">  <b class="spoiler_title">参数cassandra.yml</b> <div class="spoiler_text">  num_tokens：256 <br>  hinted_handoff_enabled：是 <br>  hinted_handoff_throttle_in_kb：1024 <br>  max_hints_delivery_threads：2 <br>  hints_directory：/ data10 / cassandra /提示 <br>  hints_flush_period_in_ms：10000 <br>  max_hints_file_size_in_mb：128 <br>  batchlog_replay_throttle_in_kb：1024 <br> 身份验证器：AllowAllAuthenticator <br> 授权者：AllowAllAuthorizer <br> 角色管理器：CassandraRoleManager <br>  role_validity_in_ms：2000 <br>  Permissions_validity_in_ms：2000 <br>  certificate_validity_in_ms：2000 <br> 分区程序：org.apache.cassandra.dht.Murmur3Partitioner <br>  data_file_directories： <br>  -/ data1 / cassandra / data＃每个dataN目录是一个单独的驱动器 <br>  -/ data2 / cassandra /数据 <br>  -/ data3 / cassandra /数据 <br>  -/ data4 /卡桑德拉/数据 <br>  -/ data5 / cassandra /数据 <br>  -/ data6 / cassandra /数据 <br>  -/ data7 /卡桑德拉/数据 <br>  -/ data8 / cassandra /数据 <br>  commitlog_directory：/ data9 / cassandra / commitlog <br>  cdc_enabled：否 <br>  disk_failure_policy：停止 <br>  commit_failure_policy：停止 <br>  prepare_statements_cache_size_mb： <br>  thrift_prepared_statements_cache_size_mb： <br>  key_cache_size_in_mb： <br>  key_cache_save_period：14400 <br>  row_cache_size_in_mb：0 <br>  row_cache_save_period：0 <br>  counter_cache_size_in_mb： <br>  counter_cache_save_period：7200 <br>  saved_caches_directory：/ data10 / cassandra / saved_caches <br>  commitlog_sync：定期 <br>  commitlog_sync_period_in_ms：10000 <br>  commitlog_segment_size_in_mb：32 <br>  seed_provider： <br>  -类别名称：org.apache.cassandra.locator.SimpleSeedProvider <br> 参数： <br>  -种子：“ *，*” <br>  parallel_reads：256＃已尝试64-未发现差异 <br>  parallel_writes：256＃已尝试64-未发现差异 <br>  parallel_counter_writes：256＃已尝试64-未发现差异 <br>  parallel_materialized_view_writes：32 <br>  memtable_heap_space_in_mb：2048＃尝试了16 GB-速度较慢 <br>  memtable_allocation_type：heap_buffers <br>  index_summary_capacity_in_mb： <br>  index_summary_resize_interval_in_minutes：60 <br>  tickle_fsync：否 <br>  rickle_fsync_interval_in_kb：10240 <br>  storage_port：7000 <br>  ssl_storage_port：7001 <br>  listen_address：* <br>  broadcast_address：* <br>  listen_on_broadcast_address：为true <br>  internode_authenticator：org.apache.cassandra.auth.AllowAllInternodeAuthenticator <br>  start_native_transport：正确 <br>  native_transport_port：9042 <br>  start_rpc：是 <br>  rpc_address：* <br>  rpc_port：9160 <br>  rpc_keepalive：正确 <br>  rpc_server_type：同步 <br>  thrift_framed_transport_size_in_mb：15 <br> 增量备份：false <br>  snapshot_before_compaction：否 <br>  auto_snapshot：为true <br>  column_index_size_in_kb：64 <br>  column_index_cache_size_in_kb：2 <br>  parallel_compactors：4个 <br>  compaction_throughput_mb_per_sec：1600 <br>  sstable_preemptive_open_interval_in_mb：50 <br>  read_request_timeout_in_ms：100000 <br>  range_request_timeout_in_ms：200000 <br>  write_request_timeout_in_ms：40000 <br>  counter_write_request_timeout_in_ms：100000 <br>  cas_contention_timeout_in_ms：20000 <br>  truncate_request_timeout_in_ms：60000 <br>  request_timeout_in_ms：200000 <br>  slow_query_log_timeout_in_ms：500 <br>  cross_node_timeout：否 <br>  endpoint_snitch：GossipingPropertyFileSnitch <br>  dynamic_snitch_update_interval_in_ms：100 <br>  dynamic_snitch_reset_interval_in_ms：600000 <br>  dynamic_snitch_badness_threshold：0.1 <br>  request_scheduler：org.apache.cassandra.scheduler.NoScheduler <br>  server_encryption_options： <br>  internode_encryption：无 <br>  client_encryption_options： <br> 启用：false <br>  internode_compression：直流 <br>  inter_dc_tcp_nodelay：假 <br>  tracetype_query_ttl：86400 <br>  tracetype_repair_ttl：604800 <br>  enable_user_defined_functions：否 <br>  enable_scripted_user_defined_functions：否 <br>  windows_timer_interval：1 <br>  transparent_data_encryption_options： <br> 启用：false <br>  tombstone_warn_threshold：1000 <br>  tombstone_failure_threshold：100000 <br>  batch_size_warn_threshold_in_kb：200 <br>  batch_size_fail_threshold_in_kb：250 <br>  unlogged_batch_across_partitions_warn_threshold：10 <br>  compaction_large_partition_warning_threshold_mb：100 <br>  gc_warn_threshold_in_ms：1000 <br>  back_pressure_enabled：否 <br>  enable_materialized_views：true <br>  enable_sasi_indexes：是 <br></div></div><br>  GC设置： <br><br><div class="spoiler">  <b class="spoiler_title">### CMS设置</b> <div class="spoiler_text">  -XX：+ UseParNewGC <br>  -XX：+ UseConcMarkSweepGC <br>  -XX：+ CMSParallelRemarkEnabled <br>  -XX：SurvivorRatio = 8 <br>  -XX：MaxTenuringThreshold = 1 <br>  -XX：CMSInitiatingOccupancyFraction = 75 <br>  -XX：+仅使用CMSInitiatingOccupancy <br>  -XX：CMSWaitDuration = 10000 <br>  -XX：+ CMSParallelInitialMarkEnabled <br>  -XX：+ CMSEdenChunksRecordAlways <br>  -XX：+ CMSClassUnloadingEnabled <br><br></div></div><br> 内存jvm.options分配了16 Gb（仍尝试32 Gb，未发现差异）。 <br><br> 创建表是通过以下命令执行的： <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> ks.t1 (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span> <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, title <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> compression = {<span class="hljs-string"><span class="hljs-string">'sstable_compression'</span></span>: <span class="hljs-string"><span class="hljs-string">'LZ4Compressor'</span></span>, <span class="hljs-string"><span class="hljs-string">'chunk_length_kb'</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>};</code> </pre> <br>  HB版本：1.2.0-cdh5.14.2（在org.apache.hadoop.hbase.regionserver.HRegion类中，我们排除了MetricsRegion，它导致RegionServer上具有1000多个区域的GC） <br><br><div class="spoiler">  <b class="spoiler_title">非默认HBase选项</b> <div class="spoiler_text">  zookeeper.session.timeout：120000 <br>  hbase.rpc.timeout：2分钟（秒） <br>  hbase.client.scanner.timeout.period：2分钟（秒） <br>  hbase.master.handler.count：10 <br>  hbase.regionserver.lease.period，hbase.client.scanner.timeout.period：2分钟 <br>  hbase.regionserver.handler.count：160 <br>  hbase.regionserver.metahandler.count：30 <br>  hbase.regionserver.logroll.period：4小时 <br>  hbase.regionserver.maxlogs：200 <br>  hbase.hregion.memstore.flush.size：1 GiB <br>  hbase.hregion.memstore.block.multiplier：6 <br>  hbase.hstore.compactionThreshold：5 <br>  hbase.hstore.blockingStoreFiles：200 <br>  hbase.hregion.majorcompaction：1天（s） <br> 用于hbase-site.xml的HBase服务高级配置代码段（安全阀）： <br>  hbase.regionserver.wal.codecorg.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec <br>  hbase.master.namespace.init.timeout3600000 <br>  hbase.regionserver.optionalcacheflushinterval18000000 <br>  hbase.regionserver.thread.compaction.large12 <br>  hbase.regionserver.wal.enablecompressiontrue <br>  hbase.hstore.compaction.max.size1073741824 <br>  hbase.server.compactchecker.interval.multiplier200 <br>  HBase RegionServer的Java配置选项： <br>  -XX：+ UseParNewGC -XX：+ UseConcMarkSweepGC -XX：CMSInitiatingOccupancyFraction = 70 -XX：+ CMSParallelRemarkEnabled -XX：ReservedCodeCacheSize = 256m <br>  hbase.snapshot.master.timeoutMillis：2分钟（秒） <br>  hbase.snapshot.region.timeout：2分钟（秒） <br>  hbase.snapshot.master.timeout.millis：2分钟（秒） <br>  HBase REST Server最大日志大小：100 MiB <br>  HBase REST Server最大日志文件备份：5 <br>  HBase Thrift Server最大日志大小：100 MiB <br>  HBase Thrift Server的最大日志文件备份数：5 <br> 主最大日志大小：100 MiB <br> 主最大日志文件备份：5 <br>  RegionServer最大日志大小：100 MiB <br>  RegionServer日志文件最大备份数：5 <br>  HBase Active Master检测窗口：4分钟 <br>  dfs.client.hedged.read.threadpool.size：40 <br>  dfs.client.hedged.read.threshold.millis：10毫秒 <br>  hbase.rest.threads.min：8 <br>  hbase.rest.threads.max：150 <br> 最大进程文件描述符：180,000 <br>  hbase.thrift.minWorkerThreads：200 <br>  hbase.master.executor.openregion.threads：30 <br>  hbase.master.executor.closeregion.threads：30 <br>  hbase.master.executor.serverops.threads：60 <br>  hbase.regionserver.thread.compaction.small：6 <br>  hbase.ipc.server.read.threadpool.size：20 <br> 区域移动线程：6 <br> 客户端Java堆大小（以字节为单位）：1 GiB <br>  HBase REST Server默认组：3 GiB <br>  HBase Thrift Server默认组：3 GiB <br>  HBase主站的Java堆大小（以字节为单位）：16 GiB <br>  HBase RegionServer的Java堆大小（以字节为单位）：32 GiB <br><br>  + ZooKeeper <br>  maxClientCnxns：601 <br>  maxSessionTimeout：120000 </div></div><br> 创建表： <br>  <i>hbase org.apache.hadoop.hbase.util.RegionSplitter ns：t1 UniformSplit -c 64 -f cf</i> <i><br></i>  <i>alter'ns：t1'，{NAME =&gt;'cf'，DATA_BLOCK_ENCODING =&gt;'FAST_DIFF'，COMPRESSION =&gt;'GZ'}</i> <br><br> 有一点很重要-DataStax描述没有说明创建HB表使用了多少个区域，尽管这对于大容量至关重要。 因此，对于测试，选择了数字= 64，这可以存储多达640 GB的数据，即 中型桌子。 <br><br> 在测试时，HBase有22,000个表和67,000个区域（如果没有上述补丁，这对于1.2.0版将是致命的）。 <br><br> 现在获取代码。 由于尚不清楚哪种配置对特定数据库更有利，因此以各种组合方式进行了测试。 即 在某些测试中，负载同时传递到4个表（所有4个节点都用于连接）。 在其他测试中，他们使用8个不同的表。 在某些情况下，批处理大小为100，在其他情况下为200（批处理参数-请参见下面的代码）。 值的数据大小为10字节或100字节（dataSize）。 在每个表中，总共写入并减去500万条记录。 同时，向每个表中写入/读取了5个流（流号为thNum），每个流都使用自己的键范围（计数= 1百万）： <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (opType.equals(<span class="hljs-string"><span class="hljs-string">"insert"</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { StringBuilder sb = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringBuilder(<span class="hljs-string"><span class="hljs-string">"BEGIN BATCH "</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { String value = RandomStringUtils.random(dataSize, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); sb.append(<span class="hljs-string"><span class="hljs-string">"INSERT INTO "</span></span>) .append(tableName) .append(<span class="hljs-string"><span class="hljs-string">"(id, title) "</span></span>) .append(<span class="hljs-string"><span class="hljs-string">"VALUES ("</span></span>) .append(key) .append(<span class="hljs-string"><span class="hljs-string">", '"</span></span>) .append(value) .append(<span class="hljs-string"><span class="hljs-string">"');"</span></span>); key++; } sb.append(<span class="hljs-string"><span class="hljs-string">"APPLY BATCH;"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> String query = sb.toString(); session.execute(query); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { StringBuilder sb = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringBuilder(<span class="hljs-string"><span class="hljs-string">"SELECT * FROM "</span></span>).append(tableName).append(<span class="hljs-string"><span class="hljs-string">" WHERE id IN ("</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { sb = sb.append(key); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (i+<span class="hljs-number"><span class="hljs-number">1</span></span> &lt; batch) sb.append(<span class="hljs-string"><span class="hljs-string">","</span></span>); key++; } sb = sb.append(<span class="hljs-string"><span class="hljs-string">");"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> String query = sb.toString(); ResultSet rs = session.execute(query); } }</code> </pre><br> 因此，为HB提供了类似的功能： <br><br><pre> <code class="java hljs">Configuration conf = getConf(); HTable table = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HTable(conf, keyspace + <span class="hljs-string"><span class="hljs-string">":"</span></span> + tableName); table.setAutoFlush(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); List&lt;Get&gt; lGet = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(); List&lt;Put&gt; lPut = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] cf = Bytes.toBytes(<span class="hljs-string"><span class="hljs-string">"cf"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] qf = Bytes.toBytes(<span class="hljs-string"><span class="hljs-string">"value"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (opType.equals(<span class="hljs-string"><span class="hljs-string">"insert"</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { lPut.clear(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { Put p = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Put(makeHbaseRowKey(key)); String value = RandomStringUtils.random(dataSize, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); p.addColumn(cf, qf, value.getBytes()); lPut.add(p); key++; } table.put(lPut); table.flushCommits(); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { lGet.clear(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { Get g = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Get(makeHbaseRowKey(key)); lGet.add(g); key++; } Result[] rs = table.get(lGet); } }</code> </pre><br> 由于客户端必须注意HB中数据的均匀分布，因此关键的盐腌功能如下所示： <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] makeHbaseRowKey(<span class="hljs-keyword"><span class="hljs-keyword">long</span></span> key) { <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] nonSaltedRowKey = Bytes.toBytes(key); CRC32 crc32 = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CRC32(); crc32.update(nonSaltedRowKey); <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> crc32Value = crc32.getValue(); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] salt = Arrays.copyOfRange(Bytes.toBytes(crc32Value), <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ArrayUtils.addAll(salt, nonSaltedRowKey); }</code> </pre><br> 现在最有趣的是结果： <br><br><img src="https://habrastorage.org/webt/id/yd/pc/idydpc9plsmulsycf0i-wqy3c3c.png"><br><br> 与图相同： <br><br><img src="https://habrastorage.org/webt/72/ag/o1/72ago1u2gdnlufjanqwavk5p1jk.png"><br><br>  HB的优势是如此惊人，以至于CS设置中存在某种瓶颈。 但是，最明显参数的谷歌搜索和扭曲（例如parallel_writes或memtable_heap_space_in_mb）没有提供加速。 同时，原木是干净的，不要发誓。 <br><br> 数据均匀分布在节点之间，来自所有节点的统计信息大致相同。 <br><br><div class="spoiler">  <b class="spoiler_title">这是带有节点之一的表的统计信息</b> <div class="spoiler_text"> 键空间：ks <br> 读数：9383707 <br> 读取延迟：0.04287025042448576 ms <br> 写数：15462012 <br> 写入延迟：0.1350068438699957 ms <br> 等待冲洗：0 <br> 表：t1 <br>  SSTable数量：16 <br> 使用的空间（实时）：148.59 MiB <br> 已使用空间（总计）：148.59 MiB <br> 快照使用的空间（总计）：0字节 <br> 使用的堆外内存（总计）：5.17 MiB <br>  SSTable压缩比：0.5720989576459437 <br> 分区数（估计）：3970323 <br> 记忆细胞计数：0 <br>  Memtable资料大小：0个位元组 <br> 已使用的表外堆内存：0个字节 <br> 内存开关数：5 <br> 本地读取计数：2346045 <br> 本地读取延迟：NaN ms <br> 本地写计数：3865503 <br> 本地写入延迟：NaN ms <br> 等待冲洗：0 <br> 修复百分比：0.0 <br> 布隆过滤器误报：25 <br> 布隆过滤器错误率：0.00000 <br> 使用的Bloom筛选器空间：4.57 MiB <br> 布隆过滤器使用的堆内存：4.57 MiB <br> 所用堆内存的索引摘要：590.02 KiB <br> 使用的堆内存压缩元数据：19.45 KiB <br> 压缩分区的最小字节数：36 <br> 压缩分区的最大字节数：42 <br> 压缩分区的平均字节数：42 <br> 每片平均活细胞数（最近五分钟）：NaN <br> 每片最大活细胞数（最近五分钟）：0 <br> 每片平均墓碑（最近五分钟）：NaN <br> 每片最大墓碑数（最近五分钟）：0 <br> 删除的变异：0个字节 <br></div></div><br> 尝试减小批次的大小（直到一个接一个地发送）没有效果，只会变得更糟。 实际上，这实际上可能是CS的最高性能，因为在CS上获得的结果与从DataStax获得的结果相似-每秒约数十万次操作。 此外，如果查看资源利用率，您会发现CS使用更多的CPU和磁盘： <br><br><img src="https://habrastorage.org/webt/us/fo/i4/usfoi4-mgkktzlosilmz2ogm7uu.png"><br>  <i>该图连续显示两个数据库在运行所有测试期间的利用率。</i> <br><br> 关于HB的强大阅读优势。 可以看出，对于这两个数据库，读取期间的磁盘利用率都非常低（读取测试是每个数据库测试周期的最后一部分，例如，对于15:20到15:40的CS）。 对于HB，原因很明显-大多数数据都挂在内存中的memstore中，而某些数据则缓存在blockcache中。 至于CS，尚不清楚其工作原理，但是，磁盘利用率也不可见，但以防万一，试图打开row_cache_size_in_mb = 2048缓存并设置caching = {'keys'：'ALL'，'rows_per_partition'：' 2,000,000'}，但情况更糟。 <br><br> 同样值得一提的是关于HB区域数目的重要观点。 在本例中，显示的值为64，如果将其减小并使其等于例如4，则读取速度下降2倍。 原因是memstore将更快地阻塞并且文件将更频繁地刷新，并且在读取时将需要处理更多文件，这对于HB来说是相当复杂的操作。 在实际条件下，可以通过考虑预植入和压缩的策略来解决，特别是，我们使用自制的实用程序来收集垃圾并在后台不断压缩HFiles。 对于DataStax测试，通常可能为每个表分配1个区域（这是不正确的），这将在某种程度上澄清为什么HB在其读取测试中损失这么多。 <br><br> 由此得出的初步结论如下。 假设在测试过程中没有发生重大错误，Cassandra就像一块巨大的粘土脚。 更准确地说，当她在一条腿上保持平衡时（如本文开头的图片中所示），她显示出相对较好的成绩，但是当她在相同条件下进行战斗时，她将完全输掉比赛。 同时，考虑到硬件的CPU使用率低，我们学会了在每个主机上安装两个RegionServer HB，从而使生产率提高了一倍。 即 考虑到资源利用率，CS的情况甚至更糟。 <br><br> 当然，这些测试是综合的，此处使用的数据量相对较少。 切换到TB时，情况可能会有所不同，但是如果对于HB我们可以加载TB，那么对于CS来说，这是有问题的。 即使与这些卷相比，它也经常引发OperationTimedOutException，尽管响应期望参数已经比默认参数增加了数倍。 <br><br> 我希望通过共同努力，我们将发现CS瓶颈，如果我们设法加快它的速度，那么我一定会在帖子末尾添加有关最终结果的信息。 <br><br>  <b>UPD：</b>以下准则适用于CS设置： <br><br>  <i>disk_optimization_strategy：旋转</i> <i><br></i>  <i>MAX_HEAP_SIZE =“ 32G”</i> <i><br></i>  <i>HEAP_NEWSIZE =“ 3200M”</i> <i><br></i>  <i>-Xms32G</i> <i><br></i>  <i>-Xmx32G</i> <i><br></i>  <i>-XX：+ UseG1GC</i> <i><br></i>  <i>-XX：G1RSetUpdatingPauseTimePercent = 5</i> <i><br></i>  <i>-XX：MaxGCPauseMillis = 500</i> <i><br></i>  <i>-XX：InitiatingHeapOccupancyPercent = 70</i> <i><br></i>  <i>-XX：ParallelGCThreads = 32</i> <i><br></i>  <i>-XX：ConcGCThreads = 8</i> <br><br> 至于操作系统设置，这是一个相当长且复杂的过程（获取root，重新启动服务器等），因此未应用这些建议。 另一方面，两个数据库处于相同条件下，因此一切都是公平的。 <br><br> 在代码部分，为写入表的所有线程建立了一个连接器： <br><pre> <code class="java hljs">connector = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CassandraConnector(); connector.connect(node, <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, CL); session = connector.getSession(); session.getCluster().getConfiguration().getSocketOptions().setConnectTimeoutMillis(<span class="hljs-number"><span class="hljs-number">120000</span></span>); KeyspaceRepository sr = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KeyspaceRepository(session); sr.useKeyspace(keyspace); prepared = session.prepare(<span class="hljs-string"><span class="hljs-string">"insert into "</span></span> + tableName + <span class="hljs-string"><span class="hljs-string">" (id, title) values (?, ?)"</span></span>);</code> </pre> <br><br> 数据是通过绑定发送的： <br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key++) { String value = RandomStringUtils.random(dataSize, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); session.execute(prepared.bind(key, value)); }</code> </pre> <br><br> 这对录制性能没有重大影响。 为了提高可靠性，我使用YCSB工具启动了加载，结果完全相同。 以下是一个线程（4个线程中）的统计信息： <br><br>  <i>2020-01-18 14:41:53：180315秒：10,000,000次操作;</i>  <i>21589.1当前操作/秒；</i>  <i>[清理：计数= 100，最大值= 2236415，最小值= 1，平均= 22356.39，90 = 4，99 = 24，99.9 = 2236415，99.99 = 2236415] [插入：计数= 119551，最大值= 174463，最小值= 273，平均= 2582.71，90 = 3491，99 = 16767，99.9 = 99711，99.99 = 171263]</i> <i><br></i>  <i>[OVERALL]，运行时间（毫秒），315539</i> <i><br></i>  <i>[总体]，吞吐量（运营/秒），31691.803548848162</i> <i><br></i>  <i>[TOTAL_GCS_PS_Scavenge]，计数，161</i> <i><br></i>  <i>[TOTAL_GC_TIME_PS_Scavenge]，时间（毫秒），2433</i> <i><br></i>  <i>[TOTAL_GC_TIME _％_ PS_Scavenge]，时间（％），0.7710615803434757</i> <i><br></i>  <i>[TOTAL_GCS_PS_MarkSweep]，计数，0</i> <i><br></i>  <i>[TOTAL_GC_TIME_PS_MarkSweep]，时间（毫秒），0</i> <i><br></i>  <i>[TOTAL_GC_TIME _％_ PS_MarkSweep]，时间（％），0.0</i> <i><br></i>  <i>[TOTAL_GCs]，计数，161</i> <i><br></i>  <i>[TOTAL_GC_TIME]，时间（毫秒），2433</i> <i><br></i>  <i>[TOTAL_GC_TIME_％]，时间（％），0.7710615803434757</i> <i><br></i>  <i>[INSERT]，运营，10,000,000</i> <i><br></i>  <i>[INSERT]，AverageLatency（美国），3114.2427012</i> <i><br></i>  <i>[INSERT]，MinLatency（美国），269</i> <i><br></i>  <i>[INSERT]，MaxLatency（美国），609279</i> <i><br></i>  <i>[INSERT]，95thPercentileLatency（美国），5007</i> <i><br></i>  <i>[INSERT]，99thPercentileLatency（美国），33439</i> <i><br></i>  <i>[INSERT]，返回= OK，10000000</i> <i><br></i> <br><br> 在这里，您可以看到一个流的速度约为每秒32,000个记录，工作了4个流，结果为12.8万。似乎没有什么可以挤出当前的磁盘子系统设置了。 <br><br> 关于阅读更有趣。 多亏了同志的建议，他才得以从根本上加速前进。 读取不是在5个流中进行的，而是在100个流中进行的。增加到200个不会产生效果。 还添加到构建器中： <br>  .withLoadBalancingPolicy（新的TokenAwarePolicy（DCAwareRoundRobinPolicy.builder（）。build（））） <br><br> 结果，如果较早的测试显示159644个操作（5个流，4个表，100个批处理），则现在： <br>  100个线程，4个表，批处理= 1（单独）：301969个操作 <br>  100个线程，4个表，批处理= 10：447608操作 <br>  100个线程，4个表，批处理= 100：625655个操作 <br><br> 由于批处理的结果更好，因此我对HB进行了类似的*测试： <br><img src="https://habrastorage.org/webt/ct/bk/-y/ctbk-yrecbwegasrbpauq6f1vv8.png"><br>  <i>*由于在400个线程中工作时，较早使用的RandomStringUtils函数将CPU加载了100％，因此它被更快的生成器所取代。</i> <br><br> 因此，加载数据时线程数的增加会使HB性能有所提高。 <br><br> 至于阅读，这是几种选择的结果。 应<a href="https://habr.com/ru/users/0x62ash/" class="user_link">0x62ash</a>的请求，在读取之前已执行了flush命令，并且还提供了其他几个选项进行比较： <br>  Memstore-从内存读取，即 在刷新到磁盘之前。 <br>  HFile + zip-从GZ算法压缩的文件中读取。 <br>  HFile + upzip-无需压缩即可读取文件。 <br><br> 一个有趣的功能是值得注意的-小文件（请参见“数据”字段，其中写入了10个字节）的处理速度较慢，尤其是在压缩时。 显然，这只有在达到一定大小后才可能实现，显然一个5 GB的文件将不会以超过10 MB的速度处理，但是它清楚地表明，在所有这些测试中，仍然没有犁various的领域来研究各种配置。 <br><br> 出于兴趣，我更正了YCSB代码，以处理100件HB批次以测量延迟等。 以下是写入表的4个副本的工作结果，每个副本具有100个线程。 结果是： <br><div class="spoiler">  <b class="spoiler_title">一次操作= 100条记录</b> <div class="spoiler_text">  [OVERALL]，运行时间（ms），1165415 <br>  [总体]，吞吐量（操作数/秒），858.06343662987 <br>  [TOTAL_GCS_PS_Scavenge]，计数，798 <br>  [TOTAL_GC_TIME_PS_Scavenge]，时间（毫秒），7346 <br>  [TOTAL_GC_TIME _％_ PS_Scavenge]，时间（％），0.6303334005483026 <br>  [TOTAL_GCS_PS_MarkSweep]，计数，1 <br>  [TOTAL_GC_TIME_PS_MarkSweep]，时间（毫秒），74 <br>  [TOTAL_GC_TIME _％_ PS_MarkSweep]，时间（％），0.006349669431061038 <br>  [TOTAL_GCs]，计数，799 <br>  [TOTAL_GC_TIME]，时间（毫秒），7420 <br>  [TOTAL_GC_TIME_％]，时间（％），0.6366830699793635 <br>  [INSERT]，运营，1,000,000 <br>  [INSERT]，AverageLatency（美国），115893.891644 <br>  [插入]，MinLatency（美国），14528 <br>  [INSERT]，MaxLatency（美国），1470463 <br>  [INSERT]，95thPercentileLatency（美国），248319 <br>  [插入]，99thPercentileLatency（美国），445951 <br>  [插入]，返回= OK，1,000,000 <br><br>  19/01/20 13:19:16 INFO client.ConnectionManager $ HConnectionImplementation：关闭zookeeper会话ID = 0x36f98ad0a4ad8cc <br>  19/01/20 13:19:16信息zookeeper.ZooKeeper：会话：0x36f98ad0a4ad8cc已关闭 <br>  19/01/20 13:19:16信息zookeeper.ClientCnxn：EventThread关闭 <br>  [OVERALL]，运行时间（毫秒），1165806 <br>  [总体]，吞吐量（操作数/秒），857.7756504941646 <br>  [TOTAL_GCS_PS_Scavenge]，计数，776 <br>  [TOTAL_GC_TIME_PS_Scavenge]，时间（毫秒），7517 <br>  [TOTAL_GC_TIME _％_ PS_Scavenge]，时间（％），0.6447899564764635 <br>  [TOTAL_GCS_PS_MarkSweep]，计数，1 <br>  [TOTAL_GC_TIME_PS_MarkSweep]，时间（毫秒），63 <br>  [TOTAL_GC_TIME _％_ PS_MarkSweep]，时间（％），0.005403986598113236 <br>  [TOTAL_GCs]，计数，777 <br>  [TOTAL_GC_TIME]，时间（毫秒），7580 <br>  [TOTAL_GC_TIME_％]，时间（％），0.6501939430745767 <br>  [INSERT]，运营，1,000,000 <br>  [INSERT]，AverageLatency（美国），116042.207936 <br>  [插入]，MinLatency（美国），14056 <br>  [INSERT]，MaxLatency（美国），1462271 <br>  [INSERT]，95thPercentileLatency（美国），250239 <br>  [插入]，99thPercentileLatency（美国），446719 <br>  [插入]，返回= OK，1,000,000 <br><br>  19/01/20 13:19:16 INFO client.ConnectionManager $ HConnectionImplementation：关闭zookeeper会话ID = 0x26f98ad07b6d67e <br>  19/01/20 13:19:16 INFO zookeeper.ZooKeeper：会话：0x26f98ad07b6d67e关闭 <br>  19/01/20 13:19:16信息zookeeper.ClientCnxn：EventThread关闭 <br>  [OVERALL]，运行时间（毫秒），1165999 <br>  [总体]，吞吐量（运营/秒），857.63366863951 <br>  [TOTAL_GCS_PS_Scavenge]，计数，818 <br> [TOTAL_GC_TIME_PS_Scavenge], Time(ms), 7557 <br> [TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.6481137633908777 <br> [TOTAL_GCS_PS_MarkSweep], Count, 1 <br> [TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 79 <br> [TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.006775305982252128 <br> [TOTAL_GCs], Count, 819 <br> [TOTAL_GC_TIME], Time(ms), 7636 <br> [TOTAL_GC_TIME_%], Time(%), 0.6548890693731299 <br> [INSERT], Operations, 1000000 <br> [INSERT], AverageLatency(us), 116172.212864 <br> [INSERT], MinLatency(us), 7952 <br> [INSERT], MaxLatency(us), 1458175 <br> [INSERT], 95thPercentileLatency(us), 250879 <br> [INSERT], 99thPercentileLatency(us), 446463 <br> [INSERT], Return=OK, 1000000 <br><br> 20/01/19 13:19:17 INFO client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x36f98ad0a4ad8cd <br> 20/01/19 13:19:17 INFO zookeeper.ZooKeeper: Session: 0x36f98ad0a4ad8cd closed <br> 20/01/19 13:19:17 INFO zookeeper.ClientCnxn: EventThread shut down <br> [OVERALL], RunTime(ms), 1166860 <br> [OVERALL], Throughput(ops/sec), 857.000839860823 <br> [TOTAL_GCS_PS_Scavenge], Count, 707 <br> [TOTAL_GC_TIME_PS_Scavenge], Time(ms), 7239 <br> [TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.6203829079752499 <br> [TOTAL_GCS_PS_MarkSweep], Count, 1 <br> [TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 67 <br> [TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.0057419056270675145 <br> [TOTAL_GCs], Count, 708 <br> [TOTAL_GC_TIME], Time(ms), 7306 <br> [TOTAL_GC_TIME_%], Time(%), 0.6261248136023173 <br> [INSERT], Operations, 1000000 <br> [INSERT], AverageLatency(us), 116230.849308 <br> [INSERT], MinLatency(us), 7352 <br> [INSERT], MaxLatency(us), 1443839 <br> [INSERT], 95thPercentileLatency(us), 250623 <br> [INSERT], 99thPercentileLatency(us), 447487 <br> [INSERT], Return=OK, 1000000 </div></div><br><br> ,    CS AverageLatency(us)   3114,   HB AverageLatency(us) = 1162 (,  1  = 100     ). <br><br>      —        HBase.   ,  SSD       .   ,       ,    ,     4 ,  400    ,      .   :  —  .  .   ScyllaDB     ,    … </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN484096/">https://habr.com/ru/post/zh-CN484096/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN484084/index.html">1C-Bitrix并尝试引入它</a></li>
<li><a href="../zh-CN484088/index.html">密码命中大游行（从泄漏中分析约50亿个密码）</a></li>
<li><a href="../zh-CN484090/index.html">俄罗斯邮政数据中心的新IT基础架构</a></li>
<li><a href="../zh-CN484092/index.html">王子和贵族穿得有些体面</a></li>
<li><a href="../zh-CN484094/index.html">使用DOTS创建第三人称僵尸射击游戏</a></li>
<li><a href="../zh-CN484100/index.html">使用Android版Google Maps SDK中的界面</a></li>
<li><a href="../zh-CN484102/index.html">PHP vs Python vs Ruby on Rails：详细比较</a></li>
<li><a href="../zh-CN484106/index.html">PostgreSQL-6中的MVCC。 真空度</a></li>
<li><a href="../zh-CN484108/index.html">Etherblade.net封装器和网络组件的导入替代（第二部分）</a></li>
<li><a href="../zh-CN484112/index.html">有可能砍飞机吗</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
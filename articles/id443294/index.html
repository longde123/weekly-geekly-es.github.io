<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🎤 🖐🏻 🈳 Apa yang diizinkan oleh Jupyter? 👩🏽‍🤝‍👩🏻 🥈 👨🏾‍🎨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kisah kami dimulai dengan tugas yang tampaknya sederhana. Itu perlu untuk menyiapkan alat analitis untuk spesialis ilmu data dan hanya analis data. Tu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apa yang diizinkan oleh Jupyter?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/443294/">  Kisah kami dimulai dengan tugas yang tampaknya sederhana.  Itu perlu untuk menyiapkan alat analitis untuk spesialis ilmu data dan hanya analis data.  Tugas ini ditujukan kepada kami oleh rekan-rekan dari divisi risiko ritel dan CRM, di mana konsentrasi spesialis ilmu data secara historis tinggi.  Pelanggan memiliki keinginan sederhana - untuk menulis kode Python, mengimpor pustaka canggih (xgboost, pytorch, tensorflow, dll.) Dan menjalankan algoritma pada data yang diangkat dari cluster HDFS. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/793/c16/22e/793c1622e8423e8cae171263790ab234.png"><br><br>  Segalanya tampak sederhana dan jelas.  Tetapi ada begitu banyak jebakan sehingga kami memutuskan untuk menulis posting tentang itu dan memposting solusi siap pakai di GitHub. <br><a name="habracut"></a><br>  Pertama, beberapa perincian tentang infrastruktur sumber: <br><br><ul><li>  Gudang Data HDFS (12 node Oracle Big Data Appliance, distribusi Cloudera).  Secara total, gudang memiliki 130 TB data dari berbagai sistem internal bank, ada juga informasi heterogen dari sumber eksternal. <br></li><li>  Dua server aplikasi tempat penggunaan alat analitik.  Perlu disebutkan bahwa tidak hanya tugas analisis lanjutan "berputar" di server ini, jadi salah satu persyaratannya adalah penggunaan alat kontainerisasi (Docker) untuk mengelola sumber daya server, menggunakan berbagai lingkungan, dan mengonfigurasinya. <br></li></ul><br>  Sebagai lingkungan utama untuk pekerjaan analis, mereka memutuskan untuk memilih JupyterHub, yang secara de facto telah menjadi salah satu standar untuk bekerja dengan data dan mengembangkan model pembelajaran mesin.  Baca lebih lanjut di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Di masa depan, kita sudah membayangkan JupyterLab. <br><br>  Tampaknya semuanya sederhana: Anda perlu mengambil dan mengonfigurasi sekelompok Python + Anaconda + Spark.  Instal Jupyter Hub di server aplikasi, integrasikan dengan LDAP, sambungkan Spark atau sambungkan ke data dalam HDFS dengan cara lain dan teruskan - buat model! <br>  Jika Anda mempelajari semua sumber data dan persyaratan, maka berikut adalah daftar yang lebih terperinci: <br><br><ul><li>  Menjalankan JupyterHub di Docker (base OS - Oracle Linux 7) <br></li><li> Cloudera CDH cluster 5.15.1 + Spark 2.3.0 dengan otentikasi Kerberos dalam konfigurasi Direktori Aktif + MIT Kerberos khusus dalam cluster (lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MIT KDC Cluster-Dedicated dengan Direktori Aktif</a> ), Oracle Linux 6 <br></li><li>  Integrasi Direktori Aktif <br></li><li>  Otentikasi transparan di Hadoop dan Spark <br></li><li>  Dukungan Python 2 dan 3 <br></li><li>  Spark 1 dan 2 (dengan kemampuan untuk menggunakan sumber daya klaster untuk model pelatihan dan memparalelkan pemrosesan data menggunakan pyspark) <br></li><li>  Kemampuan untuk membatasi sumber daya host <br></li><li>  Kumpulan perpustakaan <br></li></ul><br>  Posting ini dirancang untuk para profesional TI yang dihadapkan dengan kebutuhan untuk menyelesaikan masalah seperti itu. <br><br><h2>  Deskripsi Solusi </h2><br><h3>  Peluncuran di Docker + Cloudera Cluster Integration </h3><br>  Tidak ada yang aneh di sini.  Klien produk JupyterHub dan Cloudera dipasang di wadah (seperti - lihat di bawah), dan file konfigurasi dipasang dari mesin host: <br><br>  <b>start-hub.sh</b> <br><br><pre><code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre> <br><br><h3>  Integrasi Direktori Aktif </h3><br>  Untuk integrasi dengan Active Directory / besi Kerberos dan bukan sangat host, standar di perusahaan kami adalah produk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PBIS Open</a> .  Secara teknis, produk ini adalah serangkaian layanan yang berkomunikasi dengan Active Directory, yang pada gilirannya, klien bekerja melalui soket domain unix.  Produk ini terintegrasi dengan Linux PAM dan NSS. <br><br>  Kami menggunakan metode Docker standar - soket layanan host domain unix dipasang di sebuah wadah (soket ditemukan secara empiris oleh manipulasi sederhana dengan perintah lsof): <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z &lt;b&gt;-v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro &lt;/b&gt; -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre><br>  Pada gilirannya, paket-paket PBIS dipasang di dalam wadah, tetapi tanpa menjalankan bagian postinstall.  Jadi kami hanya menempatkan file dan pustaka yang dapat dieksekusi, tetapi jangan memulai layanan di dalam wadah - ini berlebihan bagi kami.  Perintah integrasi PAM dan NSS Linux dijalankan secara manual. <br><br>  <b>Dockerfile:</b> <br><br><pre> <code class="plaintext hljs"># Install PAM itself and standard PAM configuration packages. RUN yum install -y pam util-linux \ # Here we just download PBIS RPM packages then install them omitting scripts. # We don't need scripts since they start PBIS services, which are not used - we connect to the host services instead. &amp;&amp; find /var/yum/localrepo/ -type f -name 'pbis-open*.rpm' | xargs rpm -ivh --noscripts \ # Enable PBIS PAM integration. &amp;&amp; domainjoin-cli configure --enable pam \ # Make pam_loginuid.so module optional (Docker requirement) and add pam_mkhomedir.so to have home directories created automatically. &amp;&amp; mv /etc/pam.d/login /tmp \ &amp;&amp; awk '{ if ($1 == "session" &amp;&amp; $2 == "required" &amp;&amp; $3 == "pam_loginuid.so") { print "session optional pam_loginuid.so"; print "session required pam_mkhomedir.so skel=/etc/skel/ umask=0022";} else { print $0; } }' /tmp/login &gt; /etc/pam.d/login \ &amp;&amp; rm /tmp/login \ # Enable PBIS nss integration. &amp;&amp; domainjoin-cli configure --enable nsswitch</code> </pre><br>  Ternyata klien wadah PBIS berkomunikasi dengan layanan host PBIS.  JupyterHub menggunakan PAM authenticator, dan dengan PBIS yang dikonfigurasi dengan benar pada host, semuanya berjalan di luar kotak. <br><br>  Untuk mencegah semua pengguna dari AD memasuki JupyterHub, Anda dapat menggunakan pengaturan yang membatasi pengguna untuk grup AD tertentu. <br><br>  <b>config-example / jupyterhub / jupyterhub_config.py</b> <br><br><pre> <code class="plaintext hljs">c.DSAIAuthenticator.group_whitelist = ['COMPANY\\domain^users']</code> </pre><br><h3>  Otentikasi transparan di Hadoop dan Spark </h3><br>  Saat masuk ke JupyterHub, PBIS cache tiket Kerberos pengguna dalam file tertentu di direktori / tmp.  Untuk otentikasi transparan dengan cara ini, cukup dengan me-mount direktori / tmp dari host di wadah dan mengatur variabel KRB5CCNAME ke nilai yang diinginkan (ini dilakukan di kelas authenticator kami). <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre> <br>  <b>aset / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">env['KRB5CCNAME'] = '/host/tmp/krb5cc_%d' % pwd.getpwnam(self.user.name).pw_uid</code> </pre> <br>  Berkat kode di atas, pengguna JupyterHub dapat menjalankan perintah hdfs dari terminal Jupyter dan menjalankan pekerjaan Spark tanpa langkah otentikasi tambahan.  Memasang seluruh direktori / tmp dari host ke dalam wadah tidak aman - kami mengetahui masalah ini, tetapi solusinya masih dalam pengembangan. <br><br><h3>  Versi Python 2 dan 3 </h3><br>  Di sini, tampaknya, semuanya sederhana: Anda perlu menginstal versi Python yang diperlukan dan mengintegrasikannya dengan Jupyter, menciptakan Kernel yang diperlukan.  Masalah ini sudah dibahas di banyak tempat.  Conda digunakan untuk mengelola lingkungan Python.  Mengapa semua kesederhanaan hanya terlihat akan menjadi jelas dari bagian selanjutnya.  Contoh kernel untuk Python 3.6 (file ini tidak di git - semua file kernel dihasilkan oleh kode): <br><br>  <b>/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/share/jupyter/kernels/python3.6.6/kernel.json</b> <br><br><pre> <code class="plaintext hljs">{   "argv": [      "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python",       "-m",       "ipykernel_launcher",       "-f",      "{connection_file}"   ],   "display_name": "Python 3",   "language": "python" }</code> </pre><br><h3>  Percikan 1 dan 2 </h3><br>  Untuk berintegrasi dengan klien SPARK, Anda juga perlu membuat kernel.  Contoh kernel untuk Python 3.6 dan SPARK 2. <br><br>  <b>/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/share/jupyter/kernels/python3.6.6-pyspark2/kernel.json</b> <br><br><pre> <code class="plaintext hljs">{   "argv": [       "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python",       "-m",       "ipykernel_launcher",       "-f",      "{connection_file}"   ],   "display_name": "Python 3 + PySpark 2",   "language": "python",   "env": {       "JAVA_HOME": "/usr/java/default/",       "SPARK_HOME": "/opt/cloudera/parcels/SPARK2/lib/spark2/",       "PYTHONSTARTUP": "/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/shell.py",       "PYTHONPATH": "/opt/cloudera/parcels/SPARK2/lib/spark2/python/:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.7-src.zip",       "PYSPARK_PYTHON": "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python"   } }</code> </pre><br>  Harap perhatikan bahwa persyaratan untuk memiliki dukungan Spark 1 telah berkembang secara historis.  Namun, ada kemungkinan bahwa seseorang akan menghadapi batasan yang sama - Anda tidak dapat, misalnya, menginstal Spark 2 dalam sebuah cluster.  Oleh karena itu, kami menggambarkan di sini perangkap yang kami temui dalam perjalanan ke implementasi. <br>  Pertama, Spark 1.6.1 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tidak berfungsi</a> dengan Python 3.6.  Menariknya, dalam CDH 5.12.1 ini diperbaiki, tetapi dalam 5.15.1 - untuk beberapa alasan tidak).  Pada awalnya, kami ingin menyelesaikan masalah ini dengan hanya menerapkan tambalan yang sesuai.  Namun, di masa depan, ide ini harus ditinggalkan, karena pendekatan ini membutuhkan pemasangan Spark yang dimodifikasi dalam sebuah cluster, yang tidak dapat kami terima.  Solusinya ditemukan dalam menciptakan lingkungan Conda terpisah dengan Python 3.5. <br><br>  Masalah kedua mencegah Spark 1 dari bekerja di dalam Docker.  Driver Spark membuka port tertentu di mana Pekerja terhubung ke driver - untuk ini driver mengirimkannya alamat IP-nya.  Dalam kasus Docker Worker, ia mencoba untuk terhubung ke driver melalui IP kontainer, dan ketika menggunakan jaringan = jembatan itu tidak bekerja secara alami. <br><br>  Solusi yang jelas adalah mengirim bukan IP wadah, tetapi IP tuan rumah, yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diterapkan</a> di Spark 2 dengan menambahkan pengaturan konfigurasi yang sesuai.  Patch ini dirancang ulang secara kreatif dan diterapkan pada Spark 1. Spark yang dimodifikasi dengan cara ini tidak perlu ditempatkan pada host cluster, jadi tidak ada masalah yang mirip dengan ketidakcocokan dengan Python 3.6. <br><br>  Terlepas dari versi Spark, untuk fungsinya perlu untuk memiliki versi Python yang sama di dalam cluster seperti dalam wadah.  Untuk menginstal Anaconda secara langsung melewati Cloudera Manager, kami harus belajar melakukan dua hal: <br><br><ul><li>  bangun paket Anda dengan Anaconda dan semua lingkungan yang tepat <br></li><li>  pasang di Docker (untuk konsistensi) <br></li></ul><br><h3>  Paket perakitan Anaconda </h3><br>  Ini ternyata menjadi tugas yang cukup sederhana.  Yang Anda butuhkan adalah: <br><br><ol><li>  Siapkan konten parcel dengan menginstal versi yang diperlukan dari lingkungan Anaconda dan Python <br></li><li>  Buat file metadata dan letakkan di direktori meta <br></li><li>  Buat paket dengan tar sederhana <br></li><li>  Validasi utilitas paket dari Cloudera <br></li></ol><br>  Prosesnya dijelaskan secara lebih rinci tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GitHub</a> , ada juga kode validator di sana.  Kami meminjam metadata dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">paket</a> Anaconda resmi untuk Cloudera, mengolahnya secara kreatif. <br><br><h3>  Instal paket di Docker </h3><br>  Praktek ini telah terbukti bermanfaat karena dua alasan: <br><br><ul><li>  memastikan Spark operabilitas - tidak mungkin menempatkan Anaconda ke dalam cluster tanpa paket <br></li><li>  Spark 2 didistribusikan hanya dalam bentuk paket - Anda tentu saja dapat menginstalnya dalam wadah hanya dalam bentuk file jar, tetapi pendekatan ini ditolak <br></li></ul><br>  Sebagai bonus, sebagai hasil dari penyelesaian masalah di atas, kami menerima: <br><br><ul><li>  kemudahan pengaturan klien Hadoop dan Spark - saat memasang paket yang sama di Docker dan di cluster, jalur di cluster dan di wadah adalah sama <br></li><li>  kemudahan mempertahankan lingkungan yang seragam di dalam wadah dan di dalam kluster - saat memperbarui kluster, gambar Docker dibangun kembali dengan paket yang sama dengan yang dipasang di kluster. <br></li></ul><br>  Untuk menginstal paket di Docker, Cloudera Manager pertama kali diinstal dari paket RPM.  Untuk pemasangan parcel yang sebenarnya, kode Java digunakan.  Klien di Java tahu apa yang tidak bisa dilakukan klien dengan Python, jadi saya harus menggunakan Java dan kehilangan beberapa keseragaman), yang memanggil API. <br><br>  <b>aset / instal-parcel / src / InstallParcels.java</b> <br><br><pre> <code class="plaintext hljs">ParcelsResourceV5 parcels = clusters.getParcelsResource(clusterName); for (int i = 1; i &lt; args.length; i += 2) {   result = installParcel(api, parcels, args[i], args[i + 1], pause);   if (!result) {       System.exit(1);   } }</code> </pre><br><h3>  Batasan sumber daya host </h3><br>  Untuk mengelola sumber daya mesin host, kombinasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DockerSpawner</a> digunakan - komponen yang menjalankan pengguna akhir Jupyter dalam wadah Docker yang terpisah - dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cgroup</a> - mekanisme manajemen sumber daya di Linux.  DockerSpawner menggunakan Docker API, yang memungkinkan Anda untuk mengatur cgroup induk untuk wadah.  Tidak ada kemungkinan seperti itu di DockerSpawner biasa, jadi kami menulis kode sederhana yang memungkinkan kami untuk mengatur korespondensi antara entitas AD dan cgroup induk dalam konfigurasi. <br><br>  <b>aset / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">def set_extra_host_config(self):       extra_host_config = {}       if self.user.name in self.user_cgroup_parent:           cgroup_parent = self.user_cgroup_parent[self.user.name]       else:           pw_name = pwd.getpwnam(self.user.name).pw_name           group_found = False           for g in grp.getgrall():               if pw_name in g.gr_mem and g.gr_name in self.group_cgroup_parent:                   cgroup_parent = self.group_cgroup_parent[g.gr_name]                   group_found = True                   break           if not group_found:               cgroup_parent = self.cgroup_parent extra_host_config['cgroup_parent'] = cgroup_parent</code> </pre><br>  Sebuah modifikasi kecil juga telah diperkenalkan yang meluncurkan Jupyter dari gambar yang sama dari mana JupyterHub diluncurkan.  Karena itu, tidak perlu menggunakan lebih dari satu gambar. <br><br>  <b>aset / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">current_container = None host_name = socket.gethostname() for container in self.client.containers():   if container['Id'][0:12] == host_name:       current_container = container       break self.image = current_container['Image']</code> </pre><br>  Apa sebenarnya yang harus dijalankan dalam wadah, Jupyter atau JupyterHub, ditentukan dalam skrip startup oleh variabel lingkungan: <br><br>  <b>aset / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">#!/bin/bash ANACONDA_PATH="/opt/cloudera/parcels/Anaconda/" DEFAULT_ENV=`cat ${ANACONDA_PATH}/envs/default` source activate ${DEFAULT_ENV} if [ -z "${JUPYTERHUB_CLIENT_ID}" ]; then   while true; do       jupyterhub -f /etc/jupyterhub/jupyterhub_config.py   done else   HOME=`su ${JUPYTERHUB_USER} -c 'echo ~'`   cd ~   su ${JUPYTERHUB_USER} -p -c "jupyterhub-singleuser --KernelSpecManager.ensure_native_kernel=False --ip=0.0.0.0" fi</code> </pre><br>  Kemampuan untuk memulai wadah Docker Jupyter dari wadah Docker JupyterHub dicapai dengan memasang soket daemon Docker di wadah JupyterHub. <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-&lt;b&gt;v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z&lt;/b&gt; -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre><br>  Di masa depan, direncanakan untuk meninggalkan keputusan ini demi, misalnya, ssh. <br><br>  Saat menggunakan DockerSpawner bersama dengan Spark, masalah lain muncul: driver Spark membuka port acak, di mana Pekerja kemudian membuat koneksi eksternal.  Kami dapat mengontrol rentang nomor port yang dipilih secara acak dengan mengatur rentang ini dalam konfigurasi Spark.  Namun, rentang ini harus berbeda untuk pengguna yang berbeda, karena kami tidak dapat menjalankan wadah Jupyter dengan port yang diterbitkan sama.  Untuk mengatasi masalah ini, kode ditulis yang hanya menghasilkan rentang port oleh id pengguna dari basis data JupyterHub dan meluncurkan wadah Docker dan Spark dengan konfigurasi yang sesuai: <br><br>  <b>aset / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">def set_extra_create_kwargs(self):       user_spark_driver_port, user_spark_blockmanager_port, user_spark_ui_port, user_spark_max_retries = self.get_spark_ports()       if user_spark_driver_port == 0 or user_spark_blockmanager_port == 0 or user_spark_ui_port == 0 or user_spark_max_retries == 0:           return       ports = {}       for p in range(user_spark_driver_port, user_spark_driver_port + user_spark_max_retries):           ports['%d/tcp' % p] = None       for p in range(user_spark_blockmanager_port, user_spark_blockmanager_port + user_spark_max_retries):           ports['%d/tcp' % p] = None       for p in range(user_spark_ui_port, user_spark_ui_port + user_spark_max_retries):           ports['%d/tcp' % p] = None self.extra_create_kwargs = { 'ports' : ports }</code> </pre><br>  Kerugian dari solusi ini adalah bahwa ketika Anda me-restart wadah dengan JupyterHub, semuanya berhenti berfungsi karena kehilangan basis data.  Karena itu, ketika Anda me-restart JupyterHub untuk, misalnya, perubahan konfigurasi, kami tidak menyentuh wadah itu sendiri, tetapi hanya me-restart proses JupyterHub di dalamnya. <br><br>  <b>restart-hub.sh</b> <br><br><pre> <code class="plaintext hljs">#!/bin/bash docker ps | fgrep 'dsai1.2' | fgrep -v 'jupyter-' | awk '{ print $1; }' | while read ID; do docker exec $ID /bin/bash -c "kill \$( cat /root/jupyterhub.pid )"; done</code> </pre><br>  Cgroups sendiri dibuat oleh alat Linux standar, korespondensi antara entitas AD dan cgroups dalam konfigurasi terlihat seperti ini. <br><br><pre> <code class="plaintext hljs">&lt;b&gt;config-example/jupyterhub/jupyterhub_config.py&lt;/b&gt; c.DSAISpawner.user_cgroup_parent = {   'bank\\user1'    : '/jupyter-cgroup-1', # user 1   'bank\\user2'    : '/jupyter-cgroup-1', # user 2   'bank\\user3'    : '/jupyter-cgroup-2', # user 3 } c.DSAISpawner.cgroup_parent = '/jupyter-cgroup-3'</code> </pre><br><h3>  Kode git </h3><br>  Solusi kami tersedia untuk umum di GitHub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://github.com/DS-AI/dsai/</a> (DSAI - Ilmu Data dan Kecerdasan Buatan).  Semua kode diatur dalam direktori dengan nomor seri - kode dari setiap direktori selanjutnya dapat menggunakan artefak dari yang sebelumnya.  Hasil kode dari direktori terakhir adalah gambar Docker. <br><br>  Setiap direktori berisi file: <br><br><ul><li>  assets.sh - pembuatan artefak yang diperlukan untuk perakitan (mengunduh dari Internet atau menyalin dari direktori langkah sebelumnya) <br></li><li>  build.sh - build <br></li><li>  clean.sh - artefak pembersih yang diperlukan untuk perakitan <br></li></ul><br>  Untuk benar-benar membangun kembali gambar Docker, perlu untuk menjalankan clean.sh, assets.sh, build.sh dari direktori sesuai dengan nomor seri mereka. <br><br>  Untuk perakitan, kami menggunakan mesin dengan Linux RedHat 7.4, Docker 17.05.0-ce.  Mesin ini memiliki 8 core, 32GB RAM dan 250GB ruang disk.  Sangat disarankan agar Anda tidak menggunakan host dengan pengaturan RAM dan HDD terburuk untuk membangunnya. <br><br>  Ini adalah bantuan untuk nama-nama yang digunakan: <br><br><ul><li>  01-spark-patched - RPM Spark 1.6.1 dengan dua patch diterapkan SPARK-4563 dan SPARK-19019. <br></li><li>  02-validator - validator parsel <br></li><li>  03-anaconda-dsai-parcel-1.0 - parcel Anaconda dengan Python yang tepat (2, 3.5 dan 3.6) <br></li><li>  04-cloudera-manager-api - Perpustakaan Cloudera Manager API <br></li><li>  05-dsai1.2-offline - gambar akhir <br></li></ul><br>  Sayangnya, rakitan mungkin macet karena alasan yang tidak dapat kami perbaiki (misalnya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tar dijatuhkan</a> saat perakitan parsel. Dalam kasus ini, Anda hanya perlu me-restart perakitan, tetapi ini tidak selalu membantu (misalnya, bilah percikan bergantung pada sumber daya eksternal) Cloudera, yang mungkin tidak lagi tersedia, dll.). <br><br>  Kelemahan lainnya adalah rakitan paket tidak dapat direproduksi.  Karena perpustakaan terus diperbarui, pengulangan perakitan dapat memberikan hasil yang berbeda dari yang sebelumnya. <br><br><h2>  Final akbar </h2><br>  Sekarang pengguna berhasil menggunakan alat, jumlah mereka telah melampaui beberapa lusin dan terus bertambah.  Di masa depan, kami berencana untuk mencoba JupyterLab dan berpikir untuk menghubungkan GPU ke cluster, karena sekarang sumber daya komputasi dari dua server aplikasi yang cukup kuat tidak lagi cukup. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id443294/">https://habr.com/ru/post/id443294/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id443280/index.html">Kisah bagaimana saya merakit home theater 120 inci dari pipa, tali, layar lipat dan beludru hitam</a></li>
<li><a href="../id443282/index.html">Apa yang harus kita bangun dengan blockchain?</a></li>
<li><a href="../id443284/index.html">Indeks dalam PostgreSQL - 4 (Btree)</a></li>
<li><a href="../id443286/index.html">TDMS Fairway. Mekanisme pengisian otomatis untuk prasasti utama pada gambar dan detail dokumen</a></li>
<li><a href="../id443290/index.html">Zen Erlang [dan Elixir - sekitar. penerjemah]</a></li>
<li><a href="../id443298/index.html">Pengisian nirkabel. Bagaimana cara kerjanya dalam praktik</a></li>
<li><a href="../id443300/index.html">Bagaimana perkembangannya di United Traders</a></li>
<li><a href="../id443302/index.html">Bagaimana Apple mempersiapkan era setelah iPhone</a></li>
<li><a href="../id443306/index.html">Delapan Hukum Penamaan dalam Desain UX (Bagian 1)</a></li>
<li><a href="../id443308/index.html">Mitos fisika modern. Hukum konservasi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
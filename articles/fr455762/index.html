<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêè üßìüèæ ü§¥üèº Une br√®ve introduction aux cha√Ænes de Markov üîè ü§∑üèæ üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En 1998, Lawrence Page, Sergey Brin, Rajiv Motwani et Terry Vinograd ont publi√© l'article ¬´The PageRank Citation Ranking: Bringing Order to the Web¬ª, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Une br√®ve introduction aux cha√Ænes de Markov</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455762/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif" alt="image"></div><br>  En 1998, Lawrence Page, Sergey Brin, Rajiv Motwani et Terry Vinograd ont publi√© l'article ¬´The PageRank Citation Ranking: Bringing Order to the Web¬ª, qui d√©crivait le d√©sormais c√©l√®bre algorithme PageRank, qui est devenu le fondement de Google.  Apr√®s un peu moins de deux d√©cennies, Google est devenu un g√©ant, et m√™me si son algorithme a beaucoup √©volu√©, le PageRank est toujours le ¬´symbole¬ª des algorithmes de classement de Google (bien que seules quelques personnes puissent vraiment dire combien de poids il prend dans l'algorithme aujourd'hui) . <br><br>  D'un point de vue th√©orique, il est int√©ressant de noter que l'une des interpr√©tations standard de l'algorithme PageRank est bas√©e sur un concept simple mais fondamental des cha√Ænes de Markov.  √Ä partir de l'article, nous verrons que les cha√Ænes de Markov sont de puissants outils de mod√©lisation stochastique qui peuvent √™tre utiles √† tout scientifique des donn√©es.  En particulier, nous r√©pondrons √† ces questions fondamentales: quelles sont les cha√Ænes de Markov, quelles bonnes propri√©t√©s poss√®dent-elles et que peut-on faire avec leur aide? <br><a name="habracut"></a><br><h4>  Br√®ve revue </h4><br>  Dans la premi√®re section, nous donnons les d√©finitions de base n√©cessaires √† la compr√©hension des cha√Ænes de Markov.  Dans la deuxi√®me section, nous consid√©rons le cas particulier des cha√Ænes de Markov dans un espace √† √©tats finis.  Dans la troisi√®me section, nous consid√©rons certaines des propri√©t√©s √©l√©mentaires des cha√Ænes de Markov et illustrons ces propri√©t√©s avec de nombreux petits exemples.  Enfin, dans la quatri√®me section, nous associons les cha√Ænes de Markov √† l'algorithme PageRank et voyons avec un exemple artificiel comment les cha√Ænes de Markov peuvent √™tre utilis√©es pour classer les n≈ìuds d'un graphique. <br><br><blockquote>  <strong>Remarque</strong>  La compr√©hension de ce poste n√©cessite une connaissance des bases de la probabilit√© et de l'alg√®bre lin√©aire.  En particulier, les concepts suivants seront utilis√©s: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="noopener">probabilit√© conditionnelle</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="noopener">vecteur propre</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="noopener">formule de probabilit√© compl√®te</a> . </blockquote><br><hr><br><h3>  Quelles sont les cha√Ænes de Markov? </h3><br><h4>  Variables al√©atoires et processus al√©atoires </h4><br>  Avant d'introduire le concept de cha√Ænes de Markov, rappelons bri√®vement les concepts fondamentaux mais importants de la th√©orie des probabilit√©s. <br><br>  Premi√®rement, en dehors du langage des math√©matiques, une <strong>variable al√©atoire</strong> X est une quantit√© qui est d√©termin√©e par le r√©sultat d'un ph√©nom√®ne al√©atoire.  Son r√©sultat peut √™tre un nombre (ou "similitude d'un nombre", par exemple, des vecteurs) ou autre chose.  Par exemple, nous pouvons d√©finir une variable al√©atoire comme le r√©sultat d'un jet de d√© (nombre) ou comme le r√©sultat d'un tirage au sort (pas un nombre, sauf si nous d√©signons, par exemple, "aigle" comme 0, mais "queues" comme 1).  Nous mentionnons √©galement que l'espace des r√©sultats possibles d'une variable al√©atoire peut √™tre discret ou continu: par exemple, une variable al√©atoire normale est continue, et une variable al√©atoire de Poisson est discr√®te. <br><br>  De plus, nous pouvons d√©finir un <strong>processus al√©atoire</strong> (√©galement appel√© stochastique) comme un ensemble de variables al√©atoires index√©es par l'ensemble T, qui d√©note souvent diff√©rents moments dans le temps (dans ce qui suit, nous supposerons cela).  Les deux cas les plus courants: T peut √™tre soit un ensemble de nombres naturels (processus al√©atoire √† temps discret), soit un ensemble de nombres r√©els (processus al√©atoire √† temps continu).  Par exemple, si nous jetons une pi√®ce tous les jours, nous d√©finirons un processus al√©atoire avec une heure discr√®te, et la valeur toujours changeante d'une option sur l'√©change d√©finira un processus al√©atoire avec une heure continue.  Les variables al√©atoires √† diff√©rents moments peuvent √™tre ind√©pendantes les unes des autres (un exemple avec un tirage au sort), ou avoir une sorte de d√©pendance (un exemple avec la valeur de l'option);  de plus, ils peuvent avoir un espace d'√©tat continu ou discret (l'espace des r√©sultats possibles √† chaque instant). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/31e/ada/2f8/31eada2f80d66f0df4c007ec8da11579.jpg"></div><br>  <i>Diff√©rents types de processus al√©atoires (discrets / continus dans l'espace / temps).</i> <br><br><h4>  Propri√©t√© Markov et cha√Æne Markov </h4><br>  Il existe des familles bien connues de processus al√©atoires: processus gaussiens, processus de Poisson, mod√®les autor√©gressifs, mod√®les √† moyenne mobile, cha√Ænes de Markov et autres.  Chacun de ces cas individuels poss√®de certaines propri√©t√©s qui nous permettent de mieux les explorer et les comprendre. <br><br>  L'une des propri√©t√©s qui simplifie consid√©rablement l'√©tude d'un processus al√©atoire est la propri√©t√© Markov.  Si nous l'expliquons dans un langage tr√®s informel, la propri√©t√© Markov nous dit que si nous connaissons la valeur obtenue par un processus al√©atoire √† un moment donn√©, nous ne recevrons aucune information suppl√©mentaire sur le comportement futur du processus, en collectant d'autres informations sur son pass√©.  Dans un langage plus math√©matique: √† tout moment, la distribution conditionnelle des √©tats futurs d'un processus avec des √©tats actuels et pass√©s donn√©s ne d√©pend que de l'√©tat actuel, et non des √©tats pass√©s (la <strong>propri√©t√© du manque de m√©moire</strong> ).  Un processus al√©atoire avec une propri√©t√© Markov est appel√© <strong>processus Markov</strong> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/44f/1ba/f48/44f1baf48ceb669e0416489eea2bae35.png"></div><br>  <i>La propri√©t√© Markov signifie que si nous connaissons l'√©tat actuel √† un moment donn√©, nous n'avons pas besoin d'informations suppl√©mentaires sur l'avenir, collect√©es sur le pass√©.</i> <br><br>  Sur la base de cette d√©finition, nous pouvons formuler la d√©finition de ¬´cha√Ænes de Markov homog√®nes √† temps discret¬ª (ci-apr√®s pour des raisons de simplicit√©, nous les appellerons ¬´cha√Ænes de Markov¬ª).  <strong>La cha√Æne de Markov</strong> est un processus de Markov avec un temps discret et un espace d'√©tat discret.  Ainsi, une cha√Æne de Markov est une s√©quence d'√©tats discrets, dont chacun est extrait d'un espace d'√©tats discrets (fini ou infini), satisfaisant la propri√©t√© de Markov. <br><br>  Math√©matiquement, nous pouvons d√©signer la cha√Æne de Markov comme suit: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/114/3b7/fc3/1143b7fc371f3142534c2b886bf3e69c.png"></div><br>  o√π √† chaque instant le processus prend ses valeurs dans un ensemble discret E, tel que <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/886/a22/d76/886a22d7671798102ee3d94fe9868b81.png"></div><br>  Ensuite, la propri√©t√© Markov implique que nous avons <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/edc/8bf/384/edc8bf38422705e72c9dd7d094b249db.png"></div><br>  Notez √† nouveau que cette derni√®re formule refl√®te le fait que pour la chronologie (o√π je suis maintenant et o√π j'√©tais auparavant) la distribution de probabilit√© de l'√©tat suivant (o√π je serai le prochain) d√©pend de l'√©tat actuel, mais pas des √©tats pass√©s. <br><br><blockquote>  <strong>Remarque</strong>  Dans ce billet introductif, nous avons d√©cid√© de ne parler que de simples cha√Ænes de Markov homog√®nes √† temps discret.  Cependant, il existe √©galement des cha√Ænes de Markov inhomog√®nes (d√©pendantes du temps) et / ou des cha√Ænes √† temps continu.  Dans cet article, nous ne consid√©rerons pas de telles variations du mod√®le.  Il convient √©galement de noter que la d√©finition ci-dessus d'une propri√©t√© de Markov est extr√™mement simplifi√©e: la v√©ritable d√©finition math√©matique utilise le concept de filtrage, qui va bien au-del√† de notre connaissance introductive du mod√®le. </blockquote><br><h4>  Nous caract√©risons la dynamique d'al√©atoire d'une cha√Æne de Markov </h4><br>  Dans la sous-section pr√©c√©dente, nous nous sommes familiaris√©s avec la structure g√©n√©rale correspondant √† toute cha√Æne de Markov.  Voyons ce dont nous avons besoin pour d√©finir une "instance" sp√©cifique d'un tel processus al√©atoire. <br><br>  Tout d'abord, nous notons que la d√©termination compl√®te des caract√©ristiques d'un processus al√©atoire √† temps discret qui ne satisfait pas la propri√©t√© de Markov peut √™tre difficile: la distribution de probabilit√© √† un moment donn√© peut d√©pendre d'un ou de plusieurs moments du pass√© et / ou du futur.  Toutes ces d√©pendances temporelles possibles peuvent potentiellement compliquer la cr√©ation d'une d√©finition de processus. <br><br>  Cependant, en raison de la propri√©t√© Markov, la dynamique de la cha√Æne de Markov est assez simple √† d√©terminer.  Et en effet.  nous devons d√©terminer seulement deux aspects: la <strong>distribution de probabilit√© initiale</strong> (c'est-√†-dire la distribution de probabilit√© au temps n = 0), not√©e par <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/595/90e/140/59590e140cdb348c943d9dcab0ea011d.png"></div><br>  et <strong>la matrice de probabilit√© de transition</strong> (qui nous donne les probabilit√©s que l'√©tat au temps n + 1 soit le suivant pour un autre √©tat au temps n pour n'importe quelle paire d'√©tats), not√© par <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/011/aee/574/011aee5747fe7e42fa09bf044c421e26.png"></div><br>  Si ces deux aspects sont connus, alors la dynamique compl√®te (probabiliste) du processus est clairement d√©finie.  Et en fait, la probabilit√© de tout r√©sultat du processus peut alors √™tre calcul√©e de mani√®re cyclique. <br><br>  Exemple: supposons que nous voulons conna√Ætre la probabilit√© que les 3 premiers √©tats du processus aient des valeurs (s0, s1, s2).  Autrement dit, nous voulons calculer la probabilit√© <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6c5/991/81b/6c599181b1fd3892391711f311878b72.png"></div><br>  Ici, nous appliquons la formule de la probabilit√© totale, qui stipule que la probabilit√© d'obtenir (s0, s1, s2) est √©gale √† la probabilit√© d'obtenir les premiers s0 fois la probabilit√© d'obtenir s1, √©tant donn√© que nous avons pr√©c√©demment obtenu s0 fois la probabilit√© d'obtenir s2 en tenant compte du fait que nous avons obtenu plus t√¥t dans l'ordre s0 et s1.  Math√©matiquement, cela peut √™tre √©crit comme <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a46/da3/64f/a46da364f28d5b69055700759db02663.png"></div><br>  Et puis la simplification est r√©v√©l√©e, d√©termin√©e par l'hypoth√®se de Markov.  Et en fait, dans le cas des cha√Ænes longues, on obtient des probabilit√©s fortement conditionnelles pour ces derniers √©tats.  Cependant, dans le cas des cha√Ænes de Markov, nous pouvons simplifier cette expression en profitant du fait que <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/7f6/568/0ab7f6568e28bb562ebb287252422d51.png"></div><br>  obtenir de cette fa√ßon <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b6c/700/30a/b6c70030a8627d87c39dab96c147513a.png"></div><br>  Puisqu'ils caract√©risent pleinement la dynamique probabiliste du processus, de nombreux √©v√©nements complexes ne peuvent √™tre calcul√©s que sur la base de la distribution de probabilit√© initiale q0 et de la matrice de probabilit√© de transition p.  Il convient √©galement de mentionner un autre lien de base: l'expression de la distribution de probabilit√© au temps n + 1, exprim√©e par rapport √† la distribution de probabilit√© au temps n <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5ae/f31/a8a/5aef31a8ae120a25e5b43d6534dc20ff.png"></div><br><h3>  Cha√Ænes de Markov dans les espaces d'√©tats finis </h3><br><h4>  Repr√©sentation matricielle et graphique </h4><br>  Ici, nous supposons que l'ensemble E a un nombre fini d'√©tats possibles N: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d57/788/f81/d57788f81d0a92aa1d94ef572bdf25e3.png"></div><br>  Ensuite, la distribution de probabilit√© initiale peut √™tre d√©crite comme <strong>un vecteur ligne</strong> q0 de taille N, et les probabilit√©s de transition peuvent √™tre d√©crites comme une matrice p de taille N par N, de telle sorte que <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/100/6f8/6ae/1006f86aeff6699711058bd890190917.png"></div><br>  L'avantage de cette notation est que si nous notons la distribution de probabilit√© √† l'√©tape n par le vecteur ligne qn tel que ses composantes sont sp√©cifi√©es <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/006/19b/4ae/00619b4ae1601eacdb8fd7ce248f1738.png"></div><br>  alors les relations matricielles simples sont pr√©serv√©es <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a12/cdc/a7b/a12cdca7b75ef09ceaacef33a3667549.png"></div><br>  (ici nous ne consid√©rerons pas la preuve, mais il est tr√®s simple de la reproduire). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23c/3c6/a10/23c3c6a102bd7aa079c36a75f60a5e42.png"></div><br>  <i>Si nous multiplions le vecteur ligne √† droite, qui d√©crit la distribution de probabilit√© √† un moment donn√©, par la matrice de probabilit√© de transition, alors nous obtenons la distribution de probabilit√© au stade suivant.</i> <br><br>  Ainsi, comme nous le voyons, la transition de la distribution de probabilit√© d'un stade donn√© au suivant est simplement d√©finie comme la multiplication correcte du vecteur ligne de probabilit√©s de l'√©tape initiale par la matrice p.  De plus, cela implique que nous avons <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/35b/072/e0c/35b072e0c74397094e5bf6a9dab11417.png"></div><br>  La dynamique al√©atoire d'une cha√Æne de Markov dans un espace d'√©tats finis peut facilement √™tre repr√©sent√©e comme un graphe orient√© normalis√© de telle sorte que chaque n≈ìud du graphe est un √©tat, et pour chaque paire d'√©tats (ei, ej) il existe un bord allant de ei √† ej si p (ei, ej )&gt; 0.  La valeur de bord sera alors la m√™me probabilit√© p (ei, ej). <br><br><h4>  Exemple: un lecteur de notre site </h4><br>  Illustrons tout cela avec un exemple simple.  Consid√©rez le comportement quotidien d'un visiteur fictif sur un site.  Chaque jour, il a 3 conditions possibles: le lecteur ne visite pas le site ce jour-l√† (N), le lecteur visite le site, mais ne lit pas l'int√©gralit√© du post (V), et le lecteur visite le site et lit un post entier (R).  Nous avons donc l'espace d'√©tat suivant: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/242/b1c/627/242b1c62745a4a13f2a24b8f919c6820.png"></div><br>  Supposons que le premier jour, ce lecteur ait 50% de chances d'acc√©der uniquement au site et 50% de chances de visiter le site et de lire au moins un article.  Le vecteur d√©crivant la distribution de probabilit√© initiale (n = 0) ressemble alors √† ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/362/a5a/045/362a5a0455c939f9d855d65605945c90.png"></div><br>  Imaginez √©galement que les probabilit√©s suivantes sont observ√©es: <br><br><ul><li>  lorsque le lecteur ne visite pas un jour, il y a une probabilit√© de 25% de ne pas lui rendre visite le lendemain, une probabilit√© de 50% seulement de lui rendre visite et de 25% de visiter et de lire l'article </li><li>  lorsque le lecteur visite le site un jour, mais ne lit pas, il a 50% de chances de le visiter √† nouveau le lendemain sans lire l'article, et 50% de chances de visiter et de lire </li><li>  lorsqu'un lecteur visite et lit un article le m√™me jour, il a 33% de chances de ne pas se connecter le lendemain <em>(j'esp√®re que ce message n'aura pas un tel effet!)</em> , 33% de chances de se connecter uniquement au site et 34% de visiter et de relire l'article </li></ul><br>  Ensuite, nous avons la matrice de transition suivante: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cf5/7e6/ba5/cf57e6ba5303d4e13cbb736e6115306d.png"></div><br>  De la sous-section pr√©c√©dente, nous savons comment calculer pour ce lecteur la probabilit√© de chaque √©tat le lendemain (n = 1) <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c64/a77/76c/c64a7776cfc56a5af1a0ccf495469ef7.png"></div><br>  La dynamique probabiliste de cette cha√Æne de Markov peut √™tre repr√©sent√©e graphiquement comme suit: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/832/797/9a1/8327979a1aa6edd9d462a0b40a4c072d.png"></div><br>  <i>Pr√©sentation sous forme de graphique de la cha√Æne de Markov, mod√©lisant le comportement de notre visiteur invent√© sur le site.</i> <br><br><h3>  Propri√©t√©s des cha√Ænes de Markov </h3><br>  Dans cette section, nous ne parlerons que de certaines des propri√©t√©s ou caract√©ristiques les plus fondamentales des cha√Ænes de Markov.  Nous n'entrerons pas dans les d√©tails math√©matiques, mais fournirons un bref aper√ßu des points int√©ressants qui doivent √™tre √©tudi√©s pour utiliser les cha√Ænes de Markov.  Comme nous l'avons vu, dans le cas d'un espace √† √©tats finis, la cha√Æne de Markov peut √™tre repr√©sent√©e sous forme de graphe.  √Ä l'avenir, nous utiliserons la repr√©sentation graphique pour expliquer certaines propri√©t√©s.  Cependant, n'oubliez pas que ces propri√©t√©s ne sont pas n√©cessairement limit√©es au cas d'un espace d'√©tats fini. <br><br><h4>  D√©composabilit√©, p√©riodicit√©, irr√©vocabilit√© et r√©cup√©rabilit√© </h4><br>  Dans cette sous-section, commen√ßons par plusieurs fa√ßons classiques de caract√©riser un √©tat ou une cha√Æne de Markov enti√®re. <br><br>  Tout d'abord, nous mentionnons que la cha√Æne de Markov est <strong>ind√©composable</strong> s'il est possible d'atteindre n'importe quel √©tat √† partir de n'importe quel autre √©tat (ce n'est pas n√©cessaire qu'en une seule √©tape de temps).  Si l'espace d'√©tat est fini et que la cha√Æne peut √™tre repr√©sent√©e sous forme de graphe, alors nous pouvons dire que le graphe d'une cha√Æne de Markov ind√©composable est fortement connect√© (th√©orie des graphes). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cef/a39/05c/cefa3905cced27b4e27a4e9547fbe846.png"></div><br>  <i>Illustration de la propri√©t√© de l'ind√©composabilit√© (irr√©ductibilit√©).</i>  <i>La cha√Æne de gauche ne peut pas √™tre raccourcie: √† partir de 3 ou 4, nous ne pouvons pas entrer dans 1 ou 2. La cha√Æne de droite (un bord est ajout√©) peut √™tre raccourcie: chaque √©tat peut √™tre atteint √† partir de n'importe quel autre.</i> <br><br>  Un √©tat a une p√©riode k si, √† sa sortie, pour tout retour √† cet √©tat, le nombre de pas de temps est un multiple de k (k est le plus grand diviseur commun de toutes les longueurs possibles de chemins de retour).  Si k = 1, alors ils disent que l'√©tat est ap√©riodique, et toute la cha√Æne de Markov est <strong>ap√©riodique</strong> si tous ses √©tats sont ap√©riodiques.  Dans le cas d'une cha√Æne de Markov irr√©ductible, on peut √©galement mentionner que si un √©tat est ap√©riodique, alors tous les autres sont √©galement ap√©riodiques. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cbe/65f/a07/cbe65fa07e7b816d385408824ba0ff39.png"></div><br>  <i>Illustration de la propri√©t√© de p√©riodicit√©.</i>  <i>La cha√Æne de gauche est p√©riodique avec k = 2: lorsque vous quittez un √©tat, y revenir n√©cessite toujours le nombre de pas multiple de 2. La cha√Æne de droite a une p√©riode de 3.</i> <br><br>  Un √©tat est <strong>irr√©vocable</strong> si, √† sa sortie, il y a une probabilit√© non nulle que nous n'y revenions jamais.  Inversement, un √©tat est consid√©r√© comme <strong>retournable</strong> si nous savons qu'apr√®s avoir quitt√© l'√©tat, nous pouvons y revenir √† l'avenir avec la probabilit√© 1 (s'il n'est pas irr√©vocable). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6a0/1ad/7b0/6a01ad7b05e96f5a6606a8a48d127233.png"></div><br>  <i>Illustration de la propri√©t√© de retour / irr√©vocabilit√©.</i>  <i>La cha√Æne de gauche a les propri√©t√©s suivantes: 1, 2 et 3 sont irr√©vocables (en quittant ces points, nous ne pouvons pas √™tre absolument s√ªrs que nous y reviendrons) et ont une p√©riode de 3, et 4 et 5 sont retournables (en quittant ces points, nous sommes absolument s√ªrs un jour, nous y reviendrons) et avons une p√©riode de 2. La cha√Æne de droite a une autre nervure, ce qui rend la cha√Æne enti√®re retournable et ap√©riodique.</i> <br><br>  Pour l'√©tat de retour, nous pouvons calculer le temps de retour moyen, qui est le <strong>temps de retour attendu</strong> en quittant l'√©tat.  Notez que m√™me la probabilit√© d'un retour est 1, cela ne signifie pas que le temps de retour attendu est fini.  Par cons√©quent, parmi tous les √©tats de retour, nous pouvons distinguer <strong>les √©tats de retour positifs</strong> (avec un temps de retour attendu fini) et les <strong>√©tats de retour z√©ro</strong> (avec un temps de retour attendu infini). <br><br><h4>  Distribution stationnaire, comportement marginal et ergodicit√© </h4><br>  Dans cette sous-section, nous consid√©rons les propri√©t√©s qui caract√©risent certains aspects de la dynamique (al√©atoire) d√©crite par la cha√Æne de Markov. <br><br>  La distribution de probabilit√© œÄ sur l'espace d'√©tat E est appel√©e <strong>distribution stationnaire</strong> si elle satisfait l'expression <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/736/d70/e5d/736d70e5ddfc5aeb788d29ebfa79f9ec.png"></div><br>  Puisque nous avons <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b98/c4e/e6c/b98c4ee6c3b8032b074c7543db816c7e.png"></div><br>  Alors la distribution stationnaire satisfait l'expression <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b8/df4/0a8/2b8df40a8a9a2ae90eb49a7c60dafb55.png"></div><br>  Par d√©finition, la distribution de probabilit√© stationnaire ne change pas avec le temps.  Autrement dit, si la distribution initiale q est stationnaire, elle sera la m√™me √† toutes les √©tapes ult√©rieures du temps.  Si l'espace d'√©tat est fini, alors p peut √™tre repr√©sent√© comme une matrice, et œÄ comme un vecteur ligne, puis nous obtenons <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ee0/565/9fc/ee05659fc4ed268ee3189342a76d9311.png"></div><br>  Cela exprime √† nouveau le fait que la distribution de probabilit√© stationnaire ne change pas avec le temps (comme nous le voyons, multiplier la distribution de probabilit√© √† droite par p nous permet de calculer la distribution de probabilit√© √† l'√©tape suivante du temps).  Gardez √† l'esprit qu'une cha√Æne de Markov ind√©composable a une distribution de probabilit√© stationnaire si et seulement si l'un de ses √©tats est un retour positif. <br><br>  Une autre propri√©t√© int√©ressante li√©e √† la distribution de probabilit√© stationnaire est la suivante.  Si la cha√Æne est un retour positif (c'est-√†-dire qu'il y a une distribution stationnaire) et ap√©riodique, alors, quelles que soient les probabilit√©s initiales, la distribution de probabilit√© de la cha√Æne converge alors que les intervalles de temps tendent vers l'infini: ils disent que la cha√Æne a une <strong>distribution limite</strong> , qui n'est rien d'autre, comme une distribution stationnaire.  En g√©n√©ral, cela peut √™tre √©crit comme ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95b/fb9/1c6/95bfb91c67d024e2df40b0e6dcdaf747.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous soulignons une fois de plus que nous ne faisons aucune hypoth√®se sur la distribution de probabilit√© initiale: la distribution de probabilit√© de la cha√Æne se r√©duit √† une distribution stationnaire (distribution d'√©quilibre de la cha√Æne) quels que soient les param√®tres initiaux. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Enfin, l' </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ergodicit√©</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est une autre propri√©t√© int√©ressante li√©e au comportement de la cha√Æne de Markov. Si la cha√Æne de Markov est ind√©composable, alors on dit aussi qu'elle est ¬´ergodique¬ª car elle satisfait au th√©or√®me ergodique suivant. Supposons que nous ayons une fonction f (.) Qui va de l'espace d'√©tat E √† l'axe (cela peut √™tre, par exemple, le prix d'√™tre dans chaque √©tat). Nous pouvons d√©terminer la valeur moyenne qui d√©place cette fonction le long d'une trajectoire donn√©e (moyenne temporelle). Pour les n√®mes premiers termes, cela est not√© comme</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/af1/8c5/4a3/af18c54a3d7dc1e1ad4a4015ab7ad64c.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> On peut √©galement calculer la valeur moyenne de la fonction f sur l'ensemble E, pond√©r√©e par la distribution stationnaire (moyenne spatiale), qui est not√©e </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/04a/352/c77/04a352c77b0687ef3cc89f3b7e0edf38.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le th√©or√®me ergodique nous dit alors que lorsque la trajectoire devient infiniment longue, la moyenne temporelle est √©gale √† la moyenne spatiale (pond√©r√©e par la distribution stationnaire). </font><font style="vertical-align: inherit;">La propri√©t√© ergodicity peut s'√©crire comme suit:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/37d/c4d/6cb37dc4dcf0a3e53cc8e6baec8f4b1a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En d'autres termes, cela signifie que dans la limite ant√©rieure, le comportement de la trajectoire devient insignifiant et seul le comportement stationnaire √† long terme est important lors du calcul de la moyenne temporelle. </font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Revenons √† l'exemple avec le lecteur de site </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Encore une fois, consid√©rons l'exemple du lecteur de site. </font><font style="vertical-align: inherit;">Dans cet exemple simple, il est √©vident que la cha√Æne est ind√©composable, ap√©riodique et que tous ses √©tats sont positivement retournables. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour montrer quels r√©sultats int√©ressants peuvent √™tre calcul√©s √† l'aide des cha√Ænes de Markov, nous consid√©rons le temps moyen de retour √† l'√©tat R (l'√©tat ¬´visite le site et lit l'article¬ª). </font><font style="vertical-align: inherit;">En d'autres termes, nous voulons r√©pondre √† la question suivante: si notre lecteur visite un jour le site et lit un article, alors combien de jours devra-t-il attendre en moyenne pour qu'il revienne lire l'article? </font><font style="vertical-align: inherit;">Essayons d'obtenir un concept intuitif de la fa√ßon dont cette valeur est calcul√©e. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On note d'abord</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a2/57c/c74/2a257cc74db27e5ac89ffc1e06bd9ed9.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous voulons donc calculer m (R, R). </font><font style="vertical-align: inherit;">En parlant du premier intervalle atteint apr√®s avoir quitt√© R, on obtient</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f9/e1a/a6e/4f9e1aa6e04e736fde182693398a4dca.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cependant, cette expression n√©cessite que pour le calcul de m (R, R) nous connaissions m (N, R) et m (V, R). </font><font style="vertical-align: inherit;">Ces deux quantit√©s peuvent √™tre exprim√©es de mani√®re similaire:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e23/7cb/f2d/e237cbf2d81597544f800d38b5a59e91.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, nous avons obtenu 3 √©quations avec 3 inconnues et apr√®s les avoir r√©solues, nous obtenons m (N, R) = 2,67, m (V, R) = 2,00 et m (R, R) = 2,54. </font><font style="vertical-align: inherit;">Le temps moyen pour revenir √† l'√©tat R est alors de 2,54. </font><font style="vertical-align: inherit;">Autrement dit, en utilisant l'alg√®bre lin√©aire, nous avons pu calculer le temps moyen de retour √† l'√©tat R (ainsi que le temps de transition moyen de N √† R et le temps de transition moyen de V √† R). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour terminer avec cet exemple, voyons quelle sera la distribution stationnaire de la cha√Æne de Markov. </font><font style="vertical-align: inherit;">Pour d√©terminer la distribution stationnaire, nous devons r√©soudre l'√©quation d'alg√®bre lin√©aire suivante:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb3/73d/068/bb373d068a04d681c0501d8276731c0a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Autrement dit, nous devons trouver le vecteur propre gauche p associ√© au vecteur propre 1. En r√©solvant ce probl√®me, nous obtenons la distribution stationnaire suivante: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0c6/abe/19e/0c6abe19e37b67af5f380eb3e5c0beb9.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Distribution stationnaire dans l'exemple avec le lecteur de site. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez √©galement remarquer que œÄ (R) = 1 / m (R, R), et si un peu de r√©flexion, alors cette identit√© est tout √† fait logique (mais nous n'en parlerons pas en d√©tail).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La cha√Æne √©tant ind√©composable et ap√©riodique, cela signifie qu'√† long terme la distribution de probabilit√© converge vers une distribution stationnaire (pour tous les param√®tres initiaux). En d'autres termes, quel que soit l'√©tat initial du lecteur du site, si nous attendons assez longtemps et s√©lectionnons un jour au hasard, nous aurons la probabilit√© œÄ (N) que le lecteur ne visitera pas le site ce jour-l√†, la probabilit√© œÄ (V) que le lecteur s'arr√™tera mais ne lira pas l'article, et la probabilit√© est œÄ¬Æ que le lecteur s'arr√™te et lise l'article. Pour mieux comprendre la propri√©t√© de la convergence, regardons le graphique suivant montrant l'√©volution des distributions de probabilit√© √† partir de diff√©rents points de d√©part et convergeant (rapidement) vers une distribution stationnaire:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/128/58e/a88/12858ea88a0e3bd05950b9d30096b776.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualisation de la convergence de 3 distributions de probabilit√© avec diff√©rents param√®tres initiaux (bleu, orange et vert) vers la distribution stationnaire (rouge).</font></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exemple classique: algorithme de PageRank </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il est temps de revenir au PageRank! </font><font style="vertical-align: inherit;">Mais avant de poursuivre, il convient de mentionner que l'interpr√©tation du PageRank donn√©e dans cet article n'est pas la seule possible, et les auteurs de l'article d'origine ne se sont pas n√©cessairement appuy√©s sur l'utilisation de cha√Ænes de Markov pour d√©velopper la m√©thodologie. </font><font style="vertical-align: inherit;">Cependant, notre interpr√©tation est bonne car elle est tr√®s claire.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Utilisateur Web arbitraire </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank essaie de r√©soudre le probl√®me suivant: comment pouvons-nous classer un ensemble existant (nous pouvons supposer que cet ensemble a d√©j√† √©t√© filtr√©, par exemple, par une requ√™te) en utilisant des liens d√©j√† existants entre les pages? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour r√©soudre ce probl√®me et pouvoir classer les pages, PageRank effectue approximativement le processus suivant. Nous pensons qu'un internaute arbitraire √† la premi√®re fois est sur l'une des pages. Ensuite, cet utilisateur commence √† se d√©placer au hasard, en cliquant sur chaque page sur l'un des liens qui m√®nent √† une autre page de l'ensemble en question (il est suppos√© que tous les liens menant en dehors de ces pages sont interdits). Sur n'importe quelle page, tous les liens valides ont la m√™me probabilit√© de cliquer.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est ainsi que nous d√©finissons la cha√Æne de Markov: les pages sont des √©tats possibles, les probabilit√©s de transition sont d√©finies par des liens de page en page (pond√©r√©s de telle sorte que sur chaque page toutes les pages li√©es ont la m√™me probabilit√© de s√©lection), et les propri√©t√©s du manque de m√©moire sont clairement d√©termin√©es par le comportement de l'utilisateur. Si nous supposons √©galement que la cha√Æne donn√©e est retournable positivement et ap√©riodique (de petites astuces sont utilis√©es pour satisfaire ces exigences), alors √† long terme, la distribution de probabilit√© de la ¬´page actuelle¬ª converge vers une distribution stationnaire. Autrement dit, quelle que soit la page initiale, apr√®s une longue p√©riode, chaque page a une probabilit√© (presque fixe) de devenir actuelle si nous choisissons un moment al√©atoire dans le temps.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le PageRank est bas√© sur l'hypoth√®se suivante: les pages les plus probables d'une distribution stationnaire devraient √©galement √™tre les plus importantes (nous visitons souvent ces pages parce qu'elles obtiennent des liens de pages qui sont √©galement fr√©quemment visit√©es pendant les transitions). </font><font style="vertical-align: inherit;">Ensuite, la distribution de probabilit√© stationnaire d√©termine la valeur du PageRank pour chaque √©tat.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exemple artificiel </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour rendre cela beaucoup plus clair, regardons un exemple artificiel. </font><font style="vertical-align: inherit;">Supposons que nous ayons un petit site Web de 7 pages, libell√© de 1 √† 7, et que les liens entre ces pages correspondent √† la colonne suivante.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par souci de clart√©, les probabilit√©s de chaque transition dans l'animation ci-dessus ne sont pas affich√©es. </font><font style="vertical-align: inherit;">Cependant, comme on suppose que la ¬´navigation¬ª doit √™tre exclusivement al√©atoire (c'est ce qu'on appelle ¬´marche al√©atoire¬ª), les valeurs peuvent √™tre facilement reproduites √† partir de la r√®gle simple suivante: pour un site avec K liens sortants (page avec K liens vers d'autres pages), la probabilit√© de chaque lien sortant √©gal √† 1 / K. </font><font style="vertical-align: inherit;">Autrement dit, la matrice de probabilit√© de transition a la forme:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b30/3ec/a66/b303eca66763a4187d027842214ff529.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π les valeurs de 0,0 sont remplac√©es par commodit√© par ".". </font><font style="vertical-align: inherit;">Avant d'effectuer d'autres calculs, nous pouvons remarquer que cette cha√Æne de Markov est ind√©composable et ap√©riodique, c'est-√†-dire qu'√† long terme le syst√®me converge vers une distribution stationnaire. </font><font style="vertical-align: inherit;">Comme nous l'avons vu, cette distribution stationnaire peut √™tre calcul√©e en r√©solvant le probl√®me de vecteur propre gauche suivant</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e2f/8da/687/e2f8da6879f6f19fdc921803c8c7e371.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ce faisant, nous obtenons les valeurs de PageRank suivantes (valeurs de distribution stationnaires) pour chaque page </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a8/b69/a5b/0a8b69a5b2916bca1f5fa45955af1b4b.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Valeurs de PageRank calcul√©es pour notre exemple artificiel de 7 pages. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ensuite, le classement PageRank de ce petit site Web est 1&gt; 7&gt; 4&gt; 2&gt; 5 = 6&gt; 3.</font></font><br><br><hr><br><h3>  Conclusions </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Principales conclusions de cet article: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> les processus al√©atoires sont des ensembles de variables al√©atoires qui sont souvent index√©es par le temps (les indices indiquent souvent un temps discret ou continu) </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour un processus al√©atoire, la propri√©t√© de Markov signifie que pour un courant donn√©, la probabilit√© de l'avenir ne d√©pend pas du pass√© (cette propri√©t√© est aussi appel√©e ¬´manque de m√©moire¬ª) </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> cha√Æne de Markov √† temps discret est des processus al√©atoires avec des indices √† temps discret satisfaisant la propri√©t√© de Markov </font></font></li><li>                 (  ,  ‚Ä¶) </li><li>     PageRank ( )    -,       ;          ( ,             ,  ,      ) </li></ul><br>     ,         ,    .         , ,    (   ,             ,     ),   (   -            ),   (   ),   (           ),     . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien s√ªr, les √©normes opportunit√©s offertes par les cha√Ænes de Markov du point de vue de la mod√©lisation et du calcul sont beaucoup plus larges que celles consid√©r√©es dans cette modeste revue. </font><font style="vertical-align: inherit;">Par cons√©quent, nous esp√©rons avoir pu susciter l'int√©r√™t du lecteur √† poursuivre l'√©tude de ces outils, qui occupent une place importante dans l'arsenal d'un scientifique et expert en donn√©es.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455762/">https://habr.com/ru/post/fr455762/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455746/index.html">Celesta 7.x: ORM, migration et test ¬´dans un seul paquet¬ª</a></li>
<li><a href="../fr455754/index.html">Tests d'un stratostat d√©rivant. Lancement de Rogozin et LoRa dans la stratosph√®re</a></li>
<li><a href="../fr455756/index.html">Est [favor] e</a></li>
<li><a href="../fr455758/index.html">Hacking de croissance chez Retail Rocket: de la recherche d'hypoth√®ses aux techniques de test</a></li>
<li><a href="../fr455760/index.html">La magie de SwiftUI ou sur les constructeurs de fonctions</a></li>
<li><a href="../fr455764/index.html">Recherche de codes √† barres extr√™mement pr√©cise, rapide et l√©g√®re gr√¢ce √† la segmentation s√©mantique</a></li>
<li><a href="../fr455768/index.html">Facteurs SEO essentiels sur site</a></li>
<li><a href="../fr455770/index.html">AERODISK: attente vs r√©alit√©</a></li>
<li><a href="../fr455774/index.html">Moteurs de turbines √† gaz pour a√©ronefs</a></li>
<li><a href="../fr455784/index.html">En raison de ce que le gris fonc√© est plus clair que le gris en CSS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõê ü§ó ü§∏üèæ Crear un bot para participar en AI mini cup 2018 basado en una red neuronal recurrente (parte 2) ‚úãüèΩ üßëüèª‚Äçü§ù‚Äçüßëüèª üßúüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta es una continuaci√≥n de la primera parte del art√≠culo. 


 En la primera parte del art√≠culo, el autor habl√≥ sobre las condiciones del concurso par...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Crear un bot para participar en AI mini cup 2018 basado en una red neuronal recurrente (parte 2)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417657/"><p><img src="https://habrastorage.org/webt/of/tw/ke/oftwke-wbh5-w_nlsm_p5rmhano.jpeg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Esta es una continuaci√≥n de la primera parte del art√≠culo.</a> </p><br><p> En la primera parte del art√≠culo, el autor habl√≥ sobre las condiciones del concurso para el juego Agario en mail.ru, la estructura del mundo del juego y parcialmente sobre la estructura del bot.  En parte, porque solo afectaron el dispositivo de los sensores de entrada y los comandos a la salida de la red neuronal (en adelante, en im√°genes y texto, habr√° una abreviatura NN).  As√≠ que intentemos abrir la caja negra y entender c√≥mo se organiza todo all√≠. </p><a name="habracut"></a><br><p>  Y aqu√≠ est√° la primera foto: </p><br><p><img src="https://habrastorage.org/webt/v2/pb/_s/v2pb_sha05gqjtqcqp9bv5mnm0o.jpeg"></p><br><p>  Representa esquem√°ticamente lo que deber√≠a causar una sonrisa aburrida de mi lector, dicen nuevamente en primer grado, se les ha visto muchas veces en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">varias fuentes</a> .  Pero realmente queremos aplicar pr√°cticamente esta imagen a la administraci√≥n del bot, por lo que despu√©s de la Nota importante, la examinamos m√°s de cerca. </p><br><p>  <strong>Nota importante:</strong> hay una gran cantidad de soluciones preparadas (frameworks) para trabajar con redes neuronales: </p><br><p><img src="https://habrastorage.org/webt/jt/il/97/jtil97rhtusvazj6iared1q_hnc.png"></p><br><p>  Todos estos paquetes resuelven las tareas principales para el desarrollador de redes neuronales: la construcci√≥n y capacitaci√≥n de NN o la b√∫squeda de pesos "√≥ptimos".  Y el m√©todo principal de esta b√∫squeda es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Backpropagation</a> .  Fue inventado en los a√±os 70 del siglo pasado, como lo indica el art√≠culo en el enlace anterior, durante este tiempo, como la parte inferior del barco, ha adquirido varias mejoras, pero la esencia es la misma: encontrar coeficientes de peso con una base de ejemplos de entrenamiento y es altamente deseable que todos de estos ejemplos conten√≠a una respuesta preparada en forma de una se√±al de salida de una red neuronal.  El lector puede objetarme.  que las redes de autoaprendizaje de varias clases y principios ya se han inventado, pero todo no est√° yendo bien all√≠, por lo que yo entiendo.  Por supuesto, hay planes para estudiar este zool√≥gico con m√°s detalle, pero creo que encontrar√© personas con ideas afines de que una bicicleta hecha a medida, incluso la m√°s curva, est√° m√°s cerca del coraz√≥n del creador que un clon transportador de una bicicleta ideal. <br>  Entendiendo que el servidor de juegos probablemente no tendr√° estas bibliotecas y la potencia de c√≥mputo asignada por los organizadores como 1 n√∫cleo de procesador claramente no es suficiente para un marco pesado, el autor pas√≥ a crear su propia bicicleta.  Un comentario importante sobre esto termin√≥. </p><br><p>  Volvamos a la imagen que representa probablemente la red neuronal m√°s simple posible con una capa oculta (tambi√©n conocida como capa oculta o capa oculta).  Ahora el propio autor ha mirado fijamente la imagen con ideas sobre este sencillo ejemplo para revelar al lector las profundidades de las redes neuronales artificiales.  Cuando todo se simplifica a lo primitivo, es m√°s f√°cil entender la esencia.  La conclusi√≥n es que la neurona de la capa oculta no tiene nada que resumir.  Y lo m√°s probable es que esto ni siquiera sea una red neuronal, en los libros de texto el NN m√°s simple es una red con dos entradas.  As√≠ que aqu√≠ estamos, por as√≠ decirlo, los descubridores de la m√°s simple de las redes m√°s simples. </p><br><p>  Intentemos describir esta red neuronal (pseudoc√≥digo): <br>  Introducimos la topolog√≠a de la red en forma de matriz, donde cada elemento corresponde a la capa y al n√∫mero de neuronas que contiene: </p><br><p><code>int array Topology= { 1, 1, 1}</code> <br>  Tambi√©n necesitamos una matriz flotante de pesos de la red neuronal W, considerando nuestra red como ‚Äúredes neuronales de alimentaci√≥n hacia adelante (FF o FFNN)‚Äù, donde cada neurona de la capa actual est√° conectada a cada neurona de la capa siguiente, obtenemos la dimensi√≥n de la matriz W [n√∫mero de capas , el n√∫mero de neuronas en la capa, el n√∫mero de neuronas en la capa].  No es la codificaci√≥n √≥ptima, pero dado el aliento de la GPU en alg√∫n lugar muy cercano en el texto, es comprensible. <br>  Un breve procedimiento <code>CalculateSize</code> para contar el n√∫mero de neuronas de <code>neuroncount</code> y el n√∫mero de sus conexiones en la red neuronal de <code>neuroncount</code> , creo que explicar√° mejor al autor la naturaleza de estas conexiones: </p><br><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">void</span></span> CalculateSize(<span class="hljs-keyword"><span class="hljs-keyword">array</span></span> <span class="hljs-type"><span class="hljs-type">int</span></span> Topology, <span class="hljs-type"><span class="hljs-type">int</span></span> neuroncount, <span class="hljs-type"><span class="hljs-type">int</span></span> dendritecount) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> i : Topology) // i         neuroncount += i; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> layer = <span class="hljs-number"><span class="hljs-number">0</span></span>, layer &lt;Topology.Length - <span class="hljs-number"><span class="hljs-number">1</span></span>, layer++) //   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>, i &lt; Topology[layer] + <span class="hljs-number"><span class="hljs-number">1</span></span>, i++) //   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>, j &lt; Topology[layer + <span class="hljs-number"><span class="hljs-number">1</span></span>], j++) //   dendritecount++; }</code> </pre> <br><p>  Mi lector, el que ya sabe todo esto, el autor lleg√≥ a esta opini√≥n en el primer art√≠culo, ciertamente no preguntar√°: por qu√© en el tercer bucle anidado Topolog√≠a [capa1 + 1] en lugar de Topolog√≠a [capa1], que le da m√°s a la neurona que en la topolog√≠a de red .  No voy a responder  Tambi√©n es √∫til para el lector pedir la tarea. </p><br><p>  Estamos casi a un paso de construir una red neuronal que funcione.  Queda por agregar la funci√≥n de sumar las se√±ales en la entrada de la neurona y su activaci√≥n.  Hay muchas funciones de activaci√≥n, pero las m√°s cercanas a la naturaleza de la neurona son Sigmoides y Tangensoides <em>(probablemente sea mejor llamarlo as√≠, aunque este nombre no se usa especialmente en la literatura, el m√°ximo es tangente, pero este es el nombre del gr√°fico, aunque ¬øqu√© es un gr√°fico si no es un reflejo de la funci√≥n?)</em> </p><br><p>  As√≠ que aqu√≠ tenemos las funciones de activaci√≥n neuronal (est√°n presentes en la imagen, en su parte inferior) </p><br><pre> <code class="hljs go">float Sigmoid(float x) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (x &lt; <span class="hljs-number"><span class="hljs-number">-10.0f</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.0f</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (x &gt; <span class="hljs-number"><span class="hljs-number">10.0f</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.0f</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (float)(<span class="hljs-number"><span class="hljs-number">1.0f</span></span> / (<span class="hljs-number"><span class="hljs-number">1.0f</span></span> + expf(-x))); }</code> </pre> <br><p>  Sigmoid devuelve valores de 0 a 1. </p><br><pre> <code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Tanh</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (x &lt; <span class="hljs-number"><span class="hljs-number">-10.0f</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">-1.0f</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (x &gt; <span class="hljs-number"><span class="hljs-number">10.0f</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.0f</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)(tanhf(x)); }</code> </pre> <br><p>  El tangentoide devuelve valores de -1 a 1. </p><br><p>  La idea principal de una se√±al que pasa a trav√©s de una red neuronal es una onda: una se√±al se alimenta a las neuronas de entrada -&gt; a trav√©s de las conexiones neuronales, la se√±al va a la segunda capa -&gt; las neuronas de la segunda capa resumen las se√±ales que las alcanzaron cambiadas por los pesos interneuronales -&gt; se agrega a trav√©s de un peso de polarizaci√≥n adicional usamos la funci√≥n de activaci√≥n-&gt; y wu-al vamos a la siguiente capa (lea el primer ciclo del ejemplo por capas), es decir, repitiendo la cadena desde el principio solo las neuronas de la siguiente capa se convertir√°n en neuronas de entrada.  En simplificaci√≥n, ni siquiera necesita almacenar los valores de las neuronas de toda la red, solo necesita almacenar los pesos NN y los valores de las neuronas de la capa activa. </p><br><p>  Una vez m√°s, enviamos una se√±al a la entrada NN, la onda atraves√≥ las capas y en la capa de salida eliminamos el valor obtenido. </p><br><p>  Aqu√≠, por gusto del lector, es posible resolver mediante programaci√≥n utilizando la recursividad o simplemente un ciclo triple como el del autor, para acelerar los c√°lculos, no es necesario cercar objetos en forma de neuronas y sus conexiones y otras POO.  Nuevamente, esto se debe a la sensaci√≥n de c√°lculos cercanos de GPU, y en las GPU, debido a su naturaleza de paralelismo de masas, OOP se detiene un poco, esto es relativo a c # y C ++. </p><br><p>  Adem√°s, se invita al lector a seguir independientemente el camino para construir una red neuronal en c√≥digo, con su deseo voluntario, cuya ausencia es bastante clara y familiar para el autor, en cuanto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">a ejemplos de construcci√≥n de NN</a> desde cero, hay muchos ejemplos en la red, por lo que ser√° dif√≠cil extraviarse, es as√≠ tan sencillo como una red neuronal de distribuci√≥n directa en la imagen de arriba. </p><br><p>  Pero, ¬ød√≥nde exclamar√° el lector, que a√∫n no se ha apartado del pasaje anterior, y tendr√° raz√≥n, en la infancia, el autor determin√≥ el valor del libro mediante ilustraciones para √©l?  Aqu√≠ tienes </p><br><p><img src="https://habrastorage.org/webt/03/jl/dw/03jldwzryoeaxscxxtfi3deakie.jpeg"></p><br><p>  En la imagen vemos una neurona recurrente y un NN construido a partir de tales neuronas se llama recurrente o RNN.  La red neuronal especificada tiene una memoria a corto plazo y fue seleccionada por el autor para el bot como la m√°s prometedora en t√©rminos de adaptaci√≥n al proceso del juego.  Por supuesto, el autor construy√≥ una red neuronal de distribuci√≥n directa, pero en el proceso de b√∫squeda de una soluci√≥n "efectiva" se cambi√≥ a RNN. </p><br><p>  Una neurona recurrente tiene un estado adicional C, que se forma despu√©s del primer paso de una se√±al a trav√©s de una neurona, Tick + 0 en la l√≠nea de tiempo.  En palabras simples, esta es una copia de la se√±al de salida de una neurona.  En el segundo paso, lea Tick + 1 (dado que la red funciona a la frecuencia del bot y el servidor del juego), el valor C vuelve a la entrada de la capa neural a trav√©s de pesos adicionales y, por lo tanto, participa en la formaci√≥n de la se√±al, pero ya en el momento Tick + 1. </p><br><p>  <em>Nota: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el trabajo de los grupos de investigaci√≥n sobre el manejo de los bots del juego NN</a> , hay una tendencia a usar dos ritmos para una red neuronal, un ritmo es la frecuencia del juego Tick, el segundo ritmo, por ejemplo, es dos veces m√°s lento que el primero.</em>  <em>Las diferentes partes de la NN operan a diferentes frecuencias, lo que brinda una visi√≥n diferente de la situaci√≥n del juego dentro de la NN, lo que aumenta su flexibilidad.</em> </p><br><p>  Para construir RNN en el c√≥digo bot, introducimos una matriz adicional en la topolog√≠a, donde cada elemento corresponde a la capa y al n√∫mero de estados neuronales que contiene: </p><br><p> <code>int array TopologyNN= { numberofSensors, 16, 8, 4}</code> <br> <code>int array TopologyRNN= { 0, 16, 0, 0 }</code> </p> <br><p>  De la topolog√≠a anterior se puede ver que la segunda capa es recurrente, ya que contiene estados neurales.  Tambi√©n presentamos pesos adicionales en forma de flotante de la matriz WRR, la misma dimensi√≥n que la matriz W. </p><br><p>  El recuento de conexiones en nuestra red neuronal cambiar√° un poco: </p><br><pre> <code class="hljs matlab"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int layer = <span class="hljs-number"><span class="hljs-number">0</span></span>, layer &lt; TopologyNN.Length - <span class="hljs-number"><span class="hljs-number">1</span></span>, layer++) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int <span class="hljs-built_in"><span class="hljs-built_in">i</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">i</span></span> &lt; TopologyNN[layer] + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">i</span></span>++) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int <span class="hljs-built_in"><span class="hljs-built_in">j</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">j</span></span> &lt; TopologyNN[layer + <span class="hljs-number"><span class="hljs-number">1</span></span>] , <span class="hljs-built_in"><span class="hljs-built_in">j</span></span>++) dendritecount++; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int layer = <span class="hljs-number"><span class="hljs-number">0</span></span>, layer &lt; TopologyRNN.Length - <span class="hljs-number"><span class="hljs-number">1</span></span>, layer++) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int <span class="hljs-built_in"><span class="hljs-built_in">i</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">i</span></span>&lt; TopologyRNN[layer] + <span class="hljs-number"><span class="hljs-number">1</span></span> , <span class="hljs-built_in"><span class="hljs-built_in">i</span></span>++) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int <span class="hljs-built_in"><span class="hljs-built_in">j</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">j</span></span>&lt; TopologyRNN[layer], <span class="hljs-built_in"><span class="hljs-built_in">j</span></span>++) dendritecount++;</code> </pre> <br><p>  El autor adjuntar√° el c√≥digo general para una red neuronal recurrente al final de este art√≠culo, pero lo principal a entender es el principio: el paso de una onda a trav√©s de capas en el caso de un NN recurrente no cambia fundamentalmente nada, solo se agrega un t√©rmino m√°s a la funci√≥n de activaci√≥n neuronal.  Este es el t√©rmino del estado de las neuronas en el tic anterior multiplicado por el peso de la conexi√≥n neuronal. </p><br><p>  Suponemos que la teor√≠a y la pr√°ctica de las redes neuronales se han actualizado, pero el autor es consciente de que no ha acercado al lector a comprender c√≥mo ense√±ar esta estructura simple de redes neuronales para tomar decisiones en el juego.  No tenemos bibliotecas con ejemplos para ense√±ar NN.  En los grupos de desarrolladores de bot de Internet, hab√≠a una opini√≥n: danos un archivo de registro en forma de coordenadas de bots y otra informaci√≥n del juego para formar una biblioteca de ejemplos.  Pero, desafortunadamente, el autor no pudo descubrir c√≥mo usar este archivo de registro para entrenar a NN.  Estar√© encantado de discutir esto en los comentarios al art√≠culo.  Por lo tanto, el √∫nico m√©todo disponible para el autor para comprender el m√©todo de entrenamiento, o m√°s bien encontrar neurobalanzas "efectivas" (neuroconexiones), fue el algoritmo gen√©tico. </p><br><p>  Prepar√≥ una imagen sobre los principios del algoritmo gen√©tico: </p><br><p><img src="https://habrastorage.org/webt/-3/ex/ls/-3exlspxldh64avmkbi_3vuewou.jpeg"></p><br><p>  Entonces el <strong>algoritmo gen√©tico</strong> . </p><br><p>  El autor intentar√° no profundizar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en la teor√≠a de este proceso</a> , pero recordar√° solo el m√≠nimo necesario para continuar una lectura completa del art√≠culo. <br>  En el algoritmo gen√©tico, el principal fluido de trabajo es el gen (el ADN es el nombre de la mol√©cula).  El genoma en nuestro caso es un conjunto secuencial de genes o una matriz unidimensional de flotaci√≥n larga ... </p><br><p>  En la etapa inicial de trabajo con una red neuronal reci√©n construida, es necesario inicializarla.  La inicializaci√≥n se refiere a la asignaci√≥n de valores aleatorios de -1 a 1 a equilibrios neuronales. El autor se ha reunido menciona que el rango de valores de -1 a 1 es demasiado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">extremo</a> y las redes entrenadas tienen pesos en un rango m√°s peque√±o, por ejemplo, de -0.5 a 0.5 y que debe tomar un rango inicial de valores excelente de -1 a 1. Pero seguiremos el camino cl√°sico de recopilar todas las dificultades en una puerta y tomaremos el segmento m√°s amplio posible de variables aleatorias iniciales como base para inicializar la red neuronal. </p><br><p>  Ahora ocurrir√° una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">biyecci√≥n</a> .  Asumiremos que la longitud (tama√±o) del genoma del bot ser√° igual a la longitud total de las matrices de la red neuronal Topolog√≠aNN.Longitud + Topolog√≠aRNN.Longitud no por nada que el autor pas√≥ el tiempo del lector en el procedimiento para contar las conexiones neuronales. </p><br><p>  <em>Nota: Como el lector ya ha notado por s√≠ mismo, solo transferimos los pesos de la red neuronal al genotipo, la estructura de conexi√≥n, las funciones de activaci√≥n y los estados neuronales no se transmiten.</em>  <em>Para un algoritmo gen√©tico, solo las conexiones neuronales son suficientes, lo que sugiere que son los portadores de la informaci√≥n.</em>  <em>Hay desarrollos en los que el algoritmo gen√©tico tambi√©n cambia la estructura de las conexiones en la red neuronal y es bastante sencillo implementarlo.</em>  <em>Aqu√≠, el autor deja espacio para la creatividad para el lector, aunque √©l mismo lo pensar√° con inter√©s: debe comprender el uso de dos genomas independientes y dos funciones de aptitud (dos algoritmos gen√©ticos independientes) o todos pueden usar el mismo gen y algoritmo.</em> </p><br><p>  Y dado que inicializamos NN con variables aleatorias, de este modo inicializamos el genoma.  El proceso inverso tambi√©n es posible: inicializaci√≥n del genotipo mediante variables aleatorias y su posterior copia en pesos neuronales.  La segunda opci√≥n es com√∫n.  Dado que el algoritmo gen√©tico en el programa a menudo existe aparte de la esencia misma y se asocia con √©l solo por los datos del genoma y el valor de la funci√≥n de estado f√≠sico ... Detener, detener, el lector dir√°, la imagen muestra claramente la poblaci√≥n y no una palabra sobre el genoma individual. </p><br><p>  Ok, agregue algunas fotos al horno mental del lector: </p><br><p><img src="https://habrastorage.org/webt/h5/dz/ho/h5dzhojhlf6b1xqsol30qo63mdo.jpeg"></p><br><p>  Como el autor pint√≥ las im√°genes antes de escribir el texto del art√≠culo, apoyan el texto, pero no siguen la letra a la letra de la historia actual. </p><br><p>  De la informaci√≥n extra√≠da se deduce que el principal cuerpo de trabajo del algoritmo gen√©tico es una poblaci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">genomas</a> .  Esto es un poco contrario a lo que el autor dijo anteriormente, pero c√≥mo hacerlo en el mundo real sin peque√±as contradicciones.  Ayer, el sol giraba alrededor de la tierra, y hoy el autor habla sobre la red neuronal dentro del bot de software.  No es de extra√±ar que recordara el horno de la raz√≥n. <br>  Conf√≠o en que el lector mismo resuelva el problema de las contradicciones del mundo.  El mundo bot es completamente autosuficiente para el art√≠culo. </p><br><p>  Pero lo que el autor ya ha logrado hacer, en esta parte del art√≠culo, es formar una poblaci√≥n de bots. <br>  Echemos un vistazo desde el lado del software: </p><br><p>  Hay un Bot (puede ser un objeto en OOP, una estructura, aunque probablemente tambi√©n sea un objeto o simplemente una matriz de datos).  En el interior, el Bot contiene informaci√≥n sobre sus coordenadas, velocidad, masa y otra informaci√≥n √∫til en el proceso del juego, pero lo principal para nosotros ahora es que contiene un enlace a su genotipo o genotipo en s√≠ mismo, dependiendo de la implementaci√≥n.  Luego puede ir de diferentes maneras, limitarse a conjuntos de pesos de redes neuronales o introducir un conjunto adicional de genotipos, ya que ser√° conveniente para el lector imaginar esto en su imaginaci√≥n.  En las primeras etapas, el autor del programa asign√≥ matrices de neurobalances y genotipos.  Luego se neg√≥ a duplicar informaci√≥n y se limit√≥ a los pesos de la red neuronal. </p><br><p>  Siguiendo la l√≥gica de la historia, debe decir que la poblaci√≥n de bots es una matriz de los bots anteriores.  Qu√© bucle de juego ... Detente de nuevo, ¬øqu√© ciclo de juego?  los desarrolladores proporcionaron cort√©smente un lugar para un solo Bot a bordo de un programa de simulaci√≥n del mundo del juego en un servidor o un m√°ximo de cuatro bots en un simulador local.  Y si recuerda la topolog√≠a de la red neuronal elegida por el autor: </p><br><p><img src="https://habrastorage.org/webt/vh/1d/xq/vh1dxqmwqoejzszyh3zpfyykve4.jpeg"></p><br><p>  Y para simplificar la historia, suponga que el genotipo contiene aproximadamente 1000 conexiones neuronales, por cierto, en el simulador, los genotipos se ven as√≠ (el rojo es un valor gen√©tico negativo, el verde es un valor positivo, cada l√≠nea es un genoma separado): </p><br><p><img src="https://habrastorage.org/webt/ri/h0/s-/rih0s-ss3gaflldpts95rm9yo4u.jpeg"></p><br><p>  <em>Nota para la foto: con el tiempo, el patr√≥n cambia en la direcci√≥n del dominio de una de las soluciones, las rayas verticales son genes genot√≠picos comunes.</em> </p><br><p>  Por lo tanto, tenemos 1000 genes en el genotipo y un m√°ximo de cuatro bots en el programa simulador del mundo del juego de los organizadores de la competencia.  ¬øCu√°ntas veces necesitas ejecutar una simulaci√≥n de una batalla de bots para que por fuerza bruta, incluso los m√°s inteligentes, te acerques en busca de "efectivo" <br>  genotipo, lea la combinaci√≥n "efectiva" de conexiones neuronales, siempre que cada conexi√≥n neuronal var√≠e de -1 a 1 en pasos, ¬øy qu√© paso?  La inicializaci√≥n fue flotante aleatorio, es 15 decimales.  El paso a√∫n no est√° claro para nosotros.  Sobre el n√∫mero de variantes de combinaciones de pesos neuronales, el autor supone que este es un n√∫mero infinito, al elegir un cierto tama√±o de paso, probablemente un n√∫mero finito, pero en cualquier caso, estos n√∫meros son mucho m√°s de 4 lugares en el simulador, incluso considerando el lanzamiento secuencial desde la cola de bots m√°s el lanzamiento paralelo simult√°neo de simuladores oficiales, hasta 10 en una computadora (para fan√°ticos de la programaci√≥n vintage: computadoras). </p><br><p><img src="https://habrastorage.org/webt/it/-8/if/it-8ifszotccnx4wguexdtditpm.jpeg"></p><br><p>  Espero que las fotos ayuden al lector. </p><br><p>  Aqu√≠ debe hacer una pausa y hablar sobre la arquitectura de la soluci√≥n de software.  Dado que la soluci√≥n en forma de un bot de software separado cargado en el sitio de la competencia ya no era adecuada.  Era necesario separar el juego del robot de acuerdo con las reglas de la competencia en el marco del ecosistema de organizadores y el programa que intentaba encontrar la configuraci√≥n de la red neuronal para √©l.  El siguiente diagrama est√° tomado de la presentaci√≥n de la conferencia, pero generalmente refleja la imagen real. </p><br><p><img src="https://habrastorage.org/webt/-i/hb/ph/-ihbph2b0hlv3lfzxze7ihmu3-q.jpeg"></p><br><p>  Record√≥ un chiste barbudo: </p><br><p>  <em>Gran organizaci√≥n</em> <em><br></em>  <em>Hora 18.00, todos los empleados trabajan como uno.</em>  <em>De repente, uno de los empleados apaga la computadora, se viste y se va.</em> <em><br></em>  <em>Todos lo siguen con una mirada de sorpresa.</em> <em><br></em>  <em>Al dia siguiente</em>  <em>A las 18.00 el mismo empleado apaga la computadora y se va.</em>  <em>Todos contin√∫an trabajando y comienzan a susurrar disgustados.</em> <em><br></em>  <em>Al dia siguiente.</em>  <em>A las 18.00 el mismo empleado apaga la computadora ...</em> <em><br></em>  <em>Un colega se le acerca:</em> <em><br></em>  <em>-Como no te da verg√ºenza, estamos trabajando, al final del trimestre, tantos informes, tambi√©n queremos llegar a casa a tiempo y t√∫ eres tan individual ...</em> <em><br></em>  <em>- Chicos, generalmente estoy de vacaciones!</em> </p><br><p>  ... continuar√°. </p><br><p>  S√≠, casi olvido adjuntar el c√≥digo del procedimiento de c√°lculo RNN, es v√°lido y est√° escrito de forma independiente, por lo que tal vez haya errores en √©l.  Para la amplificaci√≥n, lo traer√© como est√°, est√° en c ++ como se aplica a CUDA (una biblioteca para calcular en la GPU). </p><br><p>  Nota: las matrices multidimensionales no se llevan bien con las GPU, por supuesto que hay texturas y c√°lculos de matriz, pero recomiendan usar matrices unidimensionales. </p><br><p>  Un ejemplo de una matriz [i, j] de dimensi√≥n M por j se convierte en una matriz de la forma [i * M + j]. </p><br><div class="spoiler">  <b class="spoiler_title">C√≥digo fuente del procedimiento de c√°lculo RNN</b> <div class="spoiler_text"><pre> <code class="hljs powershell">__global__ void cudaRNN(Bot *bot, argumentsRNN *RNN, ConstantStruct *Const, int *Topology, int *TopologyRNN, int numElements, int gameTick) { int tid = blockIdx.x * blockDim.x + threadIdx.x; int threadN = gridDim.x * blockDim.x; int TopologySize = Const-&gt;TopologySize; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int pos = tid; pos &lt; numElements; pos += threadN) { const int ii = pos; const int iiA = pos*Const-&gt;ArrayDim; int ArrayDim = Const-&gt;ArrayDim; const int iiAT = ii*TopologySize*ArrayDim; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (bot[<span class="hljs-type"><span class="hljs-type">pos</span></span>].TTF != <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; bot[<span class="hljs-type"><span class="hljs-type">pos</span></span>].Mass&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>) { RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">Topology</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>]] = <span class="hljs-number"><span class="hljs-number">1</span></span>.f; //bias int neuroncount7 = Topology[<span class="hljs-number"><span class="hljs-number">0</span></span>]; neuroncount7++; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int layer1 = <span class="hljs-number"><span class="hljs-number">0</span></span>; layer1 &lt; TopologySize - <span class="hljs-number"><span class="hljs-number">1</span></span>; layer1++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int j4 = <span class="hljs-number"><span class="hljs-number">0</span></span>; j4 &lt; Topology[<span class="hljs-type"><span class="hljs-type">layer1</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>]; j4++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int i5 = <span class="hljs-number"><span class="hljs-number">0</span></span>; i5 &lt; Topology[<span class="hljs-type"><span class="hljs-type">layer1</span></span>] + <span class="hljs-number"><span class="hljs-number">1</span></span>; i5++) { RNN-&gt;sums[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">j4</span></span>] = RNN-&gt;sums[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">j4</span></span>] + RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">i5</span></span>] * RNN-&gt;NNweights[((<span class="hljs-type"><span class="hljs-type">ii</span></span>*<span class="hljs-type"><span class="hljs-type">TopologySize</span></span> + <span class="hljs-type"><span class="hljs-type">layer1</span></span>)*<span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> + <span class="hljs-type"><span class="hljs-type">i5</span></span>)*<span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> + <span class="hljs-type"><span class="hljs-type">j4</span></span>]; } } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (TopologyRNN[<span class="hljs-type"><span class="hljs-type">layer1</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int j14 = <span class="hljs-number"><span class="hljs-number">0</span></span>; j14 &lt; Topology[<span class="hljs-type"><span class="hljs-type">layer1</span></span>]; j14++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int i15 = <span class="hljs-number"><span class="hljs-number">0</span></span>; i15 &lt; Topology[<span class="hljs-type"><span class="hljs-type">layer1</span></span>]; i15++) { RNN-&gt;sumsContext[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">j14</span></span>] = RNN-&gt;sumsContext[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">j14</span></span>] + RNN-&gt;neuronContext[<span class="hljs-type"><span class="hljs-type">iiAT</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> * <span class="hljs-type"><span class="hljs-type">layer1</span></span> + <span class="hljs-type"><span class="hljs-type">i15</span></span>] * RNN-&gt;MNweights[((<span class="hljs-type"><span class="hljs-type">ii</span></span>*<span class="hljs-type"><span class="hljs-type">TopologySize</span></span> + <span class="hljs-type"><span class="hljs-type">layer1</span></span>)*<span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> + <span class="hljs-type"><span class="hljs-type">i15</span></span>)*<span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> + <span class="hljs-type"><span class="hljs-type">j14</span></span>]; } RNN-&gt;sumsContext[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">j14</span></span>] = RNN-&gt;sumsContext[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">j14</span></span>] + <span class="hljs-number"><span class="hljs-number">1.0</span></span>f* RNN-&gt;MNweights[((<span class="hljs-type"><span class="hljs-type">ii</span></span>*<span class="hljs-type"><span class="hljs-type">TopologySize</span></span> + <span class="hljs-type"><span class="hljs-type">layer1</span></span>)*<span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> + <span class="hljs-type"><span class="hljs-type">Topology</span></span>[<span class="hljs-type"><span class="hljs-type">layer1</span></span>])*<span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> + <span class="hljs-type"><span class="hljs-type">j14</span></span>]; //bias=<span class="hljs-number"><span class="hljs-number">1</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int t = <span class="hljs-number"><span class="hljs-number">0</span></span>; t &lt; Topology[<span class="hljs-type"><span class="hljs-type">layer1</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>]; t++) { RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">t</span></span>] = Tanh(RNN-&gt;sums[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">t</span></span>] + RNN-&gt;sumsContext[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">t</span></span>]); RNN-&gt;neuronContext[<span class="hljs-type"><span class="hljs-type">iiAT</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">Array</span></span><span class="hljs-type"><span class="hljs-type">Dim</span></span> * <span class="hljs-type"><span class="hljs-type">layer1</span></span> + <span class="hljs-type"><span class="hljs-type">t</span></span>] = RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">t</span></span>]; } //SoftMax /* double sum = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt;ArrayDim; ++k) sum += exp(RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">k</span></span>]); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt; ArrayDim; ++k) RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">k</span></span>] = exp(RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">k</span></span>]) / sum; */ } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int i1 = <span class="hljs-number"><span class="hljs-number">0</span></span>; i1 &lt; Topology[<span class="hljs-type"><span class="hljs-type">layer1</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>]; i1++) { RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">i1</span></span>] = Sigmoid(RNN-&gt;sums[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">i1</span></span>]); //sigma } } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (layer1 + <span class="hljs-number"><span class="hljs-number">1</span></span> != TopologySize - <span class="hljs-number"><span class="hljs-number">1</span></span>) { RNN-&gt;outputs[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">Topology</span></span>[<span class="hljs-type"><span class="hljs-type">layer1</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>]] = <span class="hljs-number"><span class="hljs-number">1</span></span>.f; } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int i2 = <span class="hljs-number"><span class="hljs-number">0</span></span>; i2 &lt; ArrayDim; i2++) { RNN-&gt;sums[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">i2</span></span>] = <span class="hljs-number"><span class="hljs-number">0</span></span>.f; RNN-&gt;sumsContext[<span class="hljs-type"><span class="hljs-type">iiA</span></span> + <span class="hljs-type"><span class="hljs-type">i2</span></span>] = <span class="hljs-number"><span class="hljs-number">0</span></span>.f; } } } } }</code> </pre> </div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417657/">https://habr.com/ru/post/es417657/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417647/index.html">Un proyecto de ley sobre la protecci√≥n de datos personales presentado en Bielorrusia: lo que est√° "dentro" de √©l</a></li>
<li><a href="../es417649/index.html">OpenAI supera importantes limitaciones de IA para Dota 2</a></li>
<li><a href="../es417651/index.html">¬øQu√© debe hacer el lector para que leas m√°s?</a></li>
<li><a href="../es417653/index.html">Lecci√≥n abierta "Conceptos b√°sicos de bases de datos"</a></li>
<li><a href="../es417655/index.html">Antecedentes: Corporaci√≥n del Estado de Roscosmos y su trabajo.</a></li>
<li><a href="../es417659/index.html">Neuropoet y otras estrellas del pop del futuro</a></li>
<li><a href="../es417661/index.html">Aubrey de Gray visitando a Joe Rogan</a></li>
<li><a href="../es417665/index.html">La gram√°tica inglesa como matem√°tica. Por d√≥nde empezar para aquellos que no trabajaron</a></li>
<li><a href="../es417667/index.html">AI. Rastreador de barrera t√°ctica</a></li>
<li><a href="../es417671/index.html">Nuevas caracter√≠sticas del lenguaje de programaci√≥n ABAP en seminarios web de SAP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍💼 👋🏽 🤤 确定狗的品种：完整的开发周期，从Python中的神经网络到Google Play上的应用 😾 🐗 👊🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="通常，在神经网络领域尤其是模式识别领域的进步导致了这样一个事实，即创建用于处理图像的神经网络应用程序似乎是一项常规任务。 从某种意义上说，这是-如果您想到了与模式识别有关的想法，请不要怀疑有人已经写过类似的东西。 您所需要做的就是在Google中找到相应的代码，然后由作者“编译”。 

 但是，我想...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>确定狗的品种：完整的开发周期，从Python中的神经网络到Google Play上的应用</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448316/"> 通常，在神经网络领域尤其是模式识别领域的进步导致了这样一个事实，即创建用于处理图像的神经网络应用程序似乎是一项常规任务。 从某种意义上说，这是-如果您想到了与模式识别有关的想法，请不要怀疑有人已经写过类似的东西。 您所需要做的就是在Google中找到相应的代码，然后由作者“编译”。 <br><br> 但是，我想说，仍然有许多细节使这项任务不是像无聊一样难以解决。 这会花费太多时间，特别是如果您是一个需要领导才能，循序渐进，需要在您眼前进行并从头到尾完成的项目的初学者。 在这种情况下，如果没有通常的做法，“跳过这一明显的部分”就是借口。 <br><br> 在本文中，我们将考虑创建Dog Breed Identifier的任务：我们将创建和训练神经网络，然后将其移植到Android的Java并在Google Play上发布。 <br><br> 如果您想查看完成的结果，则为：Google Play上的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NeuroDog应用</a> 。 <br><br> 使用我的机器人技术的网站（正在进行中）： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">robotics.snowcron.com</a> 。 <br> 程序本身的网站，包括指南： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NeuroDog用户指南</a> 。 <br><br> 这是该程序的屏幕截图： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/186/b91/457/186b914572170b01446ed1d722bce200.png" alt="图片"><br><br><a name="habracut"></a><br><br><h3> 问题陈述 </h3><br><br> 我们将使用Keras：一个用于处理神经网络的Google库。 这是一个高级库，这意味着与我所知道的替代方法相比，它更易于使用。 如果有的话-网络中有很多关于Keras的教科书，质量很高。 <br><br> 我们将使用CNN-卷积神经网络。  CNN（以及基于它们的更高级的配置）是图像识别中的事实上的标准。 同时，训练这样的网络并不总是那么容易：您需要选择正确的网络结构，训练参数（所有这些学习率，动量，L1和L2等）。 该任务需要大量的计算资源，因此，仅通过遍历所有参数来解决该问题将失败。 <br><br> 这是为什么在大多数情况下他们使用所谓的“转移知识”而不是所谓的“香草”方法的几个原因之一。  Transfer Knowlege使用由我们之前的人员（例如Google）训练的神经网络，通常用于完成类似但仍不同的任务。 我们从中获取初始层，用我们自己的分类器替换最终层-它可以工作，并且效果很好。 <br><br> 起初，这样的结果可能令人惊讶：我们如何接受训练有素的Google网络来区分猫和椅子，并为我们识别狗的品种？ 要了解这是如何发生的，您需要了解深度神经网络工作的基本原理，包括用于模式识别的原理。 <br><br> 我们“喂食”网络一幅图片（即数字数组）作为输入。 第一层分析图像中的简单图案，例如“水平线”，“弧形”等。 下一层接收这些图案作为输入，并生成二阶图案，例如“毛发”，“眼角” ...最终，我们得到一个难题，可以用来重建狗：羊毛，两只眼睛和人的牙齿。 <br><br> 以上所有操作都是在我们（例如，从Google）获得的预训练图层的帮助下完成的。 接下来，我们添加我们的图层，并教他们从这些模式中提取品种信息。 听起来合乎逻辑。 <br><br> 总而言之，在本文中，我们将创建“原始” CNN和不同类型网络的多个“转移学习”变体。 至于“香草”：我会创建它，但我不打算通过选择参数来配置它，因为训练和配置“预训练”网络要容易得多。 <br><br> 由于我们计划教我们的神经网络识别狗的品种，因此我们必须“展示”各种品种的样本。 幸运的是， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a>为类似的任务创建了一组照片（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">原始</a>照片在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a> ）。 <br><br> 然后，我计划为android移植最好的接收网络。 将Kerasov网络移植到android相对简单，形式化，我们将做所有必要的步骤，因此重现这一部分将不难。 <br><br> 然后，我们将所有这些内容发布在Google Play上。 当然，Google会抗拒，因此将使用其他技巧。 例如，我们的应用程序的大小（由于庞大的神经网络）将大于Google Play接受的Android APK的允许大小：我们将不得不使用捆绑软件。 此外，Google不会在搜索结果中显示我们的应用程序，可以通过在应用程序中注册搜索标签来解决此问题，或者只需等待一两个星期。 <br><br> 结果，我们为Android和神经网络获得了功能齐全的“商业”（引号，因为它是免费提供的）应用程序。 <br><br><h3> 开发环境 </h3><br><br> 您可以采用不同的方式为Keras编程，具体取决于所使用的OS（建议使用Ubuntu），是否存在视频卡等等。 除了不是最简单的方法之外，在本地计算机上进行开发（并因此进行其配置）也没有什么不好。 <br><br> 首先，安装和配置大量工具和库需要花费时间，然后在发布新版本时，您将不得不再次花费时间。 其次，神经网络需要大量的计算能力来进行训练。 如果您使用GPU，则可以加快（提高10倍或更多倍）此过程。在撰写本文时，最适合此工作的顶级GPU的价格为2,000美元-7,000美元。 是的，它们也需要配置。 <br><br> 因此，我们将另辟。径。 事实是，Google允许像我们这样的贫穷刺猬免费使用其集群中的GPU，以进行与神经网络有关的计算，它还提供了完全配置的环境，总之称为Google Colab。 该服务使您可以使用python，Keras和许多其他已配置的库访问Jupiter Notebook。 您要做的就是获得一个Google帐户（获得一个Gmail帐户，这将使您能够访问其他所有内容）。 <br><br> 目前，您可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a>聘用Colab，但是了解Google，这种情况可以随时更改。 只是谷歌谷歌Colab。 <br><br> 使用Colab的明显问题是它是一个WEB服务。 我们如何访问我们的数据？ 训练后保存神经网络，例如，下载特定于我们任务的数据等等？ <br><br> 有几种（在撰写本文时-三种）不同的方式，我们使用一种我认为最方便的方式-我们使用Google云端硬盘。 <br><br>  Google云端硬盘是一种基于云的数据存储，其工作方式与常规硬盘非常相似，并且可以映射到Google Colab（请参见下面的代码）。 之后，您可以像处理本地磁盘上的文件一样使用它。 也就是说，例如，为了访问狗的照片以训练我们的神经网络，我们需要将它们上传到Google云端硬盘，仅此而已。 <br><br><h2> 创建和训练神经网络 </h2><br><br> 下面，我逐个逐节给出Python中的代码（来自Jupiter Notebook）。 您也可以将此代码复制到Jupiter Notebook中并逐块运行它，因为块可以独立执行（当然，在早期块中可能需要在早期块中定义的变量，但这显然是依赖性）。 <br><br><h3> 初始化 </h3><br><br> 首先，让我们挂载Google云端硬盘。 只有两行。 此代码仅应在Colab会话中执行一次（例如，每6小时执行一次）。 如果在会话仍处于“活动”状态时第二次调用它，则由于已安装驱动器，因此将跳过该会话。 <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> drive drive.mount(<span class="hljs-string"><span class="hljs-string">'/content/drive/'</span></span>)</code> </pre> <br><br> 在开始时，将要求您确认您的意图，没有什么复杂的。 看起来是这样的： <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>Go to this URL <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a browser: ... &gt;&gt;&gt; Enter your authorization code: &gt;&gt;&gt; ·········· &gt;&gt;&gt; Mounted at /content/drive/</code> </pre><br><br> 完全标准的<i>包含</i>部分； 可能不需要其中包含的某些文件，嗯...抱歉。 另外，由于我将测试不同的神经网络，因此您将必须针对特定类型的神经网络注释/取消注释其中包含的一些模块：例如，要使用InceptionV3 NN，请注释不包括InceptionV3，并注释掉例如ResNet50。 是否：所发生的所有变化仅是所使用的内存大小，并且不是很强。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> dt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> regularizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, Dropout, Activation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flatten, Conv2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaxPooling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization, Input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dropout, GlobalAveragePooling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Callback, EarlyStopping <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ReduceLROnPlateau <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.vgg16 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ResNet50 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> decode_predictions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> InceptionV3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> inception_v3_preprocessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.mobilenetv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MobileNetV2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.nasnet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NASNetMobile</code> </pre><br><br> 在Google云端硬盘上，我们为文件创建了一个文件夹。 第二行显示其内容： <br><br><pre> <code class="python hljs">working_path = <span class="hljs-string"><span class="hljs-string">"/content/drive/My Drive/DeepDogBreed/data/"</span></span> !ls <span class="hljs-string"><span class="hljs-string">"/content/drive/My Drive/DeepDogBreed/data"</span></span> &gt;&gt;&gt; all_images labels.csv models test train valid</code> </pre><br><br> 如您所见，这些狗的照片（从Google云端硬盘上的斯坦福数据集（见上文）复制）首先保存在<i>all_images</i>文件夹中。 稍后，我们将它们复制到<i>火车</i>目录<i>，有效</i>目录和<i>测试</i>目录中。 我们将训练好的模型保存在<i>models</i>文件夹中。 至于labels.csv文件，这是带有照片的数据集的一部分，它包含一张图片和狗的品种名称对应的表格。 <br><br> 您可以运行许多测试来了解我们从Google暂时获得的确切信息。 例如： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Is GPU Working? import tensorflow as tf tf.test.gpu_device_name() &gt;&gt;&gt; '/device:GPU:0'</span></span></code> </pre><br><br> 如您所见，GPU已真正连接，如果未连接，则需要在Jupiter Notebook设置中找到并启用此选项。 <br><br> 接下来，我们需要声明一些常量，例如图像的大小等。 我们将使用大小为256x256像素的图片，这是一个足够大的图像，以免丢失细节，又足够小，以至于所有内容都适合存储在内存中。 但是请注意，我们将使用的某些类型的神经网络期望224x224像素的图像。 在这种情况下，我们评论256而取消评论224。 <br><br> 相同的方法（注释一-取消注释）将应用于我们保存的模型的名称，仅仅是因为我们不想覆盖可能仍然有用的文件。 <br><pre> <code class="python hljs">warnings.filterwarnings(<span class="hljs-string"><span class="hljs-string">"ignore"</span></span>) os.environ[<span class="hljs-string"><span class="hljs-string">'TF_CPP_MIN_LOG_LEVEL'</span></span>] = <span class="hljs-string"><span class="hljs-string">'2'</span></span> np.random.seed(<span class="hljs-number"><span class="hljs-number">7</span></span>) start = dt.datetime.now() BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">16</span></span> EPOCHS = <span class="hljs-number"><span class="hljs-number">15</span></span> TESTING_SPLIT=<span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-comment"><span class="hljs-comment"># 70/30 % NUM_CLASSES = 120 IMAGE_SIZE = 256 #strModelFileName = "models/ResNet50.h5" # strModelFileName = "models/InceptionV3.h5" strModelFileName = "models/InceptionV3_Sgd.h5" #IMAGE_SIZE = 224 #strModelFileName = "models/MobileNetV2.h5" #IMAGE_SIZE = 224 #strModelFileName = "models/NASNetMobileSgd.h5"</span></span></code> </pre><br><br><h3> 资料载入 </h3><br><br> 首先，让我们<i>上传labels.csv</i>文件并将其分为训练和验证部分。 请注意，目前尚无测试部分，因为我将作弊以获取更多训练数据。 <br><br><pre> <code class="python hljs">labels = pd.read_csv(working_path + <span class="hljs-string"><span class="hljs-string">'labels.csv'</span></span>) print(labels.head()) train_ids, valid_ids = train_test_split(labels, test_size = TESTING_SPLIT) print(len(train_ids), <span class="hljs-string"><span class="hljs-string">'train ids'</span></span>, len(valid_ids), <span class="hljs-string"><span class="hljs-string">'validation ids'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Total'</span></span>, len(labels), <span class="hljs-string"><span class="hljs-string">'testing images'</span></span>) &gt;&gt;&gt; id breed &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">000</span></span>bec180eb18c7604dcecc8fe0dba07 boston_bull &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">001513</span></span>dfcb2ffafc82cccf4d8bbaba97 dingo &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">001</span></span>cdf01b096e06d78e9e5112d419397 pekinese &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">00214</span></span>f311d5d2247d5dfe4fe24b2303d bluetick &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">0021</span></span>f9ceb3235effd7fcde7f7538ed62 golden_retriever &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">7155</span></span> train ids <span class="hljs-number"><span class="hljs-number">3067</span></span> validation ids &gt;&gt;&gt; Total <span class="hljs-number"><span class="hljs-number">10222</span></span> testing images</code> </pre><br><br> 接下来，根据文件名将图像文件复制到training / validation / test文件夹。 以下函数将我们将其名称传输到的文件复制到指定的文件夹。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">copyFileSet</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(strDirFrom, strDirTo, arrFileNames)</span></span></span><span class="hljs-function">:</span></span> arrBreeds = np.asarray(arrFileNames[<span class="hljs-string"><span class="hljs-string">'breed'</span></span>]) arrFileNames = np.asarray(arrFileNames[<span class="hljs-string"><span class="hljs-string">'id'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(strDirTo): os.makedirs(strDirTo) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(range(len(arrFileNames))): strFileNameFrom = strDirFrom + arrFileNames[i] + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span> strFileNameTo = strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span> + arrFileNames[i] + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span>): os.makedirs(strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># As a new breed dir is created, copy 1st file # to "test" under name of that breed if not os.path.exists(working_path + "test/"): os.makedirs(working_path + "test/") strFileNameTo = working_path + "test/" + arrBreeds[i] + ".jpg" shutil.copy(strFileNameFrom, strFileNameTo) shutil.copy(strFileNameFrom, strFileNameTo)</span></span></code> </pre><br><br> 如您所见，我们仅将每个犬种复制一个文件作为<i>测试</i> 。 同样，在复制时，我们会创建子文件夹，每个子文件夹一个。 因此，按品种将照片复制到子文件夹中。 <br><br> 这样做是因为Keras可以使用结构相似的目录，可以根据需要而不是一次全部加载图像文件，从而节省了内存。 一次上传所有15,000张图片是一个坏主意。 <br><br> 我们将仅需调用一次此函数，因为它会复制图像-不再需要。 因此，为了将来使用，我们必须对此发表评论： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Move the data in subfolders so we can # use the Keras ImageDataGenerator. # This way we can also later use Keras # Data augmentation features. # --- Uncomment once, to copy files --- #copyFileSet(working_path + "all_images/", # working_path + "train/", train_ids) #copyFileSet(working_path + "all_images/", # working_path + "valid/", valid_ids)</span></span></code> </pre><br><br> 获取狗的品种列表： <br><br><pre> <code class="python hljs">breeds = np.unique(labels[<span class="hljs-string"><span class="hljs-string">'breed'</span></span>]) map_characters = {} <span class="hljs-comment"><span class="hljs-comment">#{0:'none'} for i in range(len(breeds)): map_characters[i] = breeds[i] print("&lt;item&gt;" + breeds[i] + "&lt;/item&gt;") &gt;&gt;&gt; &lt;item&gt;affenpinscher&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;afghan_hound&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;african_hunting_dog&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;airedale&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;american_staffordshire_terrier&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;appenzeller&lt;/item&gt;</span></span></code> </pre><br><br><h3> 影像处理 </h3><br><br> 我们将使用称为ImageDataGenerators的Keras库功能。  ImageDataGenerator可以处理图像，缩放，旋转等。 它还可以接受可以额外处理图像的<i>处理</i>功能。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img)</span></span></span><span class="hljs-function">:</span></span> img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) <span class="hljs-comment"><span class="hljs-comment"># or use ImageDataGenerator( rescale=1./255... img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. #img = cv2.blur(img,(5,5)) return img_1[0]</span></span></code> </pre><br><br> 请注意以下代码： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># or use ImageDataGenerator( rescale=1./255...</span></span></code> </pre><br><br> 我们可以在ImageDataGenerator本身中规范化（子数据在0-1范围内，而不是原始的0-255）。 为什么我们需要预处理器？ 例如，考虑模糊调用（注释，我不使用它）：这是相同的自定义图像操作，可以是任意的。 从HDR到对比度的任何事物。 <br><br> 我们将使用两种不同的ImageDataGenerator，一种用于训练，另一种用于验证。 不同之处在于，对于训练，我们需要轮流和缩放以增加数据的“多样性”，但对于验证，至少不需要这项任务。 <br><br><pre> <code class="python hljs">train_datagen = ImageDataGenerator( preprocessing_function=preprocess, <span class="hljs-comment"><span class="hljs-comment">#rescale=1./255, # done in preprocess() # randomly rotate images (degrees, 0 to 30) rotation_range=30, # randomly shift images horizontally # (fraction of total width) width_shift_range=0.3, height_shift_range=0.3, # randomly flip images horizontal_flip=True, ,vertical_flip=False, zoom_range=0.3) val_datagen = ImageDataGenerator( preprocessing_function=preprocess) train_gen = train_datagen.flow_from_directory( working_path + "train/", batch_size=BATCH_SIZE, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, class_mode="categorical") val_gen = val_datagen.flow_from_directory( working_path + "valid/", batch_size=BATCH_SIZE, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, class_mode="categorical")</span></span></code> </pre><br><br><h3> 创建一个神经网络 </h3><br><br> 如前所述，我们将创建几种类型的神经网络。 每次我们调用另一个函数来创建，包含其他文件时，有时会确定不同的图像大小。 因此，要在不同类型的神经网络之间切换，我们必须注释/取消注释相应的代码。 <br><br> 首先，创建一个“香草” CNN。 它不能很好地工作，因为我决定不浪费时间对其进行调试，但是至少它提供了可以根据需要进行开发的基础（通常这是一个坏主意，因为经过预先培训的网络可以提供最佳结果）。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelVanilla</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() <span class="hljs-comment"><span class="hljs-comment"># Note the (7, 7) here. This is one of technics # used to reduce memory use by the NN: we scan # the image in a larger steps. # Also note regularizers.l2: this technic is # used to prevent overfitting. The "0.001" here # is an empirical value and can be optimized. model.add(Conv2D(16, (7, 7), padding='same', use_bias=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), kernel_regularizer=regularizers.l2(0.001))) # Note the use of a standard CNN building blocks: # Conv2D - BatchNormalization - Activation # MaxPooling2D - Dropout # The last two are used to avoid overfitting, also, # MaxPooling2D reduces memory use. model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(16, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) # This is the end on "convolutional" part of CNN. # Now we need to transform multidementional # data into one-dim. array for a fully-connected # classifier: model.add(Flatten()) # And two layers of classifier itself (plus an # Activation layer in between): model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.l2(0.01))) model.add(Activation("relu")) model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.l2(0.01))) # We need to compile the resulting network. # Note that there are few parameters we can # try here: the best performing one is uncommented, # the rest is commented out for your reference. #model.compile(optimizer='rmsprop', # loss='categorical_crossentropy', # metrics=['accuracy']) #model.compile( # optimizer=keras.optimizers.RMSprop(lr=0.0005), # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #model.compile(optimizer='adadelta', # loss='categorical_crossentropy', # metrics=['accuracy']) #opt = keras.optimizers.Adadelta(lr=1.0, # rho=0.95, epsilon=0.01, decay=0.01) #model.compile(optimizer=opt, # loss='categorical_crossentropy', # metrics=['accuracy']) #opt = keras.optimizers.RMSprop(lr=0.0005, # rho=0.9, epsilon=None, decay=0.0001) #model.compile(optimizer=opt, # loss='categorical_crossentropy', # metrics=['accuracy']) # model.summary() return(model)</span></span></code> </pre><br><br> 当我们使用<i>转移学习</i>创建网络时，过程将更改： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelMobileNetV2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># First, create the NN and load pre-trained # weights for it ('imagenet') # Note that we are not loading last layers of # the network (include_top=False), as we are # going to add layers of our own: base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) # Then attach our layers at the end. These are # to build "classifier" that makes sense of # the patterns previous layers provide: x = base_model.output x = Dense(512)(x) x = Activation('relu')(x) x = Dropout(0.5)(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) # Create a model model = Model(inputs=base_model.input, outputs=predictions) # We need to make sure that pre-trained # layers are not changed when we train # our classifier: # Either this: #model.layers[0].trainable = False # or that: for layer in base_model.layers: layer.trainable = False # As always, there are different possible # settings, I tried few and chose the best: # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br> 创建其他类型的网络遵循相同的模式： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelResNet50</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> base_model = ResNet50(weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>, include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pooling=<span class="hljs-string"><span class="hljs-string">'avg'</span></span>, input_shape=(IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>)) x = base_model.output x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>)(x) x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) predictions = Dense(NUM_CLASSES, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=base_model.input, outputs=predictions) <span class="hljs-comment"><span class="hljs-comment">#model.layers[0].trainable = False # model.compile(loss='categorical_crossentropy', # optimizer='adam', metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br> 警告：赢家！ 该NN显示出最佳结果： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelInceptionV3</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># model.layers[0].trainable = False # model.compile(optimizer='sgd', # loss='categorical_crossentropy', # metrics=['accuracy']) base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) x = base_model.output x = GlobalAveragePooling2D()(x) x = Dense(512, activation='relu')(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs = base_model.input, outputs = predictions) for layer in base_model.layers: layer.trainable = False # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br> 另一个： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelNASNetMobile</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># model.layers[0].trainable = False # model.compile(optimizer='sgd', # loss='categorical_crossentropy', # metrics=['accuracy']) base_model = NASNetMobile(weights = 'imagenet', include_top = False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) x = base_model.output x = GlobalAveragePooling2D()(x) x = Dense(512, activation='relu')(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs = base_model.input, outputs = predictions) for layer in base_model.layers: layer.trainable = False # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br> 不同类型的神经网络可用于不同任务。 因此，除了对预测准确性的要求外，大小（移动NN比Inception小5倍）和速度（如果我们需要实时处理视频流，则必须牺牲准确性）也很重要。 <br><br><h3> 神经网络训练 </h3><br><br> 首先，我们正在<i>试验</i> ，因此我们应该能够删除已保存但不再使用的神经网络。 以下函数删除NN（如果存在）： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make sure that previous "best network" is deleted. def deleteSavedNet(best_weights_filepath): if(os.path.isfile(best_weights_filepath)): os.remove(best_weights_filepath) print("deleteSavedNet():File removed") else: print("deleteSavedNet():No file to remove")</span></span></code> </pre><br><br> 我们创建和删除神经网络的方法非常简单明了。 首先，删除。 当调用<i>delete</i> （仅）时，应牢记Jupiter Notebook具有“运行选择”功能，仅选择要使用的功能，然后运行它。 <br><br> 然后，如果文件不存在，则创建一个神经网络；如果文件存在，则创建一个调用：当然，我们不能调用“ delete”，然后期望NN存在，因此要使用保存的神经网络，请不要调用<i>delete</i> 。 <br><br> 换句话说，我们可以根据情况和当前正在尝试的内容来创建新的NN，或使用现有的NN。 一个简单的场景：我们训练了一个神经网络，然后去度假。 他们回来了，谷歌确定了会议的内容，因此我们需要加载以前保存的文件：注释掉“删除”，取消注释“加载”。 <br><br><pre> <code class="python hljs">deleteSavedNet(working_path + strModelFileName) <span class="hljs-comment"><span class="hljs-comment">#if not os.path.exists(working_path + "models"): # os.makedirs(working_path + "models") # #if not os.path.exists(working_path + # strModelFileName): # model = createModelResNet50() model = createModelInceptionV3() # model = createModelMobileNetV2() # model = createModelNASNetMobile() #else: # model = load_model(working_path + strModelFileName)</span></span></code> </pre><br><br>  <b>检查点</b>是我们程序中非常重要的元素。 我们可以创建一个函数数组，每个训练时代结束时应调用这些函数，并将其传递给检查点。 例如， <i>如果</i>神经网络显示的结果比已保存的结果好，则可以保存该神经网络。 <br><br><pre> <code class="python hljs">checkpoint = ModelCheckpoint(working_path + strModelFileName, monitor=<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_best_only=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, save_weights_only=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) callbacks_list = [ checkpoint ]</code> </pre><br><br> 最后，我们在训练集上教授神经网络： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Calculate sizes of training and validation sets STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size STEP_SIZE_VALID=val_gen.n//val_gen.batch_size # Set to False if we are experimenting with # some other part of code, use history that # was calculated before (and is still in # memory bDoTraining = True if bDoTraining == True: # model.fit_generator does the actual training # Note the use of generators and callbacks # that were defined earlier history = model.fit_generator(generator=train_gen, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=val_gen, validation_steps=STEP_SIZE_VALID, epochs=EPOCHS, callbacks=callbacks_list) # --- After fitting, load the best model # This is important as otherwise we'll # have the LAST model loaded, not necessarily # the best one. model.load_weights(working_path + strModelFileName) # --- Presentation part # summarize history for accuracy plt.plot(history.history['acc']) plt.plot(history.history['val_acc']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['acc', 'val_acc'], loc='upper left') plt.show() # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss') plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['loss', 'val_loss'], loc='upper left') plt.show() # As grid optimization of NN would take too long, # I did just few tests with different parameters. # Below I keep results, commented out, in the same # code. As you can see, Inception shows the best # results: # Inception: # adam: val_acc 0.79393 # sgd: val_acc 0.80892 # Mobile: # adam: val_acc 0.65290 # sgd: Epoch 00015: val_acc improved from 0.67584 to 0.68469 # sgd-30 epochs: 0.68 # NASNetMobile, adam: val_acc did not improve from 0.78335 # NASNetMobile, sgd: 0.8</span></span></code> </pre><br><br> 最佳配置的精度和损耗图如下： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/97d/9cc/f0e97d9ccdc8f8ed9e44ddba02cf1f8d.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/612/e09/8b0/612e098b088979768d1cc66c2f6972bc.png"><br><br> 如您所见，神经网络正在学习，而且还不错。 <br><br><h3> 神经网络测试 </h3><br><br> 训练完成后，我们必须测试结果； 为此，NN展示了她以前从未见过的照片-我们复制到测试文件夹中的照片-每个犬种一张。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># --- Test j = 0 # Final cycle performs testing on the entire # testing set. for file_name in os.listdir( working_path + "test/"): img = image.load_img(working_path + "test/" + file_name); img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. y_pred = model.predict_on_batch(img_1) # get 5 best predictions y_pred_ids = y_pred[0].argsort()[-5:][::-1] print(file_name) for i in range(len(y_pred_ids)): print("\n\t" + map_characters[y_pred_ids[i]] + " (" + str(y_pred[0][y_pred_ids[i]]) + ")") print("--------------------\n") j = j + 1</span></span></code> </pre><br><br><h3> 将神经网络导出到Java应用程序 </h3><br><br> 首先，我们需要从磁盘组织神经网络的加载。 原因很明显：导出是在另一个代码块中进行的，因此很可能我们将神经网络置于最佳状态时分别开始导出。 也就是说，在即将导出之前，在该程序的同一运行中，我们将不会训练网络。 如果使用此处显示的代码，则没有任何区别，因此已为您选择了最佳网络。 但是，如果您学到了一些自己的东西，那么在保存之前重新培训所有内容将浪费时间，如果在此之前您已保存了所有内容。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Test: load and run model = load_model(working_path + strModelFileName)</span></span></code> </pre><br><br> 出于同样的原因-不要跳过代码-我在此处包括了导出所需的文件。 如果您的美感需要，没有人会打扰您将其移至程序的开头： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf</code> </pre><br><br> 加载神经网络后进行的一项小型测试，只是为了确保加载的所有内容都可以正常工作： <br><br><pre> <code class="python hljs">img = image.load_img(working_path + <span class="hljs-string"><span class="hljs-string">"test/affenpinscher.jpg"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#basset.jpg") img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. y_pred = model.predict(img_1) Y_pred_classes = np.argmax(y_pred,axis = 1) # print(y_pred) fig, ax = plt.subplots() ax.imshow(img) ax.axis('off') ax.set_title(map_characters[Y_pred_classes[0]]) plt.show()</span></span></code> </pre><br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/032/846/05c03284674e4337a2e5a3ba617634dd.png" alt="图片"><br><br> 接下来，我们需要获取网络输入和输出层的名称（无论是此功能还是创建功能，我们都必须明确地“命名”这些层，而我们没有这样做）。 <br><br><pre> <code class="python hljs">model.summary() &gt;&gt;&gt; Layer (type) &gt;&gt;&gt; ====================== &gt;&gt;&gt; input_7 (InputLayer) &gt;&gt;&gt; ______________________ &gt;&gt;&gt; conv2d_283 (Conv2D) &gt;&gt;&gt; ______________________ &gt;&gt;&gt; ... &gt;&gt;&gt; dense_14 (Dense) &gt;&gt;&gt; ====================== &gt;&gt;&gt; Total params: <span class="hljs-number"><span class="hljs-number">22</span></span>,<span class="hljs-number"><span class="hljs-number">913</span></span>,<span class="hljs-number"><span class="hljs-number">432</span></span> &gt;&gt;&gt; Trainable params: <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">110</span></span>,<span class="hljs-number"><span class="hljs-number">648</span></span> &gt;&gt;&gt; Non-trainable params: <span class="hljs-number"><span class="hljs-number">21</span></span>,<span class="hljs-number"><span class="hljs-number">802</span></span>,<span class="hljs-number"><span class="hljs-number">784</span></span></code> </pre><br><br> 稍后，当我们将神经网络导入Java应用程序时，我们将使用输入和输出层的名称。 <br><br> 漫游网络以获取此数据的另一个代码： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_graph_nodes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> g = tf.GraphDef() g.ParseFromString(open(filename, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>).read()) print() print(filename) print(<span class="hljs-string"><span class="hljs-string">"=======================INPUT==================="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'input'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"=======================OUTPUT=================="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'output'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"===================KERAS_LEARNING=============="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'keras_learning_phase'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"==============================================="</span></span>) print() <span class="hljs-comment"><span class="hljs-comment">#def get_script_path(): # return os.path.dirname(os.path.realpath(sys.argv[0]))</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">但是我不喜欢他，也不推荐他。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">以下代码会将Keras神经网络导出为</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pb</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">格式，这是我们将从Android捕获的格式。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">keras_to_tensorflow</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(keras_model, output_dir, model_name,out_prefix=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"output_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, log_tensorboard=True)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> os.path.exists(output_dir) == <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>: os.mkdir(output_dir) out_nodes = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(keras_model.outputs)): out_nodes.append(out_prefix + str(i + <span class="hljs-number"><span class="hljs-number">1</span></span>)) tf.identity(keras_model.output[i], out_prefix + str(i + <span class="hljs-number"><span class="hljs-number">1</span></span>)) sess = K.get_session() <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> graph_util <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework graph_io init_graph = sess.graph.as_graph_def() main_graph = graph_util.convert_variables_to_constants( sess, init_graph, out_nodes) graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> log_tensorboard: <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.tools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> import_pb_to_tensorboard import_pb_to_tensorboard.import_to_tensorboard( os.path.join(output_dir, model_name), output_dir)</code> </pre><br><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 调用以下函数以导出神经网络： </font></font><br><br></p><pre> <code class="python hljs">model = load_model(working_path + strModelFileName) keras_to_tensorflow(model, output_dir=working_path + strModelFileName, model_name=working_path + <span class="hljs-string"><span class="hljs-string">"models/dogs.pb"</span></span>) print_graph_nodes(working_path + <span class="hljs-string"><span class="hljs-string">"models/dogs.pb"</span></span>)</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 最后一行显示了所得神经网络的结构。 </font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 使用神经网络创建Android应用程序 </font></font></h2><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Android中神经网络的导出已被形式化，不应造成任何困难。</font><font style="vertical-align: inherit;">和往常一样，有几种方法，我们使用的是最流行的（在撰写本文时）。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">首先，我们使用Android Studio创建一个新项目。</font><font style="vertical-align: inherit;">我们将“偷工减料”，因为我们的任务不是android教程。</font><font style="vertical-align: inherit;">因此，该应用程序将仅包含一个活动。</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b3/76e/997/6b376e997b34f45359c46923f6613d60.png" alt="图片"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如您所见，我们添加了“ assets”文件夹并将神经网络复制到其中（我们之前导出的那个）。</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 摇篮文件 </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在此文件中，您需要进行一些更改。</font><font style="vertical-align: inherit;">首先，我们需要导入</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tensorflow-android</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">库</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">它用于Java中的Tensorflow（以及相应的Keras）：</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a16/091/fab/a16091fab2166f834827812611142d26.png" alt="图片"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">另一个不明显的绊脚石：</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versionCode</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versionName</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">当应用程序更改时，您将需要在Google Play上上传新版本。</font><font style="vertical-align: inherit;">如果不更改gdadle中的版本（例如1-&gt; 2-&gt; 3 ...），则无法执行此操作，Google会给出错误消息“此版本已存在”。</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 清单 </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">首先，我们的应用程序将是“繁重的”-100 Mb神经网络将很容易装入现代手机的内存中，但是为从Facebook“共享”的每张照片打开单独的实例绝对不是一个好主意。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">因此，我们禁止创建多个应用程序实例：</font></font><br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">activity</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">".MainActivity"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:launchMode</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"singleTask"</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">通过向</font><font style="vertical-align: inherit;">MainActivity </font><font style="vertical-align: inherit;">添加</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">android：launchMode =“ singleTask”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，我们告诉Android打开（激活）应用程序的现有副本，而不是创建另一个实例。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">然后，我们需要将我们的应用程序包含在列表中，当有人“共享”图片时，系统会显示该应用程序：</font></font><br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">intent-filter</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Send action required to display activity in share list --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">action</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.intent.action.SEND"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Make activity default to launch --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">category</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.intent.category.DEFAULT"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Mime type ie what can be shared with this activity only image and text --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">data</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:mimeType</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"image/*"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">intent-filter</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 最后，我们需要请求应用程序将使用的功能和权限： </font></font><br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-feature</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.hardware.camera"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:required</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"true"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">= </span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.WRITE_EXTERNAL_STORAGE"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.READ_PHONE_STATE"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tools:node</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"remove"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 如果您熟悉Android编程，则此部分不会引起任何问题。 </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 布局应用程序。 </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们将创建两种布局，一种用于纵向，一种用于横向。</font><font style="vertical-align: inherit;">这就是</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portrait布局的</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">样子</font><font style="vertical-align: inherit;">。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们将添加的内容：显示图片的大视野（视图），烦人的广告列表（按下带有骨骼的按钮时显示），“帮助”按钮，用于从“文件/图库”下载图片并从相机捕获图片的按钮，最后（最初是隐藏）用于图像处理的“处理”按钮。</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/f71/882/81f/f7188281ff581965c20c7e818cb0fd77.png" alt="图片"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">根据应用程序的状态，活动本身包含显示和隐藏以及启用/禁用按钮的所有逻辑。</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 主要活动 </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 该活动继承（扩展）了标准的Android活动： </font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MainActivity</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Activity</span></span></span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">考虑负责神经网络操作的代码。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">首先，神经网络接受位图。</font><font style="vertical-align: inherit;">最初，这是来自相机或文件（m_bitmap）的大位图（任意大小），然后我们对其进行转换，从而生成标准256x256像素（m_bitmapForNn）。</font><font style="vertical-align: inherit;">我们还将位图大小（256）存储在一个常量中：</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Bitmap m_bitmap = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Bitmap m_bitmapForNn = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> m_nImageSize = <span class="hljs-number"><span class="hljs-number">256</span></span>;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们必须告诉神经网络输入和输出层的名称。</font><font style="vertical-align: inherit;">我们较早收到了它们（请参见清单），但请记住，在您的情况下，它们可能有所不同：</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String INPUT_NAME = <span class="hljs-string"><span class="hljs-string">"input_7_1"</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String OUTPUT_NAME = <span class="hljs-string"><span class="hljs-string">"output_1"</span></span>;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">然后，我们声明一个变量来保存TensofFlow对象。</font><font style="vertical-align: inherit;">另外，我们存储神经网络文件（位于资产中）的路径：</font></font><br><br><p></p><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私有TensorFlowInferenceInterface tf;</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私有字符串MODEL_PATH = </font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
	“文件：////android_asset/dogs.pb”；</font></font><font></font>
</pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 我们将狗的品种存储在列表中，以便稍后将它们显示给用户，而不是数组索引： </font></font><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String[] m_arrBreedsArray;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最初，我们下载了位图。</font><font style="vertical-align: inherit;">但是，神经网络需要一个RGB值数组，并且其输出是该品种就是图中所示概率的数组。</font><font style="vertical-align: inherit;">因此，我们需要添加两个以上的数组（请注意，我们的训练数据中存在120个犬种）：</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[] m_arrPrediction = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[<span class="hljs-number"><span class="hljs-number">120</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[] m_arrInput = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 下载tensorflow推理库： </font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> { System.loadLibrary(<span class="hljs-string"><span class="hljs-string">"tensorflow_inference"</span></span>); }</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 由于神经网络操作需要时间，因此我们需要在单独的线程中执行它们，否则我们将有可能收到系统消息“应用程序无响应”，更不用说用户不满意了。 </font></font><br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PredictionTask</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AsyncTask</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onPreExecute</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onPreExecute(); } <span class="hljs-comment"><span class="hljs-comment">// --- @Override protected Void doInBackground(Void... params) { try { # We get RGB values packed in integers # from the Bitmap, then break those # integers into individual triplets m_arrInput = new float[ m_nImageSize * m_nImageSize * 3]; int[] intValues = new int[ m_nImageSize * m_nImageSize]; m_bitmapForNn.getPixels(intValues, 0, m_nImageSize, 0, 0, m_nImageSize, m_nImageSize); for (int i = 0; i &lt; intValues.length; i++) { int val = intValues[i]; m_arrInput[i * 3 + 0] = ((val &gt;&gt; 16) &amp; 0xFF) / 255f; m_arrInput[i * 3 + 1] = ((val &gt;&gt; 8) &amp; 0xFF) / 255f; m_arrInput[i * 3 + 2] = (val &amp; 0xFF) / 255f; } // --- tf = new TensorFlowInferenceInterface( getAssets(), MODEL_PATH); //Pass input into the tensorflow tf.feed(INPUT_NAME, m_arrInput, 1, m_nImageSize, m_nImageSize, 3); //compute predictions tf.run(new String[]{OUTPUT_NAME}, false); //copy output into PREDICTIONS array tf.fetch(OUTPUT_NAME, m_arrPrediction); } catch (Exception e) { e.getMessage(); } return null; } // --- @Override protected void onPostExecute(Void result) { super.onPostExecute(result); // --- enableControls(true); // --- tf = null; m_arrInput = null; # strResult contains 5 lines of text # with most probable dog breeds and # their probabilities m_strResult = ""; # What we do below is sorting the array # by probabilities (using map) # and getting in reverse order) the # first five entries TreeMap&lt;Float, Integer&gt; map = new TreeMap&lt;Float, Integer&gt;( Collections.reverseOrder()); for(int i = 0; i &lt; m_arrPrediction.length; i++) map.put(m_arrPrediction[i], i); int i = 0; for (TreeMap.Entry&lt;Float, Integer&gt; pair : map.entrySet()) { float key = pair.getKey(); int idx = pair.getValue(); String strBreed = m_arrBreedsArray[idx]; m_strResult += strBreed + ": " + String.format("%.6f", key) + "\n"; i++; if (i &gt; 5) break; } m_txtViewBreed.setVisibility(View.VISIBLE); m_txtViewBreed.setText(m_strResult); } }</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 在MainActivity的onCreate（）中，我们需要为“ Process”按钮添加onClickListener： </font></font><br><br><pre> <code class="java hljs">m_btn_process.setOnClickListener(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> View.OnClickListener() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onClick</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(View v)</span></span></span><span class="hljs-function"> </span></span>{ processImage(); } });</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 这里的processImage（）只是调用我们上面描述的线程： </font></font><br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">processImage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { enableControls(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); <span class="hljs-comment"><span class="hljs-comment">// --- PredictionTask prediction_task = new PredictionTask(); prediction_task.execute(); } catch (Exception e) { e.printStackTrace(); } }</span></span></code> </pre><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 附加说明 </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们不打算讨论Android的UI编程的细节，因为这当然不适用于移植神经网络的任务。</font><font style="vertical-align: inherit;">但是，有一件事仍然值得一提。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">当我们阻止创建应用程序的其他实例时，我们也破坏了创建和删除活动（控制流程）的通常顺序：如果您“共享” Facebook中的图片，然后共享另一张图片，则该应用程序将不会重新启动。</font><font style="vertical-align: inherit;">这意味着在onCreate中捕获传输数据的“传统”方式是不够的，因为不会调用onCreate。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">解决此问题的方法如下：</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.在MainActivity中的onCreate中，调用onSharedIntent函数：</font></font><br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onCreate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( Bundle savedInstanceState)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onCreate(savedInstanceState); .... onSharedIntent(); ....</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 我们还为onNewIntent添加了一个处理程序： </font></font><br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onNewIntent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Intent intent)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onNewIntent(intent); setIntent(intent); onSharedIntent(); }</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 这是onSharedIntent函数本身： </font></font><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onSharedIntent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Intent receivedIntent = getIntent(); String receivedAction = receivedIntent.getAction(); String receivedType = receivedIntent.getType(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (receivedAction.equals(Intent.ACTION_SEND)) { <span class="hljs-comment"><span class="hljs-comment">// If mime type is equal to image if (receivedType.startsWith("image/")) { m_txtViewBreed.setText(""); m_strResult = ""; Uri receivedUri = receivedIntent.getParcelableExtra( Intent.EXTRA_STREAM); if (receivedUri != null) { try { Bitmap bitmap = MediaStore.Images.Media.getBitmap( this.getContentResolver(), receivedUri); if(bitmap != null) { m_bitmap = bitmap; m_picView.setImageBitmap(m_bitmap); storeBitmap(); enableControls(true); } } catch (Exception e) { e.printStackTrace(); } } } } }</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在，我们在onCreate（如果应用程序不在内存中）或onNewIntent（如果它早先启动）中处理传输的数据。</font></font><br><br><br><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">祝你好运 </font><font style="vertical-align: inherit;">如果您喜欢这篇文章，请以所有可能的方式“喜欢”它，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">网站</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">上也有“社交”按钮</font><font style="vertical-align: inherit;">。</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN448316/">https://habr.com/ru/post/zh-CN448316/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN448300/index.html">会议邮件：CLOUD-关于云及其周围</a></li>
<li><a href="../zh-CN448302/index.html">AdBlock和uBlock过滤器中的漏洞允许在用户端执行任意代码</a></li>
<li><a href="../zh-CN448304/index.html">《行动中的Vue.js》一书</a></li>
<li><a href="../zh-CN448308/index.html">数据科学文摘（2019年4月）</a></li>
<li><a href="../zh-CN448310/index.html">使用Telebot库第1部分在python中编写电报bot</a></li>
<li><a href="../zh-CN448320/index.html">为什么要硅，为什么要CMOS？</a></li>
<li><a href="../zh-CN448322/index.html">C ++ Russia 2019：免费播放第一大厅，并简要介绍了会议的内容</a></li>
<li><a href="../zh-CN448324/index.html">创建程序性地球仪</a></li>
<li><a href="../zh-CN448326/index.html">看穿 如何在不破坏学科的情况下学习学科？</a></li>
<li><a href="../zh-CN448328/index.html">在莫斯科，将展示一台可以打印器官和组织的打印机</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🦉 🛀🏽 😃 Wie man Ton zeichnet und liest 🙍🏿 🤵 ↘️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Foto von Matthew Potter  CC-BY
 
 Wie werden Audio- und Videoinformationen verbunden? Diese Frage wird oft von Wissenschaftlern und Amateuren aus der ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man Ton zeichnet und liest</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/audiomania/blog/393257/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/pw/ry/9p/pwry9psyvxotycy6ivmkj-qkosw.jpeg"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Foto von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Matthew Potter </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CC-BY</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Wie werden Audio- und Videoinformationen verbunden? </font><font style="vertical-align: inherit;">Diese Frage wird oft von Wissenschaftlern und Amateuren aus der ganzen Welt gestellt. </font><font style="vertical-align: inherit;">Im Februar 2006 verbreitete sich die Nachricht, dass es Wissenschaftlern gelungen ist, Geräusche aus einem über 6500 Jahre alten Tontopf zu reproduzieren, schnell im Internet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Töpfer soll während seiner Herstellung einen musikalischen Rhythmus auf den Topf angewendet haben. </font><font style="vertical-align: inherit;">Leider stellte sich heraus, dass dies ein erfolgloser Aprilscherz im belgischen Fernsehen war.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick Feaster </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">konnte jedoch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die Aufzeichnung verarbeiten, deren Alter 1000 Jahre überschreitet. </font><font style="vertical-align: inherit;">Bei dieser Gelegenheit sprach er im Mai 2011 auf der Konferenz der Association for Recorded Sound Collections (ARSC) mit der Eröffnung der „Paläospektrophonie“.</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eintauchen in die Geschichte: Transkribieren vergangener Aufzeichnungen</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick verwendet moderne Technologie (in diesem Fall nicht besonders modern, da das Spektrogramm vor langer Zeit erfunden wurde), um visuelle Objekte in akustische umzuwandeln. Die Menschheit ging jedoch nicht immer diesen Weg und versuchte im Gegenteil, Ton in Bildern „einzufangen“. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lange Zeit (vor der Erstellung des Phonographen durch Thomas Edison) waren die Leute besorgt über die Frage: Wie könnte man eine Methode finden, um Musik zu reparieren, die es der Person, die die Aufnahme sieht, hilft, die Melodie in ihren Köpfen so einfach zu spielen wie professionelle Musiker, wenn sie sich die Partitur ansehen. Leider ist eine solche Aufgabe laut Dr. Fister im Prinzip nicht erreichbar, da unser Gehirn in den meisten Fällen nicht gut genug ist, um visuelle Informationen in Audio umzuwandeln.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vielleicht war die Lösung dieses Problems in der Vergangenheit nicht von Erfolg gekrönt, aber die Geschichte hat uns viele Beweise dafür hinterlassen, wie Menschen in verschiedenen Epochen versucht haben, ähnliche Tonaufzeichnungssysteme zu schaffen. Das bekannteste dieser Systeme bildete die Grundlage des Phono-Autogramms - des Vorgängers des vom Franzosen Edouard Martenville erfundenen Phonographen. Ein Phonoautograph war ein Gerät, bei dem Schall durch einen Kegel geleitet wurde und die mit der Nadel verbundene Membran vibrierte. Die Nadel zeichnete wiederum wellenförmige Linien auf einen Glaszylinder, der mit rußigem Papier bedeckt war.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit Hilfe eines Phono-Autogramms konnte der Ton aufgenommen werden, aber es gab keine Möglichkeit, ihn wiederzugeben. Dies ist das Problem, das Fister entschieden hat. 2008 versammelten er, seine Kollegen und der Audioexperte David Giovannoni sich im Lawrence Berkeley National Laboratory, um einen der am besten erhaltenen Phonoautographen von Martenville zu entziffern. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lawrence's Lab entwickelte Technologien, um Töne aus hochwertigen Fotos zu extrahieren, die Bilder von zerbrechlichen Wachsmedien oder zerbrochenen Discs aufnehmen. Mit diesen Technologien erhielten Wissenschaftler aus dem Phonoautogramm die Aufnahme des 1860 aufgenommenen Liedes „Moonlight“ („Au Clair de la Lune“). Es wird angenommen, dass dies die erste Aufzeichnung ist, auf der wir eine menschliche Stimme unterscheiden können.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Lösung für dieses Problem reichte Fister jedoch nicht aus: Anschließend nahm er nicht nur Ton aus mehr als 50 Tonträgern auf, sondern untersuchte auch frühere Versuche, „Ton aufzunehmen“. </font><font style="vertical-align: inherit;">So seltsam es auch scheinen mag, der Google Books-Dienst hat diesem Wissenschaftler geholfen. </font><font style="vertical-align: inherit;">Damit schrieb Fister Charaktere aus Büchern auf, die ständig ignoriert wurden und als historische Macken galten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Er fand die älteste wellige Linie im Buch von 1806. </font><font style="vertical-align: inherit;">Durch andere Techniken konnte er die Melodie von 1677 entschlüsseln, die von vielen Punkten aufgenommen wurde. </font><font style="vertical-align: inherit;">Eine andere wurde in Aufzeichnungen des 10. Jahrhunderts entdeckt, in denen die Linien zeigten, welche Tonart gesungen werden sollte. </font><font style="vertical-align: inherit;">Beispiele für solche Einträge finden Sie auf seiner </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Phonozoic-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Website </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein anderer Ansatz</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Forscher von MIT, Microsoft und Adobe gehen einen anderen Weg: Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rekonstruieren den</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ton aus einem bewegten (oder vielmehr vibrierenden) Bild. Forscher haben einen Algorithmus entwickelt, um ein Audiosignal aus auf Video aufgezeichneten Vibrationen zu erhalten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einem dieser Experimente gelang es ihnen, lesbare Sprache aus der Aufzeichnung eines leeren Pakets unter den Chips zu extrahieren. In einer Reihe anderer Experimente konnte dasselbe mit der Oberfläche von Aluminiumfolie, einem Glas Wasser und sogar mit den Blättern einer heimischen Pflanze durchgeführt werden. 2014 präsentierte das Team seine Erfolge auf der jährlichen SIGGRAPH-Konferenz. ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> von einer Präsentation eines der Forscher, die auf der TED-Konferenz an dem Projekt gearbeitet haben.)</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tatsache ist, dass ein Geräusch, wenn es mit einem Objekt in Kontakt kommt, es vibrieren lässt. Die Bewegungen, die durch diese Schwingungen erzeugt werden, sind so gering und unsichtbar, dass eine Person sie nicht sehen kann. Die Kamera kann sie jedoch „sehen“: Um das Audiosignal aus dem Video zu extrahieren, verwendeten die Wissenschaftler Videoaufzeichnungen mit einer Bildaufnahmerate, die höher als die Frequenz des Audiosignals ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anfangs wurden in den Experimenten Kameras mit einer Aufnahmefrequenz von 2000 und 6000 Bildern pro Sekunde verwendet, aber die Forscher versuchten, andere, kostengünstigere Kameras zu verwenden. Natürlich war es nicht möglich, mit einer Bildrate von 60 Bildern pro Sekunde artikulierte Sprache aus dem aufgezeichneten Video zu extrahieren, aber es schien immer noch möglich zu sein, zu verstehen, wie viele Personen sich im Raum befanden, welches Geschlecht sie hatten und welche Merkmale ihre Aussprache hatte.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn man über solche Entwicklungen nachdenkt, fallen einem natürlich „Spionagegeschichten“ ein, doch die Forscher selbst nennen ihr Projekt die Möglichkeit, neue Facetten im Bild von Objekten zu entdecken und ihre bisher unerforschten Eigenschaften zu untersuchen. </font><font style="vertical-align: inherit;">Und wenn vor Hunderten von Jahren versucht wurde, einen Weg zu finden, um „Ton aufzunehmen“, wird eine solche „Aufnahme“ jetzt zu einem Nebeneffekt, der wiederum dazu beiträgt, neue Eigenschaften vertrauter Objekte aufzudecken.</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mach es selbst</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie bereits erwähnt, dank der Technologie der Klangwiedergabe die erste fonoavtogrammu aus Fotografien von alten Aufzeichnungen zu </font><font style="vertical-align: inherit;">entziffern (über die Technologie , die </font><font style="vertical-align: inherit;">wir bereits </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">schrieben</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in einem unsere Materialien - es präsentiert wird </font><font style="vertical-align: inherit;">und Link zu der entschlüsselten Datensatz). Patrick Fister betont jedoch, dass jeder diese Aufgabe bewältigen kann - wenn er weiß, was zu tun ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein detaillierter Prozess wird in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">diesem</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Material beschrieben. Wir stellen fest, dass Sie zur Lösung des Problems ein qualitativ hochwertiges Foto, grundlegende Photoshop-Kenntnisse (die auf Vinyl gezeichnete Welle muss digitalisiert, „begradigt“ - die Rille auf der Platte ist spiralförmig gedreht - entfernen Sie alle Arten von Rauschen und Verschiebungen) sowie einen relativ leistungsstarken Computer benötigen mit viel RAM.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um das resultierende Bild in eine WAV-Datei zu konvertieren, verwendet Patrick eine ziemlich exotische Software: Dies ist ImageToSound. Es ist kostenlos, aber trotzdem ist es ziemlich schwierig, es im Netzwerk zu finden (Patrick hat die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle geteilt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Programm konvertiert nacheinander jeden Bildblock (Blockbreite - 1 Pixel) in ein Audio-Sample. Leider unterstützt diese Software nicht einmal Windows 7 (der Autor verwendet einen separaten Computer mit Windows 98, um zu arbeiten). Als Alternative schlägt Fister vor, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">das</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> AEO-Light- </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Programm zu verwenden</font></a><font style="vertical-align: inherit;"> , warnt jedoch davor, dass er selbst nicht vollständig mit den Feinheiten der Arbeit vertraut ist.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der letzte Schritt ist die Steuerung der Wiedergabegeschwindigkeit. Hier hilft einfache Mathematik. Zuerst müssen Sie die Wiedergabegeschwindigkeit auf der Originalplatte, die Länge einer Umdrehung der digitalisierten Welle (nach „Despiralisierung“) in Pixel und die Abtastfrequenz der endgültigen Datei kennen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn das Bild in eine Audiodatei mit einer Abtastfrequenz von 44,1 kHz bearbeitet wurde, bedeutet dies, dass die Sekunde der Audiodatei 44 100 Pixel des Bildes entspricht. Wenn beispielsweise die Geschwindigkeit eines Songs auf einer Schallplatte 50 U / min betrug und nach der Digitalisierung und Despiralisierung eine Umdrehung der Schallplatte 30.000 Pixel dauerte, erhalten wir 1.500.000 Pixel pro Minute (50 x 30.000).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir diese Zahl durch 60 teilen, erhalten wir die Anzahl der Pixel pro Sekunde (1.500.000 / 60 = 25.000). </font><font style="vertical-align: inherit;">Teilen Sie die Abtastrate durch die Anzahl der Pixel pro Sekunde (44 100/25 000 = 1,764). </font><font style="vertical-align: inherit;">Multiplizieren Sie die resultierende Zahl mit der Länge der Audiodatei (Wiedergabezeit des Songs) und erhalten Sie die Zeit, mit der diese Datei ursprünglich aufgenommen wurde. </font><font style="vertical-align: inherit;">Wenn die Wiedergabegeschwindigkeit der Originalaufnahme unbekannt ist, empfiehlt Patrick, die endgültige Geschwindigkeit nach Gehör zu wählen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick Fister warnt - dies ist eine ziemlich mühsame Arbeit, die Zeit und Geduld erfordert, aber gleichzeitig manchmal erstaunliche Ergebnisse liefert: besonders wenn es um die Stimmen der Vergangenheit geht, die anscheinend für immer verloren waren. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS Weitere Materialien zum Thema Audio - in unserem Blog " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">World of Hi-Fi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ".</font></font></i></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de393257/">https://habr.com/ru/post/de393257/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de393243/index.html">Verschwörer freuen sich: Nach dem Erscheinen von UFOs wurde die Sendung der NASA mit der ISS eingestellt</a></li>
<li><a href="../de393247/index.html">Ein paar typische Geschichten vom Entwickler</a></li>
<li><a href="../de393249/index.html">Telegrammsammlung von Bots für Geeks</a></li>
<li><a href="../de393251/index.html">Er weiß alles über dich</a></li>
<li><a href="../de393253/index.html">Der zweite Trailer von WarCraft gibt Anlass zu ernsthaften Bedenken</a></li>
<li><a href="../de393261/index.html">MediaTek Labs lädt Sie zum nächsten kostenlosen Webinar zur Entwicklung von Gadgets für Smart Home ein</a></li>
<li><a href="../de393263/index.html">Wie kann man die Billionen Dollar teilen, die durch den Bergbau im Weltraum verdient werden?</a></li>
<li><a href="../de393265/index.html">Gehackte Drucker an deutschen Universitäten drucken viele antisemitische Flugblätter</a></li>
<li><a href="../de393267/index.html">Schlafwache</a></li>
<li><a href="../de393269/index.html">8 kleine Dinge aus China, um den Arbeitsplatz eines IT-Spezialisten zu organisieren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
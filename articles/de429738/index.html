<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö∂üèΩ üà≤ üì£ Optimale Shard-Anordnung im Elasticsearch-Petabyte-Cluster: Lineare Programmierung üçº ü§¥üèæ ‚òÄÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Herzst√ºck der Suchmaschinen von Meltwater und Fairhair.ai ist Elasticsearch, ein Cluster von Clustern mit Milliarden von Medien- und Social-Media-...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimale Shard-Anordnung im Elasticsearch-Petabyte-Cluster: Lineare Programmierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429738/"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/ee1/f72/fb5ee1f72a2519aae061ef6be05aa09a.png" align="left">  Das Herzst√ºck der Suchmaschinen von Meltwater und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fairhair.ai</a> ist Elasticsearch, ein Cluster von Clustern mit Milliarden von Medien- und Social-Media-Artikeln. <br><br>  Index-Shards in Clustern unterscheiden sich stark in Zugriffsstruktur, Arbeitslast und Gr√∂√üe, was einige sehr interessante Probleme aufwirft. <br><br>  In diesem Artikel beschreiben wir, wie wir mithilfe der linearen Programmierung (lineare Optimierung) die Such- und Indizierungsarbeitslast so gleichm√§√üig wie m√∂glich auf alle Knoten in den Clustern verteilt haben.  Diese L√∂sung verringert die Wahrscheinlichkeit, dass ein Knoten zu einem Engpass im System wird.  Infolgedessen haben wir die Suchgeschwindigkeit erh√∂ht und Infrastruktur gespart. <br><a name="habracut"></a><br><h1>  Hintergrund </h1><br>  Die Suchmaschinen von Fairhair.ai enthalten etwa 40 Milliarden Beitr√§ge aus sozialen Medien und Leitartikeln, die t√§glich Millionen von Anfragen bearbeiten.  Die Plattform bietet Kunden Suchergebnisse, Grafiken, Analysen und Datenexporte f√ºr erweiterte Analysen. <br><br>  Diese massiven Datens√§tze befinden sich in mehreren Elasticsearch-Clustern mit 750 Knoten und Tausenden von Indizes in √ºber 50.000 Shards. <br><br>  Weitere Informationen zu unserem Cluster finden Sie in fr√ºheren Artikeln zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Architektur</a> und zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Load Balancer f√ºr maschinelles Lernen</a> . <br><br><h1>  Ungleichm√§√üige Arbeitslastverteilung </h1><br>  Sowohl unsere Daten als auch Benutzeranfragen sind normalerweise datumsgebunden.  Die meisten Anfragen fallen in einen bestimmten Zeitraum, z. B. letzte Woche, letzten Monat, letztes Quartal oder einen beliebigen Bereich.  Um die Indizierung und Abfragen zu vereinfachen, verwenden wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeitindizierung</a> √§hnlich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem ELK-Stapel</a> . <br><br>  Diese Indexarchitektur bietet mehrere Vorteile.  Sie k√∂nnen beispielsweise eine effiziente Massenindizierung durchf√ºhren und ganze Indizes l√∂schen, wenn Daten veraltet sind.  Dies bedeutet auch, dass die Arbeitslast f√ºr einen bestimmten Index im Laufe der Zeit stark variiert. <br><br>  Im Vergleich zu den alten werden exponentiell mehr Abfragen an die neuesten Indizes gesendet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd9/4a6/25a/cd94a625ae06e77932216d721bb5eea7.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">1. Zugriffsschema f√ºr Zeitindizes.</font></i>  <i><font color="gray">Die vertikale Achse repr√§sentiert die Anzahl der abgeschlossenen Abfragen, die horizontale Achse repr√§sentiert das Alter des Index.</font></i>  <i><font color="gray">W√∂chentliche, monatliche und j√§hrliche Hochebenen sind deutlich sichtbar, gefolgt von einem langen Schwanz geringerer Arbeitsbelastung bei √§lteren Indizes</font></i> <br><br>  Die Muster in Abb.  Ich war ziemlich vorhersehbar, da unsere Kunden mehr an frischen Informationen interessiert sind und regelm√§√üig den aktuellen Monat mit der Vergangenheit und / oder dieses Jahr mit dem vergangenen Jahr vergleichen.  Das Problem ist, dass Elasticsearch dieses Muster nicht kennt und nicht automatisch f√ºr die beobachtete Arbeitslast optimiert! <br><br>  Der integrierte Elasticsearch-Shard-Zuweisungsalgorithmus ber√ºcksichtigt nur zwei Faktoren: <br><br><ol><li>  <i>Die Anzahl der Shards</i> auf jedem Knoten.  Der Algorithmus versucht, die Anzahl der Shards pro Knoten im gesamten Cluster gleichm√§√üig auszugleichen. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beschriftet den</a> freien Speicherplatz.  Elasticsearch ber√ºcksichtigt den verf√ºgbaren Speicherplatz auf einem Knoten, bevor entschieden wird, ob diesem Knoten neue Shards zugewiesen oder Segmente von diesem Knoten auf andere verschoben werden sollen.  Bei 80% der verwendeten Festplatte ist es verboten, neue Shards auf einem Knoten zu platzieren. 90% des Systems beginnen, Shards aktiv von diesem Knoten zu √ºbertragen. </li></ol><br>  Die Grundannahme des Algorithmus ist, dass jedes Segment im Cluster ungef√§hr die gleiche Arbeitslast erh√§lt und dass jeder die gleiche Gr√∂√üe hat.  In unserem Fall ist dies sehr weit von der Wahrheit entfernt. <br><br>  Standard-Lastausgleich f√ºhrt schnell zu Hot Spots im Cluster.  Sie erscheinen und verschwinden zuf√§llig, wenn sich die Arbeitslast im Laufe der Zeit √§ndert. <br><br>  Ein Hot Spot ist im Wesentlichen ein Host, der nahe der Grenze einer oder mehrerer Systemressourcen arbeitet, z. B. einer CPU, einer Festplatten-E / A oder einer Netzwerkbandbreite.  In diesem Fall stellt der Knoten die Anforderungen zun√§chst f√ºr eine Weile in die Warteschlange, wodurch sich die Antwortzeit auf die Anforderung erh√∂ht.  Wenn die √úberlastung jedoch lange anh√§lt, werden die Anforderungen letztendlich abgelehnt und Benutzer erhalten Fehler. <br><br>  Eine weitere h√§ufige Folge der √úberlastung ist der instabile Druck des JVM-M√ºlls aufgrund von Abfragen und Indexierungsvorg√§ngen, der zum Ph√§nomen der ‚Äûgruseligen H√∂lle‚Äú des JVM-M√ºllsammlers f√ºhrt.  In einer solchen Situation kann die JVM den Speicher entweder nicht schnell genug abrufen und st√ºrzt nicht mehr ab oder sie bleibt in einem endlosen Speicherbereinigungszyklus stecken, friert ein und reagiert nicht mehr auf Clusteranforderungen und Pings. <br><br>  Das Problem verschlimmerte sich, als wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unsere Architektur unter AWS √ºberarbeiteten</a> .  Zuvor wurden wir durch die Tatsache ‚Äûgerettet‚Äú, dass wir bis zu vier Elasticsearch-Knoten auf unseren eigenen leistungsstarken Servern (24 Kerne) in unserem Rechenzentrum ausgef√ºhrt haben.  Dies maskierte den Einfluss der asymmetrischen Verteilung der Scherben: Die Last wurde durch eine relativ gro√üe Anzahl von Kernen auf der Maschine weitgehend gegl√§ttet. <br><br>  Nach dem Refactoring haben wir jeweils nur einen Knoten auf weniger leistungsstarken Maschinen (8 Kerne) platziert - und die ersten Tests haben sofort gro√üe Probleme mit den ‚ÄûHot Spots‚Äú ergeben. <br><br>  Elasticsearch weist Shards in zuf√§lliger Reihenfolge zu, und bei mehr als 500 Knoten in einem Cluster hat die Wahrscheinlichkeit zu vieler ‚Äûhei√üer‚Äú Shards auf einem einzelnen Knoten stark zugenommen - und solche Knoten sind schnell √ºbergelaufen. <br><br>  F√ºr Benutzer w√ºrde dies eine ernsthafte Verschlechterung der Arbeit bedeuten, da √ºberlastete Knoten langsam reagieren und Anforderungen oder Abst√ºrze manchmal vollst√§ndig ablehnen.  Wenn Sie ein solches System in die Produktion bringen, werden Benutzer anscheinend h√§ufig zuf√§llige Verlangsamungen der Benutzeroberfl√§che und zuf√§llige Zeit√ºberschreitungen feststellen. <br><br>  Gleichzeitig bleibt eine gro√üe Anzahl von Knoten mit Shards ohne viel Last √ºbrig, die tats√§chlich inaktiv sind.  Dies f√ºhrt zu einer ineffizienten Nutzung unserer Clusterressourcen. <br><br>  Beide Probleme k√∂nnten vermieden werden, wenn Elasticsearch Shards intelligenter verteilt, da der durchschnittliche Verbrauch von Systemressourcen an allen Knoten bei einem gesunden Niveau von 40% liegt. <br><br><h3>  Cluster Continuous Change </h3><br>  Bei der Arbeit mit mehr als 500 Knoten haben wir noch eines beobachtet: eine st√§ndige √Ñnderung des Knotenzustands.  Scherben bewegen sich in Knoten unter dem Einfluss der folgenden Faktoren st√§ndig hin und her: <br><br><ul><li>  Neue Indizes werden erstellt und alte verworfen. </li><li>  Datentr√§gerbezeichnungen werden aufgrund von Indizierung und anderen Shard-√Ñnderungen ausgel√∂st. </li><li>  Elasticsearch entscheidet zuf√§llig, dass der Knoten im Vergleich zum Durchschnittswert des Clusters zu wenige oder zu viele Shards enth√§lt. </li><li>  Hardware-Abst√ºrze und Abst√ºrze auf Betriebssystemebene f√ºhren dazu, dass neue AWS-Instanzen gestartet und dem Cluster hinzugef√ºgt werden.  Bei 500 Knoten geschieht dies durchschnittlich mehrmals pro Woche. </li><li>  Aufgrund des normalen Datenwachstums werden fast jede Woche neue Websites hinzugef√ºgt. </li></ul><br>  Unter Ber√ºcksichtigung all dessen kamen wir zu dem Schluss, dass eine komplexe und kontinuierliche L√∂sung aller Probleme einen kontinuierlichen und dynamischen Algorithmus zur Neuoptimierung erfordert. <br><br><h3>  L√∂sung: Shardonnay </h3><br>  Nach einer langen Untersuchung der verf√ºgbaren Optionen kamen wir zu dem Schluss, dass wir: <br><br><ol><li>  Erstellen Sie Ihre eigene L√∂sung.  Wir haben keine guten Artikel, Codes oder andere vorhandene Ideen gefunden, die in unserem Ma√üstab und f√ºr unsere Aufgaben gut funktionieren w√ºrden. </li><li>  Starten Sie den Neuausgleichsprozess au√üerhalb von Elasticsearch und verwenden Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Clustered Redirect-APIs,</a> anstatt zu versuchen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, ein Plugin</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erstellen</a> .  Wir wollten eine schnelle R√ºckkopplungsschleife, und die Bereitstellung eines Plugins in einem Cluster dieser Gr√∂√üenordnung kann mehrere Wochen dauern. </li><li>  Verwenden Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lineare Programmierung</a> , um zu jedem Zeitpunkt optimale Shard-Bewegungen zu berechnen. </li><li>  F√ºhren Sie die Optimierung kontinuierlich durch, damit der Clusterstatus allm√§hlich optimal wird. </li><li>  Bewegen Sie nicht zu viele Scherben gleichzeitig. </li></ol><br>  Wir haben eine interessante Sache bemerkt: Wenn Sie zu viele Scherben gleichzeitig bewegen, ist es sehr einfach, einen <i>kaskadierenden Sturm von Scherbenbewegungen</i> auszul√∂sen.  Nach dem Einsetzen eines solchen Sturms kann es stundenlang andauern, wenn sich die Scherben unkontrolliert hin und her bewegen und an verschiedenen Stellen Markierungen √ºber den kritischen Speicherplatz auftreten.  Dies f√ºhrt wiederum zu neuen Splitterbewegungen und so weiter. <br><br>  Um zu verstehen, was passiert, ist es wichtig zu wissen, dass beim Verschieben eines aktiv indizierten Segments tats√§chlich viel mehr Speicherplatz auf der Festplatte belegt wird, von der es verschoben wird.  Dies liegt daran, wie Elasticsearch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transaktionsprotokolle</a> speichert.  Wir haben F√§lle gesehen, in denen sich der Index beim Verschieben eines Knotens verdoppelt hat.  Dies bedeutet, dass der Knoten, der die Shard-Bewegung aufgrund der hohen Speicherplatznutzung initiiert hat, <i>f√ºr eine</i> Weile <i>noch mehr Speicherplatz ben√∂tigt,</i> bis gen√ºgend Shards auf andere Knoten verschoben werden. <br><br>  Um dieses Problem zu l√∂sen, haben wir den <i>Shardonnay-</i> Service zu Ehren der ber√ºhmten Chardonnay-Rebsorte entwickelt. <br><br><h3>  Lineare Optimierung </h3><br>  Die lineare Optimierung (oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lineare Programmierung</a> , LP) ist eine Methode, um das beste Ergebnis wie maximalen Gewinn oder niedrigste Kosten in einem mathematischen Modell zu erzielen, dessen Anforderungen durch lineare Beziehungen dargestellt werden. <br><br>  Die Optimierungsmethode basiert auf einem System linearer Variablen, einigen Einschr√§nkungen, die erf√ºllt sein m√ºssen, und einer Zielfunktion, die bestimmt, wie eine erfolgreiche L√∂sung aussieht.  Das Ziel der linearen Optimierung besteht darin, die Werte von Variablen zu finden, die die Zielfunktion unter Einschr√§nkungen minimieren. <br><br><h3>  Scherbenverteilung als lineares Optimierungsproblem </h3><br>  Shardonnay sollte kontinuierlich arbeiten und bei jeder Iteration den folgenden Algorithmus ausf√ºhren: <br><br><ol><li>  Mithilfe der API ruft Elasticsearch Informationen zu vorhandenen Shards, Indizes und Knoten im Cluster sowie deren aktuellen Speicherort ab. </li><li>  Modelliert den Status eines Clusters als Satz bin√§rer LP-Variablen.  Jede Kombination (Knoten, Index, Shard, Replikat) erh√§lt eine eigene Variable.  Im LP-Modell gibt es eine Reihe sorgf√§ltig entworfener Heuristiken, Einschr√§nkungen und eine objektive Funktion, mehr dazu weiter unten. </li><li>  Sendet das LP-Modell an einen linearen L√∂ser, der unter Ber√ºcksichtigung der Einschr√§nkungen und der Zielfunktion eine optimale L√∂sung bietet.  Die L√∂sung besteht darin, Shards Knoten neu zuzuweisen. </li><li>  Interpretiert die L√∂sung der LP und wandelt sie in eine Folge von Splitterbewegungen um. </li><li>  Weist Elasticsearch an, Shards durch die Clusterumleitungs-API zu verschieben. </li><li>  Wartet darauf, dass der Cluster die Shards verschiebt. </li><li>  Kehrt zu Schritt 1 zur√ºck. </li></ol><br>  Die Hauptsache ist, die richtigen Einschr√§nkungen und die richtige Zielfunktion zu entwickeln.  Der Rest wird von Solver LP und Elasticsearch erledigt. <br><br>  Es √ºberrascht nicht, dass die Aufgabe f√ºr einen Cluster dieser Gr√∂√üe und Komplexit√§t sehr schwierig war! <br><br><h3>  Einschr√§nkungen </h3><br>  Wir st√ºtzen das Modell auf einige Einschr√§nkungen, die auf den von Elasticsearch selbst vorgegebenen Regeln basieren.  Halten Sie sich beispielsweise immer an Festplattenetiketten oder verbieten Sie das Platzieren eines Replikats auf demselben Knoten wie ein anderes Replikat desselben Shards. <br><br>  Andere werden aufgrund der jahrelangen Erfahrung mit gro√üen Clustern hinzugef√ºgt.  Hier sind einige Beispiele f√ºr unsere eigenen Einschr√§nkungen: <br><br><ul><li>  Verschieben Sie die heutigen Indizes nicht, da sie am hei√üesten sind und das Lesen und Schreiben nahezu konstant belasten. </li><li>  Bevorzugen Sie kleinere Shards, da Elasticsearch sie schneller verarbeitet. </li><li>  Es ist ratsam, zuk√ºnftige Shards einige Tage vor ihrer Aktivierung zu erstellen und zu platzieren, mit der Indizierung zu beginnen und einer hohen Belastung zu unterliegen. </li></ul><br><br><h3>  Kostenfunktion </h3><br>  Unsere Kostenfunktion wiegt verschiedene Faktoren zusammen.  Zum Beispiel wollen wir: <br><br><ul><li>  Minimieren Sie die Varianz von Indizierungs- und Suchanfragen, um die Anzahl der "Hot Spots" zu verringern. </li><li>  Halten Sie die minimale Varianz der Festplattennutzung f√ºr einen stabilen Systembetrieb ein. </li><li>  Minimieren Sie die Anzahl der Splitterbewegungen, damit "St√ºrme" mit einer Kettenreaktion nicht wie oben beschrieben beginnen. </li></ul><br><h3>  Reduktion von LP-Variablen </h3><br>  In unserer Gr√∂√üenordnung wird die Gr√∂√üe dieser LP-Modelle zum Problem.  Wir haben schnell erkannt, dass Probleme mit mehr als 60 Millionen Variablen nicht in angemessener Zeit gel√∂st werden k√∂nnen.  Daher haben wir viele Optimierungs- und Modellierungstricks angewendet, um die Anzahl der Variablen drastisch zu reduzieren.  Dazu geh√∂ren voreingenommene Stichproben, Heuristiken, die Divide-and-Conquer-Methode, iterative Relaxation und Optimierung. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/4db/240/fb2/4db240fb21653d48fd6a5ad69728082e.png"></a> <br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">2. Die Heatmap zeigt die unausgeglichene Last des Elasticsearch-Clusters.</font></i>  <i><font color="gray">Dies √§u√üert sich in einer gro√üen Streuung des Ressourcenverbrauchs auf der linken Seite des Diagramms.</font></i>  <i><font color="gray">Durch kontinuierliche Optimierung stabilisiert sich die Situation allm√§hlich</font></i> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/19c/fa6/f18/19cfa6f1813be7f3a2ae9d90c58570b2.png"></a> <br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">3. Die Heatmap zeigt die CPU-Auslastung auf allen Knoten des Clusters vor und nach dem Einrichten der Hotness-Funktion in Shardonnay.</font></i>  <i><font color="gray">Eine signifikante √Ñnderung der CPU-Auslastung ist bei konstanter Arbeitslast zu beobachten.</font></i> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/dfc/288/81f/dfc28881fa593f543c14c8aa14069525.png"></a> <br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">4. Die Heatmap zeigt den Lesedurchsatz der Festplatten im gleichen Zeitraum wie in Abb. 4.</font></i>  <i><font color="gray">3. Lesevorg√§nge sind auch gleichm√§√üiger √ºber den Cluster verteilt.</font></i> <br><br><h1>  Ergebnisse </h1><br>  Dadurch findet unser LP-Solver in wenigen Minuten gute L√∂sungen, selbst f√ºr unseren riesigen Cluster.  Somit verbessert das System iterativ den Zustand des Clusters in Richtung der Optimalit√§t. <br><br>  Und das Beste daran ist, dass die Streuung der Arbeitslast und der Festplattennutzung wie erwartet konvergiert - und dieser nahezu optimale Zustand bleibt nach vielen absichtlichen und unerwarteten √Ñnderungen des Clusterzustands seitdem erhalten! <br><br>  Wir unterst√ºtzen jetzt eine gesunde Arbeitslastverteilung in unseren Elasticsearch-Clustern.  Alles dank linearer Optimierung und unserem Service, den wir gerne <i>Chardonnay</i> nennen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429738/">https://habr.com/ru/post/de429738/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429724/index.html">N√ºtzliche Bewertung. 28 B√ºcher, die mein Denken beeinflusst, inspiriert oder verbessert haben</a></li>
<li><a href="../de429728/index.html">Moderne MVI-Architektur basierend auf Kotlin</a></li>
<li><a href="../de429732/index.html">Du wirst das oder eine Geschichte dar√ºber hassen, wie gut Code aussehen sollte</a></li>
<li><a href="../de429734/index.html">Der Traum vom Fliegen mit elektrischer Vorspannung</a></li>
<li><a href="../de429736/index.html">Hogweed von Sosnowski. In MO wurden Bu√ügelder f√ºr den Vertrieb eingef√ºhrt</a></li>
<li><a href="../de429744/index.html">Lerne OpenGL. Lektion 6.4 - IBL. Spiegelexposition</a></li>
<li><a href="../de429750/index.html">Entwicklerkochbuch: DDD-Rezepte (Teil 3, Anwendungsarchitektur)</a></li>
<li><a href="../de429754/index.html">Schwerwiegende Hardware-Integrationsfehler</a></li>
<li><a href="../de429756/index.html">So konfigurieren Sie die Installation der Umgebungsvariablen von Nuxt.j zur Laufzeit oder wie Sie alles tun, was nicht jedem gef√§llt, und es nicht bereuen</a></li>
<li><a href="../de429758/index.html">Warum SRE-Dokumentation wichtig ist. Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
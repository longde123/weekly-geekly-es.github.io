<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóΩ üèÜ üöÉ Peg Parser üï∂Ô∏è üëΩ üç®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor einigen Jahren fragte mich jemand, ob es sinnvoll sei, Python in einen PEG-Parser (oder in eine PEG-Grammatik zu konvertieren; ich erinnere mich n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Peg Parser</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471860/"><p>  Vor einigen Jahren fragte mich jemand, ob es sinnvoll sei, Python in einen PEG-Parser (oder in eine PEG-Grammatik zu konvertieren; ich erinnere mich nicht genau, wer und wann es war).  Dann sah ich ihn ein wenig an, kam aber zu keinem Ergebnis und lie√ü dieses Thema fallen.  Ich habe k√ºrzlich mehr √ºber PEG (Parsing Expression Grammars, Parsing Expression Grammar) erfahren und denke jetzt, dass dies eine interessante Alternative zu dem selbstgeschriebenen Parser-Generator ist, der vor 30 Jahren entwickelt wurde, als ich gerade anfing, an Python zu arbeiten.  Ich nannte es "pgen" und dies war wahrscheinlich der erste Code, den ich f√ºr Python schrieb. </p><br><div class="spoiler">  <b class="spoiler_title">Inhalt der Python PEG Parser-Serie</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Peg Parser</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PEG-Parser-Implementierung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PEG-Parser-Generierung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PEG-Parser-Visualisierung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Linke rekursive PEG-Grammatik</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hinzuf√ºgen von Aktionen zur PEG-Grammatik</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Meta-Grammatik f√ºr PEG-Parser</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung der verbleibenden Funktionen von PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PEG auf Core Developer Sprint</a> </li></ul></div></div><br><p> Der Grund, warum ich mich derzeit f√ºr den PEG-Parser interessiere, ist, dass mich die Einschr√§nkungen von pgen etwas √§rgern.  Es basiert auf einer eigenen Implementierung von LL (1), die eine Reihe von Annahmen enth√§lt.  Zum Beispiel mochte ich keine Grammatikregeln, die leere Zeilen erzeugen k√∂nnten, deshalb habe ich sie verboten.  Dadurch wurde der Algorithmus zum Erstellen von Parsing-Tabellen vereinfacht.  Ich habe auch meine eigene EBNF-√§hnliche Grammatiknotation erfunden, die ich immer noch sehr mag. </p><a name="habracut"></a><br><p> Hier sind einige Probleme mit pgen, die mich nerven.  Die ‚Äû1‚Äú im Namen LL (1) impliziert, dass nur das n√§chste Token analysiert wird, und dies schr√§nkt unsere F√§higkeit ein, gute Grammatikregeln zu erstellen.  Eine Python-Anweisung kann beispielsweise ein Ausdruck oder eine Zuweisung sein (oder etwas anderes, aber alle beginnen mit einem hervorgehobenen Schl√ºsselwort, z. B. <code>if</code> oder <code>def</code> ).  Ich m√∂chte die Syntax in pgen-Notation beschreiben.  Beachten Sie, dass dies nur ein vereinfachtes Beispiel ist, bei dem es sich um eine Teilmenge von Python handelt, wie dies normalerweise bei der Beschreibung des Sprachdesigns der Fall ist.  Dies wird eine Spielzeuggrammatik sein, die f√ºr weitere Demonstrationen n√ºtzlich sein wird. </p><br><pre> <code class="plaintext hljs">statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement</code> </pre> <br><p>  Ein paar Worte zur Notation: <code>NAME</code> und <code>NUMBER</code> sind Token und au√üerhalb der Grammatik vordefiniert.  Zitierte Zeichenfolgen vom Typ <code>'+'</code> oder <code>'if'</code> sind ebenfalls Token.  (Verschieben wir das n√§chste Mal die Diskussion dar√ºber.) Grammatikregeln beginnen mit dem Namen der Regel, gefolgt von <code>:</code> und einer oder mehreren Alternativen, die durch <code>|</code>  . </p><br><p>  Das Problem ist, dass wenn Sie die Grammatik so beschreiben, pgen nicht funktioniert.  Dies liegt an der Tatsache, dass einige Regeln ( <code>expr</code> und <code>term</code> ) rekursiv bleiben und er nicht klug genug ist, um mit solchen Situationen richtig <code>expr</code> .  Normalerweise wird dies gel√∂st, indem nur diese Regeln neu geschrieben werden und die anderen Regeln unver√§ndert bleiben.  Zum Beispiel: </p><br><pre> <code class="plaintext hljs">expr: term ('+' term | '-' term)* term: atom ('*' atom | '/' atom)*</code> </pre> <br><p>  Dies zeigt verschiedene M√∂glichkeiten von EBNF in pgen: Sie k√∂nnen Alternativen in Klammern verschachteln und Wiederholungen erstellen, indem Sie <code>*</code> nach dem Element setzen.  Die Regel f√ºr den Ausdruck Ausdruck <code>expr</code> hier also "es ist ein Term, gefolgt von null oder mehr Wiederholungen der Sequenz &lt;Term plus oder minus, gefolgt von Term&gt;".  Diese Grammatik hat dieselbe Sprache wie die erste Version, spiegelt jedoch nicht die Entwurfsabsicht der Sprache wider.  Insbesondere wird nicht angezeigt, dass die Operatoren links gebunden sind. Dies ist wichtig, wenn Sie versuchen, Code zu generieren. </p><br><p>  In diesem Beispiel (und auch in Python) gibt es jedoch ein weiteres √§rgerliches Problem.  Da nur ein Token analysiert wird, kann der Analysator nicht bestimmen, was er betrachtet - den Beginn eines Ausdrucks oder einer Zuweisung.  Zu Beginn der Operatorverarbeitung sollte der Parser nur √ºber das erste Token entscheiden, welche Alternative er analysiert.  (Warum? So funktioniert die Implementierung von Parsing in pgen) Nehmen wir an, unser Programm sieht wie folgt aus: </p><br><pre> <code class="plaintext hljs">answer = 42</code> </pre> <br><p>  Dieses Programm wird durch drei Token dargestellt: <code>NAME</code> (mit <code>answer</code> ), <code>=</code> und <code>NUMBER</code> (mit Wert <code>42</code> ).  Das einzige, was wir zu Beginn der Analyse wissen, ist das erste <code>NAME</code> Token.  Die Regel, die wir zu diesem Zeitpunkt zu analysieren versuchen, ist die <code>statement</code> (der Anfangscharakter der Grammatik).  <code>expr</code> sind drei Alternativen definiert: <code>expr</code> , <code>assignment</code> und <code>if_statement</code> .  Wir k√∂nnen <code>if_statement</code> sofort ausschlie√üen, da das vorherige Token nicht <code>if</code> .  Aber sowohl <code>expr</code> als auch <code>assignment</code> k√∂nnen mit dem <code>NAME</code> Token beginnen, und aus diesem Grund lehnt pgen unsere Grammatik als mehrdeutig ab. </p><br><p>  Dies ist nicht ganz richtig, da technisch die Grammatik selbst nicht ist;  Ich kann keine genauere Formulierung finden, also lassen Sie uns auf diese eingehen.  Und wie l√∂st pgen das?  Es berechnet f√ºr jede Grammatikregel eine sogenannte FIRST-Menge. Wenn sie sich √ºberschneiden, wird eine Ausnahme ausgel√∂st. </p><br><p>  K√∂nnen wir dieses Problem nicht l√∂sen, indem wir dem Parser einen gr√∂√üeren Anzeigepuffer zur Verf√ºgung stellen?  In unserem Beispiel ist ein zweites Vorschau-Token ausreichend, da in dieser Grammatik das zweite Zuweisungstoken <code>=</code> .  In einer realistischeren Sprache wie Python ben√∂tigen Sie m√∂glicherweise einen unbegrenzten Puffer, da der Inhalt links vom <code>=</code> token <code>=</code> beliebig komplex sein kann, zum Beispiel: </p><br><pre> <code class="python hljs">table[index + <span class="hljs-number"><span class="hljs-number">1</span></span>].name.first = <span class="hljs-string"><span class="hljs-string">'Steven'</span></span></code> </pre> <br><p>  In diesem Fall m√ºssen Sie zehn Token analysieren, bevor wir uns treffen <code>=</code> .  Aber ich versichere Ihnen, es kann l√§ngere Ausdr√ºcke geben.  Um dieses Problem in pgen zu l√∂sen, haben wir den Grammatikanalysator so ge√§ndert, dass einige falsche Ausdr√ºcke akzeptiert werden, und in einem nachfolgenden Durchgang eine zus√§tzliche Pr√ºfung hinzugef√ºgt.  Es wird ein SyntaxError-Fehler ausgegeben, wenn er nicht mit der linken und rechten Seite √ºbereinstimmen kann.  F√ºr unsere Spielzeugsprache kommt es darauf an, Folgendes zu schreiben: </p><br><pre> <code class="plaintext hljs">statement: assignment_or_expr | if_statement assignment_or_expr: expr ['=' expr]</code> </pre> <br><p>  Eckige Klammern kennzeichnen ein optionales Teil.  Und dann pr√ºfen wir beim n√§chsten Durchgang des Compilers (z. B. beim Generieren von Bytecode), ob <code>=</code> oder nicht, und wenn ja, pr√ºfen wir, ob die linke Seite mit der Zielsyntax √ºbereinstimmt. </p><br><p>  Es gibt ein √§hnliches Problem f√ºr Funktionsaufrufargumente.  Wir m√∂chten so etwas schreiben (wieder in einer vereinfachten Version der Python-Syntax): </p><br><pre> <code class="plaintext hljs">call: atom '(' arguments ')' arguments: arg (',' arg) * arg: posarg | kwarg posarg: expr kwarg: NAME '=' expr</code> </pre> <br><p>  Der Parsing-Algorithmus, der nur das n√§chste Token ber√ºcksichtigt, kann dem Parser jedoch nicht mitteilen, ob <code>NAME</code> am Anfang von Argumenten der Beginn von <code>posarg</code> (da <code>expr</code> mit <code>NAME</code> beginnen kann) oder der Beginn von <code>kwarg</code> .  Der aktuelle Python-Parser l√∂st dieses Problem erneut, indem er Folgendes ermittelt: </p><br><pre> <code class="plaintext hljs">arg: expr ['=' expr]</code> </pre> <br><p>  und vervollst√§ndigt dann die Alternative in einem nachfolgenden Compiler-Durchlauf.  (Wir haben sogar einen kleinen Fehler gemacht und <code>foo((a) = 1)</code> genau wie <code>foo(a = 1)</code> analysiert. Dies wurde nur in Python 3.8 behoben.) </p><br><p>  Wie l√∂st ein PEG-Parser diese Probleme?  Verwenden eines unendlichen Sicherungspuffers!  Die typische Implementierung verwendet den sogenannten Packrat-Parser, der nicht nur das gesamte Programm vor dem Parsen in den Speicher l√§dt, sondern auch das Zur√ºcksetzen des Analysators auf eine beliebige Anzahl von Token erm√∂glicht.  Obwohl sich der Begriff PEG haupts√§chlich auf die grammatikalische Notation bezieht, sind aus PEG-Grammatiken erzeugte Parser typischerweise Parser mit rekursiver Abstammung und unbegrenzter Rendite.  Der Packrat-Parser macht das Ego effizient, indem er sich an die Regeln erinnert, die bereits f√ºr bestimmte Positionen analysiert wurden. </p><br><p>  Dies vereinfacht den Algorithmus, aber nat√ºrlich gibt es einen Preis: Speicher.  Vor drei√üig Jahren hatte ich einen guten Grund, LL (1) zu verwenden: Speicher war teuer.  Er (wie andere Technologien wie LALR (1), bekannt geworden durch YACC) verwendet eine Zustandsmaschine und einen Stapel, um einen Analysebaum effizient zu erstellen. </p><br><p>  Gl√ºcklicherweise haben Computer mit CPython viel mehr Speicher als vor 30 Jahren, und das Speichern der gesamten Datei im Speicher ist kein Problem mehr.  Die gr√∂√üte Nicht-Test-Datei in stdlib, die ich finden konnte, ist beispielsweise <code>_pydecimal.py</code> , was ungef√§hr 223 <code>_pydecimal.py</code> dauert.  In der Gigabyte-Welt ist dies im Wesentlichen nichts, was mich dazu veranlasste, Parser anders zu betrachten. </p><br><p>  Aber es gibt noch eine Sache im aktuellen CPython-Parser, die mich st√∂rt.  Compiler sind komplexe Dinge, und die Implementierung f√ºr CPython ist keine Ausnahme.  Obwohl das Ergebnis des pgen-Parsers ein Parsing-Baum ist, wird er nicht direkt als Eingabe f√ºr den Bytecode-Generator verwendet: Er wird zuerst in einen abstrakten Syntaxbaum (AST) konvertiert, und erst dann wird dieser AST in Bytecode kompiliert.  (Tats√§chlich ist es dort noch komplizierter, aber wir werden vorerst nicht auf Details eingehen.) </p><br><p>  Warum nicht sofort aus einem Analysebaum kompilieren?  Genau so war es, aber vor ungef√§hr 15 Jahren stellten wir fest, dass der Compiler √ºberkompliziert war.  Also haben wir AST und die Transformationsphase von AST getrennt vom Analysebaum isoliert.  W√§hrend sich Python weiterentwickelte, blieb AST stabiler als das Parsen, was die Wahrscheinlichkeit von Fehlern im Compiler verringerte. </p><br><p>  AST ist auch einfacher mit Bibliotheken von Drittanbietern zu arbeiten, die Python-Code testen m√∂chten.  Es kann mit dem beliebten <code>ast</code> Modul bezogen werden.  Au√üerdem k√∂nnen Sie Knoten von Grund auf neu erstellen und vorhandene √§ndern sowie Teile zu Bytecode kompilieren.  Letzteres erm√∂glichte die Schaffung einer ganzen Branche von Spracherweiterungen f√ºr Python.  (Der Analysebaum ist auch f√ºr Python-Benutzer √ºber das Parsing-Modul zug√§nglich, die Arbeit damit ist jedoch viel schwieriger. Daher ist er nicht so beliebt.) </p><br><p>  Jetzt m√∂chte ich diese Dinge kombinieren und sehen, ob wir einen neuen Parser f√ºr CPython erstellen k√∂nnen, der PEG und Packrat verwendet, um den AST direkt w√§hrend des Parsens zu erstellen.  Somit wird es m√∂glich sein, die Erzeugung des Zwischenbaums des Parsens wegzulassen, was uns Speicher sparen kann, obwohl ein unendlicher Puffer f√ºr Token verwendet wird.  Ich bin noch im Implementierungsprozess, aber ich habe bereits einen Prototyp, der eine Teilmenge von Python in AST mit ungef√§hr der gleichen Geschwindigkeit wie der aktuelle CPython-Parser kompilieren kann.  Es wird jedoch mehr Speicher ben√∂tigt, und es scheint mir, dass das Erweitern der Teilmenge in die vollst√§ndige Sprache den PEG-Parser verlangsamt.  Bisher habe ich jedoch noch keine Optimierungen vorgenommen, daher werde ich weiterarbeiten. </p><br><p>  Der letzte Vorteil des Wechsels zu PEG besteht darin, dass es mehr Flexibilit√§t f√ºr die weitere Entwicklung der Sprache bietet.  In der Vergangenheit wurde gesagt, dass die LL (1) -Einschr√§nkungen in pgen die Python-Grammatik einfach hielten.  Dies mag durchaus zutreffen, aber wir haben viele andere Prozesse, um ein unkontrolliertes Sprachwachstum zu verhindern (haupts√§chlich den PEP-Prozess, der durch sehr strenge Anforderungen an die Abw√§rtskompatibilit√§t und eine neue Verwaltungsstruktur unterst√ºtzt wird).  Ich mache mir dar√ºber also keine Sorgen. </p><br><p>  Ich w√ºrde gerne viel mehr √ºber PEG und meine Implementierung erz√§hlen, aber es wird in den n√§chsten Beitr√§gen sein, nachdem ich den Code bereinigt habe. </p><br><p>  Lizenz f√ºr diesen Artikel und zitierten Code: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CC BY-NC-SA 4.0</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de471860/">https://habr.com/ru/post/de471860/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de471844/index.html">5 Gr√ºnde, EPAM INSIDER in Kasachstan zu besuchen</a></li>
<li><a href="../de471852/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 481 (10/01/2019 - 07/10/2019)</a></li>
<li><a href="../de471854/index.html">Hitzetod 5G</a></li>
<li><a href="../de471856/index.html">Wir l√∂sen alle 42 Versionen des Harry-Potter-Trank-Puzzles</a></li>
<li><a href="../de471858/index.html">RabbitMQ vs. Kafka: Failover und Hochverf√ºgbarkeit in Clustern</a></li>
<li><a href="../de471862/index.html">PEG-Parser-Implementierung</a></li>
<li><a href="../de471864/index.html">PEG-Parser-Generierung</a></li>
<li><a href="../de471866/index.html">PEG-Parser-Visualisierung</a></li>
<li><a href="../de471868/index.html">Genetik der Liebe: Konflikt zwischen den Geschlechtern als Grundlage f√ºr die Zusammenarbeit bei Paaren monogamer V√∂gel</a></li>
<li><a href="../de471870/index.html">Effektive Nutzung von libdispatch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
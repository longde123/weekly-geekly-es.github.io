<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöµüèª üé† üõå Wechsel von Redshift zu ClickHouse üë®üèº‚Äçüöí üë≤üèº üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="IBunny nutzte Redshift lange Zeit als Datenbank f√ºr Ereignisse, die in Backend-Diensten und mobilen Anwendungen auftreten. Es wurde gew√§hlt, weil es z...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wechsel von Redshift zu ClickHouse</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/funcorp/blog/433346/"><img src="https://habrastorage.org/webt/s8/xo/0d/s8xo0dnodxojhff6jufnruyg660.jpeg"><br><br>  IBunny nutzte Redshift lange Zeit als Datenbank f√ºr Ereignisse, die in Backend-Diensten und mobilen Anwendungen auftreten.  Es wurde gew√§hlt, weil es zum Zeitpunkt der Implementierung im Gro√üen und Ganzen keine Alternativen gab, die hinsichtlich Kosten und Zweckm√§√üigkeit vergleichbar waren. <br><br>  Nach der Ver√∂ffentlichung von ClickHouse √§nderte sich jedoch alles.  Wir haben es lange studiert, die Kosten verglichen, die ungef√§hre Architektur gesch√§tzt und schlie√ülich diesen Sommer beschlossen, herauszufinden, wie n√ºtzlich es f√ºr uns ist.  In diesem Artikel erfahren Sie mehr √ºber das Problem, das Redshift uns bei der L√∂sung geholfen hat, und wie wir diese L√∂sung auf ClickHouse verschoben haben. <br><a name="habracut"></a><br><h2>  Das Problem </h2><br>  iFunny ben√∂tigte einen √§hnlichen Service wie Yandex.Metrica, jedoch ausschlie√ülich f√ºr den Inlandsverbrauch.  Ich werde erkl√§ren warum. <br><br>  Externe Clients schreiben Ereignisse.  Dies k√∂nnen mobile Anwendungen, Websites oder interne Backend-Dienste sein.  F√ºr diese Kunden ist es sehr schwierig zu erkl√§ren, dass der Empfangsdienst f√ºr Veranstaltungen derzeit nicht verf√ºgbar ist. Versuchen Sie, ihn in 15 Minuten oder in einer Stunde zu senden.  Es gibt viele Kunden, die st√§ndig Ereignisse senden m√∂chten und √ºberhaupt nicht warten k√∂nnen. <br><br>  Im Gegensatz dazu gibt es interne Dienste und Benutzer, die diesbez√ºglich recht tolerant sind: Sie k√∂nnen auch mit einem unzug√§nglichen Analysedienst ordnungsgem√§√ü arbeiten.  Und die meisten Produktmetriken und die Ergebnisse von A / B-Tests sind im Allgemeinen sinnvoll, um sie nur einmal am Tag oder sogar noch seltener anzusehen.  Daher sind die Leseanforderungen recht gering.  Im Falle eines Unfalls oder einer Aktualisierung k√∂nnen wir es uns leisten, mehrere Stunden oder sogar Tage lang unzug√§nglich oder inkonsistent zu lesen (in einem besonders vernachl√§ssigten Fall). <br><br>  Wenn wir √ºber Zahlen sprechen, m√ºssen wir ungef√§hr f√ºnf Milliarden Ereignisse (300 GB komprimierte Daten) pro Tag erfassen und Daten drei Monate lang in einer f√ºr SQL-Abfragen verf√ºgbaren ‚Äûhei√üen‚Äú Form und zwei Jahre lang in einer ‚Äûkalten‚Äú Form speichern oder mehr, aber damit wir sie innerhalb weniger Tage in "hei√ü" verwandeln k√∂nnen. <br><br>  Grunds√§tzlich handelt es sich bei Daten um eine Sammlung von Ereignissen, die nach Zeit geordnet sind.  Es gibt ungef√§hr dreihundert Arten von Ereignissen, von denen jedes seine eigenen Eigenschaften hat.  Es gibt noch einige Daten aus Quellen von Drittanbietern, die mit der Analysedatenbank synchronisiert werden sollten: z. B. eine Sammlung von Anwendungsinstallationen von MongoDB oder einen externen AppsFlyer-Dienst. <br><br>  Es stellt sich heraus, dass wir ungef√§hr 40 TB Festplatte f√ºr die Datenbank und ungef√§hr 250 TB f√ºr den ‚Äûkalten‚Äú Speicher ben√∂tigen. <br><br><h2>  Rotverschiebungsl√∂sung </h2><br><img src="https://habrastorage.org/webt/f0/nq/dl/f0nqdl7cvriq9ygc3jlhelfdlqi.png"><br><br>  Es gibt also mobile Clients und Backend-Services, von denen Sie Ereignisse empfangen m√ºssen.  Der HTTP-Dienst akzeptiert die Daten, f√ºhrt die Mindest√ºberpr√ºfung durch, sammelt Ereignisse auf der lokalen Festplatte in Dateien, die nach einer Minute gruppiert sind, komprimiert sie sofort und sendet sie an den S3-Bucket.  Die Verf√ºgbarkeit dieses Dienstes h√§ngt von der Verf√ºgbarkeit der Server mit der Anwendung und AWS S3 ab.  Anwendungen speichern den Status nicht, sodass sie leicht ausgeglichen, skaliert und ausgetauscht werden k√∂nnen.  S3 ist ein relativ einfacher Dateispeicherdienst mit einem guten Ruf und einer guten Verf√ºgbarkeit, sodass Sie sich darauf verlassen k√∂nnen. <br><br>  Als n√§chstes m√ºssen Sie die Daten irgendwie an Redshift liefern.  Hier ist alles ganz einfach: Redshift verf√ºgt √ºber einen integrierten S3-Importer, der die empfohlene Methode zum Laden von Daten darstellt.  Daher wird alle 10 Minuten ein Skript gestartet, das eine Verbindung zu Redshift herstellt und es auffordert, Daten mit dem Pr√§fix <code>s3://events-bucket/main/year=2018/month=10/day=14/10_3*</code> herunterzuladen <code>s3://events-bucket/main/year=2018/month=10/day=14/10_3*</code> <br><br>  Um den Status der Download-Aufgabe zu √ºberwachen, verwenden wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Airflow</a> : Sie k√∂nnen den Vorgang im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehlerfall</a> wiederholen und haben einen klaren Ausf√ºhrungsverlauf, der f√ºr eine gro√üe Anzahl solcher Aufgaben wichtig ist.  Und bei Problemen k√∂nnen Sie den Download f√ºr einige Zeitintervalle wiederholen oder die ‚Äûkalten‚Äú Daten von S3 vor einem Jahr herunterladen. <br><br>  Im gleichen Airflow funktionieren auf die gleiche Weise gem√§√ü dem Zeitplan Skripte, die eine Verbindung zur Datenbank herstellen und regelm√§√üige Downloads von externen Repositorys durchf√ºhren oder Aggregationen √ºber Ereignisse in Form von <code>INSERT INTO ... SELECT ...</code> erstellen. <br><br>  Redshift hat schwache Verf√ºgbarkeitsgarantien.  Einmal pro Woche, bis zu einer halben Stunde (das Zeitfenster ist in den Einstellungen angegeben), kann AWS die Aktualisierung des Clusters oder andere geplante Arbeiten stoppen.  Im Falle eines Fehlers auf einem Knoten ist der Cluster auch nicht verf√ºgbar, bis der Host wiederhergestellt ist.  Dies dauert normalerweise etwa 15 Minuten und geschieht etwa alle sechs Monate.  Im aktuellen System ist dies kein Problem, es wurde urspr√ºnglich so konzipiert, dass die Basis regelm√§√üig nicht verf√ºgbar ist. <br><br>  Unter Redshift wurden 4 ds2.8xlarge-Instanzen verwendet (36 CPU, 16 TB HDD), was insgesamt 64 TB Festplattenspeicher ergibt. <br><br>  Der letzte Punkt ist die Sicherung.  Der Sicherungszeitplan kann in den Clustereinstellungen angegeben werden und funktioniert einwandfrei. <br><br><h2>  ClickHouse Transition Motivation </h2><br>  Wenn es keine Probleme gegeben h√§tte, h√§tte nat√ºrlich niemand daran gedacht, auf ClickHouse zu migrieren.  Sie waren es jedoch. <br><br>  Wenn Sie sich das ClickHouse-Speicherschema mit der MergeTree- und Redshift-Engine ansehen, k√∂nnen Sie feststellen, dass ihre Ideologie sehr √§hnlich ist.  Beide Datenbanken sind spaltenweise, funktionieren gut mit einer gro√üen Anzahl von Spalten und komprimieren Daten auf der Festplatte sehr gut (und in Redshift k√∂nnen Sie Komprimierungstypen f√ºr jede einzelne Spalte konfigurieren).  Sogar die Daten werden auf die gleiche Weise gespeichert: Sie sind nach Prim√§rschl√ºsseln sortiert, sodass Sie nur bestimmte Bl√∂cke lesen und keine einzelnen Indizes im Speicher behalten k√∂nnen. Dies ist wichtig, wenn Sie mit gro√üen Datenmengen arbeiten. <br><br>  Der wesentliche Unterschied liegt wie immer im Detail. <br><br><h3>  T√§glicher Tisch </h3><br>  Das Sortieren von Daten auf der Festplatte und das tats√§chliche L√∂schen in Redshift erfolgt, wenn Sie Folgendes tun: <pre> <code class="xml hljs">VACUUM <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">tablename</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre>  In diesem Fall arbeitet der Vakuumprozess mit allen Daten in dieser Tabelle.  Wenn Sie Daten f√ºr alle drei Monate in einer Tabelle speichern, dauert dieser Vorgang sehr lange und Sie m√ºssen ihn mindestens t√§glich ausf√ºhren, da alte Daten gel√∂scht und neue hinzugef√ºgt werden.  Ich musste f√ºr jeden Tag separate Tabellen erstellen und diese √ºber die Ansicht kombinieren. Dies ist nicht nur die Schwierigkeit, diese Ansicht zu drehen und zu unterst√ºtzen, sondern auch die Verlangsamung von Abfragen.  Auf Anfrage wurden nach Tabellen alle Tabellen gescannt.  Und obwohl das Scannen einer Tabelle weniger als eine Sekunde dauert, stellt sich bei einer Menge von 90 Teilen heraus, dass jede Abfrage mindestens eine Minute dauert.  Dies ist nicht sehr praktisch. <br><br><h3>  Duplikate </h3><br>  Das n√§chste Problem sind Duplikate.  Auf die eine oder andere Weise gibt es beim √úbertragen von Daten √ºber ein Netzwerk zwei M√∂glichkeiten: entweder Daten verlieren oder Duplikate empfangen.  Wir konnten keine Nachrichten verlieren, deshalb haben wir uns einfach damit abgefunden, dass ein kleiner Prozentsatz der Ereignisse dupliziert w√ºrde.  Sie k√∂nnen Duplikate pro Tag l√∂schen, indem Sie eine neue Tabelle erstellen und Daten aus der alten Tabelle einf√ºgen. Dabei werden mithilfe der Fensterfunktion Zeilen mit doppelter ID gel√∂scht, die alte Tabelle gel√∂scht und die neue umbenannt.  Da √ºber den t√§glichen Tabellen eine Ansicht vorhanden war, musste diese nicht vergessen und f√ºr die Zeit des Umbenennens der Tabellen gel√∂scht werden.  In diesem Fall war es auch erforderlich, die Sperren zu √ºberwachen. Andernfalls konnte dieser Vorgang bei einer Abfrage, die die Ansicht oder eine der Tabellen blockierte, √ºber einen l√§ngeren Zeitraum verschoben werden. <br><br><h3>  √úberwachung und Wartung </h3><br>  Keine einzige Anforderung in Redshift dauert weniger als ein paar Sekunden.  Selbst wenn Sie nur einen Benutzer hinzuf√ºgen oder eine Liste der aktiven Anforderungen anzeigen m√∂chten, m√ºssen Sie einige zehn Sekunden warten.  Nat√ºrlich k√∂nnen Sie das tolerieren, und f√ºr diese Klasse von Datenbanken ist dies akzeptabel, aber am Ende bedeutet dies eine Menge verlorener Zeit. <br><br><h3>  Kosten </h3><br>  Nach unseren Berechnungen ist die Bereitstellung von ClickHouse auf AWS-Instanzen mit genau denselben Ressourcen genau halb so teuer.  Nat√ºrlich sollte es so sein, denn mit Redshift erhalten Sie eine vorgefertigte Datenbank, mit der Sie sofort nach dem Klicken auf einige Schaltfl√§chen in der AWS-Konsole eine Verbindung zu jedem PostgreSQL-Client herstellen k√∂nnen, und AWS erledigt den Rest f√ºr Sie.  Aber ist es das wert?  Wir haben bereits die Infrastruktur, wir scheinen in der Lage zu sein, Backups, √úberwachung und Konfiguration durchzuf√ºhren, und wir tun dies f√ºr eine Reihe interner Dienste.  Warum nicht die ClickHouse-Unterst√ºtzung in Angriff nehmen? <br><br><h2>  √úbergangsprozess </h2><br>  Zuerst haben wir eine kleine ClickHouse-Installation von einem Computer aus gestartet, wo wir regelm√§√üig mit den integrierten Tools Daten von S3 heruntergeladen haben.  So konnten wir unsere Annahmen √ºber die Geschwindigkeit und die F√§higkeiten von ClickHouse testen. <br><br>  Nach einigen Wochen des Testens einer kleinen Kopie der Daten wurde klar, dass einige Probleme gel√∂st werden m√ºssen, um Redshift durch Clickhouse zu ersetzen: <br><br><ul><li>  auf welchen Arten von Instanzen und Festplatten bereitgestellt werden soll; </li><li>  Replikation verwenden? </li><li>  wie man installiert, konfiguriert und ausf√ºhrt; </li><li>  wie man √ºberwacht; </li><li>  welche Art von Schema wird sein; </li><li>  wie man Daten von S3 liefert; </li><li>  Wie schreibe ich alle Abfragen von Standard-SQL auf Nicht-Standard um? </li></ul><br>  <b>Arten von Instanzen und Datentr√§gern</b> .  Bei der Anzahl der Prozessoren, der Festplatte und des Speichers haben sie beschlossen, auf der aktuellen Installation von Redshift aufzubauen.  Es gab verschiedene Optionen, einschlie√ülich i3-Instanzen mit lokalen NVMe-Festplatten, aber es wurde beschlossen, bei r5.4xlarge anzuhalten und f√ºr jede Instanz in Form von 8T ST1 EBS zu speichern.  Sch√§tzungen zufolge h√§tte dies eine vergleichbare Leistung mit Redshift f√ºr die H√§lfte der Kosten ergeben m√ºssen.  Gleichzeitig erhalten wir aufgrund der Verwendung von EBS-Festplatten einfache Sicherungen und Wiederherstellungen durch Snapshots von Festplatten, fast wie bei Redshift. <br><br>  <b>Replikation</b> .  Da wir von Redshift ausgegangen sind, haben wir uns entschieden, keine Replikation zu verwenden.  Dar√ºber hinaus zwingt uns dies nicht dazu, ZooKeeper, das sich noch nicht in der Infrastruktur befindet, sofort zu untersuchen. Es ist jedoch gro√üartig, dass es jetzt m√∂glich ist, Replikationen bei Bedarf durchzuf√ºhren. <br><br>  <b>Installation</b>  Dies ist der einfachste Teil.  Eine ausreichend kleine Rolle f√ºr Ansible, die vorgefertigte RPM-Pakete installiert und auf jedem Host dieselbe Konfiguration vornimmt. <br><br>  <b>√úberwachung</b>  Um alle Dienste zu √ºberwachen, wird Prometheus zusammen mit Telegraf und Grafana verwendet. Daher setzen sie Telegraf-Agenten einfach mit ClickHouse auf Hosts. In Grafana wurde ein Dashboard erstellt, in dem die aktuelle Serverlast nach Prozessor, Speicher und Festplatten angezeigt wird.  √úber das Plugin f√ºr Grafana haben wir die aktuell aktiven Anforderungen f√ºr den Cluster, den Status der Importe aus S3 und andere n√ºtzliche Dinge in dieses Dashboard gebracht.  Es stellte sich als noch besser und informativer (und deutlich schneller) heraus als das Dashboard, mit dem die AWS-Konsole ausgestattet war. <br><br>  <b>Schema</b> .  Einer unserer Hauptfehler bei Redshift bestand darin, nur die Hauptereignisfelder in separaten Spalten auszugeben und die Felder hinzuzuf√ºgen, die selten zum Hinzuf√ºgen verwendet werden <br>  in einer gro√üen Spalte Eigenschaften.  Dies gab uns einerseits Flexibilit√§t bei der √Ñnderung der Felder in der Anfangsphase, als nicht genau bekannt war, welche Ereignisse wir sammeln w√ºrden, mit welchen Eigenschaften sie sich au√üerdem f√ºnfmal am Tag √§nderten.  Andererseits dauerte die Anfrage nach einer gro√üen Spalte von Immobilien immer l√§nger.  In ClickHouse haben wir uns entschlossen, sofort das Richtige zu tun. Deshalb haben wir alle m√∂glichen Spalten gesammelt und den optimalen Typ f√ºr sie eingegeben.  Das Ergebnis ist eine Tabelle mit ungef√§hr zweihundert Spalten. <br><br>  Die n√§chste Aufgabe bestand darin, die richtige Engine f√ºr die Speicherung und Partitionierung auszuw√§hlen. <br>  Sie haben nicht √ºber eine erneute Partitionierung nachgedacht, sondern das Gleiche wie in Redshift - eine Partition f√ºr jeden Tag, aber jetzt sind alle Partitionen eine Tabelle, die <br>  beschleunigt Anfragen erheblich und vereinfacht die Wartung.  Die Speicher-Engine wurde von ReplacingMergeTree √ºbernommen, da Sie damit Duplikate von einer bestimmten Partition entfernen k√∂nnen, indem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sie</a> einfach <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OPTIMIZE ... FINAL ausf√ºhren</a> .  Dar√ºber hinaus erm√∂glicht das t√§gliche Partitionierungsschema bei Fehlern oder Unf√§llen, nur mit Daten f√ºr einen Tag und nicht f√ºr einen Monat zu arbeiten, was viel schneller ist. <br><br>  <b>Lieferung von Daten von s3 an ClickHouse</b> .  Dies war einer der l√§ngsten Prozesse.  Das Laden mit den integrierten ClickHouse-Tools hat einfach nicht funktioniert, da sich die Daten in S3 in JSON befinden, jedes Feld wie in Redshift in einem eigenen JSON-Pfad extrahiert werden muss und manchmal auch eine Transformation verwendet werden muss: Zum Beispiel die UUID einer Nachricht aus einem Standarddatensatz in der Form <code>DD96C92F-3F4D-44C6-BCD3-E25EB26389E9</code> in Bytes konvertieren und in den Typ FixedString (16) eingeben. <br><br>  Ich wollte einen speziellen Service haben, der dem √§hnelt, den wir in Redshift als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">COPY-Befehl hatten</a> .  Sie fanden nichts fertig, also musste ich es tun.  Sie k√∂nnen einen separaten Artikel √ºber die Funktionsweise schreiben. Kurz gesagt, dies ist ein HTTP-Dienst, der auf jedem Host mit ClickHouse bereitgestellt wird.  Sie k√∂nnen sich auf jeden von ihnen beziehen.  Die Anforderungsparameter geben das S3-Pr√§fix an, aus dem die Dateien entnommen werden, die jsonpath-Liste f√ºr die Konvertierung von JSON in eine Reihe von Spalten sowie eine Reihe von Konvertierungen f√ºr jede Spalte.  Der Server, an den die Anforderung gesendet wurde, beginnt mit dem Scannen von Dateien in S3 und dem Verteilen der Parsing-Arbeit an andere Hosts.  Gleichzeitig ist es f√ºr uns wichtig, dass die Zeilen, die nicht importiert werden konnten, zusammen mit dem Fehler einer separaten ClickHouse-Tabelle hinzugef√ºgt werden.  Dies hilft sehr bei der Untersuchung von Problemen und Fehlern im Ereignisempfangsdienst und den Clients, die diese Ereignisse generieren.  Mit der Platzierung des Importers direkt auf den Datenbankhosts haben wir die Ressourcen verwendet, die in der Regel inaktiv sind, da komplexe Anforderungen nicht rund um die Uhr gestellt werden.  Wenn mehr Anfragen vorliegen, k√∂nnen Sie den Service des Importeurs nat√ºrlich jederzeit auf separate Hosts √ºbertragen. <br><br>  Es gab keine gro√üen Probleme beim Importieren von Daten aus externen Quellen.  In diesen Skripten wurde lediglich das Ziel von Redshift in ClickHouse ge√§ndert. <br><br>  Es gab die M√∂glichkeit, MongoDB in Form eines W√∂rterbuchs zu verbinden und keine t√§glichen Kopien zu erstellen.  Leider passte es nicht, da das W√∂rterbuch im Speicher abgelegt werden muss und die Gr√∂√üe der meisten Sammlungen in MongoDB dies nicht zul√§sst.  Aber auch W√∂rterb√ºcher waren f√ºr uns n√ºtzlich: Ihre Verwendung ist sehr praktisch, um GeoIP-Datenbanken von MaxMind aus zu verbinden und in Abfragen zu verwenden.  Hierzu verwenden wir Layout-ip_trie- und CSV-Dateien, die vom Service bereitgestellt werden.  Die Konfiguration des W√∂rterbuchs geoip_asn_blocks_ipv4 sieht beispielsweise folgenderma√üen aus: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionaries</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionary</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>geoip_asn_blocks_ipv4<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">source</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">file</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">path</span></span></span><span class="hljs-tag">&gt;</span></span>GeoLite2-ASN-Blocks-IPv4.csv<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">path</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">format</span></span></span><span class="hljs-tag">&gt;</span></span>CSVWithNames<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">format</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">file</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">\</span></span></span><span class="hljs-tag">/</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">source</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">lifetime</span></span></span><span class="hljs-tag">&gt;</span></span>300<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">lifetime</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">layout</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ip_trie</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">layout</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">structure</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">key</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>prefix<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span>String<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">key</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>autonomous_system_number<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span>UInt32<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span>0<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>autonomous_system_organization<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span>String<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">type</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span>?<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">null_value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">attribute</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">structure</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionary</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">dictionaries</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br>  Es reicht aus, diese Konfiguration in <code>/etc/clickhouse-server/geoip_asn_blocks_ipv4_dictionary.xml</code> k√∂nnen Sie das W√∂rterbuch <code>/etc/clickhouse-server/geoip_asn_blocks_ipv4_dictionary.xml</code> , um den Namen des Anbieters anhand der IP-Adresse <code>/etc/clickhouse-server/geoip_asn_blocks_ipv4_dictionary.xml</code> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> dictGetString(<span class="hljs-string"><span class="hljs-string">'geoip_asn_blocks_ipv4'</span></span>, <span class="hljs-string"><span class="hljs-string">'autonomous_system_organization'</span></span>, tuple(IPv4StringToNum(<span class="hljs-string"><span class="hljs-string">'192.168.1.1'</span></span>)));</code> </pre><br>  <b>Datenschema √§ndern</b> .  Wie oben erw√§hnt, haben wir uns entschieden, die Replikation noch nicht zu verwenden, da wir es uns jetzt leisten k√∂nnen, bei Unf√§llen oder geplanten Arbeiten unzug√§nglich zu werden. Eine Kopie der Daten befindet sich bereits auf s3 und wir k√∂nnen sie in angemessener Zeit an ClickHouse √ºbertragen.  Wenn keine Replikation vorhanden ist, wurde ZooKeeper nicht erweitert, und das Fehlen von ZooKeeper f√ºhrt auch dazu, dass der Ausdruck ON CLUSTER in DDL-Abfragen nicht verwendet werden kann.  Dieses Problem wurde durch ein kleines Python-Skript gel√∂st, das eine Verbindung zu jedem ClickHouse-Host herstellt (es gibt bisher nur acht) und die angegebene SQL-Abfrage ausf√ºhrt. <br><br>  <b>Unvollst√§ndige SQL-Unterst√ºtzung in ClickHouse</b> .  Der Prozess der √úbertragung von Anforderungen von der Redshift-Syntax zur ClickHouse-Syntax verlief parallel zur Entwicklung des Importers und wurde haupts√§chlich von einem Analystenteam bearbeitet.  Seltsamerweise war die Sache aber nicht einmal in der JOIN, sondern in den Fensterfunktionen.  Es dauerte mehrere Tage, um zu verstehen, wie sie √ºber Arrays und Lambda-Funktionen ausgef√ºhrt werden k√∂nnen.  Es ist gut, dass dieses Problem h√§ufig in Berichten √ºber ClickHouse behandelt wird, von denen es eine gro√üe Anzahl gibt, z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">events.yandex.ru/lib/talks/5420</a> .  Zu diesem Zeitpunkt wurden die Daten bereits an zwei Stellen gleichzeitig geschrieben: sowohl in Redshift als auch im neuen ClickHouse. Bei der √úbertragung der Anforderungen haben wir die Ergebnisse verglichen.  Es war problematisch, die Geschwindigkeit zu vergleichen, da wir eine gro√üe Spalte mit Eigenschaften entfernt haben und die meisten Abfragen nur mit den erforderlichen Spalten zu arbeiten begannen, was nat√ºrlich zu einem signifikanten Anstieg f√ºhrte. Die Abfragen, an denen die Eigenschaftsspalte nicht teilnahm, funktionierten jedoch auf die gleiche Weise oder etwas schneller. <br><br>  Als Ergebnis haben wir das folgende Schema erhalten: <br><br><img src="https://habrastorage.org/webt/tj/h8/ka/tjh8kagqccdbjgnswbmbm9wkloc.png"><br><br><h2>  Ergebnisse </h2><br>  Unter dem Strich haben wir folgende Vorteile: <br><br><ul><li>  Ein Tisch statt 90 </li><li>  Serviceanfragen werden in Millisekunden ausgef√ºhrt </li><li>  Die Kosten haben sich halbiert </li><li>  Einfaches Entfernen doppelter Ereignisse </li></ul><br>  Es gibt auch Nachteile, f√ºr die wir bereit sind: <br><br><ul><li>  Im Falle eines Unfalls m√ºssen Sie den Cluster selbst reparieren </li><li>  Schema√§nderungen m√ºssen jetzt auf jedem Host separat vorgenommen werden </li><li>  Das Aktualisieren auf neue Versionen muss selbst durchgef√ºhrt werden </li></ul><br>  Wir k√∂nnen die Geschwindigkeit von Anfragen nicht direkt vergleichen, da sich das Datenschema erheblich ge√§ndert hat.  Viele Abfragen sind schneller geworden, einfach weil sie weniger Daten von der Festplatte lesen.  In guter Weise musste eine solche √Ñnderung in Redshift vorgenommen werden, aber es wurde beschlossen, sie mit der Migration zu ClickHouse zu kombinieren. <br><br>  Die gesamte Migration und Vorbereitung dauerte etwa drei Monate.  Sie ging von Anfang Juli bis Ende September und forderte die Teilnahme von zwei Personen.  Am 27. September haben wir Redshift ausgeschaltet und arbeiten seitdem nur noch an ClickHouse.  Es stellt sich heraus, bereits etwas mehr als zwei Monate.  Der Begriff ist kurz, aber bisher ist noch nie ein Datenverlust oder ein kritischer Fehler aufgetreten, aufgrund dessen der gesamte Cluster aufstehen w√ºrde.  Vor uns warten Updates auf neue Versionen! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de433346/">https://habr.com/ru/post/de433346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de433336/index.html">Die Implementierung der babylonischen Bibliothek</a></li>
<li><a href="../de433338/index.html">Creality 3D-Drucker Hersteller√ºbersicht</a></li>
<li><a href="../de433340/index.html">Xiaomi Wireless-Ger√§te im ioBroker Smart Home</a></li>
<li><a href="../de433342/index.html">Ein weiterer einfacher Verilog-Prozessor</a></li>
<li><a href="../de433344/index.html">Zwei Erfolge des privaten Raums</a></li>
<li><a href="../de433348/index.html">Typisiertes DSL in TypeScript von JSX</a></li>
<li><a href="../de433350/index.html">Digitale Veranstaltungen in Moskau vom 17. bis 23. Dezember</a></li>
<li><a href="../de433352/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 343 (10. - 16. Dezember 2018)</a></li>
<li><a href="../de433354/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 438 (12/04/2018 - 12/10/2018)</a></li>
<li><a href="../de433356/index.html">Angreifer haben gelernt, die Zwei-Faktor-Authentifizierung Yahoo Mail und Gmail zu umgehen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
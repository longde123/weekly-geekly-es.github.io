<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🚀 🧚🏻 🗣️ Erstellen eines Bots zur Teilnahme am AI Mini Cup. GPU-Erfahrung 🦕 🙆🏼 🔭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fortsetzung von Artikel 1 und Artikel 2 . 


 Im Folgenden werde ich auf die Erfahrungen des Autors bei der Verwendung der GPU für Berechnungen eingeh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen eines Bots zur Teilnahme am AI Mini Cup. GPU-Erfahrung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417757/"><p><img src="https://habrastorage.org/webt/0y/a5/cb/0ya5cbi1psai9jbzlfxhlhnzx4w.jpeg"></p><br><p>  Fortsetzung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel 1</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel 2</a> . </p><br><p>  Im Folgenden werde ich auf die Erfahrungen des Autors bei der Verwendung der GPU für Berechnungen eingehen, auch als Teil der Erstellung eines Bots für die Teilnahme am AI-Minicup.  Vielmehr handelt es sich um einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufsatz</a> zum Thema GPU. </p><br><p>  - Dein Name ist magisch ... <br>  - Weißt du, Joel? Die Magie geht ... </p><a name="habracut"></a><br><p> In der Kindheit sprechen wir über das Alter, in dem die Chemie in der Schule noch nicht im Gange ist oder gerade erst beginnt, der Autor war fasziniert von der brennenden Reaktion, so dass seine Eltern ihn nicht störten und das Moskauer Ödland in der Nähe des Hauses gelegentlich von Blitzen verschiedener Kinderaktivitäten beleuchtet wurde, einer hausgemachten Rakete auf Schwarz Schießpulver, auf Zuckernitrat-Karamell usw.  Zwei Umstände schränkten die Phantasien der Kinder ein: die Zersetzung von Nitroglycerin in einem Heimlabor mit einer zischenden Decke aus Säuren und die Fahrt zu einem Polizeiraum, um Chemikalien in einem der Verteidigungsunternehmen zu beschaffen, die großzügig im U-Bahn-Gebiet Aviamotornaya verstreut sind. </p><br><p>  Und dann erschien eine Physikschule mit Yamaha-MSX-Computern, ein programmierbarer MK-Rechner zu Hause, und es blieb keine Zeit für Chemie.  Die Interessen des Kindes haben sich auf Computer verlagert.  Und was dem Autor bei der ersten Bekanntschaft mit dem Computer fehlte, war die brennende Reaktion, seine Programme schwelten, es gab nicht dieses Gefühl natürlicher Kraft.  Sie konnten den Prozess der Optimierung von Berechnungen in Spielen sehen, aber zu diesem Zeitpunkt wusste der Autor nicht, wie er die Berechnung von sin () durch die Wertetabelle dieser Funktion ersetzen sollte, es gab kein Internet ... </p><br><p>  So konnte der Autor ein Gefühl der Freude von Rechenleistung, sauberem Brennen bekommen, ich benutze GPU in Berechnungen. </p><br><p>  Auf einem Habr gibt es einige gute Artikel über Berechnungen auf GPU.  Es gibt auch viele Beispiele im Internet, daher wurde beschlossen, nur am Samstagmorgen über persönliche Gefühle zu schreiben, und es ist möglich, andere zur Massenparallelität zu drängen. </p><br><p>  Beginnen wir mit einfachen Formularen.  GPU-Computing unterstützt mehrere Frameworks, die bekanntesten sind jedoch NVIDIA CUDA und OpenCL.  Wir werden CUDA nehmen und müssen sofort unsere Programmiersprachen auf C ++ beschränken.  Es gibt Bibliotheken für die Verbindung mit CUDA in anderen Programmiersprachen, z. B. ALEA GPU in C #. Dies ist jedoch eher das Thema eines separaten Übersichtsartikels. </p><br><p>  Da sie nicht gleichzeitig ein Massenauto mit einem Strahltriebwerk herstellen konnten, obwohl einige seiner Indikatoren höher sind als die eines Verbrennungsmotors, sind parallele Berechnungen bei realen Problemen nicht immer möglich.  Die Hauptanwendung für paralleles Rechnen: Sie benötigen eine Aufgabe, die ein Element mit Massencharakter, die Multiplizität, enthält.  In unserem Fall, einen Bot zu erstellen, fällt ein neuronales Netzwerk (viele Neuronen, neuronale Verbindungen) unter die Masse und eine Population von Bots (Berechnung der Bewegungsdynamik, Kollisionen für jeden Bot dauert einige Zeit, wenn die Bots zwischen 300 und 1000 liegen, gibt der Zentralprozessor auf und Sie werden nur langsam beobachten Schwelen Ihres Programms, z. B. lange Pausen zwischen den Visualisierungsrahmen). </p><br><p>  Die beste Massenoption ist, wenn jedes Element der Berechnungen nicht vom Ergebnis der Berechnungen für ein anderes Element der Liste abhängt. Beispielsweise ist die einfache Aufgabe des Sortierens eines Arrays bereits mit allen Arten von Tricks überwachsen, da die Position der Zahl im Array von anderen Zahlen abhängt und nicht in einem <strong>parallelen Zyklus</strong> in die Stirn genommen <strong>werden kann</strong> .  Um den Wortlaut zu vereinfachen: Das erste Anzeichen für ein erfolgreiches Massenzeichen ist, dass Sie, wenn Sie die Position eines Elements im Array nicht ändern müssen, frei Berechnungen daran durchführen, die Werte anderer Elemente dafür übernehmen, es jedoch nicht von seiner Stelle verschieben können.  So etwas wie ein Märchen: Ändern Sie nicht die Reihenfolge der Elemente, sonst verwandelt sich die GPU in einen Kürbis. </p><br><p>  In modernen Programmiersprachen gibt es Konstruktionen, die parallel auf mehreren Kernen eines Zentralprozessors oder logischen Threads ausgeführt werden können, und sie sind weit verbreitet, aber der Autor konzentriert den Leser auf Massenparallelität, wenn die Anzahl der ausgeführten Module Hunderte oder Tausende von Einheiten überschreitet. </p><br><p>  Die ersten Elemente paralleler Strukturen erschienen: ein <strong>paralleler Zyklus</strong> .  Für die meisten Aufgaben wird es ausreichen.  Im weitesten Sinne ist dies die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quintessenz</a> <br>  paralleles Rechnen. </p><br><p>  Ein Beispiel für das Schreiben der Hauptschleife in CUDA (Kernel): </p><br><pre><code class="hljs perl"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tid = blockIdx.x * blockDim.x + threadIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> threadN = gridDim.x * blockDim.x; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span> = tid; <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span> &lt; numElements; <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span> += threadN) { <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>    <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span>,     ,       thread     pos.  :    thread    ,  thread   <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span>=<span class="hljs-number"><span class="hljs-number">1146</span></span>     thread c  <span class="hljs-keyword"><span class="hljs-keyword">pos</span></span>=<span class="hljs-number"><span class="hljs-number">956</span></span>.        .           . }</code> </pre> <br><p>  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation und den Überprüfungen für CUDA</a> wurde viel über GPU-Blöcke, über Threads, die in diesen Blöcken erzeugt werden, und darüber, wie die Aufgabe auf ihnen parallelisiert werden kann, geschrieben.  Wenn Sie jedoch ein Array von Daten haben und diese eindeutig aus Massenelementen bestehen, verwenden Sie die obige Schleifenform, da sie in ihrer Form einer regulären Schleife optisch ähnlich ist, was angenehm, aber leider nicht inhaltlich ist. </p><br><p>  Ich denke, der Leser versteht bereits, dass sich die Klasse der Aufgaben in Bezug auf die massenparallele Programmierung schnell verengt.  Wenn wir über das Erstellen von Spielen, 3D- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rendering-Engines</a> , neuronalen Netzen, Videobearbeitung und anderen ähnlichen Aufgaben sprechen, ist das Löschen für unabhängige Leseraktionen stark abgenutzt. Für diese Aufgaben gibt es große Programme, kleine Programme, Frameworks, bekannte und unbekannte Bibliotheken.  Das heißt, der Bereich bleibt nur vom Thema entfernt, um Ihre eigene kleine Computerrakete zu erstellen, nicht SpaceX und Roscosmos, sondern etwas Heimeliges, aber für die Berechnungen völlig Böses. </p><br><p><img src="https://habrastorage.org/webt/p6/f-/yt/p6f-ytvdsye66m74evqa0xisslc.png"></p><br><p>  Hier ist ein Bild einer vollständig brennenden Rakete abgebildet. </p><br><p>  Apropos Aufgaben, die ein paralleler Zyklus in Ihren Händen nicht lösen kann.  Und die Entwickler von CUDA in der Person von NVIDIA-Entwicklern haben bereits darüber nachgedacht. </p><br><p>  Es gibt an einigen Stellen eine Thrust-Bibliothek, die nützlich ist, bis "keine Optionen" anders ausgeführt werden.  Übrigens, fand nicht die vollständige Bewertung auf Habré. </p><br><p>  Um zu verstehen, wie es funktioniert, müssen Sie zuerst drei Sätze über die Prinzipien von CUDA sagen.  Wenn Sie mehr Wörter benötigen, können <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sie den</a> Link <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen</a> . </p><br><p>  Die Prinzipien von CUDA: </p><br><p>  Berechnungen finden auf der GPU statt, deren Programm der Kernel ist, und Sie müssen sie in C schreiben. Der Kernel kommuniziert wiederum nur mit dem GPU-Speicher, und Sie müssen die Daten aus dem Hauptprogramm in den Videoprozessorspeicher laden und wieder in das Programm hochladen.  Ausgefeilte Algorithmen auf CUDA erfordern Flexibilität. </p><br><p>  Die Thrust-Bibliothek entfernt also die Routine und übernimmt einige der "komplexen" Aufgaben für CUDA, z. B. das Summieren oder Sortieren von Arrays.  Sie müssen keinen separaten Kernel mehr schreiben, Zeiger in den Speicher laden und Daten von diesen Zeigern in den GPU-Speicher kopieren.  Das ganze Rätsel wird vor Ihren Augen im Hauptprogramm und mit einer Geschwindigkeit auftreten, die CUDA etwas unterlegen ist.  Die Thrust-Bibliothek ist in CUDA geschrieben, daher ist dies in Bezug auf die Leistung ein einzelnes Beerenfeld. </p><br><p>  In Thrust müssen Sie ein Array (push :: vector) in seiner Bibliothek erstellen, das mit regulären Arrays (std :: vector) kompatibel ist.  Das heißt natürlich, nicht alles ist so einfach, aber die Bedeutung dessen, was der Autor sagte, ähnelt der Wahrheit.  Es gibt wirklich zwei Arrays, eines auf der GPU (Gerät), das andere im Hauptprogramm (Host). </p><br><p>  Ein Beispiel zeigt die Einfachheit der Syntax (X-, Y-, Z-Arrays): </p><br><pre> <code class="hljs vhdl">// initialize X <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, .... thrust::<span class="hljs-keyword"><span class="hljs-keyword">sequence</span></span>(X.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), X.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>()); // compute Y = -X thrust::transform(X.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), X.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), Y.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), thrust::negate&lt;int&gt;()); // fill Z <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> twos thrust::fill(Z.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), Z.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), <span class="hljs-number"><span class="hljs-number">2</span></span>); // compute Y = X <span class="hljs-keyword"><span class="hljs-keyword">mod</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> thrust::transform(X.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), X.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), Z.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), Y.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), thrust::modulus&lt;int&gt;()); // replace <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> the ones <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> Y <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tens thrust::replace(Y.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), Y.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>);</code> </pre> <br><p>  Sie können sehen, wie harmlos es vor dem Hintergrund der Erstellung des CUDA-Kernels aussieht und wie viele Funktionen in Thrust vorhanden sind.  Angefangen von der Arbeit mit Zufallsvariablen, die in CUDA von einer separaten cuRAND-Bibliothek (vorzugsweise von einem separaten Kernel ausgeführt) ausgeführt wird, bis zum Sortieren, Summieren und Schreiben Ihrer Funktionen nach Funktionen in der Nähe der Kernelfunktionen. </p><br><p>  Der Autor hat wenig Erfahrung mit CUDA und C ++, zwei Monate.  Über dieses Jahr über C #.  Dies widerspricht natürlich leicht dem Beginn des Artikels über seine frühe Bekanntschaft mit Computern, Schulphysik und angewandter Mathematik als Ausbildung.  Ich werde es sagen.  Aber für das, was ich in diesem Artikel schreibe, ist es nicht so, dass ich alles so beherrsche, sondern dass sich C ++ als komfortable Sprache herausstellte (ich hatte vor dem Hintergrund von Artikeln im Habrr-Typ „Lambda-Funktionen → Überladung interner Operatoren“ ein wenig Angst davor alles neu definieren "), es ist klar, dass die Jahre seiner Entwicklung zu recht freundlichen Entwicklungsumgebungen (IDEs) geführt haben.  Die Sprache selbst in ihrer neuesten Version, es scheint, als würde sie Müll aus dem Speicher sammeln, ich weiß nicht, wie es vorher war.  Zumindest führten die vom Autor für die einfachsten algorithmischen Konstruktionen geschriebenen Programme tagelang zu Rechenalgorithmen für Bots, und es gab keine Speicherlecks und andere Fehler bei hoher Last.  Dies gilt auch für CUDA, zunächst scheint es kompliziert zu sein, aber es basiert auf einfachen Prinzipien und natürlich ist es schwierig, Orte auf GPUs an Orten zu initialisieren, an denen es viele gibt, aber dann haben Sie Ihre eigene kleine Rakete mit Rauch von der Grafikkarte. </p><br><p>  Von den Objektklassen für das Training mit der GPU empfiehlt der Autor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zellulare Automaten</a> .  Zu einer Zeit gab es eine Zunahme der Popularität und Mode für sie, aber dann ergriffen neuronale Netze die Köpfe der Entwickler. <br>  Bis zu: </p><br><p>  "Jede Größe in der Physik, einschließlich Zeit und Raum, ist endlich und diskret." <br>  als kein zellularer Automat. </p><br><p>  Aber es ist schön, wenn drei einfache Formeln dies schaffen können: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wNiBFQgrNp8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Wenn es interessant sein wird, über zellulare Automaten auf CUDA zu lesen, schreiben Sie in die Kommentare, es wird typisiertes Material für einen kleinen Artikel geben. <br>  Und dies ist die Quelle für zellulare Automaten (unter dem Video befinden sich Links zu den Quellen): </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/KJe9H6qS82I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Die Idee, nach dem Frühstück einen Artikel in einem Atemzug zu schreiben, scheint mir zu funktionieren.  Zweite Kaffeezeit.  Ich wünsche Ihnen einen schönen Wochenendleser. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de417757/">https://habr.com/ru/post/de417757/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de417747/index.html">Betreff: "Vergleich von JS-Frameworks: React, Vue und Hyperapp"</a></li>
<li><a href="../de417749/index.html">Project Loon als kommerzielles Projekt: Der erste Vertrag wird unterzeichnet</a></li>
<li><a href="../de417751/index.html">Kunstkamera: E-Meter - Scientology-Gerät zur Messung von Thetanen</a></li>
<li><a href="../de417753/index.html">Komprimierung großer Anordnungen von Primzahlen</a></li>
<li><a href="../de417755/index.html">Studie: 80% der ICOs 2017 gelten als betrügerisch</a></li>
<li><a href="../de417759/index.html">Sei meine Gummiente</a></li>
<li><a href="../de417761/index.html">GitLab wechselt von Azure zur Google Cloud Platform. Umzugsnachrichten und Wartungstermine</a></li>
<li><a href="../de417763/index.html">MVIDroid: eine Überprüfung der neuen MVI-Bibliothek (Model-View-Intent)</a></li>
<li><a href="../de417767/index.html">Text-Sentiment-Analyse unter Verwendung von Faltungs-Neuronalen Netzen</a></li>
<li><a href="../de417769/index.html">User Memory Design: Wie man für Alter entwirft</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∫üèø üñï üí™üèº Estudiamos analizadores sint√°cticos para el idioma ruso üë®üèΩ‚Äçüé§ üé® üÜí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Mi nombre es Denis Kiryanov, trabajo en Sberbank y me ocupo de los problemas del procesamiento del lenguaje natural (PNL). Una vez que necesit√°ba...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Estudiamos analizadores sint√°cticos para el idioma ruso</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/418701/">  Hola  Mi nombre es Denis Kiryanov, trabajo en Sberbank y me ocupo de los problemas del procesamiento del lenguaje natural (PNL).  Una vez que necesit√°bamos elegir un analizador sint√°ctico para trabajar con el idioma ruso.  Para hacer esto, profundizamos en la naturaleza de la morfolog√≠a y la tokenizaci√≥n, probamos diferentes opciones y evaluamos su aplicaci√≥n.  Compartimos nuestra experiencia en esta publicaci√≥n. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c87/ec8/f26/c87ec8f26a969cf54915271e24abcba1.png"><br><a name="habracut"></a><br><h2>  Preparaci√≥n para la selecci√≥n </h2><br>  Comencemos con lo b√°sico: ¬øc√≥mo funciona?  Tomamos el texto, realizamos tokenizaci√≥n y obtenemos una serie de pseudo-tokens.  Las etapas de an√°lisis posteriores se ajustan a una pir√°mide: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2f/cd9/0aa/b2fcd90aaf42d1eee5ed3ee84fcf27fd.png"><br><br>  Todo comienza con la morfolog√≠a, con un an√°lisis de la forma de una palabra y sus categor√≠as gramaticales (g√©nero, caso, etc.).  La morfolog√≠a se basa en la sintaxis: relaciones m√°s all√° de los l√≠mites de una palabra, entre palabras.  Los analizadores sint√°cticos que se discutir√°n, analizar√°n el texto y dar√°n a conocer la estructura de las dependencias de las palabras entre s√≠. <br><br><h3>  Gram√°tica de dependencias y gram√°tica de los componentes inmediatos. </h3><br>  Hay dos enfoques principales para analizar, que en teor√≠a ling√º√≠stica existen en igualdad de condiciones. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/951/f08/c59951f08529e3628f3ad969385e4be9.png"><br><br>  En la primera l√≠nea, la oraci√≥n se analiza como parte de la gram√°tica de dependencia.  Este enfoque se ense√±a en la escuela.  Cada palabra en una oraci√≥n est√° de alguna manera conectada con otras.  ‚ÄúJabones‚Äù: un predicado del que depende la materia ‚Äúmadre‚Äù (aqu√≠ la gram√°tica de las dependencias diverge de la escuela, donde el predicado depende de la materia).  El sujeto tiene una definici√≥n dependiente de "m√≠o".  El predicado tiene un "marco" complementario directo dependiente.  Y la adici√≥n directa al "marco" - la definici√≥n de "sucio". <br><br>  En la segunda l√≠nea, el an√°lisis est√° de acuerdo con la gram√°tica de los componentes mismos. <br>  Seg√∫n ella, la oraci√≥n se divide en grupos de palabras (frases).  Las palabras dentro de un grupo est√°n m√°s estrechamente relacionadas.  Las palabras "mi" y "madre" est√°n m√°s estrechamente relacionadas, "marco" y "sucio" - tambi√©n.  Y todav√≠a hay un "jab√≥n" separado. <br><br>  El segundo enfoque para el an√°lisis autom√°tico del idioma ruso es poco aplicable, porque en √©l las palabras estrechamente relacionadas (miembros del mismo grupo) a menudo no se colocan en una fila.  Tendr√≠amos que combinarlos con par√©ntesis extra√±os, en una o dos palabras.  Por lo tanto, en el an√°lisis autom√°tico del idioma ruso, se acostumbra trabajar en funci√≥n de la gram√°tica de las dependencias.  Esto tambi√©n es conveniente porque todos est√°n familiarizados con ese "marco" en la escuela. <br><br><h3>  √Årbol de dependencia </h3><br>  Podemos traducir un conjunto de dependencias en una estructura de √°rbol.  La parte superior es la palabra "jab√≥n", algunas palabras dependen directamente de ella, otras dependen de sus adictos.  Aqu√≠ est√° la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">definici√≥n</a> del √°rbol de dependencia del libro de texto de Martin y Zhurafsky: <br><br>  <i>El √°rbol de dependencia es un gr√°fico dirigido que satisface las siguientes restricciones:</i> <br><br><ul><li>  <i>Hay un √∫nico nodo ra√≠z designado que no tiene arcos entrantes.</i> <br></li><li>  <i>Con la excepci√≥n del nodo ra√≠z, cada v√©rtice tiene exactamente un arco entrante.</i> <br></li><li>  <i>Hay una ruta √∫nica desde el nodo ra√≠z a cada v√©rtice en V.</i> <br></li></ul><br>  Hay un nodo de nivel superior: un predicado.  Desde all√≠ puedes llegar a cualquier palabra.  Cada palabra depende de otra, pero solo de una.  El √°rbol de dependencias se parece a esto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b3/b16/19d/4b3b1619db261a71dfd749c28b4fde31.png"><br><br>  En este √°rbol, los bordes se firman con alg√∫n tipo especial de relaci√≥n sint√°ctica.  En la gram√°tica de las dependencias, no solo se analiza el hecho de la conexi√≥n entre palabras, sino tambi√©n la naturaleza de esta conexi√≥n.  Por ejemplo, "se toma" es casi una forma verbal, "inventario" es el tema de "se toma".  En consecuencia, tenemos un borde "es" en una direcci√≥n y la otra.  Estas no son las mismas conexiones; son de una naturaleza diferente, por lo que deben distinguirse. <br><br>  De aqu√≠ en adelante, consideramos casos simples donde los miembros de una oraci√≥n est√°n presentes, no impl√≠citos.  Hay estructuras y marcas para lidiar con los pases.  Algo aparece en el √°rbol que no tiene una expresi√≥n superficial: una palabra.  Pero este es el tema de otro estudio, pero a√∫n necesitamos enfocarnos en el nuestro. <br><br><h3>  Proyecto de dependencias universales </h3><br>  Para facilitar la elecci√≥n de un analizador sint√°ctico, dirigimos nuestra atenci√≥n al proyecto de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dependencias Universales</a> y la competencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CoNLL Shared Task</a> , que recientemente tuvo lugar dentro de su marco. <br><br>  Universal Dependencies es un proyecto para unificar el marcado de corpus sint√°cticos (tribanks) en el marco de la gram√°tica de dependencia.  En ruso, el n√∫mero de tipos de enlaces sint√°cticos es limitado: sujeto, predicado, etc.  En ingl√©s lo mismo, pero el conjunto ya es diferente.  Por ejemplo, all√≠ aparece un art√≠culo que tambi√©n debe etiquetarse de alguna manera.  Si quisi√©ramos escribir un analizador m√°gico que pudiera manejar todos los idiomas, r√°pidamente tendr√≠amos problemas para comparar diferentes gram√°ticas.  Los heroicos creadores de Dependencias Universales lograron ponerse de acuerdo entre ellos y marcar todos los edificios que estaban a su disposici√≥n en un solo formato.  No es muy importante c√≥mo acordaron, lo principal es que en la salida obtuvimos un cierto formato uniforme para presentar esta historia completa: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s de 100 tribanks para 60 idiomas</a> . <br><br>  CoNLL Shared Task es una competencia entre desarrolladores de algoritmos de an√°lisis, realizada como parte del proyecto Universal Dependencies.  Los organizadores toman un cierto n√∫mero de tribanks y los dividen en tres partes: capacitaci√≥n, validaci√≥n y prueba.  La primera parte se proporciona a los participantes de la competencia para que entrenen a sus modelos en ella.  La segunda parte tambi√©n es utilizada por los participantes para evaluar el funcionamiento del algoritmo despu√©s del entrenamiento.  Los participantes pueden repetir la capacitaci√≥n y la evaluaci√≥n de forma iterativa.  Luego dan su mejor algoritmo a los organizadores, quienes lo ejecutan en la parte de prueba, cerrado a los participantes.  Los resultados de los modelos en las partes de prueba de los tribanks son los resultados de la competencia. <br><br><h3>  M√©tricas de calidad </h3><br>  Tenemos conexiones entre las palabras y sus tipos.  Podemos evaluar si la palabra superior se encuentra correctamente: la m√©trica UAS (puntaje de archivo adjunto sin etiqueta).  O para evaluar si tanto el v√©rtice como el tipo de dependencia se encuentran correctamente: la m√©trica LAS (puntaje de apego etiquetado). <br><br><img src="https://habrastorage.org/webt/zb/q5/ic/zbq5icc6mgwabmeryltcbgnp8g4.png"><br><br>  Parece que una evaluaci√≥n de precisi√≥n se inicia aqu√≠: consideramos cu√°ntas veces obtuvimos del n√∫mero total de casos.  Si tenemos 5 palabras y para 4 determinamos correctamente la parte superior, obtenemos el 80%. <br><br>  Pero en realidad evaluar el analizador en su forma pura es problem√°tico.  Los desarrolladores que resuelven los problemas del an√°lisis autom√°tico a menudo toman el texto sin formato como entrada, que, de acuerdo con la pir√°mide de an√°lisis, pasa por las etapas de tokenizaci√≥n y an√°lisis morfol√≥gico.  Los errores de estos pasos anteriores pueden afectar la calidad del analizador.  En particular, esto se aplica al procedimiento de tokenizaci√≥n: asignaci√≥n de palabras.  Si hemos identificado las palabras de unidad incorrectas, ya no podremos evaluar correctamente las relaciones sint√°cticas entre ellas; despu√©s de todo, en nuestro cuerpo original etiquetado las unidades eran diferentes. <br><br>  Por lo tanto, la f√≥rmula de evaluaci√≥n en este caso es la medida f, donde la precisi√≥n es la proporci√≥n de resultados exactos en relaci√≥n con el n√∫mero total de predicciones, y la integridad es la proporci√≥n de resultados precisos en relaci√≥n con el n√∫mero de enlaces en los datos marcados. <br><br>  Cuando damos estimaciones en el futuro, debemos recordar que las m√©tricas utilizadas afectan no solo la sintaxis, sino tambi√©n la calidad de la tokenizaci√≥n. <br><br><h3>  Idioma ruso en las dependencias universales </h3><br>  Para que el analizador pueda marcar sint√°cticamente las oraciones que a√∫n no ha visto, necesita alimentar el corpus marcado para el entrenamiento.  Para el idioma ruso, hay varios casos de este tipo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/f92/0bf/839f920bffbfaf4efc0d054ee4804f0d.png"><br><br>  La segunda columna indica el n√∫mero de tokens: palabras.  Cuantos m√°s tokens, m√°s cuerpos de entrenamiento y mejor ser√° el algoritmo final (si se trata de buenos datos).  Obviamente, todos los experimentos se llevan a cabo en SynTagRus (desarrollado por IPPI RAS), en el que hay m√°s de un mill√≥n de tokens.  Todos los algoritmos se entrenar√°n en √©l, lo que se discutir√° m√°s adelante. <br><br><h3>  Analizadores del ruso en la tarea compartida CoNLL </h3><br>  Seg√∫n los resultados de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">competencia</a> del a√±o pasado, los modelos que fueron entrenados en el mismo SynTagRus lograron los siguientes indicadores LAS: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ded/ab4/27e/dedab427eef589c4bf8e3c24475632f7.png"><br><br>  Los resultados de los analizadores de ruso son impresionantes: son mejores que los de analizadores de ingl√©s, franc√©s y otros idiomas m√°s raros.  Tuvimos mucha suerte por dos razones a la vez.  En primer lugar, los algoritmos hacen un buen trabajo con el idioma ruso.  En segundo lugar, tenemos SynTagRus, una carcasa grande y marcada. <br><br>  Por cierto, la competencia de 2018 ya pas√≥, pero llevamos a cabo nuestra investigaci√≥n en la primavera de este a√±o, por lo que confiamos en los resultados de la pista del a√±o pasado.  Mirando hacia el futuro, notamos que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nueva versi√≥n de UDPipe</a> (Future) result√≥ ser a√∫n m√°s alta este a√±o. <br><br>  Syntaxnet, un analizador de Google, no est√° en la lista.  ¬øQu√© le pasa a √©l?  La respuesta es simple: Syntaxnet comenz√≥ solo con la etapa de an√°lisis morfol√≥gico.  Tom√≥ la tokenizaci√≥n ideal ya preparada, y ya construy√≥ el procesamiento sobre ella.  Por lo tanto, es injusto evaluarlo a la par del resto: el resto se dividi√≥ en tokens con sus propios algoritmos, y esto podr√≠a empeorar los resultados en la siguiente etapa de la sintaxis.  La muestra de Syntaxnet 2017 tiene un mejor resultado que la lista completa anterior, pero las comparaciones directas no son justas. <br><br>  La tabla tiene dos versiones de UDPipe, en 12 y 15 lugares.  Las mismas personas que participaron activamente en el proyecto de Dependencias Universales est√°n desarrollando este analizador. <br><br>  Las actualizaciones de UDPipe aparecen peri√≥dicamente (algo menos frecuente, por cierto, el dise√±o de los casos tambi√©n se actualiza).  Entonces, despu√©s de la competencia el a√±o pasado, UDPipe se actualiz√≥ (estos eran compromisos para la versi√≥n 2.0 a√∫n no lanzados; en el futuro, por simplicidad, nos referiremos aproximadamente al compromiso de UDPipe 2.0 que tomamos, aunque estrictamente hablando esto no es as√≠);  Por supuesto, no hay tales actualizaciones en la tabla de la competencia.  El resultado de "nuestro" compromiso est√° aproximadamente en el s√©ptimo lugar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/262/c42/635/262c42635f1f93cdfd690418208f79fe.png"><br><br>  Por lo tanto, debemos elegir un analizador sint√°ctico para el idioma ruso.  Como datos iniciales, tenemos la placa de arriba con el Syntaxnet l√≠der y con UDPipe 2.0 en alg√∫n lugar del s√©ptimo lugar. <br><br><h2>  Elige un modelo </h2><br>  Lo hacemos simple: comenzamos con el analizador con las tasas m√°s altas.  Si algo est√° mal con √©l, ve abajo.  Algo puede no estar bien de acuerdo con los siguientes criterios: tal vez no sean perfectos, pero se nos ocurrieron: <br><br><ul><li>  <b>Velocidad de trabajo</b> .  Nuestro analizador deber√≠a funcionar lo suficientemente r√°pido.  La sintaxis, por supuesto, est√° lejos de ser el √∫nico m√≥dulo "bajo el cap√≥" de un sistema en tiempo real, por lo que no debe gastar m√°s de una docena de milisegundos en √©l. <br></li><li>  <b>La calidad del trabajo</b> .  Como m√≠nimo, el analizador se basa en datos del idioma ruso.  El requisito es obvio.  Para el idioma ruso, tenemos analizadores morfol√≥gicos bastante buenos que se pueden integrar en nuestra pir√°mide.  Si podemos asegurarnos de que el analizador en s√≠ mismo funciona bien sin morfolog√≠a, entonces esto nos vendr√° bien; m√°s adelante deslizaremos la morfolog√≠a. <br></li><li>  <b>Disponibilidad de un c√≥digo de capacitaci√≥n y preferiblemente un modelo en el dominio p√∫blico</b> .  Si tenemos un c√≥digo de entrenamiento, podremos repetir los resultados del autor del modelo.  Para hacer esto, deben estar abiertos.  Y, adem√°s, necesitamos monitorear cuidadosamente las condiciones para la distribuci√≥n de casos y modelos. ¬øTendremos que comprar una licencia para usarlos, si los usamos como parte de nuestros algoritmos? <br></li><li>  <b>Lanzamiento sin esfuerzo extra</b> .  Este art√≠culo es muy subjetivo, pero importante.  ¬øQu√© significa esto?  Esto significa que si nos sentamos durante tres d√≠as y comenzamos algo, pero no comienza, entonces no podremos seleccionar este analizador, incluso si ser√° de una calidad perfecta. <br></li></ul><br>  Todo lo que era superior a UDPipe 2.0 en el gr√°fico del analizador no nos conven√≠a.  Tenemos un proyecto de Python, y algunos analizadores de la lista no est√°n escritos en Python.  Para implementarlos en el proyecto Python, ser√≠a necesario aplicar los s√∫per esfuerzos.  En otros casos, nos enfrentamos con c√≥digo fuente cerrado, desarrollos acad√©micos e industriales; en general, no llegar√°s al fondo. <br><br>  Star Syntaxnet merece una historia aparte sobre la calidad del trabajo.  Aqu√≠ no nos conven√≠a por la velocidad del trabajo.  El tiempo de su respuesta a algunas frases simples comunes en los chats es de 100 milisegundos.  Si gastamos tanto en sintaxis, no tenemos tiempo suficiente para nada m√°s.  Al mismo tiempo, UDPipe 2.0 analiza por ~ 3 ms.  Como resultado, la elecci√≥n recay√≥ en UDPipe 2.0. <br><br><h2>  UDPipe 2.0 </h2><br>  UDPipe es una tuber√≠a que aprende la tokenizaci√≥n, la lematizaci√≥n, el etiquetado morfol√≥gico y el an√°lisis de gram√°tica de dependencia.  Podemos ense√±arle todo esto o algo por separado.  Por ejemplo, haga otro analizador morfol√≥gico para el idioma ruso con √©l.  O entrenar y usar UDPipe como un tokenizador. <br><br>  UDPipe 2.0 est√° documentado en detalle.  Hay una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descripci√≥n de la arquitectura</a> , un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">repositorio con un c√≥digo de capacitaci√≥n</a> , un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">manual</a> .  Lo m√°s interesante son los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelos confeccionados</a> , incluso para el idioma ruso.  Descargar y ejecutar  Tambi√©n en este recurso se han publicado los par√°metros de capacitaci√≥n seleccionados para cada corpus de idiomas.  Para cada modelo de este tipo, se necesitan unos 60 par√°metros de capacitaci√≥n y, con su ayuda, puede lograr de forma independiente los mismos indicadores de calidad que en la tabla.  Puede que no sean √≥ptimos, pero al menos podemos estar seguros de que la tuber√≠a funcionar√° correctamente.  Adem√°s, la presencia de dicha referencia nos permite experimentar tranquilamente con el modelo por nuestra cuenta. <br><br><h3>  C√≥mo funciona UDPipe 2.0 </h3><br>  Primero, el texto se divide en oraciones y las oraciones en palabras.  UDPipe hace todo esto a la vez con la ayuda de un m√≥dulo conjunto: una red neuronal (GRU de dos lados de una sola capa), que para cada car√°cter predice si es el √∫ltimo en una oraci√≥n o en una palabra. <br><br>  Luego, el etiquetador comienza a funcionar, algo que predice las propiedades morfol√≥gicas del token: en cuyo caso la palabra es, en qu√© n√∫mero.  Basado en los √∫ltimos cuatro caracteres de cada palabra, un etiquetador genera hip√≥tesis con respecto a una parte del discurso y las etiquetas morfol√≥gicas de esa palabra, y luego, con la ayuda de un perceptr√≥n, selecciona la mejor opci√≥n. <br><br>  UDPipe tambi√©n tiene un lematizador que selecciona la forma inicial de las palabras.  Aprende sobre el mismo principio por el cual un hablante no nativo podr√≠a tratar de determinar el lema de una palabra desconocida.  Cortamos el prefijo y el final de la palabra, agregamos algo de "t", que est√° presente en la forma inicial del verbo, etc.  Entonces se generan los candidatos, de los cuales elige el mejor perceptr√≥n. <br><br>  El esquema de marcado morfol√≥gico (que determina el n√∫mero, el caso y todo lo dem√°s) y las predicciones de los lemas son muy similares.  Se pueden predecir juntos, pero mejor por separado: la morfolog√≠a del idioma ruso es demasiado rica.  Tambi√©n puede conectar su lista de lemas. <br><br>  Pasemos a la parte m√°s interesante: el analizador.  Existen varias arquitecturas de analizador de dependencias.  UDPipe es una arquitectura basada en la transici√≥n: funciona r√°pidamente, pasando a trav√©s de todos los tokens una vez en un tiempo lineal. <br><br>  El an√°lisis sint√°ctico en dicha arquitectura comienza con una pila (donde al principio solo hay ra√≠z) y una configuraci√≥n vac√≠a.  Hay tres formas predeterminadas de cambiarlo: <br><br><ul><li>  LeftArc: aplicable si el segundo elemento de la pila no es root.  Mantiene la relaci√≥n entre el token en la parte superior de la pila y el segundo token, y tambi√©n expulsa el segundo de la pila. <br></li><li>  RightArc es igual, pero la dependencia se construye de la otra manera y se descarta la sugerencia. <br></li><li>  Shift: transfiere la siguiente palabra del b√∫fer a la pila. <br></li></ul><br>  A continuaci√≥n se muestra un ejemplo del analizador ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fuente</a> ).  Tenemos la frase "res√©rvame el vuelo de la ma√±ana" y nos estamos volviendo a conectar: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/196/b17/845/196b17845e524d75a878837b25325a76.png"><br><br>  Aqu√≠ est√° el resultado: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/686/c78/066/686c780661b296250d53cba054317a18.png"><br><br>  El analizador cl√°sico basado en la transici√≥n tiene las tres operaciones enumeradas anteriormente: flecha unidireccional, flecha unidireccional y shift.  Tambi√©n hay una operaci√≥n de intercambio, en las arquitecturas b√°sicas de analizador basado en transici√≥n no se usa, pero se incluye en UDPipe.  Swap devuelve el segundo elemento de la pila al b√∫fer para tomar el siguiente del b√∫fer (si est√°n espaciados).  Esto ayuda a omitir algunas palabras y restablecer la conexi√≥n correcta. <br><br>  Hay un buen art√≠culo del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace de la</a> persona a la que se le ocurri√≥ la operaci√≥n de intercambio.  Seleccionaremos un punto: a pesar del hecho de que repetidamente pasamos por el b√∫fer de token inicial (es decir, nuestro tiempo ya no es lineal), estas operaciones se pueden optimizar para que el tiempo regrese muy cerca de lineal.  Es decir, ante nosotros no es solo una operaci√≥n significativa desde el punto de vista del lenguaje, sino tambi√©n una herramienta que no ralentiza mucho el trabajo del analizador. <br><br>  Usando el ejemplo anterior, mostramos las operaciones, como resultado de lo cual obtenemos alguna configuraci√≥n: el b√∫fer de token y las conexiones entre ellos.  Le damos esta configuraci√≥n en el paso actual al analizador basado en la transici√≥n, y con √©l, debe predecir la configuraci√≥n en el siguiente paso.  Al comparar los vectores de entrada y las configuraciones en cada paso, se entrena el modelo. <br><br>  Entonces, seleccionamos un analizador que se ajusta a todos nuestros criterios, e incluso entendimos c√≥mo funciona.  Procedemos a los experimentos. <br><br><h3>  Problemas UDPipe </h3><br>  Hagamos una peque√±a oraci√≥n: "Transfiera cien rublos a mam√°".  El resultado te hace agarrarte la cabeza. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9cb/948/1f2/9cb9481f2e06b366fbee26f0835d31b0.png"><br><br>  "Traducir" result√≥ ser una excusa, pero esto es bastante l√≥gico.  Determinamos la gram√°tica de la forma de la palabra por los √∫ltimos cuatro caracteres.  "Plomo" es algo as√≠ como "en el medio", por lo que la elecci√≥n es relativamente l√≥gica.  Es m√°s interesante con "mam√°": "mam√°" estaba en el caso preposicional y se convirti√≥ en el pin√°culo de esta oraci√≥n. <br><br>  Si tratamos de interpretar todo en funci√≥n de los resultados del an√°lisis, obtendr√≠amos algo as√≠ como "en medio de una madre (¬øde qui√©n es mam√°? ¬øQui√©n es esta madre?) Cientos de rublos".  No era exactamente lo que era al principio.  Necesitamos lidiar de alguna manera con esto.  Y se nos ocurri√≥ c√≥mo. <br><br>  En la pir√°mide de an√°lisis, la sintaxis se construye sobre la morfolog√≠a, basada en etiquetas morfol√≥gicas.  Aqu√≠ hay un ejemplo de libro de texto de un ling√ºista L.V.  Shcherby a este respecto: <br><br>  <i>"Gloky cuzdra shteko budlanula bokra y ni√±o de cabello rizado".</i> <br><br>  El an√°lisis de esta propuesta no causa problemas.  Por qu√©  Porque nosotros, como etiquetadores UDPipe, miramos el final de una palabra y entendemos a qu√© parte del discurso se refiere y de qu√© forma es.  La historia con "traducir" como una excusa contradice completamente nuestra intuici√≥n, pero resulta l√≥gico en el momento en que intentamos hacer lo mismo con palabras desconocidas.  Una persona puede pensar de la misma manera. <br><br>  Evaluaremos el etiquetador UDPipe por separado.  Si no nos conviene, tomaremos otro etiquetador y luego construiremos el an√°lisis sobre otro marcado morfol√≥gico. <br><br>  <i>Etiquetado desde texto sin formato (puntuaci√≥n CoNLL17 F1)</i> <br><br><ul><li>  <i>formas doradas: 301639</i> , <br></li><li>  <i>upostag: 98.15%</i> , <br></li><li>  <i>xpostag: 99.89%</i> , <br></li><li>  <b><i>haza√±as: 93.97%</i></b> , <br></li><li>  <b><i>alltags: 93.44%</i></b> , <br></li><li>  <b><i>lemas: 96.68%</i></b> <br></li></ul><br>  La calidad de la morfolog√≠a de UDPipe 2.0 no es mala.  Pero para el idioma ruso se puede lograr mejor.  El analizador Mystem (el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desarrollo de Yandex</a> ) logra mejores resultados en la determinaci√≥n de las partes del habla que UDPipe.  Adem√°s, otros analizadores son m√°s dif√≠ciles de implementar en un proyecto de Python, y trabajan m√°s lentamente con una calidad comparable a la de Mystem. ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> . <br>              UDPipe.   .  ,  Mystem     .  ,    ¬´  ¬ª  ¬´¬ª ‚Äî   ¬´¬ª,    ¬´¬ª.    .   ,     ¬´¬ª,     (),  ,    .   : <br><br><ul><li> ¬´ ¬ª ‚Äî     <br></li><li> ¬´  ¬ª ‚Äî ..     <br></li><li> ¬´ - ¬ª ‚Äî     (-     ) <br></li></ul><br>  En tales casos, Mystem honestamente le da a toda la cadena: <br><br> <code>m.analyze(" ") <br> [{'analysis': [{'lex': '', 'gr': 'PART='}], 'text': ''}, <br> {'text': ' '}, <br> {'analysis': [{'lex': '', 'gr': 'S,,=(,|,|,)'}], <br> 'text': ''}, <br> {'text': '\n'}] <br></code> <br>  Pero no podemos enviar toda la cadena de tuber√≠as a UDPipe, pero debemos especificar una etiqueta mejor.  ¬øC√≥mo elegirlo?  Si no tocas nada, quiero tomar el primero, tal vez funcione.  Pero las etiquetas se ordenan alfab√©ticamente de acuerdo con los nombres en ingl√©s, por lo que nuestra elecci√≥n ser√° casi aleatoria, y algunos an√°lisis casi pierden la oportunidad de ser los primeros. <br><br>  Hay un analizador que puede ofrecer la mejor opci√≥n: Pymorphy2.  Pero con un an√°lisis de la morfolog√≠a, √©l es peor.  Adem√°s, da la mejor palabra fuera de contexto.  Pymorphy2 solo dar√° un an√°lisis para "sin director", "ver director" y "director".  No ser√° aleatorio, pero realmente la mejor probabilidad, que en pymorphy2 se consideraba en un cuerpo de textos separado.  Pero se garantizar√° un cierto porcentaje de an√°lisis incorrecto de los textos de combate, simplemente porque pueden contener frases con diferentes formas reales: tanto "veo al director" como "los directores vinieron a la reuni√≥n" y "no hay director".  Una probabilidad de an√°lisis sin contexto no nos conviene. <br><br>  ¬øC√≥mo obtener contextualmente el mejor conjunto de etiquetas?  Usando el analizador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RNNMorph</a> .  Pocas personas se enteraron de √©l, pero el a√±o pasado gan√≥ la competencia entre analizadores morfol√≥gicos, realizada como parte de la conferencia de Di√°logo. <br><br>  RNNMorph tiene su propio problema: no tiene tokenizaci√≥n.  Si Mystem puede tokenizar texto sin formato, RNNMorph requiere una lista de tokens en la entrada.  Para llegar a la sintaxis, primero deber√° usar un tokenizador externo, luego dar el resultado a RNNMorph y solo luego alimentar la morfolog√≠a resultante al analizador de sintaxis. <br><br>  Aqu√≠ est√°n las opciones que tenemos.  No rechazaremos el an√°lisis sin contexto pymorphy2 por ahora sobre los casos discutibles en el Mystem; de repente, no se quedar√° muy atr√°s de RNNMorph.  Aunque si los comparamos puramente al nivel de calidad del marcado morfol√≥gico (datos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MorphoRuEval-2017</a> ), entonces la p√©rdida es significativa, alrededor del 15%, si tomamos la precisi√≥n de acuerdo con las palabras. <br>  A continuaci√≥n, debemos convertir la salida de Mystem al formato que UDPipe entiende: conllu.  Y nuevamente, esto es un problema, incluso hasta dos.  Puramente t√©cnico: las l√≠neas no coinciden.  Y conceptual: no siempre est√° completamente claro c√≥mo compararlos.  Frente a dos marcas diferentes de datos de idioma, es casi seguro que se encontrar√° con el problema de la coincidencia de etiquetas, consulte los ejemplos a continuaci√≥n.  Las respuestas a la pregunta "qu√© etiqueta est√° aqu√≠" pueden ser diferentes, y probablemente la respuesta correcta dependa de la tarea.  Debido a esta inconsistencia, hacer coincidir los sistemas de marcado no es una tarea f√°cil en s√≠ misma. <br><br>  ¬øC√≥mo convertir?  Hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">russian_tagsets</a> _ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">package</a> , un paquete para Python que puede convertir diferentes formatos.  No hay traducci√≥n del formato de emisi√≥n de Mystem a Conllu, que se acepta en Dependencias Universales, pero s√≠ hay una traducci√≥n a conllu, por ejemplo, del formato de marcado del corpus nacional del idioma ruso (y viceversa).  El autor del paquete (por cierto, es el autor de pymorphy2) escribi√≥ algo maravilloso directamente en la documentaci√≥n: "Si no puede usar este paquete, no lo use".  Lo hizo no porque el programador krivorukov (¬°es un excelente programador!), Sino porque si necesita convertirse uno a otro, entonces corre el riesgo de tener problemas debido a la inconsistencia ling√º√≠stica de las convenciones de marcado. <br><br>  Aqu√≠ hay un ejemplo.  A la escuela se le ense√±√≥ la "categor√≠a de condici√≥n" (fr√≠o, necesario).  Algunos dicen que es un adverbio, otros dicen un adjetivo.  Necesita convertir esto, y agrega algunas reglas, pero a√∫n as√≠ no logra una correspondencia inequ√≠voca entre un formato y otro. <br><br>  Otro ejemplo: una promesa (o alguien hizo algo o hizo algo con alguien).  "Petya mat√≥ a alguien" o "Petya fue asesinada".  "Vasya toma fotos" - "Vasya toma fotos" (es decir, "Vasya es fotografiada").  Tambi√©n hay una garant√≠a intermedia en SynTagRus: ni siquiera profundizaremos en qu√© es y por qu√©.  Pero en Mystem no lo es.  Si necesita de alguna manera llevar un formato a otro, este es un callej√≥n sin salida. <br><br>  M√°s o menos honestamente tomamos el consejo del autor del paquete russian_tagsets: no utilizamos su desarrollo, porque no encontramos el par requerido en la lista de formatos de correspondencia.  Como resultado, escribimos nuestro convertidor personalizado de Mystem a Conllu y continuamos. <br><br><h3>  Conectamos el etiquetador de terceros y el analizador UDPipe </h3><br>  Despu√©s de todas las aventuras, tomamos tres algoritmos, que se describieron anteriormente: <br><br><ul><li>  UDPipe basal <br></li><li>  Mym con desambiguaci√≥n de etiqueta de pymorphy2 <br></li><li>  RNNMorph <br></li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7a/6e8/acb/c7a6e8acba5759723b585121d296b4e5.png"><br><br>  Perdimos calidad por una raz√≥n bastante obvia.  Tomamos el modelo UDPipe entrenado en una morfolog√≠a, pero deslizamos otra morfolog√≠a en una entrada.  El problema cl√°sico de la falta de coincidencia de datos entre el tren y la prueba es el resultado de una ca√≠da en la calidad. <br><br>  Intentamos alinear nuestras herramientas autom√°ticas de marcado morfol√≥gico con el marcado SynTagRus, que se marc√≥ manualmente.  No tuvimos √©xito, por lo tanto, en el caso de entrenamiento SynTagRus, reemplazaremos todas las marcas morfol√≥gicas manuales con las obtenidas de Mystem y pymorphy2 en un caso y de RNNMorph en otro.  En un caso validado marcado a mano, nos vemos obligados a cambiar el marcado manual a autom√°tico, porque "en la batalla" nunca obtendremos el marcado manual. <br><br>  Como resultado, capacitamos al analizador UDPipe (solo el analizador) con los mismos hiperpar√°metros que la l√≠nea de base.  Lo que fue responsable de la sintaxis, la ID de v√©rtice, de la que depende el tipo de conexi√≥n, nos fuimos, cambiamos todo lo dem√°s. <br><br><h2>  Resultados </h2><br>  Adem√°s, nos comparar√© con Syntaxnet y otros algoritmos.  Los organizadores de CoNLL Shared Task han presentado la partici√≥n SynTagRus (train / dev / test 80/10/10).  Inicialmente tomamos otro (tren / prueba 70/30), por lo que los datos no siempre coinciden con nosotros, aunque fueron recibidos en el mismo caso.  Adem√°s, tomamos la √∫ltima versi√≥n (a partir de febrero-marzo) del repositorio SynTagRus: esta versi√≥n es ligeramente diferente de la de la competencia.  Los datos de lo que no despeg√≥ se dan en art√≠culos donde la divisi√≥n fue la misma que en la competencia: dichos algoritmos est√°n marcados con un asterisco en la tabla. <br><br>  Aqu√≠ est√°n los resultados finales: <br><img src="https://habrastorage.org/getpro/habr/post_images/f80/3ac/3ce/f803ac3ce0068974e855a050ebddc61b.png"><br><br>  RNNMorph realmente result√≥ ser mejor, no en el sentido absoluto, sino en el papel de una herramienta auxiliar para obtener una m√©trica com√∫n de acuerdo con los resultados del an√°lisis (en comparaci√≥n con Mystem + pymorphy2).  Es decir, cuanto mejor es la morfolog√≠a, mejor es la sintaxis, pero la separaci√≥n "sint√°ctica" es mucho menor que la morfol√≥gica.  Tenga en cuenta tambi√©n que no nos alejamos mucho del modelo de referencia, lo que significa que en la morfolog√≠a realmente no hab√≠a tanto como esper√°bamos. <br><br>  Me pregunto cu√°nto miente sobre la morfolog√≠a.  ¬øEs posible lograr una mejora fundamental en el analizador sint√°ctico debido a la morfolog√≠a ideal?  Para responder a esta pregunta, manejamos UDPipe 2.0 en tokenizaci√≥n y morfolog√≠a que estaban perfectamente calibrados (usando el est√°ndar de marcado manual est√°ndar).  Hubo un cierto margen (vea la l√≠nea sobre Gold Morph en la tabla; resulta + 1.54% de RNNMorph_reannotated_syntax) de lo que ten√≠amos, incluso desde el punto de vista de determinar correctamente el tipo de conexi√≥n.  Si alguien escribe un analizador morfol√≥gico absolutamente perfecto del idioma ruso, es probable que los resultados que obtengamos con un analizador sint√°ctico abstracto tambi√©n crezcan.  Y aproximadamente entendemos el techo (al menos el techo para esa arquitectura y para la combinaci√≥n de par√°metros que usamos para UDPipe; se muestra en la tercera fila de la tabla anterior). <br><br>  Curiosamente, casi llegamos a la versi√≥n Syntaxnet en la m√©trica LAS.  Est√° claro que tenemos datos ligeramente diferentes, pero en principio todav√≠a es comparable.  La tokenizaci√≥n de Syntaxnet es "oro", y para nosotros, de Mystem.  Escribimos el contenedor antes mencionado en Mystem, pero el an√°lisis a√∫n ocurre autom√°ticamente;  probablemente Mystem tambi√©n se equivoca en alguna parte.  De la l√≠nea de la tabla "UDPipe 2.0 gold tok", se puede ver que si toma la tokenizaci√≥n UDPipe y gold predeterminada, a√∫n pierde un poco Syntaxnet-2017.  Pero funciona mucho m√°s r√°pido. <br><br>  Lo que nadie ha alcanzado es el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">analizador Stanford</a> .  Est√° dise√±ado de la misma manera que Syntaxnet, por lo que funciona durante mucho tiempo.  En UDPipe, simplemente vamos a lo largo de la pila.  La arquitectura del analizador sint√°ctico y Syntaxnet de Stanford tiene un concepto diferente: primero generan un gr√°fico orientado completo, y luego el algoritmo funciona para dejar el esqueleto (√°rbol de expansi√≥n m√≠nima) que es m√°s probable.  Para hacer esto, pasa por combinaciones, y esta b√∫squeda ya no es lineal, porque recurrir√° a una palabra m√°s de una vez.  A pesar de que durante mucho tiempo, desde el punto de vista de la ciencia pura, al menos para el idioma ruso, es una arquitectura m√°s eficiente.  Intentamos elevar este desarrollo acad√©mico durante dos d√≠as; por desgracia, no funcion√≥.  Pero seg√∫n su arquitectura, est√° claro que no funciona r√°pido. <br><br>  En cuanto a nuestro enfoque, aunque formalmente casi no aumentamos por m√©tricas, ahora todo est√° bien con la "madre". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/423/f71/8b2/423f718b24dbb3c0db517fc13c032647.png"><br><br>  En la frase "traducir cien rublos a mam√°", "traducir" es realmente un verbo en el estado de √°nimo imperativo.  "Mam√°" tiene su caso dativo.  Y lo m√°s importante para nosotros es nuestra etiqueta (iobj), un objeto indirecto (destino).  Aunque el crecimiento en n√∫meros es insignificante, manejamos bien el problema con el que comenz√≥ la tarea. <br><br><h2>  Bonus track: puntuaci√≥n </h2><br>  Si volvemos a los datos reales, resulta que la sintaxis depende de la puntuaci√≥n.  Tome la frase "no puede ejecutar la misericordia".  Lo que no se puede hacer exactamente, "ejecutar" o "tener piedad", depende de d√≥nde se encuentre la coma.  Incluso si ponemos al ling√ºista para marcar los datos, necesitar√° la puntuaci√≥n como alg√∫n tipo de herramienta auxiliar.  No pod√≠a prescindir de ella. <br><br>  Tomemos las frases "Peter hola" y "Peter hola" y veamos su an√°lisis por el modelo baseline-UDPipe.  Dejamos de lado los problemas que, seg√∫n este modelo, entonces: <br>  1) "Petya" es un sustantivo femenino; <br>  2) "Petya" es (a juzgar por el conjunto de etiquetas) la forma inicial, pero al mismo tiempo, su lema supuestamente no es "Petya". <br><br>  As√≠ es como el resultado cambia debido a la coma, con su ayuda obtenemos algo similar a la verdad. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/46f/821/773/46f8217734e6e8c0f31e8f7f47d23d7d.png"><br><br>  En el segundo caso, "Petia" es un sujeto y "hola" es un verbo.  Volver a predecir la forma de una palabra basada en los √∫ltimos cuatro caracteres.  En la interpretaci√≥n del algoritmo, esto no es "saludos de Petia", sino "saludos de Petya".  Escriba "Petya canta" o "Petya vendr√°".  El an√°lisis es bastante comprensible: en ruso, no puede haber una coma entre el sujeto y el predicado.  Por lo tanto, si la coma es, esta es la palabra "hola", y si no hay coma, bien podr√≠a ser algo as√≠ como "Petya Privet". <br><br>  Encontraremos esto en la producci√≥n con bastante frecuencia, porque los correctores ortogr√°ficos corregir√°n la ortograf√≠a, pero no la puntuaci√≥n.  Para empeorar las cosas, el usuario puede establecer comas incorrectamente, y nuestro algoritmo las tendr√° en cuenta para comprender el lenguaje natural.  ¬øCu√°les son las posibles soluciones aqu√≠?  Vemos dos opciones. <br><br>  La primera opci√≥n es hacer lo que a veces hacen al traducir el discurso en texto.  Inicialmente, no hay puntuaci√≥n en dicho texto, por lo que se restaura a trav√©s del modelo.  El resultado es un material relativamente competente en t√©rminos de las reglas del idioma ruso, que ayuda al analizador sint√°ctico a funcionar correctamente. <br><br>  La segunda idea es algo m√°s audaz y contradice las lecciones escolares del idioma ruso.  Implica trabajar sin puntuaci√≥n: si de repente la entrada es puntuaci√≥n, la eliminaremos de all√≠.  Tambi√©n eliminaremos absolutamente todos los signos de puntuaci√≥n del cuerpo de entrenamiento.  Suponemos que el idioma ruso existe sin puntuaci√≥n.  Solo puntos por dividir en oraciones. <br><br>  T√©cnicamente, es bastante simple, porque no cambiamos los nodos finales en el √°rbol de sintaxis.  No podemos tener tal que el signo de puntuaci√≥n sea la parte superior.  Este siempre es un nodo final, excepto el signo%, que por alguna raz√≥n en SynTagRus es el v√©rtice del n√∫mero anterior (50% en SynTagRus est√° marcado como% - v√©rtice y 50 - dependiente). <br><br>  Probemos usando el modelo Mystem (+ pymorphy 2). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4e4/578/1de/4e45781de1ac88426d8e6da786903d8b.png"><br><br>  Es de vital importancia para nosotros no dar el modelo de texto de puntuaci√≥n sin puntuaci√≥n.  Pero si siempre damos el texto sin puntuaci√≥n, estaremos en la l√≠nea superior y obtendremos al menos resultados aceptables.  Si el texto sin puntuaci√≥n y el modelo funciona sin puntuaci√≥n, entonces, con respecto a la puntuaci√≥n ideal y el modelo de puntuaci√≥n, la ca√≠da ser√° solo del 3%. <br><br>  ¬øQu√© hacer al respecto?  Podemos detenernos en estos n√∫meros, obtenidos utilizando el modelo sin puntuaci√≥n y la purificaci√≥n de la puntuaci√≥n.  O invente alg√∫n tipo de clasificador para restaurar la puntuaci√≥n.  No lograremos n√∫meros ideales (aquellos con puntuaci√≥n en el modelo de puntuaci√≥n), porque el algoritmo de recuperaci√≥n de puntuaci√≥n funciona con alg√∫n error, y los n√∫meros "ideales" se calcularon en SynTagRus absolutamente puro.  Pero si vamos a escribir un modelo que restaure la puntuaci√≥n, ¬øel progreso pagar√° nuestros costos?  La respuesta a√∫n no es obvia. <br><br>  Podemos pensar durante mucho tiempo en la arquitectura del analizador sint√°ctico, pero debemos recordar que, de hecho, todav√≠a no hay un gran corpus de textos web marcado sint√°cticamente.  Su existencia ayudar√≠a a resolver mejor los problemas reales.  Hasta ahora, estamos estudiando en el cuerpo de textos editados absolutamente literarios, y estamos perdiendo calidad al obtener textos personalizados en la batalla, que a menudo se escriben analfabetos. <br><br><h2>  Conclusi√≥n </h2><br>  Examinamos el uso de varios algoritmos sint√°cticos de an√°lisis basados ‚Äã‚Äãen la gram√°tica de dependencia, tal como se aplica al idioma ruso.  Result√≥ que, en t√©rminos de velocidad, conveniencia y calidad de trabajo, UDPipe result√≥ ser la mejor herramienta.  Su modelo de referencia puede mejorarse si las etapas de tokenizaci√≥n y an√°lisis morfol√≥gico se asignan a otros analizadores de terceros: este truco permite corregir el comportamiento incorrecto del etiquetador y, como resultado, el analizador en casos importantes para el an√°lisis. <br><br>  Tambi√©n analizamos el problema de la relaci√≥n entre la puntuaci√≥n y el an√°lisis y llegamos a la conclusi√≥n de que, en nuestro caso, es mejor eliminar la puntuaci√≥n antes del an√°lisis sint√°ctico. <br><br>  Esperamos que los puntos de aplicaci√≥n discutidos en nuestro art√≠culo lo ayuden a usar el an√°lisis sint√°ctico para resolver sus problemas de la manera m√°s eficiente posible. <br><br>  <i>El autor agradece a Nikita Kuznetsova y Natalya Filippova por su ayuda en la preparaci√≥n del art√≠culo;</i>  <i>para asistencia en el estudio: Anton Alekseev, Nikita Kuznetsov, Andrei Kutuzov, Boris Orekhov y Mikhail Popov.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es418701/">https://habr.com/ru/post/es418701/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es418689/index.html">C√≥mo crear bibliotecas de componentes en Figma, ahorrando un presupuesto, usando el ejemplo de una subasta en l√≠nea</a></li>
<li><a href="../es418691/index.html">Ganadero: Kubernetes en 5 minutos sobre metal desnudo.</a></li>
<li><a href="../es418693/index.html">¬øPor qu√© es tan dif√≠cil detectar la felicidad en el cerebro?</a></li>
<li><a href="../es418695/index.html">Guerras contra la pirater√≠a: el imperio contraataca</a></li>
<li><a href="../es418699/index.html">Creaci√≥n de una m√°quina arcade emulador. Parte 3</a></li>
<li><a href="../es418705/index.html">Fundamentos de Futex</a></li>
<li><a href="../es418707/index.html">KDispatcher: bus de eventos ligero y conveniente para el uso diario</a></li>
<li><a href="../es418709/index.html">Necesidad de forzarse: controladores y barreras de interfaz</a></li>
<li><a href="../es418711/index.html">Token Managed Registers 1.0</a></li>
<li><a href="../es418713/index.html">Juego para mejorar la calidad de Wikipedia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äç‚úàÔ∏è üíü ü•ü Livre "Machine Learning et TensorFlow" ü§∂üèø üï¶ ü§òüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La connaissance de l'apprentissage automatique et de la biblioth√®que TensorFlow est similaire aux premi√®res le√ßons dans une √©cole de conduite, lorsque...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Livre "Machine Learning et TensorFlow"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/437964/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/cy/lg/n3/cylgn38lpjyhq7gveb9cmmt_ml8.jpeg" align="left" alt="image"></a>  La connaissance de l'apprentissage automatique et de la biblioth√®que TensorFlow est similaire aux premi√®res le√ßons dans une √©cole de conduite, lorsque vous souffrez de stationnement parall√®le, essayez de changer de vitesse au bon moment et de ne pas m√©langer les r√©troviseurs, en vous souvenant fr√©n√©tiquement de la s√©quence d'actions, tandis que votre pied tremble nerveusement sur les p√©dales d'acc√©l√©rateur.  C'est un exercice difficile mais n√©cessaire.  Donc dans le machine learning: avant d'utiliser des syst√®mes de reconnaissance faciale modernes ou des algorithmes de pr√©vision en bourse, vous devrez vous occuper des outils appropri√©s et d'un ensemble d'instructions afin de cr√©er ensuite vos propres syst√®mes sans probl√®me. <br><br>  Les d√©butants en apprentissage automatique appr√©cieront l'orientation appliqu√©e de ce livre, car son objectif est d'introduire les bases, puis de passer rapidement √† la r√©solution de probl√®mes r√©els.  √Ä partir d'un examen des concepts et des principes de l'apprentissage automatique du travail avec TensorFlow, vous passerez √† des algorithmes de base, √©tudier des r√©seaux de neurones et √™tre en mesure de r√©soudre ind√©pendamment les probl√®mes de classification, de clustering, de r√©gression et de pr√©vision. <br><a name="habracut"></a><br><h3>  Extrait.  R√©seaux de neurones convolutifs </h3><br>  Faire du shopping dans les magasins apr√®s une journ√©e ext√©nuante est une t√¢che tr√®s on√©reuse.  Mes yeux sont attaqu√©s par trop d'informations.  Ventes, coupons, une vari√©t√© de couleurs, petits enfants, lumi√®res vacillantes et all√©es remplies de gens - ce ne sont que quelques exemples de tous les signaux qui sont envoy√©s au cortex visuel du cerveau, que je veuille ou non y pr√™ter attention.  Le syst√®me visuel absorbe une abondance d'informations. <br><br>  Vous connaissez s√ªrement la phrase ¬´il vaut mieux voir une fois que d‚Äôentendre cent fois¬ª.  Cela peut √™tre vrai pour vous et pour moi (c'est-√†-dire pour les gens), mais la machine peut-elle trouver un sens aux images?  Nos photor√©cepteurs visuels s√©lectionnent les longueurs d'onde de la lumi√®re, mais cette information, apparemment, ne s'√©tend pas √† notre conscience.  En fin de compte, je ne peux pas dire exactement quelles longueurs d'onde de lumi√®re j'observe.  De la m√™me mani√®re, la cam√©ra re√ßoit des pixels d'image.  Mais nous voulons plut√¥t recevoir quelque chose d'un niveau sup√©rieur, par exemple des noms ou des positions d'objets.  Comment obtenir des informations per√ßues au niveau humain √† partir des pixels? <br><br>  Pour obtenir une certaine signification √† partir des donn√©es sources, il sera n√©cessaire de concevoir un mod√®le de r√©seau neuronal.  Dans les chapitres pr√©c√©dents, plusieurs types de mod√®les de r√©seaux de neurones ont √©t√© introduits, tels que les mod√®les enti√®rement connect√©s (chapitre 8) et les auto-encodeurs (chapitre 7).  Dans ce chapitre, nous pr√©senterons un autre type de mod√®le appel√© r√©seau neuronal convolutif (CNN).  Ce mod√®le fonctionne tr√®s bien avec des images et d'autres donn√©es sensorielles telles que le son.  Par exemple, le mod√®le CNN peut classer de mani√®re fiable quel objet est affich√© dans l'image. <br><br>  Le mod√®le CNN, qui sera abord√© dans ce chapitre, sera form√© pour classer les images dans l'une des 10 cat√©gories possibles.  Dans ce cas, ¬´une image vaut mieux qu'un seul mot¬ª, car nous n'avons que 10 options possibles.  C'est un petit pas vers la perception au niveau humain, mais nous devons commencer par quelque chose, non? <br><br><h3>  9.1.  Inconv√©nients des r√©seaux de neurones </h3><br>  L'apprentissage automatique est une lutte √©ternelle pour le d√©veloppement d'un mod√®le qui aurait une expressivit√© suffisante pour pr√©senter des donn√©es, mais en m√™me temps pas si universel qu'il s'agit de recycler et de m√©moriser des mod√®les.  Les r√©seaux de neurones sont propos√©s comme un moyen d'augmenter l'expressivit√©;  bien que, comme vous pouvez le deviner, ils souffrent grandement des pi√®ges de la reconversion. <br><br><blockquote>  REMARQUE Le recyclage se produit lorsqu'un mod√®le entra√Æn√© est exceptionnellement pr√©cis sur un ensemble de donn√©es d'apprentissage et mauvais sur un ensemble de donn√©es de validation.  Ce mod√®le est probablement trop universel pour la petite quantit√© de donn√©es disponibles, et au final, il se souvient simplement des donn√©es de formation. </blockquote><br>  Pour comparer la polyvalence des deux mod√®les d'apprentissage automatique, vous pouvez utiliser un algorithme heuristique rapide et grossier pour calculer le nombre de param√®tres qui doivent √™tre d√©termin√©s √† la suite de la formation.  Comme le montre la fig.  9.1, un r√©seau de neurones enti√®rement connect√© qui prend une image 256 √ó 256 et la mappe sur une couche de 10 neurones aura 256 √ó 256 √ó 10 = 655 360 param√®tres!  Comparez-le avec un mod√®le contenant seulement cinq param√®tres.  On peut supposer qu'un r√©seau de neurones enti√®rement connect√© peut pr√©senter des donn√©es plus complexes qu'un mod√®le √† cinq param√®tres. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_c/ey/qe/_ceyqe8jc1s-xzasfzbv4vezhum.png" alt="image"></div><br>  La section suivante traite des r√©seaux de neurones convolutifs, qui sont un moyen raisonnable de r√©duire le nombre de param√®tres.  Au lieu de traiter avec des r√©seaux enti√®rement connect√©s, CNN r√©utilise les m√™mes param√®tres √† plusieurs reprises. <br><br><h3>  9.2.  R√©seaux de neurones convolutifs </h3><br>  L'id√©e principale sous-jacente aux r√©seaux de neurones convolutifs est que la compr√©hension locale de l'image est suffisante.  L'avantage pratique des r√©seaux de neurones convolutifs est que, ayant plusieurs param√®tres, il est possible de r√©duire consid√©rablement le temps de formation, ainsi que la quantit√© de donn√©es n√©cessaires pour former le mod√®le. <br><br>  Au lieu de r√©seaux enti√®rement connect√©s avec des poids de chaque pixel, CNN a un nombre suffisant de poids n√©cessaires pour visualiser un petit fragment de l'image.  C'est comme lire un livre avec une loupe: √† la fin, vous lisez la page enti√®re, mais √† tout moment, n'en regardez qu'un petit fragment. <br><br>  Imaginez une image 256 √ó 256. Au lieu d'utiliser le code TensorFlow qui traite l'image enti√®re √† la fois, vous pouvez num√©riser l'image fragment par fragment, disons, une fen√™tre 5 √ó 5. Une fen√™tre 5 √ó 5 glisse sur l'image (g√©n√©ralement de gauche √† droite et de haut en bas), comme montr√© dans la fig.  9.2.  La vitesse √† laquelle il glisse est appel√©e longueur de foul√©e.  Par exemple, une longueur de pas de 2 signifie qu'une fen√™tre coulissante 5 √ó 5 d√©place 2 pixels √† la fois jusqu'√† ce que l'image enti√®re soit pass√©e.  Dans TensorFlow, comme nous le verrons bient√¥t, vous pouvez ajuster la longueur de pas et la taille de la fen√™tre √† l'aide de la biblioth√®que de fonctions int√©gr√©e. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tl/lj/br/tlljbr-3r61p02umh30yi-wtmhi.png" alt="image"></div><br>  Cette fen√™tre 5 √ó 5 a une matrice de poids 5 √ó 5 qui lui est associ√©e. <br><br><blockquote>  D√âFINITION Une convolution est une somme pond√©r√©e des valeurs d'intensit√© des pixels d'une image lorsque la fen√™tre traverse l'image enti√®re.  Il s'av√®re que ce processus de convolution de l'image avec la matrice de poids cr√©e une autre image (de m√™me taille, qui d√©pend du pliage).  La coagulation est le processus d'application de la convolution. </blockquote><br>  Toutes les manipulations de la fen√™tre glissante se produisent dans la couche convolutionnelle du r√©seau neuronal.  Un r√©seau neuronal convolutif typique comporte plusieurs couches convolutives.  Chaque couche convolutionnelle cr√©e g√©n√©ralement de nombreuses convolutions suppl√©mentaires, donc la matrice de pond√©ration est un tenseur 5 √ó 5 √ó n, o√π n est le nombre de convolutions. <br><br>  Par exemple, laissez l'image passer √† travers une couche convolutionnelle avec une matrice de poids de dimensions 5 √ó 5 √ó 64. Cela cr√©e 64 convolutions avec une fen√™tre coulissante 5 √ó 5. Par cons√©quent, le mod√®le correspondant a 5 √ó 5 √ó 64 = 1600 param√®tres, ce qui est nettement inf√©rieur au nombre de param√®tres d'un r√©seau enti√®rement connect√©. : 256 √ó 256 = 65 536. <br><br>  L'attractivit√© des r√©seaux de neurones convolutifs (CNN) est que le nombre de param√®tres utilis√©s par le mod√®le ne d√©pend pas de la taille de l'image d'origine.  Vous pouvez ex√©cuter le m√™me r√©seau neuronal convolutionnel sur des images 300 √ó 300, et le nombre de param√®tres dans la couche convolutionnelle ne changera pas! <br><br><h3>  9.3.  Pr√©paration d'image </h3><br>  Avant de commencer √† utiliser le mod√®le CNN avec TensorFlow, pr√©parez quelques images.  Les listes de cette section vous aideront √† configurer un ensemble de donn√©es de formation pour le reste du chapitre. <br><br>  Tout d'abord, t√©l√©chargez l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensemble</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">donn√©es</a> CIFAR-10 sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.cs.toronto.edu/~kriz/cifar-10-</a> python.tar.gz.  Cet ensemble contient 60 000 images r√©parties uniform√©ment sur 10 cat√©gories, ce qui est une ressource assez importante pour les t√¢ches de classification.  Ensuite, le fichier image doit √™tre plac√© dans le r√©pertoire de travail.  Dans la fig.  La figure 9.3 montre des exemples d'images de cet ensemble de donn√©es. <br><br>  Nous avons d√©j√† utilis√© l'ensemble de donn√©es CIFAR-10 dans le chapitre pr√©c√©dent sur les auto-encodeurs, et examinons √† nouveau ce code.  La liste suivante est tir√©e directement de la documentation CIFAR-10 situ√©e √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.cs.toronto.edu/~kriz/cifar.html</a> .  Placez le code dans le fichier cifar_tools.py. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xs/rd/6n/xsrd6nmuunpim-aeqepzxwj1acy.png" alt="image"></div><br>  Listing 9.1.  Chargement d'images √† partir d'un fichier CIFAR-10 en Python <br><br><pre><code class="plaintext hljs">import pickle def unpickle(file): fo = open(file, 'rb') dict = pickle.load(fo, encoding='latin1') fo.close() return dict</code> </pre> <br>  Les r√©seaux de neurones ont tendance √† se recycler, il est donc important de faire tout ce qui est possible pour minimiser cette erreur.  Pour ce faire, n'oubliez pas de nettoyer les donn√©es avant de les traiter. <br><br>  Le nettoyage des donn√©es est le processus principal du pipeline d'apprentissage automatique.  Le code du Listing 9.2 utilise les trois √©tapes suivantes pour nettoyer un ensemble d'images: <br><br>  1. Si vous avez une image en couleur, essayez de la convertir en nuances de gris pour r√©duire la dimensionnalit√© des donn√©es d'entr√©e et, par cons√©quent, r√©duire le nombre de param√®tres. <br><br>  2. Pensez √† recadrer l'image au centre, car les bords de l'image ne fournissent aucune information utile. <br><br>  3. Normalisez l'entr√©e en soustrayant la moyenne et en divisant par l'√©cart-type de chaque √©chantillon de donn√©es afin que les gradients ne changent pas trop fortement pendant la propagation arri√®re. <br><br>  La liste suivante montre comment effacer un jeu de donn√©es √† l'aide de ces m√©thodes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/nf/al/banfal_9g-9gy2lns0q_qv2qce8.png" alt="image"></div><br>  Enregistrez toutes les images de l'ensemble de donn√©es CIFAR-10 et ex√©cutez la fonction de nettoyage.  La liste suivante d√©finit une m√©thode pratique pour lire, nettoyer et structurer les donn√©es √† utiliser dans TensorFlow.  L√†, vous devez inclure le code du fichier cifar_tools.py. <br><br>  Listing 9.3.  Pr√©traitement de tous les fichiers CIFAR-10 <br><br><pre> <code class="plaintext hljs">def read_data(directory): names = unpickle('{}/batches.meta'.format(directory))['label_names'] print('names', names) data, labels = [], [] for i in range(1, 6): filename = '{}/data_batch_{}'.format(directory, i) batch_data = unpickle(filename) if len(data) &gt; 0: data = np.vstack((data, batch_data['data'])) labels = np.hstack((labels, batch_data['labels'])) else: data = batch_data['data'] labels = batch_data['labels'] print(np.shape(data), np.shape(labels)) data = clean(data) data = data.astype(np.float32) return names, data, labels</code> </pre> <br>  Dans le fichier using_cifar.py, vous pouvez utiliser la m√©thode en important cifar_tools pour cela.  Les listes 9.4 et 9.5 montrent comment extraire plusieurs images d'un ensemble de donn√©es et les visualiser. <br><br>  Listing 9.4.  Utilisation de la fonction d'assistance cifar_tools <br><br><pre> <code class="plaintext hljs">import cifar_tools names, data, labels = \ cifar_tools.read_data('your/location/to/cifar-10-batches-py')</code> </pre> <br>  Vous pouvez s√©lectionner arbitrairement plusieurs images et les dessiner en fonction de l'√©tiquette.  La liste suivante fait exactement cela, afin que vous puissiez mieux comprendre le type de donn√©es que vous allez traiter. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9s/3c/ls/9s3clsibt-fy4tqxlnmggitpydm.png" alt="image"></div><br>  En ex√©cutant ce code, vous cr√©erez le fichier cifar_examples.png, qui ressemblera √† la Fig.  9.3. <br><br>  ¬ªPlus d'informations sur le livre sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site de l'√©diteur</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Contenu</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Extrait</a> <br><br>  20% de r√©duction sur les colporteurs - <b>Machine Learning</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr437964/">https://habr.com/ru/post/fr437964/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr437952/index.html">Comment tester dans AutoCar: MindMap, analyse de code statique et MockServer</a></li>
<li><a href="../fr437956/index.html">"Impl√©mentation de Splunk 7" - le premier livre sur Splunk en russe</a></li>
<li><a href="../fr437958/index.html">Autorisation en EIES sur un serveur terminal avec signature num√©rique conform√©ment √† GOST-2012</a></li>
<li><a href="../fr437960/index.html">Conseils du directeur technique d'une entreprise informatique aux dipl√¥m√©s du bootcamp</a></li>
<li><a href="../fr437962/index.html">PVS-Studio ROI</a></li>
<li><a href="../fr437968/index.html">PVS-Studio ROI</a></li>
<li><a href="../fr437972/index.html">PHP pour les d√©butants. La session</a></li>
<li><a href="../fr437974/index.html">Comment gagner des WorldSkills num√©riques? Sur un exemple pratique</a></li>
<li><a href="../fr437976/index.html">"Vkontakte" autoris√© √† cacher des dossiers individuels √† la police</a></li>
<li><a href="../fr437978/index.html">Bienvenue sur SphinxSearch-meetup SuperJob</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
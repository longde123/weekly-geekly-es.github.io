<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèø üëÆ üèµÔ∏è Como a Yandex aplicou a vis√£o computacional para melhorar a qualidade das transmiss√µes de v√≠deo. Tecnologia DeepHD üèîÔ∏è üíö üõçÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quando as pessoas pesquisam na Internet uma foto ou um v√≠deo, geralmente adicionam a frase "de boa qualidade". A qualidade geralmente se refere √† reso...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como a Yandex aplicou a vis√£o computacional para melhorar a qualidade das transmiss√µes de v√≠deo. Tecnologia DeepHD</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/422561/">  Quando as pessoas pesquisam na Internet uma foto ou um v√≠deo, geralmente adicionam a frase "de boa qualidade".  A qualidade geralmente se refere √† resolu√ß√£o - os usu√°rios desejam que a imagem seja grande e, ao mesmo tempo, pare√ßa boa na tela de um computador, smartphone ou TV moderno.  Mas e se a fonte de boa qualidade simplesmente n√£o existir? <br><br>  Hoje, contaremos aos leitores da Habr como, com a ajuda das redes neurais, podemos aumentar a resolu√ß√£o do v√≠deo em tempo real.  Voc√™ tamb√©m aprender√° como a abordagem te√≥rica para resolver esse problema difere da pr√°tica.  Se voc√™ n√£o estiver interessado em detalhes t√©cnicos, poder√° rolar com seguran√ßa pela postagem - no final, voc√™ encontrar√° exemplos de nosso trabalho. <br><br><img width="800" src="https://habrastorage.org/webt/hx/lu/ak/hxluakxdy2mxmmskebqieei5zq4.png"><br><br>  H√° muito conte√∫do de v√≠deo na Internet em baixa qualidade e resolu√ß√£o.  Pode ser filmado h√° d√©cadas ou transmitido canais de TV que, por v√°rias raz√µes, n√£o s√£o da melhor qualidade.  Quando os usu√°rios esticam esse v√≠deo para tela cheia, a imagem fica nublada e confusa.  Uma solu√ß√£o ideal para filmes antigos seria encontrar o filme original, digitaliz√°-lo com equipamentos modernos e restaurar manualmente, mas isso nem sempre √© poss√≠vel.  As transmiss√µes s√£o ainda mais complicadas - elas precisam ser processadas ao vivo.  Nesse sentido, a op√ß√£o mais aceit√°vel para trabalharmos √© aumentar a resolu√ß√£o e limpar artefatos usando a tecnologia de vis√£o computacional. <br><br><a name="habracut"></a>  Na ind√∫stria, a tarefa de aumentar fotos e v√≠deos sem perda de qualidade √© chamada de super-resolu√ß√£o.  Muitos artigos j√° foram escritos sobre esse t√≥pico, mas as realidades do aplicativo "combate" se mostraram muito mais complicadas e interessantes.  Brevemente sobre os principais problemas que tivemos que resolver em nossa pr√≥pria tecnologia DeepHD: <br><br><ul><li>  Voc√™ precisa restaurar detalhes que n√£o estavam no v√≠deo original devido √† sua baixa resolu√ß√£o e qualidade, para finaliz√°-los. </li><li>  As solu√ß√µes da √°rea de super-resolu√ß√£o restauram os detalhes, mas tornam claros e detalhados n√£o apenas os objetos no v√≠deo, mas tamb√©m artefatos de compacta√ß√£o, o que causa avers√£o ao p√∫blico. </li><li> H√° um problema com a coleta da amostra de treinamento - √© necess√°rio um grande n√∫mero de pares em que o mesmo v√≠deo est√° presente em baixa resolu√ß√£o e qualidade e em alta.  Na realidade, geralmente n√£o h√° par de qualidade para conte√∫do ruim. </li><li>  A solu√ß√£o deve funcionar em tempo real. </li></ul><br><h3>  Sele√ß√£o de tecnologia </h3><br>  Nos √∫ltimos anos, o uso de redes neurais levou a um sucesso significativo na resolu√ß√£o de quase todas as tarefas de vis√£o computacional, e a tarefa de super-resolu√ß√£o n√£o √© exce√ß√£o.  Encontramos as solu√ß√µes mais promissoras baseadas na GAN (Redes Advers√°rias Generativas, redes rivais generativas).  Eles permitem obter imagens fotorrealistas de alta defini√ß√£o, complementando-as com os detalhes ausentes, por exemplo, desenhando cabelos e c√≠lios nas imagens das pessoas. <br><br><img src="https://habrastorage.org/webt/gq/hl/kz/gqhlkzdwwmq3ad9p78j7wapfhzs.png"><br><br>  No caso mais simples, uma rede neural consiste em duas partes.  A primeira parte - o gerador - obt√©m uma imagem de entrada e retorna uma amplia√ß√£o dobrada.  A segunda parte - o discriminador - recebe a imagem gerada e "real" como entrada e tenta distingui-la. <br><br><img width="700" src="https://habrastorage.org/webt/kn/3s/sc/kn3sscgtqtwqzcnga59cwaor-8y.png"><br><br><h3>  Prepara√ß√£o do conjunto de treinamento </h3><br>  Para treinamento, reunimos dezenas de clipes com qualidade UltraHD.  Primeiro, reduzimos para uma resolu√ß√£o de 1080p, obtendo assim exemplos de refer√™ncia.  Em seguida, reduzimos pela metade esses v√≠deos, compactando-os com uma taxa de bits diferente ao longo do caminho para obter algo semelhante a um v√≠deo real em baixa qualidade.  Dividimos os v√≠deos resultantes em quadros e os usamos de maneira a treinar a rede neural. <br><br><h3>  Desbloqueio </h3><br>  Obviamente, quer√≠amos obter uma solu√ß√£o completa: treinar a rede neural para gerar v√≠deo e qualidade de alta resolu√ß√£o diretamente do original.  No entanto, os GANs eram muito caprichosos e tentavam constantemente refinar os artefatos de compacta√ß√£o, em vez de elimin√°-los.  Portanto, tive que dividir o processo em v√°rias etapas.  O primeiro √© a supress√£o de artefatos de compacta√ß√£o de v√≠deo, tamb√©m conhecido como desbloqueio. <br><br>  Um exemplo de um dos m√©todos de lan√ßamento: <br><br><img src="https://habrastorage.org/webt/0c/sg/zx/0csgzx4zwbtceyujcgcay4mclac.jpeg"><br><br>  Nesse est√°gio, minimizamos o desvio padr√£o entre o quadro gerado e o quadro original.  Assim, embora tenhamos aumentado a resolu√ß√£o da imagem, n√£o obtivemos um aumento real na resolu√ß√£o devido √† regress√£o √† m√©dia: a rede neural, sem saber em quais pixels espec√≠ficos uma determinada borda da imagem passa, foi for√ßada a calcular a m√©dia de v√°rias op√ß√µes, obtendo um resultado desfocado.  O principal que alcan√ßamos nesse est√°gio √© a elimina√ß√£o dos artefatos de compacta√ß√£o de v√≠deo; portanto, no est√°gio seguinte, a rede generativa precisava apenas aumentar a clareza e adicionar os pequenos detalhes ausentes, texturas.  Ap√≥s centenas de experimentos, selecionamos a arquitetura ideal em termos de desempenho e qualidade, que lembra vagamente a arquitetura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DRCN</a> : <br><br><img width="800" src="https://habrastorage.org/webt/oq/au/pc/oqaupcp8k9m4rdspvx8rrrbhpy0.png"><br><br>  A id√©ia principal de uma arquitetura desse tipo √© o desejo de obter a arquitetura mais profunda, sem ter problemas com a converg√™ncia em seu treinamento.  Por um lado, cada camada convolucional subsequente extrai recursos cada vez mais complexos da imagem de entrada, o que permite determinar que tipo de objeto est√° em um determinado ponto da imagem e restaurar pe√ßas complexas e gravemente danificadas.  Por outro lado, a dist√¢ncia no gr√°fico da rede neural de qualquer camada at√© a sa√≠da permanece pequena, o que melhora a converg√™ncia da rede neural e torna-se poss√≠vel o uso de um grande n√∫mero de camadas. <br><br><h3>  Treinamento de rede generativa </h3><br>  Tomamos a arquitetura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SRGAN como</a> base de uma rede neural para aumentar a resolu√ß√£o.  Antes de treinar uma rede competitiva, voc√™ precisa pr√©-treinar o gerador - trein√°-lo da mesma maneira que no est√°gio de desbloqueio.  Caso contr√°rio, no in√≠cio do treinamento, o gerador retornar√° apenas ru√≠do, o discriminador come√ßar√° imediatamente a "vencer" - aprender√° facilmente a distinguir o ru√≠do dos quadros reais e nenhum treinamento funcionar√°. <br><br><img width="800" src="https://habrastorage.org/webt/tx/pb/r-/txpbr-pwdisdcwj62mrd6h4wuxm.png"><br><br>  Depois treinamos a GAN, mas existem algumas nuances.  √â importante para n√≥s que o gerador n√£o apenas crie quadros fotorrealistas, mas tamb√©m armazene as informa√ß√µes dispon√≠veis neles.  Para isso, adicionamos a fun√ß√£o de perda de conte√∫do √† arquitetura GAN cl√°ssica.  Representa v√°rias camadas da rede neural VGG19 treinadas no conjunto de dados ImageNet padr√£o.  Essas camadas transformam a imagem em um mapa de recursos que cont√©m informa√ß√µes sobre o conte√∫do da imagem.  A fun√ß√£o de perda minimiza a dist√¢ncia entre esses cart√µes obtidos dos quadros gerados e originais.  Al√©m disso, a presen√ßa dessa fun√ß√£o de perda permite n√£o estragar o gerador nas primeiras etapas do treinamento, quando o discriminador ainda n√£o est√° treinado e fornece informa√ß√µes in√∫teis. <br><br><img width="800" src="https://habrastorage.org/webt/d7/5p/uu/d75puuaa6jqsy6wmvknjqo-hh84.png"><br><br><h3>  Acelera√ß√£o de rede neural </h3><br>  Tudo correu bem e, ap√≥s uma s√©rie de experimentos, conseguimos um bom modelo que j√° podia ser aplicado a filmes antigos.  No entanto, ainda era muito lento para processar o streaming de v√≠deo.  Aconteceu que √© imposs√≠vel simplesmente reduzir o gerador sem uma perda significativa na qualidade do modelo final.  Ent√£o, a abordagem da destila√ß√£o de conhecimento veio em nosso aux√≠lio.  Esse m√©todo envolve o treinamento de um modelo mais leve, de modo que repita os resultados de um modelo mais pesado.  Pegamos muitos v√≠deos reais em baixa qualidade, processamos com a rede neural generativa obtida na etapa anterior e treinamos a rede mais leve para obter o mesmo resultado dos mesmos quadros.  Devido a essa t√©cnica, obtivemos uma rede que n√£o possui qualidade muito inferior √† original, mas √© dez vezes mais r√°pida: para processar um canal de TV com resolu√ß√£o 576p, √© necess√°ria uma placa NVIDIA Tesla V100. <br><br><img width="800" src="https://habrastorage.org/webt/15/b3/eg/15b3eguc_ikkl-fdaclwdsga2ka.png"><br><br><h3>  Avalia√ß√£o da qualidade das solu√ß√µes </h3><br>  Talvez o momento mais dif√≠cil ao trabalhar com redes generativas seja a avalia√ß√£o da qualidade dos modelos resultantes.  N√£o existe uma fun√ß√£o de erro clara, como, por exemplo, ao resolver o problema de classifica√ß√£o.  Em vez disso, sabemos apenas a precis√£o do discriminador, que n√£o reflete a qualidade do gerador que nos interessa (um leitor que esteja familiarizado com essa √°rea poderia sugerir o uso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">da m√©trica de Wasserstein</a> , mas, infelizmente, deu um resultado notavelmente pior). <br><br>  As pessoas nos ajudaram a resolver esse problema.  Mostramos aos usu√°rios os pares de imagens do servi√ßo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Yandex.Tolok</a> , um dos quais era a fonte e o outro processado por uma rede neural, ou ambos foram processados ‚Äã‚Äãpor diferentes vers√µes de nossas solu√ß√µes.  Por uma taxa, os usu√°rios escolheram um v√≠deo melhor de um par, por isso obtivemos uma compara√ß√£o estatisticamente significativa de vers√µes, mesmo com altera√ß√µes dif√≠ceis de ver com os olhos.  Nossos modelos finais vencem em mais de 70% dos casos, o que √© bastante, j√° que os usu√°rios gastam apenas alguns segundos na classifica√ß√£o de alguns v√≠deos. <br><br>  Um resultado interessante tamb√©m foi o fato de o v√≠deo com resolu√ß√£o 576p, aumentado pela tecnologia DeepHD para 720p, superar o mesmo v√≠deo original com resolu√ß√£o 720p em 60% dos casos - ou seja,  O processamento n√£o apenas aumenta a resolu√ß√£o do v√≠deo, mas tamb√©m melhora sua percep√ß√£o visual. <br><br><h3>  Exemplos </h3><br>  Na primavera, testamos a tecnologia DeepHD em v√°rios filmes antigos que podem ser assistidos no KinoPoisk: ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Rainbow</a> ‚Äù de Mark Donskoy (1943), ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cranes are Flying</a> ‚Äù de Mikhail Kalatozov (1957), ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">My Dear Man</a> ‚Äù de Joseph Kheifits (1958), ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">The Fate of a Man</a> ‚Äù Sergei Bondarchuk (1959), ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ivan Childhood</a> ‚Äù, de Andrei Tarkovsky (1962), ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Father of a Soldier</a> ‚Äù, Rezo Chkheidze (1964) e ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tango of Our Childhood</a> ‚Äù, de Albert Mkrtchyan (1985). <br><br><img width="800" src="https://habrastorage.org/webt/zh/un/-d/zhun-dugkeykn9bmodmrgrjfxma.png"><br><br>  A diferen√ßa entre as vers√µes antes e depois do processamento √© especialmente not√°vel se voc√™ observar os detalhes: estude as express√µes faciais dos her√≥is em close-ups, considere a textura da roupa ou um padr√£o de tecido.  Foi poss√≠vel compensar algumas das defici√™ncias da digitaliza√ß√£o: por exemplo, remover superexposi√ß√µes nas faces ou tornar mais vis√≠veis os objetos colocados na sombra. <br><br>  Mais tarde, a tecnologia DeepHD come√ßou a ser usada para melhorar a qualidade das transmiss√µes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alguns</a> canais no servi√ßo Yandex.Air.  √â f√°cil reconhecer esse conte√∫do pela tag <b>dHD</b> . <br><br>  Agora <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em Yandex</a> na melhoria da qualidade, voc√™ pode ver o "Snow Queen", "Os M√∫sicos de Bremen", "Antelope Ouro" e outro est√∫dio de cinema popular desenho animado "Soyuzmultfilm".  Alguns exemplos de din√¢mica podem ser vistos no v√≠deo: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/ainlhiNn0Yk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Para espectadores exigentes, a diferen√ßa ser√° especialmente not√°vel: a imagem ficou mais n√≠tida, folhas de √°rvores, flocos de neve, estrelas no c√©u noturno sobre a selva e outros pequenos detalhes s√£o mais vis√≠veis. <br><br>  Mais √© mais. <br><br><h3>  Links √∫teis </h3><br>  Jiwon Kim, Jung Kwon Lee, Rede convolucional profundamente recursiva de Kyoung Mu Lee para super-resolu√ß√£o de imagem [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv: 1511.04491</a> ]. <br><br>  Christian Ledig et al.  Super-resolu√ß√£o de imagem √∫nica foto-realista usando uma rede advers√°ria generativa [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv: 1609.04802</a> ]. <br><br>  Mehdi SM Sajjadi, Bernhard Sch√∂lkopf, Michael Hirsch EnhanceNet: Super-resolu√ß√£o de imagem √∫nica atrav√©s da s√≠ntese automatizada de texturas [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arXiv: 1612.07919</a> ]. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt422561/">https://habr.com/ru/post/pt422561/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt422547/index.html">Para eliminar Spectre e Meltdown, voc√™ pode precisar criar um tipo completamente novo de processador</a></li>
<li><a href="../pt422549/index.html">Corda: Kotlin</a></li>
<li><a href="../pt422551/index.html">Como roubar dinheiro de um cart√£o sem contato e do Apple Pay</a></li>
<li><a href="../pt422553/index.html">Mega extens√£o oficial do navegador rouba compartilhamento de arquivos e criptomoeda</a></li>
<li><a href="../pt422555/index.html">Arquitetura multi-m√≥dulo Android. A a Z</a></li>
<li><a href="../pt422565/index.html">Webinars de sexta-feira da Skillbox: tudo para programadores e designers</a></li>
<li><a href="../pt422569/index.html">De hora em hora, aplicativo de rastreamento de tempo</a></li>
<li><a href="../pt422571/index.html">Paralelizando tarefas com depend√™ncias - exemplo .NET</a></li>
<li><a href="../pt422573/index.html">A engenharia reversa da renderiza√ß√£o de The Witcher 3</a></li>
<li><a href="../pt422575/index.html">Intercomunicador raro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
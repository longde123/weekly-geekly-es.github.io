<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì∞ üë©üèæ‚Äçü§ù‚Äçüë©üèΩ üò¶ Classifique grandes quantidades de dados no Apache Spark usando modelos arbitr√°rios de aprendizado de m√°quina üåù üîÇ üê∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parte 1: Declara√ß√£o do Problema 
 Ol√° Habr! Sou arquiteto de solu√ß√µes na CleverDATA. Hoje vou falar sobre como classificamos grandes quantidades de da...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Classifique grandes quantidades de dados no Apache Spark usando modelos arbitr√°rios de aprendizado de m√°quina</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/413137/"><h2>  Parte 1: Declara√ß√£o do Problema </h2><br>  Ol√° Habr!  Sou arquiteto de solu√ß√µes na CleverDATA.  Hoje vou falar sobre como classificamos grandes quantidades de dados usando modelos criados usando quase qualquer biblioteca de aprendizado de m√°quina dispon√≠vel.  Nesta s√©rie de duas partes, consideraremos as seguintes perguntas. <br><br><ul><li>  Como apresentar um modelo de aprendizado de m√°quina como servi√ßo (Modelo como Servi√ßo)? </li><li>  Como as tarefas de processamento distribu√≠do de grandes quantidades de dados s√£o realizadas fisicamente usando o Apache Spark? </li><li>  Quais problemas surgem quando o Apache Spark interage com servi√ßos externos? </li><li>  Como a intera√ß√£o do Apache Spark com servi√ßos externos pode ser organizada usando as bibliotecas akka-streams e akka-http, bem como a abordagem do Reactive Streams? </li></ul><br>  Inicialmente, planejei escrever um artigo, mas como o volume de material era bastante grande, decidi dividi-lo em duas partes.  Hoje, na primeira parte, consideraremos a declara√ß√£o geral do problema, bem como os principais problemas que precisam ser resolvidos durante a implementa√ß√£o.  Na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">segunda parte,</a> falaremos sobre a implementa√ß√£o pr√°tica da solu√ß√£o para esse problema usando a abordagem de Fluxos Reativos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div><a name="habracut"></a><br>  Nossa empresa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CleverDATA</a> possui uma equipe de analistas de dados que, com a ajuda de uma ampla gama de ferramentas (como scikit-learn, facebook fastText, xgboost, tensorFlow, etc.), treinam modelos de aprendizado de m√°quina.  A linguagem de programa√ß√£o b√°sica de fato usada pelos analistas √© o Python.  Quase todas as bibliotecas para aprendizado de m√°quina, mesmo implementadas originalmente em outras linguagens, t√™m uma interface Python e s√£o integradas √†s principais bibliotecas Python (principalmente com o NumPy). <br><br>  Por outro lado, o ecossistema Hadoop √© amplamente usado para armazenar e processar grandes quantidades de dados n√£o estruturados.  Nele, os dados s√£o armazenados no sistema de arquivos HDFS na forma de blocos replicados distribu√≠dos de um determinado tamanho (geralmente 128 MB, mas √© poss√≠vel configurar).  Os algoritmos de processamento de dados distribu√≠dos mais eficientes tentam minimizar a intera√ß√£o da rede entre as m√°quinas de cluster.  Para fazer isso, os dados devem ser processados ‚Äã‚Äãnas mesmas m√°quinas em que est√£o armazenados. <br><br>  Obviamente, em muitos casos, a intera√ß√£o da rede n√£o pode ser completamente evitada, mas, no entanto, voc√™ precisa tentar executar todas as tarefas localmente e minimizar a quantidade de dados que precisar√£o ser transmitidos pela rede. <br><br>  Esse princ√≠pio de processamento de dados distribu√≠dos √© chamado de "mover c√°lculos perto dos dados".  Todas as principais estruturas, principalmente o Hadoop MapReduce e o Apache Spark, aderem a esse princ√≠pio.  Eles determinam a composi√ß√£o e a sequ√™ncia de opera√ß√µes espec√≠ficas que precisam ser executadas em m√°quinas nas quais os blocos de dados necess√°rios est√£o armazenados. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qs/os/nw/qsosnwsibgwo5ajbmzg-v4la7m0.png"></div>  <i>Figura 1. O cluster HDFS consiste em v√°rias m√°quinas, uma das quais √© um n√≥ de nome e o restante √© um n√≥ de dados.</i>  <i>O N√≥ de nome armazena informa√ß√µes sobre os arquivos que comp√µem seus blocos e sobre as m√°quinas nas quais eles est√£o localizados fisicamente.</i>  <i>Os pr√≥prios blocos s√£o armazenados no N√≥ de Dados, que s√£o replicados para v√°rias m√°quinas para aumentar a confiabilidade.</i>  <i>O N√≥ de Dados tamb√©m executa tarefas de processamento de dados.</i>  <i>As tarefas consistem no processo principal (Mestre, M), que coordena o lan√ßamento dos processos de trabalho (Trabalhador, W) nas m√°quinas em que os blocos de dados necess√°rios est√£o armazenados.</i> <br><br>  Quase todos os componentes do ecossistema Hadoop s√£o lan√ßados usando a Java Virtual Machine (JVM) e est√£o intimamente integrados entre si.  Por exemplo, para executar tarefas gravadas usando o Apache Spark para trabalhar com dados armazenados no HDFS, quase nenhuma manipula√ß√£o adicional √© necess√°ria: a estrutura fornece essa funcionalidade imediatamente. <br><br>  Infelizmente, a maior parte das bibliotecas projetadas para aprendizado de m√°quina pressup√µe que os dados s√£o armazenados e processados ‚Äã‚Äãlocalmente.  Ao mesmo tempo, existem bibliotecas totalmente integradas ao ecossistema Hadoop, por exemplo, Spark ML ou Apache Mahout.  No entanto, eles t√™m uma s√©rie de desvantagens significativas.  Primeiro, eles fornecem muito menos implementa√ß√µes de algoritmos de aprendizado de m√°quina.  Em segundo lugar, nem todos os analistas de dados podem trabalhar com eles.  As vantagens dessas bibliotecas incluem o fato de poderem ser usadas para treinar modelos em grandes volumes de dados usando computa√ß√£o distribu√≠da. <br><br>  No entanto, os analistas de dados costumam usar m√©todos alternativos para treinar modelos, em particular bibliotecas que permitem o uso de GPUs.  N√£o vou considerar os problemas dos modelos de treinamento neste artigo, porque quero focar no uso de modelos prontos criados usando qualquer biblioteca de aprendizado de m√°quina dispon√≠vel para classificar grandes quantidades de dados. <br><br>  Portanto, a principal tarefa que estamos tentando resolver aqui √© aplicar modelos de aprendizado de m√°quina a grandes quantidades de dados armazenados no HDFS.  Se pud√©ssemos usar o m√≥dulo SparkML da biblioteca Apache Spark, que implementa os algoritmos b√°sicos de aprendizado de m√°quina, classificar grandes quantidades de dados seria uma tarefa trivial: <br><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> model: <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span> = <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span>.load(<span class="hljs-string"><span class="hljs-string">"/path/to/model"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> dataset = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result = model.transform(dataset)</code> </pre> <br>  Infelizmente, essa abordagem funciona apenas para algoritmos implementados no m√≥dulo SparkML (uma lista completa pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ).  Al√©m disso, no caso de usar outras bibliotecas implementadas n√£o na JVM, tudo se torna muito mais complicado. <br><br>  Para resolver esse problema, decidimos agrupar o modelo em um servi√ßo REST.  Portanto, ao iniciar a tarefa de classificar os dados armazenados no HDFS, √© necess√°rio organizar a intera√ß√£o entre as m√°quinas nas quais os dados est√£o armazenados e a m√°quina (ou cluster de m√°quinas) em que o servi√ßo de classifica√ß√£o est√° sendo executado. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div>  <i>Figura 2. O conceito de modelo como servi√ßo</i> <br><br><h3>  Descri√ß√£o do servi√ßo de classifica√ß√£o Python </h3><br>  Para apresentar o modelo como um servi√ßo, √© necess√°rio resolver as seguintes tarefas: <br><br><ol><li>  implementar acesso eficiente ao modelo via HTTP; </li><li>  garantir o uso mais eficiente dos recursos da m√°quina (principalmente todos os n√∫cleos e mem√≥ria do processador); </li><li>  fornecer resist√™ncia a altas cargas; </li><li>  fornecer a capacidade de dimensionar horizontalmente. </li></ol><br>  O acesso ao modelo via HTTP √© bastante simples de implementar: um grande n√∫mero de bibliotecas foi desenvolvido para Python que permite implementar um ponto de acesso REST usando uma pequena quantidade de c√≥digo.  Um desses microframes √© o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Flask</a> .  A implementa√ß√£o do servi√ßo de classifica√ß√£o no Flask √© a seguinte: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> flask <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flask, request, Response model = load_model() n_features = <span class="hljs-number"><span class="hljs-number">100</span></span> app = Flask(__name__) @app.route(<span class="hljs-string"><span class="hljs-string">"/score"</span></span>, methods=[<span class="hljs-string"><span class="hljs-string">'PUT'</span></span>]) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inp = np.frombuffer(request.data, dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>).reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, n_features) result = model.predict(inp) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Response(result.tobytes(), mimetype=<span class="hljs-string"><span class="hljs-string">'application/octet-stream'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: app.run()</code> </pre> <br>  Aqui, quando o servi√ßo √© iniciado, carregamos o modelo na mem√≥ria e o usamos quando chamamos o m√©todo de classifica√ß√£o.  A fun√ß√£o load_model carrega o modelo de alguma fonte externa, seja no sistema de arquivos, no armazenamento de valores-chave, etc. <br><br>  Um modelo √© um objeto que possui um m√©todo de previs√£o.  No caso de classifica√ß√£o, ele recebe uma entrada para algum vetor de recurso de um determinado tamanho e produz um valor booleano indicando se o vetor especificado √© adequado para este modelo ou algum valor de 0 a 1, ao qual voc√™ pode aplicar o limite de corte: tudo acima do limite, √© um resultado positivo da classifica√ß√£o, o resto n√£o √©. <br><br>  O vetor de recurso que precisamos classificar √© passado em forma bin√°ria e desserializado em uma matriz numpy.  Seria sobrecarregado fazer uma solicita√ß√£o HTTP para cada vetor.  Por exemplo, no caso de um vetor 100-dimensional e usando valores do tipo float32, uma solicita√ß√£o HTTP completa, incluindo cabe√ßalhos, seria algo como isto: <br><br><pre> <code class="hljs powershell">PUT /score HTTP/<span class="hljs-number"><span class="hljs-number">1.1</span></span> Host: score<span class="hljs-literal"><span class="hljs-literal">-node</span></span><span class="hljs-literal"><span class="hljs-literal">-1</span></span>:<span class="hljs-number"><span class="hljs-number">8099</span></span> User<span class="hljs-literal"><span class="hljs-literal">-Agent</span></span>: curl/<span class="hljs-number"><span class="hljs-number">7.58</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span> Accept: */* Content<span class="hljs-literal"><span class="hljs-literal">-Type</span></span>: application/binary Content<span class="hljs-literal"><span class="hljs-literal">-Length</span></span>: <span class="hljs-number"><span class="hljs-number">400</span></span> [<span class="hljs-number"><span class="hljs-number">400</span></span> <span class="hljs-built_in"><span class="hljs-built_in">byte</span></span><span class="hljs-type"><span class="hljs-type">s</span></span> <span class="hljs-type"><span class="hljs-type">of</span></span> <span class="hljs-type"><span class="hljs-type">data</span></span>]</code> </pre> <br>  Como voc√™ pode ver, a efici√™ncia dessa solicita√ß√£o √© muito baixa (400 bytes de carga √∫til / (cabe√ßalho de 133 bytes + corpo de 400 bytes) = 75%).  Felizmente, em quase todas as bibliotecas, o m√©todo de previs√£o permite que voc√™ receba n√£o o vetor [1 xn], mas a matriz [mxn] e, consequentemente, produza o resultado imediatamente para m valores de entrada. <br><br>  Al√©m disso, a biblioteca numpy √© otimizada para trabalhar com matrizes grandes, permitindo que voc√™ use efetivamente todos os recursos dispon√≠veis da m√°quina.  Assim, podemos enviar n√£o um, mas um n√∫mero bastante grande de vetores de recurso em uma solicita√ß√£o, desserializ√°-los em uma matriz numpy de tamanho [mxn], classificar e retornar o vetor [mx 1] a partir dos valores booleanos ou float32.  Como resultado, a efici√™ncia da intera√ß√£o HTTP ao usar uma matriz de 1000 linhas se torna quase igual a 100%.  O tamanho dos cabe√ßalhos HTTP nesse caso pode ser negligenciado. <br><br>  Para testar o servi√ßo Flask na m√°quina local, voc√™ pode execut√°-lo na linha de comando.  No entanto, esse m√©todo √© completamente inadequado para uso industrial.  O fato √© que o Flask √© de thread √∫nico e, se observarmos o diagrama de carga do processador enquanto o servi√ßo estiver em execu√ß√£o, veremos que um n√∫cleo est√° 100% carregado e o restante est√° inativo.  Felizmente, existem maneiras de usar todos os kernels da m√°quina: para isso, o Flask precisa ser executado no servidor de aplicativos da web uwsgi.  Ele permite que voc√™ configure da melhor maneira o n√∫mero de processos e threads, para garantir uma carga uniforme em todos os n√∫cleos do processador.  Mais detalhes sobre todas as op√ß√µes para configurar o uwsgi podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  √â melhor usar o nginx como um ponto de entrada HTTP, pois o uwsgi pode funcionar de maneira inst√°vel em caso de altas cargas.  O Nginx, por outro lado, leva todo o fluxo de entrada de solicita√ß√µes para si mesmo, filtra solicita√ß√µes inv√°lidas e dosa a carga no uwsgi.  O Nginx se comunica com o uwsgi por soquetes do linux usando um arquivo de processo.  Um exemplo de configura√ß√£o do nginx √© mostrado abaixo: <br><br><pre> <code class="nginx hljs"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> uwsgi_params; <span class="hljs-attribute"><span class="hljs-attribute">uwsgi_pass</span></span> unix:/tmp/score.sock; } }</code> </pre><br>  Como podemos ver, acabou sendo uma configura√ß√£o bastante complicada para uma m√°quina.  Se precisarmos classificar grandes quantidades de dados, um grande n√∫mero de solicita√ß√µes chegar√° a esse servi√ßo e isso poder√° se tornar um gargalo.  A solu√ß√£o para esse problema √© a escala horizontal. <br><br>  Por conveni√™ncia, empacotamos o servi√ßo em um cont√™iner do Docker e o implantamos no n√∫mero necess√°rio de m√°quinas.  Se desejar, voc√™ pode usar ferramentas de implanta√ß√£o automatizada, como o Kubernetes.  Um exemplo de estrutura do Dockerfile para criar um cont√™iner com um servi√ßo √© fornecido abaixo. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ubuntu #Installing required ubuntu <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> python modules RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y install python3 python3-pip nginx RUN <span class="hljs-keyword"><span class="hljs-keyword">update</span></span>-alternatives <span class="hljs-comment"><span class="hljs-comment">--install /usr/bin/python python /usr/bin/python3 1 RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1 RUN pip install uwsgi flask scipy scikit-learn #copying script files WORKDIR /etc/score COPY score.py . COPY score.ini . COPY start.sh . RUN chmod +x start.sh RUN rm /etc/nginx/sites-enabled/default COPY score.nginx /etc/nginx/sites-enabled/ EXPOSE 80 ENTRYPOINT ["./start.sh"]</span></span></code> </pre> <br>  Portanto, a estrutura do servi√ßo para classifica√ß√£o √© a seguinte: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fz/4b/c7/fz4bc7kha2wb_dbhck4gifa52ho.png"></div>  <i>Figura 3. Esquema de servi√ßo para classifica√ß√£o</i> <br><br><h3>  Um breve resumo do trabalho do Apache Spark no ecossistema Hadoop </h3><br>  Agora considere o processo de processamento de dados armazenados no HDFS.  Como observei anteriormente, o princ√≠pio de transferir c√°lculos para dados √© usado para isso.  Para iniciar o processamento de tarefas, voc√™ precisa saber em quais m√°quinas os blocos de dados que precisamos est√£o armazenados para executar processos diretamente envolvidos no processamento deles.  Tamb√©m √© necess√°rio coordenar o lan√ßamento desses processos, reinici√°-los em caso de emerg√™ncia, se necess√°rio, agregar os resultados de v√°rias subtarefas, etc. <br><br>  Todas essas tarefas s√£o realizadas por uma variedade de estruturas que trabalham com o ecossistema Hadoop.  Um dos mais populares e convenientes √© o Apache Spark.  O principal conceito em torno do qual toda a estrutura √© criada √© RDD (Conjunto de dados distribu√≠dos resilientes).  Em geral, o RDD pode ser considerado uma cole√ß√£o distribu√≠da resistente a quedas.  O RDD pode ser obtido de duas maneiras principais: <br><br><ol><li>  cria√ß√£o de uma fonte externa, como uma cole√ß√£o na mem√≥ria, um arquivo ou diret√≥rio no sistema de arquivos, etc; </li><li>  convers√£o de outro RDD aplicando opera√ß√µes de transforma√ß√£o.  O RDD suporta todas as opera√ß√µes b√°sicas de trabalho com cole√ß√µes, como map, flatMap, filter, groupBy, join, etc. </li></ol><br>  √â importante entender que o RDD, diferentemente das cole√ß√µes, n√£o √© diretamente dados, mas uma sequ√™ncia de opera√ß√µes que devem ser executadas nos dados.  Portanto, quando as opera√ß√µes de transforma√ß√£o s√£o chamadas, nenhum trabalho realmente acontece e apenas obtemos um novo RDD, que conter√° mais uma opera√ß√£o do que a anterior.  O trabalho em si come√ßa quando as chamadas opera√ß√µes ou a√ß√µes do terminal s√£o chamadas.  Isso inclui salvar em um arquivo, salvar em uma cole√ß√£o na mem√≥ria, contar o n√∫mero de elementos etc. <br><br>  Ao iniciar uma opera√ß√£o do terminal, o Spark cria um gr√°fico de opera√ß√£o ac√≠clica (DAG, Directed Acyclic Graph) com base no RDD resultante e os executa sequencialmente no cluster de acordo com o gr√°fico recebido.  Ao criar um DAG baseado em RDD, o Spark realiza v√°rias otimiza√ß√µes, por exemplo, se poss√≠vel, combina v√°rias transforma√ß√µes sucessivas em uma opera√ß√£o. <br><br>  RDD foi a principal unidade de intera√ß√£o com a API Spark nas vers√µes do Spark 1.x.  No Spark 2.x, os desenvolvedores disseram que agora o principal conceito de intera√ß√£o √© o Dataset.  O conjunto de dados √© um complemento para RDD com suporte para intera√ß√£o semelhante a SQL.  Ao usar a API do conjunto de dados, o Spark permite que voc√™ use uma ampla gama de otimiza√ß√µes, incluindo as de n√≠vel bastante baixo.  Mas, em geral, os princ√≠pios b√°sicos que se aplicam aos RDDs tamb√©m se aplicam ao Dataset. <br><br>  Mais detalhes sobre o trabalho do Spark podem ser encontrados na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o no site oficial</a> . <br><br>  Vamos considerar um exemplo da classifica√ß√£o mais simples no Spark sem usar servi√ßos externos.  Um algoritmo sem sentido √© implementado aqui, que considera a propor√ß√£o de cada uma das letras latinas no texto e, em seguida, considera o desvio padr√£o.  Aqui, antes de tudo, √© importante prestar aten√ß√£o diretamente √†s etapas b√°sicas usadas ao trabalhar com o Spark. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">//</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">1</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-comment"><span class="hljs-comment">//(2) val ds: Dataset[Data] = spark.read.parquet("/path/to/data").as[Data] //(3) val result: Dataset[Score] = ds.map {d: Data =&gt; //(4) val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) }.map {f: Features =&gt; Score(f.id, std(f.vector)) //(5) } result.write.parquet("/path/to/result") //(6)</span></span></code> </pre><br>  Neste exemplo, n√≥s: <br><br><ol><li>  determinamos a estrutura dos dados de entrada, intermedi√°rios e de sa√≠da (os dados de entrada s√£o definidos como algum texto ao qual um determinado identificador est√° associado, os dados intermedi√°rios correspondem ao identificador com o vetor de caracter√≠stica e a sa√≠da corresponde ao identificador com algum valor num√©rico); </li><li>  definimos uma fun√ß√£o para calcular o valor resultante por um vetor de caracter√≠stica (por exemplo, desvio padr√£o, implementa√ß√£o n√£o mostrada); </li><li>  definir o conjunto de dados original como dados armazenados no HDFS no formato parquet ao longo do caminho / caminho / para / dados; </li><li>  Defina um conjunto de dados intermedi√°rio como um mapa de bitmap do conjunto de dados original. </li><li>  Da mesma forma, determinamos o conjunto de dados resultante por meio de uma transforma√ß√£o bit a bit do intermedi√°rio; </li><li>  salve o conjunto de dados resultante no HDFS no formato parquet ao longo do caminho / caminho / para / resultado.  Como salvar em um arquivo √© uma opera√ß√£o do terminal, os pr√≥prios c√°lculos s√£o iniciados precisamente nesse est√°gio. </li></ol><br>  O Apache Spark trabalha com o princ√≠pio de mestre-trabalhador.  Quando o aplicativo √© iniciado, o processo principal, chamado de driver, √© iniciado.  Ele executa o c√≥digo respons√°vel pela forma√ß√£o do RDD, com base no qual os c√°lculos ser√£o realizados. <br><br>  Quando uma opera√ß√£o do terminal √© chamada, o driver gera um DAG com base no RDD resultante.  Em seguida, o driver inicia o lan√ßamento de fluxos de trabalho chamados executores, nos quais os dados ser√£o processados ‚Äã‚Äãdiretamente.  Ap√≥s iniciar os fluxos de trabalho, o driver transmite a eles o bloco execut√°vel que precisa ser executado e tamb√©m indica a qual parte dos dados precisa ser aplicada. <br><br>  Abaixo est√° o c√≥digo do nosso exemplo, no qual as se√ß√µes de c√≥digo executadas no executor (entre as linhas iniciador e final do executor) s√£o destacadas.  O restante do c√≥digo √© executado no driver. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> ds: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Data</span></span>] = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>).as[<span class="hljs-type"><span class="hljs-type">Data</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Score</span></span>] = ds.map { <span class="hljs-comment"><span class="hljs-comment">// --------------- EXECUTOR PART BEGIN ----------------------- d: Data =&gt; val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) // --------------- EXECUTOR PART END ----------------------- }.map { // --------------- EXECUTOR PART BEGIN ----------------------- f: Features =&gt; Score(f.id, std(f.vector)) // --------------- EXECUTOR PART END ----------------------- } result.write.parquet(‚Äú/path/to/result‚Äù)</span></span></code> </pre><br>  No ecossistema Hadoop, todos os aplicativos s√£o executados em cont√™ineres.  Um cont√™iner √© um processo em execu√ß√£o em uma das m√°quinas em um cluster ao qual √© alocada uma certa quantidade de recursos.  O lan√ßamento dos cont√™ineres √© tratado pelo YARN Resource Manager.  Ele determina qual das m√°quinas possui um n√∫mero suficiente de n√∫cleos de processador e RAM, bem como se cont√©m os blocos de dados necess√°rios para o processamento. <br><br>  Ao iniciar o aplicativo Spark, o YARN cria e executa o cont√™iner em uma das m√°quinas de cluster nas quais inicia o driver.  Ent√£o, quando o driver prepara o DAG a partir de opera√ß√µes que precisam ser executadas nos executores, o YARN lan√ßa cont√™ineres adicionais nas m√°quinas desejadas. <br><br>  Como regra, basta que o driver aloque um n√∫cleo e uma pequena quantidade de mem√≥ria (a menos que, √© claro, o resultado do c√°lculo n√£o seja agregado no driver na mem√≥ria).  Para os executores, para otimizar recursos e reduzir o n√∫mero total de processos no sistema, mais de um n√∫cleo pode ser distinguido: nesse caso, o executor poder√° executar v√°rias tarefas simultaneamente. <br><br>  Mas aqui √© importante entender que, no caso de uma falha de uma das tarefas em execu√ß√£o no cont√™iner ou no caso de recursos insuficientes, o YARN pode decidir parar o cont√™iner e, em seguida, todas as tarefas executadas nele ter√£o que ser reiniciadas novamente em outro artista.  Al√©m disso, se alocarmos um n√∫mero suficientemente grande de n√∫cleos por cont√™iner, √© prov√°vel que o YARN n√£o consiga inici√°-lo.  Por exemplo, se tivermos duas m√°quinas nas quais dois n√∫cleos s√£o deixados sem uso, podemos iniciar em cada cont√™iner que requer dois n√∫cleos, mas n√£o podemos iniciar um cont√™iner que requer quatro n√∫cleos. <br><br>  Agora vamos ver como o c√≥digo do nosso exemplo ser√° executado diretamente no cluster.  Imagine que o tamanho dos dados de origem seja 2 Terabytes.  Portanto, se o tamanho do bloco no HDFS for de 128 megabytes, haver√° 16384 blocos no total.  Cada bloco √© replicado para v√°rias m√°quinas para garantir a confiabilidade.  Para simplificar, consideramos o fator de replica√ß√£o igual a dois, ou seja, haver√° 32768 blocos dispon√≠veis no total.  Suponha que usemos um cluster de 16 m√°quinas para armazenamento.  Consequentemente, em cada uma das m√°quinas, no caso de distribui√ß√£o uniforme, haver√° aproximadamente 2048 blocos, ou 256 Gigabytes por m√°quina.  Em cada uma das m√°quinas, temos 8 n√∫cleos de processador e 64 gigabytes de RAM. <br><br>  Para nossa tarefa, o driver n√£o precisa de muitos recursos, portanto, alocaremos 1 n√∫cleo e 1 GB de mem√≥ria para ele.  Daremos aos artistas 2 n√∫cleos e 4 GB de mem√≥ria.  Suponha que desejamos maximizar o uso de recursos de cluster.  Assim, temos 64 cont√™ineres: um para o motorista e 63 para os artistas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uw/qu/rc/uwqurc3i8v7wagn1zfexu-3dfgo.png"></div>  <i>Figura 4. Processos em execu√ß√£o no n√≥ de dados e os recursos que eles usam.</i> <br><br>  Como no nosso caso, usamos apenas opera√ß√µes de mapa, nosso DAG consistir√° em uma opera√ß√£o.  Consiste nas seguintes a√ß√µes: <br><br><ol><li>  pegue um bloco de dados do disco r√≠gido local, </li><li>  Converter dados </li><li>  salve o resultado em um novo bloco no seu pr√≥prio disco local. </li></ol><br>  No total, precisamos processar 16384 blocos, para que cada executor execute 16384 / (63 executores * 2 n√∫cleos) = 130 opera√ß√µes.  Assim, o ciclo de vida do executor como um processo separado (no caso de tudo acontecer sem quedas) ter√° a seguinte apar√™ncia. <br><br><ol><li>  Lan√ßamento de cont√™iner. </li><li>  Receber do motorista uma tarefa na qual haver√° um identificador de bloco e a opera√ß√£o necess√°ria.  Como alocamos dois n√∫cleos para o cont√™iner, o executor recebe duas tarefas ao mesmo tempo. </li><li>  Executando uma tarefa e enviando o resultado ao motorista. </li><li>  Obtendo a pr√≥xima tarefa do driver e repetindo as etapas 2 e 3 at√© que todos os blocos desta m√°quina local sejam processados. </li><li>  Parada de cont√™iner </li></ol><br>  <i>Nota</i> : DAGs mais complexos s√£o obtidos se for necess√°rio redistribuir dados intermedi√°rios entre m√°quinas, geralmente para opera√ß√µes de agrupamento (groupBy, reduzemByKey etc.) e conex√µes (jun√ß√£o), cuja considera√ß√£o est√° al√©m do escopo deste artigo. <br><br><h3>  Os principais problemas de intera√ß√£o entre o Apache Spark e servi√ßos externos </h3><br>  Se, dentro da estrutura da opera√ß√£o do mapa, precisarmos acessar algum servi√ßo externo, a tarefa se tornar√° menos trivial.  Suponha que um objeto da classe ExternalServiceClient seja respons√°vel por interagir com um servi√ßo externo.  Em geral, antes de iniciar o trabalho, precisamos inicializ√°-lo e cham√°-lo conforme necess√°rio: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-comment"><span class="hljs-comment">// val score = client.score(featureVector) // .</span></span></code> </pre><br>  Geralmente, a inicializa√ß√£o do cliente leva algum tempo; portanto, como regra, √© inicializada na inicializa√ß√£o do aplicativo e, em seguida, √© usada para obter uma inst√¢ncia do cliente de algum contexto ou pool global.  Portanto, quando um cont√™iner com o executor Spark recebe uma tarefa que requer intera√ß√£o com um servi√ßo externo, seria bom obter um cliente j√° inicializado antes de iniciar o trabalho na matriz de dados e reutiliz√°-lo para cada elemento. <br><br>  Existem duas maneiras de fazer isso no Spark.  Primeiro, se o cliente √© serializ√°vel (o pr√≥prio cliente e todos os seus campos devem estender a interface java.io.Serializable), ele pode ser inicializado no driver e depois <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">passado aos executores pelo mecanismo de vari√°vel de transmiss√£o</a> . <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> clientBroadcast = sparkContext.broadcast(client) ds.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = clientBroadcast.value.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) }</code> </pre><br>  Caso o cliente n√£o seja serializ√°vel ou a inicializa√ß√£o do cliente seja um processo que depende das configura√ß√µes da m√°quina espec√≠fica na qual est√° sendo executado (por exemplo, para equilibrar, solicita√ß√µes de uma parte das m√°quinas devem ir para a primeira m√°quina de servi√ßo e, para a outra, para a segunda), ent√£o o cliente pode ser inicializado diretamente no executor. <br><br>  Para fazer isso, o RDD (e o conjunto de dados) possui uma opera√ß√£o mapPartitions, que √© uma vers√£o generalizada da opera√ß√£o de mapa (se voc√™ observar o c√≥digo-fonte da classe RDD, a opera√ß√£o de mapa ser√° implementada por meio de mapPartitions).  A fun√ß√£o passada para a opera√ß√£o mapPartitions √© executada uma vez para cada bloco.        ,      ,          ,   : <br><br><pre> <code class="scala hljs">ds.mapPartitions {fi: <span class="hljs-type"><span class="hljs-type">Iterator</span></span>[<span class="hljs-type"><span class="hljs-type">Features</span></span>] =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() fi.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = client.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) } }</code> </pre><br>             . , , ,         ,         .     ,    ,               ,    . <br><br>      . ,             hasNext  next: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (i.hasNext()) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> item = i.next() ‚Ä¶ }</code> </pre><br>        ,         ,    . ,       8 ,  YARN       4    2 , ,     8   .       ,               .         . <br><br>          .       ,         , ,    ,   .        :    ,    ,       .   ,     hasNext       ,      .    (,          ,       )     ,   ,    ,    . , <i>    </i> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4_/hn/vl/4_hnvluet1tc0lvq68urw9ij5fi.png" width="550"></div> <i> 5.   ,     ,   mapPartitions,    .        .</i> <br><br>   ,       ,       . ,         ,    ,       . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0e/dm/yy/0edmyyfjkekpdp5f0ncx84tevei.png" width="450"></div> <i> 6.          </i> <br><br>   ,       ,  , -,        ,      , , -,      ,     . <br><br><h3>    </h3><br>  ,          .  ,            .               ,           .          ,     . ,      ,     ,  ,    , ,    . <br><br>         . <br><br><ol><li>  ,       ,       ,          . </li><li>  ,            ,    .          ,     .                         ,      . </li><li>  ,      hasNext  false,    ,       ,    ,       .      :         hasNext = false, , ,    .    ,       ,     ,           . </li></ol><br>  ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> . Stay tuned! <br><br><div class="spoiler"> <b class="spoiler_title">     ,  ,    ?</b> <div class="spoiler_text"><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desenvolvedor Java</font></font></a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Engenheiro de Sistemas</font></font></a> </li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt413137/">https://habr.com/ru/post/pt413137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt413125/index.html">A terapia g√™nica oferece aos pacientes pequenos com atrofia muscular a chance de sobreviver</a></li>
<li><a href="../pt413127/index.html">Algumas palavras sobre o desempenho real do hypervisor</a></li>
<li><a href="../pt413129/index.html">25 erros de um programador iniciante</a></li>
<li><a href="../pt413133/index.html">Antipadr√µes populares: pagina√ß√£o</a></li>
<li><a href="../pt413135/index.html">Designa√ß√£o de teste de revis√£o de c√≥digo de desenvolvedores junior react</a></li>
<li><a href="../pt413139/index.html">Carros el√©tricos: a revolu√ß√£o est√° chegando</a></li>
<li><a href="../pt413141/index.html">Classifique grandes quantidades de dados no Apache Spark usando modelos arbitr√°rios de aprendizado de m√°quina</a></li>
<li><a href="../pt413143/index.html">Bobby Urban Lite: A nova mochila urbana da XD Design</a></li>
<li><a href="../pt413145/index.html">Analista ajuda empresas a ganhar dinheiro</a></li>
<li><a href="../pt413147/index.html">√â poss√≠vel usar o Tibero em vez do Oracle. E √© necess√°rio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
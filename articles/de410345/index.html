<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùï üßíüèæ üí¥ Bildgebung ohne Objektive ‚úçÔ∏è üßóüèª üóÉÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neue Bildgebungssysteme, Mikroskope und Videomatrizen erzeugen digitale Bilder, die auf Computerberechnungen und nicht auf herk√∂mmlichen Objektiven ba...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bildgebung ohne Objektive</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/410345/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ps/f1/nc/psf1nchncjmksidiukigqmau_wq.jpeg"></div><br><p>  <em>Neue Bildgebungssysteme, Mikroskope und Videomatrizen erzeugen digitale Bilder, die auf Computerberechnungen und nicht auf herk√∂mmlichen Objektiven basieren.</em> </p><br><p>  Sogar mittelalterliche Handwerker konnten Glaslinsen und gebogene Spiegel f√ºr die Projektion von Bildern herstellen.  Solche Konstruktionen wurden verwendet, um Mikroskope, Lochkameras, Teleskope und andere Instrumente herzustellen, mit denen wir sehr kleine und gro√üe Objekte weit und nahe, auf der Erde und am Himmel besser sehen k√∂nnen.  Die n√§chste Revolution in der Bilderzeugung fand um die Mitte des 19. Jahrhunderts statt: Die Fotografie wurde erfunden.  Jetzt k√∂nnen Sie ‚Äûangehaltene Momente‚Äú erfassen, abspielen und replizieren.  Heute steht die √Ñra der chemischen Fotografie kurz vor dem Abschluss, eine neue √Ñra bl√ºht - die digitale Bildgebung.  Seine Wurzeln liegen in der Fernsehtechnologie, aber wir werden den Beginn der √Ñra 1975 betrachten, als die erste Digitalkamera erschien.  Heutzutage erfassen Milliarden von Webcams und Kameras in Mobiltelefonen weltweit mehr als eine Billion Bilder pro Jahr, und viele von ihnen werden sofort ins Internet hochgeladen.  Trotz der explosionsartigen Zunahme von Anzahl, Vielfalt und Verwendungsm√∂glichkeiten von Bildgebungssystemen bleiben die Aufgaben der Optiker weitgehend unver√§ndert: ein qualitativ hochwertiges optisches Bild zu erstellen, das die Szene genau wiedergibt, damit sie ‚Äûgut aussieht‚Äú. </p><a name="habracut"></a><br><p> In den letzten 10 bis 20 Jahren hat sich jedoch ein neues Paradigma herausgebildet: die rechnergest√ºtzte Bildgebung.  Dieses Paradigma ersetzt m√∂glicherweise traditionelle Ans√§tze nicht vollst√§ndig, wird jedoch jahrhundertealte Ideen in Frage stellen und dazu beitragen, alternative Methoden f√ºr den Entwurf von Bildgebungssystemen zu entwickeln.  Beispielsweise stehen uns bereits neue Funktionen und Formen von Bildgebungssystemen zur Verf√ºgung, darunter Super-Miniaturger√§te zum Aufnehmen von makroskopischen Objekten und Mikroskopen ohne Linsen. </p><br><h2 id="vychislitelnoe-formirovanie-izobrazheniya">  Computational Imaging </h2><br><p>  Wie der Name schon sagt, spielt das Rechnen eine Schl√ºsselrolle bei der Bildung des endg√ºltigen digitalen Bildes.  Lange Zeit haben sie sich mit Hilfe der digitalen Bildverarbeitung verbessert: Sie haben den Rote-Augen-Effekt beim Aufnehmen mit dem Blitz entfernt, die Farben angepasst usw., aber die optischen Schaltkreise der Objektive wurden nie unter Ber√ºcksichtigung dieser Anforderungen entworfen.  Die digitale Signalverarbeitung erm√∂glicht es jedoch beispielsweise, optische Verzerrungen wie "Kissen" oder Weitwinkelverzerrungen an den Bildr√§ndern zu korrigieren.  Als das Hubble-Orbital-Teleskop Ende der 1980er Jahre die ersten Bilder zur Erde schickte, waren sie viel ‚Äûseifiger‚Äú als erwartet.  Es wurde schnell klar, dass es einige Probleme mit der Optik gab.  Die Wissenschaftler der NASA stellten fest, was los war, und bis zur Reparatur des Teleskops korrigierten sie viele Jahre lang viele Fehler mithilfe ausgefeilter digitaler Verarbeitungsalgorithmen. </p><br><p><img src="https://habrastorage.org/webt/vs/yj/jk/vsyjjkzxysjrga54pwjtwlz-ixs.jpeg"></p><br><p>  Mitte der neunziger Jahre kamen Wade Thomas Cathey und Edward Dowski Jr. auf die Idee, Linsen zu entwerfen, um verschwommene, ‚Äûverschlechterte‚Äú Bilder zu erzeugen, die jedoch so verschlechtert sind, dass Digitale Verarbeitungsalgorithmen erm√∂glichten es, Bilder mit herk√∂mmlichen Objektiven nicht schlechter oder sogar besser aufzunehmen.  Insbesondere Katie und Dowsky wandten sich dem charakteristischen Merkmal aller herk√∂mmlichen Kameras zu: der begrenzten Sch√§rfentiefe.  Wenn Sie sich auf ein Objekt in durchschnittlicher Entfernung von Ihnen konzentrieren, sieht es scharf aus, aber Objekte, die n√§her und weiter entfernt sind, verschwimmen.  Die Sch√§rfentiefe bezieht sich auf den Bereich, in dem alle Objekte einigerma√üen scharf aussehen.  So entwickelten zwei Wissenschaftler eine neue Linse, die die optischen Bilder von Objekten in allen Entfernungen fast genauso stark verwischte.  Und dann sch√§rfte ein spezieller Algorithmus das gesamte Bild und erzielte eine Sch√§rfentiefe, die f√ºr gew√∂hnliche Objektive nicht erreichbar ist.  Obwohl viele Wissenschaftler die beschriebene Technik weiter verbessert haben, hat die Idee von Katie und Dowsky die Disziplin der rechnergest√ºtzten Erfassung und Bilderzeugung weit vorangetrieben. </p><br><p>  Eine weitere Konsequenz dieser wissenschaftlichen Arbeit war, dass jetzt optische Schaltungen f√ºr Linsen entwickelt werden, die auf der Erstellung von Bildern f√ºr Computer und nicht f√ºr Menschen basieren.  Es ist paradox, dass in unserer √Ñra des Total Shooting nur sehr wenige Menschen echte optische Bilder sahen, die von Kameras erzeugt wurden.  Die Zeiten sind lange vorbei, in denen der Fotograf, der sich zur Kamera beugte und sich mit einem dicken Umhang bedeckte, den Verschluss herauszog und vor dem Einlegen der Kassette mit dem Film auf dem Milchglas ein ‚ÄûLive‚Äú -Bild sah, das direkt vom Objektiv erzeugt wurde.  Heute sehen wir auf den Bildschirmen das Ergebnis der digitalen Verarbeitung von optischen Bildern, die auf Siliziummatrizen gefallen sind. </p><br><p>  Der n√§chste Anwendungsbereich f√ºr die Kombination von Optik und digitaler Verarbeitung war die Vereinfachung des Linsendesigns.  In Ihrem Smartphone kann ein Kameraobjektiv aus 7-8 optischen Elementen bestehen, und professionelle Kameraobjektive bestehen manchmal aus mehr als 15 optischen Elementen.  Eine gro√üe Anzahl von Linsen ist erforderlich, um Bildfehler zu korrigieren - Aberrationen, die jedem optischen System eigen sind: chromatisch (Farbgeister um Objekte) und optisch (Verzerrung der Form und Proportionen von Objekten).  Das hei√üt, komplexe Objektivdesigns sind erforderlich, um ‚Äûgut aussehende‚Äú Bilder zu erzeugen.  Die Kombination aus Optik und digitaler Verarbeitung hilft dabei, einen Teil der Arbeit zur Korrektur von Aberrationen auf eine digitale Komponente zu verlagern, sodass Sie auf einige optische Elemente verzichten k√∂nnen, ohne die Qualit√§t des endg√ºltigen digitalen Bilds zu beeintr√§chtigen.  Das hei√üt, Verarbeitungsalgorithmen spielen die Rolle virtueller optischer Elemente.  Dieser Ansatz erm√∂glichte es, kompaktere und billigere optische Systeme ohne Qualit√§tsverlust zu schaffen. </p><br><p>  Inwieweit werden diese Ideen entwickelt?  Welcher Anteil der Bildgebungsaufgabe kann von der Optik auf eine digitale Komponente √ºbertragen werden?  Wie einfach kann eine optische Schaltung sein, um ein anst√§ndiges Bild zu erhalten?  Ist es realistisch, Linsen und Spiegel loszuwerden?  Dies wurde in den letzten Jahren auf drei Arten erreicht: Die Linsen und die optischen Bilder, die sie erzeugen, sind vollst√§ndig ausgeschlossen.  Die Methoden basieren auf Beugung, optischer Phasenrekonstruktion und der Drucksensortechnik.  Und um das endg√ºltige Bild zu erhalten, das f√ºr Menschen geeignet ist, werden Computerberechnungen aktiv verwendet. </p><br><h2 id="difrakcionnoe-formirovanie-izobrazheniya">  Beugungsbildgebung </h2><br><p>  Herk√∂mmliche Linsen fokussieren einen Lichtstrahl mithilfe der <strong>Brechung</strong> : Licht wird beim Durchgang durch eine Mediengrenze (Luftglas) mit unterschiedlichen Lichtgeschwindigkeiten gebrochen.  Dank des Brechungseffekts scheint ein Bleistift, der mit Wasser in ein Glas getaucht ist, gekr√ºmmt zu sein: Das vom Bleistift reflektierte Licht wird gebrochen, wenn es auf dem Weg zu Ihren Augen in die Luft gelangt.  Daher ist der Unterwasserteil des Bleistifts, den wir sehen, nicht dort, wo er tats√§chlich ist. </p><br><p>  √úbrigens scheinen dank der Brechung (Brechung) an der Grenze zwischen Weltraum und Erdatmosph√§re alle Himmelsobjekte etwas h√∂her zu liegen als ihr tats√§chlicher Standort: </p><br><p><img src="https://habrastorage.org/webt/-s/tv/h-/-stvh-s4zuewp66fixucqba6rho.jpeg"></p><br><p>  Gekr√ºmmte Spiegel, wie sie in gro√üen Teleskopen verwendet werden, erzeugen ein Bild anders: durch <strong>Reflexion</strong> .  Um den Unterschied zwischen Brechung und Reflexion zu verstehen, stellen Sie sich Licht in Form von Strahlen (Linien) vor. </p><br><p><img src="https://habrastorage.org/webt/ar/kh/gw/arkhgwbtit3ubebnlldms7tzoka.jpeg"></p><br><p>  Zwei weitere physikalische Ph√§nomene helfen dabei, die Ausbreitungsrichtung des Lichts zu √§ndern und seine Wellennatur zu nutzen (denken Sie an die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Welle-Teilchen-Dualit√§t</a> ): <strong>Beugung</strong> und <strong>Interferenz</strong> .  Wenn sich zwei koh√§rente Lichtwellen treffen, √ºberlappen sie sich, die resultierende Wellenamplitude erscheint.  Wenn das Maximum einer Welle immer mit dem Maximum der anderen √ºbereinstimmt, verst√§rken sich die Wellen gegenseitig, was als <strong>konstruktive Interferenz bezeichnet wird</strong> .  Wenn das Maximum einer Welle immer mit dem Minimum der anderen √ºbereinstimmt, heben sich die Wellen gegenseitig auf - dies ist eine <strong>destruktive Interferenz</strong> , wodurch das Licht vollst√§ndig verschwinden kann. </p><br><p>  Sie k√∂nnen das Licht durch Beugung steuern, indem Sie es auf einer glatten Oberfl√§che auf das Beugungsgitter richten - eine Reihe feinster Striche (Raster).  Da Wellen unterschiedlicher L√§nge in unterschiedliche Richtungen reflektiert werden, tritt eine Farbf√§rbung auf.  Wenn beispielsweise wei√ües Licht von winzigen Rillen auf der Oberfl√§che einer CD oder DVD reflektiert wird, sehen wir Regenbogenstreifen.  Aufgrund der Abh√§ngigkeit der Wellenl√§ngen vom Raster ist es unm√∂glich, ein Beugungsgitter zu erzeugen, das die Linsen einfach ersetzt.  Ein optisches Bild, das von einem Gitter erzeugt wird, sieht niemals so gut aus wie ein Bild von einer gut gestalteten Linse.  Trotzdem ist es durchaus m√∂glich, akzeptable digitale Bilder mit einer Kombination aus Beugungsoptik (unter Verwendung von Beugung) und angepasster Signalverarbeitung (unter Ber√ºcksichtigung der Optik) zu erstellen. </p><br><h2 id="formirovanie-izobrazheniy-s-pomoschyu-difrakcii">  Beugungsbildgebung </h2><br><p>  In einer der Klassen von nicht objektiven Vorrichtungen f√ºr makroskopische Aufnahmen werden Miniaturbeugungsgitter verwendet, die sich schrittweise in der Dicke eines transparenten Materials (Glas oder Silikat) befinden und einen Teil des einfallenden Lichts relativ zum anderen Teil verz√∂gern.  Die mathematischen Eigenschaften des Stufenschemas sind derart, dass die Lichtverteilung im Material schwach von der Wellenl√§nge und daher von einer geringf√ºgigen Variation der Dicke des Glases selbst abh√§ngt, die unvermeidlich w√§hrend der Herstellung auftritt.  Gitter sind an einem <strong>lichtempfindlichen Sensor angebracht</strong> - wie die Matrix bei herk√∂mmlichen Digitalkameras.  Das einfallende Licht passiert die Gitter und erreicht das Array, das bereits speziell in ‚ÄûKomponenten‚Äú zerlegt wurde.  Es sieht √ºberhaupt nicht wie ein gew√∂hnliches Bild aus: eine Art verschwommene Wolke, die f√ºr das menschliche Auge unverst√§ndlich ist.  Diese Wolke enth√§lt jedoch gen√ºgend visuelle Informationen (wenn auch ungew√∂hnlich verteilt), um das gew√ºnschte Bild mithilfe eines als Bildfaltung bezeichneten Rechenprozesses daraus wiederherzustellen. </p><br><p><img src="https://habrastorage.org/webt/2r/zn/pn/2rznpnqz7mlol3iwmj5yhym9sdg.jpeg"></p><br><p>  Der Bildrekonstruktionsalgorithmus ist leicht empfindlich gegen√ºber visuellem Rauschen, beispielsweise zuf√§lligen Schwankungen der Anzahl der Photonen oder elektrischem Rauschen w√§hrend der Umwandlung des Signals vom Sensor in eine numerische Darstellung (der sogenannte Quantisierungsfehler).  Daher kann das Bild visuell verrauscht sein.  Obwohl diese Qualit√§t f√ºr eine Reihe einfacher Aufgaben ausreicht (z. B. um die Anzahl der Personen in einem Frame zu z√§hlen), m√ºssen Sie f√ºr ein anst√§ndigeres Bild mehr Informationen √ºber die aufgenommene Szene erfassen.  Die L√∂sung "in der Stirn" besteht darin, mehrere Miniatur-Phasengitter zu verwenden, um verschiedene Informationen √ºber die Szene zu erfassen.  Das hei√üt, jedes Gitter bildet ein digitales Komponentenbild, diese Komponenten k√∂nnen dann verarbeitet werden und ein besseres Bild kann erhalten werden. </p><br><p><img src="https://habrastorage.org/webt/m1/gi/4k/m1gi4klv3zgpvalage7le15ox14.jpeg"></p><br><p>  <em>Eine Art von linsenlosem Bildgebungssystem verwendet Arrays, die Licht streuen, anstatt es wie Linsen zu fokussieren.</em>  <em>Im obigen Beispiel ist ein Array von 12 Bin√§rphasen-Mikronetzen (links) entworfen, um so viele visuelle Informationen wie m√∂glich √ºber die Szene zu erfassen.</em>  <em>Nachdem das Licht durch das Array gelangt ist, werden 12 verschwommene Punkte erhalten, von denen keiner eine Person verstehen l√§sst, was hier (in der Mitte) gefilmt wird.</em>  <em>Dieses optische Bild enth√§lt jedoch gen√ºgend Informationen, um mithilfe der digitalen Verarbeitung, die als ‚ÄûBildfaltung‚Äú bezeichnet wird, ein vollst√§ndig lesbares Portr√§t (rechts) zu erhalten.</em> </p><br><p>  Dieser Ansatz hilft nicht nur, ein Bild der Szene zu erstellen, sondern es auch zu analysieren: um die visuellen Eigenschaften (z. B. ob das Foto ein menschliches Gesicht enth√§lt), die Richtung und Geschwindigkeit der Gesamtbewegung der Szene ( <strong>visueller Fluss</strong> , visueller Fluss) zu bestimmen und die Anzahl der Personen zu berechnen drinnen.  In solchen Situationen werden Beugungsgitter entworfen, um die erforderlichen Informationen zu extrahieren, und der Verarbeitungsalgorithmus wird an eine bestimmte Aufgabe angepasst.  Wenn wir beispielsweise einen vertikalen Barcode lesen m√ºssen, verwenden wir ein vertikales Beugungsgitter und einen Algorithmus, der jedes Pixel eines digitalen Bildes auf einen Schwellenwert bringt: Licht wird in dunkel, dunkel in schwarz umgewandelt.  Das Ergebnis ist ein digitales Schwarzwei√übild, das bereits vom Barcode-Lesealgorithmus erkannt werden kann. </p><br><h2 id="mikroskopiya-s-pomoschyu-vosstanovleniya-fazy">  Phasenrekonstruktionsmikroskopie </h2><br><p>  Der Ansatz zur Erzeugung vorgespannter Mikroskope unterscheidet sich von den Methoden zur Erzeugung von Computerkameras f√ºr Makroobjekte, obwohl das Beugungsph√§nomen auch hier verwendet wird.  Im Gegensatz zu einem Ger√§t, das eine Szene bei normaler Beleuchtung durch Sonne oder Lampen aufnimmt, kann jedoch nur koh√§rente Laserstrahlung oder monochromatisches Licht von einer oder mehreren Quellen f√ºr die Beleuchtung in der Mikroskopie ausgew√§hlt werden.  Auf diese Weise k√∂nnen Sie die Beugung und Interferenz von Licht steuern.  Dar√ºber hinaus sind die f√ºr uns interessanten Objekte so klein, dass eine Beugung auftritt, wenn Licht durch die Objekte selbst und nicht durch ein k√ºnstliches Beugungsgitter f√§llt. </p><br><p><img src="https://habrastorage.org/webt/6h/_p/k0/6h_pk0mvc3xilvyab2jabhxpdn8.jpeg"></p><br><p>  Das Schema eines solchen Mikroskops impliziert, dass die Probe auf einer lichtempfindlichen Matrix mit einer gro√üen Anzahl kleiner Pixel platziert wird: beispielsweise einer 10-Megapixel-Matrix, die h√§ufig in Digitalkameras zu finden ist.  Dieses Schema wird auch als "On-Chip-Mikroskop" bezeichnet, da die Probe direkt auf der Bilderzeugungsmatrix platziert wird.  Licht von einem Laser oder einer spektral reinen Farb-LED f√§llt auf die Probe und wird auf die aufgenommenen Objekte gestreut.  Die resultierenden Beugungswellen - die den <strong>Objektstrahl</strong> (Objektstrahl) bilden - werden der Beleuchtung √ºberlagert, die ohne Verzerrung durch die Probe geht - dem <strong>Referenzstrahl</strong> (Referenzstrahl).  Das Ergebnis ist ein komplexes Interferenzmuster, das von einer lichtempfindlichen Matrix aufgezeichnet und in der digitalen Inline-Holographie verwendet wird.  Das Rohbild √§hnelt vage den mikroskopischen Schatten der Probe, und in einigen F√§llen reicht es aus, die Anzahl und Position von Objekten grob zu berechnen.  Das rohe holographische Bild ist jedoch zu schlammig, verrauscht, enth√§lt "Ringartefakte" und erlaubt keine Bestimmung der Morphologie von Objekten.  Das Bild ist schlecht. </p><br><p>  Das Interferenzmuster durchl√§uft mehrere Stufen der digitalen Verarbeitung, die Hauptstufe ist der Phasenrekonstruktionsalgorithmus.  Darin werden unter Verwendung der Physik der optischen Interferenz Schlussfolgerungen √ºber die Struktur und Position von Objekten in der Probe gezogen.  Kurz gesagt: Der Algorithmus sucht nach optischen Informationen √ºber die im Hologramm verlorene Phase in der Matrix (die nur das Interferenzmuster und nicht die Phasen einzelner Lichtstrahlen selbst registriert).  Der Algorithmus berechnet iterativ Phaseninformationen im Objektstrahl, was h√∂chstwahrscheinlich zum Auftreten eines solchen optischen Interferenzmusters f√ºhrte.  Wenn Informationen √ºber die Phase im Objektstrahl bestimmt werden, berechnet der Algorithmus seine zeitliche √Ñnderung, um ein Bild der Objekte zu erstellen und das endg√ºltige digitale Bild zu erzeugen. </p><br><p><img src="https://habrastorage.org/webt/sb/ei/jw/sbeijwfovnxikgl5-bn4fyhqvdc.jpeg"></p><br><p>  Wie bei Makroger√§ten wird die Aufl√∂sung durch die Aufnahme mehrerer optischer Bilder erh√∂ht, von denen jedes leicht unterschiedliche Informationen enth√§lt.  Vor dem Registrieren jedes Frames k√∂nnen Sie beispielsweise die Lichtquelle, die Probe selbst oder die Matrix leicht verschieben.  Dann werden die Rahmen verarbeitet und kombiniert, um ein Interferenzbild mit erh√∂hter Aufl√∂sung zu erhalten (das f√ºr den Menschen immer noch unverst√§ndlich ist), und dann werden die Phasen der Phasenwiederherstellung und der vor√ºbergehenden Wiederherstellung durchgef√ºhrt. </p><br><p><img src="https://habrastorage.org/webt/mb/t8/gd/mbt8gdezz3ycl-ihomuyoftlllk.jpeg"></p><br><p>  Objektive Mikroskope auf einem Chip haben mehrere Vorteile. </p><br><p>  Erstens kann der Aufnahmebereich der Probe (d. H. Das Sichtfeld) extrem gro√ü sein, er ist nur durch die Gr√∂√üe der lichtempfindlichen Matrix begrenzt, auf der die Probe platziert ist.  Mit modernen Matrizen k√∂nnen Sie ein Sichtfeld von 20 bis 20 Quadratzentimetern bereitstellen. </p><br><p>  Zweitens k√∂nnen sogar transparente Objekte (zum Beispiel die meisten Bakterien in einer Wasserschicht) mit Objektivmikroskopen untersucht werden, wenn sie die Phase des durch sie hindurchtretenden Lichts √§ndern.  Spezielle optische Objektivmikroskope erm√∂glichen auch die Untersuchung solcher "Phasenobjekte", wenn auch mit einem viel kleineren Sichtfeld und der Gesamtgr√∂√üe der Probe. </p><br><p>  Drittens erm√∂glicht die digitale Verarbeitung des optischen Bildes, verschiedene Zelltypen (z. B. Spermien oder Blutzellen in den Kapillaren) zu isolieren und ihre Bewegungen zu verfolgen.  Dank dessen k√∂nnen √Ñrzte und Biologen wichtige Daten erhalten. </p><br><p>  Viertens sind solche Mikroskope viel billiger und kompakter als herk√∂mmliche.  Objektive Mikroskope k√∂nnen an ein Mobiltelefon angeschlossen werden, das in l√§ndlichen Gebieten verwendet wird, und digitale Daten k√∂nnen zur weiteren gr√ºndlichen Analyse √ºberall √ºbertragen werden. </p><br><p><img src="https://habrastorage.org/webt/co/pl/t5/coplt5sdvae88xjefwm1maid08y.jpeg"></p><br><h2 id="metodika-compressive-sensing">  Drucksensortechnik </h2><br><p>  Der dritte Ansatz zur voreingenommenen Bilderzeugung basiert auf den neuesten Fortschritten in der Mathematik und Signalstatistik - der <strong>Kompressionserfassungstechnik</strong> .  Ein optisches Bild auf einer Matrix ist ein komplexes Signal, das in Form einer Zahlenliste dargestellt und von verschiedenen Algorithmen verarbeitet wird.  Da ein komplexes Tonsignal aus vielen einfacheren T√∂nen besteht, von denen jeder im richtigen Verh√§ltnis hinzugef√ºgt wird, wird das Bild aus einer gro√üen Anzahl einfacherer Bilder gebildet.  Eine Reihe einfacher Bilder oder Signale wird als <strong>Basis bezeichnet</strong> .  Im Bereich des Klangs ist die h√§ufigste Basis eine Reihe von reinen Cosinust√∂nen.  Es spielt keine Rolle, wie kompliziert der Sound ist.  Von einer Autohupe bis zu einer Beethoven-Symphonie kann alles durch Hinzuf√ºgen einer gro√üen Anzahl von Kosinus-Grundwellen erzeugt werden, f√ºr die jeweils die erforderliche Intensit√§t und Zeitverschiebung ausgew√§hlt werden. </p><br><p>  Was k√∂nnte eine √§hnliche Grundlage im Bereich der Bilder sein?  Die zwei beliebtesten und n√ºtzlichsten visuellen Grundlagen sind S√§tze <strong>zweidimensionaler Kosinuswellen und</strong> Wavelet-Muster mit mehreren Aufl√∂sungen.  Diese Grundelemente sind mathematisch elegant und bilden die Grundlage f√ºr moderne JPEG- und JPEG 2000-Bildkomprimierungsschemata. Anstatt die Werte jedes Pixels in einem digitalen Bild zu speichern und zu √ºbertragen, bearbeiten Sie eine Datei, die die Amplituden verschiedener Komponentenbasissignale beschreibt.  Infolgedessen ist die "komprimierte" Datei viel kleiner als das Bild selbst.  Diese Basen dienten jahrzehntelang treu als Werkzeug f√ºr die Verarbeitung digitaler Bilder, f√ºhrten jedoch nicht zur Schaffung neuer Methoden f√ºr die Entwicklung optischer Schaltungen. Daher macht es kein optisches Element einfach, Basen einzuf√ºhren. </p><br><p>  Fahren wir mit der Druckmessung fort.  Theoretisch zeigen die Statistiken, dass, w√§hrend die Informationen √ºber die Szene redundant sind (d. H. Das Bild komprimiert werden kann), es nicht erforderlich ist, die Basen zu messen, Messungen einer Zufallsstichprobe ausreichend sind.     ¬´   ¬ª,     ,         (   ),       compressive sensing.  ,             ,  . </p><br><p><img src="https://habrastorage.org/webt/9x/je/dd/9xjeddra0xiflseln0v0b8nl-rc.jpeg"></p><br><p> <em> ,   (),        .         .            ¬´¬ª ,    ,   ().           ,      .</em> </p><br><p>           ,          -. <strong> </strong> (coded apertures) (    -     )            .      FlatCam    (Ashok Veeraraghavan)      .      ,      (.  ).    ‚Äî      Angry Birds ‚Äî  ( )         .  ,     ,  ,     .     ,            .     ,       .        compressive sensing   ¬´¬ª ,     . </p><br><p>       . </p><br><p>           ,           .   ,    ,       ,      .      0,5     0,2  ‚Äî     ,      .     FlatCam       ,   ,         . </p><br><h2 id="pravila-menyayutsya">   </h2><br><p>        ,   ,       ,      ,    .        ,  -  ,              .       ,       ,   . </p><br><p>                 .  ,   ,      ,    ,   ,     ,     .           ,    ,  ,  .         ,     ,     ,     . </p><br><p>        ,        .             ,      -  . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de410345/">https://habr.com/ru/post/de410345/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de410333/index.html">Das Alienschiff Oumuamua dreht sich zuf√§llig</a></li>
<li><a href="../de410335/index.html">Hacker haben die Tesla-Instanz in AWS gehackt und dort die Kryptow√§hrung abgebaut</a></li>
<li><a href="../de410337/index.html">Im neuen Jahr - mit der neuen "Fabrik". Kurz √ºber die Aktualisierung der Reihe der kartuschenlosen Drucker und MFPs Epson</a></li>
<li><a href="../de410339/index.html">Physiker wollen alle Phasen der Materie klassifizieren</a></li>
<li><a href="../de410343/index.html">Wie und warum Bezos seit 10.000 Jahren Uhren baut</a></li>
<li><a href="../de410347/index.html">Hat die UdSSR die Mondlandung beleuchtet? Ein Blick von der R√ºckseite der Erde</a></li>
<li><a href="../de410349/index.html">Warum sollten Sie keine Angst vor Killerrobotern haben?</a></li>
<li><a href="../de410351/index.html">Das Kommunikationsministerium schl√§gt vor, ICO zu regulieren</a></li>
<li><a href="../de410353/index.html">Der Wasserstand in den Ozeanen steigt schneller als der berechnete Indikator</a></li>
<li><a href="../de410355/index.html">Was ist jetzt √ºber Supersymmetrie in der Physik bekannt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äç‚úàÔ∏è üç∂ üë©‚Äçüë©‚Äçüëß Lancez LDA dans le monde r√©el. Guide d√©taill√© üçë ‚ôãÔ∏è üë®üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pr√©face 


 Il existe de nombreux tutoriels sur Internet qui expliquent comment fonctionne le LDA (Latent Dirichlet Allocation) et comment le mettre e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lancez LDA dans le monde r√©el. Guide d√©taill√©</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417167/"><h2 id="predislovie">  Pr√©face </h2><br><p>  Il existe de nombreux tutoriels sur Internet qui expliquent comment fonctionne le LDA (Latent Dirichlet Allocation) et comment le mettre en pratique.  Des exemples de formation LDA sont souvent pr√©sent√©s sur des ensembles de donn√©es ¬´exemplaires¬ª, tels que ¬´l'ensemble de donn√©es 20 groupes de discussion¬ª, qui est disponible sur sklearn. </p><br><p>  Une caract√©ristique de la formation sur l'exemple d'ensembles de donn√©es "exemplaires" est que les donn√©es y sont toujours en ordre et empil√©es en un seul endroit.  Lors de la formation de mod√®les de production, les donn√©es obtenues directement √† partir de sources r√©elles sont g√©n√©ralement le contraire: </p><br><ul><li>  Beaucoup d'√©missions. </li><li>  Balisage incorrect (le cas √©ch√©ant). </li><li>  D√©s√©quilibres de classe tr√®s forts et distributions moches de tous les param√®tres de l'ensemble de donn√©es. </li><li>  Pour les textes, ce sont: les erreurs grammaticales, un grand nombre de mots rares et uniques, le multilinguisme. </li><li>  Un moyen peu pratique de stocker des donn√©es (formats diff√©rents ou rares, besoin d'analyse) </li></ul><br><p>  Historiquement, j'essaie d'apprendre √† partir d'exemples qui se rapprochent le plus possible des r√©alit√©s de la r√©alit√© de production car c'est de cette fa√ßon que l'on peut le plus pleinement percevoir les zones probl√©matiques d'un type de t√¢che particulier.  C'√©tait donc avec le LDA, et dans cet article, je veux partager mon exp√©rience - comment ex√©cuter LDA √† partir de z√©ro, sur des donn√©es compl√®tement brutes.  Une partie de l'article sera consacr√©e √† l'obtention de ces m√™mes donn√©es, afin que l'exemple devienne un ¬´cas d'ing√©nierie¬ª √† part enti√®re. </p><a name="habracut"></a><br><h2 id="topic-modeling-i-lda">  Mod√©lisation de sujets et LDA. </h2><br><p>  Pour commencer, consid√©rez ce que fait le LDA en g√©n√©ral et quelles t√¢ches il utilise. <br>  Le plus souvent, LDA est utilis√© pour les t√¢ches de mod√©lisation de sujet.  De telles t√¢ches signifient les t√¢ches de regroupement ou de classification des textes - de telle mani√®re que chaque classe ou cluster contient des textes ayant des sujets similaires. </p><br><p>  Afin d'appliquer la LDA √† l'ensemble de donn√©es des textes (ci-apr√®s d√©nomm√© le corps du texte), il est n√©cessaire de transformer le corps en une matrice terme-document. </p><br><p>  Une matrice de document de terme est une matrice qui a une taille <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>W</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.379ex" height="2.419ex" viewBox="0 -780.1 4038 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-4E" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-66" x="1138" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6F" x="1689" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-69" x="2174" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-73" x="2520" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-57" x="2989" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi><mtext>&nbsp;</mtext><mi>f</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>W</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> N \ fois W </script>  o√π <br>  N est le nombre de documents dans l'affaire, et W est la taille du dictionnaire de l'affaire, c'est-√†-dire  le nombre de mots (uniques) que l'on retrouve dans notre corpus.  Dans la i-√®me ligne, la j-√®me colonne de la matrice est un nombre - combien de fois dans le i-√®me texte le j-√®me mot a √©t√© trouv√©. </p><br><p>  Le LDA construit, pour une matrice de document Term donn√©e et T d'un nombre pr√©d√©termin√© de th√®mes, deux distributions: </p><br><ol><li>  La r√©partition des sujets dans les textes (en pratique, donn√©e par la matrice de taille <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>T</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.58ex" height="2.419ex" viewBox="0 -780.1 3694 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-4E" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-66" x="1138" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6F" x="1689" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-69" x="2174" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-73" x="2520" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-54" x="2989" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi><mtext>&nbsp;</mtext><mi>f</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>T</mi></math></span></span><script type="math/tex" id="MathJax-Element-2"> N \ fois T </script>  ) </li><li>  La r√©partition des mots par sujet (matrice de taille <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>W</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.951ex" height="2.419ex" viewBox="0 -780.1 3854 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-54" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-66" x="954" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6F" x="1505" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-69" x="1990" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-73" x="2336" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-57" x="2805" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mtext>&nbsp;</mtext><mi>f</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>W</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> T \ fois W </script>  ) </li></ol><br><p>  Les valeurs des cellules de ces matrices sont, respectivement, les probabilit√©s que ce sujet soit contenu dans ce document (ou la proportion du sujet dans le document, si nous consid√©rons le document comme un m√©lange de diff√©rents sujets) pour la matrice `` Distribution des sujets dans les textes ''. </p><br><p>  Pour la matrice `` Distribution des mots par th√®mes '', les valeurs sont la probabilit√© de rencontrer le mot j dans le texte avec le sujet i, qualitativement, nous pouvons consid√©rer ces nombres comme des coefficients caract√©risant la fa√ßon dont ce mot est typique de ce sujet. </p><br><p>  Il faut dire que le mot sujet n'est pas une d√©finition ¬´quotidienne¬ª de ce mot.  La LDA attribue T √† ceux-ci, mais quel type de sujets sont-ils et s'ils correspondent √† des sujets de textes bien connus, tels que: ¬´Sport¬ª, ¬´Science¬ª, ¬´Politique¬ª - est inconnu.  Dans ce cas, il est plus appropri√© de parler du sujet comme d'une sorte d'entit√© abstraite, qui est d√©finie par une ligne dans la matrice de distribution des mots par sujet et avec une certaine probabilit√© correspond √† ce texte, si vous pouvez l'imaginer comme une famille d'ensembles caract√©ristiques de mots se rencontrant avec les probabilit√©s correspondantes (du tableau) dans un certain ensemble de textes. </p><br><p>  Si vous souhaitez √©tudier plus en d√©tail et ¬´dans les formules¬ª comment le LDA est form√© et fonctionne, voici quelques documents (qui ont √©t√© utilis√©s par l'auteur): </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article original</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">En anglais, avec des exemples illustratifs</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©tails en russe</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√Ä propos de la mise en ≈ìuvre de Python</a> </li></ul><br><h2 id="dobyvaem-dikie-dannye">  Nous obtenons des donn√©es sauvages </h2><br><p>  Pour nos ¬´travaux de laboratoire¬ª, nous avons besoin d'un ensemble de donn√©es personnalis√© avec ses propres d√©fauts et fonctionnalit√©s.  Vous pouvez l'obtenir √† diff√©rents endroits: t√©l√©chargez des critiques de Kinopoisk, des articles Wikip√©dia, des nouvelles d'un portail de nouvelles, nous prendrons une option un peu plus extr√™me - des publications des communaut√©s VKontakte. </p><br><p>  Nous ferons ceci comme ceci: </p><br><ol><li>  Nous s√©lectionnons un utilisateur VK. </li><li>  Nous obtenons une liste de tous ses amis. </li><li>  Pour chaque ami, nous prenons toute sa communaut√©. </li><li>  Pour chaque communaut√© de chaque ami, nous pompons les n (n = 100) premiers messages de la communaut√© et les combinons en un seul texte de communaut√©. </li></ol><br><h4 id="instrumenty-i-stati">  Outils et articles </h4><br><p>  Pour t√©l√©charger des articles, nous utiliserons le module vk pour travailler avec l'API VKontakte, pour Python.  L'un des moments les plus complexes lors de l'√©criture d'une application √† l'aide de l'API VKontakte est l'autorisation, heureusement, le code qui effectue ce travail est d√©j√† √©crit et est dans le domaine public, sauf pour vk, j'ai utilis√© un petit module d'autorisation - vkauth. </p><br><p>  Liens vers les modules et articles utilis√©s pour √©tudier l'API VKontakte: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vkauth</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tutoriel vkauth</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tutoriel vk</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tutoriel vk num√©ro 2</a> </li><li>  Documentation officielle de l'API Vkontakte </li></ul><br><h4 id="pishem-kod">  √âcrire un code </h4><br><p>  Et donc, en utilisant vkauth, connectez-vous: </p><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#authorization of app using modules imported. app_id = '6203169' perms = ['photos','friends','groups'] API_ver = '5.68' Auth = VKAuth(perms, app_id, API_ver) Auth.auth() token = Auth.get_token() user_id = Auth.get_user_id() #starting session session = vk.Session(access_token=token) api = vk.API(session)</span></span></code> </pre> <br><p>  Dans le processus, un petit module a √©t√© √©crit contenant toutes les fonctions n√©cessaires au t√©l√©chargement de contenu au format appropri√©, elles sont list√©es ci-dessous, passons en revue: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_friends_ids</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(api, user_id)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' For a given API object and user_id returns a list of all his friends ids. '''</span></span> friends = api.friends.get(user_id=user_id, v = <span class="hljs-string"><span class="hljs-string">'5.68'</span></span>) friends_ids = friends[<span class="hljs-string"><span class="hljs-string">'items'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> friends_ids <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_user_groups</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(api, user_id, moder=True, only_open=True)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' For a given API user_id returns list of all groups he subscribed to. Flag model to get only those groups where user is a moderator or an admin) Flag only_open to get only public(open) groups. '''</span></span> kwargs = {<span class="hljs-string"><span class="hljs-string">'user_id'</span></span> : user_id, <span class="hljs-string"><span class="hljs-string">'v'</span></span> : <span class="hljs-string"><span class="hljs-string">'5.68'</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> moder == <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: kwargs[<span class="hljs-string"><span class="hljs-string">'filter'</span></span>] = <span class="hljs-string"><span class="hljs-string">'moder'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> only_open == <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: kwargs[<span class="hljs-string"><span class="hljs-string">'extended'</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span> kwargs[<span class="hljs-string"><span class="hljs-string">'fields'</span></span>] = [<span class="hljs-string"><span class="hljs-string">'is_closed'</span></span>] groups = api.groups.get(**kwargs) groups_refined = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> group <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> groups[<span class="hljs-string"><span class="hljs-string">'items'</span></span>]: cond_check = (only_open <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> group[<span class="hljs-string"><span class="hljs-string">'is_closed'</span></span>] == <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> only_open <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> cond_check: refined = {} refined[<span class="hljs-string"><span class="hljs-string">'id'</span></span>] = group[<span class="hljs-string"><span class="hljs-string">'id'</span></span>] * (<span class="hljs-number"><span class="hljs-number">-1</span></span>) refined[<span class="hljs-string"><span class="hljs-string">'name'</span></span>] = group[<span class="hljs-string"><span class="hljs-string">'name'</span></span>] groups_refined.append(refined) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> groups_refined <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_n_posts_text</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(api, group_id, n_posts=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">50</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' For a given api and group_id returns first n_posts concatenated as one text. '''</span></span> wall_contents = api.wall.get(owner_id = group_id, count=n_posts, v = <span class="hljs-string"><span class="hljs-string">'5.68'</span></span>) wall_contents = wall_contents[<span class="hljs-string"><span class="hljs-string">'items'</span></span>] text = <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> post <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wall_contents: text += post[<span class="hljs-string"><span class="hljs-string">'text'</span></span>] + <span class="hljs-string"><span class="hljs-string">' '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text</code> </pre> <br><p>  Le pipeline final est le suivant: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#id of user whose friends you gonna get, like: https://vk.com/id111111111 user_id = 111111111 friends_ids = vt.get_friends_ids(api, user_id) #collecting all groups groups = [] for i,friend in tqdm(enumerate(friends_ids)): if i % 3 == 0: sleep(1) friend_groups = vt.get_user_groups(api, friend, moder=False) groups += friend_groups #converting groups to dataFrame groups_df = pd.DataFrame(groups) groups_df.drop_duplicates(inplace=True) #reading content(content == first 100 posts) for i,group in tqdm(groups_df.iterrows()): name = group['name'] group_id = group['id'] #Different kinds of fails occures during scrapping #For examples there are names of groups with slashes #Like: 'The Kaaats / Indie-rock' try: content = vt.get_n_posts_text(api, group_id, n_posts=100) dst_path = join(data_path, name + '.txt') with open(dst_path, 'w+t') as f: f.write(content) except Exception as e: print('Error occured on group:', name) print(e) continue #need it because of requests limitaion in VK API. if i % 3 == 0: sleep(1)</span></span></code> </pre> <br><h4 id="fails">  √âchoue </h4><br><p>  En g√©n√©ral, le processus de t√©l√©chargement de donn√©es n'est pas difficile en soi; vous devez faire attention √† seulement deux points: </p><br><ol><li>  Parfois, en raison de la confidentialit√© de certaines communaut√©s, vous recevrez des erreurs d'acc√®s, parfois d'autres erreurs seront r√©solues en installant try, sauf au bon endroit. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VK a une limite</a> sur le nombre de requ√™tes par seconde. </li></ol><br><p>  Lorsque vous effectuez un grand nombre de demandes, par exemple dans une boucle, nous d√©tectons √©galement des erreurs.  Ce probl√®me peut √™tre r√©solu de plusieurs mani√®res: </p><br><ol><li>  Stupidement et sans d√©tour: Stick sommeil (certains) toutes les 3 demandes.  Cela se fait sur une seule ligne et ralentit consid√©rablement le d√©chargement, dans des situations o√π les volumes de donn√©es ne sont pas importants et o√π il n'y a pas de temps pour des m√©thodes plus sophistiqu√©es - cela est tout √† fait acceptable (impl√©ment√© dans cet article). </li><li>  Comprendre le travail des demandes de sondage long <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://vk.com/dev/using_longpoll</a> </li></ol><br><p>  Dans cet article, une m√©thode simple et lente a √©t√© choisie, √† l'avenir, j'√©crirai probablement un micro article sur les moyens de contourner ou d'assouplir les restrictions sur le nombre de requ√™tes par seconde. </p><br><h4 id="itog">  R√©sum√© </h4><br><p>  Avec la graine ¬´certains¬ª utilisateurs ayant ~ 150 amis, ils ont r√©ussi √† obtenir 4 679 textes - chacun caract√©rise une certaine communaut√© VK.  Les textes varient consid√©rablement en taille et sont √©crits dans de nombreuses langues - certains d'entre eux ne conviennent pas √† nos fins, mais nous en parlerons un peu plus loin. </p><br><h3 id="osnovnaya-chast">  Corps principal </h3><br><p><img src="https://habrastorage.org/webt/bj/to/hm/bjtohmsrvsxlcbs78u0thlawxky.png" alt="image"></p><br><p>  Passons en revue tous les blocs de notre pipeline - d'abord, sur le obligatoire (id√©al), puis sur le reste - ils sont juste du plus grand int√©r√™t. </p><br><h4 id="countvectorizer">  Countvectorizer </h4><br><p>  Avant d'enseigner le LDA, nous devons pr√©senter nos documents sous la forme d'une matrice de documents Term.  Cela comprend g√©n√©ralement des op√©rations telles que: </p><br><ul><li>  Suppression des puttuctions / num√©ros / jetons inutiles. </li><li>  Tokenisation (pr√©sentation sous forme de liste de mots) </li><li>  Compter les mots, compiler une matrice de document thermique. </li></ul><br><p>  Toutes ces actions dans sklearn sont commod√©ment impl√©ment√©es dans le cadre d'une entit√© de programme - sklearn.feature_extraction.text.CountVectorizer. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien vers la documentation</a> </p><br><p>  Il vous suffit de: </p><br><pre> <code class="python hljs">count_vect = CountVectorizer(input=<span class="hljs-string"><span class="hljs-string">'filename'</span></span>, stop_words=stopwords, vocabulary=voc) dataset = count_vect.fit_transform(train_names)</code> </pre> <br><h4 id="lda">  Lda </h4><br><p>  De m√™me avec CountVectorizer, LDA est parfaitement impl√©ment√© dans Sklearn et d'autres frameworks, donc, il n'y a pas beaucoup de sens √† consacrer beaucoup d'espace directement √† leurs impl√©mentations, dans notre article purement pratique. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien vers la documentation</a> </p><br><p>  Tout ce dont vous avez besoin pour d√©marrer LDA est: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#training LDA lda = LDA(n_components = 60, max_iter=30, n_jobs=6, learning_method='batch', verbose=1) lda.fit(dataset)</span></span></code> </pre> <br><h4 id="preprocessing">  Pr√©traitement </h4><br><p>  Si nous prenons juste nos textes imm√©diatement apr√®s les avoir t√©l√©charg√©s et convertis en une matrice Term-document √† l'aide de CountVectorizer, avec le tokenizer par d√©faut int√©gr√©, nous obtiendrons une matrice de taille 4679x769801 (sur les donn√©es que j'utilise). </p><br><p>  La taille de notre dictionnaire sera de 769801. M√™me si nous supposons que la plupart des mots sont informatifs, il est peu probable que nous obtenions un bon LDA, quelque chose comme "Curses of Dimensions" nous attend, sans mentionner que pour presque tous les ordinateurs, nous allons simplement obstruer toute la RAM.  En fait, la plupart de ces mots sont compl√®tement informatifs.  La grande majorit√© d'entre eux sont: </p><br><ul><li>  √âmotic√¥nes, personnages, chiffres. </li><li>  Mots uniques ou tr√®s rares (par exemple, mots polonais d'un groupe avec des m√®mes polonais, mots mal orthographi√©s ou en ¬´albanais¬ª). </li><li>  Parties du discours tr√®s fr√©quentes (par exemple, pr√©positions et pronoms). </li></ul><br><p>  De plus, de nombreux groupes dans VK se sp√©cialisent exclusivement dans les images - il n'y a presque pas de texte l√†-bas - les textes qui leur correspondent sont d√©g√©n√©r√©s, dans la matrice de document thermique, ils nous donneront presque compl√®tement z√©ro lignes. </p><br><p>  Et donc, trions le tout! <br>  Nous tokenisons tous les textes, en supprimons la ponctuation et les nombres, regardons l'histogramme de la r√©partition des textes par le nombre de mots: <br><img src="https://habrastorage.org/webt/v4/qh/w0/v4qhw0mrgpizranmnptbz5lnivk.png" alt="image"></p><br><p>  Nous supprimons tous les textes de moins de 100 mots (il y en a 525) </p><br><p>  Maintenant le dictionnaire: <br>  Supprimer tous les jetons (mots) qui ne sont pas des lettres, dans le cadre de notre t√¢che - cela est tout √† fait acceptable.  Le CountVectorizer le fait seul, m√™me si ce n'est pas le cas, je pense qu'il n'est pas n√©cessaire de donner des exemples (ils sont dans la version compl√®te du code de l'article). </p><br><p>  L'une des proc√©dures les plus courantes pour r√©duire la taille d'un dictionnaire consiste √† supprimer les soi-disant mots vides (mots vides) - des mots qui ne portent pas de charge s√©mantique et / ou qui n'ont pas de coloration th√©matique (dans notre cas, la mod√©lisation de sujet).  De tels mots dans notre cas sont, par exemple: </p><br><ul><li>  Pronoms et pr√©positions. </li><li>  Articles - le, a. </li><li>  Mots communs: ¬´√™tre¬ª, ¬´bon¬ª, ¬´probablement¬ª, etc. </li></ul><br><p>  Le module nltk a form√© des listes de mots vides en russe et en anglais, mais ils sont plut√¥t faibles.  Sur Internet, vous pouvez √©galement trouver des listes de mots vides pour n'importe quelle langue et les ajouter √† ceux de nltk.  Nous allons donc faire.  Prenez des mots d'arr√™t suppl√©mentaires d'ici: </p><br><ul><li>  <a href="">https://github.com/stopwords-iso/stopwords-ru/blob/master/stopwords-ru.json</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://gist.github.com/menzenski/7047705</a> </li></ul><br><p>  En pratique, lors de la r√©solution de probl√®mes sp√©cifiques, les listes de mots vides sont progressivement ajust√©es et compl√©t√©es au fur et √† mesure que les mod√®les sont entra√Æn√©s, car pour chaque jeu de donn√©es et probl√®me sp√©cifique, il existe des mots "incoh√©rents" sp√©cifiques.  Nous r√©cup√©rerons √©galement des mots d'arr√™t personnalis√©s apr√®s avoir form√© notre LDA de premi√®re g√©n√©ration. </p><br><p>  En soi, la proc√©dure de suppression des mots vides est int√©gr√©e au CountVectorizer - nous avons juste besoin d'une liste d'entre eux. </p><br><p>  Est-ce que nous en avons fait assez? </p><br><p><img src="https://habrastorage.org/webt/ja/xd/6l/jaxd6lnbbnd_dmmmk6nog9a2ntm.png" alt="image"></p><br><p>  La plupart des mots qui sont dans notre dictionnaire ne sont pas encore trop informatifs pour apprendre le LDA sur eux et ne sont pas dans la liste des mots vides.  Par cons√©quent, nous appliquons une autre m√©thode de filtrage √† nos donn√©es. </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>,</mo><mi>D</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>D</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mspace linebreak=&quot;newline&quot; /><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>n</mi><mi>D</mi><mo>:</mo><mi>t</mi><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>n</mi><mi>d</mi><mspace linebreak=&quot;newline&quot; /></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="37.78ex" height="8.202ex" viewBox="0 -832 16266.3 3531.4" role="img" focusable="false" style="vertical-align: -6.27ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-69" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-64" x="345" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-66" x="869" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-28" x="1419" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-74" x="1809" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-2C" x="2170" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-44" x="2615" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-29" x="3444" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-3D" x="4111" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6C" x="5417" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6F" x="5716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-67" x="6201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-66" x="6932" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-72" x="7482" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-61" x="7934" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-63" x="8463" y="0"></use><g transform="translate(8897,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-7C" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-44" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-7C" x="1107" y="0"></use></g><g transform="translate(10282,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-7C" x="0" y="0"></use><g transform="translate(0,-1432)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-65" x="773" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6E" x="1240" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-44" x="1840" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-3A" x="2946" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-74" x="3503" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-65" x="4114" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-6E" x="4581" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMATHI-64" x="5181" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/417167/&amp;usg=ALkJrhiPOCRZVy_0MtT-jzkx2wIS3-Vfkw#MJMAIN-7C" x="5705" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>&nbsp;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>D</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mrow class="MJX-TeXAtom-ORD"><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mspace linebreak="newline"></mspace><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mtext>&nbsp;</mtext><mi>e</mi><mi>n</mi><mi>D</mi><mo>:</mo><mi>t</mi><mtext>&nbsp;</mtext><mi>e</mi><mi>n</mi><mi>d</mi><mspace linebreak="newline"></mspace></mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-4"> idf (t, D) = \ log \ frac {| D |} {| \\ {d \ en D: t \ en d \\} |} </script></p><br><p>  o√π <br>  t est un mot du dictionnaire. <br>  D - cas (nombreux textes) <br>  d est l'un des textes du corps. <br>  Nous calculons l'IDF de tous nos mots et coupons les mots avec le plus grand idf (tr√®s rare) et avec le plus petit (mots r√©pandus). </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#'training' (tf-)idf vectorizer. tf_idf = TfidfVectorizer(input='filename', stop_words=stopwords, smooth_idf=False ) tf_idf.fit(train_names) #getting idfs idfs = tf_idf.idf_ #sorting out too rare and too common words lower_thresh = 3. upper_thresh = 6. not_often = idfs &gt; lower_thresh not_rare = idfs &lt; upper_thresh mask = not_often * not_rare good_words = np.array(tf_idf.get_feature_names())[mask] #deleting punctuation as well. cleaned = [] for word in good_words: word = re.sub("^(\d+\w*$|_+)", "", word) if len(word) == 0: continue cleaned.append(word)</span></span></code> </pre> <br><p>  Obtenu apr√®s les proc√©dures ci-dessus est d√©j√† tout √† fait adapt√© √† la formation LDA, mais nous ferons plus de stemming - les m√™mes mots se retrouvent souvent dans notre ensemble de donn√©es, mais dans des cas diff√©rents.  Pour le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">stemming, pymystem3 a √©t√© utilis√©</a> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#Stemming m = Mystem() stemmed = set() voc_len = len(cleaned) for i in tqdm(range(voc_len)): word = cleaned.pop() stemmed_word = m.lemmatize(word)[0] stemmed.add(stemmed_word) stemmed = list(stemmed) print('After stemming: %d'%(len(stemmed)))</span></span></code> </pre> <br><p>  Apr√®s avoir appliqu√© le filtrage ci-dessus, la taille du dictionnaire est pass√©e de 769801 √† <br>  13611 et d√©j√† avec de telles donn√©es, vous pouvez obtenir un mod√®le LDA de qualit√© acceptable. </p><br><h3 id="testirovanie-primenenie-i-tyuning-lda">  Test, application et optimisation de LDA </h3><br><p>  Maintenant que nous avons l'ensemble de donn√©es, le pr√©traitement et les mod√®les que nous avons form√©s sur l'ensemble de donn√©es trait√©, il serait bien de v√©rifier l'ad√©quation de nos mod√®les, ainsi que de cr√©er des applications pour eux. </p><br><p>  En tant qu'application, pour commencer, envisagez la t√¢che de g√©n√©rer des mots cl√©s pour un texte donn√©.  Vous pouvez le faire de mani√®re assez simple comme suit: </p><br><ol><li>  Nous obtenons de LDA la distribution des sujets pour ce texte. </li><li>  Choisissez n (par exemple, n = 2) des sujets les plus prononc√©s. </li><li>  Pour chaque sujet, choisissez m (par exemple m = 3) les mots les plus caract√©ristiques. </li><li>  Nous avons un ensemble de n * m mots caract√©risant un texte donn√©. </li></ol><br><p>  Nous allons √©crire une classe d'interface simple qui impl√©mentera cette m√©thode de g√©n√©ration de mots cl√©s: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#Let\`s do simple interface class class TopicModeler(object): ''' Inteface object for CountVectorizer + LDA simple usage. ''' def __init__(self, count_vect, lda): ''' Args: count_vect - CountVectorizer object from sklearn. lda - LDA object from sklearn. ''' self.lda = lda self.count_vect = count_vect self.count_vect.input = 'content' def __call__(self, text): ''' Gives topics distribution for a given text Args: text - raw text via python string. returns: numpy array - topics distribution for a given text. ''' vectorized = self.count_vect.transform([text]) lda_topics = self.lda.transform(vectorized) return lda_topics def get_keywords(self, text, n_topics=3, n_keywords=5): ''' For a given text gives n top keywords for each of m top texts topics. Args: text - raw text via python string. n_topics - int how many top topics to use. n_keywords - how many top words of each topic to return. returns: list - of m*n keywords for a given text. ''' lda_topics = self(text) lda_topics = np.squeeze(lda_topics, axis=0) n_topics_indices = lda_topics.argsort()[-n_topics:][::-1] top_topics_words_dists = [] for i in n_topics_indices: top_topics_words_dists.append(self.lda.components_[i]) shape=(n_keywords*n_topics, self.lda.components_.shape[1]) keywords = np.zeros(shape=shape) for i,topic in enumerate(top_topics_words_dists): n_keywords_indices = topic.argsort()[-n_keywords:][::-1] for k,j in enumerate(n_keywords_indices): keywords[i * n_keywords + k, j] = 1 keywords = self.count_vect.inverse_transform(keywords) keywords = [keyword[0] for keyword in keywords] return keywords</span></span></code> </pre> <br><p>  Nous appliquons notre m√©thode √† plusieurs textes et voyons ce qui se passe: <br>  Communaut√© <strong>:</strong> Agence de voyage "Couleurs du monde" <br>  <strong>Mots-cl√©s:</strong> ['photo', 'social', 'voyage', 'communaut√©', 'voyage', 'euro', 'logement', 'prix', 'Pologne', 'd√©part'] <br>  <strong>Communaut√©:</strong> Gifs alimentaires <br>  <strong>Mots-cl√©s:</strong> ['beurre', 'st', 'sel', 'pc', 'p√¢te', 'cuisine', 'oignon', 'poivre', 'sucre', 'gr'] </p><br><p>  Les r√©sultats ci-dessus ne sont pas des ¬´choix de cerise¬ª et semblent assez ad√©quats.  En fait, ce sont les r√©sultats d'un mod√®le d√©j√† configur√©.  Les premiers LDA qui ont √©t√© form√©s dans le cadre de cet article ont produit des r√©sultats nettement moins bons, parmi les mots cl√©s que vous pouviez souvent voir, par exemple: </p><br><ol><li>  Composants composites d'adresses Web: www, http, ru, com ... </li><li>  Mots communs. </li><li>  unit√©s: cm, m√®tre, km ... </li></ol><br><p>  Le r√©glage (r√©glage) du mod√®le a √©t√© effectu√© comme suit: </p><br><ol><li>  Pour chaque sujet, s√©lectionnez n (n = 5) mots les plus caract√©ristiques. </li><li>  Nous les consid√©rons idf, selon le cas de formation. </li><li>  Nous apportons 5 √† 10% des mots cl√©s les plus r√©pandus. </li></ol><br><p>  Un tel ¬´nettoyage¬ª doit √™tre effectu√© avec soin, en pr√©voyant ces 10% des mots.  Les candidats √† la suppression doivent plut√¥t √™tre choisis de cette mani√®re, puis les mots qui doivent √™tre supprim√©s doivent √™tre s√©lectionn√©s manuellement parmi eux. </p><br><p>  Quelque part dans la g√©n√©ration 2-3 des mod√®les, avec une mani√®re similaire de s√©lectionner les mots vides, pour les 5% sup√©rieurs des distributions de mots les plus r√©pandues, nous obtenons: <br>  ['tout', 'compl√®tement', 'droit', 'facile', 'suivant', 'internet', 'petit', 'moyen', 'difficile', 'humeur', 'tellement', 'set', ' option ',' nom ',' discours ',' programme ',' comp√©tition ',' musique ',' cible ',' film ',' prix ',' jeu ',' syst√®me ',' jouer ',' entreprise ' , 'sympa'] </p><br><h3 id="esche-prilozheniya">  Plus d'applications </h3><br><p>  La premi√®re chose qui me vient √† l'esprit sp√©cifiquement est d'utiliser la distribution des sujets dans le texte comme des `` incorporations '' de textes, dans cette interpr√©tation, vous pouvez leur appliquer des algorithmes de visualisation ou de clustering, et rechercher les clusters th√©matiques finaux `` efficaces '' de cette mani√®re. </p><br><p>  Faisons √ßa: </p><br><pre> <code class="python hljs">term_doc_matrix = count_vect.transform(names) embeddings = lda.transform(term_doc_matrix) kmeans = KMeans(n_clusters=<span class="hljs-number"><span class="hljs-number">30</span></span>) clust_labels = kmeans.fit_predict(embeddings) clust_centers = kmeans.cluster_centers_ embeddings_to_tsne = np.concatenate((embeddings,clust_centers), axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) tSNE = TSNE(n_components=<span class="hljs-number"><span class="hljs-number">2</span></span>, perplexity=<span class="hljs-number"><span class="hljs-number">15</span></span>) tsne_embeddings = tSNE.fit_transform(embeddings_to_tsne) tsne_embeddings, centroids_embeddings = np.split(tsne_embeddings, [len(clust_labels)], axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  En sortie, nous obtenons l'image suivante: <br><img src="https://habrastorage.org/webt/7j/2r/qv/7j2rqvpp2-blr9vfq44qjs75upc.png" alt="image"></p><br><p>  Les croix sont les centres de gravit√© (c√©nro√Ødes) des grappes. </p><br><p>  Dans l'image tSNE des plongements, on peut voir que les clusters s√©lectionn√©s √† l'aide de KMeans forment des ensembles assez connect√©s et le plus souvent spatialement s√©parables. </p><br><p>  Tout le reste, √† vous de voir. </p><br><p>  Lien vers tout le code: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://gitlab.com/Mozes/VK_LDA</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417167/">https://habr.com/ru/post/fr417167/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417155/index.html">Noyau Linux 4.18: ce qui se pr√©pare pour la prochaine version</a></li>
<li><a href="../fr417157/index.html">La singularit√© approche: l'IA commence √† contr√¥ler les robots</a></li>
<li><a href="../fr417161/index.html">Burger King: surveillance secr√®te, mensonges, vol de cartes bancaires. Continuation</a></li>
<li><a href="../fr417163/index.html">Fine commits</a></li>
<li><a href="../fr417165/index.html">Ce qui menace Burger King</a></li>
<li><a href="../fr417171/index.html">√âtude: les fonds sp√©culatifs g√©r√©s par des femmes affichent de meilleurs r√©sultats</a></li>
<li><a href="../fr417173/index.html">¬´Old New Vinyl¬ª: 20 documents sur l'histoire et la production de platines vinyles et de disques</a></li>
<li><a href="../fr417175/index.html">Restauration du s√©maphore de la route d'Acme de la premi√®re moiti√© du XXe si√®cle</a></li>
<li><a href="../fr417177/index.html">Serveur Web local sous Linux, avec √©l√©vation d'h√¥te automatique et changement de version PHP</a></li>
<li><a href="../fr417179/index.html">Mise en place d'un environnement de d√©veloppement domestique (docker + gitlab + DNS)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
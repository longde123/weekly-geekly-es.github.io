<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîì üö£üèΩ üìô Inicie su detector de red neuronal en la Raspberry Pi usando Neural Compute Stick y OpenVINO ‚è∞ üò∏ ü•É</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Con la difusi√≥n y el desarrollo de las redes neuronales, existe una creciente necesidad de usarlas en dispositivos integrados, de baja potencia, robot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inicie su detector de red neuronal en la Raspberry Pi usando Neural Compute Stick y OpenVINO</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436744/">  Con la difusi√≥n y el desarrollo de las redes neuronales, existe una creciente necesidad de usarlas en dispositivos integrados, de baja potencia, robots y drones.  El dispositivo Neural Compute Stick junto con el marco Intel OpenVINO nos permite resolver este problema asumiendo los pesados ‚Äã‚Äãc√°lculos de las redes neuronales.  Gracias a esto, puede lanzar f√°cilmente un clasificador o detector de red neuronal en un dispositivo de baja potencia como el Raspberry Pi en tiempo casi real, sin aumentar en gran medida el consumo de energ√≠a.  En esta publicaci√≥n, le mostrar√© c√≥mo usar el marco OpenVINO (en C ++) y el Neural Compute Stick para lanzar un sistema simple de detecci√≥n de rostros en la Raspberry Pi. <br><br>  Como de costumbre, todo el c√≥digo est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub</a> . <br><br><img src="https://habrastorage.org/webt/qu/b_/tj/qub_tj1u6ztw9irfy9ivtaaidcc.jpeg"><br><a name="habracut"></a><br><h3>  Un poco sobre Neural Compute Stick y OpenVINO </h3><br>  En el verano de 2017, Intel lanz√≥ el dispositivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Neural Compute Stick</a> (NCS), dise√±ado para ejecutar redes neuronales en dispositivos de baja potencia, y despu√©s de un par de meses se pudo comprar y probar, lo cual hice.  NCS es un peque√±o m√≥dulo inform√°tico con una carcasa de color azul (que tambi√©n act√∫a como un radiador), conectado al dispositivo principal a trav√©s de USB.  En el interior, entre otras cosas, se encuentra la Intel Myriad <abbr title="Unidad de procesamiento de visi√≥n">VPU</abbr> , que es esencialmente un procesador paralelo de 12 n√∫cleos, enfocado para operaciones que a menudo ocurren en redes neuronales.  NCS no es adecuado para entrenar redes neuronales, pero la inferencia en redes neuronales ya entrenadas es comparable en velocidad a la de la GPU.  Todos los c√°lculos en NCS se realizan en n√∫meros flotantes de 16 bits, lo que le permite aumentar la velocidad.  NCS requiere solo 1 vatio de potencia para funcionar, es decir, a 5 V, se consume una corriente de hasta 200 mA en el conector USB; esto es incluso menos que la c√°mara para la Raspberry Pi (250 mA). <br><br><img src="https://habrastorage.org/webt/8d/u8/ov/8du8ov7hj1-f3vk8sjbenkyupvm.png"><br><br>  Para trabajar con el primer NCS, se utiliz√≥ el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Neural Compute SDK</a> (NCSDK): incluye herramientas para compilar redes neuronales en formatos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Caffe</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> en formato NCS, herramientas para medir su rendimiento, as√≠ como Python y C ++ API para inferencia. <br><br>  Luego se lanz√≥ una nueva versi√≥n del marco NCS: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NCSDK2</a> .  La API ha cambiado bastante y, aunque algunos cambios me parecieron extra√±os, hubo algunas innovaciones √∫tiles.  En particular, se agreg√≥ la conversi√≥n autom√°tica de flotante de 32 bits a flotante de 16 bits a C ++ (antes, las muletas ten√≠an que insertarse en forma de c√≥digo de Numpy).  Tambi√©n aparecieron colas de im√°genes y sus resultados de procesamiento. <br><br>  En mayo de 2018, Intel lanz√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenVINO</a> (anteriormente llamado Intel Computer Vision SDK).  Este marco est√° dise√±ado para lanzar redes neuronales de manera eficiente en varios dispositivos: procesadores Intel y tarjetas gr√°ficas, <abbr title="Matriz de puertas programable en campo">FPGA</abbr> , as√≠ como el Neural Compute Stick. <br><br>  En noviembre de 2018, se lanz√≥ una nueva versi√≥n del acelerador: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Neural Compute Stick 2</a> .  La potencia inform√°tica del dispositivo se ha incrementado: en la descripci√≥n en el sitio prometen una aceleraci√≥n de hasta 8 veces, sin embargo, no pude probar la nueva versi√≥n del dispositivo.  La aceleraci√≥n se logra al aumentar el n√∫mero de n√∫cleos de 12 a 16, as√≠ como al agregar nuevos dispositivos inform√°ticos optimizados para redes neuronales.  Es cierto que no encontr√© informaci√≥n sobre el consumo de energ√≠a de la informaci√≥n. <br><br>  La segunda versi√≥n de NCS ya es incompatible con NCSDK o NCSDK2: OpenVINO, que es capaz de trabajar con muchos otros dispositivos adem√°s de ambas versiones de NCS, pas√≥ su autoridad.  OpenVINO tiene una gran funcionalidad e incluye los siguientes componentes: <br><br><ol><li>  Model Optimizer: secuencia de comandos Python que le permite convertir redes neuronales de marcos de aprendizaje profundo populares al formato universal OpenVINO.  La lista de marcos compatibles: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Caffe</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MXNET</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaldi</a> (marco de reconocimiento de voz), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ONNX</a> (formato abierto para representar redes neuronales). </li><li>  Motor de inferencia: API C ++ y Python para inferencia de red neuronal, abstra√≠da de un dispositivo de inferencia espec√≠fico.  El c√≥digo API se ver√° casi id√©ntico para CPU, GPU, FPGA y NCS. </li><li>  Un conjunto de complementos para diferentes dispositivos.  Los complementos son bibliotecas din√°micas que se cargan expl√≠citamente en el c√≥digo del programa principal.  Estamos m√°s interesados ‚Äã‚Äãen el complemento para NCS. </li><li>  Un conjunto de modelos pre-entrenados en el formato universal OpenVINO (la lista completa est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ).  Una impresionante colecci√≥n de redes neuronales de alta calidad: detectores de rostros, peatones, objetos;  reconocimiento de la orientaci√≥n de caras, puntos especiales de caras, posturas humanas;  super resoluci√≥n;  y otros  Vale la pena se√±alar que no todos ellos son compatibles con NCS / FPGA / GPU. </li><li>  Descargador de modelos: otro script que simplifica la descarga de modelos en formato OpenVINO a trav√©s de la red (aunque puede hacerlo f√°cilmente sin √©l). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Biblioteca de</a> visi√≥n por computadora <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenCV</a> optimizada para hardware Intel. </li><li>  Biblioteca de visi√≥n por computadora <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenVX</a> . </li><li>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Compute Library para redes neuronales profundas</a> . </li><li>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Math Kernel Library para redes neuronales profundas</a> . </li><li>  Una herramienta para optimizar redes neuronales para FPGA (opcional). </li><li>  Documentaci√≥n y programas de muestra. </li></ol><br>  En mis art√≠culos anteriores, habl√© sobre c√≥mo ejecutar el detector facial YOLO en el NCS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(primer art√≠culo)</a> , as√≠ como sobre c√≥mo entrenar su detector facial SSD y ejecutarlo en el Raspberry Pi y el NCS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(segundo art√≠culo)</a> .  En estos art√≠culos, us√© NCSDK y NCSDK2.  En este art√≠culo, le dir√© c√≥mo hacer algo similar, pero usando OpenVINO, har√© una peque√±a comparaci√≥n de los dos detectores faciales diferentes y dos marcos para lanzarlos, y se√±alar√© algunas trampas.  Escribo en C ++, porque creo que de esta manera puedes lograr un mejor rendimiento, lo que ser√° importante en el caso de Raspberry Pi. <br><br><h3>  Instalar OpenVINO </h3><br>  No es la tarea m√°s dif√≠cil, aunque hay sutilezas.  Al momento de escribir esto, OpenVINO solo es compatible con Ubuntu 16.04 LTS, CentOS 7.4 y Windows 10. Tengo Ubuntu 18 y necesito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">peque√±as muletas</a> para instalarlo.  Tambi√©n quer√≠a comparar OpenVINO con NCSDK2, cuya instalaci√≥n tambi√©n tiene problemas: en particular, ajusta sus versiones de Caffe y TensorFlow y puede romper ligeramente la configuraci√≥n del entorno.  Al final, decid√≠ seguir un camino simple e instalar ambos marcos en una m√°quina virtual con Ubuntu 16 (uso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VirtualBox</a> ). <br><br>  Vale la pena se√±alar que para conectar con √©xito NCS a una m√°quina virtual, debe instalar complementos invitados VirtualBox y habilitar la compatibilidad con USB 3.0.  Tambi√©n agregu√© un filtro universal para dispositivos USB, como resultado de lo cual el NCS se conect√≥ sin problemas (aunque la c√°mara web todav√≠a tiene que estar conectada en la configuraci√≥n de la m√°quina virtual).  Para instalar y compilar OpenVINO, debe tener una cuenta Intel, elegir una opci√≥n de marco (con o sin soporte FPGA) y seguir las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">instrucciones</a> .  NCSDK es a√∫n m√°s simple: arranca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desde GitHub</a> (no olvide seleccionar la rama ncsdk2 para la nueva versi√≥n del marco), despu√©s de lo cual debe <code>make install</code> . <br><br>  El √∫nico problema que encontr√© al ejecutar NCSDK2 en una m√°quina virtual es un error de la siguiente forma: <br><br><pre> <code class="plaintext hljs">E: [ 0] dispatcherEventReceive:236 dispatcherEventReceive() Read failed -1 E: [ 0] eventReader:254 Failed to receive event, the device may have reset</code> </pre><br>  Ocurre al final de la ejecuci√≥n correcta del programa y (parece) no afecta nada.  Aparentemente, este es un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">peque√±o error relacionado con VM</a> (esto no deber√≠a estar en Raspberry). <br><br>  La instalaci√≥n en Raspberry Pi es significativamente diferente.  Primero, aseg√∫rese de tener Raspbian Stretch instalado: ambos marcos solo funcionan oficialmente en este sistema operativo.  NCSDK2 debe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">compilarse en modo solo API</a> , de lo contrario, intentar√° instalar Caffe y TensorFlow, lo que es poco probable que complazca a su Raspberry.  En el caso de OpenVINO, hay una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">versi√≥n</a> ya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ensamblada para Raspberry</a> , que solo necesita desempaquetar y configurar las variables de entorno.  En esta versi√≥n solo hay C ++ y Python API, as√≠ como la biblioteca OpenCV, todas las dem√°s herramientas no est√°n disponibles.  Esto significa que para ambos marcos, los modelos deben convertirse por adelantado en una m√°quina con Ubuntu.  Mi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">demostraci√≥n de detecci√≥n de rostros</a> funciona tanto en Raspberry como en el escritorio, por lo que acabo de agregar los archivos de red neuronal convertidos a mi repositorio de GitHub para facilitar la sincronizaci√≥n con Raspberry.  Tengo un Raspberry Pi 2 modelo B, pero deber√≠a despegar con otros modelos. <br><br>  Hay otra sutileza con respecto a la interacci√≥n de la Raspberry Pi y el Neural Compute Stick: si en el caso de una computadora port√°til es suficiente con meter el NCS en el puerto USB 3.0 m√°s cercano, entonces para Raspberry tendr√° que encontrar un cable USB, de lo contrario NSC bloquear√° los tres conectores USB restantes con su cuerpo.  Tambi√©n vale la pena recordar que Raspberry tiene todas las versiones de USB 2.0, por lo que la tasa de inferencia ser√° menor debido a retrasos en la comunicaci√≥n (una comparaci√≥n detallada ser√° m√°s adelante).  Pero si desea conectar dos o m√°s NCS a Raspberry, lo m√°s probable es que tenga que encontrar un concentrador USB con alimentaci√≥n adicional. <br><br><h3>  ¬øC√≥mo se ve el c√≥digo OpenVINO? </h3><br>  Bastante voluminoso.  Hay muchas acciones diferentes que hacer, comenzando con la carga del complemento y terminando con la inferencia misma; es por eso que escrib√≠ una clase de envoltura para el detector.  El c√≥digo completo se puede ver en GitHub, pero aqu√≠ solo enumero los puntos principales.  Comencemos en orden: <br><br>  Las definiciones de todas las funciones que necesitamos est√°n en el archivo <code>inference_engine.hpp</code> en el espacio de nombres <code>InferenceEngine</code> . <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;inference_engine.hpp&gt; using namespace InferenceEngine;</span></span></span></span></code> </pre><br>  Las siguientes variables ser√°n necesarias todo el tiempo.  necesitamos <code>inputName</code> y <code>outputName</code> para abordar la entrada y salida de la red neuronal.  En t√©rminos generales, una red neuronal puede tener muchas entradas y salidas, pero en nuestros detectores habr√° una a la vez.  La variable <code>net</code> es la red misma, la <code>request</code> es un puntero a la √∫ltima solicitud de inferencia, <code>inputBlob</code> es un puntero a la matriz de datos de entrada de la red neuronal.  Las variables restantes hablan por s√≠ mismas. <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">string</span></span> inputName; <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> outputName; ExecutableNetwork net; InferRequest::Ptr request; Blob::Ptr inputBlob; <span class="hljs-comment"><span class="hljs-comment">//input shape int netInputWidth; int netInputHeight; int netInputChannels; //output shape int maxNumDetectedFaces; //return code StatusCode ncsCode;</span></span></code> </pre><br>  Ahora descargue el complemento necesario: necesitamos el responsable de NCS y NCS2, se puede obtener con el nombre "MYRIAD".  Perm√≠tame recordarle que en el contexto de OpenVINO, un complemento es solo una biblioteca din√°mica que se conecta por solicitud expl√≠cita.  El par√°metro de la funci√≥n <code>PluginDispatcher</code> es una lista de directorios en los que buscar complementos.  Si configura las variables de entorno de acuerdo con las instrucciones, una l√≠nea vac√≠a ser√° suficiente.  Como referencia, los complementos est√°n en <code>[OpenVINO_install_dir]/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/</code> <br><br><pre> <code class="cpp hljs">InferencePlugin plugin = PluginDispatcher({<span class="hljs-string"><span class="hljs-string">""</span></span>}).getPluginByDevice(<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>);</code> </pre><br>  Ahora cree un objeto para cargar la red neuronal, considere su descripci√≥n y configure el tama√±o del lote (el n√∫mero de im√°genes procesadas simult√°neamente).  Una red neuronal en el formato OpenVINO est√° definida por dos archivos: un .xml con una descripci√≥n de la estructura y un .bin con pesos.  Si bien utilizaremos detectores listos para usar de OpenVINO, luego crearemos el nuestro.  Aqu√≠ <code>std::string filename</code> es el nombre del archivo sin la extensi√≥n.  Tambi√©n debe tener en cuenta que el NCS solo admite un tama√±o de lote de 1. <br><br><pre> <code class="cpp hljs">CNNNetReader netReader; netReader.ReadNetwork(filename+<span class="hljs-string"><span class="hljs-string">".xml"</span></span>); netReader.ReadWeights(filename+<span class="hljs-string"><span class="hljs-string">".bin"</span></span>); netReader.getNetwork().setBatchSize(<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br>  Entonces sucede lo siguiente: <br><br><ol><li>  Para ingresar a la red neuronal, establezca el tipo de datos en char sin firmar de 8 bits.  Esto significa que podemos ingresar la imagen en el formato en que proviene de la c√°mara, e InferenceEngine se encargar√° de la conversi√≥n (NCS realiza c√°lculos en formato flotante de 16 bits).  Esto se acelerar√° un poco en la Raspberry Pi; seg√∫n tengo entendido, la conversi√≥n se realiza en el NCS, por lo que hay menos retrasos en la transferencia de datos a trav√©s de USB. </li><li>  Obtenemos los nombres de entrada y salida, para que luego podamos acceder a ellos. </li><li>  Obtenemos la descripci√≥n de las salidas (este es un mapa del nombre de la salida a un puntero a un bloque de datos).  Obtenemos un puntero al bloque de datos de la primera salida (√∫nica). </li><li>  Obtenemos su tama√±o: 1 x 1 x n√∫mero m√°ximo de detecciones x longitud de la descripci√≥n de la detecci√≥n (7).  Sobre el formato de la descripci√≥n de detecciones - m√°s adelante. </li><li>  Establezca el formato de salida en flotante de 32 bits.  Nuevamente, la conversi√≥n de flotante de 16 bits se encarga de InferenceEngine. </li></ol><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//we can set input type to unsigned char: conversion will be performed on device netReader.getNetwork().getInputsInfo().begin()-&gt;second-&gt;setPrecision(Precision::U8); //get input and output names and their info structures inputName = netReader.getNetwork().getInputsInfo().begin()-&gt;first; outputName = netReader.getNetwork().getOutputsInfo().begin()-&gt;first; OutputsDataMap outputInfo(netReader.getNetwork().getOutputsInfo()); InputsDataMap inputInfo(netReader.getNetwork().getInputsInfo()); DataPtr &amp;outputData = (outputInfo.begin()-&gt;second); //get output shape: (1 x 1 x maxNumDetectedFaces x faceDescriptionLength(7)) const SizeVector outputDims = outputData-&gt;getTensorDesc().getDims(); maxNumDetectedFaces = outputDims[2]; //set input type to float32: calculations are all in float16, conversion is performed on device outputData-&gt;setPrecision(Precision::FP32);</span></span></code> </pre><br>  Ahora el punto m√°s importante: cargamos la red neuronal en el complemento (es decir, en NCS).  Aparentemente, la compilaci√≥n al formato deseado est√° sobre la marcha.  Si el programa falla en esta funci√≥n, la red neuronal probablemente no sea adecuada para este dispositivo. <br><br><pre> <code class="cpp hljs">net = plugin.LoadNetwork(netReader.getNetwork(), {});</code> </pre><br>  Y finalmente, haremos una inferencia de prueba y obtendremos los tama√±os de entrada (tal vez esto se puede hacer de manera m√°s elegante).  Primero, abrimos una solicitud de inferencia, luego de ella obtenemos un enlace al bloque de datos de entrada, y ya le solicitamos el tama√±o. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//perform single inference to get input shape (a hack) request = net.CreateInferRequestPtr(); //open inference request //we need the blob size: (batch(1) x channels(3) x H x W) inputBlob = request-&gt;GetBlob(inputName); SizeVector blobSize = inputBlob-&gt;getTensorDesc().getDims(); netInputWidth = blobSize[3]; netInputHeight = blobSize[2]; netInputChannels = blobSize[1]; request-&gt;Infer(); //close request</span></span></code> </pre><br>  Intentemos subir una imagen a NCS.  De la misma manera, creamos una solicitud de inferencia, obtenemos un puntero a un bloque de datos, y desde all√≠ obtenemos un puntero a la matriz en s√≠.  A continuaci√≥n, simplemente copie los datos de nuestra imagen (aqu√≠ ya est√° reducida al tama√±o deseado).  Vale la pena se√±alar que en <code>cv::Mat</code> y <code>inputBlob</code> mediciones se almacenan en diferente orden (en OpenCV, el √≠ndice del canal cambia m√°s r√°pido que todos, en OpenVINO es m√°s lento que todos), por lo que memcpy es indispensable.  Entonces comenzamos la inferencia asincr√≥nica. <br><br>  ¬øPor qu√© as√≠ncrono?  Esto optimizar√° la asignaci√≥n de recursos.  Si bien el NCS considera la red neuronal, puede procesar el siguiente marco, lo que conducir√° a una aceleraci√≥n notable en la Raspberry Pi. <br><br><pre> <code class="cpp hljs">cv::Mat data; ... <span class="hljs-comment"><span class="hljs-comment">//get image somehow //create request, get data blob request = net.CreateInferRequestPtr(); inputBlob = request-&gt;GetBlob(inputName); unsigned char* blobData = inputBlob-&gt;buffer().as&lt;unsigned char*&gt;(); //copy from resized frame to network input int wh = netInputHeight*netInputWidth; for (int c = 0; c &lt; netInputChannels; c++) for (int h = 0; h &lt; wh; h++) blobData[c * wh + h] = data.data[netInputChannels*h + c]; //start asynchronous inference request-&gt;StartAsync();</span></span></code> </pre><br>  Si conoce bien las redes neuronales, es posible que tenga una pregunta sobre en qu√© punto escalamos los valores de los p√≠xeles de entrada de la red neuronal (por ejemplo, lo llevamos al rango <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> [0,1] </script>  )  El hecho es que en los modelos OpenVINO esta transformaci√≥n ya est√° incluida en la descripci√≥n de la red neuronal, y cuando usamos nuestro detector haremos algo similar.  Y dado que tanto la conversi√≥n a flotante como la escala de entradas son realizadas por OpenVINO, solo necesitamos cambiar el tama√±o de la imagen. <br><br>  Ahora (despu√©s de hacer un trabajo √∫til) completaremos la solicitud de inferencia.  El programa est√° bloqueado hasta que lleguen los resultados de la ejecuci√≥n.  Obtenemos un puntero al resultado. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> * output; ncsCode = request-&gt;Wait(IInferRequest::WaitMode::RESULT_READY); output = request-&gt;GetBlob(outputName)-&gt;buffer().as&lt;<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*&gt;();</code> </pre><br>  Ahora es el momento de pensar en qu√© formato el NCS devuelve el resultado del detector.  Vale la pena se√±alar que el formato es ligeramente diferente de lo que era cuando se usa NCSDK.  En t√©rminos generales, la salida del detector es de cuatro dimensiones y tiene una dimensi√≥n (1 x 1 x n√∫mero m√°ximo de detecciones x 7), podemos suponer que se trata de una matriz de tama√±o ( <code>maxNumDetectedFaces</code> x 7). <br><br>  El par√°metro <code>maxNumDetectedFaces</code> se establece en la descripci√≥n de la red neuronal, y es f√°cil cambiarlo, por ejemplo, en la descripci√≥n .prototxt de la red en formato Caffe.  Anteriormente lo obtuvimos del objeto que representa el detector.  Este par√°metro est√° relacionado con los detalles de la clase de detectores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SSD (Single Shot Detector)</a> , que incluye todos los detectores NCS compatibles.  Un SSD siempre considera el mismo (y muy grande) n√∫mero de cuadros delimitadores para cada imagen, y despu√©s de filtrar las detecciones con una baja calificaci√≥n de confianza y eliminar los marcos superpuestos utilizando la supresi√≥n no m√°xima, generalmente dejan el mejor 100-200.  Esto es precisamente de lo que es responsable el par√°metro. <br><br>  Los siete valores en la descripci√≥n de una detecci√≥n son los siguientes: <br><br><ol><li>  el n√∫mero de imagen en el lote en el que se detecta el objeto (en nuestro caso, deber√≠a ser cero); </li><li>  clase de objeto (0 - fondo, a partir de 1 - otras clases, solo se devuelven detecciones con una clase positiva); </li><li>  confianza en presencia de detecci√≥n (en el rango <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> [0,1] </script>  ); </li><li>  Coordenada x normalizada de la esquina superior izquierda del cuadro delimitador (en el rango <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> [0,1] </script>  ); </li><li>  de manera similar - coordenada y; </li><li>  ancho del cuadro delimitador normalizado (en el rango <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-4"> [0,1] </script>  ); </li><li>  igualmente - altura; </li></ol><br><div class="spoiler">  <b class="spoiler_title">C√≥digo para extraer cuadros delimitadores de la salida del detector</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_detection_boxes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">* predictions, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> numPred, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> w, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> h, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> thresh, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt;&amp; probs, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;cv::Rect&gt;&amp; boxes)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> score = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cls = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> id = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//predictions holds numPred*7 values //data format: image_id, detection_class, detection_confidence, //box_normed_x, box_normed_y, box_normed_w, box_normed_h for (int i=0; i&lt;numPred; i++) { score = predictions[i*7+2]; cls = predictions[i*7+1]; id = predictions[i*7 ]; if (id&gt;=0 &amp;&amp; score&gt;thresh &amp;&amp; cls&lt;=1) { probs.push_back(score); boxes.push_back(Rect(predictions[i*7+3]*w, predictions[i*7+4]*h, (predictions[i*7+5]-predictions[i*7+3])*w, (predictions[i*7+6]-predictions[i*7+4])*h)); } } }</span></span></code> </pre><br>  aprendemos <code>numPred</code> del detector en s√≠, y <code>w,h</code> - tama√±os de imagen para visualizaci√≥n. <br></div></div><br>  Ahora sobre c√≥mo se ve el esquema general de inferencia en tiempo real.  Primero inicializamos la red neuronal y la c√°mara, iniciamos <code>cv::Mat</code> para cuadros en bruto y uno m√°s para cuadros reducidos al tama√±o deseado.  Llenamos nuestros cuadros con ceros; esto agregar√° confianza de que en un solo inicio la red neuronal no encontrar√° nada.  Luego comenzamos el ciclo de inferencia: <br><br><ul><li>  Cargamos la trama actual en la red neuronal mediante una solicitud asincr√≥nica: NCS ya ha comenzado a funcionar, y en este momento tenemos la oportunidad de hacer que el procesador principal funcione de manera √∫til. </li><li>  Mostramos todas las detecciones anteriores en el cuadro anterior, dibujamos un cuadro (si es necesario). </li><li>  Obtenemos un nuevo marco de la c√°mara, lo comprimimos al tama√±o deseado.  Para Raspberry, recomiendo usar el algoritmo de cambio de tama√±o m√°s simple: en OpenCV, esta es la interpolaci√≥n de vecinos m√°s cercanos.  Esto no afectar√° la calidad del rendimiento del detector, pero puede agregar un poco de velocidad.  Tambi√©n reflejo el marco para una f√°cil visualizaci√≥n (opcional). </li><li>  Ahora es el momento de obtener el resultado con NCS completando la solicitud de inferencia.  El programa se bloquear√° hasta que se reciba el resultado. </li><li>  Procesamos nuevas detecciones, seleccionamos fotogramas. </li><li>  El resto: trabajar pulsaciones de teclas, contar cuadros, etc. </li></ul><br><h3>  C√≥mo compilarlo </h3><br>  En los ejemplos de InferenceEngine, no me gustaron los voluminosos archivos CMake, y decid√≠ reescribir todo de manera compacta en mi Makefile: <br><br><pre> <code class="bash hljs">g++ $(RPI_ARCH) \ -I/usr/include -I. \ -I$(OPENVINO_PATH)/deployment_tools/inference_engine/include \ -I$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/include \ -L/usr/lib/x86_64-linux-gnu \ -L/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/lib \ -L$(OPENVINO_PATH)/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 \ -L$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/lib/raspbian_9/armv7l \ vino.cpp wrapper/vino_wrapper.cpp \ -o demo -std=c++11 \ `pkg-config opencv --cflags --libs` \ -ldl -linference_engine $(RPI_LIBS)</code> </pre><br>  Este equipo trabajar√° tanto en Ubuntu como en Raspbian, gracias a un par de trucos.  Las rutas para buscar encabezados y bibliotecas din√°micas que he indicado tanto para Raspberry como para la m√°quina Ubuntu.  De las bibliotecas, adem√°s de OpenCV, tambi√©n debe conectar <code>libinference_engine</code> y <code>libdl</code> , una biblioteca para vincular din√°micamente otras bibliotecas, es necesaria para cargar el complemento.  Al mismo tiempo, <code>libmyriadPlugin</code> no necesita ser especificado.  Entre otras cosas, para Raspberry tambi√©n conecto la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Raspicam</a> para trabajar con la c√°mara (esto es <code>$(RPI_LIBS)</code> ).  Tambi√©n tuve que usar el est√°ndar C ++ 11. <br><br>  Por separado, vale la pena se√±alar que al compilar en Raspberry, se necesita la <code>-march=armv7-a</code> (esto es <code>$(RPI_ARCH)</code> ).  Si no lo especifica, el programa se compilar√°, pero se bloquear√° con un segfault silencioso.  Tambi√©n puede agregar optimizaciones usando <code>-O3</code> , esto agregar√° velocidad. <br><br><h3>  ¬øQu√© son los detectores? </h3><br>  NCS solo admite detectores SSD Caffe de la caja, aunque con un par de trucos sucios logr√© ejecutar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">YOLO desde el formato Darknet</a> en √©l.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Single Shot Detector (SSD)</a> es una arquitectura popular entre las redes neuronales livianas, y con la ayuda de diferentes codificadores (o redes troncales) puede variar con bastante flexibilidad la relaci√≥n de velocidad y calidad. <br><br>  Experimentar√© con diferentes detectores faciales: <br><br><ul><li>  YOLO, tomado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de aqu√≠</a> , convertido primero al formato Caffe, luego al formato NCS (solo con NCSDK).  Imagen 448 x 448. </li><li>  Mi detector <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mobilenet</a> + SSD, sobre el entrenamiento del que habl√© en una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaci√≥n anterior</a> .  Todav√≠a tengo una versi√≥n recortada de este detector, que solo ve caras peque√±as, y al mismo tiempo un poco m√°s r√°pido.  Comprobar√© la versi√≥n completa de mi detector tanto en NCSDK como en OpenVINO.  Imagen 300 x 300. </li><li>  Detector de detecci√≥n de rostros-adas-0001 de OpenVINO: MobileNet + SSD.  Imagen 384 x 672. </li><li>  Detector OpenVINO de detecci√≥n de rostros-retail-0004: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SqueezeNet</a> + SSD liviano.  Imagen 300 x 300. </li></ul><br>  Para los detectores de OpenVINO, no hay escalas ni en el formato Caffe ni en el formato NCSDK, por lo que solo puedo iniciarlos en OpenVINO. <br><br><h3>  Transforme su detector en formato OpenVINO </h3><br>  Tengo dos archivos en formato Caffe: .prototxt con una descripci√≥n de la red y .caffemodel con pesos.  Necesito obtener dos archivos de ellos en el formato OpenVINO: .xml y .bin con una descripci√≥n y pesos, respectivamente.  Para hacer esto, use el script mo.py de OpenVINO (tambi√©n conocido como Model Optimizer): <br><br><pre> <code class="bash hljs">mo.py \ --framework caffe \ --input_proto models/face/ssd-face.prototxt \ --input_model models/face/ssd-face.caffemodel \ --output_dir models/face \ --model_name ssd-vino-custom \ --mean_values [127.5,127.5,127.5] \ --scale_values [127.5,127.5,127.5] \ --data_type FP16</code> </pre><br>  <code>output_dir</code> especifica el directorio en el que se crear√°n los archivos nuevos, <code>model_name</code> es el nombre de los archivos nuevos sin extensi√≥n, <code>data_type (FP16/FP32)</code> es el tipo de equilibrio en la red neuronal (NCS solo admite FP16).  Los <code>mean_values, scale_values</code> establecen el promedio y la escala para preprocesar las im√°genes antes de que se inicien en la red neuronal.  La conversi√≥n espec√≠fica se ve as√≠: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><msub><mtext>&amp;#xA0;</mtext><mi>v</mi></msub><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo>&amp;#x200B;</mo><mo>&amp;#x200B;</mo><mo>&amp;#x2212;</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><msub><mtext>&amp;#xA0;</mtext><mi>v</mi></msub><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo stretchy=&quot;false&quot;>)</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>/</mo></mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><msub><mtext>&amp;#xA0;</mtext><mi>v</mi></msub><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo>&amp;#x200B;</mo><mo>&amp;#x200B;</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="42.983ex" height="2.66ex" viewBox="0 -832 18506.4 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-28" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-70" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-69" x="893" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-78" x="1238" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-65" x="1811" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6C" x="2277" y="0"></use><g transform="translate(2576,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-76" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-61" x="3269" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6C" x="3798" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-75" x="4097" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-65" x="4669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-73" x="5136" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2212" x="5939" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6D" x="6717" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-65" x="7596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-61" x="8062" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6E" x="8592" y="0"></use><g transform="translate(9192,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-76" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-61" x="9885" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6C" x="10415" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-75" x="10713" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-65" x="11286" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-73" x="11752" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-29" x="12222" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2F" x="12611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-73" x="13112" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-63" x="13581" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-61" x="14015" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6C" x="14544" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-65" x="14843" y="0"></use><g transform="translate(15309,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-76" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-61" x="16003" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-6C" x="16532" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-75" x="16831" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-65" x="17403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMATHI-73" x="17870" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mo stretchy="false">(</mo><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><msub><mtext>&nbsp;</mtext><mi>v</mi></msub><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo>‚Äã</mo><mo>‚Äã</mo><mo>‚àí</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><msub><mtext>&nbsp;</mtext><mi>v</mi></msub><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><msub><mtext>&nbsp;</mtext><mi>v</mi></msub><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo>‚Äã</mo><mo>‚Äã</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> (pixel \ _values ‚Äã‚Äã- mean \ _values) / scale \ _values ‚Äã‚Äã</script></p><br><br>  En este caso, los valores se convierten del rango <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0.255</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.59ex" height="2.66ex" viewBox="0 -832 2837.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5B" x="0" y="0"></use><g transform="translate(278,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-30"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2E" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-32" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-35" x="1279" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-35" x="1780" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5D" x="2559" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0.255</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-6"> [0.255] </script>  en rango <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhg1Zpd46owe7TpHDBQ13RqdQyJt4g#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-7"> [0,1] </script>  .  En general, este script tiene muchos par√°metros, algunos de los cuales son espec√≠ficos de marcos individuales, le recomiendo que consulte el manual del script. <br><br>  La distribuci√≥n OpenVINO para Raspberry no tiene modelos listos, pero son bastante f√°ciles de descargar. <br><br><div class="spoiler">  <b class="spoiler_title">Por ejemplo, as√≠.</b> <div class="spoiler_text"><pre> <code class="bash hljs"> wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.xml \ -O ./models/face/vino.xml; \ wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.bin \ -O ./models/face/vino.bin</code> </pre><br></div></div><br><h3>  Comparaci√≥n de detectores y marcos </h3><br>  Utilic√© tres opciones de comparaci√≥n: 1) M√°quina virtual NCS + con Ubuntu 16.04, procesador Core i7, conector USB 3.0;  2) NCS + La misma m√°quina, conector USB 3.0 + cable USB 2.0 (habr√° m√°s demoras en el intercambio con el dispositivo);  3) NCS + Raspberry Pi 2 modelo B, Raspbian Stretch, conector USB 2.0 + cable USB 2.0. <br><br>  Comenc√© mi detector con OpenVINO y NCSDK2, detectores de OpenVINO solo con su marco nativo, YOLO solo con NCSDK2 (lo m√°s probable, tambi√©n se puede ejecutar en OpenVINO). <br><br>  La tabla FPS para diferentes detectores se ve as√≠ (los n√∫meros son aproximados): <br><br><table><tbody><tr><th>  Modelo </th><th>  USB 3.0 </th><th>  USB 2.0 </th><th>  Raspberry pi </th></tr><tr><td>  SSD personalizado con NCSDK2 </td><td>  10,8 </td><td>  9.3 </td><td>  7.2 </td></tr><tr><td>  SSD longrange personalizado con NCSDK2 </td><td>  11,8 </td><td>  10,0 </td><td>  7.3 </td></tr><tr><td>  YOLO v2 con NCSDK2 </td><td>  5.3 </td><td>  4.6 </td><td>  3.6 </td></tr><tr><td>  SSD personalizado con OpenVINO </td><td>  10,6 </td><td>  9,9 </td><td>  7,9 </td></tr><tr><td>  OpenVINO detecci√≥n de rostros-retail-0004 </td><td>  15,6 </td><td>  14,2 </td><td>  9.3 </td></tr><tr><td>  OpenVINO detecci√≥n de rostros-adas-0001 </td><td>  5.8 </td><td>  5.5 </td><td>  3.9 </td></tr></tbody></table><br><br>  <em>Nota: el rendimiento se midi√≥ para todo el programa de demostraci√≥n, incluido el procesamiento y la visualizaci√≥n de fotogramas.</em> <br><br>  YOLO fue el m√°s lento e inestable de todos.  Muy a menudo omite la detecci√≥n y no puede funcionar con marcos iluminados. <br><br>  El detector que entren√© funciona dos veces m√°s r√°pido, es m√°s resistente a la distorsi√≥n en los cuadros e incluso detecta rostros peque√±os.  Sin embargo, a veces omite la detecci√≥n y a veces detecta falsos.  Si le cortas las √∫ltimas capas, se volver√° un poco m√°s r√°pido, pero dejar√° de ver caras grandes.  El mismo detector lanzado a trav√©s de OpenVINO se vuelve un poco m√°s r√°pido cuando se usa USB 2.0, la calidad no cambia visualmente. <br><br>  Los detectores OpenVINO, por supuesto, son muy superiores tanto a YOLO como a mi detector.  (Ni siquiera comenzar√≠a a entrenar mi detector si OpenVINO existiera en su forma actual en ese momento).  El modelo retail-0004 es significativamente m√°s r√°pido y, al mismo tiempo, pr√°cticamente no pierde la cara, pero logr√© enga√±arlo un poco (aunque la confianza en estas detecciones es baja): <br><br><img src="https://habrastorage.org/webt/uj/ap/nl/ujapnlbjzkipljlzklgyvjzked4.png"><br>  <em>Ataque competitivo de inteligencia natural sobre artificial</em> <br><br>  El detector adas-0001 es mucho m√°s lento, pero funciona con im√°genes grandes y deber√≠a ser m√°s preciso.  No not√© la diferencia, pero revis√© cuadros bastante simples. <br><br><h4>  Conclusi√≥n </h4><br>  En general, es muy bueno que en un dispositivo de baja potencia como el Raspberry Pi pueda usar redes neuronales, e incluso en tiempo casi real.  OpenVINO proporciona una funcionalidad muy extensa para la inferencia de redes neuronales en muchos dispositivos diferentes, mucho m√°s amplio de lo que describ√≠ en el art√≠culo.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Creo que Neural Compute Stick y OpenVINO ser√°n muy √∫tiles en mi investigaci√≥n rob√≥tica. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436744/">https://habr.com/ru/post/es436744/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436724/index.html">Creando productos que crean h√°bitos</a></li>
<li><a href="../es436728/index.html">Gu√≠a de ML.NET: primera aplicaci√≥n en 10 minutos</a></li>
<li><a href="../es436730/index.html">Sal√≥n de la fama de la electr√≥nica de consumo: las historias de los mejores artilugios de los √∫ltimos 50 a√±os, parte 5</a></li>
<li><a href="../es436740/index.html">Investigaci√≥n propia, ¬øqu√© nos pueden decir las fuentes abiertas?</a></li>
<li><a href="../es436742/index.html">Android Robotics hasta 2019: la historia real; en 5 partes; parte 1</a></li>
<li><a href="../es436746/index.html">C√≥mo degradar el rendimiento al mejorarlo</a></li>
<li><a href="../es436748/index.html">Desarrollar hexapod desde cero (parte 3) - cinem√°tica</a></li>
<li><a href="../es436750/index.html">An√°lisis de tendencias de YouTube ruso para 2018</a></li>
<li><a href="../es436752/index.html">El pastel es una mentira</a></li>
<li><a href="../es436754/index.html">Q2VKPT: Quake II completamente reescrito con iluminaci√≥n realista</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
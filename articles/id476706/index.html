<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✍🏼 📮 👨🏿‍🎨 Sistem Cerebras memperkenalkan komputer dengan prosesor terbesar di dunia 22 × 22 sentimeter 🔻 🤺 🐞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Diagram komputer CS-1 menunjukkan bahwa sebagian besar didedikasikan untuk menyalakan dan mendinginkan Mesin Skala Wafer "prosesor-di-pelat" raksasa (...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sistem Cerebras memperkenalkan komputer dengan prosesor terbesar di dunia 22 × 22 sentimeter</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dcmiran/blog/476706/"><img src="https://habrastorage.org/getpro/habr/post_images/43e/87f/2b3/43e87f2b3b76001e51387e09935558ba.jpg"><br>  <i><font color="gray">Diagram komputer CS-1 menunjukkan bahwa sebagian besar didedikasikan untuk menyalakan dan mendinginkan Mesin Skala Wafer "prosesor-di-pelat" raksasa (WSE).</font></i>  <i><font color="gray">Foto: Sistem Cerebras</font></i> <br><br>  Pada Agustus 2019, Cerebras Systems dan mitra pabrikannya TSMC mengumumkan <a href="https://habr.com/ru/news/t/464271/">chip terbesar dalam sejarah teknologi komputer</a> .  Dengan luas 46.225 mm² dan 1,2 triliun transistor, chip Wafer Scale Engine (WSE) kira-kira 56,7 kali lebih besar dari GPU terbesar (21,1 miliar transistor, 815 mm²). <br><br>  Skeptis mengatakan bahwa mengembangkan prosesor bukanlah tugas yang paling sulit.  Tapi di sini bagaimana cara kerjanya di komputer sungguhan?  Berapa persentase pekerjaan yang rusak?  Apa daya dan pendinginan yang dibutuhkan?  Berapa biaya mesin seperti itu? <br><br>  Tampaknya para insinyur di Cerebras Systems dan TSMC mampu menyelesaikan masalah ini.  Pada 18 November 2019, pada konferensi <a href="https://sc19.supercomputing.org/">Supercomputing 2019</a> , mereka secara resmi meluncurkan <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">CS-1</a> , "komputer tercepat di dunia untuk komputasi dalam bidang pembelajaran mesin dan kecerdasan buatan." <br><a name="habracut"></a><br>  Salinan pertama CS-1 telah dikirim ke pelanggan.  Salah satunya dipasang di Laboratorium Nasional Argonne dari Departemen Energi AS, yang mana perakitan superkomputer paling kuat di AS dari <a href="https://habr.com/ru/company/dcmiran/blog/476378/">modul Aurora pada arsitektur GPU Intel baru</a> akan dimulai.  Pelanggan lain adalah Laboratorium Nasional Livermore. <br><br>  Prosesor dengan 400.000 core dirancang untuk pusat data untuk memproses komputasi di bidang pembelajaran mesin dan kecerdasan buatan.  Cerebras mengklaim bahwa komputer melatih sistem AI berdasarkan pesanan yang lebih efisien daripada peralatan yang ada.  Performa CS-1 setara dengan "ratusan server berbasis GPU" yang menghabiskan ratusan kilowatt.  Pada saat yang sama, hanya menempati 15 unit di rak server dan mengkonsumsi sekitar 17 kW. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfc/5aa/1da/cfc5aa1da0e52944fc1b68e4fca15146.jpg"><br>  <i><font color="gray">Prosesor WSE.</font></i>  <i><font color="gray">Foto: Sistem Cerebras</font></i> <br><br>  Andrew Feldman, CEO dan salah satu pendiri Cerebras Systems, mengatakan CS-1 adalah "komputer AI tercepat di dunia."  Dia membandingkannya dengan kluster TPU Google dan mencatat bahwa masing-masing dari mereka "mengambil 10 rak dan mengkonsumsi lebih dari 100 kilowatt untuk menyediakan sepertiga dari kinerja instalasi CS-1 tunggal." <br><br><img src="https://habrastorage.org/getpro/habr/post_images/523/1d3/b60/5231d3b60c445d641bb654d29b8fec21.jpg"><br>  <i><font color="gray">Komputer CS-1.</font></i>  <i><font color="gray">Foto: Sistem Cerebras</font></i> <br><br>  Belajar jaringan saraf besar dapat memakan waktu berminggu-minggu di komputer standar.  Menginstal CS-1 dengan chip prosesor 400.000 core dan 1,2 triliun transistor melakukan tugas ini dalam hitungan menit atau bahkan detik, <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/cerebras-unveils-ai-supercomputer-argonne-national-lab-first-installation">tulis</a> IEEE Spectrum.  Namun, Cerebras tidak memberikan hasil tes nyata untuk menguji pernyataan kinerja tinggi seperti <a href="https://mlperf.org/training-results-0-6">tes MLPerf</a> .  Sebagai gantinya, perusahaan secara langsung menjalin kontak dengan pelanggan potensial - dan diizinkan untuk melatih model jaringan sarafnya sendiri pada CS-1. <br><br>  Pendekatan ini tidak biasa, analis mengatakan: "Semua orang mengelola model mereka sendiri yang telah mereka kembangkan untuk bisnis mereka sendiri," kata <a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a> , seorang analis kecerdasan buatan di Moor Insights &amp; Strategies.  "Ini adalah satu-satunya hal yang penting bagi pelanggan." <br><br>  Banyak perusahaan sedang mengembangkan chip khusus untuk AI, termasuk perwakilan industri tradisional seperti Intel, Qualcomm, serta berbagai startup di AS, Inggris dan Cina.  Google telah mengembangkan chip khusus untuk jaringan saraf - prosesor tensor, atau TPU.  Beberapa pabrikan lain mengikuti.  Sistem AI beroperasi dalam mode multi-threaded, dan hambatannya adalah memindahkan data di antara chip: "Menghubungkan chip sebenarnya memperlambatnya dan membutuhkan banyak energi," <a href="https://www.nytimes.com/2019/08/19/technology/artificial-intelligence-chip-cerebras.html">jelas</a> Subramanian Iyer, seorang profesor di University of California di Los Angeles yang berspesialisasi dalam mengembangkan chip untuk kecerdasan buatan.  Pabrikan peralatan mengeksplorasi banyak opsi berbeda.  Beberapa berusaha untuk memperluas koneksi antarproses. <br><br>  Didirikan tiga tahun lalu, startup Cerebras, yang menerima lebih dari $ 200 juta dalam pembiayaan ventura, telah mengusulkan pendekatan baru.  Idenya adalah untuk menyimpan semua data pada chip raksasa - dan dengan demikian mempercepat perhitungan. <br><br><img src="https://habrastorage.org/webt/up/k1/ej/upk1ejv8zsqxtj9nadanm8898zc.jpeg"><br><br>  Seluruh pelat sirkuit mikro dibagi menjadi 400.000 bagian yang lebih kecil (inti), mengingat beberapa di antaranya tidak akan berfungsi.  Chip ini dirancang dengan kemampuan untuk rute di sekitar area yang rusak.  Kernel yang dapat diprogram SLAC (Sparse Linear Algebra Cores) dioptimalkan untuk aljabar linier, yaitu untuk perhitungan dalam ruang vektor.  Perusahaan juga mengembangkan teknologi “sparsity harvesting” untuk meningkatkan kinerja komputasi di bawah beban kerja yang jarang (mengandung nol), seperti pembelajaran yang mendalam.  Vektor dan matriks dalam ruang vektor biasanya mengandung banyak elemen nol (dari 50% hingga 98%), sehingga pada GPU tradisional, sebagian besar perhitungan terbuang sia-sia.  Sebaliknya, SLAC core pra-filter data nol. <br><br>  Komunikasi antar core disediakan oleh sistem Swarm dengan throughput 100 petabit per detik.  Perutean perangkat keras, latensi diukur dalam nanodetik. <br><br>  Biaya komputer tidak disebut.  Pakar independen percaya bahwa harga sebenarnya tergantung pada persentase pernikahan.  Juga, kinerja chip dan berapa core yang beroperasi dalam sampel nyata tidak dapat dipercaya. <br><br><h1>  Perangkat lunak </h1><br>  Cerebras telah mengumumkan beberapa detail tentang bagian perangkat lunak dari sistem CS-1.  Perangkat lunak ini memungkinkan pengguna untuk membuat model pembelajaran mesin mereka sendiri menggunakan kerangka kerja standar seperti <a href="https://pytorch.org/">PyTorch</a> dan <a href="https://www.tensorflow.org/">TensorFlow</a> .  Sistem kemudian mendistribusikan 400.000 core dan 18 gigabyte memori SRAM pada chip ke lapisan jaringan saraf sehingga semua lapisan menyelesaikan pekerjaan mereka pada waktu yang sama dengan tetangga mereka (tugas optimasi).  Akibatnya, informasi diproses oleh semua lapisan tanpa penundaan.  Dengan subsistem I / O Ethernet 100-Gigabit 12-port, CS-1 dapat memproses data 1,2 terabit per detik. <br><br>  Konversi dari jaringan saraf sumber ke representasi yang dapat dieksekusi yang dioptimalkan (Representasi Intermediate Aljabar Linear Cerebras, CLAIR) dilakukan oleh Cerebras Graph Compiler (CGC).  Kompiler mengalokasikan sumber daya komputasi dan memori untuk setiap bagian grafik, dan kemudian membandingkannya dengan array komputasi.  Kemudian, jalur komunikasi dihitung sesuai dengan struktur internal pelat, unik untuk setiap jaringan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/098/093/569/098093569a8dca7e8dea9e26fc63a81a.jpg"><br>  <i><font color="gray">Distribusi operasi matematika dari jaringan saraf oleh inti prosesor.</font></i>  <i><font color="gray"><a href="https://fortune.com/2019/11/19/artificial-intelligence-cerebras-supercomputer/">Foto</a> : Cerebras</font></i> <br><br>  Karena ukuran besar WSE, semua lapisan dalam jaringan saraf secara bersamaan terletak di atasnya dan bekerja secara paralel.  Pendekatan ini unik untuk WSE - tidak ada perangkat lain yang memiliki memori internal yang cukup untuk memuat semua lapisan pada satu chip sekaligus, kata Cerebras.  Arsitektur seperti itu dengan penempatan seluruh jaringan saraf pada sebuah chip memberikan keuntungan besar karena throughputnya yang tinggi dan latensi yang rendah. <br><br>  Perangkat lunak ini dapat melakukan tugas pengoptimalan untuk banyak komputer, memungkinkan sekelompok komputer untuk bertindak sebagai satu mesin besar.  Sekelompok komputer 32 CS-1 menunjukkan peningkatan kinerja sekitar 32 kali lipat, yang menunjukkan skalabilitas yang sangat baik.  Feldman mengatakan ini berbeda dari cluster berbasis GPU: “Hari ini, ketika Anda membuat sekelompok GPU, itu tidak berperilaku seperti satu mesin besar.  Anda mendapatkan banyak mobil kecil. " <br><br>  <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">Siaran pers</a> mengatakan bahwa Laboratorium Nasional Argonne telah bekerja dengan Cerebras selama dua tahun: "Dengan menggunakan CS-1, kami secara dramatis meningkatkan kecepatan pelatihan jaringan saraf, yang memungkinkan kami untuk meningkatkan produktivitas penelitian kami dan mencapai kesuksesan yang signifikan." <br><br>  Salah satu beban pertama untuk CS-1 adalah <a href="https://arxiv.org/abs/1903.01998">simulasi jaringan saraf dari tabrakan lubang hitam</a> dan gelombang gravitasi, yang dibuat sebagai hasil dari tabrakan ini.  Versi sebelumnya dari tugas ini bekerja pada 1024 dari 4392 node superkomputer <a href="https://www.alcf.anl.gov/theta">Theta</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id476706/">https://habr.com/ru/post/id476706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id476696/index.html">Cara membuat dan menyebarkan Full-Stack Bereaksi-aplikasi</a></li>
<li><a href="../id476698/index.html">Bagaimana Apple Membunuh Teknologi Web</a></li>
<li><a href="../id476700/index.html">Mes dalam produksi radiator baja</a></li>
<li><a href="../id476702/index.html">Bagaimana sebuah kota kecil di pedalaman berubah menjadi pusat perdagangan elektronik internasional</a></li>
<li><a href="../id476704/index.html">Cara mengotomatiskan tata letak email dengan jenis elemen yang sama: kami menggunakan objek pintar</a></li>
<li><a href="../id476708/index.html">Dasar Slurm di Moskow. Hari Ketiga Koleksi kontra intelijen dan cluster, terbang Pavel Selivanov dan "Slurm Inspires!"</a></li>
<li><a href="../id476710/index.html">Pendaftaran terbuka: Deep Dive ke IT at Mars</a></li>
<li><a href="../id476712/index.html">Layanan untuk pertemuan acak dengan orang asing, tetapi tidak berkencan. Sejarah startup kopi acak</a></li>
<li><a href="../id476714/index.html">Pengoperasian pembelajaran mesin di Mail.ru Mail</a></li>
<li><a href="../id476718/index.html">Sejarah radio nasional: Mussolini dari Radio Pedesaan dan lampu hangat Joseph Goebbels</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
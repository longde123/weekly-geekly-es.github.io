<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèø üí¶ üèÖ Wie Boston Dynamics BigDog eigenst√§ndig machte üéóÔ∏è üéà üõÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Letzte Woche haben wir herausgefunden , wie der legend√§re BigDog-Gangkoordinierungsalgorithmus funktioniert. Der Roboter war noch nicht autonom und ko...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie Boston Dynamics BigDog eigenst√§ndig machte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/smileexpo/blog/411711/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/dp/1q/lt/dp1qltdljsroi6gvosqy6ptauoe.jpeg"></div><br>  <i>Letzte Woche haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">herausgefunden</a> , wie der legend√§re BigDog-Gangkoordinierungsalgorithmus funktioniert.</i>  <i>Der Roboter war noch nicht autonom und konnte das Gel√§nde nur unter der Kontrolle des Bedieners √ºberqueren.</i> <i><br><br></i>  <i>Die meisten Leser bef√ºrworteten das letzte Mal die Idee einer neuen √úbersetzung - dar√ºber, wie BigDog gelernt hat, wie man selbst√§ndig zum richtigen Punkt geht und im Weltraum navigiert.</i>  <i>Nun, eigentlich ist er hier.</i> <a name="habracut"></a><br><br>  Das BigDog-Navigationssystem verwendet eine Kombination aus planarem Laserscanning, Stereovision und propriozeptiver Wahrnehmung.  Mit seiner Hilfe wird der Standort des Roboters in der Umgebung bestimmt.  Sie entdeckt Hindernisse und platziert sie in einem zweidimensionalen Modell der Welt.  Dann plant sie den Pfad und steuert den Roboter so, dass er dem gew√§hlten Pfad folgt.  Der Pfadplaner ist eine Variation des klassischen A * -Suchalgorithmus.  Der Gl√§ttungsalgorithmus verarbeitet die Ergebnisse und √ºbergibt sie an den Pfadverfolgungsalgorithmus.  Er berechnet die Lenkbefehle f√ºr BigDog. <br><br>  Das beschriebene System wurde in einer Waldzone mit vielen B√§umen, Felsbrocken und Unterholz getestet.  Zus√§tzlich zu den flachen Gebieten hatte es auch Steigungen (Winkel von bis zu 11 Grad).  Insgesamt wurden 26 Tests durchgef√ºhrt, von denen 88% erfolgreich waren.  Der Roboter "sah" das Gel√§nde in einem Radius von 130 Metern, wenn er sich mit einer bestimmten Geschwindigkeit bewegte, und √ºberwand mehr als 1,1 km. <br><br><h2>  Ausr√ºstung </h2><br>  <b>1) Propriozeptive Sensoren</b> <br><br>  Wird zur Steuerung des BigDog-Gangs und der autonomen Navigation verwendet.  Jeder der 16 aktiven und 4 passiven Freiheitsgrade des Roboters ist mit einem Sensor ausgestattet.  Sie liefern Daten zur aktuellen Position und Last.  Diese Informationen werden mit IMU-Daten kombiniert, um den Kontaktzustand mit dem Boden, die K√∂rperh√∂he und die Geschwindigkeit des K√∂rpers zu bewerten.  Dar√ºber hinaus zeigen eine Reihe von Sensoren den Zustand des Antriebs-, Rechen-, Hydraulik-, W√§rme- und anderer BigDog-Systeme an. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ul/d1/zt/uld1zt6ymgip1yrgosrwmepxl20.jpeg"></div><br>  <i>BigDog-Sensoren: a) GPS-Antenne;</i>  <i>b) Lidar;</i>  <i>c) Hummel-Stereokamera;</i>  <i>d) Honeywell IMU;</i>  <i>e) Gelenksensoren.</i> <br><br>  <b>2) Exterozeptive Sensoren</b> <br><br>  Der Roboter ist mit vier externen Sensoren ausgestattet: dem SICK LMS 291 Lidar, der Bumblebee PointGrey Stereokamera, dem NovAtel GPS Empf√§nger und der Honeywell IMU.  Daten von ihnen gelangen in das in der folgenden Abbildung gezeigte System. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/k5/ic/-w/k5ic-wirg74tc4ynnp8_5dmossi.png"></div><br>  <b>3) Computer</b> <br><br>  Um das System mit dem obigen Diagramm zu implementieren, werden zwei Computer verwendet.  Der BigDog-Hauptcomputer ist ein PC104 mit einem Single-Core-Intel Pentium M-Prozessor (1,8 GHz).  Es interagiert mit propriozeptiven Sensoren, steuert das Gleichgewicht und die Bewegung des Roboters, berechnet das aktuelle Modell der Umgebung und den Weg durch den Roboter und steuert auch den Gang. <br><br>  Vision wird von einem separaten Computer mit einem Intel CoreDuo-Prozessor (1,7 GHz) bereitgestellt.  Es kommuniziert mit zwei Kameras, erkennt Inkonsistenzen, wertet die visuelle Kilometerz√§hler aus und unterst√ºtzt eine 3D-Gel√§ndekarte.  Dieser Computer √ºbertr√§gt die Karten- und visuellen Kilometerz√§hlungsdaten mit einer Frequenz von 15 Hz √ºber das integrierte lokale Netzwerk an den Host-Computer. <br><br>  Der Vorteil eines solchen Systems besteht in der M√∂glichkeit, die Planungsaufgabe zu vereinfachen, indem sie in zwei Teile geteilt wird.  Die Daten von Lidar und Sensoren sind dreidimensional, aber wir k√∂nnen uns auf die Selbststabilisierung des Gangsteuersystems verlassen, um eine komplexere 3D-Wahrnehmung und -Planung aufzugeben. <br><br><h2>  Technischer Ansatz </h2><br>  In unserem allgemeinen technischen Ansatz verwenden wir Daten von zwei Umgebungssensoren, um Hindernisse zu erkennen, den Weg durch oder um Hindernisse zu berechnen und das Gangsteuerungssystem des Roboters anzuweisen, einem bestimmten Weg zu folgen. <br><br>  Der gesamte Prozess kann in drei Phasen unterteilt werden.  Zun√§chst werden Bilder vom Lidar und der Kamera verarbeitet, um eine Liste von Punkten zu erhalten, die auf Hindernisse in der Umgebung hinweisen.  Dann werden diese Punkte in disjunkte Objekte unterteilt und einige Zeit verfolgt.  Ferner werden diese Objekte zur Zuordnung im tempor√§ren Speicher kombiniert.  Diese Karte wird verwendet, um die Fahrtrichtung zu einem Zwischenziel zu planen.  Der Scheduler soll steuern, dass sich die BigDog-Trajektorien im richtigen Abstand zu Hindernissen befinden und dass die Trajektorien w√§hrend der Iterationen des Schedulers im Raum stabil sind.  Der Bewegungsalgorithmus entlang einer bestimmten Flugbahn zwingt den Roboter, dem beabsichtigten Pfad zu folgen, und sendet Geschwindigkeitsbefehle an das Gangsteuersystem.  Sie bewegt abwechselnd die Glieder des Roboters. <br><br><h3>  A. Sammlung von Informationen </h3><br>  <b>1) Einsch√§tzung der Situation</b> <br><br>  Es gibt zwei Quellen f√ºr odometrische Informationen: kinematische Sensoren in den Beinen und ein k√ºnstliches Sichtsystem.  Die daraus erhaltenen Daten werden kombiniert, um den Standort des Roboters zu bestimmen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9e/qp/xk/9eqpxkkl0tmlthiev_xbvilijbe.png"></div><br><br>  Das odometrische System berechnet anhand der kinematischen Informationen der Beine die Bewegungen des Roboters.  Das visuelle Kilometerz√§hlersystem √ºberwacht die visuellen Eigenschaften f√ºr die Berechnung der Bewegung.  Beide Tools verwenden ein Tr√§gheitsmessmodul (IMU) als Informationsquelle f√ºr die r√§umliche Orientierung.  Ein allgemeines Messger√§t kombiniert die Leistung dieser beiden Kilometerz√§hler und konzentriert sich auf die visuelle Kilometerz√§hler bei niedrigen Geschwindigkeiten und die Kinematik bei h√∂heren Geschwindigkeiten.  Die Kombination dieser beiden Indikatoren beseitigt die M√§ngel der einzelnen Z√§hler: den m√∂glichen Ausfall von Stereosystemen, die Abweichung der Kilometerst√§nde in den Gliedma√üen w√§hrend des Laufens an Ort und Stelle sowie die Fehler dieses Sensors entlang der vertikalen Achse. <br><br>  Das im BigDog-Roboter verwendete Lidar erzeugt alle 13 Millisekunden ein neues Bild.  Jedes Bild wird in ein externes Koordinatensystem mit der Mitte am Ort des Roboters umgewandelt.  In diesem Fall werden zeitsynchronisierte Informationen vom Standortz√§hler verwendet.  Die resultierende 3D-Punktwolke wird dann zur Verarbeitung durch den nachstehend beschriebenen Segmentierungsalgorithmus √ºbertragen.  In √§hnlicher Weise sammelt das stereoskopische Sichtsystem f√ºr einige Zeit Nichtkonformit√§tskarten, um eine 3D-Gel√§ndekarte auf einem 4 x 4 Meter gro√üen Quadrat zu erstellen, das auf dem Roboter zentriert ist.  Der r√§umliche Filter bestimmt die Bereiche mit signifikanten H√∂hen√§nderungen (d. H. Potenziellen Hindernissen) und √ºbertr√§gt eine Liste von Punkten, die zu diesen Bereichen geh√∂ren, an den Punktwolkensegmentierungsalgorithmus. <br><br>  <b>2) Punktwolkensegmentierung und Objektverfolgung</b> <br><br>  Aufgrund der Unregelm√§√üigkeiten der Erde und der Bewegungen des Roboters enth√§lt ein Teil der Lidar-Scannerdaten Bilder der Erde.  Reflexionen von langen Hindernissen (wie W√§nden) √§hneln Reflexionen von der Erdoberfl√§che.  F√ºr einen erfolgreichen Betrieb muss das System diese Reflexionen so interpretieren, dass es den Roboter in der N√§he der W√§nde steuern kann und keine ‚ÄûAngst‚Äú vor der Erde hat.  Der erste Schritt in diesem Prozess ist die Segmentierung der vom Lidar und der Gel√§ndekarte bereitgestellten Hindernispunkte in separate Objekte.  Seltene 3D-Punktwolken werden in Objekte segmentiert, indem einzelne Punkte zusammengef√ºhrt werden, die durch einen Abstand von weniger als 0,5 Metern voneinander getrennt sind. <br><br>  Objekte, die dank des Segmentierungsalgorithmus erhalten wurden, werden einige Zeit verfolgt.  Um diese Aufgabe zu erf√ºllen, verwenden wir einen gierigen iterativen Algorithmus mit heuristischen Einschr√§nkungen.  Das Objekt im aktuellen Bild stimmt mit dem n√§chstgelegenen Objekt des letzten Bildes √ºberein, sofern die Objekte nicht mehr als 0,7 Meter voneinander entfernt sind. <br><br>  Aufgrund der Tatsache, dass Punktwolken in Objekte unterteilt und f√ºr einige Zeit verfolgt werden, kann sich der Roboter in der Umgebung mit m√§√üigen Unebenheiten der Erde und verschiedenen Arten von Hindernissen angemessen bewegen: B√§ume, Kopfsteinpflaster, umgest√ºrzte Baumst√§mme, W√§nde.  B√§ume und W√§nde werden haupts√§chlich von einem Lidar-Scanner bestimmt, und Kopfsteinpflaster und Protokolle werden von einem stereoskopischen Sichtsystem bestimmt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tw/al/fy/twalfy7ylnbcl9a6gq1elkp79a8.jpeg"></div><br>  <i>Eine Folge von Abbildungen, die einen Roboter (gelbes Rechteck) zeigen, mit: a) Daten von einem Lidar (blaue Punkte), die in wenigen Sekunden aufgezeichnet wurden;</i>  <i>b) ihre jeweiligen Einrichtungen.</i>  <i>Hohe braune Gegenst√§nde sind B√§ume.</i>  <i>Bodenreflexionen werden transparent und flach dargestellt.</i>  <i>Der gr√ºne Zylinder ist das Ziel;</i>  <i>Die blaue Linie des berechneten Pfades f√ºhrt dorthin.</i>  <i>c) Draufsicht auf das Kartogramm: Bereiche mit dem niedrigsten t√∂dlichen Wert werden gr√ºn und Bereiche mit dem h√∂chsten Wert lila angezeigt.</i>  <i>Jede Gittereinheit entspricht 5 Metern.</i> <br><br><h3>  B. Navigationsplanung </h3><br>  Unser Ansatz zur L√∂sung des Navigationsproblems wird in der Robotergemeinschaft allgemein akzeptiert.  Hindernispunkte (aufgrund von Wahrnehmungsprozessen erhalten) werden auf einem Kartogramm mit der Mitte am Ort des Roboters aufgezeichnet.  Das endg√ºltige Ziel des Roboters wird auf die Grenze des Kartogramms projiziert und eine Variante des Algorithmus A ‚àó wird darauf angewendet.  Dieser Vorgang wird ungef√§hr einmal pro Sekunde wiederholt. <br><br>  <b>1) Erinnerung an verfolgte Hindernisse</b> <br><br>  Aufgrund des begrenzten Sichtfelds der beiden Sensoren des Roboters ist es unbedingt erforderlich, dass der Roboter eine genaue Erinnerung an Hindernisse beh√§lt, die er nicht mehr sehen kann.  Da die Objektliste vom Objektverfolgungssystem bereitgestellt wird, werden einzelne Objekte im Objektspeicher des Planungssystems hinzugef√ºgt, aktualisiert oder gel√∂scht.  Die Gr√∂√üe der Liste der Objekte ist begrenzt. Wenn also neue Objekte hinzugef√ºgt werden, m√ºssen andere gel√∂scht werden. <br><br>  Mit der aktuellen Liste der Objekte der Variablen O k√∂nnen wir zwei parametrisierte Unterklassen von O berechnen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e3/k3/lu/e3k3lua8asqfffo9e8cda22bqb4.jpeg"></div><br><br>  Hier ist Alter (q) die Differenz zwischen der aktuellen Zeit und der Zeit der letzten Messung des Objekts q, <br>  norm (q, r) inf - der Mindestabstand zwischen dem aktuellen Standort des Roboters und der Grenze des Objekts q. <br><br>  <b>Objekte werden nach folgenden Kriterien aus O gel√∂scht:</b> <br><br><ul><li>  Die Menge {P (30) ‚à© Q (15)} wird von O abgezogen. Dies sind Objekte, die √§lter als 30 Sekunden sind und sich nicht n√§her als 15 Meter am Roboter befinden. </li><li>  Die Menge {P (1800) ‚à© Q (10)} wird von O abgezogen. Dies sind Objekte, die √§lter als eine halbe Stunde sind und sich nicht n√§her als 10 Meter vom Roboter befinden. </li><li>  Objekte werden aus O entfernt, wenn das Listenlimit erreicht ist.  Die Priorit√§t des Objekts wird durch die Zeit bestimmt, in der es vom Tracker erfolgreich verfolgt wurde.  Mit anderen Worten, Objekte, die der Roboter l√§nger "sah", werden l√§nger im Speicher gespeichert. </li><li>  In den letzten 10 Sekunden verfolgte Objekte werden jedoch nicht verworfen. </li></ul><br>  Diese Zuweisung von Speicherressourcen f√ºhrt zu folgendem Verhalten: Wenn Objekte das Sichtfeld der Sensoren des Roboters verlassen, werden gel√∂schte Objekte und Objekte vergessen, die sie nicht mehrmals gesehen haben.  Objekte, die in Sichtweite oder unzug√§nglich sind, sich jedoch in der N√§he des Roboters befinden, werden nicht vergessen. <br><br>  <b>2) Erstellen eines Kartogramms</b> <br><br>  Wir verwenden ein Kartogramm, das auf der Grundlage eines 2D-Gitters erstellt wurde, um die Umgebung des Roboters darzustellen.  Anstatt dynamisch ein Kartogramm zu erstellen (wenn der Roboter neue Umgebungsinformationen erh√§lt), wird bei jeder Planungsiteration ein neues Kartogramm erstellt und mit Objekten aus dem Speicher des Planers gef√ºllt.  Daraus folgt, dass der dynamische Routenplaner nicht anstelle des A * -Algorithmus verwendet werden kann.  Da wir davon ausgehen, dass die Gr√∂√üe der Objekte begrenzt ist (dass das Fehlen einer Sackgasse in der Umgebung mehr als die H√§lfte der Karte betr√§gt), sind der Umfang der Planungsaufgabe und die Zeit f√ºr die Berechnung des Pfads gering. <br><br>  Das Kartogramm wird gem√§√ü dem folgenden Algorithmus mit Werten aus der Liste der Objekte gef√ºllt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vb/ld/cn/vbldcnab7njryzt9azsl-xt0soq.jpeg"></div><br><br>  Den Zellen, in denen sich die Objekte befinden, wird ein sehr hoher t√∂dlicher Wert zugewiesen.  Der Indikator f√ºr die Zellen in der N√§he des Objekts wird gem√§√ü der Funktion f gesetzt, die den aktuellen Abstand zu diesem Punkt ber√ºcksichtigt.  F√ºr die hier dargestellten Testergebnisse war f einfach der inverse W√ºrfel der Entfernung. <br><br>  Der Effekt dieses Ansatzes ist, dass er von Zellen mit einem sehr hohen Wert allm√§hlich abnimmt, wenn er sich von ihnen (und den von ihnen bezeichneten Objekten) entfernt. <br><br>  <b>3) Stabilit√§t des Pfades</b> <br><br>  Um sicherzustellen, dass wir BigDog nicht zuf√§llig und unsystematisch ‚Äûkontrollieren‚Äú, wird besonderes Augenmerk auf die Stabilit√§t des geplanten Pfades gelegt.  Es sollte durch Iterationen des Pfadplaners so stabil wie m√∂glich sein.  Dies erfolgt auf drei Arten. <br><br>  Erstens ist der an den A * -Algorithmus √ºbergebene Startpunkt nicht die aktuelle Position des Roboters, sondern die Projektion seiner Position am Endpunkt des zuvor vom A * -Algorithmus angegebenen Pfades (nennen wir diesen Punkt p).  Solange BigDog dem geplanten Pfad folgt, kann es seitlich geringf√ºgig davon abweichen.  Indem wir den Startpunkt auf den Punkt der vorherigen Berechnung des A * -Algorithmus projizieren, filtern wir die Schwankung der Position des Roboters heraus und die vom Scheduler angezeigten Pfade werden stabiler.  Wenn der Roboter mehr als den eingestellten Wert vom Pfad abweicht (standardm√§√üig 3 Meter), wird Punkt p einfach auf die aktuelle Position des Roboters √ºbertragen. <br><br>  Zweitens berechnen wir zur √úberpr√ºfung der Kontinuit√§t des Pfadplaners q - die Projektion der Position des Roboters von 2,5 Sekunden in der Vergangenheit bis zum letzten vom A * -Algorithmus berechneten Punkt.  Dann wird das Segment des letzten geplanten Pfades von q nach p zur Berechnung des neuen Pfades hinzugef√ºgt.  Infolgedessen verfolgt der Roboter eine kleine Strecke, die bereits zur√ºckgelegt wurde.  Dank dessen zeigt sich der Algorithmus zum Verfolgen des Pfades besser mit signifikanten Verst√∂√üen gegen die Position, auf die Roboter h√§ufig an ihren F√º√üen sto√üen. <br><br>  Drittens wird ein Teil des Verlaufs der geplanten Pfade im Speicher des Roboters gespeichert.  Diese Pfade werden verwendet, um die Werte der Zellen des Kartogramms zu reduzieren, in die der Roboter bereits gegangen ist, w√§hrend der Wert der Zellen in der Umgebung erh√∂ht wird.  Daher wiederholt ein neuer geplanter Pfad in derselben Richtung in der Regel den bereits vom Roboter zur√ºckgelegten Pfad (jedoch ohne strikte Garantie daf√ºr). <br><br>  <b>4) Pfadgl√§ttung</b> <br><br>  Der berechnete Pfad ist etwas gezackt, da er auf einem regul√§ren Raster basiert.  Wesentliche Richtungs√§nderungen k√∂nnen zu unerw√ºnschten Steuerbefehlen f√ºhren.  Um dies zu vermeiden, wird der De Boer-Gl√§ttungsalgorithmus angewendet. <br><br>  Dar√ºber hinaus f√ºhrt die gitterbasierte Pfadplanung h√§ufig zu technisch optimalen, aber weniger w√ºnschenswerten Pfaden zum Ziel.  Wir l√∂sen dieses Problem, indem wir f√ºr jede Iteration des Schedulers einen gegl√§tteten Pfad berechnen.  F√ºr nachfolgende Iterationen wird den Zellen des Kartogramms, in denen der gegl√§ttete Pfad verl√§uft, ein niedrigerer Wert zugewiesen.  Dies bietet einen direkteren und reibungsloseren Weg zum Ziel. <br><br><h3>  C. Gangkontrolle: Mobilit√§t und Gleichgewicht </h3><br>  Das Navigationsplanungssystem ermittelt ungef√§hr einmal pro Sekunde einen neuen Pfad.  Ein Algorithmus zum Folgen eines Pfades, der mit einer Frequenz von 200 Hz arbeitet, f√ºhrt den Roboter gem√§√ü dem zuletzt geplanten Pfad.  Dieser Algorithmus erstellt eine Reihe von Befehlen in Form der gew√ºnschten K√∂rpergeschwindigkeiten, einschlie√ülich Vorw√§rtsgeschwindigkeit, Quergeschwindigkeit und Gierrate des K√∂rpers.  Diese Geschwindigkeiten werden an den Gangregler √ºbertragen, der die Bewegung der Beine steuert. <br><br>  Basierend auf der Entfernung zwischen dem Roboter und dem Pfad wird eine von drei Strategien verwendet.  Befindet sich der Roboter in der N√§he eines Abschnitts des Pfades, beginnt er sich diagonal zu bewegen, bis er von der Seite mit voller Geschwindigkeit in ihn eintritt.  Wenn der Roboter weit vom Pfad entfernt ist, richtet er sich genau vorw√§rts zum gew√ºnschten Punkt.  In einer Zwischenposition wird eine Kombination dieser Strategien verwendet. <br><br>  Eine detaillierte Beschreibung der Gangsteuerungsalgorithmen w√ºrde den Rahmen dieses Artikels sprengen.  In der Regel dienen K√∂rpergeschwindigkeiten jedoch als Steuereingaben f√ºr BigDog-Gangregler mit niedrigem Pegel.  Der Gangregler erzeugt Kraft- und Positionsbefehle f√ºr jedes Gelenk, um Stabilit√§t zu gew√§hrleisten, reagiert auf Anomalien und liefert die erforderlichen K√∂rpergeschwindigkeiten.  Obwohl die Berechnungen des Path Investigator-Algorithmus f√ºr jeden BigDog-Gang verwendet werden k√∂nnen, ist das Trabrennen aufgrund der Geschwindigkeit und der F√§higkeit, unwegsames Gel√§nde zu √ºberqueren, optimal. <br><br><h2>  Feldtestergebnisse </h2><br>  Das oben beschriebene Sensor- und Navigationssystem wurde auf BigDog installiert und au√üerhalb des Labors getestet.  Die Tests wurden in einem Gebiet durchgef√ºhrt, in dem es viele B√§ume, Felsbrocken, Unterholz und H√ºgel mit H√§ngen von bis zu 11 Grad gab.  Abbildung 1 zeigt Landschaftsbeispiele.  Abbildung 2 zeigt die vom Roboter verarbeiteten Daten des Lidars. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o4/1y/ug/o41yug1warmbysmgjykntwplanc.jpeg"></div><br>  <i>Abb.</i>  <i>1. Das Gel√§nde, in dem die Tests durchgef√ºhrt wurden</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w6/_d/mq/w6_dmqlx8c_czcoay_rnoiy_4o4.jpeg"></div><br>  <i>Abb.</i>  <i>2. Testen, Draufsicht.</i>  <i>Bild von Lidar- und Stereokameras empfangen.</i>  <i>Dunkle Bereiche sind B√§ume und andere Hindernisse.</i>  <i>Die Maschenweite betr√§gt 5 Meter.</i> <br><br>  Das Navigationssystem und der Planer wurden √ºber einen Zeitraum von 7 Monaten entwickelt, wobei regelm√§√üige Tests etwa alle f√ºnf Wochen durchgef√ºhrt wurden.  Die Ergebnisse der letzten Tests werden hier beschrieben. <br><br>  Von den 26 durchgef√ºhrten Tests endeten 23 erfolgreich: Der Roboter erreichte das Ziel, stie√ü auf keines der Hindernisse und war diesem nicht nahe.  Die Ergebnisse dieser Tests sind in der PivotTable als Ziel gekennzeichnet.  Der Roboter fiel am Ende nur eines Tests, nachdem er auf einen kleinen Stein getreten war.  Normalerweise bew√§ltigt das Gangkontrollsystem solche Situationen, diesmal jedoch nicht (das Ergebnis ist in der Tabelle als Fall - ‚ÄûFall‚Äú gekennzeichnet).  In drei Tests stie√ü der Roboter auf gro√üe Hindernisse (mehr als 20 Meter breit).  Der Roboter berechnete, welche Seite am besten um das Hindernis herumkommt, und r√ºckte in einem bestimmten Zeitraum (20 Sekunden) nicht vor.  Hindernisse dieser Gr√∂√üe gehen √ºber den Rahmen hinaus, f√ºr den ein autonomes System entwickelt wurde.  Die Ergebnisse dieser Tests sind in der Tabelle als Live-Lock angegeben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/an/hu/mi/anhumiw32wo1mu8oc7dtcbgsirs.jpeg"></div><br><br>  In diesen 26 Tests wurde der Roboter in ziemlich √§hnlichen Szenarien und mitten im Wald platziert.  Wenn die Umgebung komplexer wird, steigt die Anzahl der Live-Lock-Ergebnisse und der Roboter w√§hlt weniger effiziente Pfade aus. <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interessanter - bei robo-hunter.com</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">frische Nachrichten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ;</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lebenslauf von Robotern</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ;</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Infografiken</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></li></ul><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unser YouTube-Kanal</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de411711/">https://habr.com/ru/post/de411711/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de411701/index.html">Die NASA gibt eine Mondtour in 4K erneut heraus</a></li>
<li><a href="../de411703/index.html">Xiaomi, geh r√ºber, Alfawise ist gekommen</a></li>
<li><a href="../de411705/index.html">Online-Dienst zum Vergleich von √Ñnderungen des Frequenzgangs und des Schalldrucks in Abh√§ngigkeit von der angelegten Spannung und der Quellenimpedanz</a></li>
<li><a href="../de411707/index.html">Nakraudfandili: die besten Projekte f√ºr M√§rz 2018</a></li>
<li><a href="../de411709/index.html">Preise f√ºr Haushaltsprodukte</a></li>
<li><a href="../de411713/index.html">Kryptanarchistisches Hauptquartier und Wasserpfeife f√ºr Bitcoins: Kryptow√§hrungsf√ºhrer f√ºr Prag</a></li>
<li><a href="../de411715/index.html">Gehirn, Drogen und Rock'n'Roll: Pers√∂nlichkeit und Forschung des musikalischsten Stand-Ups unter Neurowissenschaftlern</a></li>
<li><a href="../de411717/index.html">Fass in Fass. Essay 12. Welt der Ideen</a></li>
<li><a href="../de411719/index.html">Google entwickelt ein AR-Mikroskop zur schnellen Krebserkennung</a></li>
<li><a href="../de411721/index.html">Blinkende LED vom Linux-Kernelmodul</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>